{"title": [{"text": "An Analysis of Statistical Models and Features for Reading Difficulty Prediction", "labels": [], "entities": [{"text": "Reading Difficulty Prediction", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.8648074269294739}]}], "abstractContent": [{"text": "A reading difficulty measure can be described as a function or model that maps a text to a numerical value corresponding to a difficulty or grade level.", "labels": [], "entities": []}, {"text": "We describe a measure of read-ability that uses a combination of lexical features and grammatical features that are derived from subtrees of syntactic parses.", "labels": [], "entities": []}, {"text": "We also tested statistical models for nominal, ordinal, and interval scales of measurement.", "labels": [], "entities": []}, {"text": "The results indicate that a model for ordinal regression , such as the proportional odds model, using a combination of grammatical and lexical features is most effective at predicting reading difficulty.", "labels": [], "entities": []}], "introductionContent": [{"text": "A reading difficulty, or readability, measure can be described as a function or model that maps a text to a numerical value corresponding to a difficulty or grade level.", "labels": [], "entities": []}, {"text": "Inputs to this function are usually statistics for various lexical and grammatical features of the text.", "labels": [], "entities": []}, {"text": "The output is one of a set of ordered difficulty levels, usually corresponding to grade levels for elementary school through high school.", "labels": [], "entities": []}, {"text": "As such, reading difficulty prediction can be viewed as a regression of grade level on a set of textual features.", "labels": [], "entities": [{"text": "reading difficulty prediction", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.5575695832570394}]}, {"text": "Early work on readability measures employed simple proxies for grammatical and lexical complexity, including sentence length and the number of syllables in a word.", "labels": [], "entities": []}, {"text": "Fairly simple features were often employed because of alack of computational power.", "labels": [], "entities": []}, {"text": "Such features exhibit high bias because they rely on strong assumptions about what makes a text difficult to read.", "labels": [], "entities": []}, {"text": "For example, the use of sentence length as a measure of grammatical complexity assumes that a longer sentence is more grammatically complex than a shorter one, which is often but not always the case.", "labels": [], "entities": []}, {"text": "In one early model, the Dale-Chall model, reading difficulty is a linear function of the mean sentence length and the percentage of rare words, as defined by a list of 3,000 words commonly known by 4th grade.", "labels": [], "entities": []}, {"text": "In this paper, sentence length is defined as the mean number of words in the sentences of a text.", "labels": [], "entities": []}, {"text": "Many early measures did not employ direct estimates of word frequency due to computational limitations (e.g.,).", "labels": [], "entities": []}, {"text": "Instead, these measures relied on the strong relationship between the frequency of and the number of syllables in a word.", "labels": [], "entities": []}, {"text": "More frequent words are more likely to have fewer syllables (e.g., \"the\") than less frequent words (e.g., \"vocabulary\"), an association that is related to.", "labels": [], "entities": []}, {"text": "The Flesch-Kincaid measure) is probably the most common reading difficulty measure in use.", "labels": [], "entities": [{"text": "Flesch-Kincaid measure", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.9618504643440247}]}, {"text": "It is implemented in common word processing programs.", "labels": [], "entities": []}, {"text": "This measure is a linear function of the mean number of syllables per word and the mean number of words per sentence.", "labels": [], "entities": []}, {"text": "provides a summary of other early work on readability.", "labels": [], "entities": []}, {"text": "More recent approaches to reading difficulty employ more sophisticated models that make use of the growth in computational power.", "labels": [], "entities": [{"text": "reading difficulty", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9594388008117676}]}, {"text": "The Lexile Framework (e.g.,) uses individual word frequency estimates as a measure of lexical difficulty.", "labels": [], "entities": []}, {"text": "The word frequency estimates are derived from a large, varied corpus of text.", "labels": [], "entities": []}, {"text": "Lexile uses a Rasch model with the mean log word frequency as a lexical feature and the log of the mean sentence length as a grammatical feature.", "labels": [], "entities": [{"text": "Lexile", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9388651251792908}]}, {"text": "The Rasch model, related to logistic regression, is used to estimate the level of a student that would comprehend 75% of a given text.", "labels": [], "entities": []}, {"text": "The converted log odds ratio called a \"Lexile\" that is used as part of this measure can be easily mapped to grade school levels.", "labels": [], "entities": [{"text": "log odds ratio", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.6673480570316315}]}, {"text": "A reading difficulty measure developed by uses smoothed unigram language modeling to capture the predictive ability of individual words based on their frequency at each reading difficulty level.", "labels": [], "entities": []}, {"text": "Collins-Thompson and Callan found that certain words were very predictive of certain levels.", "labels": [], "entities": []}, {"text": "For example, \"grownup\" was very predictive of grade 1, and \"essay\" was very predictive of grade 12.", "labels": [], "entities": []}, {"text": "For a given text, this measure estimates the likelihood that the text was generated by each level's language model.", "labels": [], "entities": []}, {"text": "The prediction is the level of the model with the highest likelihood of generating the text.", "labels": [], "entities": []}, {"text": "There are no grammatical features.", "labels": [], "entities": []}, {"text": "Natural language processing techniques enable more sophisticated grammatical analysis for reading difficulty measures.", "labels": [], "entities": []}, {"text": "Rather than using sentence length as a proxy, measures can employ tools for automatic analysis of the syntactic structure of texts (e.g.,.", "labels": [], "entities": []}, {"text": "A measure by incorporates syntactic analyses, among a variety of other types of features.", "labels": [], "entities": []}, {"text": "It includes four grammatical features derived from syntactic parses of text: the mean parse tree height, the mean number of noun phrases, mean number of verb phrases, and mean number of \"SBARs.\"", "labels": [], "entities": [{"text": "mean number of \"SBARs", "start_pos": 171, "end_pos": 192, "type": "METRIC", "confidence": 0.872257399559021}]}, {"text": "\"SBARs\" are non-terminal nodes that are associated with subordinate clauses.", "labels": [], "entities": []}, {"text": "Their system led to better predictions than the Flesch-Kincaid and Lexile measures, but the predictive value of the grammatical features is not entirely clear.", "labels": [], "entities": []}, {"text": "In initial experiments using such course-grain grammatical features alone, rather than in conjunction with language modeling and other features as in Schwarm and Ostendorf's system, we found relatively poor prediction performance.", "labels": [], "entities": []}, {"text": "Our final approach using subtrees of syntactic parses allows fora finer level of discrimination that may support the detection of differences in grade levels between texts that exhibit the same high level features.", "labels": [], "entities": []}, {"text": "A reading difficulty measure developed by Heilman, uses the frequency of grammatical constructions as a measure of grammatical difficulty.", "labels": [], "entities": []}, {"text": "A set of approximately twenty constructions were selected from English as a Second Language grammar textbooks.", "labels": [], "entities": []}, {"text": "This set includes grammatical constructions such as the passive voice, relative clauses, and various verb tenses.", "labels": [], "entities": []}, {"text": "The frequencies are used as features fora nearest neighbor classification algorithm.", "labels": [], "entities": [{"text": "nearest neighbor classification", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7065986196200053}]}, {"text": "The unigram language modeling approach of is used to estimate lexical difficulty in this measure.", "labels": [], "entities": []}, {"text": "The final prediction is a linear function of the lexical and grammatical components.", "labels": [], "entities": []}, {"text": "That model assumes that grammatical difficulty is adequately captured by a small number of constructions chosen according to detailed knowledge of English grammar.", "labels": [], "entities": []}, {"text": "In that work, the constructions were selected from an English as a Second Language grammar textbook, a labor-and knowledge-intensive task that maybe less practical for other languages.", "labels": [], "entities": []}, {"text": "We aim to identify the appropriate scale of measurement for reading difficulty-nominal, ordinal, or interval-by comparing the effectiveness of statistical models for each type of data.", "labels": [], "entities": []}, {"text": "We also extend previous work combining lexical and grammatical features ( by making it possible to include a large number of grammatical features derived from syntactic structures without requiring significant linguistic or pedagogical content knowledge, such as a reference guide for the grammar of the language of interest.", "labels": [], "entities": []}], "datasetContent": [{"text": "Root mean square error (RMSE), Pearson's correlation coefficient, and accuracy within 1 grade level served as metrics for evaluating the performance of reading difficulty predictions.", "labels": [], "entities": [{"text": "Root mean square error (RMSE)", "start_pos": 0, "end_pos": 29, "type": "METRIC", "confidence": 0.9176029477800641}, {"text": "Pearson's correlation coefficient", "start_pos": 31, "end_pos": 64, "type": "METRIC", "confidence": 0.889594316482544}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9994882345199585}]}, {"text": "Multiple statistics were used because it is not entirely clear what the best measure of prediction quality is for reading difficulty.", "labels": [], "entities": []}, {"text": "RMSE is the square root of the empirical mean of the squared error of predictions.", "labels": [], "entities": [{"text": "RMSE", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9757161140441895}]}, {"text": "It more strongly penalizes those errors that are further away from the true value.", "labels": [], "entities": []}, {"text": "It can be interpreted as the average number of grade levels that predictions measure deviate from human-assigned labels.", "labels": [], "entities": []}, {"text": "Pearson's correlation coefficient measures the strength of the linear relationship, or similarity of trends, between two random variables.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient", "start_pos": 0, "end_pos": 33, "type": "METRIC", "confidence": 0.622665748000145}]}, {"text": "A high correlation would indicate that difficult texts would more likely receive high predicted difficulty values, and easier texts would be more likely to receive low predicted difficulty values.", "labels": [], "entities": []}, {"text": "Correlations do not, however, measure the degree to which values match in absolute terms.", "labels": [], "entities": []}, {"text": "Adjacent accuracy is the proportion of predictions that were within one grade level of the humanassigned label for the given text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.7858500480651855}]}, {"text": "Exact accuracy is too stringent a measure because the human-assigned reading levels are not always perfect and consistent.", "labels": [], "entities": [{"text": "Exact", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8942548036575317}, {"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.8081018328666687}]}, {"text": "For example, one school might read \"Romeo and Juliet\" in 9th grade while another school might read it in 10th grade.", "labels": [], "entities": [{"text": "\"Romeo and Juliet\"", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7439178228378296}]}, {"text": "The drawback of this accuracy metric is that predictions that are two levels off are treated the same as predictions that are ten levels off.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9986333250999451}]}], "tableCaptions": [{"text": " Table 1: Results from Cross-Validation and Test Set Evaluations, as measured by Correlation Coefficients (Correl.),  Root Mean Square Error (RMSE), and Adjacent Accuracy. The best result for each metric for each evaluation is  given in bold. Asterisks indicate significant differences compared to the PO model with a Combined Feature Set. * =  p < .05, ** = p < .01.", "labels": [], "entities": [{"text": "Root Mean Square Error (RMSE)", "start_pos": 118, "end_pos": 147, "type": "METRIC", "confidence": 0.9378897632871356}, {"text": "Adjacent Accuracy", "start_pos": 153, "end_pos": 170, "type": "METRIC", "confidence": 0.8204859495162964}]}]}