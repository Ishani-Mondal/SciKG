{"title": [{"text": "Automatic Identification of Discourse Moves in Scientific Article Introductions", "labels": [], "entities": [{"text": "Automatic Identification of Discourse Moves in Scientific Article Introductions", "start_pos": 0, "end_pos": 79, "type": "TASK", "confidence": 0.7427011297808753}]}], "abstractContent": [{"text": "This paper reports on the first stage of building an educational tool for international graduate students to improve their academic writing skills.", "labels": [], "entities": []}, {"text": "Taking a text-categorization approach, we experimented with several models to automatically classify sentences in research article introductions into one of three rhetorical moves.", "labels": [], "entities": []}, {"text": "The paper begins by situating the project within the larger framework of intelligent computer-assisted language learning.", "labels": [], "entities": []}, {"text": "It then presents the details of the study with very encouraging results.", "labels": [], "entities": []}, {"text": "The paper then concludes by commenting on how the system maybe improved and how the project is intended to be pursued and evaluated.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We performed five-fold cross validation on 14 different feature sets as summarized in.", "labels": [], "entities": []}, {"text": "The results of these experiments are summarized in.", "labels": [], "entities": []}, {"text": "Accuracy shows the proportion of classifications that agreed with the manually assigned labels.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9841411113739014}]}, {"text": "The other two performance measures, precision and recall, are commonly used in information retrieval, text categorization, and other NLP applications.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9994637370109558}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9980940222740173}, {"text": "information retrieval", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.8115377128124237}, {"text": "text categorization", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7949225306510925}]}, {"text": "For each category, precision measure what proportion of the items assigned to that category actually belonged to it, and recall measures what proportion of the items actually belonging to a category were labeled correctly.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9997797608375549}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9995131492614746}]}, {"text": "The measures reported here (macro-precision\u02c6\u03c0precision\u02c6 precision\u02c6\u03c0 M and macro-recal\u00ee \u03c1 M ) are weighted means of class precision and recall over the three moves.", "labels": [], "entities": [{"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9174399971961975}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9963577389717102}]}, {"text": "The figures show that the unigram models result in the best recall and the trigram models, the best precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9995044469833374}, {"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.999135434627533}]}, {"text": "Generally, we attribute lower recall to the sparseness of the data.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.999483585357666}]}, {"text": "Access to more training data will help improve recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.996826171875}]}, {"text": "We should also note the behavior of the models with respect to bigram features.", "labels": [], "entities": []}, {"text": "As seen on, increasing the size of the bigram feature set causes a decline in model precision and arise in model recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9869274497032166}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9819746613502502}]}, {"text": "Considering that there are far more frequent bigrams than unigrams or trigrams (cf. Table 4), this behavior is not surprising.", "labels": [], "entities": []}, {"text": "Including more bigrams will increase recall because there are more possible phrases to indicate a move, but that will also result in a decline in precision because those bigrams may also frequently appear in other moves.", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9993205070495605}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9991115927696228}]}, {"text": "It also seems that a model employing unigram, bigram and trigrams all will perform better than each individual model.", "labels": [], "entities": []}, {"text": "We are planning to experiment with these feature sets, as well.", "labels": [], "entities": []}, {"text": "3,000 4 Bigrams 1,000 5 2,000 6 3,000 7", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Disciplines represented in the corpus for article  introductions", "labels": [], "entities": [{"text": "article  introductions", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7125130593776703}]}, {"text": " Table 5: Interannotator agreement on 487 sentences.", "labels": [], "entities": []}]}