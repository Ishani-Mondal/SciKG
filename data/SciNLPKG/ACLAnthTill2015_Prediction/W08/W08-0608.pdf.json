{"title": [{"text": "Cascaded Classifiers for Confidence-Based Chemical Named Entity Recognition", "labels": [], "entities": [{"text": "Confidence-Based Chemical Named Entity Recognition", "start_pos": 25, "end_pos": 75, "type": "TASK", "confidence": 0.6685926735401153}]}], "abstractContent": [{"text": "Chemical named entities represent an important facet of biomedical text.", "labels": [], "entities": []}, {"text": "We have developed a system to use character-based n-grams, Maximum Entropy Markov Models and rescoring to recognise chemical names and other such entities, and to make confidence estimates for the extracted entities.", "labels": [], "entities": []}, {"text": "An adjustable threshold allows the system to be tuned to high precision or high recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9985131621360779}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9989625215530396}]}, {"text": "At a threshold set for balanced precision and recall, we were able to extract named entities at an F score of 80.7% from chemistry papers and 83.2% from PubMed abstracts.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9968138337135315}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9991349577903748}, {"text": "F score", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9883173406124115}]}, {"text": "Furthermore, we were able to achieve 57.6% and 60.3% recall at 95% precision, and 58.9% and 49.1% precision at 90% recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9988998174667358}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9970026612281799}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9977868795394897}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.991591215133667}]}, {"text": "These results show that chemical named entities can be extracted with good performance, and that the properties of the extraction can be tuned to suit the demands of the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Systems for the recognition of biomedical named entities have traditionally worked on a 'first-best' approach, where all of the entities recognised have equal status, and precision and recall are given roughly equal importance.", "labels": [], "entities": [{"text": "recognition of biomedical named entities", "start_pos": 16, "end_pos": 56, "type": "TASK", "confidence": 0.8727969527244568}, {"text": "precision", "start_pos": 171, "end_pos": 180, "type": "METRIC", "confidence": 0.9994766116142273}, {"text": "recall", "start_pos": 185, "end_pos": 191, "type": "METRIC", "confidence": 0.9992826581001282}]}, {"text": "This does not reflect that fact that precision is of greater importance for some applications, and recall is the key for others.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9989019632339478}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9983441829681396}]}, {"text": "Furthermore, knowing the confidence 1 with which the system has assigned the named entities is likely to be useful in a range of different applications.", "labels": [], "entities": []}, {"text": "Named entities of relevance to biomedical science include not only genes and proteins but also other chemical substances which can be of interest as drugs, metabolites, nutrients, enzyme cofactors, experimental reagents and in many other roles.", "labels": [], "entities": []}, {"text": "We have recently investigated the issue of chemical named entities , by compiling a set of manual annotation guidelines, demonstrating 93% interannotator agreement and manually annotating a set of 42 chemistry papers.", "labels": [], "entities": []}, {"text": "In this paper we demonstrate a named entity recogniser that assigns a confidence score to each named entity, allowing it to be tuned for high precision or recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9976551532745361}, {"text": "recall", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9894288182258606}]}, {"text": "Our review of the methods of chemical named entity recognition showed a consistent theme: the use of character-based n-Grams to identify chemical names via their constituent substrings).", "labels": [], "entities": [{"text": "chemical named entity recognition", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.6915611028671265}]}, {"text": "This can be a powerful technique, due to systematic and semisystematic chemical names and additional conventions in drug names.", "labels": [], "entities": []}, {"text": "However this technique does not coverall aspects of chemical nomenclature.", "labels": [], "entities": [{"text": "chemical nomenclature", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.738571435213089}]}, {"text": "Much current named entity work uses approaches which combine the structured prediction abilities of HMMs and their derivatives with techniques which enable the use of large, diverse feature sets such as maximum entropy (also known as logistic regression).", "labels": [], "entities": []}, {"text": "Maximum Entropy Markov Models, (MEMMs) () provide a relatively simple framework for this.", "labels": [], "entities": []}, {"text": "MEMMs do have a theoretical weakness, namely the \"label bias\" problem (), which has been ad-dressed with the development of Conditional Random Fields (CRFs).", "labels": [], "entities": []}, {"text": "CRFs are now a mainstay of the field, being used in a high proportion of entries in the latest BioCreative evaluation.", "labels": [], "entities": [{"text": "BioCreative evaluation", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.5823628604412079}]}, {"text": "However, despite the label bias problem, MEMMs still attract interest due to practical advantages such as shorter training cycles.", "labels": [], "entities": [{"text": "MEMMs", "start_pos": 41, "end_pos": 46, "type": "TASK", "confidence": 0.9202405214309692}]}, {"text": "The framework of HMMs and their successors offers three modes of operation; first-best, n-best and confidence-based.", "labels": [], "entities": []}, {"text": "In first-best NER, the Viterbi algorithm is used to identify a single sequence of labels for the target sentence.", "labels": [], "entities": [{"text": "NER", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.872591495513916}]}, {"text": "In n-best operation, then best sequences for the sentence are identified, along with their probabilities, for example by coupling the Viterbi algorithm with A* search.", "labels": [], "entities": []}, {"text": "In confidence-based operation, potential entities (with a probability above a threshold) are identified directly, without directly seeking a single optimal labelling for the entire sentence.", "labels": [], "entities": []}, {"text": "This is done by examining the probability of the label transitions within the entity, and the forward and backward probabilities at the start and end of the entity.", "labels": [], "entities": []}, {"text": "This mode has been termed the Constrained ForwardBackward algorithm ().", "labels": [], "entities": []}, {"text": "Where a single unambiguous non-overlapping labelling is required, it can be obtained by identifying cases where the entities overlap, and discarding those with lower probabilities.", "labels": [], "entities": []}, {"text": "Confidence-based extraction has two main advantages.", "labels": [], "entities": [{"text": "Confidence-based extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.777008444070816}]}, {"text": "First, it enables the balance between precision and recall to be controlled by varying the probability threshold.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9995062351226807}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9988767504692078}]}, {"text": "Second, confidence-based NER avoids over-commitment in systems where it is used as a preprocessor, since multiple overlapping options can be used as input to later components.", "labels": [], "entities": [{"text": "NER", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9520494937896729}]}, {"text": "The optimum balance between recall and precision depends on the application of the NER and on the other components in the system.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.999173104763031}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.999049961566925}]}, {"text": "High precision is useful in search even when recall is low when there is a large degree of redundancy in the information in the original documents.", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9984503984451294}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9970428347587585}]}, {"text": "High precision NER may also be useful in contexts such as the extraction of seed terms for clustering algorithms.", "labels": [], "entities": []}, {"text": "Balanced precision/recall is often appropriate for search, although in principle it is desirable to be able to shift the balance if there are too many/too few results.", "labels": [], "entities": [{"text": "Balanced", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9269813895225525}, {"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.8472632765769958}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9875978827476501}]}, {"text": "Balanced precision/recall is also generally assumed for use in strictly pipelined systems, when a single set of consistent NER results is to be passed onto subsequent processing.", "labels": [], "entities": [{"text": "Balanced", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.931119978427887}, {"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.6066470146179199}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9460196495056152}]}, {"text": "Contexts where high recall is appropriate include those where a search is being carried out where there is little redundancy or where the NER system is being used with other components which can filter the results.", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9983546137809753}]}, {"text": "One use of our NER system is within a language processing architecture () that systematically allows for ambiguity by treating the input/output of each component as a lattice (represented in terms of standoff annotation on an original XML document).", "labels": [], "entities": []}, {"text": "This system exploits relatively deep parsing, which is not fully robust to NER errors but which can exploit complex syntactic information to select between candidate NER results.", "labels": [], "entities": [{"text": "NER", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9376096725463867}]}, {"text": "NER preprocessing is especially important in the context of chemistry terms which utilise punctuation characters (e.g., '2,4-dinitrotoluene', '2,4-and 2,6-dinitrotoluene') since failure to identify these will lead to tokenisation errors in the parser.", "labels": [], "entities": []}, {"text": "Such errors frequently cause complete parse failure, or highly inaccurate analyses.", "labels": [], "entities": []}, {"text": "In our approach, the NER results contribute edges to a lattice which can (optionally) be treated as tokens by the parser.", "labels": [], "entities": []}, {"text": "The NER results may compete with analyses provided by the main parser lexicon.", "labels": [], "entities": [{"text": "NER", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8549169898033142}]}, {"text": "In this context, some NER errors are unimportant: e.g., the parser is not sensitive to all the distinctions between types of named entity.", "labels": [], "entities": []}, {"text": "In other cases, the parser will filter the NER results.", "labels": [], "entities": []}, {"text": "Hence it makes sense to emphasise recall over precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9950146079063416}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9968588352203369}]}, {"text": "We also hypothesise that we will be able to incorporate the NER confidence scores as features in the parse ranking model.", "labels": [], "entities": [{"text": "NER confidence scores", "start_pos": 60, "end_pos": 81, "type": "METRIC", "confidence": 0.6195505261421204}]}, {"text": "Another example of the use of high-recall NER in an integrated system is shown in the editing workflows used by the Royal Society of Chemistry in their Project Prospect system (, where chemical named entity recognition is used to produce semantically-enriched journal articles.", "labels": [], "entities": [{"text": "chemical named entity recognition", "start_pos": 185, "end_pos": 218, "type": "TASK", "confidence": 0.7233795821666718}]}, {"text": "In this situation, high recall is desirable, as false positives can be removed in two ways; by removing entities where a chemical structure cannot be assigned, and by having them checked by a technical editor.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9986922144889832}]}, {"text": "False negatives are harder to correct.", "labels": [], "entities": [{"text": "False negatives", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9556813538074493}]}, {"text": "The use of confidence-based recognition has been demonstrated with CRFs in the domain of contact details (, and using HMMs in the domain of gene annotation).", "labels": [], "entities": [{"text": "confidence-based recognition", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.6327241212129593}]}, {"text": "In the latter case, the LingPipe toolkit was used in the BioCreative 2 evaluation without significant adaptation.", "labels": [], "entities": [{"text": "LingPipe toolkit", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.9330546855926514}, {"text": "BioCreative 2 evaluation", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.6043286224206289}]}, {"text": "Although only 54% precision was achieved at 60% recall (the best systems were achieving precision and recall scores in the high eighties), the system was capable of 99.99% recall with 7% precision, and 95% recall with 18% precision, indicating that very high recall could be obtained in this difficult domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9993785619735718}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9980360865592957}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9986708164215088}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9807767271995544}, {"text": "recall", "start_pos": 172, "end_pos": 178, "type": "METRIC", "confidence": 0.9959414601325989}, {"text": "precision", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.9916866421699524}, {"text": "recall", "start_pos": 206, "end_pos": 212, "type": "METRIC", "confidence": 0.9977341890335083}, {"text": "precision", "start_pos": 222, "end_pos": 231, "type": "METRIC", "confidence": 0.9967032074928284}, {"text": "recall", "start_pos": 259, "end_pos": 265, "type": "METRIC", "confidence": 0.9983648657798767}]}, {"text": "Another potential use of confidence-based NER is the potential to rescore named entities.", "labels": [], "entities": [{"text": "NER", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9046359062194824}]}, {"text": "In this approach, the NER system is run, generating a set of named entities.", "labels": [], "entities": []}, {"text": "Information obtained about these entities throughout the document (or corpus) that they occur in can then be used in further classifiers.", "labels": [], "entities": []}, {"text": "We are not aware of examples of rescoring being applied to confidence-based NER, but there are precedents using other modes of operations.", "labels": [], "entities": [{"text": "NER", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.8554820418357849}]}, {"text": "For example, describe a system where a first-best CRF is used to analyse a corpus, the results of which are then used to generate additional features to use in a second first-best CRF.", "labels": [], "entities": []}, {"text": "Similarly, use an nbest MEMM to generate multiple analyses fora sentence, and re-rank the analyses based on information extracted from neighbouring sentences.", "labels": [], "entities": []}, {"text": "Therefore, to explore the potential of these techniques, we have produced a chemical NER system that uses a MEMM for confidence-based extraction of named entities, with an emphasis on the use of character-level n-Grams, and a rescoring system.", "labels": [], "entities": [{"text": "NER", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.909271240234375}, {"text": "confidence-based extraction of named entities", "start_pos": 117, "end_pos": 162, "type": "TASK", "confidence": 0.7265499234199524}]}], "datasetContent": [{"text": "The systems were evaluated by 3-fold crossvalidation methodology, whereby the data was split into three equal folds (in the case of the chemistry Ina document containing both \"ethyl acetate\" and \"ethyl group\", it would be detrimental to allow the low confidence for the \"ethyl\" in \"ethyl acetate\" to lower the confidence of the \"ethyl\" in \"ethyl group\".", "labels": [], "entities": [{"text": "Ina document", "start_pos": 146, "end_pos": 158, "type": "DATASET", "confidence": 0.908402293920517}]}, {"text": "papers, each fold consists of one paper per journal.", "labels": [], "entities": []}, {"text": "For the PubMed abstracts, each fold consists of one third of the total abstracts).", "labels": [], "entities": [{"text": "PubMed abstracts", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.9540107548236847}]}, {"text": "For each fold, the system was trained on the other two folds and then evaluated on that fold, and the results were pooled.", "labels": [], "entities": []}, {"text": "The direct output from the system is a list of putative named entities with start positions, end positions, types and confidence scores.", "labels": [], "entities": []}, {"text": "This list was sorted in order of confidence-most confident first-and each entity was classified as a true positive or a false positive according to whether an exact match (start position, end position and type all matched perfectly) could be found in the annotated corpus.", "labels": [], "entities": []}, {"text": "Also, the number of entities in the annotated corpus was recorded.", "labels": [], "entities": []}, {"text": "Precision/recall curves were plotted from these lists by selecting the first n elements, and calculating precision and recall taking all of the elements in this sublist as true or false positives, and all the entities in the corpus that were not in the sublist as false negatives.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9609546065330505}, {"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8478519320487976}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9995039701461792}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9980486631393433}]}, {"text": "The value of n was gradually increased, recording the scores at each point.", "labels": [], "entities": []}, {"text": "The area under the curve (treating precision as zero at recall values higher than the highest reported) was used to calculate mean average precision (MAP).", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9988565444946289}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9947493672370911}, {"text": "mean average precision (MAP)", "start_pos": 126, "end_pos": 154, "type": "METRIC", "confidence": 0.9165692031383514}]}, {"text": "Finally, F were generated by selecting all of the entities with a confidence score of 0.3 or higher.", "labels": [], "entities": [{"text": "F", "start_pos": 9, "end_pos": 10, "type": "METRIC", "confidence": 0.9832541346549988}]}, {"text": "The results of this evaluation on the corpus of chemistry papers is show in.", "labels": [], "entities": []}, {"text": "The full system achieves 57.6% recall at 95% precision, 58.9% precision at 90% recall, and 78.7% precision and 82.9% recall (F = 80.7%) at a confidence threshold of 0.3.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9992683529853821}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9969642758369446}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9990148544311523}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9817467927932739}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.998235821723938}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9516200423240662}, {"text": "F", "start_pos": 125, "end_pos": 126, "type": "METRIC", "confidence": 0.9411700367927551}]}, {"text": "Also shown are the results of successively eliminating parts of the system.", "labels": [], "entities": []}, {"text": "\"No Rescorer\" removes the rescorer.", "labels": [], "entities": [{"text": "rescorer", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9647629261016846}]}, {"text": "In \"No Preclassifier\", the preclassifier is disabled, and all of the dictionaries extracted during the training of the preclassifier are also disabled.", "labels": [], "entities": []}, {"text": "Finally, in \"No n-Grams\", the 1-, 2-, 3-and 4-grams used directly by the MEMM are also disabled, showing the results of using a system where no character-level n-grams are used at all.", "labels": [], "entities": []}, {"text": "These modifications apply successively-for example, in the \"No n-Grams\" case the rescorer and preclassifier are also disabled.", "labels": [], "entities": []}, {"text": "These results validate the the cascade of classifiers, and underline the importance of character-level n-grams in chemical NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.7397734522819519}]}, {"text": "We also show comparisons to an HMM-based approach, based on LingPipe 3.4.0. 6 This is essentially the same system as described by , but operating in a confidence-based mode.", "labels": [], "entities": [{"text": "LingPipe 3.4.0. 6", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.946773370107015}]}, {"text": "The HMMs used make use of character-level n-Grams, but do not allow the use of the rich feature set used by the MEMM.", "labels": [], "entities": []}, {"text": "The line \"Customised LingPipe HMM\" shows the system using the custom tokenisation and ChEBI-derived dictionary used in the MEMM system, whereas the \"Pure LingPipe HMM\" shows the system used with the default tokeniser and no external dictionaries.", "labels": [], "entities": []}, {"text": "In the region where precision is roughly equal to recall (mimicking the operation of a first-best system), the fact that the MEMM-based system outperforms an HMM is no surprise.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9991675615310669}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9990972280502319}]}, {"text": "However, it is gratifying that a clear advantage can be seen throughout the whole recall range studied (0-97%), indicating that the training processes for the MEMM are not excessively attuned to the first-best decision boundary.", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9943086504936218}]}, {"text": "This increased accuracy comes at a price in the speed of development, training and execution.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9994480013847351}]}, {"text": "It is notable that we were notable to achieve extremes of recall at tolerable levels of precision using any of the systems, whereas it was possible for LingPipe to achieve 99.99% recall at 7% precision in the BioCreative 2006 evaluation.", "labels": [], "entities": [{"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9991777539253235}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9982511401176453}, {"text": "LingPipe", "start_pos": 152, "end_pos": 160, "type": "DATASET", "confidence": 0.9291114211082458}, {"text": "recall", "start_pos": 179, "end_pos": 185, "type": "METRIC", "confidence": 0.99407958984375}, {"text": "precision", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.9852231740951538}, {"text": "BioCreative 2006 evaluation", "start_pos": 209, "end_pos": 236, "type": "DATASET", "confidence": 0.9023208618164062}]}, {"text": "There area number of potential reasons for this.", "labels": [], "entities": []}, {"text": "The first is that the 6 http://alias-i.com/lingpipe/ tokeniser used in all systems apart from the \"Pure LingPipe HMM\" system tries in general to make as few token boundaries as possible; this leads to some cases where the boundaries of the entities to be recognised in the test paper occur in the middle of tokens, thus making those entities unrecognisable whatever the threshold.", "labels": [], "entities": [{"text": "Pure LingPipe HMM\" system", "start_pos": 99, "end_pos": 124, "type": "DATASET", "confidence": 0.7441960275173187}]}, {"text": "However this does not appear to be the whole problem.", "labels": [], "entities": []}, {"text": "Other factors that may have had an influence include the more generous method of evaluation at BioCreative 2006, (where several allowable alternatives were given for difficult named entities), and the greater quantity and diversity (sentences selected from a large number of different texts, rather than a relatively small number of whole full papers) of training data.", "labels": [], "entities": [{"text": "BioCreative 2006", "start_pos": 95, "end_pos": 111, "type": "DATASET", "confidence": 0.8000252544879913}]}, {"text": "Finally, there might be some important difference between chemical names and gene names.", "labels": [], "entities": []}, {"text": "shows the results of running the system on the set of annotated PubMed abstracts.", "labels": [], "entities": []}, {"text": "The full system achieves 60.3% recall at 95% precision, 49.1% precision at 90% recall, and 85.0% precision and 81.6% recall (F = 83.2%) at a confidence threshold of 0.3.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9992187023162842}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9973912239074707}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9989896416664124}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9808792471885681}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9963850975036621}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9889106750488281}, {"text": "F", "start_pos": 125, "end_pos": 126, "type": "METRIC", "confidence": 0.9455616474151611}]}, {"text": "In PubMed abstracts, it is common to define ad-hoc abbreviations for chemicals within an abstract (e.g., the abstract might say 'dexamethasone (DEX)', and then use 'DEX' and not 'dexamethasone' throughout the rest of the abstract).", "labels": [], "entities": []}, {"text": "The rescorer provides a good place to resolve these ab-breviations, and thus has a much larger effect than in the case of chemistry papers where these ad hoc abbreviations are less common.", "labels": [], "entities": []}, {"text": "It is also notable that the maximum recall is lower in this case.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9856525659561157}]}, {"text": "One system-the \"Pure LingPipe HMM\", which uses a different, more aggressive tokeniser from the other systems-has a clear advantage in terms of maximum recall, showing that overcautious tokenisation limits the recall of the other systems.", "labels": [], "entities": [{"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9890657663345337}, {"text": "recall", "start_pos": 209, "end_pos": 215, "type": "METRIC", "confidence": 0.9981221556663513}]}, {"text": "In some cases the systems studied behave strangely, having \"spikes\" of lowered precision at very low recall, indicating that the systems can occasionally be overconfident, and assign very high confidence scores to incorrect named entities.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9975516200065613}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9979669451713562}]}], "tableCaptions": [{"text": " Table 1: Named Entity types. n Ch = number in Chem- istry corpus, n P M = number in PubMed corpus.", "labels": [], "entities": [{"text": "PubMed corpus", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.9712401330471039}]}, {"text": " Table 2: F scores (at confidence threshold of 0.3) and  Mean Average Precision (MAP) values for Figs. 1-3.", "labels": [], "entities": [{"text": "F scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9788331985473633}, {"text": "Mean Average Precision (MAP)", "start_pos": 57, "end_pos": 85, "type": "METRIC", "confidence": 0.9759274621804556}]}]}