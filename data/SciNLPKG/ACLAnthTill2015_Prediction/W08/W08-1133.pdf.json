{"title": [{"text": "Referring Expression Generation Using Speaker-based Attribute Selection and Trainable Realization (ATTR)", "labels": [], "entities": [{"text": "Referring Expression Generation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9158490896224976}]}], "abstractContent": [{"text": "In the first REG competition, researchers proposed several general-purpose algorithms for attribute selection for referring expression generation.", "labels": [], "entities": [{"text": "REG competition", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.8628992140293121}, {"text": "referring expression generation", "start_pos": 114, "end_pos": 145, "type": "TASK", "confidence": 0.8270410100618998}]}, {"text": "However, most of this work did not take into account: a) stylistic differences between speakers; or b) trainable surface realization approaches that combine semantic and word order information.", "labels": [], "entities": []}, {"text": "In this paper we describe and evaluate several end-to-end referring expression generation algorithms that take into consideration speaker style and use data-driven surface realization techniques.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.6958410739898682}]}], "introductionContent": [{"text": "There now exist numerous general-purpose algorithms for attribute selection used in referring expression generation (e.g.,).", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7249006927013397}, {"text": "referring expression generation", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.8027685085932413}]}, {"text": "However, these algorithms by-and-large focus on the algorithmic aspects of referring expression generation rather than on psycholinguistic factors that influence language production.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.7595457434654236}]}, {"text": "For example, we know that humans exhibit individual style differences during language production that can be quite pronounced (e.g.).", "labels": [], "entities": []}, {"text": "We also know that the language production process is subject to lexical priming, which means that words and concepts that have been used recently are likely to appear again.", "labels": [], "entities": []}, {"text": "In this paper, we first explore the impact of individual style and priming on attribute selection for referring expression generation.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 102, "end_pos": 133, "type": "TASK", "confidence": 0.8058865070343018}]}, {"text": "To get an idea of the potential improvement when modeling these factors, we implemented aversion of full brevity search) that uses speaker-specific constraints, and another version that also uses recency constraints.", "labels": [], "entities": []}, {"text": "We found that using speaker-specific constraints led to big performance gains for both TUNA domains, while the use of recency constraints was not as effective for TUNA-style tasks.", "labels": [], "entities": []}, {"text": "We then modified Dale and Reiter's classic attribute selection algorithm to model speakerspecific constraints, and found performance gains in this more greedy approach as well.", "labels": [], "entities": []}, {"text": "Then we looked at surface realization for referring expression generation.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.8229143818219503}]}, {"text": "There are several approaches to surface realization described in the literature) ranging from hand-crafted template-based realizers to data-driven syntax-based realizers).", "labels": [], "entities": []}, {"text": "Template-based realization involves the insertion of attribute values into predetermined templates.", "labels": [], "entities": [{"text": "Template-based realization", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8996905386447906}]}, {"text": "Data-driven syntax-based methods use syntactic relations between words (including long-distance relations) for word ordering.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 111, "end_pos": 124, "type": "TASK", "confidence": 0.7380149066448212}]}, {"text": "Other data-driven techniques exhaustively generate possible realizations with recourse to syntax in as much as it is reflected in local n-grams.", "labels": [], "entities": []}, {"text": "Such techniques have the advantage of being robust although they are inadequate to capture long-range dependencies.", "labels": [], "entities": []}, {"text": "In this paper, we explore three techniques for the task of referring expression generation that are different hybrids of hand-crafted and data-driven methods.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.8942052125930786}]}, {"text": "The remainder of this paper is organized as follows: In Section 2, we present the algorithms for attribute selection.", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7272934019565582}]}, {"text": "The different methods for surface realizers are presented in Section 3.", "labels": [], "entities": [{"text": "surface realizers", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7354159504175186}]}, {"text": "The experiments concerning the attribute selection and surface realization are presented in Section 4 and Section 5.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7682585716247559}]}, {"text": "The final remarks are discussed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data Preparation The training data were used to build the models outlined above.", "labels": [], "entities": []}, {"text": "The development data were then processed one-by-one.", "labels": [], "entities": []}, {"text": "For our final submissions, we use training and development data to build our models.", "labels": [], "entities": []}, {"text": "Results shows the results for variations of full brevity.", "labels": [], "entities": []}, {"text": "As we would expect, all approaches achieve a perfect score on uniqueness.", "labels": [], "entities": []}, {"text": "For both corpora, we see a large performance jump when we use speaker constraints.", "labels": [], "entities": []}, {"text": "However, when we incorporate recency constraints as well performance declines slightly.", "labels": [], "entities": []}, {"text": "We think this is due to two factors: first, the speakers are not in a conversation, and selfpriming may have less impact; and second, we do not always have the most recent prior utterance fora given speaker in the training data.: Results for realization rate speaker constraints, we again see a performance jump, although compared to the best possible case (full brevity) there is still room for improvement.", "labels": [], "entities": []}, {"text": "Discussion We have shown that by using speaker and recency constraints in standard algorithms, it is possible to achieve performance gains on the attribute selection task.", "labels": [], "entities": [{"text": "attribute selection task", "start_pos": 146, "end_pos": 170, "type": "TASK", "confidence": 0.7562660475571951}]}, {"text": "The most relevant previous research is the work of (), who modified Dale and Reiter's algorithm to model speaker adaptation in dialog.", "labels": [], "entities": [{"text": "speaker adaptation", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7667624056339264}]}, {"text": "However, this corpus does not involve dialog so there are no cross-speaker constraints, only withinspeaker constraints (style and priming).", "labels": [], "entities": []}, {"text": "Data Preparation We first normalize the training data to correct misspellings and remove punctuation and capitalization.", "labels": [], "entities": [{"text": "Data Preparation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.610237717628479}]}, {"text": "We then extract a phrasal lexicon.", "labels": [], "entities": []}, {"text": "For each attribute value we extract the count of all realizations of that value in the training data.", "labels": [], "entities": []}, {"text": "We treat locations as a special case, storing separately the realizations of x-y coordinate pairs and single x-or y-coordinates.", "labels": [], "entities": []}, {"text": "We add a small number of realizations to the lexicon by hand to cover possible attribute values not seen in the training data.", "labels": [], "entities": []}, {"text": "Results shows the evaluation results for string-edit distance and string accuracy on the development set with three different attributes sets: DEV -attributes selected by the human test; FB-sf -attributes generated by the full brevity algorithm with speaker frequency; and DR-sf -attributes selected by the Dale & Reiter algorithm with speaker frequency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9726732969284058}, {"text": "DEV", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9602164030075073}, {"text": "FB-sf", "start_pos": 187, "end_pos": 192, "type": "METRIC", "confidence": 0.9934456944465637}]}, {"text": "For the TUNA realization task (DEV attributes), our approaches work better for the furniture domain, where there are fewer attributes, than for the people domain.", "labels": [], "entities": [{"text": "TUNA realization task", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.8513062198956808}]}, {"text": "For the furniture domain, the Template-S approach achieves lowest string-edit distance, while for the people domain, the Dependency approach achieves lowest string-edit distance.", "labels": [], "entities": []}, {"text": "The latter method was submitted for human evaluation.", "labels": [], "entities": []}, {"text": "When we consider the \"end-to-end\" referring expression generation task (FB-sf and DR-sf attributes), the best overall performing system is the speaker-based template generator with full-brevity and speaker frequency attribute selection.", "labels": [], "entities": [{"text": "referring expression generation task", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.7178155407309532}, {"text": "FB-sf", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.5285144448280334}]}, {"text": "In terms of generated sentence quality, a preliminary and qualitative analysis shows that the combination Permute & Rank and DR-sf produces more naturalistic phrases.", "labels": [], "entities": []}, {"text": "Discussion Although the Template-S approach achieves the best string edit distance scores overall, it is not very robust.", "labels": [], "entities": []}, {"text": "If no examples were found in the training data neither Template approach will produce no output.", "labels": [], "entities": []}, {"text": "(This happens twice for each of the domains on the development data.)", "labels": [], "entities": []}, {"text": "The Dependency approach achieves good overall performance with more robustness.", "labels": [], "entities": []}, {"text": "The biggest cause of errors for the Permute and Reorder approach was missing determiners and missing modifiers.", "labels": [], "entities": [{"text": "Permute and Reorder", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.5728439490000407}]}, {"text": "The biggest cause of errors for the Dependency approach was missing determiners and reordered words.", "labels": [], "entities": []}, {"text": "The Template approach sometimes had repeated words (e.g. \"middle\", where \"middle\" referred to both x-and y-coordinates).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for attribute selection", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.895421028137207}]}]}