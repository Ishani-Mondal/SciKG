{"title": [{"text": "Graph-based Clustering for Semantic Classi\uf0decation of Onomatopoetic Words", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a method for semantic classi\uf0decation of onomatopoetic words like \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 (hum)\" and \"\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 (clip clop)\" which exist in every language, especially Japanese being rich in onomatopoetic words.", "labels": [], "entities": []}, {"text": "We used a graph-based clustering algorithm called Newman clustering.", "labels": [], "entities": []}, {"text": "The algorithm calculates a simple quality function to test whether a particular division is meaningful.", "labels": [], "entities": []}, {"text": "The quality function is calculated based on the weights of edges between nodes.", "labels": [], "entities": []}, {"text": "We combined two different similarity measures, distributional similarity, and orthographic similarity to calculate weights.", "labels": [], "entities": []}, {"text": "The results obtained by using the Web data showed a 9.0% improvement over the baseline single distributional similarity measure.", "labels": [], "entities": [{"text": "Web data", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.7698335647583008}]}], "introductionContent": [{"text": "Onomatopoeia which we call onomatopoetic word (ono word) is the formation of words whose sound is imitative of the sound of the noise or action designated, such as 'hiss'.", "labels": [], "entities": []}, {"text": "It is one of the linguistic features of Japanese.", "labels": [], "entities": []}, {"text": "Consider two sentences from Japanese.", "labels": [], "entities": []}, {"text": "(2) \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 \"I'm too sleepy because I awoke to the pit-apat of slippers in the hall.\"", "labels": [], "entities": []}, {"text": "Sentences (1) and (2) are almost the same sense.", "labels": [], "entities": []}, {"text": "However, sentence (2) which includes ono word, \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 (pit-a-pat)\" is much better to make the scene alive, or represents an image clearly.", "labels": [], "entities": []}, {"text": "Therefore large-scale semantic resource of ono words is indispensable for not only NLP, but also many semantic-oriented applications such as Question Answering, Paraphrasing, and MT systems.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.8215019106864929}, {"text": "MT", "start_pos": 179, "end_pos": 181, "type": "TASK", "confidence": 0.9804601073265076}]}, {"text": "Although several machine-readable dictionaries which are \uf0dene-grained and large-scale semantic knowledge like WordNet, COMLEX, and EDR dictionary exist, there are none or few onomatopoetic thesaurus.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.9607862830162048}]}, {"text": "Because (i) it is easy to understand its sense of ono word for Japanese, and (ii) it is a fast-changing linguistic expressions, as it is a vogue word.", "labels": [], "entities": []}, {"text": "Therefore, considering this resource scarcity problem, semantic classi\uf0decation of ono words which do not appear in the resource but appear in corpora is very important.", "labels": [], "entities": []}, {"text": "In this paper, we focus on Japanese onomatopoetic words, and propose a method for classifying them into a set with similar meaning.", "labels": [], "entities": []}, {"text": "We used the Web as a corpus to collect ono words, as they appear in different genres of dialogues including broadcast news, novels and comics, rather than a well-edited, balanced corpus like newspaper articles.", "labels": [], "entities": []}, {"text": "The problem using a large, heterogeneous collection of Web data is that the Web counts are far more noisy than counts obtained from textual corpus.", "labels": [], "entities": []}, {"text": "We thus used a graph-based clustering algorithm, called Newman clustering for classifying ono words.", "labels": [], "entities": []}, {"text": "The algorithm does not simply calculate the number of shortest paths between pairs of nodes, but instead calculates a quality function of how good a cluster structure found by an algorithm is, and thus makes the computation far more ef\uf0decient.", "labels": [], "entities": []}, {"text": "The ef\uf0decacy of the algorithm depends on a quality function which is calculated by using the weights of edges between nodes.", "labels": [], "entities": [{"text": "ef\uf0decacy", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.6516963640848795}]}, {"text": "We combined two different similarity measures, and used them to calculate weights.", "labels": [], "entities": []}, {"text": "One is co-occurrence based distributional similarity measure.", "labels": [], "entities": []}, {"text": "We tested mutual information (M I) and a \u03c7 2 statistic as a similarity measure.", "labels": [], "entities": []}, {"text": "Another is orthographic similarity which is based on a feature of ono words called \"sound symbolism\".", "labels": [], "entities": []}, {"text": "Sound symbolism indicates that phonemes or phonetic sequences express their senses.", "labels": [], "entities": []}, {"text": "As ono words imitate the sounds associated with the objects or actions they refer to, their phonetic sequences provide semantic clues for classi\uf0decation.", "labels": [], "entities": []}, {"text": "The empirical results are encouraging, and showed a 9.0% improvement over the baseline single distributional similarity measure.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data for the classi\uf0decation of ono words have been taken from the Japanese ono dictionary) that consisted of 4,500 words.", "labels": [], "entities": [{"text": "Japanese ono dictionary", "start_pos": 69, "end_pos": 92, "type": "DATASET", "confidence": 0.6666280130545298}]}, {"text": "Of these, we selected 273 words, which occurred at least 5,000 in the document URLs from the WWW.", "labels": [], "entities": [{"text": "WWW", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.4894300103187561}]}, {"text": "The minimum frequency of a word was found to be 5,220, while the maximum was about 26 million.", "labels": [], "entities": []}, {"text": "These words are classi\uf0deed into 10 classes.", "labels": [], "entities": []}, {"text": "Word classes and examples of ono words from the dictionary are listed in.", "labels": [], "entities": []}, {"text": "\"Id\" denotes id number of each class.", "labels": [], "entities": [{"text": "Id", "start_pos": 1, "end_pos": 3, "type": "METRIC", "confidence": 0.9896475672721863}]}, {"text": "\"Sense\" refers to each sense of ono word within the same class, and \"Num\" is the number of words which should be assigned to each class.", "labels": [], "entities": [{"text": "Num\"", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9383257031440735}]}, {"text": "Each word marked with bracket denotes phonetic sequences consisting of consonants and vowels.", "labels": [], "entities": []}, {"text": "We retrieved co-occurrences of ono words shown in using the search engine, Google.", "labels": [], "entities": []}, {"text": "We applied Newman clustering to the input words.", "labels": [], "entities": []}, {"text": "For comparison, we implemented standard kmeans which is often used as a baseline, as it is one of the simplest unsupervised clustering algorithms, and compared the results to those obtained by our method.", "labels": [], "entities": []}, {"text": "We used Euclidean distance (L 2 norm) as a distance metric used in the k-means.", "labels": [], "entities": []}, {"text": "For evaluation of classi\uf0decation, we used Precision(P rec), Recall(Rec), and F -measure which is a measure that balances precision and recall ().", "labels": [], "entities": [{"text": "Precision(P rec)", "start_pos": 41, "end_pos": 57, "type": "METRIC", "confidence": 0.9481995105743408}, {"text": "Recall(Rec)", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9589401185512543}, {"text": "F -measure", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9933724204699198}, {"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9987698197364807}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9971342086791992}]}, {"text": "The precise de\uf0denitions of these measures are given below:", "labels": [], "entities": [{"text": "de\uf0denitions", "start_pos": 12, "end_pos": 22, "type": "TASK", "confidence": 0.5464858909447988}]}], "tableCaptions": []}