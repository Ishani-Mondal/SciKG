{"title": [], "abstractContent": [{"text": "This paper describes an evaluation study of an ontology-driven WYSIWYM interface for metadata creation.", "labels": [], "entities": [{"text": "metadata creation", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.8319066166877747}]}, {"text": "Although the results are encouraging, they are not as positive as those of a similar tool developed for the medical domain.", "labels": [], "entities": []}, {"text": "We believe this maybe due, not to the WYSIWYM interface, but to the complexity of the underlying ontologies and the fact that subjects were unfamiliar with them.", "labels": [], "entities": []}, {"text": "We discuss the ways in which ontology development might be influenced by issues stemming from using an NLG approach for user access to data, and the effect these factors have on general usability.", "labels": [], "entities": [{"text": "ontology development", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.9009615182876587}]}], "introductionContent": [{"text": "In the PolicyGrid 1 project we are investigating how best to support social science researchers through the use of Semantic Grid technologies.", "labels": [], "entities": []}, {"text": "The Semantic Grid is often described as an 'extension of the current Grid in which information and services are given well-defined meaning, better enabling computers and people to work in cooperation'.", "labels": [], "entities": []}, {"text": "Semantic Grids thus not only share data and compute resources, but also share and process metadata and knowledge, e.g. through the use of RDF 2 (Resource Description Framework, a metadata model for making statements about resources) Funded under the UK Economic and Social Research Council e-Social Science programme; grant reference RES-149-25-1027 (http://www.policygrid.org) http://www..org/RDF/ or OWL 3 (knowledge representation language for authoring ontologies).", "labels": [], "entities": [{"text": "UK Economic and Social Research Council e-Social Science programme", "start_pos": 250, "end_pos": 316, "type": "DATASET", "confidence": 0.8676422701941596}]}, {"text": "Numerous e-science applications rely on metadata descriptions of resources.", "labels": [], "entities": []}, {"text": "But how does metadata come into existence?", "labels": [], "entities": []}, {"text": "Ideally the user should create it.", "labels": [], "entities": []}, {"text": "However, metadata creation is a complex task, and few users know how to create them in RDF.", "labels": [], "entities": [{"text": "metadata creation", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.9005303382873535}]}, {"text": "To enable our users to describe their resources, we need to provide a tool that facilitates creation, querying and browsing of metadata by users with no prior experience of such technologies.", "labels": [], "entities": []}, {"text": "Existing tools that provide access to RDF metadata are often graphical, e.g. ().", "labels": [], "entities": []}, {"text": "However, we believe that, for social scientists, natural language is the best medium to use, as the way they conduct their research and the structure of their documents and data indicate that they are more oriented towards text than graphics.", "labels": [], "entities": []}, {"text": "Natural language approaches include GINO (), an ontology editor with an approach reminiscent of Natural Language Menus (, and using Controlled languages such as PENG-D).", "labels": [], "entities": []}, {"text": "Such natural language approaches tend to restrict expressivity to ensure that every entry can be parsed, limiting the language and often making it stilted, so that there is a small learning curve before the user knows which structures are allowed.", "labels": [], "entities": []}, {"text": "In order to maintain full expressivity and to shorten the learning curve, we have elected to use WYSIWYM (What You See Is What You Meant)).", "labels": [], "entities": [{"text": "WYSIWYM", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.488552987575531}]}, {"text": "This is a natural language generation approach where the system generates a feed-back text for the user that is based on a semantic representation.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.794852058092753}]}, {"text": "This representation is edited directly by the user by manipulating the feedback text.", "labels": [], "entities": []}, {"text": "WYSI-WYM has been used by a number of other projects, such as MILE () and CLEF).", "labels": [], "entities": [{"text": "WYSI-WYM", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8835261464118958}, {"text": "MILE", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.6033246517181396}]}, {"text": "As evaluation results in both of these projects were very positive, we felt that WYSIWYM would be a suitable approach to use in our work.", "labels": [], "entities": [{"text": "WYSIWYM", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.7256105542182922}]}, {"text": "We have developed a metadata elicitation tool that enables users to create metadata in the shape of ontology instance data; the tool is driven by the ontologies that define those instances.", "labels": [], "entities": []}, {"text": "We are currently implementing a WYSIWYM tool for querying, that uses the same interface as the metadata creation tool.", "labels": [], "entities": []}, {"text": "We also aim to develop a tool for presenting the results of the query, and for browsing the descriptions in the database.", "labels": [], "entities": []}, {"text": "These three tools will be integrated into one consistent interface, so that users can switch effortlessly between querying, browsing and editing ontology instance data.", "labels": [], "entities": []}, {"text": "This aim is similar to the support that the graphical tool SHAKEN provides for ontology editing and browsing).", "labels": [], "entities": [{"text": "ontology editing", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.789708286523819}]}, {"text": "We want to ensure that these tools are generic, so that if the ontologies changeover time or are replaced, the tools will still function.", "labels": [], "entities": []}, {"text": "That means that all domain specific information (as much as is possible) should be contained in the ontologies.", "labels": [], "entities": []}, {"text": "In this paper we explore the ways in which Natural Language Generation issues influence ontology building and vice versa.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6371034582455953}, {"text": "ontology building", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.9006297886371613}]}, {"text": "This paper is structured as follows: section 2 describes the tool for metadata creation that we have implemented; section 3 discusses issues in ontology development and Natural Language Generation; and section 4 presents an evaluation study of the metadata creation tool.", "labels": [], "entities": [{"text": "metadata creation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.8354651033878326}, {"text": "ontology development", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.8748959898948669}, {"text": "Natural Language Generation", "start_pos": 169, "end_pos": 196, "type": "TASK", "confidence": 0.6274866660435995}, {"text": "metadata creation", "start_pos": 248, "end_pos": 265, "type": "TASK", "confidence": 0.7990833520889282}]}, {"text": "In section 5 the results of this study are discussed and compared to those of the CLEF project; we argue that different domains and ontologies affect the usability and complexity of metadata access interfaces.", "labels": [], "entities": []}], "datasetContent": [{"text": "The best evaluation of our tool would be to let users deposit their resources in real-life contexts, but our tool is not ready fora full deployment.", "labels": [], "entities": []}, {"text": "Another way would be to compare its usability to another metadata creation tool in an experiment where users completed the same tasks with both tools.", "labels": [], "entities": []}, {"text": "Unfortunately, most metadata tools focus on providing support for ontology editing (e.g. Prot\u00e9g\u00e9 or GINO)), or query formulation (e.g. SEWASIE).", "labels": [], "entities": [{"text": "ontology editing", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.7388115525245667}, {"text": "query formulation", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7329512536525726}]}, {"text": "A number of tools for metadata creation use formal (RDF) or controlled languages, which are difficult to use for those wholly unfamiliar with formal logic.", "labels": [], "entities": [{"text": "metadata creation", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.8705930709838867}]}, {"text": "Other tools were developed for one specific purpose, e.g. CREAM () which was developed for the annotation of web pages, and could not easily be adapted to our purposes.", "labels": [], "entities": []}, {"text": "We were not aware of any tool that we could adapt to the e-social science ontologies and thus use in an experiment.", "labels": [], "entities": []}, {"text": "Alternatively, we could have compared our interface to direct authoring of RDF; but in an environ-ment where most users have no experience of ontologies or metadata this seemed spurious.", "labels": [], "entities": []}, {"text": "Instead, we adopted an approach similar to that used in the CLEF project).", "labels": [], "entities": [{"text": "CLEF project", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.8792783319950104}]}, {"text": "They evaluated their WYSIWYM system (which enabled users to create SQL queries fora database in a medical domain) by measuring the performance of fifteen subjects on four consecutive tasks, after a brief introduction.", "labels": [], "entities": []}, {"text": "These subjects were all knowledgeable in the domain, and all but two knew the representation language of the repository and how the data contained in it was structured.", "labels": [], "entities": []}, {"text": "These subjects achieved perfect results from the second task onwards, and became faster with each task, especially after the first.", "labels": [], "entities": []}, {"text": "We also expected users to become faster and more accurate with each completed task, and indeed hoped for perfect scores on their last task.", "labels": [], "entities": [{"text": "accurate", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9721870422363281}]}, {"text": "Subjects Sixteen researchers and PhD students from various social science-related disciplines participated in the experiment.", "labels": [], "entities": []}, {"text": "None of them had prior experience of the metadata elicitation interface, and only two of the subjects had any previous experience of using ontologies.", "labels": [], "entities": []}, {"text": "The ontology driving the system models the description of social science resources and was based on requirements gathering sessions, in which a few subjects had participated.", "labels": [], "entities": []}, {"text": "None of the subjects knew its precise structure.", "labels": [], "entities": []}, {"text": "Methodology After providing some information about their background, subjects viewed a video introduction 7 of six minutes.", "labels": [], "entities": []}, {"text": "This video showed the construction of a simple resource description, highlighting the main functionalities of the interface, while a voice-over explained what was happening on the screen.", "labels": [], "entities": []}, {"text": "Subjects were then handed four short resource descriptions expressed as paragraphs of English (see 'Materials') and asked to reproduce these descriptions as closely as possible using the tool.", "labels": [], "entities": []}, {"text": "To avoid making the choice of the correct options too obvious, we tried to avoid phrases that corresponded literally to those in the menus.", "labels": [], "entities": []}, {"text": "Each subject received the descriptions in a different order, in case there were differences in the complexity of the tasks.", "labels": [], "entities": []}, {"text": "Subjects were allowed as much time as they needed to complete each task.", "labels": [], "entities": []}, {"text": "For each task, the tool recorded the completion time, the produced description, the number of operations used to produce it, and the frequency with which various operation types were used, such as 'undo' or the 'help' functions.", "labels": [], "entities": []}, {"text": "After the subjects had completed all four tasks, they were asked to rate the usability (very difficult -difficult -OK -easyvery easy) and usefulness (useless -not much use -adequate -useful -very useful) of the tool on a five-point Likert scale, and to note any feedback they might have.", "labels": [], "entities": []}, {"text": "The entire experiment took on average 50 min.", "labels": [], "entities": []}, {"text": "Materials We used four resource descriptions, one of which was: You are depositing the transcript of an interview that was held by Dr. Rivers in 1907, at Eddystone.", "labels": [], "entities": [{"text": "Eddystone", "start_pos": 154, "end_pos": 163, "type": "DATASET", "confidence": 0.9793679714202881}]}, {"text": "The interview mainly discussed 'male-female relationships', 'burial practices' and 'the social impact of the interdiction on head hunting'.", "labels": [], "entities": [{"text": "head hunting", "start_pos": 125, "end_pos": 137, "type": "TASK", "confidence": 0.9753226041793823}]}, {"text": "Access to this transcript should remain private.", "labels": [], "entities": []}, {"text": "shows the corresponding description that could be produced with the tool.", "labels": [], "entities": []}, {"text": "The separation of the transcript from the interview is an example of the clear distinctions necessary for knowledge representation.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.7506683468818665}]}, {"text": "In natural language, this distinction would not necessarily be made, and indeed this step was missed by a number of users.", "labels": [], "entities": []}, {"text": "To ensure that tasks did not repeat identical subtasks, we tried to use different parts of the ontology in each task.", "labels": [], "entities": []}, {"text": "Every task described a different resource type (conference paper, transcript, academic paper, report), which corresponded to a different class in the ontology.", "labels": [], "entities": []}, {"text": "We were also careful to choose varying menu items (corresponding to properties in the ontology), although some repetition was unavoidable (e.g. specifying names).", "labels": [], "entities": []}, {"text": "In fact, a reallife use of the tool would involve rather more task repetition (specifying titles, authors and dates would be necessary for practically any resource) than the artificial descriptions in this study.", "labels": [], "entities": []}, {"text": "Results To analyse the accuracy of the produced descriptions, we divided each description task into 8 to 10 subtasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.997715950012207}]}, {"text": "For the task shown in the previous paragraph, these subtasks were: \u2022 Specify that you are depositing a 'Transcript' \u2022 Specify that access is private -Specify the location of the interview -Specify the date of the interview As some subtasks are more complicated than others and take longer, we did not try to give each task exactly the same number of subtasks, but instead ensured that all tasks needed the same number of operations (e.g. menu item selections, button clicks, etc.) in order to be completed.", "labels": [], "entities": []}, {"text": "Each subtask that was missing or completed differently than in the description shown in 'Materials' was counted as one error.", "labels": [], "entities": []}, {"text": "Erroneous ways to complete subtasks included choosing a different menu item and adding information to the wrong object.", "labels": [], "entities": []}, {"text": "For instance, a number of subjects, instead of specifying an interviewer for the interview, added a creator for the transcript; this was counted as one erroneously completed subtask, and therefore one error.", "labels": [], "entities": []}, {"text": "The list of subtasks above shows that some subtasks depend on the successful completion of other tasks; for instance, you cannot add an interviewer unless you have created an 'interview' object.", "labels": [], "entities": []}, {"text": "We therefore analysed two error counts: the total number of errors, and the 'avoidable' errors.", "labels": [], "entities": []}, {"text": "The 'avoidable' errors were the total number of errors minus those subtasks that depended on another subtask that was missing or had been completed incorrectly.", "labels": [], "entities": []}, {"text": "We analysed the mean completion times, number of operations used and the two error counts of the tasks that were completed first, second, third and last, using a repeated measures ANOVA (see for the means and standard deviations).", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9988017082214355}]}, {"text": "Mean completion times went down significantly (Huynh-Feldt p-value < 0.01).", "labels": [], "entities": [{"text": "completion", "start_pos": 5, "end_pos": 15, "type": "METRIC", "confidence": 0.978789210319519}]}, {"text": "Tukey's HSD post-hoc (applied to a univariate ANOVA, with task order as the independent variable) test shows that both the third (p-value < 0.01) and the fourth (p-value 0.030) were completed significantly faster than the first task.", "labels": [], "entities": [{"text": "Tukey", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9281887412071228}]}, {"text": "However, no significant differences were found for the number of operations (Huynh-Feldt p-value 0.062), the total number of errors (Huynh-Feldt p-value .322) or the number of avoidable errors (HuynhFeldt p-value .931).", "labels": [], "entities": []}, {"text": "Subject feedback on the tool was positive: it was perceived as useful (\u00b5 3.94; 1='useless', 5='very useful'), and OK or easy to use (\u00b5 2.69; 1='very easy', 5='very difficult').", "labels": [], "entities": []}, {"text": "Five subjects expressed a preference fora form-based interface, and five others fora NL-interface such as the one tested.", "labels": [], "entities": []}, {"text": "In feedback, subjects indicated a desire for more formbased elements in the interface, to speedup the creation of the standard description elements (e.g. name/title, author), and complained that the environment was initially unfamiliar, with some menu items overlapping.", "labels": [], "entities": []}, {"text": "This unfamiliarity meant that items that were necessary to complete the description were often overlooked; subjects often solved this by choosing the closest approximation they could find, e.g. 'creator' instead of 'interviewer'.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Mean completion times, operations and errors per completed task.", "labels": [], "entities": [{"text": "Mean completion times", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8813748757044474}]}]}