{"title": [], "abstractContent": [{"text": "This paper describes a generic, open-domain multi-document summarisation system which combines new and existing techniques in a novel way.", "labels": [], "entities": []}, {"text": "The system is capable of automatically identifying query-related online documents and compiling a report from the most useful sources, whilst presenting the result in such away as to make it easy for the researcher to lookup the information in its original context.", "labels": [], "entities": []}], "introductionContent": [{"text": "Although electronic resources have several inherent advantages over traditional research media, they also introduce several drawbacks, such as Information Overload),which has become synonymous with the information retrieval phase of any research-related task.", "labels": [], "entities": [{"text": "information retrieval phase", "start_pos": 202, "end_pos": 229, "type": "TASK", "confidence": 0.7618901133537292}]}, {"text": "Another problem which is directly related to the one just described is that of Source Identification (.", "labels": [], "entities": [{"text": "Source Identification", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.719965249300003}]}, {"text": "This refers to the problem of having relevant results intermingled with results that are less relevant, or actually irrelevant.", "labels": [], "entities": []}, {"text": "Lastly, the researcher usually has to also manually traverse the relevant sources of information in order to form an answer to the research query.", "labels": [], "entities": []}, {"text": "These problems have led to the study of various areas in computing, all of which aim to try and minimise the manual effort of information retrieval and extraction, one of which is Multi-Document Summarisation (MDS).", "labels": [], "entities": [{"text": "information retrieval and extraction", "start_pos": 126, "end_pos": 162, "type": "TASK", "confidence": 0.7661306783556938}, {"text": "Multi-Document Summarisation (MDS)", "start_pos": 180, "end_pos": 214, "type": "TASK", "confidence": 0.8360472202301026}]}, {"text": "The core aim of any MDS system is that of processing multiple sources of information and outputting a relatively brief but broad report or sum- mary.", "labels": [], "entities": [{"text": "MDS", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9527819752693176}]}, {"text": "Uses of MDS systems vary widely, from summarisation of closed-domain documents, such as news documents), to aggregation of information from several sources in an open domain.", "labels": [], "entities": [{"text": "summarisation of closed-domain documents", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.8493041098117828}]}], "datasetContent": [{"text": "In order to evaluate the local coherence of the reports generated by the system, we employed an au-tomatic coherence evaluation method introduced by . The main objective of this part of the evaluation phase was to determine the effect on output quality when parameters are varied, namely the minimum cluster support parameter for the clustering algorithm, and the key phrase popularity.", "labels": [], "entities": [{"text": "popularity", "start_pos": 375, "end_pos": 385, "type": "METRIC", "confidence": 0.9160560369491577}]}, {"text": "From this evaluation, we empirically determined that the optimum minimum cluster support threshold for this application is 50, whilst the quality of the output is directly proportional to the keyword popularity.", "labels": [], "entities": []}, {"text": "Here we focused on determining whether the secondary objective was achieved (cf. section 2).", "labels": [], "entities": []}, {"text": "We measured the frequency of occurrence of the keyword phrase within the output, or more specifically, the keyword density.", "labels": [], "entities": []}, {"text": "The average key phrase density achieved by the system was 1.32%, when taking into account (i) the original keyword phrase and its constituent keywords, and (ii) secondary keyword phrases and their constituents.", "labels": [], "entities": []}, {"text": "In order to measure the quality of the output and determine whether the objectives of the study was achieved, three users were introduced to the system and asked to grade the system, on a scale of 1-5, on several criteria.", "labels": [], "entities": []}, {"text": "illustrates the results obtained from this evaluation.", "labels": [], "entities": []}, {"text": "From an SEO perspective, it was predictable that the system would produce query-related text, since its data source is obtained from query-related search engine results.", "labels": [], "entities": [{"text": "SEO", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.7818781733512878}]}, {"text": "However, the resulting average keyword density achieved is significant, and is at a level which is totally acceptable by most search engine ranking algorithms 6 . Manual Quality Evaluation Due to limited resources, the results of the manual evaluation procedure were not statistically significant since only three users were involved in evaluating six summaries.", "labels": [], "entities": []}, {"text": "However, allowing fora factor of subjectivity, some conclusions could still be elicited, namely: 1.", "labels": [], "entities": []}, {"text": "The system did not perform well enough to have its output rated as high as a manual summarisation procedure.", "labels": [], "entities": []}, {"text": "This can be concluded from the low rating on the output Naturalness criterion, as well as from the presence of repeated and irrelevant content in some of the output summaries.", "labels": [], "entities": []}, {"text": "2. The system performed acceptably well in generating reports that were adequately coherent and high-level enough to give an overview of concepts represented by users' queries.", "labels": [], "entities": []}, {"text": "This can be concluded from the average scores achieved in the Focus and Referential Clarity criteria.", "labels": [], "entities": []}, {"text": "3. The evaluators were also asked to give a grade indicating whether this system and similar tools would actually be useful.", "labels": [], "entities": []}, {"text": "A positive grade was obtained on this criterion, indicating that the system achieved the MDS objective, enabling users to get a brief overview of the topic as well as facilitating document identification.", "labels": [], "entities": [{"text": "MDS", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.6626429557800293}, {"text": "document identification", "start_pos": 180, "end_pos": 203, "type": "TASK", "confidence": 0.6818198710680008}]}, {"text": "When comparing these results to those achieved by, we can elicit two main conclusions: Very high keyword density (more than a threshold of 2% -5%) is usually considered as a spammy technique known as keyword stuffing.", "labels": [], "entities": [{"text": "keyword stuffing", "start_pos": 200, "end_pos": 216, "type": "TASK", "confidence": 0.7872218191623688}]}, {"text": "1. Although our system achieved lower rankings on the Non-Redundancy, Structure and Grammaticality criteria, these rankings were not unacceptable.", "labels": [], "entities": []}, {"text": "We could attributed this to the more generic domain in which our system operates, where it is not possible to introduce fixed heuristics such as those used by for avoiding repeated information by replacing a term definition by its corresponding acronym.", "labels": [], "entities": []}, {"text": "Such heuristics tend to be relevant in the context of such a term definition system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of Manual Evaluation", "labels": [], "entities": [{"text": "Manual Evaluation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7696880996227264}]}]}