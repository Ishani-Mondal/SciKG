{"title": [{"text": "An Approach to Reducing Annotation Costs for BioNLP", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 45, "end_pos": 51, "type": "TASK", "confidence": 0.5081177353858948}]}], "abstractContent": [], "introductionContent": [{"text": "There is abroad range of BioNLP tasks for which active learning (AL) can significantly reduce annotation costs and a specific AL algorithm we have developed is particularly effective in reducing annotation costs for these tasks.", "labels": [], "entities": []}, {"text": "We have previously developed an AL algorithm called ClosestInitPA that works best with tasks that have the following characteristics: redundancy in training material, burdensome annotation costs, Support Vector Machines (SVMs) work well for the task, and imbalanced datasets (i.e. when setup as a binary classification problem, one class is substantially rarer than the other).", "labels": [], "entities": []}, {"text": "Many BioNLP tasks have these characteristics and thus our AL algorithm is a natural approach to apply to BioNLP tasks.", "labels": [], "entities": [{"text": "AL", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9335148930549622}]}], "datasetContent": [{"text": "Protein-Protein Interaction Extraction: We used the AImed corpus, which was previously used for training protein interaction extraction systems in ().", "labels": [], "entities": [{"text": "Protein-Protein Interaction Extraction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8624333143234253}, {"text": "AImed corpus", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.7862988412380219}, {"text": "protein interaction extraction", "start_pos": 105, "end_pos": 135, "type": "TASK", "confidence": 0.6466908156871796}]}, {"text": "We cast RE as a binary classification task as in ().", "labels": [], "entities": []}, {"text": "We do 10-fold cross validation and use what is referred to in () as the K GC kernel with SVM light) in our experiments.", "labels": [], "entities": []}, {"text": "Medline Text Classification: We use the Ohsumed corpus and a linear kernel with SVM light with binary features for each word that occurs in the training data at least three times.", "labels": [], "entities": [{"text": "Medline Text Classification", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8957701325416565}, {"text": "Ohsumed corpus", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.8852551877498627}]}, {"text": "Results for the five largest categories for one versus the rest classification are in.", "labels": [], "entities": []}, {"text": "\"AutoStopPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": []}, {"text": "GENIA NER: We assume a two-phase model () where boundary identification of named entities is performed in the first phase and the entities are classified in the second phase.", "labels": [], "entities": [{"text": "GENIA NER", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7484874129295349}, {"text": "boundary identification of named entities", "start_pos": 48, "end_pos": 89, "type": "TASK", "confidence": 0.8203252911567688}]}, {"text": "As in the semantic classification evaluation of (), we assume that boundary identification has been performed.", "labels": [], "entities": [{"text": "semantic classification evaluation", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.7993415594100952}, {"text": "boundary identification", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.7513737380504608}]}, {"text": "We use features based on those from (), a one versus the rest setup and 10-fold cross validation.", "labels": [], "entities": []}, {"text": "show the results for the three most common types in GENIA..", "labels": [], "entities": [{"text": "GENIA.", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.8469265699386597}]}, {"text": "Cell Type stopping points performance.", "labels": [], "entities": []}, {"text": "\"AutoStopPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. AImed Stopping Point Performance. \"AutoS- topPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": [{"text": "AutoS- topPoint\"", "start_pos": 45, "end_pos": 61, "type": "METRIC", "confidence": 0.9120846390724182}]}, {"text": " Table 2. Ohsumed stopping point performance. \"AutoS- topPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": [{"text": "Ohsumed stopping point performance", "start_pos": 10, "end_pos": 44, "type": "METRIC", "confidence": 0.7466918677091599}, {"text": "AutoS- topPoint\"", "start_pos": 47, "end_pos": 63, "type": "METRIC", "confidence": 0.9177207797765732}]}, {"text": " Table 3. Protein stopping points performance. \"AutoS- topPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": [{"text": "AutoS- topPoint\"", "start_pos": 48, "end_pos": 64, "type": "METRIC", "confidence": 0.9367708563804626}]}, {"text": " Table 4. DNA stopping points performance. \"AutoS- topPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": [{"text": "AutoS- topPoint\"", "start_pos": 44, "end_pos": 60, "type": "METRIC", "confidence": 0.9294714033603668}]}, {"text": " Table 5. Cell Type stopping points performance. \"Au- toStopPoint\" is when the stopping criterion says to stop.", "labels": [], "entities": []}]}