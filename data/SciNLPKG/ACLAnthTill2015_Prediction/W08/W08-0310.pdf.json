{"title": [{"text": "LIMSI's statistical translation systems for WMT'08", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 8, "end_pos": 31, "type": "TASK", "confidence": 0.7591120898723602}, {"text": "WMT'08", "start_pos": 44, "end_pos": 50, "type": "TASK", "confidence": 0.641941249370575}]}], "abstractContent": [{"text": "This paper describes our statistical machine translation systems based on the Moses toolkit for the WMT08 shared task.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6251470744609833}, {"text": "WMT08 shared task", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.6478107372919718}]}, {"text": "We address the Europarl and News conditions for the following language pairs: English with French, Ger-man and Spanish.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.9845602512359619}, {"text": "News", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.8695294260978699}, {"text": "Ger-man", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.8328731060028076}]}, {"text": "For Europarl, n-best rescor-ing is performed using an enhanced n-gram or a neuronal language model; for the News condition, language models incorporate extra training data.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9813141226768494}, {"text": "News condition", "start_pos": 108, "end_pos": 122, "type": "DATASET", "confidence": 0.911030650138855}]}, {"text": "We also report unconvincing results of experiments with factored models.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes our statistical machine translation systems based on the Moses toolkit for the WMT 08 shared task.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6285705963770548}, {"text": "WMT 08 shared task", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.5905827134847641}]}, {"text": "We address the Europarl and News conditions for the following language pairs: English with French, German and Spanish.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.9800635576248169}, {"text": "News", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.8670135140419006}]}, {"text": "For Europarl, n-best rescoring is performed using an enhanced n-gram or a neuronal language model, and for the News condition, language models are trained with extra training data.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9769360423088074}, {"text": "News condition", "start_pos": 111, "end_pos": 125, "type": "DATASET", "confidence": 0.8798812627792358}]}, {"text": "We also report unconvincing results of experiments with factored models.", "labels": [], "entities": []}], "datasetContent": [{"text": "Even though these models were not used in our submissions, we feel it useful to comment here our (negative) experiments with factored models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of two tokenization policies", "labels": [], "entities": [{"text": "tokenization", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.960111677646637}]}, {"text": " Table 2: Effect of training on true case texts, for English  to French (case INsensitive BLEU scores, untuned sys- tems, results on test2006 dataset)", "labels": [], "entities": [{"text": "case INsensitive BLEU scores", "start_pos": 73, "end_pos": 101, "type": "METRIC", "confidence": 0.6475059762597084}, {"text": "test2006 dataset", "start_pos": 133, "end_pos": 149, "type": "DATASET", "confidence": 0.8052659928798676}]}]}