{"title": [{"text": "Affinity Measures based on the Graph Laplacian", "labels": [], "entities": [{"text": "Affinity Measures", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9234606921672821}, {"text": "Graph Laplacian", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.7165339142084122}]}], "abstractContent": [{"text": "Several language processing tasks can be inherently represented by a weighted graph where the weights are interpreted as a measure of relatedness between two ver-tices.", "labels": [], "entities": []}, {"text": "Measuring similarity between ar-bitary pairs of vertices is essential in solving several language processing problems on these datasets.", "labels": [], "entities": []}, {"text": "Random walk based measures perform better than other path based measures like shortest-path.", "labels": [], "entities": []}, {"text": "We evaluate several random walk measures and propose anew measure based on commute time.", "labels": [], "entities": []}, {"text": "We use the psuedo inverse of the Laplacian to derive estimates for commute times in graphs.", "labels": [], "entities": []}, {"text": "Further, we show that this pseudo inverse based measure could be improved by discarding the least significant eigenvectors, corresponding to the noise in the graph construction process, using singular value decomposition .", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language data lend themselves to a graph based representation.", "labels": [], "entities": []}, {"text": "Words could be linked by explicit relations as in WordNet or documents could be linked to one another via hyperlinks.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9367408752441406}]}, {"text": "Even in the absence of such a straightforward representation it is possible to derive meaningful graphs such as the nearest neighbor graphs as done in certain manifold learning methods; Belkin and Niyogi, 2001).", "labels": [], "entities": []}, {"text": "All of these graphs share the following properties: \u2022 They are edge-weighted.", "labels": [], "entities": []}, {"text": "\u2022 The edge weight encodes some notion of relatedness between the vertices.", "labels": [], "entities": []}, {"text": "\u2022 The relation represented by edges is at least weakly transitive.", "labels": [], "entities": []}, {"text": "Examples of such relations include, \"is similar to\", \"is more general than\", and soon.", "labels": [], "entities": []}, {"text": "It is important that the relations selected are transitive for the random walk to make sense.", "labels": [], "entities": []}, {"text": "Such graphs present several possibilities in solving language problems on the data.", "labels": [], "entities": []}, {"text": "One such task is, given two vertices in the graph we would like to know how related the two vertices are.", "labels": [], "entities": []}, {"text": "There is an abundance of literature on this topic, some of which will be reviewed here.", "labels": [], "entities": []}, {"text": "Finding similarity between vertices in a graph could bean end in itself, as in the lexical similarity task, or could be a stage before solving other problems like clustering and classification.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate each of the similarity measure we consider by using a linguistically motivated task of finding lexical similarity.", "labels": [], "entities": []}, {"text": "Deriving lexical relatedness between terms has been a topic of interest with applications in word sense disambiguation (), paraphrasing (), question answering (), and machine translation () to name a few.", "labels": [], "entities": [{"text": "Deriving lexical relatedness between terms", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7702792048454284}, {"text": "word sense disambiguation", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7063577969868978}, {"text": "question answering", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.8563092947006226}, {"text": "machine translation", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.8122986853122711}]}, {"text": "Lexical relatedness between terms could be derived either from a thesaurus like WordNet or from raw monolingual corpora via distributional similarity (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9529588222503662}]}, {"text": "WordNet is an interesting graph-structured thesaurus where the vertices are the words and the edges represent relations between the words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9514754414558411}]}, {"text": "For the purpose of this work, we only consider relations like hypernymy, hyponymy, and synonymy.", "labels": [], "entities": []}, {"text": "The importance of this problem has generated copious literature in the past -see () or () fora detailed review of various lexical relatedness measures on WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 154, "end_pos": 161, "type": "DATASET", "confidence": 0.9681936502456665}]}, {"text": "Our focus in this paper is not to derive the best similarity measure for WordNet but to use WordNet and the lexical relatedness task as a method to evaluate the various random walk based similarity measures.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 73, "end_pos": 80, "type": "DATASET", "confidence": 0.960240364074707}, {"text": "WordNet", "start_pos": 92, "end_pos": 99, "type": "DATASET", "confidence": 0.9573252201080322}]}, {"text": "Following the tradition in previous literature we evaluate on the dataset.", "labels": [], "entities": []}, {"text": "This data consists of 30 word-pairs along with human judgements which is areal value between 1 and 4.", "labels": [], "entities": []}, {"text": "For every measure we consider, we derive similarity scores and compare with the human judgements using the Spearman rank correlation coefficient.", "labels": [], "entities": [{"text": "similarity scores", "start_pos": 41, "end_pos": 58, "type": "METRIC", "confidence": 0.9687230885028839}, {"text": "Spearman rank correlation coefficient", "start_pos": 107, "end_pos": 144, "type": "METRIC", "confidence": 0.7763420343399048}]}], "tableCaptions": [{"text": " Table 3. shows results on  the Miller-Charles data. We use \u03b1 = 0.1, the best  value on this data. Observe that these results are", "labels": [], "entities": [{"text": "Miller-Charles data", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.7910687625408173}]}, {"text": " Table 3: Similarity via pagerank (\u03b1 = 0.1).", "labels": [], "entities": []}]}