{"title": [{"text": "Fully Unsupervised Graph-Based Discovery of General-Specific Noun Relationships from Web Corpora Frequency Counts", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose anew methodology based on directed graphs and the TextRank algorithm to automatically induce general-specific noun relations from web corpora frequency counts.", "labels": [], "entities": []}, {"text": "Different asymmetric association measures are implemented to build the graphs upon which the TextRank algorithm is applied and produces an ordered list of nouns from the most general to the most specific.", "labels": [], "entities": []}, {"text": "Experiments are conducted based on the WordNet noun hierarchy and assess 65.69% of correct word ordering.", "labels": [], "entities": [{"text": "WordNet noun hierarchy", "start_pos": 39, "end_pos": 61, "type": "DATASET", "confidence": 0.9191104968388876}]}], "introductionContent": [{"text": "Taxonomies are crucial for any knowledgebased system.", "labels": [], "entities": []}, {"text": "They are in fact important because they allow to structure information, thus fostering their search and reuse.", "labels": [], "entities": []}, {"text": "However, it is well known that any knowledge-based system suffers from the so-called knowledge acquisition bottleneck, i.e. the difficulty to actually model the domain in question.", "labels": [], "entities": []}, {"text": "As stated in, WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.9439248442649841}]}, {"text": "So, many attempts have been made to automatically produce taxonomies, but) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as \"B is a kind of A\".", "labels": [], "entities": []}, {"text": "In this paper, we are interested in dealing with the second problem of the construction of an organized lexical resource i.e. discovering generalspecific noun relationships, so that correct nouns are chosen to label internal nodes of any hierarchical knowledge base, such as the one proposed in ().", "labels": [], "entities": []}, {"text": "Most of the works proposed so far have (1) used predefined patterns or (2) automatically learned these patterns to identify hypernym/hyponym relationships.", "labels": [], "entities": []}, {"text": "From the first paradigm, first identifies a set of lexico-syntactic patterns that are easily recognizable i.e. occur frequently and across text genre boundaries.", "labels": [], "entities": []}, {"text": "These can be called seed patterns.", "labels": [], "entities": []}, {"text": "Based on these seeds, she proposes a bootstrapping algorithm to semi-automatically acquire new more specific patterns.", "labels": [], "entities": []}, {"text": "Similarly,) uses predefined patterns such as \"X is a kind of Y\" or \"X, Y, and other Zs\" to identify hypernym/hyponym relationships.", "labels": [], "entities": []}, {"text": "This approach to information extraction is based on a technique called selective concept extraction as defined by.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.8907943069934845}, {"text": "selective concept extraction", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.7387332121531168}]}, {"text": "Selective concept extraction is a form of text skimming that selectively processes relevant text while effectively ignoring surrounding text that is thought to be irrelevant to the domain.", "labels": [], "entities": [{"text": "Selective concept extraction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7608238657315572}, {"text": "text skimming", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7108508497476578}]}, {"text": "A more challenging task is to automatically learn the relevant patterns for the hypernym/hyponym relationships.", "labels": [], "entities": []}, {"text": "In the context of pattern extraction, there exist many approaches as summarized in).", "labels": [], "entities": [{"text": "pattern extraction", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8090763986110687}]}, {"text": "The most well-known work in this area is certainly the one proposed by ) who use machine learning techniques to automatically replace hand-built knowledge.", "labels": [], "entities": []}, {"text": "By using dependency path features extracted from parse trees, they introduce a general-purpose formalization and generalization of these patterns.", "labels": [], "entities": []}, {"text": "Given a training set of text containing known hypernym pairs, their algorithm automatically extracts useful dependency paths and applies them to new corpora to identify novel pairs.", "labels": [], "entities": []}, {"text": "() use a similar way as () to derive extraction patterns for hypernym/hyponym relationships by using web search engine counts from pairs of words encountered in WordNet.", "labels": [], "entities": []}, {"text": "However, the most interesting work is certainly proposed by) who extract patterns in two steps.", "labels": [], "entities": []}, {"text": "First, they find lexical relationships between synonym pairs based on snippets counts and apply wildcards to generalize the acquired knowledge.", "labels": [], "entities": []}, {"text": "Then, they apply a SVM classifier to determine whether anew pair shows a relation of synonymy or not, based on a feature vector of lexical relationships.", "labels": [], "entities": []}, {"text": "This technique could be applied to hypernym/hyponym relationships although the authors do not mention it.", "labels": [], "entities": []}, {"text": "On the one hand, links between words that result from manual or semi-automatic acquisition of relevant predicative or discursive patterns) are fine and accurate, but the acquisition of these patterns is a tedious task that requires substantial manual work.", "labels": [], "entities": []}, {"text": "On the other hand, works done by) have proposed methodologies to automatically acquire these patterns mostly based on supervised learning to leverage manual work.", "labels": [], "entities": []}, {"text": "However, training sets still need to be built.", "labels": [], "entities": []}, {"text": "Unlike other approaches, we propose an unsupervised methodology which aims at discovering general-specific noun relationships which can be assimilated to hypernym/hyponym relationships detection 2 . The advantages of this approach are clear as it can be applied to any language or any domain without any previous knowledge, based on a simple assumption: specific words tend to attract general words with more strength than the opposite.", "labels": [], "entities": [{"text": "hypernym/hyponym relationships detection", "start_pos": 154, "end_pos": 194, "type": "TASK", "confidence": 0.6848241150379181}]}, {"text": "state: \"there is a tendency fora strong forward association from a specific term like adenocarcinoma to the more general term cancer, whereas the association from cancer to adenocarcinoma is weak\".", "labels": [], "entities": []}, {"text": "Based on this assumption, we propose a methodology based on directed graphs and the TextRank algorithm () to automatically induce general-specific noun relationships from web corpora frequency counts.", "labels": [], "entities": []}, {"text": "Indeed, asymmetry in Natural Language Processing can be seen as a possible reason for the degree of generality of terms (.", "labels": [], "entities": []}, {"text": "So, different asymmetric association measures are implemented to build the graphs upon which the TextRank algorithm is applied and produces an ordered list of nouns, from the most general to the most specific.", "labels": [], "entities": []}, {"text": "Experiments have been conducted based on the WordNet noun hierarchy and assessed that 65% of the words are ordered correctly.", "labels": [], "entities": [{"text": "WordNet noun hierarchy", "start_pos": 45, "end_pos": 67, "type": "DATASET", "confidence": 0.92377108335495}]}], "datasetContent": [{"text": "Evaluation is classically a difficult task in Natural Language Processing.", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9426797032356262}]}, {"text": "In fact, as human evaluation is time-consuming and generally subjective even when strict guidelines are provided, measures to automatically evaluate experiments must be proposed.", "labels": [], "entities": []}, {"text": "In this section, we propose three evaluation measures and discuss the respective results.", "labels": [], "entities": []}, {"text": "In order to evaluate our methodology, we randomly 8 extracted 800 seed synsets for which we retrieved their hypernym and hyponym synsets.", "labels": [], "entities": []}, {"text": "For each seed synset, we then built the associated directed weighted and unweighted graphs based on the asymmetric association measures referred to in section 2 9 and ran the TextRank algorithm to produce a general-specific ordered lists of terms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. TextRank ordered lists.", "labels": [], "entities": []}, {"text": " Table 3. Results for the Evaluation by Constraints.", "labels": [], "entities": []}, {"text": " Table 4. Results for the Evaluation by Clustering.", "labels": [], "entities": []}, {"text": " Table 5. Results at the hypernym level.", "labels": [], "entities": []}, {"text": " Table 6. Results at the seed level.", "labels": [], "entities": []}, {"text": " Table 7. Results at the hyponym level.", "labels": [], "entities": []}, {"text": " Table 8. Results for the Spearman's rank correlation  coefficient.", "labels": [], "entities": [{"text": "Spearman's rank correlation  coefficient", "start_pos": 26, "end_pos": 66, "type": "METRIC", "confidence": 0.68544020652771}]}]}