{"title": [{"text": "A Joint Model for Parsing Syntactic and Semantic Dependencies", "labels": [], "entities": [{"text": "Parsing Syntactic and Semantic Dependencies", "start_pos": 18, "end_pos": 61, "type": "TASK", "confidence": 0.8149971842765809}]}], "abstractContent": [{"text": "This paper describes a system that jointly parses syntactic and semantic dependencies , presented at the CoNLL-2008 shared task (Surdeanu et al., 2008).", "labels": [], "entities": []}, {"text": "It combines online Peceptron learning (Collins, 2002) with a parsing model based on the Eisner algorithm (Eisner, 1996), extended so as to jointly assign syntactic and semantic labels.", "labels": [], "entities": []}, {"text": "Overall results are 78.11 global F 1 , 85.84 LAS, 70.35 semantic F 1.", "labels": [], "entities": [{"text": "F 1", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9091084599494934}, {"text": "LAS", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.997253954410553}, {"text": "semantic F 1", "start_pos": 56, "end_pos": 68, "type": "METRIC", "confidence": 0.8879875938097636}]}, {"text": "Official results for the shared task (63.29 global F 1 ; 71.95 LAS; 54.52 semantic F 1) were significantly lower due to bugs present at submission time.", "labels": [], "entities": [{"text": "global F 1", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.6965694030125936}, {"text": "LAS", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.899129331111908}, {"text": "semantic F 1)", "start_pos": 74, "end_pos": 87, "type": "METRIC", "confidence": 0.7985625118017197}]}], "introductionContent": [{"text": "The main goal of this work was to construct a joint learning architecture for syntactic-semantic parsing and to test whether the syntactic and semantic layers can benefit each other from the global training and inference.", "labels": [], "entities": [{"text": "syntactic-semantic parsing", "start_pos": 78, "end_pos": 104, "type": "TASK", "confidence": 0.7548052966594696}]}, {"text": "All the components of our system were built from scratch for this shared task.", "labels": [], "entities": []}, {"text": "Due to strong time limitations, our design decisions were biased towards constructing a simple and feasible system.", "labels": [], "entities": []}, {"text": "Our proposal is a first order linear model that relies on an online averaged Perceptron for learning) and an extended Eisner algorithm for the joint parsing inference.", "labels": [], "entities": [{"text": "joint parsing inference", "start_pos": 143, "end_pos": 166, "type": "TASK", "confidence": 0.6042215625445048}]}, {"text": "Systems based on Eisner algorithm showed a competitive performance in the syntactic parsing of the English language in some past CoNLL shared tasks.", "labels": [], "entities": [{"text": "syntactic parsing of the English language", "start_pos": 74, "end_pos": 115, "type": "TASK", "confidence": 0.8329308927059174}]}, {"text": "Also, we believe that extending the Eisner algorithm to jointly parse syntactic and semantic dependencies it is a natural step to follow.", "labels": [], "entities": []}, {"text": "Note that syntactic and semantic tasks are related but not identical.", "labels": [], "entities": []}, {"text": "Semantic dependencies can take place between words loosely related by the syntactic structure.", "labels": [], "entities": []}, {"text": "Another difficulty is that state of the art SRL systems () strongly rely on features extracted from the syntactic tree.", "labels": [], "entities": [{"text": "SRL", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9808602333068848}]}, {"text": "The joint model grows syntactic and semantic structures at the same time, so features extracted from the syntactic tree (e.g., a syntactic path between a modifier and a distant predicate) are not available or expensive to compute within the Eisner algorithm.", "labels": [], "entities": []}, {"text": "We overcome this problem again with a very simple (though not elegant) solution, consisting of introducing a previous syntactic parsing step.", "labels": [], "entities": []}], "datasetContent": [{"text": "All the experiments reported here were done using the full training corpus, and results are presented on the development set.", "labels": [], "entities": []}, {"text": "The number of features used by the syntactic parser is \u223c177K.", "labels": [], "entities": []}, {"text": "The joint parser uses \u223c45K additional features for recognizing semantic dependencies.", "labels": [], "entities": []}, {"text": "shows the learning curves from epoch 1 to 17 for several subsystems and variants.", "labels": [], "entities": []}, {"text": "More specifically, it includes LAS performance on syntactic parsing, both for the individual parser and for the syntactic annotation coming from the joint syntactic-semantic parser.", "labels": [], "entities": [{"text": "LAS", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.69745272397995}, {"text": "syntactic parsing", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7437122166156769}]}, {"text": "For the latter, also the F 1 score on semantic dependencies and global F 1 results are presented.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9844223658243815}, {"text": "F 1", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9013965129852295}]}, {"text": "We can observe that the syntactic LAS scores for the syntactic and joint parsers are very similar, showing that there is no loss in syntactic performance when using the joint syntactic-semantic strategy.", "labels": [], "entities": [{"text": "LAS", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.8659235239028931}]}, {"text": "Overall re- sults are quite stable from epoch 4 (syntax slightly decreases but semantics slightly increases).", "labels": [], "entities": []}, {"text": "The overall results on the test set (78.11 global F 1 , 85.84 LAS, 70.35 semantic F 1 ) were computed by using 5 epochs of training, the optimal on the development set.", "labels": [], "entities": [{"text": "F 1", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.8737292885780334}, {"text": "LAS", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9664411544799805}, {"text": "semantic F 1 )", "start_pos": 73, "end_pos": 87, "type": "METRIC", "confidence": 0.8895066231489182}]}, {"text": "The global F 1 result on the WSJ test corpus is 79.16, but these results drop 9.32 F 1 points on the out-of-domain Brown corpus.", "labels": [], "entities": [{"text": "F 1", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.992902934551239}, {"text": "WSJ test corpus", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.9744972586631775}, {"text": "F 1", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9823066890239716}, {"text": "Brown corpus", "start_pos": 115, "end_pos": 127, "type": "DATASET", "confidence": 0.915178120136261}]}, {"text": "Also, a significant performance drop is observed when moving from verb argument classification (74.58 F 1 , WSJ test) to noun argument classification (56.65 F 1 , WSJ test).", "labels": [], "entities": [{"text": "verb argument classification", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.6990422010421753}, {"text": "F 1", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9164682924747467}, {"text": "noun argument classification", "start_pos": 121, "end_pos": 149, "type": "TASK", "confidence": 0.7620518604914347}]}, {"text": "Note that the same features were used for training noun and verb argument classifiers.", "labels": [], "entities": [{"text": "noun and verb argument classifiers", "start_pos": 51, "end_pos": 85, "type": "TASK", "confidence": 0.6284872949123382}]}, {"text": "These results point out that there is room for improvement on noun argument classification.", "labels": [], "entities": [{"text": "noun argument classification", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.8776092926661173}]}, {"text": "Finally, a comparison to a simple equivalent pipeline architecture, consisting of applying the syntactic base parser followed by an independent classification of semantic dependencies (using exactly the same features) revealed that the joint model outperformed the pipeline by 4.9 F 1 points in the annotation of semantic dependencies.", "labels": [], "entities": []}, {"text": "Regarding efficiency, the proposed architecture is really feasible.", "labels": [], "entities": []}, {"text": "About 0.7GB of memory is required for the syntactic parser and 1.5GB for the joint parser.", "labels": [], "entities": []}, {"text": "Most of these memory needs are due to the filters used.", "labels": [], "entities": []}, {"text": "The filters allowed fora reduction of the computational cost by a factor of 5 with no loss inaccuracy.", "labels": [], "entities": []}, {"text": "These filters have almost no effect on the theoretical upper bound discarding the correct labels for only 0.2% of the syntactic dependencies and 0.44% of the semantic arguments in the development corpus.", "labels": [], "entities": []}, {"text": "The semantic extension of the Eisner algorithm requires only anew table with backpointers for each predicate.", "labels": [], "entities": []}, {"text": "Using a single processor of an amd64 Athlon x2 5000+, the syntactic parser can be trained at 0.2 s/sentence, and the joint parser at 0.3 s/sentence.", "labels": [], "entities": [{"text": "amd64 Athlon x2 5000+", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.9045193314552307}]}, {"text": "Efficiency attest times is only slightly better.", "labels": [], "entities": [{"text": "Efficiency attest", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.8645849525928497}]}], "tableCaptions": []}