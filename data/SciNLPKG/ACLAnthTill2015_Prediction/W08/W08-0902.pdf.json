{"title": [{"text": "Classification Errors in a Domain-Independent Assessment System", "labels": [], "entities": [{"text": "Classification Errors", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.883321076631546}]}], "abstractContent": [{"text": "We present a domain-independent technique for assessing learners' constructed responses.", "labels": [], "entities": []}, {"text": "The system exceeds the accuracy of the majority class baseline by 15.4% and a lexical baseline by 5.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9994814991950989}]}, {"text": "The emphasis of this paper is to provide an error analysis of performance, describing the types of errors committed, their frequency, and some issues in their resolution.", "labels": [], "entities": []}], "introductionContent": [{"text": "Assessment within state of the art Intelligent Tutoring Systems (ITSs) generally provides little more than an indication that the student's response expressed the target knowledge or it did not.", "labels": [], "entities": []}, {"text": "There is no indication of exactly what facets of the concept a student contradicted or failed to express.", "labels": [], "entities": []}, {"text": "Furthermore, virtually all ITSs are developed in a very domain-specific way, with each new question requiring the handcrafting of new semantic extraction frames, parsers, logic representations, or knowledge-based ontologies (c.f.,).", "labels": [], "entities": []}, {"text": "This is also true of research in the area of scoring constructed response questions (e.g.,).", "labels": [], "entities": [{"text": "scoring constructed response questions", "start_pos": 45, "end_pos": 83, "type": "TASK", "confidence": 0.8276656717061996}]}, {"text": "The present paper analyzes the errors of a system that was designed to address these limitations.", "labels": [], "entities": []}, {"text": "Rather than have a single expressed versus notexpressed assessment of the reference answer as a whole, we instead break the reference answer down into what we consider to be approximately its lowest level compositional facets.", "labels": [], "entities": []}, {"text": "This roughly translates to the set of triples composed of labeled (typed) dependencies in a dependency parse of the reference answer.", "labels": [], "entities": []}, {"text": "Breaking the reference answer down into fine-grained facets permits a more focused assessment of the student's response, but a simple yes or no entailment at the facet level still lacks semantic expressiveness with regard to the relation between the student's answer and the facet in question, (e.g., did the student contradict the facet or just fail to address it?).", "labels": [], "entities": []}, {"text": "Therefore, it is also necessary to break the annotation labels into finer levels in order to specify more clearly the relationship between the student's answer and the reference answer facet.", "labels": [], "entities": []}, {"text": "In this paper, we present an error analysis of our system, detailing the most frequent types of errors encountered in our implementation of a domainindependent ITS assessment component and discuss plans for correcting or mitigating some of the errors.", "labels": [], "entities": []}, {"text": "The system expects constructed responses of a phrase to a few sentences, but does not rely on technology developed specifically for the domain or subject matter being tutored -without changes, it should handle history as easily as science.", "labels": [], "entities": []}, {"text": "We first briefly describe the corpus used, the knowledge representation, and the annotation.", "labels": [], "entities": []}, {"text": "In section 3, we describe our assessment system.", "labels": [], "entities": []}, {"text": "Then we present the error analysis and discussion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2 Features presents the results  of our classifier. (Reduced Training is described in  the Discussion section, which follows.)", "labels": [], "entities": []}]}