{"title": [{"text": "Incremental Hypothesis Alignment for Building Confusion Networks with Application to Machine Translation System Combination", "labels": [], "entities": [{"text": "Incremental Hypothesis Alignment", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7663417061169943}, {"text": "Machine Translation System Combination", "start_pos": 85, "end_pos": 123, "type": "TASK", "confidence": 0.8251553922891617}]}], "abstractContent": [{"text": "Confusion network decoding has been the most successful approach in combining outputs from multiple machine translation (MT) systems in the recent DARPA GALE and NIST Open MT evaluations.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 100, "end_pos": 124, "type": "TASK", "confidence": 0.8011908173561096}, {"text": "DARPA GALE", "start_pos": 147, "end_pos": 157, "type": "DATASET", "confidence": 0.675395667552948}, {"text": "NIST Open MT", "start_pos": 162, "end_pos": 174, "type": "TASK", "confidence": 0.5420824686686198}]}, {"text": "Due to the varying word order between outputs from different MT systems, the hypothesis alignment presents the biggest challenge in confusion network decoding.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9636996984481812}, {"text": "confusion network decoding", "start_pos": 132, "end_pos": 158, "type": "TASK", "confidence": 0.6594623426596323}]}, {"text": "This paper describes an incremental alignment method to build confusion networks based on the translation edit rate (TER) algorithm.", "labels": [], "entities": [{"text": "translation edit rate (TER)", "start_pos": 94, "end_pos": 121, "type": "METRIC", "confidence": 0.794759194056193}]}, {"text": "This new algorithm yields significant BLEU score improvements over other recent alignment methods on the GALE test sets and was used in BBN's submission to the WMT08 shared translation task.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9764200448989868}, {"text": "GALE test sets", "start_pos": 105, "end_pos": 119, "type": "DATASET", "confidence": 0.9231726924578348}, {"text": "BBN", "start_pos": 136, "end_pos": 139, "type": "DATASET", "confidence": 0.84986811876297}, {"text": "WMT08 shared translation task", "start_pos": 160, "end_pos": 189, "type": "TASK", "confidence": 0.7627923041582108}]}], "introductionContent": [{"text": "Confusion network decoding has been applied in combining outputs from multiple machine translation systems.", "labels": [], "entities": []}, {"text": "The earliest approach in () used edit distance based multiple string alignment (MSA) ( to build the confusion networks.", "labels": [], "entities": [{"text": "edit distance based multiple string alignment (MSA)", "start_pos": 33, "end_pos": 84, "type": "TASK", "confidence": 0.6486717330084907}]}, {"text": "The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model () or edit distance alignments allowing shifts ().", "labels": [], "entities": []}, {"text": "The alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in MSA but also allowing shifts as in the TER alignment.", "labels": [], "entities": []}, {"text": "The confusion networks are built around a \"skeleton\" hypothesis.", "labels": [], "entities": []}, {"text": "The skeleton hypothesis defines the word order of the decoding output.", "labels": [], "entities": []}, {"text": "Usually, the 1-best hypotheses from each system are considered as possible skeletons.", "labels": [], "entities": []}, {"text": "Using the pair-wise hypothesis alignment, the confusion networks are builtin two steps.", "labels": [], "entities": []}, {"text": "First, all hypotheses are aligned against the skeleton independently.", "labels": [], "entities": []}, {"text": "Second, the confusion networks are created from the union of these alignments.", "labels": [], "entities": []}, {"text": "The incremental hypothesis alignment algorithm combines these two steps.", "labels": [], "entities": [{"text": "incremental hypothesis alignment", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.6668335994084676}]}, {"text": "All words from the previously aligned hypotheses are available, even if not present in the skeleton hypothesis, when aligning the following hypotheses.", "labels": [], "entities": []}, {"text": "As in (, confusion networks built around all skeletons are joined into a lattice which is expanded and rescored with language models.", "labels": [], "entities": []}, {"text": "System weights and language model weights are tuned to optimize the quality of the decoding output on a development set.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The incremental TER alignment algorithm is described in Section 2.", "labels": [], "entities": [{"text": "TER alignment", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.7929191589355469}]}, {"text": "Experimental evaluation comparing the incremental and pair-wise alignment methods are presented in Section 3 along with results on the WMT08 Europarl test sets.", "labels": [], "entities": [{"text": "WMT08 Europarl test sets", "start_pos": 135, "end_pos": 159, "type": "DATASET", "confidence": 0.9249392598867416}]}, {"text": "Conclusions and future work are presented in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The quality of the final combination output depends on many factors.", "labels": [], "entities": []}, {"text": "Combining very similar outputs does not yield as good gains as combining outputs from diverse systems.", "labels": [], "entities": []}, {"text": "It is also important that the development set used to tune the combination weights is as similar to the evaluation set as possible.", "labels": [], "entities": []}, {"text": "This development set should be different from the one used to tune the individual systems to avoid bias toward any system that maybe over-tuned.).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the Arabic GALE Phase 2 system  combination tuning set with four reference translations.", "labels": [], "entities": [{"text": "Arabic GALE Phase 2 system  combination tuning set", "start_pos": 25, "end_pos": 75, "type": "DATASET", "confidence": 0.7303317934274673}]}, {"text": " Table 2: Results on the Arabic GALE Phase 2 evaluation  set with one reference translation.", "labels": [], "entities": [{"text": "Arabic GALE Phase 2 evaluation  set", "start_pos": 25, "end_pos": 60, "type": "DATASET", "confidence": 0.6651121179262797}]}, {"text": " Table 3: NIST BLEU scores on the German-English (de- en) and French-English (fr-en) Europarl test2008 set.", "labels": [], "entities": [{"text": "NIST", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.4858205020427704}, {"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9340271353721619}, {"text": "Europarl test2008 set", "start_pos": 85, "end_pos": 106, "type": "DATASET", "confidence": 0.954188605149587}]}]}