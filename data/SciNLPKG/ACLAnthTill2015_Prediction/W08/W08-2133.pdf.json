{"title": [{"text": "Semantic Dependency Parsing using N-best Semantic Role Sequences and Roleset Information", "labels": [], "entities": [{"text": "Semantic Dependency Parsing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8412084380785624}]}], "abstractContent": [{"text": "In this paper, we describe a syntactic and semantic dependency parsing system submitted to the shared task of CoNLL 2008.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6631279587745667}, {"text": "CoNLL 2008", "start_pos": 110, "end_pos": 120, "type": "DATASET", "confidence": 0.8671303689479828}]}, {"text": "The proposed system consists of five modules: syntactic dependency parser, predicate identifier, local semantic role labeler, global role sequence candidate generator, and role sequence selector.", "labels": [], "entities": [{"text": "syntactic dependency parser", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6397307912508646}]}, {"text": "The syntactic dependency parser is based on Malt Parser and the sequence candidate generator is based on CKY style algorithm.", "labels": [], "entities": []}, {"text": "The remaining three modules are implemented by using maximum entropy classi-fiers.", "labels": [], "entities": []}, {"text": "The proposed system achieves 76.90 of labeled F1 for the overall task, 84.82 of labeled attachment, and 68.71 of labeled F1 on the WSJ+Brown test set.", "labels": [], "entities": [{"text": "F1", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.8607366681098938}, {"text": "labeled attachment", "start_pos": 80, "end_pos": 98, "type": "METRIC", "confidence": 0.7410269975662231}, {"text": "F1", "start_pos": 121, "end_pos": 123, "type": "METRIC", "confidence": 0.8559292554855347}, {"text": "WSJ+Brown test set", "start_pos": 131, "end_pos": 149, "type": "DATASET", "confidence": 0.9342154502868653}]}], "introductionContent": [{"text": "In the framework of the CoNLL08 shared task (), a system takes POS tagged sentences as input and produces sentences parsed for syntactic and semantic dependencies as output.", "labels": [], "entities": []}, {"text": "A syntactic dependency is represented by an ID of headword and a dependency relation between the headword and its modifier in a sentence.", "labels": [], "entities": []}, {"text": "A Semantic dependency is represented by predicate rolesets and semantic arguments for each predicate.", "labels": [], "entities": []}, {"text": "The task combines two sub-tasks: syntactic dependency parsing and semantic role labeling.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.7307305733362833}, {"text": "semantic role labeling", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.7240509986877441}]}, {"text": "Among the sub-tasks, we mainly focus on the semantic role labeling task.", "labels": [], "entities": [{"text": "semantic role labeling task", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.7748593986034393}]}, {"text": "Compared to previous CoNLL) and other semantic role labeling research, major differences of our semantic role labeling task are 1) considering nominal predicates and 2) identifying roleset of predicates.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.6446594993273417}, {"text": "semantic role labeling task", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.7068110629916191}]}, {"text": "Based on our observation that verbal predicate and nominal predicate have have different characteristics, we decide to build diffent classification modeles for each predicate types.", "labels": [], "entities": []}, {"text": "The modeles use same features but, their statistical parameters are different.", "labels": [], "entities": []}, {"text": "In this paper, maximum entropy 1 is used as the classification model, but any other classification models such as Naive Bayse, SVM, etc.", "labels": [], "entities": []}, {"text": "To identify roleset, we investigate a roleset match scoring method which evaluate how likely a roleset is matched with the given predicate.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have tested our system with the test set and obtained official results as shown in.", "labels": [], "entities": []}, {"text": "We have also experimented on each module and obtained promising results.", "labels": [], "entities": []}, {"text": "We have tried to find the upper bound of the local semantic role labeling module.", "labels": [], "entities": []}, {"text": "shows the performance when gold syntactic parsing result, correct predicates, and correct rolesets are given.", "labels": [], "entities": []}, {"text": "Comparing to phrase structure parser based semantic role labelings such as and, our local semantic role labeler needs to enhance the performance.", "labels": [], "entities": [{"text": "phrase structure parser based semantic role labelings", "start_pos": 13, "end_pos": 66, "type": "TASK", "confidence": 0.8009777111666543}]}, {"text": "We will try to add some lexical features or chunk features in future works.", "labels": [], "entities": []}, {"text": "Next, we have analyzed the effect of roleset based selector.", "labels": [], "entities": []}, {"text": "shows the effect of matching score and relative frequency which are the weighted factor of selection described in section 2.5.", "labels": [], "entities": [{"text": "matching score", "start_pos": 20, "end_pos": 34, "type": "METRIC", "confidence": 0.8270008265972137}, {"text": "relative frequency", "start_pos": 39, "end_pos": 57, "type": "METRIC", "confidence": 0.7940590083599091}]}, {"text": "Here, baseline means that it selects a role sequence which has the highest score in CKY module and roleset is chosen randomly.", "labels": [], "entities": [{"text": "baseline", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9551143646240234}, {"text": "CKY module", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.8774643838405609}]}, {"text": "The results show that roleset matching score and relative frequency of roleset are effective to choose the correct role sequence and identify roleset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: System performance. LM, LA, LF means  macro labeled F1 for the overall task, labeled at- tachment for syntactic dependencies, and labeled  F1 for semantic dependencies, respectively", "labels": [], "entities": [{"text": "LA", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9396799802780151}, {"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.8589836955070496}, {"text": "F1", "start_pos": 149, "end_pos": 151, "type": "METRIC", "confidence": 0.9891777038574219}]}, {"text": " Table 3: Semantic scores of global sequence selec- tion in WSJ test set. mc, rf means matching score  and relative frequency, respectively", "labels": [], "entities": [{"text": "WSJ test set", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.9471329649289449}]}]}