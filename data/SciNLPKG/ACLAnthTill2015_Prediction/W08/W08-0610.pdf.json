{"title": [{"text": "Species Disambiguation for Biomedical Term Identification", "labels": [], "entities": [{"text": "Biomedical Term Identification", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.898873766263326}]}], "abstractContent": [{"text": "An important task in information extraction (IE) from biomedical articles is term identification (TI), which concerns linking entity mentions (e.g., terms denoting proteins) in text to unambiguous identifiers in standard databases (e.g., RefSeq).", "labels": [], "entities": [{"text": "information extraction (IE) from biomedical articles", "start_pos": 21, "end_pos": 73, "type": "TASK", "confidence": 0.8936886414885521}, {"text": "term identification (TI)", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.8688601136207581}]}, {"text": "Previous work on TI has focused on species-specific documents.", "labels": [], "entities": [{"text": "TI", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9639320373535156}]}, {"text": "However, biomedical documents, especially full-length articles, often talk about entities across a number of species, in which case resolving species ambiguity becomes an indispensable part of TI.", "labels": [], "entities": []}, {"text": "This paper describes our rule-based and machine-learning based approaches to species disambiguation and demonstrates that performance of TI can be improved by over 20% if the correct species are known.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.6964735984802246}]}, {"text": "We also show that using the species predicted by the automatic species tag-gers can improve TI by a large margin.", "labels": [], "entities": [{"text": "TI", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.7439545392990112}]}], "introductionContent": [{"text": "The exponential growth of the amount of scientific literature in the fields of biomedicine and genomics has made it increasingly difficult for scientists to keep up with the state of the art.", "labels": [], "entities": []}, {"text": "The TXM project), a three-year project which aims to produce software tools to aid curation of biomedical papers, targets this problem and exploits natural language processing (NLP) technology in an attempt to automatically extract enriched protein-protein interactions (EPPI) and tissue expressions (TE) from biomedical text.", "labels": [], "entities": []}, {"text": "A critical task in TXM is term identification (TI), the task of grounding mentions of biomedical named entities to identifiers in referent databases.", "labels": [], "entities": [{"text": "TXM", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9697007536888123}, {"text": "term identification (TI)", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.8531460523605346}, {"text": "grounding mentions of biomedical named entities to identifiers in referent databases", "start_pos": 64, "end_pos": 148, "type": "TASK", "confidence": 0.7862943735989657}]}, {"text": "TI can be seen as an intermediate task that builds on the previous component in an information extraction (IE) pipeline, i.e., named entity recognition (NER), and provides crucial information as input to the more complex module of relation extraction (RE).", "labels": [], "entities": [{"text": "information extraction (IE) pipeline", "start_pos": 83, "end_pos": 119, "type": "TASK", "confidence": 0.8254049321015676}, {"text": "named entity recognition (NER)", "start_pos": 127, "end_pos": 157, "type": "TASK", "confidence": 0.8100970983505249}, {"text": "relation extraction (RE)", "start_pos": 231, "end_pos": 255, "type": "TASK", "confidence": 0.8513997554779053}]}, {"text": "The structure of the IE pipeline resembles atypical curation process by human biologists.", "labels": [], "entities": [{"text": "IE pipeline", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.8906788527965546}]}, {"text": "For example, when curating protein-protein interactions (PPIs), a curator would first markup the protein mentions in text, and then identify the mentions by finding their unique identifiers from standard protein databases such as RefSeq, and finally curate pairs of IDs as TI is a matching and disambiguation process (, and a primary source of ambiguity lies in the model organisms of the terms.", "labels": [], "entities": [{"text": "curating protein-protein interactions (PPIs)", "start_pos": 18, "end_pos": 62, "type": "TASK", "confidence": 0.799267421166102}]}, {"text": "In curation tasks, one often needs to deal with collections of articles that involve entities of a large variety of species.", "labels": [], "entities": []}, {"text": "For example, our collection of articles from PubMed and PubMed Central involve over 100 model organisms.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.9544951319694519}, {"text": "PubMed Central", "start_pos": 56, "end_pos": 70, "type": "DATASET", "confidence": 0.9141951501369476}]}, {"text": "Also, it is often the case that more than one species appear in the same document, especially when the document is a full-length article.", "labels": [], "entities": []}, {"text": "In our dataset, 74% of the articles concern more than one organism.", "labels": [], "entities": []}, {"text": "In many standard databases, such as RefSeq and SwissProt, homolog proteins in different species, which often contain nearly identical synonym lists, are assigned distinct identifiers.", "labels": [], "entities": [{"text": "RefSeq", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.9232016205787659}, {"text": "SwissProt", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.9455488920211792}]}, {"text": "This makes biomedical terms even more polysemous and hence species disambiguation becomes crucial to TI.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7241395860910416}, {"text": "TI", "start_pos": 101, "end_pos": 103, "type": "TASK", "confidence": 0.9679387211799622}]}, {"text": "For example, querying RefSeq 2 with the protein mention plk1 resulted in 98 hits.", "labels": [], "entities": []}, {"text": "By adding a species to the query, e.g. mouse, one can significantly reduce the number of results to two.", "labels": [], "entities": []}, {"text": "This paper describes our work on the task of species disambiguation.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.8078373372554779}]}, {"text": "We also report the performance gain of a TI system from integration of various automatic species taggers.", "labels": [], "entities": [{"text": "species taggers", "start_pos": 89, "end_pos": 104, "type": "TASK", "confidence": 0.7462754845619202}]}, {"text": "The paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a brief overview of related work.", "labels": [], "entities": []}, {"text": "Section 3 presents our methodologies for species disambiguation.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.8218100070953369}]}, {"text": "Section 4 describes a rule-based TI system that we developed in the TXM project, and the evaluation metrics.", "labels": [], "entities": []}, {"text": "This section also reports the evaluation results of the TI system with and without help from the species predicted by the taggers.", "labels": [], "entities": []}, {"text": "We finally conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To identify whether species disambiguation can improve performance of TI, we ran the TI system on the EPPI and TE data.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7175417393445969}, {"text": "EPPI and TE data", "start_pos": 102, "end_pos": 118, "type": "DATASET", "confidence": 0.6501221507787704}]}, {"text": "As shown in, we tested the TI systems with or without help from a number of species tagging systems, including: \u2022 Baseline: Run TI without species tags.", "labels": [], "entities": [{"text": "species tagging", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7114479243755341}]}, {"text": "13 \u2022 Gold Species: Run TI with manually tagged species.", "labels": [], "entities": []}, {"text": "This is the upper-bound performance.", "labels": [], "entities": []}, {"text": "\u2022 Rule: Run TI with species predicted by the rulebased species tagger.", "labels": [], "entities": []}, {"text": "\u2022 ML(human/mouse): Run TI with the species that occurs most frequently in the training datasets (i.e., human for EPPI and mouse for TE).", "labels": [], "entities": [{"text": "TI", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9071569442749023}]}, {"text": "\u2022 ML(EPPI): Run TI with species predicted by the ML tagger trained on the EPPI training dataset.", "labels": [], "entities": [{"text": "EPPI training dataset", "start_pos": 74, "end_pos": 95, "type": "DATASET", "confidence": 0.8324153820673624}]}, {"text": "\u2022 ML(EPPI)+Rule: Run TI with species predicted by the hybrid system using both ML(EPPI) and the rules.", "labels": [], "entities": [{"text": "ML(EPPI)+Rule", "start_pos": 2, "end_pos": 15, "type": "METRIC", "confidence": 0.6825790107250214}]}, {"text": "\u2022 ML(TE): Run TI with species predicted by the ML tagger trained on the TE training dataset.", "labels": [], "entities": [{"text": "TE training dataset", "start_pos": 72, "end_pos": 91, "type": "DATASET", "confidence": 0.6774448156356812}]}, {"text": "\u2022 ML(TE)+Rule: Run TI with species predicted by the hybrid system using both ML(TE) and the rules.", "labels": [], "entities": [{"text": "ML(TE)+Rule", "start_pos": 2, "end_pos": 13, "type": "METRIC", "confidence": 0.6917362332344055}]}, {"text": "\u2022 ML(EPPI+TE): Run TI with species predicted by the ML tagger trained on both EPPI and TE training data.", "labels": [], "entities": []}, {"text": "\u2022 ML(EPPI+TE)+Rule: Run TI with species predicted by the hybrid system using both ML(EPPI+TE) and the rules.", "labels": [], "entities": []}, {"text": "We score the systems using top n precision, where n \u2208 {1, 5, 10, 15, 20}.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9701870679855347}]}, {"text": "The argument for this evaluation scheme is that if a TI system is not good enough in predicting a single identifier correctly, a 'bag' of IDs with the correct answer included would also be helpful.", "labels": [], "entities": []}, {"text": "Rank' field denotes the averaged position where the correct answer lies in, and the lower the value is, the better the TI system performs.", "labels": [], "entities": []}, {"text": "For example, a TI system with an 'Avg.", "labels": [], "entities": []}, {"text": "Rank' of 1 would be ideal, as it would always return the correct ID at the top of the list.", "labels": [], "entities": []}, {"text": "Note that in the TE data, not only protein entities, but also genes, mRNAcDNA, and GOMOPs 14 were tagged.", "labels": [], "entities": [{"text": "TE data", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.7154658734798431}]}, {"text": "On both datasets, using the gold standard species much improved accuracy of TI (e.g.,   data).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9995952248573303}, {"text": "TI", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.74607253074646}]}, {"text": "Also, automatically predicted species tags were proven to be helpful.", "labels": [], "entities": []}, {"text": "On the EPPI data, the ML(EPPI)+Rule outperformed other systems.", "labels": [], "entities": [{"text": "EPPI data", "start_pos": 7, "end_pos": 16, "type": "DATASET", "confidence": 0.9303736984729767}, {"text": "ML(EPPI)+Rule", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.8407956719398498}]}, {"text": "Note that the species distribution in the devtest dataset is strongly biased to human, which explains why the ML(human) system performed nearly as well.", "labels": [], "entities": [{"text": "devtest dataset", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.775739312171936}]}, {"text": "However, defaulting to human was not guaranteed to succeed because one would not be able to know the prior species in a collection of unseen documents.", "labels": [], "entities": []}, {"text": "Indeed, on the TE data, the system ML(mouse), which uses the most frequent species in the training data, i.e. mouse, as default, yielded poor results.", "labels": [], "entities": [{"text": "TE data", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.7990347743034363}, {"text": "ML", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.6896809339523315}]}, {"text": "To assess the portability of the species tagging approaches, an \"artificial\" dataset was created by joining the species-specific datasets from BioCreAtIvE 1 & 2 GN tasks to form a corpus consisting of four species.", "labels": [], "entities": [{"text": "species tagging", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.7221788167953491}]}, {"text": "In detail, four datasets were taken, three from BioCreAtIvE 1 task 1B (i.e., fly, mouse and yeast) and one from BioCreAtIvE 2 task GN (i.e., human).", "labels": [], "entities": []}, {"text": "Assuming genes in each dataset are speciesspecific, we can train/test ML models for species disambiguation and apply them to help TI.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.7175849229097366}, {"text": "TI", "start_pos": 130, "end_pos": 132, "type": "TASK", "confidence": 0.9465755224227905}]}, {"text": "This task is more difficult than the original BioCreAtIvE GN tasks due to the additional ambiguity caused by multiple model organisms.", "labels": [], "entities": []}, {"text": "We first carried out experiments on species disambiguation.", "labels": [], "entities": [{"text": "species disambiguation", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8017102181911469}]}, {"text": "In addition to the TXM (i.e., the system uses ML(EPPI+TE)+Rule model) and the Majority Vote taggers, we trained the species tagger on a dataset comprising of the devtest sets from the BioCreAtIvE I & II GN tasks.", "labels": [], "entities": [{"text": "ML(EPPI+TE)+Rule model", "start_pos": 46, "end_pos": 68, "type": "METRIC", "confidence": 0.774886429309845}, {"text": "BioCreAtIvE I & II GN tasks", "start_pos": 184, "end_pos": 211, "type": "DATASET", "confidence": 0.60391965508461}]}, {"text": "In more detail, we first pre-processed the dataset and marked up gene entities with an NER system (.", "labels": [], "entities": []}, {"text": "The entities were also tagged with the species as indicated by the source dataset where they were drawn from, which were used as the 'Gold' species.", "labels": [], "entities": []}, {"text": "Using the same algorithm and feature set as described in Section: Accuracy (%) of the species disambiguation systems as tested on the BioCreAtIvE I & II test data.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.99750816822052}, {"text": "BioCreAtIvE I & II test data", "start_pos": 134, "end_pos": 162, "type": "DATASET", "confidence": 0.8967051406701406}]}, {"text": "The 'BC model' was trained on the BioCreAtIvE devtest data, the 'TXM model' was trained on the TXM EPPI and TE training data, and the 'Majority Vote' was the default species tagging system in the TI system (see Section 3.3.1).", "labels": [], "entities": [{"text": "BioCreAtIvE devtest data", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.8532870809237162}, {"text": "TXM EPPI and TE training data", "start_pos": 95, "end_pos": 124, "type": "DATASET", "confidence": 0.6640859097242355}]}, {"text": "As shown in, except on human, the TXM model yielded very disappointing results, whereas the BC model did well overall.", "labels": [], "entities": []}, {"text": "This was because the TXM model was trained on a dataset where fly and yeast entities occur rarely with only 2% and 5% of the training instances belonging to these species, respectively, which again revealed the influence of the bias introduced in the training material to the ML models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results (%) of the rule-based species tagger.", "labels": [], "entities": [{"text": "rule-based species tagger", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.5553809503714243}]}, {"text": " Table 2: Accuracy (%) of the machine-learning based species tagger and the hybrid species tagger as tested on the  EPPI and TE devtest datasets. An 'Overall' score is the micro-average of a system's accuracy on both datasets.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9989859461784363}, {"text": "EPPI", "start_pos": 116, "end_pos": 120, "type": "DATASET", "confidence": 0.9110637903213501}, {"text": "TE devtest datasets", "start_pos": 125, "end_pos": 144, "type": "DATASET", "confidence": 0.7927272021770477}, {"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9985014200210571}]}, {"text": " Table 3: Ambiguity in protein entities, with and without  species information, in EPPI and TE datasets.", "labels": [], "entities": [{"text": "EPPI and TE datasets", "start_pos": 83, "end_pos": 103, "type": "DATASET", "confidence": 0.6922809556126595}]}, {"text": " Table 4: Results of TI on the EPPI dataset. All figures, except 'Avg. Rank', are percentages. This evaluation was  carried out on protein entities only.", "labels": [], "entities": [{"text": "TI", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.7663946151733398}, {"text": "EPPI dataset", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9703631401062012}, {"text": "Avg. Rank'", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9647352546453476}]}, {"text": " Table 5: Results of TI on the TE dataset. All figures, except 'Avg. Rank', are percentages. There are four entity types  in the TE data, i.e., protein, gene, mRNAcDNA and GOMOP. The evaluation was carried out on all entity types.", "labels": [], "entities": [{"text": "TI", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9064120650291443}, {"text": "TE dataset", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.9485136866569519}, {"text": "Avg. Rank'", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9655485600233078}, {"text": "TE data", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.8094387650489807}, {"text": "GOMOP", "start_pos": 172, "end_pos": 177, "type": "DATASET", "confidence": 0.5670166015625}]}, {"text": " Table 6: Accuracy (%) of the species disambiguation  systems as tested on the BioCreAtIvE I & II test data.  The 'BC model' was trained on the BioCreAtIvE de- vtest data, the 'TXM model' was trained on the TXM EPPI  and TE training data, and the 'Majority Vote' was the de- fault species tagging system in the TI system (see Section  3.3.1).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9963969588279724}, {"text": "BioCreAtIvE I & II test data", "start_pos": 79, "end_pos": 107, "type": "DATASET", "confidence": 0.8502953151861826}, {"text": "BioCreAtIvE de- vtest data", "start_pos": 144, "end_pos": 170, "type": "DATASET", "confidence": 0.7610219717025757}, {"text": "TXM EPPI  and TE training data", "start_pos": 207, "end_pos": 237, "type": "DATASET", "confidence": 0.6655211001634598}, {"text": "de- fault species tagging", "start_pos": 271, "end_pos": 296, "type": "TASK", "confidence": 0.7166683197021484}]}, {"text": " Table 7: Performance of TI with or without the automati- cally predicted species on the joint BioCreAtIvE GN test  dataset.", "labels": [], "entities": [{"text": "TI", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.8683046698570251}, {"text": "BioCreAtIvE GN test  dataset", "start_pos": 95, "end_pos": 123, "type": "DATASET", "confidence": 0.774855837225914}]}, {"text": " Table 8: # of species per document in the TXM data.", "labels": [], "entities": [{"text": "TXM data", "start_pos": 43, "end_pos": 51, "type": "DATASET", "confidence": 0.9432394802570343}]}]}