{"title": [{"text": "Dependency-based Syntactic-Semantic Analysis with PropBank and NomBank", "labels": [], "entities": [{"text": "Dependency-based Syntactic-Semantic Analysis", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6818844079971313}, {"text": "PropBank", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9530932307243347}, {"text": "NomBank", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.6799546480178833}]}], "abstractContent": [{"text": "This paper presents our contribution in the closed track of the 2008 CoNLL Shared Task (Surdeanu et al., 2008).", "labels": [], "entities": [{"text": "2008 CoNLL Shared Task (Surdeanu et al., 2008)", "start_pos": 64, "end_pos": 110, "type": "DATASET", "confidence": 0.586419555273923}]}, {"text": "To tackle the problem of joint syntactic-semantic analysis , the system relies on a syntactic and a semantic subcomponent.", "labels": [], "entities": [{"text": "joint syntactic-semantic analysis", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.6872367461522421}]}, {"text": "The syntactic model is a bottom-up projective parser using pseudo-projective transformations, and the semantic model uses global inference mechanisms on top of a pipeline of clas-sifiers.", "labels": [], "entities": []}, {"text": "The complete syntactic-semantic output is selected from a candidate pool generated by the subsystems.", "labels": [], "entities": []}, {"text": "The system achieved the top score in the closed challenge: a labeled syntactic accuracy of 89.32%, a labeled semantic F1 of 81.65, and a labeled macro F1 of 85.49.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9169342517852783}, {"text": "labeled semantic F1", "start_pos": 101, "end_pos": 120, "type": "METRIC", "confidence": 0.5394114454587301}, {"text": "labeled macro F1", "start_pos": 137, "end_pos": 153, "type": "METRIC", "confidence": 0.5980563263098398}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 3.  After the submission deadline, we corrected a bug  in the predicate identification method. This re- sulted in improved results shown in the lower part.", "labels": [], "entities": [{"text": "predicate identification", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.7314355671405792}]}, {"text": " Table 4: Impact of second-order features.", "labels": [], "entities": []}, {"text": " Table 5: Labels affected by second-order features.", "labels": [], "entities": []}, {"text": " Table 6: SRL results on the top-scoring parse trees.", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.6129395365715027}]}]}