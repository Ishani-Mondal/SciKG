{"title": [{"text": "A Small-Vocabulary Shared Task for Medical Speech Translation", "labels": [], "entities": [{"text": "Medical Speech Translation", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.68166583776474}]}], "abstractContent": [{"text": "We outline a possible small-vocabulary shared task for the emerging medical speech translation community.", "labels": [], "entities": [{"text": "medical speech translation", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.6414138476053873}]}, {"text": "Data would consist of about 2000 recorded and transcribed utterances collected during an evaluation of an English \u2194 Spanish version of the Open Source MedSLT system; the vocabulary covered consisted of about 450 words in English, and 250 in Spanish.", "labels": [], "entities": []}, {"text": "The key problem in defining the task is to agree on a scoring system which is acceptable both to medical professionals and to the speech and language community.", "labels": [], "entities": []}, {"text": "We suggest a framework for defining and administering a scoring system of this kind.", "labels": [], "entities": []}], "introductionContent": [{"text": "In computer science research, a \"shared task\" is a competition between interested teams, where the goal is to achieve as good performance as possible on a well-defined problem that everyone agrees to work on.", "labels": [], "entities": []}, {"text": "The shared task has three main components: training data, test data, and an evaluation metric.", "labels": [], "entities": []}, {"text": "Both test and training data are divided up into sets of items, which are to be processed.", "labels": [], "entities": []}, {"text": "The evaluation metric defines a score for each processed item.", "labels": [], "entities": []}, {"text": "Competitors are first given the training data, which they use to construct and/or train their systems.", "labels": [], "entities": []}, {"text": "They are then evaluated on the test data, which they have not previously seen.", "labels": [], "entities": []}, {"text": "In many areas of speech and language processing, agreement on a shared task has been a major step forward.", "labels": [], "entities": [{"text": "speech and language processing", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.6200088188052177}]}, {"text": "Often, it has in effect created anew subfield, since it allows objective comparison of results between different groups.", "labels": [], "entities": []}, {"text": "For example, it is very common at speech conference to have special sessions devoted to recognition within a particular shared task database.", "labels": [], "entities": []}, {"text": "In fact, a conference without at least a couple of such sessions would bean anomaly.", "labels": [], "entities": []}, {"text": "A recent success story in language processing is the Recognizing Textual Entailment (RTE) task 1 . Since its inception in 2004, this has become extremely popular; the yearly RTE workshop now attracts around 40 submissions, and error rates on the task have more than halved.", "labels": [], "entities": [{"text": "language processing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7084715813398361}, {"text": "Recognizing Textual Entailment (RTE) task 1", "start_pos": 53, "end_pos": 96, "type": "TASK", "confidence": 0.773475032299757}, {"text": "error", "start_pos": 227, "end_pos": 232, "type": "METRIC", "confidence": 0.9597204327583313}]}, {"text": "Automatic medical speech translation would clearly benefit from a shared task.", "labels": [], "entities": [{"text": "medical speech translation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.6560937265555064}]}, {"text": "As was made apparent at the initial 2006 workshop in New York 2 , nearly every group has both a unique architecture and a unique set of data, essentially making comparisons impossible.", "labels": [], "entities": []}, {"text": "In this note, we will suggest an initial small-vocabulary medical shared task.", "labels": [], "entities": []}, {"text": "The aspect of the task that is hardest to define is the evaluation metric, since there unfortunately appears to be considerable tension between the preferences of medical professionals and speech system implementers.", "labels": [], "entities": []}, {"text": "Medical professionals would prefer to carryout a \"deep\" evaluation, in terms of possible clinical consequences following from a mistranslation.", "labels": [], "entities": []}, {"text": "System evaluators will on the other hand prefer an evaluation method that can be carried out quickly, enabling frequent evaluations of evolving systems.", "labels": [], "entities": []}, {"text": "The plan we will sketch out is intended to be a compromise between these two opposing positions.", "labels": [], "entities": []}, {"text": "The rest of the note is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the data we propose to use, and Section 3 discusses our approach to evaluation metrics.", "labels": [], "entities": []}], "datasetContent": [{"text": "The job of the evaluation component in the shared task is to assign a score to each translated utterance.", "labels": [], "entities": []}, {"text": "Our basic model will be the usual one for shared tasks in speech and language.", "labels": [], "entities": []}, {"text": "Each processed utterance will be assigned to a category; each category will be associated with a specified score; the score fora complete testset will the sum of the scores for all of its utterances.", "labels": [], "entities": []}, {"text": "We thus have three sub-problems: deciding what the categories are, deciding how to assign a category to a processing utterance, and deciding what scores to associate with each category.", "labels": [], "entities": []}], "tableCaptions": []}