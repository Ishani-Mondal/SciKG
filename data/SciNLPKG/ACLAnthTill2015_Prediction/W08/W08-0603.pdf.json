{"title": [{"text": "Using Automated Feature Optimisation to Create an Adaptable Relation Extraction System", "labels": [], "entities": [{"text": "Adaptable Relation Extraction", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.6878512303034464}]}], "abstractContent": [{"text": "An adaptable relation extraction system for the biomedical domain is presented.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7296759337186813}]}, {"text": "The system makes use of a large set of contextual and shallow syntactic features, which can be automatically optimised for each relation type.", "labels": [], "entities": []}, {"text": "The system is tested on three different relation types; protein-protein interactions, tissue expression relations and fragment to parent protein relations .", "labels": [], "entities": []}], "introductionContent": [{"text": "In biomedical information extraction, research in named entity recognition (ner) and relation extraction (re) has tended to focus on the extracting proteins and their interactions, with less thought given to how to adapt such systems to other entities and relations of biomedical interest.", "labels": [], "entities": [{"text": "biomedical information extraction", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.6654080450534821}, {"text": "named entity recognition (ner)", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7758758763472239}, {"text": "relation extraction (re)", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.7717865526676178}]}, {"text": "This is especially true for re, where there is very little work on relations other than protein-protein interactions.", "labels": [], "entities": []}, {"text": "Nevertheless, in order to create applications of use to biologists such as curation assistants and improved information extraction and retrieval systems it will be necessary to treat a broader range of semantic relations.", "labels": [], "entities": [{"text": "information extraction and retrieval", "start_pos": 108, "end_pos": 144, "type": "TASK", "confidence": 0.8087584972381592}]}, {"text": "The recent release of the Genia event corpus () will help to drive this research.", "labels": [], "entities": [{"text": "Genia event corpus", "start_pos": 26, "end_pos": 44, "type": "DATASET", "confidence": 0.6526143054167429}]}, {"text": "The aim of this paper is to address the problem of how to create an re system, which can be adapted to different biomedical re problems with a minimum of manual intervention.", "labels": [], "entities": []}, {"text": "Since this paper focuses on relation extraction, it will be assumed that the named entities are given, in other words the human annotated entities are used in all experiments.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.9114272892475128}]}, {"text": "The approach taken tore is to treat it as a supervised classification problem on relation candidates, using a large collection of shallow syntactic and contextual features.", "labels": [], "entities": []}, {"text": "Relation candidates are pairs of entities, picked out using an appropriate candidate generation strategy.", "labels": [], "entities": []}, {"text": "The use of shallow (as opposed to deep) syntactic features means that the system can rely on relatively robust linguistic tools such as part-ofspeech taggers and chunkers, rather than more brittle and less widely available tools such as parsers.", "labels": [], "entities": []}, {"text": "The difficulty with feature-based methods is, however, how to select the best performing feature set, as simply adding all possible features does not necessarily give the best results.", "labels": [], "entities": []}, {"text": "The approach taken here is to implement a large feature set and then use a greedy search to explore the feature set and select the best subset of features.", "labels": [], "entities": []}, {"text": "This method of feature set optimisation is not new (for example, it was applied by one team () on the BioCreative II Gene Mention task ), but in this work a comparison of search starting points and feature groupings will be presented.", "labels": [], "entities": [{"text": "BioCreative II Gene Mention task", "start_pos": 102, "end_pos": 134, "type": "TASK", "confidence": 0.6915334939956665}]}, {"text": "All re systems require a human-annotated corpus for testing, and since a supervised machine learning approach is employed, a corpus is also required for training the system.", "labels": [], "entities": []}, {"text": "The experiments described in this paper make use of the ITI TXM corpora, which include the ppi corpus addressing protein-protein interactions, and the te corpus addressing tissue expression.", "labels": [], "entities": [{"text": "ITI TXM corpora", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.8608262340227762}]}, {"text": "Both corpora consist of approximately 200 full-text biomedical research papers annotated with entities, normalisations of entities to standard databases, relations, and with enriched information added to the relations.", "labels": [], "entities": []}, {"text": "Only the entities and relations will be considered here.", "labels": [], "entities": []}, {"text": "This paper is organised as follows: after reviewing related work in the following section, there system is described in Section 3, including a description of the corpora, the relation candidate extraction strategies, the features employed, the feature optimisation methods and the evaluation method.", "labels": [], "entities": [{"text": "relation candidate extraction", "start_pos": 175, "end_pos": 204, "type": "TASK", "confidence": 0.6864124735196432}]}, {"text": "In Section 4 the results of the optimisation experiments are presented and discussed, with some concluding remarks in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In all re experiments, the annotated entities were assumed as given so that only re performance was being assessed.", "labels": [], "entities": []}, {"text": "The performance was measured using precision-recall break-even point (bep), which is found by adjusting the decision boundary (threshold) of the classifier until the precision and recall are equal then taking the value of the F 1 at this threshold.", "labels": [], "entities": [{"text": "precision-recall break-even point (bep)", "start_pos": 35, "end_pos": 74, "type": "METRIC", "confidence": 0.9629806081453959}, {"text": "precision", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.9976335763931274}, {"text": "recall", "start_pos": 180, "end_pos": 186, "type": "METRIC", "confidence": 0.9918333292007446}, {"text": "F 1", "start_pos": 226, "end_pos": 229, "type": "METRIC", "confidence": 0.9566693007946014}]}, {"text": "The bep has the advantage over F 1 that its definition is independent of the choice of threshold, but it can still be compared easily to the iaa and is based on the familiar concepts of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9992258548736572}, {"text": "recall", "start_pos": 200, "end_pos": 206, "type": "METRIC", "confidence": 0.995345413684845}]}], "tableCaptions": [{"text": " Table 3: Counts of documents and annotations in each  corpus.", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.975078821182251}]}, {"text": " Table 5: iaa for relation annotation, split by inter-and  intra-sentential", "labels": [], "entities": []}, {"text": " Table 6: Greedy search feature exploration for intra- sentential relations. Performance is measured on all re- lations, testing on devtest.", "labels": [], "entities": []}, {"text": " Table 7: Greedy search feature exploration for inter- sentential relations. Performance is measured on all re- lations, testing on devtest.", "labels": [], "entities": []}, {"text": " Table 8: Greedy search feature exploration with random  feature groupings for intra-sentential relations. The ini- tial feature set is a slightly modified all in each case, and  the search was run 5 times, testing on devtest. The  ensemble system combines the 5 optimised feature sets  using the geometric mean probability.", "labels": [], "entities": [{"text": "Greedy search feature exploration", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.5951899588108063}]}, {"text": " Table 9: The performance of the system trained on train  and devtest, and tested on test. Performance is com- pared across the baseline feature sets (base and all) and  the optimised feature set (best) using each classifier.", "labels": [], "entities": []}]}