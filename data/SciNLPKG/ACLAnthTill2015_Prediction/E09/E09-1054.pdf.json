{"title": [{"text": "Lattice Parsing to Integrate Speech Recognition and Rule-Based Machine Translation", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6805716007947922}, {"text": "Rule-Based Machine Translation", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.630908727645874}]}], "abstractContent": [{"text": "In this paper, we present a novel approach to integrate speech recognition and rule-based machine translation by lattice parsing.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8210049271583557}, {"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7376360893249512}, {"text": "lattice parsing", "start_pos": 113, "end_pos": 128, "type": "TASK", "confidence": 0.6882884353399277}]}, {"text": "The presented approach is hybrid in two senses.", "labels": [], "entities": []}, {"text": "First, it combines structural and statistical methods for language modeling task.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7855837643146515}]}, {"text": "Second, it employs a chart parser which utilizes manually created syntax rules in addition to scores obtained after statistical processing during speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.7292094528675079}]}, {"text": "The employed chart parser is a unification-based active chart parser.", "labels": [], "entities": [{"text": "unification-based active chart parser", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.6760687083005905}]}, {"text": "It can parse word graphs by using a mixed strategy instead of being bottom-up or top-down only.", "labels": [], "entities": [{"text": "parse word graphs", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.8257432182629904}]}, {"text": "The results are reported based on word error rate on the NIST HUB-1 word-lattices.", "labels": [], "entities": [{"text": "NIST HUB-1 word-lattices", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.9353112777074178}]}, {"text": "The presented approach is implemented and compared with other syntactic language modeling techniques .", "labels": [], "entities": []}], "introductionContent": [{"text": "The integration of speech and language technologies plays an important role in speech to text translation.", "labels": [], "entities": [{"text": "speech to text translation", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.618531309068203}]}, {"text": "This paper describes a unificationbased active chart parser and how it is utilized for language modeling in speech recognition or speech translation.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.7763710916042328}, {"text": "speech translation", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.7199040055274963}]}, {"text": "The fundamental idea behind the proposed solution is to combine the strengths of unification-based chart parsing and statistical language modeling.", "labels": [], "entities": [{"text": "unification-based chart parsing", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.697531928618749}, {"text": "statistical language modeling", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.8012260794639587}]}, {"text": "In the solution, all sentence hypotheses, which are represented in word-lattice format at the end of automatic speech recognition (ASR), are parsed simultaneously.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 101, "end_pos": 135, "type": "TASK", "confidence": 0.8017099599043528}]}, {"text": "The chart is initialized with the lattice and it is processed until the first sentence hypothesis is selected by the parser.", "labels": [], "entities": []}, {"text": "The parser also utilizes the scores assigned to words during the speech recognition process.", "labels": [], "entities": [{"text": "speech recognition process", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.7678214013576508}]}, {"text": "This leads to a hybrid solution.", "labels": [], "entities": []}, {"text": "An important benefit of this approach is that it allows one to make use of the available grammars and parsers for language modeling task.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.8096855580806732}]}, {"text": "So as to be used for this task, syntactic analyzer components developed fora rule-based machine translation (RBMT) system are modified.", "labels": [], "entities": [{"text": "rule-based machine translation (RBMT)", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.8014004627863566}]}, {"text": "In speech translation (ST), this approach leads to a perfect integration of the ASR and RBMT components.", "labels": [], "entities": [{"text": "speech translation (ST)", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.8599888563156128}, {"text": "ASR", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.6995794773101807}]}, {"text": "Language modeling effort in ASR and syntactic analysis effort in RBMT are overlapped and merged into a single task.", "labels": [], "entities": [{"text": "Language modeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6998797804117203}, {"text": "ASR", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9861575365066528}, {"text": "RBMT", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.7258080840110779}]}, {"text": "First, this allows us to avoid unnecessary duplication of similar jobs.", "labels": [], "entities": []}, {"text": "Secondly, by using the available components, we avoid the difficulty of building a syntactic language model all from the beginning.", "labels": [], "entities": []}, {"text": "There are two basic methods that are being used to integrate ASR and rule-based MT systems: First-best method and the N-best list method.", "labels": [], "entities": [{"text": "ASR", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9940690994262695}, {"text": "MT", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.8957622051239014}]}, {"text": "Both techniques are motivated from a software engineering perspective.", "labels": [], "entities": []}, {"text": "In the First-best approach.a), the ASR module sends a single recognized text to the MT component to translate.", "labels": [], "entities": [{"text": "ASR", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9729313254356384}]}, {"text": "Any ambiguity existing in the recognition process is resolved inside the ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8460569977760315}]}, {"text": "In contrast to the Firstbest approach, in the N-best List approach (.b); the ASR outputs N possible recognition hypotheses to be evaluated by the MT component.", "labels": [], "entities": []}, {"text": "The MT picks the first hypothesis and translates it if it is grammatically correct.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9313986301422119}]}, {"text": "Otherwise, it moves to the second hypothesis and soon.", "labels": [], "entities": []}, {"text": "If none of the available hypotheses are syntactically correct, then it translates the first one.", "labels": [], "entities": []}, {"text": "We propose anew method to couple ASR and rule-based MT system as an alternative to the ap-proaches mentioned above.", "labels": [], "entities": [{"text": "ASR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.8919550776481628}, {"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9123964905738831}]}, {"text": "represents the two currently in-use coupling methods followed by the new approach we introduce.c).", "labels": [], "entities": []}, {"text": "In the newly proposed technique, which we call the N-best word graph approach, the ASR module outputs a word graph containing all N-best hypotheses.", "labels": [], "entities": []}, {"text": "The MT component parses the word graph, thus, all possible hypotheses atone time.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.7308298945426941}]}, {"text": "While integrating the SR system with the rulebased MT system, this study uses word graphs and chart parsing with new extensions.", "labels": [], "entities": [{"text": "MT", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.8747568130493164}, {"text": "chart parsing", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.776440441608429}]}, {"text": "Parsing of word lattices has been a topic of research over the past decade.", "labels": [], "entities": [{"text": "Parsing of word lattices", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9094815999269485}]}, {"text": "The idea of chart parsing the word graph in SR systems has been previously used in different studies in order to resolve ambiguity.", "labels": [], "entities": [{"text": "chart parsing the word graph in SR", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.7538858950138092}]}, {"text": "introduced the concept of wordlattice parsing for the purpose of speech recognition and used an LR parser.", "labels": [], "entities": [{"text": "wordlattice parsing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7694233357906342}, {"text": "speech recognition", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7497021853923798}]}, {"text": "Next, used a chart parser to process word-lattices.", "labels": [], "entities": []}, {"text": "However, to the best of our knowledge, the specific method for chart parsing a word graph introduced in this paper has not been previously used for coupling purposes.", "labels": [], "entities": [{"text": "chart parsing a word graph", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.8151624858379364}]}, {"text": "Recent studies point out the importance of utilizing word graphs in speech tasks (.", "labels": [], "entities": []}, {"text": "Previous work on language modeling can be classified according to whether a system uses purely statistical methods or whether it uses them in combination with syntactic methods.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7399393320083618}]}, {"text": "In this paper, the focus is on systems that contain syntactic approaches.", "labels": [], "entities": []}, {"text": "In general, these language modeling approaches try to parse the ASR output in wordlattice format in order to choose the most probable hypothesis.", "labels": [], "entities": [{"text": "ASR", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.7949211597442627}]}, {"text": "used a unification-based CYK parser for the purpose of speech understanding. and utilized probabilistic context free grammars in conjunction with unification grammars to chart-parse a word-lattice.", "labels": [], "entities": [{"text": "speech understanding.", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7243632972240448}]}, {"text": "There are various differences between the work of and and the work presented in this paper.", "labels": [], "entities": []}, {"text": "First, in the previously mentioned studies, the chart is populated with the same word graph that comes from the speech recognizer without any pruning, whereas in our approach the word graph is reduced to an acceptable size.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.6692986339330673}]}, {"text": "Otherwise, the efficiency becomes a big challenge because the search space introduced by a chart with over thousands of initial edges can easily be beyond current practical limits.", "labels": [], "entities": []}, {"text": "Another important difference in our approach is the modification of the chart parsing algorithm to eliminate spurious parses.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.7139310538768768}]}, {"text": "Ney (1991) deals with the use of probabilistic CYK parser for continous speech recognition task.", "labels": [], "entities": [{"text": "continous speech recognition task", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.6706861257553101}]}, {"text": "Stolcke (1995) summarizes extensively their approach to utilize probabilistic Earley parsing.", "labels": [], "entities": []}, {"text": "gives an overview of different approaches to integrate linguistic models into speech recognition systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.723996639251709}]}, {"text": "They also research various techniques of producing sets of hypotheses that contain more \"semantic\" variability than the commonly used ones.", "labels": [], "entities": []}, {"text": "Some of the recent studies about structural language modeling extract a list of N-best hypotheses using an N-gram and then apply structural methods to decide on the best hypothesis).", "labels": [], "entities": [{"text": "structural language modeling", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.7043588360150655}]}, {"text": "This contrasts with the approach presented in this study where, instead of a single sentence, the word-lattice is parsed.", "labels": [], "entities": []}, {"text": "Parsing all sentence hypotheses simultaneously enables a reduction in the number of edges produced during the parsing process.", "labels": [], "entities": []}, {"text": "This is because the shared word hypotheses are processed only once compared to the Nbest list approach, where the shared words are processed each time they occur in a hypothesis.", "labels": [], "entities": []}, {"text": "Similar to the current work, other studies parse the whole word-lattice without extracting a list.", "labels": [], "entities": []}, {"text": "A significant distinction between the work of and our study is the parsing algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9779157042503357}]}, {"text": "In contrast to our chart parsing approach augmented by unification based feature structures, Charniak parser is used in's along with PCFG.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.7312829792499542}, {"text": "PCFG", "start_pos": 133, "end_pos": 137, "type": "DATASET", "confidence": 0.9689379334449768}]}, {"text": "The rest of the paper is organized as follows: In the following section, an overview of the proposed language model is presented.", "labels": [], "entities": []}, {"text": "Next, in Section 3, the parsing process of the word-lattice is described in detail.", "labels": [], "entities": []}, {"text": "Section 4 describes the exper-iments and reports the obtained results.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "After all rules are executed and no more edges are left in the agenda, the chart parsing process ends and parse evaluation begins.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.7058562636375427}, {"text": "parse evaluation", "start_pos": 106, "end_pos": 122, "type": "TASK", "confidence": 0.9583835005760193}]}, {"text": "The chart is searched for complete edges with the final symbol of the grammar (e.g. SBAR) as their category.", "labels": [], "entities": []}, {"text": "Any such edge spanning the entire input represents the full parse.", "labels": [], "entities": []}, {"text": "If there is no such edge then the parse recovery process takes control.", "labels": [], "entities": [{"text": "parse recovery", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.9596508741378784}]}, {"text": "If the input sentence is ambiguous, then, at the end of parsing, there will multiple parse trees in the chart that span the entire input.", "labels": [], "entities": []}, {"text": "Similarly, a grammar built with insufficient constraints can lead to multiple parse trees.", "labels": [], "entities": []}, {"text": "In this case, all possible edges are evaluated for completeness and coherence starting from the edge with the highest weight.", "labels": [], "entities": []}, {"text": "A parse tree is complete if all the functional roles (SUBJ, OBJ, SCOMP etc.) governed by the verb are actually present in the cstructure; it is coherent if all the functional roles present are actually governed by the verb.", "labels": [], "entities": []}, {"text": "The parse tree that is evaluated as complete and coherent and has the highest weight is selected for further processing.", "labels": [], "entities": []}, {"text": "In general, a parsing process is said to be successful if a parse tree can be built according to the input sentence.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9680964350700378}]}, {"text": "The building of the parse tree fails when the sentence is ungrammatical.", "labels": [], "entities": []}, {"text": "For the goal of MT, however, a parse tree is required for the transfer stage and the generation stage even if the input is not grammatical.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9935740828514099}]}, {"text": "Therefore, for any input sentence, a corresponding parse tree is built at the end of parsing.", "labels": [], "entities": []}, {"text": "If parsing fails, i.e. if all rules are exhausted and no successful parse tree has been produced, then the system tries to recover from the failure by creating a treelike structure.", "labels": [], "entities": [{"text": "parsing", "start_pos": 3, "end_pos": 10, "type": "TASK", "confidence": 0.9633816480636597}]}, {"text": "Appropriate complete edges in the chart are used for this purpose.", "labels": [], "entities": []}, {"text": "The idea is to piece together all partial parses for the input sentence, so that the number of constituent edges is minimum and the score of the final tree is maximum.", "labels": [], "entities": []}, {"text": "While selecting the constituents, overlapping edges are not chosen.", "labels": [], "entities": []}, {"text": "The recovery process functions as follows: \u2022 The whole chart is traversed and a complete edge is inserted into a candidate list if it has the highest score for that start-end position.", "labels": [], "entities": []}, {"text": "If two edges have the same score, then the farthest one to the leaf level is preferred.", "labels": [], "entities": []}, {"text": "\u2022 The candidate list is traversed and a combination with the minimum number of constituents is selected.", "labels": [], "entities": []}, {"text": "The edges with the widest span get into the winning combination.", "labels": [], "entities": []}, {"text": "\u2022 The c-structures and f-structures of the edges in the winning combination are joined into a whole c-structure and f-structure which represent the final parse tree for the input.", "labels": [], "entities": []}, {"text": "The experiments carried out in this paper are run on word graphs based on 1993 benchmark tests for the ARPA spoken language program.", "labels": [], "entities": [{"text": "ARPA spoken language program", "start_pos": 103, "end_pos": 131, "type": "DATASET", "confidence": 0.7056114673614502}]}, {"text": "In the large-vocabulary continuous speech recognition (CSR) tests reported by, Wall Street Journal-based CSR corpus material was made use of.", "labels": [], "entities": [{"text": "large-vocabulary continuous speech recognition (CSR)", "start_pos": 7, "end_pos": 59, "type": "TASK", "confidence": 0.7682892424719674}, {"text": "Wall Street Journal-based CSR corpus material", "start_pos": 79, "end_pos": 124, "type": "DATASET", "confidence": 0.9656172692775726}]}, {"text": "Those tests intended to measure basic speaker-independent performance on a 64K-word read-speech test set which consists of 213 utterances.", "labels": [], "entities": []}, {"text": "Each of the 10 different speakers provided 20 to 23 utterances.", "labels": [], "entities": []}, {"text": "An acoustic model and a trigram language model is trained using Wall Street Journal data by who also generated the 213 word graphs used in the current experiments.", "labels": [], "entities": [{"text": "Wall Street Journal data", "start_pos": 64, "end_pos": 88, "type": "DATASET", "confidence": 0.9716513901948929}]}, {"text": "The word graphs, referred as HUB-1 data set, contain both the acoustic scores and the trigram language model scores.", "labels": [], "entities": [{"text": "HUB-1 data set", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.9352890253067017}]}, {"text": "Previously, the same data set was used in other studies for language modeling task in ASR.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.8019931018352509}, {"text": "ASR", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.958556056022644}]}, {"text": "We conducted experiments to compare the performance for N-best list parsing and N-best word graph parsing.", "labels": [], "entities": [{"text": "N-best list parsing", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.5767723917961121}, {"text": "N-best word graph parsing", "start_pos": 80, "end_pos": 105, "type": "TASK", "confidence": 0.611816793680191}]}, {"text": "Compared to the N-best list approach, in N-best word graph parsing approach, the shared edges are processed only once for all hypotheses.", "labels": [], "entities": [{"text": "N-best word graph parsing", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.5623186156153679}]}, {"text": "This saves a lot on the number of complete and incomplete edges generated during parsing.", "labels": [], "entities": []}, {"text": "Hence, the overall processing time required to analyze the hypotheses are reduced.", "labels": [], "entities": []}, {"text": "In an N-best list approach, where each hypothesis is processed separately in the analyzer, there are different charts and different parsing instances for each sentence hypothesis.", "labels": [], "entities": []}, {"text": "Shared words in different sentences are parsed repeatedly and same edges will be created at each instance.", "labels": [], "entities": []}, {"text": "represents the number of complete and incomplete edges generated for the NIST HUB-1 data set.", "labels": [], "entities": [{"text": "NIST HUB-1 data set", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.9425888657569885}]}, {"text": "For each hypothesis, 164 complete edges and 2490 incomplete edges are generated on the average in the N-best list approach.", "labels": [], "entities": []}, {"text": "In the N-best word graph approach, the average number of complete edges and incomplete edges reduced to 31 and 341, respectively.", "labels": [], "entities": []}, {"text": "The decrease is 81.1% incomplete edges and 86.3% in incomplete edges for the NIST HUB-1 data set.", "labels": [], "entities": [{"text": "NIST HUB-1 data set", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.948283925652504}]}, {"text": "The profit introduced in the number of edges by using the N-best word graph approach is immense.", "labels": [], "entities": []}, {"text": "In order to compare this approach to previous language modeling approaches we used the same data set.", "labels": [], "entities": []}, {"text": "lists the WER for the NIST HUB-1 data set for different approaches including ours.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9976019263267517}, {"text": "NIST HUB-1 data set", "start_pos": 22, "end_pos": 41, "type": "DATASET", "confidence": 0.9397514313459396}]}, {"text": "The N-best word graph approach presented in this paper scored 12.6 WER and still needs some improvements.", "labels": [], "entities": [{"text": "WER", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9974157810211182}]}, {"text": "The English analysis grammar that was used in the experiments was designed to parse typed text containing punctuation information.", "labels": [], "entities": []}, {"text": "The speech data, however, does not contain any punctuation.", "labels": [], "entities": []}, {"text": "Therefore, the grammar has to be adjusted accordingly to improve the WER.", "labels": [], "entities": [{"text": "WER", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.8112521767616272}]}, {"text": "Another common source of error in parsing is because of unnormalized text.", "labels": [], "entities": [{"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.978640615940094}]}, {"text": "for various language models on HUB-1 lattices in addition to our approach presented in the fifth row.", "labels": [], "entities": []}, {"text": "Model WER Charniak Parser 11.8 Attention Shifting 11.9 () PCFG ( 12.0 A* decoding ( 12.3 N-best word graph (this study) 12.6 PCFG 12.7 PCFG ( 13.0 40m-word trigram 13.7 ( PCFG 15.5", "labels": [], "entities": [{"text": "Charniak Parser 11.8 Attention Shifting 11.9", "start_pos": 10, "end_pos": 54, "type": "TASK", "confidence": 0.5928596009810766}, {"text": "PCFG", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.750063419342041}, {"text": "PCFG 12.7 PCFG", "start_pos": 125, "end_pos": 139, "type": "DATASET", "confidence": 0.6710176666577657}]}], "tableCaptions": [{"text": " Table 1: Word graph accuracy for different N val- ues in the data set with 213 word graphs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9816433787345886}]}, {"text": " Table 2: Number of complete and incomplete  edges generated for the NIST HUB-1 data set us- ing different approaches.", "labels": [], "entities": [{"text": "NIST HUB-1 data set", "start_pos": 69, "end_pos": 88, "type": "DATASET", "confidence": 0.9248101860284805}]}, {"text": " Table 3: WER taken from Hall and Johnson  (2003) for various language models on HUB-1 lat- tices in addition to our approach presented in the  fifth row.  Model  WER  Charniak Parser (Charniak, 2001) 11.8  Attention Shifting  11.9  (Hall and Johnson, 2004)  PCFG (Hall, 2005)  12.0  A* decoding (Xu et al., 2002)  12.3  N-best word graph (this study)  12.6  PCFG (Roark, 2001)  12.7  PCFG (Hall and Johnson, 2004)  13.0  40m-word trigram  13.7  (Hall and Johnson, 2003)  PCFG (Hall and Johnson, 2003)  15.5", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8866201639175415}, {"text": "PCFG (Roark, 2001)  12.7  PCFG", "start_pos": 359, "end_pos": 389, "type": "DATASET", "confidence": 0.7164579182863235}]}]}