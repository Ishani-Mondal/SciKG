{"title": [{"text": "Modelling Early Language Acquisition Skills: Towards a General Statistical Learning Mechanism", "labels": [], "entities": [{"text": "Modelling Early Language Acquisition", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7900151312351227}]}], "abstractContent": [{"text": "This paper reports the ongoing research of a thesis project investigating a computational model of early language acquisition.", "labels": [], "entities": [{"text": "early language acquisition", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.6254018843173981}]}, {"text": "The model discovers word-like units from cross-modal input data and builds continuously evolving internal representations within a cog-nitive model of memory.", "labels": [], "entities": []}, {"text": "Current cognitive theories suggest that young infants employ general statistical mechanisms that exploit the statistical regularities within their environment to acquire language skills.", "labels": [], "entities": []}, {"text": "The discovery of lexical units is modelled on this behaviour as the system detects repeating patterns from the speech signal and associates them to discrete abstract semantic tags.", "labels": [], "entities": []}, {"text": "In its current state, the algorithm is a novel approach for segmenting speech directly from the acoustic signal in an unsupervised manner, therefore liberating it from a pre-defined lexicon.", "labels": [], "entities": []}, {"text": "By the end of the project, it is planned to have an architecture that is capable of acquiring language and communicative skills in an online manner, and carryout robust speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.7125535607337952}]}, {"text": "Preliminary results already show that this method is capable of segmenting and building accurate internal representations of important lexical units as 'emergent' properties from cross-modal data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conventional Automatic Speech Recognition (ASR) systems can achieve very accurate recognition results, particularly when used in their optimal acoustic environment on examples within their stored vocabularies.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.8385505278905233}]}, {"text": "However, when taken out of their comfort zone accuracy significantly deteriorates and does not come anywhere near human speech processing abilities for even the simplest of tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9987176656723022}]}, {"text": "This project investigates novel computational language acquisition techniques that attempt to model current cognitive theories in order to achieve a more robust speech recognition system.", "labels": [], "entities": [{"text": "computational language acquisition", "start_pos": 32, "end_pos": 66, "type": "TASK", "confidence": 0.695718506971995}, {"text": "speech recognition", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.7075862288475037}]}, {"text": "Current cognitive theories suggest that our surrounding environment is rich enough to acquire language through the use of simple statistical processes, which can be applied to all our senses.", "labels": [], "entities": []}, {"text": "The system underdevelopment aims to help clarify this theory, implementing a computational model that is general across multiple modalities and has not been pre-defined with any linguistic knowledge.", "labels": [], "entities": []}, {"text": "In its current form, the system is able to detect words directly from the acoustic signal and incrementally build internal representations within a memory architecture that is motivated by cognitive plausibility.", "labels": [], "entities": []}, {"text": "The algorithm proposed can be split into two main processes, automatic segmentation and word discovery.", "labels": [], "entities": [{"text": "word discovery", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.8205891251564026}]}, {"text": "Automatically segmenting speech directly from the acoustic signal is made possible through the use of dynamic programming (DP); we call this method acoustic DP-ngram's.", "labels": [], "entities": []}, {"text": "The second stage, keyword discovery (KWD), enables the model to hypothesise and build internal representations of word classes that associates the discovered lexical units with discrete abstract semantic tags.", "labels": [], "entities": [{"text": "keyword discovery (KWD)", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.8299034476280213}]}, {"text": "Cross-modal input is fed to the system through the interaction of a carer module as an 'audio' and 'visual' stream.", "labels": [], "entities": []}, {"text": "The audio stream consists of an acoustic signal representing an utterance, while the visual stream is a discrete abstract semantic tag referencing the presence of a keyword within the utterance.", "labels": [], "entities": []}, {"text": "Initial test results show that there is significant potential with the current algorithm, as it segments in an unsupervised manner and does not rely on a predefined lexicon or acoustic phone models that constrain current ASR methods.", "labels": [], "entities": [{"text": "ASR", "start_pos": 221, "end_pos": 224, "type": "TASK", "confidence": 0.9862157106399536}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews current developmental theories and computational models of early language acquisition.", "labels": [], "entities": [{"text": "early language acquisition", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.6395261089007059}]}, {"text": "In section 3, we present the current implementation of the system.", "labels": [], "entities": []}, {"text": "Preliminary experiments and results are described in sections 4 and 5 respectively.", "labels": [], "entities": []}, {"text": "Conclusions and further work are discussed in sections 6 and 7 respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "Accuracy of experiments within the ACORNS project is based on LA's response to its carer.", "labels": [], "entities": []}, {"text": "The correct response is for LA to predict the keyword tag associated with the current incoming utterance while only observing the speech signal.", "labels": [], "entities": [{"text": "LA", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.5412477850914001}]}, {"text": "LA re-uses the acoustic DP-ngram algorithm to solve this task in a similar manner to traditional DP template based speech recognition.", "labels": [], "entities": [{"text": "DP template based speech recognition", "start_pos": 97, "end_pos": 133, "type": "TASK", "confidence": 0.6079732060432435}]}, {"text": "The recognition process is carried out by comparing exemplars, of discovered key words, against the current incoming utterance and calculating a quality distance (as described in stage 3 of section 3.2).", "labels": [], "entities": []}, {"text": "Thus, the exemplar producing the highest quality score, by finding the longest alignment, is taken to be the match, with which we can predict its associated visual tag.", "labels": [], "entities": []}, {"text": "A number of different experiments have been carried out: E1 -Optimal STM Window: This experiment finds the optimal utterance window length for the system as an incremental process.", "labels": [], "entities": []}, {"text": "Varying values of the utterance window length (from 1 to 100) were used to obtain keyword recognition accuracy results across the same data set.", "labels": [], "entities": [{"text": "keyword recognition", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7214947640895844}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.8162625432014465}]}, {"text": "E2 -Batch vs. Incremental: The optimal window length chosen for the incremental implementation is compared against the batch implementation of the algorithm.", "labels": [], "entities": []}, {"text": "E3 -Centroid vs. Exemplars: The KWD process stores a list of exemplars representing each keyword class.", "labels": [], "entities": []}, {"text": "For the recognition task we can either use all the exemplars in each keyword list or a single 'centroid' exemplar that best represents the list.", "labels": [], "entities": []}, {"text": "This experiment will compare these two methods for representing internal representations of the key words.", "labels": [], "entities": []}, {"text": "E4 -Speaker Dependency: The algorithm is tested on its ability to handle the variation in speech from different speakers with different feature vectors.", "labels": [], "entities": []}, {"text": "Using normalisation methods will reduce the information within the feature vectors, removing some of the speaker variation.", "labels": [], "entities": []}, {"text": "Therefore, keyword detection should be more accurate fora data set of multiple speakers with normalisation.", "labels": [], "entities": [{"text": "keyword detection", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8945678472518921}]}], "tableCaptions": []}