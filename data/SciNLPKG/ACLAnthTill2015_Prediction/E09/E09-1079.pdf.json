{"title": [{"text": "Tagging Urdu Text with Parts of Speech: A Tagger Comparison", "labels": [], "entities": [{"text": "Tagging Urdu Text with Parts of Speech", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8689648934773037}]}], "abstractContent": [{"text": "In this paper, four state-of-art probabilistic taggers i.e. TnT tagger, TreeTagger, RF tagger and SVM tool, are applied to the Urdu language.", "labels": [], "entities": [{"text": "RF tagger", "start_pos": 84, "end_pos": 93, "type": "TASK", "confidence": 0.613219603896141}]}, {"text": "For the purpose of the experiment, a syntactic tagset is proposed.", "labels": [], "entities": []}, {"text": "A training corpus of 100,000 tokens is used to train the models.", "labels": [], "entities": []}, {"text": "Using the lexicon extracted from the training corpus, SVM tool shows the best accuracy of 94.15%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9996316432952881}]}, {"text": "After providing a separate lexicon of 70,568 types, SVM tool again shows the best accuracy of 95.66%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9995658993721008}]}], "introductionContent": [], "datasetContent": [{"text": "A corpus of approx 110,000 tokens was taken from a news corpus (www.jang.com.pk).", "labels": [], "entities": []}, {"text": "In the filtering phase, diacritics were removed from the text and normalization was applied to keep the Unicode of the characters consistent.", "labels": [], "entities": []}, {"text": "The problem of space insertion and space deletion was manually solved and space is defined as the word boundary.", "labels": [], "entities": [{"text": "space insertion", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.764470636844635}]}, {"text": "The data was randomly divided into two parts, 90% training corpus and 10% test corpus.", "labels": [], "entities": []}, {"text": "A part of the training set was also used as held out data to optimize the parameters of the taggers.", "labels": [], "entities": []}, {"text": "In the first experiment, no external lexicon was provided.", "labels": [], "entities": []}, {"text": "The types from the training corpus were used as the lexicon by the tagger.", "labels": [], "entities": []}, {"text": "SVM tool showed the best accuracy for both known and unknown words.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7745047211647034}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9993451237678528}]}, {"text": "shows the accuracies of all the taggers.", "labels": [], "entities": []}, {"text": "The baseline result where each word is annotated with its most frequent tag, irrespective of the context, is 88.0%.: Accuracies of open class tags without having an external lexicon\" In the second stage of the experiment, a large lexicon consisting of 70,568 types was provided . After adding the lexicon, there are 112 unknown tokens and 81 unknown types in the test corpus . SVM tool again showed the best accuracy of 95.66%.: Accuracies of open class tags on unknown words.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9944666028022766}, {"text": "accuracy", "start_pos": 408, "end_pos": 416, "type": "METRIC", "confidence": 0.9968664050102234}, {"text": "Accuracies", "start_pos": 429, "end_pos": 439, "type": "METRIC", "confidence": 0.9813817739486694}]}, {"text": "The number of unknown words with tag VB and ADJ are less than 10 in this experiment.\"", "labels": [], "entities": []}, {"text": "The results of the taggers are analyzed by finding the most frequently confused pairs for all the taggers.", "labels": [], "entities": []}, {"text": "It includes both the known and unknown words.", "labels": [], "entities": []}, {"text": "Only those pairs are added in the table which have an occurrence of more than 10.: Most frequently confused tag pairs with total number of occurrences.\"", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Eight most frequent tags in the test  corpus.\"", "labels": [], "entities": []}, {"text": " Table 5: Accuracies of open class tags without  having an external lexicon\"", "labels": [], "entities": []}, {"text": " Table 6: Accuracies of the taggers after adding  the lexicon. SVM tool shows the best accuracy  for known word disambiguation. RF tagger  shows the best accuracy for unknown words.\"", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9884660243988037}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.998547375202179}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9932548403739929}]}, {"text": " Table 9: Most frequently confused tag pairs  with total number of occurrences.\"", "labels": [], "entities": []}]}