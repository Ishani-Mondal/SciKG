{"title": [{"text": "Weakly Supervised Part-of-Speech Tagging for Morphologically-Rich, Resource-Scarce Languages", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.6808127909898758}]}], "abstractContent": [{"text": "This paper examines unsupervised approaches to part-of-speech (POS) tagging for morphologically-rich, resource-scarce languages, with an emphasis on Goldwa-ter and Griffiths's (2007) fully-Bayesian approach originally developed for En-glish POS tagging.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.6472882509231568}, {"text": "POS tagging", "start_pos": 241, "end_pos": 252, "type": "TASK", "confidence": 0.6580429524183273}]}, {"text": "We argue that existing unsupervised POS taggers unreal-istically assume as input a perfect POS lexicon, and consequently, we propose a weakly supervised fully-Bayesian approach to POS tagging, which relaxes the unrealistic assumption by automatically acquiring the lexicon from a small amount of POS-tagged data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 180, "end_pos": 191, "type": "TASK", "confidence": 0.8729063272476196}]}, {"text": "Since such relaxation comes at the expense of a drop in tagging accuracy, we propose two extensions to the Bayesian framework and demonstrate that they are effective in improving a fully-Bayesian POS tagger for Ben-gali, our representative morphologically-rich, resource-scarce language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9721607565879822}]}], "introductionContent": [{"text": "Unsupervised POS tagging requires neither manual encoding of tagging heuristics nor the availability of data labeled with POS information.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.8046278655529022}]}, {"text": "Rather, an unsupervised POS tagger operates by only assuming as input a POS lexicon, which consists of a list of possible POS tags for each word.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.7307345569133759}]}, {"text": "As we can see from the partial POS lexicon for English in, \"the\" is unambiguous with respect to POS tagging, since it can only be a determiner (DT), whereas \"sting\" is ambiguous, since it can be a common noun (NN), a proper noun (NNP) or a verb (VB).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.7531542778015137}]}, {"text": "In other words, the lexicon imposes constraints on the possible POS tags  Conceivably, tagging accuracy decreases with the increase in ambiguity: unambiguous words such as \"the\" will always be tagged correctly; on the other hand, unseen words (or words not present in the POS lexicon) are among the most ambiguous words, since they are not constrained at all and therefore can receive any of the POS tags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9926164746284485}]}, {"text": "Hence, unsupervised POS tagging can present significant challenges to natural language processing researchers, especially when a large fraction of the words are ambiguous.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.8842042088508606}]}, {"text": "Nevertheless, the development of unsupervised taggers potentially allows POS tagging technologies to be applied to a substantially larger number of natural languages, most of which are resource-scarce and, in particular, have little or no POS-tagged data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.893084704875946}]}, {"text": "The most common approach to unsupervised POS tagging to date has been to train a hidden Markov model (HMM) in an unsupervised manner to maximize the likelihood of an unannotated corpus, using a special instance of the expectationmaximization (EM) algorithm known as Baum-Welch.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.8672506809234619}]}, {"text": "More recently, a fully-Bayesian approach to unsupervised POS tagging has been developed byhenceforth G&G] as a viable alternative to the traditional maximumlikelihood-based HMM approach.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.7985133230686188}]}, {"text": "While unsupervised POS taggers adopting both approaches have demonstrated promising results, it is important to note that they are typically evaluated by assuming the availability of a perfect POS lexicon.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.851611316204071}]}, {"text": "This assumption, however, is fairly unrealistic in practice, as a perfect POS lexicon can only be constructed by having a linguist manually label each word in a language with its possible POS tags.", "labels": [], "entities": []}, {"text": "In other words, the labor-intensive POS lexicon construction process renders unsupervised POS taggers a lot less unsupervised than they appear.", "labels": [], "entities": [{"text": "POS lexicon construction", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7514106829961141}]}, {"text": "To make these unsupervised taggers practical, one could attempt to automatically construct a POS lexicon, a task commonly known as POS induction.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 131, "end_pos": 144, "type": "TASK", "confidence": 0.7575500905513763}]}, {"text": "However, POS induction is by no means an easy task, and it is not clear how well unsupervised POS taggers work when used in combination with an automatically constructed POS lexicon.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.932778388261795}, {"text": "POS taggers", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.7255344390869141}]}, {"text": "The goals of this paper are three-fold.", "labels": [], "entities": []}, {"text": "First, motivated by the successes of unsupervised approaches to English POS tagging, we aim to investigate whether such approaches, especially G&G's fully-Bayesian approach, can deliver similar performance for Bengali, our representative resourcescarce language.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.7836280167102814}]}, {"text": "Second, to relax the unrealistic assumption of employing a perfect lexicon as in existing unsupervised POS taggers, we propose a weakly supervised fully-Bayesian approach to POS tagging, where we automatically construct a POS lexicon from a small amount of POS-tagged data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 174, "end_pos": 185, "type": "TASK", "confidence": 0.850062906742096}]}, {"text": "Hence, unlike a perfect POS lexicon, our automatically constructed lexicon is necessarily incomplete, yielding a large number of words that are completely ambiguous.", "labels": [], "entities": []}, {"text": "The high ambiguity rate inherent in our weakly supervised approach substantially complicates the POS tagging process.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9059568047523499}]}, {"text": "Consequently, our third goal of this paper is to propose two potentially performance-enhancing extensions to G&G's Bayesian POS tagging approach, which exploit morphology and techniques successfully used in supervised POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 124, "end_pos": 135, "type": "TASK", "confidence": 0.6235357522964478}, {"text": "POS tagging", "start_pos": 218, "end_pos": 229, "type": "TASK", "confidence": 0.7622281610965729}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents related work on unsupervised approaches to POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 62, "end_pos": 73, "type": "TASK", "confidence": 0.9534812867641449}]}, {"text": "Section 3 gives an introduction to G&G's fully-Bayesian approach to unsupervised POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.8566672801971436}]}, {"text": "In Section 4, we describe our two extensions to G&G's approach.", "labels": [], "entities": []}, {"text": "Section 5 presents experimental results on Bengali POS tagging, focusing on evaluating the effective-1 When evaluating an unsupervised POS tagger, researchers typically construct a pseudo-perfect POS lexicon by collecting the possible POS tags of a word directly from the corpus on which the tagger is to be evaluated.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.6991826146841049}]}, {"text": "ness of our two extensions in improving G&G's approach.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpus Our evaluation corpus is the one used in the shared task of the IJCNLP-08 Workshop on NER for South and South East Asian Languages.", "labels": [], "entities": [{"text": "Corpus Our evaluation corpus", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.7241252213716507}, {"text": "IJCNLP-08 Workshop", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.8146320879459381}, {"text": "NER for South and South East Asian Languages", "start_pos": 93, "end_pos": 137, "type": "TASK", "confidence": 0.548755120486021}]}, {"text": "Specifically, we use the portion of the Bengali dataset that is manually POS-tagged.", "labels": [], "entities": [{"text": "Bengali dataset", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.831461638212204}]}, {"text": "IIIT Hyderabad's POS tagset , which consists of 26 tags specifically developed for Indian languages, has been used to annotate the data.", "labels": [], "entities": [{"text": "IIIT Hyderabad's POS tagset", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.9167602181434631}]}, {"text": "The corpus is composed of a training set and a test set with approxi-mately 50K and 30K tokens, respectively.", "labels": [], "entities": []}, {"text": "Importantly, all our POS tagging results will be reported using only the test set; the training set will be used for lexicon construction, as we will see shortly.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.8542583882808685}, {"text": "lexicon construction", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.7405833303928375}]}, {"text": "Tagset We collapse the set of 26 POS tags into 15 tags.", "labels": [], "entities": []}, {"text": "Specifically, while we retain the tags corresponding to the major POS categories, we merge some of the infrequent tags designed to capture Indian language specific structure (e.g., reduplication, echo words) into a category called OTHERS.", "labels": [], "entities": []}, {"text": "Hyperparameter settings Recall that our tagger consists of three types of distributions -tag transition distributions, word-based output distributions, and suffix-based output distributionsdrawn from asymmetric Dirichlet with \u03b1, \u03b2, and \u03b3 as the underlying hyperparameters, respectively.", "labels": [], "entities": []}, {"text": "We automatically determine the values of these hyperparameters by (1) randomly initializing them and resampling their values by using a Metropolis-Hastings update ( at the end of each sampling iteration.", "labels": [], "entities": []}, {"text": "Details of this update process can be found in G&G.", "labels": [], "entities": [{"text": "G&G", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.8962162733078003}]}, {"text": "Inference Inference is performed by running a Gibbs sampler for 5000 iterations.", "labels": [], "entities": [{"text": "Inference Inference", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9229815304279327}]}, {"text": "The initial temperature is set to 2.0, which is gradually lowered to 0.08 over the iterations.", "labels": [], "entities": []}, {"text": "Owing to the randomness involved in hyperparameter initialization, all reported results are averaged over three runs.", "labels": [], "entities": []}, {"text": "Lexicon construction methods To better understand the role of a POS lexicon in tagging performance, we evaluate each POS tagging model by employing lexicons constructed by three methods.", "labels": [], "entities": [{"text": "Lexicon construction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7754393815994263}]}, {"text": "The first lexicon construction method, arguably the most unrealistic among the three, follows that of G&G: for each word, w, in the test set, we (1) collect from each occurrence of win the training set and the test set its POS tag, and then (2) insert wand all the POS tags collected for w into the POS lexicon.", "labels": [], "entities": [{"text": "lexicon construction", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7649128437042236}]}, {"text": "This method is unrealistic because (1) in practice, a human needs to list all possible POS tags for each word in order to construct this lexicon, thus rendering the resulting tagger considerably less unsupervised than it appears; and (2) constructing the lexicon using the dataset on which the tagger is to be evaluated implies that there is no unseen word w.r.t. the lexicon, thus unrealistically simplifies the POS tagging task.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 413, "end_pos": 424, "type": "TASK", "confidence": 0.9368765652179718}]}, {"text": "To make the method more realistic, G&G also create a set of relaxed lexicons.", "labels": [], "entities": []}, {"text": "Each of these lexicons includes the tags for only the words that appear at least d times in the test corpus, where d ranges from 1 to 10 in our experiments.", "labels": [], "entities": []}, {"text": "Any unseen (i.e., out-of-dictionary) word is ambiguous among the 15 possible tags.", "labels": [], "entities": []}, {"text": "Not surprisingly, both ambiguity and the unseen word rate increase with d.", "labels": [], "entities": [{"text": "word rate", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.7910540103912354}]}, {"text": "For instance, the ambiguous token rate increases from 40.0% with 1.7 tags/token (d=1) to 77.7% with 8.1 tags/token (d=10).", "labels": [], "entities": []}, {"text": "Similarly, the unseen word rate increases from 16% (d=2) to 46% (d=10).", "labels": [], "entities": [{"text": "unseen word rate", "start_pos": 15, "end_pos": 31, "type": "METRIC", "confidence": 0.6209142903486887}]}, {"text": "We will refer to this set of tag dictionaries as Lexicon 1.", "labels": [], "entities": []}, {"text": "The second method generates a set of relaxed lexicons, Lexicon 2, in essentially the same way as the first method, except that these lexicons include only the words that appear at least d times in the training data.", "labels": [], "entities": []}, {"text": "Importantly, the words that appear solely in the test data are not included in any of these relaxed POS lexicons.", "labels": [], "entities": []}, {"text": "This makes Lexicon 2 a bit more realistic than Lexicon 1 in terms of the way they are constructed.", "labels": [], "entities": []}, {"text": "As a result, in comparison to Lexicon 1, Lexicon 2 has a considerably higher ambiguous token rate and unseen word rate: its ambiguous token rate ranges from 64.3% with 5.3 tags/token (d=1) to 80.5% with 8.6 tags/token (d=10), and its unseen word rate ranges from 25% (d=1) to 50% (d=10).", "labels": [], "entities": []}, {"text": "The third method, arguably the most realistic among the three, is motivated by our proposed weakly supervised approach.", "labels": [], "entities": []}, {"text": "In this method, we (1) form ten different datasets from the (labeled) training data of sizes 5K words, 10K words, . .", "labels": [], "entities": []}, {"text": "., 50K words, and then (2) create one POS lexicon from each dataset L by listing, for each word win L, all the tags associated with win L.", "labels": [], "entities": []}, {"text": "This set of tag dictionaries, which we will refer to as Lexicon 3, has an ambiguous token rate that ranges from 57.7% with 5.1 tags/token (50K) to 61.5% with 8.1 tags/token (5K), and an unseen word rate that ranges from 25% (50K) to 50% (5K).", "labels": [], "entities": []}], "tableCaptions": []}