{"title": [{"text": "Clique-Based Clustering for improving Named Entity Recognition systems", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.6991029183069865}]}], "abstractContent": [{"text": "We propose a system which builds, in a semi-supervised manner, a resource that aims at helping a NER system to annotate corpus-specific named entities.", "labels": [], "entities": []}, {"text": "This system is based on a distributional approach which uses syntactic dependencies for measuring similarities between named entities.", "labels": [], "entities": []}, {"text": "The specificity of the presented method however, is to combine a clique-based approach and a clustering technique that amounts to a soft clustering method.", "labels": [], "entities": []}, {"text": "Our experiments show that the resource constructed by using this clique-based clustering system allows to improve different NER systems.", "labels": [], "entities": [{"text": "NER", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.962921679019928}]}], "introductionContent": [{"text": "In Information Extraction domain, named entities (NEs) are one of the most important textual units as they express an important part of the meaning of a document.", "labels": [], "entities": [{"text": "Information Extraction domain, named entities (NEs)", "start_pos": 3, "end_pos": 54, "type": "TASK", "confidence": 0.7248560653792487}]}, {"text": "Named entity recognition (NER) is not anew domain (see MUC and ACE 2 conferences) but some new needs appeared concerning NEs processing.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8213324546813965}, {"text": "MUC and ACE 2 conferences", "start_pos": 55, "end_pos": 80, "type": "DATASET", "confidence": 0.7807752192020416}, {"text": "NEs processing", "start_pos": 121, "end_pos": 135, "type": "TASK", "confidence": 0.9483214318752289}]}, {"text": "For instance the NE Oxford illustrates the different ambiguity types that are interesting to address: \u2022 intra-annotation ambiguity: Wikipedia lists more than 25 cities named Oxford in the world \u2022 systematic inter-annotation ambiguity: the name of cities could be used to refer to the university of this city or the football club of this city.", "labels": [], "entities": [{"text": "NE Oxford", "start_pos": 17, "end_pos": 26, "type": "DATASET", "confidence": 0.9489038288593292}]}, {"text": "This is the case for Oxford or Newcastle \u2022 non-systematic inter-annotation ambiguity: Oxford is also a company unlike Newcastle.", "labels": [], "entities": [{"text": "Oxford", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.9549680948257446}, {"text": "Newcastle", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.6204860210418701}, {"text": "Oxford", "start_pos": 86, "end_pos": 92, "type": "DATASET", "confidence": 0.9648609161376953}]}, {"text": "The main goal of our system is to act in a complementary way with an existing NER system, in order to enhance its results.", "labels": [], "entities": []}, {"text": "We address two kinds of issues: first, we want to detect and correctly annotate corpus-specific NEs 3 that the NER system could have missed; second, we want to correct some wrong annotations provided by the existing NER system due to ambiguity.", "labels": [], "entities": []}, {"text": "In section 3, we give some examples of such corrections.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We present, in section 2, the global architecture of our system and from \u00a72.1 to \u00a72.6, we give details about each of its steps.", "labels": [], "entities": []}, {"text": "In section 3, we present the evaluation of our approach when it is combined with other classic NER systems.", "labels": [], "entities": []}, {"text": "We show that the resulting hybrid systems perform better with respect to F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9715452194213867}]}, {"text": "In the best case, the latter increased by 4.84 points.", "labels": [], "entities": []}, {"text": "Furthermore, we give examples of successful correction of NEs annotation thanks to our approach.", "labels": [], "entities": [{"text": "NEs annotation", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7903814017772675}]}, {"text": "Then, in section 4, we discuss about related works.", "labels": [], "entities": []}, {"text": "Finally we sum up the main points of this paper in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system described in this paper rather target corpus-specific NE annotation.", "labels": [], "entities": []}, {"text": "Therefore, our ex-periments will deal with a corpus of recent news articles (see () for motivations regarding our corpus choice) rather than well-known annotated corpora.", "labels": [], "entities": []}, {"text": "Our corpus is constituted of news in English published on the web during two weeks in June 2008.", "labels": [], "entities": []}, {"text": "This corpus is constituted of around 300,000 words (10Mb) which doesn't represent a very large corpus.", "labels": [], "entities": []}, {"text": "These texts were taken from various press sources and they involve different themes (sports, technology, . .", "labels": [], "entities": []}, {"text": "). We extracted randomly a subset of articles and manually annotated 916 NEs (in our experiments, we deal with three types of annotation namely <person>, <organization> and <location>).", "labels": [], "entities": []}, {"text": "This subset constitutes our test set.", "labels": [], "entities": []}, {"text": "In our experiments, first, we applied the XIP parser) to the whole corpus in order to construct the frequency matrix D given by (1).", "labels": [], "entities": []}, {"text": "Next, we computed the similarity matrix between NEs according to in order to obtain\u02c6sobtain\u02c6 obtain\u02c6s defined by.", "labels": [], "entities": []}, {"text": "Using the latter, we computed cliques of NEs that allow us to obtain the assignment matrix T given by (5).", "labels": [], "entities": []}, {"text": "Then we applied the clustering heuristic described in Algorithm 1.", "labels": [], "entities": []}, {"text": "At this stage, we want to build the NE resource using the clusters of cliques.", "labels": [], "entities": []}, {"text": "Therefore, as described in \u00a72.5, we applied two kinds of clusters annotations: the manual and the automatic processes.", "labels": [], "entities": []}, {"text": "For the first one, we manually annotated the 100 biggest clusters of cliques.", "labels": [], "entities": []}, {"text": "For the second one, we exploited the annotations provided by XIP NER () and we propagated these annotations to the different clusters (see \u00a72.5.2).", "labels": [], "entities": [{"text": "XIP NER", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.8002291321754456}]}, {"text": "The different materials that we obtained constitute the CBC system's NE resource.", "labels": [], "entities": [{"text": "CBC system's NE resource", "start_pos": 56, "end_pos": 80, "type": "DATASET", "confidence": 0.7516801238059998}]}, {"text": "Our aim now is to exploit this resource and to show that it allows to improve the performances of different classic NER systems.", "labels": [], "entities": []}, {"text": "The different NER systems that we tested are the following ones: \u2022 CBC-NER system M (in short CBC M) based on the CBC system's NE resource using the manual cluster annotation (line 1 in), \u2022 CBC-NER system A (in short CBC A) based on the CBC system's NE resource using the automatic cluster annotation (line 1 in), \u2022 XIP NER or in short XIP () (line 2 in), \u2022 GATE NER or in short GATE () (line 4 in), \u2022 and several hybrid systems which are given by the combination of pairs taken among the set of the three last-mentioned NER systems (lines 5 to 7 in).", "labels": [], "entities": [{"text": "GATE NER", "start_pos": 358, "end_pos": 366, "type": "DATASET", "confidence": 0.7959977686405182}]}, {"text": "Notice that these baseline hybrid systems use the annotation combination process described in \u00a72.6.1.", "labels": [], "entities": []}, {"text": "In we first reported in each line, the results given by each system when they are applied alone (figures in italics).", "labels": [], "entities": []}, {"text": "These performances represent our baselines.", "labels": [], "entities": []}, {"text": "Second, we tested for each baseline system, an extended hybrid system that integrates the CBC-NER systems (with respect to the combination process detailed in \u00a72.6.2).", "labels": [], "entities": []}, {"text": "The first two lines of show that the two CBC-NER systems alone lead to rather poor results.", "labels": [], "entities": [{"text": "CBC-NER", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9100080728530884}]}, {"text": "However, our aim is to show that the CBC-NER system is, despite its low performances alone, complementary to other basic NER systems.", "labels": [], "entities": []}, {"text": "In other words, we want to show that the exploitation of the CBC system's NE resource is beneficial and non-redundant compared to other baseline NER systems.", "labels": [], "entities": [{"text": "CBC system's NE resource", "start_pos": 61, "end_pos": 85, "type": "DATASET", "confidence": 0.7454692721366882}]}, {"text": "This is actually what we obtained in as for each line from 2 to 7, the extended hybrid systems that integrate the CBC-NER systems (M or A) always perform better than the baseline either in terms of precision 9 or recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 198, "end_pos": 207, "type": "METRIC", "confidence": 0.9955618381500244}, {"text": "recall", "start_pos": 213, "end_pos": 219, "type": "METRIC", "confidence": 0.981489360332489}]}, {"text": "For each line, we put in bold the best performance according to the F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9928541779518127}]}, {"text": "These results allow us to show that the NE resource built using the CBC system is complementary to any baseline NER systems and that it allows to improve the results of the latter.", "labels": [], "entities": []}, {"text": "In order to illustrate why the CBC-NER systems are beneficial, we give below some examples taken from the test corpus for which the CBC system A had allowed to improve the performances by respectively disambiguating or correcting a wrong annotation or detecting corpus-specific NEs.", "labels": [], "entities": []}, {"text": "First, in the sentence \"From the start, his parents, Lourdes and Hemery, were with him.\", the baseline hybrid system Stanford + XIP annotated the ambiguous NE \"Lourdes\" as <location> whereas Stanford + XIP + CBC A gave the correct annotation <person>.", "labels": [], "entities": []}, {"text": "Second, in the sentence \"Got 3 percent chance of survival, what ya gonna do?\"", "labels": [], "entities": []}, {"text": "The back read, \"A) Fight Through, b) Stay Strong, c) Overcome Because I Am a Warrior.\", the baseline hybrid system Stanford + XIP annotated \"Warrior\" as <organization> whereas Stanford + XIP + CBC A corrected this annotation with <none>.", "labels": [], "entities": [{"text": "Stanford + XIP + CBC A", "start_pos": 176, "end_pos": 198, "type": "DATASET", "confidence": 0.8003553549448649}]}, {"text": "Finally, in the sentence \"Matthew, also a favorite to win in his fifth and final appearance, was stunningly eliminated during the semifinal round Friday when he misspelled \"secernent\".\", the baseline hybrid system Stanford + XIP didn't give any annotation to \"Matthew\" whereas Stanford + XIP + CBC A allowed to give the annotation <person>.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results given by different hybrid NER  systems and coupled with the CBC-NER system", "labels": [], "entities": []}]}