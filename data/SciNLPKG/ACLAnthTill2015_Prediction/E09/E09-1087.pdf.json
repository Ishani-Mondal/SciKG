{"title": [{"text": "Semi-supervised Training for the Averaged Perceptron POS Tagger", "labels": [], "entities": [{"text": "POS Tagger", "start_pos": 53, "end_pos": 63, "type": "TASK", "confidence": 0.6539337038993835}]}], "abstractContent": [{"text": "This paper describes POS tagging experiments with semi-supervised training as an extension to the (supervised) averaged perceptron algorithm, first introduced for this task by (Collins, 2002).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.9250966608524323}]}, {"text": "Experiments with an iterative training on standard-sized supervised (manually annotated) dataset (10 6 tokens) combined with a relatively modest (in the order of 10 8 tokens) un-supervised (plain) data in a bagging-like fashion showed significant improvement of the POS classification task on typo-logically different languages, yielding better than state-of-the-art results for English and Czech (4.12 % and 4.86 % relative error reduction, respectively; absolute accuracies being 97.44 % and 95.89 %).", "labels": [], "entities": [{"text": "POS classification", "start_pos": 266, "end_pos": 284, "type": "TASK", "confidence": 0.868336021900177}, {"text": "relative error reduction", "start_pos": 416, "end_pos": 440, "type": "METRIC", "confidence": 0.7087026635805765}, {"text": "accuracies", "start_pos": 465, "end_pos": 475, "type": "METRIC", "confidence": 0.7183215022087097}]}], "introductionContent": [{"text": "Since 2002, we have seen a renewed interest in improving POS tagging results for English, and an inflow of results (initial or improved) for many other languages.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.8321190476417542}]}, {"text": "For English, after a relatively big jump achieved by), we have seen two significant improvements: ( and pushed the results by a significant amount each time.", "labels": [], "entities": []}, {"text": "1 In our final comparison, we have also included the results of (), because it has surpassed) as well and we have used this tagger in the data preparation phase.", "labels": [], "entities": []}, {"text": "Most recently,) published their Semi-supervised sequential labelling method, whose results on POS tagging seem to be optically better than), but no significance tests were given and the tool is not available for download, i.e. for repeating the results and significance testing.", "labels": [], "entities": [{"text": "Semi-supervised sequential labelling", "start_pos": 32, "end_pos": 68, "type": "TASK", "confidence": 0.5517686903476715}, {"text": "POS tagging", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.7378284931182861}]}, {"text": "Thus, we compare our results only to the tools listed above.", "labels": [], "entities": []}, {"text": "Even though an improvement in POS tagging might be a questionable enterprise (given that its effects on other tasks, such as parsing or other NLP problems are less than clear-at least for English), it is still an interesting problem.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.8742378652095795}, {"text": "parsing", "start_pos": 125, "end_pos": 132, "type": "TASK", "confidence": 0.9619244337081909}]}, {"text": "Moreover, the \"ideal\" 2 situation of having a single algorithm (and its implementation) for many (if not all) languages has not been reached yet.", "labels": [], "entities": []}, {"text": "We have chosen Collins' perceptron algorithm because of its simplicity, short training times, and an apparent room for improvement with (substantially) growing data sizes (see).", "labels": [], "entities": []}, {"text": "However, it is clear that there is usually little chance to get (substantially) more manually annotated data.", "labels": [], "entities": []}, {"text": "Thus, we have been examining the effect of adding a large monolingual corpus to Collins' perceptron, appropriately extended, for two typologically different languages: English and Czech.", "labels": [], "entities": []}, {"text": "It is clear however that the features (feature templates) that the taggers use are still language-dependent.", "labels": [], "entities": []}, {"text": "One of the goals is also to have a fast implementation for tagging large amounts of data quickly.", "labels": [], "entities": [{"text": "tagging large amounts of data quickly", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.8722313841183981}]}, {"text": "We have experimented with various classifier combination methods, such as those described in), and got improved results, as expected.", "labels": [], "entities": []}, {"text": "However, we view this only as aside effect (yet, a positive one)-our goal was to stay on the turf of single taggers, which are both the common ground for competing on tagger accuracy today and also significantly faster at runtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.6896210312843323}]}, {"text": "Nevertheless, we have found that it is advantageous to use them to (pre-)tag the large amounts of plain text data dur-  ing the training phase.", "labels": [], "entities": []}, {"text": "Apart from feeding the perceptron by various mixtures of manually tagged (\"supervised\") and auto-tagged (\"unsupervised\") 4 data, we have also used various feature templates extensively; for example, we use lexicalization (with the added twist of lemmatization, useful especially for Czech, an inflectionally rich language), \"manual\" tag classification into large classes (again, useful especially for Czech to avoid the huge, still-to-beovercome data sparseness for such a language 5 ), and sub-lexical features mainly targeted at OOV words.", "labels": [], "entities": []}, {"text": "Inspired i.a. by and), we also use \"lookahead\" features (however, we still remain in the left-to-right HMM world -in this respect our solution is closer to the older work of) than to (, who uses bidirectional dependencies to include the right-hand side disambiguated tags, For brevity, we will use the terms \"supervised\" and \"unsupervised\" data for \"manually annotated\" and \"(automatically annotated) plain (raw) text\" data, respectively, even though these adjectives are meant to describe the process of learning, not the data themselves.", "labels": [], "entities": []}, {"text": "5 As) writes, Czech has 4400 plausible tags, of which we have observed almost 2000 in the 100M corpus we have used in our experiments.", "labels": [], "entities": [{"text": "Czech", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.9572205543518066}]}, {"text": "However, only 1100 of them have been found in the manually annotated PDT 2.0 corpus (the corpus on which we have based the supervised experiments).", "labels": [], "entities": [{"text": "PDT 2.0 corpus", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9100135962168375}]}, {"text": "The situation with word forms (tokens) is even worse: Czech has about 20M different word forms, and the OOV rate based on the 1.5M PDT 2.0 data and measured against the 100M raw corpus is almost 10 %.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9883622825145721}]}, {"text": "To summarize, we can describe our system as follows: it is based on)'s implementation of, which has been fed at each iteration by a different dataset consisting of the supervised and unsupervised part: precisely, by a concatenation of the manually tagged training data (WSJ portion of the PTB 3 for English, morphologically disambiguated data from PDT 2.0 for Czech) and a chunk of automatically tagged unsupervised data.", "labels": [], "entities": [{"text": "WSJ portion of the PTB 3", "start_pos": 270, "end_pos": 294, "type": "DATASET", "confidence": 0.8063262601693472}]}, {"text": "The \"parameters\" of the training process (feature templates, the size of the unsupervised chunks added to the trainer at each iteration, number of iterations, the combination of taggers that should be used in the auto-tagging of the unsupervised chunk, etc.) have been determined empirically in a number of experiments on a development data set.", "labels": [], "entities": []}, {"text": "We should also note that as a result of these development-data-based optimizations, no feature pruning has been employed (see Section 4 for details); adding (even lexical) features from the auto-tagged data did not give significant accuracy improvements (and only made the training very slow).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9975712895393372}]}, {"text": "The final taggers have surpassed the current state-of-the-art taggers by significant margins (we have achieved 4.12 % relative error reduction for English and 4.86 % for Czech over the best previously published results, single or combined), using a single tagger.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 118, "end_pos": 142, "type": "METRIC", "confidence": 0.7823150952657064}]}, {"text": "However, the best English tagger combining some of the previous stateof-the-art ones is still \"optically\" better (yet not significantly-see Section 6).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: English supervised data set -WSJ part  of Penn Treebank 3", "labels": [], "entities": [{"text": "English supervised data set -WSJ part  of Penn Treebank", "start_pos": 10, "end_pos": 65, "type": "DATASET", "confidence": 0.8583419561386109}]}, {"text": " Table 2: Czech supervised data set -Prague De- pendency Treebank 2.0", "labels": [], "entities": [{"text": "Czech supervised data set -Prague De- pendency Treebank 2.0", "start_pos": 10, "end_pos": 69, "type": "DATASET", "confidence": 0.9140237732367082}]}, {"text": " Table 4: Dependence on the tagger(s) used to tag  the additional plain text data (English) 16", "labels": [], "entities": []}, {"text": " Table 5: Unsupervised data selection", "labels": [], "entities": []}, {"text": " Table 6: Dependence on the inclusion of the su- pervised training data", "labels": [], "entities": []}, {"text": " Table 7: Dependence on the feature set used by the  perceptron algorithm (English)", "labels": [], "entities": []}, {"text": " Table 8: Dependence on the GEN(x)", "labels": [], "entities": [{"text": "GEN", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.6356501579284668}]}]}