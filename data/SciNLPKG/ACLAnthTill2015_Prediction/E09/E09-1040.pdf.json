{"title": [], "abstractContent": [{"text": "This paper presents the end-to-end evaluation of an automatic simultaneous translation system, built with state-of-the-art components.", "labels": [], "entities": []}, {"text": "It shows whether, and for which situations, such a system might be advantageous when compared to a human interpreter.", "labels": [], "entities": []}, {"text": "Using speeches in English translated into Spanish, we present the evaluation procedure and we discuss the results both for the recognition and translation components as well as for the overall system.", "labels": [], "entities": []}, {"text": "Even if the translation process remains the Achilles' heel of the system, the results show that the system can keep at least half of the information, becoming potentially useful for final users.", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9728521108627319}]}], "introductionContent": [{"text": "Anyone speaking at least two different languages knows that translation and especially simultaneous interpretation are very challenging tasks.", "labels": [], "entities": [{"text": "translation", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.9798523187637329}, {"text": "simultaneous interpretation", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.6540938913822174}]}, {"text": "A human translator has to cope with the special nature of different languages, comprising phenomena like terminology, compound words, idioms, dialect terms or neologisms, unexplained acronyms or abbreviations, proper names, as well as stylistic and punctuation differences.", "labels": [], "entities": []}, {"text": "Further, translation or interpretation are not a word-by-word rendition of what was said or written in a source language.", "labels": [], "entities": [{"text": "translation or interpretation", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.8694474498430887}]}, {"text": "Instead, the meaning and intention of a given sentence have to be reexpressed in a natural and fluent way in another language.", "labels": [], "entities": []}, {"text": "Most professional full-time conference interpreters work for international organizations like the United Nations, the European Union, or the African Union, whereas the world's largest employer of translators and interpreters is currently the European Commission.", "labels": [], "entities": []}, {"text": "In 2006, the European Parliament spent about 300 million Euros, 30% of its budget, on the interpretation and translation of the parliament speeches and EU documents.", "labels": [], "entities": [{"text": "interpretation and translation of the parliament speeches and EU documents", "start_pos": 90, "end_pos": 164, "type": "TASK", "confidence": 0.8245108127593994}]}, {"text": "Generally, about 1.1 billion Euros are spent per year on the translating and interpreting services within the European Union, which is around 1% of the total EU-Budget).", "labels": [], "entities": [{"text": "translating and interpreting", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8776447971661886}]}, {"text": "This paper presents the end-to-end evaluation of an automatic simultaneous translation system, built with state-of-the-art components.", "labels": [], "entities": []}, {"text": "It shows whether, and in which cases, such a system might be advantageous compared to human interpreters.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation in speech-to-speech translation jeopardises many concepts and implies a lot of subjectivity.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.6819541156291962}]}, {"text": "Three components are involved and an overall system may grow the difficulty of estimating the output quality.", "labels": [], "entities": []}, {"text": "However, two criteria are mainly accepted in the community: measuring the information preservation and determining how much of the translation is understandable.", "labels": [], "entities": []}, {"text": "Several end-to-end evaluations in speech-tospeech translation have been carried out in the last few years, in projects such as JANUS (, Verbmobil (N\u00fcbel, 1997) or TC-STAR ().", "labels": [], "entities": [{"text": "speech-tospeech translation", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.6797439306974411}, {"text": "JANUS", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.556890070438385}, {"text": "Verbmobil (N\u00fcbel, 1997)", "start_pos": 136, "end_pos": 159, "type": "DATASET", "confidence": 0.7205827832221985}, {"text": "TC-STAR", "start_pos": 163, "end_pos": 170, "type": "DATASET", "confidence": 0.7007474899291992}]}, {"text": "Those projects use the main criteria depicted above, and protocols differ in terms of data preparation, rating, procedure, etc.", "labels": [], "entities": []}, {"text": "To our opinion, to evaluate the performance of a complete speech-to-speech translation system, we need to compare the source speech used as input to the translated output speech in the target language.", "labels": [], "entities": []}, {"text": "To that aim, we reused a large part of the evaluation protocol from the TC-STAR project().", "labels": [], "entities": [{"text": "TC-STAR project", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.8767871260643005}]}, {"text": "The evaluation is carried out on the simultaneously translated speech of a single speaker's talks and lectures in the field of speech processing, given in English, and translated into Spanish.", "labels": [], "entities": [{"text": "speech processing", "start_pos": 127, "end_pos": 144, "type": "TASK", "confidence": 0.7466044127941132}]}, {"text": "The system is evaluated as a whole  SLT evaluation.", "labels": [], "entities": [{"text": "SLT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9775916934013367}]}, {"text": "For the SLT evaluation, the automatically translated text from the ASR output is compared with two manual reference translations by means of automatic and human metrics.", "labels": [], "entities": [{"text": "SLT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9932384490966797}]}, {"text": "Two automatic metrics are used: BLEU () and mWER ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9992896318435669}]}, {"text": "For the human evaluation, each segment is evaluated in relation to adequacy and fluency.", "labels": [], "entities": []}, {"text": "For the evaluation of adequacy, the target segment is compared to a reference segment.", "labels": [], "entities": []}, {"text": "For the evaluation of fluency, the quality of the language is evaluated.", "labels": [], "entities": []}, {"text": "The two types of evaluation are done independently, but each evaluator did both evaluations (first that of fluency, then that of adequacy) fora certain number of segments.", "labels": [], "entities": []}, {"text": "For the evaluation of fluency, evaluators had to answer the question: \"Is the text written in good Spanish?\".", "labels": [], "entities": []}, {"text": "For the evaluation of adequacy, evaluators had to answer the question: \"How much of the meaning expressed in the reference translation is also expressed in the target translation?\".", "labels": [], "entities": []}, {"text": "For both evaluations, a five-point scale is proposed to the evaluators, where only extreme values are explicitly defined.", "labels": [], "entities": []}, {"text": "Three evaluations are carried out per segment, done by three different evaluators, and segments are divided randomly, because evaluators must not recreate a \"story\" and thus be influenced by the context.", "labels": [], "entities": []}, {"text": "The total number of judges was 10, with around 100 segments per judge.", "labels": [], "entities": []}, {"text": "Furthermore, the same number of judges was recruited for both categories: experts, from the domain with a knowledge of the technology, and non-experts, without that knowledge.", "labels": [], "entities": []}, {"text": "The End-to-End evaluation consists in comparing the speech in the source language to the output speech in the target language.", "labels": [], "entities": [{"text": "End-to-End", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.959962785243988}]}, {"text": "Two important aspects should betaken into account when assessing the quality of a speech-to-speech system.", "labels": [], "entities": []}, {"text": "First, the information preservation is measured by using \"comprehension questionnaires\".", "labels": [], "entities": [{"text": "information preservation", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.8249124586582184}]}, {"text": "Questions are created from the source texts (the English excerpts), then questions and answers are translated into Spanish by professional translators.", "labels": [], "entities": []}, {"text": "These questions are asked to human judges after they have listened to the output speech in the target language (Spanish).", "labels": [], "entities": []}, {"text": "At a second stage, the answers are analysed: for each answer a Spanish validator gives a score according to a binary scale (the information is either corrector incorrect).", "labels": [], "entities": []}, {"text": "This allows us to measure the information preservation.", "labels": [], "entities": [{"text": "information preservation", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.7758781611919403}]}, {"text": "Three types of questions are used in order to diversify the difficulty of the questions and test the system at different levels: simple Factual (70%), yes/no (20%) and list (10%) questions.", "labels": [], "entities": [{"text": "Factual", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.9164904952049255}]}, {"text": "For instance, questions were: What is the larynx responsible for?, Have all sites participating in CHIL built a CHIL room?, Which types of knowledge sources are used by the decoder?, respectively.", "labels": [], "entities": []}, {"text": "The second important aspect of a speech-tospeech system is the quality of the speech output (hereafter quality evaluation).", "labels": [], "entities": []}, {"text": "For assessing the quality of the speech output one question is asked to the judges at the end of each comprehension questionnaire: \"Rate the overall quality of this audio sample\", and values go from 1 (\"1: Very bad, unusable\") to 5 (\"It is very useful\").", "labels": [], "entities": []}, {"text": "Both automatic system and interpreter outputs were evaluated with the same methodology.", "labels": [], "entities": []}, {"text": "Human judges are real users and native Spanish speakers, experts and non-experts, but different from those of the SLT evaluation.", "labels": [], "entities": []}, {"text": "Twenty judges were involved (12 excerpts, 10 evaluations per excerpt and 6 evaluations per judge) and each judge evaluated both automatic and human excerpts on a 50/50 percent basis.", "labels": [], "entities": []}, {"text": "Each segment within the human evaluation is evaluated 4 times, each by a different judge.", "labels": [], "entities": []}, {"text": "This aims at having a significant number of judgments and measuring the consistency of the human evaluations.", "labels": [], "entities": [{"text": "consistency", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.9810488224029541}]}, {"text": "The consistency is measured by computing the Cohen's Kappa coefficient.", "labels": [], "entities": [{"text": "consistency", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9959307312965393}]}, {"text": "Results show a substantial agreement for fluency (kappa of 0.64) and a moderate agreement for adequacy (0.52).The overall results of the human evaluation are presented in  Both fluency and adequacy results are over the mean.", "labels": [], "entities": [{"text": "kappa", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9868319034576416}]}, {"text": "They are lower for experts than for nonexperts.", "labels": [], "entities": []}, {"text": "This maybe due to the fact that experts are more familiar with the domain and therefore more demanding than non experts.", "labels": [], "entities": []}, {"text": "Regarding the detailed evaluation per judge, scores are generally lower for non-experts than for experts.", "labels": [], "entities": []}, {"text": "Scores are computed using case-sensitive metrics.", "labels": [], "entities": []}, {"text": "Scores are rather low, with a mWER of 58.66%, meaning that more than half of the translation is correct.", "labels": [], "entities": [{"text": "mWER", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.909110963344574}]}, {"text": "According to the scoring, the T036 excerpts seem to be easier to translate than the L043 ones, the latter being of a more technical nature.", "labels": [], "entities": [{"text": "T036 excerpts", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.8898096084594727}]}, {"text": "T036 is more fluent due to the less technical nature of the speech and the more general vocabulary used.", "labels": [], "entities": [{"text": "T036", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8076085448265076}]}, {"text": "However, the T036-2 and T036-3 excerpts get a lower quality score, due to the description of data collections or institutions, and thus the use of named entities.", "labels": [], "entities": [{"text": "T036-2", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.9067004919052124}, {"text": "quality score", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9453160464763641}]}, {"text": "The interpreter does not seem to beat ease with them and is mispronouncing some of them, such as \"Grenoble\" pronounced like in English instead of in Spanish.", "labels": [], "entities": [{"text": "ease", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9319549798965454}]}, {"text": "The interpreter seems to be influenced by the speaker, as can also be seen in his use of the neologism \"el cenario\" (\"the scenario\") instead of \"el escenario\".", "labels": [], "entities": []}, {"text": "Likewise, \"Karlsruhe\" is pronounced three times differently, showing some inconsistency of the interpreter.", "labels": [], "entities": [{"text": "Karlsruhe", "start_pos": 11, "end_pos": 20, "type": "DATASET", "confidence": 0.91275954246521}]}, {"text": "The general trend in quality errors is similar to those of previous evaluations: lengthening words (\"seeee\u00f1ales\"), hesitations, pauses between syllables and catching breath (\"caracter\u00eds...ticas\"), careless mistakes (\"probibilidad\" instead of \"probabilidad\"), self-correction of wrong interpreting (\"reconocien-/reconocimiento\"), etc.", "labels": [], "entities": []}, {"text": "An important issue concerns gender and number agreement.", "labels": [], "entities": [{"text": "number agreement", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.6366912424564362}]}, {"text": "Those errors are explained by the presence of morphological gender in Spanish, like in \"estos se\u00f1ales\" instead of \"estas se\u00f1ales\" (\"these signals\") together with the speaker's speed of speech.", "labels": [], "entities": []}, {"text": "The speaker seems to start by default with a masculine determiner (which has no gender in English), adjusting the gender afterward depending on the noun following.", "labels": [], "entities": []}, {"text": "A quick translation may also be the cause for this kind of errors, like \"del se\u00f1al acustico\" (\"of the acoustic signal\") with a masculine determiner, a feminine substantive and ending in a masculine adjective.", "labels": [], "entities": []}, {"text": "Some translation errors are also present, for instance \"computerizar\" instead of \"calcular\" (\"compute\").", "labels": [], "entities": []}, {"text": "The errors made by the interpreter help to understand how difficult oral translation is.", "labels": [], "entities": [{"text": "oral translation", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.7281511127948761}]}, {"text": "This should betaken into account for the evaluation of the automatic system.", "labels": [], "entities": []}, {"text": "The automatic system results, like those of the interpreter, are higher for T036 than for L043.", "labels": [], "entities": []}, {"text": "However, scores are lower, especially for the L043-1 excerpt.", "labels": [], "entities": [{"text": "L043-1 excerpt", "start_pos": 46, "end_pos": 60, "type": "DATASET", "confidence": 0.8826388120651245}]}, {"text": "This seems to be due to the type of lexicon used by the speaker for this excerpt, more medical, since the speaker describes the articulatory system.", "labels": [], "entities": []}, {"text": "Moreover, his description is sometimes metaphorical and uses a rather colloquial register.", "labels": [], "entities": []}, {"text": "Therefore, while the interpreter finds it easier to deal with these excerpts (known vocabulary among others) and L043-3 seems to be more complicated (domain-specific, technical aspect), the automatic system finds it more complicated with the former and less with the latter.", "labels": [], "entities": []}, {"text": "In other words, the interpreter has to \"understand\" what is said in L043-3, contrary to the automatic system, in order to translate.", "labels": [], "entities": []}, {"text": "Scores are higher for the T036 excerpts.", "labels": [], "entities": [{"text": "T036 excerpts", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.9622787833213806}]}, {"text": "Indeed, there is a high lexical repetition, a large number of named entities, and the quality of the excerpt is very training-dependant.", "labels": [], "entities": [{"text": "repetition", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9430010318756104}]}, {"text": "However, the system runs into trouble to process foreign names, which are very often not understandable.", "labels": [], "entities": []}, {"text": "Differences between T036-1 and the other T036 excerpts are mainly due to the change in topic.", "labels": [], "entities": [{"text": "T036-1", "start_pos": 20, "end_pos": 26, "type": "DATASET", "confidence": 0.8708728551864624}]}, {"text": "While the former deals with a general vocabulary (i.e. description of projects), the other two excerpts describe the data collection, the evaluation metrics, etc., thus increasing the complexity of translation.", "labels": [], "entities": []}, {"text": "Generally speaking, quality scores of the automatic system are mainly due to the translation component, and to a lesser extent to the recognition component.", "labels": [], "entities": []}, {"text": "Many English words are not translated (\"bush\", \"keyboards\", \"squeaking\", etc.), and word ordering is not always correct.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 84, "end_pos": 97, "type": "TASK", "confidence": 0.7931977212429047}]}, {"text": "This is the case for the sentence \"how we solve it\", translated into \"c\u00f3mo nos resolvers lo\" instead of \"c\u00f3mo lo resolvemos\".", "labels": [], "entities": []}, {"text": "Funnily enough, the problems of gender (\"maravillosos aplicaciones\" -masc. vs fem.) and number (\"pueden realmente ser aplicado\" -plu. vs sing.) the interpreter has, are also found for the automatic system.", "labels": [], "entities": []}, {"text": "Moreover, the translation of compound nouns often shows wrong word ordering, in particular when they are long, i.e. up to three words (e.g. \"reconocimiento de habla sistemas\" for \"speech recognition system\" instead of \"sistemas de reconocimiento de habla\").", "labels": [], "entities": []}, {"text": "Finally, some error combinations result in fully non-understandable sentences, such as: \"usted tramo seen emacs es squeaking ruido y dries todos demencial\" where the following errors take place: \u2022 tramo: this translation of \"stretch\" results from the choice of a substantive instead of a verb, giving rise to two choices due to the lexical ambiguity: \"estiramiento\" and \"tramo\", which is more a linear distance than a stretch in that context; \u2022 se: the pronoun \"it\" becomes the reflexive \"se\" instead of the personal pronoun \"lo\"; \u2022 emacs: the recognition module transcribed the couple of words \"it makes\" into \"emacs\", not translated by the translation module; \u2022 squeaking: the word is not translated by the translation module; \u2022 dries: again, two successive errors are made: the word \"drives\" is transcribed into \"dries\" by the recognition module, which is then left untranslated.", "labels": [], "entities": []}, {"text": "The TTS component also contributes to decreasing the output quality.", "labels": [], "entities": [{"text": "TTS", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.4508010745048523}]}, {"text": "The prosody module finds it hard to make the sentences sound natural.", "labels": [], "entities": []}, {"text": "Pauses between words are not very frequent, but they do not sound natural (i.e. like catching breath) and they are not placed at specific points, as it would be done by a human.", "labels": [], "entities": []}, {"text": "For instance, the prosody module does not link the noun and its determiner (e.g. \"otros aplicaciones\").", "labels": [], "entities": []}, {"text": "Finally, a not userfriendly aspect of the TTS component is the repetition of the same words always pronounced in the same manner, what is quite disturbing for the listener.", "labels": [], "entities": [{"text": "TTS", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8494422435760498}]}, {"text": "Tables 5 and 6 present the results of the comprehension evaluation, for the interpreter and for the automatic system, respectively.", "labels": [], "entities": []}, {"text": "They provide the following information: identifiers of the excerpt: Source data are the same for the interpreter and the automatic system, namely the English speech; subj.", "labels": [], "entities": []}, {"text": "E2E: The subjective results of the end-toend evaluation are done by the same assessors who did the quality evaluation.", "labels": [], "entities": [{"text": "E2E", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6647433638572693}]}, {"text": "This shows the percentage of good answers; fair E2E: The objective verification of the answers.", "labels": [], "entities": [{"text": "fair E2E", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.8732689917087555}]}, {"text": "The audio files are validated to check whether they contain the answers to the questions or not (as the questions were created from the English source).", "labels": [], "entities": []}, {"text": "This shows the maximum percentage of answers an evaluator managed to find from either the interpreter (speaker audio) or the automatic system output (TTS) in Spanish.", "labels": [], "entities": []}, {"text": "For instance, information in English could have been missed by the interpreter because he/she felt that this information was meaningless and could be discarded.", "labels": [], "entities": []}, {"text": "We consider those results as an objective evaluation.", "labels": [], "entities": []}, {"text": "SLT, ASR: Verification of the answers in each component of the end-to-end process.", "labels": [], "entities": []}, {"text": "In order to determine where the information for the automatic system is lost, files from each component (recognised files for ASR, translated files for SLT, and synthesised files for TTS in the \"fair E2E\" column) are checked.", "labels": [], "entities": [{"text": "ASR", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.7007796764373779}]}, {"text": "E2E fair E2E: Comprehension evaluation results for the interpreter.", "labels": [], "entities": [{"text": "E2E", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.607729434967041}]}, {"text": "Regarding, the interpreter loses 15% of the information (i.e. 15% of the answers were incorrect or not present in the interpreter's translation) and judges correctly answered 74% of the questions.", "labels": [], "entities": []}, {"text": "Five documents get above 80% of correct results, while judges find almost above 70% of the answers for the six documents.", "labels": [], "entities": []}, {"text": "Regarding the automatic system results), the information rate found by judges is just above 50% since, by extension, more than half the questions were correctly answered.", "labels": [], "entities": [{"text": "information rate", "start_pos": 45, "end_pos": 61, "type": "METRIC", "confidence": 0.9820117950439453}]}, {"text": "The lowest excerpt, L043-1, gets a rate of 25%, the highest, T036-1, a rate of 76%, which is in agreement with the observation for the quality evaluation.", "labels": [], "entities": [{"text": "T036-1", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.8172085881233215}]}, {"text": "Information loss can be found in each component, especially for the SLT module (35% of the information is lost here).", "labels": [], "entities": [{"text": "SLT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9141951203346252}]}, {"text": "It should be noticed that the TTS module made also errors which prevented judges Excerpts subj.", "labels": [], "entities": [{"text": "TTS module", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.8526982963085175}]}, {"text": "E2E fair E2E SLT ASR: Comprehension evaluation results for the automatic system. from answering related questions.", "labels": [], "entities": [{"text": "E2E SLT ASR", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.5298485358556112}]}, {"text": "Moreover, the ASR module loses 17% of the information.", "labels": [], "entities": [{"text": "ASR", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8348014950752258}]}, {"text": "Those results are certainly due to the specific vocabulary used in this experiment.", "labels": [], "entities": []}, {"text": "So as to objectively compare the interpreter with the automatic system, we selected the questions for which the answers were included in the interpreter files (i.e. those in the \"fair E2E\" column of).", "labels": [], "entities": []}, {"text": "The goal was to compare the overall quality of the speech-to-speech translation to interpreters' quality, without the noise factor of the information missing.", "labels": [], "entities": []}, {"text": "The assumption is that the interpreter translates the \"important information\" and skips the useless parts of the original speech.", "labels": [], "entities": []}, {"text": "This experiment is to measure the level of this information that is preserved by the automatic system.", "labels": [], "entities": []}, {"text": "So anew subset of results was obtained, on the information kept by the interpreter.", "labels": [], "entities": []}, {"text": "The same study was repeated for the three components and the results are shown in Excerpts subj.", "labels": [], "entities": [{"text": "Excerpts subj", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.9249208569526672}]}, {"text": "E2E fair E2E SLT ASR: Evaluation results for the automatic system restricted to the questions for which answers can be found in the interpreter speech.", "labels": [], "entities": [{"text": "E2E", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8263995051383972}, {"text": "E2E SLT ASR", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.47209147612253827}]}, {"text": "Comparing the automatic system to the interpreter, the automatic system keeps 40% of the information where the interpreter translates the documents correctly.", "labels": [], "entities": []}, {"text": "Those results confirm that ASR loses a lot of information (20%), while SLT loses 10% further, and so does the TTS.", "labels": [], "entities": [{"text": "ASR", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.8594902753829956}, {"text": "SLT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.4201470911502838}, {"text": "TTS", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.4030918776988983}]}, {"text": "Judges are quite close to the objective validation and found most of the answers they could possibly do.", "labels": [], "entities": []}, {"text": "E2E 76 Mean 80: Evaluation results for interpreter, restricted to the questions for which answers can be found in the interpreter speech.", "labels": [], "entities": [{"text": "E2E 76", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9326523542404175}, {"text": "Mean 80", "start_pos": 7, "end_pos": 14, "type": "METRIC", "confidence": 0.5488932430744171}]}, {"text": "Subjective results for the restricted evaluation are similar to the previous results, on the full data (80% vs 74% of the information found by the judges).", "labels": [], "entities": []}, {"text": "Performance is good for the interpreter: 98% of the information correctly translated by the automatic system is also correctly interpreted by the human.", "labels": [], "entities": []}, {"text": "Although we cannot compare the performance of the restricted automatic system to that of the restricted interpreter (since data sets of questions are different), it seems that of the interpreter is better.", "labels": [], "entities": []}, {"text": "However, the loss due to subjective evaluation seems to be higher for the interpreter than for the automatic system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Regard- ing both experts' and non-experts' details, agree- ment is very similar (0.30 and 0.28, respectively).", "labels": [], "entities": [{"text": "agree- ment", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.9645412365595499}]}, {"text": " Table 2: Average rating of human evalua- tions [1<5].", "labels": [], "entities": [{"text": "Average rating", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9531275629997253}]}, {"text": " Table 3: Automatic Evaluation results for SLT.", "labels": [], "entities": [{"text": "SLT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9831605553627014}]}, {"text": " Table 4: Quality evaluation results for the inter- preter and the automatic system [1<5].", "labels": [], "entities": []}, {"text": " Table 5: Comprehension evaluation results for the  interpreter", "labels": [], "entities": []}, {"text": " Table 6: Comprehension evaluation results for the  automatic system", "labels": [], "entities": []}, {"text": " Table 7: Evaluation results for the automatic sys- tem restricted to the questions for which answers  can be found in the interpreter speech", "labels": [], "entities": []}]}