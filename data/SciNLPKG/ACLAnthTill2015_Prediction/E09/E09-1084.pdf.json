{"title": [{"text": "Using Non-lexical Features to Identify Effective Indexing Terms for Biomedical Illustrations", "labels": [], "entities": [{"text": "Identify Effective Indexing Terms", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.8839410096406937}]}], "abstractContent": [{"text": "Automatic image annotation is an attractive approach for enabling convenient access to images found in a variety of documents.", "labels": [], "entities": [{"text": "Automatic image annotation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6176866888999939}]}, {"text": "Since image captions and relevant discussions found in the text can be useful for summarizing the content of images, it is also possible that this text can be used to generate salient indexing terms.", "labels": [], "entities": [{"text": "image captions", "start_pos": 6, "end_pos": 20, "type": "TASK", "confidence": 0.7333631217479706}, {"text": "summarizing", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.9783754944801331}]}, {"text": "Unfortunately , this problem is generally domain-specific because indexing terms that are useful in one domain can be ineffective in others.", "labels": [], "entities": []}, {"text": "Thus, we present a supervised machine learning approach to image annotation utilizing non-lexical features 1 extracted from image-related text to select useful terms.", "labels": [], "entities": [{"text": "image annotation", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7246649265289307}]}, {"text": "We apply this approach to several subdomains of the biomedical sciences and show that we are able to reduce the number of ineffective indexing terms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Authors of biomedical publications often utilize images and other illustrations to convey information essential to the article and to support and reinforce textual content.", "labels": [], "entities": []}, {"text": "These images are useful in support of clinical decisions, in rich document summaries, and for instructional purposes.", "labels": [], "entities": []}, {"text": "The task of delivering these images, and the publications in which they are contained, to biomedical clinicians and researchers in an accessible way is an information retrieval problem.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 155, "end_pos": 176, "type": "TASK", "confidence": 0.745269775390625}]}, {"text": "Current research in the biomedical domain (e.g.,, has investigated hybrid approaches to image retrieval, combining elements of content-based image retrieval (CBIR) and annotation-based image retrieval (ABIR).", "labels": [], "entities": [{"text": "image retrieval", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.7288621068000793}, {"text": "annotation-based image retrieval (ABIR)", "start_pos": 168, "end_pos": 207, "type": "TASK", "confidence": 0.6718525091807047}]}, {"text": "ABIR, compared to the image-only approach of CBIR, offers a practical advantage in that queries can be more naturally specified by a human user).", "labels": [], "entities": [{"text": "ABIR", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.537555456161499}]}, {"text": "However, manually annotating biomedical images is a laborious and subjective task that often leads to noisy results.", "labels": [], "entities": []}, {"text": "Automatic image annotation is a more robust approach to ABIR than manual annotation.", "labels": [], "entities": [{"text": "Automatic image annotation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6400141616662344}, {"text": "ABIR", "start_pos": 56, "end_pos": 60, "type": "TASK", "confidence": 0.7414434552192688}]}, {"text": "Unfortunately, automatically selecting the most appropriate indexing terms is an especially challenging problem for biomedical images because of the domain-specific nature of these images and the many vocabularies used in the biomedical sciences.", "labels": [], "entities": []}, {"text": "For example, the term \"sweat gland adenocarcinoma\" could be a useful indexing term for an image found in a dermatology publication, but it is less likely to have much relevance in describing an image from a cardiology publication.", "labels": [], "entities": []}, {"text": "On the other hand, the term \"mitral annular calcification\" maybe of great relevance for cardiology images, but of little relevance for dermatology ones.", "labels": [], "entities": []}, {"text": "Our problem maybe summarized as follows: Given an image, its caption, its discussion in the article text (henceforth the image mention), and a list of potential indexing terms, select the terms that are most effective at describing the content of the image.", "labels": [], "entities": []}, {"text": "For example, assume the image shown in, obtained from the article \"Metastatic Hidradenocarcinoma: Efficacy of Capecitabine\" by in Archives of Dermatology, has the following potential indexing terms, which have been extracted from the image mention.", "labels": [], "entities": [{"text": "Efficacy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9575859308242798}]}, {"text": "While most of these do not uniquely identify Caption:.", "labels": [], "entities": [{"text": "Caption", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9473859667778015}]}, {"text": "On recurrence, histologic features of porocarcinoma with an intraepidermal spread of neoplastic clusters (hematoxylin-eosin, original magnification x100).", "labels": [], "entities": []}, {"text": "Mention: Histopathologic findings were reviewed and confirmed a diagnosis of eccrine hidradenocarcinoma for all lesions excised).", "labels": [], "entities": [{"text": "Histopathologic", "start_pos": 9, "end_pos": 24, "type": "METRIC", "confidence": 0.9610744714736938}]}, {"text": "Figure 1: Example Image.", "labels": [], "entities": []}, {"text": "We index an image with concepts generated from its caption and discussion in the document text (mention).", "labels": [], "entities": []}, {"text": "This image is from \"Metastatic Hidradenocarcinoma: Efficacy of Capecitabine\" by and is reprinted with permission from the authors.", "labels": [], "entities": [{"text": "Efficacy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9448073506355286}]}, {"text": "the image, we would like to automatically select \"sweat gland adenocarcinoma\" and \"eccrine\" for indexing because they clearly describe the content and purpose of the image-supporting a diagnosis of hidradenocarinoma, an invasive cancer of sweat glands.", "labels": [], "entities": []}, {"text": "Note that effective indexing terms need not be exact lexical matches of the text.", "labels": [], "entities": []}, {"text": "Even though \"diagnosis\" is an exact match, its meaning is too broad in this context to be a useful term.", "labels": [], "entities": [{"text": "diagnosis\"", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.931063324213028}]}, {"text": "Ina machine learning approach to image annotation, training data based on lexical features alone is not sufficient for finding salient indexing terms.", "labels": [], "entities": [{"text": "image annotation", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7127249836921692}]}, {"text": "Indeed, we must classify terms that are not encountered while training.", "labels": [], "entities": []}, {"text": "Therefore, we hypothesize that non-lexical features, which have been successfully used for speech and genre classification tasks, among others (see Section 5 for related work), maybe useful in classifying text associated with images.", "labels": [], "entities": [{"text": "speech and genre classification tasks", "start_pos": 91, "end_pos": 128, "type": "TASK", "confidence": 0.7190413892269134}, {"text": "classifying text associated with images", "start_pos": 193, "end_pos": 232, "type": "TASK", "confidence": 0.8566789507865906}]}, {"text": "While this approach is broad enough to apply to any retrieval task, given the goals of our ongoing research, we restrict ourselves to studying its feasibility in the biomedical domain.", "labels": [], "entities": []}, {"text": "In order to achieve this, we make use of the previously developed tool, which maps text to concepts contained in the Unified Medical Language System R (UMLS) Metathesaurus R ().", "labels": [], "entities": [{"text": "Unified Medical Language System R (UMLS) Metathesaurus R", "start_pos": 117, "end_pos": 173, "type": "DATASET", "confidence": 0.5359793931245804}]}, {"text": "The UMLS is a compendium of several controlled vocabularies in the biomedical sciences that provides a semantic mapping relating concepts from the various vocabularies (Section 2).", "labels": [], "entities": [{"text": "UMLS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8732739686965942}]}, {"text": "We then use a supervised machine learning approach, described in Section 3, to classify the UMLS concepts as useful indexing terms based on their non-lexical features, gleaned from the article text and MetaMap output.", "labels": [], "entities": []}, {"text": "Experimental results, presented in Section 4, indicate that ineffective indexing terms can be reduced using this classification technique.", "labels": [], "entities": []}, {"text": "We conclude that ABIR approaches to biomedical image retrieval as well as hybrid CBIR/ABIR approaches, which rely on both image content and annotations, can benefit from an automatic annotation process utilizing non-lexical features to aid in the selection of useful indexing terms.", "labels": [], "entities": [{"text": "biomedical image retrieval", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6473386685053507}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Al- though both reviewers are physicians trained in  medical informatics, their initial agreement is only  moderate, with \u03ba = 0.519. This illustrates the  subjective nature of manual ABIR and, in general,  the difficultly in reliably classifying potential in- dexing terms for biomedical images.", "labels": [], "entities": [{"text": "ABIR", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.5802091956138611}]}, {"text": " Table 1: Inter-annotator Agreement. The prob- ability of agreement Pr(a), expected probability of  chance agreement Pr(e), and the associated Co- hen's kappa coefficient \u03ba are given for each re- viewer combination.", "labels": [], "entities": [{"text": "prob- ability of agreement Pr(a)", "start_pos": 41, "end_pos": 73, "type": "METRIC", "confidence": 0.8627752264340719}, {"text": "expected probability of  chance agreement Pr(e)", "start_pos": 75, "end_pos": 122, "type": "METRIC", "confidence": 0.8281632529364692}]}, {"text": " Table 2: Feature Comparison. The information  gain and chi-square statistic is shown for each fea- ture. A higher score indicates greater influence on  term effectiveness.", "labels": [], "entities": [{"text": "information  gain", "start_pos": 34, "end_pos": 51, "type": "METRIC", "confidence": 0.8906773924827576}]}, {"text": " Table 3: Classification Results. The classifier's  precision and recall, as well as the corresponding  F 1 -score, are given for the responses of each re- viewer.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9988141059875488}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9988322854042053}, {"text": "F 1 -score", "start_pos": 104, "end_pos": 114, "type": "METRIC", "confidence": 0.9892504811286926}]}]}