{"title": [{"text": "Syntactic and Semantic Kernels for Short Text Pair Categorization", "labels": [], "entities": []}], "abstractContent": [{"text": "Automatic detection of general relations between short texts is a complex task that cannot be carried out only relying on language models and bag-of-words.", "labels": [], "entities": [{"text": "Automatic detection of general relations between short texts", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.8523853942751884}]}, {"text": "Therefore , learning methods to exploit syntax and semantics are required.", "labels": [], "entities": []}, {"text": "In this paper , we present anew kernel for the representation of shallow semantic information along with a comprehensive study on kernel methods for the exploitation of syntac-tic/semantic structures for short text pair categorization.", "labels": [], "entities": [{"text": "short text pair categorization", "start_pos": 204, "end_pos": 234, "type": "TASK", "confidence": 0.6394895017147064}]}, {"text": "Our experiments with Support Vector Machines on question/answer classification show that our kernels can be used to greatly improve system accuracy.", "labels": [], "entities": [{"text": "question/answer classification", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.7391046583652496}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9795145988464355}]}], "introductionContent": [{"text": "Previous work on Text Categorization (TC) has shown that advanced linguistic processing for document representation is often ineffective for this task, e.g.).", "labels": [], "entities": [{"text": "Text Categorization (TC)", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.8522535383701324}, {"text": "document representation", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.7133679091930389}]}, {"text": "In contrast, work in question answering suggests that syntactic and semantic structures help in solving TC).", "labels": [], "entities": [{"text": "question answering", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8285487592220306}, {"text": "solving TC", "start_pos": 96, "end_pos": 106, "type": "TASK", "confidence": 0.637885332107544}]}, {"text": "From these studies, it emerges that when the categorization task is linguistically complex, syntax and semantics may play a relevant role.", "labels": [], "entities": []}, {"text": "In this perspective, the study of the automatic detection of relationships between short texts is particularly interesting.", "labels": [], "entities": [{"text": "automatic detection of relationships between short texts", "start_pos": 38, "end_pos": 94, "type": "TASK", "confidence": 0.8485686779022217}]}, {"text": "Typical examples of such relations are given in ( or those holding between question and answer, e.g. (, i.e. if a text fragment correctly responds to a question.", "labels": [], "entities": []}, {"text": "In Question Answering, the latter problem is mostly tackled by using different heuristics and classifiers, which aim at extracting the best answers ().", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7872366309165955}]}, {"text": "However, for definitional questions, a more effective approach would be to test if a correct relationship between the answer and the query holds.", "labels": [], "entities": []}, {"text": "This, in turns, depends on the structure of the two text fragments.", "labels": [], "entities": []}, {"text": "Designing language models to capture such relation is too complex since probabilistic models suffer from (i) computational complexity issues, e.g. for the processing of large bayesian networks, (ii) problems in effectively estimating and smoothing probabilities and (iii) high sensitiveness to irrelevant features and processing errors.", "labels": [], "entities": []}, {"text": "In contrast, discriminative models such as Support Vector Machines (SVMs) have theoretically been shown to be robust to noise and irrelevant features.", "labels": [], "entities": []}, {"text": "Thus, partially correct linguistic structures may still provide a relevant contribution since only the relevant information would betaken into account.", "labels": [], "entities": []}, {"text": "Moreover, such a learning approach supports the use of kernel methods which allow for an efficient and effective representation of structured data.", "labels": [], "entities": []}, {"text": "SVMs and Kernel Methods have recently been applied to natural language tasks with promising results, e.g. (;).", "labels": [], "entities": []}, {"text": "In particular, in question classification, tree kernels, e.g. (, have shown accuracy comparable to the best models, e.g. ().", "labels": [], "entities": [{"text": "question classification", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.8402597308158875}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9992604851722717}]}, {"text": "Moreover, have shown that shallow semantic information in the form of Predicate Argument Structures (PASs)) improves the automatic detection of correct answers to a target question.", "labels": [], "entities": [{"text": "automatic detection of correct answers to a target question", "start_pos": 121, "end_pos": 180, "type": "TASK", "confidence": 0.8015750116772122}]}, {"text": "In particular, in ) kernels for the processing of PASs (in PropBank 1 format) extracted from question/answer pairs were proposed.", "labels": [], "entities": []}, {"text": "However, the relatively high kernel computational complexity and the limited improvement on bag-of-words (BOW) produced by this approach do not make the use of such technique practical for real world applications.", "labels": [], "entities": []}, {"text": "In this paper, we carryout a complete study on the use of syntactic/semantic structures for relational learning from questions and answers.", "labels": [], "entities": [{"text": "relational learning from questions and answers", "start_pos": 92, "end_pos": 138, "type": "TASK", "confidence": 0.8578788340091705}]}, {"text": "We designed sequence kernels for words and Part of Speech Tags which capture basic lexical semantics and basic syntactic information.", "labels": [], "entities": []}, {"text": "Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in ( . The extensive experiments carried out on two different corpora of questions and answers, derived from Web documents and the TREC corpus, show that: \u2022 Kernels based on PAS, POS-tag sequences and syntactic parse trees improve the BOW approach on both datasets.", "labels": [], "entities": [{"text": "TREC corpus", "start_pos": 252, "end_pos": 263, "type": "DATASET", "confidence": 0.8806960880756378}, {"text": "BOW", "start_pos": 356, "end_pos": 359, "type": "METRIC", "confidence": 0.7674692869186401}]}, {"text": "On the TREC data the improvement is interestingly high, e.g. about 61%, making its application worthwhile.", "labels": [], "entities": [{"text": "TREC data", "start_pos": 7, "end_pos": 16, "type": "DATASET", "confidence": 0.758916050195694}]}, {"text": "\u2022 The new kernel for processing PASs is more efficient and effective than previous models so that it can be practically used in systems for short text pair categorization, e.g. question/answer classification.", "labels": [], "entities": [{"text": "short text pair categorization", "start_pos": 140, "end_pos": 170, "type": "TASK", "confidence": 0.6223669201135635}, {"text": "question/answer classification", "start_pos": 177, "end_pos": 207, "type": "TASK", "confidence": 0.7478248775005341}]}, {"text": "In the remainder of this paper, Section 2 presents well-known kernel functions for structural information whereas Section 3 describes our new shallow semantic kernel.", "labels": [], "entities": []}, {"text": "Section 4 reports on our experiments with the above models and, finally, a conclusion is drawn in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments aim at studying the impact of our kernels applied to syntactic/semantic structures for the detection of relations between short texts.", "labels": [], "entities": [{"text": "detection of relations between short texts", "start_pos": 107, "end_pos": 149, "type": "TASK", "confidence": 0.8296375771363577}]}, {"text": "In particular, we first show that our SRK is far more efficient and effective than SSTK.", "labels": [], "entities": [{"text": "SRK", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.6612058877944946}]}, {"text": "Then, we study the impact of the above kernels as well as sequence kernels based on words and Part of Speech Tags and tree kernels for the classification of question/answer text pairs.", "labels": [], "entities": [{"text": "classification of question/answer text pairs", "start_pos": 139, "end_pos": 183, "type": "TASK", "confidence": 0.6656148859432766}]}, {"text": "The task used to test our kernels is the classification of the correctness of \ud97b\udf59q, a\ud97b\udf59 pairs, where a is an answer for the query q.", "labels": [], "entities": []}, {"text": "The text pair kernel operates by comparing the content of questions and the content of answers in a separate fashion.", "labels": [], "entities": []}, {"text": "Thus, given two pairs p 1 = \ud97b\udf59q 1 , a 1 \ud97b\udf59 and p 2 = \ud97b\udf59q 2 , a 2 \ud97b\udf59, a kernel function is defined as ), where \u03c4 varies across different kernel functions described hereafter.", "labels": [], "entities": []}, {"text": "As a basic kernel machine, we used our SVM-Light-TK toolkit, available at disi.unitn.", "labels": [], "entities": []}, {"text": "it/moschitti (which is based on SVM-Light (Joachims, 1999) software).", "labels": [], "entities": [{"text": "SVM-Light (Joachims, 1999)", "start_pos": 32, "end_pos": 58, "type": "DATASET", "confidence": 0.8482589522997538}]}, {"text": "In it, we implemented: the String Kernel (SK), the Syntactic Tree Kernel (STK), the Shallow Semantic Tree Kernel (SSTK) and the Semantic Role Kernel (SRK) described in sections 2 and 3.", "labels": [], "entities": []}, {"text": "Each kernel is associated with the above linguistic objects: (i) the linear kernel is used with the bag-of-words (BOW) or the bag-of-POS-tags (POS) features.", "labels": [], "entities": []}, {"text": "(ii) SK is used with word sequences (i.e. the Word Sequence Kernel, WSK) and POS sequences (i.e. the POS Sequence Kernel, PSK).", "labels": [], "entities": []}, {"text": "(iii) STK is used with syntactic parse trees automatically derived with Charniak's parser; (iv) SSTK and SRK are applied to two different PAS trees (see Section 3.1), automatically derived with our SRL system.", "labels": [], "entities": []}, {"text": "It is worth noting that, since answers often con- Figure 5: Efficiency of SRK and SSTK tain more than one PAS, we applied SRK or SSTK to all pairs P 1 \u00d7 P 2 and sum the obtained contribution, where P 1 and P 2 are the set of PASs of the first and second answer . Although different kernels can be used for questions and for answers, we used (and summed together) the same kernels except for those based on PASs, which are only used on answers.", "labels": [], "entities": []}, {"text": "To train and test our text QA classifiers, we adopted the two datasets of question/answer pairs available at disi.unitn.it/ \u02dc silviaq, containing answers to only definitional questions.", "labels": [], "entities": []}, {"text": "The datasets are based on the 138 TREC 2001 test questions labeled as \"description\" in ().", "labels": [], "entities": [{"text": "TREC 2001 test questions", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.8980178385972977}]}, {"text": "Each question is paired with all the top 20 answer paragraphs extracted by two basic QA systems: one trained with the web documents and the other trained with the AQUAINT data used in TREC'07.", "labels": [], "entities": [{"text": "AQUAINT data", "start_pos": 163, "end_pos": 175, "type": "DATASET", "confidence": 0.7419416904449463}, {"text": "TREC'07", "start_pos": 184, "end_pos": 191, "type": "DATASET", "confidence": 0.650992751121521}]}, {"text": "The WEB corpus ( ) of QA pairs contains 1,309 sentences, 416 of which are positive 4 answers whereas the TREC corpus contains 2,256 sentences, 261 of which are positive.", "labels": [], "entities": [{"text": "WEB corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.847966730594635}, {"text": "TREC corpus", "start_pos": 105, "end_pos": 116, "type": "DATASET", "confidence": 0.9200486242771149}]}], "tableCaptions": [{"text": " Table 1: F1 \u00b1 Std. Dev. of the question/answer classifier according to several kernels on the WEB and  TREC corpora.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9985492825508118}, {"text": "WEB and  TREC corpora", "start_pos": 95, "end_pos": 116, "type": "DATASET", "confidence": 0.7559269666671753}]}]}