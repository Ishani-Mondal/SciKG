{"title": [{"text": "A Generalized Vector Space Model for Text Retrieval Based on Semantic Relatedness", "labels": [], "entities": [{"text": "Text Retrieval", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7964250445365906}]}], "abstractContent": [{"text": "Generalized Vector Space Models (GVSM) extend the standard Vector Space Model (VSM) by embedding additional types of information, besides terms, in the representation of documents.", "labels": [], "entities": []}, {"text": "An interesting type of information that can be used in such models is semantic information from word thesauri like WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 115, "end_pos": 122, "type": "DATASET", "confidence": 0.9648845791816711}]}, {"text": "Previous attempts to construct GVSM reported contradicting results.", "labels": [], "entities": []}, {"text": "The most challenging problem is to incorporate the semantic information in a theoretically sound and rigorous manner and to modify the standard interpretation of the VSM.", "labels": [], "entities": [{"text": "VSM", "start_pos": 166, "end_pos": 169, "type": "DATASET", "confidence": 0.7435163259506226}]}, {"text": "In this paper we present anew GVSM model that exploits WordNet's semantic information.", "labels": [], "entities": []}, {"text": "The model is based on anew measure of semantic relatedness between terms.", "labels": [], "entities": []}, {"text": "Experimental study conducted in three TREC collections reveals that semantic information can boost text retrieval performance with the use of the proposed GVSM.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.7640030980110168}, {"text": "text retrieval", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.7810285985469818}, {"text": "GVSM", "start_pos": 155, "end_pos": 159, "type": "DATASET", "confidence": 0.9105128645896912}]}], "introductionContent": [{"text": "The use of semantic information into text retrieval or text classification has been controversial.", "labels": [], "entities": [{"text": "text retrieval", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7740910351276398}, {"text": "text classification", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.750263124704361}]}, {"text": "For example in it was shown that a GVSM using WordNet senses and their hypernyms, improves text classification performance, especially for small training sets.", "labels": [], "entities": [{"text": "text classification", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.83148193359375}]}, {"text": "In contrast, reported that even 90% accurate WSD cannot guarantee retrieval improvement, though their experimental methodology was based only on randomly generated pseudowords of varying sizes.", "labels": [], "entities": [{"text": "WSD", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.7753853797912598}]}, {"text": "Similarly, Voorhees (1993) reported a drop in retrieval performance when the retrieval model was based on WSD information.", "labels": [], "entities": []}, {"text": "On the contrary, the construction of a sense-based retrieval model by improved performance, while several years before, had already pointed out that resolving word senses can improve searches requiring high levels of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 217, "end_pos": 223, "type": "METRIC", "confidence": 0.9782605767250061}]}, {"text": "In this work, we argue that the incorporation of semantic information into a GVSM retrieval model can improve performance by considering the semantic relatedness between the query and document terms.", "labels": [], "entities": []}, {"text": "The proposed model extends the traditional VSM with term to term relatedness measured with the use of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.9663978815078735}]}, {"text": "The success of the method lies in three important factors, which also constitute the points of our contribution: 1) anew measure for computing semantic relatedness between terms which takes into account relation weights, and senses' depth; 2) anew GVSM retrieval model, which incorporates the aforementioned semantic relatedness measure; 3) exploitation of all the semantic information a thesaurus can offer, including semantic relations crossing parts of speech (POS).", "labels": [], "entities": []}, {"text": "Experimental evaluation in three TREC collections shows that the proposed model can improve in certain cases the performance of the standard TF-IDF VSM.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.80611851811409}, {"text": "TF-IDF VSM", "start_pos": 141, "end_pos": 151, "type": "DATASET", "confidence": 0.6539760231971741}]}, {"text": "The rest of the paper is organized as follows: Section 2 presents preliminary concepts, regarding VSM and GVSM.", "labels": [], "entities": [{"text": "VSM", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.8012384176254272}, {"text": "GVSM", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.429353803396225}]}, {"text": "Section 3 presents the term semantic relatedness measure and the proposed GVSM.", "labels": [], "entities": [{"text": "GVSM", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8576431274414062}]}, {"text": "Section 4 analyzes the experimental results, and Section 5 concludes and gives pointers to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental evaluation in this work is twofold.", "labels": [], "entities": []}, {"text": "First, we test the performance of the semantic relatedness measure (SR) fora pair of words in three benchmark data sets, namely the Rubenstein and Goodenough 65 word pairs)(R&G), the Miller and Charles 30 word pairs)(M&C), and the 353 similarity data set ().", "labels": [], "entities": [{"text": "semantic relatedness measure (SR)", "start_pos": 38, "end_pos": 71, "type": "METRIC", "confidence": 0.7030699054400126}, {"text": "353 similarity data set", "start_pos": 231, "end_pos": 254, "type": "DATASET", "confidence": 0.7617659121751785}]}, {"text": "Second, we evaluate the performance of the proposed GVSM in three TREC collections (TREC 1, 4 and 6).", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.7494855225086212}]}, {"text": "For the evaluation of the proposed semantic relatedness measure between two terms we experimented in three widely used data sets in which human subjects have provided scores of relatedness for each pair.", "labels": [], "entities": []}, {"text": "A kind of \"gold standard\" ranking of related word pairs (i.e., from the most related words to the most irrelevant) has thus been created, against which computer programs can test their ability on measuring semantic relatedness between words.", "labels": [], "entities": []}, {"text": "We compared our measure against ten known measures of semantic relatedness: (HS) Hirst and St-Onge (1998), (JC), (LC), (L) Lin (1998), (R) Resnik (1995), (JS) Jarmasz and Szpakowicz, (GM), (F), (HR) ) and (SP).", "labels": [], "entities": [{"text": "semantic relatedness", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.6902288943529129}]}, {"text": "In the results of SR and the ten compared measures are shown.", "labels": [], "entities": [{"text": "SR", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9463310837745667}]}, {"text": "The reported numbers are the Spearman correlation of the measures' rankings with the gold standard (human judgements).", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 29, "end_pos": 49, "type": "METRIC", "confidence": 0.6668941825628281}]}, {"text": "The correlations for the three data sets show that SR performs better than any other measure of semantic relatedness, besides the case of (HR) in the M&C data set.", "labels": [], "entities": [{"text": "SR", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.935247004032135}, {"text": "M&C data set", "start_pos": 150, "end_pos": 162, "type": "DATASET", "confidence": 0.8025659084320068}]}, {"text": "It surpasses HR though in the R&G and the 353-C data set.", "labels": [], "entities": [{"text": "R&G and the 353-C data set", "start_pos": 30, "end_pos": 56, "type": "DATASET", "confidence": 0.7928159534931183}]}, {"text": "The latter contains the word pairs of the M&C data set.", "labels": [], "entities": [{"text": "M&C data set", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.7883620500564575}]}, {"text": "To visualize the performance of our measure in a more comprehensible manner, presents for all pairs in the R&G data set, and with increasing order of relatedness values based on human judgements, the respective values of these pairs that SR produces.", "labels": [], "entities": [{"text": "R&G data set", "start_pos": 107, "end_pos": 119, "type": "DATASET", "confidence": 0.6220152378082275}]}, {"text": "A closer look on reveals that the values produced by SR (right follow a pattern similar to that of the human ratings (left.", "labels": [], "entities": []}, {"text": "Note that the x-axis in both charts begins from the least related pair of terms, according to humans, and goes up to the most related pair of terms.", "labels": [], "entities": []}, {"text": "The y-axis in the left chart is the respective humans' rating for each pair of terms.", "labels": [], "entities": []}, {"text": "The right figure shows SR for each pair.", "labels": [], "entities": [{"text": "SR", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9963544607162476}]}, {"text": "The reader can consult to confirm that all the other measures of semantic relatedness we compare to, do not follow the same pattern as the human ratings, as closely as our measure of relatedness does (low y values for small x values and high y values for high x).", "labels": [], "entities": []}, {"text": "The same pattern applies in the M&C and 353-C data sets.", "labels": [], "entities": [{"text": "M&C and 353-C data sets", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.9132183109010968}]}, {"text": "For the evaluation of the proposed GVSM model, we have experimented with three TREC collections 3 , namely TREC 1 (TIPSTER disks 1 and 2), TREC 4 (TIPSTER disks 2 and 3) and TREC 6 (TIPSTER disks 4 and 5).", "labels": [], "entities": [{"text": "TREC", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9283657670021057}]}, {"text": "We selected those TREC collections in order to cover as many different thematic subjects as possible.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 18, "end_pos": 34, "type": "DATASET", "confidence": 0.8103455305099487}]}, {"text": "For example, TREC 1 contains documents from the Wall Street Journal, Associated Press, Federal Register, and abstracts of U.S. department of energy.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 48, "end_pos": 67, "type": "DATASET", "confidence": 0.8851723074913025}, {"text": "Federal Register", "start_pos": 87, "end_pos": 103, "type": "DATASET", "confidence": 0.9576626121997833}]}, {"text": "TREC 6 differs from TREC 1, since it has documents from Financial Times, Los Angeles Times and the Foreign Broadcast Information Service.", "labels": [], "entities": [{"text": "TREC 6", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8686056733131409}, {"text": "Financial Times", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9266674816608429}, {"text": "Foreign Broadcast Information Service", "start_pos": 99, "end_pos": 136, "type": "DATASET", "confidence": 0.8775055557489395}]}, {"text": "For each TREC, we executed the standard base-, the differences in interpolated precision for the same recall levels are depicted.", "labels": [], "entities": [{"text": "TREC", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.7011820673942566}, {"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.7393910884857178}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9922870397567749}]}, {"text": "For reasons of simplicity, we have excluded the recall values in the right graphs, above which, both systems had zero precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9989185333251953}, {"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9978602528572083}]}, {"text": "Thus, for TREC 1 in the y-axis we have depicted the difference in the interpolated precision values (%) of the GVSM from the VSM, for the first 4 recall points.", "labels": [], "entities": [{"text": "TREC", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9164317846298218}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.6045207977294922}, {"text": "GVSM", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.4949948787689209}, {"text": "VSM", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.7915342450141907}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9923720359802246}]}, {"text": "For TRECs 4 and 6 we have done the same for the first 9 and 8 recall points respectively.", "labels": [], "entities": [{"text": "TRECs", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.6360726952552795}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9929670095443726}]}, {"text": "As shown in, the proposed GVSM may improve the performance of the TFIDF VSM up to 1.93% in TREC 4, 0.99% in TREC 6 and 0.42% in TREC 1.", "labels": [], "entities": [{"text": "GVSM", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.8529415130615234}, {"text": "TFIDF VSM", "start_pos": 66, "end_pos": 75, "type": "DATASET", "confidence": 0.6420394778251648}]}, {"text": "This small boost in performance proves that the proposed GVSM model is promising.", "labels": [], "entities": []}, {"text": "There are many aspects though in the GVSM that we think require further investigation, like for example the fact that we have not conducted WSD so as to map each document and query term occurrence into its correct sense, or the fact that the weighting scheme of the edges used in SR generates from the distribution of each edge type in WordNet, while there might be other more sophisticated ways to compute edge weights.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 336, "end_pos": 343, "type": "DATASET", "confidence": 0.9534894824028015}]}, {"text": "We believe that if these, but also more aspects discussed in the next section, are tackled, the proposed GVSM may improve more the retrieval performance.", "labels": [], "entities": [{"text": "GVSM", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.6866312623023987}]}], "tableCaptions": [{"text": " Table 1: Correlations of semantic relatedness measures with human judgements.", "labels": [], "entities": []}]}