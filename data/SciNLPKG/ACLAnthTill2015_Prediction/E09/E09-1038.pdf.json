{"title": [{"text": "Enhancing Unlexicalized Parsing Performance using a Wide Coverage Lexicon, Fuzzy Tag-set Mapping, and EM-HMM-based Lexical Probabilities", "labels": [], "entities": [{"text": "Fuzzy Tag-set Mapping", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.5478468835353851}]}], "abstractContent": [{"text": "We present a framework for interfacing a PCFG parser with lexical information from an external resource following a different tagging scheme than the treebank.", "labels": [], "entities": []}, {"text": "This is achieved by defining a stochas-tic mapping layer between the two resources.", "labels": [], "entities": []}, {"text": "Lexical probabilities for rare events are estimated in a semi-supervised manner from a lexicon and large unanno-tated corpora.", "labels": [], "entities": []}, {"text": "We show that this solution greatly enhances the performance of an unlexicalized Hebrew PCFG parser, resulting in state-of-the-art Hebrew parsing results both when a segmentation oracle is assumed, and in a real-word parsing scenario of parsing unsegmented tokens.", "labels": [], "entities": [{"text": "Hebrew parsing", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.5676442980766296}]}], "introductionContent": [{"text": "The intuition behind unlexicalized parsers is that the lexicon is mostly separated from the syntax: specific lexical items are mostly irrelevant for accurate parsing, and can be mediated through the use of POS tags and morphological hints.", "labels": [], "entities": []}, {"text": "This same intuition also resonates in highly lexicalized formalism such as CCG: while the lexicon categories are very fine grained and syntactic in nature, once the lexical category fora lexical item is determined, the specific lexical form is not taken into any further consideration.", "labels": [], "entities": []}, {"text": "Despite this apparent separation between the lexical and the syntactic levels, both are usually estimated solely from a single treebank.", "labels": [], "entities": []}, {"text": "PCFGs can be accurate, they suffer from vocabulary coverage problems: treebanks are small and lexicons induced from them are limited.", "labels": [], "entities": [{"text": "PCFGs", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7996764183044434}]}, {"text": "The reason for this treebank-centric view in PCFG learning is 3-fold: the English treebank is fairly large and English morphology is fairly simple, so that in English, the treebank does provide mostly adequate lexical coverage 1 ; Lexicons enumerate analyses, but don't provide probabilities for them; and, most importantly, the treebank and the external lexicon are likely to follow different annotation schemas, reflecting different linguistic perspectives.", "labels": [], "entities": [{"text": "PCFG learning", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.7945697605609894}, {"text": "English treebank", "start_pos": 74, "end_pos": 90, "type": "DATASET", "confidence": 0.7594287991523743}]}, {"text": "On a different vein of research, current POS tagging technology deals with much larger quantities of training data than treebanks can provide, and lexicon-based unsupervised approaches to POS tagging are practically unlimited in the amount of training data they can use.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.8204987943172455}, {"text": "POS tagging", "start_pos": 188, "end_pos": 199, "type": "TASK", "confidence": 0.8930505812168121}]}, {"text": "POS taggers rely on richer knowledge than lexical estimates derived from the treebank, have evolved sophisticated strategies to handle OOV and can provide distributions p(t|w, context) instead of \"best tag\" only.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7261465489864349}]}, {"text": "Can these two worlds be combined?", "labels": [], "entities": []}, {"text": "We propose that parsing performance can be greatly improved by using a wide coverage lexicon to suggest analyses for unknown tokens, and estimating the respective lexical probabilities using a semisupervised technique, based on the training procedure of a lexicon-based HMM POS tagger.", "labels": [], "entities": [{"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9695757031440735}]}, {"text": "For many resources, this approach can betaken only on the proviso that the annotation schemes of the two resources can be aligned.", "labels": [], "entities": []}, {"text": "We take Modern Hebrew parsing as our case study.", "labels": [], "entities": [{"text": "Modern Hebrew parsing", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.6018039484818777}]}, {"text": "Hebrew is a Semitic language with rich morphological structure.", "labels": [], "entities": []}, {"text": "This rich structure yields a large number of distinct word forms, resulting in a high OOV rate).", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9887678027153015}]}, {"text": "This poses a serious problem for estimating lexical probabilities from small annotated corpora, such as the Hebrew treebank).", "labels": [], "entities": [{"text": "Hebrew treebank", "start_pos": 108, "end_pos": 123, "type": "DATASET", "confidence": 0.7283816933631897}]}, {"text": "Hebrew has a wide coverage lexicon / morphological-analyzer (henceforth, KC Analyzer) available 2 , but its tagset is different than the one used by the Hebrew Treebank.", "labels": [], "entities": [{"text": "Hebrew", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9388646483421326}, {"text": "Hebrew Treebank", "start_pos": 153, "end_pos": 168, "type": "DATASET", "confidence": 0.9297945201396942}]}, {"text": "These are not mere technical differences, but derive from different perspectives on the data.", "labels": [], "entities": []}, {"text": "The Hebrew TB tagset is syntactic in nature, while the KC tagset is lexicographic.", "labels": [], "entities": [{"text": "Hebrew TB tagset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9105629920959473}, {"text": "KC tagset", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.8173551559448242}]}, {"text": "This difference in perspective yields different performance for parsers induced from tagged data, and a simple mapping between the two schemes is impossible to define (Sec. 2).", "labels": [], "entities": [{"text": "parsers induced from tagged data", "start_pos": 64, "end_pos": 96, "type": "TASK", "confidence": 0.8042650341987609}]}, {"text": "A naive approach for combining the use of the two resources would be to manually re-tag the Treebank with the KC tagset, but we show this approach harms our parser's performance.", "labels": [], "entities": []}, {"text": "Instead, we propose a novel, layered approach (Sec. 2.1), in which syntactic (TB) tags are viewed as contextual refinements of the lexicon (KC) tags, and conversely, KC tags are viewed as lexical clustering of the syntactic ones.", "labels": [], "entities": []}, {"text": "This layered representation allows us to easily integrate the syntactic and the lexicon-based tagsets, without explicitly requiring the Treebank to be re-tagged.", "labels": [], "entities": []}, {"text": "Hebrew parsing is further complicated by the fact that common prepositions, conjunctions and articles are prefixed to the following word and pronominal elements often appear as suffixes.", "labels": [], "entities": [{"text": "Hebrew parsing", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6338400691747665}]}, {"text": "The segmentation of prefixes and suffixes can be ambiguous and must be determined in a specific context only.", "labels": [], "entities": [{"text": "segmentation of prefixes and suffixes", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8193307042121887}]}, {"text": "Thus, the leaves of the syntactic parse trees do not correspond to space-delimited tokens, and the yield of the tree is not known in advance.", "labels": [], "entities": []}, {"text": "We show that enhancing the parser with external lexical information is greatly beneficial, both in an artificial scenario where the token segmentation is assumed to be known (Sec.", "labels": [], "entities": []}, {"text": "4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec. 5).", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9702199697494507}]}, {"text": "External lexical information enhances unlexicalized parsing performance by as much as 6.67 F-points, an error reduction of 20% over a Treebank-only parser.", "labels": [], "entities": [{"text": "F-points", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9966959953308105}, {"text": "error reduction", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.9661619365215302}]}, {"text": "Our results are not only the best published results for parsing Hebrew, but also on par with state-of-the-art 2 http://mila.cs.technion.ac.il/hebrew/resources/lexicons/ lexicalized Arabic parsing results assuming goldstandard fine-grained Part-of-Speech (.", "labels": [], "entities": [{"text": "parsing Hebrew", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.9094942808151245}]}], "datasetContent": [{"text": "As our Baseline, we take the best model of, run against the current version of the Treebank.", "labels": [], "entities": [{"text": "Treebank", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.507760763168335}]}, {"text": "15 This model uses the same grammar as described in Section 4.1 above, and use some external information in the form of a spell-checker wordlist.", "labels": [], "entities": []}, {"text": "We compare this Baseline with the LexFilter and LexProbs models over the Layered representation.", "labels": [], "entities": [{"text": "LexFilter", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.9751937389373779}, {"text": "LexProbs", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.6072742342948914}]}, {"text": "We use the same test/train splits as described in Section 4.", "labels": [], "entities": []}, {"text": "Contrary to the Oracle segmentation setting, here we evaluate against all sentences, including those containing tokens for which the KC Analyzer does not contain any correct analyses.", "labels": [], "entities": [{"text": "Oracle segmentation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.6595058590173721}, {"text": "KC Analyzer", "start_pos": 133, "end_pos": 144, "type": "DATASET", "confidence": 0.8672346472740173}]}, {"text": "Due to token segmentation ambiguity, the resulting parse yields maybe different than the gold ones, and evalb cannot be used.", "labels": [], "entities": [{"text": "token segmentation", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.6821819543838501}]}, {"text": "Instead, we use the evaluation measure of), also used in, which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Note that this sce- nario does not reflect actual parsing performance,  as the gold information is never available in prac- tice, and surface forms are highly ambiguous.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9622381925582886}]}, {"text": " Table 1: evalb results for parsing with Oracle  morphological information, for the two tagsets  With gold morphological information, the TB  tagging scheme is more informative for the parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9813727140426636}]}, {"text": " Table 2: evalb results for parsing with a  segmentation Oracle.  As expected, all the results are much lower than  those with gold fine-grained POS", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9741948843002319}]}, {"text": " Table 3: Parsing results for the joint parsing+seg  task, with varying external knowledge", "labels": [], "entities": [{"text": "joint parsing+seg  task", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.6894746541976928}]}]}