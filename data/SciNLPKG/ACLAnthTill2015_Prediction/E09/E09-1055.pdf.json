{"title": [{"text": "Treebank Grammar Techniques for Non-Projective Dependency Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 58, "end_pos": 65, "type": "TASK", "confidence": 0.641327977180481}]}], "abstractContent": [{"text": "An open problem in dependency parsing is the accurate and efficient treatment of non-projective structures.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8168553709983826}]}, {"text": "We propose to attack this problem using chart-parsing algorithms developed for mildly context-sensitive grammar formalisms.", "labels": [], "entities": []}, {"text": "In this paper , we provide two key tools for this approach.", "labels": [], "entities": []}, {"text": "First, we show how to reduce non-projective dependency parsing to parsing with Linear Context-Free Rewriting Systems (LCFRS), by presenting a technique for extracting LCFRS from dependency treebanks.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7441989779472351}]}, {"text": "For efficient parsing, the extracted grammars need to be transformed in order to minimize the number of nonter-minal symbols per production.", "labels": [], "entities": []}, {"text": "Our second contribution is an algorithm that computes this transformation fora large, empirically relevant class of grammars.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsing is the task of predicting the most probable dependency structure fora given sentence.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8269713222980499}]}, {"text": "One of the key choices in dependency parsing is about the class of candidate structures for this prediction.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8172358572483063}]}, {"text": "Many parsers are confined to projective structures, in which the yield of a syntactic head is required to be continuous.", "labels": [], "entities": []}, {"text": "A major benefit of this choice is computational efficiency: an exhaustive search overall projective structures can be done in cubic, greedy parsing in linear time.", "labels": [], "entities": []}, {"text": "A major drawback of the restriction to projective dependency structures is a potential loss inaccuracy.", "labels": [], "entities": []}, {"text": "For example, around 23% of the analyses in the Prague Dependency Treebank of) are nonprojective, and for German and Dutch treebanks, the proportion of non-projective structures is even higher.", "labels": [], "entities": [{"text": "Prague Dependency Treebank of)", "start_pos": 47, "end_pos": 77, "type": "DATASET", "confidence": 0.9650649309158326}]}, {"text": "The problem of non-projective dependency parsing under the joint requirement of accuracy and efficiency has only recently been addressed in the literature.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.7158951361974081}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9992938041687012}]}, {"text": "Some authors propose to solve it by techniques for recovering non-projectivity from the output of a projective parser in a post-processing step, others extend projective parsers by heuristics that allow at least certain non-projective constructions to be parsed.", "labels": [], "entities": []}, {"text": "formulate dependency parsing as the search for the most probable spanning tree over the full set of all possible dependencies.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8361366093158722}]}, {"text": "However, this approach is limited to probability models with strong independence assumptions.", "labels": [], "entities": []}, {"text": "Exhaustive nonprojective dependency parsing with more powerful models is intractable, and one has to resort to approximation algorithms).", "labels": [], "entities": []}, {"text": "In this paper, we propose to attack non-projective dependency parsing in a principled way, using polynomial chart-parsing algorithms developed for mildly context-sensitive grammar formalisms.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7715581357479095}]}, {"text": "This proposal is motivated by the observation that most dependency structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (), and by the close link between such 'mildly non-projective' dependency structures on the one hand, and grammar formalisms with mildly context-sensitive generative capacity on the other (.", "labels": [], "entities": []}, {"text": "Furthermore, as pointed out by, chart-parsing algorithms are amenable to augmentation by non-local information such as arity constraints and Markovization, and therefore should allow for more predictive statistical models than those used by current systems for non-projective dependency parsing.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 261, "end_pos": 294, "type": "TASK", "confidence": 0.810292104880015}]}, {"text": "Hence, mildly non-projective dependency parsing promises to be both efficient and accurate.", "labels": [], "entities": []}, {"text": "Contributions In this paper, we contribute two key tools for making the mildly context-sensitive approach to accurate and efficient non-projective dependency parsing work.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.6798510551452637}]}, {"text": "First, we extend the standard technique for extracting context-free grammars from phrase-structure treebanks) to mildly context-sensitive grammars and dependency treebanks.", "labels": [], "entities": []}, {"text": "More specifically, we show how to extract, from a given dependency treebank, a lexicalized Linear Context-Free Rewriting System (LCFRS) whose derivations capture the dependency analyses in the treebank in the same way as the derivations of a context-free treebank grammar capture phrasestructure analyses.", "labels": [], "entities": []}, {"text": "Our technique works for arbitrary, even non-projective dependency treebanks, and essentially reduces non-projective dependency to parsing with LCFRS.", "labels": [], "entities": []}, {"text": "This problem can be solved using standard chart-parsing techniques.", "labels": [], "entities": []}, {"text": "Our extraction technique yields a grammar whose parsing complexity is polynomial in the length of the sentence, but exponential in both a measure of the non-projectivity of the treebank and the maximal number of dependents per word, reflected as the rank of the extracted LCFRS.", "labels": [], "entities": []}, {"text": "While the number of highly non-projective dependency structures is negligible for practical applications (), the rank cannot easily be bounded.", "labels": [], "entities": []}, {"text": "Therefore, we present an algorithm that transforms the extracted grammar into a normal form that has rank 2, and thus can be parsed more efficiently.", "labels": [], "entities": []}, {"text": "This contribution is important even independently of the extraction procedure: While it is known that a rank-2 normal form of LCFRS does not exist in the general case), our algorithm succeeds fora large and empirically relevant class of grammars.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Properties of productions extracted from  the CoNLL 2006 data (3 794 605 productions)", "labels": [], "entities": [{"text": "CoNLL 2006 data", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9730662306149801}]}, {"text": " Table 1. Since it  is easy to see that our algorithm always succeeds on  context-free productions (productions where each  nonterminal has fan-out 1), we evaluated our al- gorithm on the 102 687 productions with a higher  fan-out. Out of these, only 24 (0.02%) could not be  binarized using our technique. We take this number  as an indicator for the usefulness of our result.", "labels": [], "entities": []}]}