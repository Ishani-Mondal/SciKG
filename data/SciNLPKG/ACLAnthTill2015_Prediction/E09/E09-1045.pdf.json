{"title": [{"text": "An Empirical Study on Class-based Word Sense Disambiguation *", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.7406275769074758}]}], "abstractContent": [{"text": "As empirically demonstrated by the last SensEval exercises, assigning the appropriate meaning to words in context has resisted all attempts to be successfully addressed.", "labels": [], "entities": []}, {"text": "One possible reason could be the use of inappropriate set of meanings.", "labels": [], "entities": []}, {"text": "In fact, WordNet has been used as a de-facto standard repository of meanings.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.9688385128974915}]}, {"text": "However , to our knowledge, the meanings represented by WordNet have been only used for WSD at a very fine-grained sense level or at a very coarse-grained class level.", "labels": [], "entities": [{"text": "WSD", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9272871017456055}]}, {"text": "We suspect that selecting the appropriate level of abstraction could be on between both levels.", "labels": [], "entities": []}, {"text": "We use a very simple method for deriving a small set of appropriate meanings using basic structural properties of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.9565638899803162}]}, {"text": "We also empirically demonstrate that this automatically derived set of meanings groups senses into an adequate level of abstraction in order to perform class-based Word Sense Disambiguation, allowing accuracy figures over 80%.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 164, "end_pos": 189, "type": "TASK", "confidence": 0.5909222761789957}, {"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9988539218902588}]}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is an intermediate Natural Language Processing (NLP) task which consists in assigning the correct semantic interpretation to ambiguous words in context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.787257562081019}, {"text": "assigning the correct semantic interpretation to ambiguous words in context", "start_pos": 108, "end_pos": 183, "type": "TASK", "confidence": 0.742085662484169}]}, {"text": "One of the most successful approaches in the last years is the supervised learning from examples, in which statistical or Machine Learning classification models are induced from semantically annotated corpora).", "labels": [], "entities": []}, {"text": "Generally, supervised systems have obtained better results than the unsupervised ones, as shown by experimental work and international evaluation exercises such * This paper has been supported by the European Union under the projects QALL-ME (FP6 IST-033860) and KY-OTO (FP7 ICT-211423), and the Spanish Government under the project Text-Mess (TIN2006-15265-C06-01) and KNOW as Senseval . These annotated corpora are usually manually tagged by lexicographers with word senses taken from a particular lexical semantic resource -most commonly WordNet 2 (WN).", "labels": [], "entities": [{"text": "FP6 IST-033860", "start_pos": 243, "end_pos": 257, "type": "DATASET", "confidence": 0.7912129461765289}]}, {"text": "WN has been widely criticized for being a sense repository that often provides too fine-grained sense distinctions for higher level applications like Machine Translation or Question & Answering.", "labels": [], "entities": [{"text": "WN", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7627353668212891}, {"text": "Machine Translation", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8544527292251587}, {"text": "Question & Answering", "start_pos": 173, "end_pos": 193, "type": "TASK", "confidence": 0.6860306660334269}]}, {"text": "In fact, WSD at this level of granularity has resisted all attempts of inferring robust broadcoverage models.", "labels": [], "entities": [{"text": "WSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.8400365114212036}]}, {"text": "It seems that many word-sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word-sense annotated examples.", "labels": [], "entities": []}, {"text": "Possibly, building class-based classifiers would allow to avoid the data sparseness problem of the word-based approach.", "labels": [], "entities": []}, {"text": "Recently, using WN as a sense repository, the organizers of the English all-words task at SensEval-3 reported an inter-annotation agreement of 72.5% ().", "labels": [], "entities": []}, {"text": "Interestingly, this result is difficult to outperform by state-of-the-art sense-based WSD systems.", "labels": [], "entities": []}, {"text": "Thus, some research has been focused on deriving different word-sense groupings to overcome the fine-grained distinctions of WN, ,,,) and (.", "labels": [], "entities": []}, {"text": "That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation.", "labels": [], "entities": []}, {"text": "Wikipedia has been also recently used to overcome some problems of automatic learning methods: excessively fine-grained definition of meanings, lack of annotated data and strong domain dependence of existing annotated corpora.", "labels": [], "entities": []}, {"text": "In this way, Wikipedia provides anew very large source of annotated data, constantly expanded.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.946534276008606}]}, {"text": "In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (,,), ( and).", "labels": [], "entities": []}, {"text": "That is, grouping senses of different words into the same explicit and comprehensive semantic class.", "labels": [], "entities": []}, {"text": "Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse-grained sense distinctions.", "labels": [], "entities": [{"text": "Lexicographical Files of WN", "start_pos": 47, "end_pos": 74, "type": "DATASET", "confidence": 0.8738223314285278}]}, {"text": "However, not so much attention has been paid on learning class-based classifiers from other available sense-groupings such as WordNet Domains (), SUMO labels (), EuroWordNet Base Concepts ( ), Top Concept Ontology labels ( or Basic Level Concepts (.", "labels": [], "entities": [{"text": "EuroWordNet", "start_pos": 162, "end_pos": 173, "type": "DATASET", "confidence": 0.9391874074935913}]}, {"text": "Obviously, these resources relate senses at some level of abstraction using different semantic criteria and properties that could be of interest for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 149, "end_pos": 152, "type": "TASK", "confidence": 0.9385899305343628}]}, {"text": "Possibly, their combination could improve the overall results since they offer different semantic perspectives of the data.", "labels": [], "entities": []}, {"text": "Furthermore, to our knowledge, to date no comparative evaluation has been performed on SensEval data exploring different levels of abstraction.", "labels": [], "entities": []}, {"text": "In fact, () studied the performance of class-based WSD comparing only SuperSenses and SUMO by 10-fold cross-validation on SemCor, but they did not provide results for SensEval2 nor SensEval3.", "labels": [], "entities": []}, {"text": "This paper empirically explores on the supervised WSD task the performance of different levels of abstraction provided by WordNet Domains (), SUMO labels) and Basic Level Concepts (.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.8882654309272766}]}, {"text": "We refer to this approach as class-based WSD since the classifiers are created at a class level instead of at a sense level.", "labels": [], "entities": []}, {"text": "Class-based WSD clusters senses of different words into the same explicit and comprehensive grouping.", "labels": [], "entities": []}, {"text": "Only those cases belonging to the same semantic class are grouped to train the classifier.", "labels": [], "entities": []}, {"text": "For example, the coarser word grouping obtained in () only has one remaining sense for \"church\".", "labels": [], "entities": []}, {"text": "Using a set of Base Level Concepts (, the three senses of \"church\" are still represented by faith.n#3, building.n#1 and religious ceremony.n#1.", "labels": [], "entities": []}, {"text": "The contribution of this work is threefold.", "labels": [], "entities": []}, {"text": "We empirically demonstrate that a) Basic Level Concepts group senses into an adequate level of abstraction in order to perform supervised classbased WSD, b) that these semantic classes can be successfully used as semantic features to boost the performance of these classifiers and c) that the class-based approach to WSD reduces dramatically the required amount of training examples to obtain competitive classifiers.", "labels": [], "entities": [{"text": "WSD", "start_pos": 317, "end_pos": 320, "type": "TASK", "confidence": 0.9251113533973694}]}, {"text": "After this introduction, section 2 presents the sense-groupings used in this study.", "labels": [], "entities": []}, {"text": "In section 3 the approach followed to build the class-based system is explained.", "labels": [], "entities": []}, {"text": "Experiments and results are shown in section 4.", "labels": [], "entities": []}, {"text": "Finally some conclusions are drawn in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To analyze the influence of each feature type in the class-based WSD, we designed a large set of experiments.", "labels": [], "entities": []}, {"text": "An experiment is defined by two sets of semantic classes.", "labels": [], "entities": []}, {"text": "First, the semantic class type for selecting the examples used to build the classifiers (determining the abstraction level of the system).", "labels": [], "entities": []}, {"text": "In this case, we tested: sense 12 , BLC20, BLC50, WordNet Domains (WND), SUMO and SuperSense (SS).", "labels": [], "entities": [{"text": "BLC20", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.763698935508728}, {"text": "BLC50", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.6628245711326599}, {"text": "WordNet Domains (WND)", "start_pos": 50, "end_pos": 71, "type": "DATASET", "confidence": 0.8863322734832764}]}, {"text": "Second, the semantic class type used for building the semantic features.", "labels": [], "entities": []}, {"text": "In this case, we tested: BLC20, BLC50, SuperSense, WND and SUMO.", "labels": [], "entities": [{"text": "BLC20", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.7940348386764526}, {"text": "BLC50", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.6331119537353516}]}, {"text": "Combining them, we generated the set of experiments described later.", "labels": [], "entities": []}, {"text": "presents the average polysemy on SE2 and SE3 of the different semantic classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLC for WN1.6 using all or hyponym relations", "labels": [], "entities": [{"text": "BLC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9464890956878662}, {"text": "WN1.6", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.7629090547561646}]}, {"text": " Table 2: Examples and number of them in Semcor, for", "labels": [], "entities": []}, {"text": " Table 3: Average polysemy on SE2 and SE3", "labels": [], "entities": [{"text": "SE3", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.4223003089427948}]}, {"text": " Table 4: Results for nouns", "labels": [], "entities": []}, {"text": " Table 5: Results for verbs", "labels": [], "entities": []}]}