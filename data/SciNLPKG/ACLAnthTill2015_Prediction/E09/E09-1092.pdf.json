{"title": [{"text": "Deriving Generalized Knowledge from Corpora using WordNet Abstraction", "labels": [], "entities": [{"text": "Deriving Generalized Knowledge from Corpora using WordNet Abstraction", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8147417604923248}]}], "abstractContent": [{"text": "Existing work in the extraction of com-monsense knowledge from text has been primarily restricted to factoids that serve as statements about what may possibly obtain in the world.", "labels": [], "entities": []}, {"text": "We present an approach to deriving stronger, more general claims by abstracting overlarge sets of factoids.", "labels": [], "entities": []}, {"text": "Our goal is to coalesce the observed nominals fora given predicate argument into a few predominant types, obtained as WordNet synsets.", "labels": [], "entities": []}, {"text": "The results can be construed as generically quantified sentences restricting the semantic type of an argument position of a predicate.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our interest is ultimately in building systems with commonsense reasoning and language understanding abilities.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6745165884494781}]}, {"text": "As is widely appreciated, such systems will require large amounts of general world knowledge.", "labels": [], "entities": []}, {"text": "Large text corpora are an attractive potential source of such knowledge.", "labels": [], "entities": []}, {"text": "However, current natural language understanding (NLU) methods are not general and reliable enough to enable broad assimilation, in a formalized representation, of explicitly stated knowledge in encyclopedias or similar sources.", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.8317707777023315}]}, {"text": "As well, such sources typically do not cover the most obvious facts of the world, such as that ice cream maybe delicious and maybe coated with chocolate, or that children may play in parks.", "labels": [], "entities": []}, {"text": "Methods currently exist for extracting simple \"factoids\" like those about ice cream and children just mentioned (see in particular), but these are quite weak as general claims, and -being unconditional -are unsuitable for inference chaining.", "labels": [], "entities": [{"text": "inference chaining", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.7852810919284821}]}, {"text": "Consider however the fact that when something is said, it is generally said by a person, organization or text source; this a conditional statement dealing with the potential agents of saying, and could enable useful inferences.", "labels": [], "entities": []}, {"text": "For example, in the sentence, \"The tires were worn and they said I had to replace them\", they might be mistakenly identified with the tires, without the knowledge that saying is something done primarily by persons, organizations or text sources.", "labels": [], "entities": []}, {"text": "Similarly, looking into the future one can imagine telling a household robot, \"The cat needs to drink something\", with the expectation that the robot will take into account that if a cat drinks something, it is usually water or milk (whereas people would often have broader options).", "labels": [], "entities": []}, {"text": "The work reported here is aimed at deriving generalizations of the latter sort from large sets of weaker propositions, by examining the hierarchical relations among sets of types that occur in the argument positions of verbal or other predicates.", "labels": [], "entities": []}, {"text": "The generalizations we are aiming at are certainly not the only kinds derivable from text corpora (as the extensive literature on finding isa-relations, partonomic relations, paraphrase relations, etc.", "labels": [], "entities": []}, {"text": "attests), but as just indicated they do seem potentially useful.", "labels": [], "entities": []}, {"text": "Also, thanks to their grounding in factoids obtained by open knowledge extraction from large corpora, the propositions obtained are very broad in scope, unlike knowledge extracted in a more targeted way.", "labels": [], "entities": []}, {"text": "In the following we first briefly review the method developed by Schubert and collaborators to abstract factoids from text; we then outline our approach to obtaining strengthened propositions from such sets of factoids.", "labels": [], "entities": []}, {"text": "We report positive results, while making only limited use of standard corpus statistics, concluding that future endeavors exploring knowledge extraction and WordNet should go beyond the heuristics employed in recent work.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 132, "end_pos": 152, "type": "TASK", "confidence": 0.7194534689188004}]}, {"text": "2 KNEXT presented an approach to acquiring general world knowledge from text corpora based on parsing sentences and mapping syntactic forms into logical forms (LFs), then gleaning simple propositional factoids from these LFs through abstraction.", "labels": [], "entities": []}, {"text": "Logical forms were based on Episodic Logic), a formalism designed to accommodate in a straightforward way the semantic phenomena observed in all languages, such as predication, logical compounding, generalized quantification, modification and reification of predicates and propositions, and event reference.", "labels": [], "entities": []}, {"text": "An example from of factoids obtained from a sentence in the Brown corpus by their KNEXT system is the following: Rilly or Glendora had entered her room while she slept, bringing back her washed clothes.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.9655893445014954}, {"text": "Rilly", "start_pos": 113, "end_pos": 118, "type": "METRIC", "confidence": 0.8420464396476746}]}, {"text": "Here the upper-case sentences are automatically generated verbalizations of the abstracted LFs shown beneath them.", "labels": [], "entities": []}, {"text": "The initial development of KNEXT was based on the hand-constructed parse trees in the Penn Treebank version of the Brown corpus, but subsequently Schubert and collaborators refined and extended the system to work with parse trees obtained with statistical parsers (e.g., that of Collins (1997) or) applied to larger corpora, such as the British National Corpus (BNC), a 100 million-word, mixed genre collection, along with Web corpora of comparable size (see work of Van  and Van Durme and Schubert (2008) for details).", "labels": [], "entities": [{"text": "Penn Treebank version of the Brown corpus", "start_pos": 86, "end_pos": 127, "type": "DATASET", "confidence": 0.9581686088017055}, {"text": "British National Corpus (BNC)", "start_pos": 337, "end_pos": 366, "type": "DATASET", "confidence": 0.9613308111826578}]}, {"text": "The BNC yielded over 2 factoids per sentence on average, resulting in a total collection of several million.", "labels": [], "entities": [{"text": "BNC", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.7854874134063721}]}, {"text": "Human judging of the factoids indicates that about 2 out of 3 factoids are perceived as reasonable claims.", "labels": [], "entities": []}, {"text": "The goal in this work, with respect to the example given, would be to derive with the use of a large collection of KNEXT outputs, a general statement such as If something may sleep, it is probably either an animal or a person.", "labels": [], "entities": []}], "datasetContent": [{"text": "From the entire set of BNC-derived KNEXT propositional templates, evaluations were performed on a set of 21 manually selected examples,  together representing the sorts of knowledge for which we are most interested in deriving strengthened argument type restrictions.", "labels": [], "entities": []}, {"text": "All modification of the system ceased prior to the selection of these templates, and the authors had no knowledge of the underlying words observed for any particular slot.", "labels": [], "entities": []}, {"text": "Further, some of the templates were purposefully chosen as potentially problematic, such as, A ? MAY OBSERVE A , or A PERSON MAY PAINT A . Without additional context, templates such as these were expected to allow for exceptionally broad sorts of arguments.", "labels": [], "entities": [{"text": "A ? MAY OBSERVE A", "start_pos": 93, "end_pos": 110, "type": "METRIC", "confidence": 0.8421815037727356}, {"text": "A PERSON MAY PAINT A", "start_pos": 116, "end_pos": 136, "type": "METRIC", "confidence": 0.7438936829566956}]}, {"text": "For these 21 templates, 65 types were derived, giving an average of 3.1 types per slot, and allowing for statements such as seen in.", "labels": [], "entities": []}, {"text": "One way in which to measure the quality of an argument abstraction is to go back to the underlying observed words, and evaluate the resultant sense(s) implied by the chosen abstraction.", "labels": [], "entities": []}, {"text": "We say senses plural, as the majority of KNEXT propositions select senses that are more coarse-grained than WordNet synsets.", "labels": [], "entities": []}, {"text": "Thus, we wish to evaluate these more coarse-grained sense disambiguation results entailed by our type abstractions.", "labels": [], "entities": []}, {"text": "We performed this evaluation using as comparisons the first-sense, and all-senses heuristics.", "labels": [], "entities": []}, {"text": "The first-sense heuristic can bethought of as striving for maximal specificity at the risk of precluding some admissible senses (reduced recall), Allowing for multiple fine-grained senses to be judged as appropriate in a given context goes back at least to; discussed more recently by, e.g., while the all-senses heuristic insists on including all admissible senses (perfect recall) at the risk of including inadmissible ones.", "labels": [], "entities": [{"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9691016674041748}, {"text": "recall", "start_pos": 375, "end_pos": 381, "type": "METRIC", "confidence": 0.6849977374076843}]}, {"text": "gives the results of two judges evaluating 314 word, sense pairs across the 21 selected templates.", "labels": [], "entities": []}, {"text": "These sense pairs correspond to picking one word at random for each abstracted type selected for each template slot.", "labels": [], "entities": []}, {"text": "Judges were presented with a sampled word, the originating template, and the glosses for each possible word sense (see.", "labels": [], "entities": []}, {"text": "Judges did not know ahead of time the subset of senses selected by the system (as entailed by the derived type abstraction).", "labels": [], "entities": []}, {"text": "Taking the judges' annotations as the gold standard, we report precision, recall and F-score with a \u03b2 of 0.5 (favoring precision over recall, owing to our preference for reliable knowledge over more).", "labels": [], "entities": [{"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.999728262424469}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9995684027671814}, {"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9993873834609985}, {"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9990491271018982}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9969655871391296}]}, {"text": "In all cases our method gives precision results comparable or superior to the first-sense heuristic, while at all times giving higher recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9988204836845398}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9985944628715515}]}, {"text": "In particular, for the case of Primary type, corresponding to the derived type that accounted for the largest number of observations for the given argument slot, our method shows strong performance across the board, suggesting that our derived abstractions are general enough to pickup multiple acceptable senses for observed words, but not so general as to allow unrelated senses.", "labels": [], "entities": []}, {"text": "We designed an additional test of our method's performance, aimed at determining whether the distinction between admissible senses and inadmissible ones entailed by our type abstractions were in accord with human judgement.", "labels": [], "entities": []}, {"text": "To this end, we automatically chose for each template the observed word that had the greatest number of senses not dominated by a derived type A MAY HAVE A BROTHER 1 WOMAN : an adult female person (as opposed to a man); \"the woman kept house while the man hunted\" 2 WOMAN : a female person who plays a significant role (wife or mistress or girlfriend) in the life of a particular man; \"he was faithful to his woman\" 3 WOMAN : a human female employed to do housework; \"the char will clean the carpet\"; \"I have a woman who comes in four hours a day while I write\" *4 WOMAN : women as a class; \"it's an insult to American womanhood\"; \"woman is the glory of creation\"; \"the fair sex gathered on the veranda\" If something is famous, it is probably a person1, an artifact1, or a communication2 If ? writes something, it is probably a communication2 If a person is happy with something, it is probably a communication2, a work1, a final result1, or a state of affairs1 If a fish has something, it is probably a cognition1, a torso1, an interior2, or a state2 If something is fast growing, it is probably a group1 or a business3 If a message undergoes something, it is probably a message2, a transmission2, a happening1, or a creation1 If a male builds something, it is probably a structure1, a business3, or a group1: Examples, both good and bad, of resultant statements able to be made post-derivation.", "labels": [], "entities": [{"text": "HAVE A BROTHER", "start_pos": 149, "end_pos": 163, "type": "METRIC", "confidence": 0.8515275120735168}]}, {"text": "Authors manually selected one word from each derived synset, with subscripts referring to sense number.", "labels": [], "entities": []}, {"text": "Types are given in order of support, and thus the first are examples of \"Primary\" in   restriction.", "labels": [], "entities": []}, {"text": "For each of these alternative (nondominated) senses, we selected the ancestor lying at the same distance towards the root from the given sense as the average distance from the dominated senses to the derived type restriction.", "labels": [], "entities": []}, {"text": "In the case where going this far from an alternative sense towards the root would reach a path passing through the derived type and one of its subsumed senses, the distance was cutback until this was no longer the case.", "labels": [], "entities": []}, {"text": "These alternative senses, guaranteed to not be dominated by derived type restrictions, were then presented along with the derived type and the original template to two judges, who were given the same instructions as used by Van Durme and Schubert (2008), which can be found in.", "labels": [], "entities": []}, {"text": "Results for this evaluation are found in, where we see that the automatically derived type restrictions are strongly favored over alternative judge 1 judge 2 corr derived 1.76 2.10 0.60 alternative 3.63 3.54 0.58 abstracted types that were possible based on the given word.", "labels": [], "entities": []}, {"text": "Achieving even stronger rejection of alternative types would be difficult, since KNEXT templates often provide insufficient context for full disambiguation of all their constituents, and judges were allowed to base their assessments on any interpretation of the verbalization that they could reasonably come up with.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Development templates, paired with the number of", "labels": [], "entities": []}, {"text": " Table 3: Templates chosen for evaluation.", "labels": [], "entities": []}, {"text": " Table 4: Examples, both good and bad, of resultant statements able to be made post-derivation. Authors manually selected", "labels": [], "entities": []}, {"text": " Table 5: Precision, Recall and F-score (\u03b2 = 0.5) for coarse grained WSD labels using the methods: derive from corpus data,", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9993671774864197}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9981300234794617}, {"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9990235567092896}]}]}