{"title": [{"text": "Web augmentation of language models for continuous speech recognition of SMS text messages", "labels": [], "entities": [{"text": "continuous speech recognition of SMS text messages", "start_pos": 40, "end_pos": 90, "type": "TASK", "confidence": 0.8115898285593305}]}], "abstractContent": [{"text": "In this paper, we present an efficient query selection algorithm for the retrieval of web text data to augment a statistical language model (LM).", "labels": [], "entities": []}, {"text": "The number of retrieved relevant documents is optimized with respect to the number of queries submitted.", "labels": [], "entities": []}, {"text": "The querying scheme is applied in the domain of SMS text messages.", "labels": [], "entities": []}, {"text": "Continuous speech recognition experiments are conducted on three languages: English, Span-ish, and French.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7215372622013092}]}, {"text": "The web data is utilized for augmenting in-domain LMs in general and for adapting the LMs to a user-specific vocabulary.", "labels": [], "entities": []}, {"text": "Word error rate reductions of up to 6.6 % (in LM augmentation) and 26.0 % (in LM adaptation) are obtained in setups, where the size of the web mixture LM is limited to the size of the baseline in-domain LM.", "labels": [], "entities": [{"text": "Word error rate", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.6246822675069174}, {"text": "LM adaptation", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.8554266095161438}]}], "introductionContent": [{"text": "An automatic speech recognition (ASR) system consists of acoustic models of speech sounds and of a statistical language model (LM).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 3, "end_pos": 37, "type": "TASK", "confidence": 0.8128664990266165}]}, {"text": "The LM learns the probabilities of word sequences from text corpora available for training.", "labels": [], "entities": []}, {"text": "The performance of the model depends on the amount and style of the text.", "labels": [], "entities": []}, {"text": "The more text there is, the better the model is, in general.", "labels": [], "entities": []}, {"text": "It is also important that the model be trained on text that matches the style of language used in the ASR application.", "labels": [], "entities": [{"text": "ASR application", "start_pos": 102, "end_pos": 117, "type": "TASK", "confidence": 0.9055669605731964}]}, {"text": "Well matching, in-domain, text maybe both difficult and expensive to obtain in the large quantities that are needed.", "labels": [], "entities": []}, {"text": "A popular solution is to utilize the World Wide Web as a source of additional text for LM training.", "labels": [], "entities": [{"text": "LM training", "start_pos": 87, "end_pos": 98, "type": "TASK", "confidence": 0.925776481628418}]}, {"text": "A small in-domain set is used as seed data, and more data of the same kind is retrieved from the web.", "labels": [], "entities": []}, {"text": "A decade ago, proposed a just-in-time LM that updated the current LM by retrieving data from the web using recent recognition hypotheses as queries submitted to a search engine.", "labels": [], "entities": []}, {"text": "Perplexity reductions of up to 10 % were reported.", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9717178344726562}]}, {"text": "1 Many other works have followed.", "labels": [], "entities": []}, {"text": "retrieved page and phrase counts from the web in order to update the probabilities of infrequent trigrams that occur in N-best lists.", "labels": [], "entities": []}, {"text": "Word error rate (WER) reductions of about 3 % were obtained on TREC-7 data.", "labels": [], "entities": [{"text": "Word error rate (WER)", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.9129247764746348}, {"text": "TREC-7 data", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.9463171660900116}]}, {"text": "In more recent work, the focus has turned to the collection of text rather than n-gram statistics based on page counts.", "labels": [], "entities": []}, {"text": "More effort has been put into the selection of query strings.", "labels": [], "entities": []}, {"text": "first extend their baseline vocabulary with words from a small in-domain training corpus.", "labels": [], "entities": []}, {"text": "They then use n-grams with these new words in their web queries in order to retrieve text of a certain genre.", "labels": [], "entities": []}, {"text": "For instance, they succeed in obtaining conversational style phrases, such as \"we were friends but we don't actually have a relationship.\"", "labels": [], "entities": []}, {"text": "Ina number of experiments, word error rate reductions of 2-3 % are obtained on English data, and 6 % on Mandarin.", "labels": [], "entities": [{"text": "word error rate reductions", "start_pos": 27, "end_pos": 53, "type": "METRIC", "confidence": 0.712731622159481}]}, {"text": "The same method for web data collection is applied by C \u00b8 etin and in meeting and lecture transcription tasks.", "labels": [], "entities": [{"text": "web data collection", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.6889938513437907}, {"text": "meeting and lecture transcription tasks", "start_pos": 70, "end_pos": 109, "type": "TASK", "confidence": 0.7123848140239716}]}, {"text": "The web sources reduce perplexity by 10 % and 4.3 %, respectively, and word error rates by 3.5 % and 2.2 %, respectively.", "labels": [], "entities": [{"text": "word error rates", "start_pos": 71, "end_pos": 87, "type": "METRIC", "confidence": 0.7629902760187784}]}, {"text": "chunk the in-domain text into \"n-gram islands\" consisting of only content words and excluding frequently occurring stop words.", "labels": [], "entities": []}, {"text": "An island such as \"stock fund portfolio\" is then extended by adding context, producing \"my stock fund portfolio\", for instance.", "labels": [], "entities": []}, {"text": "Multiple islands are combined using and and or operations to form web queries.", "labels": [], "entities": []}, {"text": "Significant word error reductions between 10 and 20 % are obtained; however, the in-domain data set is very small, 1700 phrases, which makes (any) new data a much needed addition.", "labels": [], "entities": []}, {"text": "Similarly, obtain very good word error reductions (20 %) in spoken dialogue systems for software support and sightseeing guidance.", "labels": [], "entities": [{"text": "word error reductions", "start_pos": 28, "end_pos": 49, "type": "METRIC", "confidence": 0.678419421116511}]}, {"text": "Nouns that have high tf/idf scores in the in-domain documents are used in the web queries.", "labels": [], "entities": []}, {"text": "The existing in-domain data sets poorly match the speaking style of the task and therefore existing dialogue corpora of different domains are included, which improves the performance considerably.", "labels": [], "entities": []}, {"text": "select query strings by comparing the n-gram counts within an in-domain topic model to the corresponding counts in an outof-domain background model.", "labels": [], "entities": []}, {"text": "Topic-specific ngrams are used as queries, and perplexity reductions of 5.4 % are obtained.", "labels": [], "entities": []}, {"text": "It is customary to postprocess and filter the downloaded web texts.", "labels": [], "entities": []}, {"text": "Sentence boundaries are detected using some heuristics.", "labels": [], "entities": [{"text": "Sentence boundaries", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9009711444377899}]}, {"text": "Text chunks with a high out-of-vocabulary (OOV) rate are discarded.", "labels": [], "entities": [{"text": "out-of-vocabulary (OOV) rate", "start_pos": 24, "end_pos": 52, "type": "METRIC", "confidence": 0.7998732686042785}]}, {"text": "Additionally, the chunks are often ranked according to their similarity with the in-domain data, and the lowest ranked chunks are discarded.", "labels": [], "entities": []}, {"text": "As a similarity measure, the perplexity of the sentence according to the in-domain LM can be used; for instance,.", "labels": [], "entities": []}, {"text": "Another measure for ranking is relative perplexity), where the in-domain perplexity is divided by the perplexity given by an LM trained on the web data.", "labels": [], "entities": []}, {"text": "Also the BLEU score familiar from the field of machine translation has been used ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.9632461667060852}, {"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.763774961233139}]}, {"text": "Some criticism has been raised by, who claim that sentence ranking has an inherent bias towards the center of the in-domain distribution.", "labels": [], "entities": []}, {"text": "They propose a data selection algorithm that selects a sentence from the web set, if adding the sentence to the already selected set reduces the relative entropy with respect to the indomain data distribution.", "labels": [], "entities": []}, {"text": "The algorithm appears efficient in producing a rather small subset (1/11) of the web data, while degrading the WER only marginally.", "labels": [], "entities": [{"text": "WER", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.40681442618370056}]}, {"text": "The current paper describes anew method for query selection and its applications in LM augmentation and adaptation using web data.", "labels": [], "entities": [{"text": "query selection", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.7806636393070221}, {"text": "LM augmentation and adaptation", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.8298742473125458}]}, {"text": "The language models are part of a continuous speech recognition system that enables users to use speech as an input modality on mobile devices, such as mobile phones.", "labels": [], "entities": [{"text": "continuous speech recognition", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.7251555919647217}]}, {"text": "The particular domain of interest is personal communication: The user dictates a message that is automatically transcribed into text and sent to a recipient as an SMS text message.", "labels": [], "entities": []}, {"text": "Memory consumption and computational speed are crucial factors in mobile applications.", "labels": [], "entities": []}, {"text": "While most studies ignore the sizes of the LMs when comparing models, we aim at improving the LM without increasing its size when web data is added.", "labels": [], "entities": []}, {"text": "Another aspect that is typically overlooked is that the collection of web data costs time and computational resources.", "labels": [], "entities": []}, {"text": "This applies to the querying, downloading and postprocessing of the data.", "labels": [], "entities": []}, {"text": "The query selection scheme proposed in this paper is economical in the sense that it strives to download as much relevant text from the web as possible using as few queries as possible avoiding overlap between the set of pages found by different queries.", "labels": [], "entities": [{"text": "query selection", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.804992288351059}]}], "datasetContent": [{"text": "We have trained language models on the indomain data together with web data, and these models have been used in speech recognition experiments.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.8276520371437073}]}, {"text": "Two kinds of experiments have been performed: (1) the in-domain LM is augmented with web data, and (2) the LM is adapted to a userspecific vocabulary utilizing web data as an additional data source.", "labels": [], "entities": []}, {"text": "One hundred native speakers for each language were recorded reading held-out subsets of the indomain text data.", "labels": [], "entities": []}, {"text": "The speech data was partitioned into training and test sets, such that around one fourth of the speakers were reserved for testing.", "labels": [], "entities": []}, {"text": "We use a continuous speech recognizer optimized for low memory footprint and fast recognition ().", "labels": [], "entities": [{"text": "continuous speech recognizer", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.6721865733464559}]}, {"text": "The recognizer runs on a server (Core2 2.33 GHz) in about one fourth of real time.", "labels": [], "entities": []}, {"text": "The LM probabilities are quantized and precompiled together with the speaker-independent acoustic models (intra-word triphones) into a finite state transducer (FST).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Perplexities.  In the tables, the perplexity and word error rate reductions of the web mixtures are computed with  respect to the in-domain models of the same size, if such models exist; otherwise the comparison is  made to the largest in-domain model available.", "labels": [], "entities": [{"text": "word error rate reductions", "start_pos": 59, "end_pos": 85, "type": "METRIC", "confidence": 0.8674686998128891}]}, {"text": " Table 2: Word error rates [%].", "labels": [], "entities": [{"text": "Word error rates", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.7709346810976664}]}]}