{"title": [{"text": "A Comparison of Merging Strategies for Translation of German Compounds", "labels": [], "entities": [{"text": "Translation of German Compounds", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.8517778813838959}]}], "abstractContent": [{"text": "In this article, compound processing for translation into German in a factored statistical MT system is investigated.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7995842099189758}, {"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9071580171585083}]}, {"text": "Compounds are handled by splitting them prior to training, and merging the parts after translation.", "labels": [], "entities": []}, {"text": "I have explored eight merging strategies using different combinations of external knowledge sources, such as word lists, and internal sources that are carried through the translation process, such as symbols or parts-of-speech.", "labels": [], "entities": []}, {"text": "I show that for merging to be successful, some internal knowledge source is needed.", "labels": [], "entities": [{"text": "merging", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9777013063430786}]}, {"text": "I also show that an extra sequence model for part-of-speech is useful in order to improve the order of compound parts in the output.", "labels": [], "entities": []}, {"text": "The best merging results are achieved by a matching scheme for part-of-speech tags.", "labels": [], "entities": []}], "introductionContent": [{"text": "In German, as in many other languages, compounds are normally written as single words without spaces or other word boundaries.", "labels": [], "entities": []}, {"text": "Compounds can be binary, i.e., made up of two parts (1a), or have more parts (1b).", "labels": [], "entities": []}, {"text": "There are also coordinated compound constructions (1c).", "labels": [], "entities": []}, {"text": "Ina few cases compounds are written with a hyphen (1d), often when one of the parts is a proper name or an abbreviation.", "labels": [], "entities": []}, {"text": "German compounds can have English translations that are compounds, written as separate words (1a), other constructions, possibly with inserted function words and reordering (1b), or single words (1e).", "labels": [], "entities": []}, {"text": "Compound parts sometimes have special compound forms, formed by addition or truncations of letters, by umlaut or by a combination of these, as in, where the letter -s is added to the first part, Regierung.", "labels": [], "entities": []}, {"text": "For an overview of German compound forms, see.", "labels": [], "entities": []}, {"text": "Compounds are productive and common in German and other Germanic languages, which makes them problematic for many applications including statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 137, "end_pos": 168, "type": "TASK", "confidence": 0.7750489711761475}]}, {"text": "For translation into a compounding language, fewer compounds than in normal texts are often produced, which can be due to the fact that the desired compounds are missing in the training data, or that they have not been aligned correctly.", "labels": [], "entities": [{"text": "translation into a compounding language", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.6598455905914307}]}, {"text": "Where a compound is the idiomatic word choice in the translation, a MT system can instead produce separate words, genitive or other alternative constructions, or only translate one part of the compound.", "labels": [], "entities": [{"text": "MT", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.9809311032295227}]}, {"text": "The most common way to integrate compound processing into statistical machine translation is to split compounds prior to training and translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.6526460150877634}]}, {"text": "Splitting of compounds has received a lot of focus in the literature, both for machine translation, and targeted at other applications such as information retrieval or speech recognition.", "labels": [], "entities": [{"text": "Splitting of compounds", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9018582503000895}, {"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7282388657331467}, {"text": "information retrieval", "start_pos": 143, "end_pos": 164, "type": "TASK", "confidence": 0.7935290932655334}, {"text": "speech recognition", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.7716352343559265}]}, {"text": "When translating into a compounding language there is a need to merge the split compounds after translation.", "labels": [], "entities": []}, {"text": "In order to do this we have to identify which words that should be merged into compounds, which is complicated by the fact that the translation process is not guaranteed to produce translations where compound parts are kept together.", "labels": [], "entities": []}, {"text": "In this article I explore the effects of merging in a factored phrase-based statistical machine translation system.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 63, "end_pos": 107, "type": "TASK", "confidence": 0.640571117401123}]}, {"text": "The system uses part-of-speech as an output factor.", "labels": [], "entities": []}, {"text": "This factor is used as a knowledge source for merging and to improve word order by using a part-of-speech (POS) sequence model.", "labels": [], "entities": []}, {"text": "There are different knowledge sources for merging.", "labels": [], "entities": [{"text": "merging", "start_pos": 42, "end_pos": 49, "type": "TASK", "confidence": 0.9712578058242798}]}, {"text": "Some are external, such as frequency lists of words, compounds, and compound parts, that could be compiled at split-time.", "labels": [], "entities": []}, {"text": "It is also possible to have internal knowledge sources, that are carried through the translation process, such as symbols on compound parts, or part-of-speech tags.", "labels": [], "entities": []}, {"text": "Choices made at split-time influence which internal knowledge sources are available at mergetime.", "labels": [], "entities": []}, {"text": "I will explore and compare three markup schemes for compound parts, and eight merging algorithms that use different combinations of knowledge sources.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two types of evaluation are performed.", "labels": [], "entities": []}, {"text": "The influence of the different merging algorithms on the overall translation quality is evaluated, using two automatic metrics.", "labels": [], "entities": []}, {"text": "In addition the performance of the merging algorithms are analysed in some more detail.", "labels": [], "entities": []}, {"text": "In both cases the effect of the POS sequence model is also discussed.", "labels": [], "entities": []}, {"text": "Even when the POS sequence model is not used, part-of-speech is carried through the translation process, so that it can be used in the merging step.", "labels": [], "entities": []}, {"text": "Translations are evaluated on two automatic metrics: Bleu () and PER, position independent error-rate ().", "labels": [], "entities": [{"text": "Translations", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9554305076599121}, {"text": "Bleu", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.996589183807373}, {"text": "PER", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9948712587356567}]}, {"text": "Case-sensitive versions of the metrics are used.", "labels": [], "entities": []}, {"text": "PER does not consider word order, it evaluates the translation as a bag-of-word, and thus the systems without part-of-speech sequence models can be expected to do well on PER.", "labels": [], "entities": []}, {"text": "Note that PER is an error-rate, so lower scores are better, whereas higher scores are better for Bleu.", "labels": [], "entities": [{"text": "PER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9988014698028564}, {"text": "Bleu", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.8480472564697266}]}, {"text": "These metrics have disadvantages, for instance because the same weight is given to all tokens, both to complex compounds, and to function words such as und (and).", "labels": [], "entities": []}, {"text": "Bleu has been criticized, see e.g.. and 5 shows the translation results using the different merging algorithms.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.813210666179657}]}, {"text": "For the systems with POS sequence models the baseline performs slightly better on Bleu, than the best systems with merging.", "labels": [], "entities": [{"text": "baseline", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9759266972541809}, {"text": "Bleu", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.7051867246627808}]}, {"text": "Without the POS sequence model, however, merging often leads to improvements, by up to 0.48 Bleu points.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.982991099357605}]}, {"text": "For all systems it is advantageous to use the POS sequence model.", "labels": [], "entities": []}, {"text": "For the baseline, the PER scores are higher for the system without a POS sequence model, which, compared to the Bleu scores, confirms the fact that word order is improved by the sequence model.", "labels": [], "entities": [{"text": "PER", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.9961440563201904}]}, {"text": "The systems with merging are better than the baseline with the POS sequence model.", "labels": [], "entities": []}, {"text": "In all cases, however, the systems with merging performs worse when not using a POS sequence model, indicating that the part-of-speech    sequence model improves the order of compound parts.", "labels": [], "entities": []}, {"text": "When measured by PER, the best results when using merging are achieved by combining symbols and word lists, but when measured by Bleu, the POS-based algorithms are best.", "labels": [], "entities": []}, {"text": "The simpler symbol-based methods, often have similar scores, and in a few cases even better.", "labels": [], "entities": []}, {"text": "Adding treatment of coordinated compounds to the POS-match algorithm changes scores marginally in both directions.", "labels": [], "entities": []}, {"text": "The word list based methods, however, generally give bad results.", "labels": [], "entities": []}, {"text": "Using the head-pos restriction improves it somewhat and using a compound list instead of a word list gives different results in the different markup schemes, but is still worse than the best systems.", "labels": [], "entities": []}, {"text": "This shows that some kind of internal knowledge source, either symbols or part-of-speech, is needed in order for merging to be successful.", "labels": [], "entities": []}, {"text": "On both metrics, the marked and unmarked system perform similarly.", "labels": [], "entities": []}, {"text": "They are better than the sepmarked system on Bleu, but the sepmarked system is a lot better on PER, which is an indication of that word order is problematic in the sepmarked system, with its separate tokens to indicate compounds.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.9827484488487244}]}, {"text": "The results of the different merging algorithms are analysed to find the number of merges and the type and quality of the merges.", "labels": [], "entities": []}, {"text": "In addition I investigate the effect of using a part-of-speech model on the merging process.", "labels": [], "entities": []}, {"text": "shows the reduction of words 3 achieved by applying the different algorithms.", "labels": [], "entities": []}, {"text": "The word list based method produces the highest number of merges in all cases, performing many merges where the parts are not recognized as such by the system.", "labels": [], "entities": []}, {"text": "The number of merges is greatly reduced by the head-pos restriction.", "labels": [], "entities": []}, {"text": "An investigation of the output of the word list based method shows that it often merges common words that incidentally form anew word, such as bei (at) and der (the) to beider (both).", "labels": [], "entities": []}, {"text": "Another type of error is due to errors in the corpus, such as the merge of umwelt (environment) and und (and), which occurs in the corpus, but is not a correct German word.", "labels": [], "entities": []}, {"text": "These two error types are often prohibited by the headpos restrictions.", "labels": [], "entities": []}, {"text": "The compound list method avoids these errors, but it does not merge compounds that were not split by the splitting algorithm, due to a high frequency, giving a very low number of splits in some cases.", "labels": [], "entities": []}, {"text": "There are small differences between the POS-match and symbol algorithms.", "labels": [], "entities": []}, {"text": "Not using the POS sequence model results in a higher number of merges for all systems.", "labels": [], "entities": []}, {"text": "A more detailed analysis was performed of the with POS-model without    For the unmarked and sepmarked systems, the classification was based on the POS-match constraint, where parts are not merged if the POS-tags do not match.", "labels": [], "entities": []}, {"text": "POS-match cannot be used for the sepmarked scheme, which has standard POS-tags.", "labels": [], "entities": [{"text": "POS-match", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.6794494390487671}]}, {"text": "shows the results of this analysis.", "labels": [], "entities": []}, {"text": "The majority of the merged compounds are known from the training corpus for all systems.", "labels": [], "entities": []}, {"text": "There is a marked difference between the two systems that use POS-match, and the sepmarked system that does not.", "labels": [], "entities": [{"text": "POS-match", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.7481033802032471}]}, {"text": "The sepmarked system found the highest number of novel compounds, but also have the highest error rate for these, which shows that it is useful to match POS-tags.", "labels": [], "entities": [{"text": "error rate", "start_pos": 92, "end_pos": 102, "type": "METRIC", "confidence": 0.9855442345142365}]}, {"text": "The other two systems find fewer novel compounds, but also make fewer mistakes.", "labels": [], "entities": []}, {"text": "The marked system has more errors for single parts than the other systems, mainly beacuse the form of compound parts were not normalized.", "labels": [], "entities": []}, {"text": "Very few errors are due to reverse normalization.", "labels": [], "entities": []}, {"text": "In the unmarked system with a POS sequence model, there were only three such errors, which is better than the results on split data in Section 3.2.", "labels": [], "entities": []}, {"text": "Generally the percentage of bad parts or compounds is lower for the systems with a POS sequence model, which shows that the sequence model is useful for the ordering of compound parts.", "labels": [], "entities": []}, {"text": "The number of single compound parts is also much higher for the systems without a POS sequence model.", "labels": [], "entities": []}, {"text": "80% of the merged compounds in the unmarked system are binary, i.e., have two parts, and the highest number of parts in a compound is 5.", "labels": [], "entities": []}, {"text": "The pattern for the other systems is similar.", "labels": [], "entities": []}, {"text": "All systems produce fewer compounds than the 4472 in the German reference text.", "labels": [], "entities": [{"text": "German reference text", "start_pos": 57, "end_pos": 78, "type": "DATASET", "confidence": 0.8782610098520914}]}, {"text": "However, there might also be compounds in the output, that were not split and merged.", "labels": [], "entities": []}, {"text": "These numbers are not directly comparable to the baseline system, and applying the POS-based splitting algorithm to translation output would not give a fair comparison.", "labels": [], "entities": [{"text": "POS-based splitting", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.6457273960113525}]}, {"text": "An indication of the number of compounds in a text is the number of long words.", "labels": [], "entities": []}, {"text": "In the reference text there are 351 words with at least 20 characters, which will be used as the limit for long words.", "labels": [], "entities": []}, {"text": "A manual analysis showed that all these words are compounds.", "labels": [], "entities": []}, {"text": "The baseline system produces 209 long words.", "labels": [], "entities": []}, {"text": "The systems with merging, discussed above, all produce more long words than the baseline, but less than the reference, between 263 and 307, with the highest number in the marked system.", "labels": [], "entities": []}, {"text": "The trend is the same for the systems without a POS sequence model, but with slightly fewer long words than for the systems with merging.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of merging errors on the split reference corpus", "labels": [], "entities": [{"text": "Number of merging errors", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.7938326597213745}]}, {"text": " Table 4: Translation results for Bleu. Baseline with POS: 20.19, without POS: 19.66. Results that are  better than the baseline are marked with bold face.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8862780928611755}, {"text": "Bleu", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.9452629089355469}, {"text": "POS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9904738068580627}, {"text": "POS", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.960985004901886}]}, {"text": " Table 5: Translation results for PER. Baseline with POS: 27.22, without POS: 26.49. Results that are  better than the baseline are marked with bold face.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8916652798652649}, {"text": "PER", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.6106993556022644}, {"text": "POS", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9818889498710632}, {"text": "POS", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9293028712272644}]}, {"text": " Table 6: Reduction of number of words by using different merging algorithms", "labels": [], "entities": []}]}