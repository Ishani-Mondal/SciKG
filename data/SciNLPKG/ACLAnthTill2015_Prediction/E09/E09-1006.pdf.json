{"title": [], "abstractContent": [{"text": "The lack of positive results on supervised domain adaptation for WSD have cast some doubts on the utility of hand-tagging general corpora and thus developing generic supervised WSD systems.", "labels": [], "entities": [{"text": "supervised domain adaptation", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.6987767219543457}, {"text": "WSD", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9322333931922913}]}, {"text": "In this paper we show for the first time that our WSD system trained on a general source corpus (BNC) and the target corpus, obtains up to 22% error reduction when compared to a system trained on the target corpus alone.", "labels": [], "entities": [{"text": "WSD", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9103060960769653}, {"text": "error reduction", "start_pos": 143, "end_pos": 158, "type": "METRIC", "confidence": 0.9788301289081573}]}, {"text": "In addition, we show that as little as 40% of the target corpus (when supplemented with the source corpus) is sufficient to obtain the same results as training on the full target data.", "labels": [], "entities": []}, {"text": "The key for success is the use of unlabeled data with SVD, a combination of kernels and SVM.", "labels": [], "entities": []}], "introductionContent": [{"text": "In many Natural Language Processing (NLP) tasks we find that a large collection of manuallyannotated text is used to train and test supervised machine learning models.", "labels": [], "entities": []}, {"text": "While these models have been shown to perform very well when tested on the text collection related to the training data (what we call the source domain), the performance drops considerably when testing on text from other domains (called target domains).", "labels": [], "entities": []}, {"text": "In order to build models that perform well in new (target) domains we usually find two settings).", "labels": [], "entities": []}, {"text": "In the semi-supervised setting, the training hand-annotated text from the source domain is supplemented with unlabeled data from the target domain.", "labels": [], "entities": []}, {"text": "In the supervised setting, we use training data from both the source and target domains to test on the target domain.", "labels": [], "entities": []}, {"text": "In (Agirre and Lopez we studied semi-supervised Word Sense Disambiguation (WSD) adaptation, and in this paper we focus on supervised WSD adaptation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD) adaptation", "start_pos": 48, "end_pos": 90, "type": "TASK", "confidence": 0.7907450710024152}, {"text": "WSD adaptation", "start_pos": 133, "end_pos": 147, "type": "TASK", "confidence": 0.9412064850330353}]}, {"text": "We compare the performance of similar supervised WSD systems on three different scenarios.", "labels": [], "entities": [{"text": "WSD", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9653844833374023}]}, {"text": "In the source to target scenario the WSD system is trained on the source domain and tested on the target domain.", "labels": [], "entities": [{"text": "WSD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9263188242912292}]}, {"text": "In the target scenario the WSD system is trained and tested on the target domain (using cross-validation).", "labels": [], "entities": [{"text": "WSD", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9434308409690857}]}, {"text": "In the adaptation scenario the WSD system is trained on both source and target domain and tested in the target domain (also using cross-validation over the target data).", "labels": [], "entities": [{"text": "WSD", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9102335572242737}]}, {"text": "The source to target scenario represents a weak baseline for domain adaptation, as it does not use any examples from the target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7348553240299225}]}, {"text": "The target scenario represents the hard baseline, and in fact, if the domain adaptation scenario does not yield better results, the adaptation would have failed, as it would mean that the source examples are not useful when we do have hand-labeled target examples.", "labels": [], "entities": []}, {"text": "Previous work shows that current state-of-theart WSD systems are notable to obtain better results on the adaptation scenario compared to the target scenario (.", "labels": [], "entities": []}, {"text": "This would mean that if a user of a generic WSD system (i.e. based on hand-annotated examples from a generic corpus) would need to adapt it to a specific domain, he would be better off throwing away the generic examples and hand-tagging domain examples directly.", "labels": [], "entities": []}, {"text": "This paper will show that domain adaptation is feasible, even for difficult domainrelated words, in the sense that generic corpora can be reused when deploying WSD systems in specific domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.733484536409378}]}, {"text": "We will also show that, given the source corpus, our technique can save up to 60% of effort when tagging domain-related occurrences.", "labels": [], "entities": [{"text": "tagging domain-related occurrences", "start_pos": 97, "end_pos": 131, "type": "TASK", "confidence": 0.8415365815162659}]}, {"text": "We performed on a publicly available corpus which was designed to study the effect of domains in WSD ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.47981661558151245}]}, {"text": "It comprises 41 nouns which are highly relevant in the SPORTS and FINANCES domains, with 300 examples for each.", "labels": [], "entities": [{"text": "SPORTS", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.4214460849761963}, {"text": "FINANCES", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.8339036703109741}]}, {"text": "The use of two target domains strengthens the conclusions of this paper.", "labels": [], "entities": []}, {"text": "Our system uses Singular Value Decomposition (SVD) in order to find correlations between terms, which are helpful to overcome the scarcity of training data in WSD ().", "labels": [], "entities": []}, {"text": "This work explores how this ability of SVD and a combination of the resulting feature spaces improves domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7174106687307358}]}, {"text": "We present two ways to combine the reduced spaces: kernel combination with Support Vector Machines (SVM), and k Nearest-Neighbors (k-NN) combination.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews prior work in the area.", "labels": [], "entities": []}, {"text": "Section 3 presents the data sets used.", "labels": [], "entities": []}, {"text": "In Section 4 we describe the learning features, including the application of SVD, and in Section 5 the learning methods and the combination.", "labels": [], "entities": []}, {"text": "The experimental results are presented in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 presents the discussion and some analysis of this paper and finally Section 8 draws the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present the results in our two reference scenarios (source to target, target) and our reference scenario (domain adaptation).", "labels": [], "entities": []}, {"text": "Note that all methods presented here have full coverage, i.e. they return a sense for all test examples, and therefore precision equals recall, and suffices to compare among systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9993360638618469}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.999218225479126}]}], "tableCaptions": [{"text": " Table 1: Source to target results: Train on BNC,  test on SPORTS and FINANCES.", "labels": [], "entities": [{"text": "BNC", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.7529070377349854}, {"text": "SPORTS", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.7956488132476807}, {"text": "FINANCES", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9927281141281128}]}, {"text": " Table 2: Target results: train and test on SPORTS,  train and test on FINANCES, using 3-fold cross- validation.", "labels": [], "entities": [{"text": "SPORTS", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.6869484186172485}, {"text": "FINANCES", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9006553292274475}]}, {"text": " Table 3: Domain adaptation results: Train on  BNC and SPORTS, test on SPORTS (same for FI-", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8173109292984009}, {"text": "BNC", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.8546091914176941}, {"text": "FI", "start_pos": 88, "end_pos": 90, "type": "DATASET", "confidence": 0.49916204810142517}]}, {"text": " Table 4: The most important results in each sce- nario.", "labels": [], "entities": []}]}