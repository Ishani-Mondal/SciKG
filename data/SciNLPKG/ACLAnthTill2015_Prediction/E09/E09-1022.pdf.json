{"title": [{"text": "Learning to Interpret Utterances Using Dialogue History", "labels": [], "entities": [{"text": "Learning to Interpret Utterances", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6000717282295227}]}], "abstractContent": [{"text": "We describe a methodology for learning a disambiguation model for deep pragmatic interpretations in the context of situated task-oriented dialogue.", "labels": [], "entities": []}, {"text": "The system accumulates training examples for ambiguity resolution by tracking the fates of alternative interpretations across dialogue, including subsequent clarificatory episodes initiated by the system itself.", "labels": [], "entities": [{"text": "ambiguity resolution", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7491475045681}]}, {"text": "We illustrate with a case study building maximum entropy models over abductive interpretations in a referential communication task.", "labels": [], "entities": []}, {"text": "The resulting model correctly resolves 81% of ambiguities left unresolved by an initial handcrafted baseline.", "labels": [], "entities": []}, {"text": "A key innovation is that our method draws exclusively on a system's own skills and experience and requires no human annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "In dialogue, the basic problem of interpretation is to identify the contribution a speaker is making to the conversation.", "labels": [], "entities": []}, {"text": "There is much to recognize: the domain objects and properties the speaker is referring to; the kind of action that the speaker is performing; the presuppositions and implicatures that relate that action to the ongoing task.", "labels": [], "entities": []}, {"text": "Nevertheless, since the seminal work of, it has been possible to conceptualize pragmatic interpretation as a unified reasoning process that selects a representation of the speaker's contribution that is most preferred according to a background model of how speakers tend to behave.", "labels": [], "entities": []}, {"text": "In principle, the problem of pragmatic interpretation is qualitatively no different from the many problems that have been tackled successfully by data-driven models in NLP.", "labels": [], "entities": [{"text": "pragmatic interpretation", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7109752595424652}]}, {"text": "However, while researchers have shown that it is sometimes possible to annotate corpora that capture features of interpretation, to provide empirical support for theories, as in (), or to build classifiers that assist in dialogue reasoning, as in (Jordan and), it is rarely feasible to fully annotate the interpretations themselves.", "labels": [], "entities": []}, {"text": "The distinctions that must be encoded are subtle, theoretically-loaded and task-specific-and they are not always signaled unambiguously by the speaker.", "labels": [], "entities": []}, {"text": "See (), for example, for an overview of problems of vagueness, underspecification and ambiguity in reference annotation.", "labels": [], "entities": []}, {"text": "As an alternative to annotation, we argue here that dialogue systems can and should prepare their own training data by inference from underspecified models, which provide sets of candidate meanings, and from skilled engagement with their interlocutors, who know which meanings are right.", "labels": [], "entities": []}, {"text": "Our specific approach is based on contribution tracking, a framework which casts linguistic inference in situated, task-oriented dialogue in probabilistic terms.", "labels": [], "entities": [{"text": "contribution tracking", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.8189499974250793}]}, {"text": "In contribution tracking, ambiguous utterances may result in alternative possible contexts.", "labels": [], "entities": [{"text": "contribution tracking", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.9044623672962189}]}, {"text": "As subsequent utterances are interpreted in those contexts, ambiguities may ramify, cascade, or disappear, giving new insight into the pattern of activity that the interlocutor is engaged in.", "labels": [], "entities": []}, {"text": "For example, consider what happens if the system initiates clarification.", "labels": [], "entities": []}, {"text": "The interlocutor's answer may indicate not only what they mean now but also what they must have meant earlier when they used the original ambiguous utterance.", "labels": [], "entities": []}, {"text": "Contribution tracking allows a system to accumulate training examples for ambiguity resolution by tracking the fates of alternative interpretations across dialogue.", "labels": [], "entities": [{"text": "Contribution tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9320785403251648}, {"text": "ambiguity resolution", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.829720675945282}]}, {"text": "The system can use these examples to improve its models of pragmatic interpretation.", "labels": [], "entities": [{"text": "pragmatic interpretation", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.7721272110939026}]}, {"text": "To demonstrate the feasibility of this approach in realistic situations, we present a system that tracks contributions to a referential communication task using an abductive interpretation model: see Section 2.", "labels": [], "entities": []}, {"text": "A user study with this system, described in Section 3, shows that this system can, in the course of interacting with its users, discover the correct interpretations of many potentially ambiguous utterances.", "labels": [], "entities": []}, {"text": "The system thereby automatically acquires a body of training data in its native representations.", "labels": [], "entities": []}, {"text": "We use this data to build a maximum entropy model of pragmatic interpretation in our referential communication task.", "labels": [], "entities": []}, {"text": "After training, we correctly resolve 81% of the ambiguities left open in our handcrafted baseline.", "labels": [], "entities": []}], "datasetContent": [{"text": "We are generally interested in whether COREF's experience with previous subjects can be leveraged to improve its interactions with new subjects.", "labels": [], "entities": []}, {"text": "Therefore, to evaluate our approach, while making maximal use of our available data set, we performed a hold-one-subject-out cross-validation using our 20 human subjects H = {h 1 , ..., h 20 }.", "labels": [], "entities": []}, {"text": "That is, for each subject hi , we trained a model on the training examples associated with subjects H \\ {h i }, and then tested the model on the examples associated with subject hi . To quantify the performance of the learned model in comparison to our baseline, we adapt the mean reciprocal rank statistic commonly used for evaluation in information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 339, "end_pos": 360, "type": "TASK", "confidence": 0.7670929133892059}]}, {"text": "We expect that a system will use the probabilities calculated by a disambiguation model to decide which interpretations to pursue and how to follow them up through the most efficient interaction.", "labels": [], "entities": []}, {"text": "What matters is not the absolute probability of the correct interpretation but its rank with respect to competing interpretations.", "labels": [], "entities": []}, {"text": "Thus, we consider each utterance as a query; the disambiguation model produces a ranked list of responses for this query (candidate interpretations), ordered by probability.", "labels": [], "entities": []}, {"text": "We find the rank r of the correct interpretation in this list and measure the outcome of the query as 1 r . Because of its weak assumptions, our baseline disambiguation model actually leaves many ties.", "labels": [], "entities": []}, {"text": "So in fact we must compute an expected reciprocal rank (ERR) statistic that averages 1 rover all ways of ordering the correct interpretation against competitors of equal probability.", "labels": [], "entities": [{"text": "expected reciprocal rank (ERR)", "start_pos": 30, "end_pos": 60, "type": "METRIC", "confidence": 0.7843251178661982}]}, {"text": "shows a histogram of ERR across", "labels": [], "entities": [{"text": "ERR", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.7499643564224243}]}], "tableCaptions": []}