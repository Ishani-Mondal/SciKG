{"title": [{"text": "Cube Summing, Approximate Inference with Non-Local Features, and Dynamic Programming without Semirings", "labels": [], "entities": [{"text": "Cube Summing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7599682211875916}]}], "abstractContent": [{"text": "We introduce cube summing, a technique that permits dynamic programming algorithms for summing over structures (like the forward and inside algorithms) to be extended with non-local features that violate the classical structural independence assumptions.", "labels": [], "entities": [{"text": "cube summing", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.7174514830112457}, {"text": "summing over structures", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.8809646765391032}]}, {"text": "It is inspired by cube pruning (Chiang, 2007; Huang and Chiang, 2007) in its computation of non-local features dynamically using scored k-best lists, but also maintains additional residual quantities used in calculating approximate marginals.", "labels": [], "entities": []}, {"text": "When restricted to local features, cube summing reduces to a novel semiring (k-best+residual) that generalizes many of the semirings of Good-man (1999).", "labels": [], "entities": [{"text": "cube summing", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.7147756218910217}]}, {"text": "When non-local features are included, cube summing does not reduce to any semiring, but is compatible with generic techniques for solving dynamic programming equations.", "labels": [], "entities": [{"text": "cube summing", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.7261779606342316}]}], "introductionContent": [{"text": "Probabilistic NLP researchers frequently make independence assumptions to keep inference algorithms tractable.", "labels": [], "entities": []}, {"text": "Doing so limits the features that are available to our models, requiring features to be structurally local.", "labels": [], "entities": []}, {"text": "Yet many problems in NLP-machine translation, parsing, named-entity recognition, and others-have benefited from the addition of non-local features that break classical independence assumptions.", "labels": [], "entities": [{"text": "NLP-machine translation", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.9329873621463776}, {"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9575961232185364}, {"text": "named-entity recognition", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.6996717303991318}]}, {"text": "Doing so has required algorithms for approximate inference.", "labels": [], "entities": [{"text": "approximate inference", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7898586988449097}]}, {"text": "Recently cube pruning) was proposed as away to leverage existing dynamic programming algorithms that find optimal-scoring derivations or structures when only local features are involved.", "labels": [], "entities": []}, {"text": "Cube pruning permits approximate decoding with non-local features, but leaves open the question of how the feature weights or probabilities are learned.", "labels": [], "entities": []}, {"text": "Meanwhile, some learning algorithms, like maximum likelihood for conditional log-linear models), unsupervised models (, and models with hidden variables (, require summing over the scores of many structures to calculate marginals.", "labels": [], "entities": []}, {"text": "We first review the semiring-weighted logic programming view of dynamic programming algorithms and identify an intuitive property of a program called proof locality that follows from feature locality in the underlying probability model ( \u00a72).", "labels": [], "entities": []}, {"text": "We then provide an analysis of cube pruning as an approximation to the intractable problem of exact optimization over structures with non-local features and show how the use of non-local features with k-best lists breaks certain semiring properties ( \u00a73).", "labels": [], "entities": []}, {"text": "The primary contribution of this paper is a novel techniquecube summing-for approximate summing over discrete structures with non-local features, which we relate to cube pruning ( \u00a74).", "labels": [], "entities": [{"text": "summing-for approximate summing", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.7626643578211466}]}, {"text": "We discuss implementation ( \u00a75) and show that cube summing becomes exact and expressible as a semiring when restricted to local features; this semiring generalizes many commonly-used semirings in dynamic programming ( \u00a76).", "labels": [], "entities": [{"text": "cube summing", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.6751266717910767}]}], "datasetContent": [], "tableCaptions": []}