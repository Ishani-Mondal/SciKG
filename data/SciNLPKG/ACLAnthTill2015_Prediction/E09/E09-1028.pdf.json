{"title": [{"text": "Effects of Word Confusion Networks on Voice Search", "labels": [], "entities": [{"text": "Voice Search", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.7057688534259796}]}], "abstractContent": [{"text": "Mobile voice-enabled search is emerging as one of the most popular applications abetted by the exponential growth in the number of mobile devices.", "labels": [], "entities": [{"text": "Mobile voice-enabled search", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6480836073557535}]}, {"text": "The automatic speech recognition (ASR) output of the voice query is parsed into several fields.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR) output", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.8023371696472168}]}, {"text": "Search is then performed on a text corpus or a database.", "labels": [], "entities": []}, {"text": "In order to improve the ro-bustness of the query parser to noise in the ASR output, in this paper, we investigate two different methods to query parsing.", "labels": [], "entities": [{"text": "query parser", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.6712852716445923}, {"text": "ASR", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.8962266445159912}, {"text": "query parsing", "start_pos": 139, "end_pos": 152, "type": "TASK", "confidence": 0.8215749859809875}]}, {"text": "Both methods exploit multiple hypotheses from ASR, in the form of word confusion networks, in order to achieve tighter coupling between ASR and query parsing and improved accuracy of the query parser.", "labels": [], "entities": [{"text": "ASR", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9205405712127686}, {"text": "ASR", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.9274792075157166}, {"text": "query parsing", "start_pos": 144, "end_pos": 157, "type": "TASK", "confidence": 0.6609751582145691}, {"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9985575079917908}]}, {"text": "We also investigate the results of this improvement on search accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9837468266487122}]}, {"text": "Word confusion-network based query parsing outperforms ASR 1-best based query-parsing by 2.7% absolute and the search performance improves by 1.8% absolute on one of our data sets.", "labels": [], "entities": [{"text": "Word confusion-network based query parsing", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7113638758659363}, {"text": "ASR 1-best", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.8638459146022797}]}], "introductionContent": [{"text": "Local search specializes in serving geographically constrained search queries on a structured database of local business listings.", "labels": [], "entities": []}, {"text": "Most textbased local search engines provide two text fields: the \"SearchTerm\" (e.g. Best Chinese Restaurant) and the \"LocationTerm\" (e.g. a city, state, street address, neighborhood etc.).", "labels": [], "entities": []}, {"text": "Most voiceenabled local search dialog systems mimic this two-field approach and employ a two-turn dialog strategy.", "labels": [], "entities": []}, {"text": "The dialog system solicits from the user a LocationTerm in the first turn followed by a SearchTerm in the second turn (.", "labels": [], "entities": []}, {"text": "Although the two-field interface has been widely accepted, it has several limitations for mobile voice search.", "labels": [], "entities": [{"text": "mobile voice search", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.6491074860095978}]}, {"text": "First, most mobile devices are location-aware which obviates the need to specify the LocationTerm.", "labels": [], "entities": []}, {"text": "Second, it's not always straightforward for users to be aware of the distinction between these two fields.", "labels": [], "entities": []}, {"text": "It is common for users to specify location information in the SearchTerm field.", "labels": [], "entities": []}, {"text": "For example, \"restaurants near Manhattan\" for SearchTerm and \"NY NY\" for LocationTerm.", "labels": [], "entities": []}, {"text": "For voice-based search, it is more natural for users to specify queries in a single utterance . Finally, many queries often contain other constraints (assuming LocationTerm is a constraint) such as that deliver in restaurants that deliver or open 24 hours in night clubs open 24 hours.", "labels": [], "entities": []}, {"text": "It would be very cumbersome to enumerate each constraint as a different text field or a dialog turn.", "labels": [], "entities": []}, {"text": "An interface that allows for specifying constraints in a natural language utterance would be most convenient.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a voice-based search system that allows users to specify search requests in a single natural language utterance.", "labels": [], "entities": []}, {"text": "The output of ASR is then parsed by a query parser into three fields: LocationTerm, SearchTerm, and Filler.", "labels": [], "entities": [{"text": "ASR", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8781881928443909}]}, {"text": "We use a local search engine, http://www.yellowpages.com/, which accepts the SearchTerm and LocationTerm as two query fields and returns the search results from a business listings database.", "labels": [], "entities": []}, {"text": "We present two methods for parsing the voice query into different fields with particular emphasis on exploiting the ASR output beyond the 1-best hypothesis.", "labels": [], "entities": [{"text": "parsing the voice query", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.8270522654056549}, {"text": "ASR", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.8853675723075867}]}, {"text": "We demonstrate that by parsing word confusion networks, the accuracy of the query parser can be improved.", "labels": [], "entities": [{"text": "parsing word confusion", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8667507767677307}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9994372725486755}]}, {"text": "We further investigate the effect of this improvement on the search task and demonstrate the benefit of tighter coupling of ASR and the query parser on search accuracy.", "labels": [], "entities": [{"text": "ASR", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.6583684086799622}, {"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9881772398948669}]}, {"text": "The paper outline is as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss some of the related threads of research relevant for our task.", "labels": [], "entities": []}, {"text": "In Section 3, we motivate the need fora query parsing module in voice-based search systems.", "labels": [], "entities": [{"text": "query parsing", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.7108054757118225}]}, {"text": "We present two different query parsing models in Section 4 and Section 5 and discuss experimental results in Section 6.", "labels": [], "entities": [{"text": "query parsing", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.7063941955566406}]}, {"text": "We summarize our results in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have access to text query logs consisting of 18 million queries to the two text fields: SearchTerm and LocationTerm.", "labels": [], "entities": []}, {"text": "In addition to these logs, we have access to 11 million unique business listing names and their addresses.", "labels": [], "entities": []}, {"text": "We use the combined data to train the parameters of the two parsing models as discussed in the previous sections.", "labels": [], "entities": []}, {"text": "We tested our approaches on three data sets, which in total include 2686 speech queries.", "labels": [], "entities": []}, {"text": "These queries were collected from users using mobile devices from different time periods.", "labels": [], "entities": []}, {"text": "Labelers transcribed and annotated the test data using SearchTerm and LocationTerm tags.", "labels": [], "entities": []}, {"text": "We use an ASR with a trigram-based language model trained on the query logs.", "labels": [], "entities": []}, {"text": "shows the ASR word accuracies on the three data sets.", "labels": [], "entities": [{"text": "ASR word accuracies", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.6148504813512167}]}, {"text": "The accuracy is the lowest on Test1, in which many users were non-native English speakers and a large percentage of queries are not intended for local search.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999650239944458}, {"text": "Test1", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.9267725944519043}]}], "tableCaptions": [{"text": " Table 2: ASR Performance on three Data Sets", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9417027235031128}]}, {"text": " Table 3: Parsing performance using the PARIS approach", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9562242031097412}, {"text": "PARIS", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.5366379022598267}]}, {"text": " Table 4: Parsing performance using the FST approach", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9616628289222717}, {"text": "FST", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.7654291391372681}]}, {"text": " Table 5: Search performances using the PARIS ap- proach", "labels": [], "entities": [{"text": "PARIS ap- proach", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.6794677525758743}]}, {"text": " Table 6: Search performances using the FST ap- proach", "labels": [], "entities": [{"text": "FST ap- proach", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.7768154889345169}]}]}