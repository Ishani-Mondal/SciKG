{"title": [{"text": "Inference Rules and their Application to Recognizing Textual Entailment", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.8729143738746643}]}], "abstractContent": [{"text": "In this paper, we explore ways of improving an inference rule collection and its application to the task of recognizing textual entailment.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 108, "end_pos": 138, "type": "TASK", "confidence": 0.8059467077255249}]}, {"text": "For this purpose, we start with an automatically acquired collection and we propose methods to refine it and obtain more rules using a hand-crafted lexical resource.", "labels": [], "entities": []}, {"text": "Following this, we derive a dependency-based structure representation from texts, which aims to provide a proper base for the inference rule application.", "labels": [], "entities": []}, {"text": "The evaluation of our approach on the recognizing textual entailment data shows promising results on precision and the error analysis suggests possible improvements .", "labels": [], "entities": [{"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9996004700660706}]}], "introductionContent": [{"text": "Textual inference plays an important role in many natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "Textual inference", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7644073367118835}]}, {"text": "In recent years, the recognizing textual entailment (RTE) () challenge, which focuses on detecting semantic inference, has attracted a lot of attention.", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE)", "start_pos": 21, "end_pos": 57, "type": "TASK", "confidence": 0.8243371546268463}, {"text": "detecting semantic inference", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.8252934813499451}]}, {"text": "Given a text T (several sentences) and a hypothesis H (one sentence), the goal is to detect if H can be inferred from T.", "labels": [], "entities": []}, {"text": "Studies such as attest that lexical substitution (e.g. synonyms, antonyms) or simple syntactic variation account for the entailment only in a small number of pairs.", "labels": [], "entities": []}, {"text": "Thus, one essential issue is to identify more complex expressions which, inappropriate contexts, convey the same (or similar) meaning.", "labels": [], "entities": []}, {"text": "However, more generally, we are also interested in pairs of expressions in which only a uni-directional inference relation holds . A typical example is the following RTE pair in which accelerate to in H is used as an alternative formulation for reach speed of in T.", "labels": [], "entities": []}, {"text": "T: The high-speed train, scheduled fora trial run on Tuesday, is able to reach a maximum speed of up to 430 kilometers per hour, or 119 meters per second.", "labels": [], "entities": [{"text": "T", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9844741821289062}]}], "datasetContent": [{"text": "Our experiments consist in predicting positive entailment in a very straightforward rule-based manner summarizes the results using three different rule collections).", "labels": [], "entities": [{"text": "predicting positive entailment", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.85600479443868}]}, {"text": "For each collection we select the RTE pairs in which we find a tree skeleton and match an inference rule.", "labels": [], "entities": []}, {"text": "The first number in our table entries represents how many of such pairs we have identified, out the 1600 of development and test pairs.", "labels": [], "entities": []}, {"text": "For these pairs we simply predict positive entailment and the second entry represents what percentage of these pairs are indeed positive entailment.", "labels": [], "entities": []}, {"text": "Our work does not focus on building a complete RTE system; however, we also combine our method with a bag of words baseline to seethe effects on the whole data set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Coverage/precision with various rule collections", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9974586367607117}]}, {"text": " Table 5: Precision on the covered RTE data", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9848222732543945}, {"text": "covered RTE data", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.7079207201798757}]}, {"text": " Table 6: Precision on full RTE data", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8758909106254578}]}]}