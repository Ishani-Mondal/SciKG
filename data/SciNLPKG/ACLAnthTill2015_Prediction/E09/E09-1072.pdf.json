{"title": [], "abstractContent": [{"text": "This article presents empirical evaluations of aspects of annotation for the linguistic property of animacy in Swedish, ranging from manual human annotation, automatic classification and, finally, an external evaluation in the task of syntactic parsing.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 158, "end_pos": 182, "type": "TASK", "confidence": 0.6627099812030792}, {"text": "syntactic parsing", "start_pos": 235, "end_pos": 252, "type": "TASK", "confidence": 0.7732772529125214}]}, {"text": "We show that a treatment of animacy as a lexical semantic property of noun types enables generalization over distri-butional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-the-art baseline parser with gold standard ani-macy information.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 178, "end_pos": 202, "type": "TASK", "confidence": 0.689073920249939}, {"text": "parsing", "start_pos": 262, "end_pos": 269, "type": "TASK", "confidence": 0.9585661292076111}, {"text": "accuracy", "start_pos": 270, "end_pos": 278, "type": "METRIC", "confidence": 0.9182252287864685}]}], "introductionContent": [{"text": "The property of animacy influences linguistic phenomena in a range of different languages, such as case marking and argument realization (, and has been shown to constitute an important factor in the production and comprehension of syntactic structure.", "labels": [], "entities": [{"text": "case marking", "start_pos": 99, "end_pos": 111, "type": "TASK", "confidence": 0.7121903598308563}, {"text": "argument realization", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.7404201179742813}]}, {"text": "In computational linguistic work, animacy has been shown to provide important information in anaphora resolution, argument disambiguation (Dell') and syntactic parsing in general.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7234353423118591}, {"text": "argument disambiguation", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.7230247557163239}, {"text": "syntactic parsing", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.7772686779499054}]}, {"text": "The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, however, other distinctions are also relevant and the animacy dimension is often viewed as a continuum ranging from humans to inanimate objects.", "labels": [], "entities": []}, {"text": "Following several animacy hierarchies have been proposed in typological studies, focusing on the linguistic category of animacy, i.e., the distinctions which are relevant for linguistic phenomena.", "labels": [], "entities": []}, {"text": "An example of an animacy hierarchy, taken from, is provided in (1): (1) Human > Animate > Inanimate Clearly, non-human animates, like animals, are not less animate than humans in a biological sense, however, humans and animals show differing linguistic behaviour.", "labels": [], "entities": []}, {"text": "Empirical studies of animacy require human annotation efforts, and, in particular, a well-defined annotation task.", "labels": [], "entities": []}, {"text": "However, annotation studies of animacy differ distinctly in their treatment of animacy as a type or token-level phenomenon, as well as in terms of granularity of categories.", "labels": [], "entities": []}, {"text": "The use of the annotated data as a computational resource furthermore poses requirements on the annotation which do not necessarily agree with more theoretical considerations.", "labels": [], "entities": []}, {"text": "Methods for the induction of animacy information for use in practical applications require the resolution of issues of level of representation, as well as granularity.", "labels": [], "entities": [{"text": "induction of animacy information", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.8366079330444336}]}, {"text": "This article addresses these issues through empirical and experimental evaluation.", "labels": [], "entities": []}, {"text": "We present an in-depth study of a manually annotated data set which indicates that animacy maybe treated as a lexical semantic property at the type level.", "labels": [], "entities": []}, {"text": "We then evaluate this proposal through supervised machine learning of animacy information and focus on an in-depth error analysis of the resulting classifier, addressing issues of granularity of the animacy dimension.", "labels": [], "entities": []}, {"text": "Finally, the automatically an-notated data set is employed in order to train a syntactic parser and we investigate the effect of the animacy information and contrast the automatically acquired features with gold standard ones.", "labels": [], "entities": []}, {"text": "The rest of the article is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2, we briefly discuss annotation schemes for animacy, the annotation strategies and categories proposed there.", "labels": [], "entities": []}, {"text": "We goon to describe annotation for the binary distinction of 'human reference' found in a Swedish dependency treebank in section 3 and we perform an evaluation of the consistency of the human annotation in terms of linguistic level.", "labels": [], "entities": [{"text": "Swedish dependency treebank", "start_pos": 90, "end_pos": 117, "type": "DATASET", "confidence": 0.7683747013409933}]}, {"text": "In section 4, we present experiments in lexical acquisition of animacy based on morphosyntactic features extracted from a considerably larger corpus.", "labels": [], "entities": [{"text": "lexical acquisition of animacy", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.7794783860445023}]}, {"text": "Section 5 presents experiments with the acquired animacy information applied in the data-driven dependency parsing of Swedish.", "labels": [], "entities": [{"text": "dependency parsing of Swedish", "start_pos": 96, "end_pos": 125, "type": "TASK", "confidence": 0.6916581988334656}]}, {"text": "Finally, section 6 concludes the article and provides some suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the freely available MaltParser system, which is a language-independent system for datadriven dependency parsing.", "labels": [], "entities": [{"text": "datadriven dependency parsing", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.639624814192454}]}, {"text": "A set of parsers are trained on Talbanken05, both with and without additional animacy information, the origin of which is either the manual annotation described in section 3 or the automatic animacy classifier described in section 4.2-4.4 (MBL).", "labels": [], "entities": [{"text": "Talbanken05", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.9295288920402527}]}, {"text": "The common nouns in the treebank are classified for animacy using leaveone-out training and testing.", "labels": [], "entities": []}, {"text": "This ensures that the training and test instances are disjoint at all times.", "labels": [], "entities": []}, {"text": "Moreover, the fact that the distributional data is taken from a separate data set ensures noncircularity since we are not basing the classification on gold standard parses.", "labels": [], "entities": []}, {"text": "All parsing experiments are performed using 10-fold cross-validation for training and testing on the entire written part of Talbanken05.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9605907201766968}, {"text": "written part of Talbanken05", "start_pos": 108, "end_pos": 135, "type": "DATASET", "confidence": 0.6772526949644089}]}, {"text": "Overall parsing accuracy will be reported using the standard metrics of labeled attachment score (LAS) and unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "parsing", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.9653013944625854}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9714697003364563}, {"text": "labeled attachment score (LAS)", "start_pos": 72, "end_pos": 102, "type": "METRIC", "confidence": 0.822519987821579}, {"text": "unlabeled attachment score (UAS)", "start_pos": 107, "end_pos": 139, "type": "METRIC", "confidence": 0.8048095256090164}]}, {"text": "Statistical significance is checked using Dan Bikel's randomized parsing evaluation comparator.", "labels": [], "entities": [{"text": "significance", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.66936856508255}]}, {"text": "As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Buchholz The SVM-classifiers generally show slightly lower results, however, only performance on the >1000 data set is significantly lower (p<.05).", "labels": [], "entities": []}, {"text": "13 LAS and UAS report the percentage of tokens that are assigned the correct head with (labeled) or without (unlabeled) the correct dependency label.), where this parser was the best performing parser for Swedish.", "labels": [], "entities": [{"text": "UAS", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.8523125648498535}]}], "tableCaptions": [{"text": " Table 1: The animacy data set from Talbanken05;  number of noun lemmas (Types) and tokens in  each class.", "labels": [], "entities": [{"text": "animacy data set from Talbanken05", "start_pos": 14, "end_pos": 47, "type": "DATASET", "confidence": 0.6588880300521851}]}, {"text": " Table 2: Accuracy for MBL and SVM classifiers  on Talbanken05 nouns in accumulated frequency  bins by Parole frequency.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9972319006919861}, {"text": "Talbanken05 nouns", "start_pos": 51, "end_pos": 68, "type": "DATASET", "confidence": 0.8796591758728027}]}, {"text": " Table 3: Precision, recall and F-scores for the two classes in MBL-experiments with a general feature  space.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9990614056587219}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9984532594680786}, {"text": "F-scores", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9969272017478943}, {"text": "MBL-experiments", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.7835683226585388}]}, {"text": " Table 5: Overall results in experiments with au- tomatic features compared to gold standard fea- tures, expressed as unlabeled and labeled attach- ment scores.", "labels": [], "entities": []}]}