{"title": [{"text": "Speech emotion recognition with TGI+.2 classifier", "labels": [], "entities": [{"text": "Speech emotion recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7623865207036337}]}], "abstractContent": [{"text": "We have adapted a classification approach coming from optical character recognition research to the task of speech emotion recognition.", "labels": [], "entities": [{"text": "optical character recognition", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.6604798237482706}, {"text": "speech emotion recognition", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.7605442802111307}]}, {"text": "The classification approach enjoys the representational power of a syntactic method and efficiency of statistical classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.964749276638031}, {"text": "statistical classification", "start_pos": 102, "end_pos": 128, "type": "TASK", "confidence": 0.8203482329845428}]}, {"text": "The syntactic part implements a tree grammar inference algorithm.", "labels": [], "entities": []}, {"text": "We have extended this part of the algorithm with various edit costs to pe-nalise more important features with higher edit costs for being outside the interval, which tree automata learned at the inference stage.", "labels": [], "entities": []}, {"text": "The statistical part implements an entropy based decision tree (C4.5).", "labels": [], "entities": []}, {"text": "We did the testing on the Berlin database of emotional speech.", "labels": [], "entities": [{"text": "Berlin database of emotional speech", "start_pos": 26, "end_pos": 61, "type": "DATASET", "confidence": 0.9475231409072876}]}, {"text": "Our classifier outper-forms the state of the art classifier (Multi-layer Perceptron) by 4.68% and a baseline (C4.5) by 26.58%, which proves validity of the approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina number of applications such as humancomputer interfaces, smart call centres, etc.", "labels": [], "entities": []}, {"text": "it is important to be able to recognise people's emotional state.", "labels": [], "entities": []}, {"text": "An aim of a speech emotion recognition (SER) engine is to produce an estimate of the emotional state of the speaker given a speech fragment as an input.", "labels": [], "entities": [{"text": "speech emotion recognition (SER)", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.7956488281488419}]}, {"text": "The standard way to do SER is through a supervised machine learning procedure (.", "labels": [], "entities": [{"text": "SER", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9940127730369568}]}, {"text": "It also should be noted that a number of alternative classification strategies has been offered recently, such as unsupervised learning ( and numeric regression () etc, and which are preferable under certain conditions.", "labels": [], "entities": []}, {"text": "Our contribution is anew algorithm of a mixed design with syntactic and statistical learning, which we borrowed from optical character recognition (Sempere,, extended, and adapted for SER.", "labels": [], "entities": [{"text": "optical character recognition", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.6261193553606669}, {"text": "SER", "start_pos": 184, "end_pos": 187, "type": "TASK", "confidence": 0.9084457159042358}]}, {"text": "The syntactic part implements tree grammar inference, and the statistical part implements C4.5.", "labels": [], "entities": []}, {"text": "The intuitive reasons underlying this solution are as follows.", "labels": [], "entities": []}, {"text": "We would like to have a classification approach that enjoys the representational power of a syntactic method and efficiency of statistical classification.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 127, "end_pos": 153, "type": "TASK", "confidence": 0.8000724017620087}]}, {"text": "First we model the objects by means of a syntactic method, i.e. we map samples into their representations.", "labels": [], "entities": []}, {"text": "A representation of a sample is a set of seven numeric values, signifying to which degree a given sample resembles the averaged pattern of each of seven classes.", "labels": [], "entities": []}, {"text": "Second, we learn to classify the mappings of samples, rather than feature vectors of samples, with a powerful statistical method.", "labels": [], "entities": []}, {"text": "We called the classifier TGI+, which stands for Tree Grammar Inference and the plus is for the statistical learning enhancement.", "labels": [], "entities": []}, {"text": "In this paper we present the second version of TGI+, which extends TGI+.1 ( and the difference is that we have added various edit costs to penalise more important features with higher edit costs for being outside the interval, which tree automata learned at the inference stage.", "labels": [], "entities": []}, {"text": "We evaluated TGI+ against a state of the art classifier.", "labels": [], "entities": []}, {"text": "To obtain a state of the art performance, we constructed a speech emotion recogniser, following the classical supervised learning approach with atop performer out of more than 20 classifiers from the weka package, which turned out to be multilayer perceptron (MLP)).", "labels": [], "entities": [{"text": "speech emotion recogniser", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6421469151973724}]}, {"text": "Experimental results showed that TGI+ outperforms MLP by 4.68%.", "labels": [], "entities": [{"text": "TGI", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.7368701100349426}, {"text": "MLP", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.4900625944137573}]}, {"text": "The structure of this paper is as follows: in this section below we explain construction of a classical speech emotion recognizer, in Section 2 we explain TGI+; Section 3 reports testing results for both, the state of the art recogniser and TGI+.", "labels": [], "entities": [{"text": "speech emotion recognizer", "start_pos": 104, "end_pos": 129, "type": "TASK", "confidence": 0.6902827819188436}]}, {"text": "Section 4 and 5 is discussion and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We did the testing on acted emotional speech from the Berlin database).", "labels": [], "entities": [{"text": "Berlin database", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9482413530349731}]}, {"text": "Although acted material has a number of well known drawbacks, it was used to establish a proof of concept for the methodology proposed and is a benchmark database for SER.", "labels": [], "entities": [{"text": "SER", "start_pos": 167, "end_pos": 170, "type": "TASK", "confidence": 0.934681236743927}]}, {"text": "In the future work we plan to do the testing on real emotions.", "labels": [], "entities": []}, {"text": "The Berlin Emotional Database (EMO-DB) contains the set of emotions from the MPEG-4 standard (anger, joy, disgust, fear, sadness, surprise and neutral).", "labels": [], "entities": [{"text": "Berlin Emotional Database (EMO-DB)", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.9221317370732626}]}, {"text": "Ten German sentences of emotionally undefined content have been acted in these emotions by ten professional actors, five of them female.", "labels": [], "entities": []}, {"text": "Throughout perception tests by twenty human listeners 488 phrases have been chosen that were classified as more than 60% natural and more than 80% clearly assignable.", "labels": [], "entities": []}, {"text": "The database is recorded in 16 bit, 16 kHz under studio noise conditions.", "labels": [], "entities": []}, {"text": "As for the testing protocol, 10-fold crossvalidation was used.", "labels": [], "entities": []}, {"text": "Recall, precision and F measure per class are given in.1 and 4.2 for C4.5, MLP and TGI+, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9997562766075134}, {"text": "F measure", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9874108731746674}, {"text": "MLP", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.5543022751808167}]}, {"text": "The overall accuracy of MLP, the state of the art recogniser, is 73.9% and the overall accuracy of the TGI+ based recogniser is 78.58%, which is a 4.68% \u00b1 3.45% in favour of TGI+.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9996722936630249}, {"text": "MLP", "start_pos": 24, "end_pos": 27, "type": "DATASET", "confidence": 0.5845823287963867}, {"text": "recogniser", "start_pos": 50, "end_pos": 60, "type": "TASK", "confidence": 0.9617273211479187}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9994285702705383}, {"text": "TGI+ based recogniser", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.5551029443740845}]}, {"text": "The confidence interval was calculated as follows: , where p is accuracy, n is cardinality of the data set, and Z is a constant for the confidence level of 95%, i.e. Z = 1.96.", "labels": [], "entities": [{"text": "confidence interval", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.9736389815807343}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9994953870773315}]}, {"text": "The proposed TGI+ has also been evaluated against C4.5 to find out which is the contribution of moving from the feature vector representation of samples to the distance to automata one.", "labels": [], "entities": []}, {"text": "C4.5 performs with 52.9% of acuracy, which is 25.68% less than TGI+.", "labels": [], "entities": [{"text": "acuracy", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9724552631378174}]}, {"text": "The positive outcome of such contrastive testing in favour of TGI+ was expected, because TGI+ was designed to enjoy strengths of two paradigms: syntactic and statistical, while MLP (or C4.5) is a powerful single paradigm statistical method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Baseline recognition with C4.5 on the  Berlin emotional database. The overall accuracy is  52.9%, which is 25.68% less accurate than TGI+.", "labels": [], "entities": [{"text": "Baseline recognition", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.6549734622240067}, {"text": "Berlin emotional database", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.9425998330116272}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9995517134666443}]}, {"text": " Table 2: State of the art recognition with MLP on  the Berlin emotional database. The overall accu- racy is 73.9%, which is 4.68% less accurate than  TGI+.", "labels": [], "entities": [{"text": "Berlin emotional database", "start_pos": 56, "end_pos": 81, "type": "DATASET", "confidence": 0.9386459390322367}, {"text": "accu- racy", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9668866594632467}, {"text": "accurate", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.981919527053833}]}, {"text": " Table 3: Performance of the TGI+ based emotion  recognizer on the Berlin emotional database. The  overall accuracy is 78.58%.", "labels": [], "entities": [{"text": "TGI+ based emotion  recognizer", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.5418329417705536}, {"text": "Berlin emotional database", "start_pos": 67, "end_pos": 92, "type": "DATASET", "confidence": 0.928835411866506}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9995681643486023}]}]}