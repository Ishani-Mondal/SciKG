{"title": [{"text": "Combining a Statistical Language Model with Logistic Regression to Predict the Lexical and Syntactic Difficulty of Texts for FFL", "labels": [], "entities": [{"text": "FFL", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.8423526287078857}]}], "abstractContent": [{"text": "Reading is known to bean essential task in language learning, but finding the appropriate text for every learner is far from easy.", "labels": [], "entities": [{"text": "language learning", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7696904838085175}]}, {"text": "In this context, automatic procedures can support the teacher's work.", "labels": [], "entities": []}, {"text": "Some tools exist for English, but at present there are none for French as a foreign language (FFL).", "labels": [], "entities": [{"text": "French as a foreign language (FFL)", "start_pos": 64, "end_pos": 98, "type": "TASK", "confidence": 0.6782697029411793}]}, {"text": "In this paper, we present an original approach to assessing the readability of FFL texts using NLP techniques and extracts from FFL textbooks as our corpus.", "labels": [], "entities": []}, {"text": "Two logistic regression models based on lexical and grammatical features are explored and give quite good predictions on new texts.", "labels": [], "entities": []}, {"text": "The results shows a slight superiority for multinomial logistic regression over the proportional odds model.", "labels": [], "entities": []}], "introductionContent": [{"text": "The current massive mobility of people has put increasing pressure on the language teaching sector, in terms of the availability of instructors and suitable teaching materials.", "labels": [], "entities": [{"text": "language teaching", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.769839346408844}]}, {"text": "The development of Intelligent Computer Aided Language Learning (ICALL) has helped both these needs, while the Internet has increasingly been used as a source of exercises.", "labels": [], "entities": [{"text": "Intelligent Computer Aided Language Learning (ICALL)", "start_pos": 19, "end_pos": 71, "type": "TASK", "confidence": 0.7016498893499374}]}, {"text": "Indeed, it allows immediate access to a huge number of texts which can be used for educational purposes, either for classical reading comprehension tasks, or as a corpus for the creation of various automatically generated exercises.", "labels": [], "entities": []}, {"text": "However, the strength of the Internet is also its main flaw : there are so many texts available to the teacher that he or she can get lost.", "labels": [], "entities": []}, {"text": "Having gathered some documents suitable in terms of subject matter, teachers still have to check if their readability levels are suitable for their students : a highly time-consuming task.", "labels": [], "entities": []}, {"text": "This is where NLP applications able to classify documents according to their reading difficulty level can be invaluable.", "labels": [], "entities": []}, {"text": "Related research will be discussed in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, the distinctive features of the corpus used in this study and a difficulty scale suitable for FFL text classification are described.", "labels": [], "entities": [{"text": "FFL text classification", "start_pos": 108, "end_pos": 131, "type": "TASK", "confidence": 0.9025254448254904}]}, {"text": "Section 4 focuses on the independent linguistic variables considered in this research, while the statistical techniques used for predictions are covered in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 gives some details of the implementations, and Section 7 presents the first results of our models.", "labels": [], "entities": []}, {"text": "Finally, Section 8 sums up the contribution of this article before providing a programme for future work and improvement of the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation measures most commonly employed in the literature are Pearson's productmoment correlation coefficient, prediction accuracy as defined by, and adjacent accuracy.", "labels": [], "entities": [{"text": "Pearson's productmoment correlation coefficient", "start_pos": 69, "end_pos": 116, "type": "METRIC", "confidence": 0.623855185508728}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.8614702820777893}, {"text": "adjacent accuracy", "start_pos": 157, "end_pos": 174, "type": "METRIC", "confidence": 0.7518712878227234}]}, {"text": "Adjacent accuracy is defined by as \"the proportion of predictions that were within one level of the human-assigned: Mean Pearson's r coefficient, exact and adjacent accuracies for both models with the tenfold cross-validation evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.983230710029602}, {"text": "Pearson's r coefficient", "start_pos": 121, "end_pos": 144, "type": "METRIC", "confidence": 0.6715478599071503}, {"text": "exact and adjacent accuracies", "start_pos": 146, "end_pos": 175, "type": "METRIC", "confidence": 0.8317602872848511}]}, {"text": "label for the given text\".", "labels": [], "entities": []}, {"text": "They defended this measure by arguing that even human-assigned reading levels are not always consistent.", "labels": [], "entities": []}, {"text": "Nevertheless, it should not be forgotten that it can give optimistic values when the number of classes is small.", "labels": [], "entities": []}, {"text": "Exploratory analysis of the corpus highlighted the importance of having a similar number of texts per class.", "labels": [], "entities": []}, {"text": "This requirement made it impossible to use all the texts from the corpus.", "labels": [], "entities": []}, {"text": "Some 465 texts were selected, distributed across the 9 levels in such away that each level contained about 50 texts.", "labels": [], "entities": []}, {"text": "Within each class, an automatic procedure discarded outliers located more than 3\u03c3 from the mean, leaving 440 texts.", "labels": [], "entities": []}, {"text": "Both models were trained on these texts.", "labels": [], "entities": []}, {"text": "The results on the training corpus were promising, but might be biased.", "labels": [], "entities": []}, {"text": "So, we turned to a ten-fold cross-validation process which guarantees more reliable values for the three evaluation measures we had chosen, as well as a better insight into the generalisability of the two models.", "labels": [], "entities": []}, {"text": "The resulting evaluation measures for training and test folds are shown in.", "labels": [], "entities": []}, {"text": "The similarity between them clearly shows that, with 440 observations, both the models were quite robust.", "labels": [], "entities": []}, {"text": "On this corpus, multinomial logistic regression was significantly more accurate (with 38% of texts correctly classified against 32.4% for the PO model), while Pearson's R was slightly higher for the PO model.", "labels": [], "entities": [{"text": "R", "start_pos": 169, "end_pos": 170, "type": "METRIC", "confidence": 0.7327165603637695}]}, {"text": "These results suggest that the exact accuracy maybe a better indicator of performance than the correlation coefficient.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.972852349281311}, {"text": "correlation", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.993024468421936}]}, {"text": "However they conflict with conclusion that the PO model performed better than the MLR one.", "labels": [], "entities": []}, {"text": "This discrepancy might arise because the PO model was less accurate for exact predictions, but better when the adjacent accuracy by level was taken into account.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9258012175559998}]}, {"text": "However, the data in do not support this hypothesis; rather they confirm the superiority of the MLR model when adjacent accuracy is considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9522116184234619}]}, {"text": "In fact, PO model's lower performance seems to be due to alack of fit to the data, as revealed by the result of the score test for the proportional-odds assumption.", "labels": [], "entities": []}, {"text": "This yielded a pvalue below 0.0001, clearly showing that the PO model was not a good fit to the corpus.", "labels": [], "entities": []}, {"text": "There remains one last issue to be discussed before comparing our results to those of other studies: the empirical evidence for tense being a good predictor of reading difficulty.", "labels": [], "entities": []}, {"text": "We selected tenses because of our experience as FLE teacher rather than on theoretical or empirical grounds.", "labels": [], "entities": [{"text": "FLE teacher", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.5559466034173965}]}, {"text": "However we found that exact accuracy decreased by 10% when the tense variables were omitted from the models.", "labels": [], "entities": [{"text": "exact", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.991231381893158}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9110158085823059}]}, {"text": "Further analysis showed that the tense contributed significantly to the adjacent accuracy of classifying the C1 and C2 texts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9970569610595703}]}], "tableCaptions": [{"text": " Table 1: Mean Pearson's r coefficient, exact and  adjacent accuracies for both models with the ten- fold cross-validation evaluation.", "labels": [], "entities": [{"text": "Pearson's r coefficient", "start_pos": 15, "end_pos": 38, "type": "METRIC", "confidence": 0.6970403864979744}, {"text": "exact and  adjacent accuracies", "start_pos": 40, "end_pos": 70, "type": "METRIC", "confidence": 0.6844407469034195}]}]}