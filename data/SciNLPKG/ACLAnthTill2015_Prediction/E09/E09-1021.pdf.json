{"title": [{"text": "Translation and Extension of Concepts Across Languages", "labels": [], "entities": [{"text": "Translation and Extension of Concepts Across Languages", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8452187946864537}]}], "abstractContent": [{"text": "We present a method which, given a few words defining a concept in some language , retrieves, disambiguates and extends corresponding terms that define a similar concept in another specified language.", "labels": [], "entities": []}, {"text": "This can be very useful for cross-lingual information retrieval and the preparation of multilingual lexical resources.", "labels": [], "entities": [{"text": "cross-lingual information retrieval", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.7009048263231913}]}, {"text": "We automatically obtain term translations from multilingual dictionaries and disambiguate them using web counts.", "labels": [], "entities": []}, {"text": "We then retrieve web snippets with co-occurring translations, and discover additional concept terms from these snippets.", "labels": [], "entities": []}, {"text": "Our term discovery is based on co-appearance of similar words in symmetric patterns.", "labels": [], "entities": []}, {"text": "We evaluate our method on a set of language pairs involving 45 languages, including combinations of very dissimilar ones such as Russian, Chinese, and He-brew for various concepts.", "labels": [], "entities": []}, {"text": "We assess the quality of the retrieved sets using both human judgments and automatically comparing the obtained categories to corresponding English WordNet synsets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Numerous NLP tasks utilize lexical databases that incorporate concepts (or word categories): sets of terms that share a significant aspect of their meanings (e.g., terms denoting types of food, tool names, etc).", "labels": [], "entities": [{"text": "NLP tasks utilize lexical databases that incorporate concepts (or word categories): sets of terms that share a significant aspect of their meanings (e.g., terms denoting types of food, tool names, etc)", "start_pos": 9, "end_pos": 210, "type": "Description", "confidence": 0.8223615922988989}]}, {"text": "These sets are useful by themselves for improvement of thesauri and dictionaries, and they are also utilized in various applications including textual entailment and question answering.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.7215960472822189}, {"text": "question answering", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.946527361869812}]}, {"text": "Manual development of lexical databases is labor intensive, error prone, and susceptible to arbitrary human decisions.", "labels": [], "entities": []}, {"text": "While databases like WordNet (WN) are invaluable for NLP, for some applications any offline resource would not be extensive enough.", "labels": [], "entities": [{"text": "WordNet (WN)", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.8533572852611542}]}, {"text": "Frequently, an application requires data on some very specific topic or on very recent news-related events.", "labels": [], "entities": []}, {"text": "In these cases even huge and ever-growing resources like Wikipedia may provide insufficient coverage.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.9447057247161865}]}, {"text": "Hence applications turn to Web-based on-demand queries to obtain the desired data.", "labels": [], "entities": []}, {"text": "The majority of web pages are written in English and a few other salient languages, hence most of the web-based information retrieval studies are done on these languages.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 112, "end_pos": 133, "type": "TASK", "confidence": 0.6899692565202713}]}, {"text": "However, due to the substantial growth of the multilingual web 1 , queries can be performed and the required information can be found in less common languages, while the query language frequently does not match the language of available information.", "labels": [], "entities": []}, {"text": "Thus, if we are looking for information about some lexical category where terms are given in a relatively uncommon language such as Hebrew, it is likely to find more detailed information and more category instances in a salient language such as English.", "labels": [], "entities": []}, {"text": "To obtain such information, we need to discover a word list that represents the desired category in English.", "labels": [], "entities": []}, {"text": "This list can be used, for instance, in subsequent focused search in order to obtain pages relevant for the given category.", "labels": [], "entities": []}, {"text": "Thus given a few Hebrew words as a description for some category, it can be useful to obtain a similar (and probably more extended) set of English words representing the same category.", "labels": [], "entities": []}, {"text": "In addition, when exploring some lexical category in a common language such as English, it is frequently desired to consider available resources from different countries.", "labels": [], "entities": []}, {"text": "Such resources are likely to be written in languages different from English.", "labels": [], "entities": []}, {"text": "In order to obtain such resources, as before, it would be beneficial, given a concept definition in English, to obtain word lists denoting the same concept in different languages.", "labels": [], "entities": []}, {"text": "In both cases a concept as a set of words should be translated as a whole from one language to another.", "labels": [], "entities": []}, {"text": "In this paper we present an algorithm that given a concept defined as a set of words in some source language discovers and extends a similar set in some specified target language.", "labels": [], "entities": []}, {"text": "Our approach comprises three main stages.", "labels": [], "entities": []}, {"text": "First, given a few terms, we obtain sets of their translations to the target language from multilingual dictionaries, and use web counts to select the appropriate word senses.", "labels": [], "entities": []}, {"text": "Next, we retrieve search engine snippets with the translated terms and extract symmetric patterns that connect these terms.", "labels": [], "entities": []}, {"text": "Finally, we use these patterns to extend the translated concept, by obtaining more terms from the snippets.", "labels": [], "entities": []}, {"text": "We performed thorough evaluation for various concepts involving 45 languages.", "labels": [], "entities": []}, {"text": "The obtained categories were manually verified with two human judges and, when appropriate, automatically compared to corresponding English WN synsets.", "labels": [], "entities": []}, {"text": "In all tested cases we discovered dozens of concept terms with state-of-the-art precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9940792322158813}]}, {"text": "Our major contribution is a novel framework for concept translation across languages.", "labels": [], "entities": [{"text": "concept translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7484862208366394}]}, {"text": "This framework utilizes web queries together with dictionaries for translation, disambiguation and extension of given terms.", "labels": [], "entities": [{"text": "translation", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.972099244594574}]}, {"text": "While our framework relies on the existence of multilingual dictionaries, we show that even with basic 1000 word dictionaries we achieve good performance.", "labels": [], "entities": []}, {"text": "Modest time and data requirements allow the incorporation of our method in practical applications.", "labels": [], "entities": []}, {"text": "In Section 2 we discuss related work, Section 3 details the algorithm, Section 4 describes the evaluation protocol and Section 5 presents our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe here the languages, concepts and dictionaries we used in our experiments.", "labels": [], "entities": []}, {"text": "We do not consider as terms the 50 most frequent words.", "labels": [], "entities": []}, {"text": "While there are numerous concept acquisition studies, no framework has been developed so far to evaluate this type of cross-lingual concept discovery, limiting our ability to perform a meaningful comparison to previous work.", "labels": [], "entities": [{"text": "concept acquisition", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7805174589157104}, {"text": "cross-lingual concept discovery", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.6485696335633596}]}, {"text": "Fair estimation of translated concept quality is a challenging task.", "labels": [], "entities": []}, {"text": "For most languages there are no widely accepted concept databases.", "labels": [], "entities": []}, {"text": "Moreover, the contents of the same concept may vary across languages.", "labels": [], "entities": []}, {"text": "Fortunately, when English is taken as a target language, the English WN allows an automated evaluation of concepts.", "labels": [], "entities": []}, {"text": "We conducted evaluation in three different settings, mostly relying on human judges and utilizing the English WN where possible.", "labels": [], "entities": []}, {"text": "1. English as source language.", "labels": [], "entities": []}, {"text": "We applied our algorithm on a subset of 24 categories using each of the 45 languages as a target language.", "labels": [], "entities": []}, {"text": "Evaluation is done by two judges 9 . 2. English as target language.", "labels": [], "entities": []}, {"text": "All other languages served as source languages.", "labels": [], "entities": []}, {"text": "In this case human subjects manually provided input terms for 150 concept definitions in each of the target languages using 150 selected English WN glosses.", "labels": [], "entities": []}, {"text": "For each gloss they were requested to provide at least 2 terms.", "labels": [], "entities": []}, {"text": "Then we ran the algorithm on these term lists.", "labels": [], "entities": []}, {"text": "Since the obtained results were English words, we performed both manual evaluation of the 24 categories and automated comparison to the original WN data.", "labels": [], "entities": [{"text": "WN data", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.7748098373413086}]}, {"text": "We created 10 different nonEnglish language pairs for the 24 concepts.", "labels": [], "entities": []}, {"text": "Concept definitions were the same as in (2) and manual evaluation followed the same protocol as in (1).", "labels": [], "entities": []}, {"text": "The absence of exhaustive term lists makes recall estimation problematic.", "labels": [], "entities": [{"text": "recall estimation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7595101594924927}]}, {"text": "In all cases we assess the quality of the discovered lists in terms of precision (P ) and length of retrieved lists (T ).", "labels": [], "entities": [{"text": "precision (P )", "start_pos": 71, "end_pos": 85, "type": "METRIC", "confidence": 0.9168374389410019}]}, {"text": "Each discovered concept was evaluated by two judges.", "labels": [], "entities": []}, {"text": "All judges were fluent English speakers and for each target language, at least one was a fluent speaker of this language.", "labels": [], "entities": []}, {"text": "They were given oneline English descriptions of each category and the full lists obtained by our algorithm for each of the 24 concepts.", "labels": [], "entities": []}, {"text": "shows the lists obtained by our algorithm for the category described as Relatives (e.g., grandmother) for several language pairs including Hebrew\u2192French and Chinese\u2192Czech.", "labels": [], "entities": []}, {"text": "We mixed \"noise\" words into each list of terms . These words were automatically and randomly extracted from the same text.", "labels": [], "entities": []}, {"text": "Subjects were required to select all words fitting the provided description.", "labels": [], "entities": []}, {"text": "They were unaware of algorithm details and desired results.", "labels": [], "entities": []}, {"text": "They were instructed to accept common abbreviations, alternative spellings or misspellings like yel \u00af ow\u2208color and to accept a term as belonging to a category if at least one of its senses belongs to it, like orange\u2208color and orange\u2208fruit.", "labels": [], "entities": []}, {"text": "They were asked to reject terms related or associated but not belonging to the target category, like tasty / \u2208food, or that are too general, like animal / \u2208dogs.", "labels": [], "entities": []}, {"text": "The first 4 columns of show averaged results of manual evaluation for 24 categories.", "labels": [], "entities": []}, {"text": "In the first two columns English is used as a source language and in the next pair of columns English is used as the target.", "labels": [], "entities": []}, {"text": "In addition we display in parentheses the amount of terms added during the extension stage.", "labels": [], "entities": []}, {"text": "We can see that for all languages, average precision (% of correct terms in concept) is above 80, and frequently above 90, and the average number of extracted terms is above 30.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9125106334686279}]}, {"text": "Internal concept quality is inline with values observed on similarly evaluated tasks for recent concept acquisition studies in English.", "labels": [], "entities": []}, {"text": "As a baseline, only 3% of the inserted 20-40% noise words were incorrectly labeled by judges.", "labels": [], "entities": []}, {"text": "Due to space limitation we do not show the full per-concept behavior; all medians for P and T were close to the average.", "labels": [], "entities": []}, {"text": "We can also observe that the majority (> 60%) of target language terms were obtained during the extension stage.", "labels": [], "entities": []}, {"text": "In fact, brief examination shows that less than half of source language terms successfully pass translation and disambiguation stage.", "labels": [], "entities": [{"text": "translation and disambiguation", "start_pos": 96, "end_pos": 126, "type": "TASK", "confidence": 0.6864750782648722}]}, {"text": "However, more than 80% of terms which were skipped due to lack of available translations were re-discovered in the target language during the extension stage, along with the discovery of new correct terms not existing in the given source definition.", "labels": [], "entities": []}, {"text": "The first two columns of show similar results for non-English language pairs.", "labels": [], "entities": []}, {"text": "We can see that these results are only slightly inferior to the ones involving English.", "labels": [], "entities": []}, {"text": "We applied our algorithm on 150 concepts with English used as the target language.", "labels": [], "entities": []}, {"text": "Since we want to consider common misspellings and morphological combinations of correct terms as hits, we used a basic speller and stemmer to resolve typos and drop some English endings.", "labels": [], "entities": []}, {"text": "The WN columns in display P and T values for this evaluation.", "labels": [], "entities": []}, {"text": "In most cases we obtain > 85% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9996695518493652}]}, {"text": "While these results (P=87,T=17) are lower than in manual evaluation, the task is much harder due to the large number (and hence sparseness) of the utilized 150 WN categories and the incomplete nature of WN data.", "labels": [], "entities": []}, {"text": "For the 10 categories of used in previous work, we have obtained (P=92,T=41) which outperforms the seed-based concept acquisition of) (P=90,T=35) on the same concepts.", "labels": [], "entities": []}, {"text": "However, it should be noted that our task setting is substantially different since we utilize more seeds and they come from languages different from English.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Results for non-English pairs. P: precision, T:", "labels": [], "entities": [{"text": "P", "start_pos": 41, "end_pos": 42, "type": "METRIC", "confidence": 0.9872558116912842}, {"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9948456287384033}, {"text": "T", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.9606215953826904}]}]}