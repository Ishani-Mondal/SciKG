{"title": [{"text": "Learning-Based Named Entity Recognition for Morphologically-Rich, Resource-Scarce Languages", "labels": [], "entities": [{"text": "Learning-Based Named Entity Recognition", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5206412225961685}]}], "abstractContent": [{"text": "Named entity recognition for morphologically rich, case-insensitive languages, including the majority of semitic languages, Iranian languages, and Indian languages, is inherently more difficult than its English counterpart.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7114497224489847}]}, {"text": "Worse still, progress on machine learning approaches to named entity recognition for many of these languages is currently hampered by the scarcity of annotated data and the lack of an accurate part-of-speech tagger.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.6259818375110626}]}, {"text": "While it is possible to rely on manually-constructed gazetteers to combat data scarcity, this gazetteer-centric approach has the potential weakness of creating irreproducible results, since these name lists are not publicly available in general.", "labels": [], "entities": []}, {"text": "Motivated in part by this concern, we present a learning-based named entity recognizer that does not rely on manually-constructed gazetteers, using Bengali as our representative resource-scarce, morphologically-rich language.", "labels": [], "entities": []}, {"text": "Our recognizer achieves a relative improvement of 7.5% in F-measure over a baseline recognizer.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9958171248435974}]}, {"text": "Improvements arise from (1) using induced affixes, (2) extracting information from online lexical databases, and (3) jointly modeling part-of-speech tagging and named entity recognition.", "labels": [], "entities": [{"text": "extracting information from online lexical databases", "start_pos": 55, "end_pos": 107, "type": "TASK", "confidence": 0.7989298403263092}, {"text": "part-of-speech tagging", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.7562691271305084}, {"text": "named entity recognition", "start_pos": 161, "end_pos": 185, "type": "TASK", "confidence": 0.660533199707667}]}], "introductionContent": [{"text": "While research in natural language processing has gained a lot of momentum in the past several decades, much of this research effort has been focusing on only a handful of politically-important languages such as English, Chinese, and Arabic.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.6638734042644501}]}, {"text": "On the other hand, being the fifth most spoken language 1 with more than 200 million native speakers residing mostly in Bangladesh and the Indian state of West Bengal, Bengali has far less electronic resources than the aforementioned languages.", "labels": [], "entities": []}, {"text": "In fact, a major obstacle to the automatic processing of Bengali is the scarcity of annotated corpora.", "labels": [], "entities": [{"text": "automatic processing of Bengali", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.7009540498256683}]}, {"text": "One potential solution to the problem of data scarcity is to hand-annotate a small amount of data with the desired linguistic information and then develop bootstrapping algorithms for combining this small amount of labeled data with a large amount of unlabeled data.", "labels": [], "entities": []}, {"text": "In fact, cotraining () has been successfully applied to English named entity recognition (NER)).", "labels": [], "entities": [{"text": "English named entity recognition (NER))", "start_pos": 56, "end_pos": 95, "type": "TASK", "confidence": 0.7045327978474754}]}, {"text": "In C&S's approach, consecutive words tagged as proper nouns are first identified as potential NEs, and each such NE is then labeled by combining the outputs of two co-trained classifiers.", "labels": [], "entities": []}, {"text": "Unfortunately, there are practical difficulties in applying this technique to Bengali NER.", "labels": [], "entities": [{"text": "Bengali NER", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.5434887856245041}]}, {"text": "First, one of C&S's co-trained classifiers uses features based on capitalization, but Bengali is case-insensitive.", "labels": [], "entities": []}, {"text": "Second, C&S identify potential NEs based on proper nouns, but unlike English, (1) proper noun identification for Bengali is non-trivial, due to the lack of capitalization; and (2) there does not exist an accurate Bengali part-of-speech (POS) tagger for providing such information, owing to the scarcity of annotated data for training the tagger.", "labels": [], "entities": [{"text": "proper noun identification", "start_pos": 82, "end_pos": 108, "type": "TASK", "confidence": 0.669269065062205}]}, {"text": "In other words, Bengali NER is complicated not only by the scarcity of annotated data, but also by the lack of an accurate POS tagger.", "labels": [], "entities": [{"text": "Bengali NER", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.512386292219162}]}, {"text": "One could imagine building a Bengali POS tagger using un-supervised induction techniques that have been successfully developed for English (e.g.,,), including the recentlyproposed prototype-driven approach) and Bayesian approach.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 37, "end_pos": 47, "type": "TASK", "confidence": 0.7849287390708923}]}, {"text": "The majority of these approaches operate by clustering distributionally similar words, but they are unlikely to work well for Bengali for two reasons.", "labels": [], "entities": []}, {"text": "First, Bengali is a relatively free word order language, and hence the distributional information collected for Bengali words may not be as reliable as that for English words.", "labels": [], "entities": []}, {"text": "Second, many closed-class words that typically appear in the distributional representation of an English word (e.g., prepositions and particles such as \"in\" and \"to\") are realized as inflections in Bengali, and the absence of these informative words implies that the context vector may no longer capture sufficient information for accurately clustering the Bengali words.", "labels": [], "entities": []}, {"text": "In view of the above problems, many learningbased Bengali NE recognizers have relied heavily on manually-constructed name lists for identifying persons, organizations, and locations.", "labels": [], "entities": [{"text": "NE recognizers", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7387169599533081}]}, {"text": "There are at least two weaknesses associated with this gazetteer-centric approach.", "labels": [], "entities": []}, {"text": "First, these name lists are typically not publicly available, making it difficult to reproduce the results of these NE recognizers.", "labels": [], "entities": [{"text": "NE recognizers", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.865984171628952}]}, {"text": "Second, it is not clear how comprehensive these lists are.", "labels": [], "entities": []}, {"text": "Relying on comprehensive lists that comprise a large portion of the names in the test set essentially reduces the NER problem to a dictionary-lookup problem, which is arguably not very interesting from a research perspective.", "labels": [], "entities": [{"text": "NER", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.9737103581428528}]}, {"text": "In addition, many existing learning-based Bengali NE recognizers have several common weaknesses.", "labels": [], "entities": [{"text": "NE recognizers", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.8153675198554993}]}, {"text": "First, they use as features pseudo-affixes, which are created by extracting the first n and the last n characters of a word (where 1 \u2264 n \u2264 4) (e.g.,).", "labels": [], "entities": []}, {"text": "While affixes encode essential grammatical information in Bengali due to its morphological richness, this extraction method is arguably too ad-hoc and does not cover many useful affixes.", "labels": [], "entities": []}, {"text": "Second, they typically adopt a pipelined NER architecture, performing POS tagging prior to NER and encoding the resulting not-so-accurate POS information as a feature.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.7754965722560883}]}, {"text": "In other words, errors in POS tagging are propagated to the NE recognizer via the POS feature, thus limiting its performance.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.7781737446784973}]}, {"text": "Motivated in part by these weaknesses, we investigate how to improve a learning-based NE recognizer that does not rely on manually-constructed gazetteers.", "labels": [], "entities": [{"text": "NE recognizer", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.8270814716815948}]}, {"text": "Specifically, we investigate two learning architectures for our NER system.", "labels": [], "entities": []}, {"text": "The first one is the aforementioned pipelined architecture in which the NE recognizer uses as features the output of a POS tagger that is trained independently of the recognizer.", "labels": [], "entities": [{"text": "NE recognizer", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.6982057690620422}]}, {"text": "Unlike existing Bengali POS and NE taggers, however, we examine two new knowledge sources for training these taggers: (1) affixes induced from an unannotated corpus and (2) semantic class information extracted from Wikipedia.", "labels": [], "entities": [{"text": "NE taggers", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.7691588699817657}]}, {"text": "In the second architecture, we jointly learn the POS tagging and the NER tasks, allowing features for one task to be accessible to the other task during learning.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.6855206191539764}]}, {"text": "The goal is to examine whether any benefits can be obtained via joint modeling, which could address the error propagation problem with the pipelined architecture.", "labels": [], "entities": []}, {"text": "While we focus on Bengali NER in this paper, none of the proposed techniques are languagespecific.", "labels": [], "entities": []}, {"text": "In fact, we believe that these techniques are of relevance and interest to the EACL community because they can be equally applicable to the numerous resource-scarce European and Middle Eastern languages that share similar linguistic and extra-linguistic properties as Bengali.", "labels": [], "entities": []}, {"text": "For instance, the majority of semitic languages and Iranian languages are, like Bengali, morphologically productive; and many East European languages such as Czech and Polish resemble Bengali in terms of not only their morphological richness, but also their relatively free word order.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly describe the related work.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 show how we induce affixes from an unannotated corpus and extract semantic class information from Wikipedia.", "labels": [], "entities": []}, {"text": "In Sections 5 and 6, we train and evaluate a POS tagger and an NE recognizer independently, augmenting the feature set typically used for these two tasks with our new knowledge sources.", "labels": [], "entities": []}, {"text": "Finally, we describe and evaluate our joint model in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: 5-fold cross-validation accuracies for  POS tagging", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.839063823223114}]}, {"text": " Table 6: 5-fold cross-validation results for NER", "labels": [], "entities": [{"text": "NER", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9268240928649902}]}, {"text": " Table 7: 5-fold cross-validation joint modeling re- sults for NER", "labels": [], "entities": [{"text": "NER", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.8769606351852417}]}]}