{"title": [{"text": "MINT: A Method for Effective and Scalable Mining of Named Entity Transliterations from Large Comparable Corpora", "labels": [], "entities": [{"text": "Scalable Mining of Named Entity Transliterations from Large Comparable Corpora", "start_pos": 33, "end_pos": 111, "type": "TASK", "confidence": 0.8313103914260864}]}], "abstractContent": [{"text": "In this paper, we address the problem of mining transliterations of Named Entities (NEs) from large comparable corpora.", "labels": [], "entities": [{"text": "mining transliterations of Named Entities (NEs)", "start_pos": 41, "end_pos": 88, "type": "TASK", "confidence": 0.8001167550683022}]}, {"text": "We leverage the empirical fact that multilingual news articles with similar news content are rich in Named Entity Transliteration Equivalents (NETEs).", "labels": [], "entities": []}, {"text": "Our mining algorithm, MINT, uses a cross-language document similarity model to align multilingual news articles and then mines NETEs from the aligned articles using a transliteration similarity model.", "labels": [], "entities": []}, {"text": "We show that our approach is highly effective on 6 different comparable corpora between English and 4 languages from 3 different language families.", "labels": [], "entities": []}, {"text": "Furthermore, it performs substantially better than a state-of-the-art competitor.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entities (NEs) play a critical role in many Natural Language Processing and Information Retrieval (IR) tasks.", "labels": [], "entities": [{"text": "Natural Language Processing and Information Retrieval (IR) tasks", "start_pos": 50, "end_pos": 114, "type": "TASK", "confidence": 0.7713959634304046}]}, {"text": "In Cross-Language Information Retrieval (CLIR) systems, they play an even more important role as the accuracy of their transliterations is shown to correlate highly with the performance of the CLIR systems).", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval (CLIR)", "start_pos": 3, "end_pos": 46, "type": "TASK", "confidence": 0.7704968601465225}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9986139535903931}]}, {"text": "Traditional methods for transliterations have not proven to be very effective in CLIR.", "labels": [], "entities": [{"text": "CLIR", "start_pos": 81, "end_pos": 85, "type": "TASK", "confidence": 0.8628215193748474}]}, {"text": "Machine Transliteration systems () usually produce incorrect transliterations and translation lexcions such as hand-crafted or statistical dictionaries are too static to have good coverage of NEs 1 occurring in the current news events.", "labels": [], "entities": [{"text": "NEs 1 occurring in the current news events", "start_pos": 192, "end_pos": 234, "type": "TASK", "confidence": 0.8791019022464752}]}, {"text": "Hence, there is a critical need for creating and continually updat-* Currently with University of Utah.", "labels": [], "entities": []}, {"text": "New NEs are introduced to the vocabulary of a language everyday.", "labels": [], "entities": []}, {"text": "On an average, 260 and 452 new NEs appeared daily in the XIE and AFE segments of the LDC English Gigaword corpora respectively.", "labels": [], "entities": [{"text": "XIE", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.7154648900032043}, {"text": "AFE", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9029903411865234}, {"text": "LDC English Gigaword corpora", "start_pos": 85, "end_pos": 113, "type": "DATASET", "confidence": 0.8555113673210144}]}, {"text": "ing multilingual Named Entity transliteration lexicons.", "labels": [], "entities": []}, {"text": "The ubiquitous availability of comparable news corpora in multiple languages suggests a promising alternative to Machine Transliteration, namely, the mining of Named Entity Transliteration Equivalents (NETEs) from such corpora.", "labels": [], "entities": []}, {"text": "News stories are typically rich in NEs and therefore, comparable news corpora can be expected to contain NETEs ().", "labels": [], "entities": [{"text": "NEs", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.90255206823349}]}, {"text": "The large quantity and the perpetual availability of news corpora in many of the world's languages, make mining of NETEs a viable alternative to traditional approaches.", "labels": [], "entities": []}, {"text": "It is this opportunity that we address in our work.", "labels": [], "entities": []}, {"text": "In this paper, we detail an effective and scalable mining method, called MINT (MIning Named-entity Transliteration equivalents), for mining of NETEs from large comparable corpora.", "labels": [], "entities": [{"text": "MINT", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.824928879737854}]}, {"text": "MINT addresses several challenges in mining NETEs from large comparable corpora: exhaustiveness (in mining sparse NETEs), computational efficiency (in scaling on corpora size), language independence (in being applicable to many language pairs) and linguistic frugality (in requiring minimal external linguistic resources).", "labels": [], "entities": [{"text": "MINT", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8352622985839844}]}, {"text": "Our contributions are as follows: \uf0b7 We give empirical evidence for the hypothesis that news articles in different languages with reasonably similar content are rich sources of NETEs).", "labels": [], "entities": [{"text": "NETEs", "start_pos": 176, "end_pos": 181, "type": "TASK", "confidence": 0.8262252807617188}]}, {"text": "\uf0b7 We demonstrate that the above insight can be translated into an effective approach for mining NETEs from large comparable corpora even when similar articles are not known a priori.", "labels": [], "entities": [{"text": "NETEs", "start_pos": 96, "end_pos": 101, "type": "TASK", "confidence": 0.7705413103103638}]}, {"text": "\uf0b7 We demonstrate MINT's effectiveness on 4 language pairs involving 5 languages (English, Hindi, Kannada, Russian, and Tamil) from 3 different language families, and its scalability on corpora of vastly different sizes (2,000 to 200,000 articles).", "labels": [], "entities": [{"text": "MINT", "start_pos": 17, "end_pos": 21, "type": "TASK", "confidence": 0.9727852940559387}]}, {"text": "\uf0b7 We show that MINT's performance is significantly better than a state of the art method ().", "labels": [], "entities": [{"text": "MINT", "start_pos": 15, "end_pos": 19, "type": "TASK", "confidence": 0.9646503329277039}]}, {"text": "We discuss the motivation behind our approach in Section 2 and present the details in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the evaluation process and in Section 5, we present the results and analysis.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our empirical investigation consists of experiments in three data environments, with each environment providing answer to specific set of questions, as listed below: The IDEAL environment is indeed ideal for MINT since every article in the comparable corpora is paired with exactly one similar article in the other language and the pairing of articles in the comparable corpora is known in advance.", "labels": [], "entities": [{"text": "MINT", "start_pos": 208, "end_pos": 212, "type": "TASK", "confidence": 0.9891697764396667}]}, {"text": "We want to emphasize here that such corpora are indeed available in many domains such as technical documents and interlinked multilingual Wikipedia articles.", "labels": [], "entities": []}, {"text": "In the IDEAL environment, only Stage 2 of MINT is put to test, as article alignments are given.", "labels": [], "entities": [{"text": "MINT", "start_pos": 42, "end_pos": 46, "type": "TASK", "confidence": 0.936210572719574}]}, {"text": "In the NEAR-IDEAL data environment, every article in the comparable corpora is known to have exactly one conjugate article in the other language though the pairing itself is not known in advance.", "labels": [], "entities": [{"text": "NEAR-IDEAL data environment", "start_pos": 7, "end_pos": 34, "type": "DATASET", "confidence": 0.9272984862327576}]}, {"text": "In such a setting, MINT needs to discover the article pairing before mining NETEs and therefore, both stages of MINT are put to test.", "labels": [], "entities": [{"text": "MINT", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.9530174136161804}, {"text": "MINT", "start_pos": 112, "end_pos": 116, "type": "TASK", "confidence": 0.9859291911125183}]}, {"text": "The best performance possible in this environment should ideally be the same as that of IDEAL, and any degradation points to the shortcoming of the Stage 1 of MINT.", "labels": [], "entities": [{"text": "MINT", "start_pos": 159, "end_pos": 163, "type": "TASK", "confidence": 0.8545774817466736}]}, {"text": "These two environments quantify the stage-wise performance of the MINT method.", "labels": [], "entities": [{"text": "MINT", "start_pos": 66, "end_pos": 70, "type": "TASK", "confidence": 0.9631898403167725}]}, {"text": "Finally, in the data environment REAL, we test MINT on large comparable corpora, where even the existence of a conjugate article in the target side fora given article in the source side of the comparable corpora is not guaranteed, as in any normal large multilingual news corpora.", "labels": [], "entities": [{"text": "MINT", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.9470412135124207}]}, {"text": "In this scenario both the stages of MINT are put to test.", "labels": [], "entities": [{"text": "MINT", "start_pos": 36, "end_pos": 40, "type": "TASK", "confidence": 0.972724437713623}]}, {"text": "This is the toughest, and perhaps the typical setting in which MINT would be used.", "labels": [], "entities": [{"text": "MINT", "start_pos": 63, "end_pos": 67, "type": "TASK", "confidence": 0.9823402166366577}]}], "tableCaptions": [{"text": " Table 3: Recall of MINT in IDEAL", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.949194610118866}, {"text": "MINT", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.7503084540367126}, {"text": "IDEAL", "start_pos": 28, "end_pos": 33, "type": "TASK", "confidence": 0.36833587288856506}]}, {"text": " Table 2: Test Beds for IDEAL & NEAR-IDEAL", "labels": [], "entities": [{"text": "NEAR-IDEAL", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.4417846202850342}]}, {"text": " Table 5: MRR of Stage 1 in NEAR-IDEAL", "labels": [], "entities": [{"text": "MRR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8657311797142029}, {"text": "NEAR-IDEAL", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.5756274461746216}]}, {"text": " Table 9 shows the  results.", "labels": [], "entities": []}, {"text": " Table 7: Test Beds for REAL", "labels": [], "entities": [{"text": "REAL", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.9020968675613403}]}]}