{"title": [{"text": "Personalizing PageRank for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.6420735021432241}]}], "abstractContent": [{"text": "In this paper we propose anew graph-based method that uses the knowledge in a LKB (based on WordNet) in order to perform unsupervised Word Sense Disam-biguation.", "labels": [], "entities": [{"text": "Word Sense Disam-biguation", "start_pos": 134, "end_pos": 160, "type": "TASK", "confidence": 0.6378512581189474}]}, {"text": "Our algorithm uses the full graph of the LKB efficiently, performing better than previous approaches in English all-words datasets.", "labels": [], "entities": []}, {"text": "We also show that the algorithm can be easily ported to other languages with good results, with the only requirement of having a wordnet.", "labels": [], "entities": []}, {"text": "In addition , we make an analysis of the performance of the algorithm, showing that it is efficient and that it could be tuned to be faster.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is a key enabling-technology that automatically chooses the intended sense of a word in context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7821527520815531}]}, {"text": "Supervised WSD systems are the best performing in public evaluations () but they need large amounts of hand-tagged data, which is typically very expensive to build.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9046182036399841}]}, {"text": "Given the relatively small amount of training data available, current state-of-the-art systems only beat the simple most frequent sense (MFS) baseline 1 by a small margin.", "labels": [], "entities": []}, {"text": "As an alternative to supervised systems, knowledge-based WSD systems exploit the information present in a lexical knowledge base (LKB) to perform WSD, without using any further corpus evidence.", "labels": [], "entities": [{"text": "WSD", "start_pos": 146, "end_pos": 149, "type": "TASK", "confidence": 0.9763878583908081}]}, {"text": "Traditional knowledge-based WSD systems assign a sense to an ambiguous word by comparing each of its senses with those of the surrounding context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.893891453742981}]}, {"text": "Typically, some semantic similarity metric is used for calculating the relatedness among senses).", "labels": [], "entities": []}, {"text": "One of the major drawbacks of these approaches stems from the fact that senses are compared in a pairwise fashion and thus the number of computations can grow exponentially with the number of words.", "labels": [], "entities": []}, {"text": "Although alternatives like simulated annealing ( and conceptual density (Agirre and were tried, most of past knowledge based WSD was done in a suboptimal word-by-word process, i.e., disambiguating words one at a time.", "labels": [], "entities": [{"text": "WSD", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9246396422386169}]}, {"text": "Recently, graph-based methods for knowledgebased WSD have gained much attention in the NLP community.", "labels": [], "entities": [{"text": "WSD", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.7428632378578186}]}, {"text": "These methods use well-known graph-based techniques to find and exploit the structural properties of the graph underlying a particular LKB.", "labels": [], "entities": []}, {"text": "Because the graph is analyzed as a whole, these techniques have the remarkable property of being able to find globally optimal solutions, given the relations between entities.", "labels": [], "entities": []}, {"text": "Graphbased WSD methods are particularly suited for disambiguating word sequences, and they manage to exploit the interrelations among the senses in the given context.", "labels": [], "entities": []}, {"text": "In this sense, they provide a principled solution to the exponential explosion problem, with excellent performance.", "labels": [], "entities": []}, {"text": "Graph-based WSD is performed over a graph composed by senses (nodes) and relations between pairs of senses (edges).", "labels": [], "entities": [{"text": "WSD", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.7992591261863708}]}, {"text": "The relations maybe of several types (lexico-semantic, coocurrence relations, etc.) and may have some weight attached to them.", "labels": [], "entities": []}, {"text": "The disambiguation is typically performed by applying a ranking algorithm over the graph, and then assigning the concepts with highest rank to the corresponding words.", "labels": [], "entities": []}, {"text": "Given the computational cost of using large graphs like WordNet, many researchers use smaller subgraphs built online for each target context.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9708424806594849}]}, {"text": "In this paper we present a novel graph-based WSD algorithm which uses the full graph of WordNet efficiently, performing significantly better that previously published approaches in English all-words datasets.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9415497183799744}]}, {"text": "We also show that the algorithm can be easily ported to other languages with good results, with the only requirement of having a wordnet.", "labels": [], "entities": []}, {"text": "The algorithm is publicly available and can be applied easily to sense inventories and knowledge bases different from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.9511183500289917}]}, {"text": "Our analysis shows that our algorithm is efficient compared to previously proposed alternatives, and that a good choice of WordNet versions and relations is fundamental for good performance.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first describe the PageRank and Personalized PageRank algorithms.", "labels": [], "entities": []}, {"text": "Section 3 introduces the graph based methods used for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9591856598854065}]}, {"text": "Section 4 shows the experimental setting and the main results, and Section 5 compares our methods with related experiments on graph-based WSD systems.", "labels": [], "entities": []}, {"text": "Section 6 shows the results of the method when applied to a Spanish dataset.", "labels": [], "entities": [{"text": "Spanish dataset", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.7435173839330673}]}, {"text": "Section 7 analyzes the performance of the algorithm.", "labels": [], "entities": []}, {"text": "Finally, we draw some conclusions in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this paper we will use two datasets for comparing graph-based WSD methods, namely, the Senseval-2 (S2AW) and Senseval-3 (S3AW) all words datasets (), which are both labeled with WordNet 1.7 tags.", "labels": [], "entities": [{"text": "WordNet 1.7 tags", "start_pos": 181, "end_pos": 197, "type": "DATASET", "confidence": 0.8876597285270691}]}, {"text": "We did not use the Semeval dataset, for the sake of comparing our results to related work, none of which used Semeval data.", "labels": [], "entities": [{"text": "Semeval dataset", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.8611019551753998}]}, {"text": "shows the results as recall of the graph-based WSD system over these datasets on the different LKBs.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.998566210269928}]}, {"text": "We detail overall results, as well as results per PoS, and the confidence interval for the overall results.", "labels": [], "entities": [{"text": "PoS", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.6473510265350342}, {"text": "confidence interval", "start_pos": 63, "end_pos": 82, "type": "METRIC", "confidence": 0.9601292312145233}]}, {"text": "The interval was computed using bootstrap resampling with 95% confidence.", "labels": [], "entities": []}, {"text": "The table shows that Ppr w2w is consistently the best method in both datasets and for all LKBs.", "labels": [], "entities": []}, {"text": "Ppr and Spr obtain comparable results, which is remarkable, given the simplicity of the Ppr algo-: Results (as recall) on Senseval-2 and Senseval-3 all words tasks.", "labels": [], "entities": [{"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.95809406042099}]}, {"text": "We also include the MFS baseline and the best results of supervised systems at competition time (SMUaw,GAMBL).", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.8289510905742645}, {"text": "SMUaw,GAMBL", "start_pos": 97, "end_pos": 108, "type": "DATASET", "confidence": 0.845659077167511}]}, {"text": "rithm, compared to the more elaborate algorithm to construct the graph.", "labels": [], "entities": []}, {"text": "The differences between methods are not statistically significant, which is a common problem on this relatively small datasets ().", "labels": [], "entities": []}, {"text": "Regarding LKBs, the best results are obtained using WordNet 1.7 and eXtended WordNet.", "labels": [], "entities": [{"text": "WordNet 1.7", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.9375709295272827}]}, {"text": "Here the differences are in many cases significant.", "labels": [], "entities": []}, {"text": "These results are surprising, as we would expect that the manually disambiguated gloss relations from WordNet 3.0 would lead to better results, compared to the automatically disambiguated gloss relations from the eXtended WordNet (linked to version 1.7).", "labels": [], "entities": []}, {"text": "The lower performance of WNet30+gloss can be due to the fact that the Senseval all words data set is tagged using WordNet 1.7 synsets.", "labels": [], "entities": [{"text": "WNet30+gloss", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.8814324537913004}, {"text": "Senseval all words data set", "start_pos": 70, "end_pos": 97, "type": "DATASET", "confidence": 0.8095818758010864}, {"text": "WordNet 1.7 synsets", "start_pos": 114, "end_pos": 133, "type": "DATASET", "confidence": 0.9253601431846619}]}, {"text": "When using a different LKB for WSD, a mapping to WordNet 1.7 is required.", "labels": [], "entities": [{"text": "WordNet 1.7", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.9412668943405151}]}, {"text": "Although the mapping is cited as having a correctness on the high 90s (), it could have introduced sufficient noise to counteract the benefits of the hand-disambiguated glosses.", "labels": [], "entities": [{"text": "correctness", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.9902777075767517}]}, {"text": "also shows the most frequent sense (MFS), as well as the best supervised systems () that participated in each competition (SMUaw and GAMBL, respectively).", "labels": [], "entities": [{"text": "frequent sense (MFS)", "start_pos": 20, "end_pos": 40, "type": "METRIC", "confidence": 0.7131807684898377}, {"text": "SMUaw", "start_pos": 123, "end_pos": 128, "type": "DATASET", "confidence": 0.8554758429527283}, {"text": "GAMBL", "start_pos": 133, "end_pos": 138, "type": "DATASET", "confidence": 0.6646654009819031}]}, {"text": "The MFS is a baseline for supervised systems, but it is considered a difficult competitor for unsupervised systems, which rarely come close to it.", "labels": [], "entities": []}, {"text": "In this case the MFS baseline was computed using previously availabel training data like SemCor.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.7529700994491577}]}, {"text": "Our best results are close to the MFS in both Senseval-2 and Senseval-3 datasets.", "labels": [], "entities": [{"text": "MFS", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.47611844539642334}, {"text": "Senseval-3 datasets", "start_pos": 61, "end_pos": 80, "type": "DATASET", "confidence": 0.8521751463413239}]}, {"text": "The results for the supervised system are given for reference, and we can see that the gap is relatively small, specially for Senseval-3.", "labels": [], "entities": []}, {"text": "Our WSD algorithm can be applied over nonenglish texts, provided that a LKB for this particular language exists.", "labels": [], "entities": []}, {"text": "We have tested the graphalgorithms proposed in this paper on a Spanish dataset, using the Spanish WordNet as knowledge source (.", "labels": [], "entities": [{"text": "Spanish dataset", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.7359010726213455}]}, {"text": "We used the Semeval-2007 Task 09 dataset as evaluation gold standard: Elapsed time (in minutes) of the algorithms when applied to the Senseval-2 dataset.", "labels": [], "entities": [{"text": "Semeval-2007 Task 09 dataset", "start_pos": 12, "end_pos": 40, "type": "DATASET", "confidence": 0.6317361146211624}, {"text": "Senseval-2 dataset", "start_pos": 134, "end_pos": 152, "type": "DATASET", "confidence": 0.8678732812404633}]}, {"text": "ally annotated with Spanish WordNet synsets.", "labels": [], "entities": [{"text": "Spanish WordNet synsets", "start_pos": 20, "end_pos": 43, "type": "DATASET", "confidence": 0.7051099936167399}]}, {"text": "It is split into a train and test part, and has an \"all words\" shape i.e. input consists on sentences, each one having at least one occurrence of a target noun.", "labels": [], "entities": []}, {"text": "We ran the experiment over the test part (792 instances), and used the train part for calculating the MFS baseline.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 102, "end_pos": 114, "type": "DATASET", "confidence": 0.5916387140750885}]}, {"text": "We used the Spanish WordNet as LKB, enriched with eXtended WordNet relations.", "labels": [], "entities": [{"text": "Spanish WordNet as LKB", "start_pos": 12, "end_pos": 34, "type": "DATASET", "confidence": 0.7423106878995895}]}, {"text": "It contains 105, 501 nodes and 623, 316 relations.", "labels": [], "entities": []}, {"text": "The results in are consistent with those for English, with our algorithm approaching MFS performance.", "labels": [], "entities": []}, {"text": "Note that for this dataset the supervised algorithm could barely improve over the MFS, suggesting that for this particular dataset MFS is particularly strong.", "labels": [], "entities": []}, {"text": "shows the time spent by the different algorithms when applied to the Senseval-2 all words dataset, using the WNet17 + Xwn as LKB.", "labels": [], "entities": [{"text": "Senseval-2 all words dataset", "start_pos": 69, "end_pos": 97, "type": "DATASET", "confidence": 0.7053593546152115}, {"text": "WNet17 + Xwn", "start_pos": 109, "end_pos": 121, "type": "DATASET", "confidence": 0.8777724305788676}]}, {"text": "The dataset consists on 2473 word instances appearing on 476 different sentences.", "labels": [], "entities": []}, {"text": "The experiments were done on a computer with four 2.66 Ghz processors and 16 Gb memory.", "labels": [], "entities": []}, {"text": "The table shows that the time elapsed by the algorithms varies between 30 minutes for the Ppr method (which thus disambiguates circa 82 instances per minute) to almost 3 hours spent by the Ppr w2w method (circa 15 instances per minute).", "labels": [], "entities": []}, {"text": "The Spr method lies in between, requiring 2 hours for completing the task, but its overall performance is well below the PageRank based Ppr w2w method.", "labels": [], "entities": []}, {"text": "Note that the algorithm is coded in C++ for greater efficiency, and uses the Boost Graph Library.", "labels": [], "entities": [{"text": "Boost Graph Library", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.8958012262980143}]}], "tableCaptions": [{"text": " Table 1: Results (as recall) on Senseval-2 and Senseval-3 all words tasks. We also include the MFS  baseline and the best results of supervised systems at competition time (SMUaw,GAMBL).", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9871047735214233}, {"text": "MFS  baseline", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.7475548684597015}, {"text": "SMUaw,GAMBL", "start_pos": 174, "end_pos": 185, "type": "DATASET", "confidence": 0.855779230594635}]}, {"text": " Table 2: Comparison with related work. Note that  Nav05 uses the MFS.", "labels": [], "entities": [{"text": "MFS", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.9052911400794983}]}, {"text": " Table 3: Results (accuracy) on Spanish Semeval07  dataset, including MFS and the best supervised  system in the competition.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9994757771492004}, {"text": "Spanish Semeval07  dataset", "start_pos": 32, "end_pos": 58, "type": "DATASET", "confidence": 0.9323095083236694}]}]}