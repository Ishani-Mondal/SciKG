{"title": [{"text": "Contextual Phrase-Level Polarity Analysis using Lexical Affect Scoring and Syntactic N-grams", "labels": [], "entities": [{"text": "Phrase-Level Polarity Analysis", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.807267447312673}]}], "abstractContent": [{"text": "We present a classifier to predict con-textual polarity of subjective phrases in a sentence.", "labels": [], "entities": []}, {"text": "Our approach features lexical scoring derived from the Dictionary of Affect in Language (DAL) and extended through WordNet, allowing us to automatically score the vast majority of words in our input avoiding the need for manual labeling.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 115, "end_pos": 122, "type": "DATASET", "confidence": 0.9429628849029541}]}, {"text": "We augment lexical scoring with n-gram analysis to capture the effect of context.", "labels": [], "entities": []}, {"text": "We combine DAL scores with syntactic constituents and then extract n-grams of constituents from all sentences.", "labels": [], "entities": []}, {"text": "We also use the polarity of all syntactic constituents within the sentence as features.", "labels": [], "entities": []}, {"text": "Our results show significant improvement over a majority class baseline as well as a more difficult baseline consisting of lexical n-grams.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is a much-researched area that deals with identification of positive, negative and neutral opinions in text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9552310407161713}, {"text": "identification of positive, negative and neutral opinions in text", "start_pos": 61, "end_pos": 126, "type": "TASK", "confidence": 0.8116964638233185}]}, {"text": "The task has evolved from document level analysis to sentence and phrasal level analysis.", "labels": [], "entities": [{"text": "document level analysis", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.6199817260106405}, {"text": "sentence and phrasal level analysis", "start_pos": 53, "end_pos": 88, "type": "TASK", "confidence": 0.6055964350700378}]}, {"text": "Whereas the former is suitable for classifying news (e.g., editorials vs. reports) into positive and negative, the latter is essential for question-answering and recommendation systems.", "labels": [], "entities": [{"text": "classifying news (e.g., editorials vs. reports)", "start_pos": 35, "end_pos": 82, "type": "TASK", "confidence": 0.786105215549469}]}, {"text": "A recommendation system, for example, must be able to recommend restaurants (or movies, books, etc.) based on a variety of features such as food, service or ambience.", "labels": [], "entities": []}, {"text": "Any single review sentence may contain both positive and negative opinions, evaluating different features of a restaurant.", "labels": [], "entities": []}, {"text": "Consider the following sentence (1) where the writer expresses opposing sentiments towards food and service of a restaurant.", "labels": [], "entities": []}, {"text": "In tasks such as this, therefore, it is important that sentiment analysis be done at the phrase level.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.9629642367362976}]}, {"text": "(1) The Taj has great food but I found their service to be lacking.", "labels": [], "entities": []}, {"text": "Subjective phrases in a sentence are carriers of sentiments in which an experiencer expresses an attitude, often towards a target.", "labels": [], "entities": []}, {"text": "These subjective phrases may express neutral or polar attitudes depending on the context of the sentence in which they appear.", "labels": [], "entities": []}, {"text": "Context is mainly determined by content and structure of the sentence.", "labels": [], "entities": []}, {"text": "For example, in the following sentence (2), the underlined subjective phrase seems to be negative, but in the larger context of the sentence, it is positive.", "labels": [], "entities": []}, {"text": "(2) The robber entered the store but his efforts were crushed when the police arrived on time.", "labels": [], "entities": []}, {"text": "Our task is to predict contextual polarity of subjective phrases in a sentence.", "labels": [], "entities": []}, {"text": "A traditional approach to this problem is to use a prior polarity lexicon of words to first set priors on target phrases and then make use of the syntactic and semantic information in and around the sentence to make the final prediction.", "labels": [], "entities": []}, {"text": "As in earlier approaches, we also use a lexicon to set priors, but we explore new uses of a Dictionary of Affect in Language (DAL) extended using WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 146, "end_pos": 153, "type": "DATASET", "confidence": 0.9528522491455078}]}, {"text": "We augment this approach with n-gram analysis to capture the effect of context.", "labels": [], "entities": []}, {"text": "We present a system for classification of neutral versus positive versus negative and positive versus negative polarity (as is also done by ).", "labels": [], "entities": []}, {"text": "Our approach is novel in the use of following features: \u2022 Lexical scores derived from DAL and extended through WordNet: The Dictionary of Affect has been widely used to aid in interpretation of emotion in speech.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9515558481216431}, {"text": "interpretation of emotion in speech", "start_pos": 176, "end_pos": 211, "type": "TASK", "confidence": 0.8647297978401184}]}, {"text": "It contains numeric scores assigned along axes of pleasantness, activeness and concreteness.", "labels": [], "entities": []}, {"text": "We introduce a method for setting numerical priors on words using these three axes, which we refer to as a \"scoring scheme\" throughout the paper.", "labels": [], "entities": []}, {"text": "This scheme has high coverage of the phrases for classification and requires no manual intervention when tagging words with prior polarities.", "labels": [], "entities": []}, {"text": "\u2022 N-gram Analysis: exploiting automatically derived polarity of syntactic constituents We compute polarity for each syntactic constituent in the input phrase using lexical affect scores for its words and extract n-grams over these constituents.", "labels": [], "entities": [{"text": "N-gram Analysis", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.6905025094747543}]}, {"text": "N-grams of syntactic constituents tagged with polarity provide patterns that improve prediction of polarity for the subjective phrase.", "labels": [], "entities": []}, {"text": "\u2022 Polarity of Surrounding Constituents: We use the computed polarity of syntactic constituents surrounding the phrase we want to classify.", "labels": [], "entities": []}, {"text": "These features help to capture the effect of context on the polarity of the subjective phrase.", "labels": [], "entities": []}, {"text": "We show that classification of subjective phrases using our approach yields better accuracy than two baselines, a majority class baseline and a more difficult baseline of lexical n-gram features.", "labels": [], "entities": [{"text": "classification of subjective phrases", "start_pos": 13, "end_pos": 49, "type": "TASK", "confidence": 0.8283049464225769}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990386962890625}]}, {"text": "We also provide an analysis of how the different component DAL scores contribute to our results through the introduction of a \"norm\" that combines the component scores, separating polar words that are less subjective (e.g., Christmas , murder) from neutral words that are more subjective (e.g., most, lack).", "labels": [], "entities": []}, {"text": "Section 2 presents an overview of previous work, focusing on phrasal level sentiment analysis.", "labels": [], "entities": [{"text": "phrasal level sentiment analysis", "start_pos": 61, "end_pos": 93, "type": "TASK", "confidence": 0.7578294277191162}]}, {"text": "Section 3 describes the corpus and the gold standard we used for our experiments.", "labels": [], "entities": []}, {"text": "In section 4, we give a brief description of DAL, discussing its utility and previous uses for emotion and for sentiment analysis.", "labels": [], "entities": [{"text": "DAL", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.7926013469696045}, {"text": "sentiment analysis", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.9696028530597687}]}, {"text": "Section 5 presents, in detail, our polarity classification framework.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7589935660362244}]}, {"text": "Here we describe our scoring scheme and the features we extract from sentences for classification tasks.", "labels": [], "entities": []}, {"text": "Experimental set-up and results are presented in Section 6.", "labels": [], "entities": []}, {"text": "We conclude with Section 7 where we also look at future directions for this research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Subjective phrases from the MPQA corpus were used in 10-fold cross-validation experiments.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9532037377357483}]}, {"text": "The MPQA corpus includes gold standard tags for each   phrase.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9806533753871918}]}, {"text": "A logistic classifier was used for two polarity classification tasks, positive versus negative versus neutral and positive versus negative.", "labels": [], "entities": []}, {"text": "We report accuracy, and F-measure for both balanced and unbalanced data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.995965838432312}, {"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9994120597839355}]}, {"text": "shows results fora 3-way classifier.", "labels": [], "entities": []}, {"text": "For the balanced data-set, each class has 2799 instances and hence the chance baseline is 33%.", "labels": [], "entities": [{"text": "chance baseline", "start_pos": 71, "end_pos": 86, "type": "METRIC", "confidence": 0.9735283851623535}]}, {"text": "For the unbalanced data-set, there are 2799 instances of positive, 6471 instances of negative and 7993 instances of neutral phrases and thus the baseline is about 46%.", "labels": [], "entities": []}, {"text": "Results show that the accuracy increases as more features are added.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9996070265769958}]}, {"text": "It maybe seen from the table that prior polarity scores do not do well alone, but when used in conjunction with other features they play an important role in achieving an accuracy much higher than both baselines (chance and lexical n-grams).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.998805046081543}]}, {"text": "To re- confirm if prior polarity scores add value, we experimented by using all features except the prior polarity scores and noticed a drop inaccuracy by about 4%.", "labels": [], "entities": []}, {"text": "This was found to be true for the other classification task as well.", "labels": [], "entities": [{"text": "classification task", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.9108670651912689}]}, {"text": "The and target neg . We thus learned n-gram patterns that are characteristic of neutral expressions (the just mentioned bigram and the first of the unigrams) as well as a pattern found mostly in negative expressions (the latter unigram).", "labels": [], "entities": []}, {"text": "It was surprising to find another top chunk feature, the bigram \" target neu [N P ] neg \" (i.e., a neutral chunk of syntactic type \"Other\" preceding a negative noun phrase), present in neutral expressions six times more than in polar expressions.", "labels": [], "entities": []}, {"text": "An instance where these chunk features could have been responsible for the correct prediction of a target phrase is shown in. shows an example sentence from the MPQA corpus, which has three annotated subjective phrases.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 161, "end_pos": 172, "type": "DATASET", "confidence": 0.9697307050228119}]}, {"text": "The manually labeled polarity of phrases (A) and (C) is negative and that of (B) is neutral.", "labels": [], "entities": []}, {"text": "shows the relevant chunk bigram which is used to predict the contextual polarity of the target phrase (B).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: DAL scores for words", "labels": [], "entities": [{"text": "DAL scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8846944272518158}]}, {"text": " Table 2: Example of scoring scheme using DAL", "labels": [], "entities": [{"text": "DAL", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.359350323677063}]}, {"text": " Table 3: Results of 3 way classification (Positive, Negative,  and Neutral). In the unbalanced case, majority class baseline  is 46.3% (*F-Measure).", "labels": [], "entities": [{"text": "majority class baseline", "start_pos": 102, "end_pos": 125, "type": "METRIC", "confidence": 0.7709633111953735}, {"text": "F-Measure", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9914143681526184}]}, {"text": " Table 4: Positive vs. Negative classification results. Baseline  is the majority class. In the unbalanced case, majority class  baseline is 69.74%. (* F-Measure)", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9931020736694336}]}]}