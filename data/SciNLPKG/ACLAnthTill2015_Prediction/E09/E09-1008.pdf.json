{"title": [{"text": "Correcting Automatic Translations through Collaborations between MT and Monolingual Target-Language Users", "labels": [], "entities": [{"text": "Correcting Automatic Translations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6758719682693481}]}], "abstractContent": [{"text": "Machine translation (MT) systems have improved significantly; however, their outputs often contain too many errors to communicate the intended meaning to their users.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8865022420883178}]}, {"text": "This paper describes a collabora-tive approach for mediating between an MT system and users who do not understand the source language and thus cannot easily detect translation mistakes on their own.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9341199398040771}]}, {"text": "Through a visualization of multiple linguistic resources, this approach enables the users to correct difficult translation errors and understand translated passages that were otherwise baffling.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent advances in machine translation (MT) have given us some very good translation systems.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.859573483467102}]}, {"text": "They can automatically translate between many languages fora variety of texts; and they are widely accessible to the public via the web.", "labels": [], "entities": []}, {"text": "The quality of the MT outputs, however, is not reliably high.", "labels": [], "entities": [{"text": "MT", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9783498048782349}]}, {"text": "People who do not understand the source language maybe especially baffled by the MT outputs because they have little means to recover from translation mistakes.", "labels": [], "entities": [{"text": "MT", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.9646115303039551}]}, {"text": "The goal of this work is to help monolingual target-language users to obtain better translations by enabling them to identify and overcome errors produced by the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 162, "end_pos": 164, "type": "TASK", "confidence": 0.8987821340560913}]}, {"text": "We argue fora human-computer collaborative approach because both the users and the MT system have gaps in their abilities that the other could compensate.", "labels": [], "entities": [{"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.8822020888328552}]}, {"text": "To facilitate this collaboration, we propose an interface that mediates between the user and the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.932353138923645}]}, {"text": "It manages additional NLP tools for the source language and translation resources so that the user can explore this extra information to gain enough understanding of the source text to correct MT errors.", "labels": [], "entities": [{"text": "MT", "start_pos": 193, "end_pos": 195, "type": "TASK", "confidence": 0.9719931483268738}]}, {"text": "The interactions between the users and the MT system may, in turn, offer researchers insights into the translation process and inspirations for better translation models.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9446548819541931}, {"text": "translation process", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.909412294626236}]}, {"text": "We have conducted an experiment in which we asked non-Chinese speakers to correct the outputs of a Chinese-English MT system for several short passages of different genres.", "labels": [], "entities": [{"text": "MT", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.8408011794090271}]}, {"text": "They performed the correction task both with the help of the visualization interface and without.", "labels": [], "entities": []}, {"text": "Our experiment addresses the following questions: \u2022 To what extent can the visual interface help the user to understand the source text?", "labels": [], "entities": []}, {"text": "\u2022 In what way do factors such as the user's backgrounds, the properties of source text, and the quality of the MT system and other NLP resources impact that understanding?", "labels": [], "entities": [{"text": "MT", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9441971182823181}]}, {"text": "\u2022 What resources or strategies are more helpful to the users?", "labels": [], "entities": []}, {"text": "What research directions do these observations suggest in terms of improving the translation models?", "labels": [], "entities": []}, {"text": "Through qualitative and quantitative analysis of the user actions and timing statistics, we have found that users of the interface achieved a more accurate understanding of the source texts and corrected more difficult translation mistakes than those who were given the MT outputs alone.", "labels": [], "entities": [{"text": "MT", "start_pos": 270, "end_pos": 272, "type": "TASK", "confidence": 0.890367329120636}]}, {"text": "Furthermore, we observed that some users made better use of the interface for certain genres, such as sports news, suggesting that the translation model maybe improved by a better integration of document-level contexts.", "labels": [], "entities": [{"text": "translation", "start_pos": 135, "end_pos": 146, "type": "TASK", "confidence": 0.963356077671051}]}], "datasetContent": [{"text": "We asked eight non-Chinese speakers to correct the machine translations of four short Chinese pascon released by the LDC; fora handful of characters that serve as function words, we added the functional definitions using an online dictionary http://www.mandarintools.com/worddict.html.", "labels": [], "entities": []}, {"text": "5 It is automatically generated by the Stanford Parser for Chinese (.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9055729508399963}]}, {"text": "We used for the information retrieval back-end; the parallel corpus is from the Federal Broadcast Information Service corpus; the monolingual corpus is from the Chinese Gigaword corpus.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7606770396232605}, {"text": "Federal Broadcast Information Service corpus", "start_pos": 80, "end_pos": 124, "type": "DATASET", "confidence": 0.8903430342674256}, {"text": "Chinese Gigaword corpus", "start_pos": 161, "end_pos": 184, "type": "DATASET", "confidence": 0.8024205764134725}]}, {"text": "The interface for users who are correcting translations without help; they have access to the document view, but they do not have access to any of the other resources.", "labels": [], "entities": [{"text": "correcting translations", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.8854052424430847}]}, {"text": "sages, with an average length of 11.5 sentences.", "labels": [], "entities": []}, {"text": "Two passages are news articles and two are excerpts of a fictional work.", "labels": [], "entities": []}, {"text": "Each participant was instructed to correct the translations for one news article and one fictional passage using all the resources made available by The Chinese Room and the other two passages without.", "labels": [], "entities": [{"text": "The Chinese Room", "start_pos": 149, "end_pos": 165, "type": "DATASET", "confidence": 0.8717193404833475}]}, {"text": "To keep the experimental conditions as similar as possible, we provided them with a restricted version of the interface (see fora screen-shot) in which all additional functionalities except for the Document View Tab are disabled.", "labels": [], "entities": []}, {"text": "We assigned each person to alternate between working with the full and the restricted versions of the system; half began without, and the others began with.", "labels": [], "entities": []}, {"text": "Thus, every passage received four sets of corrections made collaboratively with the system and four sets of corrections made based solely on the participants' internal language models.", "labels": [], "entities": []}, {"text": "All together, there are 184 participant corrected sentences (11.5 sentences \u00d7 4 passages \u00d7 4 participants) for each condition.", "labels": [], "entities": []}, {"text": "The participants were asked to complete each passage in one sitting.", "labels": [], "entities": []}, {"text": "Within a passage, they could work on the sentences in any arbitrary order.", "labels": [], "entities": []}, {"text": "They could also elect to \"pass\" any part of a sentence if they found it too difficult to correct.", "labels": [], "entities": []}, {"text": "Timing statistics were automatically collected while they made their corrections.", "labels": [], "entities": []}, {"text": "We interviewed each participant for qualitative feedbacks after all four passages were corrected.", "labels": [], "entities": []}, {"text": "Next, we asked two bilingual speakers to evaluate all the corrected translations.", "labels": [], "entities": []}, {"text": "The outcomes between different groups of users are compared, and the significance of the difference is determined using the two-sample t-test assuming unequal variances.", "labels": [], "entities": []}, {"text": "We require 90% confidence (alpha=0.1) as the cut-off fora difference to be considered statistically significant; when the difference can be established with higher confidence, we report that value.", "labels": [], "entities": []}, {"text": "In the following subsections, we describe the conditions of this study in more details.", "labels": [], "entities": []}, {"text": "Participants' Background For this study, we strove to maintain a relatively heterogeneous population; participants were selected to be varied in their exposures to NLP, experiences with foreign languages, as well as their age and gender.", "labels": [], "entities": []}, {"text": "A summary of their backgrounds is shown in.", "labels": [], "entities": []}, {"text": "Prior to the start of the study, the participants received a 20 minute long presentational tutorial about the basic functionalities supported by our system, but they did not have an opportunity to explore the system on their own.", "labels": [], "entities": []}, {"text": "This helps us to determine whether our interface is intuitive enough for new users to pickup quickly.", "labels": [], "entities": []}, {"text": "Data The four passages used for this study were chosen to span a range of difficulties and genre types.", "labels": [], "entities": []}, {"text": "The easiest of the four is a news article about anew Tamagotchi-like product from Bandai.", "labels": [], "entities": []}, {"text": "It was taken from a webpage that offers bilingual news to help Chinese students to learn English.", "labels": [], "entities": []}, {"text": "A harder news article is taken from a past NIST Chinese-English MT Evaluation; it is about Michael Jordan's knee injury.", "labels": [], "entities": [{"text": "NIST Chinese-English MT Evaluation", "start_pos": 43, "end_pos": 77, "type": "DATASET", "confidence": 0.8213064819574356}]}, {"text": "For a different genre, we considered two fictional excerpts from the first chapter of Martin Eden, a novel by Jack London that has been professionally translated into Chinese . One excerpt featured a short dialog, while the other one was purely descriptive.", "labels": [], "entities": []}, {"text": "Evaluation of Translations Bilingual human judges are presented with the source text as well as the parallel English text for reference.", "labels": [], "entities": []}, {"text": "Each judge is then shown a set of candidate translations (the original MT output, an alternative translation by a bilingual speaker, and corrected translations by the participants) in a randomized order.", "labels": [], "entities": []}, {"text": "Since the human corrected translations are likely to be fluent, we have instructed the judges to concentrate more on the adequacy of the meaning conveyed.", "labels": [], "entities": []}, {"text": "They are asked to rate each sentence on an abso- Most of the meaning is conveyed.", "labels": [], "entities": [{"text": "abso-", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.9726560413837433}]}, {"text": "5-6 Misunderstands the sentence in a major way; or has many small mistakes.", "labels": [], "entities": []}, {"text": "3-4 Very little meaning is conveyed.", "labels": [], "entities": []}, {"text": "1-2 The translation makes no sense at all.", "labels": [], "entities": [{"text": "translation", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.9664170145988464}]}, {"text": "lute scale of 1-10 using the guideline in.", "labels": [], "entities": []}, {"text": "To reduce the biases in the rating scales of different judges, we normalized the judges' scores, following standard practices in MT evaluation (.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 129, "end_pos": 142, "type": "TASK", "confidence": 0.9097114503383636}]}, {"text": "Post normalization, the correlation coefficient between the judges is 0.64.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 24, "end_pos": 47, "type": "METRIC", "confidence": 0.9834255576133728}]}, {"text": "The final assessment score for each translated sentence is the average of judges' scores, on a scale of 0-1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Averaged human judgments of the translation quality of the four different approaches: automatic  MT, corrections by participants without help, corrections by participants using The Chinese Room, and  translation produced by a bilingual speaker. The second column reports score for all documents; columns  3-6 show the per-document scores.", "labels": [], "entities": [{"text": "MT", "start_pos": 107, "end_pos": 109, "type": "TASK", "confidence": 0.9618326425552368}]}, {"text": " Table 4: The average amount of time (minutes) participants spent on correcting a sentence.", "labels": [], "entities": [{"text": "correcting a sentence", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.8423637946446737}]}, {"text": " Table 6: The quality of the corrections produced  by four participants using The Chinese Room for  the sports news article.  User1  0.57  User2  0.46  User5  0.70  User6  0.73  bilingual translator 0.73", "labels": [], "entities": [{"text": "The Chinese Room", "start_pos": 78, "end_pos": 94, "type": "DATASET", "confidence": 0.688706656297048}]}, {"text": " Table 5. In each  case, the two groups had similar levels of perfor- mance, and the differences between their correc- tions were not statistically significant. This trend  holds for both when they were collaborating with  the system and when editing on their own.", "labels": [], "entities": []}, {"text": " Table 5: A comparison of translation quality, grouped by four characteristics of participant backgrounds:  their level of exposure to NLP, exposure to another language, their gender, and education level.", "labels": [], "entities": [{"text": "translation", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.970478355884552}]}]}