{"title": [{"text": "Optimization in Coreference Resolution Is Not Needed: A Nearly-Optimal Algorithm with Intensional Constraints", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.9593267738819122}]}], "abstractContent": [{"text": "We show how global constraints such as transitiv-ity can be treated intensionally in a Zero-One Integer Linear Programming (ILP) framework which is geared to find the optimal and coherent partition of coreference sets given a number of candidate pairs and their weights delivered by a pairwise classifier (used as reliable clustering seed pairs).", "labels": [], "entities": []}, {"text": "In order to find out whether ILP optimization, which is NP-complete, actually is the best we can do, we compared the first consistent solution generated by our adaptation of an efficient Zero-One algorithm with the optimal solution.", "labels": [], "entities": [{"text": "ILP optimization", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.9298509955406189}]}, {"text": "The first consistent solution, which often can be found very fast, is already as good as the optimal solution; optimization is thus not needed.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the main advantages of Integer Linear Programming (ILP) applied to NLP problems is that prescriptive linguistic knowledge can be used to pose global restrictions on the set of desirable solutions.", "labels": [], "entities": []}, {"text": "ILP tries to find an optimal solution while adhering to the global constraints.", "labels": [], "entities": [{"text": "ILP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8778359889984131}]}, {"text": "One of the central global constraints in the field of coreference resolution evolves from the interplay of intrasentential binding constraints and the transitivity of the anaphoric relation.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9701075255870819}]}, {"text": "Consider the following sentence taken from the Internet: 'He told him that he deeply admired him'.", "labels": [], "entities": []}, {"text": "'He' and 'him' are exclusive (i.e. they could never be coreferent) within their clauses (the main and the subordinate clause, respectively).", "labels": [], "entities": []}, {"text": "A pairwise classifier could learn this given appropriate features or, alternatively, binding constraints could act as a hard filter preventing such pairs from being generated at all.", "labels": [], "entities": []}, {"text": "But in either case, since pairwise classification is trapped in its local perspective, nothing can prevent the classifier to resolve the 'he' and 'him' from the subordinate clause in two independently carried out steps to the same antecedent from the main clause.", "labels": [], "entities": [{"text": "pairwise classification", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.6131036579608917}]}, {"text": "It is transitivity that prohibits such an assignment: if two elements are both coreferent to a common third element, then the two are (transitively given) coreferent as well.", "labels": [], "entities": []}, {"text": "If they are known to be exclusive, such an assignment is disallowed.", "labels": [], "entities": []}, {"text": "But transitivity is beyond the scope of pairwise classification-it is a global phenomena.", "labels": [], "entities": [{"text": "pairwise classification-it", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.695442795753479}]}, {"text": "The solution is to take ILP as a clustering device, where the probabilities of the pairwise classifier are interpreted as weights and transitivity and other restrictions are acting as global constraints.", "labels": [], "entities": []}, {"text": "Unfortunately, in an ILP program every constraint has to be extensionalized (i.e. all instantiations of the constraint are to be generated).", "labels": [], "entities": []}, {"text": "Capturing transitivity for e.g. 150 noun phrases (about 30 sentences) already produces 1,500,000 equations (cf. Section 4).", "labels": [], "entities": []}, {"text": "Solving such ILP programs is far too slow for real applications (let alone its brute force character).", "labels": [], "entities": []}, {"text": "A closer look at existing ILP approaches to NLP reveals that they are of a special kind, namely Zero-One ILP with unweighted constraints.", "labels": [], "entities": []}, {"text": "Although still NP-complete there exist a number of algorithms such as the Balas algorithm that efficiently explore the search space and reduce thereby run time complexity in the mean.", "labels": [], "entities": []}, {"text": "We have adapted Balas' algorithm to the special needs of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.9697472751140594}]}, {"text": "First and foremost, this results in an optimization algorithm that treats global constraints intensionally, i.e. that generates instantiations of a constraint only on demand.", "labels": [], "entities": []}, {"text": "Thus, transitivity can be captured for even the longest texts.", "labels": [], "entities": []}, {"text": "But more important, we found out empirically that 'full optimization' is not really needed.", "labels": [], "entities": [{"text": "full optimization'", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7859558264414469}]}, {"text": "The first consistent solution, which often can be found very fast, is already as goodin terms of F-measure values-as the optimal solution.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9276145100593567}]}, {"text": "This is good news, since it reduces runtime and at same time maintains the empirical results.", "labels": [], "entities": []}, {"text": "We first introduce Zero-One ILP, discuss our baseline model and give an ILP formalization of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.9685554802417755}]}, {"text": "Then we go into the details of our Balas adaptation and provide empirical evidence for our central claim-that optimization search can already be stopped (without qual-ity loss) when the first consistent solution has been found.", "labels": [], "entities": [{"text": "Balas adaptation", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.5088723301887512}, {"text": "optimization search", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.9325437545776367}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Balas-First (B-First) vs. Baseline", "labels": [], "entities": [{"text": "Balas-First (B-First)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.5817294046282768}, {"text": "Baseline", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.8125708103179932}]}, {"text": " Table 3: Balas Order vs. Linear Order", "labels": [], "entities": [{"text": "Balas Order", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.4360491633415222}]}]}