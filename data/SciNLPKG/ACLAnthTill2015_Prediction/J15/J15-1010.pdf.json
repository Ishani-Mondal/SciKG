{"title": [{"text": "When the Whole Is Not Greater Than the Combination of Its Parts: A \"Decompositional\" Look at Compositional Distributional Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Distributional semantics has been extended to phrases and sentences by means of composition operations.", "labels": [], "entities": []}, {"text": "We look at how these operations affect similarity measurements, showing that similarity equations of an important class of composition methods can be decomposed into operations performed on the subparts of the input phrases.", "labels": [], "entities": []}, {"text": "This establishes a strong link between these models and convolution kernels.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional semantics approximates word meanings with vectors tracking cooccurrence in corpora.", "labels": [], "entities": []}, {"text": "Recent work has extended this approach to phrases and sentences through vector composition.", "labels": [], "entities": []}, {"text": "Resulting compositional distributional semantic models (CDSMs) estimate degrees of semantic similarity (or, more generally, relatedness) between two phrases: A good CDSM might tell us that green bird is closer to parrot than to pigeon, useful for tasks such as paraphrasing.", "labels": [], "entities": []}, {"text": "We take a mathematical look 1 at how the composition operations postulated by CDSMs affect similarity measurements involving the vectors they produce for phrases or sentences.", "labels": [], "entities": []}, {"text": "We show that, for an important class of composition methods, encompassing at least those based on linear transformations, the similarity equations can be decomposed into operations performed on the subparts of the input phrases, and typically factorized into terms that reflect the linguistic structure of the input.", "labels": [], "entities": []}, {"text": "This establishes a strong link between CDSMs and convolution kernels), which act in the same way.", "labels": [], "entities": []}, {"text": "We thus refer to our claim as the \"Convolution Conjecture.\"", "labels": [], "entities": []}, {"text": "We focus on the models in.", "labels": [], "entities": []}, {"text": "These CDSMs all apply linear methods, and we suspect that linearity is a sufficient (but not necessary) condition to ensure that the Convolution Conjecture holds.", "labels": [], "entities": []}, {"text": "We will first illustrate the conjecture for linear methods, and then briefly consider two nonlinear approaches: the dual space model of, for which it does, and a representative of the recent strand of work on neuralnetwork models of composition, for which it does not.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}