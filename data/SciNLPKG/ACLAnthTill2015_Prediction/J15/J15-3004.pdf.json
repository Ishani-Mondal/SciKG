{"title": [{"text": "Computational Constancy Measures of Texts-Yule's K and R\u00e9nyi's Entropy", "labels": [], "entities": [{"text": "Computational Constancy Measures of Texts-Yule's K", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7599277794361115}]}], "abstractContent": [{"text": "This article presents a mathematical and empirical verification of computational constancy measures for natural language text.", "labels": [], "entities": []}, {"text": "A constancy measure characterizes a given text by having an invariant value for any size larger than a certain amount.", "labels": [], "entities": []}, {"text": "The study of such measures has a 70-year history dating back to Yule's K, with the original intended application of author identification.", "labels": [], "entities": [{"text": "Yule's K", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8998708526293436}, {"text": "author identification", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.7817263305187225}]}, {"text": "We examine various measures proposed since Yule and reconsider reports made so far, thus overviewing the study of constancy measures.", "labels": [], "entities": [{"text": "Yule", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.8424611687660217}]}, {"text": "We then explain how K is essentially equivalent to an approximation of the second-order R\u00e9nyi entropy, thus indicating its signification within language science.", "labels": [], "entities": []}, {"text": "We then empirically examine constancy measure candidates within this new, broader context.", "labels": [], "entities": []}, {"text": "The approximated higher-order entropy exhibits stable convergence across different languages and kinds of text.", "labels": [], "entities": []}, {"text": "We also show, however, that it cannot identify authors, contrary to Yule's intention.", "labels": [], "entities": [{"text": "Yule's intention", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.9040304025014242}]}, {"text": "Lastly, we apply K to two unknown scripts, the Voynich manuscript and Rongorongo, and show how the results support previous hypotheses about these scripts.", "labels": [], "entities": [{"text": "Voynich manuscript", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.8140424489974976}]}], "introductionContent": [{"text": "A constancy measure fora natural language text is defined, in this article, as a computational measure that converges to a value fora certain amount of text and remains invariant for any larger size.", "labels": [], "entities": []}, {"text": "Because such a measure exhibits the same value for any size of text larger than a certain amount, its value could be considered as a text characteristic.", "labels": [], "entities": []}, {"text": "The concept of such a text constancy measure was introduced by in the form of his measure K.", "labels": [], "entities": []}, {"text": "Since Yule, there has been a continuous quest for such measures, and various formulae have been proposed.", "labels": [], "entities": [{"text": "Yule", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.8833634257316589}]}, {"text": "They can be broadly categorized into three types, namely, those measuring (1) repetitiveness, (2) power law character, and (3) complexity.", "labels": [], "entities": []}, {"text": "Yule's original intention for K's utility lay in author identification, assuming that it would differ for texts written by different authors.", "labels": [], "entities": [{"text": "Yule", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7985236048698425}, {"text": "K", "start_pos": 30, "end_pos": 31, "type": "TASK", "confidence": 0.9503163695335388}, {"text": "author identification", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7515506148338318}]}, {"text": "State-of-the-art multivariate machine learning techniques are powerful, however, for solving such language engineering tasks, in which Yule's K is used only as one variable among many, as reported in and.", "labels": [], "entities": []}, {"text": "We believe that constancy measures today, however, have greater importance in understanding the mathematical nature of language.", "labels": [], "entities": []}, {"text": "Although mathematical models of language have been studied in the computational linguistics milieu, via Markov models (), Zipf's law and its modifications, and Pitman-Yor models) more recently, the true mathematical model of linguistic processes is ultimately unknown.", "labels": [], "entities": []}, {"text": "Therefore, the convergence of a constancy measure must be examined through empirical verification.", "labels": [], "entities": []}, {"text": "Because some constancy measures have a mathematical theory of convergence fora known process, discrepancies in the behavior of real linguistic data from such a theory would shed light on the nature of linguistic processes and give hints towards improving the mathematical models.", "labels": [], "entities": []}, {"text": "Furthermore, as one application, a convergent measure would allow for comparison of different texts through a common, stable norm, provided that the measure converges fora sufficiently small amount of text.", "labels": [], "entities": []}, {"text": "One of our goals is to discover a non-trivial measure with a certain convergence speed that distinguishes the different natures of texts.", "labels": [], "entities": []}, {"text": "The objective of this article is thus to provide a potential explanation of what the study of constancy measures over 70 years has been about, by answering the three following questions mathematically and empirically:", "labels": [], "entities": []}], "datasetContent": [{"text": "From the previous discussion, we applied the three measures V, h 1 , and H 2 with five large-scale and eight small-scale natural language corpora, three programming language corpora, and two unknown script corpora, in terms of words and characters.", "labels": [], "entities": []}, {"text": "Because there were many results for different combinations of measure, data, and token (word or character), this section is structured so that it best highlights our findings.", "labels": [], "entities": []}], "tableCaptions": []}