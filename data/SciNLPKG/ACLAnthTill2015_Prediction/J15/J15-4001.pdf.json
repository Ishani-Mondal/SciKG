{"title": [{"text": "Graph-Based Word Alignment for Clinical Language Evaluation", "labels": [], "entities": [{"text": "Graph-Based Word Alignment", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6282620330651602}, {"text": "Clinical Language Evaluation", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.7179371118545532}]}], "abstractContent": [{"text": "Among the more recent applications for natural language processing algorithms has been the analysis of spoken language data for diagnostic and remedial purposes, fueled by the demand for simple, objective, and unobtrusive screening tools for neurological disorders such as dementia.", "labels": [], "entities": [{"text": "natural language processing algorithms", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.7412387728691101}]}, {"text": "The automated analysis of narrative retellings in particular shows potential as a component of such a screening tool since the ability to produce accurate and meaningful narratives is noticeably impaired in individuals with dementia and its frequent precursor, mild cognitive impairment , as well as other neurodegenerative and neurodevelopmental disorders.", "labels": [], "entities": []}, {"text": "In this article, we present a method for extracting narrative recall scores automatically and highly accurately from a word-level alignment between a retelling and the source narrative.", "labels": [], "entities": [{"text": "recall scores", "start_pos": 62, "end_pos": 75, "type": "METRIC", "confidence": 0.7764541506767273}]}, {"text": "We propose improvements to existing machine translation-based systems for word alignment, including a novel method of word alignment relying on random walks on a graph that achieves alignment accuracy superior to that of standard expectation maximization-based techniques for word alignment in a fraction of the time required for expectation maximization.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.8319695591926575}, {"text": "word alignment", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.8362396955490112}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.9473906755447388}, {"text": "word alignment", "start_pos": 276, "end_pos": 290, "type": "TASK", "confidence": 0.8013068735599518}]}, {"text": "In addition, the narrative recall score features extracted from these high-quality word alignments yield diagnostic classification accuracy comparable to that achieved using manually assigned scores and significantly higher than that achieved with summary-level text similarity metrics used in other areas of NLP.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.8303349018096924}]}, {"text": "These methods can be trivially adapted to spontaneous language samples elicited with non-linguistic stimuli, thereby demonstrating the flexibility and generalizability of these methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interest in applying natural language processing (NLP) technology to medical information has increased in recent years.", "labels": [], "entities": []}, {"text": "Much of this work has been focused on information retrieval and extraction from clinical notes, electronic medical records, and biomedical academic literature, but there has been some work in directly analyzing the spoken language of individuals elicited during the administration of diagnostic instruments in clinical settings.", "labels": [], "entities": [{"text": "information retrieval and extraction from clinical notes", "start_pos": 38, "end_pos": 94, "type": "TASK", "confidence": 0.7929294322218213}]}, {"text": "Analyzing spoken language data can reveal information not only about impairments in language but also about a patient's neurological status with respect to other cognitive processes such as memory and executive function, which are often impaired in individuals with neurodevelopmental disorders, such as autism and language impairment, and neurodegenerative conditions, particularly dementia.", "labels": [], "entities": []}, {"text": "Many widely used instruments for diagnosing certain neurological disorders include a task in which the person must produce an uninterrupted stream of spontaneous spoken language in response to a stimulus.", "labels": [], "entities": []}, {"text": "A person might be asked, for instance, to retell a brief narrative or to describe the events depicted in a drawing.", "labels": [], "entities": []}, {"text": "Much of the previous work in applying NLP techniques to such clinically elicited spoken language data has relied on parsing and language modeling to enable the automatic extraction of linguistic features, such as syntactic complexity and measures of vocabulary use and diversity, which can then be used as markers for various neurological impairments (Solorio and Liu 2008;; de la).", "labels": [], "entities": []}, {"text": "In this article, we instead use NLP techniques to analyze the content, rather than the linguistic characteristics, of weakly structured spoken language data elicited using neuropsychological assessment instruments.", "labels": [], "entities": []}, {"text": "We will show that the content of such spoken responses contains information that can be used for accurate screening for neurodegenerative disorders.", "labels": [], "entities": []}, {"text": "The features we explore are grounded in the idea that individuals recalling the same narrative are likely to use the same sorts of words and semantic concepts.", "labels": [], "entities": []}, {"text": "In other words, a retelling of a narrative will be faithful to the source narrative and similar to other retellings.", "labels": [], "entities": []}, {"text": "This similarity can be measured with techniques such as latent semantic analysis (LSA) cosine distance or the summary-level statistics that are widely used in evaluation of machine translation or automatic summarization, such as BLEU, Meteor, or ROUGE.", "labels": [], "entities": [{"text": "latent semantic analysis (LSA) cosine distance", "start_pos": 56, "end_pos": 102, "type": "METRIC", "confidence": 0.6884634084999561}, {"text": "machine translation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.7940759658813477}, {"text": "BLEU", "start_pos": 229, "end_pos": 233, "type": "METRIC", "confidence": 0.9851574897766113}, {"text": "ROUGE", "start_pos": 246, "end_pos": 251, "type": "METRIC", "confidence": 0.7400866150856018}]}, {"text": "Perhaps not surprisingly, however, previous work in using this type of spoken language data suggests that people with neurological impairments tend to include irrelevant or off-topic information and to exclude important pieces of information, or story elements, in their retellings that are usually included by neurotypical individuals.", "labels": [], "entities": []}, {"text": "Thus, it is often not the quantity of correctly recalled information but the quality of that information that reveals the most about a person's diagnostic status.", "labels": [], "entities": []}, {"text": "Summary statistics like LSA cosine distance and BLEU, which are measures of the overall degree of similarity between two texts, fail to capture these sorts of patterns.", "labels": [], "entities": [{"text": "LSA cosine distance", "start_pos": 24, "end_pos": 43, "type": "METRIC", "confidence": 0.8669159213701884}, {"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9954814910888672}]}, {"text": "The work discussed here is an attempt to reveal these patterns and to leverage them for diagnostic classification of individuals with neurodegenerative conditions, including mild cognitive impairment and dementia of the Alzheimer's type.", "labels": [], "entities": []}, {"text": "Our method for extracting the elements used in a retelling of a narrative relies on establishing a word alignment between a retelling and a source narrative.", "labels": [], "entities": []}, {"text": "Given the correspondences between the words used in a retelling and the words used in the source narrative, we can determine with relative ease the identities of the story elements of the source narrative that were used in the retelling.", "labels": [], "entities": []}, {"text": "These word alignments are much like those used to build machine translation models.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.7131612598896027}, {"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.6939513087272644}]}, {"text": "The amount of data required to generate accurate word alignment models for machine translation, however, far exceeds the amount of monolingual source-to-retelling parallel data available to train word alignment models for our task.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.7352876663208008}, {"text": "machine translation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.771343469619751}, {"text": "word alignment", "start_pos": 196, "end_pos": 210, "type": "TASK", "confidence": 0.7206166237592697}]}, {"text": "We therefore combine several approaches for producing reliable word alignments that exploit the peculiarities of our training data, including an entirely novel alignment approach relying on random walks on graphs.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7121595442295074}]}, {"text": "In this article, we demonstrate that this approach to word alignment is as accurate as and more efficient than standard hidden Markov model (HMM)-based alignment (derived using the Berkeley aligner) for this particular data.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.8152413368225098}]}, {"text": "In addition, we show that the presence or absence of specific story elements in a narrative retelling, extracted automatically from these task-specific word alignments, predicts diagnostic group membership more reliably than not only other dementia screening tools but also the lexical and semantic overlap measures widely used in NLP to evaluate pairwise language sample similarity.", "labels": [], "entities": []}, {"text": "Finally, we apply our techniques to a picture description task that lacks an existing scoring mechanism, highlighting the generalizability and adaptability of these techniques.", "labels": [], "entities": []}, {"text": "The importance of accurate screening tools for neurodegenerative disorders cannot be overstated given the increased prevalence of these disorders currently being observed worldwide.", "labels": [], "entities": []}, {"text": "In the industrialized world, for the first time in recorded history, the population over 60 years of age outnumbers the population under 15 years of age, and it is expected to be double that of children by.", "labels": [], "entities": []}, {"text": "As the elderly population grows and as researchers find new ways to slow or halt the progression of dementia, the demand for objective, simple, and noninvasive screening tools for dementia and related disorders will grow.", "labels": [], "entities": []}, {"text": "Although we will not discuss the application of our methods to the narratives of children, the need for simple screening protocols for neurodevelopmental disorders such as autism and language impairment is equally urgent.", "labels": [], "entities": []}, {"text": "The results presented here indicate that the path toward these goals might include automated spoken language analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "The participants for this study were drawn from an ongoing study of brain aging at the Layton Aging and Alzheimer's Disease Center at the Oregon Health and Science University.", "labels": [], "entities": [{"text": "Layton Aging and Alzheimer's Disease", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.6122210125128428}]}, {"text": "Seventy-two of these participants had received a diagnosis of MCI, and 163 individuals served as typically aging controls.", "labels": [], "entities": []}, {"text": "Demographic information about the experimental participants is shown in.", "labels": [], "entities": []}, {"text": "There were no significant differences in age and years of education between the two groups.", "labels": [], "entities": []}, {"text": "The Layton Center data included retellings for individuals who were not eligible for the present study because of their age or diagnosis.", "labels": [], "entities": [{"text": "Layton Center data", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9792361656824747}]}, {"text": "Transcriptions of 48 retellings produced by these ineligible participants were used to train and tune the word alignment model but were not used to evaluate the word alignment, scoring, or classification accuracy.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.7173582315444946}, {"text": "word alignment", "start_pos": 161, "end_pos": 175, "type": "TASK", "confidence": 0.6733950674533844}, {"text": "accuracy", "start_pos": 204, "end_pos": 212, "type": "METRIC", "confidence": 0.8402055501937866}]}, {"text": "We diagnose MCI using the Clinical Dementia Rating (CDR) scale (Morris 1993), following earlier work on MCI (, as well as the work of, who have previously attempted diagnostic classification using neuropsychological instrument subtest responses.", "labels": [], "entities": [{"text": "Clinical Dementia Rating (CDR) scale", "start_pos": 26, "end_pos": 62, "type": "METRIC", "confidence": 0.6479192801884243}, {"text": "diagnostic classification", "start_pos": 165, "end_pos": 190, "type": "TASK", "confidence": 0.6967791765928268}]}, {"text": "The CDR is a numerical dementia staging scale that indicates the presence of dementia and its level of severity.", "labels": [], "entities": []}, {"text": "The CDR score is derived from measures of cognitive function in six domains: Memory; Orientation; Judgment and Problem Solving; Community Affairs; Home and Hobbies; and Personal Care.", "labels": [], "entities": [{"text": "Judgment and Problem Solving", "start_pos": 98, "end_pos": 126, "type": "TASK", "confidence": 0.6255776658654213}]}, {"text": "These measures are determined during an extensive semi-structured interview with the patient and a close family member or caregiver.", "labels": [], "entities": []}, {"text": "A CDR of 0 indicates the absence of dementia, and a CDR of 0.5 corresponds to a diagnosis of MCI (.", "labels": [], "entities": [{"text": "CDR", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.9551342725753784}]}, {"text": "This measure has high expert interrater reliability and is assigned without any information derived from the WLM subtest.", "labels": [], "entities": [{"text": "reliability", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.511361837387085}, {"text": "WLM subtest", "start_pos": 109, "end_pos": 120, "type": "DATASET", "confidence": 0.6756862252950668}]}, {"text": "Recall the two baseline alignment models generated by the Berkeley aligner, described in Section 5.4: (1) the small Berkeley model, trained on Corpus 1 (the source-to-retelling corpus) and 10 instances of Corpus 3 (the word identity corpus), and (2) the large Berkeley model (trained on Corpus 1, Corpus 2, the full pairwise retelling-to-retelling corpus, and 100 instances of Corpus 3).", "labels": [], "entities": []}, {"text": "Using these models, we generate full retellingto-retelling alignments, on which we can then build two graph-based alignment models: the small graph-based model and the large graph-based model.", "labels": [], "entities": []}, {"text": "The manual gold alignments for the 235 experimental participants were evaluated against the alignments produced by each of the four models.", "labels": [], "entities": []}, {"text": "presents the precision, recall, and AER for the alignments of the experimental participants.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9997226595878601}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9988991022109985}, {"text": "AER", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9997386336326599}]}, {"text": "Not surprisingly, the larger models yield lower error rates than the smaller models.", "labels": [], "entities": [{"text": "error rates", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9712682664394379}]}, {"text": "More interestingly, each graph-based model outperforms the Berkeley model of the corresponding size by a large margin.", "labels": [], "entities": []}, {"text": "The performance of the small graph-based model is particularly remarkable because it yields an AER superior to the large Berkeley model while requiring significantly fewer computing resources.", "labels": [], "entities": [{"text": "AER", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.9967342615127563}]}, {"text": "Each of the graphbased models generated the full set of alignments in only a few minutes, whereas the large Berkeley model required 14 hours of training.", "labels": [], "entities": []}, {"text": "The element-level scores induced, as described in Section 5.2, from the four word alignments for all 235 experimental participants were evaluated against the manual per-element scores.", "labels": [], "entities": []}, {"text": "We report the precision, recall, and F-measure for all four alignment models in.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.999799907207489}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9995352029800415}, {"text": "F-measure", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9997097849845886}]}, {"text": "In addition, we report Cohen's kappa as a measure of reliability between our automated scores and the manually assigned scores.", "labels": [], "entities": [{"text": "reliability", "start_pos": 53, "end_pos": 64, "type": "METRIC", "confidence": 0.9824926853179932}]}, {"text": "We see that as AER improves, scoring accuracy also improves, with the large graph-based model outperforming all other models in terms of precision, F-measure, and inter-rater reliability.", "labels": [], "entities": [{"text": "AER", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9567399621009827}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9673638939857483}, {"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9995637536048889}, {"text": "F-measure", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9960060715675354}]}, {"text": "The scoring accuracy levels reported here are comparable to the levels of inter-rater agreement typically reported for the WLM, and reliability between our automated scores and the manual scores, as measured by Cohen's kappa, is well within the ranges reported in the literature.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.8371424674987793}, {"text": "WLM", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.6391346454620361}, {"text": "reliability", "start_pos": 132, "end_pos": 143, "type": "METRIC", "confidence": 0.970761239528656}]}, {"text": "As will be shown in the following section, scoring accuracy is important for achieving high classification accuracy of MCI.", "labels": [], "entities": [{"text": "scoring", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9262005090713501}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.8912405967712402}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.8971247673034668}]}], "tableCaptions": [{"text": " Table 2  Layton Center participant demographic data. Neither age nor years of education were  significantly different between groups.", "labels": [], "entities": [{"text": "Layton Center participant demographic", "start_pos": 10, "end_pos": 47, "type": "DATASET", "confidence": 0.9704839736223221}]}, {"text": " Table 3  Baseline classification accuracy results and standard deviation (s.d.).", "labels": [], "entities": [{"text": "Baseline classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.4833710342645645}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9781931638717651}, {"text": "standard deviation", "start_pos": 55, "end_pos": 73, "type": "METRIC", "confidence": 0.956741064786911}]}, {"text": " Table 7  Scoring accuracy results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.965844988822937}]}, {"text": " Table 8  Classification accuracy results measured by AUC (standard deviation).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8795864582061768}, {"text": "AUC", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9953969120979309}]}]}