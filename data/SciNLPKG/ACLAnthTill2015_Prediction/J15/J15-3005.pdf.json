{"title": [{"text": "Discriminative Syntax-Based Word Ordering for Text Generation", "labels": [], "entities": [{"text": "Discriminative Syntax-Based Word Ordering", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6011411994695663}, {"text": "Text Generation", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7178897559642792}]}], "abstractContent": [{"text": "Word ordering is a fundamental problem in text generation.", "labels": [], "entities": [{"text": "Word ordering", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7275101393461227}, {"text": "text generation", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.7284596860408783}]}, {"text": "In this article, we study word ordering using a syntax-based approach and a discriminative model.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.7689475119113922}]}, {"text": "Two grammar formalisms are considered: Combinatory Categorial Grammar (CCG) and dependency grammar.", "labels": [], "entities": []}, {"text": "Given the search fora likely string and syntactic analysis, the search space is massive, making discrimi-native training challenging.", "labels": [], "entities": []}, {"text": "We develop a learning-guided search framework, based on best-first search, and investigate several alternative training algorithms.", "labels": [], "entities": []}, {"text": "The framework we present is flexible in that it allows constraints to be imposed on output word orders.", "labels": [], "entities": []}, {"text": "To demonstrate this flexibility, a variety of input conditions are considered.", "labels": [], "entities": []}, {"text": "First, we investigate a \"pure\" word-ordering task in which the input is a multi-set of words, and the task is to order them into a grammatical and fluent sentence.", "labels": [], "entities": []}, {"text": "This task has been tackled previously, and we report improved performance over existing systems on a standard Wall Street Journal test set.", "labels": [], "entities": [{"text": "Wall Street Journal test set", "start_pos": 110, "end_pos": 138, "type": "DATASET", "confidence": 0.9792669415473938}]}, {"text": "Second, we tackle the same reordering problem, but with a variety of input conditions, from the bare case with no dependencies or POS tags specified, to the extreme case where all POS tags and unordered, unlabeled dependencies are provided as input (and various conditions in between).", "labels": [], "entities": []}, {"text": "When applied to the NLG 2011 shared task, our system gives competitive results compared with the best-performing systems, which provide a further demonstration of the practical utility of our system.", "labels": [], "entities": [{"text": "NLG 2011 shared task", "start_pos": 20, "end_pos": 40, "type": "DATASET", "confidence": 0.9382418692111969}]}], "introductionContent": [{"text": "Word ordering is a fundamental problem in natural language generation.", "labels": [], "entities": [{"text": "Word ordering", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7271574437618256}, {"text": "natural language generation", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6646988689899445}]}, {"text": "In this article we focus on text generation: Starting with a bag of words, or lemmas, as input, the task is to generate a fluent and grammatical sentence using those words.", "labels": [], "entities": [{"text": "text generation", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7600185573101044}]}, {"text": "Additional annotation may also be provided with the input-for example, part-of-speech (POS) tags or syntactic dependencies.", "labels": [], "entities": []}, {"text": "Applications that can benefit from better text generation algorithms include machine translation, abstractive text summarization (, and grammar correction ().", "labels": [], "entities": [{"text": "text generation", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.7324731945991516}, {"text": "machine translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7959450781345367}, {"text": "abstractive text summarization", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.6103029648462931}, {"text": "grammar correction", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.7252448499202728}]}, {"text": "Typically, statistical machine translation (SMT) systems) perform generation into the target language as part of an integrated system, which avoids the high computational complexity of independent word ordering.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 11, "end_pos": 48, "type": "TASK", "confidence": 0.8070172965526581}]}, {"text": "On the other hand, performing word ordering separately in a pipeline has many potential advantages.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.7295005172491074}]}, {"text": "For SMT, it offers better modularity between adequacy (translation) and fluency (linearization), and can potentially improve target grammaticality for syntactically different languages (e.g., Chinese and English).", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9920684099197388}]}, {"text": "More importantly, a standalone word ordering component can in principle be applied to a wide range of text generation tasks, including transfer-based machine translation (.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.7081414312124252}, {"text": "text generation", "start_pos": 102, "end_pos": 117, "type": "TASK", "confidence": 0.7257813811302185}, {"text": "transfer-based machine translation", "start_pos": 135, "end_pos": 169, "type": "TASK", "confidence": 0.661994069814682}]}, {"text": "Most word ordering systems use an n-gram language model, which is effective at controling local fluency.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 5, "end_pos": 18, "type": "TASK", "confidence": 0.7601835429668427}]}, {"text": "Syntax-based language models, in particular dependency language models, are sometimes used in an attempt to improve global fluency through the capturing of long-range dependencies.", "labels": [], "entities": []}, {"text": "In this article, we take a syntax-based approach and consider two grammar formalisms: Combinatory Categorial Grammar (CCG) and dependency grammar.", "labels": [], "entities": []}, {"text": "Our system also employs a discriminative model.", "labels": [], "entities": []}, {"text": "Coupled with heuristic search, a strength of the model is that arbitrary features can be defined to capture complex syntactic patterns in output hypotheses.", "labels": [], "entities": []}, {"text": "The discriminative model is trained using syntactically annotated data.", "labels": [], "entities": []}, {"text": "From the perspective of search, word ordering is a computationally difficult problem.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.8040677309036255}]}, {"text": "Finding the best permutation fora set of words according to a bigram language model, for example, is NP-hard, which can be proved by linear reduction from the traveling salesman problem.", "labels": [], "entities": []}, {"text": "In practice, exploring the whole search space of permutations is often prevented by adding constraints.", "labels": [], "entities": []}, {"text": "In phrase-based machine translation), a distortion limit is used to constrain the position of output phrases.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.625908374786377}]}, {"text": "In syntax-based machine translation systems such as and, synchronous grammars limit the search space so that polynomialtime inference is feasible.", "labels": [], "entities": [{"text": "syntax-based machine translation", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.7122093637784322}]}, {"text": "In fluency improvement, parts of translation hypotheses identified as having high local confidence are held fixed, so that word ordering elsewhere is strictly local.", "labels": [], "entities": [{"text": "fluency improvement", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.8514228463172913}, {"text": "word ordering", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.7277901619672775}]}, {"text": "In this article we begin by proposing a general system to solve the word ordering problem, which does not rely on constraints (which are typically task-specific).", "labels": [], "entities": [{"text": "word ordering problem", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.8417697151501974}]}, {"text": "In particular, we treat syntax-based word ordering as a structured prediction problem, for which the input is a multi-set (bag) of words and the output is an ordered sentence, together with its syntactic analysis (either CCG derivation or dependency tree, depending on the grammar formalism being used).", "labels": [], "entities": [{"text": "word ordering", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.7289107739925385}]}, {"text": "Given an input, our system searches for the highestscored output, according to a syntax-based discriminative model.", "labels": [], "entities": []}, {"text": "One advantage of this formulation of the reordering problem, which can perhaps bethought of as a \"pure\" text realization task, is that systems for solving it are easily evaluated, because all that is required is a set of sentences for reordering and a standard evaluation metric such as BLEU (.", "labels": [], "entities": [{"text": "text realization task", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.8100945154825846}, {"text": "BLEU", "start_pos": 287, "end_pos": 291, "type": "METRIC", "confidence": 0.9977952241897583}]}, {"text": "However, one potential criticism of the \"pure\" problem is that it is unclear how it relates to real realization tasks, since in practice (e.g., in statistical machine translation systems) the input does provide constraints on the possible output orderings.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 147, "end_pos": 178, "type": "TASK", "confidence": 0.6178686916828156}]}, {"text": "Our general formulation still allows task-specific contraints to be added if appropriate.", "labels": [], "entities": []}, {"text": "Hence as a test of the flexibility of our system, and a demonstration of the applicability of the system to more realistic text generation scenarios, we consider two further tasks for the dependency-based realization system.", "labels": [], "entities": [{"text": "text generation", "start_pos": 123, "end_pos": 138, "type": "TASK", "confidence": 0.7284344136714935}]}, {"text": "The first task considers a variety of input conditions for the dependency-based system, determined by two parameters.", "labels": [], "entities": []}, {"text": "The first is whether POS information is provided for each word in the input multi-set.", "labels": [], "entities": [{"text": "POS", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9302932024002075}]}, {"text": "The second is whether syntactic dependencies between the words are provided.", "labels": [], "entities": []}, {"text": "The extreme case is when all dependencies are provided, in which case the problem reduces to the tree linearization problem).", "labels": [], "entities": []}, {"text": "However, the input can also lie between the two extremes of no-and full-dependency information.", "labels": [], "entities": []}, {"text": "The second task is the NLG 2011 shared task, which provides a further demonstration of the practical utility of our system.", "labels": [], "entities": [{"text": "NLG 2011 shared task", "start_pos": 23, "end_pos": 43, "type": "DATASET", "confidence": 0.9283313602209091}]}, {"text": "The shared task is closer to areal realization scenario, in that lemmas, rather than inflected words, are provided as input.", "labels": [], "entities": [{"text": "areal realization", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.6468921601772308}]}, {"text": "Hence some modifications are required to our system in order that it can perform some word inflection, as well as deciding on the ordering.", "labels": [], "entities": []}, {"text": "The shared task data also uses labeled, rather than unlabeled, syntactic dependencies, and so the system was modified to incorporate labels.", "labels": [], "entities": []}, {"text": "The final result is that our system gives competitive BLEU scores, compared to the best-performing systems on the shared task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9981603026390076}]}, {"text": "The structured prediction problem we solve is a very hard problem.", "labels": [], "entities": [{"text": "structured prediction problem", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.7628395060698191}]}, {"text": "Due to the use of syntax, and the search fora sentence together with a single CCG derivation or dependency tree, the search space is exponentially larger than the n-gram word permutation problem.", "labels": [], "entities": []}, {"text": "No efficient algorithm exists for finding the optimal solution.", "labels": [], "entities": []}, {"text": "recognized the computational difficulty of chart-based generation, which has many similarities to the problem we address in his seminal paper.", "labels": [], "entities": [{"text": "chart-based generation", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7300445437431335}]}, {"text": "We tackle the high complexity by using learning-guided best-first search, exploring a small path in the whole search space, which contains the most likely structures according to the discriminative model.", "labels": [], "entities": []}, {"text": "One of the contributions of this article is to introduce, and provide a discriminative solution to, this difficult structured prediction problem, which is an interesting machine learning problem in its own right.", "labels": [], "entities": [{"text": "structured prediction problem", "start_pos": 115, "end_pos": 144, "type": "TASK", "confidence": 0.7405099272727966}]}, {"text": "This article is based on, and significantly extends, three conference papers (.", "labels": [], "entities": []}, {"text": "It includes a more detailed description and discussion of our guided-search approach to syntax-based word ordering, bringing together the CCG-and dependency-based systems under one unified framework.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 101, "end_pos": 114, "type": "TASK", "confidence": 0.7048775851726532}]}, {"text": "In addition, we discuss the limitations of our previous work, and show that a better model can be developed through scaling of the feature vectors.", "labels": [], "entities": []}, {"text": "The resulting model allows fair comparison of constituents of different sizes, and enables the learning algorithms to expand negative examples during training, which leads to significantly improved results over our previous work.", "labels": [], "entities": []}, {"text": "The competitive results on the NLG 2011 shared task data are new for this article, and demonstrate the applicability of our system to more realistic text realization scenarios.", "labels": [], "entities": [{"text": "NLG 2011 shared task data", "start_pos": 31, "end_pos": 56, "type": "DATASET", "confidence": 0.9107355952262879}, {"text": "text realization", "start_pos": 149, "end_pos": 165, "type": "TASK", "confidence": 0.74791219830513}]}, {"text": "The contributions of this article can be summarized as follows: r We address the problem of syntax-based word ordering, drawing attention to this challenging language modeling task and offering a general solution that does not rely on constraints to limit the search space.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.7109746187925339}]}, {"text": "r We present a novel method for solving the word ordering problem that gives the best reported accuracies to date on the standard Wall Street Journal data.", "labels": [], "entities": [{"text": "word ordering problem", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.8661301930745443}, {"text": "accuracies", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9468017816543579}, {"text": "Wall Street Journal data", "start_pos": 130, "end_pos": 154, "type": "DATASET", "confidence": 0.97603639960289}]}, {"text": "r We show how our system can be used with two different grammar formalisms: Combinatory Categorial Grammar and dependency grammar.", "labels": [], "entities": []}, {"text": "r We show how syntactic constraints can be easily incorporated into the system, presenting results for the dependency-based system with a range of input conditions.", "labels": [], "entities": []}, {"text": "r We demonstrate the applicability of the system to more realistic text realization scenarios by obtaining competitive results on the NLG 2011 shared task data, including performing some word inflection as part of a joint system that also performs word reordering.", "labels": [], "entities": [{"text": "text realization", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.7437998354434967}, {"text": "NLG 2011 shared task data", "start_pos": 134, "end_pos": 159, "type": "DATASET", "confidence": 0.9481538534164429}, {"text": "word reordering", "start_pos": 248, "end_pos": 263, "type": "TASK", "confidence": 0.726606547832489}]}, {"text": "r More generally, we propose a learning-guided, best-first search algorithm for application of discriminative models to extremely large search spaces containing structures of varying sizes.", "labels": [], "entities": []}, {"text": "This method could be applied to other complex structured prediction tasks in NLP and machine learning.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use CCGBank (Hockenmaier and Steedman 2007) and the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993) for CCG and dependency data, respectively.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.9938574433326721}]}, {"text": "CCGbank is the CCG version of the Penn Treebank.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9585425853729248}, {"text": "Penn Treebank", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9941976070404053}]}, {"text": "Standard splits were used for both: Sections 02-21 for training, Section 00 for development, and Section 23 for the final test.", "labels": [], "entities": []}, {"text": "gives statistics for the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.985222578048706}]}, {"text": "For the CCG experiments, original sentences from CCGBank are transformed into bags of words, with sequence information removed, and passed to our system as input data.", "labels": [], "entities": []}, {"text": "The system outputs are compared to the original sentences for evaluation.", "labels": [], "entities": []}, {"text": "Following, we use the BLEU metric ( for string comparison.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9980881810188293}]}, {"text": "Although BLEU is not the perfect measure of fluency or grammaticality, being based on n-gram precision, it is currently widely used for automatic evaluation and allows us to compare directly with existing work ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9982503056526184}, {"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.8683887124061584}]}, {"text": "Note also that one criticism of BLEU for evaluating machine translation systems (i.e., that it can only register exact matches between the same words in the system and reference translation), does not apply here, because the system output always contains the same words as the original reference sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.942977786064148}, {"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7386854887008667}]}, {"text": "For the dependency-based experiments, gold-standard dependency trees were derived from bracketed sentences in the treebank using the Penn2Malt tool.", "labels": [], "entities": [{"text": "Penn2Malt", "start_pos": 133, "end_pos": 142, "type": "DATASET", "confidence": 0.963225781917572}]}, {"text": "For fair comparison with, we keep base NPs as atomic units when preparing the input.", "labels": [], "entities": []}, {"text": "Wan et al. used base NPs from the Penn Treebank annotation, and we follow this practice for the dependency-based experiments.", "labels": [], "entities": [{"text": "Penn Treebank annotation", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.9903724988301595}]}, {"text": "For the CCG experiments we extract base NPs from CCGBbank by taking as base NPs those NPs that do not recursively contain other NPs.", "labels": [], "entities": []}, {"text": "These base NPs mostly correspond to the base NPs from the Penn Treebank: In the training data, there are 242,813 Penn Treebank base NPs with an average size of 1.09, and 216,670 CCGBank base NPs with an average size of 1.19.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.996757298707962}, {"text": "Penn Treebank base NPs", "start_pos": 113, "end_pos": 135, "type": "DATASET", "confidence": 0.9683556258678436}]}, {"text": "The previous sections report evaluations on the task of word ordering, an abstract yet fundamental problem in text generation.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.7273730486631393}, {"text": "text generation", "start_pos": 110, "end_pos": 125, "type": "TASK", "confidence": 0.734661653637886}]}, {"text": "One question that is not addressed by these experiments is how the abstract task can be utilized to benefit full text generation, for which more considerations need to betaken into account in addition to word ordering.", "labels": [], "entities": [{"text": "full text generation", "start_pos": 108, "end_pos": 128, "type": "TASK", "confidence": 0.6326894362767538}, {"text": "word ordering", "start_pos": 204, "end_pos": 217, "type": "TASK", "confidence": 0.7118701934814453}]}, {"text": "We investigate this question using the 2011 Generation Challenge shared task data, which provide a common-ground for the evaluation of text generation systems ().", "labels": [], "entities": [{"text": "2011 Generation Challenge shared task data", "start_pos": 39, "end_pos": 81, "type": "DATASET", "confidence": 0.8928644160429636}, {"text": "text generation", "start_pos": 135, "end_pos": 150, "type": "TASK", "confidence": 0.7731335461139679}]}, {"text": "The data are based on the CoNLL 2008 shared task data (), which consist of selected sections of the Penn WSJ Treebank, converted to syntactic dependencies via the LTH tool (Johansson and Nugues 2007).", "labels": [], "entities": [{"text": "CoNLL 2008 shared task data", "start_pos": 26, "end_pos": 53, "type": "DATASET", "confidence": 0.8907911777496338}, {"text": "Penn WSJ Treebank", "start_pos": 100, "end_pos": 117, "type": "DATASET", "confidence": 0.9595094323158264}]}, {"text": "Sections 2-21 are used for training, Section 24 for development, and Section 23 for testing.", "labels": [], "entities": []}, {"text": "A small number of sentences from the original WSJ sections are not included in this set.", "labels": [], "entities": [{"text": "WSJ sections", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8741504848003387}]}, {"text": "The input format of the shared task is an unordered syntactic dependency tree, with nodes being lemmas, and dependency relations on the arcs.", "labels": [], "entities": []}, {"text": "Named entities and hyphenated words are broken into individual nodes, and special dependency links are used to mark them.", "labels": [], "entities": []}, {"text": "Information on coarse-grained POS, number, tense, and participle features is given to each node where applicable.", "labels": [], "entities": []}, {"text": "The output is a fully ordered and inflected sentence.", "labels": [], "entities": []}, {"text": "We developed a full-text generation system according to this task specification, with the core component being the dependency-based word ordering system of Section 4.", "labels": [], "entities": [{"text": "full-text generation", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7013245224952698}, {"text": "dependency-based word ordering", "start_pos": 115, "end_pos": 145, "type": "TASK", "confidence": 0.5927445491154989}]}, {"text": "In addition to minor engineering details that were required to adapt the system to this new task, one additional task that the generation system needs to carryout is morphological generation-finding the appropriate inflected form for each input lemma.", "labels": [], "entities": []}, {"text": "Our approach is to perform joint word ordering and inflection using the learning-guided search framework, letting one statistical model decide the best order as well as the inflections of ambiguous lemmas.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.7144326269626617}]}, {"text": "For a lemma, we generate one or more candidate inflections by using a lexicon and a set of inflection rules.", "labels": [], "entities": []}, {"text": "Candidate inflections for an input lemma are generated according to the lemma itself and its input attributes, such as the number and tense.", "labels": [], "entities": []}, {"text": "Some lemmas are unambiguous, which are inflected before being passed to the word ordering system.", "labels": [], "entities": []}, {"text": "For the other lemmas, more than one candidate's inflections are passed as input words to the word ordering system.", "labels": [], "entities": []}, {"text": "To ensure that each lemma occurs only once in the output, a unique ID is given to all the inflections of the same lemma, making them mutually exclusive.", "labels": [], "entities": []}, {"text": "Four types of lemmas need morphological generation, including nouns, verbs, adjectives, and miscellaneous cases.", "labels": [], "entities": []}, {"text": "For these lemmas, we pass all possible inflections to the search module.", "labels": [], "entities": []}, {"text": "For nouns and adjectives, the inflection is relatively straightforward, since the number (e.g., singular, plural) of a lemma is given as an attribute of the input node, and comparative and superlative adjectives have specific parts of speech.", "labels": [], "entities": []}, {"text": "For those cases where the necessary information is not available from the input, all possible inflections are handed over to the search module for further disambiguation.", "labels": [], "entities": []}, {"text": "The most ambiguous lemma types are verbs, which can be further divided into be and other verbs.", "labels": [], "entities": []}, {"text": "The uniqueness of be is that the inflections for the first and second person can be different.", "labels": [], "entities": []}, {"text": "All verb inflections are disambiguated according to the tense and participle attributes of the input node.", "labels": [], "entities": []}, {"text": "In addition, for verbs in the present tense, the subject needs to be determined in order to differentiate between third-person singular verbs and others.", "labels": [], "entities": []}, {"text": "This can be straightforward when the subject is a noun or pronoun, but can be ambiguous when the subject is a wh-pronoun, in which case the real subject might not be directly identifiable from the dependency tree.", "labels": [], "entities": []}, {"text": "We leave all possible inflections of be and other verbs to the word ordering system whenever the ambiguity is not directly solvable from the subject dependency link.", "labels": [], "entities": []}, {"text": "Overall, the pre-processing step generates 1.15 inflections for each lemma on average.", "labels": [], "entities": []}, {"text": "For word ordering, the search procedure of Algorithm 4 is applied directly, and the feature templates of are used with additional labeled dependency features described subsequently.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.8103243708610535}]}, {"text": "The main reason that the dependency-based word ordering algorithm can perform joint morphological disambiguation is that it uses rich syntactic and n-gram features to score candidate hypotheses, which can also differentiate between correct and incorrect inflections under particular contexts.", "labels": [], "entities": [{"text": "dependency-based word ordering", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.6142178773880005}, {"text": "joint morphological disambiguation", "start_pos": 78, "end_pos": 112, "type": "TASK", "confidence": 0.769832452138265}]}, {"text": "For example, an honest person and a honest person can be differentiated by n-gram features, while Tom and Sally is and Tom and Sally are can be differentiated by higher-order dependency features.", "labels": [], "entities": []}, {"text": "In addition to lemma-formed inputs, one other difference between the shared task and the word ordering problem solved by Algorithm 4 is that the former uses labeled dependencies whereas Algorithm 4 constructs unlabeled dependency trees.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.7271384596824646}]}, {"text": "We address this issue by assigning dependency labels in the construction of dependency links, and applying an extra set of features.", "labels": [], "entities": []}, {"text": "The new features are defined by making a duplicate of all the features from that contain dir information, and associating each feature in the new copy with a dependency label.", "labels": [], "entities": []}, {"text": "The training of the word ordering system requires fully ordered dependency trees, while references in the shared task data are raw sentences.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.7221010476350784}]}, {"text": "We perform a pre-processing step to obtain gold-standard training data by matching the input lemmas to the reference sentence in order to obtain their gold-standard order.", "labels": [], "entities": []}, {"text": "More specifically, given a training instance, we generate all candidate inflections for each lemma, resulting in an exponential set of possible mappings between the input tree and the reference sentence.", "labels": [], "entities": []}, {"text": "We then prune these mappings bottom-up, assuming that the dependency tree is projective, and therefore that each word dominates a continuous span in the reference.", "labels": [], "entities": []}, {"text": "After such pruning, only one correct mapping is found for the majority of the cases.", "labels": [], "entities": []}, {"text": "For the cases where more than one mapping is found, we randomly choose one as the gold-standard.", "labels": [], "entities": []}, {"text": "There are also instances for which no correct ordering can be found, and these are mostly due to non-projectivity in the shared task data, with a few cases being due to conflicts between our morphological generation system and the shared task data, or inconsistency in the data itself.", "labels": [], "entities": []}, {"text": "Out of the 39K training instances, 2.8K conflicting instances are discarded, resulting in 36.2K gold-standard ordered dependency trees.", "labels": [], "entities": []}, {"text": "shows the results of our system and the top two participating systems of the shared task.", "labels": [], "entities": []}, {"text": "Our system outperforms the STUMABA system by 0.5 BLEU points, and the DCU system by 3.8 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9978755712509155}, {"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9971686005592346}]}, {"text": "More evaluation of the system was published in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Training, development, and test data from the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.994169682264328}]}, {"text": " Table 4  The effect of the scaled model and expansion of negative examples during training for the CCG  system.", "labels": [], "entities": []}, {"text": " Table 7  Development BLEU scores for partial-tree linearization, with different proportions of input POS  and dependency information randomly selected from full gold-standard trees.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9992006421089172}]}, {"text": " Table 9  Final test results on the standard word ordering task.", "labels": [], "entities": [{"text": "word ordering task", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8305201331774393}]}, {"text": " Table 10  Results and comparison with the top-performing systems on the shared task data", "labels": [], "entities": []}]}