{"title": [{"text": "A Statistical Parsing Framework for Sentiment Classification", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.9841265380382538}]}], "abstractContent": [{"text": "We present a statistical parsing framework for sentence-level sentiment classification in this article.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.6793502569198608}, {"text": "sentence-level sentiment classification", "start_pos": 47, "end_pos": 86, "type": "TASK", "confidence": 0.7931869824727377}]}, {"text": "Unlike previous works that use syntactic parsing results for sentiment analysis, we develop a statistical parser to directly analyze the sentiment structure of a sentence.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.9622504413127899}]}, {"text": "We show that complicated phenomena in sentiment analysis (e.g., negation, intensification, and contrast) can be handled the same way as simple and straightforward sentiment expressions in a unified and probabilistic way.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.9442116618156433}, {"text": "negation", "start_pos": 64, "end_pos": 72, "type": "TASK", "confidence": 0.9124050140380859}]}, {"text": "We formulate the sentiment grammar upon Context-Free Grammars (CFGs), and provide a formal description of the sentiment parsing framework.", "labels": [], "entities": [{"text": "sentiment parsing", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7644671201705933}]}, {"text": "We develop the parsing model to obtain possible sentiment parse trees fora sentence, from which the polarity model is proposed to derive the sentiment strength and polarity, and the ranking model is dedicated to selecting the best sentiment tree.", "labels": [], "entities": [{"text": "sentiment parse", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.6977217495441437}]}, {"text": "We train the parser directly from examples of sentences annotated only with sentiment polarity labels but without any syntactic annotations or polarity annotations of constituents within sentences.", "labels": [], "entities": []}, {"text": "Therefore we can obtain training data easily.", "labels": [], "entities": []}, {"text": "In particular, we train a sentiment parser, s.parser, from a large amount of review sentences with users' ratings as rough sentiment polarity labels.", "labels": [], "entities": [{"text": "sentiment parser", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7644080817699432}]}, {"text": "Extensive experiments on existing benchmark data sets show significant improvements over baseline sentiment classification approaches.", "labels": [], "entities": [{"text": "baseline sentiment classification", "start_pos": 89, "end_pos": 122, "type": "TASK", "confidence": 0.671950121720632}]}], "introductionContent": [{"text": "Sentiment analysis) has received much attention from both research and industry communities in recent years.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9416243433952332}]}, {"text": "Sentiment classification, which identifies sentiment polarity (positive or negative) from text (sentence or document), has been the most extensively studied task in sentiment analysis.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9484779238700867}, {"text": "sentiment analysis", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.9399993419647217}]}, {"text": "Until now, there have been two mainstream approaches for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.9536440372467041}]}, {"text": "The lexicon-based approach) aims to aggregate the sentiment polarity of a sentence from the polarity of words or phrases found in the sentence, and the learning-based approach treats sentiment polarity identification as a special text classification task and focuses on building classifiers from a set of sentences (or documents) annotated with their corresponding sentiment polarity.", "labels": [], "entities": [{"text": "sentiment polarity identification", "start_pos": 183, "end_pos": 216, "type": "TASK", "confidence": 0.7085080146789551}, {"text": "text classification", "start_pos": 230, "end_pos": 249, "type": "TASK", "confidence": 0.7565102577209473}]}, {"text": "The lexicon-based sentiment classification approach is simple and interpretable, but suffers from scalability and is inevitably limited by sentiment lexicons that are commonly created manually by experts.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.7790915369987488}]}, {"text": "It has been widely recognized that sentiment expressions are colloquial and evolve overtime very frequently.", "labels": [], "entities": [{"text": "sentiment expressions", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.8824290037155151}]}, {"text": "Taking tweets from Twitter 1 and movie reviews on IMDb 2 as examples, people use very casual language as well as informal and new vocabulary to comment on general topics and movies.", "labels": [], "entities": []}, {"text": "In practice, it is not feasible to create and maintain sentiment lexicons to capture sentiment expressions with high coverage.", "labels": [], "entities": []}, {"text": "On the other hand, the learning-based approach relies on large annotated samples to overcome the vocabulary coverage and deals with variations of words in sentences.", "labels": [], "entities": []}, {"text": "Human ratings in reviews () and emoticons in tweets) are extensively used to collect a large number of training corpora to train the sentiment classifier.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.8157857656478882}]}, {"text": "However, it is usually not easy to design effective features to build the classifier.", "labels": [], "entities": []}, {"text": "Among others, unigrams have been reported as the most effective features) in sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.9725200235843658}]}, {"text": "Handling complicated expressions delivering people's opinions is one of the most challenging problems in sentiment analysis.", "labels": [], "entities": [{"text": "Handling complicated expressions delivering people's opinions", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.8197508198874337}, {"text": "sentiment analysis", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.9681422710418701}]}, {"text": "Compositionalities such as negation, intensification, contrast, and their combinations are typical cases.", "labels": [], "entities": [{"text": "negation", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.9685335159301758}]}, {"text": "We show some concrete examples here: (1) The movie is not good.", "labels": [], "entities": []}, {"text": "(2) The movie is very good.", "labels": [], "entities": []}, {"text": "(3) The movie is not funny at all.", "labels": [], "entities": []}, {"text": "[negation + intensification] (4) The movie is just so so, but i still like it.", "labels": [], "entities": []}, {"text": "(5) The movie is not very good, but i still like it.", "labels": [], "entities": []}, {"text": "[negation + intensification + contrast] The negation expressions, intensification modifiers, and the contrastive conjunction can change the polarity (Examples (1), (3), (4), (5)), strength (Examples (2), (3), (5)), or both (Examples (3), (5)) of the sentiment of the sentences.", "labels": [], "entities": []}, {"text": "We do not need any detailed explanations here as they can be commonly found and easily understood in people's daily lives.", "labels": [], "entities": []}, {"text": "Existing works to address these issues usually rely on syntactic parsing results either used as features in learning-based methods or hand-crafted rules) in lexiconbased methods.", "labels": [], "entities": []}, {"text": "However, even with the difficulty and feasibility of deriving the sentiment structure from syntactic parsing results put aside, it is an even more challenging task to generate stable and reliable parsing results for text that is ungrammatical in nature and has a high ratio of out-of-vocabulary words.", "labels": [], "entities": [{"text": "sentiment structure from syntactic parsing", "start_pos": 66, "end_pos": 108, "type": "TASK", "confidence": 0.6898454546928405}]}, {"text": "The accuracy of the linguistic parsers trained on standard data sets (e.g., the Penn Treebank) drops dramatically on user-generated-content (reviews, tweets, etc.), which is actually the prime focus of sentiment analysis algorithms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994204044342041}, {"text": "Penn Treebank", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9922931492328644}, {"text": "sentiment analysis", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.9400427341461182}]}, {"text": "The error, unfortunately, will propagate downstream in the process of sentiment analysis methods building upon parsing results.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.929744154214859}]}, {"text": "We therefore propose directly analyzing the sentiment structure of a sentence.", "labels": [], "entities": []}, {"text": "The nested structure of sentiment expressions can be naturally modeled in a similar fashion as statistical syntactic parsing, which aims to find the linguistic structure of a sentence.", "labels": [], "entities": [{"text": "statistical syntactic parsing", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.6716609994570414}]}, {"text": "This idea creates many opportunities for developing sentiment classifiers from anew perspective.", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.8012892305850983}]}, {"text": "The most challenging problem and barrier in building a statistical sentiment parser lies in the acquisition of training data.", "labels": [], "entities": [{"text": "statistical sentiment parser", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.7089855074882507}]}, {"text": "Ideally, we need examples of sentences annotated with polarity for the whole sentence as well as sentiment tags for constituents within a sentence, as with the Penn TreeBank for training traditional linguistic parsers.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 160, "end_pos": 173, "type": "DATASET", "confidence": 0.9888964891433716}]}, {"text": "However, this is not practical as the annotations will be inevitably time-consuming and require laborious human efforts.", "labels": [], "entities": []}, {"text": "Therefore, it is better to learn the sentiment parser only utilizing examples annotated with the polarity label of the whole sentence.", "labels": [], "entities": [{"text": "sentiment parser", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.8025843501091003}]}, {"text": "For example, we can collect a huge number of publicly available reviews and rating scores on the Web.", "labels": [], "entities": []}, {"text": "People may use the movie is gud (\"gud\" is a popular informal expression of \"good\") to express a positive opinion towards a movie, and not a fan to express a negative opinion.", "labels": [], "entities": []}, {"text": "Also, we can find review sentences such as The movie is gud, but I am still not a fan to indicate a negative opinion.", "labels": [], "entities": []}, {"text": "We can then use these two fragments and the overall negative opinion of the sentence to deduce sentiment rules automatically from data.", "labels": [], "entities": []}, {"text": "These sentiment fragments and rules can be used to analyze the sentiment structure for new sentences.", "labels": [], "entities": []}, {"text": "In this article, we propose a statistical parsing framework to directly analyze the structure of a sentence from the perspective of sentiment analysis.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7075110077857971}, {"text": "sentiment analysis", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.916716068983078}]}, {"text": "Specifically, we formulate a Context-Free Grammar (CFG)-based sentiment grammar.", "labels": [], "entities": [{"text": "Context-Free Grammar (CFG)-based sentiment grammar", "start_pos": 29, "end_pos": 79, "type": "TASK", "confidence": 0.6377383396029472}]}, {"text": "We then develop a statistical parser to derive the sentiment structure of a sentence.", "labels": [], "entities": []}, {"text": "We leverage the CYK algorithm to conduct bottom-up parsing, and use dynamic programming to accelerate computation.", "labels": [], "entities": [{"text": "bottom-up parsing", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.5762283802032471}]}, {"text": "Meanwhile, we propose using the polarity model to derive sentiment strength and polarity of a sentiment parse tree, and the ranking model to select the best one from the sentiment parsing results.", "labels": [], "entities": [{"text": "sentiment parse", "start_pos": 94, "end_pos": 109, "type": "TASK", "confidence": 0.7312458902597427}, {"text": "sentiment parsing", "start_pos": 170, "end_pos": 187, "type": "TASK", "confidence": 0.719936728477478}]}, {"text": "We train the parser directly from examples of sentences annotated with sentiment polarity labels instead of syntactic annotations and polarity annotations of constituents within sentences.", "labels": [], "entities": []}, {"text": "Therefore we can obtain training data easily.", "labels": [], "entities": []}, {"text": "In particular, we train a sentiment parser, named s.parser, from a large number of review sentences with users' ratings as rough sentiment polarity labels.", "labels": [], "entities": [{"text": "sentiment parser", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7537116706371307}]}, {"text": "The statistical parsing-based approach builds a principled and scalable framework to support the sentiment composition and inference which cannot be well handled by bag-of-words approaches.", "labels": [], "entities": [{"text": "statistical parsing-based", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6778315901756287}, {"text": "sentiment composition", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.8399426341056824}]}, {"text": "We show that complicated phenomena in sentiment analysis (e.g., negation, intensification, and contrast) can be handled the same way as simple and straightforward sentiment expressions in a unified and probabilistic way.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.9442119002342224}, {"text": "negation", "start_pos": 64, "end_pos": 72, "type": "TASK", "confidence": 0.9124046564102173}]}, {"text": "The major contributions of the work presented in this article are as follows.", "labels": [], "entities": []}, {"text": "r We propose a statistical parsing framework for sentiment analysis that is capable of analyzing the sentiment structure fora sentence.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7187520265579224}, {"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9502286911010742}]}, {"text": "This framework can naturally handle compositionality in a probabilistic way.", "labels": [], "entities": []}, {"text": "It can be trained from sentences annotated with only sentiment polarity but without any syntactic annotations or polarity annotations of constituents within sentences.", "labels": [], "entities": []}, {"text": "r We present the parsing model, polarity model, and ranking model in the proposed framework, which are formulated and can be improved independently.", "labels": [], "entities": [{"text": "parsing", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9765610694885254}]}, {"text": "It provides a principled and flexible approach to sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.9436390697956085}]}, {"text": "r We implement the statistical sentiment parsing framework, and conduct experiments on several benchmark data sets.", "labels": [], "entities": [{"text": "statistical sentiment parsing", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.7986759543418884}]}, {"text": "The experimental results show that the proposed framework and algorithm can significantly outperform baseline methods.", "labels": [], "entities": []}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "We introduce related work in Section 2.", "labels": [], "entities": []}, {"text": "We present the statistical sentiment parsing framework, including the parsing model, polarity model, and ranking model, in Section 3.", "labels": [], "entities": [{"text": "statistical sentiment parsing", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.7158871491750082}, {"text": "parsing", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.9672969579696655}]}, {"text": "Learning methods for our model are explained in Section 4.", "labels": [], "entities": []}, {"text": "Experimental results are reported in Section 5.", "labels": [], "entities": []}, {"text": "We conclude this article with future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe experimental results on existing benchmark data sets with extensive comparisons with state-of-the-art sentiment classification methods.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.8062624037265778}]}, {"text": "We also present the effects of different experimental settings in the proposed statistical sentiment parsing framework.", "labels": [], "entities": [{"text": "statistical sentiment parsing", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.7321202357610067}]}, {"text": "We describe the data sets in Section 5.1.1, the experimental settings in Section 5.1.2, and the methods used for comparison in Section 5.1.3.", "labels": [], "entities": [{"text": "Section 5.1.1", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.8923065364360809}, {"text": "Section 5.1.2", "start_pos": 73, "end_pos": 86, "type": "DATASET", "confidence": 0.9009310603141785}]}, {"text": "In this section, we investigate the effects of different experimental settings.", "labels": [], "entities": []}, {"text": "We show the results on the data set RT-C by only changing one factor and fixing the others.", "labels": [], "entities": [{"text": "RT-C", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.5841984748840332}]}, {"text": "shows the effect of minimum fragment frequency, and maximum fragment length.", "labels": [], "entities": []}, {"text": "Specifically, indicates that a minimum fragment frequency that is too small will introduce noise, and it is difficult to estimate reliable polarity probabilities for infrequent fragments.", "labels": [], "entities": []}, {"text": "However, a minimum fragment frequency that is too large will discard too much useful information.", "labels": [], "entities": []}, {"text": "As shown in, we find that accuracy increases as the maximum fragment length increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995307922363281}]}, {"text": "The results illustrate that the large maximum fragment length is helpful for s.parser.", "labels": [], "entities": []}, {"text": "We can learn more    combination rules with a larger maximum fragment length, and long dictionary rules capture more precise expressions than unigrams.", "labels": [], "entities": []}, {"text": "This conclusion is the same as that in Section 5.2.", "labels": [], "entities": []}, {"text": "As shown in, we also investigate how the training iteration, regularization, and beam size affect the results.", "labels": [], "entities": []}, {"text": "As shown in, we try a wide range of regularization parameters \u03bb in Equation.", "labels": [], "entities": [{"text": "Equation", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.7728661298751831}]}, {"text": "The results indicate that it is insensitive to the choice of \u03bb. shows the effects of different beam size K in the search process.", "labels": [], "entities": []}, {"text": "When beam size K = 1, the optimization algorithm cannot learn the weights.", "labels": [], "entities": []}, {"text": "In this case, the decoding process is to select one search path randomly, and compute its polarity probabilities.", "labels": [], "entities": []}, {"text": "The results become better as the beam size K increases.", "labels": [], "entities": []}, {"text": "On the other hand, the computation costs increase.", "labels": [], "entities": []}, {"text": "The proper beam size K can prune some candidates to speedup the search procedure.", "labels": [], "entities": []}, {"text": "It should be noted that the sentence length also effects the run time.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Statistical information of data sets. #Negative and #Positive are the number of negative instances  and positive instances, respectively. l avg is average length of sentences in the data set, and |V| is  the vocabulary size.", "labels": [], "entities": []}, {"text": " Table 4  Sentiment classification results on different data sets; The top three methods are in bold and the  best is also underlined; SVM-m = Support Vector Machine; MNB-m = Multinomial Na\u00a8\u0131veNa\u00a8\u0131ve Bayes;  LM-m = Language Model; Voting-w/Rev = Voting with negation rules; HardRule = Rule based  method on dependency tree; Tree-CRF = Dependency tree-based method employing conditional  random fields; RAE-pretrain = Recursive autoencoders with pre-trained word vectors;  MV-RNN = Matrix-vector recursive neural network; s.parser-LongMatch = The longest  matching rules are used; s.parser-w/oComb = Without using the combination rules; s.parser =  Our method. Some of the results are missing (indicated by \"-\") in the table as there is no publicly  available implementation or they are hard to scale up.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9149602353572845}, {"text": "RAE-pretrain", "start_pos": 402, "end_pos": 414, "type": "METRIC", "confidence": 0.8651353120803833}]}, {"text": " Table 5  Number of rules learned from different data sets. \u03c4 f represents minimum fragment frequency,  |G D | represents total number of dictionary rules, and |G C | is the total number of combination  rules.", "labels": [], "entities": []}]}