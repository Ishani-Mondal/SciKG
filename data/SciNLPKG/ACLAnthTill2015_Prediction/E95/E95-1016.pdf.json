{"title": [{"text": "On Learning more Appropriate Selectional Restrictions", "labels": [], "entities": [{"text": "Appropriate Selectional Restrictions", "start_pos": 17, "end_pos": 53, "type": "METRIC", "confidence": 0.7360183894634247}]}], "abstractContent": [{"text": "We present some variations affecting the association measure and thresholding on a technique for learning Selectional Restrictions from on-line corpora.", "labels": [], "entities": [{"text": "association measure", "start_pos": 41, "end_pos": 60, "type": "METRIC", "confidence": 0.8849777579307556}]}, {"text": "It uses a wide-coverage noun taxonomy and a statistical measure to generalize the appropriate semantic classes.", "labels": [], "entities": []}, {"text": "Evaluation measures for the Selectional Restrictions learning task are discussed.", "labels": [], "entities": [{"text": "Selectional Restrictions learning task", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.868499755859375}]}, {"text": "Finally, an experimental evaluation of these variations is reported.", "labels": [], "entities": []}, {"text": "Subject Areas: corpus-based language modeling, computational lexicography", "labels": [], "entities": [{"text": "corpus-based language modeling", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.659920871257782}]}], "introductionContent": [{"text": "In recent years there has been a common agreement in the NLP research community on the importance of having an extensive coverage of selectional restrictions (SRs) tuned to the domain to work with.", "labels": [], "entities": []}, {"text": "SRs can be seen as semantic type constraints that a word sense imposes on the words with which it combines in the process of semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.7540859282016754}]}, {"text": "SRs may have different applications in NLP, specifically, they may help a parser with Word Sense Selection (WSS, as in), with preferring certain structures out of several grammatical ones ) and finally with deciding the semantic role played by a syntactic complement ( . Lexicography is also interested in the acquisition of SRs (both defining in context approach and lexical semantics work).", "labels": [], "entities": []}, {"text": "The aim of our work is to explore the feasibility of using an statistical method for extracting SRs from on-line corpora.", "labels": [], "entities": [{"text": "extracting SRs from on-line corpora", "start_pos": 85, "end_pos": 120, "type": "TASK", "confidence": 0.8290735840797424}]}, {"text": "Resnik (1992) developed a method for automatically extracting classbased SRs from on-line corpora.", "labels": [], "entities": [{"text": "extracting classbased SRs from on-line corpora", "start_pos": 51, "end_pos": 97, "type": "TASK", "confidence": 0.6658809185028076}]}, {"text": "*This research has been made in the framework of the Acquilex-II Esprit Project (7315), and has been supported by a grant of Departament d'Ensenyament, Generalitat performed some experiments using this basic technique and drew up some limitations from the corresponding results.", "labels": [], "entities": [{"text": "Acquilex-II Esprit Project (7315)", "start_pos": 53, "end_pos": 86, "type": "DATASET", "confidence": 0.8625287065903345}]}, {"text": "In this paper we will describe some substantial modifications to the basic technique and will report the corresponding experimental evaluation.", "labels": [], "entities": []}, {"text": "The outline of the paper is as follows: in section 2 we summarize the basic methodology used in , analyzing its limitations; in section 3 we explore some alternative statistical measures for ranking the hypothesized SRs; in section 4 we propose some evaluation measures on the SRs-learning problem, and use them to test the experimental results obtained by the different techniques; finally, in section 5 we draw up the final conclusions and establish future lines of research.", "labels": [], "entities": []}, {"text": "The appropriateness of a class for expressing SRs (stage 2) is quantified from tile strength of co-occurrence of verbs and classes of nouns in the. corpus.", "labels": [], "entities": [{"text": "expressing SRs", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7202849984169006}]}, {"text": "Given the verb v, the syntactic-relationship sand the candidate class c, the Association Score, Assoc, between v and c in sis defined:", "labels": [], "entities": [{"text": "Association Score", "start_pos": 77, "end_pos": 94, "type": "METRIC", "confidence": 0.9605008363723755}, {"text": "Assoc", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.9231787919998169}]}], "datasetContent": [{"text": "Evaluation on NLP has been crucial to fostering research in particular areas.", "labels": [], "entities": []}, {"text": "Evaluation of the SR learning task would provide grounds to compare different techniques that try to abstract SRs from corpus using WordNet (e.g, section 4.2).", "labels": [], "entities": [{"text": "SR learning task", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.9182952841122946}, {"text": "WordNet", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.960330605506897}]}, {"text": "It would also permit measuring the utility of the SRs obtained using WordNet in comparison with other frameworks using other kinds of knowledge.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9470880627632141}]}, {"text": "Finally it would be a powerful tool for detecting flaws of a particular technique (e.g, (Ribas, 1994a) analysis).", "labels": [], "entities": [{"text": "Ribas, 1994a) analysis", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.6102455377578735}]}, {"text": "However, a related and crucial issue is which linguistic tasks are used as a reference.", "labels": [], "entities": []}, {"text": "SRs are useful for both lexicography and NLP.", "labels": [], "entities": []}, {"text": "On the one hand, from the point of view of lexicography, the goal of evaluation would be to measure the quality of the SRs induced, (i.e., how well the resulting classes correspond to the nouns as they were used in the corpus).", "labels": [], "entities": []}, {"text": "On the other hand, from the point of view of NLP, StLs should be evaluated on their utility (i.e., how much they help on performing the reference task).", "labels": [], "entities": []}, {"text": "As far as lexicography (quality) is concerned, we think the main criteria SRs acquired from corpora should meet are: (a) correct categorization -inferred classes should correspond to the correct senses of the words that are being generalized-, (b) appropriate generalization level and (c) good coverage -the majority of the noun occurrences in the corpus should be successfully generalized by the induced SRs.", "labels": [], "entities": []}, {"text": "Some of the methods we could use for assessing experimentally the accomplishment of these criteria would be: \u2022 Introspection A lexicographer checks if the SRs accomplish the criteria (a) and (b) above (e.g., the manual diagnosis in table 1).", "labels": [], "entities": []}, {"text": "Besides the intrinsic difficulties of this approach, it does not seem appropriate when comparing across different techniques for learning SRs, because of its qualitative flavor.", "labels": [], "entities": []}, {"text": "\u2022 Quantification of generalization level appropriateness A possible measure would be the percentage of sense occurrences included in the induced SRs which are effectively correct (from now on called Abstraction Ratio).", "labels": [], "entities": [{"text": "Abstraction Ratio", "start_pos": 199, "end_pos": 216, "type": "METRIC", "confidence": 0.9767346084117889}]}, {"text": "Hopefully, a technique with a higher abstraction ratio learns classes that fit the set of examples better.", "labels": [], "entities": []}, {"text": "A manual assessment of the ratio confirmed this behavior, as testing sets With a lower ratio seemed to be inducing less ~Abs cases.", "labels": [], "entities": [{"text": "Abs cases", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9771320223808289}]}, {"text": "\u2022 Quantification of coverage It could be measured as the proportion of triples whose correct sense belongs to one of the SRs.", "labels": [], "entities": [{"text": "coverage", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.7417896389961243}]}, {"text": "The NLP tasks where SRs utility could be evaluated are diverse.", "labels": [], "entities": [{"text": "SRs", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9733847975730896}]}, {"text": "Some of them have already been introduced in section 1.", "labels": [], "entities": []}, {"text": "In the recent literature,, ...) several task oriented schemes to test Selectional Restrictions (mainly on syntactic ambiguity resolution) have been proposed.", "labels": [], "entities": [{"text": "syntactic ambiguity resolution", "start_pos": 106, "end_pos": 136, "type": "TASK", "confidence": 0.6965643763542175}]}, {"text": "However, we have tested SRs on a WSS task, using the following scheme.", "labels": [], "entities": [{"text": "SRs", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.956696093082428}, {"text": "WSS task", "start_pos": 33, "end_pos": 41, "type": "TASK", "confidence": 0.7593907415866852}]}, {"text": "For every triple in the testing set the algorithm selects as most appropriate that noun-sense that has as hyperonym the SR class with highest association score.", "labels": [], "entities": []}, {"text": "When more than one sense belongs to the highest SR, a random selection is performed.", "labels": [], "entities": []}, {"text": "When no SR has been acquired, the algorithm remains undecided.", "labels": [], "entities": [{"text": "SR", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.9879783391952515}]}, {"text": "The results of this WSS procedure are checked against a testing-sample manually analyzed, and precision and recall ratios are calculated.", "labels": [], "entities": [{"text": "WSS", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9750806093215942}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9994407296180725}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9970687031745911}]}, {"text": "Precision is calculated as the ratio of manual-automatic matches / number of noun occurrences disambiguated by the procedure.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9853388071060181}]}, {"text": "Recall is computed as the ratio of manual-automatic matches / total number of noun occurrences.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9799697995185852}]}, {"text": "rise, report, seek and present.", "labels": [], "entities": []}, {"text": "We only considered those triples that had been correctly extracted from the Treebank and whose noun had the correct sense included in WordNet (2,165 triples out of the 2,658, from now on, called the testingsample).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.9767922759056091}]}, {"text": "As evaluation measures we used coverage, abstraction ratio, and recall and precision ratios on the WSS task (section 4.1).", "labels": [], "entities": [{"text": "coverage", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9935832619667053}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9993725419044495}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.8984485864639282}, {"text": "WSS task", "start_pos": 99, "end_pos": 107, "type": "TASK", "confidence": 0.5170485526323318}]}, {"text": "In addition we performed some evaluation by hand comparing the SRs acquired by the different techniques.", "labels": [], "entities": [{"text": "SRs", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.7963120937347412}]}], "tableCaptions": [{"text": " Table 5: Precision and Recall on the WSS task", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.981532096862793}, {"text": "Recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9710337519645691}, {"text": "WSS", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.8471381068229675}]}]}