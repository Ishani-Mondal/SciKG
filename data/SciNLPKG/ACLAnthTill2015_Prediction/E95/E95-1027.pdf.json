{"title": [{"text": "Towards a Workbench for Acquisition of Domain Knowledge from Natural Language", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we describe an architecture and functionality of main components of a workbench for an acquisition of domain knowledge from large text corpora.", "labels": [], "entities": []}, {"text": "The workbench supports an incremental process of corpus analysis starting from a rough automatic extraction and organization of lexico-semantic regularities and ending with a computer supported analysis of extracted data and a semiautomatic refinement of obtained hypotheses.", "labels": [], "entities": [{"text": "corpus analysis", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7448059916496277}]}, {"text": "For doing this the workbench employs methods from computational linguistics, information retrieval and knowledge engineering.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.8314262330532074}]}, {"text": "Although the workbench is currently under implementation some of its components are already implemented and their performance is illustrated with samples from engineering fora medical domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the standard methods for the extraction of domain knowledge (or domain schema in another terminology) from texts is known as Distributional Analysis.", "labels": [], "entities": [{"text": "Distributional Analysis", "start_pos": 132, "end_pos": 155, "type": "TASK", "confidence": 0.8609870672225952}]}, {"text": "It is based on the identification of the sublanguage specific cooccurrence properties of words in the syntactic relations in which they occur in the texts.", "labels": [], "entities": []}, {"text": "These cooccurrence properties indicate important semantic characteristics of the domain: classes of objects and their hierarchical inclusion, properties of these classes, relations among them, lexicosemantic patterns for referring to certain conceptual propositions, etc.", "labels": [], "entities": []}, {"text": "This knowledge about domain in the form it is extracted is not quite suitable to be included into the knowledge base and require a post-processing of the linguistically trained knowledge engineer.", "labels": [], "entities": []}, {"text": "This is known as a conceptual analysis of the acquired lingistic data.", "labels": [], "entities": []}, {"text": "In general all this is a time consuming process and often requires the help of a domain expert.", "labels": [], "entities": []}, {"text": "However, it seems to be possible to automate some tasks and facilitate human intervention in many parts using a combination of NLP and statistical techniques for data extraction, type oriented patterns for conceptual characterization of this data and an intuitive user interface.", "labels": [], "entities": [{"text": "data extraction", "start_pos": 162, "end_pos": 177, "type": "TASK", "confidence": 0.7351185381412506}]}, {"text": "All these resources are to be put together into a Knowledge Acquisition Workbench (KAWB) which is underdevelopment at LTG of the University of Edinburgh.", "labels": [], "entities": [{"text": "LTG", "start_pos": 118, "end_pos": 121, "type": "DATASET", "confidence": 0.9296172857284546}]}, {"text": "The workbench supports an incremental process of corpus analysis starting from a rough automatic extraction and organization of lexico-semantic regularities and ending with a computer supported analysis of extracted data and a refinement of obtained hypotheses.", "labels": [], "entities": [{"text": "corpus analysis", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.746666669845581}]}], "datasetContent": [], "tableCaptions": []}