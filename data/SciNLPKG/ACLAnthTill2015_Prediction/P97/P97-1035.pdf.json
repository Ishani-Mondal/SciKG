{"title": [{"text": "PARADISE: A Framework for Evaluating Spoken Dialogue Agents", "labels": [], "entities": [{"text": "Evaluating Spoken Dialogue", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.7422136267026266}]}], "abstractContent": [{"text": "This paper presents PARADISE (PARAdigm for Dialogue System Evaluation), a general framework for evaluating spoken dialogue agents.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9543167352676392}, {"text": "Dialogue System Evaluation)", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6452610120177269}]}, {"text": "The framework decouples task requirements from an agent's dialogue behaviors, supports comparisons among dialogue strategies, enables the calculation of performance over subdialogues and whole dialogues, specifies the relative contribution of various factors to performance, and makes it possible to compare agents performing different tasks by normalizing for task complexity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent advances in dialogue modeling, speech recognition, and natural language processing have made it possible to build spoken dialogue agents fora wide variety of applications, n Potential benefits of such agents include remote or hands-free access, ease of use, naturalness, and greater efficiency of interaction.", "labels": [], "entities": [{"text": "dialogue modeling", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.9038981199264526}, {"text": "speech recognition", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7402559518814087}, {"text": "natural language processing", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.7030863364537557}]}, {"text": "However, a critical obstacle to progress in this area is the lack of a general framework for evaluating and comparing the performance of different dialogue agents.", "labels": [], "entities": []}, {"text": "One widely used approach to evaluation is based on the notion of a reference answer ().", "labels": [], "entities": []}, {"text": "An agent's responses to a query are compared with a predefined key of minimum and maximum reference answers; performance is the proportion of responses that match the key.", "labels": [], "entities": []}, {"text": "This approach has many widely acknowledged limitations), e.g., although there maybe many potential dialogue strategies for carrying out a task, the key is tied to one particular dialogue strategy.", "labels": [], "entities": []}, {"text": "In contrast, agents using different dialogue strategies can be compared with measures such as inappropriate utterance ratio, turn correction ratio, concept accuracy, implicit recovery and transaction success (Danieli LWe use the term agent to emphasize the fact that we are evaluating a speaking entity that may have a personality.", "labels": [], "entities": [{"text": "turn correction ratio", "start_pos": 125, "end_pos": 146, "type": "METRIC", "confidence": 0.7711395819981893}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.6341882348060608}]}, {"text": "Readers who wish to may substitute the word \"system\" wherever \"agent\" is used..", "labels": [], "entities": []}, {"text": "Consider a comparison of two train timetable information agents, where Agent A in Dialogue I uses an explicit confirmation strategy, while Agent B in Dialogue 2 uses an implicit confirmation strategy: (1) User: I want to go from Torino to Milano.", "labels": [], "entities": []}, {"text": "Agent A: Do you want to go from Trento to Milano?", "labels": [], "entities": []}, {"text": "User: No. (2) User: I want to travel from Torino to Milano.", "labels": [], "entities": []}, {"text": "Agent B: At which time do you want to leave from Merano to Milano?", "labels": [], "entities": [{"text": "Merano", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9094817638397217}]}, {"text": "User: No, I want to leave from Torino in the evening.", "labels": [], "entities": []}, {"text": "Danieli and Gerbino found that Agent A had a higher transaction success rate and produced less inappropriate and repair utterances than Agent B, and thus concluded that Agent A was more robust than Agent B. However, one limitation of both this approach and the reference answer approach is the inability to generalize results to other tasks and environments.", "labels": [], "entities": []}, {"text": "Such generalization requires the identification of factors that affect performance.", "labels": [], "entities": []}, {"text": "For example, while Danieli and Gerbino found that Agent A's dialogue strategy produced dialogues that were approximately twice as long as Agent B's, they had noway of determining whether Agent A's higher transaction successor Agent B's efficiency was more critical to performance.", "labels": [], "entities": []}, {"text": "In addition to agent factors such as dialogue strategy, task factors such as database size and environmental factors such as background noise may also be relevant predictors of performance.", "labels": [], "entities": [{"text": "dialogue strategy", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8865165412425995}]}, {"text": "These approaches are also limited in that they currently do not calculate performance over subdialogues as well as whole dialogues, correlate performance with an external validation criterion, or normalize performance for task complexity.", "labels": [], "entities": []}, {"text": "This paper describes PARADISE, a general framework for evaluating spoken dialogue agents that addresses these limitations.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9185999631881714}]}, {"text": "PARADISE supports comparisons among dialogue strategies by providing a task representation that decouples what an agent needs to achieve in terms of I MAXIMIZE USER SATISFACTION[ l: PARADISE's structure of objectives for spoken dialogue performance the task requirements from how the agent carries out the task via dialogue.", "labels": [], "entities": [{"text": "I MAXIMIZE USER", "start_pos": 149, "end_pos": 164, "type": "METRIC", "confidence": 0.7363224426905314}, {"text": "SATISFACTION", "start_pos": 165, "end_pos": 177, "type": "METRIC", "confidence": 0.6263561844825745}]}, {"text": "PARADISE uses a decision-theoretic framework to specify the relative contribution of various factors to an agent's overall performance.", "labels": [], "entities": []}, {"text": "Performance is modeled as a weighted function of a task-based success measure and dialogue-based cost measures, where weights are computed by correlating user satisfaction with performance.", "labels": [], "entities": []}, {"text": "Also, performance can be calculated for subdialogues as well as whole dialogues.", "labels": [], "entities": []}, {"text": "Since the goal of this paper is to explain and illustrate the application of the PARADISE framework, for expository purposes, the paper uses simplified domains with hypothetical data throughout.", "labels": [], "entities": []}, {"text": "Section 2 describes PARADISE's performance model, and Section 3 discusses its generality, before concluding in Section 4.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.4279192388057709}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Confusion matrix, Agent A", "labels": [], "entities": []}, {"text": " Table 5: Hypothetical performance data from users of  Agents A and B", "labels": [], "entities": []}]}