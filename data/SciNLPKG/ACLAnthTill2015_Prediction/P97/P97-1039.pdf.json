{"title": [{"text": "A Portable Algorithm for Mapping Bitext Correspondence", "labels": [], "entities": [{"text": "Mapping Bitext Correspondence", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.7341148257255554}]}], "abstractContent": [{"text": "The first step inmost empirical work in multilingual NLP is to construct maps of the correspondence between texts and their translations (bitext maps).", "labels": [], "entities": []}, {"text": "The Smooth Injective Map Recognizer (SIMR) algorithm presented here is a generic pattern recognition algorithm that is particularly well-suited to mapping bitext correspondence.", "labels": [], "entities": [{"text": "Smooth Injective Map Recognizer (SIMR)", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.7368528161730085}, {"text": "pattern recognition", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7305325418710709}]}, {"text": "SIMR is faster and significantly more accurate than other algorithms in the literature.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.7940879464149475}]}, {"text": "The algorithm is robust enough to use on noisy texts, such as those resulting from OCR input, and on translations that are not very literal.", "labels": [], "entities": []}, {"text": "SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort.", "labels": [], "entities": []}], "introductionContent": [{"text": "Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applications z.", "labels": [], "entities": []}, {"text": "Bitexts are the raw material from which translation models are built.", "labels": [], "entities": []}, {"text": "In addition to their use in machine translation), translation models can be applied to machineassisted translation), cross-lingual information retrieval, and gisting of World Wide Web pages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7615330517292023}, {"text": "translation", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.9620416760444641}, {"text": "machineassisted translation", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.7002319693565369}, {"text": "cross-lingual information retrieval", "start_pos": 117, "end_pos": 152, "type": "TASK", "confidence": 0.6744813323020935}, {"text": "gisting of World Wide Web pages", "start_pos": 158, "end_pos": 189, "type": "TASK", "confidence": 0.6180827965339025}]}, {"text": "Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography, computer-assisted language learning, and tools for translators (e.g. (Macklovitch, 1 \"Multitexts\" in more than two languages are even more valuable, but they are much more rare.", "labels": [], "entities": []}, {"text": "However, bitexts are of little use without an automatic method for constructing bitext maps.", "labels": [], "entities": []}, {"text": "Bitext maps identify corresponding text units between the two halves of a bitext.", "labels": [], "entities": []}, {"text": "The ideal bitext mapping algorithm should be fast and accurate, use little memory and degrade gracefully when faced with translation irregularities like omissions and in. versions.", "labels": [], "entities": []}, {"text": "It should be applicable to any text genre in any pair of languages.", "labels": [], "entities": []}, {"text": "The Smooth Injective Map Recognizer (SIMR) algorithm presented in this paper is a bitext mapping algorithm that advances the state of the art on these criteria.", "labels": [], "entities": [{"text": "Smooth Injective Map Recognizer (SIMR)", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.7371868874345507}]}, {"text": "The evaluation in Section 5 shows that SIMR's error rates are lower than those of other bitext mapping algorithms by an order of magnitude.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 39, "end_pos": 43, "type": "TASK", "confidence": 0.9078340530395508}, {"text": "error", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9682226181030273}]}, {"text": "At the same time, its expected running time and memory requirements are linear in the size of the input, better than any other published algorithm.", "labels": [], "entities": [{"text": "memory", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9683085680007935}]}, {"text": "The paper begins by laying down SIMR's geometric foundations and describing the algorithm.", "labels": [], "entities": []}, {"text": "Then, Section 4 explains how to port SIMR to arbitrary language pairs with minimal effort, without relying on genre-specific information such as sentence boundaries.", "labels": [], "entities": []}, {"text": "The last section offers some insights about the optimal level of text analysis for mapping bitext correspondence.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.7414612770080566}, {"text": "mapping bitext correspondence", "start_pos": 83, "end_pos": 112, "type": "TASK", "confidence": 0.8262380957603455}]}], "datasetContent": [{"text": "SIMR was evaluated on hand-aligned bitexts of various genres in three language pairs.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.6247236728668213}]}, {"text": "None of these test bitexts were used anywhere in the training or porting procedures.", "labels": [], "entities": [{"text": "porting", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.9021280407905579}]}, {"text": "Each test bitext was converted to a set of TPCs by noting the pair of character positions at the end of each aligned pair of text segments.", "labels": [], "entities": []}, {"text": "The test metric was the root mean squared distance, in characters, between each TPC and the interpolated bitext map produced by SIMR, where the distance was measured perpendicular to the main diagonal.", "labels": [], "entities": [{"text": "root mean squared distance", "start_pos": 24, "end_pos": 50, "type": "METRIC", "confidence": 0.6698483750224113}, {"text": "SIMR", "start_pos": 128, "end_pos": 132, "type": "DATASET", "confidence": 0.7478847503662109}]}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "The French/English part of the evaluation was performed on bitexts from the publicly available BAF corpus created at CITI).", "labels": [], "entities": [{"text": "BAF corpus created at CITI", "start_pos": 95, "end_pos": 121, "type": "DATASET", "confidence": 0.8854173183441162}]}, {"text": "SIMR's error distribution on the \"parliamentary debates\" bitext in this collection is given in.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6879472136497498}]}, {"text": "This distribution can be compared to error distributions reported in and in).", "labels": [], "entities": []}, {"text": "SIMR's RMS error on this bitext was 5.7 characters.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7496426105499268}, {"text": "RMS error", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.6402110904455185}]}, {"text": "Church's char_align algorithm) is the only algorithm that does not use sentence boundary information for which comparable results have been reported, char_align's RMS error on this bitext was 57 characters, exactly ten times higher.", "labels": [], "entities": []}, {"text": "Two teams of researchers have reported results on the same \"parliamentary debates\" bitext for algorithms that map correspondence at the sentence level).", "labels": [], "entities": []}, {"text": "Both of these algorithms use sentence boundary information.", "labels": [], "entities": []}, {"text": "showed that sentence boundary information can be used to convert SIMR's output into sentence alignments that are more accurate than those obtained by either of the other two approaches.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.9316684007644653}]}, {"text": "The test bitexts in the other two language pairs were created when SIMR was being ported to those languages.", "labels": [], "entities": []}, {"text": "The Spanish/English bitexts were drawn from the on-line Sun MicroSystems Solaris AnswerBooks.", "labels": [], "entities": [{"text": "Sun MicroSystems Solaris AnswerBooks", "start_pos": 56, "end_pos": 92, "type": "DATASET", "confidence": 0.8438890278339386}]}, {"text": "The Korean/English bitexts were provided and hand-aligned by Young-Suk Lee of MIT's Lincoln Laboratories.", "labels": [], "entities": []}, {"text": "Although it is not possible to compare SIMR's performance on these language pairs to the performance of other algorithms, shows that the performance on other language pairs is no worse than performance on French/English.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Time spent in constructing two \"gold standard\" TBMs.  estimated time  estimated time  main informant for  spent to build  spent on  language pair  matching predicate new axis generator hand-alignment  Spanish/English  lexical cognates  8 h  5 h  Korean/English  translation lexicon  6 h  12 h", "labels": [], "entities": []}, {"text": " Table 2: SIMR accuracy on different text genres in three language pairs.  language  number of  number of  RMS Error  pair  training TPCs  genre  test TPCs  in characters  French / English  598  parliamentary debates  CITI technical reports  other technical reports  court transcripts  U.N. annual report  I.L.O. report", "labels": [], "entities": [{"text": "SIMR", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.8646393418312073}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9752308130264282}, {"text": "U.N. annual report  I.L.O. report", "start_pos": 286, "end_pos": 319, "type": "DATASET", "confidence": 0.7573617339134217}]}, {"text": " Table 3:  SIMR 's error distribution on the  French/English \"parliamentary debates\" bitext.  number of  error range  fraction of  test points in characters test points  1  2  1  5  4  6  9  29  3057  3902  43  28  17  5  8  1  1  1  1  1  1", "labels": [], "entities": [{"text": "SIMR", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.6600421667098999}, {"text": "French/English \"parliamentary debates\" bitext", "start_pos": 46, "end_pos": 91, "type": "DATASET", "confidence": 0.8338616117835045}]}]}