{"title": [{"text": "Paradigmatic Cascades: a Linguistically Sound Model of Pronunciation by Analogy", "labels": [], "entities": [{"text": "Paradigmatic Cascades", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8441539406776428}]}], "abstractContent": [{"text": "We present and experimentally evaluate anew model of pronunciation by analogy: the paradigmatic cascades model.", "labels": [], "entities": []}, {"text": "Given a pronunciation lexicon, this algorithm first extracts the most productive paradigmatic mappings in the graphemic domain, and pairs them statistically with their corre-late(s) in the phonemic domain.", "labels": [], "entities": []}, {"text": "These mappings are used to search and retrieve in the lexical database the most promising analog of unseen words.", "labels": [], "entities": []}, {"text": "We finally apply to the analogs pronunciation the correlated series of mappings in the phonemic domain to get the desired pronunciation.", "labels": [], "entities": []}, {"text": "1 Motivation Psychological models of reading aloud traditionally assume the existence of two separate routes for converting print to sound: a direct lexical route, which is used to read familiar words, and a dual route relying upon abstract letter-to-sound rules to pronounce previously unseen words (Coltheart, 1978; Coltheart et al., 1993).", "labels": [], "entities": [{"text": "Coltheart, 1978; Coltheart et al.", "start_pos": 301, "end_pos": 334, "type": "DATASET", "confidence": 0.8128220353807721}]}, {"text": "This view has been challenged by a number of authors (e.g. (Glushsko, 1981)), who claim that the pronunciation process of every word, familiar or unknown, could be accounted for in a unified framework.", "labels": [], "entities": []}, {"text": "These single-route models crucially suggest that the pronunciation of unknown words results from the parallel activation of similar lexical items (the lexical neighbours).", "labels": [], "entities": []}, {"text": "This idea has been tentatively implemented both into various symbolic analogy-based algorithms (e.g. (Dedina and Nusbaum, 1991; Sullivan and Damper, 1992)) and into connectionist pronunciation devices (e.g. (Sei-denberg and McClelland, 1989)).", "labels": [], "entities": []}, {"text": "The basic idea of these analogy-based models is to pronounce an unknown word x by recombin-ing pronunciations of lexical items sharing common subparts with x.", "labels": [], "entities": []}, {"text": "To illustrate this strategy, Ded-ina and Nussbaum show how the pronunciation of the sequence lop in the pseudo-word blope is analo-gized with the pronunciation of the same sequence in sloping.", "labels": [], "entities": []}, {"text": "As there exists more than one way to re-combine segments of lexical items, Dedina and Nuss-baum's algorithm favors recombinations including large substrings of existing words.", "labels": [], "entities": []}, {"text": "In this model, the similarity between two words is thus implicitely defined as a function of the length of their common subparts: the longer the common part, the better the analogy.", "labels": [], "entities": []}, {"text": "This conception of analogical processes has an important consequence: it offers, as Damper and East-mona ((Damper and Eastmond, 1996)) state it, \"no principled way of deciding the orthographic neigh-bouts of a novel word which are deemed to influence its pronunciation (...)\".", "labels": [], "entities": []}, {"text": "For example, in the model proposed by Dedina and Nusbaum, any word having a common orthographic substring with the unknown word is likely to contribute to its pronunciation , which increases the number of lexical neigh-bouts far beyond acceptable limits (in the case of blope, this neighbourhood would contain every En-glish word starting in bl, or ending in ope, etc).", "labels": [], "entities": []}, {"text": "From a computational standpoint, implementing the recombination strategy requires a one-to-one alignment between the lexical graphemic and phonemic representations, where each grapheme is matched with the corresponding phoneme (a null symbol is used to account for the cases where the lengths of these representations differ).", "labels": [], "entities": []}, {"text": "This alignment makes it possible to retrieve, for any graphemic substring of a given lexical item, the corresponding phonemic string, at the cost however of an unmoti-vated complexification of lexical representations.", "labels": [], "entities": []}, {"text": "In comparison, the paradigmatic cascades model (PCP for short) promotes an alternative view of analogical processes, which relies upon a linguistically motivated similarity measure between words.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We have evaluated this algorithm on two different pronunciation tasks.", "labels": [], "entities": []}, {"text": "The first experiment consists in infering the pronunciation of the 70 pseudo-words originally used in Glushko's experiments, which have been used as a test-bed for various other pronunciation algorithms, and allow fora fair head-tohead comparison between the paradigmatic cascades model and other analogy-based procedures.", "labels": [], "entities": []}, {"text": "For this experiment, we have used the entire nettalk database (about 20 000 words) as the learning set.", "labels": [], "entities": []}, {"text": "The second series of experiments is intended to provide a more realistic evaluation of our model ill the task of pronouncing unknown words.", "labels": [], "entities": []}, {"text": "We have used the following experimental design: 10 pairs of disjoint (learning set, test set) are randomly selected from the nettalk database and evaluated.", "labels": [], "entities": []}, {"text": "In each experiment, the test set contains abou~ the tenth of the available data.", "labels": [], "entities": []}, {"text": "A transcription is judged to be correct when it matches exactly the pronuncia--tion listed in the database at the segmental level.", "labels": [], "entities": []}, {"text": "The number of correct phonemes in a transcription is computed on the basis of the string-to-string edit distance with the target pronunciation.", "labels": [], "entities": []}, {"text": "For each experiment, we measure the percentage of phoneme and words that are correctly predicted (referred to as correctness), and two additional figures, which are usually not significant in context of the evaluation of transcription systems.", "labels": [], "entities": []}, {"text": "Recall that our algorithm, unlike many other pronunciation algorithms, is likely to remain silent.", "labels": [], "entities": []}, {"text": "In order to take this aspect into account, we measure in each experiment the number of words that cannot be pronounced at all (the silence), and the percentage of phonemes and words that are correctly transcribed amongst those words that have been pronounced at all (the precision).", "labels": [], "entities": [{"text": "precision", "start_pos": 271, "end_pos": 280, "type": "METRIC", "confidence": 0.9988059997558594}]}, {"text": "The average values for these measures are reported hereafter.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: A Comparatiw. l~;valuation", "labels": [], "entities": [{"text": "A", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.8934665322303772}]}]}