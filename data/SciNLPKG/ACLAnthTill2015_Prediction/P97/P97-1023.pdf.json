{"title": [{"text": "Predicting the Semantic Orientation of Adjectives", "labels": [], "entities": [{"text": "Semantic Orientation of Adjectives", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.7569108158349991}]}], "abstractContent": [{"text": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives.", "labels": [], "entities": []}, {"text": "A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9992071986198425}]}, {"text": "Combining the constraints across many adjectives , a clustering algorithm separates the adjectives into groups of different orien-tations, and finally, adjectives are labeled positive or negative.", "labels": [], "entities": []}, {"text": "Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.8947820067405701}]}], "introductionContent": [{"text": "The semantic orientation or polarity of a word indicates the direction the word deviates from the norm for its semantic group or lezical field.", "labels": [], "entities": []}, {"text": "It also constrains the word's usage in the language, due to its evaluative characteristics.", "labels": [], "entities": []}, {"text": "For example, some nearly synonymous words differ in orientation because one implies desirability and the other does not (e.g., simple versus simplisfic).", "labels": [], "entities": []}, {"text": "In linguistic constructs such as conjunctions, which impose constraints on the semantic orientation of their arguments, the choices of arguments and connective are mutually constrained, as illustrated by: The tax proposal was simple and well-received } simplistic but well-received *simplistic and well-received by the public.", "labels": [], "entities": []}, {"text": "In addition, almost all antonyms have different semantic orientations3 If we know that two words relate to the same property (for example, members of the same scalar group such as hot and cold) but have different orientations, we can usually infer that they are antonyms.", "labels": [], "entities": []}, {"text": "Given that semantically similar words can be identified automatically on the basis of distributional properties and linguistic cues, identifying the semantic orientation of words would allow a system to further refine the retrieved semantic similarity relationships, extracting antonyms.", "labels": [], "entities": []}, {"text": "Unfortunately, dictionaries and similar sources (theusari, WordNet) do not include semantic orientation information.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9536760449409485}, {"text": "semantic orientation", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7160205543041229}]}, {"text": "2 Explicit links between antonyms and synonyms may also be lacking, particularly when they depend on the domain of discourse; for example, the opposition bearbull appears only in stock market reports, where the two words take specialized meanings.", "labels": [], "entities": []}, {"text": "In this paper, we present and evaluate a method that automatically retrieves semantic orientation information using indirect information collected from a large corpus.", "labels": [], "entities": [{"text": "semantic orientation information", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.7476336558659872}]}, {"text": "Because the method relies on the corpus, it extracts domain-dependent information and automatically adapts to anew domain when the corpus is changed.", "labels": [], "entities": []}, {"text": "Our method achieves high precision (more than 90%), and, while our focus to date has been on adjectives, it can be directly applied to other word classes.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9987697005271912}]}, {"text": "Ultimately, our goal is to use this method in a larger system to automatically identify antonyms and distinguish near synonyms.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since graph connectivity affects performance, we devised a method of selecting test sets that makes this dependence explicit.", "labels": [], "entities": []}, {"text": "Note that the graph density is largely a function of corpus size, and thus can be increased by adding more data.", "labels": [], "entities": []}, {"text": "Nevertheless, we report results on sparser test sets to show how our algorithm scales up.", "labels": [], "entities": []}, {"text": "We separated our sets of adjectives A (containing 1,336 adjectives) and conjunction-and morphologybased links L (containing 2,838 links) into training and testing groups by selecting, for several values of the parameter a, the maximal subset of A, An, which includes an adjective z if and only if there exist at least a links from L between x and other elements of An.", "labels": [], "entities": []}, {"text": "This operation in turn defines a subset of L, L~, which includes all links between members of An.", "labels": [], "entities": []}, {"text": "We train our log-linear model on L -La (excluding links between morphologically related adjectives), compute predictions and dissimilarities for the links in L~, and use these to classify and label the adjectives in An. c~ must beat least 2, since we need to leave some links for training.", "labels": [], "entities": []}, {"text": "shows the results of these experiments fora = 2 to 5.", "labels": [], "entities": []}, {"text": "Our method produced the correct classification between 78% of the time on the sparsest test setup to more than 92% of the time when a higher number of links was present.", "labels": [], "entities": []}, {"text": "Moreover, in all cases, the ratio of the two group frequencies correctly identified the positive subgroup.", "labels": [], "entities": []}, {"text": "These results are extremely significant statistically (P-value less than 10 -16 ) when compared with the baseline method of randomly assigning orientations to adjectives, or the baseline method of always predicting the most frequent (for types) category (50.82% of the adjectives in our collection are classified as negative).", "labels": [], "entities": [{"text": "P-value", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.9866863489151001}]}, {"text": "shows some of the adjectives in set A4 and their classifications.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Validation of our conjunction hypothesis. The P-value is the probability that similar  extreme results would have been obtained if same-and different-orientation conjunction types were  equally distributed.", "labels": [], "entities": [{"text": "P-value", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9832792282104492}]}, {"text": " Table 2: Accuracy of several link prediction models.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.99398273229599}, {"text": "link prediction", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.727179229259491}]}, {"text": " Table 3: Evaluation of the adjective classification and labeling methods.", "labels": [], "entities": [{"text": "adjective classification", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.7304167747497559}]}]}