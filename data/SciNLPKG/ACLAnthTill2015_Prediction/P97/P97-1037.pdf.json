{"title": [{"text": "ADP based Search Using Monotone Alignments in Statistical Translation", "labels": [], "entities": [{"text": "Statistical Translation", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.8500632345676422}]}], "abstractContent": [{"text": "In this paper, we describe a Dynamic Programming (DP) based search algorithm for statistical translation and present experimental results.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.8326912820339203}]}, {"text": "The statistical translation uses two sources of information: a translation model and a language model.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.716536819934845}]}, {"text": "The language model used is a standard bigram model.", "labels": [], "entities": []}, {"text": "For the translation lnodel, the alignment probabilities are made dependent on the differences in the alignment positions rather than on the absolute positions.", "labels": [], "entities": []}, {"text": "Thus, the approach amounts to a first-order Hidden Markov model (HMM) as they are used successfully in speech recognition for the time alignment problem.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.7725038826465607}, {"text": "time alignment problem", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.7701934377352396}]}, {"text": "Under the assumption that the alignment is monotone with respect to the word order in both languages, an efficient search strategy for translation can be formulated.", "labels": [], "entities": [{"text": "translation", "start_pos": 135, "end_pos": 146, "type": "TASK", "confidence": 0.9704601168632507}]}, {"text": "The details of the search algorithm are described.", "labels": [], "entities": []}, {"text": "Experiments on the EuTrans corpus produced a word error rate of 5.1(/~..", "labels": [], "entities": [{"text": "EuTrans corpus", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.9575439095497131}, {"text": "word error rate", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.6666372021039327}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Effect of the transformation steps on the  vocabulary sizes in both languages.", "labels": [], "entities": []}, {"text": " Table 3: Word error rates (INS/DEL, WER) and  sentence error rates (SER) for different transforma- tion steps.", "labels": [], "entities": [{"text": "Word error rates (INS/DEL, WER)", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.7669450402259826}, {"text": "sentence error rates (SER)", "start_pos": 47, "end_pos": 73, "type": "METRIC", "confidence": 0.8733047445615133}]}, {"text": " Table 3. the translation er- rors can be reduced systen~at.ically by applying all  transformation steps. The word error rate is re- duced from 21.2{,} t.o 5.1{2~: the sentence error rate  is reduced from 85.55~, to 30.1%. The two most ina- portant transformation steps are categorization and  word joining. What is striking, is the large fi'action  of deletion errors. These deletion errors are often  caused by the omission of word groups like 'for me  please \"and \"could you \".", "labels": [], "entities": [{"text": "word error rate", "start_pos": 110, "end_pos": 125, "type": "METRIC", "confidence": 0.8244438767433167}, {"text": "sentence error rate", "start_pos": 168, "end_pos": 187, "type": "METRIC", "confidence": 0.7427437007427216}, {"text": "word joining", "start_pos": 294, "end_pos": 306, "type": "TASK", "confidence": 0.8170442283153534}]}, {"text": " Table 5: Language model perplexity (PP), word er- ror rates (INS/DEL. WER) and sentence error rates  (SER) for different language models.", "labels": [], "entities": [{"text": "Language model perplexity (PP)", "start_pos": 10, "end_pos": 40, "type": "METRIC", "confidence": 0.6132680922746658}, {"text": "word er- ror rates (INS/DEL. WER)", "start_pos": 42, "end_pos": 75, "type": "METRIC", "confidence": 0.859293058514595}, {"text": "sentence error rates  (SER)", "start_pos": 80, "end_pos": 107, "type": "METRIC", "confidence": 0.8581373989582062}]}]}