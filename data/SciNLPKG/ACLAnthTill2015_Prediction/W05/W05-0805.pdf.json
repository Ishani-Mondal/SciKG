{"title": [{"text": "Revealing Phonological Similarities between Related Languages from Automatically Generated Parallel Corpora", "labels": [], "entities": [{"text": "Revealing Phonological Similarities between Related Languages from Automatically Generated Parallel Corpora", "start_pos": 0, "end_pos": 107, "type": "TASK", "confidence": 0.7187571173364465}]}], "abstractContent": [{"text": "In this paper, we present an approach to automatically revealing phonological correspondences within historically related languages.", "labels": [], "entities": [{"text": "automatically revealing phonological correspondences within historically related languages", "start_pos": 41, "end_pos": 131, "type": "TASK", "confidence": 0.7224606871604919}]}, {"text": "We create two bilingual pronunciation dictionaries for the language pairs German-Dutch and German-English.", "labels": [], "entities": []}, {"text": "The data is used for automatically learning phonological similarities between the two language pairs via EM-based clustering.", "labels": [], "entities": []}, {"text": "We apply our models to predict from a phonological German word the phonemes of a Dutch and an English cognate.", "labels": [], "entities": []}, {"text": "The similarity scores show that German and Dutch phonemes are more similar than German and En-glish phonemes, which supplies statistical evidence of the common knowledge that German is more closely related to Dutch than to English.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9798504114151001}]}, {"text": "We assess our approach qualitatively, finding meaningful classes caused by historical sound changes.", "labels": [], "entities": []}, {"text": "The classes can be used for language learning.", "labels": [], "entities": []}], "introductionContent": [{"text": "German and Dutch are languages that exhibit a wide range of similarities.", "labels": [], "entities": []}, {"text": "Beside similar syntactic features like word order and verb subcategorization frames, the languages share phonological features which are due to historical sound changes.", "labels": [], "entities": []}, {"text": "These similarities are one reason why it is easier to learn a closely historically related language than languages from other language families: the learner's native language provides a valuable resource which can be used in learning the new language.", "labels": [], "entities": []}, {"text": "Although English also belongs to the West Germanic languages, German and Dutch share more lexical entries with a common root than German and English.", "labels": [], "entities": []}, {"text": "The knowledge about language similarities on the lexical level is exploited in various fields.", "labels": [], "entities": []}, {"text": "In machine translation, some approaches search for similar words (cognates) which are used to align parallel texts (e.g.,).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7494871318340302}]}, {"text": "The word triple Text-tekst-text ( in German, Dutch and English) can be easily recognized as a cognate; recognizing Pfeffer-peper-pepper[f@r]-[pe:][p@r])-[p@r*]), however, requires more knowledge about sound changes within the languages.", "labels": [], "entities": []}, {"text": "The algorithms developed for machine translation search for similarities on the orthographic level, whereas some approaches to comparative and synchronic linguistics put their focus on similarities of phonological sequences.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7846106886863708}]}, {"text": "Covington (1996), for instance, suggests different algorithms to align the phonetic representation of words of historical languages.", "labels": [], "entities": []}, {"text": "presents an algorithm to align phonetic sequences by computing the similarities of these words.", "labels": [], "entities": []}, {"text": "use phonetic transcriptions to measure the phonetic distance between different dialects.", "labels": [], "entities": []}, {"text": "The above mentioned approaches presuppose either parallel texts of different languages for machine translation or manually compiled lists of transcribed cognates/words for analyzing synchronic or diachronic word pairs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7544496953487396}]}, {"text": "Unfortunately, transcribed bilingual data are scarce and it is labor-intensive to collect these kind of corpora.", "labels": [], "entities": []}, {"text": "Thus, we aim at exploiting electronic pronunciation dictionaries to overcome the lack of data.", "labels": [], "entities": []}, {"text": "In our approach, we automatically generate data as input to an unsupervised training regime and with the aim of automatically learning similar structures from these data using Expectation Maximization (EM) based clustering.", "labels": [], "entities": []}, {"text": "Although the generation of our data introduces some noise, we expect that our method is able to automatically learn meaningful sound correspondences from a large amount of data.", "labels": [], "entities": []}, {"text": "Our main assumption is that certain German/Dutch and German/English phoneme pairs from related stems occur more often and hence will appear in the same class with a higher probability than pairs not in related stems.", "labels": [], "entities": []}, {"text": "We assume that the historical sound changes are hidden information in the classes.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 presents related research.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the creation of our bilingual pronunciation dictionaries.", "labels": [], "entities": []}, {"text": "The outcome is used as input to the algorithm for automatically deriving phonological classes described in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we apply our classes to a transcribed cognate list and measure the similarity between the two language pairs.", "labels": [], "entities": []}, {"text": "A qualitative evaluation is presented in Section 6, where we interpret our best models.", "labels": [], "entities": []}, {"text": "In Sections 7 and 8, we discuss our results and draw some final conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the 59,819 onset, nucleus and coda pairs as training material for our unsupervised training.", "labels": [], "entities": [{"text": "onset", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9147210121154785}]}, {"text": "Unsupervised methods require the variation of all free parameters to search for the optimal model.", "labels": [], "entities": []}, {"text": "There are three different parameters which have to be varied: the initial start parameters, the number of classes and the number of re-estimation steps.", "labels": [], "entities": []}, {"text": "Thus, we experiment with 10 different start parameters, 6 different numbers of classes 25 and 30 4 ) and 20 steps of re-estimation.", "labels": [], "entities": []}, {"text": "Our training regime yields 1,200 onset, 1,200 coda and 1,000 nucleus models.", "labels": [], "entities": []}, {"text": "Our training material is slightly smaller for GermanEnglish than for German-Dutch.", "labels": [], "entities": [{"text": "GermanEnglish", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9242295026779175}]}, {"text": "We derive 35,847 onset, nucleus and coda pairs for training.", "labels": [], "entities": [{"text": "onset", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9526416659355164}]}, {"text": "The reduced training set is due to the structure of words which is less similar for German-English words than for German-Dutch words leading to words with unequal syllable numbers.", "labels": [], "entities": []}, {"text": "We used the same training regime as in Section 4.1, yielding the same number of models.", "labels": [], "entities": []}, {"text": "In this section, we interpret our classes by manually identifying classes that show typical similarities between the two language pairs.", "labels": [], "entities": []}, {"text": "Sometimes, the classes reflect sound changes in historically related stems.", "labels": [], "entities": []}, {"text": "Our data is synchronic, and thus it is not possible to directly identify in our classes which sound changes took place (Modern German (G), Modern English (E) and Modern Dutch (NL) did not develop from each other but from a common ancestor).", "labels": [], "entities": []}, {"text": "However, we will try to connect the data to ancient languages such as Old High German (OHG), Middle High German (MHG), Old English (OE), Middle Dutch (MNL), Old Dutch (ONL), Proto or West Germanic (PG, WG).", "labels": [], "entities": []}, {"text": "Naturally, we can only go back in history as far as it is possible according to the information provided by the following literature: For Dutch, we use de Vries (1997) and the online version of, for English, an etymological dictionary) and for German,.", "labels": [], "entities": []}, {"text": "We find that certain historic sound changes took place regularly, and thus, the results of these changes can be rediscovered in our synchronic classes.", "labels": [], "entities": []}, {"text": "shows the historic relationship between the three languages.", "labels": [], "entities": []}, {"text": "A potential learner of a related language does not have to be aware of the historic links between languages but he/she can implicitly exploit the similarities such as the ones discovered in the classes.", "labels": [], "entities": []}, {"text": "The relationship of words from different languages can be caused by different processes: some words are simply borrowed from another language and adapted to anew language.", "labels": [], "entities": []}, {"text": "Papagei-papegaai (parrot) is borrowed from Arabic and adapted to German and Dutch phonetics, where the /g/ is pronounced in German as a voiced velar plosive and in Dutch as an unvoiced velar fricative.", "labels": [], "entities": []}, {"text": "Other language changes are due to phonology; e.g., the Old English word (PG: muHs) was subject to diphthongization and changed to mouse) in Modern English.", "labels": [], "entities": []}, {"text": "A similar process took place in German and Dutch, where the same word changed to the German word Maus (MHG: m\u00fbs) and to the Dutch word muis (MNL: muus).", "labels": [], "entities": []}, {"text": "On the synchronic level, we find and in the same class of a German-English model and and in a German-Dutch model.", "labels": [], "entities": []}, {"text": "There are also other phonological processes which apply to the nuclei, such as monophthongization, raising, lowering, backing and fronting.", "labels": [], "entities": []}, {"text": "Other phonological processes can be observed in conjunction with consonants, such as assimilation, dissimilation, deletion and insertion.", "labels": [], "entities": []}, {"text": "Some of the above mentioned phonological processes are the underlying processes of the subsequent described classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Similarity scores for syllable parts of cog- nates indicating that German is closer related to  Dutch than to English.", "labels": [], "entities": [{"text": "Similarity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9500445127487183}]}]}