{"title": [{"text": "Machine Translation as Lexicalized Parsing with Hooks", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7521944046020508}, {"text": "Lexicalized Parsing with Hooks", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.7563805282115936}]}], "abstractContent": [{"text": "We adapt the \"hook\" trick for speeding up bilexical parsing to the decoding problem for machine translation models that are based on combining asynchronous context free grammar as the translation model with an n-gram language model.", "labels": [], "entities": [{"text": "bilexical parsing", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7180858254432678}, {"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7672178447246552}]}, {"text": "This dynamic programming technique yields lower complexity algorithms than have previously been described for an important class of translation models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina number of recently proposed synchronous grammar formalisms, machine translation of new sentences can bethought of as a form of parsing on the input sentence.", "labels": [], "entities": [{"text": "machine translation of new sentences", "start_pos": 64, "end_pos": 100, "type": "TASK", "confidence": 0.842110538482666}]}, {"text": "The parsing process, however, is complicated by the interaction of the context-free translation model with an m-gram 1 language model in the output language.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9777891039848328}]}, {"text": "While such formalisms admit dynamic programming solutions having polynomial complexity, the degree of the polynomial is prohibitively high.", "labels": [], "entities": []}, {"text": "In this paper we explore parallels between translation and monolingual parsing with lexicalized grammars.", "labels": [], "entities": [{"text": "translation", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.9632328748703003}]}, {"text": "Chart items in translation must be augmented with words from the output language in order to capture language model state.", "labels": [], "entities": []}, {"text": "This can bethought of as a form of lexicalization with some similarity to that of head-driven lexicalized grammars, despite being unrelated to any notion of syntactic head.", "labels": [], "entities": []}, {"text": "We show that techniques for parsing with lexicalized grammars can be adapted to the translation problem, reducing the complexity of decoding with an inversion transduction grammar and a bigram language model from O(n 7 ) to O(n 6 ).", "labels": [], "entities": [{"text": "translation", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.9640063643455505}]}, {"text": "We present background on this translation model as well as the use of the technique in bilexicalized parsing before describing the new algorithm in detail.", "labels": [], "entities": []}, {"text": "We then extend the algorithm to general m-gram language models, and to general synchronous context-free grammars for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.9646618962287903}]}], "datasetContent": [], "tableCaptions": []}