{"title": [{"text": "Parsing Word-Aligned Parallel Corpora in a Grammar Induction Context", "labels": [], "entities": [{"text": "Parsing Word-Aligned Parallel Corpora in a Grammar Induction Context", "start_pos": 0, "end_pos": 68, "type": "TASK", "confidence": 0.7773427367210388}]}], "abstractContent": [{"text": "We present an Earley-style dynamic programming algorithm for parsing sentence pairs from a parallel corpus simultaneously , building up two phrase structure trees and a correspondence mapping between the nodes.", "labels": [], "entities": []}, {"text": "The intended use of the algorithm is in bootstrapping grammars for less studied languages by using implicit grammatical information in parallel corpora.", "labels": [], "entities": []}, {"text": "Therefore, we presuppose a given (statistical) word alignment underlying in the synchronous parsing task; this leads to a significant reduction of the parsing complexity.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.7605636417865753}]}, {"text": "The theoretical complexity results are corroborated by a quantitative evaluation in which we ran an implementation of the algorithm on a suite of test sentences from the Europarl parallel corpus.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 170, "end_pos": 194, "type": "DATASET", "confidence": 0.9498527646064758}]}], "introductionContent": [{"text": "The technical results presented in this paper 1 are motivated by the following considerations: It is conceivable to use sentence pairs from a parallel corpus (along with the tentative word correspondences from a statistical word alignment) as training data fora grammar induction approach.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 262, "end_pos": 279, "type": "TASK", "confidence": 0.6889759302139282}]}, {"text": "The goal is to induce monolingual grammars for the languages under consideration; but the implicit information about syntactic structure gathered from typical patterns in the alignment goes beyond what can be obtained from unlabeled monolingual data.", "labels": [], "entities": []}, {"text": "Consider for instance the sentence pair from the Europarl corpus) in (shown with a hand-labeled word alignment): distributional patterns over this and similar sentences may show that in English, the subject (the word block \"the situation\") is in a fixed structural position, whereas in German, it can appear in various positions; similarly, the finite verb in German (here: stellt) systematically appears in second position in main clauses.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.9818530678749084}]}, {"text": "Ina way, the translation of sentences into other natural languages serves as an approximation of a (much more costly) manual structural or semantic annotation -one might speak of automatic indirect supervision in learning.", "labels": [], "entities": []}, {"text": "The technique will be most useful for low-resource languages and languages for which there is no funding for treebanking activities.", "labels": [], "entities": []}, {"text": "The only requirement will be that a parallel corpus exist for the language under consideration and one or more other languages.", "labels": [], "entities": []}, {"text": "Induction of grammars from parallel corpora is rarely viewed as a promising task in its own right; in work that has addressed the issue directly), the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in a noisy channel approach to statistical MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 297, "end_pos": 299, "type": "TASK", "confidence": 0.7352768778800964}]}, {"text": "In the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given a word alignment.", "labels": [], "entities": [{"text": "parallel corpus-based grammar induction", "start_pos": 63, "end_pos": 102, "type": "TASK", "confidence": 0.7062029466032982}, {"text": "synchronous parsing of sentence pairs", "start_pos": 136, "end_pos": 173, "type": "TASK", "confidence": 0.7397914052009582}]}, {"text": "This work represents a second pilot study (after) for the longer-term PTOLEMAIOS project at Saarland University with the goal of learning linguistic grammars from parallel corpora (compare ().", "labels": [], "entities": []}, {"text": "The grammars should be robust and assign a In the present paper we use examples from English/German for illustration, but the approach is of course independent of the language pair under consideration.", "labels": [], "entities": []}, {"text": "3 Of course, there is related work (e.g.,)) using aligned parallel corpora in order to \"project\" bracketings or dependency structures from English to another language and exploit them for training a parser for the other language.", "labels": [], "entities": []}, {"text": "But note the conceptual difference: the \"parse projection\" approach departs from a given monolingual parser, with a particular style of analysis, whereas our project will explore to what extent it may help to design the grammar topology specifically for the parallel corpus case.", "labels": [], "entities": []}, {"text": "This means that the emerging English parser maybe different from all existing ones.", "labels": [], "entities": []}, {"text": "The situation now however is radically different: Word-aligned German/English sentence pair from the Europarl corpus predicate-argument-modifier (or dependency) structure to sentences, such that they can be applied in the context of multilingual information extraction or question answering.", "labels": [], "entities": [{"text": "Europarl corpus predicate-argument-modifier", "start_pos": 101, "end_pos": 144, "type": "DATASET", "confidence": 0.9618533452351888}, {"text": "multilingual information extraction", "start_pos": 233, "end_pos": 268, "type": "TASK", "confidence": 0.6472321649392446}, {"text": "question answering", "start_pos": 272, "end_pos": 290, "type": "TASK", "confidence": 0.7521806061267853}]}], "datasetContent": [{"text": "In order to validate the theoretical complexity results empirically, we implemented the algorithm and ran it on sentence pairs from the Europarl parallel corpus.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 136, "end_pos": 160, "type": "DATASET", "confidence": 0.942575732866923}]}, {"text": "At the present stage, we are interested in quantitative results on parsing time, rather than qualitative results of parsing accuracy (for which a more extensive training of the rule parameters would be required).", "labels": [], "entities": [{"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9827092885971069}, {"text": "parsing", "start_pos": 116, "end_pos": 123, "type": "TASK", "confidence": 0.970533013343811}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.8827557563781738}]}, {"text": "We did a prototype implementation of the correspondence-guided parsing algorithm in SWI Prolog.", "labels": [], "entities": [{"text": "correspondence-guided parsing", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.5058652758598328}, {"text": "SWI Prolog", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.8967113792896271}]}, {"text": "Chart items are asserted to the knowledge base and efficiently retrieved using indexing by a hash function.", "labels": [], "entities": []}, {"text": "Besides chart construction, the Viterbi algorithm for selecting the most probable analysis has been implemented, but for the current quantitative results only chart construction was relevant.", "labels": [], "entities": [{"text": "chart construction", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.852816104888916}, {"text": "chart construction", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.709238737821579}]}, {"text": "The initial probablistic grammar for our experiments was extracted from a small \"multitree bank\" of 140 German/English sentence pairs (short examples from the Europarl corpus).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 159, "end_pos": 174, "type": "DATASET", "confidence": 0.9890428483486176}]}, {"text": "The multitree bank was annotated using the MMAX2 tool and a specially http://www.swi-prolog.org -The advantage of using Prolog is that it is very easy to experiment with various conditions on the inference rules in parsing.", "labels": [], "entities": [{"text": "MMAX2", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.944675087928772}]}, {"text": "16 http://mmax.eml-research.de tailored annotation scheme for flat correspondence structures as described in sec.", "labels": [], "entities": []}, {"text": "2. A German and English part-of-speech tagger was used to determine word categories; they were mapped to a reduced category set and projected to the syntactic constituents.", "labels": [], "entities": []}, {"text": "To obtain parameters fora probabilistic grammar, we used maximum likelihood estimation from the small corpus, based on a rather simplistic generative model, 17 which for each local subtree decides (i) what categories will be the two heads, (ii) how many daughters there will be, and for each nonhead sister (iii) whether it will be a nonterminal or a terminal (and in that case, what category pair), and (iv) in which position relative to the head to place it in both languages.", "labels": [], "entities": []}, {"text": "In order to obtain a realistically-sized grammar, we applied smoothing to all parameters; so effectively, every sequence of terminals/nonterminals of arbitrary length was possible in parsing.", "labels": [], "entities": []}, {"text": "To validate empirically that the proposed correspondence-guided synchronous parsing approach (CGSP) can effectively exploit L 2 as a guide, thereby reducing the search space of L 1 parses that have to be considered, we first ran a comparison on sentences without L 1 -NILs.", "labels": [], "entities": [{"text": "correspondence-guided synchronous parsing", "start_pos": 42, "end_pos": 83, "type": "TASK", "confidence": 0.6320843001206716}]}, {"text": "The results (average parsing time for Viterbi parsing with the sample grammar) are shown in.", "labels": [], "entities": [{"text": "Viterbi parsing", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.5924044847488403}]}, {"text": "The parser we call \"monolingual\" cannot exploit any For our learning experiments we intend to use a Maximum Entropy/log-linear model with more features.", "labels": [], "entities": []}, {"text": "The experiments were run on a 1.4GHz Pentium M processor.", "labels": [], "entities": []}, {"text": "alignment-induced restrictions from L 2 . Note that CGSP takes clearly less time.", "labels": [], "entities": []}, {"text": "Here too, the theoretical results are corroborated that with a limited number of L 1 -NILs, the CGSP is still efficient.", "labels": [], "entities": []}, {"text": "The average chart size (in terms of the number of entries) for sentences of length 8 (in L 1 ) was 212 for CGSP (and 80 for \"monolingual\" parsing).", "labels": [], "entities": [{"text": "CGSP", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.9002265334129333}]}, {"text": "The following comparison shows the effect of L 1 -NILs (note that the values for 4 and more L 1 -NILs are based on only one or two cases): We also simulated asynchronous parser which does not take advantage of a given word alignment (by providing an alignment link between any pair of words, plus the option that any word could be a NULL word).", "labels": [], "entities": []}, {"text": "For sentences of length 5, this parser took an average time of 22.3 seconds (largely independent of the presence/absence of L 1 -NILs).", "labels": [], "entities": []}, {"text": "Finally, we also ran an experiment in which the continuity condition (condition (iii) in rule (4)) was deactivated, i.e., complete constituents were allowed to be discontinuous in one of the languages.", "labels": [], "entities": [{"text": "continuity", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9693214893341064}]}, {"text": "The results in (7) underscore the importance of this condition -leaving it out leads to a tremendous increase in parsing time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 113, "end_pos": 120, "type": "TASK", "confidence": 0.9806305766105652}]}], "tableCaptions": []}