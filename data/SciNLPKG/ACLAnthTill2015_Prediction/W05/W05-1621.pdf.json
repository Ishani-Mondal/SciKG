{"title": [{"text": "Using a Corpus of Sentence Orderings Defined by Many Experts to Evaluate Metrics of Coherence for Text Structuring", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper addresses two previously unresolved issues in the automatic evaluation of Text Structuring (TS) in Natural Language Generation (NLG).", "labels": [], "entities": [{"text": "evaluation of Text Structuring (TS) in Natural Language Generation (NLG)", "start_pos": 71, "end_pos": 143, "type": "TASK", "confidence": 0.721972467643874}]}, {"text": "First, we describe how to verify the generality of an existing collection of sentence orderings defined by one domain expert using data provided by additional experts.", "labels": [], "entities": []}, {"text": "Second, a general evaluation methodology is outlined which investigates the previously unaddressed possibility that there may exist many optimal solutions for TS in the employed domain.", "labels": [], "entities": [{"text": "TS", "start_pos": 159, "end_pos": 161, "type": "TASK", "confidence": 0.9838565587997437}]}, {"text": "This methodology is implemented in a set of experiments which identify the most promising candidate for TS among several metrics of coherence previously suggested in the literature.", "labels": [], "entities": [{"text": "TS", "start_pos": 104, "end_pos": 106, "type": "TASK", "confidence": 0.9517827033996582}]}], "introductionContent": [{"text": "Research in NLG focused on problems related to TS from very early on, being a classic example.", "labels": [], "entities": [{"text": "TS", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9846232533454895}]}, {"text": "Nowadays, TS continues to bean extremely fruitful field of diverse active research.", "labels": [], "entities": [{"text": "TS", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8282586932182312}]}, {"text": "In this paper, we assume the socalled search-based approach to TS which employs a metric of coherence to select a text structure among various alternatives.", "labels": [], "entities": [{"text": "TS", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9842472076416016}]}, {"text": "The TS module is hypothesised to simply order a preselected set of information-bearing items such as sentences or database facts.", "labels": [], "entities": []}, {"text": "Empirical work on the evaluation of TS has become increasingly automatic and corpus-based.", "labels": [], "entities": [{"text": "evaluation of TS", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7071196436882019}]}, {"text": "As pointed out by inter alia, using corpora for automatic evaluation is motivated by the fact that employing human informants in extended psycholinguistic experiments is often simply unfeasible.", "labels": [], "entities": []}, {"text": "By contrast, largescale automatic corpus-based experimentation takes place much more easily.", "labels": [], "entities": []}, {"text": "[ was the first to present an experimental setting which employs the distance between two orderings to estimate automatically how close a sentence ordering produced by her probabilistic TS model stands in comparison to orderings provided by several human judges.", "labels": [], "entities": []}, {"text": "[] derived sets of facts from the database of MPIRO, an NLG system that generates short descriptions of museum artefacts.", "labels": [], "entities": [{"text": "MPIRO", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.9157639145851135}]}, {"text": "Each set consists of 6 facts each of which corresponds to a sentence as shown in.", "labels": [], "entities": []}, {"text": "The facts in each set were manually assigned an order to reflect what a domain expert, i.e. an archaeologist trained in museum labelling, considered to be the most natural ordering of the corresponding sentences.", "labels": [], "entities": []}, {"text": "Patterns of ordering facts were automatically learned from the corpus created by the expert.", "labels": [], "entities": []}, {"text": "Then, a classification-based TS approach was implemented and evaluated in comparison to the expert's orderings.", "labels": [], "entities": [{"text": "classification-based TS", "start_pos": 8, "end_pos": 31, "type": "TASK", "confidence": 0.6321072280406952}]}, {"text": "A subset of the corpus created by the expert in the previous study (to whom we will henceforth refer as E0) is employed by] who attempt to distinguish between many metrics of coherence with respect to their usefulness for TS in the same domain.", "labels": [], "entities": [{"text": "TS", "start_pos": 222, "end_pos": 224, "type": "TASK", "confidence": 0.9723685383796692}]}, {"text": "Each human ordering of facts in the corpus is scored by each of these metrics which are then penalised proportionally to the amount of alternative orderings of the same material that are found to score equally to or better than the human ordering.", "labels": [], "entities": []}, {"text": "The few metrics which manage to outperform two simple baselines in their overall performance across the corpus emerge as the most suitable candidates for TS in the investigated domain.", "labels": [], "entities": [{"text": "TS", "start_pos": 154, "end_pos": 156, "type": "TASK", "confidence": 0.9889953136444092}]}, {"text": "This methodology is very similar to the way [Barzilay and evaluate their probabilistic TS model in comparison to the approach of.", "labels": [], "entities": [{"text": "TS", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.7133758068084717}]}, {"text": "Because the data used in the studies of and are based on the insights of just one expert, an obvious unresolved question is whether they reflect general strategies for ordering facts in the domain of interest.", "labels": [], "entities": []}, {"text": "This paper addresses this issue by enhancing the dataset used in the two studies with orderings provided by three additional experts.", "labels": [], "entities": []}, {"text": "These orderings are then compared with the orders of E0 using the methodology of.", "labels": [], "entities": []}, {"text": "Since E0 is found to share a lot of common ground with two of her colleagues in the ordering task, her reliability is verified, while a fourth \"stand-alone\" expert who uses strategies not shared by any other expert is identified as well.", "labels": [], "entities": [{"text": "reliability", "start_pos": 103, "end_pos": 114, "type": "METRIC", "confidence": 0.9936859011650085}]}, {"text": "As in, the same dependent variable which allows us to estimate how different the orders of E0 are from the orders of her colleagues is used to evaluate some of the metrics which perform best in.", "labels": [], "entities": []}, {"text": "As explained in the next section, in this way we investigate the previously unaddressed possibility that there may exist many optimal solutions for TS in our domain.", "labels": [], "entities": [{"text": "TS", "start_pos": 148, "end_pos": 150, "type": "TASK", "confidence": 0.9580619931221008}]}, {"text": "The results of this additional evaluation experiment are presented and emphasis is laid on their relation with the previous findings.", "labels": [], "entities": []}, {"text": "Overall, this paper addresses two general issues: a) how to verify the generality of a dataset defined by one expert using sentence orderings provided by other experts and b) how to employ these data for the automatic evaluation of a TS approach.", "labels": [], "entities": [{"text": "TS", "start_pos": 234, "end_pos": 236, "type": "TASK", "confidence": 0.9554752111434937}]}, {"text": "Given that the methodology discussed in this paper does not rely on the employed metrics of coherence or the assumed TS approach, our work can be of interest to any NLG researcher facing these questions.", "labels": [], "entities": []}, {"text": "The next section discusses how the methodology implemented in this study complements the methods of.", "labels": [], "entities": []}, {"text": "After briefly introducing the employed metrics of coherence, we describe the data collected for our experiments.", "labels": [], "entities": []}, {"text": "Then, we present the employed dependent variable and formulate our predictions.", "labels": [], "entities": []}, {"text": "In the results section, we state which of these predictions were verified.", "labels": [], "entities": []}, {"text": "The paper is concluded with a discussion of the main findings.", "labels": [], "entities": []}], "datasetContent": [{"text": "As report, different humans often order sentences in distinct ways.", "labels": [], "entities": []}, {"text": "Thus, there might exist more than one equally good solution for TS, a view shared by almost all TS researchers, but which has not been accounted for in the evaluation methodologies of and.", "labels": [], "entities": [{"text": "TS", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9757179021835327}]}, {"text": "Collecting sentence orderings defined by many experts in our domain enables us to investigate the possibility that there might exist many good solutions for TS.", "labels": [], "entities": [{"text": "Collecting sentence orderings", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6264265875021616}, {"text": "TS", "start_pos": 157, "end_pos": 159, "type": "TASK", "confidence": 0.9876742959022522}]}, {"text": "Then, the measure of, which estimates how close two orderings stand, can be employed not only to verify the reliability of E0 but also to compare the orderings preferred by the assumed TS approach with the orderings of the experts.", "labels": [], "entities": [{"text": "reliability", "start_pos": 108, "end_pos": 119, "type": "METRIC", "confidence": 0.9939320087432861}]}, {"text": "However, this evaluation methodology has its limitations as well.", "labels": [], "entities": []}, {"text": "Being engaged in other obligations, the experts normally have just a limited amount of time to devote to the NLG researcher.", "labels": [], "entities": [{"text": "NLG researcher", "start_pos": 109, "end_pos": 123, "type": "DATASET", "confidence": 0.8576709032058716}]}, {"text": "Similarly to standard psycholinguistic experiments, consulting these informants is difficult to extend to a larger corpus like the one used e.g. by (122 sets of facts).", "labels": [], "entities": []}, {"text": "In this paper, we reach a reasonable compromise by showing how the methodology of supplements the evaluation efforts of] using a similar (yet by necessity smaller) dataset.", "labels": [], "entities": []}, {"text": "Clearly, a metric of coherence that has already done well in the previous study, gains extra bonus by passing this additional test.", "labels": [], "entities": []}, {"text": "3 Metrics of coherence discusses how a few basic notions of coherence captured by Centering Theory (CT) can be used to define a large range of metrics which might be useful for TS in our domain of interest.", "labels": [], "entities": [{"text": "TS", "start_pos": 177, "end_pos": 179, "type": "TASK", "confidence": 0.98319411277771}]}, {"text": "The metrics employed in the experiments of] include: M.NOCB which penalises NOCBs, i.e. pairs of adjacent facts without any arguments in common.", "labels": [], "entities": [{"text": "M.NOCB", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.8533024191856384}]}, {"text": "Because of its simplicity M.NOCB serves as the first baseline in the experiments of.", "labels": [], "entities": [{"text": "M.NOCB", "start_pos": 26, "end_pos": 32, "type": "TASK", "confidence": 0.564361035823822}]}, {"text": "PF.NOCB, a second baseline, which enhances M.NOCB with a global constraint on coherence that calls the PageFocus (PF).", "labels": [], "entities": []}, {"text": "PF.BFP which is based on PF as well as the original formulation of CT in.", "labels": [], "entities": [{"text": "PF.BFP", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8788498640060425}, {"text": "PF", "start_pos": 25, "end_pos": 27, "type": "DATASET", "confidence": 0.8414950370788574}]}, {"text": "PF.KP which makes use of PF as well as the recent reformulation of CT in.", "labels": [], "entities": [{"text": "PF.KP", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8928306102752686}]}, {"text": "[ report that PF.NOCB outperformed M.NOCB but was overtaken by PF.BFP and PF.KP.", "labels": [], "entities": [{"text": "M.NOCB", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.7182295918464661}, {"text": "PF.BFP", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.8985057473182678}, {"text": "PF.KP", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.8768132328987122}]}, {"text": "The two metrics beating PF.NOCB were not found to differ significantly from each other.", "labels": [], "entities": [{"text": "PF.NOCB", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.6424242258071899}]}, {"text": "This study employs PF.BFP and PF.KP, i.e. two of the best performing metrics of the experiments in, as well as M.NOCB and PF.NOCB, the two previously used baselines.", "labels": [], "entities": []}, {"text": "An additional random baseline is also defined following].", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of distances between the expert pairs", "labels": [], "entities": []}, {"text": " Table 2: Comparison of distances between the experts (E0,  E1, E2, E3) and the random baseline (RB)", "labels": [], "entities": [{"text": "random baseline (RB)", "start_pos": 80, "end_pos": 100, "type": "METRIC", "confidence": 0.7566957831382751}]}, {"text": " Table 3: Results of the concluding analysis comparing the distance between the expert pairs (EXP EXP ) with the distance  between the experts and each metric (PF.BFP, PF.NOCB, PF.KP, M.NOCB) and the random baseline (RB)", "labels": [], "entities": [{"text": "random baseline (RB)", "start_pos": 200, "end_pos": 220, "type": "METRIC", "confidence": 0.8421159982681274}]}]}