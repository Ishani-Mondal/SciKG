{"title": [{"text": "Generating an Entailment Corpus from News Headlines", "labels": [], "entities": [{"text": "Generating an Entailment Corpus from News Headlines", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.6455143945557731}]}], "abstractContent": [{"text": "We describe our efforts to generate a large (100,000 instance) corpus of textual entailment pairs from the lead paragraph and headline of news articles.", "labels": [], "entities": []}, {"text": "We manually inspected a small set of news stories in order to locate the most productive source of entailments, then built an annotation interface for rapid manual evaluation of further exemplars.", "labels": [], "entities": []}, {"text": "With this training data we built an SVM-based document classifier, which we used for corpus refinement purposes-we believe that roughly three-quarters of the resulting corpus are genuine entailment pairs.", "labels": [], "entities": [{"text": "corpus refinement", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.727449581027031}]}, {"text": "We also discuss the difficulties inherent in manual entailment judgment, and suggest ways to ameliorate some of these.", "labels": [], "entities": [{"text": "manual entailment judgment", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6811868151028951}]}], "introductionContent": [{"text": "MITRE has a long-standing interest in robust text understanding, and, like many, we believe that adequate progress in such an endeavor requires a well-designed evaluation methodology.", "labels": [], "entities": [{"text": "MITRE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9562128782272339}, {"text": "text understanding", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7144563794136047}]}, {"text": "We have explored in great depth the use of human reading comprehension exams for this purpose) as well as TRECstyle question answering.", "labels": [], "entities": [{"text": "TRECstyle question answering", "start_pos": 106, "end_pos": 134, "type": "TASK", "confidence": 0.8010643124580383}]}, {"text": "In this context, the recent Pascal RTE evaluation (Recognizing Textual Entailment,) captured our interest.", "labels": [], "entities": []}, {"text": "The goal of RTE is to assess systems' abilities at judging semantic entailment with respect to a pair of sentences, e.g.: \u2022 Fred spilled wine on the carpet.", "labels": [], "entities": [{"text": "RTE", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9509910941123962}]}, {"text": "\u2022 The rug was wet.", "labels": [], "entities": []}, {"text": "In RTE parlance, the antecedent sentence is known as the text, while the consequent sentence is known as the hypothesis.", "labels": [], "entities": [{"text": "RTE parlance", "start_pos": 3, "end_pos": 15, "type": "TASK", "confidence": 0.7739263772964478}]}, {"text": "Simply put, the challenge for an RTE system is to judge whether the text entails the hypothesis.", "labels": [], "entities": [{"text": "RTE", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9484192728996277}]}, {"text": "Judgments are Boolean, and the primary evaluation metric is simple accuracy, although there were other, secondary metrics used in the evaluation.", "labels": [], "entities": [{"text": "Judgments", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9234793782234192}, {"text": "Boolean", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9332809448242188}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.903246283531189}]}, {"text": "The RTE organizers provided 567 exemplar sentence pairs.", "labels": [], "entities": [{"text": "RTE organizers", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.949135422706604}]}, {"text": "This is adequate for system development, but not for the application of large-scale statistical models.", "labels": [], "entities": [{"text": "system development", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7959445416927338}]}, {"text": "In particular, we wished to cast the problem as one of statistical alignment as used in machine translation.", "labels": [], "entities": [{"text": "statistical alignment", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7767053246498108}, {"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7327495515346527}]}, {"text": "MT systems typically use millions of sentence pairs, and so we decided to find or generate a much larger corpus.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9586682319641113}]}, {"text": "This paper describes our efforts along these lines, as well as some observations about the problems of annotating entailment data.", "labels": [], "entities": []}, {"text": "In Section 2 we describe our initial search for an entailment corpus.", "labels": [], "entities": []}, {"text": "Section 3 briefly describes an annotation interface we devised, as well as our efforts to refine our corpus.", "labels": [], "entities": []}, {"text": "Section 4 explains many of the issues and problems inherent in manual annotation of entailment data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}