{"title": [{"text": "Examining the Effect of Improved Context Sensitive Morphology on Arabic Information Retrieval", "labels": [], "entities": [{"text": "Arabic Information Retrieval", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6196684837341309}]}], "abstractContent": [{"text": "This paper explores the effect of improved morphological analysis, particularly context sensitive morphology, on monolingual Arabic Information Retrieval (IR).", "labels": [], "entities": [{"text": "monolingual Arabic Information Retrieval (IR)", "start_pos": 113, "end_pos": 158, "type": "TASK", "confidence": 0.7293667112077985}]}, {"text": "It also compares the effect of context sensitive morphology to non-context sensitive morphology.", "labels": [], "entities": []}, {"text": "The results show that better coverage and improved correctness have a dramatic effect on IR effectiveness and that context sensitive morphology further improves retrieval effectiveness, but the improvement is not statistically significant.", "labels": [], "entities": [{"text": "coverage", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9818241000175476}, {"text": "IR", "start_pos": 89, "end_pos": 91, "type": "TASK", "confidence": 0.9934110045433044}]}, {"text": "Furthermore, the improvement obtained by the use of context sensitive morphology over the use of light stemming was not significantly significant.", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to the morphological complexity of the Arabic language, much research has focused on the effect of morphology on Arabic Information Retrieval (IR).", "labels": [], "entities": [{"text": "Arabic Information Retrieval (IR)", "start_pos": 117, "end_pos": 150, "type": "TASK", "confidence": 0.7783942917982737}]}, {"text": "The goal of morphology in IR is to conflate words of similar or related meanings.", "labels": [], "entities": [{"text": "IR", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.965808629989624}]}, {"text": "Several early studies suggested that indexing Arabic text using roots significantly increases retrieval effectiveness over the use of words or stems.", "labels": [], "entities": [{"text": "indexing Arabic text", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.8732897639274597}]}, {"text": "However, all the studies used small test collections of only hundreds of documents and the morphology in many of the studies was done manually.", "labels": [], "entities": []}, {"text": "Performing morphological analysis for Arabic IR using existing Arabic morphological analyzers, most of which use finite state transducers, is problematic for two reasons.", "labels": [], "entities": [{"text": "IR", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.6605712175369263}]}, {"text": "First, they were designed to produce as many analyses as possible without indicating which analysis is most likely.", "labels": [], "entities": []}, {"text": "This property of the analyzers complicates retrieval, because it introduces ambiguity in the indexing phase as well as the search phase of retrieval.", "labels": [], "entities": []}, {"text": "Second, the use of finite state transducers inherently limits coverage, which the number of words that the analyzer can analyze, to the cases programmed into the transducers.", "labels": [], "entities": [{"text": "coverage", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.956670343875885}]}, {"text": "Darwish attempted to solve this problem by developing a statistical morphological analyzer for Arabic called Sebawai that attempts to rank possible analyses to pick the most likely one.", "labels": [], "entities": []}, {"text": "He concluded that even with ranked analysis, morphological analysis did not yield statistically significant improvement over words in IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.9416415095329285}]}, {"text": "A later study by Aljlayl et al. on a large Arabic collection of 383,872 documents suggested that lightly stemmed words, where only common prefixes and suffixes are stripped from them, were perhaps better index term for Arabic.", "labels": [], "entities": [{"text": "Arabic collection of 383,872 documents", "start_pos": 43, "end_pos": 81, "type": "DATASET", "confidence": 0.7723031997680664}]}, {"text": "Similar studies by Darwish and Larkey also suggested that light stemming is indeed superior to morphological analysis in the context of IR.", "labels": [], "entities": [{"text": "light stemming", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7226530611515045}, {"text": "IR", "start_pos": 136, "end_pos": 138, "type": "TASK", "confidence": 0.983585000038147}]}, {"text": "However, the shortcomings of morphology might be attributed to issues of coverage and correctness.", "labels": [], "entities": [{"text": "coverage", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9533857107162476}]}, {"text": "Concerning coverage, analyzers typically fail to analyze Arabized or transliterated words, which may have prefixes and suffixes attached to them and are typically valuable in IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 175, "end_pos": 177, "type": "TASK", "confidence": 0.9924152493476868}]}, {"text": "As for correctness, the presence (or absence) of a prefix or suffix may significantly alter the analysis of a word.", "labels": [], "entities": []}, {"text": "For example, for the word \"Alksyr\" is unambiguously analyzed to the root \"ksr\" and stem \"ksyr.\"", "labels": [], "entities": []}, {"text": "However, removing the prefix \"Al\" introduces an additional analysis, namely to the root \"syr\" and the stem \"syr.\"", "labels": [], "entities": []}, {"text": "Perhaps such ambiguity can be reduced by using the context in which the word is mentioned.", "labels": [], "entities": []}, {"text": "For example, for the word \"ksyr\" in the sentence \"sAr ksyr\" (and he walked like), the letter \"k\" is likely to be a prefix.", "labels": [], "entities": []}, {"text": "The problem of coverage is practically eliminated by light stemming.", "labels": [], "entities": [{"text": "coverage", "start_pos": 15, "end_pos": 23, "type": "TASK", "confidence": 0.6804119944572449}, {"text": "light stemming", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7395507246255875}]}, {"text": "However, light stemming yields greater consistency without regard to correctness.", "labels": [], "entities": [{"text": "consistency", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.983922004699707}]}, {"text": "Although consistency is more important for IR applications than linguistic correctness, perhaps improved correctness would naturally yield great consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.978287398815155}, {"text": "IR", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9874125719070435}]}, {"text": "Lee et al. adopted a trigram language model (LM) trained on a portion of the manually segmented LDC Arabic Treebank in developing an Arabic morphology system, which attempts to improve the coverage and linguistic correctness over existing statistical analyzers such as Sebawai.", "labels": [], "entities": [{"text": "LDC Arabic Treebank", "start_pos": 96, "end_pos": 115, "type": "DATASET", "confidence": 0.7036930521329244}]}, {"text": "The analyzer of Lee et al. will be henceforth referred to as the IBM-LM analyzer.", "labels": [], "entities": [{"text": "IBM-LM analyzer", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.8027963042259216}]}, {"text": "IBM-LM's analyzer combined the trigram LM (to analyze a word within its context in the sentence) with a prefix-suffix filter (to eliminate illegal prefix suffix combinations, hence improving correctness) and unsupervised stem acquisition (to improve coverage).", "labels": [], "entities": [{"text": "IBM-LM", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8828715682029724}, {"text": "stem acquisition", "start_pos": 221, "end_pos": 237, "type": "TASK", "confidence": 0.694799542427063}]}, {"text": "Lee et al. report a 2.9% error rate in analysis compared to 7.3% error reported by Darwish for Sebawai.", "labels": [], "entities": [{"text": "error rate", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9795646071434021}]}, {"text": "This paper evaluates the IBM-LM analyzer in the context of a monolingual Arabic IR application to determine if in-context morphology leads to improved retrieval effectiveness compared to outof-context analysis.", "labels": [], "entities": []}, {"text": "To determine the effect of improved analysis, particularly the use of incontext morphology, the analyzer is used to produce analyses of words in isolation (with no context) and in-context.", "labels": [], "entities": []}, {"text": "Since IBM-LM only produces stems, Sebawai was used to produce the roots corresponding to the stems produced by IBM-LM.", "labels": [], "entities": []}, {"text": "Both are compared to Sebawai and light stemming.", "labels": [], "entities": [{"text": "light stemming", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7503779232501984}]}, {"text": "The paper will be organized as follows: Section 2 surveys related work; Section 3 describes the IR experimental setup for testing the IBM-LM analyzer; Section 4 presents experimental results; and Section 5 concludes the paper.", "labels": [], "entities": [{"text": "IR", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.8032185435295105}]}], "datasetContent": [{"text": "IR experiments were done on the LDC LDC2001T55 collection, which was used in the Text REtrieval Conference (TREC) 2002 crosslanguage track.", "labels": [], "entities": [{"text": "LDC LDC2001T55 collection", "start_pos": 32, "end_pos": 57, "type": "DATASET", "confidence": 0.9249578515688578}, {"text": "Text REtrieval Conference (TREC) 2002 crosslanguage track", "start_pos": 81, "end_pos": 138, "type": "DATASET", "confidence": 0.6064882212214999}]}, {"text": "For brevity, the collection is referred to as the TREC collection.", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.8846771419048309}]}, {"text": "The collection contains 383,872 articles from the Agence France Press (AFP) Arabic newswire.", "labels": [], "entities": [{"text": "Agence France Press (AFP) Arabic newswire", "start_pos": 50, "end_pos": 91, "type": "DATASET", "confidence": 0.8487944565713406}]}, {"text": "Fifty topics were developed cooperatively by the LDC and the National Institute of Standards and Technology (NIST), and relevance judgments were developed at the LDC by manually judging a pool of documents obtained from combining the top 100 documents from all the runs submitted by the participating teams to TREC's cross-language track in 2002.", "labels": [], "entities": [{"text": "TREC's cross-language track in 2002", "start_pos": 310, "end_pos": 345, "type": "DATASET", "confidence": 0.6439360479513804}]}, {"text": "The number of known relevant documents ranges from 10 to 523, with an average of 118 relevant documents per topic.", "labels": [], "entities": []}, {"text": "This is presently the best available large Arabic information retrieval test collection.", "labels": [], "entities": [{"text": "Arabic information retrieval test collection", "start_pos": 43, "end_pos": 87, "type": "DATASET", "confidence": 0.6104854822158814}]}, {"text": "The TREC topic descriptions include a title field that briefly names the topic, a description field that usually consists of a single sentence description, and a narrative field that is intended to contain any information that would be needed by a human judge to accurately assess the relevance of a document.", "labels": [], "entities": [{"text": "TREC topic descriptions", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6733142336209615}]}, {"text": "Queries were formed from the TREC topics by combining the title and description fields.", "labels": [], "entities": []}, {"text": "This is intended to model the sort of statement that a searcher might initially make when asking an intermediary, such as a librarian, for help with a search.", "labels": [], "entities": []}, {"text": "Experiments were performed for the queries with the following index terms: \u2022 w: words.", "labels": [], "entities": []}, {"text": "\u2022 ls: lightly stemmed words, obtained using AlStem 1 . \u2022 SEB-s: stems obtained using Sebawai.", "labels": [], "entities": [{"text": "SEB-s", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9790903329849243}]}, {"text": "\u2022 SEB-r: roots obtained using Sebawai.", "labels": [], "entities": [{"text": "SEB-r", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9905105233192444}]}, {"text": "\u2022 cIBM-LMS: stems obtained using the IBM-LM analyzer in context.", "labels": [], "entities": []}, {"text": "Basically, the entire TREC collection was processed by the analyzer and the prefixes and suffixes in the segmented output were removed.", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 22, "end_pos": 37, "type": "DATASET", "confidence": 0.6997597366571426}]}, {"text": "\u2022 cIBM-SEB-r: roots obtained by analyzing the in-context stems produced by IBM-LM using Sebawai.", "labels": [], "entities": []}, {"text": "\u2022 IBM-LMS: stems obtained using the IBM-LM analyzer without any contextual information.", "labels": [], "entities": [{"text": "IBM-LMS", "start_pos": 2, "end_pos": 9, "type": "DATASET", "confidence": 0.8465040326118469}]}, {"text": "Basically, all the unique words in the collection were analyzed one by one and the prefixes and suffixes in the segmented output were removed.", "labels": [], "entities": []}, {"text": "\u2022 IBM-SEB-r: roots obtained by analyzing the out-of-context stems produced by IBM-LM using Sebawai.", "labels": [], "entities": [{"text": "IBM-SEB-r", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.8478977084159851}]}, {"text": "All retrieval experiments were performed using the Lemur language modeling toolkit, which was configured to use Okapi BM-25 term weighting with default parameters and with and without blind relevance feedback (the top 20 terms from the top 5 retrieved documents were used for blind relevance feedback).", "labels": [], "entities": [{"text": "Okapi BM-25 term weighting", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.7005671858787537}]}, {"text": "To observe the effect of alternate indexing terms mean uninterpolated average precision was used as the measure of retrieval effectiveness.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.7295835614204407}]}, {"text": "To determine if the difference between results was statistically significant, a Wilcoxon signed-rank test, which is a nonparametric significance test for correlated samples, was used with p values less than 0.05 to claim significance.", "labels": [], "entities": []}, {"text": "shows a summary of the results for different index terms.", "labels": [], "entities": []}, {"text": "show statistical significance between different index terms using the p value of the Wilcoxon test.", "labels": [], "entities": []}, {"text": "When comparing index terms obtained using IBM-LM and Sebawai, the results clearly show that using better morphological analysis produces better retrieval effectiveness.", "labels": [], "entities": [{"text": "IBM-LM", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.9109123945236206}]}], "tableCaptions": [{"text": " Table 1. Wilcoxon p values (shaded=significant) , with blind relevance feedback.", "labels": [], "entities": []}, {"text": " Table 2. Wilcoxon p values (shaded=significant) , without blind relevanc e feedback", "labels": [], "entities": []}]}