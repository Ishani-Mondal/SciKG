{"title": [{"text": "Real-Time Stochastic Language Generation for Dialogue Systems", "labels": [], "entities": [{"text": "Real-Time Stochastic Language Generation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6147127375006676}]}], "abstractContent": [{"text": "This paper describes Acorn, a sentence planner and surface realizer for dialogue systems.", "labels": [], "entities": []}, {"text": "Improvements to previous stochastic word-forest based approaches are described, countering recent criticism of this class of algorithms for their slow speed.", "labels": [], "entities": []}, {"text": "An evaluation of the approach with semantic input shows runtimes of a fraction of a second and presents results that suggest it is also portable across domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes Acorn, a real-time sentence planner and surface realizer for dialogue systems that is independent of a specific domain.", "labels": [], "entities": []}, {"text": "Acorn is based on a two-phased grammar and stochastic approach, such as the HALogen system], but offers several improvements to make it more realistic for dialogue use.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9151864051818848}]}, {"text": "The first is to offer an algorithm for trickle-down features that passes head/foot features through the grammar as the initial word forest is created, allowing the grammar to broadly represent phenomena such as wh-movement.", "labels": [], "entities": []}, {"text": "The second is to more tightly link the grammar to a lexicon and represent syntactic properties such as number, person, and tense to constrain the over-generation process.", "labels": [], "entities": []}, {"text": "Lastly, efficiency improvements are described which further decrease the runtime of the system, allowing Acorn to be used in a real-time dialogue context.", "labels": [], "entities": []}, {"text": "It is named Acorn, based on the word forests that are created and searched.", "labels": [], "entities": []}, {"text": "The task of Natural Language Generation is frequently split into three somewhat disjoint steps: document planning, microplanning (reference and sentence planning) and surface realization.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.6384500861167908}, {"text": "document planning", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.6705237627029419}, {"text": "surface realization", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.7729248404502869}]}, {"text": "Document planning is a more reduced task in dialogue, mainly involving content determination since there is no need fora document.", "labels": [], "entities": [{"text": "Document planning", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8789695203304291}, {"text": "content determination", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7180351316928864}]}, {"text": "Since the system follows a notion of discourse, content determination is typically performed by some reasoner external to generation, such as a Task Manager.", "labels": [], "entities": [{"text": "content determination", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7241897732019424}]}, {"text": "This paper addresses the sentence planning and surface realization steps, assuming that content determination and referential generation has already occurred and is represented in a high-level semantics.", "labels": [], "entities": [{"text": "sentence planning", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7220813781023026}, {"text": "surface realization", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7738688588142395}, {"text": "content determination", "start_pos": 88, "end_pos": 109, "type": "TASK", "confidence": 0.7069088667631149}, {"text": "referential generation", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.790533035993576}]}, {"text": "This stochastic approach involves two phases; the first uses a grammar to over-generate the possible realizations of an input form into a word forest, and the second uses a language model to choose the preferred path through the forest.", "labels": [], "entities": []}, {"text": "This approach is attractive to dialogue systems because it offers flexibility and adaptivity that cannot be achieved through most symbolic systems.", "labels": [], "entities": []}, {"text": "By over-generating possible utterances, the (sometimes dynamic) language models can decide which is more natural in the current context.", "labels": [], "entities": []}, {"text": "Other advantages include domain independence and an under-specified input.", "labels": [], "entities": []}, {"text": "The main disadvantages most often cited include a very slow runtime and the inability to capture complex linguistic constraints, such as wh-movement.", "labels": [], "entities": []}, {"text": "The latter is aside effect of the word-forest creation algorithm and a solution to broaden the coverage of language is presented in this paper.", "labels": [], "entities": [{"text": "word-forest creation", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.747055321931839}]}, {"text": "The issue of runtime is critical to dialogue.", "labels": [], "entities": []}, {"text": "Slow runtime is a two-fold problem: the word-forest that is generated is extremely large and often not linguistically constrained, and second, the algorithm has not been efficiently implemented.", "labels": [], "entities": []}, {"text": "These issues must be addressed before stochastic approaches can be suited for dialogue.", "labels": [], "entities": []}, {"text": "Langkilde provides an evaluation of coverage of HALogen and shows runtimes around 28 seconds for sentences with average lengths of 22 words.", "labels": [], "entities": [{"text": "Langkilde", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9669457077980042}]}, {"text": "Callaway] later commented on the runtime that HALogen is anywhere from 6.5 to 16 times slower than the symbolic realizer FUF/SURGE (which may also be too slow for dialogue).", "labels": [], "entities": [{"text": "HALogen", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.5810195207595825}, {"text": "FUF", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.8166909217834473}]}, {"text": "This paper shows that more work can be done in stochastic generation to reduce the runtime by constraining the grammar and making simple algorithm improvements.", "labels": [], "entities": []}, {"text": "Runtimes of only a fraction of one second are presented.", "labels": [], "entities": [{"text": "Runtimes", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8785273432731628}]}, {"text": "The next section provides a brief background on stochastic generation, followed by a description of Acorn in section 3.", "labels": [], "entities": [{"text": "stochastic generation", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7982752025127411}, {"text": "Acorn", "start_pos": 100, "end_pos": 105, "type": "DATASET", "confidence": 0.9700981974601746}]}, {"text": "The description presents several new grammar additions to broaden language coverage, including a mechanism, called trickle-down features, for representing head and foot features in the grammar.", "labels": [], "entities": []}, {"text": "Section 4 describes the evaluation of Acorn, as well as the results concerning domain independence and the overall runtime.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.9269933104515076}]}, {"text": "A brief discussion and related work follows the evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "The three factors that are most important in evaluating dialogue generation is portability, coverage, and speed.", "labels": [], "entities": [{"text": "dialogue generation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.842801421880722}, {"text": "coverage", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.7685573697090149}, {"text": "speed", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9629643559455872}]}, {"text": "Other factors include naturalness, flexibility, and many more, but the above three are evaluated in this paper to address concerns of domain independent generation and real-time dialogue.", "labels": [], "entities": [{"text": "domain independent generation", "start_pos": 134, "end_pos": 163, "type": "TASK", "confidence": 0.6694923043251038}]}, {"text": "During one's efforts to address the latter concern by constraining the size of the word forest, it is very easy to lose the former.", "labels": [], "entities": []}, {"text": "Each utterance that was able to be parsed in our target dialogues was automatically transformed into the input syntax of Acorn.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 121, "end_pos": 126, "type": "DATASET", "confidence": 0.9738143086433411}]}, {"text": "These inputs were pushed through Acorn, resulting in a single, top ranked utterance.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9596209526062012}]}, {"text": "This utterance was compared to the target utterance using the Generation String Accuracy metric.", "labels": [], "entities": []}, {"text": "This metric compares a target string to the generated string and counts the number of word movements (M), substitutions (S), deletions (D), and insertions (I) (not counting deletions and insertions implicitly included in movements).", "labels": [], "entities": []}, {"text": "The metric is given below (L is the number of tokens in the target string): Before comparison, all contractions were split into single lexical items to prevent the metric from penalizing semantically similar phrases (e.g. aren't to are not).", "labels": [], "entities": []}, {"text": "The Simple String Accuracy metric was also applied to provide comparison against studies that may not use the Generation Metric; however, the Generation Metric intuitively repairs some of the former's failings, namely double penalization for word movement.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.7065751552581787}, {"text": "word movement", "start_pos": 242, "end_pos": 255, "type": "TASK", "confidence": 0.7695576846599579}]}, {"text": "More on these and other metrics can be found in ].", "labels": [], "entities": []}, {"text": "Acorn was evaluated using the Monroe Corpus, a collection of 20 dialogues.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9229353070259094}, {"text": "Monroe Corpus", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.984055906534195}]}, {"text": "Each dialogue is a conversation between two English speakers who were given a map of Monroe County, NY and a description of a task that needed to be solved.", "labels": [], "entities": []}, {"text": "There were eight different disaster scenarios ranging from a bomb attack to a broken leg, and the participants were to act as emergency dispatchers.", "labels": [], "entities": []}, {"text": "It is a significantly different domain from computer purchasing and was chosen because it offers a corpus that has been parsed by our parser and thus has readily available logical forms for input to Acorn.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 199, "end_pos": 204, "type": "DATASET", "confidence": 0.9823472499847412}]}, {"text": "The length of utterances are shown in.", "labels": [], "entities": []}, {"text": "The four dialogues that had most recently been updated to our logical form definitions were chosen for the evaluation.", "labels": [], "entities": []}, {"text": "The remaining sixteen are used by PathFinder as a bigram language model of the domain's dialogue.", "labels": [], "entities": []}, {"text": "Two series of tests were run.", "labels": [], "entities": []}, {"text": "The first includes the lexical items as input to Acorn and the second only includes the ontology concepts.", "labels": [], "entities": [{"text": "Acorn", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.9612805247306824}]}, {"text": "Generation String Accuracy is used to judge the output of the system against the original utterances in the Monroe dialogues.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.7854472398757935}]}, {"text": "While there have been other generation metrics that have been proposed, such as the Bleu Metric, the Generation String Accuracy metric still provides a measure of system improvement and a comparison against other systems.", "labels": [], "entities": [{"text": "Bleu Metric", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.690927267074585}]}, {"text": "Bleu requires more than one correct output option to be of worthwhile ('quantity leads to quality'), so is not as applicable with only one target utterance.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7460242509841919}]}, {"text": "In order to compare the domain independent evaluation with a domain specific evaluation, the same evaluation described in 4.2 was used on the computer purchasing corpus that includes the logical forms on which Acorn's grammar is based.", "labels": [], "entities": []}, {"text": "As described in 4.1, the domain is an assistant that collaboratively purchases computers online for the user.", "labels": [], "entities": []}, {"text": "There are 132 utterances of length three or more in this corpus.", "labels": [], "entities": []}, {"text": "The n-gram models were automatically generated using a hand formed word grammar of sample sentences.", "labels": [], "entities": []}, {"text": "Both Simple and Generation String Accuracy were used to compare the output of Acorn to the target utterances in the corpus.", "labels": [], "entities": [{"text": "Simple", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9809169173240662}, {"text": "Accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.5964717268943787}, {"text": "Acorn", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.937737762928009}]}], "tableCaptions": []}