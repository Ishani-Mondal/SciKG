{"title": [{"text": "Generalized Inference with Multiple Semantic Role Labeling Systems", "labels": [], "entities": [{"text": "Generalized Inference", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9116379618644714}, {"text": "Multiple Semantic Role Labeling", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6348736733198166}]}], "abstractContent": [{"text": "We present an approach to semantic role labeling (SRL) that takes the output of multiple argument classifiers and combines them into a coherent predicate-argument output by solving an optimization problem.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.7973974744478861}]}, {"text": "The optimization stage, which is solved via integer linear programming , takes into account both the recommendation of the classifiers and a set of problem specific constraints, and is thus used both to clean the classification results and to ensure structural integrity of the final role labeling.", "labels": [], "entities": []}, {"text": "We illustrate a significant improvement in overall SRL performance through this inference.", "labels": [], "entities": [{"text": "SRL", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9784120917320251}]}, {"text": "1 SRL System Architecture Our SRL system consists of four stages: pruning , argument identification, argument classification , and inference.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.73748879134655}, {"text": "argument classification", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.7247167825698853}]}, {"text": "In particular, the goal of pruning and argument identification is to identify argument candidates fora given verb predicate.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7211212068796158}]}, {"text": "The system only classifies the argument candidates into their types during the argument classification stage.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.7166598588228226}]}, {"text": "Linguistic and structural constraints are incorporated in the inference stage to resolve inconsistent global predictions.", "labels": [], "entities": []}, {"text": "The inference stage can take as its input the output of the argument classification of a single system or of multiple systems.", "labels": [], "entities": []}, {"text": "We explain the inference for multiple systems in Sec.", "labels": [], "entities": []}, {"text": "2. 1.1 Pruning Only the constituents in the parse tree are considered as argument candidates.", "labels": [], "entities": []}, {"text": "In addition, our system exploits the heuristic introduced by (Xue and Palmer, 2004) to filter out very unlikely constituents.", "labels": [], "entities": []}, {"text": "The heuristic is a recursive process starting from the verb whose arguments are to be identified.", "labels": [], "entities": []}, {"text": "It first returns the siblings of the verb; then it moves to the parent of the verb, and collects the siblings again.", "labels": [], "entities": []}, {"text": "The process goes on until it reaches the root.", "labels": [], "entities": []}, {"text": "In addition, if a constituent is a PP (propositional phrase), its children are also collected.", "labels": [], "entities": []}, {"text": "Candidates consisting of only a single punctuation mark are not considered.", "labels": [], "entities": []}, {"text": "This heuristic works well with the correct parse trees.", "labels": [], "entities": []}, {"text": "However, one of the errors by automatic parsers is due to incorrect PP attachment leading to missing arguments.", "labels": [], "entities": []}, {"text": "To attempt to fix this, we consider as arguments the combination of any consecutive NP and PP, and the split of NP and PP inside the NP that was chosen by the previous heuristics.", "labels": [], "entities": []}, {"text": "1.2 Argument Identification The argument identification stage utilizes binary classification to identify whether a candidate is an argument or not.", "labels": [], "entities": [{"text": "Argument Identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7485015094280243}, {"text": "argument identification", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.7209324836730957}]}, {"text": "We train and apply the binary clas-sifiers on the constituents supplied by the pruning stage.", "labels": [], "entities": []}, {"text": "Most of the features used in our system are standard features, which include \u2022 Predicate and POS tag of predicate indicate the lemma of the predicate and its POS tag.", "labels": [], "entities": []}, {"text": "\u2022 Voice indicates tbe voice of the predicate.", "labels": [], "entities": []}, {"text": "\u2022 Phrase type of the constituent.", "labels": [], "entities": [{"text": "Phrase", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.8628922700881958}]}, {"text": "\u2022 Head word and POS tag of the headword include headword and its POS tag of the constituent.", "labels": [], "entities": []}, {"text": "We use rules introduced by (Collins, 1999) to extract this feature.", "labels": [], "entities": [{"text": "Collins, 1999)", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9088153839111328}]}, {"text": "\u2022 First and last words and POS tags of the constituent.", "labels": [], "entities": [{"text": "POS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.8410148620605469}]}, {"text": "\u2022 Two POS tags before and after the constituent.", "labels": [], "entities": []}, {"text": "\u2022 Position feature describes if the constituent is before or after the predicate relative to the position in the sentence.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The learning algorithm used is a variation of the Winnow update rule incorporated in SNoW), a multi-class classifier that is tailored for large scale learning tasks.", "labels": [], "entities": []}, {"text": "SNoW learns a sparse network of linear functions, in which the targets (argument border predictions or argument type predictions, in this case) are represented as linear functions over a common feature space.", "labels": [], "entities": []}, {"text": "It improves the basic Winnow multiplicative update rule with a regularization term, which has the effect of trying to separate the data with a large margin separator) and voted (averaged) weight vector).", "labels": [], "entities": [{"text": "Winnow multiplicative update", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.5722240209579468}]}, {"text": "Softmax function is used to convert raw activation to conditional probabilities.", "labels": [], "entities": []}, {"text": "If there are n classes and the raw activation of class i is act i , the posterior estimation for class i is In summary, training used both full and partial syntactic information as described in Section 1.", "labels": [], "entities": []}, {"text": "In training, SNoW's default parameters were used with the exception of the separator thickness 1.5, the use of average weight vector, and 5 training cycles.", "labels": [], "entities": []}, {"text": "The parameters are optimized on the development set.", "labels": [], "entities": []}, {"text": "Training for each system took about 6 hours.", "labels": [], "entities": []}, {"text": "The evaluation on both test sets which included running: The results of individual systems and the result with joint inference on the development set.", "labels": [], "entities": []}, {"text": "Overall results on the development and test sets are shown in. shows the results of individual systems and the improvement gained by the joint inference on the development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overall results (top) and detailed results on  the WSJ test (bottom).", "labels": [], "entities": [{"text": "WSJ test", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.8127253949642181}]}, {"text": " Table 2: The results of individual systems and the  result with joint inference on the development set.", "labels": [], "entities": []}]}