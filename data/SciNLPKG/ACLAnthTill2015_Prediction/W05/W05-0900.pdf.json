{"title": [{"text": "Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization Proceedings of the ACL-05 Workshop Table of Contents A Methodology for Extrinsic Evaluation of Text Summarization: Does ROUGE Correlate? Preprocessing and Normalization for Automatic Evaluation of Machine Translation Syntactic Features for Evaluation of Machine Translation Evaluating Automatic Summaries of Meeting Recordings Evaluating DUC 2004 Tasks with the QARLA Framework On Some Pitfalls in Automatic Evaluation and Significance Testing for MT METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments", "labels": [], "entities": [{"text": "Machine Translation and/or Summarization", "start_pos": 48, "end_pos": 88, "type": "TASK", "confidence": 0.8365123371283213}, {"text": "Extrinsic Evaluation of Text Summarization", "start_pos": 160, "end_pos": 202, "type": "TASK", "confidence": 0.5997228443622589}, {"text": "Machine Translation Evaluating Automatic Summaries of Meeting Recordings Evaluating DUC", "start_pos": 343, "end_pos": 430, "type": "TASK", "confidence": 0.8750001490116119}, {"text": "MT METEOR", "start_pos": 537, "end_pos": 546, "type": "TASK", "confidence": 0.6782047897577286}, {"text": "MT Evaluation", "start_pos": 572, "end_pos": 585, "type": "TASK", "confidence": 0.926659345626831}]}], "abstractContent": [{"text": "Preface This workshop is the first meeting to focus on the challenges that the machine translation (MT) and summarization communities face in developing valid and useful evaluation measures.", "labels": [], "entities": [{"text": "machine translation (MT) and summarization", "start_pos": 79, "end_pos": 121, "type": "TASK", "confidence": 0.7764751442841121}]}, {"text": "Our aim is to bring these two communities together to learn from each other's approaches.", "labels": [], "entities": []}, {"text": "Prior ACL workshops on evaluation have had as their central focus a core computational task (e.g., word sense disambiguation, parsing), a genre (e.g., dialogue, multi-modal interfaces), a computational technique (e.g., unsupervised learning, finite state models), a resource (e.g., parallel texts, WordNet), or a process (e.g., reading comprehension, question-answering).", "labels": [], "entities": [{"text": "word sense disambiguation, parsing)", "start_pos": 99, "end_pos": 134, "type": "TASK", "confidence": 0.703609491388003}]}, {"text": "This workshop, in clear contrast, has as its central focus the examination of evaluation measures, or \"meta-evaluation\" as Dan Melamed has noted.", "labels": [], "entities": []}, {"text": "The initial impetus for this workshop came at the biennial meeting of the Association for Machine Translation in the Americas (AMTA) held at Georgetown University in September 2004, when the following question arose in a discussion session: \"Why isn't recall apart of MT evaluation the way that it is for summarization evaluation?\"", "labels": [], "entities": [{"text": "Machine Translation in the Americas (AMTA) held at Georgetown University in September 2004", "start_pos": 90, "end_pos": 180, "type": "TASK", "confidence": 0.8496755679448446}, {"text": "MT evaluation", "start_pos": 268, "end_pos": 281, "type": "TASK", "confidence": 0.8808730840682983}, {"text": "summarization evaluation", "start_pos": 305, "end_pos": 329, "type": "TASK", "confidence": 0.962046205997467}]}, {"text": "Several of us continued this discussion afterwards and proposed to convene together again more formally to address this question and other evaluation challenges that both the MT and summarization communities have been tackling.", "labels": [], "entities": [{"text": "MT", "start_pos": 175, "end_pos": 177, "type": "TASK", "confidence": 0.9542840123176575}, {"text": "summarization", "start_pos": 182, "end_pos": 195, "type": "TASK", "confidence": 0.6297323107719421}]}, {"text": "We wish to thank Bonnie Dorr and Ed Hovy, in particular, for their encouragement and contributions in shaping the initial workshop proposal and the subsequent call for papers.", "labels": [], "entities": []}, {"text": "Boyan Onyshkevych, Barb Wheatley, Donna Harmon, and Judith Klavans also provided insightful comments in the proposal writing phase of the workshop that helped guide and focus the topics we chose to address.", "labels": [], "entities": []}, {"text": "We also would like also to thank several others.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}