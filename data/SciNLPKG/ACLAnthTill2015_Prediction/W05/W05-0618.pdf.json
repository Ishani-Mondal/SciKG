{"title": [{"text": "Beyond the Pipeline: Discrete Optimization in NLP", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a discrete optimization model based on a linear programming formulation as an alternative to the cascade of classifiers implemented in many language processing systems.", "labels": [], "entities": []}, {"text": "Since NLP tasks are correlated with one another, sequential processing does not guarantee optimal solutions.", "labels": [], "entities": []}, {"text": "We apply our model in an NLG application and show that it performs better than a pipeline-based system.", "labels": [], "entities": []}], "introductionContent": [{"text": "NLP applications involve mappings between complex representations.", "labels": [], "entities": []}, {"text": "In generation a representation of the semantic content is mapped onto the grammatical form of an expression, and in analysis the semantic representation is derived from the linear structure of a text or utterance.", "labels": [], "entities": []}, {"text": "Each such mapping is typically split into a number of different tasks handled by separate modules.", "labels": [], "entities": []}, {"text": "As noted by, individual decisions that these tasks involve can be formulated as classification problems falling in either of two groups: disambiguation or segmentation.", "labels": [], "entities": []}, {"text": "The use of machine-learning to solve such tasks facilitates building complex applications out of many light components.", "labels": [], "entities": []}, {"text": "The architecture of choice for such systems has become a pipeline, with strict ordering of the processing stages.", "labels": [], "entities": []}, {"text": "An example of a generic pipeline architecture is GATE) which provides an infrastructure for building NLP applications.", "labels": [], "entities": [{"text": "GATE", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.7263351082801819}]}, {"text": "Sequential processing has also been used in several NLG systems (e.g.,), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g.,).", "labels": [], "entities": [{"text": "Sequential processing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8712392747402191}, {"text": "part-of-speech tagging", "start_pos": 152, "end_pos": 174, "type": "TASK", "confidence": 0.695623442530632}, {"text": "named entity recognition", "start_pos": 189, "end_pos": 213, "type": "TASK", "confidence": 0.6174389322598776}]}, {"text": "In this paper we address the problem of aggregating the outputs of classifiers solving different NLP tasks.", "labels": [], "entities": []}, {"text": "We compare pipeline-based processing with discrete optimization modeling used in the field of computer vision and image recognition) and recently applied in NLP by , and.", "labels": [], "entities": [{"text": "image recognition", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7109895944595337}]}, {"text": "Whereas Roth and Yih used optimization to solve two tasks only, and focused on a single task, we propose a general formulation capable of combining a large number of different NLP tasks.", "labels": [], "entities": []}, {"text": "We apply the proposed model to solving numerous tasks in the generation process and compare it with two pipeline-based systems.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: in Section 2 we discuss the use of classifiers for handling NLP tasks and point to the limitations of pipeline processing.", "labels": [], "entities": []}, {"text": "In Section 3 we present a general discrete optimization model whose application in NLG is described in Section 4.", "labels": [], "entities": []}, {"text": "Finally, in Section 5 we report on the experiments and evaluation of our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our approach we conducted experiments with two implementations of the ILP model and two different pipelines (presented below).", "labels": [], "entities": []}, {"text": "Each system takes as input a tree structure, representing the temporal structure of the text.", "labels": [], "entities": []}, {"text": "Individual nodes correspond to single discourse units and their semantic content is given by respective feature vectors.", "labels": [], "entities": []}, {"text": "Generation occurs in a number of stages, during which individual discourse units are realized.", "labels": [], "entities": []}, {"text": "We evaluated our system using leave-one-out crossvalidation, i.e. for all texts in the corpus, each text was used once for testing, and the remaining texts provided the training data.", "labels": [], "entities": []}, {"text": "To solve individual classification tasks we used the decision tree learner C4.5 in the pipeline systems and the Naive Bayes algorithm 10 in the ILP systems.", "labels": [], "entities": []}, {"text": "Both learning schemes yielded highest results in the respective configurations 11 . For each task we applied a feature selection procedure (cf.) to determine which semantic features should betaken as the input by the respective basic classifiers 12 . We started with an empty feature set, and then performed experiments checking classification accuracy with only one new feature at a time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 344, "end_pos": 352, "type": "METRIC", "confidence": 0.7806540131568909}]}, {"text": "The feature that scored highest was then added to the feature set and the whole procedure was repeated iteratively until no performance improvement took place, or no more features were left.", "labels": [], "entities": []}, {"text": "To evaluate individual tasks we applied two metrics: accuracy, calculated as the proportion of correct classifications to the total number of instances, and the \u03ba statistic, which corrects for the proportion of classifications that might occur by chance 13 Both implemented in the Weka machine learning software.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9994320273399353}, {"text": "Weka machine learning software", "start_pos": 281, "end_pos": 311, "type": "DATASET", "confidence": 0.8597907572984695}]}, {"text": "We have found that indirect comparison C4.5 reaches higher accuracies than Naive Bayes but the probability distribution that it outputs is strongly biased towards the winning label.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9684137105941772}]}, {"text": "In this case it is practically impossible for the ILP system to change the classifier's decision, as the costs of other labels get extremely high.", "labels": [], "entities": []}, {"text": "Hence the more balanced probability distribution given by Naive Bayes can be easier corrected in the optimization process.", "labels": [], "entities": []}, {"text": "12 I.e. trained using the semantic features only, with no access to the outputs of other tasks.", "labels": [], "entities": []}, {"text": "13 Hence the \u03ba values obtained for tasks of different difficul-  (.", "labels": [], "entities": []}, {"text": "For end-to-end evaluation, we applied the Phi coefficient to measure the degree of similarity between the vector representations of the generated form and the reference form obtained from the test data.", "labels": [], "entities": [{"text": "Phi coefficient", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.9581706523895264}]}, {"text": "The Phi statistic is similar to \u03ba as it compensates for the fact that a match between two multi-label features is more difficult to obtain than in the case of binary features.", "labels": [], "entities": []}, {"text": "This measure tells us how well all the tasks have been solved together, which in our case amounts to generating the whole text.", "labels": [], "entities": []}, {"text": "The results presented in show that the ILP systems achieved highest accuracy and \u03ba for most tasks and reached the highest overall Phi score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9995469450950623}, {"text": "\u03ba", "start_pos": 81, "end_pos": 82, "type": "METRIC", "confidence": 0.9595544338226318}, {"text": "Phi score", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9697173833847046}]}, {"text": "Notice that for the three correlated tasks that we considered before, i.e. Connective, S Exp. and Verb Form, ILP2 scored noticeably higher than the pipeline systems.", "labels": [], "entities": []}, {"text": "It is interesting to seethe effect of sequential processing on the results for another group of correlated tasks, i.e. Verb Lex, Phrase Type and Phrase Rank (cf..", "labels": [], "entities": [{"text": "Verb Lex", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.6753346621990204}]}, {"text": "Verb Lex got higher scores in Pipeline2, with outputs from both Phrase Type and Phrase Rank (see the respective pipeline positions), but the reverse effect did not occur: scores for both phrase tasks were lower in Pipeline1 when they had access to the output from Verb Lex, contrary to what we might expect.", "labels": [], "entities": []}, {"text": "Apparently, this was due to the low accuracy for Verb Lex which caused the already mentioned error propagation . This example shows well the advantage that optimization processing brings: both ILP systems reached much ties can be directly compared, which gives a clear notion how well individual tasks have been solved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9989942908287048}, {"text": "Verb Lex", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8801367282867432}]}, {"text": "14 Apparantly, tasks which involve lexical choice get low scores with retrieval measures as the semantic content allows typically more than one correct form higher scores for all three tasks.", "labels": [], "entities": [{"text": "Apparantly", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.9795927405357361}]}], "tableCaptions": [{"text": " Table 2: Joint distribution matrix for selected labels of tasks", "labels": [], "entities": []}, {"text": " Table 3: Joint distribution matrix for tasks Connective and", "labels": [], "entities": []}, {"text": " Table 4: Results reached by the implemented ILP systems and two baselines. For both pipeline systems, Pos. stands for the", "labels": [], "entities": []}]}