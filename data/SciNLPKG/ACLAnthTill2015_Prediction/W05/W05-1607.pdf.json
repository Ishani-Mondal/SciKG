{"title": [{"text": "A context-dependent algorithm for generating locative expressions in physically situated environments", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a framework for generating locative expressions.", "labels": [], "entities": []}, {"text": "The framework addresses the issue of combinatorial explosion inherent in the construction of relational context models by: (a) contextually defining the set of objects in the context that may function as a landmark, and (b) sequencing the order in which spatial relations are considered using a cognitively motivated hierarchy of relations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our long-term goal is to develop embodied conversational robots that are capable of natural, fluent visually situated dialog with one or more interlocutors.", "labels": [], "entities": []}, {"text": "An inherent aspect of visually situated dialog is reference to objects located in the physical environment.", "labels": [], "entities": []}, {"text": "In this paper, we present a computational framework for the generation of a spatial locative expressions in such contexts.", "labels": [], "entities": []}, {"text": "In the simplest form of locative expression, a prepositional phrase modifies a noun phrase to explicitly specify the location of the object. is an example of the type of locative we focus on generating.", "labels": [], "entities": []}, {"text": "In this example, the book is the subject of the expression and the table is the object.", "labels": [], "entities": []}, {"text": "Following, we use the terms trajector and landmark to respectively denote the subject and the object of a locative expression: the location of the trajector is specified relative to the landmark by the semantics of the preposition.", "labels": [], "entities": []}, {"text": "(1) a. the book [subject] on the table Generating locative expressions is part of the general field of generating referring expressions (GRE).", "labels": [], "entities": []}, {"text": "Most GRE algorithms deal with the same problem: given a domain description and a target object generate a description of the target object that distinguishes it from the other objects in the domain.", "labels": [], "entities": [{"text": "GRE", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9050785303115845}]}, {"text": "The term distractor objects is used to describe the objects in the context excluding the trajector that at a given point in processing fulfil the description of the target object that has been generated.", "labels": [], "entities": []}, {"text": "The description generated is said to be distinguishing when the set of distractor objects is empty.", "labels": [], "entities": []}, {"text": "Several GRE algorithms have addressed the issue of generating locative expressions.", "labels": [], "entities": []}, {"text": "However, all these algorithms assume the GRE component has access to a predefined scene model.", "labels": [], "entities": []}, {"text": "For an embodied conversational robot functioning in dynamic partially known environments this assumption is a serious drawback.", "labels": [], "entities": []}, {"text": "If an agent wishes to generate a contextually appropriate reference it cannot assume the availability of a domain model, rather it must dynamically construct one.", "labels": [], "entities": []}, {"text": "However, constructing a model containing all the relationships between all the entities in the domain is prone to combinatorial explosion, both in terms of the number of objects in the context (the location of each object in the scene must be checked against all the other objects in the scene) and number of interobject spatial relations (as a greater number of spatial relations will require a greater number of comparisons between each pair of objects.", "labels": [], "entities": []}, {"text": "1 Moreover, the context free a priori construction of such an exhaustive scene model is cognitively implausible.", "labels": [], "entities": []}, {"text": "Psychological research indicates that spatial relations are not preattentively perceptually available.", "labels": [], "entities": []}, {"text": "Rather, their perception requires attention . These findings point to subjects constructing contextually dependent reduced relational scene models, rather than an exhaustive context free model.", "labels": [], "entities": []}, {"text": "Contributions In this paper we present a framework for generating locative expressions.", "labels": [], "entities": []}, {"text": "This framework addresses the issue of combinatorial explosion inherent in relational scene model construction by incrementally creating a series of reduced scene models.", "labels": [], "entities": [{"text": "relational scene model construction", "start_pos": 74, "end_pos": 109, "type": "TASK", "confidence": 0.6812054812908173}]}, {"text": "Within each scene model only one spatial relations is considered and only a subset of objects are considered as candidate landmarks.", "labels": [], "entities": []}, {"text": "This reduces both the number of relations that must be computed over each object pair and the number of object pairs.", "labels": [], "entities": []}, {"text": "The decision as to which relations should be included in each scene model is guided by a cognitively motivated hierarchy of spatial relations.", "labels": [], "entities": []}, {"text": "The set of candidate landmarks in a given scene is dependent on the set of objects in the scene that fulfil the description of the target object and the relation that is being considered.", "labels": [], "entities": []}, {"text": "Overview In \u00a72 we present some background data relevant to our discussion.", "labels": [], "entities": []}, {"text": "In \u00a73 we present our GRE framework.", "labels": [], "entities": [{"text": "GRE", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.5255154967308044}]}, {"text": "In \u00a74 we illustrate the framework with a worked example and expand on some of the issues relevant to the framework.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}