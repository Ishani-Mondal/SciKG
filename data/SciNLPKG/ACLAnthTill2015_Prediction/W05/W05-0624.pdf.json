{"title": [{"text": "Sparse Bayesian Classification of Predicate Arguments", "labels": [], "entities": [{"text": "Bayesian Classification of Predicate Arguments", "start_pos": 7, "end_pos": 53, "type": "TASK", "confidence": 0.7687906146049499}]}], "abstractContent": [{"text": "We present an application of Sparse Bayesian Learning to the task of semantic role labeling, and we demonstrate that this method produces smaller classifiers than the popular Support Vector approach.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.7167175809542338}]}, {"text": "We describe the classification strategy and the features used by the classifier.", "labels": [], "entities": []}, {"text": "In particular , the contribution of six parse tree path features is investigated.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generalized linear classifiers, in particular Support Vector Machines (SVMs), have recently been successfully applied to the task of semantic role identification and classification), inter alia.", "labels": [], "entities": [{"text": "semantic role identification and classification", "start_pos": 133, "end_pos": 180, "type": "TASK", "confidence": 0.7668987810611725}]}, {"text": "Although the SVM approach has a number of properties that make it attractive (above all, excellent software packages exist), it also has drawbacks.", "labels": [], "entities": []}, {"text": "First, the resulting classifier is slow since it makes heavy use of kernel function evaluations.", "labels": [], "entities": []}, {"text": "This is especially the casein the presence of noise (since each misclassified example has to be stored as abound support vector).", "labels": [], "entities": []}, {"text": "The number of support vectors typically grows with the number of training examples.", "labels": [], "entities": []}, {"text": "Although there exist optimization methods that speedup the computations, the main drawback of the SVM approach is still the classification speed.", "labels": [], "entities": [{"text": "SVM", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9456104636192322}]}, {"text": "Another point is that it is necessary to tune the parameters (typically C and \u03b3).", "labels": [], "entities": []}, {"text": "This makes it necessary to train repeatedly using cross-validation to find the best combination of parameter values.", "labels": [], "entities": []}, {"text": "Also, the output of the decision function of the SVM is not probabilistic.", "labels": [], "entities": []}, {"text": "There are methods to map the decision function onto a probability output using the sigmoid function, but they are considered somewhat ad-hoc (see) fora discussion).", "labels": [], "entities": []}, {"text": "In this paper, we apply a recent learning paradigm, namely Sparse Bayesian learning, or more specifically the Relevance Vector learning method, to the problem of role classification.", "labels": [], "entities": [{"text": "role classification", "start_pos": 162, "end_pos": 181, "type": "TASK", "confidence": 0.9079517722129822}]}, {"text": "Its principal advantages compared to the SVM approach are: \u2022 It typically utilizes fewer examples compared to the SVM, which makes the classifier faster.", "labels": [], "entities": []}, {"text": "\u2022 It uses no C parameter, which reduces the need for cross-validation.", "labels": [], "entities": []}, {"text": "\u2022 The decision function is adapted for probabilistic output.", "labels": [], "entities": []}, {"text": "\u2022 Arbitrary basis functions can be used.", "labels": [], "entities": []}, {"text": "Its significant drawback is that the training procedure relies heavily on dense linear algebra, and is thus difficult to scale up to large training sets and maybe prone to numerical difficulties.", "labels": [], "entities": []}, {"text": "For a description of the task and the data, see).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overall results (top) and detailed results on  the WSJ test (bottom).", "labels": [], "entities": [{"text": "WSJ test", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.8127253949642181}]}, {"text": " Table 2: Contribution of path features", "labels": [], "entities": []}]}