{"title": [{"text": "New Experiments in Distributional Representations of Synonymy", "labels": [], "entities": [{"text": "Distributional Representations of Synonymy", "start_pos": 19, "end_pos": 61, "type": "TASK", "confidence": 0.9423564225435257}]}], "abstractContent": [{"text": "Recent work on the problem of detecting synonymy through corpus analysis has used the Test of English as a Foreign Language (TOEFL) as a benchmark.", "labels": [], "entities": [{"text": "detecting synonymy", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8403932750225067}]}, {"text": "However , this test involves as few as 80 questions , prompting questions regarding the statistical significance of reported results.", "labels": [], "entities": []}, {"text": "We overcome this limitation by generating a TOEFL-like test using WordNet, containing thousands of questions and composed only of words occurring with sufficient corpus frequency to support sound distributional comparisons.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9634515643119812}]}, {"text": "Experiments with this test lead us to a similarity measure which significantly outperforms the best proposed to date.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 40, "end_pos": 58, "type": "METRIC", "confidence": 0.9676598310470581}]}, {"text": "Analysis suggests that a strength of this measure is its relative robustness against polysemy.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many text applications are predicated on the idea that shallow lexical semantics can be acquired through corpus analysis.", "labels": [], "entities": []}, {"text": "Harris articulated the expectation that words with similar meanings would be used in similar contexts, and recent empirical work involving large corpora has borne this out.", "labels": [], "entities": []}, {"text": "In particular, by associating each word with a distribution over the words observed in its context, we can distinguish synonyms from non-synonyms with fair reliability.", "labels": [], "entities": []}, {"text": "This capability maybe exploited to generate corpus-based thesauri automatically, or used in any other application of text that might benefit from a measure of lexical semantic similarity.", "labels": [], "entities": []}, {"text": "And synonymy is a logical first step in a broader research program that seeks to account for natural language semantics through distributional means.", "labels": [], "entities": []}, {"text": "Previous research into corpus-analytic approaches to synonymy has used the Test of English as a Foreign Language (TOEFL).", "labels": [], "entities": []}, {"text": "The TOEFL consists of 300 multiple-choice question, each question involving five words: the problem or target word and four response words, one of which is a synonym of the target.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.492519736289978}]}, {"text": "The objective is to identify the synonym (call this the answer word, and call the other response words decoys).", "labels": [], "entities": []}, {"text": "In the context of research into lexical semantics, we seek a distance function which as reliably as possible orders the answer word in front of the decoys.", "labels": [], "entities": []}, {"text": "Landauer and Dumais first proposed the TOEFL as a test of lexical semantic similarity and reported a score of 64.4% on an 80-question version of the TOEFL, a score nearly identical to the average score of human test takers).", "labels": [], "entities": []}, {"text": "Subsequently, Sahlgren reported a score of 72.0% on the same test using \"random indexing\" and a different training corpus.", "labels": [], "entities": []}, {"text": "By analyzing a much larger corpus, Ehlert was able to score 82% on a 300-question version of the TOEFL, using a simple distribution over contextual words.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 97, "end_pos": 102, "type": "DATASET", "confidence": 0.7235564589500427}]}, {"text": "While success on the TOEFL does not immediately guarantee success in real-word applications requiring lexical similarity judgments, the scores have an intuitive appeal.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.6740080714225769}]}, {"text": "They are easily interpretable, and the expected performance of a random guesser (25%) and typical human performance are both known.", "labels": [], "entities": []}, {"text": "Nevertheless, the TOEFL is problematic in at least two ways.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.626313328742981}]}, {"text": "On the one hand, because it involves so few questions, conclusions based on the TOEFL regarding closely competing approaches are suspect.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.6484825611114502}]}, {"text": "Even on the 300-question TOEFL, a score of 82% is accurate only to within plus or minus 4% at the 95% confidence level.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.6161282062530518}, {"text": "accurate", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9830332398414612}]}, {"text": "The other shortcoming is a potential mis-match between the test vocabulary and the corpus vocabulary.", "labels": [], "entities": []}, {"text": "Typically, a substantial number of questions include words observed too infrequently in the training corpus fora semantic judgment to be made with any confidence.", "labels": [], "entities": []}, {"text": "We seek to overcome these difficulties by generating TOEFL-like tests automatically from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9367668032646179}]}, {"text": "While WordNet has been used before to evaluate corpus-analytic approaches to lexical similarity, the metric proposed in that study, while useful for comparative purposes, lacks an intuitive interpretation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 6, "end_pos": 13, "type": "DATASET", "confidence": 0.9249842166900635}]}, {"text": "In contrast, we emulate the TOEFL using WordNet and inherit the TOEFL's easy interpretability.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9617257714271545}]}, {"text": "Given a corpus, we first derive a list of words occurring with sufficient marginal frequency to support a distributional comparison.", "labels": [], "entities": []}, {"text": "We then use WordNet to generate a large set of questions identical in format to those in the TOEFL.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 12, "end_pos": 19, "type": "DATASET", "confidence": 0.9816948771476746}, {"text": "TOEFL", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.9264659285545349}]}, {"text": "For a vocabulary of reasonable size, this yields questions numbering in the thousands.", "labels": [], "entities": []}, {"text": "While the resulting questions differ in some interesting ways from those in the TOEFL (see below), their sheer number supports more confident conclusions.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.8062207698822021}]}, {"text": "Beyond this, we can partition them by part of speech or degree of polysemy, enabling some analyses not supported by the original TOEFL.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 129, "end_pos": 134, "type": "DATASET", "confidence": 0.9121196269989014}]}], "datasetContent": [{"text": "We experimented with various distance measures and context policies using the full North American News corpus.", "labels": [], "entities": [{"text": "North American News corpus", "start_pos": 83, "end_pos": 109, "type": "DATASET", "confidence": 0.9387989789247513}]}, {"text": "We count approximately one billion words in this corpus, which is roughly four times the size of the largest corpus considered by Ehlert.", "labels": [], "entities": []}, {"text": "Except where noted, the numbers reported here are the result of taking the full WBST, a total of 23,570 test questions.", "labels": [], "entities": [{"text": "WBST", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.8987010717391968}]}, {"text": "Given this number of questions, scores where most of the results fall are accurate to within plus or minus 0.6% at the 95% confidence level.", "labels": [], "entities": [{"text": "accurate", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9898926615715027}]}], "tableCaptions": [{"text": " Table 2: Accuracy on the WBST: an initial compar- ison of distance measures and context definitions.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9926843047142029}, {"text": "WBST", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.9068381786346436}]}]}