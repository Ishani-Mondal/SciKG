{"title": [{"text": "Inferring semantic roles using sub-categorization frames and maximum entropy model", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose an approach for inferring semantic role using sub-categorization frames and maximum entropy model.", "labels": [], "entities": []}, {"text": "Our approach aims to use the sub-categorization information of the verb to label the mandatory arguments of the verb in various possible ways.", "labels": [], "entities": []}, {"text": "The ambiguity between the assignment of roles to mandatory arguments is resolved using the maximum entropy model.", "labels": [], "entities": []}, {"text": "The unlabelled mandatory arguments and the optional arguments are labelled directly using the maximum entropy model such that their labels are not one among the frame elements of the sub-categorization frame used.", "labels": [], "entities": []}, {"text": "Maximum entropy model is preferred because of its novel approach of smoothing.", "labels": [], "entities": []}, {"text": "Using this approach, we obtained an F-measure of 68.14% on the development set of the data provided for the CONLL-2005 shared task.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9995273351669312}, {"text": "CONLL-2005 shared task", "start_pos": 108, "end_pos": 130, "type": "DATASET", "confidence": 0.8381539781888326}]}, {"text": "We show that this approach performs well in comparison to an approach which uses only the maximum entropy model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic role labelling is the task of assigning appropriate semantic roles to the arguments of a verb.", "labels": [], "entities": [{"text": "Semantic role labelling", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7535746494928995}]}, {"text": "The semantic role information is important for various applications in NLP such as Machine Translation, Question Answering, Information Extraction etc.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.8442171812057495}, {"text": "Question Answering", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.8531688153743744}, {"text": "Information Extraction", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.8129105567932129}]}, {"text": "In general, semantic role information is useful for sentence understanding.", "labels": [], "entities": [{"text": "sentence understanding", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.8231184780597687}]}, {"text": "We submitted our system for closed challenge at CONLL-2005 shared task.", "labels": [], "entities": [{"text": "CONLL-2005 shared task", "start_pos": 48, "end_pos": 70, "type": "DATASET", "confidence": 0.7966637214024862}]}, {"text": "This task encourages participants to use novel machine learning techniques suited to the task of semantic role labelling.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.7340176900227865}]}, {"text": "Previous approaches on semantic role labelling can be classified into three categories (1) Explicit Probabilistic methods ().", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.7363653381665548}]}, {"text": "(2) General machine learning algorithms () () and (3) Generative model (.", "labels": [], "entities": []}, {"text": "Our approach has two stages; first, identification whether the argument is mandatory or optional and second, the classification or labelling of the arguments.", "labels": [], "entities": [{"text": "classification or labelling of the arguments", "start_pos": 113, "end_pos": 157, "type": "TASK", "confidence": 0.7465413957834244}]}, {"text": "In the first stage, the arguments of a verb are put into three classes, (1) mandatory, (2) optional or (3) null.", "labels": [], "entities": []}, {"text": "Null stands for the fact that the constituent of the verb in the sentence is not an semantic argument of the verb.", "labels": [], "entities": []}, {"text": "It is used to rule out the false argument of the verb which were obtained using the parser.", "labels": [], "entities": []}, {"text": "The maximum entropy based classifier is used to classify the arguments into one of the above three labels.", "labels": [], "entities": []}, {"text": "After obtaining information about the nature of the non-null arguments, we proceed in the second stage to classify the mandatory and optional arguments into their semantic roles.", "labels": [], "entities": []}, {"text": "The propbank sub-categorization frames are used to assign roles to the mandatory arguments.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"John saw a tree\", the sub-categorization frame \"A0 v A1\" would assign the roles A0 to John and A1 to tree respectively.", "labels": [], "entities": []}, {"text": "After using all the sub-categorization frames of the verb irre-spective of the verb sense, there could be ambiguity in the assignment of semantic roles to mandatory arguments.", "labels": [], "entities": []}, {"text": "The unlabelled mandatory arguments and the optional arguments are assigned the most probable semantic role which is not one of the frame elements of the sub-categorization frame using the maximum entropy model.", "labels": [], "entities": []}, {"text": "Now, among all the sequences of roles assigned to the non-null arguments, the sequence which has the maximum joint probability is chosen.", "labels": [], "entities": []}, {"text": "We obtained an accuracy of 68.14% using our approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9997599720954895}]}, {"text": "We also show that our approach performs better in comparision to an approach with uses a simple maximum entropy model.", "labels": [], "entities": []}, {"text": "In section 4, we will talk about our approach in greater detail.", "labels": [], "entities": []}, {"text": "This paper is organised as follows, (2) Features, (3) Maximum entropy model, (4) Description of our system, (5) Results, (6) Comparison with our other experiments, (7) Conclusion and (8) Future work.", "labels": [], "entities": [{"text": "Conclusion", "start_pos": 168, "end_pos": 178, "type": "METRIC", "confidence": 0.9815340638160706}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overall results (top) and detailed results  on the WSJ test (bottom).", "labels": [], "entities": [{"text": "WSJ test", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.8127253949642181}]}]}