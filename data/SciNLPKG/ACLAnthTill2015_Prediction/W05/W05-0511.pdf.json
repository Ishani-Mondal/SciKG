{"title": [], "abstractContent": [{"text": "I describe steps toward \"deep lexical ac-quisition\" based on naive theories, motivated by modern results of developmental psychology.", "labels": [], "entities": []}, {"text": "I argue that today's machine learning paradigm is inappropriate to take these steps.", "labels": [], "entities": []}, {"text": "Instead we must develop computational accounts of naive theory representations , mechanisms of theory acquisition , and the mapping of naive theories to lexicalizable concepts.", "labels": [], "entities": [{"text": "theory acquisition", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7982442378997803}]}, {"text": "This will enable our theories to describe the flexibility of the human conceptual apparatus.", "labels": [], "entities": []}, {"text": "1 Where We Are Now The present Machine Learning Paradigm Much of computational linguistics has converged onto a machine learning paradigm that provides us soothing clarity.", "labels": [], "entities": []}, {"text": "The machine learning approach defines a problem as a mapping problem-map some acoustic stream onto a list of word tokens, map a list of word tokens onto a parse tree, map a parse tree onto a set of semantic roles or \"logical form\", map each word in a tree onto its best sense, and soon.", "labels": [], "entities": []}, {"text": "We then develop a learning algorithm to accomplish the desired mapping.", "labels": [], "entities": []}, {"text": "Multiple groups describe how well their algorithm maps various test sets given various training sets, and describe a \"result\" to improve upon.", "labels": [], "entities": []}, {"text": "The clarity provided by this paradigm is so soothing, one gets the sense we can turn a crank, and indeed, in many cases, progress has been made proceeding precisely along these lines.", "labels": [], "entities": []}, {"text": "Turning the crank on deep lexical acquisition, however, we might feel something is missing.", "labels": [], "entities": [{"text": "deep lexical acquisition", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.628664235273997}]}, {"text": "Underlying any model of deep lexical acquisition is a theory of the human conceptual apparatus.", "labels": [], "entities": [{"text": "deep lexical acquisition", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.7392969528834025}]}, {"text": "Unlike our handle on acoustic streams, word lists, and parse trees, our handle on a suitable \"output\" for the space of word meanings is remarkably poor.", "labels": [], "entities": []}, {"text": "Somehow, via experience (of some kind or another), children acquire a mapping from a space of vocabulary items to a space of lexicalizable concepts-the lexicon; our task as modelers is to figure out how this mapping can occur.", "labels": [], "entities": []}, {"text": "Many models for the space of lexicalizable concepts exist: concepts are points in Rn , concepts are Jackendoff's lexical conceptual structures, concepts are FrameNet's frame elements , concepts are Schankian script activators, concepts are distributions over syntactic frames, concepts are grounded in sensorimotor statistics, or all of the above.", "labels": [], "entities": []}, {"text": "Almost everyone nowadays reports how their algorithm accomplished some mapping to one or more of these models of concepts.", "labels": [], "entities": []}, {"text": "They have to, because today's de facto idea of what constitutes a \"result\" according the machine learning paradigm today is to do exactly this.", "labels": [], "entities": []}, {"text": "The Golden Oldies formed our concept models Our models of conceptual spaces did not originate from computational linguists following the machine learning paradigm.", "labels": [], "entities": []}, {"text": "They were proposed from linguists, psychologists and philosophers back in earlier eras-what we will call Golden Oldies-when the idea of a \"result\" was somewhat different.", "labels": [], "entities": []}, {"text": "There are too many to recall: Quine (1960) argued that the linguist watching the natives uttering Gavagai!", "labels": [], "entities": []}, {"text": "in the context of a rabbit would nec-91", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}