{"title": [{"text": "Efficacy of Beam Thresholding, Unification Filtering and Hybrid Parsing in Probabilistic HPSG Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic HPSG parsing using the Penn treebank.", "labels": [], "entities": [{"text": "beam search parsing", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.791854461034139}, {"text": "deep parsing", "start_pos": 68, "end_pos": 80, "type": "TASK", "confidence": 0.6645849794149399}, {"text": "HPSG parsing", "start_pos": 109, "end_pos": 121, "type": "TASK", "confidence": 0.7185676395893097}, {"text": "Penn treebank", "start_pos": 132, "end_pos": 145, "type": "DATASET", "confidence": 0.9930806457996368}]}, {"text": "We first tested the beam thresholding and iterative parsing developed for PCFG parsing with an HPSG.", "labels": [], "entities": [{"text": "beam thresholding", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.792659342288971}, {"text": "PCFG parsing", "start_pos": 74, "end_pos": 86, "type": "TASK", "confidence": 0.7097106128931046}, {"text": "HPSG", "start_pos": 95, "end_pos": 99, "type": "DATASET", "confidence": 0.9311405420303345}]}, {"text": "Next, we tested three techniques originally developed for deep parsing: quick check, large constituent inhibition, and hybrid parsing with a CFG chunk parser.", "labels": [], "entities": [{"text": "quick check", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.9277836978435516}]}, {"text": "The contributions of the large constituent inhibition and global thresholding were not significant , while the quick check and chunk parser greatly contributed to total parsing performance.", "labels": [], "entities": [{"text": "chunk parser", "start_pos": 127, "end_pos": 139, "type": "TASK", "confidence": 0.6704051047563553}]}, {"text": "The precision, recall and average parsing time for the Penn treebank (Section 23) were 87.85%, 86.85%, and 360 ms, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997420907020569}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9993958473205566}, {"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.8187420964241028}, {"text": "Penn treebank (Section 23)", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9010974069436392}]}], "introductionContent": [{"text": "We investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (HPSG) parsing for the Penn treebank.", "labels": [], "entities": [{"text": "beam search parsing", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7397506833076477}, {"text": "deep parsing", "start_pos": 68, "end_pos": 80, "type": "TASK", "confidence": 0.7124748826026917}, {"text": "phrase structure grammar (HPSG) parsing", "start_pos": 121, "end_pos": 160, "type": "TASK", "confidence": 0.7997106909751892}, {"text": "Penn treebank", "start_pos": 169, "end_pos": 182, "type": "DATASET", "confidence": 0.9902244210243225}]}, {"text": "We first applied beam thresholding techniques developed for CFG parsing to HPSG parsing, including local thresholding, global thresholding, and iterative parsing).", "labels": [], "entities": [{"text": "CFG parsing", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.7148318588733673}, {"text": "HPSG parsing", "start_pos": 75, "end_pos": 87, "type": "TASK", "confidence": 0.7519675493240356}]}, {"text": "Next, we applied parsing techniques developed for deep parsing, including quick check (), large constituent inhibition () and hybrid parsing with a CFG chunk parser (.", "labels": [], "entities": [{"text": "quick check", "start_pos": 74, "end_pos": 85, "type": "METRIC", "confidence": 0.9191924035549164}, {"text": "CFG chunk parser", "start_pos": 148, "end_pos": 164, "type": "TASK", "confidence": 0.7480533520380656}]}, {"text": "The experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the Penn treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.9803066849708557}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9995998740196228}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.998711109161377}, {"text": "speed", "start_pos": 120, "end_pos": 125, "type": "METRIC", "confidence": 0.9942737221717834}, {"text": "Penn treebank", "start_pos": 134, "end_pos": 147, "type": "DATASET", "confidence": 0.9928118288516998}]}, {"text": "Unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.", "labels": [], "entities": [{"text": "linguistic formulation", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.7110477834939957}]}, {"text": "Although they provide precise linguistic structures of sentences, their processing is considered expensive because of the detailed descriptions.", "labels": [], "entities": []}, {"text": "Since efficiency is of particular concern in practical applications, a number of studies have focused on improving the parsing efficiency of unificationbased grammars).", "labels": [], "entities": []}, {"text": "Although significant improvements in efficiency have been made, parsing speed is still not high enough for practical applications.", "labels": [], "entities": [{"text": "parsing", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.9806652665138245}, {"text": "speed", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.47466230392456055}]}, {"text": "The recent introduction of probabilistic models of wide-coverage unification-based grammars) has opened up the novel possibility of increasing parsing speed by guiding the search path using probabilities.", "labels": [], "entities": [{"text": "parsing", "start_pos": 143, "end_pos": 150, "type": "TASK", "confidence": 0.9680233597755432}]}, {"text": "That is, since we often require only the most probable parse result, we can compute partial parse results that are likely to contribute to the final parse result.", "labels": [], "entities": []}, {"text": "This approach has been extensively studied in the field of probabilistic CFG (PCFG) parsing, such as Viterbi parsing and beam thresholding.", "labels": [], "entities": [{"text": "CFG (PCFG) parsing", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.5425918519496917}, {"text": "Viterbi parsing", "start_pos": 101, "end_pos": 116, "type": "TASK", "confidence": 0.5930511057376862}, {"text": "beam thresholding", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.7956860661506653}]}, {"text": "While many methods of probabilistic parsing for unification-based grammars have been developed, their strategy is to first perform exhaustive parsing without using probabilities and then select the highest probability parse.", "labels": [], "entities": [{"text": "probabilistic parsing", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.6880080997943878}]}, {"text": "The behavior of their algorithms is like that of the Viterbi algorithm for PCFG parsing, so the correct parse with the highest probability is guaranteed.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 75, "end_pos": 87, "type": "TASK", "confidence": 0.7457600235939026}]}, {"text": "The interesting point of this approach is that, once the exhaustive parsing is completed, the probabilities of non-local dependencies, which cannot be computed during parsing, are computed after making a packed parse forest.", "labels": [], "entities": []}, {"text": "Probabilistic models where probabilities are assigned to the CFG backbone of the unification-based grammar have been developed), and the most probable parse is found by PCFG parsing.", "labels": [], "entities": [{"text": "CFG backbone", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.94692462682724}, {"text": "PCFG parsing", "start_pos": 169, "end_pos": 181, "type": "TASK", "confidence": 0.7702220976352692}]}, {"text": "This model is based on PCFG and not probabilistic unification-based grammar parsing.) proposed a dynamic programming algorithm for finding the most probable parse in a packed parse forest generated by unification-based grammars without expanding the forest.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 23, "end_pos": 27, "type": "DATASET", "confidence": 0.9525086283683777}, {"text": "unification-based grammar parsing.", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.72999240954717}]}, {"text": "However, the efficiency of this algorithm is inherently limited by the inefficiency of exhaustive parsing.", "labels": [], "entities": []}, {"text": "In this paper we describe the performance of beam thresholding, including iterative parsing, in probabilistic HPSG parsing fora large-scale corpora, the Penn treebank.", "labels": [], "entities": [{"text": "beam thresholding", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.8274758160114288}, {"text": "HPSG parsing", "start_pos": 110, "end_pos": 122, "type": "TASK", "confidence": 0.758356899023056}, {"text": "Penn treebank", "start_pos": 153, "end_pos": 166, "type": "DATASET", "confidence": 0.9919954538345337}]}, {"text": "We show how techniques developed for efficient deep parsing can improve the efficiency of probabilistic parsing.", "labels": [], "entities": []}, {"text": "These techniques were evaluated in experiments on the Penn Treebank ( with the wide-coverage HPSG parser developed by ).) is a syntactic theory based on lexicalized grammar formalism.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9957881569862366}]}, {"text": "In HPSG, a small number of schemata describe general construction rules, and a large number of lexical entries express word-specific characteristics.", "labels": [], "entities": []}, {"text": "The structures of sentences are explained using combinations of schemata and lexical entries.", "labels": [], "entities": []}, {"text": "Both schemata and lexical entries are represented by typed feature structures, and constraints represented by feature structures are checked with unification.", "labels": [], "entities": []}, {"text": "shows an example of HPSG parsing of the sentence \"Spring has come.\"", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.7935977280139923}]}, {"text": "First, each of the lexical entries for \"has\" and \"come\" is unified with a daughter feature structure of the Head-Complement", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the efficiency of the parsing techniques by using the HPSG for English developed by . The lexicon of the grammar was extracted from Sections 02-21 of the Penn Treebank () (39,832 sentences).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 167, "end_pos": 180, "type": "DATASET", "confidence": 0.8889676332473755}]}, {"text": "The grammar consisted of 2,284 lexical entry templates for 10,536 words 1 . The probabilistic disambiguation model of the grammar was trained using the same portion of the treebank ).", "labels": [], "entities": []}, {"text": "shows the abbreviations used in presenting the results.", "labels": [], "entities": []}, {"text": "We measured the accuracy of the predicateargument relations output by the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999546468257904}]}, {"text": "A predicate-argument relation is defined as a tuple \ud97b\udf59\u03c3, w h , a, w a \ud97b\udf59, where \u03c3 is the predicate type (e.g., adjective, intransitive verb), w h is the headword of the predicate, a is the argument label (MODARG, ARG1, ..., ARG4), and w a is the headword of the argument.", "labels": [], "entities": [{"text": "MODARG", "start_pos": 203, "end_pos": 209, "type": "DATASET", "confidence": 0.8825451135635376}, {"text": "ARG1", "start_pos": 211, "end_pos": 215, "type": "DATASET", "confidence": 0.6760377287864685}, {"text": "ARG4", "start_pos": 222, "end_pos": 226, "type": "DATASET", "confidence": 0.9007173180580139}]}, {"text": "Precision/recall is the ratio of tuples correctly identified by the parser.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.98987877368927}, {"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8807165026664734}]}, {"text": "This evaluation scheme was the same as used in previous evaluations of lexicalized grammars.", "labels": [], "entities": []}, {"text": "The experiments were conducted on an AMD Opteron server with a 2.4-GHz CPU.", "labels": [], "entities": []}, {"text": "Section 22 of the Treebank was used as the development set, and performance was evaluated using sentences of less than 40 words in Section 23 (2,164 sentences, 20.3 words/sentence).", "labels": [], "entities": [{"text": "Section 22 of the Treebank", "start_pos": 0, "end_pos": 26, "type": "DATASET", "confidence": 0.683191466331482}]}, {"text": "The performance of each parsing technique was analyzed using the sentences in Section 24 of less than 15 words (305 sentences) and less than 40 words (1145 sentences).", "labels": [], "entities": []}, {"text": "thresholding techniques and implementations described in Section 4 for the sentences in the development set (Section 22) and the test set (Section 23) of less than 40 words.", "labels": [], "entities": []}, {"text": "In the table, precision, recall, average parsing time per sentence, and the number of sentences that the parser failed to parse are detailed.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9996077418327332}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.999439537525177}]}, {"text": "shows the distribution of parsing time for the sentence length.", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9609648585319519}]}, {"text": "shows the performance of the Viterbi parsing, beam search parsing, and iterative parsing for the sentences in Section 24 of less than 15 words 2 . The parsing without beam searching took more than 1,000 times longer than with beam searching.", "labels": [], "entities": [{"text": "Viterbi parsing", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.5602976679801941}, {"text": "beam search parsing", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7959345579147339}]}, {"text": "However, the beam searching reduced the recall from 87.9% to 82.4%.", "labels": [], "entities": [{"text": "beam searching", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9143564999103546}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9972363114356995}]}, {"text": "The main reason for this reduction was parsing failure.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.98020339012146}]}, {"text": "That is, the parser could not output any results when the beam was too narrow instead of producing incorrect parse results.", "labels": [], "entities": []}, {"text": "Although iterative parsing was originally developed for efficiency, the results revealed that it also increases the recall.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.6505796909332275}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9990672469139099}]}, {"text": "This is because the parser continues trying until some results are output.", "labels": [], "entities": []}, {"text": "shows the logarithmic graph of parsing time for the sentence length.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9582692980766296}]}, {"text": "The left side of the figure shows the parsing time of the Viterbi parsing and the right side shows the parsing time of the iterative parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9474758505821228}, {"text": "parsing", "start_pos": 103, "end_pos": 110, "type": "TASK", "confidence": 0.9484001398086548}]}, {"text": "shows the performance of the parsing techniques for different parameters for the sentences in Section 24 of less than 40 words.", "labels": [], "entities": []}, {"text": "The combinations of thresholding techniques achieved better re- The sentence length was limited to 15 words because of inefficiency of Viterbi parsing sults than the single techniques.", "labels": [], "entities": [{"text": "re- The sentence length", "start_pos": 60, "end_pos": 83, "type": "METRIC", "confidence": 0.8282727718353271}]}, {"text": "Local thresholding using the width (width) performed better than that using the number (num).", "labels": [], "entities": [{"text": "width (width)", "start_pos": 29, "end_pos": 42, "type": "METRIC", "confidence": 0.8925064504146576}]}, {"text": "The combination of using width and number (num+width) performed better than single local and single global thresholding.", "labels": [], "entities": []}, {"text": "The superiority of iterative parsing (iterative) was again demonstrated in this experiment.", "labels": [], "entities": []}, {"text": "Although we did not observe significant improvement with global thresholding, the global plus iterative combination slightly improved performance.", "labels": [], "entities": []}, {"text": "shows the performance with and without the chunk parser.", "labels": [], "entities": []}, {"text": "The lines with white symbols represent parsing without the chunk parser, and the lines with black symbols represent parsing with the chunk parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.9663994312286377}]}, {"text": "The chunk parser improved the total parsing performance significantly.", "labels": [], "entities": [{"text": "chunk parser", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.791569709777832}]}, {"text": "The improvements with global thresholding were less with the chunk parser.", "labels": [], "entities": [{"text": "chunk parser", "start_pos": 61, "end_pos": 73, "type": "TASK", "confidence": 0.7230379283428192}]}, {"text": "Finally, shows the contribution to performance of each implementation for the sentences in Section 24 of less than 40 words.", "labels": [], "entities": []}, {"text": "The 'full' means the parser including all thresholding techniques and implementations described in Section 4.", "labels": [], "entities": []}, {"text": "The 'full \u2212 x' means the full minus x.", "labels": [], "entities": []}, {"text": "The preserved iterative parsing, the quick check, and the chunk parser greatly contributed to the final parsing speed, while the global thresholding and large constituent inhibition did not.", "labels": [], "entities": [{"text": "chunk parser", "start_pos": 58, "end_pos": 70, "type": "TASK", "confidence": 0.7280568778514862}]}], "tableCaptions": [{"text": " Table 2: Experimental results for development set (section 22) and test set (section 23)", "labels": [], "entities": []}, {"text": " Table 3: Viterbi parsing versus beam thresholding versus iterative parsing", "labels": [], "entities": [{"text": "Viterbi parsing", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.6091386675834656}, {"text": "parsing", "start_pos": 68, "end_pos": 75, "type": "TASK", "confidence": 0.5528659820556641}]}, {"text": " Table 4: Contribution to performance of each implementation", "labels": [], "entities": []}]}