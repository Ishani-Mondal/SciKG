{"title": [{"text": "Engineering of Syntactic Features for Shallow Semantic Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent natural language learning research has shown that structural kernels can be effectively used to induce accurate models of linguistic phenomena.", "labels": [], "entities": []}, {"text": "In this paper, we show that the above properties hold on a novel task related to predicate argument classification.", "labels": [], "entities": [{"text": "predicate argument classification", "start_pos": 81, "end_pos": 114, "type": "TASK", "confidence": 0.9127728740374247}]}, {"text": "A tree kernel for selecting the subtrees which encodes argument structures is applied.", "labels": [], "entities": []}, {"text": "Experiments with Support Vector Machines on large data sets (i.e. the PropBank collection) show that such kernel improves the recognition of argument boundaries.", "labels": [], "entities": [{"text": "PropBank collection", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.9449523389339447}, {"text": "recognition of argument boundaries", "start_pos": 126, "end_pos": 160, "type": "TASK", "confidence": 0.7805055677890778}]}], "introductionContent": [{"text": "The design of features for natural language processing tasks is, in general, a critical problem.", "labels": [], "entities": []}, {"text": "The inherent complexity of linguistic phenomena, often characterized by structured data, makes difficult to find effective linear feature representations for the target learning models.", "labels": [], "entities": []}, {"text": "In many cases, the traditional feature selection techniques ( are not so useful since the critical problem relates to feature generation rather than selection.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7843195796012878}, {"text": "feature generation", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.6811486482620239}]}, {"text": "For example, the design of features fora natural language syntactic parse-tree re-ranking problem) cannot be carried out without a deep knowledge about automatic syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 162, "end_pos": 179, "type": "TASK", "confidence": 0.68810074031353}]}, {"text": "The modeling of syntactic/semantic based features should take into account linguistic aspects to detect the interesting context, e.g. the ancestor nodes or the semantic dependencies (.", "labels": [], "entities": []}, {"text": "A viable alternative has been proposed in), where convolution kernels were used to implicitly define a tree substructure space.", "labels": [], "entities": []}, {"text": "The selection of the relevant structural features was left to the voted perceptron learning algorithm.", "labels": [], "entities": []}, {"text": "Another interesting model for parsing re-ranking based on tree kernel is presented in ().", "labels": [], "entities": [{"text": "parsing re-ranking", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8696346879005432}]}, {"text": "The good results show that tree kernels are very promising for automatic feature engineering, especially when the available knowledge about the phenomenon is limited.", "labels": [], "entities": [{"text": "automatic feature engineering", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.6624141037464142}]}, {"text": "Along the same line, automatic learning tasks that rely on syntactic information may take advantage of a tree kernel approach.", "labels": [], "entities": []}, {"text": "One of such tasks is the automatic boundary detection of predicate arguments of the kind defined in PropBank ().", "labels": [], "entities": [{"text": "automatic boundary detection of predicate arguments", "start_pos": 25, "end_pos": 76, "type": "TASK", "confidence": 0.7246100902557373}]}, {"text": "For this purpose, given a predicate pin a sentence s, we can define the notion of predicate argument spanning trees (P AST s) as those syntactic subtrees of s which exactly coverall and only the p's arguments (see Section 4.1).", "labels": [], "entities": []}, {"text": "The set of nonspanning trees can be then associated with all the remaining subtrees of s.", "labels": [], "entities": []}, {"text": "An automatic classifier which recognizes the spanning trees can potentially be used to detect the predicate argument boundaries.", "labels": [], "entities": []}, {"text": "Unfortunately, the application of such classifier to all possible sentence subtrees would require an exponential execution time.", "labels": [], "entities": []}, {"text": "As a consequence, we can use it only to decide fora reduced set of subtrees associated with a corresponding set of candidate boundaries.", "labels": [], "entities": []}, {"text": "Notice how these can be detected by previous approaches) in which a traditional boundary classifier (tbc) labels the parse-tree nodes as potential arguments (PA).", "labels": [], "entities": []}, {"text": "Such classifiers, generally, are not sensitive to the overall argument structure.", "labels": [], "entities": []}, {"text": "On the contrary, a P AST classifier (past c ) can consider the overall argument structure encoded in the associated subtree.", "labels": [], "entities": [{"text": "AST classifier", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8002347946166992}]}, {"text": "This is induced by the PA subsets.", "labels": [], "entities": []}, {"text": "The feature design for the P AST representation is not simple.", "labels": [], "entities": [{"text": "P AST representation", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.5525435705979665}]}, {"text": "Tree kernels area viable alternative that allows the learning algorithm to measure the similarity between two P AST sin term of all possible tree substructures.", "labels": [], "entities": []}, {"text": "In this paper, we designed and experimented a boundary classifier for predicate argument labeling based on two phases: (1) a first annotation of potential arguments by using a high recall tbc and (2) a P AST classification step aiming to select the correct substructures associated with potential arguments.", "labels": [], "entities": [{"text": "predicate argument labeling", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.8422160148620605}, {"text": "recall", "start_pos": 181, "end_pos": 187, "type": "METRIC", "confidence": 0.988407552242279}, {"text": "AST classification", "start_pos": 204, "end_pos": 222, "type": "TASK", "confidence": 0.878809243440628}]}, {"text": "Both classifiers are based on Support Vector Machines learning.", "labels": [], "entities": []}, {"text": "The past c uses the tree kernel function defined in).", "labels": [], "entities": []}, {"text": "The results show that the P AST classification can be learned with high accuracy (the f-measure is about 89%) and the impact on the overall boundary detection accuracy is good.", "labels": [], "entities": [{"text": "P AST classification", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.6950687865416209}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9983428716659546}, {"text": "boundary detection", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.6798229813575745}, {"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.8213678598403931}]}, {"text": "In the remainder of this paper, Section 2 introduces the Semantic Role Labeling problem along with the boundary detection subtask.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8118076721827189}, {"text": "boundary detection", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.751936137676239}]}, {"text": "Section 3 defines the SVMs using the linear kernel and the parse tree kernel for boundary detection.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7139246910810471}]}, {"text": "Section 4 describes our boundary detection algorithm.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7595265805721283}]}, {"text": "Section 5 shows the preliminary comparative results between the traditional and the two-step boundary detection.", "labels": [], "entities": []}, {"text": "Finally, Section 7 summarizes the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were carried outwith the SVM-light-TK software available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes the tree kernels in the SVM-light software).", "labels": [], "entities": []}, {"text": "For tbc, we used the linear kernel with a regularization parameter (option -c) equal to 1 and a cost-factor (option -j) of 10 to have a higher Recall.", "labels": [], "entities": [{"text": "Recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9983360171318054}]}, {"text": "For the past c we used \u03bb = 0.4 (see).", "labels": [], "entities": []}, {"text": "As referring dataset, we used the PropBank corpora available at www.cis.upenn.edu/\u223cace, along with the Penn TreeBank 2 (www.cis.upenn.edu/\u223ctreebank).", "labels": [], "entities": [{"text": "PropBank corpora", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.97383913397789}, {"text": "Penn TreeBank 2", "start_pos": 103, "end_pos": 118, "type": "DATASET", "confidence": 0.989518960316976}]}, {"text": "This corpus contains about 53,700 sentences and a fixed split between training and testing which has been used in other researches, e.g. ().", "labels": [], "entities": []}, {"text": "We did not include continuation and co-referring arguments in our experiments.", "labels": [], "entities": []}, {"text": "We used sections from 02 to 07 (54,443 argument nodes and 1,343,046 non-argument nodes) to train the traditional boundary classifier (tbc).", "labels": [], "entities": []}, {"text": "Then, we applied it to classify the sections from 08 to 21 (125,443 argument nodes vs. 3,010,673 nonargument nodes).", "labels": [], "entities": []}, {"text": "As results we obtained 2,988 N ST s containing at least an overlapping node pair out of the total 65,212 predicate structures (according to the tbc decisions).", "labels": [], "entities": []}, {"text": "From the 2,988 overlapping structures we extracted 3,624 positive and 4,461 negative N ST s, that we used to train the past c . The performance was evaluated with the F 1 measure 2 over the section 23.", "labels": [], "entities": [{"text": "F 1 measure 2", "start_pos": 167, "end_pos": 180, "type": "METRIC", "confidence": 0.9751951098442078}]}, {"text": "This contains 10,406 argument nodes out of 249,879 parse tree nodes.", "labels": [], "entities": []}, {"text": "By applying the tbc classifier we derived 235 overlapping N ST s, from which we extracted 204 P AST sand 385 incorrect predicate argument structures.", "labels": [], "entities": []}, {"text": "On such test data, the performance of past c was very high, i.e. 87.08% in Precision and 89.22% in Recall.", "labels": [], "entities": [{"text": "Precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9777681231498718}, {"text": "Recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9402016401290894}]}, {"text": "Using the past c we removed from the tbc the PA that cause overlaps.", "labels": [], "entities": [{"text": "PA", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.996616780757904}]}, {"text": "To measure the impact on the boundary identification performance, we compared it with three different boundary classification baselines: \u2022 tbc: overlaps are ignored and no decision is taken.", "labels": [], "entities": [{"text": "boundary identification", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.8641771674156189}]}, {"text": "This provides an upper bound for the recall as no potential argument is rejected for later labeling.", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9988879561424255}]}, {"text": "Notice that, in presence of overlapping nodes, the sentence cannot be annotated correctly.", "labels": [], "entities": []}, {"text": "\u2022: Two-steps boundary classification performance using the traditional boundary classifier tbc, the random selection of non-overlapping structures, the heuristic to select the most suitable non-overlapping node set (Heu) and the predicate argument spanning tree classifier (pastc).", "labels": [], "entities": [{"text": "boundary classification", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.7112369686365128}]}, {"text": "\u2022 Heu (heuristic): one of the N ST s which contain the nodes with the lowest overlapping score is chosen.", "labels": [], "entities": []}, {"text": "This score counts the number of overlapping node pairs in the N ST . For example, in.(a) we have a NP that overlaps with two nodes NP and PP, thus it is assigned a score of 2.", "labels": [], "entities": []}, {"text": "The third row of shows the results of tbc, tbc + RN D, tbc + Heu and tbc + past c in the columns 2,3,4 and 5, respectively.", "labels": [], "entities": []}, {"text": "We note that: \u2022 The tbc F 1 is slightly higher than the result obtained in), i.e. 95.37% vs. 93.8% on same training/testing conditions, i.e. (same PropBank version, same training and testing split and same machine learning algorithm).", "labels": [], "entities": [{"text": "tbc F 1", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.8846240043640137}]}, {"text": "This is explained by the fact that we did not include the continuations and the coreferring arguments that are more difficult to detect.", "labels": [], "entities": []}, {"text": "\u2022 Both RN D and Heu do not improve the tbc result.", "labels": [], "entities": [{"text": "RN D", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.8360558748245239}, {"text": "tbc", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.7941384315490723}]}, {"text": "This can be explained by observing that in the 50% of the cases a correct node is removed.", "labels": [], "entities": []}, {"text": "\u2022 When, to select the correct node, the past c is used, the F 1 increases of 1.49%, i.e. (96.86 vs. 95.37).", "labels": [], "entities": [{"text": "F 1", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9941514730453491}]}, {"text": "This is a very good result considering that to increase the very high baseline of tbc is hard.", "labels": [], "entities": []}, {"text": "In order to give a fairer evaluation of our approach we tested the above classifiers on the overlapping structures only, i.e. we measured the past c improvement on all and only the structures that required its application.", "labels": [], "entities": []}, {"text": "Such reduced test set contains 642 argument nodes and 15,408 non-argument nodes.", "labels": [], "entities": []}, {"text": "The fourth row of reports the classifier performance on such task.", "labels": [], "entities": []}, {"text": "We note that the past c improves the other heuristics of about 20%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Two-steps boundary classification performance using the traditional boundary classifier tbc, the random selection of", "labels": [], "entities": [{"text": "boundary classification", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7778612375259399}]}]}