{"title": [{"text": "Bootstrapping Deep Lexical Resources: Resources for Courses", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a range of deep lexical acquisition methods which make use of morphological , syntactic and ontological language resources to model word similarity and bootstrap from a seed lexicon.", "labels": [], "entities": []}, {"text": "The different methods are deployed in learning lexical items fora precision grammar , and shown to each have strengths and weaknesses over different word classes.", "labels": [], "entities": []}, {"text": "A particular focus of this paper is the relative accessibility of different language resource types, and predicted \"bang for the buck\" associated with each in deep lexical acquisition applications.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over recent years, computational linguistics has benefitted considerably from advances in statistical modelling and machine learning, culminating in methods capable of deeper, more accurate automatic analysis, over a wider range of languages.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.8676525950431824}, {"text": "statistical modelling", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.805605947971344}]}, {"text": "Implicit in much of this work, however, has been the existence of deep language resources (DLR hereafter) of ever-increasing linguistic complexity, including lexical semantic resources (e.g. WordNet and FrameNet), precision grammars (e.g. the English Resource Grammar and the various ParGram grammars) and richly-annotated treebanks (e.g. PropBank and CCGbank).", "labels": [], "entities": []}, {"text": "Due to their linguistic complexity, DLRs are invariably constructed by hand and thus restricted in size and coverage.", "labels": [], "entities": []}, {"text": "Our aim in this paper is to develop general-purpose automatic methods which can be used to automatically expand the coverage of an existing DLR, through the process of deep lexical acquisition (DLA hereafter).", "labels": [], "entities": [{"text": "deep lexical acquisition", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.6707400480906168}]}, {"text": "The development of DLRs can be broken down into two basic tasks: (1) design of a data representation to systematically capture the generalisations and idiosyncracies of the dataset of interest (system design); and (2) classification of data items according to the predefined data representation (data classification).", "labels": [], "entities": [{"text": "data classification", "start_pos": 296, "end_pos": 315, "type": "TASK", "confidence": 0.7677651941776276}]}, {"text": "In the case of a deep grammar, for example, system design encompasses the construction of the system of lexical types, templates, and/or phrase structure rules, and data classification corresponds to the determination of the lexical type(s) each individual lexeme conforms to.", "labels": [], "entities": [{"text": "system design", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.7490962445735931}]}, {"text": "DLA pertains to the second of these tasks, in automatically mapping a given lexeme onto a pre-existing system of lexical types associated with a DLR.", "labels": [], "entities": []}, {"text": "We propose to carryout DLA through a bootstrap process, that is by employing some notion of word similarity, and learning the lexical types fora novel lexeme through analogy with maximally similar word(s) for which we know the lexical types.", "labels": [], "entities": []}, {"text": "In this, we are interested in exploring the impact of different secondary language resources (LRs) on DLA, and estimating how successfully we can expect to learn new lexical items from a range of LR types.", "labels": [], "entities": []}, {"text": "That is, we estimate the expected DLA \"bang for the buck\" from a range of secondary LR types of varying size and complexity.", "labels": [], "entities": []}, {"text": "As part of this, we look at the relative impact of different LRs on DLA for different open word classes, namely nouns, verbs, adjectives and adverbs.", "labels": [], "entities": []}, {"text": "We demonstrate the proposed DLA methods relative to the English Resource Grammar (see Section 2.1), and in doing so assume the lexical types of the target DLR to be syntactico-semantic in nature.", "labels": [], "entities": [{"text": "English Resource Grammar", "start_pos": 56, "end_pos": 80, "type": "DATASET", "confidence": 0.8079485297203064}]}, {"text": "For example, we may predict that the word dog has a usage as an intransitive countable noun (n intr le, 1 cf. The dog barked), and also as a transitive verb (v np trans le, cf. It dogged my every step).", "labels": [], "entities": []}, {"text": "A secondary interest of this paper is the consideration of how well we could expect to perform DLA for languages of differing density, from \"low-density\" languages (such as Walpiri or Uighur) for which we have limited LRs, to \"high-density\" languages (such as English or Japanese) for which we have a wide variety of LRs.", "labels": [], "entities": []}, {"text": "To this end, while we exclusively target English in this paper, we experiment with a range of LRs of varying complexity and type, including morphological, syntactic and ontological LRs.", "labels": [], "entities": []}, {"text": "Note that we attempt to maintain consistency across the feature sets associated with each, to make evaluation as equitable as possible.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines the process of DLA and reviews relevant resources and literature.", "labels": [], "entities": [{"text": "DLA", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8318544030189514}]}, {"text": "Sections 3, 4 and 5 propose a range of DLA methods based on morphology, syntax and ontological semantics, respectively.", "labels": [], "entities": []}, {"text": "Section 6 evaluates the proposed methods relative to the English Resource Grammar.", "labels": [], "entities": [{"text": "English Resource Grammar", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.8661318421363831}]}], "datasetContent": [{"text": "We evaluate the component methods over the 5,675 open-class lexical items of the ERG described in Section 2.1 using 10-fold stratified cross-validation.", "labels": [], "entities": []}, {"text": "In each case, we calculate the type precision (the proportion of correct hypothesised lexical entries) and type recall (the proportion of gold-standard lexical entries for which we get a correct hit), which we roll together into the type F-score (the harmonic mean of the two) relative to the gold-standard ERG lexicon.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.6135007739067078}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.885679304599762}, {"text": "gold-standard ERG lexicon", "start_pos": 293, "end_pos": 318, "type": "DATASET", "confidence": 0.8227454821268717}]}, {"text": "We also measure the token accuracy for the lexicon derived from each method, relative to the Redwoods treebank of Verbmobil data associated with the ERG (see Section 2.1).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9556735157966614}, {"text": "Redwoods treebank of Verbmobil data", "start_pos": 93, "end_pos": 128, "type": "DATASET", "confidence": 0.9397982358932495}, {"text": "ERG", "start_pos": 149, "end_pos": 152, "type": "DATASET", "confidence": 0.8367875814437866}]}, {"text": "The token accuracy represents a weighted version of type precision, relative to the distribution of each lexical item in a representative text sample, and provides a crude approximation of the impact of each DLA method on parser coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9163080453872681}, {"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.6078810095787048}]}, {"text": "That is, it gives more credit fora method having correctly hypothesised a commonlyoccurring lexical item than a low-frequency lexical item, and no credit for having correctly identified a lexical item not occurring in the corpus.", "labels": [], "entities": []}, {"text": "The overall results are presented in, which are then broken down into the four open word classes in.", "labels": [], "entities": []}, {"text": "The baseline method (Base) in each case is a simple majority-class classifier, which generates a unique lexical item for each lexeme pre-identified as belonging to a given word class of the following type: Word class Majority-class lexical type Noun n intr le Verb v np trans le Adjective adj intrans le Adverb adv int vp le In each graph, we present the type F-score and token accuracy for each method, and mark the bestperforming method in terms of each of these evaluation measures with a star ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 378, "end_pos": 386, "type": "METRIC", "confidence": 0.8378016352653503}]}, {"text": "The results for syntaxbased DLA (S POS , S CHUNK and S PARSE ) are based on the BNC in each case.", "labels": [], "entities": [{"text": "CHUNK", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.7615489363670349}, {"text": "PARSE", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9554177522659302}, {"text": "BNC", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9009842872619629}]}, {"text": "We return to investigate the impact of corpus size on the performance of the syntax-based methods below.", "labels": [], "entities": []}, {"text": "Looking first at the combined results overall lexical types, the most successful method in terms of type F-score is syntax-based DLA, with chunker-based preprocessing marginally outperforming tagger-and parser-based preprocessing (type F-score = 0.641).", "labels": [], "entities": []}, {"text": "The most successful method in terms of token accuracy is ontology-based DLA (token accuracy = 0.544).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9442790746688843}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.6705541014671326}]}, {"text": "The figures for token accuracy require some qualification: ontology-based DLA tends to be liberal in its generation of lexical items, giving rise to over 20% more lexical items than the other methods (7,307 vs. 5-6000 for the other methods) and proportionately low type precision.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8915057182312012}, {"text": "precision", "start_pos": 270, "end_pos": 279, "type": "METRIC", "confidence": 0.9064545035362244}]}, {"text": "This correlates with an inherent advantage in terms of token accuracy, which we have noway of balancing up in our token-based evaluation, as the treebank data offers no insight into the true worth of false negative lexical items (i.e. have noway of distinguishing between unobserved lexical items which are plain wrong from those which are intuitively correct and could be expected to occur in alternate sets of treebank data).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9525893926620483}]}, {"text": "We leave investigation of the impact of these extra lexical items on the overall parser performance (in terms of chart complexity and parse selection) as an item for future research.", "labels": [], "entities": []}, {"text": "The morphology-based DLA methods were around baseline performance overall, with character n-grams marginally more successful than derivational morphology in terms of both type F-score and token accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.8378871083259583}]}, {"text": "Turning next to the results for the proposed methods over nouns, verbs, adjectives and adverbs, we observe some interesting effects.", "labels": [], "entities": []}, {"text": "First, morphology-based DLA hovers around baseline performance for all word classes except adjectives, where character n-grams produce the highest F-score of all methods, and nouns, where derivational morphology seems to aid DLA slightly (providing weak support for our original hypothesis in Section 3.2 relating to deverbal nouns and affixation).", "labels": [], "entities": [{"text": "F-score", "start_pos": 147, "end_pos": 154, "type": "METRIC", "confidence": 0.9957371950149536}]}, {"text": "Note: Base = baseline, M CHAR = morphology-based DLA with character n-grams, M DERIV = derivational morphology-based DLA, S POS = syntax-based DLA with POS tagging, S CHUNK = syntax-based DLA with chunking, S PARSE = syntax-based DLA with dependency parsing, and Ont = ontology-based DLA Syntax-based DLA leads to the highest type Fscore for nouns, verbs and adverbs, and the highest token accuracy for adjectives and adverbs.", "labels": [], "entities": [{"text": "DERIV", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9433072805404663}, {"text": "PARSE", "start_pos": 209, "end_pos": 214, "type": "METRIC", "confidence": 0.9130196571350098}, {"text": "Fscore", "start_pos": 331, "end_pos": 337, "type": "METRIC", "confidence": 0.7231072187423706}, {"text": "accuracy", "start_pos": 390, "end_pos": 398, "type": "METRIC", "confidence": 0.7748176455497742}]}, {"text": "The differential in results between syntax-based DLA and the other methods is particularly striking for adverbs, with a maximum type F-score of 0.544 (for chunker-based preprocessing) and token accuracy of 0.340 (for tagger-based preprocessing), as compared to baseline figures of 0.471 and 0.017 respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.6550347208976746}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.8617668151855469}]}, {"text": "There is relatively little separating the three styles of preprocessing in syntax-based DLA, although chunker-based preprocessing tends to have a slight edge in terms of type F-score, and tagger-based preprocessing generally produces the highest token accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 252, "end_pos": 260, "type": "METRIC", "confidence": 0.9242038130760193}]}, {"text": "11 This suggests that access to a POS tagger fora given language is sufficient to make syntaxbased DLA work, and that syntax-based DLA thus has moderately high applicability across languages of different densities.", "labels": [], "entities": []}, {"text": "Ontology-based DLA is below baseline in terms of type F-score for all word classes, but results in the highest token accuracy of all methods for nouns and verbs (although this finding must betaken with a grain of salt, as noted above).", "labels": [], "entities": [{"text": "Ontology-based DLA", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6260178983211517}, {"text": "F-score", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.6740968227386475}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9013428092002869}]}, {"text": "Another noteworthy feature of Figures 2-5 is the huge variation in absolute performance across the word classes: adjectives are very predictable, with a majority class-based baseline type F-score of 0.832 and token accuracy of 0.847; adverbs, on the other hand, are similar to verbs and nouns in terms of their baseline type F-score (at 0.471), but the adverbs that occur commonly in corpus data appear to belong to less-populated lexical types (as seen in the baseline token accuracy of a miniscule 0.017).", "labels": [], "entities": [{"text": "F-score", "start_pos": 188, "end_pos": 195, "type": "METRIC", "confidence": 0.7451887130737305}, {"text": "token accuracy", "start_pos": 209, "end_pos": 223, "type": "METRIC", "confidence": 0.6297132968902588}]}, {"text": "Nouns appear the hardest to learn in terms of the relative increment in token accuracy over the baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9567573070526123}]}, {"text": "Verbs are extremely difficult to get right at the type level, but it appears that ontology-based DLA is highly adept at getting the commonly-occurring lexical items right.", "labels": [], "entities": []}, {"text": "To summarise these findings, adverbs seem to benefit the most from syntax-based DLA.", "labels": [], "entities": []}, {"text": "Adjectives, on the other hand, can be learned most effectively from simple character n-grams, i.e. similarlyspelled adjectives tend to have similar syntax, a somewhat surprising finding.", "labels": [], "entities": []}, {"text": "Nouns are surprisingly hard to learn, but seem to benefit to some degree from corpus data and also ontological similarity.", "labels": [], "entities": []}, {"text": "Lastly, verbs pose a challenge to all methods at the type level, but ontology-based DLA seems to be able to correctly predict the commonly-occurring lexical entries.", "labels": [], "entities": []}, {"text": "Finally, we examine the impact of corpus size on the performance of syntax-based DLA with taggerbased preprocessing.", "labels": [], "entities": []}, {"text": "12 In, we examine the relative change in type F-score and token accuracy across the four word classes as we increase the corpus size (from 0.5m words to 1m and finally 100m words, in the form of the Brown corpus, WSJ corpus and BNC, respectively).", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.5884798765182495}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.858113706111908}, {"text": "Brown corpus", "start_pos": 199, "end_pos": 211, "type": "DATASET", "confidence": 0.9777656495571136}, {"text": "WSJ corpus", "start_pos": 213, "end_pos": 223, "type": "DATASET", "confidence": 0.880739837884903}, {"text": "BNC", "start_pos": 228, "end_pos": 231, "type": "DATASET", "confidence": 0.47926172614097595}]}, {"text": "For verbs and adjectives, there is almost no change in either type F-score or token accuracy when we increase the corpus size, whereas for nouns, the token accuracy actually drops slightly.", "labels": [], "entities": [{"text": "F-score", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.6783454418182373}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.5007970929145813}, {"text": "token accuracy", "start_pos": 150, "end_pos": 164, "type": "METRIC", "confidence": 0.6006428897380829}]}, {"text": "For adverbs, on the other hand, the token accuracy jumps up from 0.020 to 0.381 when we increase the corpus size from 1m words to 100m words, while the type F-score rises only slightly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9644140005111694}, {"text": "F-score", "start_pos": 157, "end_pos": 164, "type": "METRIC", "confidence": 0.7235099673271179}]}, {"text": "It thus seems to be the case that large corpora have a considerable impact on DLA for commonly-occurring adverbs, but that for the remaining word classes, it makes little difference whether we have 0.5m or 100m words.", "labels": [], "entities": []}, {"text": "This can be interpreted either as evidence that modestly-sized corpora are good enough to perform syntax-based DLA over (which would be excellent news for lowdensity languages!), or alternatively that for the simplistic syntax-based DLA methods proposed here, more corpus data is not the solution to achieving higher performance.", "labels": [], "entities": []}, {"text": "Returning to our original question of the \"bang for the buck\" associated with individual LRs, there seems to be no simple answer: simple word lists are useful in learning the syntax of adjectives in particular, but offer little in terms of learning the other three word classes.", "labels": [], "entities": []}, {"text": "Morphological lexicons with derivational information are moderately advantageous in learning the syntax of nouns but little else.", "labels": [], "entities": []}, {"text": "A POS tagger seems sufficient to carryout syntax-based DLA, and the word class which benefits the most from larger amounts of corpus data is adverbs, otherwise the proposed syntax-based DLA methods don't seem to benefit from larger-sized corpora.", "labels": [], "entities": []}, {"text": "Ontologies have the greatest impact on verbs and, to a lesser degree, nouns.", "labels": [], "entities": []}, {"text": "Ultimately, this seems to lend weight to a \"horses for courses\", or perhaps \"resources for courses\" approach to DLA.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Secondary LR and tool types targeted in this research (  *  *  *  = high expectation of availability for a  given language;  *  *  = medium expectation of availability;  *  = low expectation of availability)", "labels": [], "entities": []}, {"text": " Table 2: Feature types used in syntax-based DLA for the different preprocessors", "labels": [], "entities": []}]}