{"title": [{"text": "Temporal Feature Modification for Retrospective Categorization", "labels": [], "entities": [{"text": "Temporal Feature Modification", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8000045418739319}, {"text": "Retrospective Categorization", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.8922984004020691}]}], "abstractContent": [{"text": "We show that the intelligent use of one small piece of contextual information-a document's publication date-can improve the performance of classifiers trained on a text categorization task.", "labels": [], "entities": []}, {"text": "We focus on academic research documents , where the date of publication undoubtedly has an effect on an author's choice of words.", "labels": [], "entities": []}, {"text": "To exploit this contextual feature, we propose the technique of temporal feature modification , which takes various sources of lexical change into account, including changes in term frequency, associative strength between terms and categories, and dynamic categoriza-tion systems.", "labels": [], "entities": [{"text": "temporal feature modification", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.7106847961743673}]}, {"text": "We present results of classification experiments using both full text papers and abstracts of conference proceedings, showing improved classification accuracy across the whole collection, with performance increases of greater than 40% when temporal features are exploited.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9212521314620972}]}, {"text": "The technique is fast, classifier-independent, and works well even when making only a few modifications.", "labels": [], "entities": []}], "introductionContent": [{"text": "As they are normally conceived, many tasks relevant to Computational Linguistics (CL), such as text categorization, clustering, and information retrieval, ignore the context in which a document was written, focusing instead on the lexical content of the document.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7178546041250229}, {"text": "information retrieval", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.7564714550971985}]}, {"text": "Numerous improvements have been made in such tasks when context is considered, for example the hyperlink or citation structure of a document collection.", "labels": [], "entities": []}, {"text": "In this paper, we aim to show that the intelligent use of another dimension of context-a document's publication date-can improve the performance of classifiers trained on a text categorization task.", "labels": [], "entities": []}, {"text": "Traditional publications, such as academic papers and patents, have histories that span centuries.", "labels": [], "entities": []}, {"text": "The World Wide Web is no longer anew frontier; over a decade of its contents have been archived); Usenet and other electronic discussion boards have been around for several decades.", "labels": [], "entities": []}, {"text": "These forums continue to increase their publication rates and show no signs of slowing.", "labels": [], "entities": []}, {"text": "A cursory glance at anyone of them at two different points in time can reveal widely varying content.", "labels": [], "entities": []}, {"text": "For a concrete example, we can ask, \"What is Computational Linguistics about?\"", "labels": [], "entities": []}, {"text": "Some topics, such as machine translation, lie at the heart of the discipline and will always be of interest.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8783176243305206}]}, {"text": "Others are ephemeral or have reached theoretical upper bounds on performance.", "labels": [], "entities": []}, {"text": "It is thus more appropriate to ask what CL is about at some point in time.", "labels": [], "entities": [{"text": "ask what CL is about at some point in time", "start_pos": 31, "end_pos": 73, "type": "TASK", "confidence": 0.7360411167144776}]}, {"text": "Consider, which lists the top five unigrams that best distinguished the field at different sixyear periods, as derived from the odds ratio measure (see Section 3.2) over the full text of the ACL proceedings.", "labels": [], "entities": [{"text": "odds ratio measure", "start_pos": 128, "end_pos": 146, "type": "METRIC", "confidence": 0.9689027865727743}, {"text": "ACL proceedings", "start_pos": 191, "end_pos": 206, "type": "DATASET", "confidence": 0.8303675949573517}]}, {"text": "While these changes are interesting in their own right for an historical linguist, we aim to show that they can also be exploited for practical purposes.", "labels": [], "entities": []}, {"text": "We focus on a fairly homogeneous set of academic research documents, where the time of publication undoubtedly has an effect both on an author's choice of words and on a field's definition of underlying topical categories.", "labels": [], "entities": []}, {"text": "A document must say something novel while building upon what has already been said.", "labels": [], "entities": []}, {"text": "This dynamic generates a landscape of changing research language, where authors and disciplines constantly influence and alter the course of one another.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: ACL's most characteristic terms for four time  periods.", "labels": [], "entities": []}, {"text": " Table 3: Missing classification labels in ACM", "labels": [], "entities": [{"text": "ACM", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.7549684643745422}]}, {"text": " Table 4: Top parameter combinations for TFM by improvement in classification accuracy. Vocab frequency min. is  the minimum number of times a term must appear in the corpus in order to be included.", "labels": [], "entities": [{"text": "TFM", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8273913264274597}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9587274193763733}, {"text": "Vocab frequency min.", "start_pos": 88, "end_pos": 108, "type": "METRIC", "confidence": 0.9848634998003641}]}]}