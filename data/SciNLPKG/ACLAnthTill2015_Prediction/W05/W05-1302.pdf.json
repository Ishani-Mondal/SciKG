{"title": [{"text": "Adaptive String Similarity Metrics for Biomedical Reference Resolution", "labels": [], "entities": [{"text": "Adaptive String Similarity Metrics", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8099351972341537}, {"text": "Biomedical Reference Resolution", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.8503448963165283}]}], "abstractContent": [{"text": "In this paper we present the evaluation of a set of string similarity metrics used to resolve the mapping from strings to concepts in the UMLS MetaThesaurus.", "labels": [], "entities": [{"text": "UMLS MetaThesaurus", "start_pos": 138, "end_pos": 156, "type": "DATASET", "confidence": 0.9081977009773254}]}, {"text": "String similarity is conceived as a single component in a full Reference Resolution System that would resolve such a mapping.", "labels": [], "entities": [{"text": "Reference Resolution", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.7238741666078568}]}, {"text": "Given this qualification, we obtain positive results achieving 73.6 F-measure (76.1 precision and 71.4 recall) for the task of assigning the correct UMLS concept to a given string.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9577715992927551}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9532521963119507}, {"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.9558860063552856}]}, {"text": "Our results demonstrate that adaptive string similarity methods based on Conditional Random Fields outperform standard metrics in this domain .", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We used the UMLS MetaThesaurus for all our experiments for three reasons: 1) the UMLS represents a wide-range of important biomedical concepts for many applications and 2) the size of the UMLS (compared with BioCreative Task 1B, for example) promotes statistically significant results as well as sufficient training data 3) the problem of ambiguity (multiple concepts with the same name) is largely absent in the UMLS.", "labels": [], "entities": [{"text": "UMLS MetaThesaurus", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.8630775809288025}]}, {"text": "The UMLS is a taxonomy of medical and clinical concepts consisting of 1,938,701 lexical entries (phrase strings) where each entry belongs to one (or, in very rarely, more than one) of 887,688 concepts.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8833703994750977}]}, {"text": "We prepared the data by first selecting only those lexical entries belonging to a concept containing 12 or more entries.", "labels": [], "entities": []}, {"text": "This resulted in a total of 129,463 entries belonging to 7,993 concepts.", "labels": [], "entities": []}, {"text": "We then divided this data into a training set of 95,167 entries and test set of 34,296 entries where roughly 70% of the entries for each concept were placed in the training set and 30% in the test set.", "labels": [], "entities": []}, {"text": "Thus, the training set and test set both contained some string entries for each of the 7,993 concepts.", "labels": [], "entities": []}, {"text": "While restricting the number of entries to 12 or more was somewhat arbitrary, this allowed for at least 7 (70% of 12) entries in the training data for each concept, providing sufficient training data.", "labels": [], "entities": []}, {"text": "The task was to assign the correct concept identifier to each of the lexical entries in the test set.", "labels": [], "entities": []}, {"text": "This was carried out by finding the most similar string entry in the training data and returning the concept identifier associated with that entry.", "labels": [], "entities": []}, {"text": "Since each test instance must be assigned to exactly one concept, our system simply ranked the candidate strings  above . The SoftTFIDF-Lev model is the Soft-TFIDF metric described earlier where the secondary metric for similarity between pairs of tokens is the Levenstein distance.", "labels": [], "entities": []}, {"text": "The CRF metric is the CRF string similarity model applied to the entire strings.", "labels": [], "entities": []}, {"text": "This model was trained on pairs of strings that belonged to the same concept in the training data, resulting in 130,504 string pair training instances.", "labels": [], "entities": []}, {"text": "The SoftTFIDF-CRF metric is the SoftTFIDF method where the secondary metric is the CRF string similarity model.", "labels": [], "entities": []}, {"text": "This CRF model was trained on pairs of tokens (not entire phrases).", "labels": [], "entities": []}, {"text": "We derived pairs of tokens by finding the most similar pairs of tokens (similarity was determined hereby Levenstein distance) between strings belonging to the same concept in the training data.", "labels": [], "entities": [{"text": "Levenstein distance)", "start_pos": 105, "end_pos": 125, "type": "METRIC", "confidence": 0.8450936476389567}]}, {"text": "This resulted in 336,930 string pairs as training instances.", "labels": [], "entities": []}], "tableCaptions": []}