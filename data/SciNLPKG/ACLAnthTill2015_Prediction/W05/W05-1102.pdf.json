{"title": [{"text": "Evaluating and Integrating Treebank Parsers on a Biomedical Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "It is not clear a priori how well parsers trained on the Penn Treebank will parse significantly different corpora without retraining.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 57, "end_pos": 70, "type": "DATASET", "confidence": 0.9932830929756165}]}, {"text": "We carried out a competitive evaluation of three leading tree-bank parsers on an annotated corpus from the human molecular biology domain , and on an extract from the Penn Treebank for comparison, performing a detailed analysis of the kinds of errors each parser made, along with a quantitative comparison of syntax usage between the two corpora.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 167, "end_pos": 180, "type": "DATASET", "confidence": 0.9962944686412811}]}, {"text": "Our results suggest that these tools are becoming somewhat over-specialised on their training domain at the expense of portability, but also indicate that some of the errors encountered are of doubtful importance for information extraction tasks.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 217, "end_pos": 245, "type": "TASK", "confidence": 0.8914026618003845}]}, {"text": "Furthermore, our inital experiments with unsupervised parse combination techniques showed that integrating the output of several parsers can ameliorate some of the performance problems they encounter on unfamiliar text, providing accuracy and coverage improvements, and a novel measure of trustworthiness.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 230, "end_pos": 238, "type": "METRIC", "confidence": 0.9974159002304077}]}, {"text": "Supplementary materials are available at http://textmining.cryst.bbk.", "labels": [], "entities": []}], "introductionContent": [{"text": "The availability of large-scale syntacticallyannotated corpora in general, and the Penn Treebank 1 (PTB; in particular, has enabled the field of stochastic parsing to advance rapidly over the course of the last 10-15 years.", "labels": [], "entities": [{"text": "Penn Treebank 1 (PTB", "start_pos": 83, "end_pos": 103, "type": "DATASET", "confidence": 0.9453293919563294}, {"text": "stochastic parsing", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.6976926028728485}]}, {"text": "However, the newspaper English which makes up the bulk of the PTB is only one of many distinct genres of writing in the Anglophone world, and certainly not the only domain where potential natural-language processing (NLP) applications exist that would benefit from robust and reliable syntactic analysis.", "labels": [], "entities": [{"text": "PTB", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8178846836090088}]}, {"text": "Due to the massive glut of published literature, the biomedical sciences in general, and molecular biology in particular, constitute one such domain, and indeed much attention has been focused recently on NLP in this area.", "labels": [], "entities": []}, {"text": "Unfortunately, annotated corpora of a large enough size to retrain stochastic parsers on do not exist in this domain, and are unlikely to for sometime.", "labels": [], "entities": []}, {"text": "This is partially due to the same differences of vocabulary and usage that set biomedical English apart from the Wall Street Journal in the first place; these differences necessitate the input of both biological and linguistic knowledge on biological corpus annotation projects (), and thus require a wider variety of annotator skills than general-English projects.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 113, "end_pos": 132, "type": "DATASET", "confidence": 0.9070545633633932}]}, {"text": "For example, 5 (pronounced \"five-prime\") is an adjective in molecular biology, but p53 is a noun; amino acid is an adjective-noun sequence 2 but cadmium chloride is a pair of nouns.", "labels": [], "entities": []}, {"text": "These tagging decisions would be hard to make correctly without biological background knowledge, as would the prepositional phrase attachment decisions in.", "labels": [], "entities": [{"text": "prepositional phrase attachment", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.7076456149419149}]}, {"text": "Although it is intuitively apparent that there are differences between newspaper English and biomedical English, and that these differences are quantifiable enough for biomedical writing to be characterised as a sublanguage of English (), the performance of conventionally-trained parsers on data from this domain is to a large extent an open question.", "labels": [], "entities": []}, {"text": "Nonetheless, papers have begun to appear which employ treebank parsers on biomedical text, essentially untested (.", "labels": [], "entities": []}, {"text": "Recently, however, the GENIA project ( and the Mining the Bibliome project () have begun producing small draft corpora of biomedical journal paper abstracts with PTB-style syntactic bracketing, as well as named-entity and part-of-speech (POS) tags.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8816709518432617}, {"text": "PTB-style syntactic bracketing", "start_pos": 162, "end_pos": 192, "type": "TASK", "confidence": 0.5796471238136292}]}, {"text": "These are not currently on a scale appropriate for retraining parsers (compare the \u223c50,000 words in the GENIA Treebank to the \u223c1,000,000 in the PTB; but see also Section 7.2) but can provide a sound basis for empirical performance evaluation and analysis.", "labels": [], "entities": [{"text": "GENIA Treebank", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.9860980808734894}, {"text": "PTB", "start_pos": 144, "end_pos": 147, "type": "DATASET", "confidence": 0.9693924188613892}]}, {"text": "A collection of methods for performing such an analysis, along with several interesting results and an investigation into techniques for narrowing the performance gap, is presented here.", "labels": [], "entities": []}], "datasetContent": [{"text": "We initially chose to rate the parsers in our assessment by several different means which can be grouped into two broad classes: constituentand lineage-based.", "labels": [], "entities": []}, {"text": "While showed that there is a limited degree of correlation between the per-sentence scores assigned by the two methods, they are independent enough that a fuller picture of parser competence can be built up by combining them and thus sidestepping the drawbacks of either approach.", "labels": [], "entities": []}, {"text": "However, overall performance scores designed for competitively evaluating parsers do not provide much insight into the aetiology of errors and anomalies, so we developed a third approach based on production rules that enabled us to mine the megabytes of syntactic data for enlightening results more ef- Figure 1: These two sentences are biologically clear but syntactically ambiguous.", "labels": [], "entities": []}, {"text": "Only the knowledge that the C-terminal domain is part of a protein, whereas the TATA box and minor groove are parts of DNA, allows a human to interpret them correctly, by attaching the prepositional phrases 1 and 2 at the right level. fectively.", "labels": [], "entities": [{"text": "TATA", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9382278323173523}]}, {"text": "All the Perl scoring routines we wrote are available from our website.", "labels": [], "entities": [{"text": "Perl scoring", "start_pos": 8, "end_pos": 20, "type": "TASK", "confidence": 0.6345432102680206}]}], "tableCaptions": [{"text": " Table 1: Production and production rule usage in the two corpora.", "labels": [], "entities": []}, {"text": " Table 2: The most common production rules in the two corpora, in order, with the frequency of occur- rence of each. Notice that several rules are much more common in one corpus than the other, such as VP  \u2192 TO VP, which is the 11th most common rule in the PTB but doesn't make it into GENIA's list.", "labels": [], "entities": [{"text": "occur- rence", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.8241032560666403}, {"text": "PTB", "start_pos": 257, "end_pos": 260, "type": "DATASET", "confidence": 0.9262557029724121}, {"text": "GENIA's list", "start_pos": 286, "end_pos": 298, "type": "DATASET", "confidence": 0.9052853584289551}]}, {"text": " Table 3: Initial performance comparison.", "labels": [], "entities": []}, {"text": " Table 4: Performance scores, discounting all parse failures. Scores for the Charniak parser, and Collins  model 1 on the PTB, are shown again for comparison, although they did not fail on any sentences.", "labels": [], "entities": [{"text": "PTB", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.8868710398674011}]}, {"text": " Table 5: Ensemble scores on GENIA for Collins(3, 2, 1)\u2192Charniak and Bikel(0.9.9, 0.9.8)\u2192Charniak  fallback cascades.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.8993203043937683}, {"text": "Collins", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.898206353187561}]}, {"text": " Table 6: Ensemble scores on GENIA for parse combination by majority constituent voting.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9271917343139648}, {"text": "parse combination", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.9780236184597015}]}, {"text": " Table 7: Ensemble scores on GENIA for parse selection by three centroid-distance algorithms", "labels": [], "entities": [{"text": "GENIA", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9403923153877258}, {"text": "parse selection", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.9036044776439667}]}]}