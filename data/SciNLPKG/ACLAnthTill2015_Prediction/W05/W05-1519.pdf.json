{"title": [{"text": "Exploring Features for Identifying Edited Regions in Disfluent Sentences", "labels": [], "entities": [{"text": "Identifying Edited Regions in Disfluent Sentences", "start_pos": 23, "end_pos": 72, "type": "TASK", "confidence": 0.8506101369857788}]}], "abstractContent": [{"text": "This paper describes our effort on the task of edited region identification for parsing disfluent sentences in the Switchboard corpus.", "labels": [], "entities": [{"text": "edited region identification", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.6264774203300476}, {"text": "parsing disfluent sentences", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.89812699953715}, {"text": "Switchboard corpus", "start_pos": 115, "end_pos": 133, "type": "DATASET", "confidence": 0.7856692671775818}]}, {"text": "We focus our attention on exploring feature spaces and selecting good features and start with analyzing the distributions of the edited regions and their components in the targeted corpus.", "labels": [], "entities": []}, {"text": "We explore new feature spaces of a part-of-speech (POS) hierarchy and relaxed for rough copy in the experiments.", "labels": [], "entities": []}, {"text": "These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data [Charniak and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004].", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 55, "end_pos": 79, "type": "METRIC", "confidence": 0.7180362343788147}, {"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9808489680290222}, {"text": "F-score", "start_pos": 278, "end_pos": 285, "type": "METRIC", "confidence": 0.9731751084327698}]}], "introductionContent": [{"text": "Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena.", "labels": [], "entities": [{"text": "restarts", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.7746931314468384}]}, {"text": "Processing speech repairs properly poses a challenge to spoken dialog systems.", "labels": [], "entities": [{"text": "Processing speech repairs", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7429773807525635}]}, {"text": "Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult.", "labels": [], "entities": []}, {"text": "Because of the availability of the Switchboard corpus and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 35, "end_pos": 53, "type": "DATASET", "confidence": 0.8024393320083618}, {"text": "parsing disfluent sentences", "start_pos": 216, "end_pos": 243, "type": "TASK", "confidence": 0.9044298926989237}]}, {"text": "In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus.", "labels": [], "entities": [{"text": "edited region identification", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.6226874788602194}, {"text": "parsing disfluent sentences", "start_pos": 108, "end_pos": 135, "type": "TASK", "confidence": 0.8953621784845988}, {"text": "Switchboard corpus", "start_pos": 143, "end_pos": 161, "type": "DATASET", "confidence": 0.8044010698795319}]}, {"text": "A clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9788334965705872}, {"text": "parsing conversational speech", "start_pos": 110, "end_pos": 139, "type": "TASK", "confidence": 0.8816509445508321}]}, {"text": "Since different machine learning methods provide similar performances on many NLP tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions.", "labels": [], "entities": []}, {"text": "We start by analyzing the distributions of the edited regions and their components in the targeted corpus.", "labels": [], "entities": []}, {"text": "We then design several feature spaces to cover the disfluent regions in the training data.", "labels": [], "entities": []}, {"text": "In addition, we also explore new feature spaces of a part-of-speech hierarchy and extend candidate pools in the experiments.", "labels": [], "entities": []}, {"text": "These steps result in a significant improvement in F-score over the earlier best result reported in, where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result, where punctuation is ignored in both the training and testing data of the Switchboard corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9990026354789734}, {"text": "Switchboard corpus", "start_pos": 176, "end_pos": 194, "type": "DATASET", "confidence": 0.8064976036548615}, {"text": "F-score", "start_pos": 233, "end_pos": 240, "type": "METRIC", "confidence": 0.9975753426551819}, {"text": "Switchboard corpus", "start_pos": 344, "end_pos": 362, "type": "DATASET", "confidence": 0.8897871375083923}]}, {"text": "In this paper, we follow the definition of and others for speech repairs: A speech repair is divided into three parts: the reparandum, the part that is repaired; the interregnum, the part that can be either empty or fillers; and the repair/repeat, the part that replaces or repeats the reparandum.", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7427521497011185}, {"text": "speech repair", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.7052965611219406}, {"text": "interregnum", "start_pos": 166, "end_pos": 177, "type": "METRIC", "confidence": 0.9519929885864258}]}, {"text": "The definition can also be exemplified via the following utterance: , this is a big problem.", "labels": [], "entities": []}, {"text": "This is you know \ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59 \ud97b\udf59 This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we examine the distributions of the editing regions in Switchboard data.", "labels": [], "entities": [{"text": "Switchboard data", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.8646503984928131}]}, {"text": "Section 3, then, presents the Boosting method, the baseline system and the feature spaces we want to explore.", "labels": [], "entities": []}, {"text": "Section 4 describes, step by step, a set of experiments that lead to a large performance improvement.", "labels": [], "entities": []}, {"text": "Section 5 concludes with discussion and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted a number of experiments to test the effectiveness of our feature space exploration.", "labels": [], "entities": [{"text": "feature space exploration", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6398443877696991}]}, {"text": "Since the original code from is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3.", "labels": [], "entities": []}, {"text": "We used the exactly same training and testing data from the Switchboard corpus as in.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.9107889235019684}]}, {"text": "The training subset consists of all files in the sections 2 and 3 of the Switchboard corpus.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 73, "end_pos": 91, "type": "DATASET", "confidence": 0.8191182017326355}]}, {"text": "Section 4 is split into three approximately equal size subsets.", "labels": [], "entities": []}, {"text": "The first of the three, i.e., files sw4004.mrg to sw4153.mrg, is the testing corpus.", "labels": [], "entities": []}, {"text": "The files sw4519.mrg to sw4936.mrg are the development corpus.", "labels": [], "entities": []}, {"text": "The rest files are reserved for other purposes.", "labels": [], "entities": []}, {"text": "When punctuation is included in both training and testing, the re-established baseline has the precision, recall, and F-score of 94.73%, 68.71% and 79.65%, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9998291730880737}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9990770816802979}, {"text": "F-score", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.999778687953949}]}, {"text": "These results are comparable with the results from, i.e., 95.2%, 67.8%, and 79.2% for precision, recall, and f-score, correspondingly.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9996860027313232}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9990705847740173}, {"text": "f-score", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.995963454246521}]}, {"text": "In the subsequent experiments, the set of additional feature spaces described in section 3 are added, step-by-step.", "labels": [], "entities": []}, {"text": "The first addition includes the shortest distance to the same word and window size increases.", "labels": [], "entities": []}, {"text": "This step gives a 2.27% improvement on F-score over the baseline.", "labels": [], "entities": [{"text": "F-score", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.9996539354324341}]}, {"text": "The next addition is the introduction of the POS hierarchy in finding rough copies.", "labels": [], "entities": []}, {"text": "This also gives more than 3% absolute improvement over the baseline and 1.19% over the expanded feature set model.", "labels": [], "entities": [{"text": "absolute", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9661397337913513}]}, {"text": "The addition of the feature spaces of relaxed matches for words, POS tags, and POS hierarchy tags all give additive improvements, which leads to an overall of 8.95% absolute improvement over the re-implemented baseline, or 43.98% relative error reduction on F-score.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 239, "end_pos": 254, "type": "METRIC", "confidence": 0.8787284195423126}, {"text": "F-score", "start_pos": 258, "end_pos": 265, "type": "METRIC", "confidence": 0.9573837518692017}]}, {"text": "When compared with the latest results from, where no punctuations are used for either training or testing data, we also observe the same trend of the improved results.", "labels": [], "entities": []}, {"text": "Our best result gives 4.15% absolute improvement over their best result, or 20.44% relative error reduction in f-scores.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 83, "end_pos": 107, "type": "METRIC", "confidence": 0.8023526867230734}]}, {"text": "As a sanity check, when evaluated on the training data as a cheating experiment, we show a remarkable consistency with the results for testing data.", "labels": [], "entities": [{"text": "consistency", "start_pos": 102, "end_pos": 113, "type": "METRIC", "confidence": 0.9676284193992615}]}, {"text": "For error analysis, we randomly selected 100 sentences with 1673 words total from the test sentences that have at least one mistake.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6679956018924713}]}, {"text": "Errors can be divided into two types, miss (should be edited) and false alarm (should be noraml).", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7111908197402954}, {"text": "miss", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9945382475852966}, {"text": "false alarm", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.931604266166687}, {"text": "noraml", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9184799790382385}]}, {"text": "Among the 207 misses, about 70% of them require some phrase level analysis or acoustic cues for phrases.", "labels": [], "entities": []}, {"text": "For example, one miss is \"because of the friends because of many other things\", an error we would have a much better chance of correct identification, if we were able to identify prepositional phrases reliably.", "labels": [], "entities": []}, {"text": "Another example is \"most of all my family\".", "labels": [], "entities": []}, {"text": "Since it is grammatical by itself, certain prosodic information in between \"most of\" and \"all my family\" may help the identification.", "labels": [], "entities": [{"text": "identification", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.9604595899581909}]}, {"text": "[ reported that interruption point could help parsers to improve results.", "labels": [], "entities": []}, {"text": "also showed that prosody information could help parse disfluent sentences.", "labels": [], "entities": [{"text": "parse disfluent sentences", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.8811478416124979}]}, {"text": "The second major class of the misses is certain short words that are not labeled consistently in the corpus.", "labels": [], "entities": []}, {"text": "For example, \"so\", \"and\", and \"or\", when they occur in the beginning of a sentence, are sometimes labeled as edited, and sometimes just as normal.", "labels": [], "entities": []}, {"text": "The last category of the misses, about 5.3%, contains the ones where the distances between reparanda and repairs are often more than 10 words.", "labels": [], "entities": [{"text": "misses", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9535982012748718}]}, {"text": "Among the 95 false alarms, more than three quarters of misclassified ones are related to certain grammatical constructions.", "labels": [], "entities": []}, {"text": "Examples include cases like, \"the more \u2026 the more\" and \"I think I should \u2026\".", "labels": [], "entities": []}, {"text": "These cases maybe fixable if more elaborated grammar-based features are used.", "labels": [], "entities": []}, {"text": "distributional analysis for the edited regions, a number of feature spaces have been explored and tested to show their effectiveness.", "labels": [], "entities": []}, {"text": "We observed a 43.98% relative error reduction on F-scores for the baseline with punctuation in both training and testing.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 21, "end_pos": 45, "type": "METRIC", "confidence": 0.7858797411123911}, {"text": "F-scores", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9887829422950745}, {"text": "punctuation", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9723432064056396}]}, {"text": "Compared with the reported best result, the same approach produced a 20.44% of relative error reduction on F-scores when punctuation is ignored in training and testing data.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 79, "end_pos": 103, "type": "METRIC", "confidence": 0.7767592867215475}, {"text": "F-scores", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9767898917198181}]}, {"text": "The inclusion of both hierarchical POS tags and the relaxation for rough copy definition gives large additive improvements, and their combination has contributed to nearly half of the gain for the test set with punctuation and about 60% of the gain for the data without punctuation.", "labels": [], "entities": [{"text": "rough copy definition", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.5691835085550944}]}], "tableCaptions": [{"text": " Table 2. Result summary for various feature spaces.", "labels": [], "entities": []}, {"text": " Table 3. Description of method codes used in the result table.", "labels": [], "entities": []}]}