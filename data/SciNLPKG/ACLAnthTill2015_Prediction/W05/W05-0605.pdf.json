{"title": [], "abstractContent": [{"text": "Traditionally, word sense disambiguation (WSD) involves a different context classification model for each individual word.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.8402775029341379}]}, {"text": "This paper presents a weakly supervised learning approach to WSD based on learning a word independent context pair classification model.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9904478788375854}, {"text": "word independent context pair classification", "start_pos": 85, "end_pos": 129, "type": "TASK", "confidence": 0.5957536995410919}]}, {"text": "Statistical models are not trained for classifying the word contexts, but for classifying a pair of contexts, i.e. determining if a pair of contexts of the same ambiguous word refers to the same or different senses.", "labels": [], "entities": []}, {"text": "Using this approach, annotated corpus of a target word A can be explored to disambiguate senses of a different word B.", "labels": [], "entities": []}, {"text": "Hence, only a limited amount of existing annotated corpus is required in order to disambiguate the entire vocabulary.", "labels": [], "entities": []}, {"text": "In this research, maximum en-tropy modeling is used to train the word independent context pair classification model.", "labels": [], "entities": [{"text": "word independent context pair classification", "start_pos": 65, "end_pos": 109, "type": "TASK", "confidence": 0.6562074601650238}]}, {"text": "Then based on the context pair classification results, clustering is performed on word mentions extracted from a large raw corpus.", "labels": [], "entities": [{"text": "context pair classification", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.647523025671641}]}, {"text": "The resulting context clusters are mapped onto the external thesaurus WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.9580799341201782}]}, {"text": "This approach shows great flexibility to efficiently integrate heterogeneous knowledge sources, e.g. trigger words and parsing structures.", "labels": [], "entities": []}, {"text": "Based on Senseval-3 Lexical Sample standards , this approach achieves state-of-the-art performance in the unsupervised learning category, and performs comparably with the supervised Na\u00efve Bayes system.", "labels": [], "entities": []}, {"text": "c M K, c s s > then set { } { } M K M K , , 0 = } } output { } 0 , M K as the optimal state.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is one of the central problems in Natural Language Processing.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7893424878517786}, {"text": "Natural Language Processing", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6363138655821482}]}, {"text": "The difficulty of this task lies in the fact that context features and the corresponding statistical distribution are different for each individual word.", "labels": [], "entities": []}, {"text": "Traditionally, WSD involves training the context classification models for each ambiguous word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9887195229530334}, {"text": "context classification", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.7476920187473297}]}, {"text": "() uses the Na\u00efve Bayes method for context classification which requires a manually annotated corpus for each ambiguous word.", "labels": [], "entities": [{"text": "context classification", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7648324072360992}]}, {"text": "This causes a serious Knowledge Bottleneck.", "labels": [], "entities": [{"text": "Knowledge Bottleneck", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.8404617607593536}]}, {"text": "The bottleneck is particularly serious when considering the domain dependency of word senses.", "labels": [], "entities": []}, {"text": "To overcome the Knowledge Bottleneck, unsupervised or weakly supervised learning approaches have been proposed.", "labels": [], "entities": []}, {"text": "These include the bootstrapping approach and the context clustering approach).", "labels": [], "entities": [{"text": "context clustering", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7150349318981171}]}, {"text": "The above unsupervised or weakly supervised learning approaches are less subject to the Knowledge Bottleneck.", "labels": [], "entities": [{"text": "Knowledge Bottleneck", "start_pos": 88, "end_pos": 108, "type": "DATASET", "confidence": 0.8560592830181122}]}, {"text": "For example, only requires sense number and a few seeds for each sense of an ambiguous word (hereafter called keyword).", "labels": [], "entities": []}, {"text": "(Sch\u00fctze 1998) may only need minimal annotation to map the resulting context clusters onto external thesaurus for benchmarking and application-related purposes.", "labels": [], "entities": []}, {"text": "Both methods are based on trigger words only.", "labels": [], "entities": []}, {"text": "This paper presents a novel approach based on learning word-independent context pair classification model.", "labels": [], "entities": [{"text": "learning word-independent context pair classification", "start_pos": 46, "end_pos": 99, "type": "TASK", "confidence": 0.5848615825176239}]}, {"text": "This idea maybe traced back to) where context clusters based on generic Euclidean distance are regarded as distinct word senses.", "labels": [], "entities": []}, {"text": "Different from (Sch\u00fctze 1998), we observe that generic context clusters may not always correspond to distinct word senses.", "labels": [], "entities": []}, {"text": "Therefore, we used supervised machine learning to model the relationships between the context distinctness and the sense distinctness.", "labels": [], "entities": []}, {"text": "Although supervised machine learning is used for the context pair classification model, our overall system belongs to the weakly supervised category because the learned context pair classification", "labels": [], "entities": [{"text": "context pair classification", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6632105310757955}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. New Algorithm Using Only Trigger Words  Accuracy  Category  Fine grain (%) Coarse grain (%)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9911203980445862}]}, {"text": " Table 2. Supervised Na\u00efve Bayes System  Accuracy  Category  Fine grain (%) Coarse grain (%)  Adjective (5)  44.7  56.6  Noun (20)  66.3  74.5  Verb (32)  58.6  70.0  Overall  61.6  71.5", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9847877025604248}, {"text": "Verb", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9578875303268433}]}, {"text": " Table 3. New Algorithm Using Both Trigger Words and  Parsing  Accuracy  Category  Fine grain (%) Coarse grain (%)  Adjective (5)  49.1  64.8  Noun (20)  57.9  66.6  Verb (32)  55.3  66.3  Overall  56.3  66.4", "labels": [], "entities": []}]}