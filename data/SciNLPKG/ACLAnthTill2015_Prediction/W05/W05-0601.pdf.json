{"title": [{"text": "Effective use of WordNet semantics via kernel-based learning", "labels": [], "entities": []}], "abstractContent": [{"text": "Research on document similarity has shown that complex representations are not more accurate than the simple bag-of-words.", "labels": [], "entities": [{"text": "document similarity", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7010505348443985}]}, {"text": "Term clustering, e.g. using latent semantic indexing, word co-occurrences or synonym relations using a word ontol-ogy have been shown not very effective.", "labels": [], "entities": [{"text": "Term clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8060435950756073}]}, {"text": "In particular, when to extend the similarity function external prior knowledge is used, e.g. WordNet, the retrieval system decreases its performance.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9568783640861511}]}, {"text": "The critical issues here are methods and conditions to integrate such knowledge.", "labels": [], "entities": []}, {"text": "In this paper we propose kernel functions to add prior knowledge to learning algorithms for document classification.", "labels": [], "entities": [{"text": "document classification", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.7584611773490906}]}, {"text": "Such kernels use a term similarity measure based on the WordNet hierarchy.", "labels": [], "entities": [{"text": "WordNet hierarchy", "start_pos": 56, "end_pos": 73, "type": "DATASET", "confidence": 0.9394447505474091}]}, {"text": "The kernel trick is used to implement such space in a balanced and statistically coherent way.", "labels": [], "entities": []}, {"text": "Cross-validation results show the benefit of the approach for the Support Vector Machines when few training data is available.", "labels": [], "entities": []}], "introductionContent": [{"text": "The large literature on term clustering, term similarity and weighting schemes shows that document similarity is a central topic in Information Retrieval (IR).", "labels": [], "entities": [{"text": "term clustering", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.6395906656980515}, {"text": "Information Retrieval (IR)", "start_pos": 132, "end_pos": 158, "type": "TASK", "confidence": 0.8574256062507629}]}, {"text": "The research efforts have mostly been directed in enriching the document representation by using clustering (term generalization) or adding compounds (term specifications).", "labels": [], "entities": []}, {"text": "These studies are based on the assumption that the similarity between two documents can be expressed as the similarity between pairs of matching terms.", "labels": [], "entities": []}, {"text": "Following this idea, term clustering methods based on corpus term distributions or on external prior knowledge (e.g. provided by WordNet) were used to improve the basic term matching.", "labels": [], "entities": [{"text": "term clustering", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7498349845409393}, {"text": "WordNet", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.948503851890564}, {"text": "term matching", "start_pos": 169, "end_pos": 182, "type": "TASK", "confidence": 0.7353371977806091}]}, {"text": "An example of statistical clustering is given in (.", "labels": [], "entities": [{"text": "statistical clustering", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7784683406352997}]}, {"text": "A feature selection technique, which clusters similar features/words, called the Information Bottleneck (IB), was applied to Text Categorization (TC).", "labels": [], "entities": [{"text": "Text Categorization (TC)", "start_pos": 125, "end_pos": 149, "type": "TASK", "confidence": 0.8561055123806}]}, {"text": "Such cluster based representation outperformed the simple bag-of-words on only one out of the three experimented collections.", "labels": [], "entities": []}, {"text": "The effective use of external prior knowledge is even more difficult since no attempt has ever been successful to improve document retrieval or text classification accuracy, (e.g. see).", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7270653247833252}, {"text": "text classification", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.7412342131137848}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.7974692583084106}]}, {"text": "The main problem of term cluster based representations seems the unclear nature of the relationship between the word and the cluster information levels.", "labels": [], "entities": []}, {"text": "Even if (semantic) clusters tend to improve the system recall, simple terms are, on a large scale, more accurate (e.g. ().", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9953429698944092}]}, {"text": "To overcome this problem, hybrid spaces containing terms and clusters were experimented (e.g.) but the results, again, showed that the mixed statistical distributions of clusters and terms impact either marginally or even negatively on the overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 248, "end_pos": 256, "type": "METRIC", "confidence": 0.998174786567688}]}, {"text": "In), clusters of synonymous terms as defined in WordNet (WN) were used for document retrieval.", "labels": [], "entities": [{"text": "WordNet (WN)", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.87928806245327}, {"text": "document retrieval", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.7725531160831451}]}, {"text": "The results showed that the misleading information due to the wrong choice of the local term senses causes the overall accuracy to decrease.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9994441866874695}]}, {"text": "Word sense disambiguation (WSD) was thus applied beforehand by indexing the documents by means of disambiguated senses, i.e. synset codes).", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7542365193367004}]}, {"text": "However, even the state-of-the-art methods for WSD did not improve the accuracy because of the inherent noise introduced by the disambiguation mistakes.", "labels": [], "entities": [{"text": "WSD", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.978404700756073}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9993945360183716}]}, {"text": "The above studies suggest that term clusters decrease the precision of the system as they force weakly related or unrelated (in case of disambiguation errors) terms to give a contribution in the similarity function.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9989811778068542}]}, {"text": "The successful introduction of prior external knowledge relies on the solution of the above problem.", "labels": [], "entities": []}, {"text": "In this paper, a model to introduce the semantic lexical knowledge contained in the WN hierarchy in a supervised text classification task has been proposed.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 113, "end_pos": 137, "type": "TASK", "confidence": 0.7873891790707906}]}, {"text": "Intuitively, the main idea is that the documents dare represented through the set of all pairs in the vocabulary < t, t >\u2208 V \u00d7 V originating by the terms t \u2208 d and all the words t \u2208 V , e.g. the WN nouns.", "labels": [], "entities": []}, {"text": "When the similarity between two documents is evaluated, their matching pairs are used to account for the final score.", "labels": [], "entities": []}, {"text": "The weight given to each term pair is proportional to the similarity that the two terms have in WN.", "labels": [], "entities": []}, {"text": "Thus, the term t of the first document contributes to the document similarity according to its relatedness with any of the terms of the second document and the prior external knowledge, provided by WN, quantifies the single term to term relatedness.", "labels": [], "entities": [{"text": "WN", "start_pos": 198, "end_pos": 200, "type": "DATASET", "confidence": 0.84366774559021}]}, {"text": "Such approach has two advantages: (a) we obtain a well defined space which supports the similarity between terms of different surface forms based on external knowledge and (b) we avoid to explicitly define term or sense clusters which inevitably introduce noise.", "labels": [], "entities": []}, {"text": "The class of spaces which embeds the above pair information maybe composed by O(|V | 2 ) dimensions.", "labels": [], "entities": []}, {"text": "If we consider only the WN nouns (about 10 5 ), our space contains about 10 10 dimensions which is not manageable by most of the learning algorithms.", "labels": [], "entities": []}, {"text": "Kernel methods, can solve this problem as they allow us to use an implicit space representation in the learning algorithms.", "labels": [], "entities": []}, {"text": "Among them Support Vector Machines (SVMs) are kernel based learners which achieve high accuracy in presence of many irrelevant features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9970611929893494}]}, {"text": "This is another important property as selection of the informative pairs is left to the SVM learning.", "labels": [], "entities": []}, {"text": "Moreover, as we believe that the prior knowledge in TC is not so useful when there is a sufficient amount of training documents, we experimented our model in poor training conditions (e.g. less equal than 20 documents for each category).", "labels": [], "entities": [{"text": "TC", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9578296542167664}]}, {"text": "The improvements in the accuracy, observed on the classification of the well known Reuters and 20 NewsGroups corpora, show that our document similarity model is very promising for general IR tasks: unlike previous attempts, it makes sense of the adoption of semantic external resources (i.e. WN) in IR.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9995850920677185}, {"text": "Reuters and 20 NewsGroups corpora", "start_pos": 83, "end_pos": 116, "type": "DATASET", "confidence": 0.9037315249443054}, {"text": "IR tasks", "start_pos": 188, "end_pos": 196, "type": "TASK", "confidence": 0.9007657766342163}]}, {"text": "Section 2 introduces the WordNet-based term similarity.", "labels": [], "entities": [{"text": "WordNet-based term similarity", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.636139969031016}]}, {"text": "Section 3 defines the new document similarity measure, the kernel function and its use within SVMs.", "labels": [], "entities": []}, {"text": "Section 4 presents the comparative results between the traditional linear and the WN-based kernels within SVMs.", "labels": [], "entities": []}, {"text": "In Section 5 comparative discussion against the related IR literature is carried out.", "labels": [], "entities": [{"text": "IR", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.967803955078125}]}, {"text": "Finally Section 6 derives the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The use of WordNet (WN) in the term similarity function introduces a prior knowledge whose impact on the Semantic Kernel (SK) should be experimentally assessed.", "labels": [], "entities": []}, {"text": "The main goal is to compare the traditional Vector Space Model kernel against SK, both within the Support Vector learning algorithm.", "labels": [], "entities": []}, {"text": "The high complexity of the SK limits the size of the experiments that we can carryout in a feasible time.", "labels": [], "entities": []}, {"text": "Moreover, we are not interested to large collections of training documents as in these training conditions the simple bag-of-words models are in general very effective, i.e. they seems to model well the document similarity needed by the learning algorithms.", "labels": [], "entities": []}, {"text": "Thus, we carried out the experiments on small subsets of the 20NewsGroups 2 (20NG) and the Reuters-21578 3 corpora to simulate critical learning conditions.", "labels": [], "entities": [{"text": "Reuters-21578 3 corpora", "start_pos": 91, "end_pos": 114, "type": "DATASET", "confidence": 0.8986846009890238}]}, {"text": "For the experiments, we used the SVMlight software) (available at svmlight.joachims.org) with the default linear kernel on the token space (adopted as the baseline evaluations).", "labels": [], "entities": []}, {"text": "For the SK evaluation we implemented the Eq.", "labels": [], "entities": [{"text": "SK", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.9177616834640503}, {"text": "Eq", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.6836238503456116}]}, {"text": "3 with \u03c3(\u00b7, \u00b7) = CD(\u00b7, \u00b7) (Eq. 1) inside SVM-light.", "labels": [], "entities": []}, {"text": "1 is only defined for nouns, apart of speech (POS) tagger has been previously applied.", "labels": [], "entities": []}, {"text": "However, also verbs, adjectives and numerical features were included in the pair space.", "labels": [], "entities": []}, {"text": "For these tokens a CD = 0 is assigned to pairs made by different strings.", "labels": [], "entities": []}, {"text": "As the POS-tagger could introduce errors, in a second experiment, any token with a successful look-up in the WN noun hierarchy was considered in the kernel.", "labels": [], "entities": []}, {"text": "This approximation has the benefit to retrieve useful information even for verbs and capture the similarity between verbs and some nouns, e.g. to drive (via the noun drive) has a common synset with parkway.", "labels": [], "entities": []}, {"text": "For the evaluations, we applied a careful SVM parameterization: a preliminary investigation suggested that the trade-off (between the training-set error and margin, i.e. c option in SVM-light) parameter optimizes the F 1 measure for values in the range [0.02,0.32] . We noted also that the cost-factor parameter (i.e. j option) is not critical, i.e. a value of 10 always optimizes the accuracy.", "labels": [], "entities": [{"text": "margin", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.95998215675354}, {"text": "F 1 measure", "start_pos": 217, "end_pos": 228, "type": "METRIC", "confidence": 0.9734249512354533}, {"text": "accuracy", "start_pos": 385, "end_pos": 393, "type": "METRIC", "confidence": 0.9968371391296387}]}, {"text": "The feature selection techniques and the weighting schemes were not applied in our experiments as they cannot be accurately estimated from the small available training data.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.728945255279541}]}, {"text": "The classification performance was evaluated by means of the F 1 measure 5 for the single category and the MicroAverage for the final classifier pool.", "labels": [], "entities": [{"text": "F 1 measure 5", "start_pos": 61, "end_pos": 74, "type": "METRIC", "confidence": 0.9754897505044937}]}, {"text": "Given the high computational complexity of SK we selected 8 categories from the 20NG 6 and 8 from the Reuters corpus To derive statistically significant results with few training documents, for each corpus, we randomly selected 10 different samples from the 8 categories.", "labels": [], "entities": [{"text": "20NG 6", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.8826497197151184}, {"text": "Reuters corpus", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.9753551185131073}]}, {"text": "We trained the classifiers on one sample, parameterized on a second sample and derived the measures on the other 8.", "labels": [], "entities": []}, {"text": "By rotating the training sample we obtained 80 different measures for each model.", "labels": [], "entities": []}, {"text": "The size of the samples ranges from 24 to 160 documents depending on the target experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the linear and Semantic Kernel with", "labels": [], "entities": []}, {"text": " Table 2: Performance of the linear and Semantic Kernel with", "labels": [], "entities": []}]}