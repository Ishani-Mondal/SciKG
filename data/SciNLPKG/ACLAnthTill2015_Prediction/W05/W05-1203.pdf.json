{"title": [{"text": "Measuring the Semantic Similarity of Texts", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a knowledge-based method for measuring the semantic-similarity of texts.", "labels": [], "entities": []}, {"text": "While there is a large body of previous work focused on finding the semantic similarity of concepts and words, the application of these word-oriented methods to text similarity has not been yet explored.", "labels": [], "entities": [{"text": "text similarity", "start_pos": 161, "end_pos": 176, "type": "TASK", "confidence": 0.7103927135467529}]}, {"text": "In this paper, we introduce a method that combines word-to-word similarity metrics into a text-to-text metric, and we show that this method outperforms the traditional text similarity metrics based on lexical matching.", "labels": [], "entities": []}], "introductionContent": [{"text": "Measures of text similarity have been used fora longtime in applications in natural language processing and related areas.", "labels": [], "entities": [{"text": "text similarity", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.6750519126653671}]}, {"text": "One of the earliest applications of text similarity is perhaps the vectorial model in information retrieval, where the document most relevant to an input query is determined by ranking documents in a collection in reversed order of their similarity to the given query.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.7406198680400848}]}, {"text": "Text similarity has been also used for relevance feedback and text classification, word sense disambiguation, and more recently for extractive summarization, and methods for automatic evaluation of machine translation) or text summarization (.", "labels": [], "entities": [{"text": "Text similarity", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6959387511014938}, {"text": "text classification", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7513075768947601}, {"text": "word sense disambiguation", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.6967384815216064}, {"text": "extractive summarization", "start_pos": 132, "end_pos": 156, "type": "TASK", "confidence": 0.535450890660286}, {"text": "machine translation", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.7029263228178024}, {"text": "text summarization", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.8165308237075806}]}, {"text": "The typical approach to finding the similarity between two text segments is to use a simple lexical matching method, and produce a similarity score based on the number of lexical units that occur in both input segments.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 131, "end_pos": 147, "type": "METRIC", "confidence": 0.933562308549881}]}, {"text": "Improvements to this simple method have considered stemming, stop-word removal, part-of-speech tagging, longest subsequence matching, as well as various weighting and normalization factors).", "labels": [], "entities": [{"text": "stop-word removal", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7411863505840302}, {"text": "part-of-speech tagging", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.6710412353277206}, {"text": "longest subsequence matching", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.6127313872178396}]}, {"text": "While successful to a certain degree, these lexical matching similarity methods fail to identify the semantic similarity of texts.", "labels": [], "entities": []}, {"text": "For instance, there is an obvious similarity between the text segments I own a dog and I have an animal, but most of the current text similarity metrics will fail in identifying any kind of connection between these texts.", "labels": [], "entities": []}, {"text": "The only exception to this trend is perhaps the latent semantic analysis (LSA) method, which represents an improvement over earlier attempts to use measures of semantic similarity for information retrieval,.", "labels": [], "entities": [{"text": "latent semantic analysis (LSA)", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.6958228647708893}, {"text": "information retrieval", "start_pos": 184, "end_pos": 205, "type": "TASK", "confidence": 0.75898277759552}]}, {"text": "LSA aims to find similar terms in large text collections, and measure similarity between texts by including these additional related words.", "labels": [], "entities": []}, {"text": "However, to date LSA has not been used on a large scale, due to the complexity and computational cost associated with the algorithm, and perhaps also due to the \"black-box\" effect that does not allow for any deep insights into why some terms are selected as similar during the singular value decomposition process.", "labels": [], "entities": [{"text": "singular value decomposition", "start_pos": 277, "end_pos": 305, "type": "TASK", "confidence": 0.6442676981290182}]}, {"text": "In this paper, we explore a knowledge-based method for measuring the semantic similarity of texts.", "labels": [], "entities": []}, {"text": "While there are several methods previously proposed for finding the semantic similarity of words, to our knowledge the application of these word-oriented methods to text similarity has not been yet explored.", "labels": [], "entities": [{"text": "text similarity", "start_pos": 165, "end_pos": 180, "type": "TASK", "confidence": 0.7223087102174759}]}, {"text": "We introduce an algorithm that combines the word-to-word similarity metrics into a text-to-text semantic similarity metric, and we show that this method outperforms the simpler lexical matching similarity approach, as measured in a paraphrase identification application.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 232, "end_pos": 257, "type": "TASK", "confidence": 0.8196820616722107}]}], "datasetContent": [{"text": "To test the effectiveness of the text semantic similarity metric, we use this measure to automatically identify if two text segments are paraphrases of each other.", "labels": [], "entities": [{"text": "text semantic similarity", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.7051114539305369}]}, {"text": "We use the Microsoft paraphrase corpus (), consisting of 4,076 training pairs and 1,725 test pairs, and determine the number of correctly identified paraphrase pairs in the corpus using the text semantic similarity measure as the only indicator of paraphrasing.", "labels": [], "entities": [{"text": "Microsoft paraphrase corpus", "start_pos": 11, "end_pos": 38, "type": "DATASET", "confidence": 0.8290839393933614}]}, {"text": "In addition, we also evaluate the measure using the PASCAL corpus), consisting of 1,380 test-hypothesis pairs with a directional entailment (580 development pairs and 800 test pairs).", "labels": [], "entities": [{"text": "PASCAL corpus", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.8078216910362244}]}, {"text": "For each of the two data sets, we conduct two evaluations, under two different settings: (1) An unsupervised setting, where the decision on what constitutes a paraphrase (entailment) is made using a constant similarity threshold of 0.5 across all experiments; and (2) A supervised setting, where the optimal threshold and weights associated with various similarity metrics are determined through learning on training data.", "labels": [], "entities": []}, {"text": "In this case, we use a voted perceptron algorithm . We evaluate the text similarity metric built on top of the various word-to-word metrics introduced in Section 2.1.", "labels": [], "entities": []}, {"text": "For comparison, we also compute three baselines: (1) A random baseline created by randomly choosing a true or false value for each text pair; (2) A lexical matching baseline, which only counts the number of matching words between the two text segments, while still applying the weighting and normalization factors from equation 7; and (3) A vectorial similarity baseline, using a cosine similarity measure as traditionally used in information retrieval, with tf.idf term weighting.", "labels": [], "entities": []}, {"text": "For comparison, we also evaluated the corpus-based similarity obtained through LSA; however, the results obtained were below the lexical matching baseline and are not reported here.", "labels": [], "entities": []}, {"text": "For paraphrase identification, we use the bidirectional similarity measure, and determine the similarity with respect to each of the two text segments in turn, and then combine them into a bidirectional similarity metric.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.9789556562900543}]}, {"text": "For entailment identification, since this is a directional relation, we only measure the semantic similarity with respect to the hypothesis (the text that is entailed).", "labels": [], "entities": [{"text": "entailment identification", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.9449364840984344}]}, {"text": "We evaluate the results in terms of accuracy, representing the number of correctly identified true or false classifications in the test data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9994513392448425}]}, {"text": "We also measure precision, recall and F-measure, calculated with respect to the true values in each of the test data sets.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9996681213378906}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9997108578681946}, {"text": "F-measure", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9992392063140869}]}, {"text": "show the results obtained in the unsupervised setting, when a text semantic similarity larger than 0.5 was considered to bean indicator of paraphrasing (entailment).", "labels": [], "entities": []}, {"text": "We also evaluate a metric that combines all the similarity measures using a simple average, with results indicated in the Combined row.", "labels": [], "entities": []}, {"text": "The results obtained in the supervised setting are shown in.", "labels": [], "entities": []}, {"text": "The optimal combination of similarity metrics and optimal threshold are now determined in a learning process performed on the training set.", "labels": [], "entities": []}, {"text": "Under this setting, we also compute an additional baseline, consisting of the most frequent label, as determined from the training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Wu & Palmer word similarity scores for  computing text similarity with respect to text 1", "labels": [], "entities": []}, {"text": " Table 2: Text semantic similarity for paraphrase  identification (unsupervised)", "labels": [], "entities": [{"text": "Text semantic similarity", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7402811249097189}, {"text": "paraphrase  identification", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8911468982696533}]}, {"text": " Table 3: Text semantic similarity for entailment  identification (unsupervised)", "labels": [], "entities": [{"text": "Text semantic similarity", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.776971181233724}, {"text": "entailment  identification", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.9242209494113922}]}, {"text": " Table 4: Text semantic similarity for paraphrase  identification (supervised)", "labels": [], "entities": [{"text": "Text semantic similarity", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7275759975115458}, {"text": "paraphrase  identification", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8960466086864471}]}, {"text": " Table 5: Text semantic similarity for entailment  identification (supervised)", "labels": [], "entities": [{"text": "Text semantic similarity", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7651163736979166}, {"text": "entailment  identification", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8650874197483063}]}]}