{"title": [{"text": "A Novel Machine Learning Approach for the Identification of Named Entity Relations", "labels": [], "entities": [{"text": "Identification of Named Entity", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.8877322524785995}]}], "abstractContent": [{"text": "In this paper, a novel machine learning approach for the identification of named entity relations (NERs) called positive and negative case-based learning (PNCBL) is proposed.", "labels": [], "entities": [{"text": "identification of named entity relations (NERs)", "start_pos": 57, "end_pos": 104, "type": "TASK", "confidence": 0.8567311093211174}]}, {"text": "It pursues the improvement of the identification performance for NERs through simultaneously learning two opposite cases and automatically selecting effective multi-level linguistic features for NERs and non-NERs.", "labels": [], "entities": []}, {"text": "This approach has been applied to the identification of domain-specific and cross-sentence NERs for Chinese texts.", "labels": [], "entities": [{"text": "identification of domain-specific and cross-sentence NERs", "start_pos": 38, "end_pos": 95, "type": "TASK", "confidence": 0.601504440108935}]}, {"text": "The experimental results have shown that the overall average recall, precision, and F-measure for 14 NERs are 78.50%, 63.92% and 70.46% respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9995998740196228}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9991167187690735}, {"text": "F-measure", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9996026158332825}, {"text": "NERs", "start_pos": 101, "end_pos": 105, "type": "TASK", "confidence": 0.8440929651260376}]}, {"text": "In addition , the above F-measure has been enhanced from 63.61% to 70.46% due to adoption of both positive and negative cases.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9988477230072021}]}], "introductionContent": [{"text": "The investigation for Chinese information extraction is one of the topics of the project COLLATE dedicated to building up the German Competence Center for Language Technology.", "labels": [], "entities": [{"text": "Chinese information extraction", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.6321682830651602}]}, {"text": "After accomplishing the task concerning named entity (NE) identification, we goon studying identification issues for named entity relations.", "labels": [], "entities": [{"text": "named entity (NE) identification", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.6712918331225713}]}, {"text": "As an initial step, we define 14 different NERs based on six identified NEs in a sports domain based Chinese named entity recognition system (.", "labels": [], "entities": []}, {"text": "In order to learn NERs, we annotate the output texts from this system with XML.", "labels": [], "entities": []}, {"text": "Meanwhile, the NER annotation is performed by an interactive mode.", "labels": [], "entities": [{"text": "NER annotation", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.5388690531253815}]}, {"text": "The goal of the learning is to capture valuable information from NER and non-NER patterns, which is implicated in different features and helps us identify NERs and non-NERs.", "labels": [], "entities": []}, {"text": "Generally speaking, because not all features we predefine are important for each NER or non-NER, we should distinguish them by a reasonable measure mode.", "labels": [], "entities": []}, {"text": "According to the selection criterion we proposeself-similarity, which is a quantitative measure for the concentrative degree of the same kind of NERs or non-NERs in the corresponding pattern library, the effective feature sets -general-character feature (GCF) sets for NERs and individual-character feature (ICF) sets for non-NERs are built.", "labels": [], "entities": []}, {"text": "Moreover, the GCF and ICF feature weights serve as a proportion determination of the features' degree of importance for identifying NERs against nonNERs.", "labels": [], "entities": [{"text": "ICF feature weights", "start_pos": 22, "end_pos": 41, "type": "METRIC", "confidence": 0.8425519665082296}, {"text": "NERs", "start_pos": 132, "end_pos": 136, "type": "TASK", "confidence": 0.7299800515174866}]}, {"text": "Subsequently, identification thresholds can also be determined.", "labels": [], "entities": []}, {"text": "In the NER identification, we maybe confronted with the problem that an NER candidate in anew case matches more than one positive case, or both positive and negative cases.", "labels": [], "entities": [{"text": "NER identification", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.975142627954483}]}, {"text": "In such situations, we have to employ a vote to decide which existing case environment is more similar to the new case.", "labels": [], "entities": []}, {"text": "In addition, a number of special circumstances should be also considered, such as relation conflict and relation omission.", "labels": [], "entities": [{"text": "relation omission", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7602129578590393}]}], "datasetContent": [{"text": "The main resources used for learning and identification are NER and non-NER patterns.", "labels": [], "entities": []}, {"text": "Before learning, the texts from the Jie Fang Daily 2 in 2001 were annotated based on the NE identification.", "labels": [], "entities": [{"text": "Jie Fang Daily 2 in 2001", "start_pos": 36, "end_pos": 60, "type": "DATASET", "confidence": 0.9553041855494181}, {"text": "NE identification", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.5911812633275986}]}, {"text": "During learning, both pattern libraries are established in terms of the annotated texts and Lexical Sports Ontology.", "labels": [], "entities": []}, {"text": "They have 142 (534 NERs) and 98 (572 non-NERs) sentence groups, respectively.", "labels": [], "entities": []}, {"text": "To test the performance of our approach, we randomly choose 32 sentence groups from the Jie Fang Daily in 2002, which embody 117 different NER candidates.", "labels": [], "entities": [{"text": "Jie Fang Daily in 2002", "start_pos": 88, "end_pos": 110, "type": "DATASET", "confidence": 0.951342499256134}]}, {"text": "For evaluating the effects of negative cases, we made two experiments.", "labels": [], "entities": []}, {"text": "shows the average and total average recall, precision, and F-measure for the identification of 14 NERs only by positive case-based learning. are higher than those of corresponding NERs in; the F-measure values of three NERs (LOC_CPC, TM_CP, and PS_CP) have no variation; but the Fmeasure values of other four NERs (PS_TM, CP_LOC, TM_CPC, and HT_VT) in are lower than those of corresponding NERs in.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9935352802276611}, {"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9979318380355835}, {"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9981759786605835}, {"text": "Fmeasure", "start_pos": 279, "end_pos": 287, "type": "METRIC", "confidence": 0.9914514422416687}]}, {"text": "This shows the performances for half of NERs are improved due to the adoption of both positive and negative cases.", "labels": [], "entities": [{"text": "NERs", "start_pos": 40, "end_pos": 44, "type": "TASK", "confidence": 0.9053842425346375}]}, {"text": "Moreover, the total average Fmeasure is enhanced from 63.61% to 70.46% as a whole.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9455044269561768}]}, {"text": "Finally, we have to acknowledge that it is difficult to compare the performance of our method to others because the experimental conditions and corpus domains of other NER identification efforts are quite different from ours.", "labels": [], "entities": [{"text": "NER identification", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.9810813069343567}]}, {"text": "Nevertheless, we would like to use the performance of Chinese NER identification using memory-based learning (MBL)) fora comparison with our approach in.", "labels": [], "entities": [{"text": "NER identification", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7962824702262878}]}, {"text": "In the table, we select similar NERs in our domain to correspond to the three types of the relations.", "labels": [], "entities": []}, {"text": "From the table we can deduce that the identification performance of relations for PNCBL is roughly comparable to that of the MBL.", "labels": [], "entities": [{"text": "MBL", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.8740001320838928}]}], "tableCaptions": [{"text": " Table 3.  This shows the performances for half of NERs are  improved due to the adoption of both positive and  negative cases. Moreover, the total average F- measure is enhanced from 63.61% to 70.46% as a  whole.", "labels": [], "entities": [{"text": "NERs", "start_pos": 51, "end_pos": 55, "type": "TASK", "confidence": 0.8011947870254517}, {"text": "F- measure", "start_pos": 156, "end_pos": 166, "type": "METRIC", "confidence": 0.9938234686851501}]}, {"text": " Table 4: Identification Performance  for 14 NERs by PNCBL", "labels": [], "entities": [{"text": "NERs", "start_pos": 45, "end_pos": 49, "type": "TASK", "confidence": 0.8905371427536011}, {"text": "PNCBL", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.880711019039154}]}, {"text": " Table 5: Performances for Relation Identification  (PNCBL&I vs. MBL&I)", "labels": [], "entities": [{"text": "Relation Identification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.8920303583145142}]}]}