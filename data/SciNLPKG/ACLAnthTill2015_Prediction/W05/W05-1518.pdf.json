{"title": [{"text": "Improving Parsing Accuracy by Combining Diverse Dependency Parsers", "labels": [], "entities": [{"text": "Improving Parsing Accuracy", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7052084108193716}]}], "abstractContent": [{"text": "This paper explores the possibilities of improving parsing results by combining outputs of several parsers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9815317392349243}]}, {"text": "To some extent , we are porting the ideas of Hender-son and Brill (1999) to the world of dependency structures.", "labels": [], "entities": []}, {"text": "We differ from them in exploring context features more deeply.", "labels": [], "entities": []}, {"text": "All our experiments were conducted on Czech but the method is language independent.", "labels": [], "entities": []}, {"text": "We were able to significantly improve over the best parsing result for the given setting, known so far.", "labels": [], "entities": [{"text": "parsing", "start_pos": 52, "end_pos": 59, "type": "TASK", "confidence": 0.952394425868988}]}, {"text": "Moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Difficult and important NLP problems have the property of attracting whole range of researchers, which often leads to the development of several different approaches to the same problem.", "labels": [], "entities": []}, {"text": "If these approaches are independent enough in terms of not producing the same kinds of errors, there is a hope that their combination can bring further improvement to the field.", "labels": [], "entities": []}, {"text": "While improving any single approach gets more and more difficult once some threshold has been touched, exploring the potential of approach combination should never be omitted, provided three or more approaches are available.", "labels": [], "entities": []}, {"text": "Combination techniques have been successfully applied to part of speech tagging).", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.7431157529354095}]}, {"text": "In both cases the investigators were able to achieve significant improvements over the previous best tagging results.", "labels": [], "entities": []}, {"text": "Similar advances have been made in machine translation, speech recognition, named entity recognition (, partial parsing), word sense disambiguation () and question answering (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7876448035240173}, {"text": "speech recognition", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.767630934715271}, {"text": "named entity recognition", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.6138718624909719}, {"text": "word sense disambiguation", "start_pos": 122, "end_pos": 147, "type": "TASK", "confidence": 0.7070597211519877}, {"text": "question answering", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.8900018632411957}]}, {"text": "Brill and Hladk\u00e1 () have first explored committee-based dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7456298768520355}]}, {"text": "However, they generated multiple parsers from a single one using bagging.", "labels": [], "entities": []}, {"text": "There have not been more sufficiently good parsers available.", "labels": [], "entities": []}, {"text": "A successful application of voting and of a stacked classifier to constituent parsing followed in).", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.6271399110555649}]}, {"text": "The authors have investigated two combination techniques (constituent voting and na\u00efve Bayes), and two ways of their application to the (full) parsing: parser switching, and similarity switching.", "labels": [], "entities": [{"text": "constituent voting", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7063251584768295}, {"text": "parser switching", "start_pos": 152, "end_pos": 168, "type": "TASK", "confidence": 0.9306901097297668}, {"text": "similarity switching", "start_pos": 174, "end_pos": 194, "type": "TASK", "confidence": 0.699156254529953}]}, {"text": "They were able to gain 1.6 constituent F-score, using their most successful technique.", "labels": [], "entities": [{"text": "F-score", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.9995076656341553}]}, {"text": "In our research, we focused on dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9169468283653259}]}, {"text": "One of the differences against Henderson and Brill's situation is that a dependency parser has to assign exactly one governing node (parent word) to each word.", "labels": [], "entities": []}, {"text": "Unlike the number of constituents in constituency-based frameworks, the number of dependencies is known in advance, the parser only has to assign a link (number 0 through N) to each word.", "labels": [], "entities": []}, {"text": "In that sense, a dependency parser is similar to classifiers like POS taggers.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.6524750888347626}]}, {"text": "Unless it deliberately fails to assign a parent to a word (or assigns several alternate parents to a word), there is no need for precision & recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.9994852542877197}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9978148937225342}]}, {"text": "Instead, a single metric called accuracy is used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9993759989738464}]}, {"text": "On the other hand, a dependency parser is not areal classifier: the number of its \"classes\" is theoretically unlimited (natural numbers), and no generalization can be drawn about objects belonging to the same \"class\" (words that -sometimes -appeared to find their parent at the position i).", "labels": [], "entities": []}, {"text": "A combination of dependency parsers does not necessarily grant the resulting dependency structure being cycle-free.", "labels": [], "entities": []}, {"text": "(This contrasts to not introducing crossing brackets in constituent parsing, which is granted according to We address the issue in 4.4.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.6642729938030243}]}, {"text": "The rest of this paper is organized as follows: in Sections 2 and 3 we introduce the data and the component parsers, respectively.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss several combining techniques, and in Section 5 we describe the results of the corresponding experiments.", "labels": [], "entities": []}, {"text": "We finally compare our results to the previous work and conclude.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. A brief description of the tested parsers. Note that the Tune data is not the data used to train the  individual parsers. Higher numbers in the right column reflect just the fact that the Test part is slightly  easier to parse.", "labels": [], "entities": [{"text": "Tune data", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.8147183358669281}]}, {"text": " Table 3: Results of voting experiments.", "labels": [], "entities": []}, {"text": " Table 4: Voting under hand-invented schemes.", "labels": [], "entities": [{"text": "Voting", "start_pos": 10, "end_pos": 16, "type": "TASK", "confidence": 0.9671438336372375}]}, {"text": " Table 5: Contexts where ec is better than mc+dz.  J^ are coordination conjunctions, # is the root, V*  are verbs, Nn are nouns in case n, R* are preposi- tions, Z* are punctuation marks, An are adjectives.", "labels": [], "entities": []}, {"text": " Table 7: Unbalanced vs. balanced combining. All  runs ignored the context. Evaluated on the Test  data set.", "labels": [], "entities": [{"text": "Test  data set", "start_pos": 93, "end_pos": 107, "type": "DATASET", "confidence": 0.9582818547884623}]}]}