{"title": [{"text": "Climbing the path to grammar: a maximum entropy model of subject/object learning", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we discuss an application of Maximum Entropy to modeling the acquisition of subject and object processing in Italian.", "labels": [], "entities": [{"text": "acquisition of subject and object processing", "start_pos": 76, "end_pos": 120, "type": "TASK", "confidence": 0.6344576974709829}]}, {"text": "The model is able to learn from corpus data a set of experimentally and theoretically well-motivated linguistic constraints, as well as their relative sali-ence in Italian grammar development and processing.", "labels": [], "entities": [{"text": "Italian grammar development and processing", "start_pos": 164, "end_pos": 206, "type": "TASK", "confidence": 0.6841367661952973}]}, {"text": "The model is also shown to acquire robust syntactic generalizations by relying on the evidence provided by a small number of high token frequency verbs only.", "labels": [], "entities": [{"text": "syntactic generalizations", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.6830548644065857}]}, {"text": "These results are consistent with current research focusing on the role of high frequency verbs in allowing children to converge on the most salient constraints in the grammar.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current research in language learning supports the view that developing grammatical competence involve mastering and integrating multiple, parallel, probabilistic constraints defined over different types of linguistic (and non lingui stic) information).", "labels": [], "entities": []}, {"text": "This is particularly clear when we focus on the core of grammatical development, namely the ability to properly identify syntactic relations.", "labels": [], "entities": []}, {"text": "Psycholinguistic evidence shows that children learn to identify sentence subjects and direct objects by combining various types of probabilistic cues, such as word order, noun animacy, definiteness, agreement, etc.", "labels": [], "entities": []}, {"text": "The relative prominence of each of these cues during the development of a child's syntactic competence can considerably vary crosslinguistically, mirroring their relative salience in the adult grammar system (cf..", "labels": [], "entities": []}, {"text": "If grammatical constraints are inherently probabilistic, the path through which the child acquires adult grammar competence can be viewed as the process of building a stochastic model out of the linguistic input.", "labels": [], "entities": []}, {"text": "Consistently with \"usage-based\" approaches to language acquisition (cf.) grammatical constraints would thus emerge from language use thanks to the child's ability to keep track of statistical regularities in linguistic cues.", "labels": [], "entities": []}, {"text": "In turn, this raises the issue of how children are able to exploit the statistical distribution of cues in the linguistic input.", "labels": [], "entities": []}, {"text": "Various types of cross-linguistic evidence converge on the hypothesis that children are actually able to take great advantage of the highly skewed distribution of naturalistic language data.,, among the others argue that verbs with high token frequency in the input have a facilitatory effect in allowing children to derive robust syntactic generalizations even from surprisingly minimal input.", "labels": [], "entities": []}, {"text": "According to this model, syntactic learning is driven by a small pool of verbs occurring with the highest token frequency: they approximately correspond to so-called \"light verbs\" such as English go, give , want etc.", "labels": [], "entities": []}, {"text": "These verbs would act as \"cata-lysts\" in allow ing children to converge on the most salient grammar constraints of the language they are acquiring.", "labels": [], "entities": []}, {"text": "In computational linguistics, Maximum Entropy models have proven to be robust statistical learning algorithms that perform well in a number of processing tasks.", "labels": [], "entities": []}, {"text": "In this paper, we discuss successful application of a Maximum Entropy (ME) model to the processing of Italian syntactic relations.", "labels": [], "entities": [{"text": "processing of Italian syntactic relations", "start_pos": 88, "end_pos": 129, "type": "TASK", "confidence": 0.7668234467506408}]}, {"text": "We believe that this discussion is of general interest for two basic reasons.", "labels": [], "entities": []}, {"text": "First, the model is able to learn, from corpus data, a set of experimentally and theoretically well-motivated linguistic constraints, as well as their relative salience in the processing of Italian.", "labels": [], "entities": []}, {"text": "This suggests that it is possible fora child to bootstrap and use this type of knowledge on the basis of a specific distribution of real language data, a conclusion that bears on the question of the role and type of innate inductive biases.", "labels": [], "entities": []}, {"text": "Secondly, the model is also shown to acquire robust syntactic generalizations by relying on the evidence provided by a small number of high token frequency verbs only.", "labels": [], "entities": []}, {"text": "With some qualifications, this evidence sheds light on the interaction between highly skewed language data distributions and language maturation.", "labels": [], "entities": []}, {"text": "Robust grammar generalizations emerge on the basis of exposure to early, statist ically stable and lexically underspecified evidence, thus providing a reliable backbone to children's syntactic development and later lexical organization.", "labels": [], "entities": [{"text": "Robust grammar generalizations", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7956926226615906}]}, {"text": "In the following section we first broach the general problem of parsing subjects and objects in Italian.", "labels": [], "entities": [{"text": "parsing subjects and objects in Italian", "start_pos": 64, "end_pos": 103, "type": "TASK", "confidence": 0.8728229105472565}]}, {"text": "Section 3 describes an ME model of the problem.", "labels": [], "entities": [{"text": "ME", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.950530469417572}]}, {"text": "Section 4 and 5 are devoted to a detailed empirical analysis of the interaction of different feature configurations and of the interplay between verb token frequency and relevant generalizations.", "labels": [], "entities": []}, {"text": "Conclusions are drawn in the final discussion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}