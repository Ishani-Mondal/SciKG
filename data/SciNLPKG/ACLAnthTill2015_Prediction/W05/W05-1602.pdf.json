{"title": [{"text": "Interactive Authoring of Logical Forms for Multilingual Generation *", "labels": [], "entities": [{"text": "Multilingual Generation", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.679297000169754}]}], "abstractContent": [{"text": "We present an authoring system for logical forms encoded as conceptual graphs (CG).", "labels": [], "entities": []}, {"text": "The system belongs to the family of WYSIWYM (What You See Is What You Mean) text generation systems: logical forms are entered interactively and the corresponding linguistic realization of the expressions is generated in several languages.", "labels": [], "entities": [{"text": "WYSIWYM (What You See Is What You Mean) text generation", "start_pos": 36, "end_pos": 91, "type": "TASK", "confidence": 0.6221938282251358}]}, {"text": "The system maintains a model of the discourse context corresponding to the authored documents.", "labels": [], "entities": []}, {"text": "The system helps users author documents formulated in the CG format.", "labels": [], "entities": []}, {"text": "Ina first stage, a domain-specific ontology is acquired by learning from example texts in the domain.", "labels": [], "entities": []}, {"text": "The ontology acquisition module builds a typed hierarchy of concepts and relations derived from the WordNet and Verb-net.", "labels": [], "entities": [{"text": "ontology acquisition", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7906082570552826}, {"text": "WordNet", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.957114040851593}, {"text": "Verb-net", "start_pos": 112, "end_pos": 120, "type": "DATASET", "confidence": 0.8256822228431702}]}, {"text": "The user can then edit a specific document, by entering utterances in sequence, and maintaining a representation of the context.", "labels": [], "entities": []}, {"text": "While the user enters data, the system performs the standard steps of text generation on the basis of the authored logical forms: reference planning, aggregation, lexical choice and syntactic realization-in several languages (we have implemented English and Hebrew-and are exploring an implementation using the Bliss graphical language).", "labels": [], "entities": [{"text": "text generation", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7419502437114716}, {"text": "reference planning", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.7109697014093399}, {"text": "syntactic realization-in", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.7457480728626251}]}, {"text": "The feedback in natural language is produced in real-time for every single modification performed by the author.", "labels": [], "entities": []}, {"text": "We perform a cost-benefit analysis of the application of NLG techniques in the context of authoring cooking recipes in English and Hebrew.", "labels": [], "entities": []}, {"text": "By combining existing large-scale knowledge resources (WordNet, Verbnet, the SURGE and HUGG realization grammars) and techniques from modern integrated software development environment (such as the Eclipse IDE), we obtain an efficient tool for the generation of logical forms, in domains where content is not available in the form of databases.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.9575154185295105}]}], "introductionContent": [{"text": "Natural language generation techniques can be applied to practical systems when the \"input\" data to be rendered in text can be obtained in a cost-effective manner, and when the \"output\" requires such variability (multiple styles or languages, or customization to specific users or classes) that producing documents manually becomes prohibitively expensive.", "labels": [], "entities": [{"text": "Natural language generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6527322928110758}]}, {"text": "The input data can be either derived from an existing application database or it can be authored specifically to produce documents.", "labels": [], "entities": []}, {"text": "Applications where the data is available in a database include report generators (e.g., ANA, PlanDoc, Multimeteo], FOG).", "labels": [], "entities": [{"text": "FOG", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.6016930341720581}]}, {"text": "In other cases, researchers identified application domains where some of the data is available, but not in sufficient detail to produce full documents.", "labels": [], "entities": []}, {"text": "The \"WYSIWYM\" approach was proposed (],) as a system design methodology where users author and manipulate an underlying logical form through a user interface that provides feedback in natural language text.", "labels": [], "entities": []}, {"text": "The effort invested in authoring logical forms -either from scratch or from a partial application ontology -is justified when the logical form can be reused.", "labels": [], "entities": []}, {"text": "This is the case when documents must be generated in several languages.", "labels": [], "entities": []}, {"text": "The field of multilingual generation (MLG) has addressed this need (,).", "labels": [], "entities": [{"text": "multilingual generation (MLG)", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.8519533395767211}]}, {"text": "When documents must be produced in several versions, adapted to various contexts or users, the flexibility resulting from generation from logical forms is also valuable.", "labels": [], "entities": []}, {"text": "Another motivation for authoring logical forms (as opposed to textual documents) is that the logical form can be used for other applicative requirements: search, summarization of multiple documents, inference.", "labels": [], "entities": [{"text": "summarization of multiple documents", "start_pos": 162, "end_pos": 197, "type": "TASK", "confidence": 0.8913760930299759}]}, {"text": "This concern underlies the research programme of the Semantic Web, which promotes the encoding in standardized forms of ontological knowledge such as KIF,.", "labels": [], "entities": [{"text": "KIF", "start_pos": 150, "end_pos": 153, "type": "DATASET", "confidence": 0.7341576218605042}]}, {"text": "In this paper, we analyze an application of the WYSIWYM method to author logical forms encoded in Sowa's Conceptual Graphs (CG) format.", "labels": [], "entities": []}, {"text": "Ina first stage, users submit sample texts in a domain to the system.", "labels": [], "entities": []}, {"text": "The system learns from the samples a hierarchy of concepts and relations.", "labels": [], "entities": []}, {"text": "Given this ontology, the author then enters expressions using a simple variant of the CG Interchange Format (CGIF) which we have designed to speed editing operations.", "labels": [], "entities": []}, {"text": "The system provides realtime feedback to the author in English and Hebrew.", "labels": [], "entities": []}, {"text": "We evaluate the specific features of such a system which make it cost-effective as a tool to author logical forms.", "labels": [], "entities": []}, {"text": "We select the CG formalism as one of the representatives of the family of knowledge encoding formalisms, which benefits from well-established inference and quantification mechanisms and standard syntax encodings in graphical and linear formats.", "labels": [], "entities": []}, {"text": "The editing system we developed can be seen as CG editor motivated and expanded by natural language generation (NLG) techniques.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 83, "end_pos": 116, "type": "TASK", "confidence": 0.8045231103897095}]}, {"text": "The mixing of a practical ontology editing perspective with NLG techniques yielded the following benefits: \u2022 Generation tasks such as aggregation and reference planning are easily expressed as operations upon CGs.", "labels": [], "entities": [{"text": "ontology editing", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7150495946407318}]}, {"text": "\u2022 The construction and maintenance of context according to models of text planning, allow the author to break a complex CG into a manageable collection of small utterances.", "labels": [], "entities": []}, {"text": "Each utterance links to a global context in a natural manner.", "labels": [], "entities": []}, {"text": "\u2022 We designed a compact form to edit a textual encoding of CGs taking into account defaults, knowledge of types of concepts, sets and individual instances and context.", "labels": [], "entities": []}, {"text": "This format syntactically looks like a simple objectoriented programming language with objects, methods and attributes.", "labels": [], "entities": []}, {"text": "We use an editing environment similar to a modern programming language development environment -with a browser of types and instances, intelligent typing completion based on type analysis, and contextspecific tooltip assistance.", "labels": [], "entities": [{"text": "typing completion", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.6987381726503372}]}, {"text": "\u2022 The simultaneous generation of text in two languages (Hebrew and English) is important to distinguish between un-analyzed terms in the ontology and their linguistic counterpart.", "labels": [], "entities": []}, {"text": "We evaluate the overall effectiveness of the authoring environment in the specific domain of cooking recipes (inspired by).", "labels": [], "entities": []}, {"text": "We perform various usability studies to evaluate the overall cost of authoring cooking recipes as logical forms and evaluate the relative contribution of each component of the system: ontology, natural language feedback, user interface.", "labels": [], "entities": []}, {"text": "We conclude that the combination of these three factors results in an effective environment for authoring logical forms.", "labels": [], "entities": [{"text": "authoring logical forms", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.8242787520090739}]}, {"text": "In the paper, we first review the starting points upon which this study builds in generation and knowledge editing.", "labels": [], "entities": [{"text": "knowledge editing", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7004324197769165}]}, {"text": "We then present the tool we have implemented -its architecture, the knowledge acquisition module and the editor, we finally present the evaluation experiments and their results, and conclude with their analysis.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.7601485550403595}]}], "datasetContent": [{"text": "We have measured the following aspects of the system during the experiment.", "labels": [], "entities": []}, {"text": "Coverage -answers the questions \"can I say everything I mean\" and \"how much of the possible meanings that can be expressed in natural language can be expressed using the input language\".", "labels": [], "entities": []}, {"text": "In order to check the coverage of the tool, we examined the reference documents.", "labels": [], "entities": []}, {"text": "We compared the text generated from the reference documents with the original recipes and checked which parts of the information were included, excluded or expressed in a partial way with respect to the original.", "labels": [], "entities": []}, {"text": "We counted each of these in number of words in the original text, and expressed these 3 counts as a percentage of the words in the original recipe.", "labels": [], "entities": []}, {"text": "We summed up the result as a coverage index which combined the 3 counts (correct, missing, partial) with a factor of 70% for the partial count.", "labels": [], "entities": [{"text": "coverage index", "start_pos": 29, "end_pos": 43, "type": "METRIC", "confidence": 0.972135990858078}]}, {"text": "The results were checked by two authors independently and we report here the average of these two verifications.", "labels": [], "entities": []}, {"text": "On a total of 10 recipes, containing 1024 words overall, the coverage of the system is 91%.", "labels": [], "entities": [{"text": "coverage", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9929648637771606}]}, {"text": "Coverage was uniform across recipes and judges.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9056371450424194}]}, {"text": "We performed error analysis for the remaining 9% of the un-covered material below.", "labels": [], "entities": [{"text": "error", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9899711608886719}]}, {"text": "Intuitiveness -to assess the ease of use of the tool, we measured the \"learning curve\" for users first using the system, and measuring the time it takes to author a recipe for each successive document).", "labels": [], "entities": []}, {"text": "For 10 users first facing the tool, the time it took to author the documents is as follows: Document # 14 mn The time distribution among 10 users was extremely uniform.", "labels": [], "entities": []}, {"text": "We did not find variation in the quality of the authored documents across users and across number of document.", "labels": [], "entities": []}, {"text": "The tool is mastered quickly, by users with no prior training in knowledge representation or natural language processing.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.7234609425067902}]}, {"text": "Composing the reference documents (approximately 100-words recipes) by the authors took an average of 12 minutes.", "labels": [], "entities": []}, {"text": "Speed -we measured the time required to compose a document as a semantic representation, and compare it to the time taken to translate the same document in a different language.", "labels": [], "entities": []}, {"text": "We compare the average time for trained users to author a recipe (14 minutes) with that taken by 2 trained translators to translate 4 recipes (from English to Hebrew).", "labels": [], "entities": []}, {"text": "Semantic Authoring Time Translation Time 14 (minutes) 6 (minutes) The comparison is encouraging -it indicates that a tool for semantic authoring could become cost-effective if it is used to generate in 2 or 3 languages.", "labels": [], "entities": [{"text": "Semantic Authoring Time Translation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7563941329717636}]}, {"text": "Accuracy -We analyzed the errors in the documents prepared by the 10 users according to the following breakup: \u2022 Words in the source document not present in the semantic form \u2022 Words in the source document presented inaccurately in the semantic form \u2022 Users' errors in semantic form that are not included in the former two parameters.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9946317672729492}]}, {"text": "We calculated the accuracy for each document produced by the subjects during the experiment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9996119141578674}]}, {"text": "Then we compared each document with the corresponding reference document (used here as a gold standard).", "labels": [], "entities": []}, {"text": "Relative accuracy of this form estimates a form of confidence -\"how sure can the user be that s/he wrote what s/he meant\"?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9987900853157043}]}, {"text": "This measurement depends on the preliminary assumption that fora given recipe, any two readers (in the experiment environmentincluding the authors), will extract similar information.", "labels": [], "entities": []}, {"text": "This assumption is warranted for cooking recipes.", "labels": [], "entities": []}, {"text": "This measure takes into account the limitations of the tool and reflects the success of users to express all that the tool can express: Document # Accuracy 1st 93% 2nd 92% 3rd 95% 4th 90% Accuracy is quite consistent during the experiment sessions, i.e., it does not change as practice increases.", "labels": [], "entities": [{"text": "Accuracy 1st 93% 2nd 92% 3rd 95% 4th 90%", "start_pos": 147, "end_pos": 187, "type": "METRIC", "confidence": 0.9161055546540481}, {"text": "Accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.7075969576835632}]}, {"text": "The average 92.5% accuracy is quite high.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9804169535636902}]}, {"text": "The difficult conceptual issues (those which will require major design modifications, or put in question our choice of formalism for knowledge encoding) represent 33% of the errors -overall accounting for 2.5% of the words in the word count of the generated text.", "labels": [], "entities": [{"text": "knowledge encoding", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.70527383685112}]}, {"text": "We have conducted a user experiment, in which ten subjects were given three to four recipes in English (all taken from the Internet) from a total pool often.", "labels": [], "entities": []}, {"text": "The subjects had to compose semantic documents for these recipes using SAUT 2 . The ontology and lexicon for the specific domain of cooking recipes were prepared in advance, and we have tested the tool by composing these recipes with the system.", "labels": [], "entities": [{"text": "SAUT", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.6575526595115662}]}, {"text": "The documents the authors prepared are later used as a 'gold standard' (we refer to them as \"reference documents\").", "labels": [], "entities": []}, {"text": "The experiment was managed as follows: first, a short presentation of the tool (20 minutes) was given.", "labels": [], "entities": []}, {"text": "Then, each subject recieved a written interactive tutorial which took approximately half an hour to process.", "labels": [], "entities": []}, {"text": "Finally, each subject composed a set of 3 to 4 documents.", "labels": [], "entities": []}, {"text": "The overall time taken for each subject was 2.5 hours.", "labels": [], "entities": []}], "tableCaptions": []}