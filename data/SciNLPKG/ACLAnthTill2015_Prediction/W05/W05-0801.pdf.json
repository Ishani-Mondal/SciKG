{"title": [], "abstractContent": [{"text": "Bilingual word alignment forms the foundation of current work on statistical machine translation.", "labels": [], "entities": [{"text": "Bilingual word alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7232866287231445}, {"text": "statistical machine translation", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7371018131573995}]}, {"text": "Standard word-alignment methods involve the use of probabilistic generative models that are complex to implement and slow to train.", "labels": [], "entities": []}, {"text": "In this paper we show that it is possible to approach the alignment accuracy of the standard models using algorithms that are much faster, and in some ways simpler, based on basic word-association statistics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.7703888416290283}]}, {"text": "1 Motivation Bilingual word alignment is the first step of most current approaches to statistical machine translation.", "labels": [], "entities": [{"text": "Bilingual word alignment", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.607401450475057}, {"text": "statistical machine translation", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7005769312381744}]}, {"text": "Although the best performing systems are \"phrase-based\" (see, for instance, Och and Ney (2004) or Koehn et al.", "labels": [], "entities": []}, {"text": "(2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments.", "labels": [], "entities": [{"text": "phrase translations", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7190798223018646}]}, {"text": "The standard approach to word alignment makes use of five translation models defined by Brown et al.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8398151397705078}]}, {"text": "(1993), sometimes augmented by an HMM-based model or Och and Ney's \"Model 6\" (Och and Ney, 2003).", "labels": [], "entities": []}, {"text": "The best of these models can produce high accuracy alignments, at least when trained on a large parallel corpus of fairly direct translations in closely related languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9891582727432251}]}, {"text": "There area number of ways in which these standard models are less than ideal, however.", "labels": [], "entities": []}, {"text": "The higher-accuracy models are mathematically complex , and also difficult to train, as they do not factor in away that permits a dynamic programming solution.", "labels": [], "entities": []}, {"text": "It can thus take many hours of processing time on current standard computers to train the models and produce an alignment of a large parallel corpus.", "labels": [], "entities": []}, {"text": "In this paper, we take a different approach to word alignment, based on the use of bilingual word-association statistics rather than the generative prob-abilistic framework that the IBM and HMM models use.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8218693435192108}]}, {"text": "In the end we obtain alignment algorithms that are much faster, and in some ways simpler, whose accuracy comes surprisingly close to the established probabilistic generative approach.", "labels": [], "entities": [{"text": "alignment", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9594695568084717}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9991481304168701}]}, {"text": "2 Data and Methodology for these Experiments The experiments reported here were carried out using data from the workshop on building and using parallel texts held at HLT-NAACL 2003 (Mihalcea and Pedersen, 2003).", "labels": [], "entities": [{"text": "HLT-NAACL 2003", "start_pos": 166, "end_pos": 180, "type": "DATASET", "confidence": 0.9281697273254395}]}, {"text": "For the majority of our experiments , we used a subset of the Canadian Hansards bilingual corpus supplied for the workshop, comprising 500,000 English-French sentences pairs, including 37 sentence pairs designated as \"trial\" data, and 447 sentence pairs designated as test data.", "labels": [], "entities": [{"text": "Canadian Hansards bilingual corpus", "start_pos": 62, "end_pos": 96, "type": "DATASET", "confidence": 0.9042870402336121}]}, {"text": "The trial and test data have been manually aligned at the word level, noting particular pairs of words either as \"sure\" or \"possible\" alignments.", "labels": [], "entities": []}, {"text": "As an additional test, we evaluated our best alignment method using the workshop corpus of approximately 49,000 English-Romanian sentences pairs from diverse sources, including 248 manually aligned sentence pairs designated as test data.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The experiments reported here were carried out using data from the workshop on building and using parallel texts held at HLT-NAACL 2003.", "labels": [], "entities": [{"text": "HLT-NAACL 2003", "start_pos": 121, "end_pos": 135, "type": "DATASET", "confidence": 0.9146944880485535}]}, {"text": "For the majority of our experiments, we used a subset of the Canadian Hansards bilingual corpus supplied for the workshop, comprising 500,000 English-French sentences pairs, including 37 sentence pairs designated as \"trial\" data, and 447 sentence pairs designated as test data.", "labels": [], "entities": [{"text": "Canadian Hansards bilingual corpus", "start_pos": 61, "end_pos": 95, "type": "DATASET", "confidence": 0.9042873531579971}]}, {"text": "The trial and test data have been manually aligned at the word level, noting particular pairs of words either as \"sure\" or \"possible\" alignments.", "labels": [], "entities": []}, {"text": "As an additional test, we evaluated our best alignment method using the workshop corpus of approximately 49,000 English-Romanian sentences pairs from diverse sources, including 248 manually aligned sentence pairs designated as test data.", "labels": [], "entities": []}, {"text": "We needed annotated development data to optimize certain parameters of our algorithms, and we were concerned that the small number of sentence pairs designated as trial data would not be enough for this purpose.", "labels": [], "entities": []}, {"text": "We therefore randomly split each of the English-French and English-Romanian test data sets into two virtually equal subsets, by randomly ordering the test data pairs, and assigning alternate pairs from the random order to the two subsets.", "labels": [], "entities": [{"text": "English-Romanian test data sets", "start_pos": 59, "end_pos": 90, "type": "DATASET", "confidence": 0.7723570242524147}]}, {"text": "We used one of these subsets as a development set for parameter optimization, and held out the other fora final test set.", "labels": [], "entities": [{"text": "parameter optimization", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7637190818786621}]}, {"text": "We report the performance of various alignment algorithms in terms of precision, recall, and alignment error rate (AER) as defined by: In these definitions, S denotes the set of alignments annotated assure, P denotes the set of alignments annotated possible or sure, and A denotes the set of alignments produced by the method under test.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9996100068092346}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9985318183898926}, {"text": "alignment error rate (AER)", "start_pos": 93, "end_pos": 119, "type": "METRIC", "confidence": 0.9504891335964203}]}, {"text": "Following standard practice in the field, we take AER, which is derived from F-measure, as the primary evaluation metric that we are attempting to optimize.", "labels": [], "entities": [{"text": "AER", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9985105395317078}]}, {"text": "Our initial experiments involve algorithms that do not consider the positions of words in the sentences.", "labels": [], "entities": []}, {"text": "Thus, they are incapable of distinguishing among multiple instances of the same word type in a sentence.", "labels": [], "entities": []}, {"text": "We will say that these methods produce word type alignments.", "labels": [], "entities": [{"text": "word type alignments", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7008810738722483}]}, {"text": "We compare these algorithms on the basis of the best possible alignment of word tokens given an alignment of word types.", "labels": [], "entities": []}, {"text": "We goon to consider various ways of choosing a word token alignment fora given word type alignment, and all our final evaluations are conducted on the basis of the alignment of individual word tokens. and the hand alignments of the words in the trial and test data were created by Franz Och and Hermann Ney.", "labels": [], "entities": []}, {"text": "The manual word alignments for the English-Romanian test data were created by Rada Mihalcea and Ted Pedersen.", "labels": [], "entities": [{"text": "English-Romanian test data", "start_pos": 35, "end_pos": 61, "type": "DATASET", "confidence": 0.671161949634552}]}, {"text": "We computed the recall, precision, and AER on the held-out subset of the English-French data both for our Method 4C (using parameter values optimized on the development subset) and for IBM Model 4, computed using Och's Giza++ software package) trained on the same data as Method 4C.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9996011853218079}, {"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9987439513206482}, {"text": "AER", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9997000694274902}]}, {"text": "We used the default configuration file included with the version of Giza++ that we used, which resulted in five iterations of Model 1, followed by five iterations of the HMM model, followed by five iterations of Model 4.", "labels": [], "entities": []}, {"text": "We trained and evaluated the models in both directions, English-toFrench and French-to-English, as well as the union, intersection, and what call the \"refined\" combination of the two alignments.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We applied the same evaluation methodology to the English-Romanian data, with the results shown in  Comparison of the AER for Method 4C and IBM Model 4 shows that, in these experiments, only the refined combination of both directions of the Model 4 alignments outperforms our method, and only on the English-French data (and by a relatively small amount: 16% relative reduction in error rate).", "labels": [], "entities": [{"text": "AER", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.9803898930549622}, {"text": "IBM Model 4", "start_pos": 140, "end_pos": 151, "type": "DATASET", "confidence": 0.9294093052546183}, {"text": "error rate", "start_pos": 381, "end_pos": 391, "type": "METRIC", "confidence": 0.928472250699997}]}, {"text": "Our existing Perl implementation of Method 4C takes about 3.5 hours for the 500K sentence pair data set on a standard desktop computer.", "labels": [], "entities": []}, {"text": "It took over 8 hours to train each direction of Model 4 using Giza++ (which is written in C++).", "labels": [], "entities": []}, {"text": "We believe that if our method was ported to C++, our speed advantage over Giza++ would be substantially greater.", "labels": [], "entities": [{"text": "speed", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.960371732711792}]}, {"text": "Previous experience porting algorithms of the same general type as Method 4C from Perl to C++ has given us speed ups of a factor of 10 or more.", "labels": [], "entities": []}, {"text": "Note that we were unable to optimize the many options and free parameters of Giza++ on the development data, as we did with the parameters of Method 4C, which perhaps inhibits us from drawing stronger conclusions from these experiments.", "labels": [], "entities": []}, {"text": "However, it was simply impractical to do so, due the time required to re-train the Giza++ models with new settings.", "labels": [], "entities": []}, {"text": "With Method 4C, on the other hand, most of the time is spent either in computing initial corpus statistics that are independent of the parameters settings, or in performing the final corpus alignment once the parameters settings have been optimized.", "labels": [], "entities": []}, {"text": "Of the five parameters Method 4C requires, changes to three of them took less than one hour of retraining (on the English-French data -much lesson the English-Romanian data), and settings of the last two need to be tested only on the small amount of annotated development data, which took only a few seconds.", "labels": [], "entities": []}, {"text": "This made it possible to optimize the parameters of Method 4C in a small fraction of the time that would have been required for Giza++.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Recall/Precision Trade-Off for Method 1.", "labels": [], "entities": []}, {"text": " Table 2: Recall/Precision Trade-Off for Method 2.", "labels": [], "entities": []}, {"text": " Table 3: Recall/Precision Trade-Off for Method 3.", "labels": [], "entities": []}, {"text": " Table 4: Development Set AER for all Methods.", "labels": [], "entities": [{"text": "AER", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9408273696899414}]}]}