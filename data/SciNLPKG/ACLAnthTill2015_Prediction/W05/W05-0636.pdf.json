{"title": [{"text": "Joint Parsing and Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.6488240559895834}]}], "abstractContent": [{"text": "A striking feature of human syntactic processing is that it is context-dependent, that is, it seems to take into account semantic information from the discourse context and world knowledge.", "labels": [], "entities": [{"text": "human syntactic processing", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.630055715640386}]}, {"text": "In this paper, we attempt to use this insight to bridge the gap between SRL results from gold parses and from automatically-generated parses.", "labels": [], "entities": [{"text": "SRL", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9783289432525635}]}, {"text": "To do this, we jointly perform parsing and semantic role labeling, using a probabilistic SRL system to rerank the results of a probabilistic parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9695115089416504}, {"text": "semantic role labeling", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.5954828858375549}]}, {"text": "Our current results are negative, because a locally-trained SRL model can return inaccurate probability estimates.", "labels": [], "entities": [{"text": "SRL", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9227443337440491}]}], "introductionContent": [{"text": "Although much effort has gone into developing statistical parsing models and they have improved steadily over the years, in many applications that use parse trees errors made by the parser area major source of errors in the final output.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.711414635181427}]}, {"text": "A promising approach to this problem is to perform both parsing and the higher-level task in a single, joint probabilistic model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.9748668074607849}]}, {"text": "This not only allows uncertainty about the parser output to be carried upward, such as through an k-best list, but also allows information from higher-level processing to improve parsing.", "labels": [], "entities": []}, {"text": "For example, showed that performing parsing and information extraction in a joint model improves performance on both tasks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9753254055976868}, {"text": "information extraction", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7626192271709442}]}, {"text": "In particular, one suspects that attachment decisions, which are both notoriously hard and extremely important for semantic analysis, could benefit greatly from input from higher-level semantic analysis.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.9349974989891052}]}, {"text": "The recent interest in semantic role labeling provides an opportunity to explore how higher-level semantic information can inform syntactic parsing.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7062828739484152}, {"text": "syntactic parsing", "start_pos": 130, "end_pos": 147, "type": "TASK", "confidence": 0.7901577949523926}]}, {"text": "In previous work, it has been shown that SRL systems that use full parse information perform better than those that use shallow parse information, but that machine-generated parses still perform much worse than human-corrected gold parses.", "labels": [], "entities": [{"text": "SRL", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.978872537612915}]}, {"text": "The goal of this investigation is to narrow the gap between SRL results from gold parses and from automatic parses.", "labels": [], "entities": [{"text": "SRL", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.966158926486969}]}, {"text": "We aim to do this by jointly performing parsing and semantic role labeling in a single probabilistic model.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.5926688015460968}]}, {"text": "In both parsing and SRL, stateof-the-art systems are probabilistic; therefore, their predictions can be combined in a principled way by multiplying probabilities.", "labels": [], "entities": [{"text": "parsing", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.9712417125701904}, {"text": "SRL", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.98237544298172}]}, {"text": "In this paper, we rerank the k-best parse trees from a probabilistic parser using an SRL system.", "labels": [], "entities": []}, {"text": "We compare two reranking approaches, one that linearly weights the log probabilities, and the other that learns a reranker over parse trees and SRL frames in the manner of.", "labels": [], "entities": []}, {"text": "Currently, neither method performs better than simply selecting the top predicted parse tree.", "labels": [], "entities": []}, {"text": "We discuss some of the reasons for this; one reason being that the ranking over parse trees induced by the semantic role labeling score is unreliable, because the model is trained locally.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.5692696968714396}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Features used in baseline labeling classifier.", "labels": [], "entities": [{"text": "labeling classifier", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7898140549659729}]}, {"text": " Table 3: Comparison of Overall SRL F1 on devel- opment set by the type of parse trees used.", "labels": [], "entities": [{"text": "SRL F1", "start_pos": 32, "end_pos": 38, "type": "TASK", "confidence": 0.6065934747457504}]}, {"text": " Table 4: Overall results (top) and detailed results on  the WSJ test (bottom).", "labels": [], "entities": [{"text": "WSJ test", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.8141472339630127}]}]}