{"title": [{"text": "Hunmorph: open source word analysis", "labels": [], "entities": [{"text": "Hunmorph", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7280042171478271}, {"text": "open source word analysis", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.595471017062664}]}], "abstractContent": [{"text": "Common tasks involving orthographic words include spellchecking, stemming, morphological analysis, and morphological synthesis.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7127173542976379}, {"text": "morphological synthesis", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.772539347410202}]}, {"text": "To enable significant reuse of the language-specific resources across all such tasks, we have extended the functionality of the open source spellchecker MySpell, yielding a generic word analysis library, the runtime layer of the hunmorph toolkit.", "labels": [], "entities": []}, {"text": "We added an offline resource management component, hunlex, which complements the efficiency of our runtime layer with a high-level description language and a configurable precompiler.", "labels": [], "entities": []}, {"text": "0 Introduction Word-level analysis and synthesis problems range from strict recognition and approximate matching to full morphological analysis and generation.", "labels": [], "entities": []}, {"text": "Our technology is predicated on the observation that all of these problems are, when viewed algorith-mically, very similar: the central problem is to dynamically analyze complex structures derived from some lexicon of base forms.", "labels": [], "entities": []}, {"text": "Viewing word analysis routines as a unified problem means sharing the same codebase fora wider range of tasks, a design goal carried out by finding the parameters which optimize each of the analysis modes independently of the language-specific resources.", "labels": [], "entities": [{"text": "word analysis", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.7160549610853195}]}, {"text": "The C/C++ runtime layer of our toolkit, called hunmorph, was developed by extending the code-base of MySpell, a reimplementation of the well-known Ispell spellchecker.", "labels": [], "entities": [{"text": "Ispell spellchecker", "start_pos": 147, "end_pos": 166, "type": "DATASET", "confidence": 0.7936426997184753}]}, {"text": "Our technology, like the Ispell family of spellcheckers it descends from, enforces a strict separation between the language-specific resources (known as dictionary and affix files), and the runtime environment, which is independent of the target natural language.", "labels": [], "entities": []}, {"text": "Figure 1: Architecture Compiling accurate wide coverage machine-readable dictionaries and coding the morphology of a language can bean extremely labor-intensive task, so the benefit expected from reusing the language-specific input database across tasks can hardly be overestimated.", "labels": [], "entities": []}, {"text": "To facilitate this resource sharing and to enable systematic task-dependent optimizations from a central lexical knowledge base, we designed and implemented a powerful of-fline layer we call hunlex.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word-level analysis and synthesis problems range from strict recognition and approximate matching to full morphological analysis and generation.", "labels": [], "entities": [{"text": "approximate matching", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.6825839877128601}]}, {"text": "Our technology is predicated on the observation that all of these problems are, when viewed algorithmically, very similar: the central problem is to dynamically analyze complex structures derived from some lexicon of base forms.", "labels": [], "entities": []}, {"text": "Viewing word analysis routines as a unified problem means sharing the same codebase fora wider range of tasks, a design goal carried out by finding the parameters which optimize each of the analysis modes independently of the language-specific resources.", "labels": [], "entities": [{"text": "word analysis", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.7160549610853195}]}, {"text": "The C/C++ runtime layer of our toolkit, called hunmorph, was developed by extending the codebase of MySpell, a reimplementation of the wellknown Ispell spellchecker.", "labels": [], "entities": [{"text": "MySpell", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.9417392015457153}]}, {"text": "Our technology, like the Ispell family of spellcheckers it descends from, enforces a strict separation between the language-specific resources (known as dictionary and affix files), and the runtime environment, which is independent of the target natural language.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}