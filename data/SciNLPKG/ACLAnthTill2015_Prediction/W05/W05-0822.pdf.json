{"title": [{"text": "PORTAGE: A Phrase-based Machine Translation System", "labels": [], "entities": [{"text": "Phrase-based Machine Translation", "start_pos": 11, "end_pos": 43, "type": "TASK", "confidence": 0.7473374803860983}]}], "abstractContent": [{"text": "This paper describes the participation of the Portage team at NRC Canada in the shared task 1 of ACL 2005 Workshop on Building and Using Parallel Texts.", "labels": [], "entities": [{"text": "Portage team at NRC Canada", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.6477428257465363}, {"text": "ACL 2005 Workshop on Building and Using Parallel Texts", "start_pos": 97, "end_pos": 151, "type": "TASK", "confidence": 0.5932071606318156}]}, {"text": "We discuss Portage, a statistical phrase-based machine translation system, and present experimental results on the four language pairs of the shared task.", "labels": [], "entities": [{"text": "statistical phrase-based machine translation", "start_pos": 22, "end_pos": 66, "type": "TASK", "confidence": 0.5950713008642197}]}, {"text": "First, we focus on the French-English task using multiple resources and techniques.", "labels": [], "entities": []}, {"text": "Then we describe our contribution on the Finnish-English, Spanish-English and German-English language pairs using the provided data for the shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The rapid growth of the Internet has led to a rapid growth in the need for information exchange among different languages.", "labels": [], "entities": []}, {"text": "Machine Translation (MT) and related technologies have become essential to the information flow between speakers of different languages on the Internet.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8742833733558655}]}, {"text": "Statistical Machine Translation (SMT), a data-driven approach to producing translation systems, is becoming a practical solution to the longstanding goal of cheap natural language processing.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8484493593374888}]}, {"text": "In this paper, we describe Portage, a statistical phrase-based machine translation system, which we evaluated on all different language pairs that were provided for the shared task.", "labels": [], "entities": [{"text": "statistical phrase-based machine translation", "start_pos": 38, "end_pos": 82, "type": "TASK", "confidence": 0.5966777354478836}]}, {"text": "As Portage is a very 1 http://www.statmt.org/wpt05/mt-shared-task/ new system, our main goal in participating in the workshop was to test it out on different language pairs, and to establish baseline performance for the purpose of comparison against other systems and against future improvements.", "labels": [], "entities": []}, {"text": "To do this, we used a fairly standard configuration for phrase-based SMT, described in the next section.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.6942045092582703}]}, {"text": "Of the language pairs in the shared task, FrenchEnglish is particularly interesting to us in light of Canada's demographics and policy of official bilingualism.", "labels": [], "entities": []}, {"text": "We therefore divided our participation into two parts: one stream for French-English and another for Finnish-, German-, and Spanish-English.", "labels": [], "entities": []}, {"text": "For the French-English stream, we tested the use of additional data resources along with hand-coded rules for translating numbers and dates.", "labels": [], "entities": [{"text": "translating numbers and dates", "start_pos": 110, "end_pos": 139, "type": "TASK", "confidence": 0.8484695106744766}]}, {"text": "For the other streams, we used only the provided resources in a purely statistical framework (although we also investigated several automatic methods of coping with Finnish morphology).", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the architecture of the Portage system, including its hand-coded rules for French-English.", "labels": [], "entities": [{"text": "Portage system", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.6725322753190994}]}, {"text": "Experimental results for the four pairs of languages are reported in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 concludes and gives pointers to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments and evaluations on Portage using the diffe re ask.", "labels": [], "entities": [{"text": "Portage", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.868658185005188}]}, {"text": "The training data was provided for the ask as follows: The development test data was split into two parts: The first part that includes 1,000 sentences in each language with reference translations into English served in the optimization of weights for both the decoding and rescoring models.", "labels": [], "entities": []}, {"text": "In this study, number of n-best lists was set to 1,000.", "labels": [], "entities": []}, {"text": "The second part, which includes 1,000 sentences in each language with referenc used in the evaluation of the performance of the translation models.", "labels": [], "entities": []}, {"text": "Our goal for this language pair was to conduct experiments on hniques: 1.", "labels": [], "entities": []}, {"text": "Method E is based on the Europarl corpus as training data, 2.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9958158433437347}]}, {"text": "Method E-H is based on both Europarl and Hansard corpora as training data, Method E-p is based on the Europ as training data and parsing numbers and dates in the preprocessing phase, Method E-H-p is based on both Europarl and Hansa parsing numbers and date in the preprocessing phase.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.9646661877632141}, {"text": "Hansard corpora", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.8625591695308685}, {"text": "Europ", "start_pos": 102, "end_pos": 107, "type": "DATASET", "confidence": 0.9880598187446594}, {"text": "Europarl", "start_pos": 213, "end_pos": 221, "type": "DATASET", "confidence": 0.9413383603096008}, {"text": "Hansa parsing", "start_pos": 226, "end_pos": 239, "type": "TASK", "confidence": 0.5911209583282471}]}, {"text": "Results are shown in for the FrenchEnglish task.", "labels": [], "entities": [{"text": "FrenchEnglish task", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.9045329689979553}]}, {"text": "The first column of indicates the method, the second column gives results for decoding with Canoe only, and the third column for decoding and rescoring with Canoe.", "labels": [], "entities": [{"text": "Canoe", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.9395060539245605}, {"text": "Canoe", "start_pos": 157, "end_pos": 162, "type": "DATASET", "confidence": 0.9477903246879578}]}, {"text": "For comparison between the four methods, there was an improvement in terms of BLEU scores when using two language models and two translation models generated from Europarl and Hansard corpora; however, parsing numbers and dates had a negative impact on the ranslation els. of increased trade within North merica but also functions as a good counterpoint for French-English.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9995152950286865}, {"text": "Europarl", "start_pos": 163, "end_pos": 171, "type": "DATASET", "confidence": 0.9859994053840637}, {"text": "Hansard corpora", "start_pos": 176, "end_pos": 191, "type": "DATASET", "confidence": 0.8395668864250183}, {"text": "parsing", "start_pos": 202, "end_pos": 209, "type": "TASK", "confidence": 0.9680221676826477}]}, {"text": "BLEU scores for the French-English test sentences A noteworthy feature of these results is that the improvement given by the out-of-domain Hansard corpus was very slight.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9897488951683044}, {"text": "Hansard corpus", "start_pos": 139, "end_pos": 153, "type": "DATASET", "confidence": 0.9665423333644867}]}, {"text": "Although we suspect that somewhat better performance could have been achieved by better weight optimization, this result clearly underscores the importance of matching training and test domains.", "labels": [], "entities": [{"text": "weight optimization", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.6852854490280151}]}, {"text": "A related point is that our number and date translation rules actually caused a performance drop due to the fact that they were optimized for typographical conventions prevalent in Hansard, which are quite different from those used in Europarl.", "labels": [], "entities": [{"text": "number and date translation", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.5977437645196915}, {"text": "Hansard", "start_pos": 181, "end_pos": 188, "type": "DATASET", "confidence": 0.9621903300285339}, {"text": "Europarl", "start_pos": 235, "end_pos": 243, "type": "DATASET", "confidence": 0.9812718033790588}]}, {"text": "Our best result ranked third in the shared WPT05 French-English task , with a difference of 0.74 in terms of BLEU score from the first rank participant, and a difference of 0.67 in terms o BLEU score from the second ranked participant.", "labels": [], "entities": [{"text": "WPT05 French-English task", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.5682170192400614}, {"text": "BLEU score", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9824480712413788}, {"text": "BLEU score", "start_pos": 189, "end_pos": 199, "type": "METRIC", "confidence": 0.9761053025722504}]}, {"text": "The WPT05 workshop provides a good opportunity to achieve our benchmarking goals with corpora that provide challenging difficulties.", "labels": [], "entities": [{"text": "WPT05 workshop", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.829713374376297}]}, {"text": "German and Finnish are languages that make considerable use of compounding.", "labels": [], "entities": []}, {"text": "Finnish, in addition, has a particularly complex morphology that is organized on principles that are quite different from any in English.", "labels": [], "entities": []}, {"text": "This results in much longer word forms each of which occurs very infrequently.", "labels": [], "entities": []}, {"text": "Our original intent was to propose a number of possible statistical approaches to analyzing and splitting these word forms and improving our results.", "labels": [], "entities": []}, {"text": "Since none of these yielded results as good as the baseline, we will continue this work until we understand what is really needed.", "labels": [], "entities": []}, {"text": "We also care very much about translating between French and English in Canada and plan to spend a lot of extra effort on difficulties that occur in this case.", "labels": [], "entities": [{"text": "translating between French and English", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.8874045133590698}]}, {"text": "To establish our baseline, the only preprocessing we did was lowercasing (using the provided tokenization).", "labels": [], "entities": []}, {"text": "Canoe was run without any special settings, although weights for distortion, word penalty, language model, and translation model were optimized using a grid search, as described above.", "labels": [], "entities": [{"text": "translation", "start_pos": 111, "end_pos": 122, "type": "TASK", "confidence": 0.9746032357215881}]}, {"text": "Rescoring was also done, and usually resulted in at least an extra BLEU point.", "labels": [], "entities": [{"text": "Rescoring", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9499028325080872}, {"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9992184638977051}]}, {"text": "Our final results are shown in.", "labels": [], "entities": []}, {"text": "Ranks at the shared WPT05 Finnish-, German-, and SpanishEnglish tasks were assigned as second, third and fourth, with differences of 1.06, 1.87 ter s of BLEU sc", "labels": [], "entities": [{"text": "WPT05", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.7051494717597961}, {"text": "BLEU sc", "start_pos": 153, "end_pos": 160, "type": "METRIC", "confidence": 0.9281739890575409}]}], "tableCaptions": []}