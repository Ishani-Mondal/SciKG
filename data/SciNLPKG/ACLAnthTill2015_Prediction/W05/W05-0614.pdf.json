{"title": [{"text": "Intentional Context in Situated Natural Language Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "Natural language interfaces designed for situationally embedded domains (e.g. cars, videogames) must incorporate knowledge about the users' context to address the many ambiguities of situated language use.", "labels": [], "entities": []}, {"text": "We introduce a model of situated language acquisition that operates in two phases.", "labels": [], "entities": [{"text": "situated language acquisition", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.6104774375756582}]}, {"text": "First, intentional context is represented and inferred from user actions using probabilistic context free grammars.", "labels": [], "entities": []}, {"text": "Then, utterances are mapped onto this representation in a noisy channel framework.", "labels": [], "entities": []}, {"text": "The acquisition model is trained on unconstrained speech collected from subjects playing an interactive game, and tested on an understanding task.", "labels": [], "entities": []}], "introductionContent": [{"text": "As information technologies move off of our desktops and into the world, the need for Natural Language Processing (NLP) systems that exploit information about the environment becomes increasingly apparent.", "labels": [], "entities": []}, {"text": "Whether in physical environments (for cars and cell phones) or in virtual ones (for videogames and training simulators), applications are beginning to demand language interfaces that can understand unconstrained speech about constrained domains.", "labels": [], "entities": []}, {"text": "Unlike most text-based NLP research, which focuses on open-domain problems, work we refer to as situated NLP focuses on improving language processing by exploiting domain-specific information about the non-linguistic situational context of users' interactions.", "labels": [], "entities": []}, {"text": "For applications where agents interact in shared environments, such information is critical for successful communication.", "labels": [], "entities": []}, {"text": "Previous work in situated NLP has focused on methods for grounding the meaning of words in physical and virtual environments.", "labels": [], "entities": [{"text": "situated NLP", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.6505866944789886}, {"text": "grounding the meaning of words in physical and virtual environments", "start_pos": 57, "end_pos": 124, "type": "TASK", "confidence": 0.766700941324234}]}, {"text": "The motivation for this work comes from the inability of textbased NLP technologies to offer viable models of semantics for human computer interaction in shared environments.", "labels": [], "entities": []}, {"text": "For example, imagine a situation in which a human user is interacting with a robotic arm around a table of different colored objects.", "labels": [], "entities": []}, {"text": "If the human were to issue the command \"give me the blue one,\" both the manually-coded) and statistical models) of meaning employed in text-based NLP are inadequate; for, in both models, the meaning of a word is based only on its relations to other words.", "labels": [], "entities": []}, {"text": "However, in order for the robot to successfully \"give me the blue one,\" it must be able to link the meaning of the words in the utterance to its perception of the environment).", "labels": [], "entities": []}, {"text": "Thus, recent work on grounding meaning has focused on how words and utterances map onto physical descriptions of the environment: either in the form of perceptual representations or control schemas).", "labels": [], "entities": []}, {"text": "While such physical descriptions are useful representations for some classes of words (e.g., colors, shapes, physical movements), they are insufficient for more abstract language, such as that which denotes intentional action.", "labels": [], "entities": []}, {"text": "This insufficiency stems from the fact that intentional actions (i.e. actions performed with the purpose of achieving a goal) are highly ambiguous when described only in terms of their physically observable characteristics.", "labels": [], "entities": []}, {"text": "For example, imagine a situation in which one person moves a cup towards another person and utters the unknown word \"blicket.\"", "labels": [], "entities": []}, {"text": "Now, based only on the physical description of this action, one might come to think of \"blicket\" as meaning anything from \"give cup\", to \"offer drink\", to \"ask for change.\"", "labels": [], "entities": []}, {"text": "This ambiguity stems from the lack of contextual information that strictly perceptual descriptions of action provide.", "labels": [], "entities": []}, {"text": "This research presents a methodology for modeling the intentional context of utterances and describes how such representations can be used in a language learning task.", "labels": [], "entities": []}, {"text": "We decompose language learning into two phases: intention recognition and linguistic mapping.", "labels": [], "entities": [{"text": "intention recognition", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7049550414085388}, {"text": "linguistic mapping", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7295503467321396}]}, {"text": "In the first phase, we model intentional action using a probabilistic context free grammar.", "labels": [], "entities": []}, {"text": "We use this model to parse sequences of observed physical actions, thereby inferring a hierarchical tree representation of a user's intentions.", "labels": [], "entities": [{"text": "parse sequences of observed physical actions", "start_pos": 21, "end_pos": 65, "type": "TASK", "confidence": 0.775990883509318}]}, {"text": "In the second phase, we use a noisy channel model to learn a mapping between utterances and nodes in that tree representation.", "labels": [], "entities": []}, {"text": "We present pilot situated language acquisition experiments using a dataset of paired spontaneous speech and action collected from human subjects interacting in a shared virtual environment.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.7262443602085114}]}, {"text": "We evaluate the acquired model on a situated language understanding task.", "labels": [], "entities": [{"text": "language understanding task", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7753652036190033}]}], "datasetContent": [{"text": "Methodologies for evaluating language acquisition tasks are not standardized.", "labels": [], "entities": [{"text": "language acquisition tasks", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.7878848413626353}]}, {"text": "Given our model, there exists the possibility of employing intrinsic measures of success, such as word alignment accuracy.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.7725285887718201}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.7612252831459045}]}, {"text": "However, we choose to measure the success of learning by examining the related (and more natural) task of language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.7110123038291931}]}, {"text": "For each subject pair, the linguistic mapping algorithms are trained on the first four trials of game play and tested on the final trial.", "labels": [], "entities": [{"text": "linguistic mapping", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7097392976284027}]}, {"text": "(This gives on average 130 utterances of training data and 30 utterances of testing data per pair.)", "labels": [], "entities": []}, {"text": "For each utterance in the test data, we calculate the likelihood that it was generated by each frame seen in testing.", "labels": [], "entities": []}, {"text": "We select the maximum likelihood frame as the system's hypothesized meaning for the test utterance, and examine both how often the maximum likelihood estimate exactly matches the true frame (frame accuracy), and how many of the role fillers within the estimated frame match the role fillers of the true frame (role accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.7946919798851013}, {"text": "accuracy", "start_pos": 315, "end_pos": 323, "type": "METRIC", "confidence": 0.9193050265312195}]}, {"text": "Figure 4: Inferred intention tree (with semantic frames) from human subject game play.", "labels": [], "entities": []}, {"text": "For each subject, the algorithm's parameters are optimized using data from all other subjects.", "labels": [], "entities": []}, {"text": "We assume correct knowledge of the temporal alignment between utterances and actions.", "labels": [], "entities": []}, {"text": "In future work, we will relax this assumption to explore the effects of not knowing which actions correspond to which utterances in time.", "labels": [], "entities": []}, {"text": "To examine the performance of the model, three experiments are presented.", "labels": [], "entities": []}, {"text": "Experiment 1 examines the basic performance of the algorithms on the language understanding task described above given uniform priors.", "labels": [], "entities": [{"text": "language understanding task", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.8171102007230123}]}, {"text": "The system is tested under two conditions: 1) using the extended EM algorithm given an unknown utterance-to-level alignment, and 2) using the standard EM algorithm given the correct utterance-to-level alignment.", "labels": [], "entities": []}, {"text": "Experiment 2 tests the benefit of incorporating intentional context directly into language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.6930151283740997}]}, {"text": "This is done by using the parse probability of each hypothesized intention as the See Fleischman and for experiments detailing performance on specific word categories.", "labels": [], "entities": []}, {"text": "source probability in Equation 1.", "labels": [], "entities": []}, {"text": "Thus, given an utterance to understand, we cycle through all possible actions in the grammar, parse each one as if it were observed, and use the probability generated by the parser as its prior probability.", "labels": [], "entities": []}, {"text": "By changing the weighting coefficient (\u03b1) between the source and channel probabilities, we show the range of performances of the system from using no context at all (\u03b1=1) to using only context itself (\u03b1=0) in understanding.", "labels": [], "entities": []}, {"text": "Performance is on a language understanding task (baseline equivalent to choosing most frequent frame) Experiment 3 studies to what extent inferred tree structures are necessary when modeling language acquisition.", "labels": [], "entities": [{"text": "language understanding task", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.7929217418034872}]}, {"text": "Although, in section 1, we have presented intuitive reasons why such structures are required, one might argue that inferring trees over sequences of observed actions might not actually improve understanding performance when compared to a model trained only on the observed actions themselves.", "labels": [], "entities": []}, {"text": "This hypothesis is tested by comparing a model trained given the correct utterance-to-level alignment (described in experiment 1) with a model in which each utterance is aligned to the leaf node (i.e. observed action) below the correct level of alignment.", "labels": [], "entities": []}, {"text": "For example, in figure 4, this would correspond to mapping the utterance \"go through the door\", not to \"GO THROUGH DOOR\", but rather to \"CLICK_ON LEVER.\"", "labels": [], "entities": [{"text": "GO THROUGH DOOR", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.7349228461583456}, {"text": "CLICK_ON LEVER", "start_pos": 137, "end_pos": 151, "type": "METRIC", "confidence": 0.807207465171814}]}], "tableCaptions": []}