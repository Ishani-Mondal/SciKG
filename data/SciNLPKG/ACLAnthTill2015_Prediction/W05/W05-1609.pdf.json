{"title": [], "abstractContent": [{"text": "The paper presents an approach to utterance planning , which can dynamically use context information about the environment in which a dialogue is situated.", "labels": [], "entities": [{"text": "utterance planning", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.9376799762248993}]}, {"text": "The approach is functional in nature, using systemic networks to specify its planning grammar.", "labels": [], "entities": []}, {"text": "The planner takes a description of a communicative goal as input, and produces one or more logical forms that can express that goal in a contextually appropriate way.", "labels": [], "entities": []}, {"text": "Both the goal and the resulting logical forms are expressed in a single formalism as ontologically rich, relational structures.", "labels": [], "entities": []}, {"text": "To realize the logical forms, OpenCCG is used.", "labels": [], "entities": [{"text": "OpenCCG", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9168633222579956}]}, {"text": "The paper focuses primarily on the implementation , but also discusses how the planning grammar can be based on the grammar used in OpenCCG, and trained on (parseable) data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conversational robots often need to carryout a dialogue with other agents while being situated in a dynamic environment.", "labels": [], "entities": []}, {"text": "This poses an interesting challenge: For the robot to converse in a natural manner with other interlocutors its communication needs to be contextually appropriate, but referential contexts may naturally change in such a setting.", "labels": [], "entities": []}, {"text": "The robot thus must be actively aware of the environment, and use this awareness when producing utterances.", "labels": [], "entities": []}, {"text": "Here, we present an approach to utterance planning where we can use context information to dynamically guide decisions we need to make during planning.", "labels": [], "entities": [{"text": "utterance planning", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8871752023696899}]}, {"text": "These decisions are paradigmatic in nature, and get us from a logical form stating a communicative intention, to a logical form (or a set thereof) expressing the intention in a contextually appropriate way.", "labels": [], "entities": []}, {"text": "We specify a planning grammar as a systemic network, in the tradition of generation systems for systemic functional grammar.", "labels": [], "entities": []}, {"text": "We process using an agenda/chart-based algorithm, (meaning there is no \"determinicity\" assumption).", "labels": [], "entities": []}, {"text": "The utterance planner itself is embedded in a distributed architecture that makes it possible to access the various models of the situated environ-ment that the robot maintains.", "labels": [], "entities": []}, {"text": "This way we can dynamically use contextual information during the planning process.", "labels": [], "entities": []}, {"text": "The logical forms we operate on are all specified in a single formalism, namely Hybrid Logic Dependency Semantics (HLDS), meaning we have a representational continuum between discourse-level and utterance-level representations, and can guide utterance planning through content decisions made at higher levels.", "labels": [], "entities": [{"text": "Hybrid Logic Dependency Semantics (HLDS)", "start_pos": 80, "end_pos": 120, "type": "TASK", "confidence": 0.7337667260851178}]}, {"text": "The logical form we obtain from the utterance planner serves as input to a separate OpenCCG realizer.", "labels": [], "entities": []}, {"text": "The resulting approach is related to].", "labels": [], "entities": []}, {"text": "We adopt their idea of an utterance as a description, generated from a communicative goal, and also use an \"ontologically promiscuous\" formalism for representing meaning.", "labels": [], "entities": []}, {"text": "We differ in that we separate out the realizer, though minimize the need for backtracking in the planner by allowing for multiple, alternative logical forms to be sent to the realizer, cf..", "labels": [], "entities": []}, {"text": "Also, to establish contextual status of an entity, we can in principle use any type of model that the robot maintains of the environment, as long as we have an ontology on which we can establish a common ground in interpretation.", "labels": [], "entities": []}, {"text": "Our approach places us squarely in the full generation camp, but there is a continuum: Using the approach to including canned text as proposed in, we can freely position the actual planner between full generation and pre-baked generation.", "labels": [], "entities": []}, {"text": "We can use the flexibility of full generation where necessary, notably to achieve contextual appropriateness, but if desired we can use more direct methods to specify content.", "labels": [], "entities": []}, {"text": "Our approach owes its perspective to systemic approaches, particularly KPML.", "labels": [], "entities": [{"text": "KPML", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.8254954218864441}]}, {"text": "Where we differ is in the creation of, and relation between, the resources we use in the parser, the realizer, and the utterance planner: We use one and the same grammar for both parsing and realization (though with different algorithms), and we can derive the systemic network for utterance planning from this grammar ( \u00a74) to ensure that we have a single formulation of the robot's linguistic knowledge, in the form of a CCG grammar.", "labels": [], "entities": [{"text": "parsing and realization", "start_pos": 179, "end_pos": 202, "type": "TASK", "confidence": 0.7586638430754343}, {"text": "utterance planning", "start_pos": 282, "end_pos": 300, "type": "TASK", "confidence": 0.7944287359714508}]}, {"text": "We also point out ( \u00a74), how we can in principle train the planner, like e.g..", "labels": [], "entities": []}, {"text": "Overview In \u00a72 we briefly discuss HLDS, and the overall architecture in which we employ the utterance planner.", "labels": [], "entities": [{"text": "HLDS", "start_pos": 34, "end_pos": 38, "type": "TASK", "confidence": 0.9465001821517944}]}, {"text": "\u00a73 presents the planner, focusing on the basic structure of the planning grammar, and context sensitivity.", "labels": [], "entities": []}, {"text": "\u00a74 discusses how we can base the planning grammar on the specification of the grammar we employ for parsing and realization, and how we can in principle train the planning grammar given a corpus of (analyzable) utterances.", "labels": [], "entities": [{"text": "parsing and realization", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.85744708776474}]}], "datasetContent": [], "tableCaptions": []}