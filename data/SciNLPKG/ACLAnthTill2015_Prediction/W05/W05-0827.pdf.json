{"title": [{"text": "Improving Phrase-Based Statistical Translation by modifying phrase extraction and including several features", "labels": [], "entities": [{"text": "Improving Phrase-Based Statistical Translation", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.859392374753952}, {"text": "phrase extraction", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7157085090875626}]}], "abstractContent": [{"text": "Nowadays, most of the statistical translation systems are based on phrases (i.e. groups of words).", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7238222658634186}]}, {"text": "In this paper we study different improvements to the standard phrase-based translation system.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.760737806558609}]}, {"text": "We describe a modified method for the phrase extraction which deals with larger phrases while keeping a reasonable number of phrases.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.811790943145752}]}, {"text": "We also propose additional features which lead to a clear improvement in the performance of the translation.", "labels": [], "entities": []}, {"text": "We present results with the EuroParl task in the direction Spanish to English and results from the evaluation of the shared task \"Exploiting Parallel Texts for Statistical Machine Translation\" (ACL Workshop on Parallel Texts 2005).", "labels": [], "entities": [{"text": "EuroParl", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.9599807858467102}, {"text": "Statistical Machine Translation\" (ACL Workshop on Parallel Texts 2005)", "start_pos": 160, "end_pos": 230, "type": "TASK", "confidence": 0.6635515242815018}]}], "introductionContent": [{"text": "Statistical Machine Translation (SMT) is based on the assumption that every sentence e in the target language is a possible translation of a given sentence fin the source language.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8158038208882014}]}, {"text": "The main difference between two possible translations of a given sentence is a probability assigned to each, which has to be learned from a bilingual text corpus.", "labels": [], "entities": []}, {"text": "Thus, the translation of a source sentence f can be formulated as the search of the target sentence e that maximizes the translation probability P (e|f ), If we use Bayes rule to reformulate the translation probability, we obtain, This translation model is known as the sourcechannel approach and it consists on a language model P (e) and a separate translation model P (f |e).", "labels": [], "entities": []}, {"text": "In the last few years, new systems tend to use sequences of words, commonly called phrases, aiming at introducing word context in the translation model.", "labels": [], "entities": []}, {"text": "As alternative to the source-channel approach the decision rule can be modeled through a log-linear maximum entropy framework.", "labels": [], "entities": []}, {"text": "The features functions, h m , are the system models (translation model, language model and others) and weigths, \u03bb i , are typically optimized to maximize a scoring function.", "labels": [], "entities": []}, {"text": "It is derived from the Maximum Entropy approach suggested by fora natural language understanding task.", "labels": [], "entities": [{"text": "natural language understanding task", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.7273622825741768}]}, {"text": "It has the advantatge that additional features functions can be easily integrated in the overall system.", "labels": [], "entities": []}, {"text": "This paper addresses a modification of the phrase-extraction algorythm in.", "labels": [], "entities": []}, {"text": "It also combines several interesting features and it reports an important improvement from the baseline.", "labels": [], "entities": []}, {"text": "It is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the baseline; the following section explains the modification in the phrase extraction; section 4 shows the different features which have been taken into account; section 5 presents the evaluation framework; and the final section shows some conclusions on the experiments in the paper and on the results in the shared task.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7886068820953369}]}], "datasetContent": [{"text": "The decoder used for the presented translation system is reported in.", "labels": [], "entities": []}, {"text": "This decoder is called MARIE and it takes into account simultaneously all the 7 features functions described above.", "labels": [], "entities": [{"text": "MARIE", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9642930626869202}]}, {"text": "It implements a beam-search strategy.", "labels": [], "entities": []}, {"text": "As evaluation criteria we use: the Word Error Rate (WER), the BLEU score and the NIST score.", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 35, "end_pos": 56, "type": "METRIC", "confidence": 0.9177520175774893}, {"text": "BLEU score", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9841353595256805}, {"text": "NIST score", "start_pos": 81, "end_pos": 91, "type": "DATASET", "confidence": 0.730796217918396}]}, {"text": "As follows we report the results for several experiments that show the performance of: the baseline, adding the posterior probability, IBM Model 1 and IBM1 \u22121 , and, finally, the modification of the phrases extraction.", "labels": [], "entities": [{"text": "posterior probability", "start_pos": 112, "end_pos": 133, "type": "METRIC", "confidence": 0.9376222789287567}, {"text": "IBM Model 1", "start_pos": 135, "end_pos": 146, "type": "DATASET", "confidence": 0.8945365150769552}, {"text": "phrases extraction", "start_pos": 199, "end_pos": 217, "type": "TASK", "confidence": 0.6932259947061539}]}, {"text": "Significant improvements can be obtained by tuning the parameters of the features adequately.", "labels": [], "entities": []}, {"text": "In the complet system we have 7 parameters to tune: the relatives frecuencies P (f |e) and P (e|f ), IBM Model 1 and its inverse, the word penalty, the phrase penalty and the weight of the language model.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 101, "end_pos": 112, "type": "DATASET", "confidence": 0.8637305299441019}]}, {"text": "We applied the widely used algorithm SIMPLEX to optimise.", "labels": [], "entities": []}, {"text": "In (line 5th), we seethe final results.", "labels": [], "entities": []}, {"text": "We report the results of the baseline.", "labels": [], "entities": []}, {"text": "We use the union alignment and we extract the BP of length 3.", "labels": [], "entities": [{"text": "BP", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.9944901466369629}]}, {"text": "As default language model feature, we use the standard trigram with smoothing Kneser-Ney and interpolation.", "labels": [], "entities": []}, {"text": "Also we tune the parameters (only two parameters) with the SIM-PLEX algorithm (see).", "labels": [], "entities": []}, {"text": "shows the effect of using the posterior probability: P (e|f ).", "labels": [], "entities": []}, {"text": "We use all the features but the P (e|f ) and we optimise the parameters.", "labels": [], "entities": []}, {"text": "We seethe results without this feature decrease around 1.1 points both in BLEU and WER (see line 2rd and 5th in).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.999051034450531}, {"text": "WER", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9968029260635376}]}, {"text": "We do the same as in the paragraph above, we do not consider the IBM Model 1 and the IBM1 \u22121 . Under these conditions, the translation's quality decreases around 1.3 points both in BLEU and WER (see line 3th and 5th in).", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 65, "end_pos": 76, "type": "DATASET", "confidence": 0.9543533523877462}, {"text": "BLEU", "start_pos": 181, "end_pos": 185, "type": "METRIC", "confidence": 0.9991554021835327}, {"text": "WER", "start_pos": 190, "end_pos": 193, "type": "METRIC", "confidence": 0.9941186904907227}]}, {"text": "Modification of the Phrase Extraction.", "labels": [], "entities": [{"text": "Phrase Extraction", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8127878904342651}]}, {"text": "Finally, we made an experiment without modification of the phrases' length.", "labels": [], "entities": []}, {"text": "We can seethe comparison between: (1) the phrases of fixed maximum length of 3; and (2) including phrases with a maximum length of 5 which cannot be generated by smaller phrases.", "labels": [], "entities": []}, {"text": "We can see it in (lines 4th and 5th).", "labels": [], "entities": []}, {"text": "We observe that there is no much difference between the number of phrases, so this approach does not require more resources.", "labels": [], "entities": []}, {"text": "However, we get slightly better scores.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of training and test corpus", "labels": [], "entities": []}, {"text": " Table 2: Results for the different experiments with optimized parameters in the direction SPA->ENG", "labels": [], "entities": [{"text": "SPA->ENG", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.6719603935877482}]}, {"text": " Table 3: Results for the ACL training and ACL test", "labels": [], "entities": []}]}