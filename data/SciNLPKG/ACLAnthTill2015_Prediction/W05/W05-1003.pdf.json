{"title": [{"text": "Identifying Concept Attributes Using a Classifier", "labels": [], "entities": [{"text": "Identifying Concept Attributes", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9461827476819357}]}], "abstractContent": [{"text": "We developed a novel classification of concept attributes and two supervised classifiers using this classification to identify concept attributes from candidate attributes extracted from the Web.", "labels": [], "entities": []}, {"text": "Our binary (attribute / non-attribute) classifier achieves an accuracy of 81.82% whereas our 5-way classifier achieves 80.35%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9994775652885437}]}], "introductionContent": [{"text": "The assumption that concept attributes and, more in general, features are an important aspect of conceptual representation is widespread in all disciplines involved with conceptual representations, from Artificial Intelligence / Knowledge Representation (starting with at least and down to (), Linguistics (e.g., in the theories of the lexicon based on typed feature structures and/or Pustejovsky's Generative Lexicon theory: (Pustejovsky 1995)) and Psychology (.", "labels": [], "entities": [{"text": "Artificial Intelligence / Knowledge Representation", "start_pos": 203, "end_pos": 253, "type": "TASK", "confidence": 0.6737956881523133}]}, {"text": "This being the case, it is surprising how little attention has been devoted to this aspect of lexical representation in work on large-scale lexical semantics in Computational Linguistics.", "labels": [], "entities": [{"text": "lexical representation", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.7622361183166504}]}, {"text": "The most extensive resource at The term attribute is used informally hereto indicate the type of relational information about concepts that is expressed using so-called roles in Description Logics ()-i.e., excluding IS-A style information (that cars are vehicles, for instance).", "labels": [], "entities": []}, {"text": "It is meant to be a more restrictive term than the term feature, often used to indicate any property of concepts, particularly in Psychology.", "labels": [], "entities": []}, {"text": "We are carrying out a systematic analysis of the sets of features used in work such as) (see Discussion).", "labels": [], "entities": []}, {"text": "our disposal, WordNet contains very little information that would be considered as being about 'attributes'-only information about parts, not about qualities such as height, or even to the values of such attributes in the adjective network-and this information is still very sparse.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.9790627956390381}]}, {"text": "On the other hand, the only work on the extraction of lexical semantic relations we are aware of has concentrated on the type of relations found in WordNet: hyponymy and meronymy).", "labels": [], "entities": [{"text": "extraction of lexical semantic relations", "start_pos": 40, "end_pos": 80, "type": "TASK", "confidence": 0.8008141160011292}, {"text": "WordNet", "start_pos": 148, "end_pos": 155, "type": "DATASET", "confidence": 0.9462457895278931}]}, {"text": "The work discussed here could be perhaps best described as an example of empirical ontology: using linguistics and philosophical ideas to improve the results of empirical work on lexical / ontology acquisition, and vice versa, using findings from empirical analysis to question some of the assumptions of theoretical work on ontology and the lexicon.", "labels": [], "entities": [{"text": "lexical / ontology acquisition", "start_pos": 179, "end_pos": 209, "type": "TASK", "confidence": 0.708792194724083}]}, {"text": "Specifically, we discuss work on the acquisition of (nominal) concept attributes whose goal is twofold: on the one hand, to clarify the notion of 'attribute' and its role in lexical semantics, if any; on the other, to develop methods to acquire such information automatically (e.g., to supplement WordNet).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 297, "end_pos": 304, "type": "DATASET", "confidence": 0.9375572800636292}]}, {"text": "The structure of the paper is as follows.", "labels": [], "entities": []}, {"text": "After a short review of relevant literature on extracting semantic relations and on attributes in the lexicon, we discuss our classification of attributes, followed by the features we used to classify them.", "labels": [], "entities": []}, {"text": "We then discuss our training methods and the results we achieved.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained two classifiers: a 2-way classifier that simply classifies candidate attributes into attributes and non-attributes, and a 5-way classifier that classifies candidate attributes into activities, parts & related-objects, qualities, related-agents, and nonattributes.", "labels": [], "entities": []}, {"text": "These classifiers were trained using decision trees algorithm (J48) from WEKA (: Five examples of training instances.", "labels": [], "entities": [{"text": "WEKA", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.8948574066162109}]}, {"text": "The values for morph are as follows: DV: derived from verb; BN: basic noun; DA: derived from adjective Our training and testing material was acquired as follows.", "labels": [], "entities": [{"text": "BN", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.962176501750946}, {"text": "DA", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.9408925771713257}]}, {"text": "We started from the 24,178 candidate attributes collected for the concepts in the balanced concept dataset we recently developed (Almuhareb and).", "labels": [], "entities": []}, {"text": "We threw out every candidate attribute with a Google frequency less than 20; this reduced the number of candidate attributes to 4,728.", "labels": [], "entities": []}, {"text": "We then removed words other than nouns and gerunds as discussed above, obtaining 4,296 candidate attributes.", "labels": [], "entities": []}, {"text": "The four types of input features for this filtered set of candidate attributes were computed as discussed in the previous section.", "labels": [], "entities": []}, {"text": "The best results were obtained using all of these features.", "labels": [], "entities": []}, {"text": "A training set of 1,155 candidate attributes was selected and hand-classified (see below for agreement.", "labels": [], "entities": []}, {"text": "We tried to include enough samples for each attribute class in the training set.", "labels": [], "entities": []}, {"text": "shows the input features for five different training examples, one for each attribute class.", "labels": [], "entities": []}, {"text": "For a qualitative idea of the behavior of our classifier, the best attributes for some concepts are listed in Appendix A. We concentrate hereon quantitative analyses.", "labels": [], "entities": []}, {"text": "Our two classifiers were evaluated, first of all, using 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "The 2-way classifier correctly classified 81.82% of the candidate attributes (the baseline accuracy is 80.61%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9808030128479004}]}, {"text": "The 5-way classifier correctly classified 80.35% of the attributes (the baseline accuracy is 23.55%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9805837869644165}]}, {"text": "The precision / recall results are shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995204210281372}, {"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9649900197982788}]}, {"text": "As it can be seen from, both classifiers achieve good F values for all classes except for the non-attribute class: F-measures range from 81% to 95%.", "labels": [], "entities": [{"text": "F", "start_pos": 54, "end_pos": 55, "type": "METRIC", "confidence": 0.997377872467041}, {"text": "F-measures", "start_pos": 115, "end_pos": 125, "type": "METRIC", "confidence": 0.9830489158630371}]}, {"text": "With the 2-way classifier, the valid attribute class has an F-measure of 89.2%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9994016885757446}]}, {"text": "With the 5-way classifier, related-agent is the most accurate class (F = 95%) followed by part & related-object, activity, and quality (86.2%, 84.9%, and 81.0%, respectively).", "labels": [], "entities": [{"text": "F", "start_pos": 69, "end_pos": 70, "type": "METRIC", "confidence": 0.971367359161377}]}, {"text": "With non-attribute, however, we find an F of 41.7% in the 2-way classification, and 53.8% in the 5-way classification.", "labels": [], "entities": [{"text": "F", "start_pos": 40, "end_pos": 41, "type": "METRIC", "confidence": 0.9992966651916504}]}, {"text": "This suggests that the best strategy for lexicon building would be to use these classifiers to 'find' attributes rather than 'filter' non-attributes.", "labels": [], "entities": [{"text": "lexicon building", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7257537394762039}]}, {"text": "Next, we evaluated the accuracy of the attribute classifiers against two human judges (the authors).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9989303946495056}]}, {"text": "We randomly selected a concept from each of the 21 classes in the balanced dataset.", "labels": [], "entities": []}, {"text": "Next, we used the classifiers to classify the 20 best candidate attributes of each concept, as determined by their ttest scores.", "labels": [], "entities": []}, {"text": "Then, the judges decided if the assigned classes are corrector not.", "labels": [], "entities": []}, {"text": "For the 5-way classifier, the judges also assigned the correct class if the automatic assigned class is incorrect.", "labels": [], "entities": []}, {"text": "After a preliminary examination we decided not to consider two troublesome concepts: constructor and future.", "labels": [], "entities": []}, {"text": "The reason for eliminating constructor is that we discovered it is ambiguous: in addition to the sense of 'a person who builds things', we discovered that constructor is used widely in the Web as a name fora fundamental method in object oriented programming languages such as Java.", "labels": [], "entities": []}, {"text": "Most of the best candidate attributes (e.g., call, arguments, code, and version) related to the latter sense, that doesn't exist in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.9610380530357361}]}, {"text": "Our system is currently notable to do word sense discrimination, but we are currently working on this issue.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.8179120818773905}]}, {"text": "The reason for ignoring the concept future was that this word is most commonly used as a modifier in phrases such as: \"the car of the future\", and \"the office of the future\", and that all of the best candidate attributes occurred in this type of construction.", "labels": [], "entities": []}, {"text": "This reduced the number of evaluated concepts to 19.", "labels": [], "entities": []}, {"text": "According to the judges, the 2-way classifier was on average able to correctly assign attribute classes for 82.57% of the candidate attributes.", "labels": [], "entities": []}, {"text": "This is very close to its performance in evaluation 1.", "labels": [], "entities": []}, {"text": "The results using the F-measure reveal similar results too.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9927454590797424}]}, {"text": "shows the results of the two classifiers based on the precision and recall measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9995236396789551}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.995271623134613}]}, {"text": "According to the judges, the 5-way classifier correctly classified 68.72% on average.", "labels": [], "entities": []}, {"text": "This performance is good but not as good as its performance in evaluation 1 (80.35%).", "labels": [], "entities": []}, {"text": "The decrease in the performance was also shown in the F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9921367168426514}]}, {"text": "An important question when using human judges is the degree of agreement among them.", "labels": [], "entities": []}, {"text": "The K-statistic was used to measure this agreement.", "labels": [], "entities": [{"text": "K-statistic", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.8752456307411194}]}, {"text": "The values of K are shown in.", "labels": [], "entities": []}, {"text": "In the 2-way classification, the judges agreed on 89.84% of the cases.", "labels": [], "entities": []}, {"text": "On the other hand, the K-statistic for this classification task is 0.452.", "labels": [], "entities": [{"text": "classification task", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.8804704546928406}]}, {"text": "This indicates that part of this strong agreement is because that the majority of the candidate attributes are valid attributes.", "labels": [], "entities": []}, {"text": "It also shows the difficulty of identifying nonattributes even for human judges.", "labels": [], "entities": []}, {"text": "In the 5-way classification, the two judges have a high level of agreement; Kappa statistic is 0.749.", "labels": [], "entities": [{"text": "agreement", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9948503375053406}, {"text": "Kappa statistic", "start_pos": 76, "end_pos": 91, "type": "METRIC", "confidence": 0.9705829620361328}]}, {"text": "The judges and the 5-way classifier agreed on 63.71% of the cases.", "labels": [], "entities": []}, {"text": "Finally, we looked at whether using the classifiers results in a better lexical description for the purposes of clustering ().", "labels": [], "entities": []}, {"text": "In we show the results obtained using the output of the 2-way classifier to re-cluster the 402 concepts of our balanced dataset, comparing these results with those obtained using all attributes (first column) and all attributes that remain after frequency cutoff and POS filtering (column 2).", "labels": [], "entities": []}, {"text": "The results are based on the CLUTO evaluation meas-ures: Purity (which measures the degree of cohesion of the clusters obtained) and Entropy.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.9909048676490784}]}, {"text": "The purity and entropy formulas are shown in.", "labels": [], "entities": [{"text": "purity", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9940065145492554}, {"text": "entropy", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9241797924041748}]}, {"text": "Clustering the concepts using only filtered candidate attributes improved the clustering purity from 0.657 to 0.672.", "labels": [], "entities": []}, {"text": "This improvement in purity is not significant.", "labels": [], "entities": [{"text": "purity", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9977669715881348}]}, {"text": "However, clustering using only the attributes sanctioned by the 2-way classifier improved the purity further to 0.693, and this improvement in purity from the initial purity was significant (t = 2.646, df = 801, p < 0.05).", "labels": [], "entities": [{"text": "purity", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.964472234249115}, {"text": "purity", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9685372710227966}]}, {"text": "Sr is a cluster, n r is the size of the cluster, q is the number of classes, n i r is the number of concepts from the ith class that were assigned to the rth cluster, n is the number of concepts, and k is the number of clusters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Conceptual and attributive usage averages  for each attribute class", "labels": [], "entities": []}, {"text": " Table 4: Five examples of training instances. The  values for morph are as follows: DV: derived from  verb; BN: basic noun; DA: derived from adjective", "labels": [], "entities": []}, {"text": " Table 5: Cross-validation results for the two  attribute classifiers", "labels": [], "entities": []}, {"text": " Table 6: Evaluation against human judges results  for the two classifiers", "labels": [], "entities": []}, {"text": " Table 8: Results of re-clustering concepts using  different sets of attributes", "labels": [], "entities": []}]}