{"title": [{"text": "RALI: SMT shared task system description", "labels": [], "entities": [{"text": "RALI", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.9336046576499939}, {"text": "SMT shared task", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.8909541964530945}]}], "abstractContent": [{"text": "Thanks to the profusion of freely available tools, it recently became fairly easy to built a statistical machine translation (SMT) engine given a bitext.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) engine", "start_pos": 93, "end_pos": 137, "type": "TASK", "confidence": 0.8064739917005811}]}, {"text": "The expectations we can have on the quality of such a system may however greatly vary from one pair of languages to another.", "labels": [], "entities": []}, {"text": "We report on our experiments in building phrase-based translation engines for the four pairs of languages we had to consider for the SMT shared-task.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.6525245904922485}, {"text": "SMT shared-task", "start_pos": 133, "end_pos": 148, "type": "TASK", "confidence": 0.9278838634490967}]}], "introductionContent": [{"text": "Machine translation is nowadays mature enough that it is possible without too much effort to devise automatically a statistical translation system from just a parallel corpus.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.812076985836029}, {"text": "statistical translation", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.6914694458246231}]}, {"text": "This is possible thanks to the dissemination of valuable packages.", "labels": [], "entities": []}, {"text": "The performance of such a system may however greatly vary from one pair of languages to another.", "labels": [], "entities": []}, {"text": "Indeed, there is no free lunch for system developers, and if a black box approach can sometimes be good enough for some applications (we can surely accomplish translation gisting with the French-English and Spanish-English systems we developed during this exercice), making use of the output of such a system for, let's say, quality translation is another kettle offish (especially in our case with the Finnish-English system we ended-up with).", "labels": [], "entities": []}, {"text": "We devoted two weeks to the SMT shared task, the aim of which was precisely to see how well systems can do across different language families.", "labels": [], "entities": [{"text": "SMT shared task", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.9267530838648478}]}, {"text": "We began with a core system which is described in the next section and from which we obtained baseline performances that we tried to improve upon.", "labels": [], "entities": []}, {"text": "Since the French-and Spanish-English systems produced output that were comprehensible enough 1 , we focussed on the two languages whose translations were noticeably worse: German and Finnish.", "labels": [], "entities": []}, {"text": "For German, we tried to move around words in order to mimic English word order; and we tried to split compound words.", "labels": [], "entities": []}, {"text": "This is described in section 4.", "labels": [], "entities": []}, {"text": "For the Finnish/English pair, we tried to decompose Finnish words into smaller substrings (see section 5).", "labels": [], "entities": []}, {"text": "In parallel to that, we tried to smooth a phrasebased model (PBM) making use of WORDNET.", "labels": [], "entities": []}, {"text": "We report on this experiment in section 3.", "labels": [], "entities": []}, {"text": "We describe in section 6 the final setting of the systems we used for submitting translations and their official results as computed by the organizers.", "labels": [], "entities": []}, {"text": "Finally, we conclude our two weeks of efforts in section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Baseline performances measured on the  500 top sentences of the DEV corpus in terms of  WER (word error rate), SER (sentence error rate),  NIST and BLEU scores.", "labels": [], "entities": [{"text": "DEV corpus", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9609506130218506}, {"text": "WER (word error rate)", "start_pos": 98, "end_pos": 119, "type": "METRIC", "confidence": 0.9139116505781809}, {"text": "SER (sentence error rate)", "start_pos": 121, "end_pos": 146, "type": "METRIC", "confidence": 0.919891744852066}, {"text": "NIST", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.721693754196167}, {"text": "BLEU", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.9980618357658386}]}, {"text": " Table 2: Performances of the swapping and the  compound splitting approaches on the top 500  sentences of the development set.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.6676495373249054}]}, {"text": " Table 3: Results measured by the organizers for  the TEST corpus.", "labels": [], "entities": [{"text": "TEST corpus", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.8912409245967865}]}]}