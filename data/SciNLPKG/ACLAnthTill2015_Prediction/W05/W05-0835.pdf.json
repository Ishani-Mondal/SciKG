{"title": [{"text": "A Recursive Statistical Translation Model *", "labels": [], "entities": [{"text": "Recursive Statistical Translation", "start_pos": 2, "end_pos": 35, "type": "TASK", "confidence": 0.7709721724192301}]}], "abstractContent": [{"text": "A new model for statistical translation is presented.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.856171190738678}]}, {"text": "A novel feature of this model is that the alignments it produces are hierarchically arranged.", "labels": [], "entities": []}, {"text": "The generative process begins by splitting the input sentence in two parts.", "labels": [], "entities": [{"text": "generative process", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9152213931083679}]}, {"text": "Each of the parts is translated by a recursive application of the model and the resulting translation are then concatenated.", "labels": [], "entities": []}, {"text": "If the sentence is small enough, a simpler model (in our case IBM's model 1) is applied.", "labels": [], "entities": []}, {"text": "The training of the model is explained.", "labels": [], "entities": []}, {"text": "Finally , the model is evaluated using the corpora from a large vocabulary shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Suppose you were to find an English translation fora Spanish sentence.", "labels": [], "entities": []}, {"text": "One possible approach is to assume that every English sentence is a candidate but that different English sentences have different probabilities of being the correct translation.", "labels": [], "entities": []}, {"text": "Then, the translation task can be divided in two parts: define an adequate probability distribution that answers to the question \"given this English sentence, which is the probability that it is a good translation of that Spanish sentence?\"; and use that distribution in order to find the most likely translation of your input sentence.", "labels": [], "entities": [{"text": "translation task", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.887497067451477}]}, {"text": "* Work partially supported by Bancaixa through the project \"Sistemas Inductivos, Estad\u00edsticos y Estructurales, para la Traducci\u00f3n Autom\u00e1tica (Siesta)\".", "labels": [], "entities": []}, {"text": "This approach is referred to as the statistical approach to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8159454166889191}]}, {"text": "The usual approach is to define an statistical model and train its parameters from a training corpus consisting in pairs of sentences that are known to be translation of each other.", "labels": [], "entities": []}, {"text": "Different models have been presented in the literature, see for instance).", "labels": [], "entities": []}, {"text": "Most of them rely on the concept of alignment: a mapping from words or groups of words in a sentence into words or groups in the other (in the case of () the mapping goes from rules in a grammar fora language into rules of a grammar for the other language).", "labels": [], "entities": []}, {"text": "This concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (.", "labels": [], "entities": [{"text": "corpus alignment", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.7204131036996841}]}, {"text": "A new statistical model is proposed in this paper, which was initially introduced in.", "labels": [], "entities": []}, {"text": "This model is designed so that the alignment between two sentences can be seen in an structured manner: each sentence is divided in two parts and they are put in correspondence; then each of those parts is similarly divided and related to its translation.", "labels": [], "entities": []}, {"text": "This way, the alignment can be seen as a tree structure which aligns progressively smaller segments of the sentences.", "labels": [], "entities": []}, {"text": "This recursive procedure gives its name to the model: MAR, which comes from \"Modelo de Alineamiento Recursivo\", which is Spanish for \"Recursive Alignment Model\".", "labels": [], "entities": [{"text": "MAR", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9208078384399414}]}, {"text": "The rest of the paper is structured as follows: after a comment on previous works, we introduce the notation that we will use throughout the paper, then we briefly explain the model 1 from IBM, next we introduce our model, then we explain the process of parameter estimation, and how to use the model to translate new test sentences.", "labels": [], "entities": [{"text": "IBM", "start_pos": 189, "end_pos": 192, "type": "DATASET", "confidence": 0.8867815732955933}, {"text": "parameter estimation", "start_pos": 254, "end_pos": 274, "type": "TASK", "confidence": 0.6536416560411453}, {"text": "translate new test sentences", "start_pos": 304, "end_pos": 332, "type": "TASK", "confidence": 0.8390113264322281}]}, {"text": "Finally, we present some experiments and results, together with conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to test the model, we have decided to participate in the shared task for this workshop.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the training corpora. The  languages are German (De), English (En), Span- ish (Es), Finnish (Fi) and French (Fr).", "labels": [], "entities": []}, {"text": " Table 2: Number of training pairs after splitting to  a maximum length of ten. \"Provided\" refers to the  alignment provided in the task, \"GIZA++\" to those  obtained with GIZA++.", "labels": [], "entities": []}, {"text": " Table 3. Again, the influence of the  type of alignment was small. Except for Finnish,  the number of dictionary templates was roughly two  thirds of the templates extracted from the align- ments.", "labels": [], "entities": []}, {"text": " Table 4: Best weights for each language pair. The  columns are for the probability given by the model,  the counts of the templates, the normalized counts  and the weight given to the dictionary.", "labels": [], "entities": []}, {"text": " Table 5: BLEU scores of the translations.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9561887681484222}, {"text": "translations", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9381327629089355}]}]}