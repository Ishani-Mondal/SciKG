{"title": [{"text": "ISI's Participation in the Romanian-English Alignment Task", "labels": [], "entities": [{"text": "Romanian-English Alignment", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.6617028117179871}]}], "abstractContent": [{"text": "We discuss results on the shared task of Romanian-English word alignment.", "labels": [], "entities": [{"text": "Romanian-English word alignment", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.5375442008177439}]}, {"text": "The baseline technique is that of symmetrizing two word alignments automatically generated using IBM Model 4.", "labels": [], "entities": [{"text": "symmetrizing two word alignments", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.6266730427742004}]}, {"text": "A simple vocabulary reduction technique results in an improvement in performance.", "labels": [], "entities": [{"text": "vocabulary reduction", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7347290217876434}]}, {"text": "We also report on anew alignment model and anew training algorithm based on alternating maximization of likelihood with minimization of error rate.", "labels": [], "entities": []}], "introductionContent": [{"text": "ISI participated in the WPT05 Romanian-English word alignment task.", "labels": [], "entities": [{"text": "ISI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7950825691223145}, {"text": "WPT05 Romanian-English word alignment task", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.714331078529358}]}, {"text": "The system used for baseline experiments is two runs of IBM Model 4 () in the GIZA++ ( implementation, which includes smoothing extensions to Model 4.", "labels": [], "entities": []}, {"text": "For symmetrization, we found that Och and Ney's \"refined\" technique described in) produced the best AER for this data set under all experimental conditions.", "labels": [], "entities": [{"text": "AER", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.99897301197052}]}, {"text": "We experimented with a statistical model for inducing a stemmer cross-lingually, but found that the best performance was obtained by simply lowercasing both the English and Romanian text and removing all but the first four characters of each word.", "labels": [], "entities": []}, {"text": "We also tried anew model and anew training criterion based on alternating the maximization of likelihood and minimization of the alignment error rate.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 129, "end_pos": 149, "type": "METRIC", "confidence": 0.7731344898541769}]}, {"text": "For these experiments, we have implemented an alignment package for IBM Model 4 using a hillclimbing search and Viterbi training as described in, and extended this to use new submodels.", "labels": [], "entities": [{"text": "IBM Model 4", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.8872875769933065}]}, {"text": "The starting point is the final alignment generated using GIZA++'s implementation of IBM Model 1 and the Aachen HMM model (.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 85, "end_pos": 96, "type": "DATASET", "confidence": 0.9143752853075663}, {"text": "Aachen HMM model", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.8757313291231791}]}, {"text": "Paper organization: Section 2 is on the baseline, Section 3 discusses vocabulary reduction, Section 4 introduces our new model and training method, Section 5 describes experiments, Section 6 concludes.", "labels": [], "entities": [{"text": "vocabulary reduction", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.8267595767974854}]}, {"text": "We use the following notation: e refers to an English sentence composed of English words labeled e i . f refers to a Romanian sentence composed of Romanian words labeled f j . a is an alignment of e to f . We use the term \"Viterbi alignment\" to denote the most probable alignment we can find, rather than the true Viterbi alignment.", "labels": [], "entities": []}], "datasetContent": [{"text": "Results: \u2022 Our new 1-to-many alignment model and training method are successful, producing decreases of 0.03 AER when the source is Romanian, and 0.01 AER when the source is English.", "labels": [], "entities": [{"text": "AER", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.9937393665313721}, {"text": "AER", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.9937055706977844}]}, {"text": "\u2022 These decreases do not translate to a large improvement in the end-to-end task of producing many-to-many alignments with a balanced precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9990022778511047}, {"text": "recall", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.9976605176925659}]}, {"text": "We had a very small decrease of 0.002 AER using the \"refined\" heuristic.", "labels": [], "entities": [{"text": "AER", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9979937076568604}]}, {"text": "\u2022 The many-to-many alignments produced using \"union\" and the 1-to-1 alignments produced using \"intersection\" were also improved.", "labels": [], "entities": []}, {"text": "\u2022 It maybe a problem that we trained p0 using likelihood (it is in submodel 3) rather than optimizing p0 discriminatively as we did for the baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Submodels used for alignment", "labels": [], "entities": [{"text": "alignment", "start_pos": 29, "end_pos": 38, "type": "TASK", "confidence": 0.5961911082267761}]}, {"text": " Table 2: Summary of results for 2003 test set", "labels": [], "entities": [{"text": "2003 test set", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.9180829723676046}]}, {"text": " Table 3: Full results on shared task submissions (blind test 2005)", "labels": [], "entities": []}]}