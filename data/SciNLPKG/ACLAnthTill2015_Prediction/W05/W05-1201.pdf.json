{"title": [{"text": "Classification of semantic relations by humans and machines *", "labels": [], "entities": [{"text": "Classification of semantic relations", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8083612471818924}]}], "abstractContent": [{"text": "This paper addresses the classification of semantic relations between pairs of sentences extracted from a Dutch parallel corpus at the word, phrase and sentence level.", "labels": [], "entities": [{"text": "classification of semantic relations between pairs of sentences extracted from a Dutch parallel", "start_pos": 25, "end_pos": 120, "type": "TASK", "confidence": 0.7861211116497333}]}, {"text": "We first investigate the performance of human annotators on the task of manually aligning dependency analyses of the respective sentences and of assigning one of five semantic relations to the aligned phrases (equals, generalizes, specifies, restates and intersects).", "labels": [], "entities": []}, {"text": "Results indicate that humans can perform this task well, with an F-score of .98 on alignment and an F-score of .95 on semantic relations (after correction).", "labels": [], "entities": [{"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9991913437843323}, {"text": "F-score", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9987866282463074}]}, {"text": "We then describe and evaluate a combined alignment and classification algorithm, which achieves an F-score on alignment of .85 (using EuroWordNet) and an F-score of .80 on semantic relation classification.", "labels": [], "entities": [{"text": "F-score", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.998445451259613}, {"text": "EuroWordNet", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.9835492372512817}, {"text": "F-score", "start_pos": 154, "end_pos": 161, "type": "METRIC", "confidence": 0.9979216456413269}, {"text": "semantic relation classification", "start_pos": 172, "end_pos": 204, "type": "TASK", "confidence": 0.7498067816098531}]}], "introductionContent": [{"text": "An automatic method that can determine how two sentences relate to each other in terms of semantic overlap or textual entailment (e.g.,)) would be a very useful thing to have for robust natural language applications.", "labels": [], "entities": []}, {"text": "A summarizer, for instance, could use it to extract the most informative sentences, while a questionanswering system -to give a second examplecould use it to select potential answer string), perhaps preferring more specific answers over more general ones.", "labels": [], "entities": []}, {"text": "In general, it * This work was carried out within the IMIX-IMOGEN (Interactive Multimodal Output Generation) project, sponsored by the Netherlands Organization of Scientific Research (NWO). is very useful to know whether some sentence S is more specific (entails) or more general than (is entailed by) an alternative sentence S , or whether the two sentences express essentially the same information albeit in a different way (paraphrasing).", "labels": [], "entities": [{"text": "Interactive Multimodal Output Generation)", "start_pos": 67, "end_pos": 108, "type": "TASK", "confidence": 0.5889777660369873}]}, {"text": "Research on automatic methods for recognizing semantic relations between sentences is still relatively new, and many basic issues need to be resolved.", "labels": [], "entities": [{"text": "recognizing semantic relations between sentences", "start_pos": 34, "end_pos": 82, "type": "TASK", "confidence": 0.8819347977638244}]}, {"text": "In this paper we address two such related issues: to what extent can human annotators label semantic overlap relations between words, phrases and sentences, and what is the added value of linguistically informed analyses.", "labels": [], "entities": []}, {"text": "It is generally assumed that pure string overlap is not sufficient for recognizing semantic relations; and that using some form of syntactic analysis maybe beneficial (e.g.,),).", "labels": [], "entities": []}, {"text": "Our working hypothesis is that semantic overlap at the word and phrase levels may provide a good basis for deciding the semantic relation between sentences.", "labels": [], "entities": []}, {"text": "Recognising semantic relations between sentences then becomes a two-step procedure: first, the words and phrases in the respective sentences need to be aligned, after which the relations between the pairs of aligned words and phrases should be labeled in terms of semantic relations.", "labels": [], "entities": [{"text": "Recognising semantic relations between sentences", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8806651592254638}]}, {"text": "Various alignment algorithms have been developed for data-driven approaches to machine translation (e.g.).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7896926701068878}]}, {"text": "Initially work focused on word-based alignment, but more and more work is also addressing alignment at the higher levels (substrings, syntactic phrases or trees), e.g.,,.", "labels": [], "entities": [{"text": "word-based alignment", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.7303571999073029}]}, {"text": "For our purposes, an additional advantage of aligning syntactic structures is that it keeps the alignment feasible (as the number of arbitrary substrings that maybe aligned grows exponentially to the number of words in the sentence).", "labels": [], "entities": []}, {"text": "Here, following) and, we will align sentences at the level of dependency structures.", "labels": [], "entities": []}, {"text": "In addition, we will label the alignments in terms of five basic semantic relations to be defined below.", "labels": [], "entities": []}, {"text": "We will perform this task both manually and automatically, so that we can address both of the issues raised above.", "labels": [], "entities": []}, {"text": "Section 2 describes a monolingual parallel corpus consisting of two Dutch translations, and formalizes the alignment-classification task to be performed.", "labels": [], "entities": []}, {"text": "In section 3 we report the results on alignment, first describing interannotator agreement on this task and then the results on automatic alignment.", "labels": [], "entities": [{"text": "alignment", "start_pos": 38, "end_pos": 47, "type": "TASK", "confidence": 0.899586021900177}]}, {"text": "In section 4, then, we address the semantic relation classification; again, first describing interannotator results, followed by results obtained using memorybased machine learning techniques.", "labels": [], "entities": [{"text": "semantic relation classification", "start_pos": 35, "end_pos": 67, "type": "TASK", "confidence": 0.6917978525161743}]}, {"text": "We end with a general discussion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Interannotator agreement with respect  to alignment between annotators 1 and 2 before  (A 1 , A 2 ) and after (A 1 , A 2 ) revision , and between  the consensus and annotator 1 (A c , A 1 ) and annota- tor 2 (A c , A 2 ) respectively.", "labels": [], "entities": []}, {"text": " Table 2: Precision, recall and F-score on automatic  alignment", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9991171956062317}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9995436072349548}, {"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9992706179618835}, {"text": "alignment", "start_pos": 54, "end_pos": 63, "type": "TASK", "confidence": 0.6316756010055542}]}, {"text": " Table 3: Interannotator agreement with respect to se- mantic relation labeling between annotators 1 and 2  before (A 1 , A 2 ) and after (A 1 , A 2 ) revision , and  between the consensus and annotator 1 (A c , A 1 )  and annotator 2 (A c , A 2 ) respectively.", "labels": [], "entities": [{"text": "se- mantic relation labeling", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.6654395699501038}]}, {"text": " Table 5: Average precision, recall and F-score (and  SD) over all 5 folds on automatic classification of  semantic relations without using previous decisions.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9796778559684753}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9996836185455322}, {"text": "F-score", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.9966865181922913}, {"text": "SD)", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9574206173419952}, {"text": "automatic classification of  semantic relations", "start_pos": 78, "end_pos": 125, "type": "TASK", "confidence": 0.6823272049427033}]}]}