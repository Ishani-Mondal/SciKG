{"title": [{"text": "Experiments Using MAR for Aligning Corpora *", "labels": [], "entities": [{"text": "MAR", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.5338460206985474}, {"text": "Aligning Corpora", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.9083034098148346}]}], "abstractContent": [{"text": "We present some experiments conducted within the context of one of the shared tasks of the ACL 2005 Workshop on Building and Using Parallel Texts.", "labels": [], "entities": [{"text": "ACL 2005 Workshop", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.8348279595375061}]}, {"text": "We have employed anew model for finding the alignments.", "labels": [], "entities": []}, {"text": "This new model takes a recursive approach in order to find the alignments.", "labels": [], "entities": []}, {"text": "As its computational costs are quite high, a method for splitting the training sentences in smaller parts is used.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present the experiments we conducted within the context of the shared task of the track on building and using parallel texts for languages with scarce resources of the ACL 2005 Workshop on Building and Using Parallel Texts.", "labels": [], "entities": [{"text": "ACL 2005 Workshop", "start_pos": 171, "end_pos": 188, "type": "DATASET", "confidence": 0.8821345567703247}]}, {"text": "The aim of the task was to align the words of sentence pairs in different language pairs.", "labels": [], "entities": []}, {"text": "We have participated using the Romanian-English corpora.", "labels": [], "entities": []}, {"text": "We have used anew model, the MAR (from the Spanish initials of Recursive Alignment Model) that allowed us to find structured alignments that were later transformed in a more conventional format.", "labels": [], "entities": [{"text": "MAR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9159184098243713}]}, {"text": "The basic idea of the model is that the translation of a sentence can be obtained in three steps: first, the sentence is divided in two parts; second, each part is translated separately using the same process; and * Work partially supported by Bancaixa through the project \"Sistemas Inductivos, Estad\u00edsticos y Estructurales, para la Traducci\u00f3n Autom\u00e1tica (SIEsTA)\".", "labels": [], "entities": []}, {"text": "third, the two translations are joined.", "labels": [], "entities": []}, {"text": "The high computational costs associated with the training of the model made it necessary to split the training pairs in smaller parts using a simple heuristic.", "labels": [], "entities": []}, {"text": "Initial work with this model can be seen in.", "labels": [], "entities": []}, {"text": "A detailed presentation can be found in).", "labels": [], "entities": []}, {"text": "This model shares some similarities with the stochastic inversion transduction grammars (SITG) presented by Wu in.", "labels": [], "entities": [{"text": "stochastic inversion transduction grammars (SITG)", "start_pos": 45, "end_pos": 94, "type": "TASK", "confidence": 0.7482846634728568}]}, {"text": "The main point in common is the number of possible alignments between the two models.", "labels": [], "entities": []}, {"text": "On the other hand, the parametrizations of SITGs and the MAR are completely different.", "labels": [], "entities": [{"text": "MAR", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.5014744997024536}]}, {"text": "The generative process of SITGs produces simultaneously the input and output sentences and the parameters of the model refer to the rules of the nonterminals.", "labels": [], "entities": []}, {"text": "This gives a clear symmetry to both input and output sentences.", "labels": [], "entities": []}, {"text": "Our model clearly distinguishes an input and output sentence and the parameters are based on observable properties of the sentences (their lengths and the words composing them).", "labels": [], "entities": []}, {"text": "Also, the idea of splitting the sentences until a simple structure is found in the Divisive Clustering presented in).", "labels": [], "entities": []}, {"text": "Again, the main difference is in the probabilistic modeling of the alignments.", "labels": [], "entities": []}, {"text": "In Divisive Clustering a uniform distribution on the alignments is assumed while MAR uses a explicit parametrization.", "labels": [], "entities": [{"text": "MAR", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.4929073750972748}]}, {"text": "The rest of the paper is structured as follows: the next section gives an overview of the MAR, then we explain the task and how the corpora were split, after that, how the alignments were obtained is explained, finally the results and conclusions are presented.", "labels": [], "entities": [{"text": "MAR", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.628955602645874}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of the training corpus. Vocabulary  refers to the number of different words.", "labels": [], "entities": []}, {"text": " Table 2: Results for the task", "labels": [], "entities": []}]}