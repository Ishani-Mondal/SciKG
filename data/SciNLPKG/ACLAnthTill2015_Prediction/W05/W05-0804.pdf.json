{"title": [{"text": "Bilingual Word Spectral Clustering for Statistical Machine Translation", "labels": [], "entities": [{"text": "Bilingual Word Spectral Clustering", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7551709860563278}, {"text": "Statistical Machine Translation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.8252972960472107}]}], "abstractContent": [{"text": "In this paper, a variant of a spectral clustering algorithm is proposed for bilingual word clustering.", "labels": [], "entities": [{"text": "bilingual word clustering", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.6672419011592865}]}, {"text": "The proposed algorithm generates the two sets of clusters for both languages efficiently with high semantic correlation within monolingual clusters , and high translation quality across the clusters between two languages.", "labels": [], "entities": []}, {"text": "Each cluster level translation is considered as a bilingual concept, which generalizes words in bilingual clusters.", "labels": [], "entities": []}, {"text": "This scheme improves the robustness for statistical machine translation models.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.6886028150717417}]}, {"text": "Two HMM-based translation models are tested to use these bilingual clusters.", "labels": [], "entities": [{"text": "HMM-based translation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7174410223960876}]}, {"text": "Improved per-plexity, word alignment accuracy, and translation quality are observed in our experiments .", "labels": [], "entities": [{"text": "word alignment", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7769084870815277}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.947460949420929}, {"text": "translation", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.93855881690979}]}], "introductionContent": [{"text": "Statistical natural language processing usually suffers from the sparse data problem.", "labels": [], "entities": [{"text": "Statistical natural language processing", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6567411050200462}]}, {"text": "Comparing to the available monolingual data, we have much less training data especially for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 92, "end_pos": 129, "type": "TASK", "confidence": 0.8232162694136301}]}, {"text": "For example, in language modelling, there are more than 1.7 billion words corpora available: English Gigaword by.", "labels": [], "entities": []}, {"text": "However, for machine translation tasks, there are typically less than 10 million words of training data.", "labels": [], "entities": [{"text": "machine translation tasks", "start_pos": 13, "end_pos": 38, "type": "TASK", "confidence": 0.8392531077067057}]}, {"text": "Bilingual word clustering is a process of forming corresponding word clusters suitable for machine translation.", "labels": [], "entities": [{"text": "Bilingual word clustering", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7421911756197611}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7199503183364868}]}, {"text": "Previous work from ( showed improvements in perplexity-oriented measures using mixture-based translation lexicon (.", "labels": [], "entities": []}, {"text": "A later study by) showed improvements on perplexity of bilingual corpus, and word translation accuracy using a template-based translation model.", "labels": [], "entities": [{"text": "word translation", "start_pos": 77, "end_pos": 93, "type": "TASK", "confidence": 0.7786537110805511}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9319997429847717}]}, {"text": "Both approaches are optimizing the maximum likelihood of parallel corpus, in which a data point is a sentence pair: an English sentence and its translation in another language such as French.", "labels": [], "entities": []}, {"text": "These algorithms are essentially the same as monolingual word clusterings-an iterative local search.", "labels": [], "entities": [{"text": "word clusterings-an iterative local search", "start_pos": 57, "end_pos": 99, "type": "TASK", "confidence": 0.8407432615756989}]}, {"text": "In each iteration, a two-level loop over every possible word-cluster assignment is tested for better likelihood change.", "labels": [], "entities": []}, {"text": "This kind of approach has two drawbacks: first it is easily to get stuck in local optima; second, the clustering of English and the other language are basically two separated optimization processes, and cluster-level translation is modelled loosely.", "labels": [], "entities": [{"text": "cluster-level translation", "start_pos": 203, "end_pos": 228, "type": "TASK", "confidence": 0.6354846209287643}]}, {"text": "These drawbacks make their approaches generally not very effective in improving translation models.", "labels": [], "entities": [{"text": "translation", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.9772734045982361}]}, {"text": "In this paper, we propose a variant of the spectral clustering algorithm () for bilingual word clustering.", "labels": [], "entities": [{"text": "bilingual word clustering", "start_pos": 80, "end_pos": 105, "type": "TASK", "confidence": 0.6670608520507812}]}, {"text": "Given parallel corpus, first, the word's bilingual context is used directly as features -for instance, each English word is represented by its bilingual word translation candidates.", "labels": [], "entities": []}, {"text": "Second, latent eigenstructure analysis is carried out in this bilingual feature space, which leads to clusters of words with similar translations.", "labels": [], "entities": []}, {"text": "Essentially an affinity matrix is computed using these cross-lingual features.", "labels": [], "entities": []}, {"text": "It is then decomposed into two sub-spaces, which are meaningful for translation tasks: the left subspace corresponds to the representation of words in English vocabulary, and the right sub-space corresponds to words in French.", "labels": [], "entities": []}, {"text": "Each eigenvector is considered as one bilingual concept, and the bilingual clusters are considered to be its realizations in two languages.", "labels": [], "entities": []}, {"text": "Finally, a general K-means cluster-ing algorithm is used to find out word clusters in the two sub-spaces.", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows: in section 2, concepts of translation models are introduced together with two extended HMMs; in section 3, our proposed bilingual word clustering algorithm is explained in detail, and the related works are analyzed; in section 4, evaluation metrics are defined and the experimental results are given; in section 5, the discussions and conclusions.", "labels": [], "entities": [{"text": "word clustering algorithm", "start_pos": 183, "end_pos": 208, "type": "TASK", "confidence": 0.7783680558204651}]}], "datasetContent": [{"text": "To test our algorithm, we applied it to the TIDES Chinese-English small data track evaluation test set.", "labels": [], "entities": [{"text": "TIDES Chinese-English small data track evaluation test set", "start_pos": 44, "end_pos": 102, "type": "DATASET", "confidence": 0.942174643278122}]}, {"text": "After preprocessing, such as English tokenization, Chinese word segmentation, and parallel sentence splitting, there are in total 4172 parallel sentence pairs for training.", "labels": [], "entities": [{"text": "English tokenization", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.5156899392604828}, {"text": "Chinese word segmentation", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.6248749494552612}, {"text": "parallel sentence splitting", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.6499346792697906}]}, {"text": "We manually labeled word alignments for 627 test sentence pairs randomly sampled from the dry-run test data in 2001, which has four human translations for each Chinese sentence.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7062219083309174}, {"text": "dry-run test data in 2001", "start_pos": 90, "end_pos": 115, "type": "DATASET", "confidence": 0.8488468527793884}]}, {"text": "The preprocessing for the test data is different from the above, as it is designed for humans to label word alignments correctly by removing ambiguities from tokenization and word segmentation as much as possible.", "labels": [], "entities": [{"text": "label word alignments", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.6279947956403097}, {"text": "word segmentation", "start_pos": 175, "end_pos": 192, "type": "TASK", "confidence": 0.7010001093149185}]}, {"text": "The data statistics are shown in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Training and Test data statistics", "labels": [], "entities": [{"text": "Training and Test data", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.4833308830857277}]}, {"text": " Table 2: Bilingual Cluster Examples", "labels": [], "entities": []}, {"text": " Table 3: NIST'03 C-E Small Data Track Evaluation", "labels": [], "entities": [{"text": "NIST'03 C-E Small Data Track Evaluation", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.785721093416214}]}]}