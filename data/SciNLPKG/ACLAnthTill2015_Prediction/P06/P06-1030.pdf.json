{"title": [{"text": "Automated Japanese Essay Scoring System based on Articles Written by Experts", "labels": [], "entities": [{"text": "Automated Japanese Essay Scoring", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6702250614762306}]}], "abstractContent": [{"text": "We have developed an automated Japanese essay scoring system called Jess.", "labels": [], "entities": [{"text": "Japanese essay scoring", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.5532133877277374}]}, {"text": "The system needs expert writings rather than expert raters to build the evaluation model.", "labels": [], "entities": []}, {"text": "By detecting statistical outliers of predetermined aimed essay features compared with many professional writings for each prompt, our system can evaluate essays.", "labels": [], "entities": []}, {"text": "The following three features are examined: (1) rhetoric-syntactic variety, or the use of various structures in the arrangement of phases, clauses, and sentences, (2) organization-characteristics associated with the orderly presentation of ideas, such as rhetorical features and linguistic cues, and (3) content-vocabulary related to the topic, such as relevant information and precise or specialized vocabulary.", "labels": [], "entities": []}, {"text": "The final evaluation score is calculated by deducting from a perfect score assigned by a learning process using editorials and columns from the Mainichi Daily News newspaper.", "labels": [], "entities": [{"text": "Mainichi Daily News newspaper", "start_pos": 144, "end_pos": 173, "type": "DATASET", "confidence": 0.9911848604679108}]}, {"text": "A diagnosis for the essay is also given.", "labels": [], "entities": []}], "introductionContent": [{"text": "When giving an essay test, the examiner expects a written essay to reflect the writing ability of the examinee.", "labels": [], "entities": []}, {"text": "A variety of factors, however, can affect scores in a complicated manner.", "labels": [], "entities": []}, {"text": "states that \"various factors including the writer, topic, mode, time limit, examination situation, and rater can introduce error into the scoring of essays used to measure writing ability.\"", "labels": [], "entities": [{"text": "rater", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.9798933267593384}]}, {"text": "Most of these factors are present in giving tests, and the human rater, in particular, is a major error factor in the scoring of essays.", "labels": [], "entities": [{"text": "rater", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.5140516757965088}]}, {"text": "In fact, many other factors influence the scoring of essay tests, as listed below, and much research has been devoted.", "labels": [], "entities": []}, {"text": "Handwriting skill (handwriting quality, spelling) Serial effects of rating (the order in which essay answers are rated) ( Topic selection (how should essays written on different topics be rated?)", "labels": [], "entities": []}, {"text": "Other error factors (writer's gender, ethnic group, etc.)", "labels": [], "entities": []}, {"text": "In recent years, with the aim of removing these error factors and establishing fairness, considerable research has been performed on computerbased automated essay scoring (AES) systems ().", "labels": [], "entities": [{"text": "computerbased automated essay scoring (AES)", "start_pos": 133, "end_pos": 176, "type": "TASK", "confidence": 0.6730918671403613}]}, {"text": "The AES systems provide the users with prompt feedback to improve their writings.", "labels": [], "entities": []}, {"text": "Therefore, many practical AES systems have been used.", "labels": [], "entities": []}, {"text": "Erater (, developed by the Educational Testing Service, began being used for operational scoring of the Analytical Writing Assessment in the Graduate Management Admission Test (GMAT), an entrance examination for business graduate schools, in February 1999, and it has scored approximately 360,000 essays per year.", "labels": [], "entities": [{"text": "Graduate Management Admission Test (GMAT)", "start_pos": 141, "end_pos": 182, "type": "TASK", "confidence": 0.6364857298987252}]}, {"text": "The system includes several independent NLP-based modules for identifying features relevant to the scoring guide from three categories: syntax, discourse, and topic.", "labels": [], "entities": []}, {"text": "Each of the featurerecognition modules correlate the essay scores with assigned by human readers.", "labels": [], "entities": []}, {"text": "E-rater uses a model-building module to select and weight predictive features for essay scoring.", "labels": [], "entities": [{"text": "E-rater", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9075189828872681}, {"text": "essay scoring", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.7901784181594849}]}, {"text": "Project Essay Grade (PEG), which was the first automated essay scorer, uses a regression model like e-rater ().", "labels": [], "entities": []}, {"text": "IntelliMetric was first commercially released by Vantage Learning in January 1998 and was the first AI-based essay-scoring tool available to educational agencies.", "labels": [], "entities": []}, {"text": "The system internalizes the pooled wisdom of many expert scorers.", "labels": [], "entities": []}, {"text": "The Intelligent Essay Assessor (IEA) is a set of software tools for scoring the quality of the conceptual content of essays based on latent semantic analysis ().", "labels": [], "entities": [{"text": "Intelligent Essay Assessor (IEA)", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7155286371707916}]}, {"text": "The Bayesian Essay Test Scoring sYstem (BETSY) is a windows-based program that classifies text based on trained material.", "labels": [], "entities": [{"text": "Bayesian Essay Test Scoring sYstem (BETSY)", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.6016193367540836}]}, {"text": "The features include multi-nomial and Bernoulli Naive Bayes models).", "labels": [], "entities": []}, {"text": "Note that all above-mentioned systems are based on the assumption that the true quality of essays must be defined by human judges.", "labels": [], "entities": []}, {"text": "However, have criticized the overreliance on human ratings as the sole criterion for evaluating computer performance because ratings are typically based as a constructed rubric that may ultimately achieve acceptable reliability at the cost of validity.", "labels": [], "entities": []}, {"text": "In addition, Friedman, in research during the 1980s, found that holistic ratings by human raters did not award particularly high marks to professionally written essays mixed in with student productions.", "labels": [], "entities": []}, {"text": "This is a kind of negative halo effect: create a bad impression, and you will be scored low on everything.", "labels": [], "entities": []}, {"text": "insists that another approach to doing better than ordinary human raters would be to use expert writers rather than expert raters.", "labels": [], "entities": []}, {"text": "Reputable professional writers produce sophisticated and easy-toread essays.", "labels": [], "entities": []}, {"text": "The use of professional writings as the criterion, whether the evaluation is based on holistic or trait rating, has an advantage, described below.", "labels": [], "entities": []}, {"text": "The methods based on expert rater evaluations require much effort to setup the model for each prompt.", "labels": [], "entities": []}, {"text": "For example, e-rater and PEG use some sort of regression approaches insetting up the statistical models.", "labels": [], "entities": []}, {"text": "Depending on how many variables are involved, these models may require thousands of cases to derive stable regression weights.", "labels": [], "entities": []}, {"text": "BETSY requires the Bayesian rules, and IntelliMetric, the AI-based rules.", "labels": [], "entities": [{"text": "BETSY", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.4938300549983978}]}, {"text": "Thus, the methodology limits the grader's practical utility to largescale testing operations in which such data collection is feasible.", "labels": [], "entities": []}, {"text": "On the other hand, a method based on professional writings can overcome this; i.e., in our system, we need not setup a model simulating a human rater because thousands of articles by professional writers can easily be obtained via various electronic media.", "labels": [], "entities": []}, {"text": "By detecting a statistical outlier to predetermined essay features compared with many professional writings for each prompt, our system can evaluate essays.", "labels": [], "entities": []}, {"text": "In Japan, it is possible to obtain complete articles from the Mainichi Daily News newspaper up to 2005 from Nichigai Associates, Inc. and from the Nihon Keizai newspaper up to 2004 from Nikkei Books and Software, Inc.", "labels": [], "entities": [{"text": "Mainichi Daily News newspaper", "start_pos": 62, "end_pos": 91, "type": "DATASET", "confidence": 0.9869513511657715}, {"text": "Nichigai Associates", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.9076909720897675}]}, {"text": "for purposes of linguistic study.", "labels": [], "entities": [{"text": "linguistic study", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.715414822101593}]}, {"text": "In short, it is relatively easy to collect editorials and columns (e.g., \"Yoroku\") on some form of electronic media for use as essay models.", "labels": [], "entities": []}, {"text": "Literary works in the public domain can be accessed from Aozora Bunko (http://www.aozora.gr.jp/).", "labels": [], "entities": [{"text": "Aozora Bunko", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.8820168077945709}]}, {"text": "Furthermore, with regard to morphological analysis, the basis of Japanese natural language processing, a number of free Japanese morphological analyzers are available.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.8296426832675934}, {"text": "Japanese natural language processing", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.5780395120382309}]}, {"text": "These include JUMAN (http://www-lab25.kuee.kyotou.ac.jp/nlresource/juman.html), developed by the Language Media Laboratory of Kyoto University, and ChaSen (http://chasen.aist-nara.ac.jp/, used in this study) from the Matsumoto Laboratory of the Nara Institute of Science and Technology.", "labels": [], "entities": []}, {"text": "Likewise, for syntactic analysis, free resources are available such as KNP (http://www-lab25.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.8205080330371857}]}, {"text": "kuee.kyoto-u.ac.jp/nlresource/knp.html) from Kyoto University, SAX and BUP (http://cactus.aistnara.ac.jp/lab/nlt/ sax,bup\u00a1 .html) from the Nara Institute of Science and Technology, and the MSLR parser (http://tanaka-www.cs.titech.ac.jp/ pub/mslr/index-j.html) from the Tanaka Tokunaga Laboratory of the Tokyo Institute of Technology.", "labels": [], "entities": [{"text": "SAX", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.7152205109596252}, {"text": "BUP", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9756490588188171}, {"text": "MSLR parser", "start_pos": 189, "end_pos": 200, "type": "DATASET", "confidence": 0.8516303896903992}]}, {"text": "With resources such as these, we prepared tools for computer processing of the articles and columns that we collect as essay models.", "labels": [], "entities": []}, {"text": "In addition, for the scoring of essays, where it is essential to evaluate whether content is suitable, i.e., whether a written essay responds appropriately to the essay prompt, it is becoming possible for us to use semantic search technologies not based on pattern matching as used by search engines on the Web.", "labels": [], "entities": []}, {"text": "The methods for implementing such technologies are explained in detail by and elsewhere.", "labels": [], "entities": []}, {"text": "We believe that this statistical outlier detection ap-proach to using published professional essays and columns as models makes it possible to develop a system essentially superior to other AES systems.", "labels": [], "entities": []}, {"text": "We have named this automated Japanese essay scoring system \"Jess.\"", "labels": [], "entities": []}, {"text": "This system evaluates essays based on three features : (1) rhetoric, (2) organization, and (3) content, which are basically the same as the structure, organization, and content used by e-rater.", "labels": [], "entities": []}, {"text": "Jess also allows the user to designate weights (allotted points) for each of these essay features.", "labels": [], "entities": []}, {"text": "If the user does not explicitly specify the point allotment, the default weights are 5, 2, and 3 for structure, organization, and content, respectively, fora total of 10 points.", "labels": [], "entities": []}, {"text": "(Incidentally, a perfect score in e-rater is 6.)", "labels": [], "entities": [{"text": "perfect score", "start_pos": 17, "end_pos": 30, "type": "METRIC", "confidence": 0.975671112537384}]}, {"text": "This default point allotment in which \"rhetoric\" is weighted higher than \"organization\" and \"content\" is based on the work of.", "labels": [], "entities": []}, {"text": "In that research, 15 criteria were given for scoring essays: (1) wrong/omitted characters, (2) strong vocabulary, (3) character usage, (4) grammar, (5) style, (6) topic relevance, (7) ideas, (8) sentence structure, (9) power of expression, (10) knowledge, (11) logic/consistency, (12) power of thinking/judgment, (13) complacency, nuance, and (15) affinity.", "labels": [], "entities": [{"text": "affinity", "start_pos": 348, "end_pos": 356, "type": "METRIC", "confidence": 0.9375715255737305}]}, {"text": "Here, correlation coefficients were given to reflect the evaluation value of each of these criteria.", "labels": [], "entities": [{"text": "correlation", "start_pos": 6, "end_pos": 17, "type": "METRIC", "confidence": 0.9831297993659973}]}, {"text": "For example, (3) character usage, which is deeply related to \"rhetoric,\" turned out to have the highest correlation coefficient at 0.58, and (1) wrong/omitted characters was relatively high at 0.36.", "labels": [], "entities": []}, {"text": "In addition, (8) sentence structure and (11) logic/consistency, which is deeply related to \"organization,\" had correlation coefficients of 0.32 and 0.26, respectively, both lower than that of \"rhetoric,\" and (6) topic relevance and nuance, which are though to be deeply related to \"content,\" had correlation coefficients of 0.27 and 0.32, respectively.", "labels": [], "entities": []}, {"text": "Our system, Jess, is the first automated Japanese essay scorer and has become most famous in Japan, since it was introduced in February 2005 in a headline in the Asahi Daily News, which is well known as the most reliable and most representative newspaper of Japan.", "labels": [], "entities": [{"text": "Japanese essay scorer", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.5955187678337097}, {"text": "Asahi Daily News", "start_pos": 162, "end_pos": 178, "type": "DATASET", "confidence": 0.9732967416445414}]}, {"text": "The following sections describe the scoring criteria of Jess in detail.", "labels": [], "entities": [{"text": "Jess", "start_pos": 56, "end_pos": 60, "type": "TASK", "confidence": 0.8355560302734375}]}, {"text": "Sections 2, 3, and 4 examine rhetoric, organization, and content, respectively.", "labels": [], "entities": []}, {"text": "Section 5 presents an application example and associated operation times, and section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: State transition probabilities on", "labels": [], "entities": []}, {"text": " Table 2: Comparison of scoring results", "labels": [], "entities": []}, {"text": " Table 3: Correlation between Jess score, average  of expert raters, and linguistic understanding test", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9608922004699707}, {"text": "Jess score", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9802945852279663}, {"text": "linguistic understanding", "start_pos": 73, "end_pos": 97, "type": "TASK", "confidence": 0.6814441531896591}]}]}