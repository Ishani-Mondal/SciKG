{"title": [{"text": "Using comparable corpora to solve problems difficult for human translators", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present a tool that uses comparable corpora to find appropriate translation equivalents for expressions that are considered by translators as difficult.", "labels": [], "entities": []}, {"text": "For a phrase in the source language the tool identifies a range of possible expressions used in similar contexts in target language corpora and presents them to the translator as a list of suggestions.", "labels": [], "entities": []}, {"text": "In the paper we discuss the method and present results of human evaluation of the performance of the tool, which highlight its usefulness when dictionary solutions are lacking .", "labels": [], "entities": []}], "introductionContent": [{"text": "There is no doubt that both professional and trainee translators need access to authentic data provided by corpora.", "labels": [], "entities": []}, {"text": "With respect to polysemous lexical items, bilingual dictionaries list several translation equivalents fora headword, but words taken in their contexts can be translated in many more ways than indicated in dictionaries.", "labels": [], "entities": []}, {"text": "For instance, the Oxford Russian Dictionary (ORD) lacks a translation for the Russian expression \u00e8\u00f1\u00f7\u00e5\u00f0\u00ef\u00fb\u00e2\u00e0\u00fe\u00f9\u00e8\u00e9 \u00ee\u00f2\u00e2\u00e5\u00f2 ('comprehensive answer'), while the Multitran Russian-English dictionary suggests that it can be translated as irrefragable answer.", "labels": [], "entities": [{"text": "Oxford Russian Dictionary (ORD)", "start_pos": 18, "end_pos": 49, "type": "DATASET", "confidence": 0.9181765019893646}, {"text": "Multitran Russian-English dictionary", "start_pos": 153, "end_pos": 189, "type": "DATASET", "confidence": 0.9323145945866903}]}, {"text": "Yet this expression is extremely rare in English; on the Internet it occurs mostly in pages produced by Russian speakers.", "labels": [], "entities": []}, {"text": "On the other hand, translations for polysemous words are too numerous to be listed for all possible contexts.", "labels": [], "entities": []}, {"text": "For example, the entry for strong in ORD already has 57 subentries and yet it fails to mention many word combinations frequent in the British National Corpus (BNC), such as strong {feeling, field, opposition, sense, voice}.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 134, "end_pos": 163, "type": "DATASET", "confidence": 0.9656400382518768}]}, {"text": "Strong voice is also not listed in the Oxford French, German or Spanish Dictionaries.", "labels": [], "entities": [{"text": "Oxford French, German or Spanish Dictionaries", "start_pos": 39, "end_pos": 84, "type": "DATASET", "confidence": 0.9545328872544425}]}, {"text": "There has been surprisingly little research on computational methods for finding translation equivalents of words from the general lexicon.", "labels": [], "entities": []}, {"text": "Practically all previous studies have concerned detection of terminological equivalence.", "labels": [], "entities": []}, {"text": "For instance, project Termight at AT&T aimed to develop a tool for semi-automatic acquisition of termbanks in the computer science domain.", "labels": [], "entities": []}, {"text": "There was also a study concerning the use of multilingual webpages to develop bilingual lexicons and termbanks).", "labels": [], "entities": []}, {"text": "However, neither of them concerned translations of words from the general lexicon.", "labels": [], "entities": []}, {"text": "At the same time, translators often experience more difficulty in dealing with such general expressions because of their polysemy, which is reflected differently in the target language, thus causing the dependency of their translation on the corresponding context.", "labels": [], "entities": []}, {"text": "Such variation is often not captured by dictionaries.", "labels": [], "entities": []}, {"text": "Because of their importance, words from the general lexicon are studied by translation researchers, and comparable corpora are increasingly used in translation practice and training.", "labels": [], "entities": []}, {"text": "However, such studies are mostly confined to lexicographic exercises, which compare the contexts and functions of potential translation equivalents once they are known, for instance, absolutely vs. assolutamente in Italian.", "labels": [], "entities": []}, {"text": "Such studies do not provide a computational model for finding appropriate translation equivalents for expressions that are not listed or are inadequate in dictionaries.", "labels": [], "entities": []}, {"text": "Parallel corpora, conisting of original texts and their exact translations, provide a useful supplement to decontextualised translation equivalents listed in dictionaries.", "labels": [], "entities": []}, {"text": "However, parallel corpora are not representative.", "labels": [], "entities": []}, {"text": "Many of them are in the range of a few million words, which is simply too small to account for variations in translation of moderately frequent words.", "labels": [], "entities": []}, {"text": "Those that area bit larger, such as the Europarl corpus, are restricted in their domain.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9906063079833984}]}, {"text": "For instance, all of the 14 instances of strong voice in the English section of Europarl are used in the sense of 'the opinion of apolitical institution'.", "labels": [], "entities": [{"text": "English section of Europarl", "start_pos": 61, "end_pos": 88, "type": "DATASET", "confidence": 0.7918800562620163}]}, {"text": "At the same time the BNC contains 46 instances of strong voice covering several different meanings.", "labels": [], "entities": [{"text": "BNC", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.9007418751716614}]}, {"text": "In this paper we propose a computational method for using comparable corpora to find translation equivalents for source language expressions that are considered as difficult by trainee or professional translators.", "labels": [], "entities": []}, {"text": "The model is based on detecting frequent multi-word expressions (MWEs) in the source and target languages and finding a mapping between them in comparable monolingual corpora, which are designed in a similar way in the two languages.", "labels": [], "entities": [{"text": "detecting frequent multi-word expressions (MWEs)", "start_pos": 22, "end_pos": 70, "type": "TASK", "confidence": 0.6237983873912266}]}, {"text": "The described methodology is implemented in ASSIST, a tool that helps translators to find solutions for difficult translation problems.", "labels": [], "entities": [{"text": "ASSIST", "start_pos": 44, "end_pos": 50, "type": "TASK", "confidence": 0.6372604966163635}]}, {"text": "The tool presents the results as lists of translation suggestions (usually 50 to 100 items) ordered alphabetically or by their frequency in target language corpora.", "labels": [], "entities": []}, {"text": "Translators can skim through these lists and identify an example which is most appropriate in a given context.", "labels": [], "entities": []}, {"text": "In the following sections we outline our approach, evaluate the output of the prototype of AS-SIST and discuss future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "There are several attributes of our system which can be evaluated, and many of them are crucial for its efficient use in the workflow of professional translators, including: usability, quality of final solutions, trade-off between adequacy and fluency across usable examples, precision and recall of potentially relevant suggestions, as well as real-text evaluation, i.e. \"What is the coverage of difficult translation problems typically found in a text that can be successfully tackled?\"", "labels": [], "entities": [{"text": "precision", "start_pos": 276, "end_pos": 285, "type": "METRIC", "confidence": 0.9952398538589478}, {"text": "recall", "start_pos": 290, "end_pos": 296, "type": "METRIC", "confidence": 0.9848946928977966}]}, {"text": "In this paper we focus on evaluating the quality of potentially relevant translation solutions, which is the central point for developing and calibrating our methodology.", "labels": [], "entities": []}, {"text": "The evaluation experiment discussed below was specifically designed to assess the usefulness of translation suggestions generated by our tool -in cases where translators have doubts about the usefulness of dictionary solutions.", "labels": [], "entities": []}, {"text": "In this paper we do not evaluate other equally important aspects of the system's functionality, which will be the matter of future research.", "labels": [], "entities": []}, {"text": "For each translation direction we collected ten examples of possibly recalcitrant translation problems -words or phrases whose translation is not straightforward in a given context.", "labels": [], "entities": []}, {"text": "Some of these examples were sent to us by translators in response to our request for difficult cases.", "labels": [], "entities": []}, {"text": "For each example, which we included in the evaluation kit, the word or phrase either does not have a translation in ORD (which is a kind of a baseline standard reference for Russian translators), or its translation has significantly lower frequency in a target language corpus in comparison to the frequency of the source expression.", "labels": [], "entities": [{"text": "ORD", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.994515597820282}]}, {"text": "If an MWE is not listed in available dictionaries, we produced compositional (word-for-word) translations using ORD.", "labels": [], "entities": []}, {"text": "In order to remove a possible anti-dictionary bias from our experiment, we also checked translations in Multitran, an on-line translation dictionary, which was often quoted as one of the best resources for translation from and into Russian.", "labels": [], "entities": []}, {"text": "For each translation problem five solutions were presented to translators for evaluation.", "labels": [], "entities": [{"text": "translation", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.9620004296302795}]}, {"text": "One or two of these solutions were taken from a dictionary (usually from Multitran, and if available and different, from ORD).", "labels": [], "entities": [{"text": "Multitran", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.9663309454917908}]}, {"text": "The other suggestions were manually selected from lists of possible solutions returned by ASSIST.", "labels": [], "entities": [{"text": "ASSIST", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.6658796668052673}]}, {"text": "Again, the criteria for selection were intuitive: we included those suggestions which made best sense in the given context.", "labels": [], "entities": []}, {"text": "Dictionary suggestions and the output of ASSIST were indistinguishable in the questionnaires to the evaluators.", "labels": [], "entities": [{"text": "ASSIST", "start_pos": 41, "end_pos": 47, "type": "TASK", "confidence": 0.7352156043052673}]}, {"text": "The segments were presented in sentence context and translators had an option of providing their own solutions and comments.", "labels": [], "entities": []}, {"text": "Table 2 shows one of the questions sent to evaluators.", "labels": [], "entities": []}, {"text": "The problem example is \u00f7\u00e5\u00f2\u00ea\u00e0\u00ff \u00ef\u00f0\u00ee\u00e3\u00f0\u00e0\u00ec\u00ec\u00e0 are generated by ASSIST.", "labels": [], "entities": []}, {"text": "We then asked professional translators affiliated to a translator's association (identity witheld at this stage) to rate these five potential equivalents using a five-point scale: 5 = The suggestion is an appropriate translation as it is.", "labels": [], "entities": []}, {"text": "1 = The suggestion is totally irrelevant.", "labels": [], "entities": []}, {"text": "We received responses from eight translators.", "labels": [], "entities": []}, {"text": "Some translators did not score all solutions, but there were at least four independent judgements for each of the 100 translation variants.", "labels": [], "entities": []}, {"text": "An example of the combined answer sheet for all responses to the question from is given in: Scores to translation equivalents t2,.", "labels": [], "entities": []}, {"text": "denote translators; the dictionary translation is clear programme).", "labels": [], "entities": [{"text": "translators", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.9500450491905212}]}], "tableCaptions": [{"text": " Table 1: MWEs in News Corpora", "labels": [], "entities": []}, {"text": " Table 3: Scores to translation equivalents", "labels": [], "entities": [{"text": "translation equivalents", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.8590857088565826}]}, {"text": " Table 4: Examples for the two groups", "labels": [], "entities": []}, {"text": " Table 5: Averages for the two groups", "labels": [], "entities": [{"text": "Averages", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9950799942016602}]}]}