{"title": [{"text": "Estimating Class Priors in Domain Adaptation for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Estimating Class Priors in Domain Adaptation", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6876621395349503}, {"text": "Word Sense Disambiguation", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.7039195696512858}]}], "abstractContent": [{"text": "Instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word).", "labels": [], "entities": []}, {"text": "This in turn affects the accuracy of word sense disambiguation (WSD) systems trained and applied on different domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9990553259849548}, {"text": "word sense disambiguation (WSD)", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.8184801737467448}]}, {"text": "This paper presents a method to estimate the sense priors of words drawn from anew domain, and highlights the importance of using well calibrated probabilities when performing these estimations.", "labels": [], "entities": []}, {"text": "By using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in WSD accuracy.", "labels": [], "entities": [{"text": "WSD", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.900723397731781}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.873308539390564}]}], "introductionContent": [{"text": "Many words have multiple meanings, and the process of identifying the correct meaning, or sense of a word in context, is known as word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 130, "end_pos": 161, "type": "TASK", "confidence": 0.7780697047710419}]}, {"text": "Among the various approaches to WSD, corpus-based supervised machine learning methods have been the most successful to date.", "labels": [], "entities": [{"text": "WSD", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.988655686378479}]}, {"text": "With this approach, one would need to obtain a corpus in which each ambiguous word has been manually annotated with the correct sense, to serve as training data.", "labels": [], "entities": []}, {"text": "However, supervised WSD systems faced an important issue of domain dependence when using such a corpus-based approach.", "labels": [], "entities": [{"text": "WSD", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9459264278411865}]}, {"text": "To investigate this, conducted experiments using the DSO corpus, which contains sentences drawn from two different corpora, namely Brown Corpus (BC) and Wall Street Journal (WSJ).", "labels": [], "entities": [{"text": "DSO corpus", "start_pos": 53, "end_pos": 63, "type": "DATASET", "confidence": 0.9694905579090118}, {"text": "Brown Corpus (BC)", "start_pos": 131, "end_pos": 148, "type": "DATASET", "confidence": 0.9605906367301941}, {"text": "Wall Street Journal (WSJ)", "start_pos": 153, "end_pos": 178, "type": "DATASET", "confidence": 0.9540230135122935}]}, {"text": "They found that training a WSD system on one part (BC or WSJ) of the DSO corpus and applying it to the other part can result in an accuracy drop of 12% to 19%.", "labels": [], "entities": [{"text": "WSD", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9335747361183167}, {"text": "WSJ) of the DSO corpus", "start_pos": 57, "end_pos": 79, "type": "DATASET", "confidence": 0.6370869874954224}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.999355137348175}]}, {"text": "One reason for this is the difference in sense priors (i.e., the proportions of the different senses of a word) between BC and WSJ.", "labels": [], "entities": [{"text": "BC", "start_pos": 120, "end_pos": 122, "type": "METRIC", "confidence": 0.8925616145133972}, {"text": "WSJ", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.8958580493927002}]}, {"text": "For instance, the noun interest has these 6 senses in the DSO corpus: sense 1, 2, 3, 4, 5, and 8.", "labels": [], "entities": [{"text": "DSO corpus", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.9754669666290283}]}, {"text": "In the BC part of the DSO corpus, these senses occur with the proportions: 34%, 9%, 16%, 14%, 12%, and 15%.", "labels": [], "entities": [{"text": "BC part of the DSO corpus", "start_pos": 7, "end_pos": 32, "type": "DATASET", "confidence": 0.9301210443178812}]}, {"text": "However, in the WSJ part of the DSO corpus, the proportions are different: 13%, 4%, 3%, 56%, 22%, and 2%.", "labels": [], "entities": [{"text": "WSJ part of the DSO corpus", "start_pos": 16, "end_pos": 42, "type": "DATASET", "confidence": 0.9434902568658193}]}, {"text": "When the authors assumed they knew the sense priors of each word in BC and WSJ, and adjusted these two datasets such that the proportions of the different senses of each word were the same between BC and WSJ, accuracy improved by 9%.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8482866287231445}, {"text": "WSJ", "start_pos": 204, "end_pos": 207, "type": "DATASET", "confidence": 0.8653156757354736}, {"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.9995417594909668}]}, {"text": "In another work, Agirre and Martinez (2004) trained a WSD system on data which was automatically gathered from the Internet.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9584266543388367}]}, {"text": "The authors reported a 14% improvement inaccuracy if they have an accurate estimate of the sense priors in the evaluation data and sampled their training data according to these sense priors.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9617984294891357}]}, {"text": "The work of these researchers showed that when the domain of the training data differs from the domain of the data on which the system is applied, there will be a decrease in WSD accuracy.", "labels": [], "entities": [{"text": "WSD", "start_pos": 175, "end_pos": 178, "type": "TASK", "confidence": 0.7106136679649353}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.6790865659713745}]}, {"text": "To build WSD systems that are portable across different domains, estimation of the sense priors (i.e., determining the proportions of the different senses of a word) occurring in a text corpus drawn from a domain is important.", "labels": [], "entities": []}, {"text": "provided a partial solution by describing a method to predict the predominant sense, or the most frequent sense, of a word in a corpus.", "labels": [], "entities": []}, {"text": "Using the noun interest as an example, their method will try to predict that sense 1 is the predominant sense in the BC part of the DSO corpus, while sense 4 is the predominant sense in the WSJ part of the corpus.", "labels": [], "entities": [{"text": "BC part of the DSO corpus", "start_pos": 117, "end_pos": 142, "type": "DATASET", "confidence": 0.6753139446179072}, {"text": "WSJ part of the corpus", "start_pos": 190, "end_pos": 212, "type": "DATASET", "confidence": 0.8741892576217651}]}, {"text": "In our recent work), we directly addressed the problem by applying machine learning methods to automatically estimate the sense priors in the target domain.", "labels": [], "entities": []}, {"text": "For instance, given the noun interest and the WSJ part of the DSO corpus, we attempt to estimate the proportion of each sense of interest occurring in WSJ and showed that these estimates help to improve WSD accuracy.", "labels": [], "entities": [{"text": "WSJ part of the DSO corpus", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.8397520879904429}, {"text": "WSD", "start_pos": 203, "end_pos": 206, "type": "TASK", "confidence": 0.9434956908226013}, {"text": "accuracy", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.8789839744567871}]}, {"text": "In our work, we used naive Bayes as the training algorithm to provide posterior probabilities, or class membership estimates, for the instances in the target domain.", "labels": [], "entities": []}, {"text": "These probabilities were then used by the machine learning methods to estimate the sense priors of each word in the target domain.", "labels": [], "entities": []}, {"text": "However, it is known that the posterior probabilities assigned by naive Bayes are not reliable, or not well calibrated.", "labels": [], "entities": []}, {"text": "These probabilities are typically too extreme, often being very near 0 or 1.", "labels": [], "entities": []}, {"text": "Since these probabilities are used in estimating the sense priors, it is important that they are well calibrated.", "labels": [], "entities": []}, {"text": "In this paper, we explore the estimation of sense priors by first calibrating the probabilities from naive Bayes.", "labels": [], "entities": []}, {"text": "We also propose using probabilities from another algorithm (logistic regression, which already gives well calibrated probabilities) to estimate the sense priors.", "labels": [], "entities": []}, {"text": "We show that by using well calibrated probabilities, we can estimate the sense priors more effectively.", "labels": [], "entities": []}, {"text": "Using these estimates improves WSD accuracy and we achieve results that are significantly better than using our earlier approach described in).", "labels": [], "entities": [{"text": "WSD", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9403070211410522}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9699167013168335}]}, {"text": "In the following section, we describe the algorithm to estimate the sense priors.", "labels": [], "entities": []}, {"text": "Then, we describe the notion of being well calibrated and discuss why using well calibrated probabilities helps in estimating the sense priors.", "labels": [], "entities": []}, {"text": "Next, we describe an algorithm to calibrate the probability estimates from naive Bayes.", "labels": [], "entities": []}, {"text": "Then, we discuss the corpora and the set of words we use for our experiments before presenting our experimental results.", "labels": [], "entities": []}, {"text": "Next, we propose using the well calibrated probabilities of logistic regression to estimate the sense priors, and perform significance tests to compare our various results before concluding.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we discuss the motivations in choosing the particular corpora and the set of words used in our experiments.", "labels": [], "entities": []}, {"text": "Similar to our previous work, we used the supervised WSD approach described in () for our experiments, using the naive Bayes algorithm as our classifier.", "labels": [], "entities": [{"text": "WSD", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9090723395347595}]}, {"text": "Knowledge sources used include partsof-speech, surrounding words, and local collocations.", "labels": [], "entities": []}, {"text": "This approach achieves state-of-the-art accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9960642457008362}]}, {"text": "All accuracies reported in our experiments are micro-averages overall test examples.", "labels": [], "entities": []}, {"text": "In, we used a multiclass naive Bayes classifier (denoted by NB) for each word.", "labels": [], "entities": []}, {"text": "Following this approach, we noted the WSD accuracies achieved without any adjustment, in the column L under NB in.", "labels": [], "entities": [{"text": "WSD accuracies", "start_pos": 38, "end_pos": 52, "type": "METRIC", "confidence": 0.6270114779472351}]}, {"text": "The predictions , before being adjusted by these estimated sense priors based on Equation (4).", "labels": [], "entities": [{"text": "Equation", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9700764417648315}]}, {"text": "The resulting WSD accuracies after adjustment are listed in the column EM \u00a1 in, representing the WSD accuracies achievable by following the approach we described in).", "labels": [], "entities": [{"text": "EM", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9684115052223206}]}, {"text": "Next, we used the one-against-all approach to reduce each multiclass problem into a set of binary class problems.", "labels": [], "entities": []}, {"text": "We trained a naive Bayes classifier for each binary problem and calibrated the probabilities from these binary classifiers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Micro-averaged WSD accuracies using the various methods. The different naive Bayes classifiers are: multiclass", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8980177044868469}]}, {"text": " Table 2: Relative accuracy improvement based on cali-", "labels": [], "entities": [{"text": "Relative", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8333460688591003}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9257906675338745}]}, {"text": " Table 3: KL divergence between the true and estimated", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7470972537994385}]}]}