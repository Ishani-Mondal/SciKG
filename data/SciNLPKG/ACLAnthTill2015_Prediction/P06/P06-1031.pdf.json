{"title": [{"text": "A Feedback-Augmented Method for Detecting Errors in the Writing of Learners of English", "labels": [], "entities": [{"text": "Detecting Errors in the Writing of Learners of English", "start_pos": 32, "end_pos": 86, "type": "TASK", "confidence": 0.821198927031623}]}], "abstractContent": [{"text": "This paper proposes a method for detecting errors in article usage and singular plural usage based on the mass count distinction.", "labels": [], "entities": []}, {"text": "First, it learns decision lists from training data generated automatically to distinguish mass and count nouns.", "labels": [], "entities": []}, {"text": "Then, in order to improve its performance, it is augmented by feedback that is obtained from the writing of learners.", "labels": [], "entities": []}, {"text": "Finally, it detects errors by applying rules to the mass count distinction.", "labels": [], "entities": []}, {"text": "Experiments show that it achieves a recall of 0.71 and a precision of 0.72 and outperforms other methods used for comparison when augmented by feedback.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9996412992477417}, {"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9989303946495056}]}], "introductionContent": [{"text": "Although several researchers) have shown that rulebased methods are effective to detecting grammatical errors in the writing of learners of English, it has been pointed out that it is hard to write rules for detecting errors concerning the articles and singular plural usage.", "labels": [], "entities": []}, {"text": "To be precise, it is hard to write rules for distinguishing mass and count nouns which are particularly important in detecting these errors.", "labels": [], "entities": []}, {"text": "The major reason for this is that whether a noun is amass noun or a count noun greatly depends on its meaning or its surrounding context (refer to and for details of the mass count distinction).", "labels": [], "entities": []}, {"text": "The above errors are very common among Japanese learners of English (.", "labels": [], "entities": []}, {"text": "This is perhaps because the Japanese language does not have amass count distinction system similar to that of English.", "labels": [], "entities": []}, {"text": "Thus, it is favorable for error detection systems aiming at Japanese learners to be capable of detecting these errors.", "labels": [], "entities": [{"text": "error detection", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7256919592618942}]}, {"text": "In other words, such systems need to somehow distinguish mass and count nouns.", "labels": [], "entities": []}, {"text": "This paper proposes a method for distinguishing mass and count nouns in context to complement the conventional rules for detecting grammatical errors.", "labels": [], "entities": []}, {"text": "In this method, first, training data, which consist of instances of mass and count nouns, are automatically generated from a corpus.", "labels": [], "entities": []}, {"text": "Then, decision lists for distinguishing mass and count nouns are learned from the training data.", "labels": [], "entities": []}, {"text": "Finally, the decision lists are used with the conventional rules to detect the target errors.", "labels": [], "entities": []}, {"text": "The proposed method requires a corpus to learn decision lists for distinguishing mass and count nouns.", "labels": [], "entities": []}, {"text": "General corpora such as newspaper articles can be used for the purpose.", "labels": [], "entities": []}, {"text": "However, a drawback to it is that there are differences in character between general corpora and the writing of non-native learners of English).", "labels": [], "entities": []}, {"text": "For instance, point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English.", "labels": [], "entities": []}, {"text": "Consequently, the differences affect the performance of the proposed method.", "labels": [], "entities": []}, {"text": "In order to reduce the drawback, the proposed method is augmented by feedback; it takes as feedback learners' essays whose errors are corrected by a teacher of English (hereafter, referred to as the feedback corpus).", "labels": [], "entities": []}, {"text": "In essence, the feedback corpus could be added to a general corpus to generate training data.", "labels": [], "entities": []}, {"text": "Or, ideally training data could be generated only from the feedback corpus just as from a general corpus.", "labels": [], "entities": []}, {"text": "However, this causes a serious problem in practice since the size of the feedback corpus is normally far smaller than that of a general corpus.", "labels": [], "entities": []}, {"text": "To make it practical, this paper discusses the problem and explores its solution.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the method for detecting the target errors based on the mass count distinction.", "labels": [], "entities": [{"text": "mass count distinction", "start_pos": 76, "end_pos": 98, "type": "METRIC", "confidence": 0.7821357448895773}]}, {"text": "Section 3 explains how the method is augmented by feedback.", "labels": [], "entities": []}, {"text": "Section 4 discusses experiments conducted to evaluate the proposed method.", "labels": [], "entities": []}], "datasetContent": [{"text": "A set of essays 9 written by Japanese learners of English was used as the target essays in the experiments.", "labels": [], "entities": []}, {"text": "It consisted of 47 essays (3180 words) on the topic traveling.", "labels": [], "entities": []}, {"text": "A native speaker of English who was a professional rewriter of English recognized 105 target errors in it.", "labels": [], "entities": []}, {"text": "The written part of the British National Corpus (BNC) was used to learn decision lists.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 24, "end_pos": 53, "type": "DATASET", "confidence": 0.9705069462458292}, {"text": "decision lists", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.7560472190380096}]}, {"text": "Sentences the OAK system 10 , which was used to extract NPs from the corpus, failed to analyze were excluded.", "labels": [], "entities": [{"text": "OAK system 10", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.9091300964355469}]}, {"text": "After these operations, the size of the corpus approximately amounted to 80 million words.", "labels": [], "entities": []}, {"text": "Hereafter, the corpus will be referred to as the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.9434731006622314}]}, {"text": "As another corpus, the English concept explication in the EDR English-Japanese Bilingual dictionary and the EDR corpus (1993) were used; it will be referred to as the EDR corpus, hereafter.", "labels": [], "entities": [{"text": "EDR English-Japanese Bilingual dictionary", "start_pos": 58, "end_pos": 99, "type": "DATASET", "confidence": 0.9333720952272415}, {"text": "EDR corpus (1993)", "start_pos": 108, "end_pos": 125, "type": "DATASET", "confidence": 0.9618873834609986}, {"text": "EDR corpus", "start_pos": 167, "end_pos": 177, "type": "DATASET", "confidence": 0.9357235729694366}]}, {"text": "Its size amounted to about 3 million words.", "labels": [], "entities": []}, {"text": "Performance of the proposed method was evaluated by recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9997441172599792}, {"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.999071478843689}]}, {"text": "Recall is defined by  First, decision lists for each target noun in the target essays were learned from the BNC 11 . To extract noun phrases and their head nouns, the OAK system was used.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9395216107368469}, {"text": "BNC 11", "start_pos": 108, "end_pos": 114, "type": "DATASET", "confidence": 0.9416585862636566}]}, {"text": "An optimal value for $ (window size of context) was estimated as follows.", "labels": [], "entities": []}, {"text": "For 25 nouns shown in) as examples of nouns used as both mass and count nouns, accuracy on the BNC was calculated using ten-fold cross validation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9995456337928772}, {"text": "BNC", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.774800717830658}]}, {"text": "As a result of setting small ($ was selected in the experiments.", "labels": [], "entities": []}, {"text": "Second, the target nouns were distinguished whether they were mass or count by the learned decision lists, and then the target errors were detected by applying the detection rules to the mass count distinction.", "labels": [], "entities": []}, {"text": "As a preprocessing, spelling errors were corrected using a spellchecker.", "labels": [], "entities": []}, {"text": "The results of the detection were compared to those done by the native-speaker of English.", "labels": [], "entities": []}, {"text": "From the comparison, recall and precision were calculated.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9997630715370178}, {"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9997434020042419}]}, {"text": "Then, the feedback-augmented method was evaluated on the same target essays.", "labels": [], "entities": []}, {"text": "Each target essay in turn was left out, and all the remaining target essays were used as a feedback corpus.", "labels": [], "entities": []}, {"text": "The target errors in the left-out essay were detected using the feedback-augmented method.", "labels": [], "entities": []}, {"text": "The results of all 47 detections were integrated into one to calculate overall performance.", "labels": [], "entities": []}, {"text": "This way of feedback can be regarded as that one uses revised essays previously written in a class to detect errors in essays on the same topic written in other classes.", "labels": [], "entities": []}, {"text": "Finally, the above two methods were compared with their seven variants shown in.", "labels": [], "entities": []}, {"text": "\"DL\" in refers to the nine decision list based methods (the above two methods and their seven variants).", "labels": [], "entities": []}, {"text": "The words in brackets denote the corpora used to learn decision lists; the symbol \"+FB\" means that the feedback corpus was simply added to the general corpus.", "labels": [], "entities": [{"text": "FB", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.9928697943687439}]}, {"text": "indicate that the feedback was done by using Equation (8) and Equation (9), respectively.", "labels": [], "entities": [{"text": "Equation", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9827616810798645}, {"text": "Equation (9)", "start_pos": 62, "end_pos": 74, "type": "METRIC", "confidence": 0.9265887141227722}]}, {"text": "In addition to the seven variants, two kinds of earlier method were used for comparison.", "labels": [], "entities": []}, {"text": "One was one of the rule-based methods.", "labels": [], "entities": []}, {"text": "It judges singular head nouns with no determiner to be erroneous since missing articles are most common in the writing of Japanese learners of English.", "labels": [], "entities": []}, {"text": "In the experiments, this was implemented by treating all nouns as count nouns and applying the same detection rules as in the proposed method to the countability.", "labels": [], "entities": []}, {"text": "The other was a web-based method) 12 for generating articles.", "labels": [], "entities": []}, {"text": "It retrieves web counts for queries consisting of two words preceding the NP that the target noun head, one of the articles ( \u0091 a/an, the, \u0093 \u0092 ) , and the core NP to generate articles.", "labels": [], "entities": []}, {"text": "All queries are performed as exact matches using quotation marks and submitted to the Google search engine in lowercase.", "labels": [], "entities": []}, {"text": "For example, in the case of \"*She is good student.\", it retrieves web counts for \"she is a good student\", \"she is the good student\", and \"she is good student\".", "labels": [], "entities": []}, {"text": "Then, it generates the article that maximizes the web counts.", "labels": [], "entities": []}, {"text": "We extended it to make it capable of detecting our target errors.", "labels": [], "entities": []}, {"text": "First, the singular/plural distinction was taken into account in the queries (e.g., \"she is a good students\", \"she is the good students\", and \"she is good students\" in addition to the above three queries).", "labels": [], "entities": []}, {"text": "The one(s) that maximized the web counts was judged to be correct; the rest were judged to be erroneous.", "labels": [], "entities": []}, {"text": "Second, if determiners other than the articles modify head nouns, only the distinction between singular and plural was taken into account (e.g., \"he has some book\" vs \"he has some books\").", "labels": [], "entities": []}, {"text": "In the case of \"much/many\", the target noun in singular form modified by \"much\" and that in plural form modified by \"many\" were compared (e.g., \"he has much furniture\" vs \"he has many furnitures).", "labels": [], "entities": []}, {"text": "Finally, some rules were used to detect literal errors.", "labels": [], "entities": []}, {"text": "For example, plural head nouns modified by \"this\" were judged to be erroneous.", "labels": [], "entities": []}, {"text": "\"Rulebased\" and \"Web-based\" in refer to the rule-based method and the web-based method, respectively.", "labels": [], "entities": []}, {"text": "The other symbols are as already explained in Section 4.2.", "labels": [], "entities": []}, {"text": "As we can see from, all the decision list based methods outperform the earlier methods.", "labels": [], "entities": []}, {"text": "The rule-based method treated all nouns as count nouns, and thus it did notwork well at all on mass nouns.", "labels": [], "entities": []}, {"text": "This caused a lot of false-positives and false-negatives.", "labels": [], "entities": []}, {"text": "The web-based method suffered a lot from other errors than the target errors since it implicitly assumed that there were no errors except the target errors.", "labels": [], "entities": []}, {"text": "Contrary to this assumption, not only did the target essays contain the target errors but also other errors since they were written by Japanese learners of English.", "labels": [], "entities": []}, {"text": "This indicate that the queries often contained the other errors when web counts were retrieved.", "labels": [], "entities": []}, {"text": "These errors made the web counts useless, and thus it did not perform well.", "labels": [], "entities": []}, {"text": "By contrast, the decision list based methods did because they distinguished mass and count nouns by one of the words around the target noun that was most likely to be effective according to the log-likelihood ratio ; the best performing decision list based method (DL \u0097 \u0084 \u0098 \u009a (EDR)) is significantly superior to the best performing 14 nondecision list based method (Web-based) in both recall and precision at the 99% confidence level.", "labels": [], "entities": [{"text": "recall", "start_pos": 385, "end_pos": 391, "type": "METRIC", "confidence": 0.9993915557861328}, {"text": "precision", "start_pos": 396, "end_pos": 405, "type": "METRIC", "confidence": 0.9988821148872375}]}, {"text": "also shows that the feedback-augmented methods benefit from feedback.", "labels": [], "entities": []}, {"text": "Only an exception is \"DL \u0097 \u0084 \u0098 \u0099 (BNC)\".", "labels": [], "entities": [{"text": "DL", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.7279910445213318}]}, {"text": "The reason is that the size of BNC is far larger than that of the feedback corpus and thus it did not affect the performance.", "labels": [], "entities": []}, {"text": "This also explains that simply adding the feedback corpus to the general corpus achieved little or no improvement as \"DL (EDR+FB)\" and \"DL (BNC+FB)\" show.", "labels": [], "entities": []}, {"text": "Unlike these, both \"DL \u0097 \u0084 \u0098 \u009a (BNC)\" and \"DL \u0097 \u0084 \u0098 \u009a (EDR)\" benefit from feedback since the effect of the general corpus is limited to some extent by the log function in Equation (9).", "labels": [], "entities": []}, {"text": "Because of this, both benefit from feedback despite the differences in size between the feedback corpus and the general corpus.", "labels": [], "entities": []}, {"text": "Although the experimental results have shown that the feedback-augmented method is effective to detecting the target errors in the writing of Japanese learners of English, even the best performing method (DL \u0097 \u0084 \u0098 \u009a (EDR)) made 30 falsenegatives and 29 false-positives.", "labels": [], "entities": []}, {"text": "About 70% of the false-negatives were errors that required other sources of information than the mass count distinction to be detected.", "labels": [], "entities": [{"text": "mass count distinction", "start_pos": 97, "end_pos": 119, "type": "METRIC", "confidence": 0.679080863793691}]}, {"text": "For example, extra definite articles (e.g., *the traveling) cannot be detected even if the correct mass count distinction is given.", "labels": [], "entities": []}, {"text": "Thus, only a little improvement is expected in recall however much feedback corpus data become available.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9986359477043152}]}, {"text": "On the other hand, most of the false-positives were due to the decision lists themselves.", "labels": [], "entities": []}, {"text": "Considering this, it is highly possible that precision will improve as the size of the feedback corpus increases.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9993008375167847}]}], "tableCaptions": [{"text": " Table 2: Rules in a decision list  Mass  Count", "labels": [], "entities": []}]}