{"title": [{"text": "Discovering asymmetric entailment relations between verbs using selectional preferences", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we investigate a novel method to detect asymmetric entailment relations between verbs.", "labels": [], "entities": []}, {"text": "Our starting point is the idea that some point-wise verb selec-tional preferences carry relevant semantic information.", "labels": [], "entities": []}, {"text": "Experiments using Word-Net as a gold standard show promising results.", "labels": [], "entities": [{"text": "Word-Net", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.9604755640029907}]}, {"text": "Where applicable, our method, used in combination with other approaches, significantly increases the performance of en-tailment detection.", "labels": [], "entities": [{"text": "en-tailment detection", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.775510311126709}]}, {"text": "A combined approach including our model improves the AROC of 5% absolute points with respect to standard models.", "labels": [], "entities": [{"text": "AROC", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9897300004959106}]}], "introductionContent": [{"text": "Natural Language Processing applications often need to rely on large amount of lexical semantic knowledge to achieve good performances.", "labels": [], "entities": []}, {"text": "Asymmetric verb relations are part of it.", "labels": [], "entities": []}, {"text": "Consider for example the question \"What college did Marcus Camby play for?\".", "labels": [], "entities": [{"text": "Marcus Camby play", "start_pos": 52, "end_pos": 69, "type": "DATASET", "confidence": 0.7561695277690887}]}, {"text": "A question answering (QA) system could find the answer in the snippet \"Marcus Camby won for Massachusetts\" as the question verb play is related to the verb win.", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.8456784725189209}, {"text": "Marcus Camby won for Massachusetts", "start_pos": 71, "end_pos": 105, "type": "DATASET", "confidence": 0.8460657358169555}]}, {"text": "The viceversa is not true.", "labels": [], "entities": []}, {"text": "If the question is \"What college did Marcus Camby won for?\", the snippet \"Marcus Camby played for Massachusetts\" cannot be used.", "labels": [], "entities": [{"text": "Marcus Camby won", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.8618554472923279}]}, {"text": "Winnig entails playing but not vice-versa, as the relation between win and play is asymmetric.", "labels": [], "entities": []}, {"text": "Recently, many automatically built verb lexicalsemantic resources have been proposed to support lexical inferences, such as.", "labels": [], "entities": []}, {"text": "All these resources focus on symmetric semantic relations, such as verb similarity.", "labels": [], "entities": []}, {"text": "Yet, not enough attention has been paid so far to the study of asymmetric verb relations, that are often the only way to produce correct inferences, as the example above shows.", "labels": [], "entities": []}, {"text": "In this paper we propose a novel approach to identify asymmetric relations between verbs.", "labels": [], "entities": []}, {"text": "The main idea is that asymmetric entailment relations between verbs can be analysed in the context of class-level and word-level selectional preferences.", "labels": [], "entities": []}, {"text": "Selectional preferences indicate an entailment relation between a verb and its arguments.", "labels": [], "entities": []}, {"text": "For example, the selectional preference {human} win maybe read as a smooth constraint: if x is the subject of win then it is likely that x is a human, i.e. win(x) \u2192 human(x).", "labels": [], "entities": []}, {"text": "It follows that selectional preferences like {player} win maybe read as suggesting the entailment relation win(x) \u2192 play(x).", "labels": [], "entities": []}, {"text": "Selectional preferences have been often used to infer semantic relations among verbs and to build symmetric semantic resources as in.", "labels": [], "entities": []}, {"text": "However, in those cases these are exploited in a different way.", "labels": [], "entities": []}, {"text": "The assumption is that verbs are semantically related if they share similar selectional preferences.", "labels": [], "entities": []}, {"text": "Then, according to the Distributional Hypothesis, verbs occurring in similar sentences are likely to be semantically related.", "labels": [], "entities": []}, {"text": "The Distributional Hypothesis suggests a generic equivalence between words.", "labels": [], "entities": []}, {"text": "Related methods can then only discover symmetric relations.", "labels": [], "entities": []}, {"text": "These methods can incidentally find verb pairs as (win,play) where an asymmetric entailment relation holds, but they cannot state the direction of entailment (e.g., win\u2192play).", "labels": [], "entities": []}, {"text": "As we investigate the idea that a single relevant verb selectional preference (as {player} win) could produce an entailment relation between verbs, our starting point cannot be the Distributional Hypothesis.", "labels": [], "entities": []}, {"text": "Our assumption is that some point-wise assertions carry relevant semantic information (as in).", "labels": [], "entities": []}, {"text": "We do not derive a semantic relation between verbs by comparing their selectional preferences, but we use pointwise corpus-induced selectional preferences.", "labels": [], "entities": []}, {"text": "The rest of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "2 we discuss the intuition behind our research.", "labels": [], "entities": []}, {"text": "3 we describe different types of verb entailment.", "labels": [], "entities": []}, {"text": "4 we introduce our model for detecting entailment relations among verbs . In Sec.", "labels": [], "entities": [{"text": "detecting entailment relations among verbs", "start_pos": 29, "end_pos": 71, "type": "TASK", "confidence": 0.8881543159484864}]}, {"text": "5 we review related works that are used both for comparison and for building combined methods.", "labels": [], "entities": []}, {"text": "6 we present the results of our experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of the experimental evaluation is to establish if the nominalized pattern is useful to help hb hb + pe hb + pe + n hb + pe + n in detecting verb entailment.", "labels": [], "entities": [{"text": "detecting verb entailment", "start_pos": 138, "end_pos": 163, "type": "TASK", "confidence": 0.8730553388595581}]}, {"text": "We experiment with the method by itself or in combination with other sets of patterns.", "labels": [], "entities": []}, {"text": "We are then interested only in verb pairs where the nominalized pattern is applicable.", "labels": [], "entities": []}, {"text": "The best pattern or the best combined method should be the one that gives the highest values of S to verb pairs in entailment relation, and the lowest value to other pairs.", "labels": [], "entities": []}, {"text": "We need a corpus C over which to estimate probabilities, and two dataset, one of verb entailment pairs, the True Set (T S), and another with verbs not in entailment, the Control Set (CS).", "labels": [], "entities": []}, {"text": "We use the web as corpus C whereto estimate S mi and Google TM as a count estimator.", "labels": [], "entities": []}, {"text": "The web has been largely employed as a corpus (e.g.,).", "labels": [], "entities": []}, {"text": "The findings described in suggest that the count estimations we need in our study over Subject-Verb bigrams are highly correlated to corpus counts.", "labels": [], "entities": []}, {"text": "Since we have a predefined (but not exhaustive) set of verb pairs in entailment, i.e. ent in WordNet, we cannot replicate a natural distribution of verb pairs that are or are not in entailment.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9435153603553772}]}, {"text": "Recall and precision lose sense.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.4514641761779785}, {"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9989978671073914}]}, {"text": "Then, the best way to compare the patterns is to use the ROC curve () mixing sensitivity and specificity.", "labels": [], "entities": [{"text": "ROC", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9901367425918579}]}, {"text": "ROC analysis provides a natural means to check and estimate how a statistical measure is able to distinguish positive examples, the True Set (T S), and negative examples, the Control Set (CS).", "labels": [], "entities": [{"text": "ROC analysis", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8687428534030914}]}, {"text": "Given a threshold t, Se(t) is the probability of a candidate pair (v h , v t ) to belong to True Set if the testis positive, while Sp(t) is the probability of belonging to ControlSet if the testis negative, i.e.: The ROC curve (Se(t) vs. 1 \u2212 Sp(t)) naturally follows (see).", "labels": [], "entities": []}, {"text": "Better methods will have ROC curves more similar to the step function f (1 \u2212 Sp(t)) = 0 when 1 \u2212 Sp(t) = 0 and f (1 \u2212 Sp(t)) = 1 when 0 < 1 \u2212 Sp(t) \u2264 1.", "labels": [], "entities": []}, {"text": "The ROC analysis provides another useful evaluation tool: the AROC, i.e. the total area under the ROC curve.", "labels": [], "entities": [{"text": "AROC", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9674743413925171}]}, {"text": "Statistically, AROC represents the probability that the method in evaluation will rank a chosen positive example higher than a randomly chosen negative instance.", "labels": [], "entities": [{"text": "AROC", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9889869689941406}]}, {"text": "AROC is usually used to better compare two methods that have similar ROC curves.", "labels": [], "entities": [{"text": "AROC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.46004077792167664}]}, {"text": "Better methods will have higher AROCs.", "labels": [], "entities": [{"text": "AROCs", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.8447445034980774}]}, {"text": "As True Set (T S) we use the controlled verb entailment pairs ent contained in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.9788898229598999}]}, {"text": "3, the entailment relation is a semantic relation defined at the synset level, standing in the verb sub-hierarchy.", "labels": [], "entities": []}, {"text": "That is, each pair of synsets (S t , S h ) is an oriented entailment relation between St and S h . WordNet contains 409 entailed synsets.", "labels": [], "entities": []}, {"text": "These entailment relations are consequently stated also at the lexical level.", "labels": [], "entities": []}, {"text": "The pair (S t , S h ) naturally implies that v t entails v h for each possible v t \u2208 St and v h \u2208 S h . It is possible to derive from the 409 entailment synset a test set of 2,233 verb pairs.", "labels": [], "entities": []}, {"text": "As Control Set we use two sets: random and ent.", "labels": [], "entities": []}, {"text": "The random set is randomly generated using verb in ent, taking care of avoiding to capture pairs in entailment relation.", "labels": [], "entities": []}, {"text": "A pair is considered a control pair if it is not in the True Set (the intersection between the True Set and the Control Set is empty).", "labels": [], "entities": []}, {"text": "The ent is the set of pairs in ent with pairs in the reverse order.", "labels": [], "entities": []}, {"text": "These two Control Sets will give two possible ways of evaluating the methods: a general and a more complex task.", "labels": [], "entities": []}, {"text": "As a pre-processing step, we have to clean the two sets from pairs in which the hypotheses cannot be nominalized, as our pattern P nom is applicable only in these cases.", "labels": [], "entities": []}, {"text": "The pre-processing step retains 1,323 entailment verb pairs.", "labels": [], "entities": []}, {"text": "For comparative purposes the random Control Set is kept with the same cardinality of the True Set (in all, 1400 verb pairs).", "labels": [], "entities": []}, {"text": "S is then evaluated for each pattern over the True Set and the Control Set, using equation for P nom , and equation for P pe and P hb . The best pattern or combined method is the one that is able to most neatly split entailment pairs from random pairs.", "labels": [], "entities": []}, {"text": "That is, it should in average assign higher S values to pairs in the True Set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performances in the general case: ent vs.  random", "labels": [], "entities": []}, {"text": " Table 3: Performances in the complex case: ent  vs. ent", "labels": [], "entities": []}]}