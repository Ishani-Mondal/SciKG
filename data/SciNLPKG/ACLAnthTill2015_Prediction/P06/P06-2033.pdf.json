{"title": [{"text": "Conceptual Coherence in the Generation of Referring Expressions", "labels": [], "entities": []}], "abstractContent": [{"text": "One of the challenges in the automatic generation of referring expressions is to identify a set of domain entities coherently , that is, from the same conceptual perspective.", "labels": [], "entities": []}, {"text": "We describe and evaluate an algorithm that generates a conceptually coherent description of a target set.", "labels": [], "entities": []}, {"text": "The design of the algorithm is motivated by the results of psycholinguistic experiments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Algorithms for the Generation of Referring Expressions (GRE) seek a set of properties that distinguish an intended referent from its distractors in a knowledge base.", "labels": [], "entities": [{"text": "Generation of Referring Expressions (GRE)", "start_pos": 19, "end_pos": 60, "type": "TASK", "confidence": 0.7512968523161752}]}, {"text": "Much of the GRE literature has focused on developing efficient content determination strategies that output the best available description according to some interpretation of the Gricean maxims (, especially Brevity.", "labels": [], "entities": [{"text": "GRE", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.8677039742469788}, {"text": "Brevity", "start_pos": 208, "end_pos": 215, "type": "METRIC", "confidence": 0.9955915808677673}]}, {"text": "Work on reference to sets has also proceeded within this general framework.", "labels": [], "entities": []}, {"text": "One problem that has not received much attention is that of conceptual coherence in the generation of plural references, i.e. the ascription of related properties to elements of a set, so that the resulting description constitutes a coherent cover for the plurality.", "labels": [], "entities": []}, {"text": "As an example, consider a reference to {e 1 , e 3 } in using the Incremental Algorithm (IA).", "labels": [], "entities": []}, {"text": "IA searches along an ordered list of attributes, selecting properties of the intended referents that remove some distractors.", "labels": [], "entities": [{"text": "IA", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9754652380943298}]}, {"text": "Assuming the ordering in the top row, IA would yield the postgraduate and the chef, which is fine in case occupation is the relevant attribute in the discourse, but otherwise is arguably worse than an alternative like the italian and the maltese, because it is more difficult to see what a postgraduate and a chef have in common.", "labels": [], "entities": [{"text": "IA", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.7047612071037292}]}, {"text": "Conceptual Coherence Constraint (CC): As far as possible, describe objects using related properties.", "labels": [], "entities": [{"text": "Conceptual Coherence Constraint (CC)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7541598826646805}]}, {"text": "Related issues have been raised in the formal semantics literature.", "labels": [], "entities": []}, {"text": "argues that an appropriate answer to a question of the form 'Wh x?'", "labels": [], "entities": []}, {"text": "must conceptualise the different instantiations of x using a perspective which is relevant given the hearer's information state and the context.", "labels": [], "entities": []}, {"text": "distinguishes a description's functional relevance -i.e. its success in distinguishing a referent -from its conversational relevance, which arises in part from implicatures.", "labels": [], "entities": []}, {"text": "In our example, describing e 1 as the postgraduate carries the implicature that the entity's academic role is relevant.", "labels": [], "entities": []}, {"text": "When two entities are described using contrasting properties, say the student and the italian, the contrast maybe misleading for the listener.", "labels": [], "entities": []}, {"text": "Any attempt to port these observations to the GRE scenario must do so without sacrificing logical completeness.", "labels": [], "entities": [{"text": "GRE scenario", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.7748022973537445}]}, {"text": "While a GRE algorithm should attempt to find the most coherent description available, it should not fail in the absence of a coherent set of properties.", "labels": [], "entities": []}, {"text": "This paper aims to achieve a dual goal.", "labels": [], "entities": []}, {"text": "First ( \u00a72), we will show that the CC can be explained and modelled in terms of lexical semantic forces within a description, a claim supported by the results of two experiments.", "labels": [], "entities": []}, {"text": "Our focus on 'low-level', lexical, determinants of adequacy constitutes a departure from the standard Gricean view.", "labels": [], "entities": []}, {"text": "Second, we describe an algorithm motivated by the experimental findings ( \u00a73) which seeks to find the most coherent description available in a domain according to CC.", "labels": [], "entities": []}], "datasetContent": [{"text": "In Experiment 1, participants were placed in a situation where they were buying objects from an online store.", "labels": [], "entities": []}, {"text": "They saw scenarios containing four pictures of objects, three of which (the targets) were identically priced.", "labels": [], "entities": []}, {"text": "Participants referred to them by completing a 2-sentence discourse: S1 The object1 and the object 2 cost amount.", "labels": [], "entities": []}, {"text": "Experiment 2 was a sentence continuation task, designed to closely approximate content determination in GRE.", "labels": [], "entities": [{"text": "sentence continuation task", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.8118784030278524}, {"text": "content determination", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.6900627613067627}]}, {"text": "Participants saw a series of discourses, in which three entities (e 1 , e 2 , e 3 ) were introduced, each with two distinguishing properties.", "labels": [], "entities": []}, {"text": "The final sentence in each discourse had a missing plural subject NP referring to two of these.", "labels": [], "entities": []}, {"text": "The context made it clear which of the three entities had to be referred to.", "labels": [], "entities": []}, {"text": "Our hypothesis was that participants would prefer to use semantically similar properties for the plural reference, even if dissimilar properties were also available.", "labels": [], "entities": []}, {"text": "Materials, design and procedure Materials consisted of 24 discourses, such as those in2.", "labels": [], "entities": []}, {"text": "After an initial introductory sentence, the 3 entities were introduced in separate sentences.", "labels": [], "entities": []}, {"text": "In all discourses, the pairs {e 1 , e 2 } and {e 2 , e 3 } could be described using either pairwise similar or dissimilar properties (similar pairs are coindexed in the.", "labels": [], "entities": []}, {"text": "In half the discourses, the distinguishing properties of each entity were nouns; thus, although all three entities belonged to the same ontological category (e.g. all human), they had distinct types (e.g. duke, prince, bachelor).", "labels": [], "entities": []}, {"text": "In the other half, entities were of the same type, that is the NPs introducing them had the same nominal head, but had distinguishing adjectival modifiers.", "labels": [], "entities": []}, {"text": "For counterbalancing, two versions of each discourse were constructed, such that, if {e 1 , e 2 } was the target set in Version 1, then {e 2 , e 3 } was the target in Version 2.", "labels": [], "entities": []}, {"text": "Twelve filler items requiring singular reference in the continuation were also included.", "labels": [], "entities": []}, {"text": "The order in which the entities were introduced was randomised across participants, as was the order of trials.", "labels": [], "entities": []}, {"text": "The experiment was completed by 18 native speakers of English, selected from the Aberdeen NLG Group database.", "labels": [], "entities": [{"text": "Aberdeen NLG Group database", "start_pos": 81, "end_pos": 108, "type": "DATASET", "confidence": 0.9894963651895523}]}, {"text": "They were randomly assigned to either Version 1 or 2.", "labels": [], "entities": []}, {"text": "Results and discussion Responses were coded 1 if the semantically similar properties were used (e.g. the prince and the duke in; 2 if the similar properties were used together with other properties (e.g. the prince and the bachelor duke); 3 if a superordinate term was used to replace the similar properties (e.g. the noblemen); 4 otherwise (e.g. The duke and the collector).", "labels": [], "entities": []}, {"text": "Response types differed significantly in the nominal condition both by subjects (\u03c7 2 1 = 45.89, p < .001) and by items (\u03c7 2 2 = 287.9, p < .001).", "labels": [], "entities": []}, {"text": "Differences were also reliable in the modifier condition (\u03c7 2 1 = 36.3, p < .001, \u03c7 2 2 = 199.2, p < .001).", "labels": [], "entities": []}, {"text": "However, the trends across conditions were opposed, with more items in the 1 response category in the nominal condition (53.7%) and more in the 4 category in the modifier condition (47.2%).", "labels": [], "entities": []}, {"text": "Recoding responses as binary ('similar' = 1,2,3; 'dissimilar' = 4) showed a significant difference in proportions for the nominal category (\u03c7 2 = 4.78, p = .03), but not the modifier category.", "labels": [], "entities": []}, {"text": "Pairwise comparisons showed a significantly larger proportion of 1 (Z = 2.7, p = .007) and 2 responses (Z = 2.54, p = .01) in the nominal compared to the modifier condition.", "labels": [], "entities": []}, {"text": "The results suggest that in a referential task, participants are likely to conform to the CC, but that the CC operates mainly on nouns, and less soon (adjectival) modifiers.", "labels": [], "entities": []}, {"text": "Nouns (or types, as we shall sometimes call them) have the function of categorising objects; thus similar types facilitate the mental representation of a plurality in a conceptually coherent way.", "labels": [], "entities": []}, {"text": "According to the definition in (1), this is because similarity of two types implies a greater likelihood of their being used in the same predicate-argument structures.", "labels": [], "entities": []}, {"text": "As a result, it is easier to map the elements of a plurality to a common role in a sentence.", "labels": [], "entities": []}, {"text": "A related proposal has been made by, whose Scenario Mapping Principle holds that a plural reference is licensed to the extent that the elements of the plurality can be mapped to a common role in the discourse.", "labels": [], "entities": []}, {"text": "This is influenced by how easy it is to conceive of such a role for the referents.", "labels": [], "entities": []}, {"text": "Our results can be viewed as providing a handle on the notion of 'ease of conception of a common role'; in particular we propose that likelihood of occurrence in the same linguistic contexts directly reflects the extent to which two types can be mapped to a single plural role.", "labels": [], "entities": [{"text": "ease", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9828318953514099}]}, {"text": "As regards modifiers, while it is probably premature to suggest that CC plays no role in modifier selection, it is likely that modifiers play a different role from nouns.", "labels": [], "entities": [{"text": "modifier selection", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7180513590574265}]}, {"text": "Previous work has shown that  restrictions on the plausibility of adjective-noun combinations exist (, and that using unlikely combinations (e.g. the immaculate kitchen rather than the spotless kitchen) impacts processing in online tasks.", "labels": [], "entities": []}, {"text": "Unlike types, which have a categorisation function, modifiers have the role of adding information about an element of a category.", "labels": [], "entities": []}, {"text": "This would partially explain the experimental results: When elements of a plurality have identical types (as in the modifier version of our experiment), the CC is already satisfied, and selection of modifiers would presumably depend on respecting adjective-noun combination restrictions.", "labels": [], "entities": [{"text": "CC", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.9541476964950562}]}, {"text": "Further research is required to verify this, although the algorithm presented below makes use of the Sketch Engine database to take modifier-noun combinations into account.", "labels": [], "entities": [{"text": "Sketch Engine database", "start_pos": 101, "end_pos": 123, "type": "DATASET", "confidence": 0.796310305595398}]}, {"text": "It has been known at least since that the best distinguishing description is not always the shortest one.", "labels": [], "entities": []}, {"text": "Yet, brevity plays apart in all GRE algorithms, sometimes in a strict form, or by letting the algorithm approximate the shortest description (for example, in the Dale and Reiter's IA).", "labels": [], "entities": []}, {"text": "This is also true of references to sets, the clearest example being Gardent's constraint based approach, which always finds the description with the smallest number of logical operators.", "labels": [], "entities": []}, {"text": "Such proposals do not take coherence (in our sense of the word) into account.", "labels": [], "entities": []}, {"text": "This raises obvious questions about the relative importance of brevity and coherence in reference to sets.", "labels": [], "entities": []}, {"text": "The evaluation took the form of an experiment to compare the output of our Coherence Model with the family of algorithms that have placed Brevity at the centre of content determination.", "labels": [], "entities": [{"text": "Brevity", "start_pos": 138, "end_pos": 145, "type": "METRIC", "confidence": 0.9602574110031128}]}, {"text": "Participants were asked to compare pairs of descriptions of one and the same target set, selecting the one they found most natural.", "labels": [], "entities": []}, {"text": "Each description could either be optimally brief or not (\u00b1b) and also either optimally coherent or not (\u00b1c).", "labels": [], "entities": []}, {"text": "Non-brief descriptions, took the form the A, the B and the C.", "labels": [], "entities": []}, {"text": "Brief descriptions 'aggregated' two disjuncts into one (e.g. the A and the D's where D comprises the union of B and C).", "labels": [], "entities": []}, {"text": "We expected to find that: H1 +c descriptions are preferred over \u2212c.", "labels": [], "entities": []}, {"text": "Confirmation of H1 would be interpreted as evidence that, by taking coherence into account, our Three old manuscripts were auctioned at Sotheby's.", "labels": [], "entities": [{"text": "Sotheby's", "start_pos": 136, "end_pos": 145, "type": "DATASET", "confidence": 0.9742626249790192}]}, {"text": "One of them is a book, a biography of a composer.", "labels": [], "entities": []}, {"text": "The second, a sailor's journal, was published in the form of a pamphlet.", "labels": [], "entities": []}, {"text": "It is a record of a voyage.", "labels": [], "entities": []}, {"text": "The third, another pamphlet, is an essay by Hume.", "labels": [], "entities": []}, {"text": "The biography, the journal and the essay were sold to a collector.", "labels": [], "entities": []}, {"text": "(+c, +b) The book and the pamphlets were sold to a collector.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Response proportions (%)", "labels": [], "entities": [{"text": "Response", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9914388656616211}]}]}