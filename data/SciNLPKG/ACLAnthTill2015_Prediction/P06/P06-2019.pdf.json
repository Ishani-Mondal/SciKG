{"title": [{"text": "Constraint-based Sentence Compression An Integer Programming Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "The ability to compress sentences while preserving their grammaticality and most of their meaning has recently received much attention.", "labels": [], "entities": []}, {"text": "Our work views sentence compression as an optimisation problem.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7537412047386169}]}, {"text": "We develop an integer programming formulation and infer globally optimal compressions in the face of linguistically motivated constraints.", "labels": [], "entities": []}, {"text": "We show that such a formulation allows for relatively simple and knowledge-lean compression models that do not require parallel corpora or large-scale resources.", "labels": [], "entities": []}, {"text": "The proposed approach yields results comparable and in some cases superior to state-of-the-art.", "labels": [], "entities": []}], "introductionContent": [{"text": "A mechanism for automatically compressing sentences while preserving their grammaticality and most important information would greatly benefit a wide range of applications.", "labels": [], "entities": []}, {"text": "Examples include text summarisation, subtitle generation from spoken transcripts) and information retrieval).", "labels": [], "entities": [{"text": "text summarisation", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7391777038574219}, {"text": "subtitle generation from spoken transcripts", "start_pos": 37, "end_pos": 80, "type": "TASK", "confidence": 0.840228283405304}, {"text": "information retrieval", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.818167507648468}]}, {"text": "Sentence compression is a complex paraphrasing task with information loss involving substitution, deletion, insertion, and reordering operations.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9381023347377777}]}, {"text": "Recent years have witnessed increased interest on a simpler instantiation of the compression problem, namely word deletion.", "labels": [], "entities": [{"text": "word deletion", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.7659949958324432}]}, {"text": "More formally, given an input sentence of words W = w 1 , w 2 , . .", "labels": [], "entities": []}, {"text": ", w n , a compression is formed by removing any subset of these words.", "labels": [], "entities": []}, {"text": "Sentence compression has received both generative and discriminative formulations in the literature.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9686077535152435}]}, {"text": "Generative approaches are instantiations of the noisy-channel model: given along sentence l, the aim is to find the corresponding short sentence s which maximises the conditional probability P(s|l).", "labels": [], "entities": []}, {"text": "Ina discriminative setting), sentences are represented by a rich feature space (typically induced from parse trees) and the goal is to learn rewrite rules indicating which words should be deleted in a given context.", "labels": [], "entities": []}, {"text": "Both modelling paradigms assume access to a training corpus consisting of original sentences and their compressions.", "labels": [], "entities": []}, {"text": "Unsupervised approaches to the compression problem are few and far between (see Hori and.", "labels": [], "entities": []}, {"text": "This is surprising considering that parallel corpora of original-compressed sentences are not naturally available in the way multilingual corpora are.", "labels": [], "entities": []}, {"text": "The scarcity of such data is demonstrated by the fact that most work to date has focused on a single parallel corpus, namely the Ziff-Davis corpus (.", "labels": [], "entities": []}, {"text": "And some effort into developing appropriate training data would be necessary when porting existing algorithms to new languages or domains.", "labels": [], "entities": []}, {"text": "In this paper we present an unsupervised model of sentence compression that does not rely on a parallel corpus -all that is required is a corpus of uncompressed sentences and a parser.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7451105564832687}]}, {"text": "Given along sentence, our task is to form a compression by preserving the words that maximise a scoring function.", "labels": [], "entities": []}, {"text": "In our case, the scoring function is an n-gram language model, \"with a few strings attached\".", "labels": [], "entities": []}, {"text": "While straightforward to estimate, a language model is a fairly primitive scoring function: it has no notion of the overall sentence structure, grammaticality or underlying meaning.", "labels": [], "entities": []}, {"text": "We thus couple our language model with a small number of structural and semantic constraints capturing global properties of the compression process.", "labels": [], "entities": []}, {"text": "We encode the language model and linguistic constraints as linear inequalities and use Integer Programming (IP) to infer compressions that are consistent with both.", "labels": [], "entities": []}, {"text": "The IP formulation allows us to capture global sentence properties and can be easily manipulated to provide compressions tailored for specific applications.", "labels": [], "entities": []}, {"text": "For example, we could prevent overly long or overly short compressions or generally avoid compressions that lack a main verb or consist of repetitions of the same word.", "labels": [], "entities": []}, {"text": "In the following section we provide an overview of previous approaches to sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.8256302773952484}]}, {"text": "In Section 3 we motivate the treatment of sentence compression as an optimisation problem and formulate our language model and constraints in the IP framework.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7230661064386368}]}, {"text": "Section 4 discusses our experimental set-up and Section 5 presents our results.", "labels": [], "entities": []}, {"text": "Discussion of future work concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the approach presented in the previous sections against Knight and Marcu's (2002) decision-tree model.", "labels": [], "entities": []}, {"text": "This model is a good basis for comparison as it operates on parse trees and therefore is aware of syntactic structure (as our models are) but requires a large parallel corpus for training whereas our models do not; and it yields comparable performance to the noisy-channel model.", "labels": [], "entities": []}, {"text": "The decision-tree model was compared against two variants of our IP model.", "labels": [], "entities": []}, {"text": "Both variants employed the constraints described in Section 3.2 but differed in that one variant included the significance score in its objective function (see), whereas the other one did not (see).", "labels": [], "entities": [{"text": "significance score", "start_pos": 110, "end_pos": 128, "type": "METRIC", "confidence": 0.9577023386955261}]}, {"text": "In both cases the sequential constraints from Section 3.1 were applied to ensure that the language model was wellformed.", "labels": [], "entities": []}, {"text": "We give details below on the corpora we used and explain how the different model parameters were estimated.", "labels": [], "entities": []}, {"text": "We also discuss how evaluation was carried out using human judgements.", "labels": [], "entities": [{"text": "evaluation", "start_pos": 20, "end_pos": 30, "type": "TASK", "confidence": 0.9701834917068481}]}, {"text": "As mentioned earlier, the output of our models is evaluated on 40 examples.", "labels": [], "entities": []}, {"text": "Although the size of our test set is comparable to previous studies (which are typically assessed on 32 sentences from the Ziff-Davis corpus), the sample is too small to conduct significance testing.", "labels": [], "entities": []}, {"text": "To counteract this, human judgements are often collected on compression output; however the evaluations are limited to small subject pools (often four judges;) which makes difficult to apply inferential statistics on the data.", "labels": [], "entities": []}, {"text": "We overcome this problem by conducting our evaluation using a larger sample of subjects.", "labels": [], "entities": []}, {"text": "Specifically, we elicited human judgements from 56 unpaid volunteers, all self reported native English speakers.", "labels": [], "entities": []}, {"text": "The elicitation study was conducted over the Internet.", "labels": [], "entities": []}, {"text": "Participants were presented with a set of instructions that explained the sentence compression task with examples.", "labels": [], "entities": [{"text": "sentence compression task", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7826339900493622}]}, {"text": "They were asked to judge 160 compressions in total.", "labels": [], "entities": []}, {"text": "These included the output of the three automatic systems on the 40 test sentences paired with their gold standard compressions.", "labels": [], "entities": []}, {"text": "Participants were asked to read the original sentence and then reveal its compression by pressing a button.", "labels": [], "entities": []}, {"text": "They were told that all compressions were generated automatically.", "labels": [], "entities": []}, {"text": "A Latin square design ensured that subjects did not see two different compressions of the same sentence.", "labels": [], "entities": []}, {"text": "The order of the sentences was randomised.", "labels": [], "entities": []}, {"text": "Participants rated each compression on a five point scale based on the information retained and its grammaticality.", "labels": [], "entities": []}, {"text": "Examples of our experimental items are given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Compression examples (O: original sen- tence, G: Gold standard, D: Decision-tree, LM: IP  language model, Sig: IP language model with sig- nificance score)", "labels": [], "entities": []}, {"text": " Table 3: Compression results; compression rate  (CompR) and average human judgements (Rat- ing);  *  : sig. diff. from gold standard;  \u2020 : sig. diff.  from LangModel+Significance", "labels": [], "entities": [{"text": "compression rate  (CompR)", "start_pos": 31, "end_pos": 56, "type": "METRIC", "confidence": 0.9378360033035278}, {"text": "average human judgements (Rat- ing)", "start_pos": 61, "end_pos": 96, "type": "METRIC", "confidence": 0.8415304273366928}]}]}