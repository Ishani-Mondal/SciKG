{"title": [{"text": "A Phrase-based Statistical Model for SMS Text Normalization", "labels": [], "entities": [{"text": "SMS Text Normalization", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.8055704832077026}]}], "abstractContent": [{"text": "Short Messaging Service (SMS) texts behave quite differently from normal written texts and have some very special phenomena.", "labels": [], "entities": [{"text": "Short Messaging Service (SMS) texts", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8000470783029284}]}, {"text": "To translate SMS texts, traditional approaches model such irregularities directly in Machine Translation (MT).", "labels": [], "entities": [{"text": "translate SMS texts", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.8717113931973776}, {"text": "Machine Translation (MT)", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.8387745976448059}]}, {"text": "However, such approaches suffer from customization problem as tremendous effort is required to adapt the language model of the existing translation system to handle SMS text style.", "labels": [], "entities": []}, {"text": "We offer an alternative approach to resolve such irregularities by normalizing SMS texts before MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.5733035206794739}]}, {"text": "In this paper, we view the task of SMS normalization as a translation problem from the SMS language to the English language and we propose to adapt a phrase-based statistical MT model for the task.", "labels": [], "entities": [{"text": "SMS normalization", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8740564584732056}, {"text": "MT", "start_pos": 175, "end_pos": 177, "type": "TASK", "confidence": 0.9000465273857117}]}, {"text": "Evaluation by 5-fold cross validation on a parallel SMS normalized corpus of 5000 sentences shows that our method can achieve 0.80702 in BLEU score against the baseline BLEU score 0.6958.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.9814010262489319}, {"text": "BLEU", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.992489218711853}]}, {"text": "Another experiment of translating SMS texts from English to Chinese on a separate SMS text corpus shows that, using SMS normalization as MT preprocessing can largely boost SMS translation performance from 0.1926 to 0.3770 in BLEU score.", "labels": [], "entities": [{"text": "SMS translation", "start_pos": 172, "end_pos": 187, "type": "TASK", "confidence": 0.7679509222507477}, {"text": "BLEU score", "start_pos": 225, "end_pos": 235, "type": "METRIC", "confidence": 0.978657454252243}]}], "introductionContent": [], "datasetContent": [{"text": "The aim of our experiment is to verify the effectiveness of the proposed statistical model for SMS normalization and the impact of SMS normalization on MT.", "labels": [], "entities": [{"text": "SMS normalization", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.8538199663162231}, {"text": "SMS normalization", "start_pos": 131, "end_pos": 148, "type": "TASK", "confidence": 0.6940861344337463}, {"text": "MT", "start_pos": 152, "end_pos": 154, "type": "TASK", "confidence": 0.9465387463569641}]}, {"text": "A set of 5000 parallel SMS messages, which consists of raw (un-normalized) SMS messages and reference messages manually prepared by two project members with inter-normalization agreement checked, was prepared for training and testing.", "labels": [], "entities": []}, {"text": "For evaluation, we use IBM's BLEU score () to measure the performance of the SMS normalization.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9753077924251556}, {"text": "SMS normalization", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.61332967877388}]}, {"text": "BLEU score measures the similarity between two sentences using n-gram statistics with a penalty for too short sentences, which is already widely-used in MT evaluation..", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9737468957901001}, {"text": "MT evaluation.", "start_pos": 153, "end_pos": 167, "type": "TASK", "confidence": 0.9150479137897491}]}, {"text": "Performance of different setups of the baseline experiments on the 5000 parallel SMS messages  The baseline experiment is to moderate the texts using a lingo dictionary comprises 142 normalization pairs, which is also used in bootstrapping the phrase alignment learning process.", "labels": [], "entities": [{"text": "phrase alignment learning", "start_pos": 244, "end_pos": 269, "type": "TASK", "confidence": 0.8594033519426981}]}, {"text": "compares the performance of the different setups of the baseline experiments.", "labels": [], "entities": []}, {"text": "We first measure the complexity of the SMS normalization task by directly computing the similarity between the raw SMS text and the normalized English text.", "labels": [], "entities": [{"text": "SMS normalization task", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8298483888308207}]}, {"text": "The 1 st row of reports the similarity as 0.5784 in BLEU score, which implies that there are quite a number of English word 3-gram that are common in the raw and normalized messages.", "labels": [], "entities": [{"text": "similarity", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9907664060592651}, {"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9832847714424133}]}, {"text": "The 2 nd experiment is carried out using only simple dictionary look-up.", "labels": [], "entities": []}, {"text": "Lexical ambiguity is addressed by selecting the highest-frequency normalization candidate, i.e., only unigram LM is used.", "labels": [], "entities": []}, {"text": "The performance of the 2 nd experiment is 0.6958 in BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.968524158000946}]}, {"text": "It suggests that the lingo dictionary plus the unigram LM is very useful for SMS normalization.", "labels": [], "entities": [{"text": "SMS normalization", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.9010659158229828}]}, {"text": "Finally we carryout the 3 rd experiment using dictionary look-up plus bi-gram LM.", "labels": [], "entities": []}, {"text": "Only a slight improvement of 0.0128 (0.7086-0.6958) is obtained.", "labels": [], "entities": []}, {"text": "This is largely because the English words in the lingo dictionary are mostly highfrequency and commonly-used.", "labels": [], "entities": []}, {"text": "Thus bi-gram does not show much more discriminative ability than unigram without the help of the phrasebased lexical mapping model.", "labels": [], "entities": []}, {"text": "Experimental result analysis reveals that the strength of our model is in its ability to disambiguate mapping as in \"2\" to \"two\" or \"to\" and \"w\" to \"with\" or \"who\".", "labels": [], "entities": []}, {"text": "Error analysis shows that the challenge of the model lies in the proper insertion of subject pronoun and auxiliary or copula verb, which serves to give further semantic information about the main verb, however this requires significant context understanding.", "labels": [], "entities": []}, {"text": "For example, a message such as \"u smart\" gives little clues on whether it should be normalized to \"Are you smart?\" or \"You are smart.\" unless the full conversation is studied.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Examples of SMS Messages", "labels": [], "entities": []}, {"text": " Table 2. Distribution of Insertion, Deletion and  Substitution Transformation.", "labels": [], "entities": [{"text": "Insertion", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.7388389110565186}, {"text": "Substitution Transformation", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6459763795137405}]}, {"text": " Table 6. Normalization results for 5- fold cross validation test", "labels": [], "entities": []}, {"text": " Table 8. SMS Translation BLEU score with or  without SMS normalization", "labels": [], "entities": [{"text": "SMS Translation", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.749299943447113}, {"text": "BLEU score", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9581072330474854}]}]}