{"title": [{"text": "A Rote Extractor with Edit Distance-based Generalisation and Multi-corpora Precision Calculation", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe a rote extrac-tor that learns patterns for finding semantic relationships in unrestricted text, with new procedures for pattern generalization and scoring.", "labels": [], "entities": []}, {"text": "These include the use of part-of-speech tags to guide the generalization, Named Entity categories inside the patterns , an edit-distance-based pattern generalization algorithm, and a pattern accuracy calculation procedure based on evaluating the patterns on several test corpora.", "labels": [], "entities": [{"text": "edit-distance-based pattern generalization", "start_pos": 123, "end_pos": 165, "type": "TASK", "confidence": 0.603113075097402}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9209033250808716}]}, {"text": "In an evaluation with 14 entities, the system attains a precision higher than 50% for half of the relationships considered.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9992660880088806}]}], "introductionContent": [{"text": "Recently, there is an increasing interest in automatically extracting structured information from large corpora and, in particular, from the Web ().", "labels": [], "entities": [{"text": "automatically extracting structured information from large corpora", "start_pos": 45, "end_pos": 111, "type": "TASK", "confidence": 0.7535830778735024}]}, {"text": "Because of the difficulty of collecting annotated data, several procedures have been described that can be trained on unannotated textual corpora ().", "labels": [], "entities": []}, {"text": "An interesting approach is that of rote extractors), which look for textual contexts that happen to convey a certain relationship between two concepts.", "labels": [], "entities": []}, {"text": "In this paper, we describe some contributions to the training of Rote extractors, including a procedure for generalizing the patterns, and a more complex way of calculating their accuracy.", "labels": [], "entities": [{"text": "Rote extractors", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.8743700981140137}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9950801134109497}]}, {"text": "We first introduce the general structure of a rote extractor and its limitations.", "labels": [], "entities": []}, {"text": "Next, we describe the proposed modifications (Sections 2, 3 and 4) and the evaluation performed (Section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "The procedure has been tested with 10 different relationships.", "labels": [], "entities": []}, {"text": "For each pair in each seed list, a corpus with 500 documents has been collected using Google, from which the patterns are extracted.", "labels": [], "entities": []}, {"text": "shows the number of patterns obtained.", "labels": [], "entities": []}, {"text": "It is interesting to see that for some relations, such as birth-year or birth-place, more than one thousand patterns have been reduced to a few.", "labels": [], "entities": []}, {"text": "shows the patterns obtained for the relationship birthyear.", "labels": [], "entities": []}, {"text": "It can also be seen that some of the patterns with good precision contain the wildcard *, which helped extract the correct birth year in roughly 50 occasions.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9985226988792419}, {"text": "wildcard *", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.8802631199359894}]}, {"text": "Specially of interest is the last pattern, which resulted in an accuracy of 0.29 with the pro-: Precision, inclusion precision and number of times that a pattern extracted information, when applied to a test corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9994688630104065}, {"text": "Precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9787716269493103}, {"text": "inclusion precision", "start_pos": 107, "end_pos": 126, "type": "METRIC", "confidence": 0.8499184548854828}]}, {"text": "cedure here indicated, but which would have obtained an accuracy of 0.54 using the traditional hook corpus approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9992295503616333}]}, {"text": "This is because in other test corpora (e.g. in the one containing soccer players and clubs) it is more frequent to find the name of a person followed by a number that is not his/her birth year, while that did not happen so often in the birth year test corpus.", "labels": [], "entities": []}, {"text": "For evaluating the patterns, anew test corpus has been collected for fourteen entities not present in the training corpora, again using Google.", "labels": [], "entities": []}, {"text": "The chosen entities are Robert de Niro and Natalie Wood (actors), Isaac Asimov and Alfred Bester (writers), Montevideo and Yaounde (capitals), Gloria Macapagal Arroyo and Hosni Mubarak (country presidents), Bernardo Bertolucci and Federico Fellini (directors), Peter Paul Rubens and Paul Gauguin (painters), and Jens Lehmann and Thierry Henry (soccer players).", "labels": [], "entities": []}, {"text": "shows the results obtained for each relationship.", "labels": [], "entities": []}, {"text": "We have observed that, for those relationships in which the target does not belong to a Named Entity type, it is common for the patterns to extract additional words together with the right target.", "labels": [], "entities": []}, {"text": "For example, rather than extracting The Last Emperor, the patterns may extract this title together with its rating or its length, the title between quotes, or phrases such as The classic The Last Emperor.", "labels": [], "entities": [{"text": "The Last Emperor", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.685806671778361}, {"text": "length", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9841825366020203}]}, {"text": "In the second column in the table, we measured the percentage of times that a correct answer appears inside the extracted target, so these examples would be considered correct.", "labels": [], "entities": []}, {"text": "We call this metric inclusion precision.", "labels": [], "entities": [{"text": "metric inclusion precision", "start_pos": 13, "end_pos": 39, "type": "METRIC", "confidence": 0.6067003607749939}]}], "tableCaptions": [{"text": " Table 4: Precision, inclusion precision and num- ber of times that a pattern extracted information,  when applied to a test corpus.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9989867806434631}, {"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.5709919333457947}, {"text": "num- ber", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.964456836382548}]}, {"text": " Table 5. As  can be seen, our procedure seems to perform bet- ter for all of the relations except birth place. It  is interesting to note that, as could be expected,  for those targets for which there is no entity type  defined (films, books and pictures),", "labels": [], "entities": []}]}