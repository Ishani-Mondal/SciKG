{"title": [{"text": "Semantic Taxonomy Induction from Heterogenous Evidence", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel algorithm for inducing semantic taxonomies.", "labels": [], "entities": []}, {"text": "Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.9153509140014648}]}, {"text": "By contrast, our algorithm flexibly incorporates evidence from multiple clas-sifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word's coordinate terms to help in determining its hypernyms, and vice versa.", "labels": [], "entities": []}, {"text": "We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term clas-sifiers with the knowledge in a preexisting semantic taxonomy (WordNet 2.1).", "labels": [], "entities": [{"text": "noun hyponym acquisition", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.622336357831955}]}, {"text": "We add 10, 000 novel synsets to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a non-joint algorithm using the same component classifiers.", "labels": [], "entities": [{"text": "WordNet 2.1", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.9230608642101288}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9982703924179077}]}, {"text": "Finally , we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hy-pernym pairs.", "labels": [], "entities": [{"text": "F-score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.99885094165802}]}], "introductionContent": [{"text": "The goal of capturing structured relational knowledge about lexical terms has been the motivating force underlying many projects in lexical acquisition, information extraction, and the construction of semantic taxonomies.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.798987090587616}, {"text": "information extraction", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.8353323638439178}]}, {"text": "Broad-coverage semantic taxonomies such as WordNet and CYC have been constructed by hand at great cost; while a crucial source of knowledge about the relations between words, these taxonomies still suffer from sparse coverage.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9489817023277283}]}, {"text": "Many algorithms with the potential for automatically extending lexical resources have been proposed, including work in lexical acquisition ( and in discovering instances, named entities, and alternate glosses ().", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7314004600048065}]}, {"text": "Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hyponyms, meronyms, synonyms (, a variety of verb relations (, and general purpose analogy relations (.", "labels": [], "entities": []}, {"text": "Such classifiers use hand-written or automaticallyinduced patterns like Such NP y as NP xor NP y like NP x to determine, for example that NP y is a hyponym of NP x (i.e., NP y IS-A NP x ).", "labels": [], "entities": []}, {"text": "While such classifiers have achieved some degree of success, they frequently lack the global knowledge necessary to integrate their predictions into a complex taxonomy with multiple relations.", "labels": [], "entities": []}, {"text": "Past work on semantic taxonomy induction includes the noun hypernym hierarchy created in), the part-whole taxonomies in, and a great deal of recent work described in).", "labels": [], "entities": [{"text": "semantic taxonomy induction", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.7172527511914571}]}, {"text": "Such work has typically either focused on only inferring small taxonomies over a single relation, or as in), has used evidence for multiple relations independently from one another, by for example first focusing strictly on inferring clusters of coordinate terms, and then by inferring hypernyms over those clusters.", "labels": [], "entities": []}, {"text": "Another major shortfall in previous techniques for taxonomy induction has been the inability to handle lexical ambiguity.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9068070352077484}]}, {"text": "Previous approaches have typically sidestepped the issue of polysemy altogether by making the assumption of only a single sense per word, and inferring taxonomies explicitly over words and not senses.", "labels": [], "entities": []}, {"text": "Enforcing a false monosemy has the downside of making potentially erroneous inferences; for example, collapsing the polysemous term Bush into a single sense might lead one to infer by transitivity that arose bush is a kind of U.S. president.", "labels": [], "entities": []}, {"text": "Our approach simultaneously provides a solution to the problems of jointly considering evidence about multiple relationships as well as lexical ambiguity within a single probabilistic framework.", "labels": [], "entities": []}, {"text": "The key contribution of this work is to offer a solution to two crucial problems in taxonomy in-duction and hyponym acquisition: the problem of combining heterogenous sources of evidence in a flexible way, and the problem of correctly identifying the appropriate word sense of each new word added to the taxonomy.", "labels": [], "entities": [{"text": "hyponym acquisition", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7089268416166306}]}], "datasetContent": [{"text": "In order to evaluate our framework for taxonomy induction, we have applied hyponym acquisition to construct several distinct taxonomies, starting with the base of WordNet 2.1 and only adding novel noun hyponyms.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.9007227718830109}, {"text": "hyponym acquisition", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7514797747135162}]}, {"text": "Further, we have constructed taxonomies using a baseline algorithm, which uses the identical hypernym and coordinate classifiers used in our joint algorithm, but which does not combine the evidence of the classifiers.", "labels": [], "entities": []}, {"text": "In section 4.1 we describe our evaluation methodology; in sections 4.2 and 4.3 we analyze the fine-grained precision and disambiguation precision of our algorithm compared to the baseline; in section 4.4 we compare the coarse-grained precision of our links (motivated by categories defined by the WordNet supersenses) against the baseline algorithm and against an \"oracle\" for named entity recognition.", "labels": [], "entities": [{"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.6810272336006165}, {"text": "named entity recognition", "start_pos": 377, "end_pos": 401, "type": "TASK", "confidence": 0.6156173845132192}]}, {"text": "Finally, in section 4.5 we evaluate the taxonomies inferred by our algorithm directly against the WordNet 2.1 taxonomy; we perform this evaluation by testing each taxonomy on a set of human judgments of hypernym and non-hypernym noun pairs sampled from newswire text.", "labels": [], "entities": [{"text": "WordNet 2.1 taxonomy", "start_pos": 98, "end_pos": 118, "type": "DATASET", "confidence": 0.9307283560434977}]}, {"text": "We compute coarse-grained precision as (c 1 + c 3 )/total.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.8490138053894043}]}, {"text": "Inferring the correct coarse-grained supersense of a novel hyponym can be viewed as a fine-grained (26-category) Named Entity Recognition task; our algorithm for taxonomy induction can thus be viewed as performing high-accuracy fine-grained NER.", "labels": [], "entities": [{"text": "Named Entity Recognition task", "start_pos": 113, "end_pos": 142, "type": "TASK", "confidence": 0.7176176160573959}, {"text": "taxonomy induction", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.8599251806735992}]}, {"text": "Here we compare against both the baseline non-joint algorithm as well as an \"oracle\" algorithm for Named Entity Recognition, which perfectly classifies the supersense of all nouns that fall under the four supersenses {person, group, location, quantity}, but works only for those supersenses.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.6555367410182953}]}, {"text": "shows the results of this coarse-grained evaluation.", "labels": [], "entities": []}, {"text": "We see that the baseline non-joint algorithm has higher precision than the NER oracle as 10,000 and 20,000 links; however, both are significantly outperformed by our joint algorithm, which maintains high coarse-grained precision (92%) even at 20,000 links.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9963399171829224}, {"text": "NER oracle", "start_pos": 75, "end_pos": 85, "type": "DATASET", "confidence": 0.9007799327373505}, {"text": "precision", "start_pos": 219, "end_pos": 228, "type": "METRIC", "confidence": 0.6991999745368958}]}], "tableCaptions": [{"text": " Table 2: Fine-grained and disambiguation preci- sion and error reduction for hyponym acquisition", "labels": [], "entities": [{"text": "Fine-grained", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9588314294815063}]}, {"text": " Table 3: Coarse-grained precision and error reduc- tion vs. Non-joint baseline and NER Oracle", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9777193069458008}]}, {"text": " Table 4: Taxonomy hypernym classification vs.  WordNet 2.1 on hand-labeled testset", "labels": [], "entities": [{"text": "Taxonomy hypernym classification", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.7422904968261719}]}]}