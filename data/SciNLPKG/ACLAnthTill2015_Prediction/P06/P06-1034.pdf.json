{"title": [{"text": "Learning to Generate Naturalistic Utterances Using Reviews in Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Learning to Generate Naturalistic Utterances", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.5610813975334168}]}], "abstractContent": [{"text": "Spoken language generation for dialogue systems requires a dictionary of mappings between semantic representations of concepts the system wants to express and re-alizations of those concepts.", "labels": [], "entities": [{"text": "Spoken language generation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7810479005177816}]}, {"text": "Dictionary creation is a costly process; it is currently done by hand for each dialogue domain.", "labels": [], "entities": [{"text": "Dictionary creation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7517286837100983}]}, {"text": "We propose a novel unsupervised method for learning such mappings from user reviews in the target domain, and test it on restaurant reviews.", "labels": [], "entities": []}, {"text": "We test the hypothesis that user reviews that provide individual ratings for distinguished attributes of the domain entity make it possible to map review sentences to their semantic representation with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 207, "end_pos": 216, "type": "METRIC", "confidence": 0.9841122031211853}]}, {"text": "Experimental analyses show that the mappings learned cover most of the domain ontology, and provide good linguistic variation.", "labels": [], "entities": []}, {"text": "A subjective user evaluation shows that the consistency between the semantic representations and the learned realizations is high and that the naturalness of the realizations is higher than a hand-crafted baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "One obstacle to the widespread deployment of spoken dialogue systems is the cost involved with hand-crafting the spoken language generation module.", "labels": [], "entities": [{"text": "spoken language generation", "start_pos": 113, "end_pos": 139, "type": "TASK", "confidence": 0.6580588817596436}]}, {"text": "Spoken language generation requires a dictionary of mappings between semantic representations of concepts the system wants to express and realizations of those concepts.", "labels": [], "entities": [{"text": "Spoken language generation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7384495933850607}]}, {"text": "Dictionary creation is a costly process: an automatic method for creating them would make dialogue technology more scalable.", "labels": [], "entities": [{"text": "Dictionary creation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7305918037891388}]}, {"text": "A secondary benefit is that a learned dictionary may produce more natural and colloquial utterances.", "labels": [], "entities": []}, {"text": "We propose a novel method for mining user reviews to automatically acquire a domain specific generation dictionary for information presentation in a dialogue system.", "labels": [], "entities": [{"text": "information presentation", "start_pos": 119, "end_pos": 143, "type": "TASK", "confidence": 0.7156219184398651}]}, {"text": "Our hypothesis is that reviews that provide individual ratings for various distinguished attributes of review entities can be used to map review sentences to a semantic rep-  resentation.", "labels": [], "entities": []}, {"text": "shows a user review in the restaurant domain, where we hypothesize that the user rating food=5 indicates that the semantic representation for the sentence \"The best Spanish food in New York\" includes the relation 'RESTAU-RANT has foodquality=5.", "labels": [], "entities": [{"text": "RESTAU-RANT", "start_pos": 214, "end_pos": 225, "type": "METRIC", "confidence": 0.9445658326148987}]}, {"text": "We apply the method to extract 451 mappings from restaurant reviews.", "labels": [], "entities": []}, {"text": "Experimental analyses show that the mappings learned cover most of the domain ontology, and provide good linguistic variation.", "labels": [], "entities": []}, {"text": "A subjective user evaluation indicates that the consistency between the semantic representations and the learned realizations is high and that the naturalness of the realizations is significantly higher than a hand-crafted baseline.", "labels": [], "entities": []}, {"text": "Section 2 provides a step-by-step description of the method.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 present the evaluation results.", "labels": [], "entities": []}, {"text": "Section 5 covers related work.", "labels": [], "entities": []}, {"text": "Section 6 summarizes and discusses future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the obtained mappings in two respects: the consistency between the automatically derived semantic representation and the realizafood=1 awful, bad, burnt, cold, very ordinary food=2 acceptable, bad, flavored, not enough, very bland, very good food=3 adequate, bland and mediocre, flavorful but cold, pretty good, rather bland, very good food=4 absolutely wonderful, awesome, decent, excellent, good, good and generous, great, outstanding, rather good, really good, traditional, very fresh and tasty, very good, very very good food=5 absolutely delicious, absolutely fantastic, absolutely great, absolutely terrific, ample, well seasoned and hot, awesome, best, delectable and plentiful, delicious, delicious but simple, excellent, exquisite, fabulous, fancy but tasty, fantastic, fresh, good, great, hot, incredible, just fantastic, large and satisfying, outstanding, plentiful and outstanding, plentiful and tasty, quick and hot, simply great, so delicious, so very tasty, superb, terrific, tremendous, very good, wonderful tion, and the naturalness of the realization.", "labels": [], "entities": []}, {"text": "For comparison, we used a baseline of handcrafted mappings from () except that we changed the word decor to atmosphere and added five mappings for overall.", "labels": [], "entities": []}, {"text": "For scalar relations, this consists of the realization \"RESTAURANT has ADJ LEX\" where ADJ is mediocre, decent, good, very good, or excellent for rating values 1-5, and LEX is food quality, service, atmosphere, value, or overall depending on the relation.", "labels": [], "entities": [{"text": "RESTAURANT", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9771229028701782}, {"text": "ADJ LEX", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.7687228322029114}, {"text": "ADJ", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.8735394477844238}, {"text": "LEX", "start_pos": 168, "end_pos": 171, "type": "METRIC", "confidence": 0.9883147478103638}]}, {"text": "RESTAURANT is filled with the name of a restaurant at runtime.", "labels": [], "entities": [{"text": "RESTAURANT", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.7925468683242798}]}, {"text": "For example, 'RESTAU-RANT has foodquality=1' is realized as \"RESTAU-RANT has mediocre food quality.", "labels": [], "entities": []}, {"text": "\" The location and food type relations are mapped to \"RESTAU-RANT is located in and \"RESTAU-RANT is a FOODTYPE restaurant.", "labels": [], "entities": [{"text": "RESTAU-RANT", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.8203396797180176}, {"text": "RESTAU-RANT", "start_pos": 85, "end_pos": 96, "type": "METRIC", "confidence": 0.693801999092102}, {"text": "FOODTYPE", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9556893110275269}]}, {"text": "\" The learned mappings include 23 distinct semantic representations fora single-relation (22 for scalar-valued relations and one for location) and 50 for multi-relations.", "labels": [], "entities": []}, {"text": "Therefore, using the handcrafted mappings, we first created 23 utterances for the single-relations.", "labels": [], "entities": []}, {"text": "We then created three utterances for each of 50 multi-relations using different clause-combining operations from (.", "labels": [], "entities": []}, {"text": "This gave a total of 173 baseline utterances, which together with 451 learned mappings, service=1 awful, bad, great, horrendous, horrible, inattentive, forgetful and slow, marginal, really slow, silly and inattentive, still marginal, terrible, young service=2 overly slow, very slow and inattentive service=3 bad, bland and mediocre, friendly and knowledgeable, good, pleasant, prompt, very friendly service=4 all very warm and welcoming, attentive, extremely friendly and good, extremely pleasant, fantastic, friendly, friendly and helpful, good, great, great and courteous, prompt and friendly, really friendly, so nice, swift and friendly, very friendly, very friendly and accommodating service=5 all courteous, excellent, excellent and friendly, extremely friendly, fabulous, fantastic, friendly, friendly and helpful, friendly and very attentive, good, great, great, prompt and courteous, happy and friendly, impeccable, intrusive, legendary, outstanding, pleasant, polite, attentive and prompt, prompt and courteous, prompt and pleasant, quick and cheerful, stupendous, superb, the most attentive, unbelievable, very attentive, very congenial, very courteous, very friendly, very friendly and helpful, very friendly and pleasant, very friendly and totally personal, very friendly and welcoming, very good, very helpful, very timely, warm and friendly, wonderful yielded 624 utterances for evaluation.", "labels": [], "entities": []}, {"text": "Ten subjects, all native English speakers, evaluated the mappings by reading them from a webpage.", "labels": [], "entities": []}, {"text": "For each system utterance, the subjects were asked to express their degree of agreement, on a scale of 1 (lowest) to 5 (highest), with the statement (a) The meaning of the utterance is consistent with the ratings expressing their semantics, and with the statement (b) The style of the utterance is very natural and colloquial.", "labels": [], "entities": []}, {"text": "They were asked not to correct their decisions and also to rate each utterance on its own merit.", "labels": [], "entities": []}, {"text": "shows the means and standard deviations of the scores for baseline vs. learned utterances for consistency and naturalness.", "labels": [], "entities": [{"text": "consistency", "start_pos": 94, "end_pos": 105, "type": "METRIC", "confidence": 0.9883592128753662}]}, {"text": "A t-test shows that the consistency of the learned expression is significantly lower than the baseline (df=4712, p < .001) but that their naturalness is significantly higher than the baseline (df=3107, p < .001).", "labels": [], "entities": [{"text": "consistency", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.9928323030471802}]}, {"text": "However, consistency is still high.", "labels": [], "entities": [{"text": "consistency", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.9984398484230042}]}, {"text": "Only 14 of the learned utterances (shown in Tab. 10) have a mean consistency score lower than 3, which indicates that, by and large, the human judges felt that the inferred semantic representations were consistent with the meaning of the learned expressions.", "labels": [], "entities": [{"text": "consistency score", "start_pos": 65, "end_pos": 82, "type": "METRIC", "confidence": 0.9172447919845581}]}, {"text": "The correlation coefficient between consistency and naturalness scores is 0.42, which indicates that consisOriginal SPaRKy utterances \u2022 Babbo has the best overall quality among the selected restaurants with excellent decor, excellent service and superb food quality.", "labels": [], "entities": [{"text": "consistency", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.9968838095664978}]}], "tableCaptions": [{"text": " Table 2: Filtering statistics: the number of sen- tences filtered and retained by each filter.", "labels": [], "entities": []}, {"text": " Table 3: Domain coverage of single scalar-valued  relation mappings.", "labels": [], "entities": []}, {"text": " Table 4: Counts for multi-relation mappings.", "labels": [], "entities": []}, {"text": " Table 5: Common syntactic patterns of DSyntSs, flattened to a POS sequence for readability. NN, VB,  JJ, RB, CC stand for noun, verb, adjective, adverb, and conjunction, respectively.", "labels": [], "entities": []}, {"text": " Table 9: Consistency and naturalness scores aver- aged over 10 subjects.", "labels": [], "entities": []}]}