{"title": [{"text": "Noun Phrase Chunking in Hebrew Influence of Lexical and Morphological Features", "labels": [], "entities": [{"text": "Noun Phrase Chunking", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.518982470035553}]}], "abstractContent": [{"text": "We present a method for Noun Phrase chunking in Hebrew.", "labels": [], "entities": [{"text": "Noun Phrase chunking", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7700729767481486}]}, {"text": "We show that the traditional definition of base-NPs as non-recursive noun phrases does not apply in Hebrew, and propose an alternative definition of Simple NPs.", "labels": [], "entities": []}, {"text": "We review syntactic properties of Hebrew related to noun phrases, which indicate that the task of Hebrew SimpleNP chunking is harder than base-NP chunking in English.", "labels": [], "entities": [{"text": "SimpleNP chunking", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7190616726875305}]}, {"text": "As a confirmation, we apply methods known to work well for English to Hebrew data.", "labels": [], "entities": []}, {"text": "These methods give low results (F from 76 to 86) in Hebrew.", "labels": [], "entities": [{"text": "F", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9963296055793762}]}, {"text": "We then discuss our method, which applies SVM induction over lexical and morphological features.", "labels": [], "entities": [{"text": "SVM induction", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.8776441216468811}]}, {"text": "Morphological features improve the average precision by ~0.5%, recall by ~1%, and F-measure by ~0.75, resulting in a system with average performance of 93% precision, 93.4% recall and 93.2 F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9674072861671448}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9995558857917786}, {"text": "F-measure", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.998898983001709}, {"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9970775842666626}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9989216327667236}, {"text": "F-measure", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.982088029384613}]}], "introductionContent": [{"text": "Modern Hebrew is an agglutinative Semitic language, with rich morphology.", "labels": [], "entities": []}, {"text": "Like most other non-European languages, it lacks NLP resources and tools, and specifically there are currently no available syntactic parsers for Hebrew.", "labels": [], "entities": []}, {"text": "We address the task of NP chunking in Hebrew as a * This work was funded by the Israel Ministry of Science and Technology under the auspices of the Knowledge Center for Processing Hebrew.", "labels": [], "entities": [{"text": "NP chunking", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9411524534225464}]}, {"text": "Additional funding was provided by the Lynn and William Frankel Center for Computer Sciences.", "labels": [], "entities": []}, {"text": "first step to fulfill the need for such tools.", "labels": [], "entities": []}, {"text": "We also illustrate how this task can successfully be approached with little resource requirements, and indicate how the method is applicable to other resource-scarce languages.", "labels": [], "entities": []}, {"text": "NP chunking is the task of labelling noun phrases in natural language text.", "labels": [], "entities": [{"text": "NP chunking", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7478056252002716}, {"text": "labelling noun phrases in natural language text", "start_pos": 27, "end_pos": 74, "type": "TASK", "confidence": 0.8149098924228123}]}, {"text": "The input to this task is free text with part-of-speech tags.", "labels": [], "entities": []}, {"text": "The output is the same text with brackets around base noun phrases.", "labels": [], "entities": []}, {"text": "A base noun phrase is an NP which does not contain another NP (it is not recursive).", "labels": [], "entities": []}, {"text": "NP chunking is the basis for many other NLP tasks such as shallow parsing, argument structure identification, and information extraction We first realize that the definition of base-NPs must be adapted to the case of Hebrew (and probably other Semitic languages as well) to correctly handle its syntactic nature.", "labels": [], "entities": [{"text": "NP chunking", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8083953261375427}, {"text": "shallow parsing", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.6593329906463623}, {"text": "argument structure identification", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.680078387260437}, {"text": "information extraction", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.8282175362110138}]}, {"text": "We propose such a definition, which we call simple NPs and assess the difficulty of chunking such NPs by applying methods that perform well in English to Hebrew data.", "labels": [], "entities": []}, {"text": "While the syntactic problem in Hebrew is indeed more difficult than in English, morphological clues do provide additional hints, which we exploit using an SVM learning method.", "labels": [], "entities": []}, {"text": "The resulting method reaches performance in Hebrew comparable to the best results published in English.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all the SVM chunking experiments, we use the YamCha 8 toolkit (.", "labels": [], "entities": [{"text": "SVM chunking", "start_pos": 12, "end_pos": 24, "type": "TASK", "confidence": 0.9014072120189667}, {"text": "YamCha 8 toolkit", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.8322485089302063}]}, {"text": "We use forward moving tagging, using standard SVM with polynomial kernel of degree 2, and C=1.", "labels": [], "entities": [{"text": "forward moving tagging", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.6355888644854227}]}, {"text": "For the multiclass classification, we use pairwise voting.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.8104181587696075}]}, {"text": "For all the reported experiments, we chose the context to be a -2/+2 tokens windows, centered at the current token.", "labels": [], "entities": []}, {"text": "We use the standard metrics of accuracy (% of correctly tagged tokens), precision, recall and Fmeasure, with the only exception of normalizing all punctuation tokens from the data prior to evaluation, as the TreeBank is highly inconsistent regarding the bracketing of punctuations, and we don't consider the exclusions/inclusions of punctuations from our chunks to be errors (i.e., \" [an apple]\" \"[a book] , [an apple]\" and \"[a book] [, an apple]\" are all equivalent chunkings in our view).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9989281296730042}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9996500015258789}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9996750354766846}, {"text": "Fmeasure", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9996737241744995}]}, {"text": "All our development work was done with the first 500 sentences allocated for testing, and the rest for training.", "labels": [], "entities": []}, {"text": "For evaluation, we used a 10-fold cross-validation scheme, each time with different consecutive 500 sentences serving for testing and the rest for training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Size of Hebrew and English NPs", "labels": [], "entities": [{"text": "Size of Hebrew and English NPs", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.780662347873052}]}, {"text": " Table 3. Baseline results for Simple NP chunking  SVM Chunking in Hebrew", "labels": [], "entities": [{"text": "NP chunking  SVM Chunking", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.815926656126976}]}, {"text": " Table 4. SVM results for Hebrew", "labels": [], "entities": []}, {"text": " Table 5. Improvement over WP", "labels": [], "entities": [{"text": "Improvement", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9924403429031372}, {"text": "WP", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.44705361127853394}]}]}