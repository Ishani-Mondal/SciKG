{"title": [{"text": "You Can't Beat Frequency (Unless You Use Linguistic Knowledge) - A Qualitative Evaluation of Association Measures for Collocation and Term Extraction", "labels": [], "entities": [{"text": "Collocation and Term Extraction", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.6591056883335114}]}], "abstractContent": [{"text": "In the past years, a number of lexical association measures have been studied to help extract new scientific terminology or general-language collocations.", "labels": [], "entities": []}, {"text": "The implicit assumption of this research was that newly designed term measures involving more sophisticated statistical criteria would outperform simple counts of co-occurrence frequencies.", "labels": [], "entities": []}, {"text": "We here explicitly test this assumption.", "labels": [], "entities": []}, {"text": "By way of four qualitative criteria, we show that purely statistics-based measures reveal virtually no difference compared with frequency of occurrence counts, while linguistically more informed metrics do reveal such a marked difference.", "labels": [], "entities": []}], "introductionContent": [{"text": "Research on domain-specific automatic term recognition (ATR) and on general-language collocation extraction (CE) has gone mostly separate ways in the last decade although their underlying procedures and goals turnout to be rather similar.", "labels": [], "entities": [{"text": "domain-specific automatic term recognition (ATR)", "start_pos": 12, "end_pos": 60, "type": "TASK", "confidence": 0.7462478024618966}, {"text": "general-language collocation extraction (CE)", "start_pos": 68, "end_pos": 112, "type": "TASK", "confidence": 0.8003248473008474}]}, {"text": "In both cases, linguistic filters (POS taggers, phrase chunkers, (shallow) parsers) initially collect candidates from large text corpora and then frequency-or statistics-based evidence or association measures yield scores indicating to what degree a candidate qualifies as a term or a collocation.", "labels": [], "entities": [{"text": "POS taggers, phrase chunkers", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.6942287504673004}]}, {"text": "While term mining and collocation mining, as a whole, involve almost the same analytical processing steps, such as orthographic and morphological normalization, normalization of term or collocation variation etc., it is exactly the measure which grades termhood or collocativity of a candidate on which alternative approaches diverge.", "labels": [], "entities": [{"text": "term mining", "start_pos": 6, "end_pos": 17, "type": "TASK", "confidence": 0.7594463527202606}, {"text": "collocation mining", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7576259076595306}]}, {"text": "Still, the output of such mining algorithms look similar.", "labels": [], "entities": []}, {"text": "It is typically constituted by a ranked list on which, ideally, the true terms or collocations are placed in the top portion of the list, while the non-terms / non-collocations occur in its bottom portion.", "labels": [], "entities": []}, {"text": "While there have been lots of approaches to come up with a fully adequate ATR/CE metric (cf. Section 2), we have made observations in our experiments that seem to indicate that simplicity rules, i.e., frequency of occurrence is the dominating factor for the ranking in the result lists even when much smarter statistical machinery is employed.", "labels": [], "entities": [{"text": "ATR/CE metric", "start_pos": 74, "end_pos": 87, "type": "METRIC", "confidence": 0.8081745803356171}, {"text": "simplicity", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.9815836548805237}]}, {"text": "In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference -for the problem of term and collocation mining at least.", "labels": [], "entities": [{"text": "term and collocation mining", "start_pos": 265, "end_pos": 292, "type": "TASK", "confidence": 0.5978162065148354}]}], "datasetContent": [{"text": "In order to determine any potential merit of the above measures, we use the four criteria described in Section 3.1 and qualitatively compare the different rankings given to true positives and true negatives by an AM and by Frequency.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 223, "end_pos": 232, "type": "METRIC", "confidence": 0.9889161586761475}]}, {"text": "For this purpose, we chose the middle rank as a mark to divide a ranked output list into an upper portion and a lower portion.", "labels": [], "entities": []}, {"text": "Then we looked at the true positives (TPs) and true negatives (TNs) assigned to these portions by Frequency and quantified, according to the criteria postulated in Section 3.1, to what degree the other AMs changed these rankings (or not).", "labels": [], "entities": [{"text": "true negatives (TNs)", "start_pos": 47, "end_pos": 67, "type": "METRIC", "confidence": 0.7166500806808471}, {"text": "Frequency", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.8423288464546204}]}, {"text": "In order to better quantify the degrees of movement, we partitioned both the upper and the lower portions into three further subportions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data sets for Collocation Extraction (CE) and Au-", "labels": [], "entities": [{"text": "Collocation Extraction (CE)", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.8308077692985535}, {"text": "Au-", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.5593537837266922}]}, {"text": " Table 2: Results on the four qualitative criteria for Collocation Extraction (CE)", "labels": [], "entities": [{"text": "Collocation Extraction (CE)", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.9115302085876464}]}, {"text": " Table 3: Results on the four qualitative criteria for Automatic Term Discovery (ATR)", "labels": [], "entities": [{"text": "Automatic Term Discovery (ATR)", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.8122937579949697}]}]}