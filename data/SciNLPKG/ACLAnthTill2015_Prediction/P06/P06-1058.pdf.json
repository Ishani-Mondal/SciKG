{"title": [{"text": "An Equivalent Pseudoword Solution to Chinese Word Sense Disambiguation", "labels": [], "entities": [{"text": "Chinese Word Sense Disambiguation", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.6320707872509956}]}], "abstractContent": [{"text": "This paper presents anew approach based on Equivalent Pseudowords (EPs) to tackle Word Sense Disambiguation (WSD) in Chinese language.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.7668022116025289}]}, {"text": "EPs are particular artificial ambiguous words, which can be used to realize unsupervised WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.594664454460144}]}, {"text": "A Bayesian classifier is implemented to test the efficacy of the EP solution on Senseval-3 Chinese test set.", "labels": [], "entities": [{"text": "Senseval-3 Chinese test set", "start_pos": 80, "end_pos": 107, "type": "DATASET", "confidence": 0.963362067937851}]}, {"text": "The performance is better than state-of-the-art results with an average F-measure of 0.80.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9994179010391235}]}, {"text": "The experiment verifies the value of EP for unsupervised WSD.", "labels": [], "entities": [{"text": "EP", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9953368306159973}]}], "introductionContent": [{"text": "Word sense disambiguation (WSD) has been a hot topic in natural language processing, which is to determine the sense of an ambiguous word in a specific context.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8435355474551519}, {"text": "determine the sense of an ambiguous word in a specific context", "start_pos": 97, "end_pos": 159, "type": "TASK", "confidence": 0.6916615421121771}]}, {"text": "It is an important technique for applications such as information retrieval, text mining, machine translation, text classification, automatic text summarization, and soon.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.8036814332008362}, {"text": "text mining", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.8342045545578003}, {"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.8080788552761078}, {"text": "text classification", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.8210318386554718}, {"text": "automatic text summarization", "start_pos": 132, "end_pos": 160, "type": "TASK", "confidence": 0.5750151375929514}]}, {"text": "Statistical solutions to WSD acquire linguistic knowledge from the training corpus using machine learning technologies, and apply the knowledge to disambiguation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9728432893753052}]}, {"text": "The first statistical model of WSD was built by.", "labels": [], "entities": [{"text": "WSD", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.891629695892334}]}, {"text": "Since then, most machine learning methods have been applied to WSD, including decision tree, Bayesian model, neural network, SVM, maximum entropy, genetic algorithms, and soon.", "labels": [], "entities": [{"text": "WSD", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9674380421638489}]}, {"text": "For different learning methods, supervised methods usually achieve good performance at a cost of human tagging of training corpus.", "labels": [], "entities": []}, {"text": "The precision improves with larger size of training corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.999306321144104}]}, {"text": "Compared with supervised methods, unsupervised methods do not require tagged corpus, but the precision is usually lower than that of the supervised methods.", "labels": [], "entities": [{"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9995067119598389}]}, {"text": "Thus, knowledge acquisition is critical to WSD methods.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.8781235218048096}, {"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9730221629142761}]}, {"text": "This paper proposes an unsupervised method based on equivalent pseudowords, which acquires WSD knowledge from raw corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.8905846476554871}]}, {"text": "This method first determines equivalent pseudowords for each ambiguous word, and then uses the equivalent pseudowords to replace the ambiguous word in the corpus.", "labels": [], "entities": []}, {"text": "The advantage of this method is that it does not need parallel corpus or seed corpus for training.", "labels": [], "entities": []}, {"text": "Thus, it can use a largescale monolingual corpus for training to solve the data-sparseness problem.", "labels": [], "entities": []}, {"text": "Experimental results show that our unsupervised method performs better than the supervised method.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarizes the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the conception of Equivalent Pseudoword.", "labels": [], "entities": []}, {"text": "Section 4 describes EP-based Unsupervised WSD Method and the evaluation result.", "labels": [], "entities": [{"text": "WSD", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.7726187705993652}]}, {"text": "The last section concludes our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Senseval-3 Chinese ambiguous words are taken as the testing set, which includes 20 words, each with 2-8 senses.", "labels": [], "entities": []}, {"text": "The data for the ambiguous words are divided into a training set and a testing set by a ratio of 2:1.", "labels": [], "entities": []}, {"text": "There are 15-20 training instances for each sense of the words, and occurs by the same frequency in the training and test set.", "labels": [], "entities": []}, {"text": "Supervised WSD is first implemented using the Bayesian model on the Senseval-3 data set.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9390072226524353}, {"text": "Senseval-3 data set", "start_pos": 68, "end_pos": 87, "type": "DATASET", "confidence": 0.9689657886823019}]}, {"text": "With a context window of (-10, +10), the open test results are shown in table 2.", "labels": [], "entities": []}, {"text": "The F-measure in table 2 is defined in (2).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.8811036348342896}]}, {"text": "(2) Where P and R refer to the precision and recall of the sense tagging respectively, which are calculated as shown in and ) tagged ( Where C(tagged) is the number of tagged instances of senses, C(correct) is the number of correct tags, and C(all) is the number of tags in the gold standard set.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9992462396621704}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9974697828292847}, {"text": "gold standard set", "start_pos": 278, "end_pos": 295, "type": "DATASET", "confidence": 0.7615870436032613}]}, {"text": "Every sense of the ambiguous word has a P value, a R value and a F value.", "labels": [], "entities": [{"text": "F", "start_pos": 65, "end_pos": 66, "type": "METRIC", "confidence": 0.9729648232460022}]}, {"text": "The F value in table 2 is a weighted average of all the senses.", "labels": [], "entities": [{"text": "F", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9979749321937561}]}, {"text": "In the EP-based unsupervised WSD experiment, a 100M corpus (People's Daily for year 1998) is used for the EP training instances.", "labels": [], "entities": [{"text": "WSD", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.7346298098564148}, {"text": "People's Daily for year 1998)", "start_pos": 60, "end_pos": 89, "type": "DATASET", "confidence": 0.8895238552774701}]}, {"text": "The Senseval-3 data is used for the test.", "labels": [], "entities": [{"text": "Senseval-3 data", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.87956103682518}]}, {"text": "In our experiments, a context window of (-10, +10) is taken.", "labels": [], "entities": []}, {"text": "The detailed results are shown in table 3.", "labels": [], "entities": []}, {"text": "Two evaluation criteria are used in the experiments, which are the F-measure and precision.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9985742568969727}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9995620846748352}]}, {"text": "Precision is a usual criterion in WSD performance analysis.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9887474179267883}, {"text": "WSD performance analysis", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.8893641630808512}]}, {"text": "Only in recent years, the precision, recall, and F-measure are all taken to evaluate the WSD performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9998012185096741}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9995154142379761}, {"text": "F-measure", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.999602735042572}, {"text": "WSD", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9671528339385986}]}, {"text": "In this paper, we will only show the f-measure score because it is a combined score of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9996640682220459}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9980177879333496}]}, {"text": "The experiment results in table 2 reveals that the results of supervised WSD and those of (Qin and) are different.", "labels": [], "entities": [{"text": "WSD", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8972375988960266}]}, {"text": "Although they are all based on the Bayesian model, used an ensemble classifier.", "labels": [], "entities": []}, {"text": "However, the difference of the average value is not remarkable.", "labels": [], "entities": []}, {"text": "As introduced above, in the supervised WSD experiment, the various senses of the instances are evenly distributed.", "labels": [], "entities": [{"text": "WSD", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9404783844947815}]}, {"text": "The lower bound as suggested should be very low and it is more difficult to disambiguate if there are more senses.", "labels": [], "entities": []}, {"text": "The experiment verifies this reasoning, because the highest F-measure is less than 90%, and the lowest is less than 60%, averaging about 70%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9974035620689392}]}, {"text": "With the same number of senses and the same scale of training data, there is a big difference between the WSD results.", "labels": [], "entities": [{"text": "WSD", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.8690014481544495}]}, {"text": "This shows that other factors exist which influence the performance other than the number of senses and training data size.", "labels": [], "entities": []}, {"text": "For example, the discriminability among the senses is an important factor.", "labels": [], "entities": []}, {"text": "The WSD task becomes more difficult if the senses of the ambiguous word are more similar to each other.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9086117744445801}]}, {"text": "The EP-based unsupervised method takes the same open test set as the supervised method.", "labels": [], "entities": []}, {"text": "The unsupervised method shows a better performance, with the highest F-measure score at 100%, lowest at 59% and average at 80%.", "labels": [], "entities": [{"text": "F-measure score", "start_pos": 69, "end_pos": 84, "type": "METRIC", "confidence": 0.9878964126110077}, {"text": "average", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9917973279953003}]}, {"text": "The results shows that EP is useful in unsupervised WSD., it can be seen that 16 among the 20 ambiguous words show better WSD performance in unsupervised SWD than in supervised WSD, while only 2 of them shows similar results and 2 performs worse . The average F-measure of the unsupervised method is higher by more than 10%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 260, "end_pos": 269, "type": "METRIC", "confidence": 0.9980320334434509}]}, {"text": "The reason lies in the following aspects:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. The F-measure for the Supervised WSD", "labels": [], "entities": [{"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9924952983856201}, {"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.4267374277114868}]}, {"text": " Table 3. The Results for Unsupervised WSD based on EPs", "labels": [], "entities": [{"text": "WSD", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8729874491691589}]}]}