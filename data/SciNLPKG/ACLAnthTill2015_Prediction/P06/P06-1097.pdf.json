{"title": [{"text": "Semi-Supervised Training for Statistical Word Alignment", "labels": [], "entities": [{"text": "Statistical Word Alignment", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.8632834752400717}]}], "abstractContent": [{"text": "We introduce a semi-supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word-alignment quality on a small, manually word-aligned sub-corpus.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.7078956464926401}, {"text": "Expectation Maximization", "start_pos": 120, "end_pos": 144, "type": "TASK", "confidence": 0.7251430302858353}]}, {"text": "We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.6797627210617065}]}], "introductionContent": [{"text": "The most widely applied training procedure for statistical machine translation -IBM model 4 () unsupervised training followed by post-processing with symmetrization heuristics -yields low quality word alignments.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.6995010773340861}, {"text": "word alignments", "start_pos": 196, "end_pos": 211, "type": "TASK", "confidence": 0.7481893002986908}]}, {"text": "When compared with gold standard parallel data which was manually aligned using a high-recall/precision methodology, the word-level alignments produced automatically have an F-measure accuracy of 64.6 and 76.4% (see Section 2 for details).", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9871496558189392}, {"text": "F-measure accuracy", "start_pos": 174, "end_pos": 192, "type": "METRIC", "confidence": 0.8006958663463593}]}, {"text": "In this paper, we improve word alignment and, subsequently, MT accuracy by developing a range of increasingly sophisticated methods: 1.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.8140107989311218}, {"text": "MT", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.988431990146637}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9259216785430908}]}, {"text": "We first recast the problem of estimating the IBM models () in a discriminative framework, which leads to an initial increase in word-alignment accuracy.", "labels": [], "entities": [{"text": "IBM models", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.7730004787445068}, {"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.967770516872406}]}, {"text": "2. We extend the IBM models with new (sub)models, which leads to additional increases in word-alignment accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9468787312507629}]}, {"text": "In the process, we also show that these improvements are explained not only by the power of the new models, but also by a novel search procedure for the alignment of highest probability.", "labels": [], "entities": []}, {"text": "3. Finally, we propose a training procedure that interleaves discriminative training with maximum likelihood training.", "labels": [], "entities": []}, {"text": "These steps lead to word alignments of higher accuracy which, in our case, correlate with higher MT accuracy.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7403820157051086}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9977704286575317}, {"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.9399298429489136}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.7760300040245056}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review the data sets we use to validate experimentally our algorithms and the associated baselines.", "labels": [], "entities": []}, {"text": "In Section 3, we present iteratively our contributions that eventually lead to absolute increases in alignment quality of 4.8% for French/English and 4.8% for Arabic/English, as measured using F-measure for large word alignment tasks.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 193, "end_pos": 202, "type": "METRIC", "confidence": 0.9778062701225281}, {"text": "word alignment tasks", "start_pos": 213, "end_pos": 233, "type": "TASK", "confidence": 0.7837414940198263}]}, {"text": "These contributions pertain to the casting of the training procedure in the discriminative framework (Section 3.1); the IBM model extensions and modified search procedure for the Viterbi alignments (Section 3.2); and the interleaved, minimum error/maximum likelihood, training algorithm (Section 4).", "labels": [], "entities": []}, {"text": "In Section 5, we assess the impact that our improved alignments have on MT quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.996110737323761}]}, {"text": "We conclude with a comparison of our work with previous research on discriminative training for word alignment and a short discussion of semi-supervised learning.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.803488552570343}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Baseline Results. F-measures are presented on both the alignment discriminative training set  and the alignment test set sub-corpora, separated by /.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9542944431304932}]}, {"text": " Table 3: Sub-Models. Note that sub-models 1 to 5 are IBM Model 4, sub-models 6 to 16 are new.", "labels": [], "entities": [{"text": "IBM Model 4", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.9038559993108114}]}, {"text": " Table 4: Discriminative Reranking with Improved Search. F-measures are presented on both the align- ment discriminative training set and the alignment test set sub-corpora, separated by /.", "labels": [], "entities": [{"text": "Discriminative Reranking", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7427631318569183}, {"text": "F-measures", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9702765345573425}]}, {"text": " Table 5: Comparison of New Search Algorithm with Old Search Algorithm", "labels": [], "entities": []}, {"text": " Table 6: Impact of Improved Search on Discriminative Reranking of Model 4", "labels": [], "entities": [{"text": "Discriminative Reranking", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.44019128382205963}]}, {"text": " Table 7: Semi-Supervised Training Task F-measure", "labels": [], "entities": [{"text": "Semi-Supervised Training Task F-measure", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.46723292022943497}]}, {"text": " Table 8: Evaluation of Translation Quality", "labels": [], "entities": [{"text": "Evaluation of Translation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6148741642634074}]}]}