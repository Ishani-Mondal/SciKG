{"title": [{"text": "Efficient Unsupervised Discovery of Word Categories Using Symmetric Patterns and High Frequency Words", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a novel approach for discovering word categories, sets of words sharing a significant aspect of their meaning.", "labels": [], "entities": []}, {"text": "We utilize meta-patterns of high-frequency words and content words in order to discover pattern candidates.", "labels": [], "entities": []}, {"text": "Symmetric patterns are then identified using graph-based measures, and word categories are created based on graph clique sets.", "labels": [], "entities": []}, {"text": "Our method is the first pattern-based method that requires no corpus annotation or manually provided seed patterns or words.", "labels": [], "entities": []}, {"text": "We evaluate our algorithm on very large corpora in two languages, using both human judgments and WordNet-based evaluation.", "labels": [], "entities": []}, {"text": "Our fully unsupervised results are superior to previous work that used a POS tagged corpus, and computation time for huge corpora are orders of magnitude faster than previously reported.", "labels": [], "entities": [{"text": "POS tagged corpus", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.6717463632424673}]}], "introductionContent": [{"text": "Lexical resources are crucial inmost NLP tasks and are extensively used by people.", "labels": [], "entities": []}, {"text": "Manual compilation of lexical resources is labor intensive, error prone, and susceptible to arbitrary human decisions.", "labels": [], "entities": [{"text": "Manual compilation of lexical resources", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7525231003761291}]}, {"text": "Hence there is a need for automatic authoring that would be as unsupervised and languageindependent as possible.", "labels": [], "entities": []}, {"text": "An important type of lexical resource is that given by grouping words into categories.", "labels": [], "entities": []}, {"text": "In general, the notion of a category is a fundamental one in cognitive psychology.", "labels": [], "entities": []}, {"text": "A lexical category is a set of words that share a significant aspect of their meaning, e.g., sets of words denoting vehicles, types of food, tool names, etc.", "labels": [], "entities": [{"text": "A lexical category is a set of words that share a significant aspect of their meaning, e.g., sets of words denoting vehicles, types of food, tool names, etc", "start_pos": 0, "end_pos": 156, "type": "Description", "confidence": 0.7726077726393035}]}, {"text": "A word can obviously belong to more than a single category.", "labels": [], "entities": []}, {"text": "We will use 'category' instead of 'lexical category' for brevity . Grouping of words into categories is useful in itself (e.g., for the construction of thesauri), and can serve as the starting point in many applications, such as ontology construction and enhancement, discovery of verb subcategorization frames, etc.", "labels": [], "entities": [{"text": "Grouping of words into categories", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.8697786688804626}, {"text": "ontology construction", "start_pos": 229, "end_pos": 250, "type": "TASK", "confidence": 0.8764291405677795}, {"text": "discovery of verb subcategorization frames", "start_pos": 268, "end_pos": 310, "type": "TASK", "confidence": 0.7785003185272217}]}, {"text": "Our goal in this paper is a fully unsupervised discovery of categories from large unannotated text corpora.", "labels": [], "entities": []}, {"text": "We aim for categories containing single words (multi-word lexical items will be dealt within future papers.)", "labels": [], "entities": []}, {"text": "Our approach is based on patterns, and utilizes the following stages: 1.", "labels": [], "entities": []}, {"text": "Discovery of a set of pattern candidates that might be useful for induction of lexical relationships.", "labels": [], "entities": []}, {"text": "We do this in a fully unsupervised manner, using meta-patterns comprised of high frequency words and content words.", "labels": [], "entities": []}, {"text": "2. Identification of pattern candidates that give rise to symmetric lexical relationships.", "labels": [], "entities": []}, {"text": "This is done using simple measures in a word relationship graph.", "labels": [], "entities": []}, {"text": "3. Usage of a novel graph clique-set algorithm in order to generate categories from information on the co-occurrence of content words in the symmetric patterns.", "labels": [], "entities": []}, {"text": "We performed a thorough evaluation on two English corpora (the BNC and a 68GB web corpus) and on a 33GB Russian corpus, and a sanity-check test on smaller Danish, Irish and Portuguese corpora.", "labels": [], "entities": [{"text": "BNC and a 68GB web corpus", "start_pos": 63, "end_pos": 88, "type": "DATASET", "confidence": 0.7163104563951492}]}, {"text": "Evaluations were done using both human judgments and WordNet in a setting quite similar to that done (for the BNC) in previous work.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9542650580406189}]}, {"text": "Our unsupervised results are superior to previous work that used a POS tagged corpus, are less language dependent, and are very efficient computationally . Patterns area common approach in lexical acquisition.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 189, "end_pos": 208, "type": "TASK", "confidence": 0.7858595550060272}]}, {"text": "Our approach is novel in several aspects: (1) we discover patterns in a fully unsupervised manner, as opposed to using a manually prepared pattern set, pattern seed or words seeds; (2) our pattern discovery requires no annotation of the input corpus, as opposed to requiring POS tagging or partial or full parsing; (3) we discover general symmetric patterns, as opposed to using a few hard-coded ones such as 'x and y'; (4) the cliqueset graph algorithm in stage 3 is novel.", "labels": [], "entities": [{"text": "pattern discovery", "start_pos": 189, "end_pos": 206, "type": "TASK", "confidence": 0.7501614391803741}]}, {"text": "In addition, we demonstrated the relatively language independent nature of our approach by evaluating on very large corpora in two languages . Section 2 surveys previous work.", "labels": [], "entities": []}, {"text": "Section 3 describes pattern discovery, and Section 4 describes the formation of categories.", "labels": [], "entities": [{"text": "pattern discovery", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.9029553234577179}]}, {"text": "Evaluation is presented in Section 5, and a discussion in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Lexical acquisition algorithms are notoriously hard to evaluate.", "labels": [], "entities": [{"text": "Lexical acquisition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9015814960002899}]}, {"text": "We have attempted to be as thorough as possible, using several languages and both automatic and human evaluation.", "labels": [], "entities": []}, {"text": "In the automatic part, we followed as closely as possible the methodology and data used in previous work, so that meaningful comparisons could be made.", "labels": [], "entities": []}, {"text": "The purpose of the human evaluation was dual: to assess the quality of the discovered categories in terms of precision, and to compare with those obtained by a baseline clustering algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.999250590801239}]}, {"text": "For the baseline, we implemented k-means as follows.", "labels": [], "entities": []}, {"text": "We have removed stopwords from the corpus, and then used as features the words which appear before or after the target word.", "labels": [], "entities": []}, {"text": "In the calculation of feature values and inter-vector distances, and in the removal of less informative features, we have strictly followed).", "labels": [], "entities": []}, {"text": "We ran the algorithm 10 times using k = 500 with randomly selected centroids, producing 5000 clusters.", "labels": [], "entities": []}, {"text": "We then merged the resulting clusters using the same 50% overlap criterion as in our algorithm.", "labels": [], "entities": [{"text": "overlap", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.8263943791389465}]}, {"text": "The result included 3090, 2116, and 3206 clusters for Dmoz, BNC and Russian respectively.", "labels": [], "entities": [{"text": "Dmoz", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.8818511962890625}]}, {"text": "We used 8 subjects for evaluation of the English categories and 15 subjects for evaluation of the Russian ones.", "labels": [], "entities": []}, {"text": "In order to assess the subjects' reliability, we also included random categories (see below.)", "labels": [], "entities": [{"text": "reliability", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9772153496742249}]}, {"text": "The experiment contained two parts.", "labels": [], "entities": []}, {"text": "In Part I, subjects were given 40 triplets of words and were asked to rank them using the following scale: (1) the words definitely share a significant part of their meaning; (2) the words have a shared meaning but only in some context; (3) the words have a shared meaning only under a very unusual context/situation; (4) the words do not share any meaning; (5) I am not familiar enough with some/all of the words.", "labels": [], "entities": []}, {"text": "The 40 triplets were obtained as follows.", "labels": [], "entities": []}, {"text": "20 of our categories were selected at random from the non-overlapping categories we have discovered, and three words were selected from each of these at random.", "labels": [], "entities": []}, {"text": "10 triplets were selected in the same manner from the categories produced by k-means, and 10 triplets were generated by random selection of content words from the same window in the corpus.", "labels": [], "entities": []}, {"text": "In Part II, subjects were given the full categories of the triplets that were graded as 1 or 2 in Part I (that is, the full 'good' categories in terms of sharing of meaning.)", "labels": [], "entities": []}, {"text": "They were asked to grade the categories from 1 (worst) to 10 (best) according to how much the full category had met the expectations they had when seeing only the triplet.", "labels": [], "entities": []}, {"text": "The first line gives the average percentage of triplets that were given scores of 1 or 2 (that is, 'significant shared meaning'.)", "labels": [], "entities": []}, {"text": "The 2nd line gives the average score of a triplet (1 is best.)", "labels": [], "entities": []}, {"text": "In these lines scores of 5 were not counted.", "labels": [], "entities": []}, {"text": "The 3rd line gives the average score given to a full category (10 is best.)", "labels": [], "entities": []}, {"text": "Interevaluator Kappa between scores 1,2 and 3,4 was 0.56, 0.67 and 0.72 for Dmoz, BNC and Russian respectively.", "labels": [], "entities": [{"text": "Interevaluator Kappa", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.8983525931835175}, {"text": "Dmoz", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.8785039186477661}, {"text": "BNC", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.6437383890151978}]}, {"text": "Our algorithm clearly outperforms k-means, which outperforms random.", "labels": [], "entities": []}, {"text": "We believe that the Russian results are better because the percentage of native speakers among our subjects for Russian was larger than that for English.", "labels": [], "entities": []}, {"text": "The major guideline in this part of the evaluation was to compare our results with previous work having a similar goal ().", "labels": [], "entities": []}, {"text": "We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpus (BNC) in addition to the Dmoz and Russian corpora . The evaluation method is as follows.", "labels": [], "entities": []}, {"text": "We took the exact 10 WN subsets referred to as 'subjects' in (, and removed all multi-word items.", "labels": [], "entities": []}, {"text": "We now selected at random 10 pairs of words from each subject.", "labels": [], "entities": []}, {"text": "For each pair, we found the largest of our discovered categories containing it (if there isn't one, we pick another pair.", "labels": [], "entities": []}, {"text": "This is valid because our Recall is obviously not even close to 100%, so if we did not pick another pair we would seriously harm the validity of the evaluation.)", "labels": [], "entities": [{"text": "Recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9046595692634583}]}, {"text": "The various morphological forms of the same word were treated as one during the evaluation.", "labels": [], "entities": []}, {"text": "The only difference from the () experiment is the usage of pairs rather than single words.", "labels": [], "entities": []}, {"text": "We did this in order to disambiguate our categories.", "labels": [], "entities": []}, {"text": "This was not needed in) because they had directly accessed the word graph, which maybe an advantage in some applications.", "labels": [], "entities": []}, {"text": "The Russian evaluation posed a bit of a problem because the Russian WordNet is not readily available and its coverage is rather small.", "labels": [], "entities": []}, {"text": "Fortunately, the subject list is such that WordNet words could be translated unambiguously to Russian and words in our discovered categories could be translated unambiguously into English.", "labels": [], "entities": []}, {"text": "This was the methodology taken.", "labels": [], "entities": []}, {"text": "For each found category C containing N words, we computed the following (see): (1) Precision: the number of words present in both C and WN divided by N ; (2) Precision*: the number of correct words divided by N . Correct words are either words that appear in the WN subtree, or words whose entry in the American Heritage Dictionary or the Britannica directly defines them as belonging to the given class (e.g., 'keyboard' is defined as 'a piano'; 'mitt' is defined by 'a type of glove'.)", "labels": [], "entities": [{"text": "Precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9888371229171753}, {"text": "Precision", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9739401936531067}, {"text": "American Heritage Dictionary", "start_pos": 303, "end_pos": 331, "type": "DATASET", "confidence": 0.7825807332992554}]}, {"text": "This was done in order to overcome the relative poorness of WordNet; (3) Recall: the number of words present in both C and WN divided by the number of (single) words in WN; (4) The number of correctly discovered words (New) that are not in WN.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9610053300857544}, {"text": "Recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9924478530883789}]}, {"text": "The shows the number of WN words (:WN), in order to get a feeling by how much WN could be improved here.", "labels": [], "entities": []}, {"text": "For each subject, we show the average over the 10 randomly selected pairs.", "labels": [], "entities": []}, {"text": "also shows the average of each measure over the subjects, and the two precision measures when computed on the total set of WN words.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.998485267162323}]}, {"text": "The (uncorrected) precision is the only metric given in), who reported 82% (for the BNC.)", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9789930582046509}, {"text": "BNC", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9385027885437012}]}, {"text": "Our method gives 90.47% for this metric on the same corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of evaluation by human judgment of three data sets (ours, that obtained by k-means, and  random categories) on the three corpora. See text for detailed explanations.", "labels": [], "entities": []}, {"text": " Table 2: WordNet evaluation. Note the BNC 'all  words' precision of 90.47%. This metric was re- ported to be 82% in", "labels": [], "entities": [{"text": "WordNet", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.8886321187019348}, {"text": "BNC 'all  words' precision", "start_pos": 39, "end_pos": 65, "type": "METRIC", "confidence": 0.6662620544433594}]}]}