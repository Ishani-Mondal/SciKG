{"title": [{"text": "An Improved Redundancy Elimination Algorithm for Underspecified Representations", "labels": [], "entities": [{"text": "Improved Redundancy Elimination Algorithm", "start_pos": 3, "end_pos": 44, "type": "TASK", "confidence": 0.719355896115303}]}], "abstractContent": [{"text": "We present an efficient algorithm for the redundancy elimination problem: Given an underspecified semantic representation (USR) of a scope ambiguity, compute an USR with fewer mutually equivalent readings.", "labels": [], "entities": [{"text": "redundancy elimination", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7531213164329529}]}, {"text": "The algorithm operates on underspec-ified chart representations which are derived from dominance graphs; it can be applied to the USRs computed by large-scale grammars.", "labels": [], "entities": [{"text": "USRs", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.7608949542045593}]}, {"text": "We evaluate the algorithm on a corpus, and show that it reduces the degree of ambiguity significantly while taking negligible runtime.", "labels": [], "entities": []}], "introductionContent": [{"text": "Underspecification is nowadays the standard approach to dealing with scope ambiguities in computational semantics).", "labels": [], "entities": []}, {"text": "The basic idea behind it is to not enumerate all possible semantic representations for each syntactic analysis, but to derive a single compact underspecified representation (USR).", "labels": [], "entities": []}, {"text": "This simplifies semantics construction, and current algorithms support the efficient enumeration of the individual semantic representations from an USR (.", "labels": [], "entities": [{"text": "semantics construction", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.8409493267536163}, {"text": "USR", "start_pos": 148, "end_pos": 151, "type": "DATASET", "confidence": 0.9293368458747864}]}, {"text": "A major promise of underspecification is that it makes it possible, in principle, to rule out entire subsets of readings that we are not interested in wholesale, without even enumerating them.", "labels": [], "entities": []}, {"text": "For instance, real-world sentences with scope ambiguities often have many readings that are semantically equivalent.", "labels": [], "entities": []}, {"text": "Subsequent modules (e.g. for doing inference) will typically only be interested in one reading from each equivalence class, and all others could be deleted.", "labels": [], "entities": []}, {"text": "This situation is illustrated by the following two (out of many) sentences from the Rondane treebank, which is distributed with the English Resource Grammar (ERG;), a large-scale HPSG grammar of English.", "labels": [], "entities": [{"text": "Rondane treebank", "start_pos": 84, "end_pos": 100, "type": "DATASET", "confidence": 0.9201555848121643}]}, {"text": "(1) For travellers going to Finnmark there is a bus service from Oslo to Alta through Sweden.", "labels": [], "entities": []}, {"text": "(2) We quickly put up the tents in the lee of a small hillside and cook for the first time in the open.", "labels": [], "entities": []}, {"text": "(Rondane 892) For the annotated syntactic analysis of, the ERG derives an USR with eight scope bearing operators, which results in a total of 3960 readings.", "labels": [], "entities": [{"text": "ERG", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.8570752143859863}, {"text": "USR", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.70732581615448}]}, {"text": "These readings are all semantically equivalent to each other.", "labels": [], "entities": []}, {"text": "On the other hand, the USR for (2) has 480 readings, which fall into two classes of mutually equivalent readings, characterised by the relative scope of \"the lee of\" and \"a small hillside.\"", "labels": [], "entities": [{"text": "USR", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.890373945236206}]}, {"text": "In this paper, we present an algorithm for the redundancy elimination problem: Given an USR, compute an USR which has fewer readings, but still describes at least one representative of each equivalence class -without enumerating any readings.", "labels": [], "entities": [{"text": "redundancy elimination problem", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.8402367234230042}]}, {"text": "This algorithm makes it possible to compute the one or two representatives of the semantic equivalence classes in the examples, so subsequent modules don't have to deal with all the other equivalent readings.", "labels": [], "entities": []}, {"text": "It also closes the gap between the large number of readings predicted by the grammar and the intuitively perceived much lower degree of ambiguity of these sentences.", "labels": [], "entities": []}, {"text": "Finally, it can be helpful fora grammar designer because it is much more feasible to check whether two readings are linguistically reasonable than 480.", "labels": [], "entities": []}, {"text": "Our algorithm is applicable to arbitrary USRs (not just those computed by the ERG).", "labels": [], "entities": []}, {"text": "While its effect is particularly significant on the ERG, which uniformly treats all kinds of noun phrases, including proper names and pronouns, as generalised quantifiers, it will generally help deal with spurious ambiguities (such as scope ambiguities between indef-inites), which have been a ubiquitous problem inmost theories of scope since Montague Grammar.", "labels": [], "entities": [{"text": "Montague Grammar", "start_pos": 344, "end_pos": 360, "type": "DATASET", "confidence": 0.9009449779987335}]}, {"text": "We model equivalence in terms of rewrite rules that permute quantifiers without changing the semantics of the readings.", "labels": [], "entities": []}, {"text": "The particular USRs we work with are underspecified chart representations, which can be computed from dominance graphs (or USRs in some other underspecification formalisms) efficiently.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the algorithm on the Rondane treebank and show that it reduces the median number of readings from 56 to 4, by up to a factor of 666.240 for individual USRs, while running in negligible time.", "labels": [], "entities": [{"text": "Rondane treebank", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.8236671984195709}]}, {"text": "To our knowledge, our algorithm and its less powerful predecessor) are the first redundancy elimination algorithms in the literature that operate on the level of USRs.", "labels": [], "entities": [{"text": "redundancy elimination", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7332264482975006}, {"text": "USRs", "start_pos": 162, "end_pos": 166, "type": "DATASET", "confidence": 0.8452765941619873}]}, {"text": "There has been previous research on enumerating only some representatives of each equivalence class, but these approaches don't maintain underspecification: After running their algorithms, they are left with a set of readings rather than an underspecified representation, i.e. we could no longer run other algorithms on an USR.", "labels": [], "entities": [{"text": "USR", "start_pos": 323, "end_pos": 326, "type": "DATASET", "confidence": 0.9584120512008667}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We will first define dominance graphs and review the necessary background theory in Section 2.", "labels": [], "entities": []}, {"text": "We will then introduce our notion of equivalence in Section 3, and present the redundancy elimination algorithm in Section 4.", "labels": [], "entities": [{"text": "redundancy elimination", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.7198562622070312}]}, {"text": "In Section 5, we describe the evaluation of the algorithm on the Rondane corpus.", "labels": [], "entities": [{"text": "Rondane corpus", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.9294544756412506}]}, {"text": "Finally, Section 6 concludes and points to further work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this final section, we evaluate the the effectiveness and efficiency of the elimination algorithm: We run it on USRs from a treebank and measure how many readings are redundant, to what extent the algorithm eliminates this redundancy, and how much time it takes to do this.", "labels": [], "entities": []}, {"text": "The experiments are based on the Rondane corpus, a Redwoods () style corpus which is distributed with the English Resource Grammar).", "labels": [], "entities": [{"text": "Rondane corpus", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.8847751915454865}, {"text": "English Resource Grammar", "start_pos": 106, "end_pos": 130, "type": "DATASET", "confidence": 0.8408289353052775}]}, {"text": "The corpus contains analyses for 1076 sentences from the tourism domain, which are associated with USRs based upon Minimal Recursion Semantics (MRS).", "labels": [], "entities": [{"text": "USRs", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.7349774837493896}]}, {"text": "The MRS representations are translated into dominance graphs using the open-source utool tool (, which is restricted to MRS representations whose translations are hnc.", "labels": [], "entities": []}, {"text": "By restricting ourselves to such MRSs, we end up with a data set of 999 dominance graphs.", "labels": [], "entities": [{"text": "MRSs", "start_pos": 33, "end_pos": 37, "type": "TASK", "confidence": 0.9124858975410461}]}, {"text": "The average number of scope bearing operators in the data set is 6.5, and the median number of readings is 56.", "labels": [], "entities": []}, {"text": "We then defined a (rather conservative) rewrite system R ERG for capturing the permutability relation of the quantifiers in the ERG.", "labels": [], "entities": []}, {"text": "This amounted to 34 rule schemata, which are automatically expanded to 494 rewrite rules.", "labels": [], "entities": []}, {"text": "We first analysed the extent to which our algorithm eliminated the redundancy of the USRs in the corpus.", "labels": [], "entities": [{"text": "USRs in the corpus", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.8035811632871628}]}, {"text": "We computed dominance charts for all USRs, ran the algorithm on them, and counted the number of configurations of the reduced charts.", "labels": [], "entities": [{"text": "USRs", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.8923148512840271}]}, {"text": "We then compared these numbers against a baseline and an upper bound.", "labels": [], "entities": []}, {"text": "The upper bound is the true number of log(#configurations) Factor Algorithm Baseline Classes: Mean reduction factor on Rondane.", "labels": [], "entities": []}, {"text": "equivalence classes with respect to R ERG ; for efficiency reasons we could only compute this number for USRs with up to 500.000 configurations (95 % of the data set).", "labels": [], "entities": [{"text": "R ERG", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.6214025616645813}]}, {"text": "The baseline is given by the number of readings that remain if we replace proper names and pronouns by constants and variables, respectively.", "labels": [], "entities": []}, {"text": "This simple heuristic is easy to compute, and still achieves nontrivial redundancy elimination because proper names and pronouns are quite frequent (28% of the noun phrase occurrences in the data set).", "labels": [], "entities": []}, {"text": "It also shows the degree of non-trivial scope ambiguity in the corpus.", "labels": [], "entities": []}, {"text": "For each measurement, we sorted the USRs according to the number N of configurations, and grouped USRs according to the natural logarithm of N (rounded down) to obtain a logarithmic scale.", "labels": [], "entities": []}, {"text": "First, we measured the mean reduction factor for each log(N) class, i.e. the ratio of the number of all configurations to the number of remaining configurations after redundancy elimination.", "labels": [], "entities": [{"text": "mean reduction factor", "start_pos": 23, "end_pos": 44, "type": "METRIC", "confidence": 0.8829293847084045}]}, {"text": "The upper-bound line in the figure shows that there is a great deal of redundancy in the USRs in the data set.", "labels": [], "entities": [{"text": "USRs in the data set", "start_pos": 89, "end_pos": 109, "type": "DATASET", "confidence": 0.823945164680481}]}, {"text": "The average performance of our algorithm is close to the upper bound and much better than the baseline.", "labels": [], "entities": []}, {"text": "For USRs with fewer thane 8 = 2980 configurations (83 % of the data set), the mean reduction factor of our algorithm is above 86 % of the upper bound.", "labels": [], "entities": []}, {"text": "The median number of configurations for the USRs in the whole data set is 56, and the median number of equivalence classes is 3; again, the median number of configurations of the reduced charts is very close to the upper bound, at 4 (baseline: 8).", "labels": [], "entities": [{"text": "USRs in the whole data set", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.8126675089200338}]}, {"text": "The highest reduction factor for an individual USR is 666.240.", "labels": [], "entities": [{"text": "reduction", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9904234409332275}, {"text": "USR", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.5508679151535034}]}, {"text": "We also measured the ratio of USRs for which the algorithm achieves complete reduction): The algorithm is complete for 56 % of the USRs in the data set.", "labels": [], "entities": [{"text": "USRs", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.6696361303329468}, {"text": "USRs in the data set", "start_pos": 131, "end_pos": 151, "type": "DATASET", "confidence": 0.7516027987003326}]}, {"text": "It is complete for 78 % of the USRs with fewer thane 5 = 148 configurations (64 % of the data set), and still complete for 66 % of the USRs with fewer thane 8 configurations.", "labels": [], "entities": [{"text": "USRs", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.9460511207580566}]}, {"text": "Finally, we measured the runtime of the elimination algorithm.", "labels": [], "entities": []}, {"text": "The runtime of the elimination algorithm is generally comparable to the runtime for computing the chart in the first place.", "labels": [], "entities": []}, {"text": "However, in our experiments we used an optimised version of the elimination algorithm, which computes the reduced chart directly from a dominance graph by checking each split for eliminability before it is added to the chart.", "labels": [], "entities": []}, {"text": "We compare the performance of this algorithm to the baseline of computing the complete chart.", "labels": [], "entities": []}, {"text": "For comparison, we have also added the time it takes to enumerate all configurations of the graph, as a lower bound for any algorithm that computes the equivalence classes based on the full set of configurations.", "labels": [], "entities": []}, {"text": "shows the mean runtimes for each log(N) class, on the USRs with less than one million configurations (958 USRs).", "labels": [], "entities": [{"text": "USRs", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.9390896558761597}]}, {"text": "As the figure shows, the asymptotic runtimes for computing the complete chart and the reduced chart are about the same, whereas the time for enumerating all configurations grows much faster.", "labels": [], "entities": []}, {"text": "(Note that the runtime is reported on a logarithmic scale.)", "labels": [], "entities": []}, {"text": "For USRs with many configurations, computing the reduced chart actually takes less time on average than computing the complete chart because the chart-filling algorithm is called on fewer subgraphs.", "labels": [], "entities": []}, {"text": "While the reduced-chart algorithm seems to be slower than the complete-chart one for USRs with less thane 5 configurations, these runtimes remain below 20 milliseconds on average, and the measurements are thus quite unreliable.", "labels": [], "entities": []}, {"text": "In summary, we can say that there is no overhead for redundancy elimination in practice.", "labels": [], "entities": [{"text": "redundancy elimination", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.9599739909172058}]}], "tableCaptions": []}