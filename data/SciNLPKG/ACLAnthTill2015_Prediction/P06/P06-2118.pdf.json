{"title": [{"text": "Aligning Features with Sense Distinction Dimensions 1", "labels": [], "entities": [{"text": "Aligning", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9573652744293213}]}], "abstractContent": [{"text": "In this paper we present word sense disambiguation (WSD) experiments on ten highly polysemous verbs in Chinese, where significant performance improvements are achieved using rich linguistic features.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8017211606105169}]}, {"text": "Our system performs significantly better, and in some cases substantially better, than the baseline on all ten verbs.", "labels": [], "entities": []}, {"text": "Our results also demonstrate that features extracted from the output of an automatic Chinese semantic role labeling system in general benefited the WSD system, even though the amount of improvement was not consistent across the verbs.", "labels": [], "entities": [{"text": "Chinese semantic role labeling", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.5766219794750214}, {"text": "WSD", "start_pos": 148, "end_pos": 151, "type": "TASK", "confidence": 0.7195375561714172}]}, {"text": "For a few verbs, semantic role information actually hurt WSD performance.", "labels": [], "entities": [{"text": "WSD", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9851086735725403}]}, {"text": "The inconsistency of feature performance is a general characteristic of the WSD task, as has been observed by others.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 76, "end_pos": 84, "type": "TASK", "confidence": 0.9214044213294983}]}, {"text": "We argue that this result can be explained by the fact that word senses are partitioned along different dimensions for different verbs and the features therefore need to be tailored to particular verbs in order to achieve adequate accuracy on verb sense disambiguation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.9972629547119141}, {"text": "verb sense disambiguation", "start_pos": 243, "end_pos": 268, "type": "TASK", "confidence": 0.6593882739543915}]}], "introductionContent": [{"text": "Word sense disambiguation, the determination of the correct sense of a polysemous word from a number of possible senses based on the context in which it occurs, is a continuing obstacle to high performance natural language processing applications.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6896632313728333}, {"text": "determination of the correct sense of a polysemous word from a number of possible senses based on the context in which it occurs", "start_pos": 31, "end_pos": 159, "type": "Description", "confidence": 0.7222594022750854}]}, {"text": "There are several well-documented factors that make accurate WSD particularly challenging.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.8574293851852417}]}, {"text": "The first has to do with how senses are defined.", "labels": [], "entities": []}, {"text": "The English data used for the SENSEVAL exercises, arguably the most widely used data to train and test WSD systems, are annotated based on very fine-grained distinctions defined in WordNet, with human inter-annotator agreement at a little over seventy percent and the top-ranked systems' performances falling between 60%~70%).", "labels": [], "entities": [{"text": "SENSEVAL exercises", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8551304042339325}, {"text": "WSD", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9331891536712646}, {"text": "WordNet", "start_pos": 181, "end_pos": 188, "type": "DATASET", "confidence": 0.9471508264541626}]}, {"text": "The second source of difficulty for accurate WSD comes from how senses are distributed.", "labels": [], "entities": [{"text": "WSD", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.7855331301689148}]}, {"text": "It is often the case that a polysemous word has a dominant sense or several dominant senses that occur with high frequency and not enough instances can be found for its low frequency senses in the currently publicly available data.", "labels": [], "entities": []}, {"text": "There are on-going efforts to address these issues.", "labels": [], "entities": []}, {"text": "For example, the sense annotation component of the OntoNotes project) attempts to create a large-scale coarsegrained sense-annotated corpus with senses defined based on explicit linguistic criteria.", "labels": [], "entities": []}, {"text": "These problems will be alleviated when resources like this are available to the general NLP community.", "labels": [], "entities": []}, {"text": "There have already been experiments that show such coarse-grained senses lead to substantial improvement in system performance ().", "labels": [], "entities": []}, {"text": "The goal of our experiments is to explore the implications of a related and yet separate problem, specifically the extent to which the linguistic criteria used to define senses are related to what features need to be used in machine-learning systems.", "labels": [], "entities": []}, {"text": "There are already published results that show WSD for different syntactic categories may need different types of features.", "labels": [], "entities": [{"text": "WSD", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9238535761833191}]}, {"text": "For example,, in their experiments on SENSEVAL2 English data, showed that sense distinctions of verbs relied more on linguistically motivated features than other parts-of-speech.", "labels": [], "entities": [{"text": "SENSEVAL2 English data", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.6575376093387604}]}, {"text": "In this paper, we will go one step further and show that even for words of the same syntactic category senses are often defined along different dimensions based on different criteria.", "labels": [], "entities": []}, {"text": "One direct implication of this observation for supervised machinelearning approaches to WSD is that the features have to be customized for different word categories, or even for different words of the same category.", "labels": [], "entities": [{"text": "WSD", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.970280110836029}]}, {"text": "This supports previous arguments for word-specific feature design and parametric modeling for WSD tasks.", "labels": [], "entities": [{"text": "word-specific feature design", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.6198696692784628}, {"text": "WSD tasks", "start_pos": 94, "end_pos": 103, "type": "TASK", "confidence": 0.9238410294055939}]}, {"text": "We report experiments on ten highly polysemous Chinese verbs and show that features are not uniformly useful for all words.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe our WSD system, focusing on the features we used.", "labels": [], "entities": [{"text": "WSD", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9685243368148804}]}, {"text": "We also briefly compare the features we use for Chinese with those used in a similar English WSD system.", "labels": [], "entities": []}, {"text": "In Section 3, we present our experimental results and show that although rich linguistic features and features derived from a Chinese Semantic Role Labeling improve the WSD accuracy, the improvement is not uniform across all verbs.", "labels": [], "entities": [{"text": "WSD", "start_pos": 169, "end_pos": 172, "type": "TASK", "confidence": 0.9469568729400635}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.8695033192634583}]}, {"text": "We show that this lack of consistency is due to the different dimensions along which the features are defined.", "labels": [], "entities": [{"text": "consistency", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.9887718558311462}]}, {"text": "In Section 4, we discuss related work.", "labels": [], "entities": []}, {"text": "Finally Section 5 concludes this paper and describes future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data we used for our experiments are developed as part of the OntoNotes project) and they come from a variety of sources.", "labels": [], "entities": []}, {"text": "Part of the data is from the Chinese Treebank ( ), which has a combination of Xinhua news and Sinorama News Magazine.", "labels": [], "entities": [{"text": "Chinese Treebank", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.9868185520172119}, {"text": "Xinhua news", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.927560955286026}, {"text": "Sinorama News Magazine", "start_pos": 94, "end_pos": 116, "type": "DATASET", "confidence": 0.9427931308746338}]}, {"text": "Since some verbs have an insufficient number of instances for any meaningful experiments, we also annotated portions of the People's Daily corpus, developed by Peking University.", "labels": [], "entities": [{"text": "People's Daily corpus", "start_pos": 124, "end_pos": 145, "type": "DATASET", "confidence": 0.9134059399366379}]}, {"text": "We chose not to use the Chinese WSD dataset used in Senseval 3 1 because we are mainly interested in investigating how the features used in WSD are related to the criteria used to define the senses of Chinese verbs.", "labels": [], "entities": [{"text": "Chinese WSD dataset", "start_pos": 24, "end_pos": 43, "type": "DATASET", "confidence": 0.5916336874167124}]}, {"text": "The Chinese Senseval dataset includes both nouns and verbs.", "labels": [], "entities": [{"text": "Chinese Senseval dataset", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.9111490646998087}]}, {"text": "In addition, the criteria used to define their senses are not made explicit and therefore are not clear to us.", "labels": [], "entities": []}, {"text": "(Columns 7 to 10) also shows the experimental results.", "labels": [], "entities": []}, {"text": "As we can see, on average, our system achieved about 19% improvement (absolute gain) inaccuracy compared to the most frequent sense baseline.", "labels": [], "entities": [{"text": "absolute gain) inaccuracy", "start_pos": 70, "end_pos": 95, "type": "METRIC", "confidence": 0.9043332785367966}]}, {"text": "Its performance is consistently better than the baseline for all 10 verbs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 Corpus Statistics and Experimental Results for the 10 Chinese Verbs", "labels": [], "entities": [{"text": "Chinese Verbs", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.7687612771987915}]}]}