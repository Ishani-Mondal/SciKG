{"title": [{"text": "Continuous Space Language Models for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.812869668006897}]}], "abstractContent": [{"text": "Statistical machine translation systems are based on one or more translation models and a language model of the target language.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6172533531983694}]}, {"text": "While many different translation models and phrase extraction algorithms have been proposed, a standard word n-gram back-off language model is used inmost systems.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.834551215171814}]}, {"text": "In this work, we propose to use anew statistical language model that is based on a continuous representation of the words in the vocabulary.", "labels": [], "entities": []}, {"text": "A neural network is used to perform the projection and the probability estimation.", "labels": [], "entities": []}, {"text": "We consider the translation of European Parliament Speeches.", "labels": [], "entities": [{"text": "translation of European Parliament Speeches", "start_pos": 16, "end_pos": 59, "type": "TASK", "confidence": 0.6479597628116608}]}, {"text": "This task is part of an international evaluation organized by the TC-STAR project in 2006.", "labels": [], "entities": [{"text": "TC-STAR project in 2006", "start_pos": 66, "end_pos": 89, "type": "DATASET", "confidence": 0.8679425418376923}]}, {"text": "The proposed method achieves consistent improvements in the BLEU score on the development and test data.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9772205352783203}]}, {"text": "We also present algorithms to improve the estimation of the language model probabilities when splitting long sentences into shorter chunks.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f . Among all possible target sentences the one with maximal probability is chosen.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.8113177369038264}]}, {"text": "The classical Bayes relation is used to introduce a target language model: where Pr(f |e) is the translation model and is the target language model.", "labels": [], "entities": []}, {"text": "This approach is usually referred to as the noisy source-channel approach in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.6956460575262705}]}, {"text": "Since the introduction of this basic model, many improvements have been made, but it seems that research is mainly focused on better translation and alignment models or phrase extraction algorithms as demonstrated by numerous publications on these topics.", "labels": [], "entities": [{"text": "translation and alignment", "start_pos": 133, "end_pos": 158, "type": "TASK", "confidence": 0.8989262382189432}, {"text": "phrase extraction", "start_pos": 169, "end_pos": 186, "type": "TASK", "confidence": 0.8332917094230652}]}, {"text": "On the other hand, we are aware of only a small amount of papers investigating new approaches to language modeling for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 119, "end_pos": 150, "type": "TASK", "confidence": 0.70606729388237}]}, {"text": "Traditionally, statistical machine translation systems use a simple 3-gram back-off language model (LM) during decoding to generate n-best lists.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.6774050494035085}]}, {"text": "These n-best lists are then rescored using a log-linear combination of feature functions: Pr(e) \u03bb 1 Pr(f |e) \u03bb (1) where the coefficients \u03bb i are optimized on a development set, usually maximizing the BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 201, "end_pos": 211, "type": "METRIC", "confidence": 0.9776095449924469}]}, {"text": "In addition to the standard feature functions, many others have been proposed, in particular several ones that aim at improving the modeling of the target language.", "labels": [], "entities": []}, {"text": "In most SMT systems the use of a 4-gram back-off language model usually achieves improvements in the BLEU score in comparison to the 3-gram LM used during decoding.", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9917638301849365}, {"text": "BLEU score", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.9826809465885162}]}, {"text": "It seems however difficult to improve upon the 4-gram LM.", "labels": [], "entities": []}, {"text": "Many different feature functions were explored in ().", "labels": [], "entities": []}, {"text": "In that work, the incorporation of part-of-speech (POS) information gave only a small improvement compared to a 3-gram backoff LM.", "labels": [], "entities": []}, {"text": "In another study, a factored LM using POS information achieved the same results as the 4-gram LM ().", "labels": [], "entities": []}, {"text": "Syntaxbased LMs were investigated in (, and reranking of translation hypothesis using structural properties in ().", "labels": [], "entities": []}, {"text": "An interesting experiment was reported at the NIST 2005 MT evaluation workshop: starting with a 5-gram LM trained on 75 million words of Broadcast News data, again of about 0.5 point BLEU was observed each time when the amount of LM training data was doubled, using at the end 237 billion words of texts.", "labels": [], "entities": [{"text": "NIST 2005 MT evaluation workshop", "start_pos": 46, "end_pos": 78, "type": "DATASET", "confidence": 0.8145406484603882}, {"text": "Broadcast News data", "start_pos": 137, "end_pos": 156, "type": "DATASET", "confidence": 0.9399576187133789}, {"text": "BLEU", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.9990944862365723}]}, {"text": "Most of this additional data was collected by Google on the Internet.", "labels": [], "entities": []}, {"text": "We believe that this kind of approach is difficult to apply to other tasks than Broadcast News and other target languages than English.", "labels": [], "entities": [{"text": "Broadcast News", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.9377238154411316}]}, {"text": "There are many areas where automatic machine translation could be deployed and for which considerably less appropriate in-domain training data is available.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7493107318878174}]}, {"text": "We could for instance mention automatic translation of medical records, translation systems for tourism related tasks or even any task for which Broadcast news and Web texts is of limited help.", "labels": [], "entities": [{"text": "automatic translation of medical records", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.7633777379989624}]}, {"text": "In this work, we consider the translation of European Parliament Speeches from Spanish to English, in the framework of an international evaluation organized by the European TC-STAR project in February 2006.", "labels": [], "entities": [{"text": "translation of European Parliament Speeches from Spanish to English", "start_pos": 30, "end_pos": 97, "type": "TASK", "confidence": 0.8846377266777886}, {"text": "European TC-STAR project in February 2006", "start_pos": 164, "end_pos": 205, "type": "DATASET", "confidence": 0.8655077616373698}]}, {"text": "The training data consists of about 35M words of aligned texts that are also used to train the target LM.", "labels": [], "entities": []}, {"text": "In our experiments, adding more than 580M words of Broadcast News data had no impact on the BLEU score, despite a notable decrease of the perplexity of the target LM.", "labels": [], "entities": [{"text": "Broadcast News data", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.9367422262827555}, {"text": "BLEU score", "start_pos": 92, "end_pos": 102, "type": "METRIC", "confidence": 0.9786749184131622}]}, {"text": "Therefore, we suggest to use more complex statistical LMs that are expected to take better advantage of the limited amount of appropriate training data.", "labels": [], "entities": []}, {"text": "Promising candidates are random forest LMs (), random cluster LMs () and the neural network LM (.", "labels": [], "entities": []}, {"text": "In this paper, we investigate whether the latter approach can be used in a statistical machine translation system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.646298329035441}]}, {"text": "The basic idea of the neural network LM, also called continuous space LM, is to project the word indices onto a continuous space and to use a probability estimator operating on this space.", "labels": [], "entities": []}, {"text": "Since the resulting probability functions are smooth functions of the word representation, better generalization to unknown n-grams can be expected.", "labels": [], "entities": []}, {"text": "A neural network can be used to simultaneously learn the projection of the words onto the continuous space and to estimate the n-gram probabilities.", "labels": [], "entities": []}, {"text": "This is still a n-gram approach, but the LM posterior probabilities are \"interpolated\" for any possible context of length n-1 instead of backing-off to shorter contexts.", "labels": [], "entities": []}, {"text": "This approach was successfully used in large vocabulary speech recognition (), and we are interested here if similar ideas can be applied to statistical machine translation.", "labels": [], "entities": [{"text": "large vocabulary speech recognition", "start_pos": 39, "end_pos": 74, "type": "TASK", "confidence": 0.5984734892845154}, {"text": "statistical machine translation", "start_pos": 141, "end_pos": 172, "type": "TASK", "confidence": 0.6605527400970459}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section we first describe the baseline statistical machine translation system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.6093655029932658}]}, {"text": "Section 3 presents the architecture of the continuous space LM and section 4 summarizes the experimental evaluation.", "labels": [], "entities": []}, {"text": "The paper concludes with a discussion of future research directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental results provided here were obtained in the framework of an international evaluation organized by the European TC-STAR project in February 2006.", "labels": [], "entities": [{"text": "European TC-STAR project in February 2006", "start_pos": 118, "end_pos": 159, "type": "DATASET", "confidence": 0.9088075558344523}]}, {"text": "This project is envisaged as a long-term effort to advance research in all core technologies for speech-to-speech translation.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 97, "end_pos": 125, "type": "TASK", "confidence": 0.7366307377815247}]}, {"text": "The main goal of this evaluation is to translate public European Parliament Plenary Sessions (EPPS).", "labels": [], "entities": [{"text": "European Parliament Plenary Sessions (EPPS)", "start_pos": 56, "end_pos": 99, "type": "DATASET", "confidence": 0.6347257792949677}]}, {"text": "The training material consists of the minutes edited by the European Parliament in several languages, also known as the Final Text Editions ().", "labels": [], "entities": [{"text": "Final Text Editions", "start_pos": 120, "end_pos": 139, "type": "DATASET", "confidence": 0.655263622601827}]}, {"text": "These texts were aligned at the sentence level and they are used to train the statistical translation models (see: Statistics of the parallel texts used to train the statistical machine translation system.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7425732314586639}, {"text": "statistical machine translation", "start_pos": 166, "end_pos": 197, "type": "TASK", "confidence": 0.6207014620304108}]}, {"text": "the speech recognizers, but the transcriptions were also used for the target LM of the translation system (about 740k words).", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.6784929037094116}]}, {"text": "Three different conditions are considered in the TC-STAR evaluation: translation of the Final Text Edition (text), translation of the transcriptions of the acoustic development data (verbatim) and translation of speech recognizer output (ASR).", "labels": [], "entities": [{"text": "TC-STAR", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.8507484793663025}, {"text": "translation", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.9529983401298523}, {"text": "translation of speech recognizer output (ASR", "start_pos": 197, "end_pos": 241, "type": "TASK", "confidence": 0.7548098734446934}]}, {"text": "Here we only consider the verbatim condition, translating from Spanish to English.", "labels": [], "entities": []}, {"text": "For this task, the development data consists of 792 sentences (25k words) and the evaluation data of 1597 sentences (61k words).", "labels": [], "entities": []}, {"text": "Parts of the test data origins from the Spanish parliament which results in a (small) mismatch between the development and test data.", "labels": [], "entities": []}, {"text": "Two reference translations are provided.", "labels": [], "entities": []}, {"text": "The scoring is case sensitive and includes punctuation symbols.", "labels": [], "entities": []}, {"text": "The translation model was trained on 1.2M sentences of parallel text using the Giza++ tool.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9769918322563171}]}, {"text": "All back-off LMs were built using modified KneserNey smoothing and the SRI LM-toolkit).", "labels": [], "entities": [{"text": "SRI LM-toolkit", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.9244781136512756}]}, {"text": "Separate LMs were first trained on the English EPPS texts (33.8M words) and the transcriptions of the acoustic training material (740k words) respectively.", "labels": [], "entities": [{"text": "English EPPS texts", "start_pos": 39, "end_pos": 57, "type": "DATASET", "confidence": 0.8488390644391378}]}, {"text": "These two LMs were then interpolated together.", "labels": [], "entities": []}, {"text": "Interpolation usually results in lower perplexities than training directly one LM on the pooled data, in particular if the corpora come from different sources.", "labels": [], "entities": []}, {"text": "An EM procedure was used to find the interpolation coefficients that minimize the perplexity on the development data.", "labels": [], "entities": [{"text": "EM", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.7279060482978821}]}, {"text": "The optimal coefficients are 0.78 for the Final Text edition and 0.22 for the transcriptions.", "labels": [], "entities": [{"text": "Final Text edition", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.9209845264752706}]}], "tableCaptions": [{"text": " Table 2: BLEU scores for different ways to trans- late sentence chunks and to extract the global so- lution (see text for details).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991426467895508}, {"text": "trans- late sentence chunks", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.5791498780250549}]}, {"text": " Table 3: Result comparison for the different LMs.  BLEU uses 2 reference translations. WER=word  error rate, PER=position independent WER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9747449159622192}, {"text": "WER", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9829351305961609}, {"text": "word  error rate", "start_pos": 92, "end_pos": 108, "type": "METRIC", "confidence": 0.7992039124170939}, {"text": "PER", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.9779688715934753}, {"text": "position independent WER", "start_pos": 114, "end_pos": 138, "type": "METRIC", "confidence": 0.6208388209342957}]}]}