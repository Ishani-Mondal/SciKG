{"title": [{"text": "Towards Conversational QA: Automatic Identification of Problematic Situations and User Intent *", "labels": [], "entities": [{"text": "Automatic Identification of Problematic Situations", "start_pos": 27, "end_pos": 77, "type": "TASK", "confidence": 0.7666288316249847}]}], "abstractContent": [{"text": "To enable conversational QA, it is important to examine key issues addressed in conversational systems in the context of question answering.", "labels": [], "entities": [{"text": "conversational QA", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.5797305405139923}, {"text": "question answering", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.8262870013713837}]}, {"text": "In conversational systems , understanding user intent is critical to the success of interaction.", "labels": [], "entities": []}, {"text": "Recent studies have also shown that the capability to automatically identify problematic situations during interaction can significantly improve the system performance.", "labels": [], "entities": []}, {"text": "Therefore, this paper investigates the new implications of user intent and problematic situations in the context of question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.8657749593257904}]}, {"text": "Our studies indicate that, in basic interactive QA, there are different types of user intent that are tied to different kinds of system performance (e.g., problematic/error free situations).", "labels": [], "entities": []}, {"text": "Once users are motivated to find specific information related to their information goals, the interaction context can provide useful cues for the system to automatically identify problematic situations and user intent.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interactive question answering (QA) has been identified as one of the important directions in QA research ().", "labels": [], "entities": [{"text": "Interactive question answering (QA)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8055054545402527}]}, {"text": "One ultimate goal is to support intelligent conversation between a user and a QA system to better facilitate user information needs.", "labels": [], "entities": []}, {"text": "However, except fora few systems that use dialog to address complex questions (), the general dialog capabilities have been lacking inmost ques-tion answering systems.", "labels": [], "entities": []}, {"text": "To move towards conversational QA, it is important to examine key issues relevant to conversational systems in the context of interactive question answering.", "labels": [], "entities": [{"text": "conversational QA", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.6356474459171295}, {"text": "question answering", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7035644054412842}]}, {"text": "This paper focuses on two issues related to conversational QA.", "labels": [], "entities": [{"text": "conversational QA", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7294993102550507}]}, {"text": "The first issue is concerned with user intent.", "labels": [], "entities": []}, {"text": "In conversational systems, understanding user intent is the key to the success of the interaction.", "labels": [], "entities": []}, {"text": "In the context of interactive QA, one question is what type of user intent should be captured.", "labels": [], "entities": []}, {"text": "Unlike most dialog systems where user intent can be characterized by dialog acts such as question, reply, and statement, in interactive QA, user inputs are already in the form of question.", "labels": [], "entities": []}, {"text": "Then the problems become whether there are different types of intent behind these questions that should be handled differently by a QA system and how to automatically identify them.", "labels": [], "entities": []}, {"text": "The second issue is concerned with problematic situations during interaction.", "labels": [], "entities": []}, {"text": "In spoken dialog systems, many problematic situations could arise from insufficient speech recognition and language understanding performance.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7416202127933502}]}, {"text": "Recent work has shown that the capability to automatically identify problematic situations (e.g., speech recognition errors) can help control and adapt dialog strategies to improve performance).", "labels": [], "entities": []}, {"text": "Similarly, QA systems also face challenges of technology limitation from language understanding and information retrieval.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7290654182434082}, {"text": "information retrieval", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.7718574106693268}]}, {"text": "Thus one question is, in the context of interactive QA, how to characterize problematic situations and automatically identify them when they occur.", "labels": [], "entities": []}, {"text": "In interactive QA, these two issues are intertwined.", "labels": [], "entities": []}, {"text": "Questions formed by a user not only depend on his/her information goals, but are also influenced by the answers from the system.", "labels": [], "entities": []}, {"text": "Problematic situations will impact user intent in the follow-up questions, which will further influence system performance.", "labels": [], "entities": []}, {"text": "Both the awareness of problematic situations and understanding of user intent will allow QA systems to adapt better strategies during interaction and move towards intelligent conversational QA.", "labels": [], "entities": []}, {"text": "To address these two questions, we conducted a user study where users interacted with a controlled QA system to find information of interest.", "labels": [], "entities": []}, {"text": "These controlled studies allowed us to focus on the interaction aspect rather than information retrieval or answer extraction aspects.", "labels": [], "entities": [{"text": "information retrieval or answer extraction", "start_pos": 83, "end_pos": 125, "type": "TASK", "confidence": 0.7163251280784607}]}, {"text": "Our studies indicate that in basic interactive QA where users always ask questions and the system always provides some kind of answers, there are different types of user intent that are tied to different kinds of system performance (e.g., problematic/error free situations).", "labels": [], "entities": []}, {"text": "Once users are motivated to find specific information related to their information goals, the interaction context can provide useful cues for the system to automatically identify problematic situations and user intent.", "labels": [], "entities": []}], "datasetContent": [{"text": "Eleven users participated in our study.", "labels": [], "entities": []}, {"text": "Each user was asked to interact with our system to complete information seeking tasks related to four specific scenarios: the 2004 presidential debates, Tom Cruise, Hawaii, and Pompeii.", "labels": [], "entities": []}, {"text": "The experimental scenarios were further divided into two types: structured and unstructured.", "labels": [], "entities": []}, {"text": "In the structured task scenarios (for topics Tom Cruise and Pompeii), users had to fill in blanks on a diagram pertaining to the given topic.", "labels": [], "entities": []}, {"text": "Using the diagram was to avoid the influence of these scenarios on the language formation of the relevant questions.", "labels": [], "entities": [{"text": "language formation", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7158726900815964}]}, {"text": "Because users must find certain information, they were constrained in the range of questions in which they could ask, but not the way they ask those questions.", "labels": [], "entities": []}, {"text": "The task was completed when all of the blanks on the diagram were filled.", "labels": [], "entities": []}, {"text": "The structured scenarios were designed to mimic the real information seeking practice in which users have real motivation to find specific information related to their information goals.", "labels": [], "entities": []}, {"text": "In the unstructured scenarios (for topics the 2004 presidential debates and Hawaii), users were given a general topic to investigate, but were not required to find specific information.", "labels": [], "entities": []}, {"text": "This gave the user the ability to ask a much wider range of questions than the structured scenarios.", "labels": [], "entities": []}, {"text": "Users were generally in an exploration mode when performing these unstructured tasks.", "labels": [], "entities": []}, {"text": "They were not motivated to find specific information and were content with any information provided by the system.", "labels": [], "entities": []}, {"text": "In our view, the unstructured scenarios are less representative of the true information seeking situations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Categorization of user intent with the cor- responding number of occurrences from the un- structured scenarios, the structured scenarios, and  the entire dataset.", "labels": [], "entities": []}, {"text": " Table 2: Performance of automatic identification of problematic situations", "labels": [], "entities": [{"text": "automatic identification of problematic situations", "start_pos": 25, "end_pos": 75, "type": "TASK", "confidence": 0.7869510531425477}]}, {"text": " Table 3: Performance of automatic identification  of user intent", "labels": [], "entities": []}]}