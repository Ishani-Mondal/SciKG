{"title": [{"text": "Direct Word Sense Matching for Lexical Substitution", "labels": [], "entities": [{"text": "Direct Word Sense Matching", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.5474188476800919}, {"text": "Lexical Substitution", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7350687384605408}]}], "abstractContent": [{"text": "This paper investigates conceptually and empirically the novel sense matching task, which requires to recognize whether the senses of two synonymous words match in context.", "labels": [], "entities": [{"text": "sense matching task", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7773717840512594}]}, {"text": "We suggest direct approaches to the problem, which avoid the intermediate step of explicit word sense disambigua-tion, and demonstrate their appealing advantages and stimulating potential for future research.", "labels": [], "entities": [{"text": "explicit word sense disambigua-tion", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.6034387052059174}]}], "introductionContent": [{"text": "In many language processing settings it is needed to recognize that a given word or term maybe substituted by a synonymous one.", "labels": [], "entities": []}, {"text": "Ina typical information seeking scenario, an information need is specified by some given source words.", "labels": [], "entities": [{"text": "information seeking", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7992965877056122}]}, {"text": "When looking for texts that match the specified need the source words might be substituted with synonymous target words.", "labels": [], "entities": []}, {"text": "For example, given the source word 'weapon' a system may substitute it with the target synonym 'arm'.", "labels": [], "entities": []}, {"text": "This scenario, which is generally referred here as lexical substitution, is a common technique for increasing recall in Natural Language Processing (NLP) applications.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.7600639462471008}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.971881091594696}]}, {"text": "In Information Retrieval (IR) and Question Answering (QA) it is typically termed query/question expansion).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.8585551738739013}, {"text": "Question Answering (QA)", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8558815002441407}, {"text": "query/question expansion", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6586452275514603}]}, {"text": "Lexical Substitution is also commonly applied to identify synonyms in text summarization, for paraphrasing in text generation, or is integrated into the features of supervised tasks such as Text Categorization and Information Extraction.", "labels": [], "entities": [{"text": "Lexical Substitution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8801736831665039}, {"text": "text summarization", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.6709705293178558}, {"text": "text generation", "start_pos": 110, "end_pos": 125, "type": "TASK", "confidence": 0.6995056867599487}, {"text": "Text Categorization", "start_pos": 190, "end_pos": 209, "type": "TASK", "confidence": 0.7531045079231262}, {"text": "Information Extraction", "start_pos": 214, "end_pos": 236, "type": "TASK", "confidence": 0.7835412621498108}]}, {"text": "Naturally, lexical substitution is a very common first step in textual entailment recognition, which models semantic inference between a pair of texts in a generalized application independent setting ().", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.7526576817035675}, {"text": "textual entailment recognition", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.8046864767869314}]}, {"text": "To perform lexical substitution NLP applications typically utilize a knowledge source of synonymous word pairs.", "labels": [], "entities": [{"text": "lexical substitution NLP", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.7740641037623087}]}, {"text": "The most commonly used resource for lexical substitution is the manually constructed WordNet.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7309659123420715}, {"text": "WordNet", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.957740306854248}]}, {"text": "Another option is to use statistical word similarities, such as in the database constructed by Dekang Lin.", "labels": [], "entities": []}, {"text": "We generically refer to such resources as substitution lexicons.", "labels": [], "entities": []}, {"text": "When using a substitution lexicon it is assumed that there are some contexts in which the given synonymous words share the same meaning.", "labels": [], "entities": []}, {"text": "Yet, due to polysemy, it is needed to verify that the senses of the two words do indeed match in a given context.", "labels": [], "entities": []}, {"text": "For example, there are contexts in which the source word 'weapon' maybe substituted by the target word 'arm'; however one should recognize that 'arm' has a different sense than 'weapon' in sentences such as \"repetitive movements could cause injuries to hands, wrists and arms.\"", "labels": [], "entities": []}, {"text": "A commonly proposed approach to address sense matching in lexical substitution is applying Word Sense Disambiguation (WSD) to identify the senses of the source and target words.", "labels": [], "entities": [{"text": "sense matching in lexical substitution", "start_pos": 40, "end_pos": 78, "type": "TASK", "confidence": 0.6990933060646057}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 91, "end_pos": 122, "type": "TASK", "confidence": 0.7086903154850006}]}, {"text": "Then, substitution is applied only if the words have the same sense (or synset, in WordNet terminology).", "labels": [], "entities": []}, {"text": "In settings in which the source is given as a single term without context, sense disambiguation is performed only for the target word; substitution is then applied only if the target word's sense matches at least one of the possible senses of the source word.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.6639511436223984}]}, {"text": "One might observe that such application of WSD addresses the task at hand in a somewhat indirect manner.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9628103971481323}]}, {"text": "In fact, lexical substitution only requires knowing that the source and target senses do match, but it does not require that the matching senses will be explicitly identified.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.8801811039447784}]}, {"text": "Selecting explicitly the right sense in context, which is then followed by verifying the desired matching, might be solving a harder intermediate problem than required.", "labels": [], "entities": []}, {"text": "Instead, we can define the sense matching problem directly as a binary classification task fora pair of synonymous source and target words.", "labels": [], "entities": [{"text": "sense matching problem", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.8003934522469839}]}, {"text": "This task requires to decide whether the senses of the two words door do not match in a given context (but it does not require to identify explicitly the identity of the matching senses).", "labels": [], "entities": []}, {"text": "A highly related task was proposed in).", "labels": [], "entities": []}, {"text": "McCarthy's proposal was to ask systems to suggest possible \"semantically similar replacements\" of a target word in context, where alternative replacements should be grouped together.", "labels": [], "entities": []}, {"text": "While this task is somewhat more complicated as an evaluation setting than our binary recognition task, it was motivated by similar observations and applied goals.", "labels": [], "entities": [{"text": "binary recognition task", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.8061610460281372}]}, {"text": "From another perspective, sense matching maybe viewed as a lexical sub-case of the general textual entailment recognition setting, where we need to recognize whether the meaning of the target word \"entails\" the meaning of the source word in a given context.", "labels": [], "entities": [{"text": "sense matching", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.7882211804389954}, {"text": "textual entailment recognition", "start_pos": 91, "end_pos": 121, "type": "TASK", "confidence": 0.670553853114446}]}, {"text": "This paper provides a first investigation of the sense matching problem.", "labels": [], "entities": [{"text": "sense matching problem", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.8799107869466146}]}, {"text": "To allow comparison with the classical WSD setting we derived an evaluation dataset for the new problem from the Senseval-3 English lexical sample dataset).", "labels": [], "entities": [{"text": "Senseval-3 English lexical sample dataset", "start_pos": 113, "end_pos": 154, "type": "DATASET", "confidence": 0.875292432308197}]}, {"text": "We then evaluated alternative supervised and unsupervised methods that perform sense matching either indirectly or directly (i.e. with or without the intermediate sense identification step).", "labels": [], "entities": [{"text": "sense matching", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.8065610826015472}, {"text": "sense identification", "start_pos": 163, "end_pos": 183, "type": "TASK", "confidence": 0.7416914105415344}]}, {"text": "Our findings suggest that in the supervised setting the results of the direct and indirect approaches are comparable.", "labels": [], "entities": []}, {"text": "However, addressing directly the binary classification task has practical advantages and can yield high precision values, as desired in precision-oriented applications such as IR and QA.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.785738468170166}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9619948863983154}]}, {"text": "More importantly, direct sense matching sets the ground for implicit unsupervised approaches that may utilize practically unlimited volumes of unlabeled training data.", "labels": [], "entities": [{"text": "direct sense matching", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.6193236311276754}]}, {"text": "Furthermore, such approaches circumvent the sisyphean need for specifying explicitly a set of stipulated senses.", "labels": [], "entities": []}, {"text": "We present an initial implementation of such an approach using a one-class classifier, which is trained on unlabeled occurrences of the source word and applied to occurrences of the target word.", "labels": [], "entities": []}, {"text": "Our current results outperform the unsupervised baseline and put forth a whole new direction for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "To investigate the direct sense matching problem it is necessary to obtain an appropriate dataset of examples for this binary classification task, along with gold standard annotation.", "labels": [], "entities": [{"text": "direct sense matching", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.6662078499794006}, {"text": "binary classification task", "start_pos": 119, "end_pos": 145, "type": "TASK", "confidence": 0.7528761625289917}]}, {"text": "While there is no such standard (application independent) dataset available it is possible to derive it automatically from existing WSD evaluation datasets, as described below.", "labels": [], "entities": [{"text": "WSD evaluation datasets", "start_pos": 132, "end_pos": 155, "type": "DATASET", "confidence": 0.7972569465637207}]}, {"text": "This methodology also allows comparing direct approaches for sense matching with classical indirect approaches, which apply an intermediate step of identifying the most likely WordNet sense.", "labels": [], "entities": [{"text": "sense matching", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.7201534509658813}]}, {"text": "We derived our dataset from the Senseval-3 English lexical sample dataset), taking all 25 nouns, adjectives and adverbs in this sample.", "labels": [], "entities": [{"text": "Senseval-3 English lexical sample dataset", "start_pos": 32, "end_pos": 73, "type": "DATASET", "confidence": 0.8659314751625061}]}, {"text": "Verbs were excluded since their sense annotation in Senseval-3 is not based on WordNet senses.", "labels": [], "entities": []}, {"text": "The Senseval dataset includes a set of example occurrences in context for each word, split to training and test sets, where each example is manually annotated with the corresponding WordNet synset.", "labels": [], "entities": [{"text": "Senseval dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8049558103084564}]}, {"text": "For the sense matching setting we need examples of pairs of source-target synonymous words, whereat least one of these words should occur in a given context.", "labels": [], "entities": [{"text": "sense matching", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.7663162350654602}]}, {"text": "Following an applicative motivation, we mimic an IR setting in which a single source word query is expanded (substituted) by a synonymous target word.", "labels": [], "entities": [{"text": "IR setting", "start_pos": 49, "end_pos": 59, "type": "TASK", "confidence": 0.8937153518199921}]}, {"text": "Then, it is needed to identify contexts in which the target word appears in a sense that matches the source word.", "labels": [], "entities": []}, {"text": "Accordingly, we considered each of the 25 words in the Senseval sample as a target word for the sense matching task.", "labels": [], "entities": [{"text": "sense matching task", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.8412460088729858}]}, {"text": "Next, we had to pick for each target word a corresponding synonym to play the role of the source word.", "labels": [], "entities": []}, {"text": "This was done by creating a list of all WordNet synonyms of the target word, under all its possible senses, and picking randomly one of the synonyms as the source word.", "labels": [], "entities": []}, {"text": "For example, the word 'disc' is one of the words in the Senseval lexical sample.", "labels": [], "entities": [{"text": "Senseval lexical sample", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.9352100690205892}]}, {"text": "For this target word the synonym 'record' was picked, which matches 'disc' in its musical sense.", "labels": [], "entities": []}, {"text": "Overall, 59% of all possible synsets of our target words included an additional synonym, which could play the role of the source word (that is, 41% of the synsets consisted of the target word only).", "labels": [], "entities": []}, {"text": "Similarly, 62% of the test examples of the target words were annotated by a synset that included an additional synonym.", "labels": [], "entities": []}, {"text": "While creating source-target synonym pairs it was evident that many WordNet synonyms correspond to very infrequent senses or word usages, such as the WordNet synonyms germ and source.", "labels": [], "entities": []}, {"text": "Such source synonyms are useless for evaluating sense matching with the target word since the senses of the two words would rarely match in perceivable contexts.", "labels": [], "entities": [{"text": "sense matching", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.6746601462364197}]}, {"text": "In fact, considering our motivation for lexical substitution, it is usually desired to exclude such obscure synonym pairs from substitution lexicons in practical applications, since they would mostly introduce noise to the system.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.715239405632019}]}, {"text": "To avoid this problem the list of WordNet synonyms for each target word was filtered by a lexicographer, who excluded manually obscure synonyms that seemed worthless in practice.", "labels": [], "entities": []}, {"text": "The source synonym for each target word was then picked randomly from the filtered list.", "labels": [], "entities": []}, {"text": "shows the 25 source-target pairs created for our experiments.", "labels": [], "entities": []}, {"text": "In future work it maybe possible to apply automatic methods for filtering infrequent sense correspondences in the dataset, by adopting algorithms such as in ().", "labels": [], "entities": []}, {"text": "Having source-target synonym pairs, a classification instance for the sense matching task is created from each example occurrence of the target word in the Senseval dataset.", "labels": [], "entities": [{"text": "sense matching task", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8285703063011169}, {"text": "Senseval dataset", "start_pos": 156, "end_pos": 172, "type": "DATASET", "confidence": 0.8461796641349792}]}, {"text": "A classification instance is thus defined by a pair of source and target words and a given occurrence of the target word in context.", "labels": [], "entities": []}, {"text": "The instance should be classified as positive if the sense of the target word in the given context matches one of the possible senses of the source word, and as negative otherwise.", "labels": [], "entities": []}, {"text": "illustrates positive and negative example instances for the source-target synonym pair 'record-disc', where only occurrences of 'disc' in the musical sense are considered positive.", "labels": [], "entities": []}, {"text": "The gold standard annotation for the binary sense matching task can be derived automatically from the Senseval annotations and the corresponding WordNet synsets.", "labels": [], "entities": [{"text": "binary sense matching task", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.7254099920392036}, {"text": "WordNet synsets", "start_pos": 145, "end_pos": 160, "type": "DATASET", "confidence": 0.9301568865776062}]}, {"text": "An example occurrence of the target word is considered positive if the annotated synset for that example includes also the source word, and Negative otherwise.", "labels": [], "entities": []}, {"text": "Notice that different positive examples might correspond to different senses of the target word.", "labels": [], "entities": []}, {"text": "This happens when the source and target share several senses, and hence they appear together in several synsets.", "labels": [], "entities": []}, {"text": "Finally, since in Senseval an example maybe an-source-target source-target source-target source-target source-target statement-argument subdivision-arm atm-atmosphere hearing-audience camber-bank level-degree deviation-difference dissimilar-different trouble-difficulty record-disc raging-hot ikon-image crucial-important sake-interest bare-simple opinion-judgment arrangement-organization newspaper-paper company-party substantial-solid execution-performance design-plan protection-shelter variety-sort root-source: Source and target pairs sentence annotation This is anyway a stunning disc, thanks to the playing of the Moscow Virtuosi with Spivakov.", "labels": [], "entities": []}, {"text": "positive He said computer networks would not be affected and copies of information should be made on floppy discs.", "labels": [], "entities": []}, {"text": "In the lexical substitution (and expansion) setting, the standard WSD metrics) are not suitable, because we are interested in the binary decision of whether the target word matches the sense of a given source word.", "labels": [], "entities": []}, {"text": "In analogy to IR, we are more interested in positive assignments, while the opposite case (i.e. when the two words cannot be substituted) is less interesting.", "labels": [], "entities": [{"text": "IR", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.9811593294143677}]}, {"text": "Accordingly, we utilize the standard definitions of precision, recall and F 1 typically used in IR benchmarks.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.99965500831604}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9994127750396729}, {"text": "F 1", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9851078391075134}, {"text": "IR", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.9657820463180542}]}, {"text": "In the rest of this section we will report micro averages for these measures on the test set described in Section 3.", "labels": [], "entities": []}, {"text": "Following the Senseval methodology, we evaluated two different baselines for unsupervised and supervised methods.", "labels": [], "entities": []}, {"text": "The random baseline, used for the unsupervised algorithms, was obtained by choosing either the positive or the negative class at random resulting in P = 0.262, R = 0.5, F 1 = 0.344.", "labels": [], "entities": [{"text": "F 1", "start_pos": 169, "end_pos": 172, "type": "METRIC", "confidence": 0.9781274795532227}]}, {"text": "The Most Frequent baseline has been used for the supervised algorithms and is obtained by assigning the positive class when the Freely available from www.csie.ntu.edu.tw/ /\u223ccjlin/libsvm.", "labels": [], "entities": []}, {"text": "percentage of positive examples in the training set is above 50%, resulting in P = 0.65, R = 0.41, F 1 = 0.51.", "labels": [], "entities": [{"text": "P", "start_pos": 79, "end_pos": 80, "type": "METRIC", "confidence": 0.9585544466972351}, {"text": "R", "start_pos": 89, "end_pos": 90, "type": "METRIC", "confidence": 0.9823933839797974}, {"text": "F 1", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9846735298633575}]}], "tableCaptions": [{"text": " Table 3: Classification results on the sense matching task", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9660387635231018}, {"text": "sense matching", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.9083503782749176}]}]}