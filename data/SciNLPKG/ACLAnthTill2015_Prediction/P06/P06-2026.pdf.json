{"title": [{"text": "Chinese-English Term Translation Mining Based on Semantic Prediction", "labels": [], "entities": [{"text": "Term Translation", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7858502566814423}]}], "abstractContent": [{"text": "Using abundant Web resources to mine Chinese term translations can be applied in many fields such as reading/writing assistant , machine translation and cross-language information retrieval.", "labels": [], "entities": [{"text": "mine Chinese term translations", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.6077119708061218}, {"text": "machine translation", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.8323845267295837}, {"text": "cross-language information retrieval", "start_pos": 153, "end_pos": 189, "type": "TASK", "confidence": 0.7398101290067037}]}, {"text": "In mining English translations of Chinese terms, how to obtain effective Web pages and evaluate translation candidates are two challenging issues.", "labels": [], "entities": []}, {"text": "In this paper, the approach based on semantic prediction is first proposed to obtain effective Web pages.", "labels": [], "entities": [{"text": "semantic prediction", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8073391616344452}]}, {"text": "The proposed method predicts possible English meanings according to each constituent unit of Chinese term, and expands these English items using semantically relevant knowledge for searching.", "labels": [], "entities": []}, {"text": "The refined related terms are extracted from top retrieved documents through feedback learning to construct anew query expansion for acquiring more effective Web pages.", "labels": [], "entities": []}, {"text": "For obtaining a correct translation list, a translation evaluation method in the weighted sum of multi-features is presented to rank these candidates estimated from effective Web pages.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate that the proposed method has good performance in Chinese-English term translation acquisition, and achieves 82.9% accuracy.", "labels": [], "entities": [{"text": "Chinese-English term translation acquisition", "start_pos": 82, "end_pos": 126, "type": "TASK", "confidence": 0.6841285452246666}, {"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9899196624755859}]}], "introductionContent": [{"text": "The goal of Web-based Chinese-English (C-E) term translation mining is to acquire translations of terms or proper nouns which cannot be looked up in the dictionary from the Web using a statistical method, and then construct an application system for reading/writing assistant (e.g., \u4e09\u56fd\u6f14 \u4e49AEThe Romance of Three Kingdoms).", "labels": [], "entities": [{"text": "Web-based Chinese-English (C-E) term translation mining", "start_pos": 12, "end_pos": 67, "type": "TASK", "confidence": 0.6241847462952137}]}, {"text": "During translating or writing foreign language articles, people usually encounter terms, but they cannot obtain native translations after many lookup efforts.", "labels": [], "entities": [{"text": "translating or writing foreign language articles", "start_pos": 7, "end_pos": 55, "type": "TASK", "confidence": 0.7881212830543518}]}, {"text": "Some skilled users perhaps resort to a Web search engine, but a large amount of retrieved irrelevant pages and redundant information hamper them to acquire effective information.", "labels": [], "entities": []}, {"text": "Thus, it is necessary to provide a system to automatically mine translation knowledge of terms using abundant Web information so as to help users accurately read or write foreign language articles.", "labels": [], "entities": []}, {"text": "The system of Web-based term translation mining has many applications.", "labels": [], "entities": [{"text": "term translation mining", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.7610966463883718}]}, {"text": "1) Reading/writing assistant.", "labels": [], "entities": [{"text": "Reading/writing", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.8419171770413717}]}, {"text": "2) The construction tool of bilingual or multilingual dictionary for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7787092626094818}]}, {"text": "The system cannot only provide translation candidates for compiling a lexicon, but also rescore the candidate list of the dictionary.", "labels": [], "entities": []}, {"text": "We can also use English as a medium language to build a lexicon translation bridge between two languages with few bilingual annotations (e.g., Japanese and Chinese).", "labels": [], "entities": []}, {"text": "3) Provide the translations of unknown queries in crosslanguage information retrieval (CLIR).", "labels": [], "entities": [{"text": "translations of unknown queries", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.8543807864189148}, {"text": "crosslanguage information retrieval (CLIR)", "start_pos": 50, "end_pos": 92, "type": "TASK", "confidence": 0.7196495831012726}]}, {"text": "4) As one of the typical application paradigms of the combination of CLIR and Web mining.", "labels": [], "entities": [{"text": "Web mining", "start_pos": 78, "end_pos": 88, "type": "TASK", "confidence": 0.6522503942251205}]}, {"text": "Automatic acquisition of bilingual translations has been extensively researched in the literature.", "labels": [], "entities": [{"text": "Automatic acquisition of bilingual translations", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7212686657905578}]}, {"text": "The methods of acquiring translations are usually summarized as the following six categories.", "labels": [], "entities": []}, {"text": "1) Acquiring translations from parallel corpora.", "labels": [], "entities": [{"text": "Acquiring translations from parallel corpora", "start_pos": 3, "end_pos": 47, "type": "TASK", "confidence": 0.8673735141754151}]}, {"text": "To reduce the workload of manual annotations, researchers have proposed different methods to automatically collect parallel corpora of different language versions from the Web.", "labels": [], "entities": []}, {"text": "2) Acquiring translations from nonparallel corpora.", "labels": [], "entities": [{"text": "Acquiring translations from nonparallel corpora", "start_pos": 3, "end_pos": 50, "type": "TASK", "confidence": 0.8524442553520203}]}, {"text": "It is based on the clue that the context of source term is very similar to that of target translation in a large amount of corpora.", "labels": [], "entities": []}, {"text": "3) Acquiring translations from a combination of translations of constituent words ().", "labels": [], "entities": [{"text": "Acquiring translations from a combination of translations of constituent words", "start_pos": 3, "end_pos": 81, "type": "TASK", "confidence": 0.8503924548625946}]}, {"text": "4) Acquiring translations using cognate matching or transliteration ().", "labels": [], "entities": [{"text": "Acquiring translations", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.840207576751709}]}, {"text": "This method is very suitable for the translation between two languages with some intrinsic relationships, e.g., acquiring translations from Japanese to Chinese or from Korean to English.", "labels": [], "entities": []}, {"text": "5) Acquiring translations using anchor text information ().", "labels": [], "entities": [{"text": "Acquiring translations", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.8635132908821106}]}, {"text": "6) Acquiring translations from the Web.", "labels": [], "entities": [{"text": "Acquiring translations from the Web", "start_pos": 3, "end_pos": 38, "type": "TASK", "confidence": 0.8717447638511657}]}, {"text": "When people use Asia language (Chinese, Japanese, and Korean) to write, they often annotate associated English meanings after terms.", "labels": [], "entities": []}, {"text": "With the development of Web and the open of accessible electronic documents, digital library, and scientific articles, these resources will become more and more abundant.", "labels": [], "entities": []}, {"text": "Thus, acquiring term translations from the Web is a feasible and effective way.", "labels": [], "entities": [{"text": "acquiring term translations from the Web", "start_pos": 6, "end_pos": 46, "type": "TASK", "confidence": 0.8132910629113516}]}, {"text": "proposed an empirical function of the byte distance between Japanese and English terms as an evaluation criterion to extract translations of Japanese words, and the results could be used as a Japanese-English dictionary.", "labels": [], "entities": []}, {"text": "utilized the Web as the corpus source to translate English unknown queries for CLIR.", "labels": [], "entities": []}, {"text": "They proposed context-vector and chi-square methods to determine Chinese translations for unknown query terms via mining of top 100 search-result pages from Web search engines.", "labels": [], "entities": []}, {"text": "proposed using a Web search engine to obtain translations of Chinese out-of-vocabulary terms from the Web to improve CLIR performance.", "labels": [], "entities": []}, {"text": "The method used Chinese as query items, and retrieved previous 100 document snippets by Google, and then estimated possible translations using co-occurrence information.", "labels": [], "entities": []}, {"text": "From the review above, we know that previous related researches didn't concern the issue how to obtain effective Web pages with bilingual annotations, and they mainly utilized the frequency feature as the clue to mine the translation.", "labels": [], "entities": []}, {"text": "In fact, previous 100 Web results seldom contain effective English equivalents.", "labels": [], "entities": []}, {"text": "Apart from the frequency information, there are some other features such as distribution, length ratio, distance, keywords, key symbols and boundary information which have very important impacts on term translation mining.", "labels": [], "entities": [{"text": "term translation mining", "start_pos": 198, "end_pos": 221, "type": "TASK", "confidence": 0.8143483599026998}]}, {"text": "In this paper, the approach based on semantic prediction is proposed to obtain effective Web pages; for acquiring a correct translation list, the evaluation strategy in the weighted sum of multi-features is employed to rank the candidates.", "labels": [], "entities": [{"text": "semantic prediction", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7613129317760468}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we give an overview of the system.", "labels": [], "entities": []}, {"text": "Section 3 proposes effective Web page collection.", "labels": [], "entities": [{"text": "Web page collection", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7051116824150085}]}, {"text": "In Section 4, we introduce translation candidate construction and noise solution.", "labels": [], "entities": [{"text": "translation candidate construction", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.927653988202413}]}, {"text": "Section 5 presents candidate evaluation based on multi-features.", "labels": [], "entities": []}, {"text": "Section 6 shows experimental results.", "labels": [], "entities": []}, {"text": "The conclusion is drawn in the last section.", "labels": [], "entities": []}], "datasetContent": [{"text": "After translation noise handling, we evaluate candidate translations so that possible candidates get higher scores.", "labels": [], "entities": [{"text": "translation noise handling", "start_pos": 6, "end_pos": 32, "type": "TASK", "confidence": 0.8440348108609518}]}, {"text": "The method in the weighted sum of multi-features including: candidate frequency, distribution, length ratio, distance, keywords, key symbols and boundary information between S-T, is proposed to rank the candidates.", "labels": [], "entities": []}, {"text": "The evaluation method is formulized as follows: In the equation, Score(t) is proportional to . If the bigger these component values are, the more they contribute to the whole evaluation formula, and correspondingly the candidate has higher score.", "labels": [], "entities": [{"text": "Score(t)", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.919529139995575}]}, {"text": "The length ratio relation reflects the proportion relation between S-T as a whole, so its weight will be impacted on the Score(t) in the macro-view.", "labels": [], "entities": [{"text": "length ratio relation", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.9672353863716125}, {"text": "Score(t)", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9293151199817657}]}, {"text": "The weights are trained through a large amount of technical terms and proper nouns, where each relation corresponds to one probability.", "labels": [], "entities": []}, {"text": "N denotes the total number of Web pages that contain candidates, and partly reflects the distribution information of candidates in different Web pages.", "labels": [], "entities": []}, {"text": "If the greater N is, the greater Score(t) will become.", "labels": [], "entities": [{"text": "Score(t)", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9056495130062103}]}, {"text": "The distance relation is defined as the distance contribution probability of the jth source-candidate pair on the ith Web pages, which is impacted on every word pair emerged on the Web in the point of micro-view.", "labels": [], "entities": [{"text": "distance contribution probability", "start_pos": 40, "end_pos": 73, "type": "METRIC", "confidence": 0.8471232453982035}]}, {"text": "Its calculation formula is defined in Section 5.1.", "labels": [], "entities": []}, {"text": "The weights of \u03bb and 2 \u03bb represent the proportion of term frequency and term distribution, and 1 \u03bb denotes the weight of the total number of one candidate occurrences, and 2 \u03bb represents the weight of counting the nearest distance occurrence for each Web page. is the contribution probability of keywords, key symbols and boundary information.", "labels": [], "entities": []}, {"text": "If there are predefined keywords, key symbols, and boundary information between S-T, i.e., , then the evaluation formula will give a reward w, otherwise, indicate that there is no impact on the whole equation.", "labels": [], "entities": []}, {"text": "Our experimental data consist of two sets: 400 C-E term pairs and 3511 C-E term pairs in the financial domain.", "labels": [], "entities": []}, {"text": "There is no intersection between the two sets.", "labels": [], "entities": []}, {"text": "Each term often consists of 2-8 Chinese characters, and the associated translation contains 2-5 English words.", "labels": [], "entities": []}, {"text": "In the test set of 400 terms, there are more than one English translation for every Chinese term, and only one English translation for 3511 term pairs.", "labels": [], "entities": []}, {"text": "In the test sets, Chinese terms are inputted to our system on batch, and their corresponding translations are viewed as a criterion to evaluate these mined candidates.", "labels": [], "entities": []}, {"text": "The top n accuracy is defined as the percentage of terms whose top n translations include correct translations in the term pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9000826478004456}]}, {"text": "A series of experiments are conducted on the two test sets.", "labels": [], "entities": []}, {"text": "Experiments on the number of feedback pages: To obtain the best parameter of feedback Web pages that influence the whole system accuracy, we perform the experiments on the test set of 400 terms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9977867603302002}]}, {"text": "The number of feedback Web pages is respectively set to 0, 10, 20, 30, and 40.", "labels": [], "entities": []}, {"text": "N=1, 3, 5 represent the accuracies of top 1, 3, and 5.", "labels": [], "entities": []}, {"text": "From the feedback pages, previous 5 semantically-relevant terms are extracted to construct anew query expansion for retrieving more effective Web pages.", "labels": [], "entities": []}, {"text": "Translation candidates are mined from these effective pages, whose accuracy curves are depicted in.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9321801662445068}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9985252022743225}]}, {"text": "As seen from the figure above, when the number of feedback Web pages is 20, the accuracy reaches the best.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9996802806854248}]}, {"text": "Thus, the feedback parameter in our experiments is set to 20.", "labels": [], "entities": []}, {"text": "Experiments on the parameter 1 \u03bb : In the candidate evaluation method using multi-features, the parameter of 1 \u03bb need be chosen through the experiments.", "labels": [], "entities": []}, {"text": "To obtain the best parameter, the experiments are set as follows.", "labels": [], "entities": []}, {"text": "The accuracy of top 5 candidates is viewed as a performance criterion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9990554451942444}]}, {"text": "The parameters are respectively set from 0 to 1 with the increase of 0.1 step.", "labels": [], "entities": []}, {"text": "The results are listed in.", "labels": [], "entities": []}, {"text": "As seen from the figure, 1 \u03bb =0.4 is best parameter, and therefore 2 \u03bb =0.6.", "labels": [], "entities": []}, {"text": "In the following experiments, the parameters are all set to this value.", "labels": [], "entities": []}, {"text": "Experiments on the test set of 400 terms using different methods: The methods respectively without prediction(NP), with prediction(P), with prediction and feedback(PF) only using term frequency (TM), and with prediction and feedback using multi-features(PF+MF) are employed on the test set of 400 terms.", "labels": [], "entities": [{"text": "term frequency (TM)", "start_pos": 179, "end_pos": 198, "type": "METRIC", "confidence": 0.819338345527649}]}, {"text": "The results are listed in.", "labels": [], "entities": []}, {"text": "As seen from this table, if there is no semantic prediction, the obtained translations from Web pages are about 48% in the top 30 candidates.", "labels": [], "entities": []}, {"text": "This is because general search engines will retrieve more relevant Chinese Web pages rather than those effective pages including English meanings.", "labels": [], "entities": []}, {"text": "Thus, the semantic prediction method is employed.", "labels": [], "entities": [{"text": "semantic prediction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8594067096710205}]}, {"text": "Experiments demonstrate the method with semantic prediction distinctly improves the accuracy, about 36.8%.", "labels": [], "entities": [{"text": "semantic prediction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8639021217823029}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9997076392173767}]}, {"text": "To further improve the performance, the feedback learning technique is proposed, and it increases the average accuracy of 6.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.981619119644165}]}, {"text": "Though TM is very effective in mining the term translation, the multifeature method fully utilizes the context of candidates, and therefore obtains more accurate results, about 92.8% in the top 5 candidates.", "labels": [], "entities": [{"text": "TM", "start_pos": 7, "end_pos": 9, "type": "TASK", "confidence": 0.866221010684967}, {"text": "term translation", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.6260634064674377}]}, {"text": "Experiments on a large vocabulary: To validate our system performance, experiments are carried on a large vocabulary of 3511 terms using different methods.", "labels": [], "entities": []}, {"text": "One method is to use term frequency (TM) as an evaluation criterion, and the other method is to use multi-features (MF) as an evaluation criterion.", "labels": [], "entities": [{"text": "term frequency (TM)", "start_pos": 21, "end_pos": 40, "type": "METRIC", "confidence": 0.9379798889160156}]}, {"text": "Experimental results are shown as follows.", "labels": [], "entities": []}, {"text": "From, we know the accuracy with top Only top 3 English translations are listed for each Chinese term.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995381832122803}]}], "tableCaptions": [{"text": " Table 1. As seen from this table, if there is no  semantic prediction, the obtained translations  from Web pages are about 48% in the top 30  candidates. This is because general search en- gines will retrieve more relevant Chinese Web  pages rather than those effective pages including  English meanings. Thus, the semantic prediction  method is employed. Experiments demonstrate  the method with semantic prediction distinctly  improves the accuracy, about 36.8%. To further  improve the performance, the feedback learning  technique is proposed, and it increases the aver- age accuracy of 6.5%. Though TM is very effec- tive in mining the term translation, the multi- feature method fully utilizes the context of can- didates, and therefore obtains more accurate re- sults, about 92.8% in the top 5 candidates.", "labels": [], "entities": [{"text": "semantic prediction", "start_pos": 316, "end_pos": 335, "type": "TASK", "confidence": 0.7177459746599197}, {"text": "semantic prediction", "start_pos": 398, "end_pos": 417, "type": "TASK", "confidence": 0.7203544825315475}, {"text": "accuracy", "start_pos": 443, "end_pos": 451, "type": "METRIC", "confidence": 0.9993250370025635}, {"text": "aver- age accuracy", "start_pos": 570, "end_pos": 588, "type": "METRIC", "confidence": 0.7881819158792496}, {"text": "accurate re- sults", "start_pos": 757, "end_pos": 775, "type": "METRIC", "confidence": 0.7863581329584122}]}, {"text": " Table 1. The term translation results using different  methods", "labels": [], "entities": [{"text": "term translation", "start_pos": 14, "end_pos": 30, "type": "TASK", "confidence": 0.6862378716468811}]}, {"text": " Table 2. The term translation results on a large vo- cabulary", "labels": [], "entities": []}]}