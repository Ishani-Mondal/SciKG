{"title": [{"text": "Graph Transformations in Data-Driven Dependency Parsing", "labels": [], "entities": [{"text": "Graph Transformations", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7698599398136139}]}], "abstractContent": [{"text": "Transforming syntactic representations in order to improve parsing accuracy has been exploited successfully in statistical parsing systems using constituency-based representations.", "labels": [], "entities": [{"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9786035418510437}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.8537110090255737}, {"text": "statistical parsing", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.6443390250205994}]}, {"text": "In this paper, we show that similar transformations can give substantial improvements also in data-driven dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.6870747804641724}]}, {"text": "Experiments on the Prague Dependency Treebank show that systematic transformations of coordinate structures and verb groups result in a 10% error reduction fora deterministic data-driven dependency parser.", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 19, "end_pos": 45, "type": "DATASET", "confidence": 0.9499826033910116}]}, {"text": "Combining these transformations with previously proposed techniques for recovering non-projective dependencies leads to state-of-the-art accuracy for the given data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9986018538475037}]}], "introductionContent": [{"text": "It has become increasingly clear that the choice of suitable internal representations can be a very important factor in data-driven approaches to syntactic parsing, and that accuracy can often be improved by internal transformations of a given kind of representation.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.7701407372951508}, {"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9981526732444763}]}, {"text": "This is well illustrated by the Collins parser), scrutinized by, where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation.", "labels": [], "entities": [{"text": "Collins parser", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.941350668668747}]}, {"text": "Other examples can be found in the work of and, which show that well-chosen transformations of syntactic representations can greatly improve the parsing accuracy obtained with probabilistic context-free grammars.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9102891087532043}]}, {"text": "In this paper, we apply essentially the same techniques to data-driven dependency parsing, specifically targeting the analysis of coordination and verb groups, two very common constructions that pose special problems for dependency-based approaches.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.750956654548645}]}, {"text": "The basic idea is that we can facilitate learning by transforming the training data for the parser and that we can subsequently recover the original representations by applying an inverse transformation to the parser's output.", "labels": [], "entities": []}, {"text": "The data used in the experiments come from the Prague Dependency Treebank (PDT)), the largest available dependency treebank, annotated according to the theory of Functional Generative Description (FGD) (.", "labels": [], "entities": [{"text": "Prague Dependency Treebank (PDT))", "start_pos": 47, "end_pos": 80, "type": "DATASET", "confidence": 0.9216064314047495}, {"text": "Functional Generative Description (FGD)", "start_pos": 162, "end_pos": 201, "type": "TASK", "confidence": 0.7954086363315582}]}, {"text": "The parser used is MaltParser (), a freely available system that combines a deterministic parsing strategy with discriminative classifiers for predicting the next parser action.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides the necessary background, including a definition of dependency graphs, a discussion of different approaches to the analysis of coordination and verb groups in dependency grammar, as well as brief descriptions of PDT, MaltParser and some related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces a set of dependency graph transformations, specifically defined to deal with the dependency annotation found in PDT, which are experimentally evaluated in section 4.", "labels": [], "entities": []}, {"text": "While the experiments reported in section 4.1 deal with pure treebank transformations, in order to establish an upper bound on what can be achieved in parsing, the experiments presented in section 4.2 examine the effects of different transformations on parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 151, "end_pos": 158, "type": "TASK", "confidence": 0.9700586199760437}, {"text": "parsing", "start_pos": 253, "end_pos": 260, "type": "TASK", "confidence": 0.9616149663925171}, {"text": "accuracy", "start_pos": 261, "end_pos": 269, "type": "METRIC", "confidence": 0.8604195713996887}]}, {"text": "Finally, in section 4.3, we combine these transformations with previously proposed techniques in order to optimize overall parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 123, "end_pos": 130, "type": "TASK", "confidence": 0.9710229635238647}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.923845112323761}]}, {"text": "We conclude in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments are based on PDT 1.0, which is divided into three data sets, a training set (\u2206 t ), a development test set (\u2206 d ), and an evaluation test set (\u2206 e ).", "labels": [], "entities": []}, {"text": "shows the size of each data set, as well as the relative frequency of the specific constructions that are in focus here.", "labels": [], "entities": []}, {"text": "Only 1.3% of all words in the training data are identified as auxiliary verbs (A), whereas coordination (S and C) is more common in PDT.", "labels": [], "entities": []}, {"text": "This implies that coordination transformations are more likely to have a greater impact on overall accuracy compared to the verb group transformations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9885482788085938}]}, {"text": "In the parsing experiments reported in sections 4.1-4.2, we use \u2206 t for training, \u2206 d for tuning, and \u2206 e for the final evaluation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 7, "end_pos": 14, "type": "TASK", "confidence": 0.9677784442901611}]}, {"text": "The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in   MaltParser is used with the parsing algorithm of Nivre together with the feature model used for parsing Czech by.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7341163456439972}, {"text": "HMM tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.69937664270401}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.8540359139442444}, {"text": "parsing", "start_pos": 293, "end_pos": 300, "type": "TASK", "confidence": 0.9751467108726501}]}, {"text": "In section 4.2 we use MBL, again with the same settings as Nivre and, and in section 4.2 we use SVM with a polynomial kernel of degree 2.", "labels": [], "entities": [{"text": "MBL", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.7222253084182739}]}, {"text": "The metrics for evaluation are the attachment score (AS) (labeled and unlabeled), i.e., the proportion of words that are assigned the correct head, and the exact match (EM) score (labeled and unlabeled), i.e., the proportion of sentences that are assigned a completely correct analysis.", "labels": [], "entities": [{"text": "attachment score (AS)", "start_pos": 35, "end_pos": 56, "type": "METRIC", "confidence": 0.9402266502380371}, {"text": "exact match (EM) score", "start_pos": 156, "end_pos": 178, "type": "METRIC", "confidence": 0.9550864299138387}]}, {"text": "All tokens, including punctuation, are included in the evaluation scores.", "labels": [], "entities": []}, {"text": "Statistical significance is assessed using McNemar's test.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.6796164512634277}, {"text": "McNemar's test", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.5584596991539001}]}, {"text": "The algorithms are fairly simple.", "labels": [], "entities": []}, {"text": "In addition, there will always be a small proportion of syntactic constructions that do not follow the expected pattern.", "labels": [], "entities": []}, {"text": "Hence, the transformation and inverse transformation will inevitably result in some distortion.", "labels": [], "entities": []}, {"text": "In order to estimate the expected reduction in parsing accuracy due to this distortion, we first consider a pure treebank transformation experiment, where we compare \u03c4 \u22121 (\u03c4 (\u2206 t )) to \u2206 t , for all the different transformations \u03c4 defined in the previous section.", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9744567275047302}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9355878829956055}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We see that, even though coordination is more frequent, verb groups are easier to handle.", "labels": [], "entities": []}, {"text": "The coordination version with the least loss of information (\u03c4 c+ ) fails to recover the correct head for 0.4% of all words in \u2206 t . The difference between \u03c4 c+ and \u03c4 c is expected.", "labels": [], "entities": []}, {"text": "However, in the next section this will be contrasted with the increased burden on the parser for \u03c4 c+ , since it is also responsible for selecting the correct dependency type for each arc among as many as 2 \u00b7 |R| types instead of |R|.", "labels": [], "entities": []}, {"text": "Parsing experiments are carried out in four steps (for a given transformation \u03c4 ): 1.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9461489915847778}]}, {"text": "Transform the training data set into \u03c4 (\u2206 t ).", "labels": [], "entities": []}, {"text": "2. Train a parser p on \u03c4 (\u2206 t ).", "labels": [], "entities": []}, {"text": "3. Parse a test set \u2206 using p with output p(\u2206).", "labels": [], "entities": []}, {"text": "4. Transform the parser output into \u03c4 \u22121 (p(\u2206)).", "labels": [], "entities": []}, {"text": "presents the results fora selection of transformations using MaltParser with MBL, tested on the evaluation test set \u2206 e with the untransformed data as baseline.", "labels": [], "entities": [{"text": "MBL", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.6095126867294312}]}, {"text": "Rows 2-5 show that transforming coordinate structures to MS improves parsing accuracy compared to the baseline, regardless of which transformation and inverse transformation are used.", "labels": [], "entities": [{"text": "parsing", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.9642848372459412}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9655246734619141}]}, {"text": "Moreover, the parser benefits from the verb group transformation, as seen in row 6.", "labels": [], "entities": [{"text": "verb group transformation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6372628808021545}]}, {"text": "The final row shows the best combination of a coordination transformation with the verb group transformation, which amounts to an improvement of roughly two percentage points, or a ten percent overall error reduction, for unlabeled accuracy.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 201, "end_pos": 216, "type": "METRIC", "confidence": 0.9240404367446899}, {"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9863523244857788}]}, {"text": "All improvements over the baseline are statistically significant (McNemar's test) with respect to attachment score (labeled and unlabeled) and unlabeled exact match, with p < 0.01 except for the unlabeled exact match score of the verb group transformation, where 0.01 < p < 0.05.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.7260223428408304}, {"text": "exact match", "start_pos": 153, "end_pos": 164, "type": "METRIC", "confidence": 0.9553726315498352}]}, {"text": "For the labeled exact match, no differences are significant.", "labels": [], "entities": []}, {"text": "The experimental results indicate that MS is more suitable than PS as the target representation for deterministic data-driven dependency parsing.", "labels": [], "entities": [{"text": "deterministic data-driven dependency parsing", "start_pos": 100, "end_pos": 144, "type": "TASK", "confidence": 0.5622120872139931}]}, {"text": "A relevant question is of course why this is the case.", "labels": [], "entities": []}, {"text": "A partial explanation maybe found in the \"short-dependency preference\" exhibited by most parsers   short arcs, but that accuracy drops quite rapidly as the arcs get longer.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9989087581634521}]}, {"text": "This can be related to the mean arc length in \u2206 t , which is 2.59 in the untransformed version, 2.40 in \u03c4 c (\u2206 t ) and 2.54 in \u03c4 v (\u2206 t ).", "labels": [], "entities": [{"text": "mean arc length", "start_pos": 27, "end_pos": 42, "type": "METRIC", "confidence": 0.6915321946144104}]}, {"text": "Rows 3-5 in show the distribution of arcs for different arc lengths in different versions of the data set.", "labels": [], "entities": []}, {"text": "Both \u03c4 c and \u03c4 v make arcs shorter on average, which may facilitate the task for the parser.", "labels": [], "entities": []}, {"text": "Another possible explanation is that learning is facilitated if similar constructions are represented similarly.", "labels": [], "entities": []}, {"text": "For instance, it is probable that learning is made more difficult when a unit has different heads depending on whether it is part of a coordination or not.", "labels": [], "entities": []}, {"text": "In this section we combine the best results from the previous section with the graph transformations proposed by to recover non-projective dependencies.", "labels": [], "entities": []}, {"text": "We write \u03c4 p for the projectivization of training data and \u03c4 \u22121 p for the inverse transformation applied to the parser's output.", "labels": [], "entities": []}, {"text": "In addition, we replace MBL with SVM, a learning algorithm that tends to give higher accuracy in classifier-based parsing although it is more: Detailed results for SVM; T = transformation; P = unlabeled precision, R = unlabeled recall costly to train.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9968151450157166}, {"text": "classifier-based parsing", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.5605838298797607}, {"text": "precision", "start_pos": 203, "end_pos": 212, "type": "METRIC", "confidence": 0.9149088263511658}, {"text": "recall", "start_pos": 228, "end_pos": 234, "type": "METRIC", "confidence": 0.9289445281028748}]}, {"text": "shows the results, for both MBL and SVM, of the baseline, the pure pseudo-projective parsing, and the combination of pseudo-projective parsing with PS-to-MS transformations.", "labels": [], "entities": []}, {"text": "We see that pseudo-projective parsing brings a very consistent increase inaccuracy of at least 1.5 percentage points, which is more than that reported by, and that the addition of the PS-to-MS transformations increases accuracy with about the same margin.", "labels": [], "entities": [{"text": "pseudo-projective parsing", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.5726203173398972}, {"text": "accuracy", "start_pos": 219, "end_pos": 227, "type": "METRIC", "confidence": 0.9994714856147766}]}, {"text": "We also see that SVM outperforms MBL by about two percentage points across the board, and that the positive effect of the graph transformations is most pronounced for the unlabeled exact match score, where the improvement is more than five percentage points overall for both MBL and SVM.", "labels": [], "entities": []}, {"text": "gives a more detailed analysis of the parsing results for SVM, comparing the optimal parser to the baseline, and considering specifically the (unlabeled) precision and recall of the categories involved in coordination (separators Sand conjuncts C) and verb groups (auxiliary verbs A and main verbs M ).", "labels": [], "entities": [{"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9990699887275696}, {"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.997967541217804}]}, {"text": "All figures indicate, without exception, that the transformations result in higher precision and recall for all directly involved words.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9990405440330505}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9990237951278687}]}, {"text": "(All differences are significant beyond the 0.01 level.)", "labels": [], "entities": []}, {"text": "It is worth noting that the error reduction is actually higher for A and M than for Sand C, although the former are less frequent.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 28, "end_pos": 43, "type": "METRIC", "confidence": 0.9814867973327637}]}, {"text": "With respect to unlabeled attachment score, the results of the optimized parser are slightly below the best published results fora single parser.", "labels": [], "entities": []}, {"text": "report a score of 85.1%, applying a corrective model to the output of Charniak's parser; achieve a score of 85.2% using a second-order spanning tree algorithm.", "labels": [], "entities": []}, {"text": "Using ensemble methods and a pool of different parsers, Zeman and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y (2005) attain atop score of 87.0%.", "labels": [], "entities": []}, {"text": "For unlabeled exact match, our results are better than any previously reported results, including those of.", "labels": [], "entities": []}, {"text": "(For the labeled scores, we are not aware of any comparable results in the literature.)", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: PDT data sets; S = sentence, W = word;  S = separator, C = conjunct, A = auxiliary verb", "labels": [], "entities": [{"text": "PDT data sets", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8782475193341573}]}, {"text": " Table 2: Transformations; T = transformation;  AS = attachment score (unlabeled) of \u03c4 \u22121 (\u03c4 (\u2206 t ))  compared to \u2206 t", "labels": [], "entities": [{"text": "AS", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.99224454164505}, {"text": "attachment score", "start_pos": 53, "end_pos": 69, "type": "METRIC", "confidence": 0.9868639409542084}]}, {"text": " Table 3: Parsing accuracy (MBL, \u2206 e ); T = trans- formation; AS = attachment score, EM = exact  match; U = unlabeled, L = labeled", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9211351871490479}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9250420928001404}, {"text": "MBL", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.8625935316085815}, {"text": "AS = attachment score", "start_pos": 62, "end_pos": 83, "type": "METRIC", "confidence": 0.8651054203510284}, {"text": "EM", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9267370700836182}, {"text": "exact  match", "start_pos": 90, "end_pos": 102, "type": "METRIC", "confidence": 0.9139379560947418}]}, {"text": " Table 4: Baseline labeled AS per arc length on \u2206 e  (row 1); proportion of arcs per arc length in \u2206 t  (rows 3-5)", "labels": [], "entities": [{"text": "AS", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.8306732773780823}]}, {"text": " Table 5: Optimized parsing results (SVM, \u2206 e ); T = transformation; LA = learning algorithm; AS =  attachment score, EM = exact match; U = unlabeled, L = labeled", "labels": [], "entities": [{"text": "AS =  attachment score", "start_pos": 94, "end_pos": 116, "type": "METRIC", "confidence": 0.7787196338176727}, {"text": "EM", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9118707180023193}, {"text": "exact match", "start_pos": 123, "end_pos": 134, "type": "METRIC", "confidence": 0.9025399386882782}]}, {"text": " Table 6: Detailed results for SVM; T = transformation; P = unlabeled precision, R = unlabeled recall", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.8012125492095947}]}]}