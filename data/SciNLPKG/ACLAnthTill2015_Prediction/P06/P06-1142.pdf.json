{"title": [{"text": "Learning Transliteration Lexicons from the Web", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an adaptive learning framework for Phonetic Similarity Modeling (PSM) that supports the automatic construction of transliteration lexicons.", "labels": [], "entities": [{"text": "Phonetic Similarity Modeling (PSM)", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.886222650607427}]}, {"text": "The learning algorithm starts with minimum prior knowledge about machine transliteration, and acquires knowledge iteratively from the Web.", "labels": [], "entities": []}, {"text": "We study the active learning and the unsupervised learning strategies that minimize human supervision in terms of data labeling.", "labels": [], "entities": []}, {"text": "The learning process refines the PSM and constructs a transliteration lexicon at the same time.", "labels": [], "entities": []}, {"text": "We evaluate the proposed PSM and its learning algorithm through a series of systematic experiments, which show that the proposed framework is reliably effective on two independent databases.", "labels": [], "entities": []}], "introductionContent": [{"text": "In applications such as cross-lingual information retrieval (CLIR) and machine translation (MT), there is an increasing need to translate out-ofvocabulary (OOV) words, for example from an alphabetical language to Chinese.", "labels": [], "entities": [{"text": "cross-lingual information retrieval (CLIR)", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.7756292273600897}, {"text": "machine translation (MT)", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.8502938508987427}]}, {"text": "Foreign proper names constitute a good portion of OOV words, which are translated into Chinese through transliteration.", "labels": [], "entities": []}, {"text": "Transliteration is a process of translating a foreign word into a native language by preserving its pronunciation in the original language, otherwise known as translation-bysound.", "labels": [], "entities": [{"text": "Transliteration is a process of translating a foreign word into a native language by preserving its pronunciation in the original language, otherwise known as translation-bysound", "start_pos": 0, "end_pos": 178, "type": "Description", "confidence": 0.77736763885388}]}, {"text": "MT and CLIR systems rely heavily on bilingual lexicons, which are typically compiled manually.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.7691613435745239}]}, {"text": "However, in view of the current information explosion, it is labor intensive, if not impossible, to compile a complete proper nouns lexicon.", "labels": [], "entities": []}, {"text": "The Web is growing at a fast pace and is providing a live information source that is rich in transliterations.", "labels": [], "entities": []}, {"text": "This paper presents a novel solution for automatically constructing an English-Chinese transliteration lexicon from the Web.", "labels": [], "entities": []}, {"text": "Research on automatic transliteration has reported promising results for regular transliteration (), where transliterations follow rigid guidelines.", "labels": [], "entities": []}, {"text": "However, in Web publishing, translators in different countries and regions may not observe common guidelines.", "labels": [], "entities": []}, {"text": "They often skew the transliterations in different ways to create special meanings to the sound equivalents, resulting in casual transliterations.", "labels": [], "entities": []}, {"text": "In this case, the common generative models () fail to predict the transliteration most of the time.", "labels": [], "entities": []}, {"text": "For example, \"Coca Cola\" is transliterated into \" \u53ef\u53e3\u53ef\u6a02 /Ke-Kou-Ke-Le/\" as a sound equivalent in Chinese, which literately means \"happiness in the mouth\".", "labels": [], "entities": [{"text": "Coca Cola\"", "start_pos": 14, "end_pos": 24, "type": "DATASET", "confidence": 0.9499208728472391}]}, {"text": "In this paper, we are interested in constructing lexicons that cover both regular and casual transliterations.", "labels": [], "entities": []}, {"text": "When anew English word is first introduced, many transliterations are invented.", "labels": [], "entities": []}, {"text": "Most of them are casual transliterations because a regular transliteration typically does not have many variations.", "labels": [], "entities": []}, {"text": "After awhile, the transliterations converge into one or two popular ones.", "labels": [], "entities": []}, {"text": "For example, \"Taxi\" becomes \" \u7684\u58eb /Di-Shi/\" in China and \" \u5fb7\u58eb /De-Shi/\" in Singapore.", "labels": [], "entities": []}, {"text": "Therefore, the adequacy of a transliteration entry could be judged by its popularity and its conformity with the translation-by-sound principle.", "labels": [], "entities": []}, {"text": "In any case, the phonetic similarity should serve as the primary basis of judgment.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly introduce prior works pertaining to machine transliteration.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.7284137606620789}]}, {"text": "In Section 3, we propose a phonetic similarity model (PSM) for confidence scoring of transliteration.", "labels": [], "entities": []}, {"text": "In Section 4, we propose an adaptive learning process for PSM modeling and lexicon construction.", "labels": [], "entities": [{"text": "PSM modeling", "start_pos": 58, "end_pos": 70, "type": "TASK", "confidence": 0.9821439385414124}, {"text": "lexicon construction", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.7877174019813538}]}, {"text": "In Section 5, we conduct experiments to evaluate different adaptive learning strategies.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first construct a development corpus by crawling of webpages.", "labels": [], "entities": []}, {"text": "This corpus consists of about 500 MB of webpages, called SET1 ().", "labels": [], "entities": [{"text": "SET1", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.7130881547927856}]}, {"text": "Out of 80,094 qualified sentences, 8,898 DQTPs are manually extracted from SET1, which serve as the gold standard in testing.", "labels": [], "entities": [{"text": "SET1", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.7234518527984619}]}, {"text": "To establish a baseline system, we first train a PSM using all 8,898 DQTPs in supervised manner and conduct a closed test on SET1 as in", "labels": [], "entities": [{"text": "PSM", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9443337321281433}, {"text": "SET1", "start_pos": 125, "end_pos": 129, "type": "DATASET", "confidence": 0.9055749773979187}]}], "tableCaptions": [{"text": " Table 1. Supervised learning test on SET1", "labels": [], "entities": [{"text": "SET1", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.6753705143928528}]}, {"text": " Table 3. SET1-derived PSM adapted towards  SET2.", "labels": [], "entities": [{"text": "SET1-derived PSM", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.4518855810165405}, {"text": "SET2", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.7362111210823059}]}]}