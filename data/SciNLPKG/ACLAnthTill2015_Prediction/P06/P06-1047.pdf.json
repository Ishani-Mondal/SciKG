{"title": [{"text": "Extractive Summarization using Inter-and Intra-Event Relevance", "labels": [], "entities": [{"text": "Extractive Summarization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8973071575164795}, {"text": "Inter-and Intra-Event Relevance", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.5406978925069174}]}], "abstractContent": [{"text": "Event-based summarization attempts to select and organize the sentences in a summary with respect to the events or the sub-events that the sentences describe.", "labels": [], "entities": []}, {"text": "Each event has its own internal structure, and meanwhile often relates to other events semantically, temporally, spatially, causally or conditionally.", "labels": [], "entities": []}, {"text": "In this paper, we define an event as one or more event terms along with the named entities associated, and present a novel approach to derive intra-and inter-event relevance using the information of internal association, semantic relatedness, distributional similarity and named entity clustering.", "labels": [], "entities": []}, {"text": "We then apply PageRank ranking algorithm to estimate the significance of an event for inclusion in a summary from the event relevance derived.", "labels": [], "entities": []}, {"text": "Experiments on the DUC 2001 test data shows that the relevance of the named entities involved in events achieves better result when their relevance is derived from the event terms they associate.", "labels": [], "entities": [{"text": "DUC 2001 test data", "start_pos": 19, "end_pos": 37, "type": "DATASET", "confidence": 0.9884705096483231}]}, {"text": "It also reveals that the topic-specific relevance from documents themselves outperforms the semantic relevance from a general purpose knowledge base like Word-Net.", "labels": [], "entities": [{"text": "Word-Net", "start_pos": 154, "end_pos": 162, "type": "DATASET", "confidence": 0.9364288449287415}]}], "introductionContent": [{"text": "Extractive summarization selects sentences which contain the most salient concepts in documents.", "labels": [], "entities": [{"text": "Extractive summarization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9032766819000244}]}, {"text": "Two important issues with it are how the concepts are defined and what criteria should be used to judge the salience of the concepts.", "labels": [], "entities": []}, {"text": "Existing work has typically been based on techniques that extract key textual elements, such as keywords (also known as significant terms) as weighed by their tf*idf score, or concepts (such as events or entities) with linguistic and/or statistical analysis.", "labels": [], "entities": []}, {"text": "Then, sentences are selected according to either the important textual units they contain or certain types of intersentence relations they hold.", "labels": [], "entities": []}, {"text": "Event-based summarization which has emerged recently attempts to select and organize sentences in a summary with respect to events or sub-events that the sentences describe.", "labels": [], "entities": [{"text": "Event-based summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.4414453059434891}]}, {"text": "With regard to the concept of events, people do not have the same definition when introducing it in different domains.", "labels": [], "entities": []}, {"text": "While traditional linguistics work on semantic theory of events and the semantic structures of verbs, studies in information retrieval (IR) within topic detection and tracking framework look at events as narrowly defined topics which can be categorized or clustered as a set of related documents (TDT).", "labels": [], "entities": [{"text": "semantic theory of events", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.8018777519464493}, {"text": "information retrieval (IR)", "start_pos": 113, "end_pos": 139, "type": "TASK", "confidence": 0.7540537238121032}, {"text": "topic detection and tracking", "start_pos": 147, "end_pos": 175, "type": "TASK", "confidence": 0.7872418165206909}]}, {"text": "IR events are broader (or to say complex) events in the sense that they may include happenings and their causes, consequences or even more extended effects.", "labels": [], "entities": [{"text": "IR events", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9095742106437683}]}, {"text": "In the information extraction (IE) community, events are defined as the pre-specified and structured templates that relate an action to its participants, times, locations and other entities involved.", "labels": [], "entities": [{"text": "information extraction (IE) community", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.8802675604820251}]}, {"text": "IE defines what people call atomic events.", "labels": [], "entities": [{"text": "IE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.49748900532722473}]}, {"text": "Regardless of their distinct perspectives, people all agree that events are collections of activities together with associated entities.", "labels": [], "entities": []}, {"text": "To apply the concept of events in the context of text summarization, we believe it is more appropriate to consider events at the sentence level, rather than at the document level.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.6790805459022522}]}, {"text": "To avoid the complexity of deep semantic and syntactic processing, we complement the advantages of statistical techniques from the IR community and structured information provided by the IE community.", "labels": [], "entities": []}, {"text": "We propose to extract semi-structured events with shallow natural language processing (NLP) techniques and estimate their importance for inclusion in a summary with IR techniques.", "labels": [], "entities": []}, {"text": "Though it is most likely that documents narrate more than one similar or related event, most event-based summarization techniques reported so far explore the importance of the events independently.", "labels": [], "entities": []}, {"text": "Motivated by this observation, this paper addresses the task of event-relevance based summarization and explores what sorts of relevance make a contribution.", "labels": [], "entities": [{"text": "event-relevance based summarization", "start_pos": 64, "end_pos": 99, "type": "TASK", "confidence": 0.4951391319433848}]}, {"text": "To this end, we investigate intra-event relevance, that is actionentity relevance, and inter-event relevance, that is event-event relevance.", "labels": [], "entities": []}, {"text": "While intra-event relevance is measured with frequencies of the associated events and entities directly, inter-event relevance is derived indirectly from a general WordNet similarity utility, distributional similarity in the documents to be summarized, named entity clustering and soon.", "labels": [], "entities": []}, {"text": "Pagerank ranking algorithm is then applied to estimate the event importance for inclusion in a summary using the aforesaid relevance.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces related work.", "labels": [], "entities": []}, {"text": "Sections 3 introduces our proposed event-based summarization approaches which make use of intra-and inter-event relevance.", "labels": [], "entities": []}, {"text": "Section 4 presents experiments and evaluates different approaches.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the event based summarization approaches proposed, we conduct a set of experiments on 30 English document sets provide by the DUC 2001 multi-document summarization task.", "labels": [], "entities": [{"text": "summarization", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8094434142112732}, {"text": "DUC 2001 multi-document summarization task", "start_pos": 138, "end_pos": 180, "type": "TASK", "confidence": 0.7403871774673462}]}, {"text": "The documents are pre-processed with GATE to recognize the previously mentioned four types of name entities.", "labels": [], "entities": [{"text": "GATE", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.7934971451759338}]}, {"text": "On average, each set contains 10.3 documents, 602 sentences, 216 event terms and 148.5 name entities.", "labels": [], "entities": []}, {"text": "To evaluate the quality of the generated summaries, we choose an automatic summary evaluation metric ROUGE, which has been used in DUCs.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.9691469073295593}]}, {"text": "ROUGE is a recall-based metric for fixed length summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9645125865936279}, {"text": "recall-based", "start_pos": 11, "end_pos": 23, "type": "METRIC", "confidence": 0.9971292614936829}]}, {"text": "It bases on N-gram cooccurrence and compares the system generated summaries to human judges (.", "labels": [], "entities": []}, {"text": "For each DUC document set, the system creates a summary of 200 word length and present three of the ROUGE metrics: ROUGE-1 (unigram-based), ROUGE-2 (bigram-based), and ROUGE-W (based on longest common subsequence weighed by the length) in the following experiments and evaluations.", "labels": [], "entities": [{"text": "DUC document set", "start_pos": 9, "end_pos": 25, "type": "DATASET", "confidence": 0.7308390935262045}, {"text": "ROUGE-1", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9055891633033752}, {"text": "ROUGE-2", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.9171342849731445}, {"text": "ROUGE-W", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9887963533401489}]}, {"text": "We first evaluate the summaries generated based on ) , ( NE ET R itself.", "labels": [], "entities": [{"text": "NE ET R", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.5438931981722513}]}, {"text": "In the pre-evaluation experiments, we have observed that some fre<Person>, a-position-name of <Organization>, does something.", "labels": [], "entities": []}, {"text": "<Person> and another <Person> do something.", "labels": [], "entities": []}, {"text": "quently occurring nouns, such as \"doctors\" and \"hospitals\", by themselves are not marked by general NE taggers.", "labels": [], "entities": []}, {"text": "But they indicate persons, organizations or locations.", "labels": [], "entities": []}, {"text": "We compare the ROUGE scores of adding frequent nouns or not to the set of named entities in.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.9932331442832947}]}, {"text": "A noun is considered as a frequent noun when its frequency is larger than 10.", "labels": [], "entities": []}, {"text": "Roughly 5% improvement is achieved when high frequent nouns are taken into the consideration.", "labels": [], "entities": []}, {"text": "Hereafter, when we mention NE in latter experiments, the high frequent nouns are included.", "labels": [], "entities": []}, {"text": "The topic-specific relevance derived from the documents to be summarized outperforms the general purpose Word-Net relevance by about 4%.", "labels": [], "entities": []}, {"text": "This result is reasonable as WordNet may introduce the word relatedness which is not necessary in the topic-specific documents.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9448813199996948}]}, {"text": "When we examine the relevance matrix from the event term pairs with the highest relevant, we find that the pairs, like \"abort\" and \"confirm\", \"vote\" and confirm\", do reflect semantics (antonymous) and associated (causal) relations to some degree..", "labels": [], "entities": []}, {"text": "Looking more closely, we conclude that compared to event terms, named entities are more representative of the documents in which they are included.", "labels": [], "entities": []}, {"text": "In other words, event terms are more likely to be distributed around all the document sets, whereas named entities are more topic-specific and therefore cluster in a particular document set more.", "labels": [], "entities": []}, {"text": "Examples of high related named entities in relevance matrix are \"Andrew\" and \"Florida\", \"Louisiana\" and \"Florida\".", "labels": [], "entities": []}, {"text": "Although their relevance is not as explicit as the same of event terms (their relevance is more contextual than semantic), we can still deduce that some events may happen in both Louisiana and Florida, or about Andrew in Florida.", "labels": [], "entities": []}, {"text": "In addition, it also shows that the relevance we would have expected to be derived from patterns and clustering can also be discovered by As discussed in Section 3.2, the named entities in the same cluster may often be relevant but not always be co-referred.", "labels": [], "entities": []}, {"text": "In the following last set of experiments, we evaluate the two ways to use the clustering results.", "labels": [], "entities": []}, {"text": "One is to consider them as related as if they are in the same cluster and derive the NE-NE relevance with (E5).", "labels": [], "entities": []}, {"text": "The other is to merge the entities in one cluster as one reprehensive named entity and then use it in ET-NE with (E1).", "labels": [], "entities": [{"text": "ET-NE", "start_pos": 102, "end_pos": 107, "type": "DATASET", "confidence": 0.6094465255737305}]}, {"text": "The rationality of the former approach is validated.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 Some results of the named entity  merged", "labels": [], "entities": []}, {"text": " Table 3. A noun is  considered as a frequent noun when its fre- quency is larger than 10. Roughly 5% improve- ment is achieved when high frequent nouns are  taken into the consideration. Hereafter, when we  mention NE in latter experiments, the high fre- quent nouns are included.", "labels": [], "entities": [{"text": "fre- quency", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.8944407304128011}, {"text": "improve- ment", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.9608021179835001}]}, {"text": " Table 5. Looking more closely, we  conclude that compared to event terms, named  entities are more representative of the docu- ments in which they are included. In other words,  event terms are more likely to be distributed  around all the document sets, whereas named  entities are more topic-specific and therefore  cluster in a particular document set more. Ex- amples of high related named entities in rele- vance matrix are \"Andrew\" and \"Florida\",", "labels": [], "entities": [{"text": "Florida", "start_pos": 444, "end_pos": 451, "type": "DATASET", "confidence": 0.9090465307235718}]}, {"text": " Table 6 ROUGE scores using complete R matrix  and with different summary lengths", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9730706810951233}]}]}