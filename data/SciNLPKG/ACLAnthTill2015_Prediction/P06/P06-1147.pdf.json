{"title": [{"text": "Utilizing Co-Occurrence of Answers in Question Answering", "labels": [], "entities": [{"text": "Utilizing Co-Occurrence of Answers in Question Answering", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.7106180914810726}]}], "abstractContent": [{"text": "In this paper, we discuss how to utilize the co-occurrence of answers in building an automatic question answering system that answers a series of questions on a specific topic in a batch mode.", "labels": [], "entities": [{"text": "question answering", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7007912248373032}]}, {"text": "Experiments show that the answers to the many of the questions in the series usually have a high degree of co-occurrence in relevant document passages.", "labels": [], "entities": []}, {"text": "This feature sometimes can't be easily utilized in an automatic QA system which processes questions independently.", "labels": [], "entities": []}, {"text": "However it can be utilized in a QA system that processes questions in a batch mode.", "labels": [], "entities": []}, {"text": "We have used our pervious TREC QA system as base-line and augmented it with new answer clustering and co-occurrence maximiza-tion components to build the batch QA system.", "labels": [], "entities": []}, {"text": "The experiment results show that the QA system running under the batch mode get significant performance improvement over our baseline TREC QA system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Question answering of a series of questions on one topic has gained more and more research interest in the recent years.", "labels": [], "entities": [{"text": "Question answering of a series of questions on one topic", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8941084146499634}]}, {"text": "The current TREC QA test set contains factoid and list questions grouped into different series, where each series has the target of a definition associated with it (Overview of the TREC 2004 Question Answering Track, Voorhees 2005).", "labels": [], "entities": [{"text": "TREC QA test set", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.8917135149240494}, {"text": "TREC 2004 Question Answering", "start_pos": 181, "end_pos": 209, "type": "TASK", "confidence": 0.8457414954900742}]}, {"text": "Usually, the target is also called \"topic\" by QA researchers.", "labels": [], "entities": []}, {"text": "One of the restrictions of TREC QA is that \"questions within a series must be processed in order, without looking ahead.\"", "labels": [], "entities": [{"text": "TREC QA", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.6025956124067307}]}, {"text": "That is, systems are allowed to use answers to earlier questions to help answer later questions in the same series, but cannot use later questions to help answer earlier questions.", "labels": [], "entities": []}, {"text": "This requirement models the dialogue discourse between the user and the QA system.", "labels": [], "entities": []}, {"text": "However our experiments on interactive QA system show that some impatient QA users will throw a bunch of questions to the system and waiting for the answers returned in all.", "labels": [], "entities": []}, {"text": "This prompted us to consider building a QA system which can accept as many questions as possible from users once in all and utilizing the relations between these questions to help find answers.", "labels": [], "entities": []}, {"text": "We would also like to know the performance difference between the QA system processing the question series in an order and the QA system processing the question series as a whole.", "labels": [], "entities": []}, {"text": "We call the second type of QA system as batch QA system to avoid the ambiguity in the following description in this paper.", "labels": [], "entities": []}, {"text": "What kind of relations between questions could be utilized is a key problem in building the batch QA system.", "labels": [], "entities": []}, {"text": "By observing the test questions of TREC QA, we found that the questions given under the same topic are not independent at all.", "labels": [], "entities": [{"text": "TREC QA", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.6777681708335876}]}, {"text": "shows a series of three questions proposed under the topic \"Russian submarine Kursk Sinks\" and some relevant passages to this topic found in the TREC data set.", "labels": [], "entities": [{"text": "Russian submarine Kursk Sinks", "start_pos": 60, "end_pos": 89, "type": "DATASET", "confidence": 0.6067527085542679}, {"text": "TREC data set", "start_pos": 145, "end_pos": 158, "type": "DATASET", "confidence": 0.9420119722684225}]}, {"text": "These passages contain answers not to just one but to two or three of the questions.", "labels": [], "entities": []}, {"text": "This indicates that the answers to these questions have high co-occurrence.", "labels": [], "entities": []}, {"text": "In an automatic QA system which processes the questions independently, the answers to the questions mayor may not always be extracted due to algorithmic limitations or noisy information around the correct answer.", "labels": [], "entities": []}, {"text": "However in building a batch QA system, the interdependence between the answers could be utilized to help to filter out the noisy information and pinpoint the correct answer for each question in the series.", "labels": [], "entities": []}, {"text": "We will discuss later in this paper how to utilize the co-occurrence of answers to a series of questions in building a batch QA system.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data corpus we used is TREC QA data (AQUAINT Corpus).", "labels": [], "entities": [{"text": "TREC QA data (AQUAINT Corpus)", "start_pos": 27, "end_pos": 56, "type": "DATASET", "confidence": 0.7533172028405326}]}, {"text": "The test questions are TREC QA 2004 and TREC QA 2005 questions.", "labels": [], "entities": [{"text": "TREC QA 2004", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.7912866473197937}, {"text": "TREC QA 2005 questions", "start_pos": 40, "end_pos": 62, "type": "DATASET", "confidence": 0.9110806882381439}]}, {"text": "Each topic is followed with a series of factoid questions.", "labels": [], "entities": []}, {"text": "The number of questions selected from TREC 2004 collection is 230 and the number of question series is 65.", "labels": [], "entities": [{"text": "TREC 2004 collection", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.9037105838457743}]}, {"text": "The number of questions selected from TREC 2005 collection is 362 and the number of question series is 75.", "labels": [], "entities": [{"text": "TREC 2005 collection", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.9207371473312378}]}, {"text": "We performed 4 different experiments: (1).", "labels": [], "entities": []}, {"text": "Batch QA system (Baseline system with co-occurrence maximization).", "labels": [], "entities": []}, {"text": "Baseline system with web supporting.", "labels": [], "entities": []}, {"text": "Batch QA with web supporting.", "labels": [], "entities": []}, {"text": "We introduced web supporting into the experiments because usually the information on the web tends to share more co-occurrence and redundancy which is also proved by our results.", "labels": [], "entities": []}, {"text": "Compared between the baseline system and batch system, the experiment results show that the overall accuracy score has been improved from 0.34 to 0.39 on TREC 2004 test questions and from 0.31 to 0.37 on TREC 2005 test questions.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 100, "end_pos": 114, "type": "METRIC", "confidence": 0.9816828370094299}, {"text": "TREC 2004 test questions", "start_pos": 154, "end_pos": 178, "type": "DATASET", "confidence": 0.9535903334617615}, {"text": "TREC 2005 test questions", "start_pos": 204, "end_pos": 228, "type": "DATASET", "confidence": 0.9630897045135498}]}, {"text": "Compared between the baseline system and batch system with web supporting, the accuracy score can be improved up to 0.498.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 79, "end_pos": 93, "type": "METRIC", "confidence": 0.9780957698822021}]}, {"text": "We also noticed that the average number of questions under each topic in TREC 2004 test questions is 3.538, which is significantly lower than the 4.8267 average in TREC 2005 questions series.", "labels": [], "entities": [{"text": "TREC 2004 test questions", "start_pos": 73, "end_pos": 97, "type": "DATASET", "confidence": 0.9304772913455963}, {"text": "TREC 2005 questions series", "start_pos": 164, "end_pos": 190, "type": "DATASET", "confidence": 0.8772362172603607}]}, {"text": "This may explain why the improvement we obtained on TREC2004 data is not as significant as the improvement obtained on TREC 2005 questions.", "labels": [], "entities": [{"text": "TREC2004 data", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.9604284465312958}, {"text": "TREC 2005 questions", "start_pos": 119, "end_pos": 138, "type": "DATASET", "confidence": 0.9229150414466858}]}, {"text": "The accuracy score of each TREC2005 question series is also calculated.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9747277498245239}, {"text": "TREC2005 question series", "start_pos": 27, "end_pos": 51, "type": "DATASET", "confidence": 0.7106135288874308}]}, {"text": "Figure3-4 shows the comparisons between 4 different experiment methods.", "labels": [], "entities": []}, {"text": "We also calculate the number of question series with accuracy increased, unchanged and decreased.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9991413354873657}]}, {"text": "It is also shown in the following table.", "labels": [], "entities": []}, {"text": "(\"+\" means number of question series with accuracy increased, \"=\" unchanged and \"-\" decreased.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9975360631942749}]}, {"text": "Some question series get unchanged accuracy because the questions can't be clustered according to our clustering template so that it can't utilize the co-occurrence of answers in the cluster.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9994124174118042}]}, {"text": "Some question series get decreased accuracy because the questions because the noisy information had even higher co-occurrence, the error occurred during the question clustering and the answers didn't show any co-relations in the retrieved passages at all.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9988611936569214}]}, {"text": "A deep and further error analysis is necessary for this answer cooccurrence maximization technique to be applied topic independently.", "labels": [], "entities": []}], "tableCaptions": []}