{"title": [{"text": "An Unsupervised Morpheme-Based HMM for Hebrew Morphological Disambiguation", "labels": [], "entities": [{"text": "Hebrew Morphological Disambiguation", "start_pos": 39, "end_pos": 74, "type": "TASK", "confidence": 0.7410630385080973}]}], "abstractContent": [{"text": "Morphological disambiguation is the process of assigning one set of morphological features to each individual word in a text.", "labels": [], "entities": [{"text": "Morphological disambiguation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8949187994003296}]}, {"text": "When the word is ambiguous (there are several possible analyses for the word), a disambiguation procedure based on the word context must be applied.", "labels": [], "entities": []}, {"text": "This paper deals with morphological disambiguation of the Hebrew language, which combines morphemes into a word in both agglutina-tive and fusional ways.", "labels": [], "entities": []}, {"text": "We present an un-supervised stochastic model-the only resource we use is a morphological analyzer-which deals with the data sparseness problem caused by the affixational morphology of the Hebrew language.", "labels": [], "entities": []}, {"text": "We present a text encoding method for languages with affixational morphology in which the knowledge of word formation rules (which are quite restricted in He-brew) helps in the disambiguation.", "labels": [], "entities": [{"text": "text encoding", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.7019497156143188}, {"text": "word formation", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.704428181052208}]}, {"text": "We adapt HMM algorithms for learning and searching this text representation, in such away that segmentation and tagging can be learned in parallel in one step.", "labels": [], "entities": []}, {"text": "Results on a large scale evaluation indicate that this learning improves disambiguation for complex tag sets.", "labels": [], "entities": []}, {"text": "Our method is applicable to other languages with affix morphology.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological disambiguation is the process of assigning one set of morphological features to each individual word in a text, according to the word context.", "labels": [], "entities": [{"text": "Morphological disambiguation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8896327018737793}]}, {"text": "In this work, we investigate morphological disambiguation in Modern Hebrew.", "labels": [], "entities": [{"text": "morphological disambiguation", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.674790695309639}]}, {"text": "We explore unsupervised learning method, which is more challenging than the supervised case.", "labels": [], "entities": []}, {"text": "The main motivation for this approach is that despite the development of annotated corpora in Hebrew 1 , there is still not enough data available for supervised training.", "labels": [], "entities": []}, {"text": "The other reason, is that unsupervised methods can handle the dynamic nature of Modern Hebrew, as it evolves overtime.", "labels": [], "entities": []}, {"text": "In the case of English, because morphology is simpler, morphological disambiguation is generally covered under the task of part-of-speech tagging.", "labels": [], "entities": [{"text": "morphological disambiguation", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6918593347072601}, {"text": "part-of-speech tagging", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.6997677087783813}]}, {"text": "The main morphological variations are embedded in the tag name (for example, Ns and Np for noun singular or plural).", "labels": [], "entities": []}, {"text": "The tagging accuracy of supervised stochastic taggers is around 96%-97% (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.975744366645813}]}, {"text": "reports an accuracy of 86.6% for an unsupervised word-based HMM, trained on a corpus of 42,186 sentences (about 1M words), over a tag set of 159 different tags., in contrast, reports an accuracy of 75.49%, 80.87% and 79.12% for unsupervised word-based HMM trained on parts of the LOB corpora, with a tagset of 134 tags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9994747042655945}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9991528987884521}]}, {"text": "With good initial conditions, such as good approximation of the tag distribution for each word, Elworthy reports an improvement to 94.6%, 92.27% and 94.51% on the same data sets.", "labels": [], "entities": []}, {"text": "Merialdo, on the other hand, reports an improvement to 92.6% and 94.4% for the case where 100 and 2000 sentences of the training corpus are manually tagged.", "labels": [], "entities": []}, {"text": "Modern Hebrew is characterized by rich morphology, with a high level of ambiguity.", "labels": [], "entities": []}, {"text": "On average, in our corpus, the number of possible analyses per word reached 2.4 (in contrast to 1.4 for English).", "labels": [], "entities": []}, {"text": "In Hebrew, several morphemes combine into a single word in both agglutinative and fusional ways.", "labels": [], "entities": []}, {"text": "This results in a potentially high number of tags for each word.", "labels": [], "entities": []}, {"text": "In contrast to English tag sets whose sizes range from 48 to 195, the number of tags for Hebrew, based on all combinations of the morphological attributes (part-of-speech, gender, number, person, tense, status, and the affixes' properties 2 ), The Knowledge Center for Hebrew processing is developing such corpora: http://mila.cs.technion.ac.il/ The list of morphological attributes is described in).", "labels": [], "entities": []}, {"text": "An in-depth discussion of the Hebrew word form is provided in can grow theoretically to about 300,000 tags.", "labels": [], "entities": []}, {"text": "In practice, we found only 1,934 tags in a corpus of news stories we gathered, which contains about 6M words.", "labels": [], "entities": []}, {"text": "The large size of such a tag set (about 10 times larger than the most comprehensive English tag set) is problematic in term of data sparseness.", "labels": [], "entities": []}, {"text": "Each morphological combination appears rarely, and more samples are required in order to learn the probabilistic model.", "labels": [], "entities": []}, {"text": "In this paper, we hypothesize that the large set of morphological features of Hebrew words, should be modeled by a compact morpheme model, based on the segmented words.", "labels": [], "entities": []}, {"text": "Our main result is that best performance is obtained when learning segmentation and morpheme tagging in one step, which is made possible by an appropriate text representation.", "labels": [], "entities": [{"text": "morpheme tagging", "start_pos": 84, "end_pos": 100, "type": "TASK", "confidence": 0.7356599867343903}]}], "datasetContent": [{"text": "We ran a series of experiments on a Hebrew corpus to compare various approaches to the full morphological disambiguation and PoS tagging tasks.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.8149074018001556}]}, {"text": "The training corpus is obtained from various newspaper sources and is characterized by the following statistics: 6M word occurrences, 178,580 distinct words, 64,541 distinct lemmas.", "labels": [], "entities": []}, {"text": "Overall, the ambiguity level is 2.4 (average number of analyses per word).", "labels": [], "entities": [{"text": "ambiguity level", "start_pos": 13, "end_pos": 28, "type": "METRIC", "confidence": 0.9753515720367432}]}, {"text": "We tested the results on a test corpus, manually annotated by 2 taggers according to the guidelines we published and checked for agreement.", "labels": [], "entities": []}, {"text": "The test corpus contains about 30K words.", "labels": [], "entities": []}, {"text": "We compared two unsupervised models over this data set: Word model, and Morpheme model.", "labels": [], "entities": []}, {"text": "We also tested two different sets of initial conditions.", "labels": [], "entities": []}, {"text": "Uniform distribution: For each word, each analysis provided by the analyzer is estimated with an equal likelihood.", "labels": [], "entities": []}, {"text": "Context Free approximation: We applied the CF algorithm of to estimate the likelihood of each analysis.", "labels": [], "entities": []}, {"text": "reports the results of full morphological disambiguation.", "labels": [], "entities": [{"text": "morphological disambiguation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.8714534342288971}]}, {"text": "For each morpheme and word models, three types of models were tested: First-order HMM, [2-] Partial second-order HMMonly state transitions were modeled (excluding B2 matrix), Second-order HMM (including the B2 matrix).", "labels": [], "entities": []}, {"text": "Analysis If we consider the tagger which selects the most probable morphological analysis for each Termination and path readout, the impact of error reduction is much less than reported therefor English -about 70% (79 -94).", "labels": [], "entities": [{"text": "error reduction", "start_pos": 143, "end_pos": 158, "type": "METRIC", "confidence": 0.9421824514865875}]}, {"text": "The key difference (beside the unclear characteristic of Elworthy initial condition -since he made use of an annotated corpus) is the much higher quality of the uniform distribution for Hebrew.", "labels": [], "entities": []}, {"text": "(3) Model order: The partial second-order HMM [2-] produced the best results for both word (85.75%) and morpheme (88.5%) models over the initial condition.", "labels": [], "entities": []}, {"text": "The full second-order HMM didn't upgrade the accuracy of the partial second-order, but achieved the best results for the uniform distribution morpheme model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9996531009674072}]}, {"text": "This is because the context-free approximation does not take into account the tag of the previous word, which is part of model 2.", "labels": [], "entities": []}, {"text": "We believe that initializing the morpheme model over a small set of annotated corpus will set much stronger initial condition for this model.", "labels": [], "entities": []}, {"text": "(4) Model type: The main result of this paper is the error reduction of the morpheme model with respect to the word model: about 19.3% (85.75 -88.5).", "labels": [], "entities": [{"text": "error reduction", "start_pos": 53, "end_pos": 68, "type": "METRIC", "confidence": 0.9645174741744995}]}, {"text": "In addition, we apply the above models for the simpler task of segmentation and PoS tagging, as reported in.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 63, "end_pos": 75, "type": "TASK", "confidence": 0.9829902648925781}, {"text": "PoS tagging", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.8117330074310303}]}, {"text": "The task requires picking the correct morphemes of each word with their correct PoS (excluding all other morphological features).", "labels": [], "entities": [{"text": "PoS", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9500328898429871}]}, {"text": "The best result for this task is obtained with the morpheme model 2: 92.32%.", "labels": [], "entities": []}, {"text": "For this simpler task, the improvement brought by the morpheme model over the word model is less significant, but still consists of a 5% error reduction.", "labels": [], "entities": []}, {"text": "Unknown words account fora significant chunk of the errors.", "labels": [], "entities": []}, {"text": "shows the distribution of errors contributed by unknown words (words that cannot be analyzed by the morphological analyzer).", "labels": [], "entities": []}, {"text": "7.5% of the words in the test corpus are unknown: 4% are not recognized at all by the morphological analyzer (marked as   , and for 3.5%, the set of analyses proposed by the analyzer does not contain the correct analysis.", "labels": [], "entities": []}, {"text": "We extended the lexicon to include missing and none lexemes of the closed sets.", "labels": [], "entities": []}, {"text": "In addition, we modified the analyzer to extract all possible segmentations of unknown words, with all the possible tags for the segmented affixes, where the remaining unknown baseforms are tagged as UK.", "labels": [], "entities": []}, {"text": "The model was trained over this set.", "labels": [], "entities": []}, {"text": "In the next phase, the corpus was automatically tagged, according to the trained model, in order to form a tag distribution for each unknown word, according to its context and its form.", "labels": [], "entities": []}, {"text": "Finally, the tag for each unknown word were selected according to its tag distribution.", "labels": [], "entities": []}, {"text": "This strategy accounts for about half of the 7.5% unknown words.", "labels": [], "entities": []}, {"text": "shows the confusion matrix for known words (5% and up).", "labels": [], "entities": []}, {"text": "The key confusions can be attributed to linguistic properties of Modern Hebrew: most Hebrew proper names are also nouns (and they are not marked by capitalization) -which explains the PN/N confusion.", "labels": [], "entities": []}, {"text": "The verb/noun and verb/adjective confusions are explained by the nature of the participle form in Hebrew (beinoni) -participles behave syntactically almost in an identical manner as nouns.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Segmentation and PoS Tagging", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9588216543197632}, {"text": "PoS Tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.832498162984848}]}, {"text": " Table 5: Unknown Word Distribution", "labels": [], "entities": [{"text": "Unknown Word Distribution", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6910115679105123}]}]}