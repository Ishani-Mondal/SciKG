{"title": [{"text": "Semantic Role Labeling via FrameNet, VerbNet and PropBank", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7660241921742758}, {"text": "VerbNet", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.9277981519699097}, {"text": "PropBank", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8285115957260132}]}], "abstractContent": [{"text": "This article describes a robust semantic parser that uses abroad knowledge base created by interconnecting three major resources: FrameNet, VerbNet and PropBank.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.867447018623352}, {"text": "PropBank", "start_pos": 152, "end_pos": 160, "type": "DATASET", "confidence": 0.8975206017494202}]}, {"text": "The FrameNet corpus contains the examples annotated with semantic roles whereas the VerbNet lexicon provides the knowledge about the syntactic behavior of the verbs.", "labels": [], "entities": [{"text": "FrameNet corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9043439030647278}, {"text": "VerbNet lexicon", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.9047888517379761}]}, {"text": "We connect VerbNet and FrameNet by mapping the FrameNet frames to the VerbNet Intersec-tive Levin classes.", "labels": [], "entities": []}, {"text": "The PropBank corpus, which is tightly connected to the VerbNet lexicon, is used to increase the verb coverage and also to test the effectiveness of our approach.", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9382412135601044}, {"text": "VerbNet lexicon", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9395309388637543}]}, {"text": "The results indicate that our model is an interesting step towards the design of more robust semantic parsers.", "labels": [], "entities": []}], "introductionContent": [{"text": "During the last years a noticeable effort has been devoted to the design of lexical resources that can provide the training ground for automatic semantic role labelers.", "labels": [], "entities": [{"text": "automatic semantic role labelers", "start_pos": 135, "end_pos": 167, "type": "TASK", "confidence": 0.6008060276508331}]}, {"text": "Unfortunately, most of the systems developed until now are confined to the scope of the resource used for training.", "labels": [], "entities": []}, {"text": "Avery recent example in this sense was provided by the CONLL 2005 shared task) on PropBank (PB)) role labeling.", "labels": [], "entities": [{"text": "CONLL 2005 shared task", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.9197711646556854}, {"text": "PropBank (PB)) role labeling", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.6366532742977142}]}, {"text": "The systems that participated in the task were trained on the Wall Street Journal corpus (WSJ) and tested on portions of WSJ and Brown corpora.", "labels": [], "entities": [{"text": "Wall Street Journal corpus (WSJ)", "start_pos": 62, "end_pos": 94, "type": "DATASET", "confidence": 0.9690712094306946}, {"text": "WSJ", "start_pos": 121, "end_pos": 124, "type": "DATASET", "confidence": 0.9723313450813293}]}, {"text": "While the best F-measure recorded on WSJ was 80%, on the Brown corpus, the F-measure dropped below 70%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9764180779457092}, {"text": "WSJ", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.9349706172943115}, {"text": "Brown corpus", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9840229451656342}, {"text": "F-measure", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9935821890830994}]}, {"text": "The most significant causes for this performance decay were highly ambiguous and unseen predicates (i.e. predicates that do not have training examples).", "labels": [], "entities": []}, {"text": "The same problem was again highlighted by the results obtained with and without the frame information in the Senseval-3 competition) of FrameNet () role labeling task.", "labels": [], "entities": [{"text": "FrameNet () role labeling task", "start_pos": 136, "end_pos": 166, "type": "TASK", "confidence": 0.6561342477798462}]}, {"text": "When such information is not used by the systems, the performance decreases by 10 percent points.", "labels": [], "entities": []}, {"text": "This is quite intuitive as the semantics of many roles strongly depends on the focused frame.", "labels": [], "entities": []}, {"text": "Thus, we cannot expect a good performance on new domains in which this information is not available.", "labels": [], "entities": []}, {"text": "A solution to this problem is the automatic frame detection.", "labels": [], "entities": [{"text": "frame detection", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.8380893170833588}]}, {"text": "Unfortunately, our preliminary experiments showed that given a FrameNet (FN) predicate-argument structure, the task of identifying the associated frame can be performed with very good results when the verb predicates have enough training examples, but becomes very challenging otherwise.", "labels": [], "entities": []}, {"text": "The predicates belonging to new application domains (i.e. not yet included in FN) are especially problematic since there is no training data available.", "labels": [], "entities": [{"text": "FN", "start_pos": 78, "end_pos": 80, "type": "DATASET", "confidence": 0.7540314793586731}]}, {"text": "Therefore, we should rely on a semantic context alternative to the frame (.", "labels": [], "entities": []}, {"text": "Such context should have a wide coverage and should be easily derivable from FN data.", "labels": [], "entities": [{"text": "FN data", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.8461883664131165}]}, {"text": "Avery good candidate seems to be the Intersective Levin class (ILC) () that can be found as well in other predicate resources like PB and VerbNet (VN) ().", "labels": [], "entities": []}, {"text": "In this paper we have investigated the above claim by designing a semi-automatic algorithm that assigns ILCs to FN verb predicates and by carrying out several semantic role labeling (SRL) experiments in which we replace the frame with the ILC information.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 159, "end_pos": 187, "type": "TASK", "confidence": 0.7849251925945282}]}, {"text": "We used support vector ma-chines with (a) polynomial kernels to learn the semantic role classification and (b) Tree Kernels) for learning both frame and ILC classification.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.6510178844134012}, {"text": "ILC classification", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.6834314316511154}]}, {"text": "Tree kernels were applied to the syntactic trees that encode the subcategorization structures of verbs.", "labels": [], "entities": []}, {"text": "This means that, although FN contains three types of predicates (nouns, adjectives and verbs), we only concentrated on the verb predicates and their roles.", "labels": [], "entities": [{"text": "FN", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.6946395635604858}]}, {"text": "The results show that: (1) ILC can be derived with high accuracy for both FN and Probank and (2) ILC can replace the frame feature with almost no loss in the accuracy of the SRL systems.", "labels": [], "entities": [{"text": "ILC", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.7342261672019958}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9989902377128601}, {"text": "FN", "start_pos": 74, "end_pos": 76, "type": "DATASET", "confidence": 0.9012241363525391}, {"text": "Probank", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.8557548522949219}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9990960359573364}]}, {"text": "At the same time, ILC provides better predicate coverage as it can also be learned from other corpora (e.g. PB).", "labels": [], "entities": []}, {"text": "In the remainder of this paper, Section 2 summarizes previous work done on FN automatic role detection.", "labels": [], "entities": [{"text": "FN automatic role detection", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.8763930201530457}]}, {"text": "It also explains in more detail why models based exclusively on this corpus are not suitable for free-text parsing.", "labels": [], "entities": [{"text": "free-text parsing", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7040883898735046}]}, {"text": "Section 3 focuses on VN and PB and how they can enhance the robustness of our semantic parser.", "labels": [], "entities": []}, {"text": "Section 4 describes the mapping between frames and ILCs whereas Section 5 presents the experiments that support our thesis.", "labels": [], "entities": []}, {"text": "Finally, Section 6 summarizes the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the previous sections we have presented the algorithm for annotating the verb predicates of FrameNet (FN) with Intersective Levin classes (ILCs).", "labels": [], "entities": [{"text": "FrameNet (FN)", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.7663299441337585}]}, {"text": "In order to show the effectiveness of this annotation and of the ILCs in general we have performed several experiments.", "labels": [], "entities": []}, {"text": "First, we trained (1) an ILC multiclassifier from FN, (2) an ILC multiclassifier from PB and    Our second set of experiments regards the automatic labeling of FN semantic roles on FN corpus when using as features: gold frame, gold ILC, automatically detected frame and automatically detected ILC.", "labels": [], "entities": [{"text": "FN", "start_pos": 50, "end_pos": 52, "type": "DATASET", "confidence": 0.9367738962173462}, {"text": "FN corpus", "start_pos": 181, "end_pos": 190, "type": "DATASET", "confidence": 0.8212031722068787}]}, {"text": "We show that in all situations in which the VN class feature is used, the accuracy loss, compared to the usage of the frame feature, is negligible.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9995487332344055}]}, {"text": "This suggests that the ILC can successfully replace the frame feature for the task of semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.705608586470286}]}, {"text": "Another set of experiments regards the generalization property of the ILC.", "labels": [], "entities": [{"text": "ILC", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.9273742437362671}]}, {"text": "We show the impact of this feature when very few training data is available and its evolution when adding more and more training examples.", "labels": [], "entities": []}, {"text": "We again perform the experiments for: gold frame, gold ILC, automatically detected frame and automatically detected ILC.", "labels": [], "entities": []}, {"text": "Finally, we simulate the difficulty of free text by annotating PB with FN semantic roles.", "labels": [], "entities": []}, {"text": "We used PB because it covers a different set of verbal predicates and also because it is very different from FN at the level of vocabulary and sometimes even syntax.", "labels": [], "entities": []}, {"text": "These characteristics make PB a difficult testbed for the semantic role models trained on FN.", "labels": [], "entities": [{"text": "FN", "start_pos": 90, "end_pos": 92, "type": "DATASET", "confidence": 0.8370245099067688}]}, {"text": "In the following section we present the results obtained for each of the experiments mentioned above.", "labels": [], "entities": []}, {"text": "The corpora available for the experiments were PB and FN.", "labels": [], "entities": [{"text": "FN", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.6018974184989929}]}, {"text": "PB contains about 54,900 predicates and gold parse trees.", "labels": [], "entities": [{"text": "PB", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.863192617893219}]}, {"text": "We used sections from 02 to 22 (52,172 predicates) to train the ILC classifiers and Section 23 (2,742 predicates) for testing purposes.", "labels": [], "entities": [{"text": "ILC", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.9654260277748108}]}, {"text": "The number of ILCs is 180 in PB and 133 on FN, i.e. the classes that we were able to map.", "labels": [], "entities": [{"text": "FN", "start_pos": 43, "end_pos": 45, "type": "DATASET", "confidence": 0.8736751079559326}]}, {"text": "For the experiments on FN corpus, we extracted 58,384 sentences from the 319 frames that contain at least one verb annotation.", "labels": [], "entities": [{"text": "FN corpus", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.8308118879795074}]}, {"text": "There are 128,339 argument instances of 454 semantic roles.", "labels": [], "entities": []}, {"text": "In our evaluation we use only verbal predicates.", "labels": [], "entities": []}, {"text": "Moreover, as there is no fixed split between training and testing, we randomly selected 20% of sentences for testing and 80% for training.", "labels": [], "entities": []}, {"text": "The sentences were processed using Charniak's parser) to generate parse trees automatically.", "labels": [], "entities": []}, {"text": "The classification models were implemented by means of the SVM-light-TK software available at http://ai-nlp.info.uniroma2.it/moschitti which encodes tree kernels in the SVM-light software.", "labels": [], "entities": []}, {"text": "We used the default parameters.", "labels": [], "entities": []}, {"text": "The classification performance was evaluated using the F 1 measure for the individual role and ILC classifiers and the accuracy for the multiclassifiers.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9558390378952026}, {"text": "F 1 measure", "start_pos": 55, "end_pos": 66, "type": "METRIC", "confidence": 0.9803370038668314}, {"text": "ILC", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.8900893330574036}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9993983507156372}]}], "tableCaptions": [{"text": " Table 3: Results of the mapping algorithm.", "labels": [], "entities": []}, {"text": " Table 4: F1s of some individual ILC classifiers and the overall multiclassifier accuracy (180 classes on  PB and 133 on FN).", "labels": [], "entities": [{"text": "F1s", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9993764758110046}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.92282634973526}]}, {"text": " Table 5: F1s of some individual FN role classifiers and the overall multiclassifier accuracy (454 roles).", "labels": [], "entities": [{"text": "F1s", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9992223978042603}, {"text": "FN role classifiers", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.6112697223822275}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9091605544090271}]}]}