{"title": [{"text": "The Effect of Translation Quality in MT-Based Cross-Language Information Retrieval", "labels": [], "entities": [{"text": "MT-Based Cross-Language Information Retrieval", "start_pos": 37, "end_pos": 82, "type": "TASK", "confidence": 0.8805714398622513}]}], "abstractContent": [{"text": "This paper explores the relationship between the translation quality and the retrieval effectiveness in Machine Translation (MT) based Cross-Language Information Retrieval (CLIR).", "labels": [], "entities": [{"text": "Machine Translation (MT) based Cross-Language Information Retrieval (CLIR)", "start_pos": 104, "end_pos": 178, "type": "TASK", "confidence": 0.8318667411804199}]}, {"text": "To obtain MT systems of different translation quality, we degrade a rule-based MT system by decreasing the size of the rule base and the size of the dictionary.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9859570264816284}, {"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9248017072677612}]}, {"text": "We use the degraded MT systems to translate queries and submit the translated queries of varying quality to the IR system.", "labels": [], "entities": [{"text": "IR", "start_pos": 112, "end_pos": 114, "type": "TASK", "confidence": 0.642677366733551}]}, {"text": "Retrieval effectiveness is found to correlate highly with the translation quality of the queries.", "labels": [], "entities": [{"text": "Retrieval", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.880313515663147}]}, {"text": "We further analyze the factors that affect the retrieval effectiveness.", "labels": [], "entities": []}, {"text": "Title queries are found to be preferred in MT-based CLIR.", "labels": [], "entities": [{"text": "MT-based CLIR", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.7196567952632904}]}, {"text": "In addition, dictionary-based degradation is shown to have stronger impact than rule-based degradation in MT-based CLIR.", "labels": [], "entities": [{"text": "MT-based CLIR", "start_pos": 106, "end_pos": 119, "type": "TASK", "confidence": 0.7669075131416321}]}], "introductionContent": [{"text": "Cross-Language Information Retrieval (CLIR) enables users to construct queries in one language and search the documents in another language.", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval (CLIR)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7913975814978281}]}, {"text": "CLIR requires that either the queries or the documents be translated from a language into another, using available translation resources.", "labels": [], "entities": [{"text": "CLIR", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7890106439590454}]}, {"text": "Previous studies have concentrated on query translation because it is computationally less expensive than document translation, which requires a lot of processing time and storage costs.", "labels": [], "entities": [{"text": "query translation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.9001321494579315}, {"text": "document translation", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.7819221615791321}]}, {"text": "There are three kinds of methods to perform query translation, namely Machine Translation (MT) based methods, dictionary-based methods and corpus-based methods.", "labels": [], "entities": [{"text": "query translation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7334354966878891}, {"text": "Machine Translation (MT)", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.8377829194068909}]}, {"text": "Corresponding to these methods, three types of translation resources are required: MT systems, bilingual wordlists and parallel or comparable corpora.", "labels": [], "entities": [{"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.9510571956634521}]}, {"text": "CLIR effectiveness depends on both the design of the retrieval system and the quality of the translation resources that are used.", "labels": [], "entities": []}, {"text": "In this paper, we explore the relationship between the translation quality of the MT system and the retrieval effectiveness.", "labels": [], "entities": [{"text": "MT", "start_pos": 82, "end_pos": 84, "type": "TASK", "confidence": 0.9761850237846375}]}, {"text": "The MT system involved in this research is a rule-based Englishto-Chinese MT (ECMT) system.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9532642364501953}]}, {"text": "We degrade the MT system in two ways.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9778615832328796}]}, {"text": "One is to degrade the rule base of the system by progressively removing rules from it.", "labels": [], "entities": []}, {"text": "The other is to degrade the dictionary by gradually removing word entries from it.", "labels": [], "entities": []}, {"text": "In both methods, we observe successive changes on translation quality of the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9736642241477966}]}, {"text": "We conduct query translation with the degraded MT systems and obtain translated queries of varying quality.", "labels": [], "entities": [{"text": "query translation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8426681458950043}, {"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9308035373687744}]}, {"text": "Then we submit the translated queries to the IR system and evaluate the performance.", "labels": [], "entities": [{"text": "IR", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.8086018562316895}]}, {"text": "Retrieval effectiveness is found to be strongly influenced by the translation quality of the queries.", "labels": [], "entities": []}, {"text": "We further analyze the factors that affect the retrieval effectiveness.", "labels": [], "entities": []}, {"text": "Title queries are found to be preferred in MT-based query translation.", "labels": [], "entities": [{"text": "MT-based query translation", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.9256914258003235}]}, {"text": "In addition, the size of the dictionary is shown to have stronger impact on retrieval effectiveness than the size of the rule base in MTbased query translation.", "labels": [], "entities": [{"text": "MTbased query translation", "start_pos": 134, "end_pos": 159, "type": "TASK", "confidence": 0.7680715123812357}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we briefly review related work.", "labels": [], "entities": []}, {"text": "In section 3, we introduce two systems involved in this research: the rule-based ECMT system and the KIDS IR system.", "labels": [], "entities": [{"text": "KIDS IR", "start_pos": 101, "end_pos": 108, "type": "TASK", "confidence": 0.575583815574646}]}, {"text": "In section 4, we describe our experimental method.", "labels": [], "entities": []}, {"text": "Section 5 and section 6 reports and discusses the experimental results.", "labels": [], "entities": []}, {"text": "Finally we present our conclusion and future work in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "To obtain MT systems of varying quality, we degrade the rule-based ECMT system by impairing the translation resources comprised in the system.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9895983934402466}]}, {"text": "Then we use the degraded MT systems to translate the queries and evaluate the translation quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.8258850574493408}]}, {"text": "Next, we submit the translated queries to the KIDS system and evaluate the retrieval performance.", "labels": [], "entities": [{"text": "KIDS", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.6985573768615723}]}, {"text": "Finally we calculate the correlation between the variation of translation quality and the variation of retrieval effectiveness to analyze the relationship between MT performance and CLIR performance.", "labels": [], "entities": [{"text": "MT", "start_pos": 163, "end_pos": 165, "type": "TASK", "confidence": 0.9826220273971558}]}, {"text": "We measure the performance of the MT system by translation quality and use NIST score as the evaluation measure).", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9893630146980286}, {"text": "NIST score", "start_pos": 75, "end_pos": 85, "type": "DATASET", "confidence": 0.779874324798584}]}, {"text": "The In the following part of this paper, rules refer to transfer rules unless explicitly stated.", "labels": [], "entities": []}, {"text": "NIST scores reported in this paper are generated by NIST scoring toolkit 2 . For retrieval performance, we use Mean Average Precision (MAP) as the evaluation measure.", "labels": [], "entities": [{"text": "NIST", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.911902666091919}, {"text": "NIST scoring toolkit", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.8528188467025757}, {"text": "Mean Average Precision (MAP)", "start_pos": 111, "end_pos": 139, "type": "METRIC", "confidence": 0.972830464442571}]}, {"text": "The MAP values reported in this paper are generated by trec_eval toolkit 3 , which is the standard tool used by TREC for evaluating an ad hoc retrieval run.", "labels": [], "entities": [{"text": "MAP", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8339505195617676}]}, {"text": "For each TREC topic, three fields are provided: title, description and narrative, both in Chinese and English, as shown in.", "labels": [], "entities": [{"text": "TREC topic", "start_pos": 9, "end_pos": 19, "type": "TASK", "confidence": 0.799444854259491}]}, {"text": "The title field is the statement of the topic.", "labels": [], "entities": []}, {"text": "The description field lists some terms that describe the topic.", "labels": [], "entities": []}, {"text": "The narrative field provides a complete description of document relevance for the assessors.", "labels": [], "entities": []}, {"text": "In our experiments, we use two kinds of queries: title queries (use only the title field) and desc queries (use only the description field).", "labels": [], "entities": []}, {"text": "We do not use narrative field because it is the criteria used by the assessors to judge whether a document is relevant or not, so it usually contains quite a number of unrelated words.", "labels": [], "entities": []}, {"text": "Title queries are one-sentence queries.", "labels": [], "entities": [{"text": "Title queries", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6177721172571182}]}, {"text": "When use NIST scoring tool to evaluate the translation quality of the MT system, reference translations of source language sentences are required.", "labels": [], "entities": [{"text": "MT", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9751064777374268}]}, {"text": "NIST scoring tool supports multi references.", "labels": [], "entities": [{"text": "NIST scoring", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8467189371585846}]}, {"text": "In our experiments, we introduce two reference translations for each title query.", "labels": [], "entities": []}, {"text": "One is the Chinese title (C-title) in title field of the original TREC topic (reference translation 1); the other is the translation of the title query given by a human translator (reference translation 2).", "labels": [], "entities": []}, {"text": "This is to alleviate the bias on translation evaluation introduced by only one reference translation.", "labels": [], "entities": [{"text": "translation evaluation", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.9653719961643219}]}, {"text": "An example of title query and its reference translations are shown in.", "labels": [], "entities": []}, {"text": "Reference 1 is the Chinese title provided in original TREC topic.", "labels": [], "entities": [{"text": "TREC topic", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.6680372357368469}]}, {"text": "Reference 2 is the human translation of the query.", "labels": [], "entities": []}, {"text": "For this query, the translation output generated by the MT system is \"\u5728\u4e2d\u56fd\u7684\u673a\u5668\u4eba\u6280\u672f\u7814\u7a76\".", "labels": [], "entities": [{"text": "MT", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.8049538135528564}]}, {"text": "If only use reference 1 as reference translation, the system output will not be regarded as a good translation.", "labels": [], "entities": []}, {"text": "But in fact, it is a good translation for the query.", "labels": [], "entities": []}, {"text": "Introducing reference 2 helps to alleviate the unfair evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Summary of Runs", "labels": [], "entities": [{"text": "Summary of Runs", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.5537653168042501}]}, {"text": " Table 4. Fall on Translation Quality & Retrieval  Effectiveness", "labels": [], "entities": [{"text": "Translation Quality & Retrieval  Effectiveness", "start_pos": 18, "end_pos": 64, "type": "TASK", "confidence": 0.7479974031448364}]}]}