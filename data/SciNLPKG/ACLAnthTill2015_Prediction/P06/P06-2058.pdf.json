{"title": [{"text": "Obfuscating Document Stylometry to Preserve Author Anonymity", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper explores techniques for reducing the effectiveness of standard authorship attribution techniques so that an author A can preserve anonymity fora particular document D.", "labels": [], "entities": []}, {"text": "We discuss feature selection and adjustment and show how this information can be fed back to the author to create anew document D' for which the calculated attribution moves away from A.", "labels": [], "entities": []}, {"text": "Since it can belabor intensive to adjust the document in this fashion , we attempt to quantify the amount of effort required to produce the ano-nymized document and introduce two levels of anonymization: shallow and deep.", "labels": [], "entities": []}, {"text": "In our test set, we show that shallow anonymization can be achieved by making 14 changes per 1000 words to reduce the likelihood of identifying A as the author by an average of more than 83%.", "labels": [], "entities": []}, {"text": "For deep anonymization, we adapt the unmasking work of Koppel and Schler to provide feedback that allows the author to choose the level of ano-nymization.", "labels": [], "entities": []}], "introductionContent": [{"text": "Authorship identification has been along standing topic in the field of stylometry, the analysis of literary style).", "labels": [], "entities": [{"text": "Authorship identification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8240390717983246}]}, {"text": "Issues of style, genre, and authorship are an interesting sub-area of text categorization.", "labels": [], "entities": []}, {"text": "In authorship detection it is not the topic of a text but rather the stylistic properties that are of interest.", "labels": [], "entities": [{"text": "authorship detection", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8449400961399078}]}, {"text": "The writing style of a particular author can be identified by analyzing the form of the writing, rather than the content.", "labels": [], "entities": []}, {"text": "The analysis of style therefore needs to abstract away from the content and focus on the content-independent form of the linguistic expressions in a text.", "labels": [], "entities": []}, {"text": "Advances in authorship attribution have raised concerns about whether or not authors can truly maintain their anonymity (.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.8021975159645081}]}, {"text": "While there are clearly many reasons for wanting to unmask an anonymous author, notably law enforcement and historical scholarship, there are also many legitimate reasons for an author to wish to remain anonymous, chief among them the desire to avoid retribution from an employer or government agency.", "labels": [], "entities": []}, {"text": "Beyond the issue of personal privacy, the public good is often served by whistle-blowers who expose wrongdoing in corporations and governments.", "labels": [], "entities": []}, {"text": "The loss of an expectation of privacy can result in a chilling effect where individuals are too afraid to draw attention to a problem, because they fear being discovered and punished for their actions.", "labels": [], "entities": []}, {"text": "It is for this reason that we set out to investigate the feasibility of creating a tool to support anonymizing a particular document, given the assumption that the author is willing to expend a reasonable amount of effort in the process.", "labels": [], "entities": []}, {"text": "More generally, we sought to investigate the sensitivity of current attribution techniques to manipulation.", "labels": [], "entities": []}, {"text": "For our experiments, we chose a standard data set, the Federalist Papers, since the variety of published results allows us to simulate authorship attribution \"attacks\" on the obfuscated document.", "labels": [], "entities": [{"text": "Federalist Papers", "start_pos": 55, "end_pos": 72, "type": "DATASET", "confidence": 0.9100448787212372}]}, {"text": "This is important since there is no clear consensus as to which features should be used for authorship attribution.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.854602575302124}]}], "datasetContent": [{"text": "Evaluating the effectiveness of any authorship obfuscation approach is made difficult by the fact that it is crucially dependent on the authorship detection method that is being utilized.", "labels": [], "entities": [{"text": "authorship detection", "start_pos": 136, "end_pos": 156, "type": "TASK", "confidence": 0.7929675877094269}]}, {"text": "An advantage of using the Federalist Papers as the test data set is that there are numerous papers documenting various methods that researchers have used to identify the authors of the disputed papers.", "labels": [], "entities": [{"text": "Federalist Papers", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.8983557522296906}]}, {"text": "However, because of differences in the exact data set 2 and machine learning algorithm used, it is not reasonable to create an exact and complete implementation of each system.", "labels": [], "entities": []}, {"text": "For our experiments, we used only the standard Federalist Papers documents and tested each feature set using linear-kernel SVMs, which have been shown to be effective in text categorization.", "labels": [], "entities": [{"text": "Federalist Papers documents", "start_pos": 47, "end_pos": 74, "type": "DATASET", "confidence": 0.9299134413401285}]}, {"text": "To train our SVMs we used a sequential minimal optimization (SMO) implementation described in).", "labels": [], "entities": [{"text": "sequential minimal optimization (SMO)", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7111852069695791}]}, {"text": "The SVM feature sets that we used for the evaluation are summarized in.", "labels": [], "entities": []}, {"text": "For the early experiments described in the previous section we used SVM30, which incorporates the final set of 30 terms that Mosteller & Wallace used for their study.", "labels": [], "entities": [{"text": "SVM30", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.8132302165031433}]}, {"text": "As noted earlier, they made use of a different data set than we did, so we did expect to see some differences in the results.", "labels": [], "entities": []}, {"text": "The baseline model (plotted as the leftmost column of points in and) assigned all of the disputed papers to Madison except one  We built SVMs for each feature set listed in and applied the obfuscation technique described above by adjusting the values in the feature vector by increments of the single-word probability for each document.", "labels": [], "entities": []}, {"text": "The results that we obtained were the same as observed with our test model -all of the models were coerced to prefer Hamilton for each of the disputed documents.", "labels": [], "entities": []}, {"text": "Federalists with the possible exception of No. 55. For No. 55 our evidence is relatively weak.\" shows the graph for SVM70, the model that was most resilient to our obfuscation techniques.", "labels": [], "entities": [{"text": "SVM70", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.9145873785018921}]}, {"text": "The results for all models are summarized in 99.01% 0.74% : Percent reduction in the confidence of assigning the disputed papers to Madison for each of the tested feature sets.", "labels": [], "entities": [{"text": "confidence", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9732787609100342}]}, {"text": "Of particular note in the results are those for SVM03, which proved to be the most fragile model because of its low dimension.", "labels": [], "entities": [{"text": "SVM03", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.8970446586608887}]}, {"text": "If we consider this case an outlier and remove it from study, our overall reduction becomes 83.82%.", "labels": [], "entities": [{"text": "reduction", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9849227666854858}]}], "tableCaptions": [{"text": " Table 6. The overall reduction  achieved across all models is 86.86%.", "labels": [], "entities": [{"text": "reduction", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9885313510894775}]}]}