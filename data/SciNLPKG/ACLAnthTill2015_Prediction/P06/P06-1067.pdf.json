{"title": [{"text": "Distortion Models For Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.83650141954422}]}], "abstractContent": [{"text": "In this paper, we argue that n-gram language models are not sufficient to address word reordering required for Machine Translation.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.6993542462587357}, {"text": "Machine Translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.8786425292491913}]}, {"text": "We propose anew distortion model that can be used with existing phrase-based SMT decoders to address those n-gram language model limitations.", "labels": [], "entities": [{"text": "SMT decoders", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.858810156583786}]}, {"text": "We present empirical results in Arabic to English Machine Translation that show statistically significant improvements when our proposed model is used.", "labels": [], "entities": [{"text": "English Machine Translation", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.601039876540502}]}, {"text": "We also propose a novel metric to measure word order similarity (or difference) between any pair of languages based on word alignments.", "labels": [], "entities": [{"text": "word order similarity (or difference)", "start_pos": 42, "end_pos": 79, "type": "METRIC", "confidence": 0.6645517476967403}]}], "introductionContent": [{"text": "A language model is a statistical model that gives a probability distribution over possible sequences of words.", "labels": [], "entities": []}, {"text": "It computes the probability of producing a given word w 1 given all the words that precede it in the sentence.", "labels": [], "entities": []}, {"text": "An n-gram language model is an n-th order Markov model where the probability of generating a given word depends only on the last n \u2212 1 words immediately preceding it and is given by the following equation: P (w k 1 ) = P (w 1 )P (w 2 |w 1 ) \u00b7 \u00b7 \u00b7 P (w n |w n\u22121 where k >= n.", "labels": [], "entities": []}, {"text": "N -gram language models have been successfully used in Automatic Speech Recognition (ASR) as was first proposed by (.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.7836734652519226}]}, {"text": "They play an important role in selecting among several candidate word realization of a given acoustic signal.", "labels": [], "entities": []}, {"text": "N -gram language models have also been used in Statistical Machine Translation (SMT) as proposed by).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.8796386818091074}]}, {"text": "The run-time search procedure used to find the most likely translation (or transcription in the case of Speech Recognition) is typically referred to as decoding.", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7569493055343628}]}, {"text": "There is a fundamental difference between decoding for machine translation and decoding for speech recognition.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7211233675479889}, {"text": "speech recognition", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7908214628696442}]}, {"text": "When decoding a speech signal, words are generated in the same order in which their corresponding acoustic signal is consumed.", "labels": [], "entities": []}, {"text": "However, that is not necessarily the casein MT due to the fact that different languages have different word order requirements.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9792978763580322}]}, {"text": "For example, in Spanish and Arabic adjectives are mainly noun post-modifiers, whereas in English adjectives are noun pre-modifiers.", "labels": [], "entities": []}, {"text": "Therefore, when translating between Spanish and English, words must usually be reordered.", "labels": [], "entities": []}, {"text": "Existing statistical machine translation decoders have mostly relied on language models to select the proper word order among many possible choices when translating between two languages.", "labels": [], "entities": [{"text": "statistical machine translation decoders", "start_pos": 9, "end_pos": 49, "type": "TASK", "confidence": 0.7114680707454681}]}, {"text": "In this paper, we argue that a language model is not sufficient to adequately address this issue, especially when translating between languages that have very different word orders as suggested by our experimental results in Section 5.", "labels": [], "entities": []}, {"text": "We propose anew distortion model that can be used as an additional component in SMT decoders.", "labels": [], "entities": [{"text": "SMT decoders", "start_pos": 80, "end_pos": 92, "type": "TASK", "confidence": 0.9347434341907501}]}, {"text": "This new model leads to significant improvements in MT quality as measured by BLEU ().", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9822573065757751}, {"text": "BLEU", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9983514547348022}]}, {"text": "The experimental results we report in this paper are for Arabic-English machine translation of news stories.", "labels": [], "entities": [{"text": "machine translation of news stories", "start_pos": 72, "end_pos": 107, "type": "TASK", "confidence": 0.8325497925281524}]}, {"text": "We also present a novel method for measuring word order similarity (or differences) between any given pair of languages based on word alignments as described in Section 3.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents a review of related work.", "labels": [], "entities": []}, {"text": "In Section 3 we propose a method for measuring the distortion between any given pair of languages.", "labels": [], "entities": []}, {"text": "In Section 4, we present our proposed distortion model.", "labels": [], "entities": []}, {"text": "In Section 5, we present some empirical results that show the utility of our distortion model for statistical machine translation systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.6226693093776703}]}, {"text": "Then, we conclude this paper with a discussion in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The phrase-based decoder we use is inspired by the decoder described in ( and similar to that described in.", "labels": [], "entities": []}, {"text": "It is a multistack, multi-beam search decoder with n stacks (where n is the length of the source sentence being decoded): BLEU scores for the word order restoration task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.9994001388549805}, {"text": "word order restoration", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.7976786891619364}]}, {"text": "The BLEU scores reported here are with 1 reference.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9986172914505005}]}, {"text": "The input is the reordered English in the reference.", "labels": [], "entities": []}, {"text": "The 95% Confidence \u03c3 ranges from 0.011 to 0.016 and abeam associated with each stack as described in).", "labels": [], "entities": [{"text": "Confidence \u03c3", "start_pos": 8, "end_pos": 20, "type": "METRIC", "confidence": 0.9658858180046082}]}, {"text": "The search is done inn time steps.", "labels": [], "entities": []}, {"text": "In time step i, only hypotheses that cover exactly i source words are extended.", "labels": [], "entities": []}, {"text": "The beam search algorithm attempts to find the translation (i.e., hypothesis that covers all source words) with the minimum cost as in ( and . The distortion cost is added to the log-linear mixture of the hypothesis extension in a fashion similar to the language model cost.", "labels": [], "entities": []}, {"text": "A hypothesis covers a subset of the source words.", "labels": [], "entities": []}, {"text": "The final translation is a hypothesis that covers all source words and has the minimum cost among all possible hypotheses that coverall source words.", "labels": [], "entities": []}, {"text": "A hypothesis h is extended by matching the phrase dictionary against source word sequences in the input sentence that are not covered in h.", "labels": [], "entities": []}, {"text": "The cost of the new hypothesis C(h new ) = C(h) + C(e), where C(e) is the cost of this extension.", "labels": [], "entities": []}, {"text": "The main components of the cost of extension e can be defined by the following equation: where C LM (e) is the language model cost, CT M (e) is the translation model cost, and CD (e) is the distortion cost.", "labels": [], "entities": [{"text": "distortion", "start_pos": 190, "end_pos": 200, "type": "METRIC", "confidence": 0.9521331191062927}]}, {"text": "The extension cost depends on the hypothesis being extended, the phrase being used in the extension, and the source word positions being covered.", "labels": [], "entities": []}, {"text": "The word reorderings that are explored by the search algorithm are controlled by two parameters sand was described in (.", "labels": [], "entities": []}, {"text": "The first parameter s denotes the number of source words that are temporarily skipped (i.e., temporarily left uncovered) during the search to cover a source word to the right of the skipped words.", "labels": [], "entities": []}, {"text": "The second parameter is the window width w, which is defined as the distance (in number of source words) between the left-most uncovered source word and the right-most covered source word.", "labels": [], "entities": [{"text": "window width w", "start_pos": 28, "end_pos": 42, "type": "METRIC", "confidence": 0.7392500241597494}]}, {"text": "To illustrate these restrictions, let us assume the input sentence consists of the following sequence (f 1 , f 2 , f 3 , f 4 ).", "labels": [], "entities": []}, {"text": "For s=1 and w=2, the permissible permutations are (f 1 , f 2 , f 3 , f 4 ), (f 2 , f 1 , f 3 , f 4 ), Exploring all possible hypothesis with all possible word permutations is computationally intractable.", "labels": [], "entities": []}, {"text": "Therefore, the search algorithm gives an approximation to the optimal solution.", "labels": [], "entities": []}, {"text": "All possible hypotheses refers to all hypotheses that were explored by the decoder.", "labels": [], "entities": []}, {"text": "(f 2 , f 3 , f 1 , f 4 ), (f 1 , f 3 , f 2 , f 4 ),(f 1 , f 3 , f 4 , f 2 ), and (f 1 , f 2 , f 4 , f 3 ).", "labels": [], "entities": []}, {"text": "The experiments reported in this section are in the context of SMT from Arabic into English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9971534013748169}]}, {"text": "The training data is a 500K sentence-pairs subsample of the 2005 Large Track Arabic-English Data for NIST MT Evaluation.", "labels": [], "entities": [{"text": "NIST MT Evaluation", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.48593254884084064}]}, {"text": "The language model used is an interpolated trigram model described in ().", "labels": [], "entities": []}, {"text": "The language model is trained on the LDC English GigaWord Corpus.", "labels": [], "entities": [{"text": "LDC English GigaWord Corpus", "start_pos": 37, "end_pos": 64, "type": "DATASET", "confidence": 0.9415545761585236}]}, {"text": "The test set used in the experiments in this section is the 2003 NIST MT Evaluation test set (which is not part of the training data).", "labels": [], "entities": [{"text": "NIST MT Evaluation test set", "start_pos": 65, "end_pos": 92, "type": "DATASET", "confidence": 0.8855988264083863}]}, {"text": "The phrases in the phrase dictionary we use in the experiments reported here area combination", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Word order similarity for two language pairs: Arabic-English and Chinese-English. n-gPrec is the n-gram  precision as defined in BLEU.", "labels": [], "entities": [{"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.7868442535400391}, {"text": "BLEU", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.8612354397773743}]}, {"text": " Table 3: BLEU scores for the word order restoration task. The BLEU scores reported here are with 1 reference.  The input is the reordered English in the reference. The 95% Confidence \u03c3 ranges from 0.011 to 0.016", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9976728558540344}, {"text": "word order restoration task", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.8332825750112534}, {"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9988240599632263}, {"text": "Confidence \u03c3", "start_pos": 173, "end_pos": 185, "type": "METRIC", "confidence": 0.9776519536972046}]}, {"text": " Table 4: Examples of reordering with perfect translations. The examples show English in Arabic order (Eng Ar.),  English in its original order (Orig. Eng.) and decoding with two different parameter settings. Output1 is decoding  with (s=3,w=4). Output2 is decoding with (s=4,w=12). The sentence lengths of the examples presented here are  much shorter than the average in our test set (\u223c 28.5).", "labels": [], "entities": []}, {"text": " Table 5: BLEU scores for the Arabic-English machine translation task. The 95% Confidence \u03c3 ranges from 0.0158  to 0.0176. s is the number of words temporarily skipped, and w is the word permutation window size.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990262985229492}, {"text": "machine translation task", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.7584710915883383}, {"text": "Confidence \u03c3", "start_pos": 79, "end_pos": 91, "type": "METRIC", "confidence": 0.9648930132389069}]}]}