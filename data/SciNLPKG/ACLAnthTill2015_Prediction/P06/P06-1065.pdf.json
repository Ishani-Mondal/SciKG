{"title": [], "abstractContent": [{"text": "For many years, statistical machine translation relied on generative models to provide bilingual word alignments.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.682360847791036}, {"text": "bilingual word alignments", "start_pos": 87, "end_pos": 112, "type": "TASK", "confidence": 0.6665479640165964}]}, {"text": "In 2005, several independent efforts showed that discriminative models could be used to enhance or replace the standard genera-tive approach.", "labels": [], "entities": []}, {"text": "Building on this work, we demonstrate substantial improvement in word-alignment accuracy, partly though improved training methods, but predominantly through selection of more and better features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.979562520980835}]}, {"text": "Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 35, "end_pos": 55, "type": "METRIC", "confidence": 0.7362147470315298}, {"text": "Canadian Hansards bilingual data", "start_pos": 72, "end_pos": 104, "type": "DATASET", "confidence": 0.9143587797880173}]}], "introductionContent": [{"text": "Until recently, almost all work in statistical machine translation was based on word alignments obtained from combinations of generative probabalistic models developed at IBM by, sometimes augmented by an HMMbased model or Och and Ney's \"Model 6\".", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.6594754457473755}, {"text": "word alignments", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.6994494497776031}]}, {"text": "In 2005, however, several independent efforts () demonstrated that discriminatively trained models can equal or surpass the alignment accuracy of the standard models, if the usual unlabeled bilingual training corpus is supplemented with human-annotated word alignments for only a small subset of the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.8522855043411255}]}, {"text": "The work cited above makes use of various training procedures and a wide variety of features.", "labels": [], "entities": []}, {"text": "Indeed, whereas it can be difficult to design a factorization of a generative model that incorporates all the desired information, it is relatively easy to add arbitrary features to a discriminative model.", "labels": [], "entities": []}, {"text": "We take advantage of this, building on our existing framework, to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data.", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 91, "end_pos": 117, "type": "METRIC", "confidence": 0.8653534849484762}]}, {"text": "Through a careful choice of features, and modest improvements in training procedures, we obtain the lowest error rate yet reported for word alignment of Canadian Hansards data.", "labels": [], "entities": [{"text": "error rate", "start_pos": 107, "end_pos": 117, "type": "METRIC", "confidence": 0.9788236320018768}, {"text": "word alignment", "start_pos": 135, "end_pos": 149, "type": "TASK", "confidence": 0.8040909469127655}, {"text": "Canadian Hansards data", "start_pos": 153, "end_pos": 175, "type": "DATASET", "confidence": 0.8788010676701864}]}], "datasetContent": [{"text": "We used the same training and test data as in our previous work, a subset of the Canadian Hansards bilingual corpus supplied for the bilingual word alignment workshop held at HLT-NAACL 2003.", "labels": [], "entities": [{"text": "Canadian Hansards bilingual corpus", "start_pos": 81, "end_pos": 115, "type": "DATASET", "confidence": 0.9108909070491791}, {"text": "bilingual word alignment workshop held at HLT-NAACL 2003", "start_pos": 133, "end_pos": 189, "type": "TASK", "confidence": 0.7082553841173649}]}, {"text": "This subset comprised 500,000 English-French sentences pairs, including 224 manually word-aligned sentence pairs for labeled training data, and 223 labeled sentences pairs as test data.", "labels": [], "entities": []}, {"text": "Automatic sentence alignment of the training data was provided by Ulrich Germann, and the hand alignments of the labeled data were created by Franz Och and Hermann Ney.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6950401365756989}]}, {"text": "For baselines, package, using the default configuration file (Och and Ney, 2003).", "labels": [], "entities": []}, {"text": "2 \"Prev LLR\" is our earlier stage 1 model, and CLP 1 and CLP 2 are two versions of our earlier stage 2 model.", "labels": [], "entities": []}, {"text": "For CLP 1 , conditional link probabilities were estimated from the alignments produced by our \"Prev LLR\" model, and for CLP 2 , they were obtained from a yet earlier, heuristic alignment model.", "labels": [], "entities": []}, {"text": "Results for IBM Model 4 are reported for models trained in both directions, English-to-French and French-toEnglish, and for the union, intersection, and what Och and Ney (2003) call the \"refined\" combination of the those two alignments.", "labels": [], "entities": [{"text": "intersection", "start_pos": 135, "end_pos": 147, "type": "METRIC", "confidence": 0.9041973948478699}]}, {"text": "Results for our new stage 1 model are presented in.", "labels": [], "entities": []}, {"text": "The first line is for the model described in Section 3, optimizing non-lexical features before lexical features.", "labels": [], "entities": []}, {"text": "The second line gives results for optimizing all features simultaneously.", "labels": [], "entities": []}, {"text": "The next line omits lexical features entirely.", "labels": [], "entities": []}, {"text": "The last line is for our original stage 1 model, but trained using our improved perceptron training method.", "labels": [], "entities": []}, {"text": "As we can see, our best stage 1 model reduces the error rate of previous stage 1 model by almost half.", "labels": [], "entities": [{"text": "error rate", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.985415518283844}]}, {"text": "Comparing the first two lines shows that twophase training of non-lexical and lexical features produces a 0.7% reduction in test set error.", "labels": [], "entities": []}, {"text": "Although the purpose of the two-phase training was to mitigate overfitting to the training data, we also found training set AER was reduced (7.3% vs. 8.8%).", "labels": [], "entities": [{"text": "AER", "start_pos": 124, "end_pos": 127, "type": "METRIC", "confidence": 0.9096764922142029}]}, {"text": "Taken all together, the results show a 7.9% total reduction in error rate: 4.0% from new nonlexical features, 3.3% from lexical features with two-phase training, and 0.6% from other improvements in perceptron training.", "labels": [], "entities": [{"text": "error rate", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9848026633262634}]}, {"text": "presents results for perceptron training of our new stage 2 model.", "labels": [], "entities": []}, {"text": "The first line is for the model as described in Section 4.", "labels": [], "entities": []}, {"text": "Since the use of log odds is somewhat unusual, in the second line Thanks to Chris Quirk for providing Giza++ alignments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Stage 1 Model Results.", "labels": [], "entities": []}, {"text": " Table 3: Stage 2 Model Results.", "labels": [], "entities": []}, {"text": " Table 4: SVM Training Results.", "labels": [], "entities": [{"text": "SVM Training", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.7007145285606384}]}]}