{"title": [{"text": "Adding Syntax to Dynamic Programming for Aligning Comparable Texts for the Generation of Paraphrases", "labels": [], "entities": []}], "abstractContent": [{"text": "Multiple sequence alignment techniques have recently gained popularity in the Natural Language community, especially for tasks such as machine translation, text generation, and paraphrase identification.", "labels": [], "entities": [{"text": "Multiple sequence alignment", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6550706525643667}, {"text": "machine translation", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.7925586104393005}, {"text": "text generation", "start_pos": 156, "end_pos": 171, "type": "TASK", "confidence": 0.7795843482017517}, {"text": "paraphrase identification", "start_pos": 177, "end_pos": 202, "type": "TASK", "confidence": 0.9300600588321686}]}, {"text": "Prior work falls into two categories, depending on the type of input used: (a) parallel corpora (e.g., multiple translations of the same text) or (b) comparable texts (non-parallel but on the same topic).", "labels": [], "entities": []}, {"text": "So far, only techniques based on parallel texts have successfully used syntactic information to guide alignments.", "labels": [], "entities": []}, {"text": "In this paper, we describe an algorithm for incorporating syntactic features in the alignment process for non-parallel texts with the goal of generating novel paraphrases of existing texts.", "labels": [], "entities": []}, {"text": "Our method uses dynamic programming with alignment decision based on the local syntactic similarity between two sentences.", "labels": [], "entities": []}, {"text": "Our results show that syntactic alignment outrivals syntax-free methods by 20% in both grammaticality and fidelity when computed over the novel sentences generated by alignment-induced finite state automata.", "labels": [], "entities": [{"text": "syntactic alignment", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7462228238582611}]}], "introductionContent": [{"text": "In real life, we often encounter comparable texts such as news on the same events reported by different sources and papers on the same topic authored by different people.", "labels": [], "entities": []}, {"text": "It is useful to recognize if one text cites another in cases like news sharing among media agencies or citations in academic work.", "labels": [], "entities": [{"text": "news sharing among media agencies", "start_pos": 66, "end_pos": 99, "type": "TASK", "confidence": 0.844778859615326}]}, {"text": "Applications of such recognition include machine translation, text generation, paraphrase identification, and question answering, all of which have recently drawn the attention of a number of researchers in natural language processing community.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.8094252049922943}, {"text": "text generation", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7977485358715057}, {"text": "paraphrase identification", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.9247209429740906}, {"text": "question answering", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.8980483412742615}]}, {"text": "Multiple sequence alignment (MSA) is the basis for accomplishing these tasks.", "labels": [], "entities": [{"text": "Multiple sequence alignment (MSA)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7538583129644394}]}, {"text": "Previous work aligns a group of sentences into a compact word lattice (, a finite state automaton representation that can be used to identify commonality or variability among comparable texts and generate paraphrases.", "labels": [], "entities": []}, {"text": "Nevertheless, this approach has a drawback of over-generating ungrammatical sentences due to its \"almost-free\" alignment.", "labels": [], "entities": []}, {"text": "Pang et al. provide a remedy to this problem by performing alignment on the Charniak parse trees of the clustered sentences (.", "labels": [], "entities": []}, {"text": "Although it is so far the most similar work to ours, Pang's solution assumes the input sentences to be semantically equivalent.", "labels": [], "entities": []}, {"text": "Two other important references for string-based alignments algorithms, mostly with applications in Biology, are and.", "labels": [], "entities": []}, {"text": "In our approach, we work on comparable texts (not necessarily equivalent in their semantic meanings) as Barzilay and Lee did.", "labels": [], "entities": []}, {"text": "However, we use local syntactic similarity (as opposed to lexical similarity) in doing the alignment on the raw sentences instead of on their parse trees.", "labels": [], "entities": []}, {"text": "Because of the semantic discrepancies among the inputs, applying syntactic features in the alignment has a larger impact on the grammaticality and fidelity of the generated unseen sentences.", "labels": [], "entities": []}, {"text": "While previous work positions the primary focus on the quality of paraphrases and/or translations, we are more interested in the relation between the use of syntactic features and the correctness of the sentences being generated, including those that are not paraphrases of the original input.", "labels": [], "entities": [{"text": "paraphrases and/or translations", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6278196454048157}]}, {"text": "illustrates the difference between alignment based solely on lexical similarity and alignment with consideration of syntactic features.", "labels": [], "entities": []}, {"text": "Ignoring syntax, the word \"Milan\" in both sentences is aligned.", "labels": [], "entities": [{"text": "Milan", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.6535956859588623}]}, {"text": "But it would unfortunately generate an ungrammatical sentence \"I went to Milan is beautiful\".", "labels": [], "entities": []}, {"text": "Aligning according to syntac- tic features, on the other hand, would avoid this improper alignment by detecting that the syntactic feature values of the two \"Milan\" differ too much.", "labels": [], "entities": []}, {"text": "We shall explain syntactic features and their usages later.", "labels": [], "entities": []}, {"text": "In this small example, our syntax-based alignment will align nothing (the bottom FSA in) since \"Milan\" is the only lexically common word in both sentences.", "labels": [], "entities": [{"text": "FSA", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.832014799118042}]}, {"text": "For much larger clusters in our experiments, we are able to produce a significant number of novel sentences from our alignment with such tightened syntactic conditions.", "labels": [], "entities": []}, {"text": "shows one of the actual clusters used in our work that has 18 unique sentences.", "labels": [], "entities": []}, {"text": "Two of the many automatically generated grammatical sentences are also shown.", "labels": [], "entities": []}, {"text": "Another piece of related work, (), starts off with parallel inputs and uses monolingual Statistical Machine Translation techniques to align them and generate novel sentences.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.6828905840714773}]}, {"text": "In our work, the input text does not need to be nearly as parallel.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is a syntaxbased alignment technique for generating novel paraphrases of sentences that describe a particular fact.", "labels": [], "entities": [{"text": "syntaxbased alignment", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7264337241649628}]}, {"text": "Such techniques can be potentially useful in multi-document summarizers such as Newsblaster (http://newsblaster.cs. columbia.edu) and NewsInEssence (http: //www.newsinessence.com).", "labels": [], "entities": [{"text": "Newsblaster", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.9747094511985779}, {"text": "NewsInEssence", "start_pos": 134, "end_pos": 147, "type": "DATASET", "confidence": 0.9452244639396667}]}, {"text": "Such systems are notorious for mostly reusing text from existing news stories.", "labels": [], "entities": []}, {"text": "We believe that allowing them to use novel formulations of known facts will make these systems much more successful.", "labels": [], "entities": []}], "datasetContent": [{"text": "For each cluster, we ran the 5 alignment versions and produce 5 FSA's.", "labels": [], "entities": [{"text": "FSA", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.5842421054840088}]}, {"text": "From each FSA (corresponding to a cluster A and alignment version i), 100 sentences are randomly generated.", "labels": [], "entities": [{"text": "FSA", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.609304666519165}]}, {"text": "We removed those that appear in the original cluster.", "labels": [], "entities": []}, {"text": "The remaining ones are hence novel sentences, among which we randomly chose 10 to test the performance of alignment version ion cluster A.", "labels": [], "entities": []}, {"text": "In the human evaluation, each sentence received two scores -grammaticality and fidelity.", "labels": [], "entities": []}, {"text": "These two properties are independent since a sentence could possibly score high on fidelity even if it is not fully grammatical.", "labels": [], "entities": []}, {"text": "Four different scores are possible for both criteria: (4) perfect (fully grammatical or faithful); (3) good (occasional errors or quite faithful); (2) bad (many grammar errors or unfaithful pieces); and (1) nonsense.", "labels": [], "entities": [{"text": "perfect", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9604525566101074}, {"text": "nonsense", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.9479935169219971}]}], "tableCaptions": [{"text": " Table 2: Alignment techniques used in the experi- ments.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.8410288095474243}]}, {"text": " Table 3: Evaluation results on training and dev- testing clusters. For the results on the test clusters,  see", "labels": [], "entities": []}, {"text": " Table 4: Average grammaticality scores on testing  clusters.", "labels": [], "entities": []}, {"text": " Table 5: Average fidelity scores on testing clusters.", "labels": [], "entities": []}, {"text": " Table 6: Mean and standard deviation of human  judgments.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9979057312011719}, {"text": "standard", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.7974092364311218}]}]}