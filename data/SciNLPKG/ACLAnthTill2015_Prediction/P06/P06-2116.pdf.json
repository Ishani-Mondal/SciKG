{"title": [{"text": "A Grammatical Approach to Understanding Textual Tables using Two-Dimensional SCFGs", "labels": [], "entities": [{"text": "Grammatical Approach", "start_pos": 2, "end_pos": 22, "type": "TASK", "confidence": 0.7843261659145355}]}], "abstractContent": [{"text": "We present an elegant and extensible model that is capable of providing semantic interpretations for an unusually wide range of textual tables in documents.", "labels": [], "entities": []}, {"text": "Unlike the few existing table analysis models , which largely rely on relatively ad hoc heuristics, our linguistically-oriented approach is systematic and grammar based, which allows our model (1) to be concise and yet (2) recognize a wider range of data models than others, and (3) disambiguate to a significantly finer extent the underlying semantic interpretation of the table in terms of data models drawn from relation database theory.", "labels": [], "entities": [{"text": "table analysis", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.7503006756305695}]}, {"text": "To accomplish this, the model introduces Viterbi parsing under two-dimensional stochastic CFGs.", "labels": [], "entities": []}, {"text": "The cleaner grammatical approach facilitates not only greater coverage, but also grammar extension and maintenance, as well as a more direct and declarative link to semantic interpretation, for which we also introduce anew, cleaner data model.", "labels": [], "entities": [{"text": "grammar extension", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.6798445582389832}, {"text": "semantic interpretation", "start_pos": 165, "end_pos": 188, "type": "TASK", "confidence": 0.7473985254764557}]}, {"text": "In disambiguation experiments on recognizing relevant data models of unseen web tables from different domains, a blind evaluation of the model showed 60% precision and 80% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9996306896209717}, {"text": "recall", "start_pos": 172, "end_pos": 178, "type": "METRIC", "confidence": 0.9989755153656006}]}], "introductionContent": [{"text": "Natural language processing has historically tended to emphasize understanding of linear strings-sentences, paragraphs, discourse structure.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6555474797884623}]}, {"text": "The vast body of work that focuses on text understanding is often seen as an approximation of spoken language understanding.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8149784803390503}]}, {"text": "Yet real-life text is actually heavily dependent on visual layout and formatting, which compensate for cues normally found in spoken language but are absent in text.", "labels": [], "entities": []}, {"text": "As reiterated in the opening ACL'03 invited talk: \"The overlay of graphics on text is in many ways equivalent to the overlay of prosody on speech...", "labels": [], "entities": []}, {"text": "Just as prosody undoubtedly contributes to the meaning of utterances, so too does a text's graphical presentation contribute to its meaning.", "labels": [], "entities": []}, {"text": "few natural language understanding systems use graphical presentational features to aid interpretation...\".", "labels": [], "entities": []}, {"text": "Nowhere is this more evident than in the widespread use of tables in real-world, unsimplified text documents. or greater complexity as other elements of text.", "labels": [], "entities": []}, {"text": "Unfortunately, in mainstream NLP it is not uncommon for tables to be regarded as a somehow \"degenerate\" form of text, unworthy of the same degree of attention as the rest of the text.", "labels": [], "entities": []}, {"text": "But as we will discuss, the degree of ambiguity in table understanding is at least as great as for many sense and attachment problems.", "labels": [], "entities": [{"text": "table understanding", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7801169753074646}]}, {"text": "Many of the same mechanisms used for understanding linear text are also required for table understanding.", "labels": [], "entities": [{"text": "table understanding", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.8366319537162781}]}, {"text": "The same division of surface syntax and underlying semantics is found.", "labels": [], "entities": []}, {"text": "Indeed, to perceive the limitations of existing table understanding models, we may distinguish several very different levels of table analysis tasks.", "labels": [], "entities": [{"text": "table understanding", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7901426553726196}, {"text": "table analysis", "start_pos": 128, "end_pos": 142, "type": "TASK", "confidence": 0.7854428887367249}]}, {"text": "In table classification, the table is classified into one of several coarse categories (in the extreme case, some models simply predict whether the purpose of the table is for page layout versus tabular data).", "labels": [], "entities": [{"text": "table classification", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8045659363269806}]}, {"text": "In table synactic recognition, the surface types of individual cells or block regions are labeled (e.g., as heading or data) but the underlying semantic relationships between the table elements remain unrecognized and usually highly ambiguous (i.e., no logical relations between the elements in the table are assigned).", "labels": [], "entities": [{"text": "table synactic recognition", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.70212721824646}]}, {"text": "In contrast, in table semantic interpretation, the exact logical relations between the elements in the table must be recognized (e.g., by associating the table and/or subregions thereof with precise table schemas in relational database style).", "labels": [], "entities": [{"text": "table semantic interpretation", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.7799345453580221}]}, {"text": "Existing table understanding work largely lies at the level of superficial table classification or syntactic recognition.", "labels": [], "entities": [{"text": "table understanding", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.8512988388538361}, {"text": "superficial table classification", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.6135136882464091}, {"text": "syntactic recognition", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.6689484119415283}]}, {"text": "Rarely, if ever, are precise logical relations assigned between the elements in the table.", "labels": [], "entities": []}, {"text": "Ad hoc heuristic approaches tend to rule, rather than linguistic approaches.", "labels": [], "entities": []}, {"text": "On the other hand, in the linguistic approach advocated by and, tables were not considered.", "labels": [], "entities": []}, {"text": "The various physical presentation elements discussed included headings, captions, and bulleted lists-all of which exhibit numerous similarities to tabular elements.", "labels": [], "entities": []}, {"text": "Possibly, tables were not considered because they are difficult to describe adequately within the expressiveness of common linguistic formalisms like CFGs.", "labels": [], "entities": []}, {"text": "The work presented here aims to address this problem.", "labels": [], "entities": []}, {"text": "Our model provides an enabling foundation toward a linguistic approach by first shifting to a two-dimensional CFG framework.", "labels": [], "entities": []}, {"text": "This permits us to construct a grammar where all the rules are meaningfully discriminative, such thatunlike existing table understanding models-any analysis of a table includes a full parse tree that assigns precise data model labels to all its regions (including nested subregions) thereby specifying the logical relations between the table's elements.", "labels": [], "entities": [{"text": "table understanding", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7107690572738647}]}, {"text": "Additionally, probabilities on the production rules support thresholding (or ranking) of the alternative candidate table interpretation hypotheses.", "labels": [], "entities": []}, {"text": "As with many natural language phenomena, a full model of disambiguation must ultimately integrate lexical semantics.", "labels": [], "entities": []}, {"text": "However, in this research step we focus on the question of how much semantic interpretation can be performed on the basis of other features, in the absence of a lexical or ontological model.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7583484947681427}]}, {"text": "Just as syntax and morphology and prosody alone already permit much recognition and disambiguation of semantic roles and argument structure to be done for sentence, the same can be done for tables.", "labels": [], "entities": []}, {"text": "At the same time, we believe future integration of lexical semantics will be facilitated by the grammatical framework of our model.", "labels": [], "entities": []}, {"text": "One way to think about this is that we wish to.", "labels": [], "entities": []}, {"text": "Djhi Rubzlx model what you might be able to recognize from a \"Martian\" table such as that in.", "labels": [], "entities": []}, {"text": "The nonMartian reader relies solely on knowledge of alphabets and numbers, can spot font and formatting clues, and is familiar with the conventions (i.e., grammars) of tables in general.", "labels": [], "entities": []}, {"text": "You might reasonably interpret this table as a collection of vertical records with an attributes header column (Pbje, Hoer, NQ, Ncowifl) on the left.", "labels": [], "entities": []}, {"text": "You might additionally interpret it as a table that contains an record key header row (Kwe, Zxc, Amc) along with the attributes header column (Pbje, Hoer, NQ, Ncowifl).", "labels": [], "entities": []}, {"text": "You might assign the latter interpretation a slightly higher probability, noticing the slightly longer form of Pbje compared to Kwe, Zxc, and Amc.", "labels": [], "entities": []}, {"text": "On the other hand, even without reading English, you could reject the interpretation as a collection of horizontal records under the header attributes row (Pbje, Kwe, Zxc, Amc), since each row contains different forms and types, in a pattern that is consistent across columns.", "labels": [], "entities": []}, {"text": "Other interpretations are also possible, but unlikely given the regularity of the patterns.", "labels": [], "entities": []}, {"text": "Thus by analyzing the structure of a table, the reader would form a hypothesis about its data model, providing a semantic interpretation that allows the reader to extract information from the table.", "labels": [], "entities": []}, {"text": "As can be seen from the restored original English version of the same example in, the most likely interpretation was predicted even without access to specific lexical knowledge.", "labels": [], "entities": []}, {"text": "We aim to show that a fairly useful baseline level of semantic interpretation accuracy can already be achieved, even with relatively little lexical and ontological knowledge.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.8082237541675568}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.8896962404251099}]}, {"text": "We model these alternative hypotheses for the interpretation of ambiguous tables as competing parses.", "labels": [], "entities": []}, {"text": "Just as with ordinary parsing and semantic interpretation, the reader often builds multiple competing interpretations of the same table.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.7041697651147842}]}, {"text": "Note that many previous models do not even distinguish between the alternative possible interpretations in the Martian example.", "labels": [], "entities": []}, {"text": "Existing mod-els such as interpret tables with the same structural layout simply by assigning them same data model, which stops short of recognizing that it is necessary to rank multiple competing interpretations that entail different sets of logical relations.", "labels": [], "entities": []}, {"text": "In contrast, our proposed model is capable of producing multiple competing parses indicating different semantic interpretations of tables having the same structural layout, by selecting specific data models for the table and its subregions.", "labels": [], "entities": []}], "datasetContent": [{"text": "To the best of our knowledge, unfortunately none of the table corpora mentioned in previous work are available to the public.", "labels": [], "entities": []}, {"text": "Thus, it was necessary to construct a corpus for our experiments.", "labels": [], "entities": []}, {"text": "We collected a large sample of tables by issuing Google searches with a list of random keywords, for example, census age, confusion matrix, data table, movie ranking, MSFT, school ranking, telephone plan, tsunami numbers, weather report, and    For the blind evaluation, a human annotator independently manually annotated a randomly chosen sample of 45 tables from the collection.", "labels": [], "entities": []}, {"text": "All tables in the evaluation sample were previously unseen test cases, never inspected prior to the construction of the two-dimensional grammar.", "labels": [], "entities": []}, {"text": "Each tokenized table was tagged by the human judge with a list of types T relevant to the table.", "labels": [], "entities": []}, {"text": "The relevance is defined as follows: a data model is relevant to a table if and only if the human would agree that such a data model would naturally be hypothesized as an interpretation for that table (analogously to the way that word senses are manually annotated for WSD evaluations).", "labels": [], "entities": [{"text": "WSD evaluations", "start_pos": 269, "end_pos": 284, "type": "TASK", "confidence": 0.9110040962696075}]}, {"text": "Each type is a tuple of the form (R, O, S), where R is the relevant data model, O is the reading orientation of R, and S is a boolean saying if a schema (i.e. attributes) exist in the table.", "labels": [], "entities": []}, {"text": "Thus, would be tagged as {(flat, vertical, true)} while the table in would be tagged as {(flat, horizontal, true), (flat, vertical, true), (dimensional, , true)}.", "labels": [], "entities": []}, {"text": "But maybe tagged as {(flat, horizontal, false)}.", "labels": [], "entities": []}, {"text": "The exceptions are that both the nested model and the dimensional model always have a schema, while the dimensional model does not have orientation.", "labels": [], "entities": []}, {"text": "In cases where multiple legitimate readings were possible, the table was tagged We processed the tokenized tables with the twodimensional SCFG parser, and computed the precision and the recall rates against the judge's lists of tags for all the test cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9995168447494507}, {"text": "recall", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.9985970854759216}]}], "tableCaptions": [{"text": " Table 1: Example \"Martian\" table (see text).", "labels": [], "entities": []}, {"text": " Table 1. The non- Martian reader relies solely on knowledge of al- phabets and numbers, can spot font and formatting  clues, and is familiar with the conventions (i.e.,  grammars) of tables in general.", "labels": [], "entities": []}, {"text": " Table 2: Example from Table 1 in its original ver- sion, with the English words restored.  Date  Thu  Fri  Sat  Temp  15 -18  17 -20  19 -23  RH  85 -95% 70 -90% 75 -95%  Weather Cool  Cool  Cloudy", "labels": [], "entities": [{"text": "Date  Thu  Fri  Sat  Temp  15 -18  17 -20  19 -23  RH", "start_pos": 92, "end_pos": 145, "type": "DATASET", "confidence": 0.846273257335027}]}, {"text": " Table 3: Example of a ranking table, which is typ- ically laid out in a flat relational model.  Pos Teams  Pld Pts  1.  Chelsea  38  95  2.  Arsenal  38  83  3.  Man United 38  77", "labels": [], "entities": [{"text": "Man United 38", "start_pos": 163, "end_pos": 176, "type": "DATASET", "confidence": 0.9626297553380331}]}, {"text": " Table 4: Example table showing revenue accord- ing to Location = {Vancouver, Victoria}, Type =  {Phone, Computer} and Time = {2001, 2002}, us- ing a tabular view of a 3-dimensional data cube.", "labels": [], "entities": [{"text": "Time", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.8717536330223083}]}, {"text": " Table 5: Example relational database table con- taining the same logical information as Table 4.  Location  Type  Time Revenue  Vancouver Phone  2001 845  Vancouver Phone  2002 943  Vancouver Computer 2001 1078  Vancouver Computer 2002 1130  Victoria  Phone  2001 818  Victoria  Phone  2002 894  Victoria  Computer 2001 968  Victoria  Computer 2002 1024", "labels": [], "entities": [{"text": "Vancouver Phone  2001 845  Vancouver Phone  2002 943  Vancouver Computer 2001 1078  Vancouver Computer 2002 1130  Victoria  Phone  2001 818  Victoria  Phone  2002 894  Victoria  Computer 2001 968  Victoria  Computer 2002 1024", "start_pos": 129, "end_pos": 354, "type": "DATASET", "confidence": 0.911235480569303}]}, {"text": " Table 6: Example table of grades.", "labels": [], "entities": []}, {"text": " Table 7: Example table for Figures 2 and 4.  VA  VB", "labels": [], "entities": [{"text": "VA  VB", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.5895056873559952}]}, {"text": " Table 8: Example table for Figure 3.  VA  VB", "labels": [], "entities": [{"text": "VA  VB", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.6147621273994446}]}, {"text": " Table 9: Example table showing a floor legend.  6 School of Business & Management  5 Department of Biochemistry  4 Classrooms 4202 -4205  3 Department of Computer Science  3 Department of Mathematics", "labels": [], "entities": []}, {"text": " Table 10: Experimental results.  Precision Recall  0.60  0.80", "labels": [], "entities": [{"text": "Precision Recall  0.60  0.80", "start_pos": 34, "end_pos": 62, "type": "METRIC", "confidence": 0.8634607344865799}]}]}