{"title": [{"text": "Meaningful Clustering of Senses Helps Boost Word Sense Disambiguation Performance", "labels": [], "entities": [{"text": "Boost Word Sense Disambiguation", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.7119820043444633}]}], "abstractContent": [{"text": "Fine-grained sense distinctions are one of the major obstacles to successful Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.6924060185750326}]}, {"text": "In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense hierarchies , namely the Oxford Dictionary of English.", "labels": [], "entities": [{"text": "WordNet sense inventory", "start_pos": 71, "end_pos": 94, "type": "DATASET", "confidence": 0.8944981296857198}, {"text": "Oxford Dictionary of English", "start_pos": 189, "end_pos": 217, "type": "DATASET", "confidence": 0.9752686023712158}]}, {"text": "We assess the quality of the mapping and the induced clustering, and evaluate the performance of coarse WSD systems in the Senseval-3 English all-words task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is undoubtedly one of the hardest tasks in the field of Natural Language Processing.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7883689204851786}, {"text": "Natural Language Processing", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.6374339361985525}]}, {"text": "Even though some recent studies report benefits in the use of WSD in specific applications (e.g. and), the present performance of the best ranking WSD systems does not provide a sufficient degree of accuracy to enable real-world, language-aware applications.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9966250658035278}]}, {"text": "Most of the disambiguation approaches adopt the WordNet dictionary) as a sense inventory, thanks to its free availability, wide coverage, and existence of a number of standard test sets based on it.", "labels": [], "entities": [{"text": "WordNet dictionary", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.9721825420856476}]}, {"text": "Unfortunately, WordNet is a fine-grained resource, encoding sense distinctions that are often difficult to recognize even for human annotators).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9585345983505249}]}, {"text": "Recent estimations of the inter-annotator agreement when using the WordNet inventory report figures of 72.5% agreement in the preparation of the English all-words test set at Senseval-3 (Snyder and) and 67.3% on the Open Mind Word Expert annotation exercise).", "labels": [], "entities": [{"text": "WordNet inventory report", "start_pos": 67, "end_pos": 91, "type": "DATASET", "confidence": 0.9727341135342916}, {"text": "English all-words test set at Senseval-3", "start_pos": 145, "end_pos": 185, "type": "DATASET", "confidence": 0.6369701623916626}]}, {"text": "These numbers lead us to believe that a credible upper bound for unrestricted fine-grained WSD is around 70%, a figure that state-of-the-art automatic systems find it difficult to outperform.", "labels": [], "entities": [{"text": "WSD", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.8661001920700073}]}, {"text": "Furthermore, even if a system were able to exceed such an upper bound, it would be unclear how to interpret such a result.", "labels": [], "entities": []}, {"text": "It seems therefore that the major obstacle to effective WSD is the fine granularity of the WordNet sense inventory, rather than the performance of the best disambiguation systems.", "labels": [], "entities": [{"text": "WSD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9863395690917969}, {"text": "WordNet sense inventory", "start_pos": 91, "end_pos": 114, "type": "DATASET", "confidence": 0.8456330498059591}]}, {"text": "Interestingly, show that, when a coarse-grained sense inventory is adopted, the increase in interannotator agreement is much higher than the reduction of the polysemy degree.", "labels": [], "entities": [{"text": "interannotator agreement", "start_pos": 92, "end_pos": 116, "type": "METRIC", "confidence": 0.6900527775287628}]}, {"text": "Following these observations, the main question that we tackle in this paper is: can we produce and evaluate coarse-grained sense distinctions and show that they help boost disambiguation on standard test sets?", "labels": [], "entities": []}, {"text": "We believe that this is a crucial research topic in the field of WSD, that could potentially benefit several application areas.", "labels": [], "entities": [{"text": "WSD", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.986620306968689}]}, {"text": "The contribution of this paper is two-fold.", "labels": [], "entities": []}, {"text": "First, we provide a wide-coverage method for clustering WordNet senses via a mapping to a coarse-grained sense inventory, namely the Oxford Dictionary of English () (Section 2).", "labels": [], "entities": [{"text": "clustering WordNet senses", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.668389211098353}, {"text": "Oxford Dictionary of English", "start_pos": 133, "end_pos": 161, "type": "DATASET", "confidence": 0.9788112789392471}]}, {"text": "We show that this method is well-founded and accurate with respect to manually-made clusterings (Section 3).", "labels": [], "entities": []}, {"text": "Second, we evaluate the performance of WSD systems when using coarse-grained sense inventories (Section 4).", "labels": [], "entities": [{"text": "WSD", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9647607207298279}]}, {"text": "We conclude the paper with an account of related work (Section 5), and some final remarks (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "As a first experiment, we assessed the effect of the automatic sense clustering on the English allwords task at Senseval-3 ().", "labels": [], "entities": []}, {"text": "This task required WSD systems to provide a sense choice for 2,081 content words in a set of 301 sentences from the fiction, news story, and editorial domains.", "labels": [], "entities": []}, {"text": "We considered the three best-ranking WSD systems -GAMBL (), SenseLearner (, and Koc: Performance of WSD systems at Senseval-3 on coarse-grained sense inventories.", "labels": [], "entities": [{"text": "GAMBL", "start_pos": 50, "end_pos": 55, "type": "DATASET", "confidence": 0.809226393699646}]}], "tableCaptions": [{"text": " Table 2: Performance of the lexical and semantic  mapping functions.", "labels": [], "entities": []}, {"text": " Table 3: Comparison with gold standards.", "labels": [], "entities": []}, {"text": " Table 4: Performance of WSD systems at  Senseval-3 on coarse-grained sense inventories.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9268391728401184}]}, {"text": " Table 5: Performance of SSI on coarse inventories  (SSI  *  uses a coarse-grained knowledge base).  System  Prec. Recall F1  SSI + baseline 0.758 0.758  0.758  SSI  0.717 0.576  0.639  SSI  *   0.748 0.674  0.709", "labels": [], "entities": [{"text": "System  Prec. Recall", "start_pos": 101, "end_pos": 121, "type": "DATASET", "confidence": 0.7616891264915466}, {"text": "F1", "start_pos": 122, "end_pos": 124, "type": "METRIC", "confidence": 0.709527850151062}]}]}