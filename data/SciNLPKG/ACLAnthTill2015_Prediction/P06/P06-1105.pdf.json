{"title": [{"text": "Japanese Dependency Parsing Using Co-occurrence Information and a Combination of Case Elements", "labels": [], "entities": [{"text": "Japanese Dependency Parsing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6007320086161295}]}], "abstractContent": [{"text": "In this paper, we present a method that improves Japanese dependency parsing by using large-scale statistical information.", "labels": [], "entities": [{"text": "Japanese dependency parsing", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.697012186050415}]}, {"text": "It takes into account two kinds of information not considered in previous statistical (machine learning based) parsing methods: information about dependency relations among the case elements of a verb, and information about co-occurrence relations between a verb and its case element.", "labels": [], "entities": []}, {"text": "This information can be collected from the results of automatic dependency parsing of large-scale corpora.", "labels": [], "entities": [{"text": "dependency parsing of large-scale corpora", "start_pos": 64, "end_pos": 105, "type": "TASK", "confidence": 0.7871140837669373}]}, {"text": "The results of an experiment in which our method was used to rerank the results obtained using an existing machine learning based parsing method showed that our method can improve the accuracy of the results obtained using the existing method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9977546334266663}]}], "introductionContent": [{"text": "Dependency parsing is a basic technology for processing Japanese and has been the subject of much research.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8456833064556122}]}, {"text": "The Japanese dependency structure is usually represented by the relationship between phrasal units called bunsetsu, each of which consists of one or more content words that maybe followed by any number of function words.", "labels": [], "entities": []}, {"text": "The dependency between two bunsetsus is direct from a dependent to its head.", "labels": [], "entities": []}, {"text": "Manually written rules have usually been used to determine which bunsetsu another bunsetsu tends to modify, but this method poses problems in terms of the coverage and consistency of the rules.", "labels": [], "entities": [{"text": "consistency", "start_pos": 168, "end_pos": 179, "type": "METRIC", "confidence": 0.9595553874969482}]}, {"text": "The recent availability of larger-scale corpora annotated with dependency information has thus resulted in more work on statistical dependency analysis technologies that use machine learning algorithms ().", "labels": [], "entities": [{"text": "statistical dependency analysis", "start_pos": 120, "end_pos": 151, "type": "TASK", "confidence": 0.7080012361208597}]}, {"text": "Work on statistical Japanese dependency analysis has usually assumed that all the dependency relations in a sentence are independent of each other, and has considered the bunsetsus in a sentence independently when judging whether or not a pair of bunsetsus is in a dependency relation.", "labels": [], "entities": [{"text": "statistical Japanese dependency analysis", "start_pos": 8, "end_pos": 48, "type": "TASK", "confidence": 0.5402697324752808}]}, {"text": "In judging which bunsetsu a bunsetsu modifies, this type of work has used as features the information of two bunsetsus, such as the head words of the two bunsetsus, and the morphemes at the ends of the bunsetsus ().", "labels": [], "entities": []}, {"text": "It is necessary, however, to also consider features for the contextual information of the two bunsetsus.", "labels": [], "entities": []}, {"text": "One such feature is the constraint that two case elements with the same case do not modify a verb.", "labels": [], "entities": []}, {"text": "Statistical Japanese dependency analysis takes into account syntactic information but tends not to take into account lexical information, such as cooccurrence between a case element and a verb.", "labels": [], "entities": [{"text": "Japanese dependency analysis", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6008059084415436}]}, {"text": "The recent availability of more corpora has enabled much information about dependency relations to be obtained by using a Japanese dependency analyzer such as KNP ( or CaboCha (.", "labels": [], "entities": []}, {"text": "Although this information is less accurate than manually annotated information, these automatic analyzers provide a large amount of co-occurrence information as well as information about combinations of multiple cases that tend to modify a verb.", "labels": [], "entities": []}, {"text": "In this paper, we present a method for improving the accuracy of Japanese dependency analysis by representing the lexical information of cooccurrence and dependency relations of multiple cases as statistical models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9991636276245117}, {"text": "Japanese dependency analysis", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.638899544874827}]}, {"text": "We also show the results of experiments demonstrating the effectiveness of our method.", "labels": [], "entities": []}, {"text": "Keisatsu-de umibe-de hitori-de arui-teiru syonen-wo hogo-shita (The police/subj) (on the beach) (alone) (was walking) (boy/obj) (had custody) (The police had custody of the boy who was walking alone on the beach.): Example of a Japanese sentence, bunsetsu and dependencies", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the effectiveness of our model experimentally.", "labels": [], "entities": []}, {"text": "Since our model treats only the de-: Example of the co-occurrence probabilities of particle sets pendency relations between a noun and a verb, we cannot determine all the dependency relations in a sentence.", "labels": [], "entities": []}, {"text": "We therefore use one of the currently available dependency analyzers to generate an ordered list of n-best possible parses for the sentence and then use our proposed model to rerank them and select the best parse.", "labels": [], "entities": []}, {"text": "The evaluation data we used was Kyodai Corpus 3.0, a corpus manually annotated with dependency relations ().", "labels": [], "entities": [{"text": "Kyodai Corpus 3.0", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9459439118703207}]}, {"text": "The statistics of the data are as follows: The evaluation measures we used were bunsetsu accuracy (the percentage of bunsetsu for which the correct modifyee was identified) and sentence accuracy (the percentage of sentences for which the correct dependency structure was identified).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.5496797561645508}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.7030447125434875}]}, {"text": "Our first experiment evaluated the effectiveness of reranking with our proposed model.", "labels": [], "entities": []}, {"text": "Bunsetsu  and sentence accuracies before and after reranking, for the entire set of test data as well as for only those sentences whose parse was actually reranked, are listed in.", "labels": [], "entities": [{"text": "Bunsetsu", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9882281422615051}]}, {"text": "The results showed that the accuracy could be improved by using our proposed model to rerank the results obtained with the posterior context model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9996005892753601}]}, {"text": "McNemar testing showed that the null hypothesis that there is no difference between the accuracy of the results obtained with the posterior context model and those obtained with our model could be rejected with a p value < 0.01.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.998174786567688}]}, {"text": "The difference inaccuracy is therefore significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Example of the co-occurrence probabili- ties of particle sets", "labels": [], "entities": []}, {"text": " Table 4: 2 \u00d7 2 contingency table of the number of  correct bunsetsu (posterior context model \u00d7 our  model)", "labels": [], "entities": []}, {"text": " Table 5: Comparison of various models", "labels": [], "entities": []}, {"text": " Table 6: The variance of the number of elements per verb", "labels": [], "entities": [{"text": "variance", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9692293405532837}]}]}