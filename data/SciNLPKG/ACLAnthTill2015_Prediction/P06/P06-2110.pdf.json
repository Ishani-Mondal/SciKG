{"title": [{"text": "Word Vectors and Two Kinds of Similarity", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper examines what kind of similarity between words can be represented by what kind of word vectors in the vector space model.", "labels": [], "entities": []}, {"text": "Through two experiments, three methods for constructing word vectors , i.e., LSA-based, cooccurrence-based and dictionary-based methods, were compared in terms of the ability to represent two kinds of similarity, i.e., taxonomic similarity and associative similarity.", "labels": [], "entities": []}, {"text": "The result of the comparison was that the dictionary-based word vectors better reflect taxonomic similarity, while the LSA-based and the cooccurrence-based word vectors better reflect associative similarity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, geometric models have been used to represent words and their meanings, and proven to be highly useful both for many NLP applications associated with semantic processing) and for human modeling in cognitive science.", "labels": [], "entities": []}, {"text": "There are also good reasons for studying geometric models in the field of computational linguistics.", "labels": [], "entities": []}, {"text": "First, geometric models are cost-effective in that it takes much less time and less effort to construct large-scale geometric representation of word meanings than it would take to construct dictionaries or thesauri.", "labels": [], "entities": []}, {"text": "Second, they can represent the implicit knowledge of word meanings that dictionaries and thesauri cannot do.", "labels": [], "entities": []}, {"text": "Finally, geometric representation is easy to revise and extend.", "labels": [], "entities": []}, {"text": "A vector space model is the most commonly used geometric model for the meanings of words.", "labels": [], "entities": []}, {"text": "The basic idea of a vector space model is that words are represented by high-dimensional vectors, i.e., word vectors, and the degree of semantic similarity between any two words can be easily computed as a cosine of the angle formed by their vectors.", "labels": [], "entities": []}, {"text": "A number of methods have been proposed for constructing word vectors.", "labels": [], "entities": []}, {"text": "Latent semantic analysis (LSA) is the most well-known method that uses the frequency of words in a fraction of documents to assess the coordinates of word vectors and singular value decomposition (SVD) to reduce the dimension.", "labels": [], "entities": [{"text": "Latent semantic analysis (LSA)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8369384109973907}, {"text": "singular value decomposition (SVD)", "start_pos": 167, "end_pos": 201, "type": "TASK", "confidence": 0.6943929443756739}]}, {"text": "LSA was originally put forward as a document indexing technique for automatic information retrieval), but several studies have shown that LSA successfully mimics many human behaviors associated with semantic processing.", "labels": [], "entities": [{"text": "document indexing", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.6795372068881989}, {"text": "information retrieval", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7190977782011032}]}, {"text": "Other methods use a variety of other information: cooccurrence of two words), occurrence of a word in the sense definitions of a dictionary ( or word association norms ().", "labels": [], "entities": []}, {"text": "However, despite the fact that there are different kinds of similarity between words, or different relations underlying word similarity such as a synonymous relation and an associative relation, no studies have ever examined the relationship between methods for constructing word vectors and the type of similarity involved in word vectors in a systematic way.", "labels": [], "entities": []}, {"text": "Some studies on word vectors have compared the performance among different methods on some specific tasks such as semantic disambiguation and cued/free recall (), but it is not at all clear whether there are essential differences in the quality of similarity among word vectors constructed by different methods, and if so, what kind of similarity is involved in what kind of word vectors.", "labels": [], "entities": [{"text": "semantic disambiguation", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.727499708533287}]}, {"text": "Even in the field of cognitive psychology, although geometric models of similarity such as multidimensional scaling have long been studied and debated, the possibility that different methods for word vectors may cap-ture different kinds of word similarity has never been addressed.", "labels": [], "entities": []}, {"text": "This study, therefore, aims to examine the relationship between the methods for constructing word vectors and the type of similarity in a systematic way.", "labels": [], "entities": []}, {"text": "Especially this study addresses three methods, LSA-based, cooccurrence-based, and dictionary-based methods, and two kinds of similarity, taxonomic similarity and associative similarity.", "labels": [], "entities": []}, {"text": "Word vectors constructed by these methods are compared in the performance of two tasks, i.e., multiple-choice synonym test and word association, which measure the degree to which they reflect these two kinds of similarity.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of mean correct rate among  the combinations of two corpora and two text units", "labels": [], "entities": [{"text": "mean correct rate", "start_pos": 24, "end_pos": 41, "type": "METRIC", "confidence": 0.8444592356681824}]}, {"text": " Table 2: Associates for the stimulus word writer", "labels": [], "entities": [{"text": "Associates", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9650620818138123}]}, {"text": " Table 3: Comparison of mean precision among the  combinations of two corpora and two text units", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.5059558153152466}]}]}