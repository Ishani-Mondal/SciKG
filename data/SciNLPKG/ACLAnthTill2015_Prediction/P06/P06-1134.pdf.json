{"title": [], "abstractContent": [{"text": "Subjectivity and meaning are both important properties of language.", "labels": [], "entities": []}, {"text": "This paper explores their interaction, and brings empirical evidence in support of the hypotheses that (1) subjectivity is a property that can be associated with word senses, and (2) word sense disambiguation can directly benefit from subjectivity annotations.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 183, "end_pos": 208, "type": "TASK", "confidence": 0.6177628735701243}]}], "introductionContent": [{"text": "There is growing interest in the automatic extraction of opinions, emotions, and sentiments in text (subjectivity), to provide tools and support for various NLP applications.", "labels": [], "entities": [{"text": "automatic extraction of opinions, emotions, and sentiments in text (subjectivity)", "start_pos": 33, "end_pos": 114, "type": "TASK", "confidence": 0.8358260904039655}]}, {"text": "Similarly, there is continuous interest in the task of word sense disambiguation, with sense-annotated resources being developed for many languages, and a growing number of research groups participating in large-scale evaluations such as SENSEVAL.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7431956926981608}]}, {"text": "Though both of these areas are concerned with the semantics of a text, overtime there has been little interaction, if any, between them.", "labels": [], "entities": []}, {"text": "In this paper, we address this gap, and explore possible interactions between subjectivity and word sense.", "labels": [], "entities": []}, {"text": "There are several benefits that would motivate such a joint exploration.", "labels": [], "entities": []}, {"text": "First, at the resource level, the augmentation of lexical resources such as WordNet with subjectivity labels could support better subjectivity analysis tools, and principled methods for refining word senses and clustering similar meanings.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9366903305053711}]}, {"text": "Second, at the tool level, an explicit link between subjectivity and word sense could help improve methods for each, by integrating features learned from one into the other in a pipeline approach, or through joint simultaneous learning.", "labels": [], "entities": []}, {"text": "In this paper we address two questions about word sense and subjectivity.", "labels": [], "entities": [{"text": "word sense", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.7035559862852097}]}, {"text": "First, can subjectivity labels be assigned to word senses?", "labels": [], "entities": []}, {"text": "To address this question, we perform two studies.", "labels": [], "entities": []}, {"text": "The first (Section 3) investigates agreement between annotators who manually assign the labels subjective, objective, or both to WordNet senses.", "labels": [], "entities": []}, {"text": "The second study (Section 4) evaluates a method for automatic assignment of subjectivity labels to word senses.", "labels": [], "entities": [{"text": "automatic assignment of subjectivity labels", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.6873230695724487}]}, {"text": "We devise an algorithm relying on distributionally similar words to calculate a subjectivity score, and show how it can be used to automatically assess the subjectivity of a word sense.", "labels": [], "entities": []}, {"text": "Second, can automatic subjectivity analysis be used to improve word sense disambiguation?", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.7358825504779816}]}, {"text": "To address this question, the output of a subjectivity sentence classifier is input to a word-sense disambiguation system, which is in turn evaluated on the nouns from the SENSEVAL-3 English lexical sample task (Section 5).", "labels": [], "entities": [{"text": "SENSEVAL-3 English lexical sample task", "start_pos": 172, "end_pos": 210, "type": "TASK", "confidence": 0.5541685521602631}]}, {"text": "The results of this experiment show that a subjectivity feature can significantly improve the accuracy of a word sense disambiguation system for those words that have both subjective and objective senses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9990780353546143}, {"text": "word sense disambiguation", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.6254245638847351}]}, {"text": "A third obvious question is, can word sense disambiguation help automatic subjectivity analysis?", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.7508242925008138}, {"text": "automatic subjectivity analysis", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.6759395996729533}]}, {"text": "However, due to space limitations, we do not address this question here, but rather leave it for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of the algorithm is performed against the gold standard of 64 words (354 word senses) using Judge 1's annotations, as described in Section 3.", "labels": [], "entities": []}, {"text": "For each sense of each word in the set of 64 ambiguous words, we use Algorithm 1 to determine a subjectivity score.", "labels": [], "entities": []}, {"text": "A subjectivity label is then assigned depending on the value of this score with respect to a pre-selected threshold.", "labels": [], "entities": []}, {"text": "While a threshold of 0 seems like a sensible choice, we perform the evaluation for different thresholds ranging across the [-1,+1] interval, and correspondingly determine the precision of the algorithm at different points of recall 7 . Note that the word senses for which none of the distributionally similar words are found in the MPQA corpus are not included in this evaluation (excluding 82 senses), since in this case a subjectivity score cannot be calculated.", "labels": [], "entities": [{"text": "precision", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9990605711936951}, {"text": "MPQA corpus", "start_pos": 332, "end_pos": 343, "type": "DATASET", "confidence": 0.9354541897773743}]}, {"text": "The evaluation is therefore performed on a total of 272 word senses.", "labels": [], "entities": []}, {"text": "As a baseline, we use an \"informed\" random assignment of subjectivity labels, which randomly assigns S labels to word senses in the data set, such that the maximum number of S assignments equals the number of correct S labels in the gold standard data set.", "labels": [], "entities": [{"text": "gold standard data set", "start_pos": 233, "end_pos": 255, "type": "DATASET", "confidence": 0.87413689494133}]}, {"text": "This baseline guarantees a maximum recall of 1 (which under true random conditions might not be achievable).", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9994632601737976}]}, {"text": "Correspondingly, given the controlled distribution of S labels across the data set in the baseline setting, the precision is equal for all eleven recall points, and is determined as the total number of correct subjective assignments divided by the size of the data set 8 . Number  There are two aspects of the sense subjectivity scoring algorithm that can influence the label assignment, and correspondingly their evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9987689852714539}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9763537645339966}]}, {"text": "First, as indicated above, after calculating the semantic similarity of the distributionally similar words with each sense, we can either use all the distributionally similar words for the calculation of the subjectivity score of each sense (similarityall), or we can use only those that lead to the highest similarity (similarity-selected).", "labels": [], "entities": []}, {"text": "Interestingly, this aspect can drastically affect the algorithm accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9931660294532776}]}, {"text": "The setting where a distributionally similar word can belong only to one sense significantly improves the algorithm performance.", "labels": [], "entities": []}, {"text": "plots the interpolated precision for eleven points of recall, for similarity-all, similarity-selected, and baseline.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9033572673797607}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9986369013786316}]}, {"text": "As shown in this figure, the precisionrecall curves for our algorithm are clearly above the \"informed\" baseline, indicating the ability of our algorithm to automatically identify subjective word senses.", "labels": [], "entities": [{"text": "precisionrecall", "start_pos": 29, "end_pos": 44, "type": "METRIC", "confidence": 0.9994109869003296}]}, {"text": "Second, the number of distributionally similar words considered in the first stage of the algorithm can vary, and might therefore influence the output of the algorithm.", "labels": [], "entities": []}, {"text": "We experiment with two different values, namely 100 and 160 top-ranked distributionally similar words.", "labels": [], "entities": []}, {"text": "shows the break-even points for the four different settings that were evaluated, with results that are almost double compared to the informed baseline.", "labels": [], "entities": [{"text": "break-even", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9731929302215576}]}, {"text": "As it turns out, for weaker versions of the algorithm (i.e., similarity-all), the size of the set of distributionally similar words can significantly impact the performance of the algorithm.", "labels": [], "entities": []}, {"text": "However, for the already improved similarity-selected algorithm version, this parameter does not seem to have influence, as similar results are obtained regardless of the number of distributionally similar words.", "labels": [], "entities": []}, {"text": "This is in agreement with the finding of () that, in their word sense ranking method, a larger set of neighbors did not influence the algorithm accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9915137887001038}]}], "tableCaptions": [{"text": " Table 1: Agreement on balanced set (Agreement:  85.5%, \u03ba: 0.74)", "labels": [], "entities": [{"text": "Agreement", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.977332592010498}]}, {"text": " Table 2: Break-even point for different algorithm  and parameter settings", "labels": [], "entities": [{"text": "Break-even", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9750065207481384}]}, {"text": " Table 3: Word Sense Disambiguation with and  without subjectivity information, for the set of am- biguous nouns in SENSEVAL-3", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6922880510489146}, {"text": "SENSEVAL-3", "start_pos": 116, "end_pos": 126, "type": "TASK", "confidence": 0.4771469533443451}]}]}