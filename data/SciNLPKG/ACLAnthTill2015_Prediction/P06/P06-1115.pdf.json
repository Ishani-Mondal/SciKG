{"title": [{"text": "Using String-Kernels for Learning Semantic Parsers", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew approach for mapping natural language sentences to their formal meaning representations using string-kernel-based classifiers.", "labels": [], "entities": []}, {"text": "Our system learns these classifiers for every production in the formal language grammar.", "labels": [], "entities": []}, {"text": "Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers.", "labels": [], "entities": []}, {"text": "Our experiments on two real-world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computational systems that learn to transform natural language sentences into formal meaning representations have important practical applications in enabling user-friendly natural language communication with computers.", "labels": [], "entities": []}, {"text": "However, most of the research in natural language processing (NLP) has been focused on lower-level tasks like syntactic parsing, word-sense disambiguation, information extraction etc.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.829329917828242}, {"text": "syntactic parsing", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.727300226688385}, {"text": "word-sense disambiguation", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.7481143474578857}, {"text": "information extraction", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.8272913694381714}]}, {"text": "In this paper, we have considered the important task of doing deep semantic parsing to map sentences into their computer-executable meaning representations.", "labels": [], "entities": [{"text": "deep semantic parsing", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.6706877847512563}]}, {"text": "Previous work on learning semantic parsers either employ rule-based algorithms), or use statistical feature-based methods).", "labels": [], "entities": [{"text": "learning semantic parsers", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.6372247139612833}]}, {"text": "In this paper, we present a novel kernel-based statistical method for learning semantic parsers.", "labels": [], "entities": [{"text": "learning semantic parsers", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6347718238830566}]}, {"text": "Kernel methods) are particularly suitable for semantic parsing because it involves mapping phrases of natural language (NL) sentences to semantic concepts in a meaning representation language (MRL).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.759051501750946}]}, {"text": "Given that natural languages are so flexible, there are various ways in which one can express the same semantic concept.", "labels": [], "entities": []}, {"text": "It is difficult for rule-based methods or even statistical featurebased methods to capture the full range of NL contexts which map to a semantic concept because they tend to enumerate these contexts.", "labels": [], "entities": []}, {"text": "In contrast, kernel methods allow a convenient mechanism to implicitly work with a potentially infinite number of features which can robustly capture these range of contexts even when the data is noisy.", "labels": [], "entities": []}, {"text": "Our system, KRISP (Kernel-based Robust Interpretation for Semantic Parsing), takes NL sentences paired with their formal meaning representations as training data.", "labels": [], "entities": []}, {"text": "The productions of the formal MRL grammar are treated like semantic concepts.", "labels": [], "entities": [{"text": "MRL grammar", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.8740758895874023}]}, {"text": "For each of these productions, a SupportVector Machine (SVM)) classifier is trained using string similarity as the kernel ().", "labels": [], "entities": []}, {"text": "Each classifier then estimates the probability of the production covering different substrings of the sentence.", "labels": [], "entities": []}, {"text": "This information is used to compositionally build a complete meaning representation (MR) of the sentence.", "labels": [], "entities": []}, {"text": "Some of the previous work on semantic parsing has focused on fairly simple domains, primarily, ATIS (Air Travel Information Service)) whose semantic analysis is equivalent to filling a single semantic frame.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.831727534532547}, {"text": "ATIS (Air Travel Information Service))", "start_pos": 95, "end_pos": 133, "type": "DATASET", "confidence": 0.6779517957142421}]}, {"text": "In this paper, we have tested KRISP on two real-world domains in which meaning representations are more complex with richer predicates and nested structures.", "labels": [], "entities": []}, {"text": "Our experiments demonstrate that KRISP compares favor-NL: \"If the ball is in our goal area then our player 1 should intercept it.\"", "labels": [], "entities": []}, {"text": "CLANG: ((bpos (goal-area our)) (do our {1} intercept)) Figure 1: An example of an NL advice and its CLANG MR.", "labels": [], "entities": []}, {"text": "ably to other existing systems and is particularly robust to noise.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have translations of a subset of the GEOQUERY corpus with 250 examples (GEO250 corpus) in three other natural languages: Spanish, Turkish and Japanese.", "labels": [], "entities": [{"text": "GEOQUERY corpus", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9649894535541534}, {"text": "GEO250 corpus", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.9509762823581696}]}, {"text": "Since KRISP's learning algorithm does not use any natural language specific knowledge, it is directly applicable to other natural languages.", "labels": [], "entities": []}, {"text": "shows that KRISP performs competently on other languages as well.", "labels": [], "entities": []}, {"text": "Any real world application in which semantic parsers would be used to interpret natural language of a user is likely to face noise in the input.", "labels": [], "entities": []}, {"text": "If the user is interacting through spontaneous speech and the input to the semantic parser is coming form the output of a speech recognition system then there are many ways in which noise could creep in the NL sentences: interjections (like um's and ah's), environment noise (like door slams, phone rings etc.), out-of-domain words, grammatically ill-formed utterances etc..", "labels": [], "entities": []}, {"text": "As opposed to the other systems, KRISP's stringkernel-based semantic parsing does not use hardmatching rules and should be thus more flexible and robust to noise.", "labels": [], "entities": [{"text": "stringkernel-based semantic parsing", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.6012318134307861}]}, {"text": "We tested this hypothesis by running experiments on data which was artificially corrupted with simulated speech recognition errors.", "labels": [], "entities": []}, {"text": "The interjections, environment noise etc. are likely to be recognized as real words by a speech recognizer.", "labels": [], "entities": []}, {"text": "To simulate this, after every word in a sentence, with some probability P add , an extra word is added which is chosen with probability proportional to its word frequency found in the British National Corpus (BNC), a good representative sample of English.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 184, "end_pos": 213, "type": "DATASET", "confidence": 0.9700607558091482}]}, {"text": "A speech recognizer may sometimes completely fail to detect words, so with a probability of P drop a word is sometimes dropped.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.7013841420412064}, {"text": "P drop", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9557827711105347}]}, {"text": "A speech recognizer could also introduce noise by confusing a word with a high frequency phonetically close word.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.7147274017333984}]}, {"text": "We sim- ulate this type of noise by substituting a word in the corpus by another word, w, with probability p ed(w) * P (w), where p is a parameter, ed(w) is w's edit distance from the original word and P (w) is w's probability proportional to its word frequency.", "labels": [], "entities": []}, {"text": "The edit distance which calculates closeness between words is character-based rather than based on phonetics, but this should not make a significant difference in the experimental results.", "labels": [], "entities": []}, {"text": "shows the results on the CLANG corpus with increasing amounts of noise, from level 0 to level 4.", "labels": [], "entities": [{"text": "CLANG corpus", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9122568666934967}]}, {"text": "The noise level 0 corresponds to no noise.", "labels": [], "entities": []}, {"text": "The noise parameters, P add and P drop , were varied uniformly from being 0 at level 0 and 0.1 at level 4, and the parameter p was varied uniformly from being 0 at level 0 and 0.01 at level 4.", "labels": [], "entities": [{"text": "P drop", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9023103415966034}]}, {"text": "We are showing the best F-measure (harmonic mean of precision and recall) for each system at different noise levels.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.998202919960022}, {"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.7969930768013}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9965588450431824}]}, {"text": "As can be seen, KRISP's performance degrades gracefully in the presence of noise while other systems' performance degrade much faster, thus verifying our hypothesis.", "labels": [], "entities": []}, {"text": "In this experiment, only the test sentences were corrupted, we get qualitatively similar results when both training and test sentences are corrupted.", "labels": [], "entities": []}, {"text": "The results are also similar on the GEOQUERY corpus.", "labels": [], "entities": [{"text": "GEOQUERY corpus", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.9786750376224518}]}], "tableCaptions": []}