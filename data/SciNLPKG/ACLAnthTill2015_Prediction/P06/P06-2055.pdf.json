{"title": [{"text": "Analysis and Repair of Name Tagger Errors", "labels": [], "entities": [{"text": "Repair of Name Tagger Errors", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.7833087801933288}]}], "abstractContent": [{"text": "Name tagging is a critical early stage in many natural language processing pipelines.", "labels": [], "entities": [{"text": "Name tagging", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8865571916103363}]}, {"text": "In this paper we analyze the types of errors produced by a tagger, distinguishing name classification and various types of name identification errors.", "labels": [], "entities": [{"text": "distinguishing name classification", "start_pos": 67, "end_pos": 101, "type": "TASK", "confidence": 0.6896215180555979}, {"text": "name identification", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7477579116821289}]}, {"text": "We present a joint inference model to improve Chinese name tagging by incorporating feedback from subsequent stages in an information extraction pipeline: name structure parsing, cross-document coreference, semantic relation extraction and event extraction.", "labels": [], "entities": [{"text": "Chinese name tagging", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.6016144653161367}, {"text": "name structure parsing", "start_pos": 155, "end_pos": 177, "type": "TASK", "confidence": 0.658256729443868}, {"text": "semantic relation extraction", "start_pos": 207, "end_pos": 235, "type": "TASK", "confidence": 0.6889772017796835}, {"text": "event extraction", "start_pos": 240, "end_pos": 256, "type": "TASK", "confidence": 0.7672664225101471}]}, {"text": "We show through examples and performance measurement how different stages can correct different types of errors.", "labels": [], "entities": []}, {"text": "The resulting accuracy approaches that of individual human an-notators.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9994482398033142}]}], "introductionContent": [{"text": "High-performance named entity (NE) tagging is crucial in many natural language processing tasks, such as information extraction and machine translation.", "labels": [], "entities": [{"text": "named entity (NE) tagging", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.7315875391165415}, {"text": "information extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8324841260910034}, {"text": "machine translation", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.7978004217147827}]}, {"text": "In 'traditional' pipelined system architectures, NE tagging is one of the first steps in the pipeline.", "labels": [], "entities": [{"text": "NE tagging", "start_pos": 49, "end_pos": 59, "type": "TASK", "confidence": 0.9008744359016418}]}, {"text": "NE errors adversely affect subsequent stages, and error rates are often compounded by later stages.", "labels": [], "entities": [{"text": "NE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9325595498085022}, {"text": "error rates", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.9580570161342621}]}, {"text": "However,) and our recent work have focused on incorporating richer linguistic analysis, using the \"feedback\" from later stages to improve name taggers.", "labels": [], "entities": [{"text": "name taggers", "start_pos": 138, "end_pos": 150, "type": "TASK", "confidence": 0.8062354028224945}]}, {"text": "We expanded our last year's model) that used the results of coreference analysis and relation extraction, by adding 'feedback' from more information extraction componentsname structure parsing, cross-document coreference, and event extraction -to incrementally rerank the multiple hypotheses from a baseline name tagger.", "labels": [], "entities": [{"text": "coreference analysis", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.9303348064422607}, {"text": "relation extraction", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.8153974115848541}, {"text": "structure parsing", "start_pos": 175, "end_pos": 192, "type": "TASK", "confidence": 0.7539869844913483}, {"text": "event extraction", "start_pos": 226, "end_pos": 242, "type": "TASK", "confidence": 0.759078323841095}]}, {"text": "While together these components produced a further improvement on last year's model, our goal in this paper is to look behind the overall performance figures in order to understand how these varied components contribute to the improvement, and compare the remaining system errors with the human annotator's performance.", "labels": [], "entities": []}, {"text": "To this end, we shall decompose the task of name tagging into two subtasks \u2022 Name Identification -The process of identifying name boundaries in the sentence.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.7102149724960327}, {"text": "Name Identification", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7653990387916565}]}, {"text": "\u2022 Name Classification -Given the correct name boundaries, assigning the appropriate name types to them. and observe the effects that different components have on errors of each type.", "labels": [], "entities": [{"text": "Name Classification", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.8570074141025543}]}, {"text": "Errors of identification will be further subdivided by type (missing names, spurious names, and boundary errors).", "labels": [], "entities": []}, {"text": "We believe such detailed understanding of the benefits of joint inference is a prerequisite for further improvements in name tagging performance.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 120, "end_pos": 132, "type": "TASK", "confidence": 0.8878228068351746}]}, {"text": "After summarizing some prior work in this area, describing our baseline NE tagger, and analyzing its errors, we shall illustrate, through a series of examples, the potential for feedback to improve NE performance.", "labels": [], "entities": []}, {"text": "We then present some details on how this improvement can be achieved through hypothesis reranking in the extraction pipeline, and analyze the results in terms of different types of identification and classification errors.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following we evaluate the contributions of re-rankers in name identification and classification separately.", "labels": [], "entities": [{"text": "name identification and classification", "start_pos": 64, "end_pos": 102, "type": "TASK", "confidence": 0.7982414215803146}]}, {"text": "show the performance on identification, classification, and the combined task as we add each re-ranker to the system.", "labels": [], "entities": [{"text": "identification", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.9579771161079407}, {"text": "classification", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.8509854078292847}]}], "tableCaptions": []}