{"title": [{"text": "Guiding a Constraint Dependency Parser with Supertags", "labels": [], "entities": [{"text": "Supertags", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.8714343309402466}]}], "abstractContent": [{"text": "We investigate the utility of supertag information for guiding an existing dependency parser of German.", "labels": [], "entities": []}, {"text": "Using weighted constraints to integrate the additionally available information, the decision process of the parser is influenced by changing its preferences, without excluding alternative structural interpretations from being considered.", "labels": [], "entities": []}, {"text": "The paper reports on a series of experiments using varying models of su-pertags that significantly increase the parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 112, "end_pos": 119, "type": "TASK", "confidence": 0.9709897041320801}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9320850372314453}]}, {"text": "In addition, an upper bound on the accuracy that can be achieved with perfect supertags is estimated.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9995576739311218}]}], "introductionContent": [{"text": "Supertagging is based on the combination of two powerful and influential ideas of natural language processing: On the one hand, parsing is (at least partially) reduced to a decision on the optimal sequence of categories, a problem for which efficient and easily trainable procedures exist.", "labels": [], "entities": []}, {"text": "On the other hand, supertagging exploits complex categories, i.e. tree fragments which much better reflect the mutual compatibility between neighbouring lexical items than say part-of-speech tags.", "labels": [], "entities": []}, {"text": "Bangalore and Joshi (1999) derived the notion of supertag within the framework of Lexicalized Tree-Adjoining Grammars (LTAG) (.", "labels": [], "entities": []}, {"text": "They considered supertagging a process of almost parsing, since all that needs to be done after having a sufficiently reliable sequence of supertags available is to decide on their combination into a spanning tree for the complete sentence.", "labels": [], "entities": []}, {"text": "Thus the approach lends itself easily to preprocessing sentences or filtering parsing results with the goal of guiding the parser or reducing its output ambiguity.", "labels": [], "entities": []}, {"text": "estimated that perfect supertag information already provides fora parsing accuracy of 98% if a correct supertag assignment were available.", "labels": [], "entities": [{"text": "parsing", "start_pos": 66, "end_pos": 73, "type": "TASK", "confidence": 0.9430338740348816}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9695765972137451}]}, {"text": "Unfortunately, perfectly reliable supertag information cannot be expected; usually this uncertainty is compensated by running the tagger in multi-tagging mode, expecting that the reliability can be increased by not forcing the tagger to take unreliable decisions but instead offering a set of alternatives from which a subsequent processing component can choose.", "labels": [], "entities": []}, {"text": "A grammar formalism which seems particularly well suited to decompose structural descriptions into lexicalized tree fragments is dependency grammar.", "labels": [], "entities": [{"text": "dependency grammar", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.8349441587924957}]}, {"text": "It allows us to define supertags on different levels of granularity), thus facilitating a fine grained analysis of how the different aspects of supertag information influence the parsing behaviour.", "labels": [], "entities": [{"text": "parsing", "start_pos": 179, "end_pos": 186, "type": "TASK", "confidence": 0.9622718691825867}]}, {"text": "In the following we will use this characteristic to study in more detail the utility of different kinds of supertag information for guiding the parsing process.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 144, "end_pos": 159, "type": "TASK", "confidence": 0.9229282140731812}]}, {"text": "Usually supertags are combined with a parser in a filtering mode, i.e. parsing hypotheses which are not compatible with the supertag predictions are simply discarded.", "labels": [], "entities": []}, {"text": "Drawing on the ability of Weighted Constraint Dependency Grammar (WCDG) () to deal with defeasible constraints, here we try another option for making available supertag information: Using a score to estimate the general reliability of unique supertag decisions, the information can be combined with evidence derived from other constraints of the grammar in a soft manner.", "labels": [], "entities": []}, {"text": "It makes possible to rank parsing hypotheses according to their plausibility and allows the parser to even override potentially wrong supertag decisions.", "labels": [], "entities": []}, {"text": "Starting from a range of possible supertag models, Section 2 explores the reliability with which dependency-based supertags can be determined on  different levels of granularity.", "labels": [], "entities": []}, {"text": "Then, Section 3 describes how supertags are integrated into the existing parser for German.", "labels": [], "entities": []}, {"text": "The complex nature of supertags as we define them makes it possible to separate the different structural predictions made by a single supertag into components and study their contributions independently (c.f. Section 4).", "labels": [], "entities": []}, {"text": "We can show that indeed the parser is robust enough to tolerate supertag errors and that even with a fairly low tagger performance it can profit from the additional, though unreliable information.", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested the effect of supertag predictions on a full parser by adding the new constraints to the WCDG of German described in ( ) and re-parsing the same 1,000 sentences from the NEGRA corpus.", "labels": [], "entities": [{"text": "NEGRA corpus", "start_pos": 180, "end_pos": 192, "type": "DATASET", "confidence": 0.971622109413147}]}, {"text": "The quality of a dependency parser such as this can be measured as the ratio of correctly attached words to all words (structural accuracy) or the ratio of the correctly attached and correctly labelled words to all words (labelled accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.7458329796791077}, {"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.7475124597549438}]}, {"text": "Note that because the parser always finds exactly one analysis with exactly one subordination per word, there is no distinction between recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9979573488235474}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9926242232322693}]}, {"text": "The structural accuracy without any supertags is 89.6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9964458346366882}]}, {"text": "To determine the best trade-off between complexity and prediction quality, we tested all 10 supertag models against the baseline case of no supertags at all.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "Two observations can be made about the effect of the supertag model on parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9641874432563782}]}, {"text": "Firstly, all types of supertag prediction, even the very basic model A which predicts only edge labels, improve the overall accuracy of parsing, although the baseline is already quite high.", "labels": [], "entities": [{"text": "supertag prediction", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.8561633229255676}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9992484450340271}, {"text": "parsing", "start_pos": 136, "end_pos": 143, "type": "TASK", "confidence": 0.9767151474952698}]}, {"text": "Second, the richer models of supertags appear to be more suitable for guiding the parser than the simpler ones, even though their own accuracy is markedly lower; almost one third of the supertag predictions according to the most compli-cated definition J are wrong, but nevertheless their inclusion reduces the remaining error rate of the parser by over 20%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9989548921585083}, {"text": "error rate", "start_pos": 321, "end_pos": 331, "type": "METRIC", "confidence": 0.9414707720279694}]}, {"text": "This result confirms the assumption that if supertags are integrated as individual constraints, their component accuracy is more important than the supertag accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9794426560401917}, {"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9355531930923462}]}, {"text": "The decreasing accuracy of more complex supertags is more than counterbalanced by the additional information that they contribute to the analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9989010095596313}]}, {"text": "Obviously, this trend cannot continue indefinitely; a supertag definition that predicted even larger parts of the dependency tree would certainly lead to much lower accuracy by even the most lenient measure, and a prediction that is mostly wrong must ultimately degrade parsing performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.997894823551178}]}, {"text": "Since the most complex model J shows no parsing improvement over its successor I, this point might already have been reached.", "labels": [], "entities": []}, {"text": "The use of supertags in WCDG is comparable to previous work which integrated POS tagging and chunk parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.7737230062484741}, {"text": "chunk parsing", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.7811071872711182}]}, {"text": "( showed that the correct balance between the new knowledge and the existing grammar is crucial for successful integration.", "labels": [], "entities": []}, {"text": "This is achieved by means of an additional parameter, modeling how trustworthy supertag predictions are considered.", "labels": [], "entities": []}, {"text": "Its effect is shown in Table 4.", "labels": [], "entities": []}, {"text": "As expected, making supertag constraints hard (with a value of 0.0) over-constrains most parsing problems, so that hardly any analyses can be computed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 89, "end_pos": 96, "type": "TASK", "confidence": 0.972380518913269}]}, {"text": "Other values near 0 avoid this problem but still lead to much worse overall performance, as wrong or even impossible predictions too often overrule the normal syntax constraints.", "labels": [], "entities": []}, {"text": "The previously used value of 0.9 actually yields the best results with this particular grammar.", "labels": [], "entities": []}, {"text": "The fact that a statistical model can improve parsing performance when superimposed on a sophisticated hand-written grammar is of particular interest because the statistical model we used is so simple, and in fact not particularly accurate; it certainly does not represent the state of the art in supertagging.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9733375906944275}]}, {"text": "This gives rise to the hope that as better supertaggers for German become available, parsing results will continue to see additional improvements, i.e., future supertagging research will directly benefit parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.9815426468849182}, {"text": "parsing", "start_pos": 204, "end_pos": 211, "type": "TASK", "confidence": 0.9736936092376709}]}, {"text": "The obvious question is how great this benefit might conceivably become under optimal conditions.", "labels": [], "entities": []}, {"text": "To obtain this upper limit of the utility of supertags we repeated: Unlabelled and labelled parsing accuracy with a simulated perfect supertagger.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.904678225517273}]}, {"text": "the process of translating each supertag into additional WCDG constraints, but this time using the test set itself rather than TnT's predictions.", "labels": [], "entities": []}, {"text": "again gives the unlabelled and labelled parsing accuracy for all 10 different supertag models with the integration strengths of 0 and 0.9.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9336420893669128}, {"text": "integration", "start_pos": 103, "end_pos": 114, "type": "METRIC", "confidence": 0.9676677584648132}]}, {"text": "(Note that since all our models predict the edge label of each word, hard integration of perfect predictions eliminates the difference between labelled und unlabelled accuracy.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9790104627609253}]}, {"text": "As expected, an improved accuracy of supertagging would lead to improved parsing accuracy in each case.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9993545413017273}, {"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.971158504486084}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9614938497543335}]}, {"text": "In fact, knowing the correct supertag would solve the parsing problem almost completely with the more complex models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9822263717651367}]}, {"text": "This confirms earlier findings for English ().", "labels": [], "entities": []}, {"text": "Since perfect supertaggers are not available, we have to make do with the imperfect ones that do exist.", "labels": [], "entities": []}, {"text": "One method of avoiding some errors introduced by supertagging would be to reject supertag predictions that tend to be wrong.", "labels": [], "entities": []}, {"text": "To this end, we ran the supertagger on its training set and determined the average component accuracy of each occurring supertag.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.967787504196167}]}, {"text": "The supertags whose average precision fell below a variable threshold were not considered during parsing as if the supertagger had not made a prediction.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.981355607509613}]}, {"text": "This means that a threshold of 100% corresponds to the baseline of not using supertags at all, while a threshold of 0% prunes nothing, so that these two cases duplicate the first and last line from.", "labels": [], "entities": []}, {"text": "As shows, pruning supertags that are wrong more often than they are right results in a further small improvement in parsing accuracy: unlabelled syntax accuracy rises up to 92.1% against the 91.8% if all supertags of model J are used.", "labels": [], "entities": [{"text": "parsing", "start_pos": 116, "end_pos": 123, "type": "TASK", "confidence": 0.9672287106513977}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9518041610717773}, {"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.8826983571052551}]}, {"text": "However, the effect is not very noticeable, so that it would be almost certainly more useful to: Parsing accuracy with empirically pruned supertag predictions.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 97, "end_pos": 104, "type": "TASK", "confidence": 0.8948439359664917}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9747294187545776}]}, {"text": "improve the supertagger itself rather than secondguess its output.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An annotation of the example sentence", "labels": [], "entities": []}, {"text": " Table 2: Definition of all supertag models used.", "labels": [], "entities": []}, {"text": " Table 3: Influence of supertag integration on pars- ing accuracy.", "labels": [], "entities": [{"text": "supertag integration", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.8749624490737915}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.7888057231903076}]}, {"text": " Table 4: Parsing accuracy depending on different  strength of supertag integration.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8403708338737488}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.955487847328186}, {"text": "supertag integration", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.7431530356407166}]}, {"text": " Table 5: Unlabelled and labelled parsing accuracy  with a simulated perfect supertagger.", "labels": [], "entities": [{"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.7870660424232483}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9537960886955261}]}, {"text": " Table 6: Parsing accuracy with empirically pruned  supertag predictions.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.929996132850647}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9753774404525757}]}]}