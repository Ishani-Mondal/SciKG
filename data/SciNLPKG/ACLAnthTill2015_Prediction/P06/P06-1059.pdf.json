{"title": [{"text": "Improving the Scalability of Semi-Markov Conditional Random Fields for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.765453577041626}]}], "abstractContent": [{"text": "This paper presents techniques to apply semi-CRFs to Named Entity Recognition tasks with a tractable computational cost.", "labels": [], "entities": [{"text": "Named Entity Recognition tasks", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.7003705129027367}]}, {"text": "Our framework can handle an NER task that has long named entities and many labels which increase the computational cost.", "labels": [], "entities": [{"text": "NER task", "start_pos": 28, "end_pos": 36, "type": "TASK", "confidence": 0.8994360566139221}]}, {"text": "To reduce the computational cost, we propose two techniques: the first is the use of feature forests, which enables us to pack feature-equivalent states, and the second is the introduction of a filtering process which significantly reduces the number of candidate states.", "labels": [], "entities": []}, {"text": "This framework allows us to use a rich set of features extracted from the chunk-based representation that can capture informative characteristics of entities.", "labels": [], "entities": []}, {"text": "We also introduce a simple trick to transfer information about distant entities by embedding label information into nonentity labels.", "labels": [], "entities": [{"text": "transfer information about distant entities", "start_pos": 36, "end_pos": 79, "type": "TASK", "confidence": 0.8722138404846191}]}, {"text": "Experimental results show that our model achieves an F-score of 71.48% on the JNLPBA 2004 shared task without using any external resources or post-processing techniques.", "labels": [], "entities": [{"text": "F-score", "start_pos": 53, "end_pos": 60, "type": "METRIC", "confidence": 0.9995500445365906}, {"text": "JNLPBA 2004 shared task", "start_pos": 78, "end_pos": 101, "type": "DATASET", "confidence": 0.8863502740859985}]}], "introductionContent": [{"text": "The rapid increase of information in the biomedical domain has emphasized the need for automated information extraction techniques.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.7314411401748657}]}, {"text": "In this paper we focus on the Named Entity Recognition (NER) task, which is the first step in tackling more complex tasks such as relation extraction and knowledge mining.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) task", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.8086136536938804}, {"text": "relation extraction", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.9213888943195343}, {"text": "knowledge mining", "start_pos": 154, "end_pos": 170, "type": "TASK", "confidence": 0.8137638866901398}]}, {"text": "Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain.", "labels": [], "entities": [{"text": "Biomedical NER (Bio-NER) tasks", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7592281823356947}]}, {"text": "For example, the best F-score in the shared task of) was 72.55% () , whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9979804158210754}, {"text": "MUC-6", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.8765411972999573}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9994019269943237}]}, {"text": "Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (, the dictionary HMM model () and Maximum Entropy Markov Models (MEMMs) ().", "labels": [], "entities": []}, {"text": "Among these methods, conditional random fields (CRFs)) have achieved good results (), presumably because they are free from the so-called label bias problem by using a global normalization.", "labels": [], "entities": []}, {"text": "have recently introduced semi-Markov conditional random fields (semi-CRFs).", "labels": [], "entities": []}, {"text": "They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens 2 . The semiMarkov formulation allows one to easily construct entity-level features.", "labels": [], "entities": []}, {"text": "Since the features can capture all the characteristics of a subsequence, we can use, for example, a dictionary feature which measures the similarity between a candidate segment and the closest element in the dictionary.", "labels": [], "entities": []}, {"text": "have recently showed that semiCRFs perform better than CRFs in the task of recognition of protein entities.", "labels": [], "entities": [{"text": "recognition of protein entities", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.8275035917758942}]}, {"text": "The main difficulty of applying semi-CRFs to Bio-NER lies in the computational cost at training because the number of named entity classes tends to be large, and the training data typically contain many long entities, which makes it difficult to enumerate all the entity candidates in training.", "labels": [], "entities": []}, {"text": "shows the length distribution of entities in the training set of the shared task in 2004 JNLPBA.", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 89, "end_pos": 95, "type": "DATASET", "confidence": 0.8052558898925781}]}, {"text": "Formally, the computational cost of training semi- where L is the upper bound length of entities, N is the length of sentence and K is the size of label set.", "labels": [], "entities": []}, {"text": "And that of training in first order semi-CRFs is O(K 2 LN ).", "labels": [], "entities": [{"text": "O", "start_pos": 49, "end_pos": 50, "type": "METRIC", "confidence": 0.988716721534729}]}, {"text": "The increase of the cost is used to transfer non-adjacent entity information.", "labels": [], "entities": []}, {"text": "To improve the scalability of semi-CRFs, we propose two techniques: the first is to introduce a filtering process that significantly reduces the number of candidate entities by using a \"lightweight\" classifier, and the second is to use feature forest), with which we pack the feature equivalent states.", "labels": [], "entities": []}, {"text": "These enable us to construct semi-CRF models for the tasks where entity names maybe long and many class-labels exist at the same time.", "labels": [], "entities": []}, {"text": "We also present an extended version of semi-CRFs in which we can make use of information about a preceding named entity in defining features within the framework of first order semi-CRFs.", "labels": [], "entities": []}, {"text": "Since the preceding entity is not necessarily adjacent to the current entity, we achieve this by embedding the information on preceding labels for named entities into the labels for non-named entities.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were performed on the training and evaluation set provided by the shared task in COLING 2004 JNLPBA ().", "labels": [], "entities": [{"text": "COLING 2004 JNLPBA", "start_pos": 97, "end_pos": 115, "type": "DATASET", "confidence": 0.8448901176452637}]}, {"text": "The training data used in this shared task came from the GENIA version 3.02 corpus.", "labels": [], "entities": [{"text": "GENIA version 3.02 corpus", "start_pos": 57, "end_pos": 82, "type": "DATASET", "confidence": 0.9270647019147873}]}, {"text": "In the task there are five semantic labels: protein, DNA, RNA, cell line and cell type.", "labels": [], "entities": []}, {"text": "The training set consists of 2000 abstracts from MEDLINE, and the evaluation set consists of 404 abstracts.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.9484207630157471}]}, {"text": "We divided the original training set into 1800 abstracts and 200 abstracts, and the former was used as the training data and the latter as the development data.", "labels": [], "entities": []}, {"text": "For semi-CRFs, we used amis 3 for training the semi-CRF with feature-forest.", "labels": [], "entities": []}, {"text": "We used GENIA taggar 4 for POS-tagging and shallow parsing.", "labels": [], "entities": [{"text": "GENIA taggar 4", "start_pos": 8, "end_pos": 22, "type": "DATASET", "confidence": 0.8518475294113159}, {"text": "shallow parsing", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.6086151003837585}]}, {"text": "We set L = 10 for training and evaluation when we do not state L explicitly , where L is the upper bound of the length of possible chunks in semiCRFs.", "labels": [], "entities": []}, {"text": "lists the features used in our semi-CRFs.", "labels": [], "entities": []}, {"text": "We describe the chunk-dependent features in detail, which cannot be encoded in token-level features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Length distribution of entities in the train- ing set of the shared task in 2004 JNLPBA", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 91, "end_pos": 97, "type": "DATASET", "confidence": 0.8506723046302795}]}, {"text": " Table 2: Features used in the naive Bayes Classi- fier for the entity candidate: w s , w s+1 , ..., w e . sp i  is the result of shallow parsing at w i .", "labels": [], "entities": []}, {"text": " Table 4: Filtering results using the naive Bayes  classifier. The number of entity candidates for the  training set was 4179662, and that of the develop- ment set was 418628.", "labels": [], "entities": []}, {"text": " Table 5: Performance with filtering on the development data. (< 1.0 \u00d7 10 \u221212 ) means the threshold  probability of the filtering is 1.0 \u00d7 10 \u221212 .", "labels": [], "entities": []}, {"text": " Table 6: Overall performance on the evaluation set. L is the upper bound of the length of possible chunks  in semi-CRFs.  Recall Precision F-score  L < 5  64.33  65.51  64.92  L = 10 + Filtering (< 1.0 \u00d7 10.0 \u221212 ) 70.87  68.33  69.58  L = 10 + Filtering (< 1.0 \u00d7 10.0 \u221215 ) 72.59  70.16  71.36  w/o Chunk Feature  70.53  69.92  70.22  + Preceding Entity  72.65  70.35  71.48", "labels": [], "entities": [{"text": "Precision F-score  L", "start_pos": 130, "end_pos": 150, "type": "METRIC", "confidence": 0.7444628874460856}]}, {"text": " Table 7: Performance of our system on the evalu- ation set  Class Recall Precision F-score  protein 77.74  68.92  73.07  DNA 69.03  70.16  69.59  RNA 69.49  67.21  68.33  cell type 65.33  82.19  72.80  cell line 57.60  53.14  55.28  overall 72.65  70.35  71.48", "labels": [], "entities": [{"text": "Class Recall Precision F-score  protein 77.74  68.92  73.07  DNA 69.03  70.16  69.59  RNA 69.49  67.21  68.33  cell type 65.33  82.19  72.80  cell line", "start_pos": 61, "end_pos": 212, "type": "DATASET", "confidence": 0.7893431342166403}]}, {"text": " Table 8: Comparison with other systems", "labels": [], "entities": []}]}