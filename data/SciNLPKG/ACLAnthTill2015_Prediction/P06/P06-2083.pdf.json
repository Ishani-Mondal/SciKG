{"title": [{"text": "A Term Recognition Approach to Acronym Recognition", "labels": [], "entities": [{"text": "Term Recognition Approach to Acronym Recognition", "start_pos": 2, "end_pos": 50, "type": "TASK", "confidence": 0.6715738624334335}]}], "abstractContent": [{"text": "We present a term recognition approach to extract acronyms and their definitions from a large text collection.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7179582864046097}]}, {"text": "Parentheti-cal expressions appearing in a text collection are identified as potential acronyms.", "labels": [], "entities": []}, {"text": "Assuming terms appearing frequently in the proximity of an acronym to be the expanded forms (definitions) of the acronyms, we apply a term recognition method to enumerate such candidates and to measure the likelihood scores of the expanded forms.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.7259077280759811}, {"text": "likelihood", "start_pos": 206, "end_pos": 216, "type": "METRIC", "confidence": 0.9667355418205261}]}, {"text": "Based on the list of the expanded forms and their likelihood scores, the proposed algorithm determines the final acronym-definition pairs.", "labels": [], "entities": []}, {"text": "The proposed method combined with a letter matching algorithm achieved 78% precision and 85% recall on an evaluation corpus with 4,212 acronym-definition pairs.", "labels": [], "entities": [{"text": "letter matching", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.7767205834388733}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9994117021560669}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9995105266571045}]}], "introductionContent": [{"text": "In the biomedical literature the amount of terms (names of genes, proteins, chemical compounds, drugs, organisms, etc) is increasing at an astounding rate.", "labels": [], "entities": []}, {"text": "Existing terminological resources and scientific databases (such as Swiss-Prot 1 , SGD 2 , FlyBase , and UniProt 4 ) cannot keep up-to-date with the growth of neologisms ().", "labels": [], "entities": [{"text": "Swiss-Prot 1", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.930627703666687}, {"text": "FlyBase", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9597921967506409}]}, {"text": "Although curation teams maintain terminological resources, integrating neologisms is very difficult if not based on systematic extraction and * Research Fellow of the Japan Society for the Promotion of Science (JSPS)  collection of terminology from literature.", "labels": [], "entities": [{"text": "Japan Society for the Promotion of Science (JSPS", "start_pos": 167, "end_pos": 215, "type": "TASK", "confidence": 0.5153802732626597}]}, {"text": "Term identification in literature is one of the major bottlenecks in processing information in biology as it faces many challenges ().", "labels": [], "entities": [{"text": "Term identification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9647727310657501}]}, {"text": "The major challenges are due to term variation, e.g. spelling, morphological, syntactic, semantic variations (one term having different termforms), term synonymy and homonymy, which are all central concerns of any term management system.", "labels": [], "entities": []}, {"text": "Acronyms are among the most productive type of term variation.", "labels": [], "entities": [{"text": "Acronyms", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9281460642814636}]}, {"text": "Acronyms (e.g. RARA) are compressed forms of terms, and are used as substitutes of the fully expanded termforms (e.g., retinoic acid receptor alpha).", "labels": [], "entities": [{"text": "Acronyms", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9783063530921936}]}, {"text": "reported that, in MEDLINE abstracts, 64,242 new acronyms were introduced in 2004 with the estimated number being 800,000.", "labels": [], "entities": [{"text": "MEDLINE abstracts", "start_pos": 18, "end_pos": 35, "type": "DATASET", "confidence": 0.8666232824325562}]}, {"text": "reported that 5,477 documents could be retrieved by using the acronym JNK while only 3,773 documents could be retrieved by using its full term, c-jun N-terminal kinase.", "labels": [], "entities": [{"text": "JNK", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.8539680242538452}]}, {"text": "In practice, there are no rules or exact patterns for the creation of acronyms.", "labels": [], "entities": []}, {"text": "Moreover, acronyms are ambiguous, i.e., the same acronym may refer to different concepts (GR abbreviates both glucocorticoid receptor and glutathione reductase).", "labels": [], "entities": []}, {"text": "Acronyms also have variant forms (e.g. NF kappa B, NF kB, NF-KB, NF-kappaB, NFKB factor for nuclear factor-kappa B).", "labels": [], "entities": []}, {"text": "Ambiguity and variation present a challenge for any text mining system, since acronyms have not only to be recognised, but their variants have to be linked to the same canonical form and be disambiguated.", "labels": [], "entities": [{"text": "text mining", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.7449458241462708}]}, {"text": "Thus, discovering acronyms and relating them to their expanded forms is important for terminology management.", "labels": [], "entities": [{"text": "terminology management", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.9382610619068146}]}, {"text": "In this paper, we present a term recognition approach to construct an acronym dic-tionary from a large text collection.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7175138145685196}]}, {"text": "The proposed method focuses on terms appearing frequently in the proximity of an acronym and measures the likelihood scores of such terms to be the expanded forms of the acronyms.", "labels": [], "entities": []}, {"text": "We also describe an algorithm to combine the proposed method with a conventional letter-based method for acronym recognition.", "labels": [], "entities": [{"text": "acronym recognition", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.9729281961917877}]}], "datasetContent": [{"text": "Several evaluation corpora for acronym recognition are available.", "labels": [], "entities": [{"text": "acronym recognition", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.981425404548645}]}, {"text": "The Medstract Gold Standard Evaluation Corpus, which consists of 166 alias pairs annotated to 201 MEDLINE abstracts, is widely used for evaluation.", "labels": [], "entities": [{"text": "Medstract Gold Standard Evaluation Corpus", "start_pos": 4, "end_pos": 45, "type": "DATASET", "confidence": 0.9069237589836121}]}, {"text": "However, the amount of the text in the corpus is insufficient for the proposed method, which makes use of statistical features in a text collection.", "labels": [], "entities": []}, {"text": "Therefore, we prepared an evaluation corpus with a large text collection and examined how the proposed algorithm extracts short/long forms precisely and comprehensively.", "labels": [], "entities": []}, {"text": "We applied the short-form mining described in Section 3 to 7,306,153 MEDLINE abstracts . Out of 921,349 unique short-forms recognized by the short-form mining, top 50 acronyms 11 appearing frequently in the abstracts were chosen for our evaluation corpus.", "labels": [], "entities": []}, {"text": "We asked an expert in bioinformatics to extract long forms from 600,375 contextual sentences with the following criteria: along form with minimum necessary elements (words) to produce its acronym is accepted; along form with unnecessary elements, e.g., magnetic resonance imaging unit (MRI) or computed x-ray tomography (CT), is not accepted; a misspelled long-form, e.g., hidden markvov model (HMM), is accepted (to separate the acronym-recognition task from a spelling-correction task).", "labels": [], "entities": []}, {"text": "shows the top 20 acronyms in our evaluation corpus, the number of their contextual sentences, and the number of unique long-forms extracted.", "labels": [], "entities": []}, {"text": "Using this evaluation corpus as a gold standard, we examined precision, recall, and f-measure 12 of long forms recognized by the proposed algorithm and baseline systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9995220899581909}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.999381422996521}, {"text": "f-measure 12", "start_pos": 84, "end_pos": 96, "type": "METRIC", "confidence": 0.9475628435611725}]}, {"text": "We compared five systems: the proposed algorithm with Schwartz and Hearst's algorithm integrated (PM+SH); the proposed algorithm without any letter-matching algorithm integrated (PM); the proposed algorithm but using the original C-value measure for long-form likelihood scores (CV+SH); the proposed algorithm but using co-occurrence frequency for longform likelihood scores (FQ+SH); and Schwartz and Hearst's algorithm (SH).", "labels": [], "entities": []}, {"text": "The threshold for the proposed algorithm was set to four.", "labels": [], "entities": []}, {"text": "The bestperforming configuration of algorithms (PM+SH) achieved 78% precision and 85% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9996240139007568}, {"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9991557598114014}]}, {"text": "The Schwartz and Hearst's (SH) algorithm obtained a good recall (93%) but misrecognized a number of long-forms (56% precision), e.g., the kinetics of serum tumour necrosis alpha (TNF-ALPHA) and infected mice lacking the gamma interferon (IFN-GAMMA).", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9995324611663818}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9974880218505859}]}, {"text": "The SH algorithm cannot gather variations of long forms for an acronym, e.g., ACE as angiotensin-converting enzyme level, angiotensin i-converting enzyme gene, angiotensin-1-converting enzyme, angiotensin-converting, angiotensin converting activity, etc.", "labels": [], "entities": []}, {"text": "The proposed method combined with the Schwartz and Hearst's algorithm remedied these misrecognitions based on the likelihood scores and the long-form validation algorithm.", "labels": [], "entities": []}, {"text": "The PM+SH also outperformed other likelihood measures, CV+SH and FQ+SH.", "labels": [], "entities": [{"text": "PM+SH", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8315724531809489}, {"text": "FQ+SH", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.9397291541099548}]}, {"text": "We count the number of unique long forms, i.e., count once even if short/long form pair HMM, hidden markov model occurs more than once in the text collection.", "labels": [], "entities": []}, {"text": "The Porter's stemming algorithm was applied to long forms before comparing them with the gold standard.: Evaluation result of long-form recognition.", "labels": [], "entities": [{"text": "long-form recognition", "start_pos": 126, "end_pos": 147, "type": "TASK", "confidence": 0.742530107498169}]}, {"text": "The proposed algorithm without Schwartz and Hearst's algorithm (PM) identified long forms the most precisely (81% precision) but misses a number of long forms in the text collection (14% recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9874740839004517}, {"text": "recall", "start_pos": 187, "end_pos": 193, "type": "METRIC", "confidence": 0.9970445036888123}]}, {"text": "The result suggested that the proposed likelihood measure performed well to extract frequently used long-forms in a large text collection, but could not extract rare acronym-definition pairs.", "labels": [], "entities": []}, {"text": "We also found the case where PM missed a set of long forms for acronym ER which end with rate, e.g., eating rate, elimination rate, embolic rate, etc.", "labels": [], "entities": [{"text": "eating rate", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.8635455965995789}, {"text": "elimination rate", "start_pos": 114, "end_pos": 130, "type": "METRIC", "confidence": 0.8738681375980377}]}, {"text": "This was because the word rate was used with a variety of expansions (i.e., the likelihood score for rate was not reduced much) while it can be also interpreted as the long form of the acronym.", "labels": [], "entities": [{"text": "likelihood score", "start_pos": 80, "end_pos": 96, "type": "METRIC", "confidence": 0.9456404745578766}]}, {"text": "Even though the Medstract corpus is insufficient for evaluating the proposed method, we examined the number of long/short pairs extracted from 7,306,153 MEDLINE abstracts and also appearing in the Medstract corpus.", "labels": [], "entities": [{"text": "Medstract corpus", "start_pos": 16, "end_pos": 32, "type": "DATASET", "confidence": 0.8988010287284851}, {"text": "Medstract corpus", "start_pos": 197, "end_pos": 213, "type": "DATASET", "confidence": 0.9265199899673462}]}, {"text": "We can neither calculate the precision from this experiment nor compare the recall directly with other acronym recognition methods since the size of the source texts is different.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9994693398475647}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9980496168136597}, {"text": "acronym recognition", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.9148242175579071}]}, {"text": "Out of 166 pairs in Medstract corpus, 123 (74%) pairs were exactly covered by the proposed method, and 15 (83% in total) pairs were partially covered 13 . The algorithm missed 28 pairs because: 17 (10%) pairs in the corpus were not acronyms but more generic aliases, e.g., alpha tocopherol (Vitamin E); 4 (2%) pairs in the corpus were incorrectly annotated (e.g, long form in the corpus embryo fibroblasts lacks word mouse to form acronym MEFS); and 7 (4%) long forms are missed by the algorithm, e.g., the algorithm recognized pair protein kinase (PKR) while the correct pair in the corpus is RNA-activated protein kinase (PKR).", "labels": [], "entities": [{"text": "Medstract corpus", "start_pos": 20, "end_pos": 36, "type": "DATASET", "confidence": 0.9633828699588776}]}], "tableCaptions": [{"text": " Table 2: Long-form candidates for ADM.", "labels": [], "entities": [{"text": "ADM", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9461222887039185}]}, {"text": " Table 3: Statistics on our evaluation corpus.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation result of long-form recogni- tion.", "labels": [], "entities": []}]}