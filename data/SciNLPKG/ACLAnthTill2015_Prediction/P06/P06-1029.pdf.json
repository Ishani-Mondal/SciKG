{"title": [{"text": "Approximation Lasso Methods for Language Modeling", "labels": [], "entities": [{"text": "Approximation", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9804379940032959}, {"text": "Language Modeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7125843614339828}]}], "abstractContent": [{"text": "Lasso is a regularization method for parameter estimation in linear models.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.6744911670684814}]}, {"text": "It optimizes the model parameters with respect to a loss function subject to model complexities.", "labels": [], "entities": []}, {"text": "This paper explores the use of lasso for statistical language modeling for text input.", "labels": [], "entities": [{"text": "statistical language modeling", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.7872181534767151}]}, {"text": "Owing to the very large number of parameters, directly optimizing the penalized lasso loss function is impossible.", "labels": [], "entities": []}, {"text": "Therefore, we investigate two approximation methods, the boosted lasso (BLasso) and the forward stagewise linear regression (FSLR).", "labels": [], "entities": [{"text": "BLasso", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.830547571182251}, {"text": "forward stagewise linear regression (FSLR)", "start_pos": 88, "end_pos": 130, "type": "METRIC", "confidence": 0.7468691383089338}]}, {"text": "Both methods, when used with the exponential loss function, bear strong resemblance to the boosting algorithm which has been used as a discrimi-native training method for language mod-eling.", "labels": [], "entities": []}, {"text": "Evaluations on the task of Japanese text input show that BLasso is able to produce the best approximation to the lasso solution, and leads to a significant improvement, in terms of character error rate, over boosting and the traditional maximum likelihood estimation.", "labels": [], "entities": [{"text": "BLasso", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.8482890129089355}, {"text": "character error rate", "start_pos": 181, "end_pos": 201, "type": "METRIC", "confidence": 0.6383680403232574}]}], "introductionContent": [{"text": "Language modeling (LM) is fundamental to a wide range of applications.", "labels": [], "entities": [{"text": "Language modeling (LM)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8481654047966003}]}, {"text": "Recently, it has been shown that a linear model estimated using discriminative training methods, such as the boosting and perceptron algorithms, outperforms significantly a traditional word trigram model trained using maximum likelihood estimation (MLE) on several tasks such as speech recognition and Asian language text input (;.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 279, "end_pos": 297, "type": "TASK", "confidence": 0.7944222986698151}]}, {"text": "The success of discriminative training methods is largely due to fact that unlike the traditional approach (e.g., MLE) that maximizes the function (e.g., likelihood of training data) that is loosely associated with error rate, discriminative training methods aim to directly minimize the error rate on training data even if they reduce the likelihood.", "labels": [], "entities": []}, {"text": "However, given a finite set of training samples, discriminative training methods could lead to an arbitrary complex model for the purpose of achieving zero training error.", "labels": [], "entities": []}, {"text": "It is well-known that complex models exhibit high variance and perform poorly on unseen data.", "labels": [], "entities": [{"text": "variance", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9500079154968262}]}, {"text": "Therefore some regularization methods have to be used to control the complexity of the model.", "labels": [], "entities": []}, {"text": "Lasso is a regularization method for parameter estimation in linear models.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.6744911670684814}]}, {"text": "It optimizes the model parameters with respect to a loss function subject to model complexities.", "labels": [], "entities": []}, {"text": "The basic idea of lasso is originally proposed by.", "labels": [], "entities": []}, {"text": "Recently, there have been several implementations and experiments of lasso on multi-class classification tasks where only a small number of features need to be handled and the lasso solution can be directly computed via numerical methods.", "labels": [], "entities": [{"text": "multi-class classification tasks", "start_pos": 78, "end_pos": 110, "type": "TASK", "confidence": 0.7436333199342092}]}, {"text": "To our knowledge, this paper presents the first empirical study of lasso fora realistic, large scale task: LM for Asian language text input.", "labels": [], "entities": []}, {"text": "Because the task utilizes millions of features and training samples, directly optimizing the penalized lasso loss function is impossible.", "labels": [], "entities": []}, {"text": "Therefore, two approximation methods, the boosted lasso (BLasso,) and the forward stagewise linear regression), are investigated.", "labels": [], "entities": [{"text": "BLasso", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9095458984375}]}, {"text": "Both methods, when used with the exponential loss function, bear strong resemblance to the boosting algorithm which has been used as a discriminative training method for LM.", "labels": [], "entities": [{"text": "LM", "start_pos": 170, "end_pos": 172, "type": "TASK", "confidence": 0.9133711457252502}]}, {"text": "Evaluations on the task of Japanese text input show that BLasso is able to produce the best approximation to the lasso solution, and leads to a significant improvement, in terms of character error rate, over the boosting algorithm and the traditional MLE.", "labels": [], "entities": [{"text": "BLasso", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.886273980140686}, {"text": "character error rate", "start_pos": 181, "end_pos": 201, "type": "METRIC", "confidence": 0.6423402925332388}]}], "datasetContent": [], "tableCaptions": []}