{"title": [{"text": "A Pipeline Framework for Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7961603701114655}]}], "abstractContent": [{"text": "Pipeline computation, in which a task is decomposed into several stages that are solved sequentially, is a common computational strategy in natural language processing.", "labels": [], "entities": [{"text": "Pipeline computation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8912067413330078}, {"text": "natural language processing", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.6317336360613505}]}, {"text": "The key problem of this model is that it results in error accumulation and suffers from its inability to correct mistakes in previous stages.", "labels": [], "entities": []}, {"text": "We develop a framework for decisions made via in pipeline models, which addresses these difficulties, and presents and evaluates it in the context of bottom up dependency parsing for English.", "labels": [], "entities": [{"text": "bottom up dependency parsing", "start_pos": 150, "end_pos": 178, "type": "TASK", "confidence": 0.6673592403531075}]}, {"text": "We show improvements in the accuracy of the inferred trees relative to existing models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9992639422416687}]}, {"text": "Interestingly, the proposed algorithm shines especially when evaluated globally, at a sentence level, where our results are significantly better than those of existing approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "A pipeline process over the decisions of learned classifiers is a common computational strategy in natural language processing.", "labels": [], "entities": []}, {"text": "In this model a task is decomposed into several stages that are solved sequentially, where the computation in the ith stage typically depends on the outcome of computations done in previous stages.", "labels": [], "entities": []}, {"text": "For example, a semantic role labeling program) may start by using a part-of-speech tagger, then apply a shallow parser to chunk the sentence into phrases, identify predicates and arguments and then classify them to types.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.6544894576072693}]}, {"text": "In fact, any left to right processing of an English sentence maybe viewed as a pipeline computation as it processes a token and, potentially, makes use of this result when processing the token to the right.", "labels": [], "entities": []}, {"text": "The pipeline model is a standard model of computation in natural language processing for good reasons.", "labels": [], "entities": []}, {"text": "It is based on the assumption that some decisions might be easier or more reliable than others, and their outcomes, therefore, can be counted on when making further decisions.", "labels": [], "entities": []}, {"text": "Nevertheless, it is clear that it results in error accumulation and suffers from its inability to correct mistakes in previous stages.", "labels": [], "entities": []}, {"text": "Researchers have recently started to address some of the disadvantages of this model.", "labels": [], "entities": []}, {"text": "E.g.,) suggests a model in which global constraints are taken into account in a later stage to fix mistakes due to the pipeline.", "labels": [], "entities": []}, {"text": "() also address some aspects of this problem.", "labels": [], "entities": []}, {"text": "However, these solutions rely on the fact that all decisions are made with respect to the same input; specifically, all classifiers considered use the same examples as their input.", "labels": [], "entities": []}, {"text": "In addition, the pipelines they study are shallow.", "labels": [], "entities": []}, {"text": "This paper develops a general framework for decisions in pipeline models which addresses these difficulties.", "labels": [], "entities": []}, {"text": "Specifically, we are interested in deep pipelines -a large number of predictions that are being chained.", "labels": [], "entities": []}, {"text": "A pipeline process is one in which decisions made in the ith stage (1) depend on earlier decisions and (2) feed on input that depends on earlier decisions.", "labels": [], "entities": []}, {"text": "The latter issue is especially important at evaluation time since, at training time, a gold standard data set might be used to avoid this issue.", "labels": [], "entities": []}, {"text": "We develop and study the framework in the context of a bottom up approach to dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.8869864344596863}]}, {"text": "We suggest that two principles to guide the pipeline algorithm development: (i) Make local decisions as reliable as possible.", "labels": [], "entities": []}, {"text": "(ii) Reduce the number of decisions made.", "labels": [], "entities": []}, {"text": "Using these as guidelines we devise an algo-rithm for dependency parsing, prove that it satisfies these principles, and show experimentally that this improves the accuracy of the resulting tree.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.8691303431987762}, {"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.99839848279953}]}, {"text": "Specifically, our approach is based on a shiftreduced parsing as in.", "labels": [], "entities": []}, {"text": "Our general framework provides insights that allow us to improve their algorithm, and to principally justify some of the algorithmic decisions.", "labels": [], "entities": []}, {"text": "Specifically, the first principle suggests to improve the reliability of the local predictions, which we do by improving the set of actions taken by the parsing algorithm, and by using a lookahead search.", "labels": [], "entities": [{"text": "reliability", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9813706278800964}, {"text": "parsing algorithm", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.8846363425254822}]}, {"text": "The second principle is used to justify the control policy of the parsing algorithmwhich edges to consider at any point of time.", "labels": [], "entities": [{"text": "parsing algorithmwhich edges", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.8630447785059611}]}, {"text": "We prove that our control policy is optimal in some sense, and that the decisions we made, guided by these, principles lead to a significant improvement in the accuracy of the resulting parse tree.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9988695979118347}]}], "datasetContent": [{"text": "We use the standard corpus for this task, the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9953258335590363}]}, {"text": "The training set consists of sections 02 to 21 and the testing set is section 23.", "labels": [], "entities": []}, {"text": "The POS tags for the evaluation data sets were provided by the tagger of () (which has an accuracy of 97.2% section  We use the same evaluation metrics as in).", "labels": [], "entities": [{"text": "POS", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.7619529366493225}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9989456534385681}]}, {"text": "Dependency accuracy (DA) is the proportion of non-root words that are assigned the correct head.", "labels": [], "entities": [{"text": "accuracy (DA)", "start_pos": 11, "end_pos": 24, "type": "METRIC", "confidence": 0.9169488996267319}]}, {"text": "Complete accuracy (CA) indicates the fraction of sentences that have a complete correct analysis.", "labels": [], "entities": [{"text": "Complete accuracy (CA)", "start_pos": 0, "end_pos": 22, "type": "METRIC", "confidence": 0.902030634880066}]}, {"text": "We also measure that root accuracy (RA) and leaf accuracy (LA), as in (.", "labels": [], "entities": [{"text": "root accuracy (RA)", "start_pos": 21, "end_pos": 39, "type": "METRIC", "confidence": 0.8377565503120422}, {"text": "leaf accuracy (LA)", "start_pos": 44, "end_pos": 62, "type": "METRIC", "confidence": 0.9339860439300537}]}, {"text": "When evaluating the result, we exclude the punctuation marks, as done in) and ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 compares the three  policies in terms of the number of actions required  to build a tree.", "labels": [], "entities": []}, {"text": " Table 2: The significant of the action WaitLeft.", "labels": [], "entities": [{"text": "WaitLeft", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9723950624465942}]}, {"text": " Table 3: The effect of different depth settings.", "labels": [], "entities": []}, {"text": " Table 4: The effect of sentences length. The ex- periment is done with depth = 4.", "labels": [], "entities": [{"text": "depth", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9563264846801758}]}, {"text": " Table 5: Comparing different sources of POS tag- ging in a pipeline model. We set depth= 4 in all  the experiments of this table.", "labels": [], "entities": []}, {"text": " Table 6: The comparison between the current  work with other dependency parsing systems.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.801941305398941}]}]}