{"title": [{"text": "Expressing Implicit Semantic Relations without Supervision", "labels": [], "entities": [{"text": "Supervision", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.5373907089233398}]}], "abstractContent": [{"text": "We present an unsupervised learning algorithm that mines large text corpora for patterns that express implicit semantic relations.", "labels": [], "entities": []}, {"text": "For a given input word pair Y X : with some unspecified semantic relations, the corresponding output list of patterns m PP , , 1 \ud97b\udf59 is ranked according to how well each pattern i P expresses the relations between X and Y.", "labels": [], "entities": []}, {"text": "For example , given ostrich = X and bird = Y , the two highest ranking output patterns are \"X is the largest Y\" and \"Y such as the X\".", "labels": [], "entities": []}, {"text": "The output patterns are intended to be useful for finding further pairs with the same relations, to support the construction of lexicons, ontologies, and semantic networks.", "labels": [], "entities": []}, {"text": "The patterns are sorted by pertinence, where the pertinence of a pattern i P fora word pair Y X : is the expected relational similarity between the given pair and typical pairs for i P.", "labels": [], "entities": []}, {"text": "The algorithm is empirically evaluated on two tasks, solving multiple-choice SAT word analogy questions and classifying semantic relations in noun-modifier pairs.", "labels": [], "entities": [{"text": "multiple-choice SAT word analogy questions", "start_pos": 61, "end_pos": 103, "type": "TASK", "confidence": 0.6666742086410522}]}, {"text": "On both tasks, the algorithm achieves state-of-the-art results, performing significantly better than several alternative pattern ranking algorithms, based on tf-idf.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina widely cited paper, showed that the lexico-syntactic pattern \"Y such as the X\" can be used to mine large text corpora for word pairs Y X : in which X is a hyponym (type) of Y.", "labels": [], "entities": []}, {"text": "For example, if we search in a large corpus using the pattern \"Y such as the X\" and we find the string \"bird such as the ostrich\", then we can infer that \"ostrich\" is a hyponym of \"bird\".", "labels": [], "entities": []}, {"text": "demonstrated that the patterns \"Y's X\" and \"X of the Y\" can be used to mine corpora for pairs Y X : in which X is a meronym (part) of Y (e.g., \"wheel of the car\").", "labels": [], "entities": []}, {"text": "Here we consider the inverse of this problem: Given a word pair Y X : with some unspecified semantic relations, can we mine a large text corpus for lexico-syntactic patterns that express the implicit relations between X and Y ? For example, if we are given the pair ostrich:bird, can we discover the pattern \"Y such as the X\"?", "labels": [], "entities": []}, {"text": "We are particularly interested in discovering high quality patterns that are reliable for mining further word pairs with the same semantic relations.", "labels": [], "entities": []}, {"text": "In our experiments, we use a corpus of web pages containing about", "labels": [], "entities": []}], "datasetContent": [{"text": "In these experiments, we evaluate pertinence using 374 college-level multiple-choice word analogies, taken from the SAT test.", "labels": [], "entities": []}, {"text": "For each question, there is a target word pair, called the stem pair, and five choice pairs.", "labels": [], "entities": []}, {"text": "The task is to find the choice that is most analogous (i.e., has the highest relational similarity) to the stem.", "labels": [], "entities": []}, {"text": "This choice pair is called the solution and the other choices are distractors.", "labels": [], "entities": []}, {"text": "pairs in the input set W.", "labels": [], "entities": []}, {"text": "In Step 4 of the algorithm, we double the pairs, but we also drop some pairs because they do not co-occur in the corpus.", "labels": [], "entities": []}, {"text": "This leaves us with 4194 rows in the matrix.", "labels": [], "entities": []}, {"text": "As mentioned in Step 5, the matrix has 84,064 columns (patterns).", "labels": [], "entities": []}, {"text": "The sparse matrix density is 0.91%.", "labels": [], "entities": []}, {"text": "To answer a SAT question, we generate ranked lists of patterns for each of the six word pairs.", "labels": [], "entities": []}, {"text": "Each choice is evaluated by taking the intersection of its patterns with the stem's patterns.", "labels": [], "entities": []}, {"text": "The shared patterns are scored by the average of their rank in the stem's lists and the choice's lists.", "labels": [], "entities": []}, {"text": "Since the lists are sorted in order of decreasing pertinence, a low score means a high pertinence.", "labels": [], "entities": []}, {"text": "Our guess is the choice with the lowest scoring shared pattern.", "labels": [], "entities": []}, {"text": "shows three examples, two questions that are answered correctly followed by one that is answered incorrectly.", "labels": [], "entities": []}, {"text": "The correct answers are in bold font.", "labels": [], "entities": []}, {"text": "For the first question, the stem is ostrich:bird and the best choice is (a) lion:cat.", "labels": [], "entities": []}, {"text": "The highest ranking pattern that is shared by both of these pairs is \"Y such as the X\".", "labels": [], "entities": []}, {"text": "The third question illustrates that, even when the answer is incorrect, the best shared pattern (\"Y powered * * X\") maybe plausible.", "labels": [], "entities": []}, {"text": "Three examples of SAT questions.", "labels": [], "entities": []}, {"text": "shows the four highest ranking patterns for the stem and solution for the first example.", "labels": [], "entities": []}, {"text": "The pattern \"X lion Y\" is anomalous, but the other patterns seem reasonable.", "labels": [], "entities": []}, {"text": "The shared pattern \"Y such as the X\" is ranked 1 for both pairs, hence the average score for this pattern is 1.0, as shown in.", "labels": [], "entities": []}, {"text": "Note that the \"ostrich is the largest bird\" and \"lions are large cats\", but the largest cat is the Siberian tiger.", "labels": [], "entities": []}, {"text": "X\" ostrich:bird \"X is the largest Y\" \"Y such as the X\" \"X is * largest Y\" \"Y such * the X\" lion:cat \"X lion Y\" \"Y such as the X\" \"X are large Y\" \"Y and mountain X\".", "labels": [], "entities": []}, {"text": "lists the top five pairs in W that match the pattern \"Y such as the X\".", "labels": [], "entities": []}, {"text": "The pairs are sorted by ) : . The pattern \"Y such as the X\" is one of 146 patterns that are shared by ostrich:bird and lion:cat.", "labels": [], "entities": []}, {"text": "Most of these shared patterns are not very informative..", "labels": [], "entities": []}, {"text": "The top five pairs for \"Y such as the X\".", "labels": [], "entities": []}, {"text": "In, we compare ranking patterns by pertinence to ranking by various other measures, mostly based on varieties of tf-idf (term frequency times inverse document frequency, a common way to rank documents in information retrieval).", "labels": [], "entities": []}, {"text": "The tf-idf measures are taken from.", "labels": [], "entities": []}, {"text": "For comparison, we also include three algorithms that do not rank patterns (the bottom three rows in the table).", "labels": [], "entities": []}, {"text": "These three algorithms can answer the SAT questions, but they do not provide any kind of explanation for their answers.", "labels": [], "entities": []}, {"text": "In these experiments, we evaluate pertinence on the task of classifying noun-modifier pairs.", "labels": [], "entities": []}, {"text": "The problem is to classify a noun-modifier pair, such as \"flu virus\", according to the semantic relation between the head noun (virus) and the modifier (flu).", "labels": [], "entities": []}, {"text": "For example, \"flu virus\" is classified as a causality relation (the flu is caused by a virus).", "labels": [], "entities": []}, {"text": "For these experiments, we use a set of 600 manually labeled noun-modifier pairs.", "labels": [], "entities": []}, {"text": "There are five general classes of labels with thirty subclasses.", "labels": [], "entities": []}, {"text": "We present here the results with five classes; the results with thirty subclasses follow the same trends (that is, pertinence performs significantly better than the other ranking methods).", "labels": [], "entities": []}, {"text": "The five classes are causality (storm cloud), temporality (daily exercise), spatial (desert storm), participant (student protest), and quality (expensive book).", "labels": [], "entities": [{"text": "quality", "start_pos": 135, "end_pos": 142, "type": "METRIC", "confidence": 0.9915027618408203}]}, {"text": "The input set W consists of the 600 nounmodifier pairs.", "labels": [], "entities": []}, {"text": "This set is doubled in Step 4, but we drop some pairs because they do not co-occur in the corpus, leaving us with 1184 rows in the matrix.", "labels": [], "entities": []}, {"text": "There are 16,849 distinct patterns with a pair frequency often or more, resulting in 33,698 columns.", "labels": [], "entities": []}, {"text": "The matrix density is 2.57%.", "labels": [], "entities": []}, {"text": "To classify a noun-modifier pair, we use a single nearest neighbour algorithm with leave-oneout cross-validation.", "labels": [], "entities": []}, {"text": "We split the set 600 times.", "labels": [], "entities": []}, {"text": "Each pair gets a turn as the single testing example, while the other 599 pairs serve as training examples.", "labels": [], "entities": []}, {"text": "The testing example is classified according to the label of its nearest neighbour in the training set.", "labels": [], "entities": []}, {"text": "The distance between two nounmodifier pairs is measured by the average rank of their best shared pattern.", "labels": [], "entities": []}, {"text": "To gain some insight into the algorithm, we examined the 600 best shared patterns for each pair and its single nearest neighbour.", "labels": [], "entities": []}, {"text": "For each of the five classes, lists the most frequent pattern among the best shared patterns for the given class.", "labels": [], "entities": []}, {"text": "All of these patterns seem appropriate for their respective classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Three examples of SAT questions.", "labels": [], "entities": []}, {"text": " Table 3. The top five pairs for \"Y such as the X\".", "labels": [], "entities": []}, {"text": " Table 4. Performance of various algorithms on SAT.", "labels": [], "entities": []}, {"text": " Table 5 shows the re- sulting precision, recall, and F, when ranking  patterns by pertinence.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9298920035362244}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9997827410697937}, {"text": "F", "start_pos": 54, "end_pos": 55, "type": "METRIC", "confidence": 0.9998252987861633}]}, {"text": " Table 7. Performance on noun-modifiers.", "labels": [], "entities": []}]}