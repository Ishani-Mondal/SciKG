{"title": [{"text": "A Logic-based Semantic Approach to Recognizing Textual Entailment", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.81191086769104}]}], "abstractContent": [{"text": "This paper proposes a knowledge representation model and a logic proving setting with axioms on demand successfully used for recognizing textual entail-ments.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.7422414422035217}]}, {"text": "It also details a lexical inference system which boosts the performance of the deep semantic oriented approach on the RTE data.", "labels": [], "entities": [{"text": "RTE data", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.7410809695720673}]}, {"text": "The linear combination of two slightly different logical systems with the third lexical inference system achieves 73.75% accuracy on the RTE 2006 data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9993804693222046}, {"text": "RTE 2006 data", "start_pos": 137, "end_pos": 150, "type": "DATASET", "confidence": 0.9849193890889486}]}], "introductionContent": [{"text": "While communicating, humans use different expressions to convey the same meaning.", "labels": [], "entities": []}, {"text": "One of the central challenges for natural language understanding systems is to determine whether different text fragments have the same meaning or, more generally, if the meaning of one text can be derived from the meaning of another.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.6368453204631805}]}, {"text": "A module that recognizes the semantic entailment between two text snippets can be employed by many NLP applications.", "labels": [], "entities": []}, {"text": "For example, Question Answering systems have to identify texts that entail expected answers.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.8468497097492218}]}, {"text": "In Multi-document Summarization, the redundant information should be recognized and omitted from the summary.", "labels": [], "entities": [{"text": "Multi-document Summarization", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.8573073744773865}]}, {"text": "Trying to boost research in textual inferences, the PASCAL Network proposed the Recognizing Textual Entailment (RTE) challenges).", "labels": [], "entities": [{"text": "textual inferences", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7503164112567902}, {"text": "PASCAL Network", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.9304971992969513}, {"text": "Recognizing Textual Entailment (RTE)", "start_pos": 80, "end_pos": 116, "type": "TASK", "confidence": 0.6980465054512024}]}, {"text": "For a pair of two text fragments, the task is to determine if the meaning of one text (the entailed hypothesis denoted by ) can be inferred from the meaning of the other text (the entailing text or \u00a1 ).", "labels": [], "entities": []}, {"text": "In this paper, we propose a model to represent the knowledge encoded in text and a logical setting suitable to a recognizing semantic entailment system.", "labels": [], "entities": []}, {"text": "We cast the textual inference problem as a logic implication between meanings.", "labels": [], "entities": []}, {"text": "Text \u00a1 semantically entails if its meaning logically implies the meaning of . Thus, we, first, transform both text fragments into logic form, capture their meaning by detecting the semantic relations that hold between their constituents and load these rich logic representations into a natural language logic prover to decide if the entailment holds or not.", "labels": [], "entities": []}, {"text": "illustrates our approach to RTE.", "labels": [], "entities": [{"text": "RTE", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9217789769172668}]}, {"text": "The following sections of the paper shall detail the logic proving methodology, our logical representation of text and the various types of axioms that the prover uses.", "labels": [], "entities": [{"text": "logic proving", "start_pos": 53, "end_pos": 66, "type": "TASK", "confidence": 0.7799243927001953}]}, {"text": "To our knowledge, there are few logical approaches to) represents \u00a1 and into a first-order logic translation of the DRS language used in Discourse Representation Theory ( and uses a theorem prover and a model builder with some generic, lexical and geographical background knowledge to prove the entailment between the two texts.", "labels": [], "entities": [{"text": "Discourse Representation Theory", "start_pos": 137, "end_pos": 168, "type": "TASK", "confidence": 0.7420783837636312}]}], "datasetContent": [{"text": "The benchmark corpus for the RTE 2005 task consists of seven subsets with a 50%-50% split be-     showed that while WordNet lexical chains and NLP axioms are the most frequently used axioms throughout the proofs, the semantic and temporal axioms bring the highest improvement inaccuracy, for the RTE data.", "labels": [], "entities": [{"text": "RTE 2005 task", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.6365940570831299}, {"text": "RTE data", "start_pos": 296, "end_pos": 304, "type": "DATASET", "confidence": 0.9426730275154114}]}], "tableCaptions": [{"text": " Table 3: RTE 2005 data results (accuracy, confidence-weighted score, and f-measure for the true class)", "labels": [], "entities": [{"text": "RTE 2005 data", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.9596055348714193}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9995028972625732}, {"text": "confidence-weighted score", "start_pos": 43, "end_pos": 68, "type": "METRIC", "confidence": 0.9166606664657593}, {"text": "f-measure", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9610665440559387}]}, {"text": " Table 4: RTE 2006 data results (accuracy, average precision, and f-measure for the true class)", "labels": [], "entities": [{"text": "RTE 2006 data", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.9522095918655396}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9995750784873962}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.7374284267425537}, {"text": "f-measure", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9539589881896973}]}]}