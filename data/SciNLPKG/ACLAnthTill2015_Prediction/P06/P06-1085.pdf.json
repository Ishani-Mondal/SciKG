{"title": [{"text": "Contextual Dependencies in Unsupervised Word Segmentation *", "labels": [], "entities": [{"text": "Contextual Dependencies in Unsupervised Word Segmentation", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.6566199411948522}]}], "abstractContent": [{"text": "Developing better methods for segmenting continuous text into words is important for improving the processing of Asian languages, and may shed light on how humans learn to segment speech.", "labels": [], "entities": [{"text": "segmenting continuous text into words", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.8447357058525086}]}, {"text": "We propose two new Bayesian word segmenta-tion methods that assume unigram and bi-gram models of word dependencies respectively.", "labels": [], "entities": []}, {"text": "The bigram model greatly out-performs the unigram model (and previous probabilistic models), demonstrating the importance of such dependencies for word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.7527942657470703}]}, {"text": "We also show that previous probabilistic models rely crucially on sub-optimal search procedures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word segmentation, i.e., discovering word boundaries in continuous text or speech, is of interest for both practical and theoretical reasons.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6922036558389664}, {"text": "discovering word boundaries in continuous text or speech", "start_pos": 25, "end_pos": 81, "type": "TASK", "confidence": 0.8183284997940063}]}, {"text": "It is the first step of processing orthographies without explicit word boundaries, such as Chinese.", "labels": [], "entities": []}, {"text": "It is also one of the key problems that human language learners must solve as they are learning language.", "labels": [], "entities": []}, {"text": "Many previous methods for unsupervised word segmentation are based on the observation that transitions between units (characters, phonemes, or syllables) within words are generally more predictable than transitions across word boundaries.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7381030023097992}]}, {"text": "Statistics that have been proposed for measuring these differences include \"successor frequency\", \"transitional probabilities\", mutual information (Sun et al., * This work was partially supported by the following grants: NIH 1R01-MH60922, NIH RO1-DC000314, NSF IGERT-DGE-9870676, and the DARPA CALO project. 1998), \"accessor variety\", and boundary entropy).", "labels": [], "entities": [{"text": "NIH", "start_pos": 239, "end_pos": 242, "type": "DATASET", "confidence": 0.7553205490112305}, {"text": "RO1-DC000314", "start_pos": 243, "end_pos": 255, "type": "METRIC", "confidence": 0.3542155623435974}]}, {"text": "While methods based on local statistics are quite successful, here we focus on approaches based on explicit probabilistic models.", "labels": [], "entities": []}, {"text": "Formulating an explicit probabilistic model permits us to cleanly separate assumptions about the input and properties of likely segmentations from details of algorithms used to find such solutions.", "labels": [], "entities": []}, {"text": "Specifically, this paper demonstrates the importance of contextual dependencies for word segmentation by comparing two probabilistic models that differ only in that the first assumes that the probability of a word is independent of its local context, while the second incorporates bigram dependencies between adjacent words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7165030539035797}]}, {"text": "The algorithms we use to search for likely segmentations do differ, but so long as the segmentations they produce are close to optimal we can be confident that any differences in the segmentations reflect differences in the probabilistic models, i.e., in the kinds of dependencies between words.", "labels": [], "entities": []}, {"text": "We are not the first to propose explicit probabilistic models of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7470018863677979}]}, {"text": "Two successful word segmentation systems based on explicit probabilistic models are those of and.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7321960628032684}]}, {"text": "Brent's ModelBased Dynamic Programming (MBDP) system assumes a unigram word distribution.", "labels": [], "entities": [{"text": "ModelBased Dynamic Programming (MBDP)", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.6932826985915502}]}, {"text": "Venkataraman uses standard unigram, bigram, and trigram language models in three versions of his system, which we refer to as n-gram Segmentation (NGS).", "labels": [], "entities": []}, {"text": "Despite their rather different generative structure, the MBDP and NGS segmentation accuracies are very similar.", "labels": [], "entities": [{"text": "MBDP", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.6861404776573181}, {"text": "NGS segmentation", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.6280391067266464}]}, {"text": "Moreover, the segmentation accuracy of the NGS unigram, bigram, and trigram models hardly differ, suggesting that contextual dependencies are irrelevant to word segmentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8301351070404053}, {"text": "word segmentation", "start_pos": 156, "end_pos": 173, "type": "TASK", "confidence": 0.7333763092756271}]}, {"text": "How-ever, the segmentations produced by both these methods depend crucially on properties of the search procedures they employ.", "labels": [], "entities": []}, {"text": "We show this by exhibiting for each model a segmentation that is less accurate but more probable under that model.", "labels": [], "entities": []}, {"text": "In this paper, we present an alternative framework for word segmentation based on the Dirichlet process, a distribution used in nonparametric Bayesian statistics.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7373403608798981}]}, {"text": "This framework allows us to develop extensible models that are amenable to standard inference procedures.", "labels": [], "entities": []}, {"text": "We present two such models incorporating unigram and bigram word dependencies, respectively.", "labels": [], "entities": []}, {"text": "We use Gibbs sampling to sample from the posterior distribution of possible segmentations under these models.", "labels": [], "entities": []}, {"text": "The plan of the paper is as follows.", "labels": [], "entities": []}, {"text": "In the next section, we describe MBDP and NGS in detail.", "labels": [], "entities": [{"text": "MBDP", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.5318672060966492}, {"text": "NGS", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8079928159713745}]}, {"text": "In Section 3 we present the unigram version of our own model, the Gibbs sampling procedure we use for inference, and experimental results.", "labels": [], "entities": []}, {"text": "Section 4 extends that model to incorporate bigram dependencies, and Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the same basic setup for our experiments with the HDP model as we used for the DP model.", "labels": [], "entities": []}, {"text": "We experimented with different values of \u03b1 0 and \u03b1 1 , keeping p # = .5 throughout.", "labels": [], "entities": []}, {"text": "Some results of these experiments are plotted in.", "labels": [], "entities": []}, {"text": "With appropriate parameter settings, both lexicon and token accuracy are higher than in the unigram model (dramatically so, for tokens), and there is no longer a negative correlation between the two.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9507635831832886}]}, {"text": "Only a few collocations remain in the lexicon, and most lexicon errors are on low-frequency words.", "labels": [], "entities": []}, {"text": "The best values of \u03b1 0 are much larger than in the unigram model, presumably because all unique word types must be generated via P 0 , but in the bigram model there is an additional level of discounting (the unigram process) before reaching P 0 . Smaller values of \u03b1 0 lead to fewer word types with fewer characters on average.", "labels": [], "entities": []}, {"text": "compares the optimal results of the HDP model to the only previous model incorporating bigram dependencies, NGS.", "labels": [], "entities": [{"text": "NGS", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.9191355109214783}]}, {"text": "Due to search, the performance of the bigram NGS model is not much different from that of the unigram model.", "labels": [], "entities": []}, {"text": "In contrast, our HDP model performs far better than our DP model, leading to the highest published accuracy for this corpus on both tokens and lexical items.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9928796887397766}]}, {"text": "Overall, these results strongly support our hypothesis that modeling bigram dependencies is important for accurate word segmentation.", "labels": [], "entities": [{"text": "accurate word segmentation", "start_pos": 106, "end_pos": 132, "type": "TASK", "confidence": 0.5991895397504171}]}], "tableCaptions": [{"text": " Table 1: Accuracy of the various systems, with  best scores in bold. The unigram version of NGS  is shown. DP results are with p # = .5 and \u03b1 0 =  20. (a) Results on the true corpus. (b) Results on  the permuted corpus.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9826008677482605}, {"text": "NGS", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.9350422620773315}]}, {"text": " Table 2: Negative log probabilities (x 1000) un- der each model of the true solution, the solution  with no utterance-internal boundaries, and the so- lutions found by each algorithm. Best solutions  under each model are bold.", "labels": [], "entities": []}]}