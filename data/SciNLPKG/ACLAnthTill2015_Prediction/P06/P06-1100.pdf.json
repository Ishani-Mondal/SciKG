{"title": [], "abstractContent": [{"text": "Many algorithms have been developed to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories.", "labels": [], "entities": []}, {"text": "In this paper, we propose two algorithms for automatically ontologiz-ing (attaching) semantic relations into WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.8674408793449402}]}, {"text": "We present an empirical evaluation on the task of attaching part-of and causation relations, showing an improvement on F-score over a baseline model.", "labels": [], "entities": [{"text": "F-score", "start_pos": 119, "end_pos": 126, "type": "METRIC", "confidence": 0.9942504167556763}]}], "introductionContent": [{"text": "NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (), semantic lexicons (, concept lists (, and word similarity lists).", "labels": [], "entities": []}, {"text": "Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (), is-a, part-of (, and other relations.", "labels": [], "entities": [{"text": "extracting binary semantic relations between entities", "start_pos": 41, "end_pos": 94, "type": "TASK", "confidence": 0.8444196879863739}]}, {"text": "The output of most of these systems is flat lists of lexical semantic knowledge such as \"Italy is-a country\" and \"orange similar-to blue\".", "labels": [], "entities": []}, {"text": "However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet.", "labels": [], "entities": [{"text": "keyword matching", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.801186740398407}, {"text": "WordNet", "start_pos": 186, "end_pos": 193, "type": "DATASET", "confidence": 0.9489113688468933}]}, {"text": "defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy.", "labels": [], "entities": []}, {"text": "For example, \"orange similar-to blue\" ontologizes in WordNet to \"orange#2 similar-to blue#1\" and \"orange#2 similar-to blue#2\".", "labels": [], "entities": [{"text": "WordNet", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9500013589859009}]}, {"text": "In his framework, Pantel proposed a method of inducing ontological co-occurrence vectors 1 which are subsequently used to ontologize unknown terms into WordNet with 74% accuracy.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 152, "end_pos": 159, "type": "DATASET", "confidence": 0.9037440419197083}, {"text": "accuracy", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.9959646463394165}]}, {"text": "In this paper, we take the next step and explore two algorithms for ontologizing binary semantic relations into WordNet and we present empirical results on the task of attaching part-of and causation relations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.9375647902488708}]}, {"text": "Formally, given an instance (x, r, y) of a binary relation r between terms x and y, the ontologizing task is to identify the WordNet senses of x and y where r holds.", "labels": [], "entities": []}, {"text": "For example, the instance (proton, PART-OF, element) ontologizes into WordNet as (proton#1, PART-OF, element#2).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.9615091681480408}]}, {"text": "The first algorithm that we explore, called the anchoring approach, was suggested as a promising avenue of future work in).", "labels": [], "entities": []}, {"text": "This bottom up algorithm is based on the intuition that x can be disambiguated by retrieving the set of terms that occur in the same relation r with y and then finding the senses of x that are most similar to this set.", "labels": [], "entities": []}, {"text": "The assumption is that terms occurring in the same relation will tend to have similar meaning.", "labels": [], "entities": []}, {"text": "In this paper, we propose a measure of similarity to capture this intuition.", "labels": [], "entities": []}, {"text": "In contrast to anchoring, our second algorithm, called the clustering approach, takes a top-down view.", "labels": [], "entities": [{"text": "anchoring", "start_pos": 15, "end_pos": 24, "type": "TASK", "confidence": 0.9619566202163696}]}, {"text": "Given a relation r, suppose that we are given every conceptual instance of r, i.e., instances of r in the upper ontology like (particles#1,).", "labels": [], "entities": []}, {"text": "An instance (x, r, y) can then be ontologized easily by finding the senses of x and y that are subsumed by ancestors linked by a conceptual instance of r.", "labels": [], "entities": []}, {"text": "For example, the instance (proton, PART-OF, element) ontologizes to (proton#1, PART-OF, element#2) since proton#1 is subsumed by particles and element#2 is subsumed by substances.", "labels": [], "entities": [{"text": "PART-OF", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.8354789614677429}]}, {"text": "The problem then is to automatically infer the set of con-ceptual instances.", "labels": [], "entities": []}, {"text": "In this paper, we develop a clustering algorithm for generalizing a set of relation instances to conceptual instances by looking up the WordNet hypernymy hierarchy for common ancestors, as specific as possible, that subsume as many instances as possible.", "labels": [], "entities": [{"text": "WordNet hypernymy hierarchy", "start_pos": 136, "end_pos": 163, "type": "DATASET", "confidence": 0.9054106672604879}]}, {"text": "An instance is then attached to its senses that are subsumed by the highest scoring conceptual instances.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we provide an empirical evaluation of our two algorithms.", "labels": [], "entities": []}, {"text": "Researchers have developed many algorithms for harvesting semantic relations from corpora and the Web.", "labels": [], "entities": []}, {"text": "For the purposes of this paper, we may choose anyone of them and manually validate its mined relations.", "labels": [], "entities": []}, {"text": "We choose Espresso 4 , a generalpurpose, broad, and accurate corpus harvesting algorithm requiring minimal supervision.", "labels": [], "entities": [{"text": "corpus harvesting", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7120914906263351}]}, {"text": "Adopt-ing a bootstrapping approach, Espresso takes as input a few seed instances of a particular relation and iteratively learns surface patterns to extract more instances.", "labels": [], "entities": []}, {"text": "\u2022 the correctness of the conceptual instances.", "labels": [], "entities": []}, {"text": "Incorrect conceptual instances such as, discovered by our system, can impede WSD and extraction tools where precise selectional restrictions are needed; and \u2022 the accuracy of the conceptual instances.", "labels": [], "entities": [{"text": "WSD and extraction", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7321679691473643}, {"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9989051818847656}]}, {"text": "Sometimes, an instance is incorrectly attached to a correct conceptual instance.", "labels": [], "entities": []}, {"text": "For example, the instance (air mass, PART-OF, cold front) is incorrectly clustered in [group#1, PART-OF, multitude#3] since mass and front both have a sense that is descendant of group#1 and multitude#3.", "labels": [], "entities": []}, {"text": "However, these are not the correct senses of mass and front for which the part-of relation holds.", "labels": [], "entities": []}, {"text": "For evaluating correctness, we manually verify how many correct conceptual instances are produced by Phase 2 of the clustering approach described in Section 3.2.", "labels": [], "entities": []}, {"text": "The claim is that a correct conceptual instance is one for which the relation holds for all possible subsumed senses.", "labels": [], "entities": []}, {"text": "For example, the conceptual instance [group#1, PART-OF, multitude#3] is correct, as the relation holds for every semantic subsumption of the two senses.", "labels": [], "entities": [{"text": "PART-OF", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.775856614112854}]}, {"text": "An example of an incorrect conceptual instance is [state#4, CAUSE, abstraction#6] since it subsumes the incorrect instance (audience, CAUSE, new context).", "labels": [], "entities": []}, {"text": "A manual evaluation of the highest scoring 200 conceptual instances, generated on our test sets described in Section 4.1, showed 82% correctness for the part-of relation and 86% for causation.", "labels": [], "entities": [{"text": "correctness", "start_pos": 133, "end_pos": 144, "type": "METRIC", "confidence": 0.9639920592308044}]}, {"text": "For estimating the overall clustering accuracy, we evaluated the number of correctly clustered instances in each conceptual instance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9416494369506836}]}, {"text": "For example, the instance (business people, PART-OF, committee) is correctly clustered in [multitude#3, PART-OF, group#1] and the instance (law, PART-OF, constitutional pitfalls) is incorrectly clustered in [group#1,.", "labels": [], "entities": []}, {"text": "We estimated the overall accuracy by manually judging the instances attached to 10 randomly sampled conceptual instances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995061159133911}]}, {"text": "The accuracy for part-of is 84% and for causation it is 76.6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997791647911072}]}], "tableCaptions": [{"text": " Table 2. System precision, recall and F-score on  the causation relation.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9891229271888733}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9997244477272034}, {"text": "F-score", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.9988976716995239}]}, {"text": " Table 1. System precision, recall and F-score on  the part-of relation.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9860801100730896}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9997507929801941}, {"text": "F-score", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.9989780187606812}]}]}