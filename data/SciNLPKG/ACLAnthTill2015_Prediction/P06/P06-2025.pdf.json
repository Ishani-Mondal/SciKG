{"title": [{"text": "A Modified Joint Source-Channel Model for Transliteration", "labels": [], "entities": [{"text": "Transliteration", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.8400676250457764}]}], "abstractContent": [{"text": "Most machine transliteration systems transliterate out of vocabulary (OOV) words through intermediate phonemic mapping.", "labels": [], "entities": []}, {"text": "A framework has been presented that allows direct orthographical mapping between two languages that are of different origins employing different alphabet sets.", "labels": [], "entities": []}, {"text": "A modified joint source-channel model along with a number of alternatives have been proposed.", "labels": [], "entities": []}, {"text": "Aligned transliteration units along with their context are automatically derived from a bilingual training corpus to generate the collocational statistics.", "labels": [], "entities": []}, {"text": "The transliteration units in Bengali words take the pattern C + M where C represents a vowel or a consonant or a conjunct and M represents the vowel modifier or matra.", "labels": [], "entities": []}, {"text": "The English transliteration units are of the form C*V* where C represents a consonant and V represents a vowel.", "labels": [], "entities": []}, {"text": "A Bengali-English machine transliteration system has been developed based on the proposed models.", "labels": [], "entities": []}, {"text": "The system has been trained to transliterate person names from Bengali to English.", "labels": [], "entities": []}, {"text": "It uses the linguistic knowledge of possible conjuncts and diphthongs in Bengali and their equivalents in English.", "labels": [], "entities": []}, {"text": "The system has been evaluated and it has been observed that the modified joint source-channel model performs best with a Word Agreement Ratio of 69.3% and a Transliteration Unit Agreement Ratio of 89.8%.", "labels": [], "entities": [{"text": "Word Agreement Ratio", "start_pos": 121, "end_pos": 141, "type": "METRIC", "confidence": 0.6631689170996348}]}], "introductionContent": [{"text": "In Natural Language Processing (NLP) application areas such as information retrieval, question answering systems and machine translation, there is an increasing need to translate OOV words from one language to another.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.767051100730896}, {"text": "question answering", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8290015757083893}, {"text": "machine translation", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7842919528484344}]}, {"text": "They are translated through transliteration, the method of translating into another language by expressing the original foreign words using characters of the target language preserving the pronunciation in their original languages.", "labels": [], "entities": []}, {"text": "Thus, the central problem in transliteration is predicting the pronunciation of the original word.", "labels": [], "entities": [{"text": "predicting the pronunciation of the original word", "start_pos": 48, "end_pos": 97, "type": "TASK", "confidence": 0.8848551426615033}]}, {"text": "Transliteration between two languages, that use the same set of alphabets, is trivial: the word is left as it is.", "labels": [], "entities": []}, {"text": "However, for languages that use different alphabet sets, the names must be transliterated or rendered in the target language alphabets.", "labels": [], "entities": []}, {"text": "Technical terms and named entities makeup the bulk of these OOV words.", "labels": [], "entities": []}, {"text": "Named entities hold a very important place in NLP applications.", "labels": [], "entities": []}, {"text": "Proper identification, classification and translation of named entities are very crucial in many NLP applications and pose a very big challenge to NLP researchers.", "labels": [], "entities": [{"text": "translation of named entities", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.8572477549314499}]}, {"text": "Named entities are usually not found in bilingual dictionaries and they are very productive in nature.", "labels": [], "entities": []}, {"text": "Translation of named entities is a tricky task: it involves both translation and transliteration.", "labels": [], "entities": [{"text": "Translation of named entities", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9054030179977417}]}, {"text": "Transliteration is commonly used for named entities, even when the words could be translated.", "labels": [], "entities": []}, {"text": "Different types of named entities are translated differently.", "labels": [], "entities": []}, {"text": "Numerical and temporal expressions typically use a limited set of vocabulary words (e.g., names of months, days of the week etc.) and can be translated fairly easily using simple translation patterns.", "labels": [], "entities": []}, {"text": "The named entity machine transliteration algorithms presented in this work focus on person names, locations and organizations.", "labels": [], "entities": [{"text": "named entity machine transliteration", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.6187918111681938}]}, {"text": "A machine transliteration system that is trained on person names is very important in a multilingual country like India where large name collections like census data, electoral roll and railway reservation information must be available to multilingual citizens of the country in their vernacular.", "labels": [], "entities": []}, {"text": "In the present work, the various proposed models have been evaluated on a training corpus of person names.", "labels": [], "entities": []}, {"text": "A hybrid neural network and knowledge-based system to generate multiple English spellings for Arabic personal names is described in.) developed a phoneme-based statistical model using finite state transducer that implements transformation rules to do back-transliteration.) adapted this approach for back transliteration from Arabic to English for English names.", "labels": [], "entities": []}, {"text": "A spelling-based model is described in) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations.", "labels": [], "entities": []}, {"text": "The phonetics-based and spelling-based models have been linearly combined into a single transliteration model in) for transliteration of Arabic named entities into English.", "labels": [], "entities": [{"text": "transliteration of Arabic named entities into English", "start_pos": 118, "end_pos": 171, "type": "TASK", "confidence": 0.8716896772384644}]}, {"text": "Several phoneme-based techniques have been proposed in the recent past for machine transliteration using transformation-based learning algorithm (.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.6944817304611206}]}, {"text": "( have presented a simple statistical technique to train an EnglishArabic transliteration model from pairs of names.", "labels": [], "entities": []}, {"text": "The two-stage training procedure first learns which n-gram segments should be added to unigram inventory for the source language, and then a second stage learns the translation model over this inventory.", "labels": [], "entities": []}, {"text": "This technique requires no heuristic or linguistic knowledge of either language.", "labels": [], "entities": []}, {"text": "() described an EnglishJapanese transliteration method in which an English word is divided into conversion units that are partial English character strings in an English word and each English conversion unit is converted into a partial Japanese Katakana character string.", "labels": [], "entities": []}, {"text": "It calculates the likelihood of a particular choice of letters of chunking into English conversion units for an English word by linking them to Katakana characters using syllables.", "labels": [], "entities": []}, {"text": "Thus the English conversion units consider phonetic aspects.", "labels": [], "entities": []}, {"text": "It considers the English and Japanese contextual information simultaneously to calculate the plausibility of conversion from each English conversion unit to various Japanese conversion units using a single probability model based on the maximum entropy method.", "labels": [], "entities": []}, {"text": "() presented a framework that allows direct orthographical mapping between English and Chinese through a joint source-channel model, called n-gram transliteration model.", "labels": [], "entities": []}, {"text": "The orthographic alignment process is automated using the maximum likelihood approach, through the Expectation Maximization algorithm to derive aligned transliteration units from a bilingual dictionary.", "labels": [], "entities": [{"text": "orthographic alignment", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7437834143638611}, {"text": "Expectation Maximization", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.6624284237623215}]}, {"text": "The joint source-channel model tries to capture how source and target names can be generated simultaneously, i.e., the context information in both the source and the target sides are taken into account.", "labels": [], "entities": []}, {"text": "A tuple n-gram transliteration model) has been loglinearly combined with feature functions to develop a statistical machine translation system for Spanish-to-English and English-to-Spanish translation tasks.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.6016570031642914}, {"text": "English-to-Spanish translation tasks", "start_pos": 170, "end_pos": 206, "type": "TASK", "confidence": 0.755971630414327}]}, {"text": "The model approximates the joint probability between source and target languages by using trigrams.", "labels": [], "entities": []}, {"text": "The present work differs from () in the sense that identification of the transliteration units in the source language is done using regular expressions and no probabilistic model is used.", "labels": [], "entities": []}, {"text": "The proposed modified joint source-channel model is similar to the model proposed by) but it differs in the way the transliteration units and the contextual information are defined in the present work.", "labels": [], "entities": []}, {"text": "No linguistic knowledge is used in () whereas the present work uses linguistic knowledge in the form of possible conjuncts and diphthongs in Bengali.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "The machine transliteration problem has been formulated under both noisy-channel model and joint source-channel model in Section 2.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7276836931705475}]}, {"text": "A number of transliteration models based on collocation statistics including the modified joint source-channel model and their evaluation scheme have been proposed in Section 3.", "labels": [], "entities": []}, {"text": "The Bengali-English machine transliteration scenario has been presented in Section 4.", "labels": [], "entities": [{"text": "Bengali-English machine transliteration", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.577524334192276}]}, {"text": "The proposed models have been evaluated and the result of evaluation is reported in Section 5.", "labels": [], "entities": []}, {"text": "The conclusion is drawn in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Machine transliteration has been viewed as a sense disambiguation problem.", "labels": [], "entities": [{"text": "Machine transliteration", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7489883005619049}, {"text": "sense disambiguation", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7182887047529221}]}, {"text": "A number of transliteration models have been proposed that can generate the English transliteration from a Bengali word that is not registered in any bilingual or pronunciation dictionary.", "labels": [], "entities": []}, {"text": "The Bengali word is divided into Transliteration Units (TU) that have the pattern C + M, where C represents a vowel or a consonant or conjunct and M represents the vowel modifier or matra.", "labels": [], "entities": []}, {"text": "An English word is divided into TUs that have the pattern C*V*, where C represents a consonant and V represents a vowel.", "labels": [], "entities": []}, {"text": "The TUs are considered as the lexical units for machine transliteration.", "labels": [], "entities": []}, {"text": "The system considers the Bengali and English contextual information in the form of collocated TUs simultaneously to calculate the plausibility of transliteration from each Bengali TU to various English candidate TUs and chooses the one with maximum probability.", "labels": [], "entities": []}, {"text": "This is equivalent to choosing the most appropriate sense of a word in the source language to identify its representation in the target language.", "labels": [], "entities": []}, {"text": "The system learns the mappings automatically from the bilingual training corpus guided by linguistic features.", "labels": [], "entities": []}, {"text": "The output of this mapping process is a decision-list classifier with collocated TUs in the source language and their equivalent TUs in collocation in the target language along with the probability of each decision obtained from a training corpus.", "labels": [], "entities": []}, {"text": "The machine transliteration of the input Bengali word is obtained using direct orthographic mapping by identifying the equivalent English TU for each Bengali TU in the input and then placing the English TUs in order.", "labels": [], "entities": []}, {"text": "The various proposed models differ in the nature of collocational stastistics used during machine transliteration process: monogram model with no context, bigram model with previous (with respect to the current TU to be transliterated) source TU as the context, bigram model with next source TU as the context, bigram model with previous source and target TUs as the context (this is the joint source channel model), trigram model with previous and next source TUs as the context and the modified joint source-channel model with previous and next source TUs and the previous target TU as the context.", "labels": [], "entities": []}, {"text": "\u2022 Model A In this model, no context is considered in either the source or the target side.", "labels": [], "entities": []}, {"text": "This is essentially the monogram model.", "labels": [], "entities": []}, {"text": "K P(B,E) = \u03a0 P(<b,e> k ) k=1 \u2022 Model B This is essentially a bigram model with previous source TU, i.e., the source TU occurring to the left of the current TU to be transliterated, as the context.", "labels": [], "entities": []}, {"text": "K P(B,E) = \u03a0 P(<b,e> k | b k-1 ) k=1 \u2022Model C This is essentially a bigram model with next source TU, i.e., the source TU occurring to the right of the current TU to be transliterated, as the context.", "labels": [], "entities": []}, {"text": "K P(B,E) = \u041f P(<b,e> k \u2502 b k+1 ) k=1 \u2022 Model D This is essentially the joint source-channel model where the previous TUs in both the source and the target sides are considered as the context.", "labels": [], "entities": []}, {"text": "The previous TU on the target side refers to the transliterated TU to the immediate left of the current target TU to be transliterated.", "labels": [], "entities": []}, {"text": "K P(B,E) = \u03a0 P( <b,e> k \ud97b\udf59 \ud97b\udf59 | <b,e> k-1 ) k=1 \u2022 Model E This is basically the trigram model where the previous and the next source TUs are considered as the context K P(B,E) = \u03a0 P(<b,e> k | b k-1, b k+1 ) k=1 \u2022 Model F In this model, the previous and the next TUs in the source and the previous target TU are considered as the context.", "labels": [], "entities": []}, {"text": "This is the modified joint source-channel model . The performance of the system is evaluated in terms of Transliteration Unit Agreement Ratio (TUAR) and Word Agreement Ratio (WAR) following the evaluation scheme in ().", "labels": [], "entities": [{"text": "Transliteration Unit Agreement Ratio (TUAR)", "start_pos": 105, "end_pos": 148, "type": "METRIC", "confidence": 0.7429049270493644}, {"text": "Word Agreement Ratio (WAR)", "start_pos": 153, "end_pos": 179, "type": "METRIC", "confidence": 0.7824603368838629}]}, {"text": "The evaluation parameter Character Agreement Ratio in () has been modified to Transliteration Unit Agreement Ratio as vowel modifier matra symbols in Bengali words are not independent and must always follow a consonant or a conjunct in a Transliteration Unit.", "labels": [], "entities": []}, {"text": "Let, B be the input Bengali word, E be the English transliteration given by the user in open test and E / be the system generates the transliteration.", "labels": [], "entities": []}, {"text": "TUAR is defined as, TUAR = (L-Err)/ L, where L is the number of TUs in E, and Err is the number of wrongly transliterated TUs in E / generated by the system.", "labels": [], "entities": [{"text": "TUAR", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.981319785118103}, {"text": "Err", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9664844870567322}]}, {"text": "WAR is defined as, WAR= (S-Err / ) / S, where S is the test sample size and Err / is is the number of erroneous names generated by the system (when E / does not match with E).", "labels": [], "entities": [{"text": "WAR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6687242388725281}, {"text": "WAR", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.8797653913497925}, {"text": "Err", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9702694416046143}]}, {"text": "Each of these models has been evaluated with linguistic knowledge of the set of possible conjuncts and diphthongs in Bengali and their equivalents in English.", "labels": [], "entities": []}, {"text": "It has been observed that the Modified Joint Source Channel Model with linguistic knowledge performs best in terms of Word Agreement Ratio and Transliteration Unit Agreement Ratio.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2.  The modified joint source-channel model (Model  F) that incorporates linguistic knowledge  performs best among all the models with a Word  Agreement Ratio (WAR) of 69.3% and a  Transliteration Unit Agreement Ratio (TUAR) of  89.8%. The joint source-channel model with  linguistic knowledge (Model D) has not  performed well in the Bengali-English machine  transliteration whereas the trigram model (Model  E) needs further attention as its result are  comparable to the modified joint source-channel", "labels": [], "entities": [{"text": "Word  Agreement Ratio (WAR)", "start_pos": 144, "end_pos": 171, "type": "METRIC", "confidence": 0.883468916018804}, {"text": "Transliteration Unit Agreement Ratio (TUAR)", "start_pos": 188, "end_pos": 231, "type": "METRIC", "confidence": 0.7676226709570203}]}, {"text": " Table 1: Value of Err and Err / for each model  (B2E transliteration)", "labels": [], "entities": [{"text": "Err", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9165880084037781}, {"text": "Err", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9796182513237}]}, {"text": " Table 2: Results with Evaluation Metrics  (B2E transliteration)", "labels": [], "entities": []}, {"text": " Table 3: Results with Evaluation Metrics  (E2B transliteration)", "labels": [], "entities": []}]}