{"title": [], "abstractContent": [{"text": "Recently proposed deterministic classifier-based parsers (Nivre and Scholz, 2004; Sagae and Lavie, 2005; Yamada and Mat-sumoto, 2003) offer attractive alternatives to generative statistical parsers.", "labels": [], "entities": [{"text": "generative statistical parsers", "start_pos": 167, "end_pos": 197, "type": "TASK", "confidence": 0.9065783023834229}]}, {"text": "Determin-istic parsers are fast, efficient, and simple to implement, but generally less accurate than optimal (or nearly optimal) statistical parsers.", "labels": [], "entities": [{"text": "Determin-istic parsers", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6510358154773712}]}, {"text": "We present a statistical shift-reduce parser that bridges the gap between deterministic and probabilis-tic parsers.", "labels": [], "entities": []}, {"text": "The parsing model is essentially the same as one previously used for deterministic parsing, but the parser performs a best-first search instead of a greedy search.", "labels": [], "entities": [{"text": "deterministic parsing", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.6272889375686646}]}, {"text": "Using the standard sections of the WSJ corpus of the Penn Tree-bank for training and testing, our parser has 88.1% precision and 87.8% recall (us-ing automatically assigned part-of-speech tags).", "labels": [], "entities": [{"text": "WSJ corpus of the Penn Tree-bank", "start_pos": 35, "end_pos": 67, "type": "DATASET", "confidence": 0.9320410291353861}, {"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9983733892440796}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9994009733200073}]}, {"text": "Perhaps more interestingly, the parsing model is significantly different from the generative models used by other well-known accurate parsers, allowing fora simple combination that produces precision and recall of 90.9% and 90.7%, respectively .", "labels": [], "entities": [{"text": "parsing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9783201217651367}, {"text": "precision", "start_pos": 190, "end_pos": 199, "type": "METRIC", "confidence": 0.9996108412742615}, {"text": "recall", "start_pos": 204, "end_pos": 210, "type": "METRIC", "confidence": 0.9991986155509949}]}], "introductionContent": [{"text": "Over the past decade, researchers have developed several constituent parsers trained on annotated data that achieve high levels of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9957414865493774}]}, {"text": "Some of the more popular and more accurate of these approaches to data-driven parsing) have been based on generative models that are closely related to probabilistic contextfree grammars.", "labels": [], "entities": []}, {"text": "Recently, classifier-based dependency parsing ( has showed that deterministic parsers are capable of high levels of accuracy, despite great simplicity.", "labels": [], "entities": [{"text": "classifier-based dependency parsing", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7345160841941833}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9976319074630737}]}, {"text": "This work has led to the development of deterministic parsers for constituent structures as well).", "labels": [], "entities": []}, {"text": "However, evaluations on the widely used WSJ corpus of the Penn Treebank ( show that the accuracy of these parsers still lags behind the state-of-theart.", "labels": [], "entities": [{"text": "WSJ corpus of the Penn Treebank", "start_pos": 40, "end_pos": 71, "type": "DATASET", "confidence": 0.9398397902647654}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9993749260902405}]}, {"text": "A reasonable and commonly held assumption is that the accuracy of deterministic classifier-based parsers can be improved if determinism is abandoned in favor of a search over a larger space of possible parses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9989257454872131}]}, {"text": "While this assumption was shown to be true for the parser of, only a moderate improvement resulted from the addition of a non-greedy search strategy, and overall parser accuracy was still well below that of state-of-the-art statistical parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.994897186756134}]}, {"text": "We present a statistical parser that is based on a shift-reduce algorithm, like the parsers of Sagae and and, but performs a best-first search instead of pursuing a single analysis path in deterministic fashion.", "labels": [], "entities": []}, {"text": "The parser retains much of the simplicity of deterministic classifier-based parsers, but achieves results that are closer inaccuracy to state-of-the-art statistical parsers.", "labels": [], "entities": []}, {"text": "Furthermore, a simple combination of the shift-reduce parsing model with an existing generative parsing model produces results with accuracy that surpasses any that of any single (nonreranked) parser tested on the WSJ Penn Treebank, and comes close to the best results obtained with discriminative reranking).", "labels": [], "entities": [{"text": "generative parsing", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8337014615535736}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9990772008895874}, {"text": "WSJ Penn Treebank", "start_pos": 214, "end_pos": 231, "type": "DATASET", "confidence": 0.9476704796155294}]}], "datasetContent": [{"text": "We evaluated our classifier-based best-first parser on the Wall Street Journal corpus of the Penn Treebank () using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.", "labels": [], "entities": [{"text": "Wall Street Journal corpus of the Penn Treebank", "start_pos": 59, "end_pos": 106, "type": "DATASET", "confidence": 0.9566296637058258}]}, {"text": "Every experiment reported here was performed on a Pentium4 3.2GHz with 2GB of RAM.", "labels": [], "entities": []}, {"text": "Each tree in the training set had empty-node and function tag information removed, and the trees were lexicalized using the same head-table rules as in the Collins (1999) parser (these rules were taken from Bikel's (2002) implementation of the Collins parser).", "labels": [], "entities": []}, {"text": "The trees were then converted into trees containing only unary and binary productions, using the binarization transform described in section 2.", "labels": [], "entities": []}, {"text": "Classifier training instances of features paired with classes (parser actions) were extracted from the trees in the training set, and the total number of training instances was about 1.9 million.", "labels": [], "entities": []}, {"text": "It is interesting to note that the procedure of training the best-first parser is identical to the training of a deterministic version of the parser: the deterministic Let: S(n) denote the nth item from the top of the stack S, and W (n) denote the nth item from the front of the queue W . Features: 1.", "labels": [], "entities": []}, {"text": "The head-word (and its POS tag) of: S(0), S(1), S(2), andS 2.", "labels": [], "entities": []}, {"text": "The head-word (and its POS tag) of: W (0), W (1), W (2) and W 3.", "labels": [], "entities": []}, {"text": "The non-terminal node of the root of: S(0), and S 4.", "labels": [], "entities": []}, {"text": "The non-terminal node of the left child of the root of: S(0), and S 5.", "labels": [], "entities": []}, {"text": "The non-terminal node of the right child of the root of: S(0), and S 6.", "labels": [], "entities": []}, {"text": "The POS tag of the head-word of the left child of the root of: S(0), and S(1)", "labels": [], "entities": [{"text": "POS", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8548629879951477}]}], "tableCaptions": [{"text": " Table 1: Summary of results on labeled precision and recall of constituents, and time required to parse  the test set. We first show results for the parsers described here, then for four of the most accurate or  most widely known parsers, for the Ratnaparkhi maximum entropy parser, and finally for three recent  classifier-based parsers. For the purposes of direct comparisons, only results obtained with automatically  assigned part-of-speech tags are shown (tags are assigned by the parser itself or by a separate part-of- speech tagger). * Times reported by authors running on different hardware.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9411726593971252}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9864757657051086}, {"text": "Ratnaparkhi maximum entropy parser", "start_pos": 248, "end_pos": 282, "type": "TASK", "confidence": 0.7027607411146164}]}]}