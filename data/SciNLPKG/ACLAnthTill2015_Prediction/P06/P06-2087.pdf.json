{"title": [{"text": "Argumentative Feedback: A Linguistically-motivated Term Expansion for Information Retrieval", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.7682867646217346}]}], "abstractContent": [{"text": "We report on the development of anew automatic feedback model to improve information retrieval in digital libraries.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.7310207784175873}]}, {"text": "Our hypothesis is that some particular sentences, selected based on argumentative criteria, can be more useful than others to perform well-known feedback information retrieval tasks.", "labels": [], "entities": [{"text": "feedback information retrieval tasks", "start_pos": 145, "end_pos": 181, "type": "TASK", "confidence": 0.7236583679914474}]}, {"text": "The argumentative model we explore is based on four disjunct classes, which has been very regularly observed in scientific reports: PURPOSE, METHODS, RESULTS , CONCLUSION.", "labels": [], "entities": [{"text": "PURPOSE", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.990385890007019}, {"text": "METHODS", "start_pos": 141, "end_pos": 148, "type": "METRIC", "confidence": 0.9812747836112976}, {"text": "RESULTS", "start_pos": 150, "end_pos": 157, "type": "METRIC", "confidence": 0.9905964136123657}]}, {"text": "To test this hypothesis , we use the Rocchio algorithm as baseline.", "labels": [], "entities": []}, {"text": "While Rocchio selects the features to be added to the original query based on statistical evidence, we propose to base our feature selection also on argumentative criteria.", "labels": [], "entities": []}, {"text": "Thus, we restrict the expansion on features appearing only in sentences classified into one of our argumentative categories.", "labels": [], "entities": []}, {"text": "Our results, obtained on the OHSUMED collection, show a significant improvement when expansion is based on PURPOSE (mean average precision = +23%) and CONCLUSION (mean average precision = +41%) contents rather than on other argumentative contents.", "labels": [], "entities": [{"text": "OHSUMED collection", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.9523143768310547}, {"text": "PURPOSE (mean average precision", "start_pos": 107, "end_pos": 138, "type": "METRIC", "confidence": 0.7029821455478669}, {"text": "CONCLUSION (mean average precision", "start_pos": 151, "end_pos": 185, "type": "METRIC", "confidence": 0.8055962085723877}]}, {"text": "These results suggest that argumentation is an important linguistic dimension that could benefit information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.728609710931778}]}], "introductionContent": [{"text": "Information retrieval (IR) is a challenging endeavor due to problems caused by the underlying expressiveness of all natural languages.", "labels": [], "entities": [{"text": "Information retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8778287231922149}]}, {"text": "One of these problems, synonymy, is that authors and users frequently employ different words or expressions to refer to the same meaning (accident maybe expressed as event, incident, problem, difficulty, unfortunate situation, the subject of your last letter, what happened last week, etc.)", "labels": [], "entities": []}, {"text": "(. Another problem is ambiguity, where a specific term may have several (and sometimes contradictory) meanings and interpretations (e.g., the word horse as in Trojan horse, light horse, to work like a horse, horse about).", "labels": [], "entities": []}, {"text": "In order to obtain better meaning-based matches between queries and documents, various propositions have been suggested, usually without giving any consideration to the underlying domain.", "labels": [], "entities": []}, {"text": "During our participation in different international evaluation campaigns such as the TREC Genomics track, the BioCreative initiative (), as well as in our attempts to deliver advanced search tools for biologists ) and healthcare providers), we were more concerned with domain-specific information retrieval in which systems must return a ranked list of MEDLINE records in response to an expert's information request.", "labels": [], "entities": [{"text": "TREC Genomics track", "start_pos": 85, "end_pos": 104, "type": "DATASET", "confidence": 0.7998649875322977}, {"text": "domain-specific information retrieval", "start_pos": 269, "end_pos": 306, "type": "TASK", "confidence": 0.66971355676651}]}, {"text": "This involved a set of available queries describing typical search interests, in which gene, protein names, and diseases were often essential for an effective retrieval.", "labels": [], "entities": []}, {"text": "Biomedical publications however tend to generate new information very rapidly and also use a wide variation in terminology, thus leading to the current situation whereby a large number of names, symbols and synonyms are used to denote the same concepts.", "labels": [], "entities": []}, {"text": "Current solutions to these issues can be classified into domain-specific strategies, such as thesaurus-based expansion, and domain-independent strategies, such as blindfeedback.", "labels": [], "entities": []}, {"text": "By proposing to explore a third type of approach, which attempts to take advantage of argumentative specificities of scientific reports, our study initiates anew research direction for natural language processing applied to information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 224, "end_pos": 245, "type": "TASK", "confidence": 0.7764991223812103}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents some related work in information retrieval and in argumentative parsing, while Section 3 depicts the main characteristics of our test collection and the metrics used in our experiments.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7951602041721344}, {"text": "argumentative parsing", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7899215221405029}]}, {"text": "Section 4 details the strategy used to develop our improved feedback method.", "labels": [], "entities": []}, {"text": "Section 5 reports on results obtained by varying our model and Section 6 contains conclusions on our experiments.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 5: Results without feedback, with Roc- chio and with argumentative feedback applied  on PURPOSE and CONCLUSION sentences.  The number of relevant document for all queries  is 1178.", "labels": [], "entities": [{"text": "Roc", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9289820790290833}, {"text": "PURPOSE", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.8081504106521606}]}]}