{"title": [{"text": "Analysis of Selective Strategies to Build a Dependency-Analyzed Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper discusses sampling strategies for building a dependency-analyzed corpus and analyzes them with different kinds of corpora.", "labels": [], "entities": []}, {"text": "We used the Kyoto Text Corpus, a dependency-analyzed corpus of newspaper articles, and prepared the IPAL corpus, a dependency-analyzed corpus of example sentences in dictionaries, as anew and different kind of corpus.", "labels": [], "entities": [{"text": "Kyoto Text Corpus", "start_pos": 12, "end_pos": 29, "type": "DATASET", "confidence": 0.9747180938720703}, {"text": "IPAL corpus", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.8296858072280884}]}, {"text": "The experimental results revealed that the length of the test set controlled the accuracy and that the longest-first strategy was good for an expanding corpus, but this was not the case when constructing a corpus from scratch.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9995256662368774}]}], "introductionContent": [{"text": "Dependency-structure analysis plays a very important role in natural language processing (NLP).", "labels": [], "entities": [{"text": "Dependency-structure analysis", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8212736546993256}, {"text": "natural language processing (NLP)", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.7888736228148142}]}, {"text": "Thus, so far, much research has been done on this subject, with many analyzers being developed such as rule-based analyzers and corpus-based analyzers that use machine-learning techniques.", "labels": [], "entities": []}, {"text": "However, the maximum accuracy achieved by state-of-the art analyzers is almost 90% for newspaper articles; it seems very difficult to exceed this figure of 90%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9995895028114319}]}, {"text": "To improve our analyzers, we have to write more rules for rule-based analyzers or prepare more corpora for corpus-based analyzers.", "labels": [], "entities": []}, {"text": "If we take a machine-learning approach, it is important to consider what features are used.", "labels": [], "entities": []}, {"text": "However, there are several machine-learning techniques, such as support vector machines (SVMs) with a kernel function, that have strong generalization ability and are very robust for choosing the right features.", "labels": [], "entities": []}, {"text": "If we use such machine-learning techniques, we will be free from choosing a feature set because it will be possible to use all possible features with little or no decline in performance.", "labels": [], "entities": []}, {"text": "Actually, Sasano tried to expand the feature set fora Japanese dependency analyzer using SVMs in, with a small improvement inaccuracy.", "labels": [], "entities": [{"text": "dependency analyzer", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.6188440322875977}]}, {"text": "To write rules fora rule-based analyzer, and to produce an analyzer using machine-learning techniques, it is crucial to construct a dependencyanalyzed corpus.", "labels": [], "entities": []}, {"text": "Such a corpus is very useful not only for constructing a dependency analyzer but also for other natural language processing applications.", "labels": [], "entities": [{"text": "dependency analyzer", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7574829161167145}]}, {"text": "However, building this kind of resource is very expensive and labor-intensive because it is difficult to annotate a large amount of dependencyanalyzed corpus in short time.", "labels": [], "entities": []}, {"text": "At present, one promising approach to mitigating the annotation bottleneck problem is to use selective sampling, a variant of active learning).", "labels": [], "entities": []}, {"text": "In general, selective sampling is an interactive learning method in which the machine takes the initiative in selecting unlabeled data for the human to annotate.", "labels": [], "entities": [{"text": "selective sampling", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.6864508986473083}]}, {"text": "Under this framework, the system has access to a large pool of unlabeled data, and it has to predict how much it can learn from each candidate in the pool if that candidate is labeled.", "labels": [], "entities": []}, {"text": "Most of the experiments that had been carried out in the previous works for selective sampling used an annotated corpus in a limited domain.", "labels": [], "entities": [{"text": "selective sampling", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7633115947246552}]}, {"text": "The most typical corpus is WSJ of Penn Treebank.", "labels": [], "entities": [{"text": "WSJ of Penn Treebank", "start_pos": 27, "end_pos": 47, "type": "DATASET", "confidence": 0.8831634819507599}]}, {"text": "The reason why the domain was so limited is very simple; corpus annotation is very expensive.", "labels": [], "entities": []}, {"text": "However, we want to know the effects of selective sampling for corpora in various domains because a dependency analyzer constructed from a corpus does not always analyze a text in limited domain.", "labels": [], "entities": []}, {"text": "On the other hand, there is no clear guideline nor development strategy for constructing a dependency-analyzed corpus to produce a highly accurate dependency analyzer.", "labels": [], "entities": []}, {"text": "Thus in this paper, we discuss fundamental sampling strategies fora dependency-analyzed corpus for corpus-based dependency analyzers with several types of corpora.", "labels": [], "entities": []}, {"text": "This paper unveils the essential characteristics of basic sampling strategies fora dependencyanalyzed corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out several experiments to determine the basic characteristics of several selective strategies fora Japanese dependency-analyzed corpus.", "labels": [], "entities": [{"text": "Japanese dependency-analyzed corpus", "start_pos": 111, "end_pos": 146, "type": "DATASET", "confidence": 0.6734097401301066}]}, {"text": "First, we briefly introduce Japanese dependency structure.", "labels": [], "entities": [{"text": "Japanese dependency structure", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.5809755822022756}]}, {"text": "Second, we carryout basic experiments with our dependency-analyzed corpora and analyze the errors.", "labels": [], "entities": []}, {"text": "Finally, we conduct simulations to ascertain the fundamental characteristics of these strategies.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 shows the details of the Kyoto Text Cor- pus.", "labels": [], "entities": [{"text": "Kyoto Text Cor- pus", "start_pos": 34, "end_pos": 53, "type": "DATASET", "confidence": 0.9671503782272339}]}, {"text": " Table 3: Results of cross-validation tests", "labels": [], "entities": []}, {"text": " Table 4: Modifier POS sequences of mis-analyzed  dependencies and their frequencies in the cross- validation test (top 10)", "labels": [], "entities": []}, {"text": " Table 5: Frequencies of dependency distances at  error and correct cases in the cross-validation test  (top 10)", "labels": [], "entities": []}, {"text": " Table 7: Analyzed results of K-mag (which is  different domain and has long average sentence  length) with these learning corpora", "labels": [], "entities": []}, {"text": " Table 8: Analyzed results of IPAL0 (which is  different domain and has short average sentence  length) with these learning corpora", "labels": [], "entities": []}, {"text": " Table 10: Results of initial situation experiment", "labels": [], "entities": []}]}