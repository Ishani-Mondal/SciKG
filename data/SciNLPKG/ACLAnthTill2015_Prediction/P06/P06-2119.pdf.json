{"title": [{"text": "Word Sense Disambiguation using lexical cohesion in the context", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7486331562201182}]}], "abstractContent": [{"text": "This paper designs a novel lexical hub to disambiguate word sense, using both syn-tagmatic and paradigmatic relations of words.", "labels": [], "entities": []}, {"text": "It only employs the semantic network of WordNet to calculate word similarity , and the Edinburgh Association Thesaurus (EAT) to transform contextual space for computing syntagmatic and other domain relations with the target word.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9417692422866821}, {"text": "Edinburgh Association Thesaurus (EAT)", "start_pos": 87, "end_pos": 124, "type": "DATASET", "confidence": 0.8131506443023682}]}, {"text": "Without any back-off policy the result on the English lexical sample of SENSEVAL-2 1 shows that lexical cohesion based on edge-counting techniques is a good way of unsupervisedly disam-biguating senses.", "labels": [], "entities": [{"text": "English lexical sample of SENSEVAL-2 1", "start_pos": 46, "end_pos": 84, "type": "DATASET", "confidence": 0.9006540377934774}]}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is generally taken as an intermediate task like part-of-speech (POS) tagging in natural language processing, but it has not so far achieved the sufficient precision for application as POS tagging (for the history of WSD, cf.).", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7710583557685217}, {"text": "part-of-speech (POS) tagging", "start_pos": 80, "end_pos": 108, "type": "TASK", "confidence": 0.7182693004608154}, {"text": "precision", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.998185932636261}, {"text": "POS tagging", "start_pos": 216, "end_pos": 227, "type": "TASK", "confidence": 0.7112036943435669}]}, {"text": "It is partly due to the nature of its complexity and difficulty, and to the widespread disagreement and controversy on its necessity in language engineering, and to the representation of the senses of words, as well as to the validity of its evaluation).", "labels": [], "entities": []}, {"text": "However the endeavour to automatically achieve WSD has been continuous since the earliest work of the 1950's.", "labels": [], "entities": [{"text": "WSD", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.8519920706748962}]}, {"text": "In this paper we specifically investigate the role of semantic hierarchies of lexical knowledge on WSD, using datasets and evaluation methods from SENSEVAL ( http://www.senseval.org/ 2000) as these are well known and accepted in the community of computational linguistics.", "labels": [], "entities": [{"text": "WSD", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9321165680885315}]}, {"text": "With respect to whether or not they employ the training materials provided, SENSEVAL roughly categorizes the participating systems into \"unsupervised systems\" and \"supervised systems\".", "labels": [], "entities": [{"text": "SENSEVAL", "start_pos": 76, "end_pos": 84, "type": "TASK", "confidence": 0.8938185572624207}]}, {"text": "Those that don't use the training data are not usually truly unsupervised, being based on lexical knowledge bases such as dictionaries, thesauri or semantic nets to discriminate word senses; conversely the \"supervised\" systems learn from corpora marked up with word senses.", "labels": [], "entities": []}, {"text": "The fundamental assumption, in our \"unsupervised\" technique for WSD in this paper, is that the similarity of contextual features of the target with the pre-defined features of its sense in the lexical knowledge base provides a quantitative cue for identifying the true sense of the target.", "labels": [], "entities": [{"text": "WSD", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9669991135597229}]}, {"text": "The lexical ambiguity of polysemy and homonymy, whose distinction is however not absolute as sometimes the senses of word maybe intermediate, is the main object of WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 164, "end_pos": 167, "type": "TASK", "confidence": 0.7571456432342529}]}, {"text": "Verbs, with their more flexible roles in a sentence, tend to be more polysemous than nouns, so worsening the computational feasibility.", "labels": [], "entities": []}, {"text": "In this paper we disambiguated the sense of a word after its POS tagging has assigned them either a noun or a verb tag.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.6376371085643768}]}, {"text": "Furthermore, we deal with nouns and verbs separately.", "labels": [], "entities": []}, {"text": "2 Some previous work on WSD using semantic similarity utilized the semantic network of nouns in WordNet to disambiguate term senses to improve the precision of SMART information retrieval at the stage of indexing, in which he assigned two different weights for both directions of edges in the network to compute the similarity of two nodes.", "labels": [], "entities": [{"text": "WSD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9696314930915833}, {"text": "WordNet", "start_pos": 96, "end_pos": 103, "type": "DATASET", "confidence": 0.9625621438026428}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9990823268890381}, {"text": "SMART information retrieval", "start_pos": 160, "end_pos": 187, "type": "TASK", "confidence": 0.9102157155672709}]}, {"text": "He then exploited the moving fixed size window to minimize the sum of all combinations of the shortest distances among target and context words.", "labels": [], "entities": []}, {"text": "extended Lesk's definition method (1986) to discriminate word sense through the definitions of both target and its IS-A relatives, and achieved a better result in the English lexical sample task of SENSEVAL-2, compared with other edge-counting or statistical estimation metrics on WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 281, "end_pos": 288, "type": "DATASET", "confidence": 0.9690460562705994}]}, {"text": "Humans carefully select words in a sentence to express harmony or cohesion in order to ease the ambiguity of the sentence.", "labels": [], "entities": []}, {"text": "argued that cohesive chains unite text structure together through reiteration of reference and lexical semantic relations (superordinate and subordinate).", "labels": [], "entities": []}, {"text": "suggested building lexical chains is important in the resolution of lexical ambiguity and the determination of coherence and discourse structure.", "labels": [], "entities": [{"text": "resolution of lexical ambiguity", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.7902429699897766}]}, {"text": "They argued that lexical chains, which cover the multiple semantic relations (systematic and nonsystematic), can transform the context setting into the computational one to narrow down the specific meaning of the target, manually realizing this with the help of Roget's Thesaurus.", "labels": [], "entities": []}, {"text": "They defined a lexical chain within Roget's very general hierarchy, in which lexical relationships are traced through a common category.", "labels": [], "entities": []}, {"text": "Hirst and St-Onge (1997) define a lexical chain using the syn/antonym and hyper/hyponym links of WordNet to detect and correct malapropisms in context, in which they specified three different weights from extra-strong to medium strong to score word similarity to decide the inserting sequence in the lexical chain.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.9541282653808594}]}, {"text": "They first computationally employed WordNet to form a \"greedy\" lexical chain as a substitute of the context to solve the matter of malapropism, where the word sense is decided by its preceding words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.933620274066925}]}, {"text": "Around the same time, realized a \"non-greedy\" lexical chain, which determined the word sense after processing of all words, in the context of text summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.6073242872953415}]}, {"text": "In this paper we propose an improved lexical chain, the lexical hub, that holds the target to be disambiguated as the centre, replacing the usual chain topology used in text summarization and cohesion analysis.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.6677634418010712}, {"text": "cohesion analysis", "start_pos": 192, "end_pos": 209, "type": "TASK", "confidence": 0.7530963718891144}]}, {"text": "In contrast with previous methods we only record the lexical hub of each sense of the target, and we don't keep track of other context words.", "labels": [], "entities": []}, {"text": "In other words, after the computation of lexical hub of the target, we can immediately produce the right sense of the target even though the senses of the context words are still in question.", "labels": [], "entities": []}, {"text": "We also transform the context surroundings through a word association thesaurus to explore the effect of other semantic relationships such as syntagmatic relation against WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 171, "end_pos": 174, "type": "TASK", "confidence": 0.6097169518470764}]}], "datasetContent": [], "tableCaptions": []}