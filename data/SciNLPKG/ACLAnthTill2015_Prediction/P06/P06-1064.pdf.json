{"title": [{"text": "Creating a CCGbank and a wide-coverage CCG lexicon for German", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an algorithm which creates a German CCGbank by translating the syntax graphs in the German Tiger corpus into CCG derivation trees.", "labels": [], "entities": [{"text": "German CCGbank", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.8923843801021576}, {"text": "German Tiger corpus", "start_pos": 95, "end_pos": 114, "type": "DATASET", "confidence": 0.9282252788543701}]}, {"text": "The resulting corpus contains 46,628 derivations, covering 95% of all complete sentences in Tiger.", "labels": [], "entities": []}, {"text": "Lexicons extracted from this corpus contain correct lexical entries for 94% of all known tokens in unseen text.", "labels": [], "entities": []}], "introductionContent": [{"text": "A number of wide-coverage TAG, CCG, LFG and HPSG grammars) have been extracted from the Penn Treebank (, and have enabled the creation of widecoverage parsers for English which recover local and non-local dependencies that approximate the underlying predicate-argument structure).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 88, "end_pos": 101, "type": "DATASET", "confidence": 0.9956610202789307}]}, {"text": "However, many corpora () use dependency graphs or other representations, and the extraction algorithms that have been developed for Penn Treebank style corpora may not be immediately applicable to this representation.", "labels": [], "entities": [{"text": "Penn Treebank style corpora", "start_pos": 132, "end_pos": 159, "type": "DATASET", "confidence": 0.937604621052742}]}, {"text": "As a consequence, research on statistical parsing with \"deep\" grammars has largely been confined to English.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8184842467308044}]}, {"text": "Free-word order languages typically pose greater challenges for syntactic theories, and the richer inflectional morphology of these languages creates additional problems both for the coverage of lexicalized formalisms such as CCG or TAG, and for the usefulness of dependency counts extracted from the training data.", "labels": [], "entities": []}, {"text": "On the other hand, formalisms such as CCG and TAG are particularly suited to capture the crossing dependencies that arise in languages such as Dutch or German, and by choosing an appropriate linguistic representation, some of these problems maybe mitigated.", "labels": [], "entities": [{"text": "TAG", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.7103469371795654}]}, {"text": "Here, we present an algorithm which translates the German Tiger corpus () into CCG derivations.", "labels": [], "entities": [{"text": "German Tiger corpus", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.9698776404062907}]}, {"text": "Similar algorithms have been developed by to create CCGbank, a corpus of CCG derivations) from the Penn Treebank, by C \u00b8 ak\u0131c\u0131 (2005) to extract a CCG lexicon from a Turkish dependency corpus, and by to induce a type-logical grammar for Dutch.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 99, "end_pos": 112, "type": "DATASET", "confidence": 0.9952267706394196}]}, {"text": "The annotation scheme used in Tiger is an extension of that used in the earlier, and smaller, German Negra corpus ().", "labels": [], "entities": [{"text": "Tiger", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.929865300655365}, {"text": "German Negra corpus", "start_pos": 94, "end_pos": 113, "type": "DATASET", "confidence": 0.8116775155067444}]}, {"text": "Tiger is better suited for the extraction of subcategorization information (and thus the translation into \"deep\" grammars of any kind), since it distinguishes between PP complements and modifiers, and includes \"secondary\" edges to indicate shared arguments in coordinate constructions.", "labels": [], "entities": []}, {"text": "Tiger also includes morphology and lemma information.", "labels": [], "entities": []}, {"text": "Negra is also provided with a \"Penn Treebank\"-style representation, which uses flat phrase structure trees instead of the crossing dependency structures in the original corpus.", "labels": [], "entities": [{"text": "Penn Treebank\"-", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.9642021258672079}]}, {"text": "This version has been used by  to extract a German LFG.", "labels": [], "entities": [{"text": "German LFG", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.7910931706428528}]}, {"text": "However, have demonstrated that lexicalization does not help a Collins-style parser that is trained on this corpus, and have shown that its context-free representation is a poor approximation to the underlying dependency structure.", "labels": [], "entities": []}, {"text": "The resource presented here will enable future research to address the question whether \"deep\" grammars such as CCG, which capture the underlying dependencies directly, are better suited to parsing German than linguistically inadequate context-free approximations.", "labels": [], "entities": []}], "datasetContent": [{"text": "Translation coverage The algorithm can fail at several stages.", "labels": [], "entities": [{"text": "Translation coverage", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9564964771270752}]}, {"text": "If the graph cannot be turned into a tree, it cannot be translated.", "labels": [], "entities": []}, {"text": "This happens in 1.3% (647) of all sentences.", "labels": [], "entities": []}, {"text": "In many cases, this is due to coordinated NPs or PPs where one or more conjuncts are extraposed.", "labels": [], "entities": []}, {"text": "We believe that these are anaphoric, and further preprocessing could take care of this.", "labels": [], "entities": []}, {"text": "In other cases, this is due to verb topicalization (gegeben hat Peter Maria das Buch), which our algorithm cannot currently deal with.", "labels": [], "entities": [{"text": "verb topicalization", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.686357393860817}]}, {"text": "For 1.9% of the sentences, the algorithm cannot obtain a correct CCG derivation.", "labels": [], "entities": []}, {"text": "Mostly this is the case because some traces and extraposed elements cannot be discharged properly.", "labels": [], "entities": []}, {"text": "Typically this happens either in local scrambling, where an object of the main verb appears between the auxiliary and the subject (hat das Buch Peter...)", "labels": [], "entities": []}, {"text": ", or when an argument of a noun that appears in a relative clause is extraposed to the right.", "labels": [], "entities": []}, {"text": "There are also a small number of constituents whose head is not annotated.", "labels": [], "entities": []}, {"text": "We ignore any gapping construction or argument cluster coordination that we cannot get into the right shape (1.5%), 732 sentences).", "labels": [], "entities": []}, {"text": "There are also a number of other constructions that we do not currently deal with.", "labels": [], "entities": []}, {"text": "We do not process sentences if the root of the graph is a \"virtual root\" that does not expand into a sentence (1.7%, 869).", "labels": [], "entities": []}, {"text": "This is mostly the case for strings such as Frankfurt (Reuters)), or if we cannot identify ahead child of the root node (1.3%, 648; mostly fragments or elliptical constructions).", "labels": [], "entities": [{"text": "Frankfurt (Reuters))", "start_pos": 44, "end_pos": 64, "type": "DATASET", "confidence": 0.9446202218532562}]}, {"text": "Overall, we obtain CCG derivations for 92.4% (46,628) of all 54,0474 sentences, including 88.4% (12,122) of those whose Tiger graphs are marked as discontinuous, and 95.2% of all 48,957 full sentences (excluding headless roots, and fragments, but counting coordinate structures such as gapping).", "labels": [], "entities": []}, {"text": "Lexicon size There are 2,506 lexical category types, but 1,018 of these appear only once.", "labels": [], "entities": []}, {"text": "933 category types appear more than 5 times.", "labels": [], "entities": []}, {"text": "Lexical coverage In order to evaluate coverage of the extracted lexicon on unseen data, we split the corpus into segments of 5,000 sentences (ignoring the last 474), and perform 10-fold crossvalidation, using 9 segments to extract a lexicon and the 10th to test its coverage.", "labels": [], "entities": []}, {"text": "Average coverage is 86.7% (by token) of all lexical categories.", "labels": [], "entities": [{"text": "coverage", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9492822885513306}]}, {"text": "Coverage varies between 84.4% and 87.6%.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9439141750335693}]}, {"text": "On average, 92% (90.3%-92.6%) of the lexical tokens that appear in the held-out data also appear in the training data.", "labels": [], "entities": []}, {"text": "On these seen tokens, coverage is 94.2% (93.5%-92.6%).", "labels": [], "entities": [{"text": "coverage", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.998572587966919}]}, {"text": "More than half of all missing lexical entries are nouns.", "labels": [], "entities": []}, {"text": "In the English CCGbank, a lexicon extracted from section 02-21 (930,000 tokens) has 94% coverage on all tokens in section 00, and 97.7% coverage on all seen tokens).", "labels": [], "entities": [{"text": "English CCGbank", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.9250001609325409}]}, {"text": "In the English data set, the proportion of seen tokens (96.2%) is much higher, most likely because of the relative lack of derivational and inflectional morphology.", "labels": [], "entities": [{"text": "English data set", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8689218362172445}]}, {"text": "The better lexical coverage on seen tokens is also to be expected, given that the flexible word order of German requires case markings on all nouns as well as at least two different categories for each tensed verb, and more in order to account for local scrambling.", "labels": [], "entities": [{"text": "coverage", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9351821541786194}]}], "tableCaptions": []}