{"title": [{"text": "Automatic learning of textual entailments with cross-pair similarities", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we define a novel similarity measure between examples of textual en-tailments and we use it as a kernel function in Support Vector Machines (SVMs).", "labels": [], "entities": []}, {"text": "This allows us to automatically learn the rewrite rules that describe anon trivial set of entailment cases.", "labels": [], "entities": []}, {"text": "The experiments with the data sets of the RTE 2005 challenge show an improvement of 4.4% over the state-of-the-art methods.", "labels": [], "entities": [{"text": "RTE 2005 challenge", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.880034347375234}]}], "introductionContent": [{"text": "Recently, textual entailment recognition has been receiving a lot of attention.", "labels": [], "entities": [{"text": "textual entailment recognition", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8819826046625773}]}, {"text": "The main reason is that the understanding of the basic entailment processes will allow us to model more accurate semantic theories of natural languages) and design important applications (), e.g., Question Answering and Information Extraction.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 197, "end_pos": 215, "type": "TASK", "confidence": 0.8693214058876038}, {"text": "Information Extraction", "start_pos": 220, "end_pos": 242, "type": "TASK", "confidence": 0.7877887189388275}]}, {"text": "However, previous work (e.g.,) suggests that determining whether or not a text T entails a hypothesis H is quite complex even when all the needed information is explicitly asserted.", "labels": [], "entities": []}, {"text": "For example, the sentence T 1 : \"At the end of the year, all solid companies pay dividends.\" entails the hypothesis H 1 : \"At the end of the year, all solid insurance companies pay dividends.\" but it does not entail the hypothesis H 2 : \"At the end of the year, all solid companies pay cash dividends.\"", "labels": [], "entities": []}, {"text": "Although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance (or similarity) between hypothesis and text, e.g.,).", "labels": [], "entities": [{"text": "automatic recognition", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.72982257604599}]}, {"text": "Indeed, according to such approaches, the hypotheses H 1 and H 2 are very similar and seem to be similarly related to T 1 . This suggests that we should study the properties and differences of such two examples (negative and positive) to derive more accurate entailment models.", "labels": [], "entities": []}, {"text": "For example, if we consider the following entailment: T3 \"All wild animals eat plants that have scientifically proven medicinal properties.\"", "labels": [], "entities": [{"text": "T3", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9558975696563721}]}, {"text": "H3 \"All wild mountain animals eat plants that have scientifically proven medicinal properties.\" we note that T 3 is structurally (and somehow lexically similar) to T 1 and H 3 is more similar to H 1 than to H 2 . Thus, from T 1 \u21d2 H 1 we may extract rules to derive that T 3 \u21d2 H 3 . The above example suggests that we should rely not only on a intra-pair similarity between T and H but also on a cross-pair similarity between two pairs (T , H ) and (T , H ).", "labels": [], "entities": []}, {"text": "The latter similarity measure along with a set of annotated examples allows a learning algorithm to automatically derive syntactic and lexical rules that can solve complex entailment cases.", "labels": [], "entities": []}, {"text": "In this paper, we define anew cross-pair similarity measure based on text and hypothesis syntactic trees and we use such similarity with traditional intra-pair similarities to define a novel semantic kernel function.", "labels": [], "entities": []}, {"text": "We experimented with such kernel using Support Vector Machines on the test tests of the Recognizing Textual Entailment (RTE) challenges).", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE)", "start_pos": 88, "end_pos": 124, "type": "TASK", "confidence": 0.6617885778347651}]}, {"text": "The comparative results show that (a) we have designed an effective way to automatically learn entailment rules from examples and (b) our approach is highly accurate and exceeds the accuracy of the current state-of-the-art models () by about 4.4% (i.e. 63% vs. 58.6%) on the RTE 1 test set ( ).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9991257786750793}, {"text": "RTE 1 test set", "start_pos": 275, "end_pos": 289, "type": "DATASET", "confidence": 0.9494741708040237}]}, {"text": "In the remainder of this paper, Sec.", "labels": [], "entities": []}, {"text": "2 illustrates the related work, Sec.", "labels": [], "entities": []}, {"text": "3 introduces the complexity of learning entailments from examples, Sec.", "labels": [], "entities": []}, {"text": "4 describes our models, Sec.", "labels": [], "entities": []}, {"text": "6 shows the experimental results and finally Sec.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of the experiments is twofold: we show that (a) entailment recognition rules can be learned from examples and (b) our kernel functions over syntactic structures are effective to derive syntactic properties.", "labels": [], "entities": [{"text": "entailment recognition", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.699405625462532}]}, {"text": "The above goals can be achieved by comparing the different intra and cross pair similarity measures.", "labels": [], "entities": []}, {"text": "For the experiments, we used the Recognizing Textual Entailment Challenge data sets, which we name as follows: -D1, T 1 and D2, T 2, are the development and the test sets of the first ( ) and second) challenges, respectively.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment Challenge data sets", "start_pos": 33, "end_pos": 83, "type": "DATASET", "confidence": 0.6463615298271179}]}, {"text": "D1 contains 567 examples whereas T 1, D2 and T 2 have all the same size, i.e. 800 training/testing instances.", "labels": [], "entities": []}, {"text": "The positive examples constitute the 50% of the data.", "labels": [], "entities": []}, {"text": "-ALL is the union of D1, D2, and T 1, which we also split in 70%-30%.", "labels": [], "entities": [{"text": "ALL", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.9761430025100708}]}, {"text": "This set is useful to test if we can learn entailments from the data prepared in the two different challenges.", "labels": [], "entities": []}, {"text": "-D2(50%) and D2(50%) is a random split of D2.", "labels": [], "entities": []}, {"text": "It is possible that the data sets of the two competitions are quite different thus we created this homogeneous split.", "labels": [], "entities": []}, {"text": "We also used the following resources: -The Charniak parser) and the morpha lemmatiser () to carryout the syntactic and morphological analysis.", "labels": [], "entities": []}, {"text": "-WordNet 2.0 to extract both the verbs in entailment, Ent set, and the derivationally related words, Der set.", "labels": [], "entities": []}, {"text": "-The wn::similarity package () to compute the Jiang&Conrath (J&C) distance as in).", "labels": [], "entities": []}, {"text": "This is one of the best figure method which provides a similarity score in the interval.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 55, "end_pos": 71, "type": "METRIC", "confidence": 0.9667040109634399}]}, {"text": "We used it to implement the d(l w , l w ) function.", "labels": [], "entities": []}, {"text": "-A selected portion of the British National Corpus 2 to compute the inverse document frequency (idf ).", "labels": [], "entities": [{"text": "British National Corpus 2", "start_pos": 27, "end_pos": 52, "type": "DATASET", "confidence": 0.9608433842658997}, {"text": "inverse document frequency (idf )", "start_pos": 68, "end_pos": 101, "type": "METRIC", "confidence": 0.8454512506723404}]}, {"text": "We assigned the maximum idf to words not found in the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.9440833330154419}]}, {"text": "-SVM-light-TK 3) which encodes the basic tree kernel function, K T , in SVMlight.", "labels": [], "entities": []}, {"text": "We used such software to implement K s (Eq. 6), K 1 , K 2 (Eq. 5) and K s + K i kernels.", "labels": [], "entities": []}, {"text": "The latter combines our new kernel with traditional approaches (i \u2208 {1, 2}).", "labels": [], "entities": []}, {"text": "reports the results of different similarity kernels on the different training and test splits described in the previous section.", "labels": [], "entities": []}, {"text": "The table is organized as follows:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results of the different methods over different test settings", "labels": [], "entities": []}]}