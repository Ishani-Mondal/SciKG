{"title": [{"text": "Learning the Structure of Task-driven Human-Human Dialogs", "labels": [], "entities": [{"text": "Learning the Structure of Task-driven Human-Human Dialogs", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.6721308316503253}]}], "abstractContent": [{"text": "Data-driven techniques have been used for many computational linguistics tasks.", "labels": [], "entities": [{"text": "computational linguistics tasks", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.796221395333608}]}, {"text": "Models derived from data are generally more robust than hand-crafted systems since they better reflect the distribution of the phenomena being modeled.", "labels": [], "entities": []}, {"text": "With the availability of large corpora of spoken dialog, dialog management is now reaping the benefits of data-driven techniques.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.869110494852066}]}, {"text": "In this paper, we compare two approaches to modeling subtask structure in dialog: a chunk-based model of subdialog sequences, and a parse-based, or hierarchical , model.", "labels": [], "entities": []}, {"text": "We evaluate these models using customer agent dialogs from a catalog service domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "As large amounts of language data have become available, approaches to sentence-level processing tasks such as parsing, language modeling, named-entity detection and machine translation have become increasingly data-driven and empirical.", "labels": [], "entities": [{"text": "parsing", "start_pos": 111, "end_pos": 118, "type": "TASK", "confidence": 0.942050039768219}, {"text": "language modeling", "start_pos": 120, "end_pos": 137, "type": "TASK", "confidence": 0.7288439869880676}, {"text": "named-entity detection", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.7625812888145447}, {"text": "machine translation", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.7575367391109467}]}, {"text": "Models for these tasks can be trained to capture the distributions of phenomena in the data resulting in improved robustness and adaptability.", "labels": [], "entities": []}, {"text": "However, this trend has yet to significantly impact approaches to dialog management in dialog systems.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.9159300923347473}]}, {"text": "Dialog managers (both plan-based and call-flow based, for example) have traditionally been hand-crafted and consequently somewhat brittle and rigid.", "labels": [], "entities": [{"text": "Dialog managers", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8930049240589142}]}, {"text": "With the ability to record, store and process large numbers of human-human dialogs (e.g. from call centers), we anticipate that data-driven methods will increasingly influence approaches to dialog management.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 190, "end_pos": 207, "type": "TASK", "confidence": 0.9124659299850464}]}, {"text": "A successful dialog system relies on the synergistic working of several components: speech recognition (ASR), spoken language understanding (SLU), dialog management (DM), language generation (LG) and text-to-speech synthesis (TTS).", "labels": [], "entities": [{"text": "speech recognition (ASR)", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8341742217540741}, {"text": "spoken language understanding (SLU)", "start_pos": 110, "end_pos": 145, "type": "TASK", "confidence": 0.7783635159333547}, {"text": "dialog management (DM)", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.8359895944595337}, {"text": "language generation (LG)", "start_pos": 171, "end_pos": 195, "type": "TASK", "confidence": 0.8178018569946289}, {"text": "text-to-speech synthesis (TTS)", "start_pos": 200, "end_pos": 230, "type": "TASK", "confidence": 0.7927520573139191}]}, {"text": "While data-driven approaches to ASR and SLU are prevalent, such approaches to DM, LG and TTS are much less well-developed.", "labels": [], "entities": [{"text": "ASR", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.993588924407959}]}, {"text": "In ongoing work, we are investigating data-driven approaches for building all components of spoken dialog systems.", "labels": [], "entities": []}, {"text": "In this paper, we address one aspect of this problem -inferring predictive models to structure taskoriented dialogs.", "labels": [], "entities": []}, {"text": "We view this problem as a first step in predicting the system state of a dialog manager and in predicting the system utterance during an incremental execution of a dialog.", "labels": [], "entities": []}, {"text": "In particular, we learn models for predicting dialog acts of utterances, and models for predicting subtask structures of dialogs.", "labels": [], "entities": [{"text": "predicting dialog acts of utterances", "start_pos": 35, "end_pos": 71, "type": "TASK", "confidence": 0.766630208492279}, {"text": "predicting subtask structures of dialogs", "start_pos": 88, "end_pos": 128, "type": "TASK", "confidence": 0.826887333393097}]}, {"text": "We use three different dialog act tag sets for three different human-human dialog corpora.", "labels": [], "entities": []}, {"text": "We compare a flat chunk-based model to a hierarchical parse-based model as models for predicting the task structure of dialogs.", "labels": [], "entities": []}, {"text": "The outline of this paper is as follows: In Section 2, we review current approaches to building dialog systems.", "labels": [], "entities": []}, {"text": "In Section 3, we review related work in data-driven dialog modeling.", "labels": [], "entities": [{"text": "dialog modeling", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.7727110385894775}]}, {"text": "In Section 4, we present our view of analyzing the structure of task-oriented human-human dialogs.", "labels": [], "entities": []}, {"text": "In Section 5, we discuss the problem of segmenting and labeling dialog structure and building models for predicting these labels.", "labels": [], "entities": []}, {"text": "In Section 6, we report experimental results on Maptask, Switchboard and a dialog data collection from a catalog ordering service domain.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the results of our experiments for modeling subtask structure.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Error rates in dialog act tagging", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9828252196311951}, {"text": "dialog act tagging", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.731626828511556}]}, {"text": " Table 5: Error rate for predicting the refined sub- task labels. The error rates without the well- formedness constraint is shown in parenthesis.  The error rates with dialog acts as features are sep- arated by a slash.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9936874508857727}]}]}