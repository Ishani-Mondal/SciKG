{"title": [{"text": "Combination of Arabic Preprocessing Schemes for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.8627291123072306}]}], "abstractContent": [{"text": "Statistical machine translation is quite robust when it comes to the choice of input representation.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.685294896364212}]}, {"text": "It only requires consistency between training and testing.", "labels": [], "entities": []}, {"text": "As a result, there is a wide range of possible preprocessing choices for data used in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7118959029515585}]}, {"text": "This is even more so for morphologically rich languages such as Arabic.", "labels": [], "entities": []}, {"text": "In this paper, we study the effect of different word-level preprocessing schemes for Arabic on the quality of phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 110, "end_pos": 154, "type": "TASK", "confidence": 0.5793734341859818}]}, {"text": "We also present and evaluate different methods for combining pre-processing schemes resulting in improved translation quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT) is quite robust when it comes to the choice of input representation.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8208098709583282}]}, {"text": "It only requires consistency between training and testing.", "labels": [], "entities": []}, {"text": "As a result, there is a wide range of possible preprocessing choices for data used in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9922894835472107}]}, {"text": "This is even more so for morphologically rich languages such as Arabic.", "labels": [], "entities": []}, {"text": "We use the term \"preprocessing\" to describe various input modifications applied to raw training and testing texts for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.993316113948822}]}, {"text": "Preprocessing includes different kinds of tokenization, stemming, part-of-speech (POS) tagging and lemmatization.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.6057885110378265}]}, {"text": "The ultimate goal of preprocessing is to improve the quality of the SMT output by addressing issues such as sparsity in training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9946300983428955}]}, {"text": "We refer to a specific kind of preprocessing as a \"scheme\" and differentiate it from the \"technique\" used to obtain it.", "labels": [], "entities": []}, {"text": "Ina previous publication, we presented results describing six preprocessing schemes for Arabic).", "labels": [], "entities": []}, {"text": "These schemes were evaluated against three different techniques that vary in linguistic complexity; and across a learning curve of training sizes.", "labels": [], "entities": []}, {"text": "Additionally, we reported on the effect of scheme/technique combination on genre variation between training and testing.", "labels": [], "entities": []}, {"text": "In this paper, we shift our attention to exploring and contrasting additional preprocessing schemes for Arabic and describing and evaluating different methods for combining them.", "labels": [], "entities": []}, {"text": "We use a single technique throughout the experiments reported here.", "labels": [], "entities": []}, {"text": "We show an improved MT performance when combining different schemes.", "labels": [], "entities": [{"text": "MT", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.9700021743774414}]}, {"text": "Similarly to, the set of schemes we explore are all word-level.", "labels": [], "entities": []}, {"text": "As such, we do not utilize any syntactic information.", "labels": [], "entities": []}, {"text": "We define the word to be limited to written Modern Standard Arabic (MSA) strings separated by white space, punctuation and numbers.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA) strings", "start_pos": 44, "end_pos": 80, "type": "DATASET", "confidence": 0.8176559550421578}]}, {"text": "Section 2 presents previous relevant research.", "labels": [], "entities": []}, {"text": "Section 3 presents some relevant background on Arabic linguistics to motivate the schemes discussed in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 presents the tools and data sets used, along with the results of basic scheme experiments.", "labels": [], "entities": []}, {"text": "Section 6 presents combination techniques and their results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now describe the system and the data sets we used to conduct our experiments.", "labels": [], "entities": []}, {"text": "All of the training data we use is available from the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 54, "end_pos": 86, "type": "DATASET", "confidence": 0.8550355484088262}]}, {"text": "We use an Arabic-English parallel corpus of about 5 million words for translation model training data.", "labels": [], "entities": [{"text": "translation model training", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.896505614121755}]}, {"text": "We created the English language model from the English side of the parallel corpus together with 116 million words the English Gigaword Corpus (LDC2005T12) and 128 million words from the English side of the UN Parallel corpus (LDC2004E13).", "labels": [], "entities": [{"text": "English Gigaword Corpus (LDC2005T12)", "start_pos": 119, "end_pos": 155, "type": "DATASET", "confidence": 0.8996257185935974}, {"text": "UN Parallel corpus (LDC2004E13)", "start_pos": 207, "end_pos": 238, "type": "DATASET", "confidence": 0.903420090675354}]}, {"text": "English preprocessing simply included lowercasing, separating punctuation from words and splitting off \"'s\".", "labels": [], "entities": []}, {"text": "The same preprocessing was used on the English data for all experiments.", "labels": [], "entities": [{"text": "English data", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.7639398872852325}]}, {"text": "Only Arabic preprocessing was varied.", "labels": [], "entities": []}, {"text": "Decoding weight optimization was done using a set of 200 sentences from the 2003 NIST MT evaluation test set (MT03).", "labels": [], "entities": [{"text": "Decoding weight optimization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8711836735407511}, {"text": "NIST MT evaluation test set (MT03)", "start_pos": 81, "end_pos": 115, "type": "DATASET", "confidence": 0.9046564847230911}]}, {"text": "We report results on the 2004 NIST MT evaluation test set (MT04) The experiment design and choices of schemes and techniques were done independently of the test set.", "labels": [], "entities": [{"text": "NIST MT evaluation test set (MT04", "start_pos": 30, "end_pos": 63, "type": "DATASET", "confidence": 0.8527995262827192}]}, {"text": "The data sets, MT03 and MT04, include one Arabic source and four English reference translations.", "labels": [], "entities": [{"text": "MT03", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.9505764245986938}, {"text": "MT04", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.9352812767028809}]}, {"text": "We use the evaluation metric BLEU-4 () although we are aware of its caveats).", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9900525212287903}]}, {"text": "We conducted experiments with all schemes discussed in Section 4 with different training corpus sizes: 1%, 10%, 50% and 100%.", "labels": [], "entities": []}, {"text": "The results of the experiments are summarized in.", "labels": [], "entities": []}, {"text": "These results are not English case sensitive.", "labels": [], "entities": []}, {"text": "All reported scores must have over 1.1% BLEU-4 difference to be significant at the 95% confidence level for 1% training.", "labels": [], "entities": [{"text": "BLEU-4 difference", "start_pos": 40, "end_pos": 57, "type": "METRIC", "confidence": 0.9848013520240784}]}, {"text": "For all other training sizes, the difference must be over 1.7% BLEU-4.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9978487491607666}]}, {"text": "Error intervals were computed using bootstrap resampling.", "labels": [], "entities": [{"text": "Error intervals", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9696570336818695}]}, {"text": "Across different schemes, EN performs the best under scarce-resource condition; and D2 performs as best under large resource conditions.", "labels": [], "entities": []}, {"text": "The results from the learning curve are consistent with previous published work on using morphological preprocessing for SMT: deeper morph analysis helps for small data sets, but the effect is diminished with more data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9948011636734009}]}, {"text": "One interesting observation is that for our best performing system (D2), the BLEU score at 50% training (35.91) was higher than the baseline ST at 100% training data.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9819257855415344}]}, {"text": "This relationship is not consistent across the rest of the experiments.", "labels": [], "entities": []}, {"text": "ON improves over the baseline but only statistically significantly at the 1% level.", "labels": [], "entities": [{"text": "ON", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.996085524559021}]}, {"text": "The results for WA are generally similar to D1.", "labels": [], "entities": [{"text": "WA", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.864793062210083}]}, {"text": "This makes sense since w+ is by far the most common of the two conjunctions D1 splits off.", "labels": [], "entities": []}, {"text": "The TB scheme behaves similarly to D2, the best scheme we have.", "labels": [], "entities": []}, {"text": "It outperformed D2 in few instances, but the difference were not statistically significant.", "labels": [], "entities": []}, {"text": "L1 and L2 behaved similar to EN across the different training size.", "labels": [], "entities": []}, {"text": "However, both were always worse than EN.", "labels": [], "entities": [{"text": "EN", "start_pos": 37, "end_pos": 39, "type": "DATASET", "confidence": 0.7185866832733154}]}, {"text": "Neither variant was consistently better than the other.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Scheme Experiment Results (BLEU-4)", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9755738377571106}]}, {"text": " Table 4: ROC Approach Results", "labels": [], "entities": [{"text": "ROC", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7877969145774841}, {"text": "Approach", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.49242836236953735}]}, {"text": " Table 5: DRC Approach Results", "labels": [], "entities": [{"text": "DRC", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.5604950189590454}, {"text": "Approach", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.7274735569953918}]}, {"text": " Table 6: Statistical Significance using Bootstrap  Resampling", "labels": [], "entities": [{"text": "Statistical Significance", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7654744684696198}, {"text": "Resampling", "start_pos": 52, "end_pos": 62, "type": "TASK", "confidence": 0.6508298516273499}]}]}