{"title": [{"text": "Exploiting Syntactic Patterns as Clues in Zero-Anaphora Resolution", "labels": [], "entities": []}], "abstractContent": [{"text": "We approach the zero-anaphora resolution problem by decomposing it into intra-sentential and inter-sentential zero-anaphora resolution.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7248173356056213}, {"text": "inter-sentential zero-anaphora resolution", "start_pos": 93, "end_pos": 134, "type": "TASK", "confidence": 0.6935580770174662}]}, {"text": "For the former problem , syntactic patterns of the appearance of zero-pronouns and their antecedents are useful clues.", "labels": [], "entities": []}, {"text": "Taking Japanese as a target language, we empirically demonstrate that incorporating rich syntactic pattern features in a state-of-the-art learning-based anaphora resolution model dramatically improves the accuracy of intra-sentential zero-anaphora, which consequently improves the overall performance of zero-anaphora resolution.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9985578656196594}, {"text": "zero-anaphora resolution", "start_pos": 304, "end_pos": 328, "type": "TASK", "confidence": 0.7660007476806641}]}], "introductionContent": [{"text": "Zero-anaphora is a gap in a sentence that has an anaphoric function similar to a pro-form (e.g. pronoun) and is often described as \"referring back\" to an expression that supplies the information necessary for interpreting the sentence.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"There are two roads to eternity, a straight and narrow, and abroad and crooked,\" the gaps in \"a straight and narrow (gap)\" and \"a broad and crooked (gap)\" have a zero-anaphoric relationship to \"two roads to eternity.\"", "labels": [], "entities": []}, {"text": "The task of identifying zero-anaphoric relations in a given discourse, zero-anaphora resolution, is essential in a wide range of NLP applications.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.7361194491386414}]}, {"text": "This is the case particularly in such a language as Japanese, where even obligatory arguments of a predicate are often omitted when they are inferable from the context.", "labels": [], "entities": []}, {"text": "In fact, in our Japanese newspaper corpus, for example, 45.5% of the nominative arguments of verbs are omitted.", "labels": [], "entities": [{"text": "Japanese newspaper corpus", "start_pos": 16, "end_pos": 41, "type": "DATASET", "confidence": 0.7628901203473409}]}, {"text": "Since such gaps cannot be interpreted only by shallow syntactic parsing, a model specialized for zero-anaphora resolution needs to be devised on the top of shallow syntactic and semantic processing.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.7312862873077393}]}, {"text": "Recent work on zero-anaphora resolution can be located in two different research contexts.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7464805245399475}]}, {"text": "First, zero-anaphora resolution is studied in the context of anaphora resolution (AR), in which zeroanaphora is regarded as a subclass of anaphora.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 7, "end_pos": 31, "type": "TASK", "confidence": 0.7367631793022156}, {"text": "anaphora resolution (AR)", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.8173823237419129}]}, {"text": "In AR, the research trend has been shifting from rulebased approaches) to empirical, or corpus-based, approaches) because the latter are shown to be a cost-efficient solution achieving a performance that is comparable to best performing rule-based systems (see the Coreference task in MUC 1 and the Entity Detection and Tracking task in the ACE program 2 ).", "labels": [], "entities": [{"text": "Entity Detection and Tracking task", "start_pos": 299, "end_pos": 333, "type": "TASK", "confidence": 0.8030433833599091}, {"text": "ACE program", "start_pos": 341, "end_pos": 352, "type": "DATASET", "confidence": 0.88539919257164}]}, {"text": "The same trend is observed also in Japanese zeroanaphora resolution, where the findings made in rule-based or theory-oriented work) have been successfully incorporated in machine learning-based frameworks ().", "labels": [], "entities": [{"text": "Japanese zeroanaphora resolution", "start_pos": 35, "end_pos": 67, "type": "TASK", "confidence": 0.5630692938963572}]}, {"text": "Second, the task of zero-anaphora resolution has some overlap with Propbank -style semantic role labeling (SRL), which has been intensively studied, for example, in the context of the CoNLL SRL task 4 . In this task, given a sentence \"To attract younger listeners, Radio Free Europe intersperses the latest in Western rock groups\", an SRL model is asked to identify the NP Radio Free Europe as the A0 (Agent) argument of the verb attract.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.7377085089683533}, {"text": "Propbank -style semantic role labeling (SRL)", "start_pos": 67, "end_pos": 111, "type": "TASK", "confidence": 0.6968563497066498}, {"text": "CoNLL SRL task 4", "start_pos": 184, "end_pos": 200, "type": "TASK", "confidence": 0.558464452624321}, {"text": "NP Radio Free Europe", "start_pos": 370, "end_pos": 390, "type": "DATASET", "confidence": 0.9328517615795135}]}, {"text": "This can be seen as the task of finding the zero-anaphoric relationship between a nominal gap (the A0 argument of attract) and its antecedent (Radio Free Europe) under the condition that the gap and its antecedent appear in the same sentence.", "labels": [], "entities": []}, {"text": "In spite of this overlap between AR and SRL, there are some important findings that are yet to be exchanged between them, partly because the two fields have been evolving somewhat independently.", "labels": [], "entities": [{"text": "SRL", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.7528514266014099}]}, {"text": "The AR community has recently made two important findings: \u2022 A model that identifies the antecedent of an anaphor by a series of comparisons between candidate antecedents has a remarkable advantage over a model that estimates the absolute likelihood of each candidate independently of other candidates (.", "labels": [], "entities": []}, {"text": "\u2022 An AR model that carries out antecedent identification before anaphoricity determination, the decision whether a given NP is anaphoric or not (i.e. discourse-new), significantly outperforms a model that executes those subtasks in the reverse order or simultaneously ().", "labels": [], "entities": []}, {"text": "To our best knowledge, however, existing SRL models do not exploit these advantages.", "labels": [], "entities": [{"text": "SRL", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9552781581878662}]}, {"text": "In SRL, on the other hand, it is common to use syntactic features derived from the parse tree of a given input sentence for argument identification.", "labels": [], "entities": [{"text": "SRL", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9361507296562195}, {"text": "argument identification", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.7191153019666672}]}, {"text": "A typical syntactic feature is the path on a parse tree from a target predicate to a noun phrase in question ().", "labels": [], "entities": []}, {"text": "However, existing AR models deal with intra-and inter-sentential anaphoric relations in a uniform manner; that is, they do not use as rich syntactic features as state-of-the-art SRL models do, even in finding intra-sentential anaphoric relations.", "labels": [], "entities": []}, {"text": "We believe that the AR and SRL communities can learn more from each other.", "labels": [], "entities": []}, {"text": "Given this background, in this paper, we show that combining the aforementioned techniques derived from each research trend makes significant impact on zero-anaphora resolution, taking Japanese as a target language.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 152, "end_pos": 176, "type": "TASK", "confidence": 0.8112572729587555}]}, {"text": "More specifically, we demonstrate the following: \u2022 Incorporating rich syntactic features in a state-of-the-art AR model dramatically improves the accuracy of intra-sentential zeroanaphora resolution, which consequently improves the overall performance of zeroanaphora resolution.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9992386102676392}]}, {"text": "This is to be considered as a contribution to AR research.", "labels": [], "entities": [{"text": "AR research", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.9763108491897583}]}, {"text": "\u2022 Analogously to inter-sentential anaphora, decomposing the antecedent identification task into a series of comparisons between candidate antecedents works remarkably well also in intra-sentential zero-anaphora resolution.", "labels": [], "entities": [{"text": "zero-anaphora resolution", "start_pos": 197, "end_pos": 221, "type": "TASK", "confidence": 0.7667136788368225}]}, {"text": "We hope this finding to be adopted in SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.6722071766853333}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the task definition of zeroanaphora resolution in Japanese.", "labels": [], "entities": [{"text": "zeroanaphora resolution", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.6520140171051025}]}, {"text": "In Section 3, we review previous approaches to AR.", "labels": [], "entities": [{"text": "AR", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9823696613311768}]}, {"text": "Section 4 described how the proposed model incorporates effectively syntactic features into the machine learning-based approach.", "labels": [], "entities": []}, {"text": "We then report the results of our experiments on Japanese zeroanaphora resolution in Section 5 and conclude in Section 6.", "labels": [], "entities": [{"text": "Japanese zeroanaphora resolution", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.7013862133026123}]}], "datasetContent": [{"text": "We conducted an evaluation of our method using Japanese newspaper articles.", "labels": [], "entities": []}, {"text": "The following four models were compared: 1.", "labels": [], "entities": []}, {"text": "BM: Ng and Cardie (2002a)'s model, which identify antecedents by the candidatewise classification model, and determine anaphoricity using the one-step model.", "labels": [], "entities": [{"text": "candidatewise classification", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.6575892418622971}]}], "tableCaptions": [{"text": " Table 1: Accuracy of antecedent identification.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9912793040275574}, {"text": "antecedent identification", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.5618348121643066}]}]}