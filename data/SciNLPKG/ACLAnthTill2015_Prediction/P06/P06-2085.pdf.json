{"title": [{"text": "Using Machine Learning to Explore Human Multimodal Clarification Strategies", "labels": [], "entities": [{"text": "Explore Human Multimodal Clarification Strategies", "start_pos": 26, "end_pos": 75, "type": "TASK", "confidence": 0.6266443729400635}]}], "abstractContent": [{"text": "We investigate the use of machine learning in combination with feature engineering techniques to explore human multi-modal clarification strategies and the use of those strategies for dialogue systems.", "labels": [], "entities": []}, {"text": "We learn from data collected in a Wizard-of-Oz study where different wizards could decide whether to ask a clarification request in a multimodal manner or else use speech alone.", "labels": [], "entities": []}, {"text": "We show that there is a uniform strategy across wizards which is based on multiple features in the context.", "labels": [], "entities": []}, {"text": "These are generic runtime features which can be implemented in dialogue systems.", "labels": [], "entities": []}, {"text": "Our prediction models achieve a weighted f-score of 85.3% (which is a 25.5% improvement over a one-rule baseline).", "labels": [], "entities": [{"text": "f-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.8582685589790344}]}, {"text": "To assess the effects of models, feature dis-cretisation, and selection, we also conduct a regression analysis.", "labels": [], "entities": []}, {"text": "We then interpret and discuss the use of the learnt strategy for dialogue systems.", "labels": [], "entities": []}, {"text": "Throughout the investigation we discuss the issues arising from using small initial Wizard-of-Oz data sets, and we show that feature engineering is an essential step when learning from such limited data.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.780897319316864}]}], "introductionContent": [{"text": "Good clarification strategies in dialogue systems help to ensure and maintain mutual understanding and thus play a crucial role in robust conversational interaction.", "labels": [], "entities": []}, {"text": "In dialogue application domains with high interpretation uncertainty, for example caused by acoustic uncertainties from a speech recogniser, multimodal generation and input leads to more robust interaction) and reduced cognitive load).", "labels": [], "entities": [{"text": "speech recogniser", "start_pos": 122, "end_pos": 139, "type": "TASK", "confidence": 0.7088568210601807}]}, {"text": "In this paper we investigate the use of machine learning (ML) to explore human multimodal clarification strategies and the use of those strategies to decide, based on the current dialogue context, when a dialogue system's clarification request (CR) should be generated in a multimodal manner.", "labels": [], "entities": []}, {"text": "In previous work) we showed that for spoken CRs in humanhuman communication people follow a contextdependent clarification strategy which systematically varies across domains (and even across Germanic languages).", "labels": [], "entities": []}, {"text": "In this paper we investigate whether there exists a context-dependent \"intuitive\" human strategy for multimodal CRs as well.", "labels": [], "entities": []}, {"text": "To test this hypothesis we gathered data in a Wizard-of-Oz (WOZ) study, where different wizards could decide when to show a screen output.", "labels": [], "entities": []}, {"text": "From this data we build prediction models, using supervised learning techniques together with feature engineering methods, that may explain the underlying process which generated the data.", "labels": [], "entities": []}, {"text": "If we can build a model which predicts the data quite reliably, we can show that there is a uniform strategy that the majority of our wizards followed in certain contexts.", "labels": [], "entities": []}, {"text": "The overall method and corresponding structure of the paper is as shown in.", "labels": [], "entities": []}, {"text": "In section 2 we present the WOZ corpus from which we extract a potential context using \"Information State Update\" (ISU)-based features ( ), listed in section 3.", "labels": [], "entities": [{"text": "WOZ corpus", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.8733514547348022}]}, {"text": "We also address the question how to define a suitable \"local\" context definition for the wizard actions.", "labels": [], "entities": []}, {"text": "We apply the feature engineering methods described in section 4 to address the questions of unique thresholds and feature subsets across wizards.", "labels": [], "entities": []}, {"text": "These techniques also help to reduce the context representation and thus the feature space used for learning.", "labels": [], "entities": []}, {"text": "In section 5 we test different classifiers upon this reduced context and separate out the independent contribution of learning algorithms and feature engineering techniques.", "labels": [], "entities": []}, {"text": "In section 6 we discuss and interpret the learnt strategy.", "labels": [], "entities": []}, {"text": "Finally we argue for the use of reinforcement learning to optimise the multimodal clarification strategy.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of context definitions for lo- cal features (* denotes p < .05)", "labels": [], "entities": []}, {"text": " Table 3: Average accuracy and wf-scores for models in feature engineering experiments .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9381213784217834}]}]}