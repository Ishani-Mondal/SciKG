{"title": [{"text": "LARGE LEXICONS FOR NATURAL LANGUAGE PROCESSING: UTILISING THE GRAMMAR CODING SYSTEM OF LDOCE", "labels": [], "entities": [{"text": "LARGE LEXICONS FOR NATURAL LANGUAGE", "start_pos": 0, "end_pos": 35, "type": "METRIC", "confidence": 0.5701749563217163}, {"text": "UTILISING THE GRAMMAR CODING SYSTEM", "start_pos": 48, "end_pos": 83, "type": "TASK", "confidence": 0.5516576170921326}]}], "abstractContent": [{"text": "This article focusses on the derivation of large lexicons for natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.625451515118281}]}, {"text": "We describe the development of a dictionary support environment linking a restructured version of the Longman Dictionary of Contemporary English to natural language processing systems.", "labels": [], "entities": [{"text": "Longman Dictionary of Contemporary English", "start_pos": 102, "end_pos": 144, "type": "DATASET", "confidence": 0.9462632179260254}]}, {"text": "The process of restructuring the information in the machine readable version of the dictionary is discussed.", "labels": [], "entities": []}, {"text": "The Longman grammar code system is used to construct 'theory neutral' lexical entries.", "labels": [], "entities": []}, {"text": "We demonstrate how such lexical entries can be put to practical use by linking up the system described herewith the experimental PATR-II grammar development environment.", "labels": [], "entities": [{"text": "PATR-II grammar development", "start_pos": 129, "end_pos": 156, "type": "TASK", "confidence": 0.6048099597295126}]}, {"text": "Finally, we offer an evaluation of the utility of the grammar coding system for use by automatic natural language parsing systems.", "labels": [], "entities": [{"text": "automatic natural language parsing", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.7157682478427887}]}], "introductionContent": [{"text": "The grammar coding system employed by the Longman Dictionary of Contemporary English (henceforth LDOCE) is the most comprehensive description of grammatical properties of words to be found in any published dictionary available in machine readable form.", "labels": [], "entities": [{"text": "Longman Dictionary of Contemporary English (henceforth LDOCE)", "start_pos": 42, "end_pos": 103, "type": "DATASET", "confidence": 0.9350338247087266}]}, {"text": "This paper describes the extraction of this, and other, information from LDOCE and discusses the utility of the coding system for automated natural language processing.", "labels": [], "entities": [{"text": "automated natural language processing", "start_pos": 130, "end_pos": 167, "type": "TASK", "confidence": 0.611005425453186}]}, {"text": "Recent developments in linguistics, and especially on grammatical theory --for example, Generalised Phrase Structure Grammar (GPSG) (, Lexical Functional Grammar (LFG) --and on natural language parsing frameworks for example, Functional Unification Grammar (FUG), PATR-II (Shieber, 1984) --make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language.", "labels": [], "entities": [{"text": "Generalised Phrase Structure Grammar (GPSG)", "start_pos": 88, "end_pos": 131, "type": "TASK", "confidence": 0.7418187430926731}, {"text": "natural language parsing", "start_pos": 177, "end_pos": 201, "type": "TASK", "confidence": 0.7222843567530314}, {"text": "syntactic analysis of substantial fragments of natural language", "start_pos": 367, "end_pos": 430, "type": "TASK", "confidence": 0.8185812011361122}]}, {"text": "These developments also emphasise that if natural language processing systems are to be able to handle the grammatical and semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central component of the parsing system.", "labels": [], "entities": []}, {"text": "Real-time parsing imposes stringent requirements on a dictionary support environment; at the very least it must allow frequent and rapid access to the information in the dictionary via the dictionary head words.", "labels": [], "entities": [{"text": "Real-time parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.5149074643850327}]}, {"text": "The research described below is taking place in the context of three collaborative projects to develop a general-purpose, wide coverage morphological and syntactic analyser for English.", "labels": [], "entities": []}, {"text": "One motivation for our interest in machine readable dictionaries is to attempt to provide a substantial lexicon with lexical entries containing grammatical information compatible with the grammatical framework employed by the analyser.", "labels": [], "entities": []}, {"text": "The idea of using the machine readable source of a published dictionary has occurred to a wide range of researchers, for spelling correction, lexical analysis, thesaurus construction, and machine translation, to name but a few applications.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.9377453029155731}, {"text": "lexical analysis", "start_pos": 142, "end_pos": 158, "type": "TASK", "confidence": 0.7373480796813965}, {"text": "thesaurus construction", "start_pos": 160, "end_pos": 182, "type": "TASK", "confidence": 0.7589464485645294}, {"text": "machine translation", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.7146236151456833}]}, {"text": "Most of the work on automated dictionaries has concentrated on extracting lexical or other information, essentially by batch processing (eg.", "labels": [], "entities": []}], "datasetContent": [{"text": "The utility of the work reported above rests ultimately on the accuracy of the lexical entries which can be derived from the LDOCE tape.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9992881417274475}, {"text": "LDOCE tape", "start_pos": 125, "end_pos": 135, "type": "DATASET", "confidence": 0.8578868806362152}]}, {"text": "We have not attempted a systematic analysis of the entries which would result if the decompacting and grammar code transformation programs were applied to the entire dictionary.", "labels": [], "entities": []}, {"text": "In Section 3 we outlined some of the errors in the grammar codes which are problematic for the decompacting stage.", "labels": [], "entities": []}, {"text": "However, mistakes or omissions in the assignment of grammar codes represent a more serious problem.", "labels": [], "entities": []}, {"text": "While inconsistencies or errors in the application of the grammar coding system in some cases can be rectified by the gradual refinement of the decompacting program, it is not possible to correct errors of omission or assignment automatically.", "labels": [], "entities": []}, {"text": "On the basis of unsystematic evaluation, using the programs to dynamically produce entries for the PATR-II parsing system, a number of errors of this type have emerged.", "labels": [], "entities": [{"text": "PATR-II parsing", "start_pos": 99, "end_pos": 114, "type": "TASK", "confidence": 0.7319425046443939}]}, {"text": "For example, the LDOCE definitions and associated code fields in, demonstrate that upset(3) needs it + D5 which would correspond to its use with a noun phrase and a sentential complement; suppose(2) is missing optional \"to be\" for the X1 and X7 codes listed; help(l) needs a T3 code since it does not always require a direct object as well as an infinitive complement; and detest needs a V4 code because it can take a direct object as well as a gerund complement.", "labels": [], "entities": []}, {"text": "It is difficult to quantify the extent of this problem on the the basis of enumeration of examples of this type.", "labels": [], "entities": []}, {"text": "Therefore, we have undertaken a limited test of both the accuracy of the assignment of the LDOCE codes in the source dictionary and the reliability of the more ambitious (and potentially controversial) aspects of the grammar code transformation rules.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9987242817878723}, {"text": "grammar code transformation", "start_pos": 217, "end_pos": 244, "type": "TASK", "confidence": 0.6321839094161987}]}, {"text": "It is not clear, in particular, that the rules for computing semantic types for verbs are well enough motivated linguistically or that the LDOCE lexicographers were sensitive enough to the different transformational potential of the various classes of verbs to make a rule such as our one for Object Raising viable.", "labels": [], "entities": [{"text": "Object Raising", "start_pos": 293, "end_pos": 307, "type": "TASK", "confidence": 0.9038879871368408}]}, {"text": "We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in and.", "labels": [], "entities": [{"text": "classification of verbs into semantic types", "start_pos": 14, "end_pos": 57, "type": "TASK", "confidence": 0.8120188017686208}]}, {"text": "gives the number of verbs classified under each category by these authors and the number successfully classified into the same categories by the system.", "labels": [], "entities": []}, {"text": "The overall error rate of the system was 14%; however, as the table illustrates, the rules discussed above classify verbs into Subject Raising, Subject Equi and   Object Equi very successfully.", "labels": [], "entities": [{"text": "error rate", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9840790033340454}, {"text": "Subject Raising", "start_pos": 127, "end_pos": 142, "type": "TASK", "confidence": 0.7186122834682465}]}, {"text": "The two Subject Raising verbs which were not so classified by the system were come about and turnout.", "labels": [], "entities": [{"text": "Subject Raising verbs", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.8979452053705851}, {"text": "turnout", "start_pos": 93, "end_pos": 100, "type": "METRIC", "confidence": 0.986045777797699}]}, {"text": "Come about is coded 15 in LDOCE, but is not given any word qualifier; turnout is not given any 15 code.", "labels": [], "entities": [{"text": "Come", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.817939043045044}, {"text": "LDOCE", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.6625314950942993}, {"text": "turnout", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9273221492767334}]}, {"text": "These are clear examples of omissions on the part of the Longman lexicographers, rather than of failure of the rule.", "labels": [], "entities": []}, {"text": "Similarly, trust is not recognised as an Object Equi verb, because its dictionary entry does not contain a V3 code; this must bean omission, given the grammaticality of (6) I trust him to do the job.", "labels": [], "entities": []}, {"text": "Prefer is misclassified as Object Raising, rather than as Object Equi, because the relevant code field contains a T5 code, as well as a V3 code.", "labels": [], "entities": [{"text": "Prefer", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8384965658187866}, {"text": "Object Raising", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7620873749256134}]}, {"text": "The T5 code is marked as 'rare', and the occurrence of prefer with a tensed sentential complement, as opposed to with an infinitive, is certainly marginal: This example also highlights a deficiency in the LDOCE coding system since prefer occurs much more naturally with a sentential complement if it collocates with a modal such as \"would\".", "labels": [], "entities": []}, {"text": "This deficiency is rectified in the verb classification system employed by in the Brandeis verb catalogue.", "labels": [], "entities": [{"text": "verb classification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.6957125067710876}, {"text": "Brandeis verb catalogue", "start_pos": 82, "end_pos": 105, "type": "DATASET", "confidence": 0.8230959375699362}]}, {"text": "The main source of error comes from the misclassification of Object Raising into Object Equi verbs.", "labels": [], "entities": [{"text": "Object Raising into Object Equi verbs", "start_pos": 61, "end_pos": 98, "type": "TASK", "confidence": 0.7979699472586314}]}, {"text": "Arguably, these errors also derive mostly from errors in the dictionary, rather than a defect of the rule.", "labels": [], "entities": []}, {"text": "66% of the Object Raising verbs were misclassified as Object Equi verbs, because the cooccurrence of the T5 and V (2, 3, or 4) codes in the same code fields, as predicted by the Object Raising rule above, was not confirmed by LDOCE.", "labels": [], "entities": [{"text": "Object Raising verbs", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.8306963046391805}, {"text": "Object Raising", "start_pos": 178, "end_pos": 192, "type": "TASK", "confidence": 0.7789633870124817}, {"text": "LDOCE", "start_pos": 226, "end_pos": 231, "type": "DATASET", "confidence": 0.9315175414085388}]}, {"text": "All the 14 verbs misclassified contain V codes and 10 of these also contain T5 codes.", "labels": [], "entities": []}, {"text": "However, the Longman lexicographers typically define two different word senses, one of which is marked (perhaps among other codes) T5 and the other with a V code.", "labels": [], "entities": []}], "tableCaptions": []}