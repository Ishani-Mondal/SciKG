{"title": [{"text": "Using Corpus Statistics and WordNet Relations for Sense Identification", "labels": [], "entities": [{"text": "Corpus Statistics", "start_pos": 6, "end_pos": 23, "type": "DATASET", "confidence": 0.7873281836509705}, {"text": "Sense Identification", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8041599988937378}]}], "abstractContent": [{"text": "Corpus-based approaches to word sense identification have flexibility and generality but suffer from a knowledge acquisition bottleneck.", "labels": [], "entities": [{"text": "word sense identification", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8010179400444031}]}, {"text": "We show how knowledge-based techniques can be used to open the bottleneck by automatically locating training corpora.", "labels": [], "entities": []}, {"text": "We describe a statistical classifier that combines topical context with local cues to ident~y a word sense.", "labels": [], "entities": []}, {"text": "The classifier is used to disambiguate a noun, a verb, and an adjective.", "labels": [], "entities": []}, {"text": "A knowledge base in the form of WordNet's lexical relations is used to automatically locate training examples in a general text corpus.", "labels": [], "entities": []}, {"text": "Test results are compared with those from manually tagged training examples.", "labels": [], "entities": []}], "introductionContent": [{"text": "An impressive array of statistical methods have been developed for word sense identification.", "labels": [], "entities": [{"text": "word sense identification", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.8605740269025167}]}, {"text": "They range from dictionary-based approaches that rely on definitions) to corpus-based approaches that use only word cooccurrence frequencies extracted from large textual corpora.", "labels": [], "entities": []}, {"text": "We have drawn on these two traditions, using corpus-based co-occurrence and the lexical knowledge base that is embodied in the WordNet lexicon.", "labels": [], "entities": [{"text": "WordNet lexicon", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.9519577622413635}]}, {"text": "The two traditions complement each other.", "labels": [], "entities": []}, {"text": "Corpus-based approaches have the advantage of being generally applicable to new texts, domains, and corpora without needing costly and perhaps error-prone parsing or semantic analysis.", "labels": [], "entities": []}, {"text": "They require only training corpora in which the sense distinctions have been marked, but therein lies their weakness.", "labels": [], "entities": []}, {"text": "Obtaining training materials for statistical methods is costly and timeconsuming--it is a \"knowledge acquisition bottleneck\".", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 91, "end_pos": 112, "type": "TASK", "confidence": 0.7685854434967041}]}, {"text": "To open this bottleneck, we use WordNet's lexical relations to locate unsupervised training examples.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.9188989996910095}]}, {"text": "Section 2 describes a statistical classifier, TLC (Topical/Local Classifier), that uses topical context (the open-class words that co-occur with a particular sense), local context (the open-and closed-class items that occur within a small window around a word), or a combination of the two.", "labels": [], "entities": []}, {"text": "The results of combining the two types of context to disambiguate a noun (line), a verb (serve), and an adjective (hard) are presented.", "labels": [], "entities": []}, {"text": "The following questions are discussed: When is topical context superior to local context (and vice versa)?", "labels": [], "entities": []}, {"text": "Is their combination superior to either type alone?", "labels": [], "entities": []}, {"text": "Do the answers to these questions depend on the size of the training?", "labels": [], "entities": []}, {"text": "Do they depend on the syntactic category of the target?", "labels": [], "entities": []}, {"text": "Manually tagged training materials were used in the development of TLC and the experiments in Section 2.", "labels": [], "entities": [{"text": "TLC", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9551748037338257}]}, {"text": "The Cognitive Science Laboratory at Princeton University, with support from NSF-ARPA, is producing textual corpora that can be used in developing and evaluating automatic methods for disambiguation.", "labels": [], "entities": []}, {"text": "Examples of the different meanings of one thousand common, polysemous, open-class English words are being manually tagged.", "labels": [], "entities": []}, {"text": "The results of this effort will be a useful resource for training statistical classifiers, but what about the next thousand polysemous words, and the next?", "labels": [], "entities": []}, {"text": "In order to identify senses of these words, it will be necessary to learn how to harvest training examples automatically.", "labels": [], "entities": []}, {"text": "Section 3 describes WordNet's lexical relations and the role that monosemous \"relatives\" of polysemous words can play in creating unsupervised training materials.", "labels": [], "entities": []}, {"text": "TLC is trained with automatically extracted examples, its performance is compared with that obtained from manually tagged training materials.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}