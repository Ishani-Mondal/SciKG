{"title": [], "abstractContent": [{"text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering.", "labels": [], "entities": [{"text": "context-group discrimination", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.7338824719190598}]}, {"text": "Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word.", "labels": [], "entities": []}, {"text": "Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity.", "labels": [], "entities": []}, {"text": "Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur within turn occur with similar words in a training corpus.", "labels": [], "entities": []}, {"text": "The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources.", "labels": [], "entities": []}, {"text": "The paper demonstrates good performance of context-group discrimination fora sample of natural and artificial ambiguous words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation is the task of assigning sense labels to occurrences of an ambiguous word.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.676778644323349}, {"text": "assigning sense labels to occurrences of an ambiguous word", "start_pos": 41, "end_pos": 99, "type": "TASK", "confidence": 0.5219397015041776}]}, {"text": "This problem can be divided into two subproblems: sense discrimination and sense labeling.", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7211379557847977}, {"text": "sense labeling", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7308658361434937}]}, {"text": "Sense discrimination divides the occurrences of a word into a number of classes by determining for any two occurrences whether they belong to the same sense or not.", "labels": [], "entities": [{"text": "Sense discrimination", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.779247522354126}]}, {"text": "Sense labeling assigns a sense to each class, and, in combination with sense discrimination, to each occurrence of the ambiguous word.", "labels": [], "entities": [{"text": "Sense labeling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7905497550964355}]}, {"text": "This view of disambiguation as a two-stage process may not be completely general (for example, it may not be appropriate for the iterative process by which a lexicographer arrives at the sense divisions of a dictionary entry), but it seems applicable to most work on disambiguation in computational linguistics.", "labels": [], "entities": []}, {"text": "In this paper, we will address the problem of sense discrimination as defined above.", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7283188253641129}]}, {"text": "That is, we will not be concerned with the sense-labeling component of word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.6870361963907877}]}, {"text": "Word sense discrimination is easier than full disambiguation since we need only determine which occurrences have the same meaning and not what the meaning actually is.", "labels": [], "entities": [{"text": "Word sense discrimination", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7513715326786041}, {"text": "full disambiguation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7200330495834351}]}, {"text": "Focusing solely on word sense discrimination also liberates us of a serious constraint common to other work on word sense disambiguation.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.7099147240320841}, {"text": "word sense disambiguation", "start_pos": 111, "end_pos": 136, "type": "TASK", "confidence": 0.6794650157292684}]}, {"text": "If sense labeling is part of the task, an outside source of knowledge is necessary to define the senses.", "labels": [], "entities": [{"text": "sense labeling", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.7151188254356384}]}, {"text": "Regardless of whether it takes the form of dictionaries, thesauri, bilingual corpora (, or hand-labeled training sets, providing information for sense definitions can be a considerable burden.", "labels": [], "entities": []}, {"text": "What makes our approach unique is that, since we narrow the problem to sense discrimination, we can dispense of an outside source of knowledge for defining senses.", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.7608717978000641}]}, {"text": "We therefore call our approach automatic word sense discrimination, since we do not require manually constructed sources of knowledge.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7391104400157928}]}, {"text": "In many applications, word sense disambiguation must both discriminate and label occurrences; for example, in order to find the correct translation of an ambiguous word in machine translation or the right pronunciation in a text-to-speech system.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.759984532992045}]}, {"text": "The application of interest to us is information access, i.e., making sense of and finding information in large text databases.", "labels": [], "entities": [{"text": "information access", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7839462757110596}]}, {"text": "For many problems in information access, it is sufficient to solve the discrimination problem only.", "labels": [], "entities": [{"text": "information access", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8204923272132874}]}, {"text": "In one study, we measured document-query similarity based on word senses rather than words and achieved a considerable improvement in ranking relevant documents ahead of nonrelevant documents (.", "labels": [], "entities": []}, {"text": "Since the measurement of similarity is a systeminternal process, no reference to externally defined senses need be made.", "labels": [], "entities": []}, {"text": "Another potentially beneficial application of word sense discrimination in information access is the design of interfaces that take account of ambiguity.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6709984441598257}]}, {"text": "If a user enters a query that contains an ambiguous word, a system capable of discrimination can give examples of the different senses of the word in the text database.", "labels": [], "entities": []}, {"text": "The user can then decide which sense was intended and only documents with the intended sense would be retrieved.", "labels": [], "entities": []}, {"text": "Again, a reference to external sense definitions is not required for this task.", "labels": [], "entities": []}, {"text": "The algorithm we propose in this paper is context-group discrimination.", "labels": [], "entities": [{"text": "context-group discrimination", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.7085154205560684}]}, {"text": "1 Contextgroup discrimination groups the occurrences of an ambiguous word into clusters, where clusters consist of contextually similar occurrences.", "labels": [], "entities": [{"text": "Contextgroup discrimination", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.8338906764984131}]}, {"text": "Words, contexts, and clusters are represented in a high-dimensional, real-valued vector space.", "labels": [], "entities": []}, {"text": "Context vectors capture the information present in second-order co-occurrence.", "labels": [], "entities": []}, {"text": "Instead of forming a context representation from the words that the ambiguous word directly occurs within a particular context (first-order co-occurrence), we form the context representation from the words that these words in turn co-occur within the training corpus.", "labels": [], "entities": []}, {"text": "Second-order co-occurrence information is less sparse and more robust than first-order information.", "labels": [], "entities": []}, {"text": "In context-group discrimination, the context of each occurrence of the ambiguous word in the training corpus is represented as a context vector formed from secondorder co-occurrence information.", "labels": [], "entities": [{"text": "context-group discrimination", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.6987131088972092}]}, {"text": "The context vectors are then clustered into coherent groups such that occurrences judged similar according to second-order co-occurrence are assigned to the same cluster.", "labels": [], "entities": []}, {"text": "Clusters are represented by their centroids, the average of their elements.", "labels": [], "entities": []}, {"text": "An occurrence in a test text is disambiguated by computing the second-order representation of the relevant context, and assigning it to the cluster whose centroid is closest to that representation.", "labels": [], "entities": []}, {"text": "Since the choice of representation influences the formation of clusters, we will experiment with several representations in this paper, some involving a dimensionality reduction using singular value decomposition (SVD).", "labels": [], "entities": []}, {"text": "Context-group discrimination can be generalized to do a discrimination task that goes beyond the notion of sense that underlies many other contributions to the disambiguation literature.", "labels": [], "entities": [{"text": "Context-group discrimination", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.846003532409668}]}, {"text": "If the ambiguous word's occurrences are clustered into a large number n of clusters (e.g., n = 10), then the clusters can capture fine contextual distinctions.", "labels": [], "entities": []}, {"text": "Consider the example of space.", "labels": [], "entities": []}, {"text": "For a small number of clusters, only the senses \"outer space\" and \"limited extent in one, two, or three dimensions\" are separated.", "labels": [], "entities": []}, {"text": "If the word's occurrences are clustered into more clusters, then finer distinctions such as the one between \"office space\" and \"exhibition space\" are also discovered.", "labels": [], "entities": []}, {"text": "Note that differences between sense entries in dictionaries are often similarly fine-grained.", "labels": [], "entities": []}, {"text": "Even if the contextual distinctions captured by generalized context-group discrimination do not lineup perfectly with finer distinctions made in dictionaries, they still help characterize the contextual meaning in which the ambiguous word is used in a particular instance.", "labels": [], "entities": []}, {"text": "Such a characterization is useful for the information-access applications described above, among others.", "labels": [], "entities": []}, {"text": "The basic idea of context-group discrimination is to induce senses from contextual similarity.", "labels": [], "entities": [{"text": "context-group discrimination", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.7215909659862518}]}, {"text": "There is some evidence that contextual similarity also plays a crucial role inhuman semantic categorization.", "labels": [], "entities": []}, {"text": "found evidence in several experiments that humans determine the semantic similarity of words from the similarity of the contexts they are used in.", "labels": [], "entities": []}, {"text": "We hypothesize that, by extension, senses are also based on contextual similarity: a sense is a group of contextually similar occurrences of a word.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test context-group discrimination on the 10 natural ambiguous words that formed the test set in Schfitze (1992b) and on 10 artificial ambiguous words.", "labels": [], "entities": []}, {"text": "glosses the major senses of the 20 words.", "labels": [], "entities": []}, {"text": "Number of occurrences of test words in training and test set, percent rare senses in test set, baseline performance (all occurrences assigned to most frequent sense), and the two main senses of each of the 20 artificial and natural ambiguous words used in the experiment.", "labels": [], "entities": []}, {"text": "Artificial ambiguous words or pseudowords area convenient means of testing disambiguation algorithms.", "labels": [], "entities": []}, {"text": "It is time-consuming to hand-label a large number of instances of an ambiguous word for evaluating the performance of a disambiguation algorithm.", "labels": [], "entities": []}, {"text": "Pseudowords circumvent this need: Two or more words, e.g., banana and door, are conflated into anew type: banana~door.", "labels": [], "entities": []}, {"text": "All occurrences of either word in the corpus are then replaced by the new type.", "labels": [], "entities": []}, {"text": "It is easy to evaluate disambiguation performance for pseudowords since one can go back to the original text to decide whether a correct decision was made.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Results of disambiguation experiments. Rows give total accuracy for each word (\"t.') as well  as accuracy for the two senses separately (\"$1\", \"$2\"). The average in the bottom row is an  average over total (\"t.') accuracy numbers only. Columns describe experimental conditions  and the mean (\"]~\") and standard deviation (\"a\") of", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9818520545959473}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9991292357444763}, {"text": "accuracy", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.9840303659439087}, {"text": "standard deviation (\"a\")", "start_pos": 312, "end_pos": 336, "type": "METRIC", "confidence": 0.9317255735397338}]}, {"text": " Table 8  Correlation coefficients of three words before and after SVD  dimensionality reduction.", "labels": [], "entities": [{"text": "SVD  dimensionality reduction", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.6349286437034607}]}]}