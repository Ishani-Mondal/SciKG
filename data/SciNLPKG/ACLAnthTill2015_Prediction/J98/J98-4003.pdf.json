{"title": [], "abstractContent": [{"text": "It is challenging to translate names and technical terms across languages with different alphabets and sound inventories.", "labels": [], "entities": [{"text": "translate names and technical terms", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.7848356366157532}]}, {"text": "These items are commonly transliterated, i.e., replaced with approximate phonetic equivalents.", "labels": [], "entities": []}, {"text": "For example, \"computer\" in English comes out as \"konpyuutaa\" in Japanese.", "labels": [], "entities": []}, {"text": "Translating such items from Japanese back to English is even more challenging, and of practical interest, as transliterated items makeup the bulk of text phrases not found in bilingual dictionaries.", "labels": [], "entities": []}, {"text": "We describe and evaluate a method for performing backwards transliterations by machine.", "labels": [], "entities": []}, {"text": "This method uses a generative model, incorporating several distinct stages in the transliteration process.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the most frequent problems translators must deal with is translating proper names and technical terms.", "labels": [], "entities": [{"text": "translators", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.9729915857315063}, {"text": "translating proper names and technical terms", "start_pos": 64, "end_pos": 108, "type": "TASK", "confidence": 0.8032110035419464}]}, {"text": "For language pairs like Spanish/English, this presents no great challenge: a phrase like Antonio Gil usually gets translated as Antonio Gil.", "labels": [], "entities": []}, {"text": "However, the situation is more complicated for language pairs that employ very different alphabets and sound systems, such as Japanese/English and Arabic/English.", "labels": [], "entities": []}, {"text": "Phonetic translation across these pairs is called transliteration.", "labels": [], "entities": [{"text": "Phonetic translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8154266178607941}]}, {"text": "We will look at Japanese/English transliteration in this article.", "labels": [], "entities": [{"text": "Japanese/English transliteration", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.5468991622328758}]}, {"text": "Japanese frequently imports vocabulary from other languages, primarily (but not exclusively) from English.", "labels": [], "entities": []}, {"text": "It has a special phonetic alphabet called katakana, which is used primarily (but not exclusively) to write down foreign names and loanwords.", "labels": [], "entities": []}, {"text": "The katakana symbols are shown in, with their Japanese pronunciations.", "labels": [], "entities": []}, {"text": "The two symbols shown in the lower right corner ( --, 7 ) are used to lengthen any Japanese vowel or consonant.", "labels": [], "entities": []}, {"text": "To write a word like golfbag in katakana, some compromises must be made.", "labels": [], "entities": []}, {"text": "For example, Japanese has no distinct Land R sounds: the two English sounds collapse onto the same Japanese sound.", "labels": [], "entities": []}, {"text": "A similar compromise must be struck for English H and F.", "labels": [], "entities": [{"text": "English H", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.8234758079051971}]}, {"text": "Also, Japanese generally uses an alternating consonant-vowel structure, making it impossible to pronounce LFB without intervening vowels.", "labels": [], "entities": []}, {"text": "Katakana writing is a syllabary rather than an alphabet--there is one symbol for ga (~\"), another for gi ( 4 ~\" ), another for gu ( Y\" ), etc.", "labels": [], "entities": []}, {"text": "So the way to write golfbag in katakana is ~',,t, 7 ~,< 7 Y', roughly pronounced go-ru-hu-ba-ggu.", "labels": [], "entities": []}, {"text": "Here area few more examples:", "labels": [], "entities": []}], "datasetContent": [{"text": "We have performed two large-scale experiments, one using a full-language P(w) model, and one using a personal name language model.", "labels": [], "entities": []}, {"text": "In the first experiment, we extracted 1,449 unique katakana phrases from a corpus of 100 short news articles.", "labels": [], "entities": []}, {"text": "Of these, 222 were missing from an on-line 100,000-entry bilingual dictionary.", "labels": [], "entities": []}, {"text": "We back-transliterated these 222 phrases.", "labels": [], "entities": []}, {"text": "Many of the translations are perfect: technical program, sex scandal, omaha beach, new york times, ramon diaz.", "labels": [], "entities": []}, {"text": "Others are close: tanya harding, nickel simpson, danger washington, world cap.", "labels": [], "entities": [{"text": "danger washington", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.6168520450592041}]}, {"text": "Some miss the mark: nancy care again, plus occur, patriot miss real.", "labels": [], "entities": []}, {"text": "4 While it is difficult to judge overall accuracy--some of the phrases are onomatopoetic, and others are simply too hard even for good human translators--it is easier to identify system weaknesses, and most of these lie in the P(w) model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9963487386703491}]}, {"text": "For example, nancy kerrigan should be preferred over nancy care again.", "labels": [], "entities": []}, {"text": "Ina second experiment, we took (non-OCR) katakana versions of the names of 100 U.S. politicians, e.g.: -Y~ y \u2022 7\"~-(jyon.buroo), T~I,,~yx \u2022 :9\"-v.;, }-(aruhonsu. damatto), and -v 4 ~ \u2022 Y V 4 Y (maiku. dewain).", "labels": [], "entities": []}, {"text": "We back-transliterated these by machine and asked four human subjects to do the same.", "labels": [], "entities": []}, {"text": "These subjects were native English speakers and news-aware; we gave them brief instructions.", "labels": [], "entities": []}, {"text": "The results were as in.", "labels": [], "entities": []}, {"text": "There is room for improvement on both sides.", "labels": [], "entities": []}, {"text": "Being English speakers, the human subjects were good at English name spelling and U.S. politics, but not at Japanese phonetics.", "labels": [], "entities": [{"text": "English name spelling", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.6658414701620737}]}, {"text": "A native Japanese speaker might be expert at the latter but not the former.", "labels": [], "entities": []}, {"text": "People who are expert in all of these areas, however, are rare.", "labels": [], "entities": []}, {"text": "On the automatic side, many errors can be corrected.", "labels": [], "entities": []}, {"text": "A first-name/last-name model would rank richard bryan more highly than richard brian.", "labels": [], "entities": []}, {"text": "A bigram model would prefer orren hatch over olin hatch.", "labels": [], "entities": []}, {"text": "Other errors are due to unigram training problems, or more rarely, incorrect or brittle phonetic models.", "labels": [], "entities": []}, {"text": "For example, Long occurs much more often than Ron in newspaper text, and our word selection does not exclude phrases like Long Island.", "labels": [], "entities": [{"text": "Long", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9785057902336121}, {"text": "Long Island", "start_pos": 122, "end_pos": 133, "type": "DATASET", "confidence": 0.932928740978241}]}, {"text": "So we get long wyden instead of ron wyden.", "labels": [], "entities": []}, {"text": "One way to fix these problems is by manually changing unigram probabilities.", "labels": [], "entities": []}, {"text": "Reducing P(long) by a factor often solves the problem while maintaining a high score for P(long I rongu).", "labels": [], "entities": []}, {"text": "Despite these problems, the machine's performance is impressive.", "labels": [], "entities": []}, {"text": "When word separators (o) are removed from the katakana phrases, rendering the task exceedingly difficult for people, the machine's performance is unchanged.", "labels": [], "entities": []}, {"text": "In other words, it offers the same top-scoring translations whether or not the separators are present; however, their presence significantly cuts down on the number of alternatives considered, improving efficiency.", "labels": [], "entities": []}, {"text": "When we use OCR, 7% of katakana tokens are misrecognized, affecting 50% of test strings, but translation accuracy only drops from 64% to 52%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9309960603713989}]}], "tableCaptions": []}