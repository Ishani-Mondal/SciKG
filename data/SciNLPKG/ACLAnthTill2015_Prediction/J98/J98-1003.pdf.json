{"title": [{"text": "Topical Clustering of MRD Senses Based on Information Retrieval Techniques", "labels": [], "entities": [{"text": "MRD Senses", "start_pos": 22, "end_pos": 32, "type": "TASK", "confidence": 0.7817060053348541}, {"text": "Information Retrieval", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.695969894528389}]}], "abstractContent": [{"text": "This paper describes a heuristic approach capable of automatically clustering senses in a machine-readable dictionary (MRD).", "labels": [], "entities": [{"text": "clustering senses in a machine-readable dictionary (MRD)", "start_pos": 67, "end_pos": 123, "type": "TASK", "confidence": 0.5877786642975278}]}, {"text": "Including these clusters in the MRD-based lexical database offers several positive benefits for word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 96, "end_pos": 127, "type": "TASK", "confidence": 0.8139360447724661}]}, {"text": "First, the clusters can be used as a coarser sense division, so unnecessarily fine sense distinction can be avoided.", "labels": [], "entities": []}, {"text": "The clustered entries in the MRD can also be used as materials for supervised training to develop a WSD system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.9823809862136841}]}, {"text": "Furthermore, if the algorithm is run on several MRDs, the clusters also provide a means of linking different senses across multiple MRDs to create an integrated lexical database.", "labels": [], "entities": []}, {"text": "An implementation of the method for clustering definition sentences in the Longman Dictionary of Contemporary English (LDOCE) is described.", "labels": [], "entities": [{"text": "clustering definition sentences", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.8956354260444641}, {"text": "Longman Dictionary of Contemporary English (LDOCE)", "start_pos": 75, "end_pos": 125, "type": "DATASET", "confidence": 0.9318464025855064}]}, {"text": "To this end, the topical word lists and topical cross-references in the Longman Lexicon of Contemporary English (LLOCE) are used.", "labels": [], "entities": [{"text": "Longman Lexicon of Contemporary English (LLOCE)", "start_pos": 72, "end_pos": 119, "type": "DATASET", "confidence": 0.9167641773819923}]}, {"text": "Nearly half of the senses in the LDOCE can be linked precisely to a relevant LLOCE topic using a simple heuristic.", "labels": [], "entities": []}, {"text": "With the definitions of senses linked to the same topic viewed as a document, topical clustering of the MRD senses bears a striking resemblance to retrieval of relevant documents fora given query in information retrieval (IR) research.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 199, "end_pos": 225, "type": "TASK", "confidence": 0.767231285572052}]}, {"text": "Relatively well-established IR techniques of weighting terms and ranking document relevancy are applied to find the topical clusters that are most relevant to the definition of each MRD sense.", "labels": [], "entities": [{"text": "IR", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9450886845588684}, {"text": "MRD sense", "start_pos": 182, "end_pos": 191, "type": "TASK", "confidence": 0.8992020487785339}]}, {"text": "Finally, we describe an implemented version of the algorithms for the LDOCE and the LLOCE and assess the performance of the proposed approach in a series of experiments and evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (), machine translation (, and speech synthesis.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8014051765203476}, {"text": "information retrieval", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.7833299040794373}, {"text": "machine translation", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.8358075022697449}, {"text": "speech synthesis", "start_pos": 173, "end_pos": 189, "type": "TASK", "confidence": 0.744482696056366}]}, {"text": "WSD has received increasing attention in recent literature on computational linguistics).", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6794160008430481}]}, {"text": "Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates.", "labels": [], "entities": [{"text": "WSD", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9909913539886475}]}, {"text": "It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part of speech, and valency.", "labels": [], "entities": []}, {"text": "Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictionaries, (2) automatic or hand-crafted clusters of dictionary senses, (3) thesaurus categories, (4) translation in another language, (5) automatically induced clusters with sublexical representation), and (6) hand-crafted lexicons.", "labels": [], "entities": [{"text": "word sense division", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7768195668856303}, {"text": "WSD", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9668483138084412}]}, {"text": "This paper is motivated by the observation that directly using dictionary senses for sense division offers several advantages.", "labels": [], "entities": [{"text": "sense division", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.7685911655426025}]}, {"text": "Sense distinction according to a dictionary is readily available from machine-readable dictionaries (MRDs) such as the Longman Dictionary of Contemporary English (LDOCE).", "labels": [], "entities": [{"text": "Sense distinction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.738457977771759}, {"text": "Longman Dictionary of Contemporary English (LDOCE)", "start_pos": 119, "end_pos": 169, "type": "DATASET", "confidence": 0.8995007202029228}]}, {"text": "A dictionary such as the LDOCE has broad coverage of word senses, useful for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9760663509368896}]}, {"text": "Furthermore, indicative words and concepts for each sense are directly available in numbered definitions and examples.", "labels": [], "entities": []}, {"text": "describes the first MRD-based WSD method that relies on the extent of overlap between words in a dictionary definition and words in the local context of the word to be disambiguated.", "labels": [], "entities": [{"text": "MRD-based WSD", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.7763007283210754}]}, {"text": "The author reports that WSD performance ranges from 50% to 70% and his method works well for senses strongly associated with specific collocations, such as ice-cream cone and pine cone.", "labels": [], "entities": [{"text": "WSD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9720692038536072}]}, {"text": "Unfortunately, using MRDs as the knowledge source for sense division and disambiguation leads to some problems.", "labels": [], "entities": [{"text": "sense division", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.8067878484725952}]}, {"text": "notes that the dictionary dichotomy of senses is inadequate for WSD, because it is defined along grammatical, not semantic, lines.", "labels": [], "entities": [{"text": "WSD", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9440863132476807}]}, {"text": "Furthermore, as pointed out in, the sense division in an MRD is frequently too fine-grained for the purpose of WSD.", "labels": [], "entities": [{"text": "MRD", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.8210568428039551}, {"text": "WSD", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.9402526617050171}]}, {"text": "A WSD system based on dictionary senses often faces unnecessary and difficult \"forced-choices.\"", "labels": [], "entities": [{"text": "WSD", "start_pos": 2, "end_pos": 5, "type": "TASK", "confidence": 0.9680985808372498}]}, {"text": "Dolan proposes a heuristic algorithm for forming unlabeled clusters of closely related senses in the LDOCE to eliminate distinctions that are unnecessarily fine for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.8399470448493958}]}, {"text": "Regrettably, the proposed algorithm was only described in a few examples and was not developed further.", "labels": [], "entities": []}, {"text": "Lacking an automatic method, recent WSD works) still resort to human intervention to identify and group closely related senses in an MRD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9050384759902954}]}, {"text": "Using thesaurus categories directly as a coarse sense division may seem to be a viable alternative.", "labels": [], "entities": []}, {"text": "However, typical thesauri, such as Roget's Thesaurus, suffer sense gaps and, occasionally, are too fine-grained.", "labels": [], "entities": [{"text": "Thesaurus", "start_pos": 43, "end_pos": 52, "type": "DATASET", "confidence": 0.785559356212616}]}, {"text": "reports that there are uses not listed in Roget's for 3 of 12 nouns in his WSD study, while uses which a native speaker might consider as a single sense are often encoded in several Roget's categories.", "labels": [], "entities": [{"text": "WSD", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.8618749380111694}]}, {"text": "As an alternative approach to word sense division, this paper presents an algorithm capable of automatically clustering senses in an MRD based on topical information in a thesaurus.", "labels": [], "entities": [{"text": "word sense division", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7932290037473043}]}, {"text": "We refer to the algorithm as TopSense (Topical clustering of Senses).", "labels": [], "entities": []}, {"text": "The current implementation of TopSense uses the topical information in the Longman Lexicon of Contemporary English (LLOCE)) to cluster LDOCE senses.", "labels": [], "entities": [{"text": "Longman Lexicon of Contemporary English (LLOCE))", "start_pos": 75, "end_pos": 123, "type": "DATASET", "confidence": 0.8857521936297417}]}, {"text": "The method makes use of none of the idiosyncratic information in either the LLOCE or the LDOCE.", "labels": [], "entities": []}, {"text": "Therefore, the TopSense algorithm is quite general and is expected to produce comparable results for other MRDs and thesauri.", "labels": [], "entities": [{"text": "MRDs", "start_pos": 107, "end_pos": 111, "type": "TASK", "confidence": 0.9456071853637695}]}, {"text": "TopSense is tested on 20 words extensively investigated in recent WSD literature.", "labels": [], "entities": [{"text": "WSD", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9514460563659668}]}, {"text": "According to the experimental results, the automatically derived topical clusters can be used to good effect without any human intervention as a coarse sense division for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 171, "end_pos": 174, "type": "TASK", "confidence": 0.9254608154296875}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 starts outwith a description of the MRDs and thesauri used in the computational lexicography and WSD literature, followed by some observations to justify the topic-based approach to word sense division.", "labels": [], "entities": [{"text": "WSD", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.7359422445297241}, {"text": "word sense division", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.7885134617487589}]}, {"text": "Section 3 describes the LinkSense algorithm for linking senses between an MRD and a thesaurus.", "labels": [], "entities": []}, {"text": "Section 4 shows how the TopSense algorithm based on the IR model maybe used to cluster the senses in an MRD.", "labels": [], "entities": []}, {"text": "Examples are given in both Sections 3 and 4 to illustrate how the algorithms work.", "labels": [], "entities": []}, {"text": "Section 4 also describes an implementation of the algorithms for the LDOCE and the LLOCE and reports the evaluation results for both algorithms based on a 20-word test set.", "labels": [], "entities": []}, {"text": "Section 5 analyzes the experimental results to demonstrate the strengths and limitations of the method.", "labels": [], "entities": []}, {"text": "The implication of TopSense to WSD and other issues related to lexical semantics are also touched upon.", "labels": [], "entities": []}, {"text": "Section 6 compares the proposed method with other approaches in the computational linguistics literature.", "labels": [], "entities": []}, {"text": "Finally, conclusions are made and directions for further research are pointed out in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "An experiment involving the LDOCE and the LLOCE was carried out to assess the effectiveness of the LinkSense algorithm (see).", "labels": [], "entities": [{"text": "LLOCE", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.8956663012504578}]}, {"text": "To evaluate the performance of algorithms, we define the ratios of applicability A and precision P as follows: #(all labeled definitions) A = # (all definitions)  An experiment was conducted to assess the effectiveness of the LinkSense and TopSense algorithms.", "labels": [], "entities": [{"text": "precision P", "start_pos": 87, "end_pos": 98, "type": "METRIC", "confidence": 0.9729403853416443}]}, {"text": "The experimental results show that the LinkSense links nearly 11,045 of some 39,000 nominal LDOCE senses to a topical sense in the LLOCE.", "labels": [], "entities": []}, {"text": "Evaluation based on a 20-word test set shows that, on the average, 50% of the LDOCE instances linked to an LLOCE sense, and, of these links, 95% are correct.", "labels": [], "entities": []}, {"text": "These linked LDOCE senses establish 129 topical clusters, one for each LLOCE topic.", "labels": [], "entities": []}, {"text": "When the proposed LinkSense algorithm is applied to assign sense definitions in LDOCE with relevant topical labels, it obtains very high precision but low coverage.", "labels": [], "entities": [{"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9962978959083557}]}, {"text": "TopSense is design specifically to improve coverage by providing a reliable method for clustering MRD entries left unlabeled by LinkSense.", "labels": [], "entities": [{"text": "clustering MRD entries left unlabeled by LinkSense", "start_pos": 87, "end_pos": 137, "type": "TASK", "confidence": 0.7836859737123761}]}, {"text": "3 A document of defining terms is then formed from MRD senses in each of these clusters.", "labels": [], "entities": []}, {"text": "Subsequently, TopSense runs on the nominal LDOCE sense, attempting to merge it to one of the topical clusters.", "labels": [], "entities": []}, {"text": "The thresholds for LinkSense and TopSense are selected according to random sampiing from definitions in the LDOCE.", "labels": [], "entities": [{"text": "LDOCE", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.9363910555839539}]}, {"text": "Assume 0 is the threshold and 0 is an estimator of 8, and B is the bound on the error of estimation.", "labels": [], "entities": []}, {"text": "The problem is to limit the error of estimation below B with probability 1 -o~.", "labels": [], "entities": [{"text": "error", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9847074151039124}, {"text": "estimation", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.7947100400924683}]}, {"text": "This can be stated as P(I~ -~1 < B) = 1 -o~, since the number of definitions is large enough to permit estimation of population parameter 8.", "labels": [], "entities": [{"text": "P(I~ -~1 < B)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.745149678654141}]}, {"text": "Considering Central Limit Theory, the parameter ~ tends to have approximately a normal distribution.", "labels": [], "entities": []}, {"text": "We will usually select B = 2cr6, and hence 1 -o~ will be approximately 0.95 for normal distribution.", "labels": [], "entities": [{"text": "B", "start_pos": 23, "end_pos": 24, "type": "METRIC", "confidence": 0.9892130494117737}]}, {"text": "To estimate ~, a simple random sample of 100 definitions (about 350 senses) is used.", "labels": [], "entities": []}, {"text": "Thus, the estimate of threshold is 0.12 for LinkSense.", "labels": [], "entities": [{"text": "LinkSense", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.9368652701377869}]}, {"text": "Similar estimation was done for the threshold used in TopSense.", "labels": [], "entities": [{"text": "estimation", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9770442843437195}, {"text": "TopSense", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9397133588790894}]}, {"text": "Evaluation was done on a set of 20 polysemous words that have been used in recent literature on WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9703079462051392}]}, {"text": "These words focus on the more difficult cases of sense ambiguity, as can be seen by the degree of ambiguity as recorded in the LDOCE.", "labels": [], "entities": [{"text": "LDOCE", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.915222704410553}]}, {"text": "These words have 5.3 senses on the average, as opposed to the average of 2.6 senses for all words in the LDOCE.", "labels": [], "entities": [{"text": "LDOCE", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.913653552532196}]}, {"text": "The evaluation is based on the relevancy assessment by two human judges.", "labels": [], "entities": []}, {"text": "The Appendix gives a sense-by-sense rundown of all senses tested and evaluated.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9475524425506592}]}, {"text": "summarizes the word-by-word applicability and precision of TopSense.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9991796612739563}]}, {"text": "Although not all senses are clustered and not all clustered senses are correct, applicability and precision are rather high, which seems to indicate that the resulting sense division is directly usable in WSD, and thus, eliminates the need for human intervention.", "labels": [], "entities": [{"text": "applicability", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.9873749017715454}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9992759823799133}, {"text": "WSD", "start_pos": 205, "end_pos": 208, "type": "TASK", "confidence": 0.9643504619598389}]}], "tableCaptions": []}