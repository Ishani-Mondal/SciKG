{"title": [{"text": "Book Reviews Memory and Context for Language Interpretation MEMORY AND CONTEXT FOR LANGUAGE INTERPRETATION (STUDIES IN NATURAL-LANGUAGE PROCESSING)", "labels": [], "entities": [{"text": "Language Interpretation MEMORY", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.7619558672110239}, {"text": "CONTEXT FOR LANGUAGE", "start_pos": 71, "end_pos": 91, "type": "METRIC", "confidence": 0.696053683757782}, {"text": "INTERPRETATION", "start_pos": 92, "end_pos": 106, "type": "METRIC", "confidence": 0.5220632553100586}]}], "abstractContent": [{"text": "that the only objective of the book is description of linguistic phenomena.", "labels": [], "entities": []}, {"text": "It is difficult to imagine practical application of the theory in natural-language processing systems.", "labels": [], "entities": []}, {"text": "Although the book was not aimed at presenting practical applications, a short chapter on this topic could dispel the doubts of a reader studying this type of problem for the first time.", "labels": [], "entities": []}, {"text": "Furthermore, the addition of an index would have facilitated the reader in returning to certain issues or unmemorized definitions.", "labels": [], "entities": []}, {"text": "Still, this book is one of the more interesting recent publications on the application of logic in natural-language description.", "labels": [], "entities": [{"text": "natural-language description", "start_pos": 99, "end_pos": 127, "type": "TASK", "confidence": 0.7144325971603394}]}, {"text": "Reading it will inspire further research on the logical structure of natural language, and is highly recommended.", "labels": [], "entities": []}, {"text": "Leonard Bole is the editor of several collections of papers on various aspects of natural-language systems, including the recent Natural-language parsing systems (Springer-Verlag).", "labels": [], "entities": [{"text": "Natural-language parsing", "start_pos": 129, "end_pos": 153, "type": "TASK", "confidence": 0.7514721155166626}]}, {"text": "His address is: Instytut Podstaw Informatyka, Polskiej Aka-demii Nauk, This book is a reorganization of a 1983 doctoral thesis.", "labels": [], "entities": [{"text": "Polskiej Aka-demii Nauk", "start_pos": 46, "end_pos": 69, "type": "DATASET", "confidence": 0.7712564468383789}]}, {"text": "It seems little effort has been spent to take into account the impressive amount of research in text comprehension since 1983.", "labels": [], "entities": [{"text": "text comprehension", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7962975800037384}]}, {"text": "Indeed, the reference section lists only five post-1983 entries.", "labels": [], "entities": []}, {"text": "Nevertheless the book is very relevant to the field of computational linguistics: it constitutes an archetype of the assumptions, strategies, and limitations faced by anyone attempting to implement a text-processing tool.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7352088689804077}]}, {"text": "This relatively short book (188 pages, double-spaced) is divided into two parts.", "labels": [], "entities": []}, {"text": "The first, comprising four chapters, overviews the model, which is then detailed in the second part.", "labels": [], "entities": []}, {"text": "The first chapter introduces the basic assumptions and goals of the thesis; the research fo-cuses on memory mechanisms, not inferencing or reasoning.", "labels": [], "entities": []}, {"text": "The author states that the work is carried out in terms of automatic natural-language processing (NLP) and thus that he will avoid claims and suggestions about human language processing.", "labels": [], "entities": [{"text": "automatic natural-language processing (NLP)", "start_pos": 59, "end_pos": 102, "type": "TASK", "confidence": 0.6665709763765335}]}, {"text": "Indeed, the title is somewhat misleading: the use of the word \"memory\" in the dissertation has little to do with human memory.", "labels": [], "entities": []}, {"text": "In essence, the thesis describes marker-passing algorithms used to select between possible candidates for disam-biguation.", "labels": [], "entities": []}, {"text": "The algorithms search for candidates in a database and choose between them according to the current context, which simply constrains memory retrieval.", "labels": [], "entities": []}, {"text": "The system, called Capture, was designed not only for text processing but also to process collections of English paragraphs and produce an output incorpo-rable into a conventional database.", "labels": [], "entities": [{"text": "text processing", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.8048085570335388}]}, {"text": "The second chapter overviews the representational scheme and algorithms developed by the author.", "labels": [], "entities": []}, {"text": "The knowledge base is constructed out of two types of assertions: specializations (IS-A declarations) and correspondences , which take the form role C1 of owner D1 is a role-specialization of role C2 whose owner is D2.", "labels": [], "entities": []}, {"text": "These types of assertions can carry further information about the relationships between their arguments.", "labels": [], "entities": []}, {"text": "This information is encoded as a list of flags given as an additional argument to the assertion.", "labels": [], "entities": []}, {"text": "The author remarks that \"the motivation for the choice of flags that were defined for the memory formalism is simply that these seem to be useful, in practice, for stating information at the level of this kind of formalism\".", "labels": [], "entities": []}, {"text": "Context is represented by a collection of context factors, each of which contributes activation to a particular set of memory entities (i.e., to the \"objects\" referred to in the assertions).", "labels": [], "entities": []}, {"text": "There are seven major types of context factor, including recency, syntactic emphasis, deixis, and a priori subject area.", "labels": [], "entities": []}, {"text": "These are essentially static rules that define how activation is managed for each memory entity involved during comprehension.", "labels": [], "entities": []}, {"text": "The rules are applied for disambiguation and for defining the focus space; that is, the set of most \"activated\" memory entities.", "labels": [], "entities": []}, {"text": "In the remainder of the chapter, Alshawi discusses his standard marker-passing model.", "labels": [], "entities": []}, {"text": "The third chapter addresses the problem of interpretation.", "labels": [], "entities": []}, {"text": "The author tackles noun phrase (NP) reference interpretation, compound NPs, possessive NPs, with-PPs, and word-sense disambiguation.", "labels": [], "entities": [{"text": "noun phrase (NP) reference interpretation", "start_pos": 19, "end_pos": 60, "type": "TASK", "confidence": 0.656101678098951}, {"text": "word-sense disambiguation", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.7013136148452759}]}, {"text": "Conditionals, negation , and \"phenomena going beyond memory mech-anisms\" (e.g., modality and metaphor) are not handled.", "labels": [], "entities": []}, {"text": "The algorithms are simple to understand but often lack proper motivation.", "labels": [], "entities": []}, {"text": "In the fourth chapter, Alshawi discusses related research as of 1983.", "labels": [], "entities": []}, {"text": "In particular, the author acknowledges the strong influence of Fahlman's work on marker-passing, and of Grosz's notion of global focus.", "labels": [], "entities": []}, {"text": "The second part starts on page 76.", "labels": [], "entities": []}, {"text": "In the rest of the book, Alshawi details the ideas of the first part (see summary table, p.", "labels": [], "entities": []}, {"text": "94) and elaborates on the Capture feature that creates a relational database as the result of text processing.", "labels": [], "entities": []}, {"text": "The author concludes with a chapter on the complexity of techniques for efficient retrieval from a database, a topic too often ignored in NLP models.", "labels": [], "entities": []}, {"text": "I said above that this book is, in my opinion, an archetype of the NLP thesis in computational linguistics.", "labels": [], "entities": []}, {"text": "The first appendix, which lists some of the 30 short texts processed by Capture, confirms this: the examples", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}