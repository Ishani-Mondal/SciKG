{"title": [{"text": "Development and Evaluation of a Broad-Coverage Probabilistic Grammar of English-Language Computer Manuals", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an approach to grammar development where the task is decomposed into two separate subtasks.", "labels": [], "entities": [{"text": "grammar development", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8380304872989655}]}, {"text": "The first task is hnguistic, with the goal of producing a set of rules that have a large coverage (in the sense that the correct parse is among the proposed parses) on a bhnd test set of sentences.", "labels": [], "entities": []}, {"text": "The second task is statistical, with the goal of developing a model of the grammar which assigns maximum probability for the correct parse.", "labels": [], "entities": []}, {"text": "We give parsing results on text from computer manuals.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many language understanding systems and machine translation systems rely on a parser of English as the first step in processing an input sentence.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.7346979081630707}, {"text": "machine translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7668993473052979}]}, {"text": "The general impression maybe that parsers with broad coverage of English are readily available.", "labels": [], "entities": []}, {"text": "In an effort to gauge the state of the art in parsing, the authors conducted an experiment in Summer 1990 in which 35 sentences, all of length 13 words or less, were selected randomly from a several-millionword corpus of Associated Press news wire.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9737958908081055}, {"text": "Associated Press news wire", "start_pos": 221, "end_pos": 247, "type": "DATASET", "confidence": 0.8778490573167801}]}, {"text": "The sentences were parsed by four of the major large-coverage parsers for general English.", "labels": [], "entities": []}, {"text": "1 Each of the authors, working separately, scored 140 parses for correctness of constituent boundaries, constituent labels, and part-of-speech labels.", "labels": [], "entities": []}, {"text": "All that was required of parses was accuracy in delimiting and identifying obvious constituents such as noun phrases, prepositional phrases, and clauses, along with at least rough correctness in assigning part-of-speech labels, e.g. a noun could not be labelled as a verb.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.998610258102417}]}, {"text": "The tallies of each evaluator were compared, and were identical or very close in all cases.", "labels": [], "entities": []}, {"text": "The best-performing parser was correct for 60% of the sentences and the the remaining parsers were below 40%.", "labels": [], "entities": [{"text": "correct", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9833269715309143}]}, {"text": "More recently, in early 1992, the creator of another well-known system performed self-scoring on a similar task and reported 30% of input sentences as having been correctly parsed.", "labels": [], "entities": []}, {"text": "On the basis of the preceeding evidence it seems that the current state of the t At least one of the parties involved insisted that no performance results be made public.", "labels": [], "entities": []}, {"text": "Such reticence is widespread and understandable.", "labels": [], "entities": []}, {"text": "However, it is nonetheless important that performance norms be established for the field.", "labels": [], "entities": []}, {"text": "Some progress has been made in this direction.", "labels": [], "entities": []}, {"text": "art is far from being able to produce a robust parser of general English.", "labels": [], "entities": []}, {"text": "In order to breakthrough this bottleneck and begin making steady and quantifiable progress toward the goal of developing a highly accurate parser for general English, organization of the grammar-development process along scientific lines and the introduction of stochastic modelling techniques are necessary, in our view.", "labels": [], "entities": []}, {"text": "We have initiated a research program on these principles, which we describe in what follows.", "labels": [], "entities": []}, {"text": "An account of our overall method of attacking the problem is presented in Section 2.", "labels": [], "entities": []}, {"text": "The grammar involved is discussed in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 is concerned with the statistical modelling methods we employ.", "labels": [], "entities": []}, {"text": "Finally, in Section 5, we present our experimental results to date.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we will give a brief description of the procedures that we have adopted for parsing and training a probabilistic model for our grammar.", "labels": [], "entities": []}, {"text": "In parsing with the above grammar, it is necessary to have an efficient way of determining if, for example, a particular feature bundle A = (AI, A2,...,AN) can be the parent of a given production, some of whose features are expressed as variables.", "labels": [], "entities": []}, {"text": "As mentioned previously, we use the term unification to denote this matching procedure, and it is defined precisely in.", "labels": [], "entities": []}, {"text": "In practice, the unification operations are carried out very efficiently by representing bundles of features as bitstrings, and realizing unification in terms of logical bit operations in the programming language PL.8 which is similar to C.", "labels": [], "entities": []}, {"text": "We have developed our own tools to translate the rule templates and conditions into PL.8 programs.", "labels": [], "entities": []}, {"text": "A second operation that is required is to partition the set of nonterminals, which is potentially extremely large, into a set of equivalence classes, or mnemonics, as mentioned earlier.", "labels": [], "entities": []}, {"text": "In fact, it is useful to have a tree, which hierarchically organizes the space of possible fea- Unconstrained training: Since our grammar has an extremely large number of non-terminals, we first describe how we adapt the well-known Inside-Outside algorithm to estimate the parameters of a stochastic contextfree grammar that approximates the above context-free grammar.", "labels": [], "entities": []}, {"text": "We begin by describing the case, which wc call unconstrained training, of maximizing the likelihood of an unbrackctcd corpus.", "labels": [], "entities": []}, {"text": "We will later describe the modifications necessary to train with the constraint of a bracketed corpus.", "labels": [], "entities": []}, {"text": "To describe the training procedure we have used, we will assume familiarity with both the CKY algorithm and the Inside-Outside algorithm, which we have adapted to the problem of training our grammar.", "labels": [], "entities": []}, {"text": "The main computations of the Inside-Outside algorithm are indexed using the CKY procedure which is a bottom-up chart parsing algorithm.", "labels": [], "entities": [{"text": "bottom-up chart parsing", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.719943126042684}]}, {"text": "To summarize the main points 190 in our adaptation of these algorithms, let us assume that the grammar is in Chomsky normal form.", "labels": [], "entities": []}, {"text": "The general case involves only straight-forward modifications.", "labels": [], "entities": []}, {"text": "Proceeding in a bottom-up fashion, then, we suppose that we have two nonterminals (bundles of features) B and C, and we find all nonterminals A for which A -~ BC is a production in the grammar.", "labels": [], "entities": [{"text": "A -~ BC", "start_pos": 154, "end_pos": 161, "type": "METRIC", "confidence": 0.7257418831189474}]}, {"text": "This is accomplished by using the unfication operation and checking that the relevent Boolean conditions are satisfied for the nonterminals A, B, and C.", "labels": [], "entities": []}, {"text": "Having found such a nonterminal, the usual InsideOutside algorithm requires a recursive update of the Inside probabilities IA(i,j) and outside probabilities OA(i , j) that A spans (i, j).", "labels": [], "entities": [{"text": "OA", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.8942391276359558}]}, {"text": "These updates involve the probability parameter PrA(A ---* B C).", "labels": [], "entities": [{"text": "PrA", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.7285594344139099}]}, {"text": "In the case of our feature-based grammar, however, the number of such parameters would be extremely large (the grammar can have on the order of few billion nonterminals).", "labels": [], "entities": []}, {"text": "We thus organize productions into the equivalence classes induced by the mncmomic classes on the non-terminals.", "labels": [], "entities": []}, {"text": "The update then uses mnemonic productions for the stochastic grammar using the parameter Of course, for lexical productions A --) w we use the corresponding probability Pr~(A)(jVI(A ) -~ w) in the event that we are rewriting not a pair of nonterminals, but a word w.", "labels": [], "entities": [{"text": "Pr~(A)(jVI(A ) -~ w)", "start_pos": 169, "end_pos": 189, "type": "METRIC", "confidence": 0.843336430462924}]}, {"text": "Thus, probabilities are expressed in terms of the set of mnemonics (that is, by the nodes in the mnemonic tree), rather that in terms of the actual nonterminals of the grammar.", "labels": [], "entities": []}, {"text": "It is in this manner that we can obtain efficient and reliable estimates of our parameters.", "labels": [], "entities": []}, {"text": "Since the grammar is very detailed, the mnemonic map JUt can be increasingly refined so that a greater number of linguistic phenomena are caputured in the probabilities.", "labels": [], "entities": []}, {"text": "In principle, this could be carried out automatically to determine the optimum level of detail to be incorporated into the model, and different paramcterizations could be smoothed together.", "labels": [], "entities": []}, {"text": "To date, however, we have only contructed mnemonic maps by hand, and have thus experimented with only a small number of paramcterizations.", "labels": [], "entities": []}, {"text": "Constrained training: The Inside-Outside algorithm is a special case of the general EM algorithm, and as such, succssive iteration is guaranteed to converge to a set of parameters which locally maximize the likelihood of generating the training corpus.", "labels": [], "entities": []}, {"text": "We have found it useful to employ the trccbank to supervise the training of these parameters.", "labels": [], "entities": []}, {"text": "Intuitively, the idea is to modify the algorithm to locally maximize the likelihood of generating the training corpus using parses which are \"similar\" to the treebank parses.", "labels": [], "entities": []}, {"text": "This is accomplished by only collecting statistics over those parses which are consistent with the treebank parses, in a manner which we will now describe.", "labels": [], "entities": []}, {"text": "The notion of label-consistent is defined by a (many-to-many) mapping from the mnemonics of the feature-based grammar to the nonterminal labels of the treebank grammar.", "labels": [], "entities": []}, {"text": "For example, our grammar maintains a fairly large number of semantic classes of singular nouns, and it is natural to stipulate that each of them is label-consistent with the nonterminal NI~I denoting a generic singular noun in the treebank.", "labels": [], "entities": []}, {"text": "Of course, to exhaustively specify such a mapping would be rather time consuming.", "labels": [], "entities": []}, {"text": "In practice, the mapping is implemented by organizing the nonterminals hierarchically into a tree, and searching for consistency in a recursive fashion.", "labels": [], "entities": []}, {"text": "The simple modification of the CKY algorithm which takes into account the treebank parse is, then, the following.", "labels": [], "entities": []}, {"text": "Given a pair of nonterminals B and C in the CKY chart, if the span of the parent is not structure-consistent then this occurence of BC cannot be used in the parse and we continue to the next pair.", "labels": [], "entities": [{"text": "CKY chart", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.953757256269455}]}, {"text": "If, on the other hand, it is structure-consistent then we find all candidate parents A for which A ~ BC is a production of the grammar, but include only those that are label-consistent with the treebank nonterminal (if any) in that position.", "labels": [], "entities": []}, {"text": "The probabilities are updated in exactly the same manner as for the standard Inside-Outside algorithm.", "labels": [], "entities": []}, {"text": "The procedure that we have described is called constrained training, and it significantly improves the effectiveness of the parser, providing a dramatic reduction in computational requirements for parameter estimation as well as a modest improvement in parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 253, "end_pos": 260, "type": "TASK", "confidence": 0.9632892608642578}, {"text": "accuracy", "start_pos": 261, "end_pos": 269, "type": "METRIC", "confidence": 0.9138549566268921}]}, {"text": "Sample mappings from the terminals and nonterminals of our grammar to those of the Lancaster treebank are provided in.", "labels": [], "entities": [{"text": "Lancaster treebank", "start_pos": 83, "end_pos": 101, "type": "DATASET", "confidence": 0.9129528403282166}]}, {"text": "For ease of understanding, we use the version of our grammar in which the semantics are eliminated from the mnemonics (see above).", "labels": [], "entities": []}, {"text": "Category names from our grammar are shown first, and the Lancaster categories to which they map are shown second: The first case above is straightforward: our prepositional-phrase category maps to Lancaster's.", "labels": [], "entities": []}, {"text": "In the second case, we breakdown the category Relative Clause more finely than Lancaster does, by specifying the syntax of the embedded clause (e.g. FRV2: \"that opened the adapter\").", "labels": [], "entities": []}, {"text": "The third case relates to relative clauses lacking prefatory particles, such as: \"the row you are specifying\"; we would call \"you are specifying\" an SD (Declarative Sentence), while Lancaster calls it an Fr (Relative Clause).", "labels": [], "entities": [{"text": "Fr", "start_pos": 204, "end_pos": 206, "type": "METRIC", "confidence": 0.9436284899711609}]}, {"text": "Our practice of distinguishing constituents which function as interrupters from the same constituents tout court accounts for the fourth case; the category in question is Infinitival Clause.", "labels": [], "entities": []}, {"text": "Finally, we generate attributive adjectives (JB) directly from past participles (VVN) by rule, whereas Lancaster opts to label as adjectives (J J) those past participles so functioning.", "labels": [], "entities": []}, {"text": "We report results below for two test sets.", "labels": [], "entities": []}, {"text": "One (Test Set A) is drawn from the 600,000-word subsection of our corpus of computer manuals text which we referred to above.", "labels": [], "entities": []}, {"text": "The other (Test Set B) is drawn from our full 40-million-word computer manuals corpus.", "labels": [], "entities": []}, {"text": "Due to a more or less constant error rate of 2.5% in the treebank parses themselves, there is a corresponding built-in margin of error in our scores.", "labels": [], "entities": [{"text": "error rate", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9707003533840179}, {"text": "margin of error", "start_pos": 119, "end_pos": 134, "type": "METRIC", "confidence": 0.8237472573916117}]}, {"text": "For each of the two test sets, results are presented first for the linguistic task: making sure that a correct parse is present in the set of parses the grammar proposes for each sentence of the test set.", "labels": [], "entities": []}, {"text": "Second, results are presented for the statistical task, which is to ensure that the parse which is selected as most likely, for each sentence of the test set, is a correct parse.", "labels": [], "entities": []}], "tableCaptions": []}