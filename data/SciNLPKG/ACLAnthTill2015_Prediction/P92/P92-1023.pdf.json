{"title": [{"text": "GPSM: A GENERALIZED PROBABILISTIC SEMANTIC MODEL FOR AMBIGUITY RESOLUTION tJing", "labels": [], "entities": [{"text": "A GENERALIZED PROBABILISTIC SEMANTIC MODEL FOR AMBIGUITY RESOLUTION tJing", "start_pos": 6, "end_pos": 79, "type": "METRIC", "confidence": 0.7917538483937582}]}], "abstractContent": [{"text": "In natural language processing, ambiguity resolution is a central issue, and can be regarded as a preference assignment problem.", "labels": [], "entities": [{"text": "ambiguity resolution", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7406485974788666}]}, {"text": "In this paper, a Generalized Probabilistic Semantic Model (GPSM) is proposed for preference computation.", "labels": [], "entities": [{"text": "preference computation", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7420949339866638}]}, {"text": "An effective semantic tagging procedure is proposed for tagging semantic features.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.6894071400165558}, {"text": "tagging semantic features", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.906650185585022}]}, {"text": "A semantic score function is derived based on a score function, which integrates lexical, syntactic and semantic preference under a uniform formulation.", "labels": [], "entities": []}, {"text": "The semantic score measure shows substantial improvement in structural disambiguation over a syntax-based approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina large natural language processing system, such as a machine translation system (MTS), ambiguity resolution is a critical problem.", "labels": [], "entities": [{"text": "machine translation system (MTS)", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.8264227509498596}, {"text": "ambiguity resolution", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.7424546182155609}]}, {"text": "Various rule-based and probabilistic approaches had been proposed to resolve various kinds of ambiguity problems on a case-by-case basis.", "labels": [], "entities": []}, {"text": "In rule-based systems, a large number of rules are used to specify linguistic constraints for resolving ambiguity.", "labels": [], "entities": []}, {"text": "Any parse that violates the semantic constraints is regarded as ungrammatical and rejected.", "labels": [], "entities": []}, {"text": "Unfortunately, because every \"rule\" tends to have exception and uncertainty, and illformedness has significant contribution to the error rate of a large practical system, such \"hard rejection\" approaches fail to deal with these situations.", "labels": [], "entities": [{"text": "exception", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9802872538566589}, {"text": "error rate", "start_pos": 131, "end_pos": 141, "type": "METRIC", "confidence": 0.940210372209549}]}, {"text": "A better way is to find all possible interpretations and place emphases on preference, rather than weU-formedness (e.g.,.)", "labels": [], "entities": []}, {"text": "However, most of the known approaches forgiving preference depend heavily on heuristics such as counting the number of constraint satisfactions.", "labels": [], "entities": []}, {"text": "Therefore, most such preference measures cannot be objectively justified.", "labels": [], "entities": []}, {"text": "Moreover, it is hard and cosily to acquire, verify and maintain the consistency of the large fine-grained rule base by hand.", "labels": [], "entities": [{"text": "consistency", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.9966461062431335}]}, {"text": "Probabilistic approaches greatly relieve the knowledge acquisition problem because they are usually trainable, consistent and easy to meet certain optimum criteria.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.882435530424118}]}, {"text": "They can also provide more objective preference measures for \"soft rejection.\"", "labels": [], "entities": [{"text": "soft rejection", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.663096159696579}]}, {"text": "Hence, they are attractive fora large system.", "labels": [], "entities": []}, {"text": "The current probabilistic approaches have a wide coverage including lexical analysis, syntactic analysis [Garside 87, Fujisaki 89,, restricted semantic analysis [Church 89,, and experimental translation systems.", "labels": [], "entities": [{"text": "restricted semantic analysis", "start_pos": 132, "end_pos": 160, "type": "TASK", "confidence": 0.703265110651652}]}, {"text": "However, there is still no integrated approach for modeling the joint effects of lexical, syntactic and semantic information on preference evaluation.", "labels": [], "entities": []}, {"text": "A generalized probabilistic semantic model (GPSM) will be proposed in this paper to overcome the above problems.", "labels": [], "entities": []}, {"text": "In particular, an integrated formulation for lexical, syntactic and semantic knowledge will be used to derive the semantic score for semantic preference evaluation.", "labels": [], "entities": [{"text": "semantic preference evaluation", "start_pos": 133, "end_pos": 163, "type": "TASK", "confidence": 0.637334942817688}]}, {"text": "Application of the model to structural disam-biguation is investigated.", "labels": [], "entities": []}, {"text": "Preliminary experiments show about 10%-14% improvement of the semantic score measure over a model that uses syntactic information only.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2. Open Test of Semantic Score", "labels": [], "entities": [{"text": "Open Test", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.85794997215271}]}]}