{"title": [{"text": "Estimating Upper and Lower Bounds on the Performance of Word-Sense Disambiguation Programs", "labels": [], "entities": [{"text": "Word-Sense Disambiguation", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.6742160022258759}]}], "abstractContent": [{"text": "We have recently reported on two new word-sense disambiguation systems, one trained on bilingual material (the Canadian Hansards) and the other trained on monolingual material (Roget's Thesaurus and Grolier's Encyclopedia).", "labels": [], "entities": [{"text": "Canadian Hansards)", "start_pos": 111, "end_pos": 129, "type": "DATASET", "confidence": 0.9143162767092387}]}, {"text": "After using both the monolingual and bilingual classifiers fora few months, we have convinced ourselves that the performance is remarkably good.", "labels": [], "entities": []}, {"text": "Nevertheless, we would really like to be able to make a stronger statement, and therefore, we decided to try to develop some more objective evaluation measures.", "labels": [], "entities": []}, {"text": "Although there has been a fair amount of literature on sense-disambiguation, the literature does not offer much guidance in how we might establish the successor failure of a proposed solution such as the two systems mentioned in the previous paragraph.", "labels": [], "entities": []}, {"text": "Many papers avoid quantitative evaluations altogether, because it is so difficult to come up with credible estimates of performance.", "labels": [], "entities": []}, {"text": "This paper will attempt to establish upper and lower bounds on the level of performance that can be expected in an evaluation.", "labels": [], "entities": []}, {"text": "An estimate of the lower bound of 75% (averaged over ambiguous types) is obtained by measuring the performance produced by a baseline system that ignores context and simply assigns the most likely sense in all cases.", "labels": [], "entities": []}, {"text": "An estimate of the upper bound is obtained by assuming that our ability to measure performance is largely limited by our ability obtain reliable judgments from human informants.", "labels": [], "entities": []}, {"text": "Not surprisingly, the upper bound is very dependent on the instructions given to the judges.", "labels": [], "entities": []}, {"text": "Jorgensen, for example, suspected that lexicographers tend to depend too much on judgments by a single informant and found considerable variation over judgments (only 68% agreement), as she had suspected.", "labels": [], "entities": []}, {"text": "In our own experiments, we have set out to find word-sense disambiguation tasks where the judges can agree often enough so that we could show that they were outperforming the baseline system.", "labels": [], "entities": [{"text": "word-sense disambiguation tasks", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.796628475189209}]}, {"text": "Under quite different conditions, we have found 96.8% agreement over judges.", "labels": [], "entities": [{"text": "agreement", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9688151478767395}]}], "introductionContent": [], "datasetContent": [{"text": "Although there has been a fair amount of literature on sense-disambiguation, the literature does not offer much guidance in how we might establish the successor failure of a proposed solution such as the two described above.", "labels": [], "entities": []}, {"text": "Most papers tend to avoid quantitative evaluations., an extremely innovative and commonly cited reference on the subject, provides a short discussion of evaluation, but fails to offer any very satisfying solutions that we might adopt to quantify the performance of our two disambiguation algorithms.", "labels": [], "entities": []}, {"text": "3 Perhaps the most common evaluation technique is to select a small sample of words and compare the results of the machine with those of a human judge.", "labels": [], "entities": []}, {"text": "This method has been used very effectively by,,, and many others.", "labels": [], "entities": []}, {"text": "Nevertheless, this technique is not without its problems, perhaps the worst of which is that the sample may not be very representative of the general vocabulary., for example, reports 70% performance for the word interest, and then acknowledges that this level of performance may not generalize very well to other words.", "labels": [], "entities": []}, {"text": "4 Although we agree with Zernik's prediction that interest is not very representative of other words, we suspect that interest is actually more difficult than most other words, not less difficult.", "labels": [], "entities": []}, {"text": "shows the performance of Yarowsky (1992) on twelve words which have been previously discussed in the literature.", "labels": [], "entities": []}, {"text": "Note that interest is at the bottom of the list.", "labels": [], "entities": []}, {"text": "The reader should exercise some caution in interpreting the numbers in.", "labels": [], "entities": []}, {"text": "It is natural to try to use these numbers to predict performance on new words, but the study was not designed for that purpose.", "labels": [], "entities": []}, {"text": "The test words were selected from the literature in order to make comparisons over systems.", "labels": [], "entities": []}, {"text": "If the study had been intended to support predictions on new words, then the study should have used a random sample of such words, rather than a sample of words from the literature.", "labels": [], "entities": []}, {"text": "3. \"What is the current performance of this program?", "labels": [], "entities": []}, {"text": "Some very brief experimentation with my program has yielded accuracies of 50-70% on short samples of Pride and Prejudice and an Associated Press news story.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9987305998802185}, {"text": "Associated Press news story", "start_pos": 128, "end_pos": 155, "type": "DATASET", "confidence": 0.8726342469453812}]}, {"text": "Considerably more work is needed both to improve the program and to do more thorough evaluation...", "labels": [], "entities": []}, {"text": "There is too much subjectivity in these measurements.\"", "labels": [], "entities": []}, {"text": "In addition to the sampling questions, one feels uncomfortable about comparing results across experiments, since there are many potentially important differences including different corpora, different words, different judges, differences in treatment of precision and recall, and differences in the use of tools such as parsers and part of speech taggers, etc.", "labels": [], "entities": [{"text": "precision", "start_pos": 254, "end_pos": 263, "type": "METRIC", "confidence": 0.9858972430229187}, {"text": "recall", "start_pos": 268, "end_pos": 274, "type": "METRIC", "confidence": 0.936897873878479}, {"text": "part of speech taggers", "start_pos": 332, "end_pos": 354, "type": "TASK", "confidence": 0.6667962446808815}]}, {"text": "In short, there seem to be a number of serious questions regarding the commonly used technique of reporting percent correct on a few words chosen by hand.", "labels": [], "entities": []}, {"text": "Apparently, the literature on evaluation of word-sense disambiguation algorithms fails to offer a clear role model that we might follow in order to quantify the performance of our disambiguation algorithms.", "labels": [], "entities": [{"text": "word-sense disambiguation algorithms", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.7284692426522573}]}, {"text": "For evaluation purposes, it is important to find a task that is somewhat easier for the judges.", "labels": [], "entities": []}, {"text": "If the task is too hard (as Jorgensen's classification task may he), then there will be almost no room between the limits of the measurement and the baseline.", "labels": [], "entities": []}, {"text": "In other words, there won't be enough dynamic range to measure differences between better systems and worse systems.", "labels": [], "entities": []}, {"text": "In contrast, if we focus on easier tasks, then we might have enough dynamic range to show some interesting differences.", "labels": [], "entities": []}, {"text": "Therefore, unlike Jorgensen who was interested in highlighting differences among judgments, we are much more interested in highlighting agreements.", "labels": [], "entities": []}, {"text": "Fortunately, we have found in) that the agreement rate can be very high (96.8%), which is well above the baseline, under very different experimental conditions.", "labels": [], "entities": [{"text": "agreement rate", "start_pos": 40, "end_pos": 54, "type": "METRIC", "confidence": 0.961490660905838}]}, {"text": "Of course, it is a fairly major step to redefine the problem from a classification task to a discrimination one, as we are proposing.", "labels": [], "entities": []}, {"text": "One might have preferred not to do so, but we simply don't know how one could establish enough dynamic range in that case to show any interesting differences.", "labels": [], "entities": []}, {"text": "It has been our experience that it is very hard to design an experiment of any kind which will produce the desired agreement among judges.", "labels": [], "entities": []}, {"text": "We are very happy with the 96.8% agreement that we were able to show, even if it is limited to a much easier task than the one that Jorgensen was interested in.", "labels": [], "entities": []}, {"text": "We originally designed the experiment in Gale et al.", "labels": [], "entities": []}, {"text": "(1992) to test the hypothesis that multiple uses of a polysemous word tend to have the same sense within a common discourse.", "labels": [], "entities": []}, {"text": "A simple (but non-blind) pilot experiment provided some suggestive evidence confirming the hypothesis.", "labels": [], "entities": []}, {"text": "A random sample of 108 nouns (which included the 97 words previously mentioned) was extracted for further study.", "labels": [], "entities": []}, {"text": "A panel of three judges (the three authors of this paper) were given 100 sets of concordance lines containing one of the test words selected from a single article in Grolier's.", "labels": [], "entities": []}, {"text": "The judges were asked to indicate if the set of concordance lines used the same sense or not.", "labels": [], "entities": []}, {"text": "Only 6 of 300 articlejudgements were judged to contain multiple senses of one of the test words.", "labels": [], "entities": []}, {"text": "All three judges were convinced after grading 100 articles that there was considerable validity to the hypothesis.", "labels": [], "entities": [{"text": "validity", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9603316187858582}]}, {"text": "With this promising preliminary verification, the following blind test was devised.", "labels": [], "entities": []}, {"text": "Five subjects (the three authors and two of their colleagues) were given a questionnaire starting with a set of definitions selected from OALD (Crowie et al., 1989) and followed by a number of pairs of concordance lines, randomly selected from Grolier's Encyclopedia (1991).", "labels": [], "entities": [{"text": "OALD", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.511410653591156}, {"text": "Grolier's Encyclopedia (1991)", "start_pos": 244, "end_pos": 273, "type": "DATASET", "confidence": 0.7794225662946701}]}, {"text": "The subjects were asked to decide for each pair, whether the two concordance lines corresponded to the same sense or not.", "labels": [], "entities": []}, {"text": "jointed organ found in pairs on the heads of insects and crustaceans, used for feeling, etc.", "labels": [], "entities": []}, {"text": "---> the illus at insect.", "labels": [], "entities": []}, {"text": "2. radio or TV aerial.", "labels": [], "entities": []}, {"text": "lack eyes, legs, wings, antennae, and distinct mouthparts and The Brachycera have short antennae and include the more evolved silk moths passes over the antennae .SB Only males that detect relatively simple form of antenna is the dipole, or doublet The questionnaire contained a total of 82 pairs of concordance lines for 9 polysemous words: antenna, campaign, deposit, drum, hull, interior, knife, landscape, and marine.", "labels": [], "entities": []}, {"text": "The results of the experiment are shown below in.", "labels": [], "entities": []}, {"text": "With the exception of judge 2, all of the judges agreed with the majority opinion in all but one or two of the 82 cases.", "labels": [], "entities": []}, {"text": "The agreement rate was 96.8%, averaged overall judges, or 99.1%, averaged over the four best judges.", "labels": [], "entities": [{"text": "agreement rate", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9853824973106384}]}, {"text": "In either case, the agreement rate is well above the previously described ceiling.", "labels": [], "entities": [{"text": "agreement rate", "start_pos": 20, "end_pos": 34, "type": "METRIC", "confidence": 0.8460056781768799}]}, {"text": "Incidentally, the experiment did, in fact, confirm the hypothesis that multiple uses of a polysemous word will generally take on the same sense within a discourse.", "labels": [], "entities": []}, {"text": "Of the 82 judgments, 54 were selected from the same discourse and were judged to have the same sense by the majority in 96.9% of the cases.", "labels": [], "entities": []}, {"text": "(The remaining 28 of the 82 judgments were used as a control to force the judges to say that some pairs were different.)", "labels": [], "entities": []}, {"text": "Note that the tendency for multiple uses of a polysemous word to have the same sense is extremely strong; 96.9% is much greater than the baseline, and indeed, it is considerably above the level of performance that might be expected from state-of-the-art word-sense disambiguation systems.", "labels": [], "entities": []}, {"text": "Since it is so reliable and so easy to compute, it might be used as a quick-and-dirty measure for testing such systems.", "labels": [], "entities": []}, {"text": "Unfortunately, we also need a complementary measure that would penalize a system like the baseline system that simply assigned all instances of a polysemous word to the same sense.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison over Systems  Word  Yarowsky (1992) Previous Systems", "labels": [], "entities": []}, {"text": " Table 2: The Baseline  Word  Baseline Yarowsky (1992)  issue  96%  94%  duty  87%  96%  galley  83%  99%  star  83%  96%  taste  74%  93%  bass  70%  99%  slug  62%  97%  sentence  62%  98%  interest  60%  72%  mole  59%  99%  cone  51%  77%  bow  48%  91%  AVERAGE 70%  92%", "labels": [], "entities": [{"text": "AVERAGE", "start_pos": 259, "end_pos": 266, "type": "METRIC", "confidence": 0.8468717932701111}]}, {"text": " Table 3. With the exception of judge 2, all of  the judges agreed with the majority opinion in all but  one or two of the 82 cases. The agreement rate was  96.8%, averaged over all judges, or 99.1%, averaged  over the four best judges. In either case, the agreement  rate is well above the previously described ceiling.", "labels": [], "entities": [{"text": "agreement rate", "start_pos": 137, "end_pos": 151, "type": "METRIC", "confidence": 0.989723801612854}, {"text": "agreement  rate", "start_pos": 257, "end_pos": 272, "type": "METRIC", "confidence": 0.9866540729999542}]}, {"text": " Table 3  Judge  n  %  1  82  100.0%  2  72  87.8%  3  81  98.7%  4  82  100.0%  5  80  97.6%  Average  96.8%  Average (without Judge 2)  99.1%", "labels": [], "entities": [{"text": "Judge", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9499959945678711}, {"text": "Average  96.8%  Average", "start_pos": 95, "end_pos": 118, "type": "METRIC", "confidence": 0.7891499996185303}]}]}