{"title": [{"text": "DOCUMENTATION PARSER TO EXTRACT SOFTWARE TEST CONDITIONS", "labels": [], "entities": [{"text": "PARSER TO EXTRACT SOFTWARE TEST CONDITIONS", "start_pos": 14, "end_pos": 56, "type": "METRIC", "confidence": 0.6320891877015432}]}], "abstractContent": [{"text": "OVERVIEW This project concerns building a document parser that can be used as a software engineering tool.", "labels": [], "entities": [{"text": "OVERVIEW", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7216283679008484}]}, {"text": "A software tester's task frequently involves comparing the behavior of a running system with a document describing the behavior of the system.", "labels": [], "entities": []}, {"text": "If a problem is found, it may indicate an update is required to the document, the software system, or both.", "labels": [], "entities": []}, {"text": "A tool to generate tests automatically based on documents would be very useful to software engineers, but it requires a document parser which can identify and extract testable conditions in the text.", "labels": [], "entities": []}, {"text": "This tool would also be useful in reverse engineering , or taking existing artifacts of a software system and using them to write the specification of the system.", "labels": [], "entities": [{"text": "reverse engineering", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.917626291513443}]}, {"text": "Most reverse engineering tools work only on source code.", "labels": [], "entities": [{"text": "reverse engineering", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.8888554573059082}]}, {"text": "However, many systems are described by documents that contain valuable information for reverse engineering.", "labels": [], "entities": [{"text": "reverse engineering", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.8972553312778473}]}, {"text": "Building a document parser would allow this information to be harvested as well.", "labels": [], "entities": []}, {"text": "Documents describing a large software project (i.e. user manuals, database dictionaries) are often semi-formatted text in that they have fixed-format sections and free text sections.", "labels": [], "entities": []}, {"text": "The benefits of parsing the fixed-format portions have been seen in the CARPER project (Schlimmer, 1991), where information found in the fixed-format sections of the documents describing the system under testis used to initialize a test system automatically.", "labels": [], "entities": [{"text": "CARPER project (Schlimmer, 1991)", "start_pos": 72, "end_pos": 104, "type": "DATASET", "confidence": 0.8048199585505894}]}, {"text": "The current project looks at the free text descriptions to see what useful information can be extracted from them.", "labels": [], "entities": []}, {"text": "PARSING A DATABASE DICTIONARY The current focus of this project is on extracting database related testcases from the database dictionary of the XCON/XSEL configuration system (XCS) (Barker & O'Connor, 294 1989).", "labels": [], "entities": [{"text": "PARSING", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9252013564109802}, {"text": "XCON/XSEL configuration system (XCS) (Barker & O'Connor, 294 1989)", "start_pos": 144, "end_pos": 210, "type": "DATASET", "confidence": 0.7923512943089008}]}, {"text": "The CARPER project is aimed at building a self-maintaining database checker for the XCS database.", "labels": [], "entities": [{"text": "XCS database", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.9096217453479767}]}, {"text": "As part of its processing, it extracts basic information contained in the fixed-format sections of the database dictionary.", "labels": [], "entities": []}, {"text": "This project looks at what additional testing information can be retrieved from the database dictionary.", "labels": [], "entities": []}, {"text": "In particular, each attribute description contains a \"sanity checks\" section which includes information relevant for testing the attribute, such as the format and allowable values of the attribute, or information about attributes which must or must not be used together.", "labels": [], "entities": []}, {"text": "If this information is extracted using a text parser, either it will verify the accuracy of CARPER's checks, or it will augment them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9993258714675903}]}, {"text": "The database checks generated from a document parser will reflect changes made to the database dictionary automatically.", "labels": [], "entities": []}, {"text": "This will be particularly useful when new attributes are added and when changes are made to attribute descriptions.", "labels": [], "entities": []}, {"text": "(Lutsky, 1989) investigated the parsing of manuals for system routines to extract the maximum allowed length of the character string parameters.", "labels": [], "entities": []}, {"text": "Database dictionary parsing represents anew software domain as well as a more complex type of testable information.", "labels": [], "entities": [{"text": "Database dictionary parsing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5816740791002909}]}, {"text": "SYSTEM ARCHITECTURE The overall structure of the system is given in Figure 1.", "labels": [], "entities": [{"text": "ARCHITECTURE", "start_pos": 7, "end_pos": 19, "type": "METRIC", "confidence": 0.8799250721931458}]}, {"text": "The input to the parser is a set of system documents and the output is testcase information.", "labels": [], "entities": []}, {"text": "The parser has two main domain-independent components, one a testing knowledge module and one a general purpose parser.", "labels": [], "entities": []}, {"text": "It also has two domain-specific components: a domain model and a sublanguage grammar of expressions for representing testable information in the domain.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Experiments were done to investigate the utility of the document parser.", "labels": [], "entities": []}, {"text": "A portion of the database dictionary was analyzed to determine the ways the target concepts are expressed in that portion of the document.", "labels": [], "entities": []}, {"text": "Then a grammar was constructed to cover these initial sentences.", "labels": [], "entities": []}, {"text": "The grammar was run on the entire document to evaluate its recall and precision in identifying additional relevant sentences.", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9994358420372009}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9996362924575806}]}, {"text": "The outcome of the run on the entire document was 296 used to augment the grammar, which can then be run on successive versions of the document overtime to determine its value.", "labels": [], "entities": []}, {"text": "Preliminary experiments using the grammar to extract information about the allowable XCS attribute and class combinations showed that the system works with good recall (six of twenty-six testcases were missed) and precision (only two incorrect testcases were returned).", "labels": [], "entities": [{"text": "recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.999194324016571}, {"text": "precision", "start_pos": 214, "end_pos": 223, "type": "METRIC", "confidence": 0.9996384382247925}]}, {"text": "The grammar was augmented to cover the additional cases and not return the incorrect ones.", "labels": [], "entities": []}, {"text": "Subsequent versions of the database dictionary will provide additional data on its effectiveness.", "labels": [], "entities": []}], "tableCaptions": []}