{"title": [{"text": "INFORMATION RETRIEVAL USING ROBUST NATURAL LANGUAGE PROCESSING", "labels": [], "entities": [{"text": "INFORMATION RETRIEVAL USING ROBUST NATURAL LANGUAGE PROCESSING", "start_pos": 0, "end_pos": 62, "type": "METRIC", "confidence": 0.7065039958272662}]}], "abstractContent": [{"text": "We developed a prototype information retrieval system which uses advanced natural language processing techniques to enhance the effectiveness of traditional keyword based document retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7492232620716095}, {"text": "keyword based document retrieval", "start_pos": 157, "end_pos": 189, "type": "TASK", "confidence": 0.7001812532544136}]}, {"text": "The backbone of our system is a statistical retrieval engine which performs automated indexing of documents, then search and ranking in response to user queries.", "labels": [], "entities": [{"text": "statistical retrieval", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7468223869800568}]}, {"text": "This core architecture is augmented with advanced natural language processing tools which are both robust and efficient.", "labels": [], "entities": []}, {"text": "In early experiments, the augmented system has displayed capabilities that appear to make it superior to the purely statistical base.", "labels": [], "entities": []}], "introductionContent": [{"text": "A typical information retrieval fiR) task is to select documents from a database in response to a user's query, and rank these documents according to relevance.", "labels": [], "entities": [{"text": "information retrieval fiR)", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.788351908326149}]}, {"text": "This has been usually accomplished using statistical methods (often coupled with manual encoding), but it is now widely believed that these traditional methods have reached their limits.", "labels": [], "entities": []}, {"text": "1 These limits are particularly acute for text databases, where natural language processing (NLP) has long been considered necessary for further progress.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.7274329562981924}]}, {"text": "Unfortunately, the difficulties encountered in applying computational linguistics technologies to text processing have contributed to a wide-spread belief that automated NLP may not be suitable in IR.", "labels": [], "entities": [{"text": "text processing", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.7831061780452728}, {"text": "IR", "start_pos": 197, "end_pos": 199, "type": "TASK", "confidence": 0.9813261032104492}]}, {"text": "These difficulties included inefficiency, limited coverage, and prohibitive cost of manual effort required to build lexicons and knowledge bases for each new text domain.", "labels": [], "entities": []}, {"text": "On the other hand, while numerous experiments did not establish the usefulness of NLP, they cannot be considered conclusive because of their very limited scale.", "labels": [], "entities": []}, {"text": "Another reason is the limited scale at which NLP was used.", "labels": [], "entities": []}, {"text": "Syntactic parsing of the database contents, for example, has been attempted in order to extract linguistically motivated \"syntactic phrases\", which presumably were better indicators of contents than \"statistical phrases\" where words were grouped solely on the basis of physical proximity (eg. \"college junior\" is not the same as \"junior college\").", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7456047534942627}]}, {"text": "These intuitions, however, were not confirmed by experiments; worse still, statistical phrases regularly outperformed syntactic phrases.", "labels": [], "entities": []}, {"text": "Attempts to overcome the poor statistical behavior of syntactic phrases has led to various clustering techniques that grouped synonymous or near synonymous phrases into \"clusters\" and replaced these by single \"metaterms\".", "labels": [], "entities": []}, {"text": "Clustering techniques were somewhat successful in upgrading overall system performance, but their effectiveness was diminished by frequently poor quality of syntactic analysis.", "labels": [], "entities": []}, {"text": "Since full-analysis wide-coverage syntactic parsers were either unavailable or inefficient, various partial parsing methods have been used.", "labels": [], "entities": []}, {"text": "Partial parsing was usually fast enough, but it also generated noisy data_\" as many as 50% of all generated phrases could be incorrect ().", "labels": [], "entities": [{"text": "Partial parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7200739979743958}]}, {"text": "Other efforts concentrated on processing of user queries (eg. Spack.", "labels": [], "entities": [{"text": "Spack.", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9397733807563782}]}, {"text": "Since queries were usually short and few, even relatively inefficient NLP techniques could be of benefit to the system.", "labels": [], "entities": []}, {"text": "None of these attempts proved conclusive, and some were never properly evaluated either.", "labels": [], "entities": []}, {"text": "i As far as the aut~natic document retrieval is concerned.", "labels": [], "entities": []}, {"text": "Techniques involving various forms of relevance feedback are usually far more effective, but they require user's manual intervention in the retrieval process.", "labels": [], "entities": []}, {"text": "In this paper, we are concerned with fully automated retrieval only.", "labels": [], "entities": []}, {"text": "2 Standard IR benchmark collections are statistically too small and the experiments can easily produce counterintuitive results.", "labels": [], "entities": [{"text": "IR", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9325427412986755}]}, {"text": "For example, Cranfield collection is only approx. 180,000 English words, while CACM-3204 collection used in the present experiments is approx. 200,000 words.", "labels": [], "entities": [{"text": "Cranfield collection", "start_pos": 13, "end_pos": 33, "type": "DATASET", "confidence": 0.8668729960918427}, {"text": "CACM-3204 collection", "start_pos": 79, "end_pos": 99, "type": "DATASET", "confidence": 0.8948359191417694}]}, {"text": "We believe that linguistic processing of both the database and the user's queries need to be done fora maximum benefit, and moreover, the two processes must be appropriately coordinated.", "labels": [], "entities": []}, {"text": "This prognosis is supported by the experiments performed by the NYU group (, and by the group at the University of.", "labels": [], "entities": [{"text": "NYU group", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.9721569716930389}]}, {"text": "We explore this possibility further in this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. IC values for terms  become the basis for calculating term-to-term simi- larity coefficients. If two terms tend to be modified  with a number of common modifiers and otherwise  appear in few distinct contexts, we assign them a  similarity coefficient, a real number between 0 and 1.  The similarity is determined by comparing distribu- tion characteristics for both terms within the corpus:  how much information contents do they carry, do  their information contribution over contexts vary  greatly, are the common contexts in which these  terms occur specific enough? In general we will  credit high-contents terms appearing in identical con- texts, especially if these contexts are not too com- monplace. 9 The relative similarity between two  words Xl and x2 is obtained using the following for- mula (a is a large constant): l0", "labels": [], "entities": []}, {"text": " Table 1. IC coefficients obtained from CACM-3204", "labels": [], "entities": [{"text": "CACM-3204", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.8705086708068848}]}, {"text": " Table 2. Filtered word similarities (* indicates the  more specific term).", "labels": [], "entities": [{"text": "Filtered word similarities", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.8147577246030172}]}]}