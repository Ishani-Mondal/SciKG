{"title": [{"text": "Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6608753502368927}]}], "abstractContent": [{"text": "We explore the contribution of lexical and inflectional morphology features to dependency parsing of Arabic, a morphologically rich language with complex agreement patterns.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.8453746438026428}]}, {"text": "Using controlled experiments, we contrast the contribution of different part-of-speech (POS) tag sets and morphological features in two input conditions: machine-predicted condition (in which POS tags and morphological feature values are automatically assigned), and gold condition (in which their true values are known).", "labels": [], "entities": []}, {"text": "We find that more informative (fine-grained) tag sets are useful in the gold condition, but maybe detrimental in the predicted condition, where they are outperformed by simpler but more accurately predicted tag sets.", "labels": [], "entities": []}, {"text": "We identify a set of features (definiteness, person, number, gender, and undiacritized lemma) that improve parsing quality in the predicted condition, whereas other features are more useful in gold.", "labels": [], "entities": []}, {"text": "We are the first to show that functional features for gender and number (e.g., \"broken plurals\"), and optionally the related rationality (\"humanness\") feature, are more helpful for parsing than form-based gender and number.", "labels": [], "entities": []}, {"text": "We finally show that parsing quality in the predicted condition can dramatically improve by training in a combined gold+predicted condition.", "labels": [], "entities": [{"text": "parsing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9675149321556091}]}, {"text": "We experimented with two transition-based parsers, MaltParser and Easy-First Parser.", "labels": [], "entities": []}, {"text": "Our findings are robust across parsers, models, and input conditions.", "labels": [], "entities": []}, {"text": "This suggests that the contribution of the linguistic knowledge in the tag sets and features we identified goes beyond particular experimental settings, and maybe informative for other parsers and morphologically rich languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "For Arabic-as for other morphologically rich languages-the role of morphology is often expected to be essential in syntactic modeling, and the role of word order is less important than in morphologically poorer languages such as English.", "labels": [], "entities": [{"text": "syntactic modeling", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.7437087595462799}]}, {"text": "Morphology interacts with syntax in two ways: agreement and assignment.", "labels": [], "entities": []}, {"text": "In agreement, there is coordination between the morphological features of two words in a sentence based on their syntactic configuration (e.g., subject-verb or noun-adjective agreement in GENDER and/or NUMBER).", "labels": [], "entities": [{"text": "GENDER", "start_pos": 188, "end_pos": 194, "type": "DATASET", "confidence": 0.5749388933181763}]}, {"text": "In assignment, specific morphological feature values are assigned in certain syntactic configurations (e.g., CASE assignment for the subject or direct object of a verb).", "labels": [], "entities": [{"text": "CASE assignment for the subject or direct object of a verb", "start_pos": 109, "end_pos": 167, "type": "TASK", "confidence": 0.7573574998162009}]}, {"text": "Parsing model design aims to come up with features that best help parsers learn the syntax and choose among different parses.", "labels": [], "entities": [{"text": "Parsing model design", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9083608388900757}]}, {"text": "The choice of optimal linguistic features depends on three factors: relevance, redundancy, and accuracy.", "labels": [], "entities": [{"text": "relevance", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9571294784545898}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9974013566970825}]}, {"text": "A feature has relevance if it is useful in making an attachment (or labeling) decision.", "labels": [], "entities": [{"text": "attachment (or labeling) decision", "start_pos": 53, "end_pos": 86, "type": "TASK", "confidence": 0.666320318977038}]}, {"text": "A particular feature mayor may not be relevant to parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.9822964072227478}]}, {"text": "For example, the  ), it should attach to the feminine the-car, resulting in 'the door of the new car.'", "labels": [], "entities": []}, {"text": "Conversely, the ASPECT feature does not constrain any syntactic decision.", "labels": [], "entities": [{"text": "ASPECT", "start_pos": 16, "end_pos": 22, "type": "TASK", "confidence": 0.8543342351913452}]}, {"text": "Even if relevant, a feature may not necessarily contribute to optimal performance because it maybe redundant with other features that surpass it in relevance.", "labels": [], "entities": []}, {"text": "For example, as we will see, the DET and STATE features alone both help parsing because they help identify the idafa construction, but they are redundant with each other and the DET feature is more helpful because it also helps with adjectival modification of nouns.", "labels": [], "entities": [{"text": "STATE", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.6957913041114807}]}, {"text": "Finally, the accuracy of automatically predicting the feature values (ratio of correct predictions out of all predictions) of course affects the value of a feature on unseen text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9989182949066162}]}, {"text": "Even if relevant and non-redundent, a feature maybe hard to predict with sufficient accuracy by current technology, in which case it will be of little or no help for parsing, even if helpful when its gold values are provided.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9927593469619751}, {"text": "parsing", "start_pos": 166, "end_pos": 173, "type": "TASK", "confidence": 0.9848974347114563}]}, {"text": "As we will see, the CASE feature is very relevant and not redundant, but it cannot be predicted with high accuracy and overall it is not useful.", "labels": [], "entities": [{"text": "CASE", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.8671900033950806}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9889785647392273}]}, {"text": "Different languages vary with respect to which features maybe most helpful given various tradeoffs among these three factors.", "labels": [], "entities": []}, {"text": "In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 158, "end_pos": 165, "type": "TASK", "confidence": 0.9777591228485107}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9124840497970581}]}, {"text": "For example, modeling CASE in Czech improves Czech parsing (): CASE is relevant, not redundant, and can be predicted with sufficient accuracy.", "labels": [], "entities": [{"text": "Czech parsing", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.5246986895799637}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9947181344032288}]}, {"text": "It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9879910349845886}, {"text": "dependency parsing", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7987491190433502}]}, {"text": "In this article we investigate morphological features for dependency parsing of Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.8422373533248901}, {"text": "Modern Standard Arabic (MSA)", "start_pos": 80, "end_pos": 108, "type": "DATASET", "confidence": 0.6361198027928671}]}, {"text": "For MSA, the space of possible morphological features is fairly large.", "labels": [], "entities": [{"text": "MSA", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9662210941314697}]}, {"text": "We determine which morphological features help and why.", "labels": [], "entities": []}, {"text": "We further determine the upper bound for their contribution to parsing quality.", "labels": [], "entities": [{"text": "parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9830164313316345}]}, {"text": "Similar to previous results, assignment features, specifically CASE, are very helpful in MSA, though only under gold conditions: Because CASE is rarely explicit in the typically undiacritized written MSA, it has a dismal accuracy rate, which makes it useless when used in a machine-predicted (real, non-gold) condition.", "labels": [], "entities": [{"text": "MSA", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9357270002365112}, {"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.9968217611312866}]}, {"text": "In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions.", "labels": [], "entities": []}, {"text": "This is likely a result of MSA having a rich agreement system, covering both verb-subject and noun-adjective relations.", "labels": [], "entities": []}, {"text": "The result holds for both the MaltParser (Nivre 2008) and the Easy-First Parser (.", "labels": [], "entities": [{"text": "MaltParser (Nivre 2008)", "start_pos": 30, "end_pos": 53, "type": "DATASET", "confidence": 0.8864718437194824}]}, {"text": "Additionally, almost all work to date in MSA morphological analysis and part-ofspeech (POS) tagging has concentrated on the morphemic form of the words.", "labels": [], "entities": [{"text": "MSA morphological analysis", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.9358756144841512}, {"text": "part-ofspeech (POS) tagging", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.5816232562065125}]}, {"text": "Often, however, the functional morphology (which is relevant to agreement, and relates to the meaning of the word) is at odds with the \"surface\" (form-based) morphology; a well-known example of this are the \"broken\" (irregular) plurals of nominals.", "labels": [], "entities": []}, {"text": "We show that by modeling the functional morphology rather than the form-based morphology, we obtain a further increase in parsing performance (again, both when using gold and when using predicted POS and morphological features).", "labels": [], "entities": [{"text": "parsing", "start_pos": 122, "end_pos": 129, "type": "TASK", "confidence": 0.9709551930427551}]}, {"text": "To our knowledge, this work is the first to use functional morphology features in MSA processing.", "labels": [], "entities": [{"text": "MSA processing", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.9636410176753998}]}, {"text": "As a further contribution of this article, we show that for parsing with predicted POS and morphological features, training on a combination of gold and predicted POS and morphological feature values outperforms the alternative training scenarios.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9784604907035828}]}, {"text": "The article is structured as follows.", "labels": [], "entities": []}, {"text": "We first present relevant Arabic linguistic facts, their representation in the annotated corpus we use, and variations of abstraction thereof in several POS tag sets (Section 2).", "labels": [], "entities": [{"text": "POS tag sets", "start_pos": 153, "end_pos": 165, "type": "DATASET", "confidence": 0.7453119158744812}]}, {"text": "We follow with a survey of related work (Section 3), and describe our basic experiments in Section 4.", "labels": [], "entities": []}, {"text": "We first explore the contribution of various POS tag sets, (form-based) morphological features, and promising combinations thereof, to Arabic dependency parsing quality-in straightforward feature engineering design and combination heuristics.", "labels": [], "entities": [{"text": "Arabic dependency parsing", "start_pos": 135, "end_pos": 160, "type": "TASK", "confidence": 0.5636857549349467}]}, {"text": "We also explore more sophisticated feature engineering for the determiner (DET) feature.", "labels": [], "entities": []}, {"text": "In Section 5, we proceed to an extended exploration of functional features.", "labels": [], "entities": []}, {"text": "This includes using functional and GENDER feature values, instead of form-based values; using the non-form-based rationality (RAT) feature; and combinations thereof.", "labels": [], "entities": [{"text": "GENDER", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.7863337993621826}]}, {"text": "We additionally consider the applicability of our results to a different parser (Section 6) and consider combining gold and predicted data for training (Section 7).", "labels": [], "entities": []}, {"text": "Section 8 presents a result validation on unseen test data, as well as an analysis of parsing error types under different conditions.", "labels": [], "entities": []}, {"text": "We conclude and provide a download link to our model in Section 9.", "labels": [], "entities": []}, {"text": "Last, we include an appendix with further explorations of PERSON feature engineering, \"binning\" of Arabic number constructions according to their complex syntactic patterns, and embedding useful morphological features in the POS tag set.", "labels": [], "entities": [{"text": "PERSON feature engineering", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.6821673711140951}, {"text": "binning\" of Arabic number constructions", "start_pos": 87, "end_pos": 126, "type": "TASK", "confidence": 0.7128503123919169}, {"text": "POS tag set", "start_pos": 225, "end_pos": 236, "type": "DATASET", "confidence": 0.8881527781486511}]}, {"text": "Much of Sections 2-5 was presented in two previous publications).", "labels": [], "entities": []}, {"text": "This article extends that previous work by: 1.", "labels": [], "entities": []}, {"text": "evaluating all our parsing models in both gold and non-gold conditions (where before this was true for only select models in Sections 4-5), 2.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9675305485725403}]}, {"text": "using a newer version of our Arabic functional morphology resource (Section 5), 3.", "labels": [], "entities": []}, {"text": "evaluating several of our most notable parsing models with an additional parser (Section 6), 4.", "labels": [], "entities": []}, {"text": "exploring two additional training methods, as already mentioned above (Section 7), and 5.", "labels": [], "entities": []}, {"text": "providing an extended discussion and comparison of several notable and best performing models, including analyses of their performance per dependency tag (Section 8).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the linguistic concepts relevant to our discussion of Arabic parsing, and the data we use for our experiments.", "labels": [], "entities": [{"text": "Arabic parsing", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.6194244623184204}]}, {"text": "We start with the central concept of the morpheme followed by the more abstract concepts of the lexeme and lexical and inflectional features.", "labels": [], "entities": []}, {"text": "Throughout this section, we use the term feature in its linguistic sense, as opposed to its machine learning sense that we use in Section 4.", "labels": [], "entities": []}, {"text": "Discussions of the challenges of form-based (morpheme-based) versus functional features on the one hand, and morpho-syntactic interactions on the other hand, follow.", "labels": [], "entities": []}, {"text": "Finally, we present the annotated corpus we use, and the various POS tag sets, that are extracted from this corpus (in varying degrees of abstraction and lexicalization), and which we use in the rest of the article.", "labels": [], "entities": []}, {"text": "We examined a large space of settings.", "labels": [], "entities": []}, {"text": "In all our experiments, we contrasted the results obtained using machine-predicted input with the results obtained using gold input (the upper bound for using these features).", "labels": [], "entities": []}, {"text": "We started by looking at individual features (including POS tag sets) and their prediction accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9013532400131226}]}, {"text": "We then explored various feature combinations in a hill-climbing fashion.", "labels": [], "entities": []}, {"text": "We examined these issues in the following order: 1.", "labels": [], "entities": []}, {"text": "the contribution of POS tag sets to the parsing quality, as a function of the amount of information encoded in the tag set, using (a) gold input, and (b) machinepredicted POS tags; 2.", "labels": [], "entities": [{"text": "parsing", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9676938652992249}]}, {"text": "the contribution of numerous inflectional features in a controlled fashion, using (c) gold input and (d) machine-predicted input; (e) the prediction accuracy of each inflectional feature; 3.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9809069037437439}]}, {"text": "the contribution of the lexical features in a similar fashion, again using (f) gold input and (g) predicted input; (h) the prediction accuracy of each lexical feature; 4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9248427748680115}]}, {"text": "(i) certain feature combinations and (j) the embedding of the best combination in the POS tag set; and In Section 5 we explore using functional (instead of form-based) feature values.", "labels": [], "entities": [{"text": "POS tag set", "start_pos": 86, "end_pos": 97, "type": "DATASET", "confidence": 0.8937743107477824}]}, {"text": "In Section 6 we repeat key experiments with another parser, illustrating the robustness of our findings across these frameworks.", "labels": [], "entities": []}, {"text": "In Section 7 we explore alternative training methods, and their impact on key models.", "labels": [], "entities": []}, {"text": "All results are reported mainly in terms of labeled attachment accuracy score (the parent word and the type of dependency relation to it, abbreviated as LAS), which is also used for greedy (hill-climbing) decisions for feature combination.", "labels": [], "entities": [{"text": "labeled attachment accuracy score", "start_pos": 44, "end_pos": 77, "type": "METRIC", "confidence": 0.6445159167051315}, {"text": "LAS", "start_pos": 153, "end_pos": 156, "type": "METRIC", "confidence": 0.9690598249435425}]}, {"text": "Unlabeled attachment accuracy score (UAS) and label accuracy (dependency relation regardless of parent, LS) are also given.", "labels": [], "entities": [{"text": "Unlabeled attachment accuracy score (UAS)", "start_pos": 0, "end_pos": 41, "type": "METRIC", "confidence": 0.7787372129304069}, {"text": "label accuracy", "start_pos": 46, "end_pos": 60, "type": "METRIC", "confidence": 0.7956642806529999}, {"text": "dependency relation regardless of parent, LS)", "start_pos": 62, "end_pos": 107, "type": "METRIC", "confidence": 0.7596131190657616}]}, {"text": "For statistical significance, we use McNemar's test on non-gold LAS, as implemented by.", "labels": [], "entities": []}, {"text": "We denote p < 0.05 and p < 0.01 with + and ++ , respectively.", "labels": [], "entities": []}, {"text": "Section 4 explored the contribution of various POS tag sets, (form-based) morphological features, and promising combinations thereof, to Arabic dependency parsing qualityin straightforward feature engineering design and combination heuristics.", "labels": [], "entities": [{"text": "Arabic dependency parsing", "start_pos": 137, "end_pos": 162, "type": "TASK", "confidence": 0.5716721514860789}]}, {"text": "This section explores more sophisticated feature engineering: using functional NUMBER and GENDER feature values, instead of form-based values; using the non-form-based rationality (RAT) feature; and combinations thereof.", "labels": [], "entities": [{"text": "GENDER", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.6919147968292236}]}, {"text": "For additional experiments regarding alternative representation for digit tokens, and the \"binning\" Arabic number constructions according to their complex syntactic patterns, seethe Appendix, Section A.3.", "labels": [], "entities": []}, {"text": "In this section, we validate the contribution of key tag sets and morphological featuresand combinations thereof-using a different parser: the Easy-First Parser (.", "labels": [], "entities": []}, {"text": "As in Section 4, all models are evaluated on both gold and non-gold (machine-predicted) feature values.", "labels": [], "entities": []}, {"text": "The Easy-First Parser is a shift-reduce parser (as is MaltParser).", "labels": [], "entities": []}, {"text": "Unlike MaltParser, however, it does not attempt to attach arcs \"eagerly\" as early as possible (as in previous sections), or at the latest possible stage (an option we abandoned early on in preliminary experiments).", "labels": [], "entities": []}, {"text": "Instead, the Easy-First Parser keeps a stack of partially built treelets, and attaches them to one another in order of confidence (from high confidence, \"easy\" attachment, to low, as estimated by the classifier).", "labels": [], "entities": []}, {"text": "Labeling the relation arcs is done in a second pass, with a separate training step, after all attachments have been decided (the code for which was added after the publication of, which only included an unlabeled attachment version).", "labels": [], "entities": [{"text": "Labeling the relation arcs", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7881397902965546}]}, {"text": "Setting machine-learning features for Easy-First Parser is not as simple and elegant as for MaltParser, but it gives the feature designer greater flexibility.", "labels": [], "entities": []}, {"text": "For example, the POS tag can be dynamically split (or not) according to the token's word-form and/or the already-built attachment treelets, whereas in MaltParser, one can meld several features into a single complex feature only if applied unconditionally to all tokens.", "labels": [], "entities": []}, {"text": "The Easy-First Parser's first version comes with the code for the features used in its first publication.", "labels": [], "entities": []}, {"text": "These include POS tag splitting and feature melding for prepositional attachment chains (e.g., parent-preposition-child).", "labels": [], "entities": [{"text": "POS tag splitting", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.8460704684257507}]}, {"text": "For greater control of the contribution of the various POS tag and morphological features in the experiments, and fora better \"apples-to-apples\" comparison with MaltParser (as used here), we disabled these features, and instead used features (and selected feature melding) that were as equivalent to MaltParser as possible.", "labels": [], "entities": []}, {"text": "shows results with Easy-First Parser.", "labels": [], "entities": []}, {"text": "Results with Easy-First Parser are consistently higher than the corresponding results with MaltParser, with similar trends for the various features' contribution: Functional GENDER and NUMBER features contribute more than their form-based counterparts, in both gold and predicted conditions; rationality (RAT) as a single feature on top of the POS tag set helps in gold (and with Easy-First Parser, also in predicted conditions)-but when used in combination with PERSON, LMM, functional GENDER, and NUMBER, it actually slightly lowers parsing scores in predicted conditions (but with Easy-First Parser, it helps in gold conditions); DET is the most useful single feature in predicted conditions (from those we tried here); and the best performing model in predicted conditions is the same as with MaltParser: As before, we see that the patterns of gain achieved with the \"morphology-free\" CORE12 hold also for CATIBEX, the best performing tag set on predicted input.", "labels": [], "entities": [{"text": "DET", "start_pos": 633, "end_pos": 636, "type": "METRIC", "confidence": 0.8691596984863281}]}, {"text": "Interestingly, with this parser, the greater 1.6% (absolute) advantage of CATIBEX (without additional features) over the morphology-free CORE12 on machine-predicted input (compare with only 1% in MaltParser in) has shrunk completely with these functional feature combinations.", "labels": [], "entities": []}, {"text": "This suggests that Easy-First Parser is more resilient to accuracy errors (presumably due to its design to make less ambiguous decisions earlier), and hence can take better advantage of the relevant information encoded in our functional morphology features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9973180890083313}]}], "tableCaptions": [{"text": " Table 1  Penn Arabic Treebank part 3 v3.1 data split.", "labels": [], "entities": [{"text": "Arabic Treebank part 3 v3.1 data split", "start_pos": 15, "end_pos": 53, "type": "DATASET", "confidence": 0.9678583826337542}]}, {"text": " Table 3  Prediction accuracy, value set sizes, descriptions, and value examples of features used in this  work. Accuracy was measured over the development set. * = The set includes a \"N/A\" value(s).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9930481910705566}, {"text": "Accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9991195797920227}]}, {"text": " Table 4  CORE12 POS tag set with morphological inflectional features. Left half: Using gold POS tag and  feature values. In it: Top part (All ): Adding all nine inflectional features to CORE12. Second part  (Sep): Adding each feature separately to CORE12. Third part (Greedy): Greedily adding next  best feature from Sep, and keeping it if improving score. Right half: Same as left half, but with  predicted POS tag and feature values. Statistical significance tested only on predicted (non-gold)  input, against the CORE12 baseline.", "labels": [], "entities": [{"text": "CORE12", "start_pos": 187, "end_pos": 193, "type": "DATASET", "confidence": 0.8850938677787781}, {"text": "Statistical significance", "start_pos": 437, "end_pos": 461, "type": "METRIC", "confidence": 0.8318896293640137}, {"text": "CORE12 baseline", "start_pos": 518, "end_pos": 533, "type": "DATASET", "confidence": 0.8832718133926392}]}, {"text": " Table 5  Models with lexical morpho-semantic features. Top: Adding all lexical features together on top  of the CORE12 baseline. Center: Adding each feature separately. Bottom: Greedily adding best  features from previous part, on predicted input. Statistical significance tested only on predicted  (non-gold) input, against the CORE12 baseline.", "labels": [], "entities": [{"text": "CORE12 baseline", "start_pos": 113, "end_pos": 128, "type": "DATASET", "confidence": 0.8980191349983215}, {"text": "CORE12 baseline", "start_pos": 330, "end_pos": 345, "type": "DATASET", "confidence": 0.9114901423454285}]}, {"text": " Table 6  Models with inflectional and lexical morphological features together (predicted value-guided  heuristic). Statistical significance tested only on predicted input, against the CORE12 baseline.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 116, "end_pos": 140, "type": "METRIC", "confidence": 0.7181520462036133}]}, {"text": " Table 7  Models with re-engineered DET and PERSON inflectional features. Statistical significance tested  only on predicted input, against the CORE12 baseline.", "labels": [], "entities": [{"text": "PERSON", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.8785853385925293}, {"text": "Statistical significance", "start_pos": 74, "end_pos": 98, "type": "METRIC", "confidence": 0.8824065923690796}, {"text": "CORE12 baseline", "start_pos": 144, "end_pos": 159, "type": "DATASET", "confidence": 0.6896804124116898}]}, {"text": " Table 8  Models with functional features: GENDER, NUMBER, rationality (RAT). FN* = functional  feature(s) based on Alkuhlani and Habash (2011); GN = GENDER+NUMBER; GNR = GENDER+  NUMBER+RAT. Statistical significance tested only for CORE12+. . . models on predicted input,  against the CORE12 baseline.", "labels": [], "entities": [{"text": "FN", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9932373762130737}]}, {"text": " Table 9  Select models trained using the Easy-First Parser. Statistical significance tested only for  CORE12. . . models on predicted input: significance of the Easy-First Parser CORE12 baseline  model against its MaltParser counterpart; and significance of all other CORE12+. . . models  against the Easy-First Parser CORE12 baseline model.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 61, "end_pos": 85, "type": "METRIC", "confidence": 0.8911541402339935}]}, {"text": " Table 10  Alternatives to training on gold-only feature values. Top: Select MaltParser CORE12+. . . models  re-trained on predicted or gold + predicted feature values. Bottom: Similar models to the top  half, with the Easy-First Parser. Statistical significance tested only for CORE12+. . . models on  predicted input: significance of the MaltParser models from the MaltParser CORE12 baseline  model, and significance of the Easy-First Parser models from the Easy-First Parser CORE12  baseline.", "labels": [], "entities": [{"text": "Easy-First Parser CORE12  baseline", "start_pos": 460, "end_pos": 494, "type": "DATASET", "confidence": 0.5845752581954002}]}, {"text": " Table 11  Alternatives to training on gold-only feature values for CATIBEX and BW tag sets. Top: Select  MaltParser models re-trained on predicted or gold + predicted feature values. Bottom: Similar  models to the top half, with the Easy-First Parser. (Statistical significance was tested only for  CORE12+. . . models -none here).", "labels": [], "entities": [{"text": "BW tag sets", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.8273977438608805}]}, {"text": " Table 12  Results on PATB3-TEST for form-based models which performed best on PATB3-DEV - predicted input. Statistical significance tested on the PATB3-TEST set, only for MaltParser  CORE12+. . . models against the MaltParser CORE12 baseline model output.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 108, "end_pos": 132, "type": "METRIC", "confidence": 0.8743898272514343}, {"text": "PATB3-TEST set", "start_pos": 147, "end_pos": 161, "type": "DATASET", "confidence": 0.7531698048114777}, {"text": "MaltParser CORE12 baseline model output", "start_pos": 216, "end_pos": 255, "type": "DATASET", "confidence": 0.9459837555885315}]}, {"text": " Table 13  Results on PATB3-TEST for models that performed best on PATB3-DEV -predicted input. Using  MaltParser, unless indicated otherwise. g+p = trained on combination of gold and predicted  input (instead of gold-only). Statistical significance tested only for CORE12+. . . models: For  MaltParser CORE12+. . . models against the MaltParser CORE12 baseline model output, and for  Easy-First Parser CORE12+. . . models against the Easy-First Parser CORE12 baseline model  output.", "labels": [], "entities": [{"text": "PATB3-TEST", "start_pos": 22, "end_pos": 32, "type": "DATASET", "confidence": 0.774080216884613}, {"text": "Statistical significance", "start_pos": 224, "end_pos": 248, "type": "METRIC", "confidence": 0.8817871510982513}, {"text": "MaltParser CORE12 baseline model output", "start_pos": 334, "end_pos": 373, "type": "DATASET", "confidence": 0.7838273048400879}]}, {"text": " Table 14  Results for best performing model on PATB3-DEV and PATB3-TEST for sentences up to 70 tokens  long (predicted input).", "labels": [], "entities": [{"text": "PATB3-DEV", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.8541293144226074}, {"text": "PATB3-TEST", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.8408074378967285}]}, {"text": " Table 15  Training the MaltParser on gold tags, accuracy by gold attachment type (selected): subject,  object, modification (of a verb or a noun) by a noun, modification (of a verb or a noun) by a  preposition, idafa, and overall results (repeated).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999411940574646}]}, {"text": " Table 16  Training the MaltParser on gold and predicted tags, accuracy by gold attachment type (selected):  subject, object, modification (of a verb or a noun) by a noun, modification (of a verb or a noun)  by a preposition, idafa, and overall results (repeated).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9992302656173706}]}, {"text": " Table 17  Training the Easy-First Parser on gold and predicted tags, accuracy by gold attachment type  (selected): subject, object, modification (of a verb or a noun) by a noun, modification (of a verb or  a noun) by a preposition, idafa, and overall results (repeated).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9993059635162354}]}, {"text": " Table 18  Analysis of grammaticality of agreement relations between verb and subject and between a noun  and a nominal modifier (correct agreement in percent).", "labels": [], "entities": []}]}