{"title": [], "abstractContent": [{"text": "Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7628960013389587}, {"text": "information retrieval", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.7463650405406952}]}, {"text": "Manually created lexicons focus on opposites, such as hot and cold.", "labels": [], "entities": []}, {"text": "Opposites are of many kinds such as antipodals, complementaries, and gradable.", "labels": [], "entities": []}, {"text": "Existing lexicons often do not classify opposites into the different kinds, however.", "labels": [], "entities": []}, {"text": "They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as warm and cold or tropical and freezing.", "labels": [], "entities": []}, {"text": "We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words, A and B, are contrasting, then there is a pair of opposites, C and D, such that A and C are strongly related and B and Dare strongly related.", "labels": [], "entities": []}, {"text": "(For example, there exists the pair of opposites hot and cold such that tropical is related to hot, and freezing is related to cold.)", "labels": [], "entities": []}, {"text": "We will call this the contrast hypothesis.", "labels": [], "entities": []}, {"text": "We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds.", "labels": [], "entities": []}, {"text": "In the process, we flesh out key features of different kinds of opposites.", "labels": [], "entities": []}, {"text": "We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis, corpus statistics, and the structure of a Roget-like thesaurus.", "labels": [], "entities": []}, {"text": "We show how, using four different data sets, we evaluated our approach on two different tasks, solving \"most contrasting word\" questions and distinguishing synonyms from opposites.", "labels": [], "entities": []}, {"text": "The results are analyzed across four parts of speech and across five different kinds of opposites.", "labels": [], "entities": []}, {"text": "We show that the proposed measure of lexical contrast obtains high precision and large coverage, outperforming existing methods.", "labels": [], "entities": [{"text": "lexical contrast", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.6966665834188461}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9988847374916077}, {"text": "coverage", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9652122855186462}]}], "introductionContent": [{"text": "Native speakers of a language intuitively recognize different degrees of lexical contrastfor example, most people will agree that hot and cold have a higher degree of contrast than cold and lukewarm, and cold and lukewarm have a higher degree of contrast than penguin and clown.", "labels": [], "entities": []}, {"text": "Automatically determining the degree of contrast between words has many uses, including:.", "labels": [], "entities": []}, {"text": "This is in turn useful in effectively reranking target language hypotheses in machine translation, and for reranking query responses in information retrieval.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7578299641609192}, {"text": "information retrieval", "start_pos": 136, "end_pos": 157, "type": "TASK", "confidence": 0.7315778434276581}]}, {"text": "r Understanding discourse structure and improving dialogue systems.", "labels": [], "entities": []}, {"text": "Opposites often indicate the discourse relation of contrast ( r Detecting humor.", "labels": [], "entities": []}, {"text": "Satire and jokes tend to have contradictions and oxymorons.", "labels": [], "entities": [{"text": "Satire and jokes", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.85545680920283}]}, {"text": "r Distinguishing near-synonyms from word pairs that are semantically contrasting in automatically created distributional thesauri.", "labels": [], "entities": []}, {"text": "Measures of distributional similarity typically fail to do so.", "labels": [], "entities": []}, {"text": "Detecting lexical contrast is not sufficient by itself to solve most of these problems, but it is a crucial component.", "labels": [], "entities": [{"text": "Detecting lexical contrast", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8909218509991964}]}, {"text": "Lexicons of pairs of words that native speakers consider opposites have been created for certain languages, but their coverage is limited.", "labels": [], "entities": []}, {"text": "Opposites are of many kinds, such as antipodals, complementaries, and gradable (summarized in Section 3).", "labels": [], "entities": []}, {"text": "Existing lexicons often do not classify opposites into the different kinds, however.", "labels": [], "entities": []}, {"text": "Further, the terminology is inconsistent across different sources.", "labels": [], "entities": []}, {"text": "For example, Cruse (1986) defines antonyms as gradable adjectives that are opposite in meaning, whereas the WordNet antonymy link connects some verb pairs, noun pairs, and adverb pairs too.", "labels": [], "entities": [{"text": "WordNet antonymy link", "start_pos": 108, "end_pos": 129, "type": "DATASET", "confidence": 0.9393400351206461}]}, {"text": "In this article, we will follow Cruse's terminology, and we will refer to word pairs connected by WordNet's antonymy link as opposites, unless referring specifically to gradable adjectival pairs.", "labels": [], "entities": [{"text": "WordNet's antonymy link", "start_pos": 98, "end_pos": 121, "type": "DATASET", "confidence": 0.9248747229576111}]}, {"text": "Manually created lexicons also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as warm and cold or tropical and cold.", "labels": [], "entities": []}, {"text": "Further, contrasting word pairs far outnumber those that are commonly considered opposites.", "labels": [], "entities": []}, {"text": "In our own experiments described later in this article, we find that more than 90% of the contrasting pairs in GRE \"most contrasting word\" questions are not listed as antonyms in WordNet.", "labels": [], "entities": [{"text": "GRE \"most contrasting word\" questions", "start_pos": 111, "end_pos": 148, "type": "TASK", "confidence": 0.5638281617845807}, {"text": "WordNet", "start_pos": 179, "end_pos": 186, "type": "DATASET", "confidence": 0.9526810050010681}]}, {"text": "We should not infer from this that WordNet or any other lexicographic resource is a poor source for detecting opposites, but rather that identifying the large number of contrasting word pairs requires further computation, possibly relying on other semantic relations stored in the lexicographic resource.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9374222159385681}]}, {"text": "Even though a number of computational approaches have been proposed for semantic closeness, and some for hypernymy-hyponymy), measures of lexical contrast have been less successful.", "labels": [], "entities": []}, {"text": "To some extent, this is because lexical contrast is not as well understood as other classical lexicalsemantic relations.", "labels": [], "entities": []}, {"text": "Over the years, many definitions of semantic contrast and opposites have been proposed by linguists (, cognitive scientists, psycholinguists, and lexicographers, which differ from each other in various respects.", "labels": [], "entities": []}, {"text": "observes that even though people have a robust intuition of opposites, \"the overall class is not a well-defined one.\"", "labels": [], "entities": []}, {"text": "He points out that a defining feature of opposites is that they tend to have many common properties, but differ saliently along one dimension of meaning.", "labels": [], "entities": []}, {"text": "We will refer to this semantic dimension as the dimension of opposition.", "labels": [], "entities": []}, {"text": "For example, giant and dwarf are both living beings; they both eat, they both walk, they are both capable of thinking, and soon.", "labels": [], "entities": []}, {"text": "They are most saliently different, however, along the dimension of height.", "labels": [], "entities": []}, {"text": "Cruse also points out that sometimes it is difficult to identify or articulate the dimension of opposition (for example, city-farm).", "labels": [], "entities": []}, {"text": "Another way to define opposites is that they are word pairs with a \"binary incompatible relation\".", "labels": [], "entities": []}, {"text": "That is to say that one member entails the absence of the other, and given one member, the identity of the other member is obvious.", "labels": [], "entities": []}, {"text": "Thus, night and day are good examples of opposites because night is best paraphrased by not day, rather than the negation of any other term.", "labels": [], "entities": []}, {"text": "On the other hand, blue and yellow make poor opposites because even though they are incompatible, they do not have an obvious binary relation such that blue is understood to be a negation of yellow.", "labels": [], "entities": []}, {"text": "It should be noted that there is a relation between binary incompatibility and difference along just one dimension of meaning.", "labels": [], "entities": []}, {"text": "For this article, we define opposites to be term pairs that clearly satisfy either the property of binary incompatibility or the property of salient difference across a dimension of meaning.", "labels": [], "entities": []}, {"text": "Word pairs may satisfy the two properties to different degrees, however.", "labels": [], "entities": []}, {"text": "We will refer to all word pairs that satisfy either of the two properties to some degree as contrasting.", "labels": [], "entities": []}, {"text": "For example, daylight and darkness are very different along the dimension of light, and they satisfy the binary incompatibity property to some degree, but not as strongly as day and night.", "labels": [], "entities": []}, {"text": "Thus we will consider both daylight and darkness as well as day and night as semantically contrasting pairs (the former pair less so than the latter), but only day and night as opposites.", "labels": [], "entities": []}, {"text": "Even though there are subtle differences in the meanings of the terms contrasting, opposite, and antonym, they have often been used interchangeably in the literature, dictionaries, and common parlance.", "labels": [], "entities": []}, {"text": "Thus, we list here what we use these terms to mean in this article: r Opposites are word pairs that have a strong binary incompatibility relation with each other and/or are saliently different across a dimension of meaning.", "labels": [], "entities": []}, {"text": "r Contrasting word pairs are word pairs that have some non-zero degree of binary incompatibility and/or have some non-zero difference across a dimension of meaning.", "labels": [], "entities": []}, {"text": "Thus, all opposites are contrasting, but not all contrasting pairs are opposites.", "labels": [], "entities": []}, {"text": "r Antonyms are opposites that are also gradable adjectives.", "labels": [], "entities": []}, {"text": "In this article, we present an automatic method to identify contrasting word pairs that is based on the following hypothesis: Contrast Hypothesis: If a pair of words, A and B, are contrasting, then there is a pair of opposites, C and D, such that A and C are strongly related and B and Dare strongly related.", "labels": [], "entities": []}, {"text": "For example, there exists the pair of opposites night and day such that darkness is related tonight, and daylight is related today.", "labels": [], "entities": []}, {"text": "We then determine the degree of contrast between two words using this hypothesis: Degree of Contrast Hypothesis: If a pair of words, A and B, are contrasting, then their degree of contrast is proportional to their tendency to co-occur in a large corpus.", "labels": [], "entities": [{"text": "Degree of Contrast Hypothesis", "start_pos": 82, "end_pos": 111, "type": "METRIC", "confidence": 0.7963558286428452}]}, {"text": "For example, consider the contrasting word pairs top-low and top-down; because top and down occur together much more often than top and low, our method concludes that the pair top-down has a higher degree of lexical contrast than the pair top-low.", "labels": [], "entities": []}, {"text": "The degree of contrast hypothesis is inspired by the idea that opposites tend to co-occur more often than chance.", "labels": [], "entities": []}, {"text": "claim that this is because together opposites convey contrast well, which is rhetorically useful.", "labels": [], "entities": []}, {"text": "Thus we hypothesize that the higher the degree of contrast between two words, the higher the tendency of people to use them together.", "labels": [], "entities": []}, {"text": "Because opposites area key component of our method, we begin by first understanding different kinds of opposites (Section 3).", "labels": [], "entities": []}, {"text": "Then we describe a crowdsourced project on the annotation of opposites into different kinds (Section 4).", "labels": [], "entities": []}, {"text": "In Section 5.1, we examine whether opposites and other highly contrasting word pairs occur together in text more often than randomly chosen word pairs.", "labels": [], "entities": []}, {"text": "This experiment is crucial to the degree of contrast hypothesis because if our assumption is true, then we should find that highly contrasting pairs are used together much more often than randomly chosen word pairs.", "labels": [], "entities": []}, {"text": "Section 5.2 examines this question.", "labels": [], "entities": []}, {"text": "Section 6 presents our method to automatically compute the degree of contrast between word pairs by relying on the contrast hypothesis, the degree of contrast hypothesis, seed opposites, and the structure of a Roget-like thesaurus.", "labels": [], "entities": []}, {"text": "(This method was first described in.)", "labels": [], "entities": []}, {"text": "Finally we present experiments that evaluate various aspects of the automatic method (Section 7).", "labels": [], "entities": []}, {"text": "Following is a summary of the key research questions addressed by this article: (1) On the kinds of opposites: Research questions: How good are humans at identifying different kinds of opposites?", "labels": [], "entities": []}, {"text": "Can certain term pairs belong to more than one kind of opposite?", "labels": [], "entities": []}, {"text": "Experiment: In Sections 3 and 4, we describe how we designed a questionnaire to acquire annotations about opposites.", "labels": [], "entities": []}, {"text": "Because the annotations are done by crowdsourcing, and there is no control over the educational background of the annotators, we devote extra effort to make sure that the questions are phrased in a simple, yet clear, manner.", "labels": [], "entities": []}, {"text": "We deploy a quality control method that uses a word-choice question to automatically identify and discard dubious and outlier annotations.", "labels": [], "entities": []}, {"text": "Findings: We find that humans agree markedly in identifying opposites; there is significant variation in the agreement for different kinds of opposites, however.", "labels": [], "entities": []}, {"text": "We find that a large number of opposing word pairs have properties pertaining to more than one kind of opposite.", "labels": [], "entities": []}], "datasetContent": [{"text": "Research questions: How accurate are automatic methods at identifying whether one word pair has a higher degree of contrast than another?", "labels": [], "entities": []}, {"text": "What is the accuracy of this method in detecting opposites (a notable subset of the contrasting pairs)?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9996243715286255}]}, {"text": "How does this accuracy vary for different kinds of opposites?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.99859219789505}]}, {"text": "2 How easy is it for automatic methods to distinguish between opposites and synonyms?", "labels": [], "entities": []}, {"text": "How does the proposed method perform when compared with other automatic methods?", "labels": [], "entities": []}, {"text": "Experiments: We conduct three experiments (described in Sections 7.1, 7.2, and 7.3) involving three different data sets and two tasks to answer these questions.", "labels": [], "entities": []}, {"text": "We compare performance of our method with methods proposed by and.", "labels": [], "entities": []}, {"text": "We automatically generate anew set of 1,296 \"most contrasting word\" questions to evaluate performance of our method on five different kinds of opposites and across four parts of speech.", "labels": [], "entities": []}, {"text": "(The evaluation described in Section 7.1 was first described in.)", "labels": [], "entities": []}, {"text": "Findings: We find that the proposed measure of lexical contrast obtains high precision and large coverage, outperforming existing methods.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.998908281326294}, {"text": "coverage", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9557681679725647}]}, {"text": "Our method performs best on gradable pairs, antipodal pairs, and complementary pairs, but poorly on disjoint opposite pairs.", "labels": [], "entities": []}, {"text": "Among different parts of speech, the method performs best on noun pairs, and relatively worse on verb pairs.", "labels": [], "entities": []}, {"text": "All of the data created and compiled as part of this research are summarized in (Section 8), and is available for download.", "labels": [], "entities": []}, {"text": "We evaluate our algorithm on two different tasks and four data sets.", "labels": [], "entities": []}, {"text": "Section 7.1 describes experiments on solving existing GRE \"choose the most contrasting word\" questions (a recapitulation of the evaluation reported in).", "labels": [], "entities": [{"text": "GRE \"choose the most contrasting word\" questions", "start_pos": 54, "end_pos": 102, "type": "TASK", "confidence": 0.7261639965905083}]}, {"text": "Section 7.2 describes experiments on solving newly created \"choose the most contrasting word\" questions specifically designed to determine performance on different kinds of opposites.", "labels": [], "entities": []}, {"text": "And lastly, Section 7.3 describes experiments on two different data sets where the goal is to identify whether a given word pair is synonymous or antonymous.", "labels": [], "entities": []}, {"text": "We applied our method of lexical contrast to solve the complete set of 1,269 questions and also the various subsets.", "labels": [], "entities": [{"text": "lexical contrast", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.71040378510952}]}, {"text": "Because this test set is Percentage of contrast questions correctly answered by the automatic method, where different question sets correspond to target-answer pairs of different kinds.", "labels": [], "entities": []}, {"text": "The automatic method did not use WordNet seeds for this task.", "labels": [], "entities": [{"text": "WordNet seeds", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.9569931626319885}]}, {"text": "The results shown for 'ALL' are micro-averages, that is, they are the results for the master set of 1,269 contrast questions.", "labels": [], "entities": [{"text": "ALL'", "start_pos": 23, "end_pos": 27, "type": "TASK", "confidence": 0.6720190644264221}]}, {"text": "created from WordNet opposites, we applied the algorithm without the use of WordNet seeds (no WordNet information was used by the method).", "labels": [], "entities": [{"text": "WordNet seeds", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9403745532035828}]}, {"text": "shows the precision (P), recall (R), and F-score (F) obtained by the method on the data sets corresponding to different kinds of opposites.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.951982244849205}, {"text": "recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9569589793682098}, {"text": "F-score (F)", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.9661578685045242}]}, {"text": "The column '# instances' shows the number of questions in each of the data sets.", "labels": [], "entities": []}, {"text": "The performance of our method on the complete data set is shown in the last row ALL.", "labels": [], "entities": [{"text": "ALL", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9914513230323792}]}, {"text": "Observe that the F-score of 0.85 is markedly higher than the score obtained on the GRE-preparatory questions.", "labels": [], "entities": [{"text": "F-score", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9996421337127686}, {"text": "GRE-preparatory questions", "start_pos": 83, "end_pos": 108, "type": "DATASET", "confidence": 0.7020740807056427}]}, {"text": "This is expected because the GRE questions involved vocabulary from a higher reading level, and included carefully chosen distractors to confuse the examinee.", "labels": [], "entities": [{"text": "GRE", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.6538525223731995}]}, {"text": "The automatic method obtains highest F-score on the data sets of gradable adjectives (0.90), antipodals (0.89), and complementaries (0.89).", "labels": [], "entities": [{"text": "F-score", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9987812638282776}]}, {"text": "The precisions and recalls for these opposites are significantly higher than those of disjoint opposites.", "labels": [], "entities": [{"text": "precisions", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9996645450592041}, {"text": "recalls", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9915164709091187}]}, {"text": "The recall for reversives is also significantly lower than that for the gradable adjectives, antipodals, and complementaries, but precision on reversives is quite good (0.93).", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9996492862701416}, {"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9995433688163757}]}, {"text": "shows the precision, recall, and F-score obtained by the method on the the data sets corresponding to different parts of speech.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9996671676635742}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9992444515228271}, {"text": "F-score", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9995995163917542}]}, {"text": "Observe that performances on all parts of speech are fairly high.", "labels": [], "entities": []}, {"text": "The method deals with adverb pairs best (F-score of 0.89), and the lowest performance is for verbs (F-score of 0.80).", "labels": [], "entities": [{"text": "F-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9950627684593201}, {"text": "F-score", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9854276776313782}]}, {"text": "The differences in precision values between various parts of speech are not significant.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9990987777709961}]}, {"text": "The recall obtained on the adverbs is significantly higher than that obtained on adjectives, however, and the recall on adjectives is significantly higher than that obtained on verbs.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9983426332473755}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9975785613059998}]}, {"text": "The difference between the recalls on adverbs and nouns is not significant.", "labels": [], "entities": [{"text": "recalls", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9896747469902039}]}, {"text": "We used the Fisher Exact Test and a confidence interval of 95% for all significance testing reported in this section.", "labels": [], "entities": [{"text": "Fisher Exact Test", "start_pos": 12, "end_pos": 29, "type": "METRIC", "confidence": 0.8058847586313883}, {"text": "confidence interval", "start_pos": 36, "end_pos": 55, "type": "METRIC", "confidence": 0.9283469915390015}]}], "tableCaptions": [{"text": " Table 1  Target word pairs chosen for annotation. Each term was annotated about eight times.", "labels": [], "entities": []}, {"text": " Table 2  Number of word pairs and average number of annotations per word pair in the master set.", "labels": [], "entities": []}, {"text": " Table 3  Percentage of word pairs that received a response of \"yes\" for the questions in the questionnaire.  adj. = adjectives; adv. = adverbs.", "labels": [], "entities": []}, {"text": " Table 4  Percentage of WordNet source pairs that are contrasting, opposite, and \"contrasting but not  opposite.\"", "labels": [], "entities": []}, {"text": " Table 5  Percentage of contrasting word pairs belonging to various subtypes. The subtype \"reversives\"  applies only to verbs. The subtype \"gradable\" applies only to adjectives and adverbs.", "labels": [], "entities": []}, {"text": " Table 6  Breakdown of answer agreement by target-pair part of speech and question: For every target  pair, a question is answered by about eight annotators. The majority response is chosen as the  answer. The ratio of the size of the majority and the number of annotators is indicative of the  amount of agreement. The table shows the average percentage of this ratio.", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.889196515083313}]}, {"text": " Table 7  Pointwise mutual information (PMI) of word pairs. High positive values imply a tendency to  co-occur in text more often than random chance.", "labels": [], "entities": [{"text": "Pointwise mutual information (PMI)", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.5207629054784775}]}, {"text": " Table 8  Distributional similarity of word pairs. The measure proposed in Lin (1998) was used.", "labels": [], "entities": []}, {"text": " Table 9  Fifteen affix patterns used to generate opposites. Here 'X' stands for any sequence of letters  common to both words w 1 and w 2 .", "labels": [], "entities": []}, {"text": " Table 10  Results obtained on contrast questions. The best performing system and configuration are  shown in bold.", "labels": [], "entities": []}, {"text": " Table 11  Percentage of contrast questions correctly answered by the automatic method, where different  question sets correspond to target-answer pairs of different kinds. The automatic method did not  use WordNet seeds for this task. The results shown for 'ALL' are micro-averages, that is, they are  the results for the master set of 1,269 contrast questions.", "labels": [], "entities": [{"text": "WordNet seeds", "start_pos": 207, "end_pos": 220, "type": "DATASET", "confidence": 0.9442146718502045}]}, {"text": " Table 12  Percentage of contrast questions correctly answered by the automatic method, where different  question sets correspond to different parts-of-speech.", "labels": [], "entities": []}, {"text": " Table 14  Results obtained on the synonym-or-opposite questions in TURN. The best performing systems  are marked in bold.", "labels": [], "entities": [{"text": "TURN", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.8043928146362305}]}, {"text": " Table 17  Results for individual components as well as certain combinations of components on the  synonym-or-opposite questions in TURN. The best performing configuration is shown in bold.", "labels": [], "entities": [{"text": "TURN", "start_pos": 132, "end_pos": 136, "type": "DATASET", "confidence": 0.7974323630332947}]}]}