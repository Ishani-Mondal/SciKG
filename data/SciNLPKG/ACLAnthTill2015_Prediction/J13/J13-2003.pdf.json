{"title": [], "abstractContent": [{"text": "Metaphor is highly frequent in language, which makes its computational processing indispensable for real-world NLP applications addressing semantic tasks.", "labels": [], "entities": []}, {"text": "Previous approaches to metaphor modeling rely on task-specific hand-coded knowledge and operate on a limited domain or a subset of phenomena.", "labels": [], "entities": [{"text": "metaphor modeling", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.9312269985675812}]}, {"text": "We present the first integrated open-domain statistical model of metaphor processing in unrestricted text.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.8866990506649017}]}, {"text": "Our method first identifies metaphorical expressions in running text and then paraphrases them with their literal paraphrases.", "labels": [], "entities": []}, {"text": "Such a text-to-text model of metaphor interpretation is compatible with other NLP applications that can benefit from metaphor resolution.", "labels": [], "entities": [{"text": "metaphor interpretation", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.8895122408866882}, {"text": "metaphor resolution", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7401004284620285}]}, {"text": "Our approach is minimally supervised, relies on the state-of-the-art parsing and lexical acquisition technologies (distributional clustering and selectional preference induction), and operates with a high accuracy.", "labels": [], "entities": [{"text": "selectional preference induction", "start_pos": 145, "end_pos": 177, "type": "TASK", "confidence": 0.7060198187828064}, {"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.995992124080658}]}], "introductionContent": [{"text": "Our production and comprehension of language is a multi-layered computational process.", "labels": [], "entities": []}, {"text": "Humans carryout high-level semantic tasks effortlessly by subconsciously using avast inventory of complex linguistic devices, while simultaneously integrating their background knowledge, to reason about reality.", "labels": [], "entities": []}, {"text": "An ideal computational model of language understanding would also be capable of performing such high-level semantic tasks.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.7210936546325684}]}, {"text": "With the rapid advances in statistical natural language processing (NLP) and computational lexical semantics, increasingly complex semantic tasks can now be addressed.", "labels": [], "entities": [{"text": "statistical natural language processing (NLP)", "start_pos": 27, "end_pos": 72, "type": "TASK", "confidence": 0.7445098374571119}]}, {"text": "Tasks that have received much attention so far include, for example, word sense disambiguation (WSD), supervised and unsupervised lexical classification, selectional preference induction, and semantic role labeling.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.8169897894064585}, {"text": "supervised and unsupervised lexical classification", "start_pos": 102, "end_pos": 152, "type": "TASK", "confidence": 0.7254370927810669}, {"text": "selectional preference induction", "start_pos": 154, "end_pos": 186, "type": "TASK", "confidence": 0.7278806368509928}, {"text": "semantic role labeling", "start_pos": 192, "end_pos": 214, "type": "TASK", "confidence": 0.6561023195584615}]}, {"text": "In this article, we take a step further and show that state-of-the-art statistical NLP and computational lexical semantic techniques can be used to successfully model complex meaning transfers, such as metaphor.", "labels": [], "entities": []}, {"text": "Metaphors arise when one concept is viewed in terms of the properties of another.", "labels": [], "entities": []}, {"text": "Humans often use metaphor to describe abstract concepts through reference to more concrete or physical experiences.", "labels": [], "entities": []}, {"text": "Some examples of metaphor include the following.", "labels": [], "entities": []}, {"text": "(1) How can I kill a process?", "labels": [], "entities": []}, {"text": "(2) Hillary brushed aside the accusations.", "labels": [], "entities": []}, {"text": "(3) I invested myself fully in this research.", "labels": [], "entities": []}], "datasetContent": [{"text": "The first task for metaphor processing within NLP is its identification in text.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.9252511858940125}]}, {"text": "As discussed earlier, previous approaches to this problem either utilize hand-coded knowledge or reduce the task to searching for metaphors of a specific domain defined a priori (e.g., MOTION metaphors) in a specific type of discourse (e.g., the Wall Street Journal).", "labels": [], "entities": [{"text": "Wall Street Journal)", "start_pos": 246, "end_pos": 266, "type": "DATASET", "confidence": 0.9416288435459137}]}, {"text": "In contrast, the search space in our experiments is the entire BNC and the domain of the expressions identified is unrestricted.", "labels": [], "entities": []}, {"text": "In addition, the developed technique does not rely on any hand-crafted lexical or world knowledge, but rather captures metaphoricity by means of verb and noun clustering in a data-driven manner.", "labels": [], "entities": []}, {"text": "The motivation behind the use of clustering methods for the metaphor identification task lies in CMT.", "labels": [], "entities": [{"text": "metaphor identification task", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.9015296300252279}]}, {"text": "The patterns of conceptual metaphor (e.g., FEELINGS ARE LIQUIDS) always operate on semantic classes, that is, groups of related concepts, defined by Lakoff and Johnson as conceptual domains (FEELINGS include love, anger, hatred, etc.; LIQUIDS include water, tea, petrol, beer, etc.).", "labels": [], "entities": [{"text": "FEELINGS", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.7853761911392212}]}, {"text": "Thus modeling metaphorical mechanisms in accordance with CMT would involve capturing such semantic classes automatically.", "labels": [], "entities": []}, {"text": "Previous research on corpus-based lexical semantics has shown that it is possible to automatically induce semantic word classes from corpus data via clustering of contextual cues).", "labels": [], "entities": []}, {"text": "The current consensus is that the lexical items showing similar behavior in a large body of text most likely have related meanings.", "labels": [], "entities": []}, {"text": "The second reason for the use of unsupervised and weakly supervised methods is suggested by the results of corpus-based studies of conceptual metaphor.", "labels": [], "entities": []}, {"text": "The analysis of conceptual mappings in unrestricted text, conducted by, although confirming some aspects of CMT, uncovered a number of fundamental difficulties.", "labels": [], "entities": []}, {"text": "One of these is the choice of the level of abstraction and granularity of categories (i.e., labels for source and target domains).", "labels": [], "entities": []}, {"text": "This suggests that it is hard to define a comprehensive inventory of labels for source and target domains.", "labels": [], "entities": []}, {"text": "Thus a computational model of metaphorical associations should not rely on explicit domain labels.", "labels": [], "entities": []}, {"text": "Unsupervised methods allow us to recover patterns in data without assigning any explicit labels to concepts, and thus to model interconceptual mappings implicitly.", "labels": [], "entities": []}, {"text": "The method behind our metaphor identification system relies on distributional clustering.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.916970431804657}]}, {"text": "Noun clustering, specifically, is central to the approach.", "labels": [], "entities": [{"text": "Noun clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7922349870204926}]}, {"text": "It is traditionally assumed that noun clusters produced using distributional clustering contain concepts that are similar to each other.", "labels": [], "entities": []}, {"text": "This is true only in part, however.", "labels": [], "entities": []}, {"text": "There exist two types of concepts: concrete, those concepts denoting physical entities or physical experiences (e.g., chair, apple, house, rain) and abstract, those concepts that do not physically exist at any particular time or place, but rather exist as a type of thing or as an idea (e.g., justice, love, democracy).", "labels": [], "entities": []}, {"text": "It is the abstract concepts that tend to be described metaphorically, rather than concrete concepts.", "labels": [], "entities": []}, {"text": "Humans use metaphor attempting to gain a better understanding of an abstract concept by comparing it to their physical experiences.", "labels": [], "entities": []}, {"text": "As a result, abstract concepts expose different distributional behavior in a corpus.", "labels": [], "entities": []}, {"text": "This in turn affects the application of clustering techniques and the obtained clusters for concrete and abstract concepts would be structured differently.", "labels": [], "entities": []}, {"text": "The figure shows a cluster containing concrete concepts (on the right) that are various kinds of mechanisms; a cluster containing verbs co-occurring with mechanisms in the corpus (at the bottom); and a cluster containing abstract concepts (on the left) that tend to co-occur with these verbs.", "labels": [], "entities": []}, {"text": "Such abstract concepts, albeit having quite distinct meanings (e.g., marriage and democracy), are observed in similar lexico-syntactic environments.", "labels": [], "entities": []}, {"text": "This is due to the fact that they are systematically used metaphorically with the verbs from the domain of MECHANISM.", "labels": [], "entities": [{"text": "MECHANISM", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.7785443067550659}]}, {"text": "Hence, they are automatically assigned to the same cluster.", "labels": [], "entities": []}, {"text": "The following examples illustrate this phenomenon in textual data.", "labels": [], "entities": []}, {"text": "(18) Our relationship is not really working.", "labels": [], "entities": []}, {"text": "Such a structure of the abstract clusters can be explained by the fact that relationships, marriages, collaborations, and political systems are all cognitively mapped to the same source domain of MECHANISM.", "labels": [], "entities": []}, {"text": "In contrast to concrete concepts, such as tea, water, coffee, beer, drink, liquid, that are clustered together when they have similar meanings, abstract concepts tend to be clustered together if they are associated with the same source domain.", "labels": [], "entities": []}, {"text": "We define this phenomenon as clustering by association and it becomes central to the system design.", "labels": [], "entities": []}, {"text": "The expectation is that clustering by association would allow the harvesting of new target domains that are associated with the same source domain, and thus identify new metaphors.", "labels": [], "entities": []}, {"text": "The metaphor identification system starts from a small set of seed metaphorical expressions, that is, annotated metaphors (such as those in or), which serve as training data.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7702332139015198}]}, {"text": "Note that seed annotation only concerns linguistic metaphors; metaphorical mappings are not annotated.", "labels": [], "entities": []}, {"text": "The system then (1) creates source domains describing these examples by means of verb clustering (such as the verb cluster in); (2) identifies new target domains associated with the same source domain by means of noun clustering (see, e.g., ABSTRACT cluster in), and (3) establishes a link between the source and the target clusters based on the seed examples.", "labels": [], "entities": []}, {"text": "Thus the system captures metaphorical associations implicitly.", "labels": [], "entities": []}, {"text": "It generalizes over the associated domains by means of verb and noun clustering.", "labels": [], "entities": [{"text": "noun clustering", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.7086764574050903}]}, {"text": "The obtained clusters then represent source and target concepts between which metaphorical associations hold.", "labels": [], "entities": []}, {"text": "The knowledge of such associations is then used to identify new metaphorical expressions in a large corpus.", "labels": [], "entities": []}, {"text": "In addition to this, we build a selectional preference-based metaphor filter.", "labels": [], "entities": []}, {"text": "This idea stems from the view of, but is, however, a modification of it.", "labels": [], "entities": []}, {"text": "The filter assumes that the verbs exhibiting weak selectional preferences, namely, verbs cooccurring with any argument class in linguistic data (remember, influence, etc.) generally have no or only weak potential for being a metaphor.", "labels": [], "entities": []}, {"text": "It has been previously shown that it is possible to quantify verb selectional preferences on the basis of corpus data, using, for example, a measure defined by.", "labels": [], "entities": []}, {"text": "Once the candidate metaphors are identified in the corpus using clustering methods, those displaying weak selectional preferences can be filtered out.", "labels": [], "entities": []}, {"text": "Figures 4 and 5 depict the metaphor identification pipeline: first, the identification of metaphorical associations and then that of metaphorical expressions in text.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7302131056785583}]}, {"text": "In  The paraphrasing system is first tested individually on a set of metaphorical expressions extracted from a manually annotated metaphor corpus of.", "labels": [], "entities": []}, {"text": "This is the same data set as the one used for seeding the identification module (see Section 3.1.1 for description).", "labels": [], "entities": []}, {"text": "Because the paraphrasing evaluation described in this section is conducted independently from the identification experiment, and no part of the paraphrasing system relies on the output of the identification system and vice versa, the use of the same data set does not give any unfair advantage to the systems.", "labels": [], "entities": []}, {"text": "In the later experiment (Section 5) when the identification and paraphrasing system are evaluated jointly, again the same seed set will be used for identification; paraphrasing, however, will be performed on the output of the identification system (i.e., the new identified metaphors) and both the identified metaphors and their paraphrases will be evaluated by human judges not used in the previous and the current experiments.", "labels": [], "entities": []}, {"text": "The evaluation data for metaphor identification was the BNC parsed by the RASP parser).", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.9481770396232605}, {"text": "BNC", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.805596113204956}, {"text": "RASP parser", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.8431706726551056}]}, {"text": "We used the grammatical relation (GR) output of RASP for the BNC created by.", "labels": [], "entities": [{"text": "RASP", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.7097864151000977}]}, {"text": "The system searched the corpus for the source and target domain vocabulary within a particular grammatical relation (verb-direct objector verb-subject).", "labels": [], "entities": []}, {"text": "In order to assess the quality of metaphor identification by both systems, their output was assessed by human judgments.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8396486639976501}]}, {"text": "For this purpose, we randomly sampled sentences containing metaphorical expressions as annotated by the system and by the baseline and asked human annotators to decide whether these were metaphorical or not.", "labels": [], "entities": []}, {"text": "Participants Five volunteers participated in the experiment.", "labels": [], "entities": []}, {"text": "They were all native speakers of English and had no formal training in linguistics.", "labels": [], "entities": []}, {"text": "Materials The subjects were presented with a set of 78 randomly sampled sentences annotated by the two systems.", "labels": [], "entities": []}, {"text": "Fifty percent of the data set were the sentences annotated by the identification system and the remaining 50% were annotated by the baseline; and the sentences were randomized.", "labels": [], "entities": []}, {"text": "The annotation was done electronically in Microsoft Word.", "labels": [], "entities": []}, {"text": "An example of annotated sentences is given in.", "labels": [], "entities": []}, {"text": "Task and guidelines The subjects were asked to mark which of the expressions were metaphorical in their judgment.", "labels": [], "entities": []}, {"text": "The participants were encouraged to rely on their own intuition of what a metaphor is in the annotation process.", "labels": [], "entities": []}, {"text": "Additional guidance, however, in the form of the following definition of metaphor (Pragglejaz Group 2007) was also provided: 1.", "labels": [], "entities": [{"text": "Pragglejaz Group 2007)", "start_pos": 83, "end_pos": 105, "type": "DATASET", "confidence": 0.9543175548315048}]}, {"text": "For each verb establish its meaning in context and try to imagine a more basic meaning of this verb in other contexts.", "labels": [], "entities": []}, {"text": "Basic meanings normally are: (1) more concrete; (2) related to bodily action; (3) more precise (as opposed to vague); (4) historically older.", "labels": [], "entities": []}, {"text": "As is the casein metaphor identification, the majority of existing approaches to metaphor interpretation also rely on task-specific hand-coded knowledge) and produce interpretations in a non-textual format.", "labels": [], "entities": [{"text": "casein metaphor identification", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.7590818603833517}, {"text": "metaphor interpretation", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.7777825891971588}]}, {"text": "The ultimate objective of automatic metaphor processing, however, is a type of interpretation that can be directly embedded into other systems to enhance their performance.", "labels": [], "entities": [{"text": "automatic metaphor processing", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.6813143193721771}]}, {"text": "We thus define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text.", "labels": [], "entities": [{"text": "metaphor interpretation", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.835860937833786}]}, {"text": "Our method is also distinguished from previous work in that it does not rely on any hand-crafted knowledge about metaphor, but in contrast is corpus-based and uses automatically induced selectional preferences.", "labels": [], "entities": []}, {"text": "The metaphor paraphrasing task can be divided into two subtasks: (1) generating paraphrases, that is, other ways of expressing the same meaning in a given context, and (2) discriminating between literal and metaphorical paraphrases.", "labels": [], "entities": [{"text": "metaphor paraphrasing", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7169216573238373}]}, {"text": "Consequently, the proposed approach is theoretically grounded in two ideas underlying each of these subtasks: r The meaning of a word in context emerges through interaction with the meaning of the words surrounding it.", "labels": [], "entities": []}, {"text": "This assumption is widely accepted in lexical semantics theory and has been exploited for lexical acquisition.", "labels": [], "entities": [{"text": "lexical semantics theory", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.7480417291323344}, {"text": "lexical acquisition", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.8059321045875549}]}, {"text": "It suggests that the context itself imposes certain semantic restrictions on the words which can occur within it.", "labels": [], "entities": []}, {"text": "Given a large amount of linguistic data, it is possible to model these semantic restrictions in probabilistic terms.", "labels": [], "entities": []}, {"text": "This can be done by deriving a ranking scheme for possible paraphrases that fit or do not fit in a specific context based on word co-occurrence evidence.", "labels": [], "entities": []}, {"text": "This is how initial paraphrases are generated within the metaphor paraphrasing module.", "labels": [], "entities": []}, {"text": "r Literalness can be detected via strong selectional preference.", "labels": [], "entities": []}, {"text": "This idea is a mirror-image of the selectional preference violation view of, who suggested that a violation of selectional preferences indicates a metaphor.", "labels": [], "entities": []}, {"text": "The key information that selectional preferences provide is whether there is an association between the predicate and its potential argument and how strong that association is.", "labels": [], "entities": []}, {"text": "A literal paraphrase would normally come from the target domain (e.g., \"understand the explanation\") and be strongly associated with the target concept, whereas a metaphorical paraphrase would belong to the source domain (e.g., \"grasp the explanation\") and be associated with the concepts from this source domain more strongly than with the target concept.", "labels": [], "entities": []}, {"text": "Hence we use a selectional preference model to measure the semantic fit of the generated paraphrases into the given context as opposed to all other contexts.", "labels": [], "entities": []}, {"text": "The highest semantic fit then indicates the most literal paraphrase.", "labels": [], "entities": []}, {"text": "Thus the context-based probabilistic model is used for paraphrase generation and the selectional preference model for literalness detection.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.9223438799381256}, {"text": "literalness detection", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.9281783401966095}]}, {"text": "The key difference between the two models is that the former favors the paraphrases that co-occur with the words in the context more frequently than other paraphrases do, and the latter favors the paraphrases that co-occur with the words from the context more frequently than with any other lexical items in the corpus.", "labels": [], "entities": []}, {"text": "This is the main intuition behind our approach.", "labels": [], "entities": []}, {"text": "The system thus incorporates the following components: r a context-based probabilistic model that acquires paraphrases for metaphorical expressions from a large corpus; r a WordNet similarity component that filters out the irrelevant paraphrases based on their similarity to the metaphorical term (similarity is defined as sharing a common hypernym within three levels in the WordNet hierarchy); r a selectional preference model that discriminates literal paraphrases from the metaphorical ones.", "labels": [], "entities": []}, {"text": "It re-ranks the paraphrases, de-emphasizing the metaphorical ones and emphasizing the literal ones.", "labels": [], "entities": []}, {"text": "In addition, the system disambiguates the sense of the paraphrases using the WordNet inventory of senses.", "labels": [], "entities": [{"text": "WordNet inventory", "start_pos": 77, "end_pos": 94, "type": "DATASET", "confidence": 0.9392640292644501}]}, {"text": "The context-based model together with the WordNet filter constitute a metaphor paraphrasing baseline.", "labels": [], "entities": [{"text": "WordNet filter", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9212857484817505}]}, {"text": "By comparing the final system to this baseline, we demonstrate that simple context-based substitution, even supplied by extensive knowledge contained in lexical resources, is not sufficient for metaphor interpretation and that a selectional preference model is needed to establish the literalness of the paraphrases.", "labels": [], "entities": [{"text": "metaphor interpretation", "start_pos": 194, "end_pos": 217, "type": "TASK", "confidence": 0.8848807513713837}]}, {"text": "This section first provides an overview of paraphrasing and lexical substitution and relates these tasks to the problem of metaphor interpretation.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.7566033601760864}, {"text": "metaphor interpretation", "start_pos": 123, "end_pos": 146, "type": "TASK", "confidence": 0.8902271687984467}]}, {"text": "It then describes the experimental data used to develop and test the paraphrasing system and the method itself, and finally, concludes with the system evaluation and the presentation of results.", "labels": [], "entities": []}, {"text": "As in the case of identification, the paraphrasing system was tested on verb-subject and verb-direct object metaphorical expressions.", "labels": [], "entities": []}, {"text": "These were extracted from the manually annotated metaphor corpus of, as described in Section 3.1.1.", "labels": [], "entities": []}, {"text": "We compared the output of the final selectional-preference based system to that of the WordNet filter acting as a baseline.", "labels": [], "entities": [{"text": "WordNet filter", "start_pos": 87, "end_pos": 101, "type": "DATASET", "confidence": 0.9408180415630341}]}, {"text": "We evaluated the quality of paraphrasing with the help of human judges in two different experimental settings.", "labels": [], "entities": [{"text": "paraphrasing", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.9625846147537231}]}, {"text": "The first setting involved direct judgments of system output by humans.", "labels": [], "entities": []}, {"text": "In the second setting, the subjects did not have access to system output and had to provide their own literal paraphrases for the metaphorical expressions in the data set.", "labels": [], "entities": []}, {"text": "The system was then evaluated against human judgments in Setting 1 and a paraphrasing gold standard created by merging annotations in Setting 2.", "labels": [], "entities": []}, {"text": "Up to now, the identification and the paraphrasing systems were evaluated individually as modules.", "labels": [], "entities": []}, {"text": "To determine to which extent the presented systems are applicable within NLP, we then ran the two systems together in a pipeline and evaluated the accuracy of the resulting text-to-text metaphor processing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9984350800514221}]}, {"text": "First, the metaphor identification system was applied to naturally occurring text taken from the BNC and then the metaphorical expressions identified in those texts were paraphrased by the paraphrasing system.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.6984319984912872}, {"text": "BNC", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.9595312476158142}]}, {"text": "Some of the expressions identified and paraphrased by the integrated system are shown in.", "labels": [], "entities": []}, {"text": "The system output was compared against human judgments in two phases.", "labels": [], "entities": []}, {"text": "In phase 1, a small sample of sentences containing metaphors identified and paraphrased by the system was judged by multiple judges.", "labels": [], "entities": []}, {"text": "In phase 2, a larger sample of phrases was judged by only one judge (one of the authors of this article).", "labels": [], "entities": []}, {"text": "Agreement of the judgments of the latter with the other judges was measured on the data from phase 1.", "labels": [], "entities": [{"text": "Agreement", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.979680597782135}]}, {"text": "Because our goal was to evaluate both the accuracy of the integrated system and its usability by other NLP tasks, we assessed its performance in a two-fold fashion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9989882111549377}]}, {"text": "Instances where metaphors were both correctly identified and paraphrased by the system were considered strictly correct, as they show that the system fully achieved CKM 391 Time and time again he would stare at the ground, hand on hip, if he thought he had received a bad call, and then swallow his anger and play tennis.", "labels": [], "entities": [{"text": "CKM 391", "start_pos": 165, "end_pos": 172, "type": "DATASET", "confidence": 0.5352453291416168}]}, {"text": "CKM 391 Time and time again he would stare at the ground, hand on hip, if he thought he had received a bad call, and then suppress his anger and play tennis.", "labels": [], "entities": [{"text": "CKM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9344461560249329}]}, {"text": "AD9 3205 He tried to disguise the anxiety he felt when he found the comms system down, but Tammuz was nearly hysterical by this stage.", "labels": [], "entities": [{"text": "AD9", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9508395791053772}]}, {"text": "AD9 3205 He tried to hide the anxiety he felt when he found the comms system down, but Tammuz was nearly hysterical by this stage.", "labels": [], "entities": [{"text": "AD9", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9481009840965271}]}, {"text": "AMA 349 We will halt the reduction in NHS services for long-term care and community health services which support elderly and disabled patients at home.", "labels": [], "entities": [{"text": "AMA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8293762803077698}]}, {"text": "AMA 349 We will prevent the reduction in NHS services for long-term care and community health services which support elderly and disabled patients at home.", "labels": [], "entities": [{"text": "AMA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8625996112823486}]}, {"text": "J7F 77 An economist would frame this question in terms of a cost-benefit analysis: the maximization of returns for the minimum amount of effort injected.", "labels": [], "entities": [{"text": "J7F 77", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9641056954860687}]}, {"text": "J7F 77 An economist would phrase this question in terms of a cost-benefit analysis: the maximization of returns for the minimum amount of effort injected.", "labels": [], "entities": [{"text": "J7F 77", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9632843732833862}]}, {"text": "EEC 1362 In it, Younger stressed the need for additional alternatives to custodial sentences, which had been implicit in the decision to ask the Council to undertake the enquiry.", "labels": [], "entities": [{"text": "EEC 1362", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9757877290248871}]}, {"text": "EEC 1362 In it, Younger stressed the need for additional alternatives to custodial sentences, which had been implicit in the decision to ask the Council to initiate the enquiry.", "labels": [], "entities": [{"text": "EEC 1362", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.973755270242691}]}, {"text": "A1F 24 Moreover, Mr Kinnock brushed aside the suggestion that he needed a big idea or unique selling point to challenge the appeal of Thatcherism.", "labels": [], "entities": [{"text": "A1F", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7416446805000305}]}, {"text": "A1F 24 Moreover, Mr Kinnock dismissed the suggestion that he needed a big idea or unique selling point to challenge the appeal of Thatcherism.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Corpus statistics for linguistic cues.", "labels": [], "entities": []}, {"text": " Table 2  Verbs with weak direct object SPs.", "labels": [], "entities": []}, {"text": " Table 3  Verbs with strong direct object SPs.", "labels": [], "entities": []}, {"text": " Table 4  Examples of seed set expansion by the system.", "labels": [], "entities": []}, {"text": " Table 5  Examples of seed set expansion by the baseline.", "labels": [], "entities": []}, {"text": " Table 6  Common system errors by type.", "labels": [], "entities": []}, {"text": " Table 8  Paraphrases re-ranked by SP model (correct paraphrases are underlined).", "labels": [], "entities": []}, {"text": " Table 9  System and baseline P(1) and MAP.", "labels": [], "entities": [{"text": "baseline P(1)", "start_pos": 21, "end_pos": 34, "type": "METRIC", "confidence": 0.8574591636657715}, {"text": "MAP", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9216880202293396}]}, {"text": " Table 10  Common system errors by type.", "labels": [], "entities": []}, {"text": " Table 13  System errors by component. Three categories are cases where the identification model  incorrectly tagged a literal expression as metaphoric (false negatives from this module  were not measured). The remaining two categories are for paraphrase errors on correctly  identified metaphors.", "labels": [], "entities": []}, {"text": " Table 14  Errors of the paraphrasing component by type.", "labels": [], "entities": [{"text": "Errors", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9755953550338745}]}]}