{"title": [{"text": "A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.9193945825099945}]}], "abstractContent": [{"text": "This work is focused on research in machine learning for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.9711861610412598}]}, {"text": "Coreference resolution is a natural language processing task that consists of determining the expressions in a discourse that refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9203341901302338}]}, {"text": "The main contributions of this article are (i) anew approach to coreference resolution based on constraint satisfaction, using a hypergraph to represent the problem and solving it by relaxation labeling; and (ii) research towards improving coreference resolution performance using world knowledge extracted from Wikipedia.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.9663607180118561}, {"text": "coreference resolution", "start_pos": 240, "end_pos": 262, "type": "TASK", "confidence": 0.9350212216377258}]}, {"text": "The developed approach is able to use an entity-mention classification model with more expressiveness than the pair-based ones, and overcome the weaknesses of previous approaches in the state of the art such as linking contradictions, classifications without context, and lack of information evaluating pairs.", "labels": [], "entities": []}, {"text": "Furthermore, the approach allows the incorporation of new information by adding constraints, and research has been done in order to use world knowledge to improve performances.", "labels": [], "entities": []}, {"text": "RelaxCor, the implementation of the approach, achieved results at the state-of-the-art level, and participated in international competitions: SemEval-2010 and CoNLL-2011.", "labels": [], "entities": [{"text": "RelaxCor", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8528591990470886}, {"text": "CoNLL-2011", "start_pos": 159, "end_pos": 169, "type": "DATASET", "confidence": 0.8847283720970154}]}, {"text": "RelaxCor achieved second place in CoNLL-2011.", "labels": [], "entities": [{"text": "RelaxCor", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.899903416633606}, {"text": "CoNLL-2011", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.9022793173789978}]}], "introductionContent": [{"text": "Coreference resolution is a natural language processing (NLP) task that consists of determining which mentions in a discourse refer to the same entity or event.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9077401757240295}]}, {"text": "A mention is a referring expression that has an entity or event as a referent.", "labels": [], "entities": []}, {"text": "By referring expression we mean noun phrases (NP), named entities (NEs), embedded nouns, and pronouns (all but pleonastic and interrogative ones) whose meaning as a whole is a will answer as always, is not for sale and do not want to let go.\"", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments consist of the execution of RELAXCOR using each one of the models to incorporate information.", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.6026191115379333}]}, {"text": "RELAXCOR + features incorporates the new features to the original model and repeats the training process from the beginning.", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.6949509978294373}]}, {"text": "Constraints are learned using these new feature functions mixed with all the others (a detailed list of features is in Section 4.2).", "labels": [], "entities": []}, {"text": "RELAXCOR + constraints incorporates the new constraints.", "labels": [], "entities": []}, {"text": "In this case, the learning process uses the constraints already learned for RELAXCOR and adds the new constraints to the model.", "labels": [], "entities": []}, {"text": "The training process is then applied normally to compute the weight of the constraints using their precision in the training files.", "labels": [], "entities": [{"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9978737831115723}]}, {"text": "shows the results obtained when adding world knowledge compared with the results of RELAXCOR without world knowledge.", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.4795284569263458}]}, {"text": "The first three columns list the cWiki3 Output from the Organization of Petroleum Exporting Countries is already...", "labels": [], "entities": [{"text": "cWiki3 Output", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.9219803810119629}]}, {"text": "As a result, the effort by some oil ministers to get OPEC to approve...", "labels": [], "entities": [{"text": "OPEC", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.7044771909713745}]}, {"text": "The organization is scheduled to meet in Vienna...", "labels": [], "entities": []}, {"text": "Constraints for the entity-mention model are automatically obtained using the training data examples that the mention-pair model could not solve, with predefined influence rules and limited to N = 3.", "labels": [], "entities": []}, {"text": "The training process is explained in Section 4.4.", "labels": [], "entities": []}, {"text": "Experiments with the entity-mention model are conducted using both models at the same time.", "labels": [], "entities": []}, {"text": "The goal of the experiments is to improve the performance of the mention-pair model itself.", "labels": [], "entities": []}, {"text": "shows the experimental results using the SemEval-2010 English corpus.", "labels": [], "entities": [{"text": "SemEval-2010 English corpus", "start_pos": 41, "end_pos": 68, "type": "DATASET", "confidence": 0.8899679382642111}]}, {"text": "The table compares the entity-mention results (RELAXCOR using N = 3 constraints with influence rules, including the whole set of N = 2 constraints) with those using mentionpairs (RELAXCOR using just N = 2 constraints).", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.7786346077919006}]}, {"text": "The entity-mention model outperforms the mention-pair model.", "labels": [], "entities": []}, {"text": "The number of really useful examples (i.e., mentions wrongly classified by the mention-pair model but correctly classified by the entity-mention model), however, is low.", "labels": [], "entities": []}, {"text": "Consequently, the difference in their scores is not significant.", "labels": [], "entities": []}, {"text": "The N = 3 constraints have a good precision and also an acceptable recall, although most of the mentions affected by these constraints were already affected and correctly solved by the mention-pair model.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9993170499801636}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9994157552719116}]}, {"text": "Further research is needed in order to find more useful constraints, either by writing more elaborate group constraints or finding a better system that automatically finds them.", "labels": [], "entities": []}, {"text": "These results maybe somewhat justified, because the entity-mention model uses the same feature functions and, consequently, the same information as the mentionpair model.", "labels": [], "entities": []}, {"text": "In fact, only the new information is that information already included in the conditions of the influence rules, which take into account the entities assigned to each mention during resolution.", "labels": [], "entities": []}, {"text": "In addition, group constraints can also include, in an implicit way, information about the structure of the discourse.", "labels": [], "entities": []}, {"text": "It seems clear, however, that this new information is either minimal or not relevant enough.", "labels": [], "entities": []}, {"text": "shows an example of a learned entity-mention constraint.", "labels": [], "entities": []}, {"text": "Even though the obtained performance does not significantly outperform the mention-pair model, we can draw some positive conclusions from these experiments.", "labels": [], "entities": []}, {"text": "First of all, the approach is ready to use either model (mention-pair or entity-mention) in a constructive way.", "labels": [], "entities": []}, {"text": "As soon as new feature functions specific to entity-mention models appear, the results will reflect this.", "labels": [], "entities": []}, {"text": "One research line to follow in this field is the incorporation of feature functions following discourse theories, such as focusing and centering.", "labels": [], "entities": []}, {"text": "Another research line is the introduction of world knowledge using these models, as explained in the next section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Mention detection results on OntoNotes (Corpus: CoNLL-2011 Shared Task).", "labels": [], "entities": [{"text": "OntoNotes (Corpus: CoNLL-2011 Shared Task)", "start_pos": 39, "end_pos": 81, "type": "DATASET", "confidence": 0.8088401332497597}]}, {"text": " Table 2  Results on ACE-phase02.", "labels": [], "entities": [{"text": "ACE-phase02", "start_pos": 21, "end_pos": 32, "type": "DATASET", "confidence": 0.8512399792671204}]}, {"text": " Table 3  Results of RELAXCOR on development data (SemEval-2010).", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.48224321007728577}, {"text": "SemEval-2010)", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.8565803170204163}]}, {"text": " Table 4  Results of RELAXCOR on test data (SemEval-2010).", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9433187246322632}, {"text": "SemEval-2010)", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.8720630705356598}]}, {"text": " Table 5  RELAXCOR results on the development data set (CoNLL-2011).", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9703552722930908}, {"text": "development data set", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.8179163535435995}, {"text": "CoNLL-2011)", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.794748842716217}]}, {"text": " Table 6  RELAXCOR official test results (CoNLL-2011).", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8615046739578247}, {"text": "CoNLL-2011)", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.9306838512420654}]}, {"text": " Table 7  Comparison of RELAXCOR results using just the mention-pair model (N = 2) with those also  using the entity-mention model (N = 3) (Corpus:", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8016657829284668}]}, {"text": " Table 9  Results of RELAXCOR in English OntoNotes from SemEval-2010 without world knowledge.", "labels": [], "entities": [{"text": "RELAXCOR", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8320841193199158}]}]}