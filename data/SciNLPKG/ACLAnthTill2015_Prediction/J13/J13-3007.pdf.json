{"title": [{"text": "OntoLearn Reloaded: A Graph-Based Algorithm for Taxonomy Induction", "labels": [], "entities": [{"text": "Taxonomy Induction", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.842265397310257}]}], "abstractContent": [{"text": "In 2004 we published in this journal an article describing OntoLearn, one of the first systems to automatically induce a taxonomy from documents and Web sites.", "labels": [], "entities": []}, {"text": "Since then, OntoLearn has continued to bean active area of research in our group and has become a reference work within the community.", "labels": [], "entities": []}, {"text": "In this paper we describe our next-generation taxonomy learning methodology , which we name OntoLearn Reloaded.", "labels": [], "entities": [{"text": "OntoLearn Reloaded", "start_pos": 92, "end_pos": 110, "type": "DATASET", "confidence": 0.8383823335170746}]}, {"text": "Unlike many taxonomy learning approaches in the literature, our novel algorithm learns both concepts and relations entirely from scratch via the automated extraction of terms, definitions, and hypernyms.", "labels": [], "entities": []}, {"text": "This results in a very dense, cyclic and potentially disconnected hypernym graph.", "labels": [], "entities": []}, {"text": "The algorithm then induces a taxonomy from this graph via optimal branching and a novel weighting policy.", "labels": [], "entities": []}, {"text": "Our experiments show that we obtain high-quality results, both when building brand-new taxonomies and when reconstructing sub-hierarchies of existing taxonomies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ontologies have proven useful for different applications, such as heterogeneous data integration, information search and retrieval, question answering, and, in general, for fostering interoperability between systems.", "labels": [], "entities": [{"text": "data integration", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.7886379361152649}, {"text": "information search and retrieval", "start_pos": 98, "end_pos": 130, "type": "TASK", "confidence": 0.8630286008119583}, {"text": "question answering", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.9198406338691711}]}, {"text": "Ontologies can be classified into three main types, namely: i) formal ontologies, that is, conceptualizations whose categories are distinguished by axioms and formal definitions, stated in logic to support complex inferences and computations; ii) prototype-based ontologies, which are based on typical instances or prototypes rather than axioms and definitions in logic; iii) lexicalized (or terminological) ontologies, which are specified by subtype-supertype relations and describe concepts by labels or synonyms rather than by prototypical instances.", "labels": [], "entities": []}, {"text": "Here we focus on lexicalized ontologies because, in order to enable natural language applications such as semantically enhanced information retrieval and question answering, we need a clear connection between our formal representation of the Instead, we also analyze the extracted taxonomy in its entirety; furthermore, we acquire two \"brand new\" taxonomies in the domains of r Finally, our taxonomy-building workflow is fully implemented and the software components are either freely available from our Web site, or reproducible.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.7491256594657898}, {"text": "question answering", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.8680111765861511}]}, {"text": "In this paper we extend our recent work on the topic as follows: i) we describe in full detail the taxonomy induction algorithm; ii) we enhance our methodology with a final step aimed at creating a DAG, rather than a strict tree-like taxonomical structure; iii) we perform a large-scale multi-faceted evaluation of the taxonomy learning algorithm on six domains; and iv) we contribute a novel methodology for evaluating an automatically learned taxonomy against a reference gold standard.", "labels": [], "entities": [{"text": "taxonomy induction algorithm", "start_pos": 99, "end_pos": 127, "type": "TASK", "confidence": 0.8162537018458048}]}, {"text": "In Section 2 we illustrate the related work.", "labels": [], "entities": []}, {"text": "We then describe our taxonomyinduction algorithm in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4 we present our experiments, and discuss the results.", "labels": [], "entities": []}, {"text": "Evaluation is both qualitative (on new ARTIFICIAL INTELLIGENCE and FINANCE taxonomies), and quantitative (on WordNet and MeSH sub-hierarchies).", "labels": [], "entities": [{"text": "FINANCE", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.8783166408538818}, {"text": "WordNet", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.942969560623169}]}, {"text": "Section 5 is dedicated to concluding remarks.", "labels": [], "entities": [{"text": "concluding remarks", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9071792960166931}]}], "datasetContent": [{"text": "Ontology evaluation is a hard task that is difficult even for humans, mainly because there is no unique way of modeling the domain of interest.", "labels": [], "entities": [{"text": "Ontology evaluation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9278214573860168}]}, {"text": ", and more theoretical features (Guarino and Welty 2002) like essentiality, rigidity, and unity.", "labels": [], "entities": []}, {"text": "Methods (a) and (b) are by far the most popular ones.", "labels": [], "entities": []}, {"text": "In this section, we will discuss in some detail the pros and cons of these two approaches.", "labels": [], "entities": []}, {"text": "The most popular approach for the evaluation of lexicalized taxonomies (adopted, e.g., in Snow, Jurafsky, and Ng 2006; is to attempt to reconstruct an existing gold standard (Maedche, Pekar, and Staab 2002), such as WordNet or the Open Directory Project.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 216, "end_pos": 223, "type": "DATASET", "confidence": 0.9519495368003845}]}, {"text": "This method is applicable when the set of taxonomy concepts are given, and the evaluation task is restricted to measuring the ability to reproduce hypernymy links between concept pairs.", "labels": [], "entities": []}, {"text": "The evaluation is far more complex when learning a specialized taxonomy entirely from scratch, that is, when both terms and relations are unknown.", "labels": [], "entities": []}, {"text": "In reference taxonomies, even in the same domain, the granularity and cotopy 15 of an abstract concept might vary according to the scope of the taxonomy and the expertise of the team who created it.", "labels": [], "entities": [{"text": "cotopy 15", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9428385198116302}]}, {"text": "For example, both the terms chiaroscuro and collage are classified under picture, image, icon in WordNet, but in the Art & Architecture Thesaurus (AA&T) 16 chiaroscuro is categorized under perspective and shading techniques whereas collage is classified under image-making processes and techniques.", "labels": [], "entities": []}, {"text": "As long as common-sense, non-specialist knowledge is considered, it is still feasible for an automated system to replicate an existing classification, because the Web will provide abundant evidence for it.", "labels": [], "entities": []}, {"text": "For example, are very successful at reproducing the WordNet sub-taxonomy for ANIMALS, because dozens of definitional patterns are found on the Web that classify, for example, lion as a carnivorous feline mammal, or carnivorous, or feline.", "labels": [], "entities": [{"text": "WordNet sub-taxonomy", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.9421297907829285}]}, {"text": "As we show later in this section, however, and as also suggested by the previous AA&T example, finding hypernymy patterns in more specialized domains is far more complex.", "labels": [], "entities": [{"text": "AA&T", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.8586992820103964}]}, {"text": "Even in simpler domains, however, it is not clear how to evaluate the concepts and relations not found in the reference taxonomy.", "labels": [], "entities": []}, {"text": "Concerning this issue, Zornitsa Kozareva comments that: \"When we gave sets of terms to annotators and asked them to produce a taxonomy, people struggled with the domain terminology and produced quite messy organization.", "labels": [], "entities": []}, {"text": "Therefore, we decided to go with WordNet and use it as a gold truth\" (personal communication).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9765552878379822}]}, {"text": "Accordingly, K&H do not provide an evaluation of the nodes and relations other than those for which the ground truth is known.", "labels": [], "entities": []}, {"text": "This is further clarified in a personal communication: \"Currently we do not have a full list of all is-a outside WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 113, "end_pos": 120, "type": "DATASET", "confidence": 0.973969578742981}]}, {"text": "In the experiments, we work only with the terms present in WordNet [...]", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9653743505477905}]}, {"text": "The evaluation is based only on the WordNet relations.", "labels": [], "entities": [{"text": "WordNet relations", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.9054888486862183}]}, {"text": "However, the harvesting algorithm extracts much more.", "labels": [], "entities": []}, {"text": "Currently, we do not know how to evaluate the Web taxonomization.\"", "labels": [], "entities": []}, {"text": "To conclude, gold standard evaluation has some evident drawbacks: r When both concepts and relations are unknown, it is almost impossible to replicate a reference taxonomy accurately.", "labels": [], "entities": []}, {"text": "r In principle, concepts not in the reference taxonomy can be either wrong or correct; therefore the evaluation is in any case incomplete.", "labels": [], "entities": []}, {"text": "Another issue in gold standard evaluation is the definition of an adequate evaluation metric.", "labels": [], "entities": []}, {"text": "The most common measure used in the literature to compare a learned with a gold-standard taxonomy is the overlapping factor.", "labels": [], "entities": []}, {"text": "Given the set of is-a relations in the two taxonomies, the overlapping factor simply computes the ratio between the intersection and union of these sets.", "labels": [], "entities": []}, {"text": "Therefore the overlapping factor gives a useful global measure of the similarity between the two taxonomies.", "labels": [], "entities": []}, {"text": "It provides no structural comparison, however: Errors or differences in grouping concepts in progressively more general classes are not evidenced by this measure.", "labels": [], "entities": [{"text": "Errors", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9930773973464966}]}, {"text": "Comparison against a gold standard has been analyzed in a more systematic way by Zavitsanos, Paliouras, and Vouros (2011) and.", "labels": [], "entities": []}, {"text": "They propose two different strategies for escaping the \"naming\" problem that we have outlined.", "labels": [], "entities": [{"text": "escaping the \"naming\" problem", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.7213218112786611}]}, {"text": "Zavitsanos, Paliouras, and Vouros (2011) propose transforming the ontology concepts and their properties into distributions over the term space of the source data from which the ontology has been learned.", "labels": [], "entities": []}, {"text": "These distributions are used to compute pairwise concept similarity between gold standard and learned ontologies.", "labels": [], "entities": []}, {"text": "Brank, Mladenic, and exploit the analogy between ontology learning and unsupervised clustering, and propose OntoRand, a modified version of the Rand Index for computing the similarity between ontologies. and, however, demonstrated a high dependency of the Rand Index (and consequently of OntoRand itself) upon the number of clusters, and show that the Rand Index has the undesirable property of converging to 1 as the number of clusters increases, even in the unrealistic case of independent clusterings.", "labels": [], "entities": []}, {"text": "These undesired outcomes have also been experienced by, who note that \"the similarity of an ontology to the original one is still as high as 0.74 even if only the top three levels of the ontology have been kept.\"", "labels": [], "entities": [{"text": "similarity", "start_pos": 75, "end_pos": 85, "type": "METRIC", "confidence": 0.9785404205322266}]}, {"text": "Another problem with the OntoRand formula, as also remarked in Zavitsanos, Paliouras, and Vouros (2011), is the requirement of comparing ontologies with the same set of instances.", "labels": [], "entities": []}, {"text": "Comparison against a gold standard is important because it represents a sort of objective evaluation of an automated taxonomy learning method.", "labels": [], "entities": []}, {"text": "As we have already remarked, however, learning an existing taxonomy is not particularly interesting in itself.", "labels": [], "entities": []}, {"text": "Taxonomies are mostly needed in novel, often highly technical domains for which there are no gold standards.", "labels": [], "entities": []}, {"text": "For a system to claim to be able to acquire a taxonomy from the ground up, manual evaluation seems indispensable.", "labels": [], "entities": []}, {"text": "Nevertheless, none of the taxonomy learning systems surveyed in Section 2 performs such evaluation.", "labels": [], "entities": []}, {"text": "Furthermore, manual evaluation should not be limited to an assessment of the acquired hypernymy relations \"in isolation,\" but must also provide a structural assessment aimed at identifying common phenomena and the overall quality of the taxonomic structure.", "labels": [], "entities": []}, {"text": "Unfortunately, as already pointed out, manual evaluation is a hard task.", "labels": [], "entities": [{"text": "manual evaluation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.5495556890964508}]}, {"text": "Deciding whether or not a concept belongs to a given domain is more or less feasible fora domain expert, but assessing the quality of a hypernymy link is far more complex.", "labels": [], "entities": []}, {"text": "On the other hand, asking a team of experts to blindly reconstruct a hierarchy, given a set of terms, may result in the \"messy organization\" reported by Zornitsa Kozareva.", "labels": [], "entities": []}, {"text": "In contrast to previous approaches to taxonomy induction, OntoLearn Reloaded provides a natural solution to this problem, because is-a links in the taxonomy are supported by one or more definition sentences from which the hypernymy relation was extracted.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8831552565097809}]}, {"text": "As shown later in this section, definitions proved to be a very helpful feature in supporting manual analysis, both for hypernym evaluation and structural assessment.", "labels": [], "entities": [{"text": "hypernym evaluation", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.871741533279419}, {"text": "structural assessment", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.7840963006019592}]}, {"text": "The rest of this section is organized as follows.", "labels": [], "entities": []}, {"text": "We first describe the experimental set-up (Section 4.1): OntoLearn Reloaded is applied to the task of acquiring six taxonomies, four of which attempt to replicate already existing gold standard subhierarchies in WordNet and in the MeSH medical ontology, and the other two are new taxonomies acquired from scratch.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 212, "end_pos": 219, "type": "DATASET", "confidence": 0.9425879716873169}, {"text": "MeSH medical ontology", "start_pos": 231, "end_pos": 252, "type": "DATASET", "confidence": 0.8438333670298258}]}, {"text": "Next, we present a large-scale multi-faceted evaluation of OntoLearn Reloaded focused on three of the previously described evaluation methods, namely: comparison against a gold standard, manual evaluation, and structural evaluation.", "labels": [], "entities": [{"text": "OntoLearn Reloaded", "start_pos": 59, "end_pos": 77, "type": "DATASET", "confidence": 0.9161438643932343}]}, {"text": "In Section 4.2 we introduce a novel measure for comparing an induced taxonomy against a gold standard one.", "labels": [], "entities": []}, {"text": "Finally, Section 4.3 is dedicated to a manual evaluation of the six taxonomies.", "labels": [], "entities": []}, {"text": "We now provide details on the set-up of our experiments.", "labels": [], "entities": []}, {"text": "In this section we propose a novel, general measure for the evaluation of a learned taxonomy against a gold standard.", "labels": [], "entities": []}, {"text": "We borrow the Brank, Mladenic, and Grobelnik (2006) idea of exploiting the analogy with unsupervised clustering but, rather than representing the two taxonomies as flat clusterings, we propose a measure that takes into account the hierarchical structure of the two analyzed taxonomies.", "labels": [], "entities": []}, {"text": "Under this perspective, a taxonomy can be transformed into a hierarchical clustering by replacing each label of a non-leaf node (e.g., perspective and shading techniques) with the transitive closure of its hyponyms (e.g., cangiatismo, chiaroscuro, foreshortening, hatching).", "labels": [], "entities": []}, {"text": "in, although the only method for comparing hierarchical clusters, to the best of our knowledge, is that proposed by.", "labels": [], "entities": []}, {"text": "Suppose that we have two hierarchical clusterings H 1 and H 2 , with an identical set of n objects.", "labels": [], "entities": []}, {"text": "Let k be the maximum depth of both H 1 and H 2 , and H i j a cut of the hierarchy, where i \u2208 {0, . .", "labels": [], "entities": []}, {"text": ", k} is the cut level and j \u2208 {1, 2} selects the clustering of interest.", "labels": [], "entities": []}, {"text": "Then, for each cut i, the two hierarchies can be seen as two flat clusterings Ci 1 and Ci 2 of then concepts.", "labels": [], "entities": []}, {"text": "When i = 0 the cut is a single cluster incorporating all the objects, and when i = k we obtain n singleton clusters.", "labels": [], "entities": []}, {"text": "Now let: r n 11 be the number of object pairs that are in the same cluster in both Ci 1 and Ci 2 ; r n 00 be the number of object pairs that are in different clusters in both Ci 1 and Ci 2 ; r n 10 be the number of object pairs that are in the same cluster in Ci 1 but not in Ci 2 ; r n 01 be the number of object pairs that are in the same cluster in Ci The generalized Fowlkes and Mallows (F&M) measure of cluster similarity for the cut i (i \u2208 {0, . .", "labels": [], "entities": []}, {"text": ", k}), as reformulated by, is defined as: . Note that the formula can be interpreted as the geometric mean of precision and recall of an automated method in clustering the same concept pairs as in a gold-standard clustering.", "labels": [], "entities": [{"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9899918437004089}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9982142448425293}]}, {"text": "This formula has a few undesirable properties: first, the value of Bi 1,2 gets close to its maximum 1.0 as we approach the root of the hierarchy (i = 0); second, the two hierarchies need to have the same maximum depth k; third, the hierarchies need to have the same number of initial objects and a crisp classification.", "labels": [], "entities": [{"text": "Bi", "start_pos": 67, "end_pos": 69, "type": "METRIC", "confidence": 0.9512494802474976}]}, {"text": "In order to apply the F&M measure to the task of comparing a learned and a goldstandard taxonomy, we need to mitigate these problems.", "labels": [], "entities": [{"text": "F&M measure", "start_pos": 22, "end_pos": 33, "type": "DATASET", "confidence": 0.7535696774721146}]}, {"text": "Equation copes with the third problem without modifications.", "labels": [], "entities": []}, {"text": "In fact, if the sets of objects in H 1 and H 2 are different, the integers n 10 and n 01 can be considered as also including objects that belong to one hierarchy and not to the other.", "labels": [], "entities": []}, {"text": "In this case, the value of B 0 1,2 will provide a measure of the overlapping objects in the learned taxonomy and the gold standard one.", "labels": [], "entities": [{"text": "B", "start_pos": 27, "end_pos": 28, "type": "METRIC", "confidence": 0.9851676821708679}]}, {"text": "In order to take into account multiple (rather than crisp) classifications, again, there is no need to change the formula, which is still meaningful if an object is allowed to belong to more than one cluster.", "labels": [], "entities": []}, {"text": "As before, mismatches between H 1 and H 2 would result in higher values of n 10 and n 01 and lower Bi 1,2 . A more serious problem with Equation is that the lower the value of i, the higher the value of the formula, whereas, ideally, we would like to reward similar clusterings when the clustering task is more difficult and fine-grained, that is, for cuts that are close to the leaf nodes.", "labels": [], "entities": [{"text": "Bi", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.9828504323959351}, {"text": "Equation", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.7756332755088806}]}, {"text": "To assign a reward to \"early\" similarity values, we weight the values of Bi 1,2 with a coefficient i+1 k . We can then compute a cumulative measure of similarity with the following formula: Finally, to solve the problem of different depths of the two hierarchies, we define a policy that penalizes a learned taxonomy that is less structured than the gold standard one, and rewards-or at least does not penalize-the opposite case.", "labels": [], "entities": [{"text": "Bi", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9748625159263611}]}, {"text": "As an example, consider, which shows two taxonomies H 1 and H 2 , with non-identical sets of objects {a, b, c, d, e, f } and {a, b, c, d, e, g}.", "labels": [], "entities": []}, {"text": "In the figure each edge is labeled by its distance from the root node (the value i in the F&M formula).", "labels": [], "entities": [{"text": "F&M formula", "start_pos": 90, "end_pos": 101, "type": "DATASET", "confidence": 0.907868430018425}]}, {"text": "Notice that H 1 and H 2 have multiple classifications (i.e., multiple hypernyms in our case) for the object e, thus modeling the common problem of lexical ambiguity and polysemy.", "labels": [], "entities": []}, {"text": "Let us suppose that H 1 is the learned taxonomy, and H 2 the gold standard one.", "labels": [], "entities": []}, {"text": "We start comparing the clusterings at cut 0 and stop at cut k r \u2212 1, where k r is the depth of the gold standard taxonomy.", "labels": [], "entities": []}, {"text": "This means that if the learned taxonomy is less structured we replicate the cut kl \u2212 1 fork r \u2212 kl times (where kl is the maximum depth of the learned taxonomy), whereas if it is more structured we stop at cut k r \u2212 1.", "labels": [], "entities": []}, {"text": "In contrast to previous evaluation models, our aim is to reward (instead of penalize) more structured taxonomies provided they still match the gold standard one.", "labels": [], "entities": []}, {"text": "shows the cuts from 0 to 3 of H 1 and H 2 and the values of Bi 1,2 . For i = 2 the B value is 0, if H 2 is the learned taxonomy, and is not defined, if H 2 is the gold standard.", "labels": [], "entities": []}, {"text": "Therefore, when computing the cumulative Equation, we obtain the desired effect of penalizing less the structured learned taxonomies.", "labels": [], "entities": [{"text": "Equation", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.8468632102012634}]}, {"text": "Note that, when the two hierarchies have different depths, the value k \u2212 1 in Equation is replaced by k r \u2212 1.", "labels": [], "entities": [{"text": "Equation", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9617599844932556}]}, {"text": "Finally, we briefly compare our evaluation approach with the OntoRand index, introduced by.", "labels": [], "entities": []}, {"text": "The Rand Index measures the similarity between two clusterings Cl and Cr by the formula: where n 11 , n 00 , and n have the same meaning described earlier.", "labels": [], "entities": [{"text": "Rand Index", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7016221284866333}]}, {"text": "In Brank, Mladenic, and Grobelnik, a clustering is obtained from an ontology by associating each ontology instance to its concept.", "labels": [], "entities": []}, {"text": "The set of clusters is hence represented by the set of leaf concepts in the hierarchy, namely, according to our notation, the clustering C k\u22121 i . In order to take into account the hierarchical structure, they define the OntoRand formula.", "labels": [], "entities": []}, {"text": "This measure, rather than summing up to 1 or 0, depending on whether or not two given instances i and j belong to the same cluster in the compared ontologies, returns areal number in depending upon the distance between i and j in terms of common ancestors.", "labels": [], "entities": []}, {"text": "In other terms, if i and j do not belong to the same concept but have a very close common ancestor, the OntoRand measure returns a value still close to 1.", "labels": [], "entities": [{"text": "OntoRand measure", "start_pos": 104, "end_pos": 120, "type": "METRIC", "confidence": 0.6880308985710144}]}, {"text": "Our measure has several advantages over the OntoRand index: i) It allows fora comparison at different levels of depth of the hierarchy, and the cumulative similarity measure penalizes the contribution of the highest cuts of the hierarchy.", "labels": [], "entities": []}, {"text": "ii) It does not require that the two hierarchies have the same depth, nor that they have the same number of leaf nodes.", "labels": [], "entities": []}, {"text": "iii) The measure can be extended to lattices (e.g., it is not required that each object belongs precisely to one cluster).", "labels": [], "entities": []}, {"text": "This section is dedicated to the manual assessment of the learned ontologies.", "labels": [], "entities": []}, {"text": "The section is divided in three parts: Section 4.3.1 is concerned with the human validation of hypernymy relations, Section 4.3.2 examines the global learned taxonomic structure in the search for common phenomena across the six domains, and finally Section 4.3.3 investigates the possibility of enhancing our hypernymy harvesting method with K&H's Hearst-like patterns, applying their method to the AI domain and manually evaluating the extracted hypernyms.", "labels": [], "entities": []}, {"text": "To reduce subjectivity in taxonomy evaluation, we asked three annotators, only one of whom was a co-author, to validate, for each of the three experiments of each of the six domains, a random sample of hypernymy relations.", "labels": [], "entities": [{"text": "taxonomy evaluation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8763615787029266}]}, {"text": "For each relation the definition(s) supporting the relation were also provided.", "labels": [], "entities": []}, {"text": "This was especially helpful for domains like VIRUSES, but also PLANTS and ANIMALS, in which the annotators were not expert.", "labels": [], "entities": [{"text": "VIRUSES", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.5303101539611816}, {"text": "ANIMALS", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.7354553937911987}]}, {"text": "The size of each random sample was 300 for the (larger) AI and FINANCE domains and 100 for the others.", "labels": [], "entities": [{"text": "FINANCE", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.8711752891540527}]}, {"text": "Each evaluator was asked to tag incorrect relations, regardless of whether the error was due to the selection of non-domain definitions (e.g., for VEHICLES: \"a driver is a golf club with a near vertical face that is used for hitting long shots from the tee\"), to a poor definition (e.g., for AI: \"a principle is a fundamental essence, particularly one producing a given quality\") or to a wrong selection of the hypernym.", "labels": [], "entities": [{"text": "VEHICLES", "start_pos": 147, "end_pos": 155, "type": "DATASET", "confidence": 0.813800573348999}]}, {"text": "As an example of the latter, in the PLANTS domain, we extracted the hypernym species from the sentence: \"geranium is a genus of 422 species of flowering annual, biennial, and perennial plants   Almost perfect agreement that are commonly known as the cranesbills\" since, in the WCL verb set, we have \"is a * species of\" and \"is a * genus of\", but not the concatenation of these two patterns.", "labels": [], "entities": [{"text": "PLANTS domain", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.7881227731704712}, {"text": "WCL verb set", "start_pos": 277, "end_pos": 289, "type": "DATASET", "confidence": 0.7064012289047241}]}, {"text": "Annotators could mark with ? a hyponym-hypernym pair for which they felt uncertain.", "labels": [], "entities": []}, {"text": "Though it would have been useful to distinguish between the different types of error, we found that regarding many error types there was, anyway, very low inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Indeed the annotation task would appear to be intrinsically complex and controversial.", "labels": [], "entities": []}, {"text": "In any case, an assessment of the definition and hypernym extraction tasks in isolation was already provided by. summarizes the results.", "labels": [], "entities": [{"text": "hypernym extraction", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.6972185671329498}]}, {"text": "Precision of each classification was computed on a majority basis, and we used Fleiss' kappa statistics) to measure the interannotator agreement.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9861343502998352}]}, {"text": "In general, the precision is rather good, though it is lower for the AI domain, probably due to its high \"vitality\" (many new terms continuously arise, and for some of them it is difficult to find good quality definitions).", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9996427297592163}]}, {"text": "In general, precision is higher in focused domains (VIRUSES, ANIMALS, PLANTS, and VEHICLES) than in widerange domains (AI and FINANCE).", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9995276927947998}, {"text": "VIRUSES", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.6646922826766968}, {"text": "ANIMALS", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.7868244647979736}, {"text": "VEHICLES", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.6591660380363464}, {"text": "FINANCE", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.883359968662262}]}, {"text": "The former domains, however, have just one quite \"narrow\" upper concept (virus for VIRUSES, etc.), whereas AI and FINANCE have several upper concepts (e.g., person or abstraction), and furthermore they are less focused.", "labels": [], "entities": [{"text": "FINANCE", "start_pos": 114, "end_pos": 121, "type": "METRIC", "confidence": 0.7008941769599915}]}, {"text": "This means that there is an inherently higher ambiguity and this maybe seen as justifying the lower performance.", "labels": [], "entities": []}, {"text": "In we also note that TREE structures achieve in general a higher precision, except for PLANTS, whereas the DAG has the advantage of improving recall (see also Section 4.2.2).", "labels": [], "entities": [{"text": "TREE", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.8411930799484253}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9992372989654541}, {"text": "PLANTS", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9022592306137085}, {"text": "DAG", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.8881665468215942}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9992190599441528}]}, {"text": "Note that high precision here does not contradict the results shown in Section 4.2.2: In this case, each single relation is evaluated in isolation, therefore overgenerality or overspecificity do not imply a penalty, provided the relation is judged to be correct.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9990109205245972}]}, {"text": "Furthermore, global consistency is not considered here: for example, distance metric learning \u2190 parametric technique, and eventually ends up in technique, whereas belief network learning \u2190 machine learning algorithm ends up in algorithm and then in procedure.", "labels": [], "entities": [{"text": "distance metric learning", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.6340503394603729}]}, {"text": "In isolation, these hypernymy patterns are acceptable, but within a taxonomic structure one would like to see a category node grouping all terms denoting machine learning algorithms.", "labels": [], "entities": []}, {"text": "This behavior should be favored by the node weighting strategy described in Section 3.4, aimed at attracting nodes with multiple hypernyms towards the most populated category nodes.", "labels": [], "entities": []}, {"text": "As in the previous example, however, there are category nodes that are almost equally \"attractive\" (e.g., algorithm and technique), and, furthermore, the taxonomy induction algorithm can only select among the set of hypernyms extracted during the harvesting phase.", "labels": [], "entities": []}, {"text": "Consequently, when no definition suggests that distance metric learning is a hyponym of machine learning algorithm, or of any other concept connected to machine learning algorithm, there is noway of grouping distance metric learning and belief network learning in the desired way.", "labels": [], "entities": [{"text": "distance metric learning", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7188797990481058}]}, {"text": "This task must be postponed to manual post-editing.", "labels": [], "entities": []}, {"text": "Concerning the kappa statistics, we note that the values range from moderate to substantial inmost cases.", "labels": [], "entities": []}, {"text": "These numbers are apparently low, but the task of evaluating hypernymy relations is quite a complex one.", "labels": [], "entities": []}, {"text": "Similar kappa values were obtained in in a human-guided ontology learning task.", "labels": [], "entities": []}, {"text": "As previously remarked, do not actually apply their algorithm to the task of creating anew taxonomy, but rather they try to reproduce three WordNet taxonomies, under the assumption that the taxonomy nodes are known (cf. Section 4).", "labels": [], "entities": []}, {"text": "Therefore, there is no evidence of the precision of their method on new domains, where the category nodes are unknown.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9988856911659241}]}, {"text": "On the other hand, if Hearst's patterns, which are at the basis of K&H's hypernymy harvesting algorithm, could show adequate precision, we would use them in combination with our definitional patterns.", "labels": [], "entities": [{"text": "precision", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9950944185256958}]}, {"text": "This section investigates the matter.", "labels": [], "entities": []}, {"text": "As briefly summarized in Section 2, K&H create a hypernym graph in three steps.", "labels": [], "entities": []}, {"text": "Given a few root concepts (e.g., animal) and basic level concepts or instances (e.g., lion), they:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6  Structural evaluation of three versions of our taxonomy-learning algorithm on six different  domains.", "labels": [], "entities": []}, {"text": " Table 8  Values of B 1,2 for the domains of VIRUSES, ANIMALS, PLANTS, and VEHICLES.", "labels": [], "entities": [{"text": "B", "start_pos": 20, "end_pos": 21, "type": "METRIC", "confidence": 0.9815011620521545}, {"text": "VIRUSES", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.49646440148353577}, {"text": "ANIMALS", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.9134058356285095}, {"text": "PLANTS", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.8091341257095337}, {"text": "VEHICLES", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.6124935746192932}]}, {"text": " Table 9  Precision of hypernym edges on six domains (calculated on a majority basis) and inter-annotator  agreement on the corresponding sample of relations.", "labels": [], "entities": []}, {"text": " Table 10  K&H performance on the AI domain.", "labels": [], "entities": []}]}