{"title": [{"text": "Knowledge Sources for Constituent Parsing of German, a Morphologically Rich and Less-Configurational Language", "labels": [], "entities": [{"text": "Constituent Parsing of German", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.7988024204969406}]}], "abstractContent": [{"text": "We study constituent parsing of German, a morphologically rich and less-configurational language.", "labels": [], "entities": []}, {"text": "We use a probabilistic context-free grammar treebank grammar that has been adapted to the morphologically rich properties of German by markovization and special features added to its productions.", "labels": [], "entities": []}, {"text": "We evaluate the impact of adding lexical knowledge.", "labels": [], "entities": []}, {"text": "Then we examine both monolingual and bilingual approaches to parse reranking.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.8189572095870972}]}, {"text": "Our reranking parser is the new state of the art in constituency parsing of the TIGER Treebank.", "labels": [], "entities": [{"text": "reranking parser", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.6240067780017853}, {"text": "constituency parsing", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.820129930973053}, {"text": "TIGER Treebank", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.9319679737091064}]}, {"text": "We perform an analysis, concluding with lessons learned, which apply to parsing other morphologically rich and less-configurational languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "A large part of the methodology for parsing in natural language processing has been developed for English and a majority of publications on parsing are about parsing of English.", "labels": [], "entities": [{"text": "parsing in natural language processing", "start_pos": 36, "end_pos": 74, "type": "TASK", "confidence": 0.6138071954250336}, {"text": "parsing", "start_pos": 140, "end_pos": 147, "type": "TASK", "confidence": 0.9620546102523804}, {"text": "parsing of English", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.872669001420339}]}, {"text": "English is a strongly configurational language.", "labels": [], "entities": []}, {"text": "Nearly all of the syntactic information needed by any NLP application can be obtained by configurational analysis (e.g., by having a correct constituent parse).", "labels": [], "entities": []}, {"text": "Many other languages of the world are fundamentally different from English in this respect.", "labels": [], "entities": []}, {"text": "At the other end of the configurational-nonconfigurational spectrum we find a language like Hungarian that has very little fixed structure on the level of the sentence.", "labels": [], "entities": []}, {"text": "Leaving aside the issue of the internal structure of NPs, most sentence-level syntactic information in Hungarian is conveyed by morphology, not by configuration.", "labels": [], "entities": []}, {"text": "In this paper, we address German, a third type of language that is intermediate between English and Hungarian.", "labels": [], "entities": []}, {"text": "German has strong configurational constraints (e.g., main clauses are verb-second) as well as rich derivational and inflectional morphology, all of which must be modeled for high-quality parsing.", "labels": [], "entities": []}, {"text": "German's intermediate status raises a number of interesting issues in parsing that are of particular prominence fora mixed configurational/morphological language, but are-as we will argue-of general relevance for morphologically rich languages.", "labels": [], "entities": []}, {"text": "Partly this is the case because there are few (if any) languages archetypical of being purely configurational and purely nonconfigurational (e.g., morphology is also important for English and even Hungarian has configurational constraints).", "labels": [], "entities": []}, {"text": "For lack of a better term we refer to intermediate languages as typified by German as MR&LC for morphologically rich and less-configurational.", "labels": [], "entities": []}, {"text": "Part of the motivation for this special issue is that most work on parsing to date has been done on English, a morphologically simple language.", "labels": [], "entities": []}, {"text": "As computational linguistics broadens its focus beyond English it becomes important to take a more general approach to parsing that can handle languages that are typologically very different from English.", "labels": [], "entities": []}, {"text": "Rich morphology (RM) is one very salient characteristic of a language that affects the design of parsing methods.", "labels": [], "entities": [{"text": "Rich morphology (RM)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6487256050109863}]}, {"text": "We argue that there are two other properties of languages that are relevant in a discussion of parsing RM languages: syncretism and configurationality.", "labels": [], "entities": [{"text": "parsing RM languages", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.824053943157196}]}, {"text": "These two properties are correlated typologically with RM and should therefore betaken into account when we address parsing RM languages.", "labels": [], "entities": [{"text": "parsing RM languages", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.8600508570671082}]}, {"text": "We first define the three properties and explain their relevance for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.9731733202934265}]}, {"text": "The large number of languages for which this correlation holds can be ordered along a single dimension that can be interpreted as degree of morphological complexity.", "labels": [], "entities": []}, {"text": "We give examples fora number of languages that are positioned at different points on this scale.", "labels": [], "entities": []}, {"text": "Finally, we argue that just as languages that are at the opposite end of the spectrum from English (prototypical examples of morphological richness like Hungarian) require parsing methods that can be quite different from those optimal for English, the same is true fora language like German that is in the middle of the spectrum-and what is required is in some respects different from what is optimal for one extreme (English) or the other (Hungarian).", "labels": [], "entities": []}, {"text": "The three correlated properties are rich morphology, syncretism, and configurationality.", "labels": [], "entities": []}, {"text": "Morphological richness can be roughly measured by the number of different morphological forms a word of a particular syntactic category can have; for example, atypical English noun has two forms (singular and plural), atypical German noun has eight forms (singular and plural in four different cases), and atypical Hungarian noun has several hundreds of forms.", "labels": [], "entities": []}, {"text": "Syncretism refers to the fact that different morphological forms have identical surface realization; for example, the form Mann ('man' in German) can be the nominative, dative, or accusative singular of Mann depending on context.", "labels": [], "entities": []}, {"text": "Configurationality refers to the degree to which the arrangement of words and phrases of a particular syntactic function in a sentence is fixed.", "labels": [], "entities": []}, {"text": "English is highly configurational: it has limited flexibility in how the major phrases in a sentence (subject, verb, direct object, indirect object, etc.) can be ordered.", "labels": [], "entities": []}, {"text": "Hungarian and Latin are highly flexible: Even though there are pragmatic constraints, in principle a large number of possible orderings are grammatical.", "labels": [], "entities": []}, {"text": "It has some strict constraints (verb second in main clauses, verb final insubordinate clauses), but also some properties of a nonconfigurational language; for example, ordering of phrases in the mittelfeld (the part of the main clause enclosed by the two parts of the verbal complex) is very flexible.", "labels": [], "entities": []}, {"text": "It is obvious why configurationality and rich morphology are typologically (negatively) correlated.", "labels": [], "entities": []}, {"text": "Rich morphology specifies the syntactic role of a phrase in the sentence, so fixing a position is not required, and many morphologically rich languages therefore do not fix the position.", "labels": [], "entities": []}, {"text": "Conversely, simple morphology gives little specific information about the role of words and phrases in the sentence.", "labels": [], "entities": []}, {"text": "One device often used by morphologically simple languages to address this problem and reduce widespread ambiguity is to fix the order of words and phrases in the sentence.", "labels": [], "entities": []}, {"text": "Syncretism has an effect that is similar to simplification of complex morphology.", "labels": [], "entities": []}, {"text": "Simple morphology is unspecific about grammatical function because it uses a small number of morphological categories.", "labels": [], "entities": [{"text": "Simple morphology", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7929654717445374}]}, {"text": "Syncretism is unspecific about grammatical function because it suffers from a high degree of ambiguity.", "labels": [], "entities": []}, {"text": "Even though the number of different morphological categories is potentially large, syncretic forms conflate many of these categories, so that these forms are much less helpful in determining grammatical function than forms in a nonsyncretic language with the same number of categories.", "labels": [], "entities": []}, {"text": "Again, to counteract the communicative difficulties that lack of morphological specificity would create, stricter constraints on ordering and configuration are often used by syncretic languages.", "labels": [], "entities": []}, {"text": "We have used English and Hungarian as examples for the extremes and German for the middle of the spectrum.", "labels": [], "entities": []}, {"text": "We now give examples of other languages and their positions on the scale.", "labels": [], "entities": []}, {"text": "Dutch is similar to German in that it also is verb second in main clauses and verb final insubordinate clauses.", "labels": [], "entities": []}, {"text": "The order of arguments in the mittelfeld is much more restricted than in German, however.", "labels": [], "entities": []}, {"text": "At the same time, Dutch morphology has been much more simplified in the last centuries than German morphology.", "labels": [], "entities": [{"text": "Dutch morphology", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.6984025537967682}]}, {"text": "This nicely confirms the correlation between RM and configurationality.", "labels": [], "entities": [{"text": "RM", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9123306274414062}]}, {"text": "Thus, Dutch is positioned between English and German on the scale.", "labels": [], "entities": []}, {"text": "Classical Arabic is somewhat similar to German: The number of different morphological forms is roughly comparable to German and it allows a number of different word orders.", "labels": [], "entities": []}, {"text": "Modern Standard Arabic speakers rarely mark case, however, at least not in spontaneous speech.", "labels": [], "entities": []}, {"text": "At the same time, Modern Standard Arabic speakers use SVO order much more frequently and consistently than is the casein Classical Arabic.", "labels": [], "entities": []}, {"text": "Thus, Classical Arabic is roughly at the same position as German on the scale whereas spoken Modern Standard Arabic maybe more comparable to Dutch.", "labels": [], "entities": []}, {"text": "Finally, Modern Greek is a language that is intermediate between German and Hungarian.", "labels": [], "entities": []}, {"text": "It has richer morphology than German, but it has a fair amount of syncretism and therefore more morphological ambiguity than Hungarian.", "labels": [], "entities": []}, {"text": "SVO is the predominant word order in modern Greek, but other word orders can be used.", "labels": [], "entities": []}, {"text": "The order within the noun phrase is more flexible than in German: Adjectives can precede or follow the noun.", "labels": [], "entities": []}, {"text": "In the examples we have given, the amount of information conveyed by a morphological form is negatively correlated with the amount of information conveyed by configuration.", "labels": [], "entities": []}, {"text": "If morphology conveys a lot of information (due to a large number of distinctions and the lack of syncretism), then word order is freer and conveys less information.", "labels": [], "entities": []}, {"text": "If morphology conveys less information (due to fewer distinctions or more syncretism), then configuration is fixed and provides more information to the speaker.", "labels": [], "entities": []}, {"text": "This suggests that RM and configuration are important variables that should betaken into account in the design of parsing methods.", "labels": [], "entities": [{"text": "parsing", "start_pos": 114, "end_pos": 121, "type": "TASK", "confidence": 0.9625067114830017}]}, {"text": "In addition to looking at the extremes of the spectrum that are exemplified by English and Hungarian, we should also investigate the middle: morphologically (somewhat) rich languages that are less configurational.", "labels": [], "entities": []}, {"text": "In this article, we look at the example of German.", "labels": [], "entities": []}, {"text": "One key question for MR&LC parsing is which type of parsing formalism to adopt, constituency or dependency.", "labels": [], "entities": [{"text": "MR&LC parsing", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.715083584189415}]}, {"text": "It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing).", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 233, "end_pos": 253, "type": "TASK", "confidence": 0.7049596905708313}]}, {"text": "As point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages.", "labels": [], "entities": []}, {"text": "In fact, most state-of-the-art dependency parsers) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step.", "labels": [], "entities": []}, {"text": "Comparable post-processing techniques have been used in English constituency parsing to identify discontinuous constituents and might work for other languages, as well.", "labels": [], "entities": [{"text": "English constituency parsing", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.5713108877340952}]}, {"text": "The overview paper of the Parsing German Shared Task (K \u00a8 ubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparison is not fair as it required phrase boundaries to be correct on the constituent side while the tokens were the unit of evaluation on the dependency side.", "labels": [], "entities": [{"text": "Parsing German Shared Task (K \u00a8 ubler 2008)", "start_pos": 26, "end_pos": 69, "type": "TASK", "confidence": 0.7265702545642853}]}, {"text": "How to carryout an absolutely fair comparison of the two representations is still an open research question.", "labels": [], "entities": []}, {"text": "Constituent parses often provide more information than dependency parses.", "labels": [], "entities": [{"text": "Constituent parses", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.721186637878418}]}, {"text": "An example is the coordination ambiguity in old men and women versus old men and children.", "labels": [], "entities": []}, {"text": "The correct constituent parse for the first expression contains a coordination at the noun level whereas the parse for the second expression coordinates at the level of NPs.", "labels": [], "entities": []}, {"text": "The dependency structures of both expressions, on the other hand, are usually identical and thus unable to reflect the fact that old modifies women but not children.", "labels": [], "entities": []}, {"text": "It is possible, in principle, to encode the difference in dependency trees (cf. Rambow 2010), 2 This is due to how the evalb tool used to calculate PARSEVAL works.", "labels": [], "entities": []}, {"text": "If a constituent is not perfectly matched, the grammatical function is considered to be wrong, even if there was a partial match (at the token level).", "labels": [], "entities": []}, {"text": "This is not a problem with dependency-based evaluation.", "labels": [], "entities": []}, {"text": "For further discussion of the PARSEVAL metric and dependency-based evaluation see, for example, and Tsarfaty, Nivre, and Andersson (2012).", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.701592206954956}]}, {"text": "3 Two possible solutions are to use, or to conduct an analysis of grammatical functions at the token level in a consistent fashion for both dependency and constituent parsers.", "labels": [], "entities": []}, {"text": "In our case, the latter would require a high quality conversion from the Tiger constituency representation to a dependency representation, which we hope to implement in future work.", "labels": [], "entities": [{"text": "Tiger constituency representation", "start_pos": 73, "end_pos": 106, "type": "DATASET", "confidence": 0.9189023971557617}]}, {"text": "for example, by enriching the edge labels, but the constituent representation is simpler for this phenomenon.", "labels": [], "entities": []}, {"text": "Finally, there are some applications that need constituent parses rather than dependency parses.", "labels": [], "entities": []}, {"text": "For instance, many hierarchical statistical machine translation systems use constituency parses, requiring the output of a dependency parser to be transformed into a constituent parse.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.630233496427536}]}, {"text": "We conclude that there is no clear evidence for preferring dependency parsing over constituency parsing in analyzing languages with RM and instead argue that research in both frameworks is important.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7849908173084259}, {"text": "constituency parsing", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7302123755216599}]}, {"text": "We view the detailed description of a constituency parsing system fora morphologically rich language, a system that addresses the major problems that arise in constituency parsing for MR&LC, as one of our main contributions in this paper.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.7668635845184326}, {"text": "constituency parsing", "start_pos": 159, "end_pos": 179, "type": "TASK", "confidence": 0.7705274224281311}, {"text": "MR&LC", "start_pos": 184, "end_pos": 189, "type": "DATASET", "confidence": 0.7369990150133768}]}, {"text": "The first problem we address is the proliferation of phrase structure rules in MR&LC languages.", "labels": [], "entities": []}, {"text": "For example, there area large number of possible orderings of the phrases in the German mittelfeld, and many orderings are exceedingly rare.", "labels": [], "entities": []}, {"text": "A standard constituency parser cannot estimate probabilities for the corresponding rules reliably.", "labels": [], "entities": []}, {"text": "The solution we adopt here is markovization-complex rules are decomposed into small unidirectional rules that can be modeled and estimated more reliably than complex rules.", "labels": [], "entities": []}, {"text": "Although markovization in itself is not new, we stress its importance for MR&LC languages here and present a detailed, reproducible account of how we use it for German.", "labels": [], "entities": []}, {"text": "Markovization combines the best of both worlds for MR&LC languages: Preferential configurational information can be formalized and exploited by the parser without incurring too large of a performance penalty due to sparse data problems.", "labels": [], "entities": []}, {"text": "The second problem that needs to be addressed in parsing many MR&LC languages is widespread syncretism.", "labels": [], "entities": [{"text": "parsing", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.9641113877296448}]}, {"text": "We mainly address syncretism by using a high performance finite-state automata-based morphological analyzer.", "labels": [], "entities": []}, {"text": "Such an analyzer is of obvious importance for any morphologically rich language because the productivity of morphologically rich languages significantly increases the unknown-word rate in new text versus morphologically poor languages.", "labels": [], "entities": []}, {"text": "So the parser cannot simply memorize the grammatical properties of words in the Treebank used for training.", "labels": [], "entities": []}, {"text": "Instead we incorporate a complex guesser into our parser that, based on the input from the morphological analyzer, predicts the grammatical properties of new words and (equally important) unobserved grammatical properties of known words.", "labels": [], "entities": []}, {"text": "With prevailing syncretism, this task is much more complex than in a language where case, gender, number, and so forth, can be deterministically deduced from morphology.", "labels": [], "entities": []}, {"text": "The morphological analyzer is based on (i) a finite state formalization of German morphology and (ii) a large lexicon of morphologically analyzed German words.", "labels": [], "entities": [{"text": "morphological analyzer", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7662458121776581}]}, {"text": "We refer to these two components together as lexical knowledge.", "labels": [], "entities": []}, {"text": "We show that lexical knowledge is beneficial for parsing performance for an MR&LC language like German.", "labels": [], "entities": [{"text": "parsing", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.9657477736473083}]}, {"text": "In addition to lexical knowledge, there is a second important aspect of syncretism that needs to be addressed in MR&LC languages.", "labels": [], "entities": [{"text": "MR&LC languages", "start_pos": 113, "end_pos": 128, "type": "TASK", "confidence": 0.6711526960134506}]}, {"text": "Syntactic disambiguation in these languages must always involve both systems of grammatical encoding, morphology and configuration, acting together.", "labels": [], "entities": [{"text": "Syntactic disambiguation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8581063449382782}]}, {"text": "The most natural way of doing this in a language like German is to perform this integration of the two knowledge sources directly as part of parsing.", "labels": [], "entities": []}, {"text": "We do this by annotating constituent labels with grammatical function where appropriate.", "labels": [], "entities": []}, {"text": "In contrast with syntactic parses of strongly configurational languages like English, syntactic parses of German are not useful for most tasks without having grammatical functions indicated.", "labels": [], "entities": []}, {"text": "It is not even possible to access the basic subcategorization of the verb (such as determining the subject) without grammatical functions.", "labels": [], "entities": []}, {"text": "We argue that MR&LC languages like German should always be evaluated on labelscum-grammatical-function.", "labels": [], "entities": []}, {"text": "Our last main contribution in this paper concerns the fact that we believe that MR&LC languages give rise to more ambiguity than languages that are predominantly configurational or morphological.", "labels": [], "entities": []}, {"text": "As an example consider the German sentence \"Die [the] Katze jagt die [the] Schlange.\"", "labels": [], "entities": []}, {"text": "In German either the cat or the snake can be the hunter.", "labels": [], "entities": []}, {"text": "This type of ambiguity neither occurs in a strongly configurational language like English (where configuration determines grammatical function) nor in a morphologically rich language like Hungarian that has no or little syncretism (where morphology determines grammatical function).", "labels": [], "entities": []}, {"text": "Although morphology and configuration in MR&LC languages often work hand in hand for complete disambiguation, there are also many sentences where neither of the two provides the necessary information for disambiguation.", "labels": [], "entities": []}, {"text": "We believe that this distinguishing characteristic of MR&LC languages makes it necessary to tap additional knowledge sources.", "labels": [], "entities": []}, {"text": "In this paper, we look at two such knowledge sources: monolingual reranking (which captures global properties of well-formed parses for additional disambiguation) and bilingual reranking (which exploits parallel text in a different language for disambiguation).", "labels": [], "entities": []}, {"text": "For monolingual reranking, we define a novel set of rich features based on subcategorization frames.", "labels": [], "entities": []}, {"text": "We compare our compact feature set with a sparse feature set designed for German previously by.", "labels": [], "entities": []}, {"text": "We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set-moreover, they complement each other.", "labels": [], "entities": []}, {"text": "For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.5475847721099854}]}, {"text": "We pursue this approach fora number of reasons.", "labels": [], "entities": []}, {"text": "First, one limiting factor for syntactic approaches to statistical machine translation is parse quality.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.739141176144282}]}, {"text": "Improved parses of bitext should result in improved machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.6995498090982437}]}, {"text": "Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext.", "labels": [], "entities": []}, {"text": "Third, we hope that the improved parses of bitext can serve as higher quality training data for improving monolingual parsing using a process similar to self-training.", "labels": [], "entities": [{"text": "parses", "start_pos": 33, "end_pos": 39, "type": "TASK", "confidence": 0.957184374332428}, {"text": "monolingual parsing", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.5064893364906311}]}, {"text": "We show that the three different knowledge sources we use in this paper (lexical knowledge, monolingual features, and bilingual features) are valuable separately.", "labels": [], "entities": []}, {"text": "We also show that the gain of the two sets of reranking features (monolingual and bilingual) is additive, suggesting that they capture different types of information.", "labels": [], "entities": []}, {"text": "The resulting parser is currently the best constituent parser for German (with or without bilingual features).", "labels": [], "entities": []}, {"text": "In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain.", "labels": [], "entities": []}], "datasetContent": [{"text": "As we present each knowledge source, we would like to evaluate it against manually annotated Treebanks.", "labels": [], "entities": []}, {"text": "Our first evaluation shows that our generative parser introduced in the previous section is comparable with the Berkeley generative parser.", "labels": [], "entities": [{"text": "generative parser", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.945889413356781}]}, {"text": "Before we present this comparison in Section 4.1 we discuss evaluating parse accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.8473001718521118}]}, {"text": "In our evaluations, we use the Tiger Treebank ( and a small Europarl Treebank (Pad\u00f3Pad\u00b4Pad\u00f3 and Lapata 2009).", "labels": [], "entities": [{"text": "Tiger Treebank", "start_pos": 31, "end_pos": 45, "type": "DATASET", "confidence": 0.9908167123794556}, {"text": "Europarl Treebank", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.9942743480205536}, {"text": "Pad\u00f3Pad\u00b4Pad\u00f3 and Lapata 2009", "start_pos": 79, "end_pos": 107, "type": "DATASET", "confidence": 0.849494680762291}]}, {"text": "We take the first 40,474 sentences of the Tiger Treebank as training data (Tiger train), the next 5,000 sentences as development data (Tiger dev), and the last 5,000 sentences as test data (Tiger test).", "labels": [], "entities": [{"text": "Tiger Treebank", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9552631080150604}, {"text": "Tiger train)", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.8513142069180807}, {"text": "Tiger test", "start_pos": 190, "end_pos": 200, "type": "DATASET", "confidence": 0.932322770357132}]}, {"text": "The Europarl data consists of 662 sentences and are either completely used as test data and not divided up or we carried out seven-fold cross-validation experiments with our reranking models.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9946316480636597}]}, {"text": "All parsers are evaluated on projectivized parse trees.", "labels": [], "entities": []}, {"text": "This means that we apply step 1 of the grammar extraction process described in Section 3.1 to the test parses and use the result as the gold standard (except for the Pad\u00f3Pad\u00b4Pad\u00f3 set, which is already projectivized).", "labels": [], "entities": [{"text": "grammar extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7023206651210785}, {"text": "Pad\u00f3Pad\u00b4Pad\u00f3 set", "start_pos": 166, "end_pos": 182, "type": "DATASET", "confidence": 0.7874805629253387}]}, {"text": "The test sentences are parsed and the resulting parse trees are converted The weighted information gain is the difference between the entropy of the parent node and the entropy of the current node, multiplied by the total frequency of the current node and divided by the number of \"observed\" POS tags of the current node.", "labels": [], "entities": []}, {"text": "14 A similar pooling of lexicon entries was previously used in the POS tagger of.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.8794203400611877}]}, {"text": "15 We use only the sentences in this set which had a single sentence as a translation, so that they could be used in bilingual reranking, which will be discussed later.", "labels": [], "entities": []}, {"text": "to the same format as the gold standard trees by undoing Steps 2, 3, and 4 of Section 3.1.", "labels": [], "entities": []}, {"text": "This conversion involves four steps: 1.", "labels": [], "entities": []}, {"text": "Demarkovization removes all the auxiliary nodes introduced by markovization and raises their children to the next non-auxiliary node.", "labels": [], "entities": []}, {"text": "We rerank 100-best lists from BitPar (Schmid 2004), which uses the grammar extraction procedure and lexical resources introduced in Section 3.", "labels": [], "entities": [{"text": "grammar extraction", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.6953405290842056}]}, {"text": "In each of the experiments we extracted the grammar from the Tiger train and used it to obtain the 100-best parses for the sentences of the evaluation corpus.", "labels": [], "entities": [{"text": "Tiger train", "start_pos": 61, "end_pos": 72, "type": "DATASET", "confidence": 0.9400674998760223}]}, {"text": "We trained reranking models on the Tiger train as described in Section 6 using our subcategorization-based features, the Versley09 feature set, and the union of these two The PARSEVAL score of monolingual features to rerank the parses of Europarl (seven-way cross-validation on 662 sentences) and Tiger2 (development and test sets).", "labels": [], "entities": [{"text": "Tiger train", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.954062819480896}, {"text": "Versley09 feature set", "start_pos": 121, "end_pos": 142, "type": "DATASET", "confidence": 0.8583436210950216}, {"text": "PARSEVAL score", "start_pos": 175, "end_pos": 189, "type": "METRIC", "confidence": 0.9619108736515045}, {"text": "Europarl", "start_pos": 238, "end_pos": 246, "type": "DATASET", "confidence": 0.9773964881896973}]}, {"text": "In the latter we followed the seven-fold cross-validation approach, that is, the reranking models were trained on six-sevenths of Europarl.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 130, "end_pos": 138, "type": "DATASET", "confidence": 0.9935312867164612}]}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "The results presented in show that the reranking models achieve an improvement over the baseline parser using both our and the Versley09 feature sets.", "labels": [], "entities": [{"text": "Versley09 feature sets", "start_pos": 127, "end_pos": 149, "type": "DATASET", "confidence": 0.9498144189516703}]}, {"text": "The Versley09 feature set achieved better results than our monolingual features when a training dataset with sufficient size is given (Tiger).", "labels": [], "entities": [{"text": "Versley09 feature set", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.8778956333796183}]}, {"text": "On the other hand using our 16 rich features (compared with 117,000 sparse features) is more suitable for the settings where only a limited amount of training instances are available (the training sets consist of 567 sentences of Europarl in seven-fold cross-validation).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 230, "end_pos": 238, "type": "DATASET", "confidence": 0.9805670380592346}]}, {"text": "The reranking models using the union of the feature sets obtain close to the sum of the improvements of the two individual feature sets.", "labels": [], "entities": []}, {"text": "The subcategorization features model rich non-local information, and the fine-grained features capture local distinctions well and the features based on the Web corpus access additional knowledge.", "labels": [], "entities": []}, {"text": "We performed an experiment adding one feature at a time, and found that the most effective features were ProbAdverbAttach, MI VPP, MI VPRF, MI VSubj, and MI VArg.", "labels": [], "entities": [{"text": "ProbAdverbAttach", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.909746527671814}]}, {"text": "After this the variation caused by numeric instability was too high to see a consistent incremental gain from the rest of the features.", "labels": [], "entities": []}, {"text": "We conclude that these features can be robustly estimated and have more discriminative power than the others, but we emphasize that we used all features in our experiments.", "labels": [], "entities": []}, {"text": "shows a parse tree produced by the BitPar parser in which the noun phrase diese Finanzierung is incorrectly classified as an accusative object.", "labels": [], "entities": []}, {"text": "The monolingual subcategorization features MI VSubcat, MI VSimpleSubcat, and MI VArg enable the reranker to correctly analyze the noun phrase as a subject and to move it from the VP level to the S level.", "labels": [], "entities": []}, {"text": "We performed experiments looking at bilingual reranking performance.", "labels": [], "entities": []}, {"text": "To train the parameters of the probabilistic feature functions, we use 1-best parses of the large Europarl parallel corpus (from CJRERANK and BitPar).", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 98, "end_pos": 122, "type": "DATASET", "confidence": 0.9329667886098226}]}, {"text": "We work on the same 100-best list (of the German sentences in the small Pad\u00f3Pad\u00b4Pad\u00f3 set) as was used in the previous section.", "labels": [], "entities": [{"text": "Pad\u00f3Pad\u00b4Pad\u00f3 set", "start_pos": 72, "end_pos": 88, "type": "DATASET", "confidence": 0.8129567503929138}]}, {"text": "We parse the English sentences of the small Europarl set with CJRERANK; this parse is used as our bilingual knowledge source.", "labels": [], "entities": [{"text": "Europarl set", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9364947378635406}]}, {"text": "Finally we rerank using the bilingual features (results in the first row of).", "labels": [], "entities": []}, {"text": "We then combine the monolingual features with the bilingual features.", "labels": [], "entities": []}, {"text": "We rerank using both the monolingual and the bilingual features together, and the results are presented in.", "labels": [], "entities": []}, {"text": "The bilingual feature-based reranker achieved 1 percentage point improvement over the baseline.", "labels": [], "entities": []}, {"text": "This advantage was just slightly decreased when monolingual features are also present.", "labels": [], "entities": []}, {"text": "This indicates again that the monolingual and bilingual features can capture different linguistic phenomena and their information content is rather different.", "labels": [], "entities": []}, {"text": "As in the Europarl IN setting, using the large sparse Versley09 feature set the reranker could not learn a meaningful model from a moderate-sized training data set.", "labels": [], "entities": [{"text": "Europarl IN setting", "start_pos": 10, "end_pos": 29, "type": "DATASET", "confidence": 0.9477594097455343}, {"text": "Versley09 feature set", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.8099351326624552}]}, {"text": "The parse tree in demonstrates the value of bilingual features.", "labels": [], "entities": []}, {"text": "It was produced by the monolingual reranker and it incorrectly combines the two adverbs aber and ebenso into an adverbial phrase and places this under the VP.", "labels": [], "entities": []}, {"text": "The bilingual reranker instead attaches the two adverbs separately at the S level.", "labels": [], "entities": []}, {"text": "The attachment to the S node indicates that the two adverbs modify the modal verb kann and not the full verb sagen.", "labels": [], "entities": []}, {"text": "This is triggered by the feature POSPar2Prj.", "labels": [], "entities": [{"text": "POSPar2Prj", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.8675651550292969}]}], "tableCaptions": [{"text": " Table 3  The PARSEVAL score of monolingual features to rerank the parses of Europarl (seven-way  cross-validation on 662 sentences) and Tiger2 (development and test sets).", "labels": [], "entities": [{"text": "PARSEVAL score", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.9530188739299774}, {"text": "Europarl", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.9870747327804565}]}, {"text": " Table 5  PARSEVAL scores of bi+monolingual features to rerank the parses of Europarl (seven-way  cross-validation) and the added value of bilingual features over the results achieved by the  corresponding monolingual feature set.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9937939643859863}, {"text": "Europarl", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.9675398468971252}]}]}