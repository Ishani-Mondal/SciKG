{"title": [], "abstractContent": [{"text": "With the increasing rate of patent application filings, automated patent classification is of rising economic importance.", "labels": [], "entities": [{"text": "automated patent classification", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.6240073343118032}]}, {"text": "This article investigates how patent classification can be improved by using different representations of the patent documents.", "labels": [], "entities": [{"text": "patent classification", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8125968873500824}]}, {"text": "Using the Linguistic Classification System (LCS), we compare the impact of adding statistical phrases (in the form of bigrams) and linguistic phrases (in two different dependency formats) to the standard bag-of-words text representation on a subset of 532,264 English abstracts from the CLEF-IP 2010 corpus.", "labels": [], "entities": [{"text": "CLEF-IP 2010 corpus", "start_pos": 287, "end_pos": 306, "type": "DATASET", "confidence": 0.9374053279558817}]}, {"text": "In contrast to previous findings on classification with phrases in the Reuters-21578 data set, for patent classification the addition of phrases results in significant improvements over the unigram baseline.", "labels": [], "entities": [{"text": "Reuters-21578 data set", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.9842569231987}, {"text": "patent classification", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.7020324021577835}]}, {"text": "The best results were achieved by combining all four representations, and the second best by combining unigrams and lemmatized bigrams.", "labels": [], "entities": []}, {"text": "This article includes extensive analyses of the class models (a.k.a. class profiles) created by the classifiers in the LCS framework, to examine which types of phrases are most informative for patent classification.", "labels": [], "entities": [{"text": "patent classification", "start_pos": 193, "end_pos": 214, "type": "TASK", "confidence": 0.7368526756763458}]}, {"text": "It appears that bigrams contribute most to improvements in classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.9637333750724792}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.8443844318389893}]}, {"text": "Similar experiments were performed on subsets of French and German abstracts to investigate the generalizability of these findings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Around the world, the patent filing rates in the national patent offices have been increasing year after year, creating an enormous volume of texts, which patent examiners are struggling to manage.", "labels": [], "entities": []}, {"text": "To speedup the examination process, a patent application needs to be directed to patent examiners specialized in the subfield(s) of that particular patent as quickly as possible.", "labels": [], "entities": []}, {"text": "This preclassification is done automatically inmost patent offices, but substantial additional manual labor is still necessary.", "labels": [], "entities": []}, {"text": "Furthermore, since 2010, the International Patent Classification 1 (IPC) is revised every year to keep track of recent developments in the various subdomains.", "labels": [], "entities": [{"text": "International Patent Classification 1 (IPC)", "start_pos": 29, "end_pos": 72, "type": "DATASET", "confidence": 0.8522965567452567}]}, {"text": "Such a revision is followed by a reclassification of portions of the existing patent corpus, which is currently done mainly by hand by the national patent offices.", "labels": [], "entities": []}, {"text": "Both preclassification and reclassification could be improved, and a higher consistency of the classifications of the documents in the patent corpus could be obtained, if more reliable and precise automatic text classification algorithms were available.", "labels": [], "entities": [{"text": "consistency", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.9945118427276611}]}, {"text": "Most approaches to text classification use the bag-of-words (BOW) text representation, which represents each document by the words that occur in it, irrespective of their ordering in the original document.", "labels": [], "entities": [{"text": "text classification", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7146895825862885}]}, {"text": "In the last decades much research has gone into expanding this representation with additional information, such as statistical phrases 2 (n-grams) or some forms of syntactic or semantic knowledge.", "labels": [], "entities": []}, {"text": "Even though (statistical) phrases are more representative units for classes than single words, they are so sparsely distributed that they have limited impact during the classification process.", "labels": [], "entities": []}, {"text": "Therefore, it is not surprising that the best scoring multi-class, multi-label classification results for the well-known Reuters-21578 data set have been obtained using a BOW representation.", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 67, "end_pos": 93, "type": "TASK", "confidence": 0.6609625667333603}, {"text": "Reuters-21578 data set", "start_pos": 121, "end_pos": 143, "type": "DATASET", "confidence": 0.9833062092463175}, {"text": "BOW", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.6168723106384277}]}, {"text": "But the limited contribution of phrases in addition to the BOW-representation does not seem to hold for all classification tasks: \u00a8 Ozg\u00fcrOzg\u00a8Ozg\u00fcr and G \u00a8 ung\u00f6rung\u00a8ung\u00f6r (2010) found significant differences in the impact of linguistic phrases between short newswire texts (Reuters-21578), scientific abstracts (NSF), and informal posts in usenet groups (MiniNg): Especially the classification of scientific abstracts could be improved by using phrases as index terms.", "labels": [], "entities": [{"text": "BOW-representation", "start_pos": 59, "end_pos": 77, "type": "METRIC", "confidence": 0.7377166152000427}]}, {"text": "Ina follow-up study, \u00a8 Ozg\u00fcrOzg\u00a8Ozg\u00fcr and G \u00a8 ung\u00f6rung\u00a8ung\u00f6r (2012) found that for the three different data sets, different types of linguistic phrases have most impact.", "labels": [], "entities": []}, {"text": "The authors conclude that more formal text types benefit from more complex syntactic dependencies.", "labels": [], "entities": []}, {"text": "In this article, we investigate if similar improvements can be found for patent classification and, more specifically, which types of phrases are most effective for this particular task.", "labels": [], "entities": [{"text": "patent classification", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.7965346872806549}]}, {"text": "In this article we investigate the value of phrases for classification by comparing the improvements that can be gained from extending the BOW representation with (1) statistical phrases (in the form of bigrams); (2) linguistic phrases originating from the Stanford parser (see Section 3.2.2); (3) aboutness-based 4 linguistic phrases from the AEGIR parser (Section 3.2.3); and (4) a combination of all of these.", "labels": [], "entities": [{"text": "AEGIR parser", "start_pos": 344, "end_pos": 356, "type": "DATASET", "confidence": 0.9104095995426178}]}, {"text": "Furthermore, we will investigate the importance of different syntactic relations for the classification task, and the extent to which the words in the phrases overlap with the unigrams.", "labels": [], "entities": []}, {"text": "We also investigate which syntactic relations capture most information in the opinion of human annotators.", "labels": [], "entities": []}, {"text": "Finally, we perform experiments to investigate if our findings are languagedependent.", "labels": [], "entities": []}, {"text": "We will then draw some conclusions on what information is most valuable for improving automatic patent classification. was the first to investigate the use of phrases as index terms for text classification.", "labels": [], "entities": [{"text": "automatic patent classification.", "start_pos": 86, "end_pos": 118, "type": "TASK", "confidence": 0.718338668346405}, {"text": "text classification", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.748956024646759}]}, {"text": "He found that phrases generally suffer from data sparseness and may actually cause classification performance to deteriorate.", "labels": [], "entities": []}, {"text": "These findings were confirmed by Apt\u00e9,.", "labels": [], "entities": [{"text": "Apt\u00e9", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.5539290904998779}]}, {"text": "With the advent of increasing computational power and bigger data sets, however, the topic has been revisited in the last two decades.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this article, we investigate the relative contributions of different types of terms to the performance of patent classification.", "labels": [], "entities": [{"text": "patent classification", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7391380965709686}]}, {"text": "We use four different types of terms, namely, lemmatized unigrams, lemmatized bigrams (see Section 3.2.1), lemmatized dependency triples obtained with the Stanford parser (see Section 3.2.2), and lemmatized dependency triples obtained with the AEGIR parser (see Section 3.2.3).", "labels": [], "entities": [{"text": "AEGIR parser", "start_pos": 244, "end_pos": 256, "type": "DATASET", "confidence": 0.9111320674419403}]}, {"text": "We will leave term (feature) selection to the preprocessing module of the Linguistic Classification System (LCS) which we used for all experiments (see Section 3.3).", "labels": [], "entities": [{"text": "Linguistic Classification System (LCS)", "start_pos": 74, "end_pos": 112, "type": "DATASET", "confidence": 0.6884529789288839}]}, {"text": "We will analyze the relation between unigrams and phrases in the class profiles in some detail, however (see Sections 4.2 and 4.3).", "labels": [], "entities": []}, {"text": "The classification experiments were carried out within the framework of the LCS.", "labels": [], "entities": [{"text": "LCS", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8782749772071838}]}, {"text": "The LCS has been developed for the purpose of comparing different text representations.", "labels": [], "entities": []}, {"text": "Currently, three classifier algorithms are available: Naive Bayes, Balanced Winnow (Dagan, Karov, and Roth 1997), and SVM-light (Joachims 1999).", "labels": [], "entities": []}, {"text": "found that Balanced Winnow and SVM-light yield comparable classification accuracy scores for patent texts on a similar data set, but that Balanced Winnow is much faster than SVM-light for classification problems with a large number of classes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.8155274391174316}]}, {"text": "The Naive Bayes classifier yielded a lower accuracy.", "labels": [], "entities": [{"text": "Naive Bayes classifier", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.5622945030530294}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9986446499824524}]}, {"text": "We therefore only used the Balanced Winnow algorithm for our classification experiments, which were run with the following LCS configuration, based on tuning experiments on the same data by r Global term selection (GTS): Document frequency minimum is 2, term frequency minimum is 3.", "labels": [], "entities": [{"text": "term frequency minimum", "start_pos": 254, "end_pos": 276, "type": "METRIC", "confidence": 0.9332155187924703}]}, {"text": "Although initial term selection is necessary when dealing with such a large corpus, we deliberately aimed at keeping as many of the sparse phrasal terms as possible.", "labels": [], "entities": [{"text": "initial term selection", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.61981729666392}]}, {"text": "r Local term selection (LTS): Simple Chi Square (.", "labels": [], "entities": [{"text": "Local term selection (LTS)", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.6754857152700424}]}, {"text": "We used the LCS option to automatically select the most representative terms for every class, with a hard maximum of 10,000 terms per class.", "labels": [], "entities": []}, {"text": "r After LTS the selected terms of all classes are aggregated into one combined term vocabulary, which is used as the starting point for training the individual classes (see).", "labels": [], "entities": []}, {"text": "20 By \"gain\" we mean the decrease in number of types for the lemmatized forms compared to the non-lemmatized forms, which will result in higher corresponding token/type ratios.", "labels": [], "entities": []}, {"text": "21 Increasing the cut-off to 100,000 terms resulted in a small increase inaccuracy (F1 values) for the combined representations, mostly for the larger classes.", "labels": [], "entities": [{"text": "F1 values)", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9671708941459656}]}, {"text": "Because the patent domain has a large lexical variety, a large amount of low-frequency terms in the tail of the term distribution can have a large impact on the accuracy scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9989053010940552}]}, {"text": "Because we are more interested in the relative gains between different text representations and the corresponding top terms in the class profiles than in achieving maximum classification scores, we opted to use only 10,000 terms for efficiency reasons.", "labels": [], "entities": []}, {"text": "r For each document the LCS returns a ranked list of all possible labels and the attendant confidence scores.", "labels": [], "entities": []}, {"text": "If the score assigned is higher than a predetermined threshold, the document is assigned that category.", "labels": [], "entities": []}, {"text": "The Winnow algorithm has a default (natural) threshold equal to one.", "labels": [], "entities": []}, {"text": "We configured the LCS to return a minimum of one label (with the highest score, even if it is lower than the threshold) and a maximum of four labels for each document.", "labels": [], "entities": []}, {"text": "r The classification quality was determined by calculating the Precision, Recall, and F1 measures per document/class combination (see, e.g., Koster, Seutter, and Beney 2003), on the document level (micro-averaged scores).", "labels": [], "entities": [{"text": "Precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.996863603591919}, {"text": "Recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.946351170539856}, {"text": "F1", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9978694915771484}]}, {"text": "shows the impact of our global term selection criteria for the different text representations.", "labels": [], "entities": []}, {"text": "This first feature reduction step is category-independent: The features are discarded on the basis of the term and document frequencies over the corpus, disregarding their distributions for the specific categories.", "labels": [], "entities": [{"text": "feature reduction", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7545578479766846}]}, {"text": "We can see that the token/type ratio of The sparsest syntactic phrases lose most terms.", "labels": [], "entities": []}, {"text": "Although the Stanford parser output is the sparsest text representation, it has the largest pool of terms to select from at the end of the GTS process.", "labels": [], "entities": []}, {"text": "The impact of the second feature reduction phase is shown in.", "labels": [], "entities": []}, {"text": "During local term selection, the LCS finds the most representative terms for each class by selecting the terms whose distributions in the sets of positive and negative training examples for that class are maximally different from the general term distribution.", "labels": [], "entities": [{"text": "local term selection", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.6117195785045624}]}, {"text": "We can see that in the combined runs only around 50% of the selectable unigrams (after GTS) are  selected as features during LTS.", "labels": [], "entities": []}, {"text": "This means that the phrases replace at least apart of the information contained in the possible unigrams.", "labels": [], "entities": []}, {"text": "shows the micro-averages of Precision, Recall, and F1 for five classification experiments with different document representations.", "labels": [], "entities": [{"text": "Precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9855981469154358}, {"text": "Recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9795005321502686}, {"text": "F1", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9986951947212219}]}, {"text": "To give an idea of the complexity of the task we have included a random guessing baseline in the first row.", "labels": [], "entities": []}, {"text": "We found that extending a unigram representation with statistical and/or linguistic phrases gives a significant improvement in classification accuracy over the unigram baseline.", "labels": [], "entities": [{"text": "classification", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.9214383363723755}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9626496434211731}]}, {"text": "The bestperforming classifier is the one that combines all four text representations.", "labels": [], "entities": []}, {"text": "When adding only type of phrase to unigrams, the unigrams + bigrams combination is significantly better than the combinations with syntactic phrases.", "labels": [], "entities": []}, {"text": "Combining all four representations boosts recall, but has less impact on precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9994111061096191}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9985817670822144}]}, {"text": "To gain more insight in the syntactic and semantic relations that are considered most informative by humans, we conducted an experiment in which we asked human annotators to select the five to ten most informative phrases 29 for 15 sentences taken at random from documents in the three largest classes in the corpus.", "labels": [], "entities": []}, {"text": "We then compiled a reference set consisting of 70 phrases (4.6 phrases per sentence) which were considered as \"informative\" by at least three out of four annotators.", "labels": [], "entities": []}, {"text": "Of these, 57 phrases were noun-noun compounds and 11 were combinations of an adjectival modifier with a noun.", "labels": [], "entities": []}, {"text": "None of the annotators selected phrases containing determiners.", "labels": [], "entities": []}, {"text": "We created bigrams from the input and extracted head-modifier pairs from the parser output for the sentences in the test set.", "labels": [], "entities": []}, {"text": "We then compared the overlap of the generated phrases with the reference phrases.", "labels": [], "entities": []}, {"text": "We found that bigrams overlap with 53 of the 70 reference phrases; Stanford triples overlap with 62 phrases and AEGIR triples overlap with 57 phrases.", "labels": [], "entities": [{"text": "AEGIR", "start_pos": 112, "end_pos": 117, "type": "METRIC", "confidence": 0.799270749092102}]}, {"text": "Although three data points are not enough to compute a formal measure, it is interesting to note the correspondence with the number of terms kept for the three text representations after Local Term Selection (see).", "labels": [], "entities": []}, {"text": "The fact that the text representation with the smallest number of terms after LTC and with the smallest overlap with \"contentful\" phrases in a text as indicated by human annotators still yields the best classification performance suggests that not all \"contentful\" phrases are important or useful for the task of classifying that text.", "labels": [], "entities": []}, {"text": "This finding is reminiscent of the fact that the \"optimal\" summary of a text is dependent on the goal with which the summary was produced (.", "labels": [], "entities": []}, {"text": "Only 15% of the phrases extracted by the human annotators contain word combinations that have long-distance dependencies in the original sentences.", "labels": [], "entities": []}, {"text": "This suggests that the most meaningful phrases are expressed in local dependencies, that is, adjacent words.", "labels": [], "entities": []}, {"text": "Consequently, syntactic analysis aimed at discovering meaning expressed by long-distance dependencies can only make a small contribution.", "labels": [], "entities": []}, {"text": "A further analysis of the phrases showed that the smaller coverage of the bigrams is due to the fact that some of the relevant noun-noun combinations are missed because function words, typically determiners or prepositions, occur between the nouns.", "labels": [], "entities": []}, {"text": "For example, the annotators constructed the reference phrase rotation axis for the noun phrase the rotation of the second axis.", "labels": [], "entities": []}, {"text": "This reference phrase cannot be captured by the bigram representation.", "labels": [], "entities": []}, {"text": "When intervening function words are removed from the sentences, the coverage of the resulting bigrams on the reference set rises 31 to 59 phrases (more than AEGIR, and almost as many as Stanford).", "labels": [], "entities": [{"text": "AEGIR", "start_pos": 157, "end_pos": 162, "type": "DATASET", "confidence": 0.786218523979187}]}, {"text": "Despite the fact that generating more phrases does not necessarily lead to better classification performance, we intend to use bigrams stripped of function words as additional terms for patent classification in future experiments.", "labels": [], "entities": [{"text": "patent classification", "start_pos": 186, "end_pos": 207, "type": "TASK", "confidence": 0.7355316430330276}]}, {"text": "The analysis also revealed an indication why syntactic phrases may lead to inferior classification results: Both syntactic parsers consistently fail to find the correct structural analysis of the long and complex noun phrases such as an implantable, inflatable dual chamber shape retention tissue expander, which are frequent in patent texts.", "labels": [], "entities": []}, {"text": "Phrases like this contain many compounds in an otherwise complex syntactic structure, namely For a parser it is impossible to parse this correctly without knowing which word sequences are actually compounds.", "labels": [], "entities": []}, {"text": "That knowledge might be gleaned from the frequency with which sequences of nouns and adjectives occur in a given domain.", "labels": [], "entities": []}, {"text": "For the time being, the Stanford parser (and the AEGIR parser, to a lesser extent) will parse any noun phrase by attaching the individual words to the right-most head noun, resulting in the following analysis: This effectively destroys many of the noun-noun compounds, which are the most important features for patent classification (see).", "labels": [], "entities": [{"text": "AEGIR", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.7539476752281189}, {"text": "patent classification", "start_pos": 311, "end_pos": 332, "type": "TASK", "confidence": 0.7785172164440155}]}, {"text": "Bigrams are less prone to this type of \"error.\"", "labels": [], "entities": []}, {"text": "These findings are confirmed when looking at the overlap of the word combinations: Although there is high lexical overlap between the phrases of the different representations (80% overlap of the parts of phrases in Section 4.3.1), the overlap of the word combinations that makeup the phrases is much lower: Only 33% of the top 1,000 phrases are common between all three representations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Impact of lemmatization on the different text types in the training set (80% of the corpus).", "labels": [], "entities": []}, {"text": " Table 2  Impact of global term selection (GTS) criteria on the different text types in the training set (80%  of the corpus).", "labels": [], "entities": [{"text": "global term selection (GTS)", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.7463009854157766}]}, {"text": " Table 3  Impact of local term selection (LTS) criteria in the training set (80% of the corpus).", "labels": [], "entities": [{"text": "local term selection (LTS)", "start_pos": 20, "end_pos": 46, "type": "TASK", "confidence": 0.6966124723354975}]}, {"text": " Table 4  Classification results on CLEF-IP 2010 English abstracts, with ranges for a 95% confidence  interval. Bold figures indicate the best results obtained with the five classifiers. (P: Precision;  R: Recall, F1: F1-score).", "labels": [], "entities": [{"text": "CLEF-IP 2010 English abstracts", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.9532871842384338}, {"text": "Precision", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.863099992275238}, {"text": "Recall", "start_pos": 206, "end_pos": 212, "type": "METRIC", "confidence": 0.9136015176773071}, {"text": "F1", "start_pos": 214, "end_pos": 216, "type": "METRIC", "confidence": 0.9963907599449158}, {"text": "F1-score", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.7544203400611877}]}, {"text": " Table 6  Distribution of the top 100 statistical and syntactic phrases in the B60 class profiles.", "labels": [], "entities": [{"text": "B60 class profiles", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.9294114112854004}]}, {"text": " Table 7  Classification results on CLEF-IP 2010 French and German abstracts, with ranges for  95% confidence intervals.", "labels": [], "entities": [{"text": "CLEF-IP 2010 French and German abstracts", "start_pos": 36, "end_pos": 76, "type": "DATASET", "confidence": 0.9460139175256094}]}]}