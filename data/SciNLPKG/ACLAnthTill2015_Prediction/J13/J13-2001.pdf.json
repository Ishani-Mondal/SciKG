{"title": [{"text": "A Joint Model to Identify and Align Bilingual Named Entities", "labels": [], "entities": [{"text": "Identify and Align Bilingual Named Entities", "start_pos": 17, "end_pos": 60, "type": "TASK", "confidence": 0.799149269858996}]}], "abstractContent": [{"text": "In this article, an integrated model is derived that jointly identifies and aligns bilingual named entities (NEs) between Chinese and English.", "labels": [], "entities": []}, {"text": "The model is motivated by the following observations: (1) whether an NE is translated semantically or phonetically depends greatly on its entity type, (2) entities within an aligned pair should share the same type, and (3) the initially detected NEs can act as anchors and provide further information while selecting NE candidates.", "labels": [], "entities": []}, {"text": "Based on these observations, this article proposes a translation mode ratio feature (defined as the proportion of NE internal tokens that are semantically translated), enforces an entity type consistency constraint, and utilizes additional new NE likelihoods (based on the initially detected NE anchors).", "labels": [], "entities": []}, {"text": "Experiments show that this novel method significantly outperforms the baseline.", "labels": [], "entities": []}, {"text": "The type-insensitive F-score of identified NE pairs increases from 78.4% to 88.0% (12.2% relative improvement) in our Chinese-English NE alignment task, and the type-sensitive F-score increases from 68.4% to 83.0% (21.3% relative improvement).", "labels": [], "entities": [{"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9023541212081909}, {"text": "Chinese-English NE alignment task", "start_pos": 118, "end_pos": 151, "type": "TASK", "confidence": 0.5632583871483803}, {"text": "F-score", "start_pos": 176, "end_pos": 183, "type": "METRIC", "confidence": 0.8407609462738037}]}, {"text": "Furthermore, the proposed model demonstrates its robustness when it is tested across different domains.", "labels": [], "entities": []}, {"text": "Finally, when semi-supervised learning is conducted to train the adopted English NE recognition model, the proposed model also significantly boosts the English NE recognition type-sensitive F-score.", "labels": [], "entities": [{"text": "English NE recognition", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.5774678687254587}, {"text": "English NE recognition type-sensitive", "start_pos": 152, "end_pos": 189, "type": "TASK", "confidence": 0.5988882929086685}, {"text": "F-score", "start_pos": 190, "end_pos": 197, "type": "METRIC", "confidence": 0.6615791320800781}]}], "introductionContent": [{"text": "Named entities (NEs), especially person names (PER), location names (LOC), and organization names (ORG), deliver essential context and meaning inhuman languages.", "labels": [], "entities": []}, {"text": "Therefore, NE translation plays a critical role in trans-lingual language processing tasks, such as machine translation (MT) and cross-lingual information retrieval.", "labels": [], "entities": [{"text": "NE translation", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.93315389752388}, {"text": "machine translation (MT)", "start_pos": 100, "end_pos": 124, "type": "TASK", "confidence": 0.8376846075057983}, {"text": "cross-lingual information retrieval", "start_pos": 129, "end_pos": 164, "type": "TASK", "confidence": 0.7302976449330648}]}, {"text": "To learn NE translation knowledge, bilingual NE alignment (which links source NEs and target NEs to generate desired NE pairs) is the first step in producing the NE translation table (which can then be used to train the NE translation model).", "labels": [], "entities": [{"text": "NE translation knowledge", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.8941694498062134}, {"text": "NE alignment", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.6972794532775879}, {"text": "NE translation", "start_pos": 220, "end_pos": 234, "type": "TASK", "confidence": 0.7676266133785248}]}, {"text": "Furthermore, with additional alignment constraints from the other language, the alignment module can also refine those initially recognized NEs, and thus can be adopted to conduct semisupervised learning to learn monolingual NE recognition models from a large untagged bilingual corpus.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 225, "end_pos": 239, "type": "TASK", "confidence": 0.781524121761322}]}, {"text": "Because NE alignment can only be conducted after its associated NEs have been identified, the NE recognition errors propagate into the alignment stage.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 8, "end_pos": 20, "type": "TASK", "confidence": 0.9441091418266296}, {"text": "NE recognition", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.8757055997848511}]}, {"text": "The typeinsensitive inclusion rate 1 of the initial recognition stage thus significantly limits the final alignment performance.", "labels": [], "entities": []}, {"text": "One way to alleviate this error propagation problem is to jointly perform NE recognition and alignment.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7557046115398407}, {"text": "NE recognition", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.9633768200874329}, {"text": "alignment", "start_pos": 93, "end_pos": 102, "type": "TASK", "confidence": 0.929733395576477}]}, {"text": "Such a combined approach is usually infeasible, however, due to the high computational cost of evaluating alignment scores fora large number 2 of NE pair candidates.", "labels": [], "entities": []}, {"text": "In order to make the problem computationally tractable, a sequential approach is usually used to first identify NEs and then align them.", "labels": [], "entities": []}, {"text": "Two such kinds of sequential strategies that alleviate the error propagation problem have been proposed.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7108242809772491}]}, {"text": "The first strategy, named asymmetry alignment), identifies NEs only on the source side and then finds their corresponding NEs on the target side.", "labels": [], "entities": []}, {"text": "Although this approach avoids the NE recognition errors resulting from the target side, which would otherwise be brought into the alignment process, the NE recognition errors from the source side continue to affect alignment.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.8273589909076691}]}, {"text": "To further reduce the errors from the source side, the second strategy, denoted symmetry alignment, expands the NE candidate sets in both languages before conducting the alignment.", "labels": [], "entities": []}, {"text": "This is achieved by using the original results as anchors, and enlarging or shrinking the boundaries of the anchors to generate new candidates.", "labels": [], "entities": []}, {"text": "This strategy fails to work if the NE anchor has already been missed in the initial NE recognition stage, however.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 84, "end_pos": 98, "type": "TASK", "confidence": 0.8908673822879791}]}, {"text": "In our data set (1,000 ChineseEnglish sentence pairs randomly selected from the Chinese News Translation Text corpus), this strategy significantly improves the type-insensitive NE pair inclusion rate from 83.9% to 96.1%; 3 in the meantime, the type-insensitive Chinese NE (CNE) recognition inclusion rate rises from 88.7% to 95.9%, and that of English NE (ENE) from 92.8% to 97.2%.", "labels": [], "entities": [{"text": "Chinese News Translation Text corpus", "start_pos": 80, "end_pos": 116, "type": "DATASET", "confidence": 0.7864334940910339}, {"text": "type-insensitive NE pair inclusion", "start_pos": 160, "end_pos": 194, "type": "TASK", "confidence": 0.4934193268418312}, {"text": "type-insensitive Chinese NE (CNE) recognition inclusion", "start_pos": 244, "end_pos": 299, "type": "TASK", "confidence": 0.6166455782949924}]}, {"text": "This strategy is thus adopted in this article.", "labels": [], "entities": []}, {"text": "Although the symmetric expansion strategy has substantially alleviated the problem of error propagation, the final alignment accuracy, in terms of type-sensitive F-score (achieved by the approach proposed by Huang, Vogel, and Waibel) continues to be as low as 68.4% (see in in Section 4.3).", "labels": [], "entities": [{"text": "error propagation", "start_pos": 86, "end_pos": 103, "type": "TASK", "confidence": 0.6812891066074371}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.7464686036109924}, {"text": "F-score", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.9018433094024658}]}, {"text": "After having examined the data, we found the following: (1) How a given NE is translated, either semantically (called translation) or phonetically (called transliteration), depends greatly on its associated entity type.", "labels": [], "entities": []}, {"text": "The translation mode ratio, which is the percentage of NE internal tokens that are translated semantically, thus can help to identify the NE type.", "labels": [], "entities": []}, {"text": "(2) Entities within an aligned pair should share the same type, and this restriction should be integrated into the NE alignment model as a constraint.", "labels": [], "entities": []}, {"text": "(3) In prior work, the initially identified monolingual NEs were used only to construct the candidate set without playing any role in final NE identification.", "labels": [], "entities": [{"text": "NE identification", "start_pos": 140, "end_pos": 157, "type": "TASK", "confidence": 0.8523467481136322}]}, {"text": "Indeed, these monolingual NEs do carry other useful information and can act as anchors to give NE likelihoods, which can provide additional scope preference information to those regenerated candidates.", "labels": [], "entities": []}, {"text": "Based on these observations, we propose a novel joint model that adopts the translation mode ratio, enforces the entity type consistency constraint, and also utilizes the NE likelihoods.", "labels": [], "entities": []}, {"text": "This proposed approach jointly identifies and aligns bilingual NEs under an integrated framework, which consists of three stages: Initial NE Recognition, NECandidate Set Expansion, and NE Re-identification & Alignment.", "labels": [], "entities": [{"text": "NE Recognition", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.6288135647773743}]}, {"text": "The Initial NE Recognition stage identifies the initial NEs and their associated NE types in both the source and target.", "labels": [], "entities": [{"text": "NE Recognition", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.7252102494239807}]}, {"text": "In the next stage, NE Candidate Set Expansion regenerates the candidate sets in both languages in order to remedy the initial NE recognition errors.", "labels": [], "entities": []}, {"text": "In the final stage, NE Re-identification & Alignment jointly recognizes and aligns bilingual NEs via the proposed joint model.", "labels": [], "entities": [{"text": "NE Re-identification & Alignment", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.7311697453260422}]}, {"text": "The experimental results validate our proposed three-step method.", "labels": [], "entities": []}, {"text": "The integrated model that jointly identifies and aligns bilingual named entities between Chinese and English was originally introduced in Chen, Zong, and.", "labels": [], "entities": []}, {"text": "In this article, the problem has been re-formulated and derived.", "labels": [], "entities": []}, {"text": "The new derivation starts from two given NE sequences, whereas the original derivation only begins with one given NE pair.", "labels": [], "entities": []}, {"text": "We also give more details of the problem study, model analysis, and experiments.", "labels": [], "entities": [{"text": "model analysis", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7260070443153381}]}, {"text": "Moreover, we report additional experiments, which include those that study the effect of adopting different initial NE recognizers and the effectiveness of the proposed model across different domains.", "labels": [], "entities": [{"text": "NE recognizers", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.8716569542884827}]}, {"text": "Finally, a complete error analysis is given in the current version.", "labels": [], "entities": []}, {"text": "The remainder of this article is organized as follows: Section 2 motivates the proposed method.", "labels": [], "entities": []}, {"text": "Afterwards, the proposed model is formally introduced in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes experiments conducted on various configurations of the method.", "labels": [], "entities": []}, {"text": "The associated error analysis and discussion of results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 gives applications of the proposed model.", "labels": [], "entities": []}, {"text": "We review related work in Section 7.", "labels": [], "entities": []}, {"text": "Finally, conclusions are drawn in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the proposed approach, prior work (Huang, Vogel, and Waibel 2003) is re-implemented as our baseline (see Section 4.2).", "labels": [], "entities": []}, {"text": "This is because the work not only adopts the same candidate set expansion strategy mentioned previously, but also utilizes monolingual information when selecting NE pairs (only a simple bigram model is used, however).", "labels": [], "entities": []}, {"text": "This is in contrast to other works), which only used alignment scores.", "labels": [], "entities": [{"text": "alignment", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.7452149987220764}]}, {"text": "The same training and test sets are used for the various experiment configurations.", "labels": [], "entities": []}, {"text": "The adopted training set includes two parts.", "labels": [], "entities": []}, {"text": "The first part consists of 110,874 aligned sentence pairs from newswire data in the Foreign Broadcast Information Service (LDC2003E14 7 ) corpus, which is denoted as Training Set I. The average length of the Chinese sentences in this data set is 74.6 characters, and the average length of the English sentences is 30.2 words.", "labels": [], "entities": [{"text": "Foreign Broadcast Information Service (LDC2003E14 7 ) corpus", "start_pos": 84, "end_pos": 144, "type": "DATASET", "confidence": 0.9337726897663541}]}, {"text": "Training Set I is initially tagged by Chinese/English NE taggers, and then reference NE boundaries and types are manually labeled.", "labels": [], "entities": [{"text": "Chinese/English NE taggers", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.5238901555538178}]}, {"text": "The second part of the training set is the LDC2005T34 8 bilingual NE pair list with a total of 218,772 NE pairs, which is denoted as Training Set II.", "labels": [], "entities": [{"text": "LDC2005T34 8 bilingual NE pair list", "start_pos": 43, "end_pos": 78, "type": "DATASET", "confidence": 0.7958049774169922}]}, {"text": "The required features (e.g., NE type and translation-mode) are then manually labeled throughout the two training sets.", "labels": [], "entities": []}, {"text": "Because Training Set II only contains isolated NE pairs that are not associated with their surrounding context, Training Set I is thus required to train those context-related parameters.", "labels": [], "entities": []}, {"text": "In the baseline system, translation cost and transliteration cost models are trained on Training Set II, and tagging cost is trained on Training Set I. For the proposed approach, the NE likelihoods are trained on Training Set I, and Training Set II is used to train the parameters relating to the NE alignment probability.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 297, "end_pos": 309, "type": "TASK", "confidence": 0.8125212788581848}]}, {"text": "For the test set, 300 sentence pairs are randomly selected from the Linguistic Data Consortium (LDC) Chinese-English News Text (LDC2005T06) corpus, which contains at least one NE pair in each sentence.", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC) Chinese-English News Text (LDC2005T06) corpus", "start_pos": 68, "end_pos": 146, "type": "DATASET", "confidence": 0.8938697026326106}]}, {"text": "The average length of Chinese sentences is 59.4 characters, and the average length of English sentences is 24.8 words.", "labels": [], "entities": []}, {"text": "The answer keys to NE recognition and alignment are annotated manually, and used as the gold standard to calculate the metrics of precision (P), recall (R), and F-score (F) for both NE recognition and alignment.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9303788244724274}, {"text": "precision (P)", "start_pos": 130, "end_pos": 143, "type": "METRIC", "confidence": 0.9627823382616043}, {"text": "recall (R)", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.9621603041887283}, {"text": "F-score (F)", "start_pos": 161, "end_pos": 172, "type": "METRIC", "confidence": 0.9696003049612045}, {"text": "NE recognition and alignment", "start_pos": 182, "end_pos": 210, "type": "TASK", "confidence": 0.7516589015722275}]}, {"text": "A total of 765 Chinese NEs and 747 English NEs are manually identified in the test set, in which there are 718 reference NE pairs (including 214 PER pairs, 371 LOC pairs, and 133 ORG pairs).", "labels": [], "entities": []}, {"text": "NE alignment result is a subset of NE recognition results, because not all those recognized NEs can be aligned.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6415580213069916}, {"text": "NE recognition", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.9004831612110138}]}, {"text": "The development set for feature selection and weight training is composed of 200 sentence pairs selected from the LDC2005T06 corpus, which includes 482 manually tagged NE pairs.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.8362247943878174}, {"text": "LDC2005T06 corpus", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.9713179767131805}]}, {"text": "The average length of Chinese sentences is 56.4 characters, and the average length of English sentences is 23.2 words.", "labels": [], "entities": []}, {"text": "There is no overlap between the training, development, and test sets.", "labels": [], "entities": []}, {"text": "These data sets will be adopted in a series of experiments that investigate the proposed model.", "labels": [], "entities": []}, {"text": "Among them, the results of initial NE recognition are given in Section 4.1, and those related to the baseline system are given in Section 4.2.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.945356696844101}]}, {"text": "In Section 4.3, a series of experiments are conducted to examine the effect of various features adopted in the proposed model.", "labels": [], "entities": []}, {"text": "The weighted version of the proposed model is also tested.", "labels": [], "entities": []}, {"text": "Furthermore, the effectiveness of adopting different initial NE recognizers is shown in Section 4.4, and the effectiveness of the proposed model across different domains is illustrated in Section 4.5.", "labels": [], "entities": [{"text": "NE recognizers", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.9214449822902679}]}, {"text": "Finally, the result of directly using all available features under a Maximum Entropy framework without developing a principled model is given in Section 4.6.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Initial type-sensitive Chinese/English NER performance.", "labels": [], "entities": [{"text": "type-sensitive Chinese/English NER", "start_pos": 18, "end_pos": 52, "type": "TASK", "confidence": 0.5011456906795502}]}, {"text": " Table 5  NEA type-insensitive (type-sensitive) performance with the same Chinese NE recognizer  (Wu's system) and different English NE recognizers.", "labels": [], "entities": []}, {"text": " Table 11  Comparison between a ME framework and the derived model on the same test set.", "labels": [], "entities": []}, {"text": " Table 17  Type-insensitive improvement for Chinese/English NER.", "labels": [], "entities": [{"text": "Chinese/English NER", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.4775035008788109}]}, {"text": " Table 19  English NE recognition on test data after semi-supervised learning.", "labels": [], "entities": [{"text": "English NE recognition", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.7587350805600485}]}, {"text": " Table 20  NE alignment on test data after semi-supervised learning.", "labels": [], "entities": []}]}