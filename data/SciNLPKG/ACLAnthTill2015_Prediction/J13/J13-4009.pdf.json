{"title": [{"text": "Generation of Compound Words in Statistical Machine Translation into Compounding Languages", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6318772534529368}]}], "abstractContent": [{"text": "In this article we investigate statistical machine translation (SMT) into Germanic languages, with a focus on compound processing.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.8130434254805247}, {"text": "compound processing", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7761330306529999}]}, {"text": "Our main goal is to enable the generation of novel compounds that have not been seen in the training data.", "labels": [], "entities": []}, {"text": "We adopt a split-merge strategy, where compounds are split before training the SMT system, and merged after the translation step.", "labels": [], "entities": [{"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9887645244598389}]}, {"text": "This approach reduces sparsity in the training data, but runs the risk of placing translations of compound parts in non-consecutive positions.", "labels": [], "entities": []}, {"text": "It also requires a postprocessing step of compound merging, where compounds are reconstructed in the translation output.", "labels": [], "entities": [{"text": "compound merging", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.6763825565576553}]}, {"text": "We present a method for increasing the chances that components that should be merged are translated into contiguous positions and in the right order and show that it can lead to improvements both by direct inspection and in terms of standard translation evaluation metrics.", "labels": [], "entities": []}, {"text": "We also propose several new methods for compound merging, based on heuristics and machine learning, which outperform previously suggested algorithms.", "labels": [], "entities": [{"text": "compound merging", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.8278965353965759}]}, {"text": "These methods can produce novel compounds and a translation with at least the same overall quality as the baseline.", "labels": [], "entities": []}, {"text": "For all subtasks we show that it is useful to include part-of-speech based information in the translation process, in order to handle compounds.", "labels": [], "entities": []}], "introductionContent": [{"text": "In many languages including most of the Germanic (German, Swedish, etc.) and Uralic (Finnish, Hungarian, etc.) language families, so-called closed compounds are used productively.", "labels": [], "entities": []}, {"text": "Closed compounds are written as single words without spaces or other word boundaries, as in German Goldring.", "labels": [], "entities": []}, {"text": "We will refer to these languages as compounding languages.", "labels": [], "entities": []}, {"text": "In English, on the other hand, compounds are generally open, that is, written as two words as in gold ring.", "labels": [], "entities": []}, {"text": "This difference in compound orthography leads to problems for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.8351066609223684}]}, {"text": "For translation into a compounding language, often fewer compounds than in normal texts are produced.", "labels": [], "entities": [{"text": "translation into a compounding language", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.6697265923023223}]}, {"text": "This can be due to the fact that the desired compounds are missing in the training data or that they have not been aligned correctly.", "labels": [], "entities": []}, {"text": "When a compound is the idiomatic word choice in the translation, systems often produce separate words, genitive or other alternative constructions, or translate only one part of the compound.", "labels": [], "entities": []}, {"text": "For an SMT system to cope with the productivity of the phenomenon, any effective strategy should be able to correctly process compounds that have never been seen in the training data as such, although possibly their components have, either in isolation or within a different compound.", "labels": [], "entities": [{"text": "SMT", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9937855005264282}]}, {"text": "Previous work (e.g., has shown that compound splitting improves translation from compounding languages into English.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8785855770111084}]}, {"text": "In this article we explore several aspects of the less-researched area of compound treatment for translation into such languages, using three Germanic languages as examples.", "labels": [], "entities": [{"text": "compound treatment", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.772841066122055}]}, {"text": "The assumption is that splitting compounds will also improve translation for this translation direction and lead to more natural translations.", "labels": [], "entities": []}, {"text": "The strategy we adopt is to split compounds in the training data, and to merge them in the translation output.", "labels": [], "entities": []}, {"text": "Our overall goal is to improve translation quality by productively generating compounds in SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9848874807357788}]}, {"text": "The main contributions of the article are as follows: r Demonstrating improved coalescence (adjacency and order) of compound parts in translation through the use of sequence models based on customized part-of-speech sets and count features r Designing and evaluating several heuristic methods for compound merging that outperforms previous heuristic merging methods r Designing and evaluating a novel method for compound merging based on sequence labeling r Demonstrating the ability of these merging methods to generate novel unseen compounds In addition, we report effects on translation performance from a number of variations in the methods for compound splitting and merging.", "labels": [], "entities": [{"text": "compound splitting and merging", "start_pos": 649, "end_pos": 679, "type": "TASK", "confidence": 0.7109960243105888}]}, {"text": "The rest of the article is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of compound formation in the three target languages used in this work.", "labels": [], "entities": [{"text": "compound formation", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7223914861679077}]}, {"text": "Section 3 reports related work on compound processing for machine translation.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8060160279273987}, {"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7933061122894287}]}, {"text": "Section 4 describes the compound processing strategy we use and Section 5 describes compound splitting.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7929770052433014}]}, {"text": "Section 6 addresses compound coalescence, followed by compound merging in Section 7.", "labels": [], "entities": [{"text": "compound merging", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.6711849421262741}]}, {"text": "In Section 8 we present experimental results and in Section 9 we state our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we report experimental results for the strategies proposed in this article.", "labels": [], "entities": []}, {"text": "We first describe, in Section 8.1, the overall experimental set-up.", "labels": [], "entities": []}, {"text": "We then report on the experiments, as follows: r In Section 8.2 we report on general effects of compound processing.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.6903975158929825}]}, {"text": "r In Section 8.6 we apply the overall best strategies to corpora of different sizes and to out-of-domain data.", "labels": [], "entities": []}, {"text": "We performed experiments on translation from English into German, Swedish, and Danish, all of which have closed compounds.", "labels": [], "entities": [{"text": "translation from English", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.8878937164942423}]}, {"text": "We tested all experimental conditions on Europarl) for translation from English to German.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.9747115969657898}, {"text": "translation from English to German", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.8808642387390136}]}, {"text": "We also give contrasting results on English-Swedish Europarl and for an automotive corpus for translation from English to Swedish and Danish.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.7849226593971252}, {"text": "translation from English", "start_pos": 94, "end_pos": 118, "type": "TASK", "confidence": 0.8555087049802145}]}, {"text": "The automotive corpus was gathered from translation memory data.", "labels": [], "entities": [{"text": "automotive corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9116306006908417}]}, {"text": "The two corpora are quite different.", "labels": [], "entities": []}, {"text": "The automotive corpus is from a limited domain, and of a homogeneous nature, whereas Europarl is more diverse, and tends to have a more complex language than the automotive corpus.", "labels": [], "entities": [{"text": "automotive corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8431357741355896}, {"text": "Europarl", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.9742316603660583}]}, {"text": "summarizes the sizes for the corpora that we used in Sections 8.2-8.5.", "labels": [], "entities": []}, {"text": "The German test set is the test2007 set from the WMT 2008 workshop.", "labels": [], "entities": [{"text": "German test set", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9198315540949503}, {"text": "test2007 set from the WMT 2008 workshop", "start_pos": 27, "end_pos": 66, "type": "DATASET", "confidence": 0.9122510382107326}]}, {"text": "We have chosen to use a smaller part of Europarl, to reduce runtimes and allow more experiments.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9887349009513855}]}, {"text": "In Section 8.6 we report results from scaling experiments and on out-of-domain data.", "labels": [], "entities": []}, {"text": "This option can also be extended so that the training data is split into chunks where each chunk is translated by a system that is trained on the remaining chunks, a strategy that has been successfully used for parse reranking.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 211, "end_pos": 226, "type": "TASK", "confidence": 0.9704661965370178}]}, {"text": "Because we found that using fresh data did not give any significant improvements on the merging task except with little training data (see Section 8.5.2, We used factored translation (  in our experiments, with both surface words and part-of-speech tags on the target side, with a sequence model on parts-of-speech.", "labels": [], "entities": [{"text": "factored translation", "start_pos": 162, "end_pos": 182, "type": "TASK", "confidence": 0.7015757858753204}]}, {"text": "For part-of-speech tagging we used TreeTagger for German, an in-house hidden Markov model tagger based on for Danish and Swedish, and for Swedish also the Granska tagger.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7400232255458832}]}, {"text": "For the majority of experiments we used the Moses decoder ( ), which is a standard phrase-based statistical decoder, which allows factored decoding.", "labels": [], "entities": []}, {"text": "For word alignment, Giza++ (Och and Ney 2003) was used and for language modeling we used SRILM).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8253856003284454}, {"text": "SRILM", "start_pos": 89, "end_pos": 94, "type": "METRIC", "confidence": 0.8617968559265137}]}, {"text": "For parameter optimization we used minimum error rate training).", "labels": [], "entities": [{"text": "parameter optimization", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7177771329879761}]}, {"text": "For each experiment we ran minimum error rate training three times in order to reduce the effect of optimizer instability, and report the average result and standard deviation.", "labels": [], "entities": [{"text": "minimum error rate", "start_pos": 27, "end_pos": 45, "type": "METRIC", "confidence": 0.7402020196119944}]}, {"text": "In the merging experiments based on sequence labeling we used the CRF++ toolkit.", "labels": [], "entities": [{"text": "CRF++ toolkit", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.9021967848141988}]}, {"text": "For the merging experiment with sequence labeling, we used the Matrax decoder () on the automotive corpus.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.6684962511062622}, {"text": "Matrax decoder", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.9501357674598694}, {"text": "automotive corpus", "start_pos": 88, "end_pos": 105, "type": "DATASET", "confidence": 0.7707241475582123}]}, {"text": "Matrax is a phrasebased decoder that allows discontiguous phrases, and parameter optimization based on gradient descent for smoothed NIST.", "labels": [], "entities": []}, {"text": "We extended the original Matrax decoder with factored decoding on the target side.", "labels": [], "entities": [{"text": "Matrax decoder", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.9441364109516144}]}, {"text": "Compounds were split before training using the corpus-based method described in Section 5.", "labels": [], "entities": []}, {"text": "Except for the experiments comparing different compound merging methods, we used the POS-match merging algorithm developed by us.", "labels": [], "entities": [{"text": "POS-match merging", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.663655087351799}]}, {"text": "We report results on three metrics: Bleu (  In the first experiment we investigated different compound representation schemes for German Europarl.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9846704006195068}, {"text": "German Europarl", "start_pos": 130, "end_pos": 145, "type": "DATASET", "confidence": 0.8997154533863068}]}, {"text": "shows the results using different representation schemes, comparing them with two baselines, with and without a POSsequence model.", "labels": [], "entities": []}, {"text": "There is generally a small significant improvement when a POS-based sequence model is used compared with the same model without a POS-based sequence model.", "labels": [], "entities": []}, {"text": "Especially for the systems with compound splitting, it was clearly worse not to use *POS-models, and all such systems perform significantly worse than both baselines on most metrics.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.6899759471416473}]}, {"text": "The representation scheme with sepmarked words and SPOS-tags did not perform well, which can both be due to less power of the mark-up system, and to the fact that it cannot use the POS-match merging heuristic.", "labels": [], "entities": [{"text": "POS-match merging heuristic", "start_pos": 181, "end_pos": 208, "type": "TASK", "confidence": 0.6164921323458353}]}, {"text": "The two systems with EPOS-models do perform well though, and are on par with the factored baseline, and mostly better than the unfactored baseline.", "labels": [], "entities": [{"text": "EPOS-models", "start_pos": 21, "end_pos": 32, "type": "DATASET", "confidence": 0.8954458832740784}]}, {"text": "The marked and unmarked systems with EPOS perform similarly, with no significant differences between them.", "labels": [], "entities": [{"text": "EPOS", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.9665976166725159}]}, {"text": "It is thus hard to say which of these classification systems are preferable, but at least it is clear that the use of EPOS-tags are useful.", "labels": [], "entities": [{"text": "EPOS-tags", "start_pos": 118, "end_pos": 127, "type": "DATASET", "confidence": 0.8990966081619263}]}, {"text": "A more detailed analysis was performed of the compound parts in the output.", "labels": [], "entities": []}, {"text": "The outcomes of the merging process were classified into four groups: known compounds; novel compounds; parts of coordinated compounds; and unmerged, single parts.", "labels": [], "entities": []}, {"text": "They were further classified into good or bad outcomes.", "labels": [], "entities": []}, {"text": "Compounds were judged as bad if they formed non-words or had the wrong form, and compound parts were judged as bad if they should have been merged with the next word, or did notwork as a standalone word.", "labels": [], "entities": []}, {"text": "shows the results of this analysis.", "labels": [], "entities": []}, {"text": "The majority of the merged compounds are known from the training corpus for all representation schemes.", "labels": [], "entities": []}, {"text": "There is, again, a marked difference between the systems that use POS-match merging and the sepmarked systems that do not have that information.", "labels": [], "entities": [{"text": "POS-match merging", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.6953185200691223}]}, {"text": "The sepmarked system found the highest number of novel compounds, but also had the highest error rate, which shows that it is useful to match POS-tags.", "labels": [], "entities": [{"text": "error rate", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9925143718719482}]}, {"text": "The EPOS systems have a higher number of novel compounds than the marked and unmarked options without an EPOS model.", "labels": [], "entities": [{"text": "EPOS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.923496663570404}]}, {"text": "All these systems had a low error rate of the novel compounds, however.", "labels": [], "entities": [{"text": "error rate", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9893177449703217}]}, {"text": "Very few errors were due to reverse normalization; In the EPOS-unmarked system there were only three such errors.", "labels": [], "entities": [{"text": "EPOS-unmarked", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9194291830062866}]}, {"text": "Generally, the percentage of bad parts or compounds is lower for the systems with a *POS-sequence model, which shows that the sequence model is useful for the ordering of compound parts.", "labels": [], "entities": []}, {"text": "The number of single compound parts is also much higher for the systems without a POS sequence model.", "labels": [], "entities": []}, {"text": "The number of compounds found by the splitting algorithm in the German reference text was 4,472.", "labels": [], "entities": [{"text": "German reference text", "start_pos": 64, "end_pos": 85, "type": "DATASET", "confidence": 0.9157248139381409}]}, {"text": "All systems produce fewer compounds than this number.", "labels": [], "entities": []}, {"text": "The numbers in cannot be directly compared to the baseline system, however, because we do not know which words in its output are compounds.", "labels": [], "entities": []}, {"text": "An indication of how many compounds there are in a text is the number of long words.", "labels": [], "entities": []}, {"text": "In the reference text there are 231 word types with at least 20 characters and 1,178 word types with at least 15 characters, which we used as the limits for long words.", "labels": [], "entities": []}, {"text": "Other length limits give similar results.", "labels": [], "entities": [{"text": "length", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9778621196746826}]}, {"text": "gives data on absolute numbers of these long word types and recall, precision, and F-score compared with long words found in the reference for the different systems.", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9995304346084595}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9997093081474304}, {"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9996275901794434}]}, {"text": "The distribution of long words in the systems with compound processing generally follows the distribution of compounds from, which indicates that this is a good indicator of the number of compounds.", "labels": [], "entities": []}, {"text": "Both baseline systems have fewer long words than all compound processing systems, indicating that the split-merge strategy does indeed help in increasing the number of compounds in the translation output.", "labels": [], "entities": []}, {"text": "The SPOS systems had the highest number of long words; for up to 15 characters there are even more long words than in the reference.", "labels": [], "entities": []}, {"text": "The EPOS systems have the same number for up to 15 characters, but a bit lower for up to 20 characters.", "labels": [], "entities": [{"text": "EPOS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9812349677085876}]}, {"text": "The EPOS systems also have the highest recall of all systems for both character lengths.", "labels": [], "entities": [{"text": "EPOS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9675639271736145}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9995406866073608}]}, {"text": "The F-scores are similar for the baseline systems and the EPOS systems, with the baseline higher on precision, and the EPOS systems higher on recall.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9972099661827087}, {"text": "EPOS", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.938182532787323}, {"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9993282556533813}, {"text": "EPOS", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.9031972289085388}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9986568689346313}]}, {"text": "Although the baseline has a higher precision, the absolute number of overlapping words is still higher in many of the systems with compound processing-for instance, for words of up to 20 characters there are 431 in EPOS-unmarked compared with 388 in baseline+POS.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9974250793457031}, {"text": "EPOS-unmarked", "start_pos": 215, "end_pos": 228, "type": "DATASET", "confidence": 0.8685898780822754}]}, {"text": "It is important to notice, however, that the reference is not a trustworthy gold standard, because there are many possible alternative good translations, and the real quality of long words are likely underestimated.", "labels": [], "entities": []}, {"text": "Thus, as can be seen in, the clear majority of produced compounds in the EPOS systems are judged acceptable, even though the precision of overlap for long words with the reference is at most 47% for the EPOS models.", "labels": [], "entities": [{"text": "precision of overlap", "start_pos": 125, "end_pos": 145, "type": "METRIC", "confidence": 0.8842849930127462}]}, {"text": "To further test whether a compound processing strategy using a customized tagset is useful, we performed experiments on an additional language pair, English-Swedish.", "labels": [], "entities": []}, {"text": "In this case we always used the successful EPOS-tagset, in combination with either the marked or unmarked representation of compounds.", "labels": [], "entities": [{"text": "EPOS-tagset", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9086803197860718}]}, {"text": "shows the results for translation into Swedish.", "labels": [], "entities": [{"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9857854247093201}]}, {"text": "Both systems with compound processing have higher scores on all metrics.", "labels": [], "entities": []}, {"text": "The difference is significant on Meteor, and on either Bleu or NIST for the two systems with compound processing.", "labels": [], "entities": [{"text": "Meteor", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.948697566986084}, {"text": "Bleu", "start_pos": 55, "end_pos": 59, "type": "DATASET", "confidence": 0.6705796718597412}, {"text": "NIST", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.8894534707069397}]}, {"text": "The only significant differences between using marked and unmarked representations is that the marked system is better on NIST.", "labels": [], "entities": [{"text": "NIST", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.8914937973022461}]}, {"text": "To investigate compound translation specifically, we manually classified the system translations corresponding to the first 100 compounds in the reference text that had a clear counterpart in the English source text.", "labels": [], "entities": [{"text": "compound translation", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.8400225341320038}]}, {"text": "As good translations we considered identical translations to the reference, and alternative translations with the same meaning, which we also distinguished between other compounds, single words, or other constructions.", "labels": [], "entities": []}, {"text": "We also had a category for word groups that were translated as separate words, but should have been compounded, split compounds.", "labels": [], "entities": []}, {"text": "The result of this evaluation can be seen in.", "labels": [], "entities": []}, {"text": "There are more translations that are identical to the reference in the two systems with splitting, but the total number of identical and alternative translations is approximately the same in the three systems.", "labels": [], "entities": []}, {"text": "The number of split compounds is higher in the baseline system.", "labels": [], "entities": []}, {"text": "The unmarked system produces more split compounds and partial translations than the marked system.", "labels": [], "entities": []}, {"text": "This can be seen as an indication of marking having an effect, which, however, is not clear in the automatic evaluation.", "labels": [], "entities": []}, {"text": "We also investigated the quality of the merged compounds, especially with regard to the reverse normalization that is needed in the unmarked systems, where compounding forms were normalized.", "labels": [], "entities": []}, {"text": "There were no merging errors in the marked system.", "labels": [], "entities": []}, {"text": "In the  unmarked system there were only two minor errors due to failed reverse normalization.", "labels": [], "entities": []}, {"text": "The first error is a missing insertion of an +s for medlem/+s/l\u00e4nder (member countries) and in the second case, *samh\u00e4ll/-e+s/politiska (socio-political), a combination change -e/+s is wrong.", "labels": [], "entities": []}, {"text": "In the third set of experiments with factored translation models we investigated the RPOS tagsets and the use of count features for the Danish and Swedish automotive corpus and German Europarl.", "labels": [], "entities": [{"text": "RPOS tagsets", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.7979600727558136}, {"text": "Danish and Swedish automotive corpus", "start_pos": 136, "end_pos": 172, "type": "DATASET", "confidence": 0.6994096517562867}, {"text": "German Europarl", "start_pos": 177, "end_pos": 192, "type": "DATASET", "confidence": 0.7050018608570099}]}, {"text": "Compound parts were merged using the POS-match heuristic.", "labels": [], "entities": []}, {"text": "Results on the two automotive corpora are shown in.", "labels": [], "entities": []}, {"text": "The scores are very high, which is due to the fact that it is an easy domain with many repetitive sentence types.", "labels": [], "entities": []}, {"text": "In this case there are no significant differences between the two baselines when using a POS-model.", "labels": [], "entities": []}, {"text": "For Swedish, the results are overall higher for the systems with compound splitting, a difference that is significant for some systems and metrics.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7076277285814285}]}, {"text": "Overall, the RPOS system performs best for Swedish, with results significantly better than at least one baseline on all metrics.", "labels": [], "entities": [{"text": "RPOS", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.5356707572937012}]}, {"text": "For Danish, on the other hand, the only significant difference between any baseline and system with splitting is for the EPOS system, which is slightly worse than the baseline with POS.", "labels": [], "entities": [{"text": "EPOS", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.9113869667053223}]}, {"text": "For the other systems there are no significant differences to the baseline.", "labels": [], "entities": []}, {"text": "shows results using RPOS for German Europarl.", "labels": [], "entities": [{"text": "RPOS", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.8505337834358215}, {"text": "German Europarl", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.8508478999137878}]}, {"text": "For this corpus neither the RPOS model nor the boost and punish models works well.", "labels": [], "entities": []}, {"text": "They all give significantly worse results than the baseline.", "labels": [], "entities": []}, {"text": "As we have seen before, however, the EPOS model gives competitive results to the baseline for this corpus.", "labels": [], "entities": []}, {"text": "Overall, we found that it was successful to use *POS-sequence models in a factored translation model in order to handle compound coalescence.", "labels": [], "entities": []}, {"text": "Our best models with compound splitting perform at least on par with the baseline, and sometimes better.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7696846127510071}]}, {"text": "We also showed that there are other advantages to using compound processing, especially that the number of long words are similar to the baseline, which is not the case for our baseline systems, which have too few long words.", "labels": [], "entities": []}, {"text": "We also showed that *POSsequence models are essential for the compound processing approach to be successful.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.748188853263855}]}, {"text": "On Europarl the EPOS-tagset was the most successful, whereas the RPOS-tagset and count features could help for the automotive domain.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.9946038126945496}, {"text": "EPOS-tagset", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.9123906493186951}, {"text": "RPOS-tagset", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.8308092355728149}]}], "tableCaptions": [{"text": " Table 5  Type and token counts and ratio for the German Europarl corpus.", "labels": [], "entities": [{"text": "ratio", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9516061544418335}, {"text": "German Europarl corpus", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.892490287621816}]}, {"text": " Table 6  Type and token counts and ratio for the Swedish Europarl corpus.", "labels": [], "entities": [{"text": "ratio", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.953478217124939}, {"text": "Swedish Europarl corpus", "start_pos": 50, "end_pos": 73, "type": "DATASET", "confidence": 0.9061724742253622}]}, {"text": " Table 7  Average phrase lengths and English/German length ratios in the phrase table and during  translation for German Europarl. German-m is German with merged compounds, where we  calculated the phrase length as if compounds were merged using the POS-match method.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.8758355379104614}]}, {"text": " Table 8  Average phrase lengths and English/Swedish length ratios in the phrase table and during  translation for Swedish Europarl. Swedish-m is Swedish with merged compounds, where we  calculated the phrase length as if compounds were merged using the POS-match method.", "labels": [], "entities": [{"text": "Swedish length ratios", "start_pos": 45, "end_pos": 66, "type": "METRIC", "confidence": 0.6429701248804728}, {"text": "Europarl", "start_pos": 123, "end_pos": 131, "type": "DATASET", "confidence": 0.5027236342430115}]}, {"text": " Table 10  Analysis of merged compounds from different representation schemes. The sepmarked systems  do not do any matching, and can thus not leave any single parts.", "labels": [], "entities": []}, {"text": " Table 11  Number of long word types in the translations, and R(ecall), P(recision), and F(-score) compared  with long word types in the reference.", "labels": [], "entities": [{"text": "F(-score)", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.8333266526460648}]}, {"text": " Table 13  Analysis of the translations of 100 source items yielding compounds in a Swedish reference text.", "labels": [], "entities": [{"text": "Swedish reference text", "start_pos": 84, "end_pos": 106, "type": "DATASET", "confidence": 0.7775564789772034}]}, {"text": " Table 16  One-to-one correspondence of split compounds compared with a manually annotated gold  standard for the different splitting methods.", "labels": [], "entities": []}, {"text": " Table 20  Number of merges for the different merging algorithms. The numbers can be compared with the  number of compounds found by the splitting algorithm in the reference text, which is 4,472.", "labels": [], "entities": []}, {"text": " Table 21  Overview of the experimental settings for comparing heuristic and sequence labeling merging.  Training sentences are taken from translated SMT training data, except extra data, which was  not used for SMT training.", "labels": [], "entities": [{"text": "sequence labeling merging", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.7061571876207987}, {"text": "SMT training", "start_pos": 150, "end_pos": 162, "type": "TASK", "confidence": 0.8937049508094788}, {"text": "SMT training", "start_pos": 212, "end_pos": 224, "type": "TASK", "confidence": 0.9376509785652161}]}, {"text": " Table 22  Experimental results for CRF on Danish Automotive, with different training data and sizes.  SMT is the same data that was used to train the SMT system, and new is additional data.", "labels": [], "entities": [{"text": "CRF", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8486738204956055}, {"text": "Danish Automotive", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.9357953071594238}, {"text": "SMT", "start_pos": 151, "end_pos": 154, "type": "TASK", "confidence": 0.9794568419456482}]}, {"text": " Table 23  Precision, Recall, and F-score for compound merging methods based on heuristics or sequence  labeling on validation data and on held-out test data. The superscripts mark the systems that are  significantly worse than the system in question (l-list, p-POS, lp-list\u2228POS, c-best CRF  configuration).  |  Validation data  Test data  Precision Recall  F-score  Precision Recall  F-score", "labels": [], "entities": [{"text": "Recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9207580089569092}, {"text": "F-score", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9964417815208435}, {"text": "F-score  Precision Recall  F-score", "start_pos": 358, "end_pos": 392, "type": "METRIC", "confidence": 0.5443771183490753}]}, {"text": " Table 25  Overview of the corpus for large evaluation sets, and the corpus sizes in sentences. The names of  the corpora refer to those used for the WMT evaluations. For the tuning data only a subset of the  full data was used.", "labels": [], "entities": [{"text": "WMT evaluations", "start_pos": 150, "end_pos": 165, "type": "TASK", "confidence": 0.5983599126338959}]}]}