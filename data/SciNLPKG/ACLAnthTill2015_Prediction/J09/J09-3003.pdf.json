{"title": [{"text": "Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis", "labels": [], "entities": [{"text": "Recognizing Contextual Polarity", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8667013247807821}, {"text": "Phrase-Level Sentiment Analysis", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.844571590423584}]}], "abstractContent": [{"text": "Many approaches to automatic sentiment analysis begin with a large lexicon of words marked with their prior polarity (also called semantic orientation).", "labels": [], "entities": [{"text": "automatic sentiment analysis", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.7325630784034729}]}, {"text": "However, the contextual polarity of the phrase in which a particular instance of a word appears maybe quite different from the word's prior polarity.", "labels": [], "entities": []}, {"text": "Positive words are used in phrases expressing negative sentiments, or vice versa.", "labels": [], "entities": []}, {"text": "Also, quite often words that are positive or negative out of context are neutral in context, meaning they are not even being used to express a sentiment.", "labels": [], "entities": []}, {"text": "The goal of this work is to automatically distinguish between prior and contextual polarity, with a focus on understanding which features are important for this task.", "labels": [], "entities": []}, {"text": "Because an important aspect of the problem is identifying when polar terms are being used in neutral contexts, features for distinguishing between neutral and polar instances are evaluated, as well as features for distinguishing between positive and negative contextual polarity.", "labels": [], "entities": []}, {"text": "The evaluation includes assessing the performance of features across multiple machine learning algorithms.", "labels": [], "entities": []}, {"text": "For all learning algorithms except one, the combination of all features together gives the best performance.", "labels": [], "entities": []}, {"text": "Another facet of the evaluation considers how the presence of neutral instances affects the performance of features for distinguishing between positive and negative polarity.", "labels": [], "entities": []}, {"text": "These experiments show that the presence of neutral instances greatly degrades the performance of these features, and that perhaps the best way to improve performance across all polarity classes is to improve the system's ability to identify when an instance is neutral.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is a type of subjectivity analysis) that focuses on identifying positive and negative opinions, emotions, and evaluations expressed in natural language.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8926376104354858}, {"text": "identifying positive and negative opinions, emotions, and evaluations expressed in natural language", "start_pos": 71, "end_pos": 170, "type": "TASK", "confidence": 0.6102836898394993}]}, {"text": "It has been a central component in applications ranging from recognizing inflammatory messages, to tracking sentiments overtime in online discussions, to classifying positive and negative reviews.", "labels": [], "entities": [{"text": "classifying positive and negative reviews", "start_pos": 154, "end_pos": 195, "type": "TASK", "confidence": 0.8010069370269776}]}, {"text": "Although a great deal of work in sentiment analysis has targeted documents, applications such as opinion question answering ( and review mining to extract opinions about companies and products ( require sentence-level or even phrase-level analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9646451473236084}, {"text": "opinion question answering", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.6483257015546163}]}, {"text": "For example, if a question answering system is to successfully answer questions about people's opinions, it must be able not only to pinpoint expressions of positive and negative sentiments, such as we find in sentence (1), but also to determine when an opinion is not being expressed by a word or phrase that typically does evoke one, such as condemned in sentence (2).", "labels": [], "entities": [{"text": "question answering", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7386443763971329}]}, {"text": "(1) African observers generally approved (positive) of his victory while Western governments denounced (negative) it.", "labels": [], "entities": []}, {"text": "(2) Gavin Elementary School was condemned in April 2004.", "labels": [], "entities": [{"text": "Gavin Elementary School", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.9717025955518087}]}, {"text": "A common approach to sentiment analysis is to use a lexicon with information about which words and phrases are positive and which are negative.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.960600733757019}]}, {"text": "This lexicon maybe manually compiled, as is the case with the General Inquirer (), a resource often used in sentiment analysis.", "labels": [], "entities": [{"text": "General Inquirer", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.9229681491851807}, {"text": "sentiment analysis", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.9577826857566833}]}, {"text": "Alternatively, the information in the lexicon maybe acquired automatically.", "labels": [], "entities": []}, {"text": "Acquiring the polarity of words and phrases is itself an active line of research in the sentiment analysis community, pioneered by the work of on predicting the polarity or semantic orientation of adjectives.", "labels": [], "entities": [{"text": "Acquiring the polarity of words and phrases", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8832062142235892}, {"text": "sentiment analysis", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.9118664860725403}, {"text": "predicting the polarity or semantic orientation of adjectives", "start_pos": 146, "end_pos": 207, "type": "TASK", "confidence": 0.8153726533055305}]}, {"text": "Various techniques have been proposed for learning the polarity of words.", "labels": [], "entities": [{"text": "learning the polarity of words", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.8453312277793884}]}, {"text": "They include corpus-based techniques, such as using constraints on the co-occurrence in conjunctions of words with similar or opposite polarity ( and statistical measures of word association, as well as techniques that exploit information about lexical relationships) and glosses) in resources such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 302, "end_pos": 309, "type": "DATASET", "confidence": 0.9642437100410461}]}, {"text": "Acquiring the polarity of words and phrases is undeniably important, and there are still open research challenges, such as addressing the sentiments of different senses of words, and soon.", "labels": [], "entities": []}, {"text": "However, what the polarity of a given word or phrase is when it is used in a particular context is another problem entirely.", "labels": [], "entities": []}, {"text": "Consider, for example, the underlined positive and negative words in the following sentence.", "labels": [], "entities": []}, {"text": "(3) Philip Clapp, president of the National Environment Trust, sums up well the general thrust of the reaction of environmental movements: \"There is no reason at all to believe that the polluters are suddenly going to become reasonable.\"", "labels": [], "entities": [{"text": "National Environment Trust", "start_pos": 35, "end_pos": 61, "type": "DATASET", "confidence": 0.9750863114992777}]}, {"text": "The first underlined word is Trust.", "labels": [], "entities": []}, {"text": "Although many senses of the word trust express a positive sentiment, in this case, the word is not being used to express a sentiment at all.", "labels": [], "entities": []}, {"text": "It is simply part of an expression referring to an organization that has taken on the charge of caring for the environment.", "labels": [], "entities": []}, {"text": "The adjective well is considered positive, and indeed it is positive in this context.", "labels": [], "entities": []}, {"text": "However, the same is not true for the words reason and reasonable.", "labels": [], "entities": []}, {"text": "Out of context, we would consider both of these words to be positive.", "labels": [], "entities": []}, {"text": "In context, the word reason is being negated, changing its polarity from positive to negative.", "labels": [], "entities": []}, {"text": "The phrase no reason at all to believe changes the polarity of the proposition that follows; because reasonable falls within this proposition, its polarity becomes negative.", "labels": [], "entities": []}, {"text": "The word polluters has a negative connotation, but herein the context of the discussion of the article and its position in the sentence, polluters is being used less to express a sentiment and more to objectively refer to companies that pollute.", "labels": [], "entities": []}, {"text": "To clarify how the polarity of polluters is affected by its subject role, consider the purely negative sentiment that emerges when it is used as an object: They are polluters.", "labels": [], "entities": []}, {"text": "We call the polarity that would be listed fora word in a lexicon the word's prior polarity, and we call the polarity of the expression in which a word appears, considering the context of the sentence and document, the word's contextual polarity.", "labels": [], "entities": []}, {"text": "Although words often do have the same prior and contextual polarity, many times a word's prior and contextual polarities differ.", "labels": [], "entities": []}, {"text": "Words with a positive prior polarity may have a negative contextual polarity, or vice versa.", "labels": [], "entities": []}, {"text": "Quite often words that are positive or negative out of context are neutral in context, meaning that they are not even being used to express a sentiment.", "labels": [], "entities": []}, {"text": "Similarly, words that are neutral out of context, neither positive or negative, may combine to create a positive or negative expression in context.", "labels": [], "entities": []}, {"text": "The focus of this work is on the recognition of contextual polarity-in particular, disambiguating the contextual polarity of words with positive or negative prior polarity.", "labels": [], "entities": []}, {"text": "We begin by presenting an annotation scheme for marking sentiment expressions and their contextual polarity in the Multi-perspective Question Answering (MPQA) opinion corpus.", "labels": [], "entities": [{"text": "Multi-perspective Question Answering (MPQA) opinion corpus", "start_pos": 115, "end_pos": 173, "type": "TASK", "confidence": 0.7420831769704819}]}, {"text": "We show that, given a set of subjective expressions (identified from the existing annotations in the MPQA corpus), contextual polarity can be annotated reliably.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 101, "end_pos": 112, "type": "DATASET", "confidence": 0.9435122013092041}]}, {"text": "Using the contextual polarity annotations, we conduct experiments in automatically distinguishing between prior and contextual polarity.", "labels": [], "entities": []}, {"text": "Beginning with a large lexicon of clues tagged with prior polarity, we identify the contextual polarity of the instances of those clues in the corpus.", "labels": [], "entities": []}, {"text": "The process that we use has two steps, first classifying each clue as being in a neutral or polar phrase, and then disambiguating the contextual polarity of the clues marked as polar.", "labels": [], "entities": []}, {"text": "For each step in the process, we experiment with a variety of features and evaluate the performance of the features using several different machine learning algorithms.", "labels": [], "entities": []}, {"text": "Our experiments reveal a number of interesting findings.", "labels": [], "entities": []}, {"text": "First, being able to accurately identify neutral contextual polarity-when a positive or negative clue is not being used to express a sentiment-is an important aspect of the problem.", "labels": [], "entities": []}, {"text": "The importance of neutral examples has previously been noted for classifying the sentiment of documents (), but ours is the first work to explore how neutral instances affect classifying the contextual polarity of words and phrases.", "labels": [], "entities": [{"text": "classifying the sentiment of documents", "start_pos": 65, "end_pos": 103, "type": "TASK", "confidence": 0.8599547266960144}, {"text": "classifying the contextual polarity of words and phrases", "start_pos": 175, "end_pos": 231, "type": "TASK", "confidence": 0.687743604183197}]}, {"text": "In particular, we found that the performance of features for distinguishing between positive and negative polarity greatly degrades when neutral instances are included in the experiments.", "labels": [], "entities": []}, {"text": "We also found that achieving the best performance for recognizing contextual polarity requires a wide variety of features.", "labels": [], "entities": []}, {"text": "This is particularly true for distinguishing between neutral and polar instances.", "labels": [], "entities": []}, {"text": "Although some features help to increase polar or neutral recall or precision, it is only the combination of features together that achieves significant improvements inaccuracy over the baselines.", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9957422614097595}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9902426600456238}]}, {"text": "Our experiments show that for distinguishing between positive and negative instances, features capturing negation are clearly the most important.", "labels": [], "entities": []}, {"text": "However, there is more to the story than simple negation.", "labels": [], "entities": []}, {"text": "Features that capture relationships between instances of clues also perform well, indicating that identifying features that represent more complex interdependencies between sentiment clues maybe an important avenue for future research.", "labels": [], "entities": []}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of some of the things that can influence contextual polarity.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our corpus and present our annotation scheme and inter-annotator agreement study for marking contextual polarity.", "labels": [], "entities": [{"text": "marking contextual polarity", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.808974047501882}]}, {"text": "Sections 4 and 5 describe the lexicon used in our experiments and how the contextual polarity annotations are used to determine the gold-standard tags for instances from the lexicon.", "labels": [], "entities": []}, {"text": "In Section 6, we consider what kind of performance can be expected from a simple, prior-polarity classifier.", "labels": [], "entities": []}, {"text": "Section 7 describes the features that we use for recognizing contextual polarity, and our experiments and results are presented in Section 8.", "labels": [], "entities": []}, {"text": "In Section 9 we discuss related work, and we conclude in Section 10.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have two primary goals with our experiments in recognizing contextual polarity.", "labels": [], "entities": []}, {"text": "The first is to evaluate the features described in Section 7 as to their usefulness for this task.", "labels": [], "entities": []}, {"text": "The second is to investigate the importance of recognizing neutral instancesrecognizing when a sentiment clue is not being used to express a sentiment-for classifying contextual polarity.", "labels": [], "entities": [{"text": "classifying contextual polarity", "start_pos": 155, "end_pos": 186, "type": "TASK", "confidence": 0.6906245549519857}]}, {"text": "To evaluate features, we investigate their performance, both together and separately, across several different learning algorithms.", "labels": [], "entities": []}, {"text": "Varying the learning algorithm allows us to verify that the features are robust and that their performance is not the artifact of a particular algorithm.", "labels": [], "entities": []}, {"text": "We experiment with four different types of machine learning: boosting, memory-based learning, rule learning, and support vector learning.", "labels": [], "entities": [{"text": "rule learning", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.8273724615573883}]}, {"text": "For boosting, we use BoosTexter (Schapire and Singer 2000) AdaBoost.MH.", "labels": [], "entities": [{"text": "BoosTexter (Schapire and Singer 2000) AdaBoost.MH", "start_pos": 21, "end_pos": 70, "type": "DATASET", "confidence": 0.7019529230892658}]}, {"text": "For rule learning, we use Ripper (Cohen 1996).", "labels": [], "entities": [{"text": "rule learning", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9311326146125793}]}, {"text": "For memory-based learning, we use TiMBL () IB1 (k-nearest neighbor).", "labels": [], "entities": [{"text": "TiMBL () IB1", "start_pos": 34, "end_pos": 46, "type": "METRIC", "confidence": 0.5910647213459015}]}, {"text": "For support vector learning, we use SVM-light and SVM-multiclass (Joachims 1999).", "labels": [], "entities": []}, {"text": "SVM-light is used for the experiments involving binary classification (neutral-polar classification), and SVM-multiclass is used for experiments with more than two classes.", "labels": [], "entities": [{"text": "SVM-light", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.910865843296051}]}, {"text": "These machine learning algorithms were chosen because they have been used successfully fora number of natural language processing tasks, and they represent several different types of learning.", "labels": [], "entities": []}, {"text": "For all of the classification algorithms except for SVM, the features fora clue instance are represented as they are presented in Section 7.", "labels": [], "entities": []}, {"text": "For SVM, the representations for numeric and discrete-valued features are changed.", "labels": [], "entities": []}, {"text": "Numeric features, such as the count of strongsubj clue instances in a sentence, are scaled to range between 0 and 1.", "labels": [], "entities": []}, {"text": "Discrete-valued features, such as the reliability class feature, are converted into multiple binary features.", "labels": [], "entities": []}, {"text": "For example, the reliability class feature is represented by two binary features: one for whether the clue instance is a strongsubj clue and one for whether the clue instance is a weaksubj clue.", "labels": [], "entities": []}, {"text": "To investigate the importance of recognizing neutral instances, we perform two sets of polarity classification (step two) experiments.", "labels": [], "entities": []}, {"text": "First, we experiment with classifying the polarity of all gold-standard polar instances-the clue instances identified as polar in context by the manual polarity annotations.", "labels": [], "entities": []}, {"text": "Second, we experiment with using the polar instances identified automatically by the neutral-polar classifiers.", "labels": [], "entities": []}, {"text": "Because the second set of experiments includes the neutral instances misclassified in step one, we can compare results for the two sets of experiments to see how the noise of neutral instances affects the performance of the polarity features.", "labels": [], "entities": []}, {"text": "All experiments are performed using 10-fold cross validation over a test set of 10,287 sentences from 494 MPQA corpus documents.", "labels": [], "entities": [{"text": "MPQA corpus documents", "start_pos": 106, "end_pos": 127, "type": "DATASET", "confidence": 0.962300697962443}]}, {"text": "We measure performance in terms of accuracy, recall, precision, and F-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9996156692504883}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.99956876039505}, {"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9995965361595154}, {"text": "F-measure", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9975650310516357}]}, {"text": "Accuracy is simply the total number of instances correctly classified.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9910706281661987}]}, {"text": "Recall, precision, and F-measure fora given class C are defined as follows.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.959021806716919}, {"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9993090629577637}, {"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9937641024589539}]}, {"text": "Recall is the percentage of all instances of class C correctly identified.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9897597432136536}]}, {"text": "To evaluate the performance of the various features for polarity classification, we again perform a series of ablation experiments.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.919882744550705}]}, {"text": "As before, we start with the word+priorpol baseline classifier, add different sets of polarity features, train new classifiers, and compare the results of the new classifiers to the baseline.", "labels": [], "entities": []}, {"text": "Increases and decreases fora given metric as compared to the word+priorpol baseline are indicated by + or -, respectively; ++ or --indicates the change is significant at the p < 0.1 level; +++ or ---indicates significance at the p < 0.05 level.", "labels": [], "entities": []}, {"text": "lists the sets of features tested in each experiment, and shows the results of the experiments.", "labels": [], "entities": []}, {"text": "Results are reported as they were previously in Section 8.1.2, with increases and decreases compared to the baseline fora given metric indicated by + or -, respectively.", "labels": [], "entities": [{"text": "Section 8.1.2", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.8996550142765045}]}, {"text": "Looking at, we see that all three sets of polarity features help to increase performance as measured by accuracy and positive and negative F-measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9994449019432068}, {"text": "F-measures", "start_pos": 139, "end_pos": 149, "type": "METRIC", "confidence": 0.9650081992149353}]}, {"text": "This is true for all the classification algorithms.", "labels": [], "entities": []}, {"text": "As we might expect, including the negation features has the most marked effect on the performance of polarity classification, with statistically significant improvements for most metrics across all the algorithms.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.8925554156303406}]}, {"text": "The polarity-modification features also seem to be important for polarity classification, in particular for disambiguating the positive instances.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.722078949213028}]}, {"text": "For all the algorithms except TiMBL, including the polarity-modification features results in significant improvements for at least one of the positive metrics.", "labels": [], "entities": []}, {"text": "The polarity shifters also help classification, but they seem to be the weakest of the features: Including them does not result in significant improvements for any algorithm.", "labels": [], "entities": [{"text": "classification", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.985770583152771}]}, {"text": "Another question that is interesting to consider is how much the word token feature contributes to polarity classification, given all the other polarity features.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.8885611593723297}]}, {"text": "Is it enough to know the prior polarity of a word, whether it is being negated, and how it is related to other polarity influencers?", "labels": [], "entities": []}, {"text": "To answer this question, we train classifiers using all the polarity features except for word token.", "labels": [], "entities": []}, {"text": "gives the results for these classifiers; for comparison, the results for the all-feature polarity classifiers are also given.", "labels": [], "entities": []}, {"text": "Interestingly, excluding the word token feature produces only small changes in the overall results.", "labels": [], "entities": []}, {"text": "The results for BoosTexter and Ripper are slightly lower, and the results for SVM are practically unchanged.", "labels": [], "entities": [{"text": "BoosTexter", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.8484198451042175}, {"text": "SVM", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.4952336847782135}]}, {"text": "TiMBL actually shows a slight improvement, with the exception of the both class.", "labels": [], "entities": [{"text": "TiMBL", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9469022750854492}]}, {"text": "This provides further evidence of the strength of the polarity features.", "labels": [], "entities": []}, {"text": "Also, a classifier not tied to actual word tokens may potentially be a more domain-independent classifier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Contingency table for contextual polarity agreement.", "labels": [], "entities": [{"text": "contextual polarity agreement", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.7140017549196879}]}, {"text": " Table 4  Contingency table for contextual polarity agreement, borderline cases removed.", "labels": [], "entities": []}, {"text": " Table 5  Distribution of contextual polarity tags.", "labels": [], "entities": []}, {"text": " Table 6  Confusion matrix for the prior-polarity classifier on the development set.", "labels": [], "entities": []}, {"text": " Table 11  Results for neutral-polar classification (step one).", "labels": [], "entities": [{"text": "neutral-polar classification", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.7352869510650635}]}, {"text": " Table 15  Results for polarity classification (step two) using gold-standard polar instances.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9277656078338623}]}, {"text": " Table 18  Results for polarity classification without and with the word token feature.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9329188764095306}]}, {"text": " Table 19  Results for polarity classification (step two) using automatically identified polar instances.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9051116704940796}]}, {"text": " Table 20  Results for contextual polarity classification for both two-step and one-step approaches.", "labels": [], "entities": [{"text": "contextual polarity classification", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.8386807044347128}]}]}