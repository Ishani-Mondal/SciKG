{"title": [{"text": "The Syntax and Semantics of Prepositions in the Task of Automatic Interpretation of Nominal Phrases and Compounds: A Cross-Linguistic Study", "labels": [], "entities": []}], "abstractContent": [{"text": "In this article we explore the syntactic and semantic properties of prepositions in the context of the semantic interpretation of nominal phrases and compounds.", "labels": [], "entities": [{"text": "semantic interpretation of nominal phrases and compounds", "start_pos": 103, "end_pos": 159, "type": "TASK", "confidence": 0.7377391713006156}]}, {"text": "We investigate the problem based on cross-linguistic evidence from a set of six languages: English, Spanish, Italian, French, Portuguese, and Romanian.", "labels": [], "entities": []}, {"text": "The focus on English and Romance languages is well motivated.", "labels": [], "entities": []}, {"text": "Most of the time, English nominal phrases and compounds translate into constructions of the form NP N in Romance languages, where the P (preposition) may vary in ways that correlate with the semantics.", "labels": [], "entities": []}, {"text": "Thus, we present empirical observations on the distribution of nominal phrases and compounds and the distribution of their meanings on two different corpora, based on two state-of-the-art classification tag sets: Lauer's set of eight prepositions and our list of 22 semantic relations.", "labels": [], "entities": []}, {"text": "A mapping between the two tag sets is also provided.", "labels": [], "entities": []}, {"text": "Furthermore, given a training set of English nominal phrases and compounds along with their translations in the five Romance languages, our algorithm automatically learns classification rules and applies them to unseen test instances for semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 238, "end_pos": 261, "type": "TASK", "confidence": 0.7865321636199951}]}, {"text": "Experimental results are compared against two state-of-the-art models reported in the literature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Prepositions are an important and frequently used category in both English and Romance languages.", "labels": [], "entities": []}, {"text": "Ina corpus study of one million English words, shows that one in ten words is a preposition.", "labels": [], "entities": []}, {"text": "Moreover, about 10% of the 175 most frequent words in a corpus of 20 million Spanish words were found to be prepositions ().", "labels": [], "entities": []}, {"text": "Studies on language acquisition) have shown that the acquisition and understanding of prepositions in languages such as English and Romance is a difficult task for native speakers, and even more difficult for second language learners.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.7352884411811829}, {"text": "acquisition and understanding of prepositions", "start_pos": 53, "end_pos": 98, "type": "TASK", "confidence": 0.670312124490738}]}, {"text": "For example, together with articles, prepositions represent the primary source of grammatical errors for learners of English as a foreign language).", "labels": [], "entities": []}, {"text": "Although the complexity of preposition usage has been argued for and documented by various scholars in linguistics, psycholinguistics, and computational linguistics, very few studies have been done on the function of prepositions in natural language processing (NLP) applications.", "labels": [], "entities": []}, {"text": "The reason is that prepositions are probably the most polysemous category and thus, their linguistic realizations are difficult to predict and their cross-linguistic regularities difficult to identify.", "labels": [], "entities": []}, {"text": "In this article we investigate the role of prepositions in the task of automatic semantic interpretation of English nominal phrases and compounds.", "labels": [], "entities": [{"text": "automatic semantic interpretation of English nominal phrases and compounds", "start_pos": 71, "end_pos": 145, "type": "TASK", "confidence": 0.8406835496425629}]}, {"text": "The problem is simple to define: Given a compositional noun phrase (the meaning of the phrase derives from the meaning of the constituents) constructed out of a pair of nouns, N 1 N 2 , one representing the head and the other the modifier, determine the semantic relationship between the two nouns.", "labels": [], "entities": []}, {"text": "For example, the noun-noun compound family estate encodes a POSSESSION relation, while the nominal phrase the faces of the children refers to PART-WHOLE.", "labels": [], "entities": [{"text": "POSSESSION", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9919289350509644}, {"text": "PART-WHOLE", "start_pos": 142, "end_pos": 152, "type": "METRIC", "confidence": 0.7817075848579407}]}, {"text": "The problem, although simple to state, is difficult for automatic semantic interpretation.", "labels": [], "entities": [{"text": "automatic semantic interpretation", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.6003075540065765}]}, {"text": "The reason is that the meaning of these constructions is most of the time implicit (it cannot be easily recovered from morphological analysis).", "labels": [], "entities": []}, {"text": "Interpreting nominal phrases and compounds correctly requires various types of information, from world knowledge to lexico-syntactic and discourse information.", "labels": [], "entities": [{"text": "Interpreting nominal phrases and compounds", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.887489402294159}]}, {"text": "This article focuses on nominal phrases of the type NP N and noun compounds (N N) and investigates the problem based on cross-linguistic evidence from a set of six languages: English, Spanish, Italian, French, Portuguese, and Romanian.", "labels": [], "entities": []}, {"text": "The choice of these constructions is empirically motivated.", "labels": [], "entities": []}, {"text": "Ina study of 6,200 (Europarl 1 ) and 2,100 (CLUVI 2 ) English token nominal phrase and compound instances randomly chosen from two English-Romance parallel text collections of different genres, we show that over 80% of their Romance noun phrase translations are encoded by NP N and N N constructions.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.9674304723739624}]}, {"text": "For instance, beer glass, an English compound of the form N 1 N 2 , translates into N 2 P N 1 instances in Romance: tarro de cerveza ('glass of beer') in Spanish, bicchiere da birra ('glass for beer') in Italian, verr\u00e8 ab\u00ec ere ('glass at/to beer') in French, copo de cerveja ('glass of beer') in Portuguese, and pahar de bere ('glass of beer') in Romanian.", "labels": [], "entities": []}, {"text": "In this article, in addition to the sense translation (in italics), when relevant we also provide the word-by-word gloss (in 'parentheses').", "labels": [], "entities": [{"text": "sense translation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.694720596075058}]}, {"text": "Moreover, we use N 1 , N 2 to denote the two lexical nouns that encode a semantic relation (where N 1 is the syntactic modifier and N 2 is the syntactic head), and Arg 1 , Arg 2 to denote the semantic arguments of the relation encoded by the two nouns.", "labels": [], "entities": [{"text": "Arg", "start_pos": 164, "end_pos": 167, "type": "METRIC", "confidence": 0.9905673861503601}, {"text": "Arg", "start_pos": 172, "end_pos": 175, "type": "METRIC", "confidence": 0.9341214895248413}]}, {"text": "For example, beer glass encodes a PURPOSE relation where Arg 1 (beer) is the purpose of Arg 2 ('glass'; thus 'glass (used) for beer').", "labels": [], "entities": [{"text": "PURPOSE", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.8716556429862976}, {"text": "Arg 1", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9782477021217346}, {"text": "Arg", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9840169548988342}]}, {"text": "We argue here that the syntactic directionality given by the head-modifier relation (N 1 N 2 in noun compounds and N 2 P N 1 in nominal phrases) is not always the same as the semantic directionality given by the semantic argument frame of the semantic relation.", "labels": [], "entities": []}, {"text": "Otherwise said, N 1 does not always map to Arg 1 and N 2 to Arg 2 for any given relation.", "labels": [], "entities": []}, {"text": "Languages choose different nominal phrases and compounds to encode relationships between nouns.", "labels": [], "entities": []}, {"text": "For example, English nominal phrases and compounds of the", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed various experiments on both the Europarl and CLUVI testing corpora using seven sets of supervised models.", "labels": [], "entities": [{"text": "Europarl and CLUVI testing corpora", "start_pos": 45, "end_pos": 79, "type": "DATASET", "confidence": 0.8022888660430908}]}, {"text": "shows the results obtained against SS and Lapata and Keller's model on both corpora and the contribution of the features exemplified in seven versions of the SVM model.", "labels": [], "entities": []}, {"text": "Supervised models 1 and 2 are defined only for the English features.", "labels": [], "entities": []}, {"text": "Here, features F1 and F2 measure the contribution of the WordNet IS-A lexical hierarchy specialization.", "labels": [], "entities": [{"text": "F1", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.9932752847671509}, {"text": "WordNet IS-A lexical hierarchy", "start_pos": 57, "end_pos": 87, "type": "DATASET", "confidence": 0.8707296252250671}]}, {"text": "However, supervised model 1, which is also the baseline, does not differentiate between unambiguous and ambiguous training examples and thus does not specialize those that are ambiguous.", "labels": [], "entities": []}, {"text": "These models show the difference between SS and SVM and the contribution of the other English features, such as preposition and nominalization (F1-F7).", "labels": [], "entities": [{"text": "F1-F7", "start_pos": 144, "end_pos": 149, "type": "METRIC", "confidence": 0.9740518927574158}]}, {"text": "The table shows that overall the performance is better for the Europarl corpus than for CLUVI.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.993998646736145}, {"text": "CLUVI", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.9135463237762451}]}, {"text": "For the supervised models 1 and 2, SS [F1 + F2] gives better results than SVM [F1 + F2].", "labels": [], "entities": [{"text": "SS", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9019272327423096}, {"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.7917667031288147}]}, {"text": "The inclusion of the other English features (SVM [F1-F7]) adds more than 10% accuracy (with a higher increase in Europarl) for the supervised model 1.", "labels": [], "entities": [{"text": "F1-F7", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.575954794883728}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9995972514152527}, {"text": "Europarl", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.8688878417015076}]}, {"text": "The results obtained are presented using the standard measure of accuracy (the number of correctly labeled instances over the number of instances in the test set).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9990171194076538}]}], "tableCaptions": [{"text": " Table 1  The set of 22 semantic relations along with examples interpreted in context and the semantic  argument frame.", "labels": [], "entities": []}, {"text": " Table 3  The inter-annotator agreement on the annotation of the nominal phrases and compounds in the  two corpora. For the instances that encoded more than one classification category, the agreement  was measured on the first relation on which the annotators agreed. N/A = not applicable.", "labels": [], "entities": []}, {"text": " Table 4  The distribution of syntactic constructions used in the translation of 6,200 Europarl and 2,310  English NN and N P N instances. N A = noun-adjective; pph = other syntactic paraphrase.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.8716891407966614}]}]}