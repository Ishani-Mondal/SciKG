{"title": [{"text": "Last Words That's Nice . . . What Can You Do With It?", "labels": [], "entities": []}], "abstractContent": [{"text": "A regular fixture on the mid 1990s international research seminar circuit was the \"billion-neuron artificial brain\" talk.", "labels": [], "entities": []}, {"text": "The idea behind this project was simple: in order to create artificial intelligence, what was needed first of all was a very large artificial brain; if a big enough set of interconnected modules of neurons could be implemented, then it would be possible to evolve mammalian-level behavior with current computational-neuron technology.", "labels": [], "entities": []}, {"text": "The talk included progress reports on the current size of the artificial brain, its structure, \"update rate,\" and power consumption, and explained how intelligent behavior was going to develop by mechanisms simulating biological evolution.", "labels": [], "entities": [{"text": "update rate", "start_pos": 96, "end_pos": 107, "type": "METRIC", "confidence": 0.9718766212463379}]}, {"text": "What the talk didn't mention was what kind of functionality the team had so far managed to evolve, and so the first comment at the end of the talk was inevitably \"nice work, but have you actually done anything with the brain yet?\"", "labels": [], "entities": []}, {"text": "1 In human language technology (HLT) research, we currently report a range of evaluation scores that measure and assess various aspects of systems, in particular the similarity of their outputs to samples of human language or to human-produced gold-standard annotations, but are we leaving ourselves open to the same question as the billion-neuron artificial brain researchers?", "labels": [], "entities": []}, {"text": "Shrinking Horizons HLT evaluation has along history.", "labels": [], "entities": [{"text": "Shrinking Horizons HLT evaluation", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8282576650381088}]}, {"text": "Sp\u00e4rck Jones's Information Retrieval Experiment (1981) already had two decades of IR evaluation history to look back on.", "labels": [], "entities": [{"text": "Information Retrieval Experiment (1981)", "start_pos": 15, "end_pos": 54, "type": "TASK", "confidence": 0.8335567116737366}, {"text": "IR evaluation", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.9225136637687683}]}, {"text": "It provides a fairly comprehensive snapshot of HLT evaluation at the time, as much of HLT evaluation research was in the field of IR.", "labels": [], "entities": [{"text": "HLT evaluation", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9628979563713074}, {"text": "HLT evaluation", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.8866364657878876}, {"text": "IR", "start_pos": 130, "end_pos": 132, "type": "TASK", "confidence": 0.9639990329742432}]}, {"text": "One thing that is striking from today's perspective is the rich diversity of evaluation paradigms-user-oriented and developer-oriented, intrinsic and extrinsic 2-that were being investigated and discussed on an equal footing 1 To which the answer was, in effect, \"the brain isn't big enough yet to be used.\"", "labels": [], "entities": []}, {"text": "The original aim of the CAM-Brain Project was to evolve behavior as complex as that of a kitten (the brain was going to control a robotic kitten, the \"Robokoneko\").", "labels": [], "entities": []}, {"text": "The functionality reported for the modules the brain was composed of was on the level of the XOR-function (de Garis et al. 1999).", "labels": [], "entities": [{"text": "XOR-function", "start_pos": 93, "end_pos": 105, "type": "METRIC", "confidence": 0.9754135012626648}]}, {"text": "To date, no functionality appears to have been reported for the brain as a whole.", "labels": [], "entities": []}, {"text": "2 User-oriented evaluations (covered by ISO standards 9126 and 14598 on software evaluation) look at a set of requirements (available computational, financial, and other resources, acceptable processing time, maintenance cost, etc.) of the user (embedding application or person) and assess how well different technological alternatives fulfill them.", "labels": [], "entities": []}, {"text": "Developer-oriented evaluations focus on functionality (just one component in the ISO standards) and seek to assess the quality of a system's (or component's) outputs.", "labels": [], "entities": []}, {"text": "The user-oriented vs. developer-oriented distinction concerns evaluation purpose.", "labels": [], "entities": []}, {"text": "Another common distinction is about evaluation methods: intrinsic evaluations assess properties of systems in their own right, for example, comparing their outputs to reference outputs in a corpus, whereas extrinsic evaluations assess the effect of a system on something that is external to it, for example, the effect on human performance at a given task or the value added to an application (Sp\u00e4rck Jones 1994).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}