{"title": [], "abstractContent": [{"text": "Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output, but are often very computationally intensive.", "labels": [], "entities": [{"text": "statistical machine translation output", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.7263176888227463}]}, {"text": "The complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages.", "labels": [], "entities": []}, {"text": "We develop a theory of binarization for synchronous context-free grammars and present a linear-time algorithm for binarizing synchronous rules when possible.", "labels": [], "entities": []}, {"text": "In our large-scale experiments, we found that almost all rules are binarizable and the resulting binarized rule set significantly improves the speed and accuracy of a state-of-the-art syntax-based machine translation system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9980500936508179}, {"text": "machine translation", "start_pos": 197, "end_pos": 216, "type": "TASK", "confidence": 0.72221639752388}]}, {"text": "We also discuss the more general, and computationally more difficult, problem of finding good parsing strategies for non-binarizable rules, and present an approximate polynomial-time algorithm for this problem.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several recent syntax-based models for machine translation) can be seen as instances of the general framework of synchronous grammars and tree transducers.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7588956952095032}]}, {"text": "In this framework, both alignment (synchronous parsing) and decoding can bethought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right-hand side of a grammar rule.", "labels": [], "entities": []}, {"text": "To alleviate this problem, we investigate bilingual binarization as a technique to factor each synchronous grammar rule into a series of binary rules.", "labels": [], "entities": []}, {"text": "Although monolingual context-free grammars (CFGs) can always be binarized, this is not the case r In the final, theoretical, sections of this article, we investigate the general problem of finding the most efficient synchronous parsing or decoding strategy for arbitrary synchronous context-free grammar (SCFG) rules, including non-binarizable cases.", "labels": [], "entities": []}, {"text": "Although this problem is believed to be NP-complete, we prove two results that substantially reduce the search space over strategies.", "labels": [], "entities": []}, {"text": "We also present an optimal algorithm that runs tractably in practice and a polynomial-time algorithm that is a good approximation of the former.", "labels": [], "entities": []}, {"text": "discusses binarization of multi-text grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing.", "labels": [], "entities": []}, {"text": "One way around this difficulty is to stipulate that all rules must be binary from the outset, as in Inversion Transduction Grammar (ITG)) and the binary SCFG employed by the Hiero system) to model the hierarchical phrases.", "labels": [], "entities": []}, {"text": "In contrast, the rule extraction method of aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7508708834648132}]}, {"text": "This approach results in rules with many nonterminals, making good binarization techniques critical.", "labels": [], "entities": []}, {"text": "We explain how synchronous rule binarization interacts with n-gram language models and affects decoding for machine translation in Section 2.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7805102169513702}]}, {"text": "We define binarization formally in Section 3, and present an efficient algorithm for the problem in Section 4.", "labels": [], "entities": []}, {"text": "Experiments described in Section 5 show that binarization improves machine translation speed and quality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7253703474998474}]}, {"text": "Some rules cannot be binarized, and we present a decoding strategy for these rules in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 gives a solution to the general theoretical problem of finding optimal decoding and synchronous parsing strategies for arbitrary SCFGs, and presents complexity results on the nonbinarizable rules from our Chinese-English data.", "labels": [], "entities": []}, {"text": "These final two sections are of primarily theoretical interest, as nonbinarizable rules have not been shown to benefit real-world machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7189579159021378}]}, {"text": "However, the algorithms presented may become relevant as machine translation systems improve.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7460077702999115}]}], "datasetContent": [{"text": "The combination of minimizing SCFG rule length as a preprocessing step and then applying the best-first version of Algorithm 3 makes it possible to find optimal parsing strategies for all of the rules in the large Chinese-English rule set used for our decoding experiments.", "labels": [], "entities": []}, {"text": "For the 157,212 non-binarizable rules (0.3% of the total), the complexity of the optimal parsing strategies is shown in.", "labels": [], "entities": []}, {"text": "Although the worst parsing complexity is O(|w| 12 ), this is only achieved by a single rule.", "labels": [], "entities": [{"text": "O", "start_pos": 41, "end_pos": 42, "type": "METRIC", "confidence": 0.9765055179595947}]}, {"text": "The best-first analyzer takes approximately five minutes of CPU time to analyze this single rule, but processes all others in less than one second.", "labels": [], "entities": []}, {"text": "We tested the CKY-based factorization algorithm on our set of non-binarizable rules extracted from the Chinese-English data.", "labels": [], "entities": []}, {"text": "The CKY-on-English method found an optimal parsing strategy for 98% of the rules, and its worst-case complexity over the entire ruleset was O(|w| 15 ), rather than the optimal O(|w| 12 ).", "labels": [], "entities": []}, {"text": "If we run CKY factorization from two directions (one for the permutation \u03c0 and the other for the permutation \u03c0 \u22121 ) and take the minimum of both, we can get an even better approximation.", "labels": [], "entities": []}, {"text": "In, we compare the approximate strategy which takes the minimum of CKY runs for The distribution of parsing complexities of non-binarizable rules extracted from the GIZA-aligned Chinese-English data in Section 5.", "labels": [], "entities": [{"text": "parsing complexities", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.8825870156288147}, {"text": "GIZA-aligned Chinese-English data", "start_pos": 165, "end_pos": 198, "type": "DATASET", "confidence": 0.8929257988929749}]}, {"text": "The first column denotes the exponent of the time complexity-for example, 10 means O(|w| 10 ).", "labels": [], "entities": []}, {"text": "opt denotes the optimal parsing strategy and cky-min denotes the approximation strategy that takes the better of the CKY results on both sides.", "labels": [], "entities": []}, {"text": "two languages, which we call CKY-min, with the optimal strategy.", "labels": [], "entities": []}, {"text": "For synchronous parsing, for 99.77% of the rules, the CKY-min method found an optimal strategy.", "labels": [], "entities": [{"text": "synchronous parsing", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.52298903465271}]}, {"text": "When generalized for m-gram integrated decoding, CKY maintains continuous spans on the output language and allows for discontinuous parsing on the input sentence.", "labels": [], "entities": []}, {"text": "The difference between CKY-on-output and the optimal decoding strategy was negligible in the situation of trigram-integrated decoding for the given rules.", "labels": [], "entities": []}, {"text": "The worst-case complexity for decoding into English by CKY-on-English was O(|w| 18 ), versus O(|w| 17 ) from the optimal strategy.", "labels": [], "entities": [{"text": "CKY-on-English", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.9354815483093262}, {"text": "O", "start_pos": 74, "end_pos": 75, "type": "METRIC", "confidence": 0.9809258580207825}, {"text": "O", "start_pos": 93, "end_pos": 94, "type": "METRIC", "confidence": 0.9649605751037598}]}, {"text": "The CKY-on-English approach found an optimal decoding strategy for 99.97% of the non-binarizable rules.", "labels": [], "entities": []}, {"text": "The CKY-min strategy was even better, only finding sub-optimal results for six rules out of all rules, which translates to 99.996%.", "labels": [], "entities": []}, {"text": "In, we have also included the comparison for translating into Chinese, in which case the inverted permutations are used and the language model weight is put on the Chinese side.", "labels": [], "entities": [{"text": "translating into Chinese", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.8841579755147299}]}, {"text": "A similar approximation accuracy was achieved.", "labels": [], "entities": [{"text": "approximation", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.8839210867881775}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8573511242866516}]}], "tableCaptions": [{"text": " Table 1  Summary of non-binarizable ratios from hand-aligned data.", "labels": [], "entities": []}, {"text": " Table 2  Machine translation results for syntax-based systems vs. the phrase-based Alignment Template  System.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.821109414100647}]}, {"text": " Table 4  The distribution of parsing complexities of non-binarizable rules extracted from the  GIZA-aligned Chinese-English data in Section 5. The first column denotes the exponent of the  time complexity-for example, 10 means O(|w| 10 ). opt denotes the optimal parsing strategy and  cky-min denotes the approximation strategy that takes the better of the CKY results on both sides.", "labels": [], "entities": [{"text": "parsing complexities", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.9025174379348755}, {"text": "GIZA-aligned Chinese-English data", "start_pos": 96, "end_pos": 129, "type": "DATASET", "confidence": 0.9312694072723389}]}]}