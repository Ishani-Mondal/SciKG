{"title": [{"text": "Evaluating Centering for Information Ordering Using Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "In this article we discuss several metrics of coherence defined using centering theory and investigate the usefulness of such metrics for information ordering in automatic text generation.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 138, "end_pos": 158, "type": "TASK", "confidence": 0.7492620348930359}, {"text": "automatic text generation", "start_pos": 162, "end_pos": 187, "type": "TASK", "confidence": 0.5861913959185282}]}, {"text": "We estimate empirically which is the most promising metric and how useful this metric is using a general methodology applied on several corpora.", "labels": [], "entities": []}, {"text": "Our main result is that the simplest metric (which relies exclusively on NOCB transitions) sets a robust baseline that cannot be outperformed by other metrics which make use of additional centering-based features.", "labels": [], "entities": []}, {"text": "This baseline can be used for the development of both text-to-text and concept-to-text generation systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information ordering (, that is, deciding in which sequence to present a set of preselected information-bearing items, has received much attention in recent work in automatic text generation.", "labels": [], "entities": [{"text": "Information ordering", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8190195560455322}, {"text": "automatic text generation", "start_pos": 165, "end_pos": 190, "type": "TASK", "confidence": 0.6783334612846375}]}, {"text": "This is because text generation systems need to organize the content in away that makes the output text coherent, that is, easy to read and understand.", "labels": [], "entities": [{"text": "text generation", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7052085995674133}]}, {"text": "The easiest way to exemplify coherence is by arbitrarily reordering the sentences of a comprehensible text.", "labels": [], "entities": []}, {"text": "This process very often gives rise to documents that do not make sense although the information content is the same before and after the reordering.", "labels": [], "entities": []}, {"text": "Entity coherence, which is based on the way the referents of noun phrases (NPs) relate subsequent clauses in the text, is an important aspect of textual organization.", "labels": [], "entities": []}, {"text": "Since the early 1980s, when it was first introduced, centering theory has been an influential framework for modelling entity coherence.", "labels": [], "entities": []}, {"text": "Seminal papers on centering such as Brennan, Friedman, and Pollard and suggest that centering may provide solutions for information ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 120, "end_pos": 140, "type": "TASK", "confidence": 0.8162420690059662}]}, {"text": "Indeed, following the pioneering work of, recent work on text generation exploits constraints on entity coherence to organize information (;.", "labels": [], "entities": [{"text": "text generation", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.7476685047149658}]}, {"text": "Although these approaches often make use of heuristics related to centering, the features of entity coherence they employ are usually defined informally.", "labels": [], "entities": []}, {"text": "Additionally, centering-related features are combined with other coherence-inducing factors in ways that are based mainly on intuition, leaving many equally plausible options unexplored.", "labels": [], "entities": []}, {"text": "Thus, the answers to the following questions remain unclear: (i) How appropriate is centering for information ordering in text generation?", "labels": [], "entities": [{"text": "information ordering in text generation", "start_pos": 98, "end_pos": 137, "type": "TASK", "confidence": 0.6427169799804687}]}, {"text": "(ii) Which aspects of centering are most useful for this purpose?", "labels": [], "entities": []}, {"text": "These are the issues we investigate in this paper, which presents the first systematic evaluation of centering for information ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 115, "end_pos": 135, "type": "TASK", "confidence": 0.7875301539897919}]}, {"text": "To do this, we define centering-based metrics of coherence which are compatible with several extant information ordering approaches.", "labels": [], "entities": []}, {"text": "An important insight of our work is that centering can give rise to many such metrics of coherence.", "labels": [], "entities": []}, {"text": "Hence, a general methodology for identifying which of these metrics represent the most promising candidates for information ordering is required.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.894024133682251}]}, {"text": "We adopt a corpus-based approach to compare the metrics empirically and demonstrate the portability and generality of our evaluation methods by experimenting with several corpora.", "labels": [], "entities": []}, {"text": "Our main result is that the simplest metric (which relies exclusively on NOCB transitions) sets a baseline that cannot be outperformed by other metrics that make use of additional centering-related features.", "labels": [], "entities": []}, {"text": "Thus, we provide substantial insight into the role of centering as an information ordering constraint and offer researchers working on text generation a simple, yet robust, baseline to use against their own information ordering approaches during system development.", "labels": [], "entities": [{"text": "text generation", "start_pos": 135, "end_pos": 150, "type": "TASK", "confidence": 0.7320508509874344}]}, {"text": "The article is structured as follows: In Section 2 we discuss our information ordering approach in relation to other work on text generation.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.8324207067489624}, {"text": "text generation", "start_pos": 125, "end_pos": 140, "type": "TASK", "confidence": 0.7492844462394714}]}, {"text": "After a brief introduction to centering in Section 3, Section 4 demonstrates how we derived centering data structures from existing corpora.", "labels": [], "entities": []}, {"text": "Section 5 discusses how centering can be used to define various metrics of coherence suitable for information ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.7730747163295746}]}, {"text": "Then, Section 6 outlines a corpus-based methodology for choosing among these metrics.", "labels": [], "entities": []}, {"text": "Section 7 reports on the results of our experiments and Section 8 discusses their implications.", "labels": [], "entities": []}, {"text": "We conclude the paper with directions for future work and a summary of our main contributions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We made use of the data of, the GNOME corpus (), and the two corpora that experimented with.", "labels": [], "entities": [{"text": "GNOME corpus", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.9631641507148743}]}, {"text": "In this section, we discuss how the centering representations we utilize were derived from each corpus.", "labels": [], "entities": []}, {"text": "Because using naturally occurring discourse in psycholinguistic studies to investigate coherence effects is almost infeasible, computational corpus-based experiments are often the most viable alternative (.", "labels": [], "entities": []}, {"text": "Corpusbased evaluation can be usefully employed during system development and maybe later supplemented by less extended evaluation based on human judgments as suggested by.", "labels": [], "entities": []}, {"text": "The corpus-based methodology of Karamanis (2003) served as our experimental framework.", "labels": [], "entities": []}, {"text": "This methodology is based on the premise that the original sentence order (OSO,) observed in a corpus text is more coherent than any other ordering.", "labels": [], "entities": []}, {"text": "If a metric takes an alternative ordering to be more coherent than the OSO, it has to be penalized.", "labels": [], "entities": [{"text": "OSO", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.8872389197349548}]}, {"text": "Karamanis introduced a performance measure called the classification error rate which is computed according to the formula: Better(M,OSO)+Equal(M,OSO)/2.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 54, "end_pos": 79, "type": "METRIC", "confidence": 0.7102462848027548}, {"text": "Better(M,OSO)+Equal(M,OSO)/", "start_pos": 124, "end_pos": 151, "type": "METRIC", "confidence": 0.7253971248865128}]}, {"text": "Better(M,OSO) stands for the percentage of orderings that score better than the OSO according to a metric M, and Equal(M,OSO) is the percentage of orderings that score equal to the OSO.", "labels": [], "entities": [{"text": "Equal(M,OSO)", "start_pos": 113, "end_pos": 125, "type": "METRIC", "confidence": 0.9115276336669922}]}, {"text": "This measure provides an indication of how likely a metric is to lead to an ordering different from the OSO.", "labels": [], "entities": [{"text": "OSO", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.8588166832923889}]}, {"text": "When comparing several metrics with each other, the one with the lowest classification error rate is the most appropriate for ordering the sentences that the OSO consists of.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 72, "end_pos": 97, "type": "METRIC", "confidence": 0.6756653487682343}]}, {"text": "In other words, the smaller the classification error rate, the better a metric is expected to perform for information ordering.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 32, "end_pos": 57, "type": "METRIC", "confidence": 0.7995364864667257}, {"text": "information ordering", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.8243394494056702}]}, {"text": "The average classification error rate is used to summarize the performance of each metric in a corpus.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 12, "end_pos": 37, "type": "METRIC", "confidence": 0.7704448203245798}]}, {"text": "To compute the classification error rate we permute the CF lists of the OSO and classify each alternative ordering as scoring better, equal, or worse than the OSO according to M.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 15, "end_pos": 40, "type": "METRIC", "confidence": 0.7869052688280741}, {"text": "OSO", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.8676862716674805}, {"text": "OSO", "start_pos": 159, "end_pos": 162, "type": "DATASET", "confidence": 0.9186415076255798}]}, {"text": "When the number of CF lists in the OSO is fairly small, it is feasible to search through all possible orderings.", "labels": [], "entities": [{"text": "OSO", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.8758431077003479}]}, {"text": "For OSOs consisting of more than 10 CF lists, the classification error rate for the entire population of orderings can be reliably estimated using a random sample of one million permutations (Karamanis 2003, Chapter 5).", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 50, "end_pos": 75, "type": "METRIC", "confidence": 0.807129442691803}]}, {"text": "shows the average performance of each metric in the corpora employed in our experiments.", "labels": [], "entities": []}, {"text": "The smallest-that is, best-score in each corpus is printed in boldface.", "labels": [], "entities": []}, {"text": "The table indicates that the baseline M.NOCB performs best in three out of four corpora.", "labels": [], "entities": [{"text": "M.NOCB", "start_pos": 38, "end_pos": 44, "type": "TASK", "confidence": 0.5649134516716003}]}, {"text": "There has been significant recent work on the corpus-based evaluation for information ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.8162902891635895}]}, {"text": "In this section, we discuss the methodological differences between our work and the studies which are most closely related to it. introduce a stochastic model for information ordering which computes the probability of generating the OSO and every alternative ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 163, "end_pos": 183, "type": "TASK", "confidence": 0.7456090152263641}]}, {"text": "Then, all orderings are ranked according to this probability and the rank given to the OSO is retrieved.", "labels": [], "entities": [{"text": "OSO", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.806922972202301}]}, {"text": "Several evaluation measures are discussed, the most important of which is the average OSO rank, that is, the average rank of the OSOs in their corpora.", "labels": [], "entities": []}, {"text": "This measure does not take into account that the OSOs differ in length.", "labels": [], "entities": []}, {"text": "However, this information is necessary to estimate reliably the performance of an information ordering approach, as we discuss in in more detail.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.7495160400867462}]}, {"text": "overcome this difficulty by introducing a performance measure called ranking accuracy which expresses the percentage of alternative orderings that are ranked lower than the OSO.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9298207759857178}, {"text": "OSO", "start_pos": 173, "end_pos": 176, "type": "DATASET", "confidence": 0.8464419841766357}]}, {"text": "In terms, ranking accuracy equals 100% \u2212 Better(M, OSO), assuming that no equally ranking orderings exist.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9834910035133362}]}, {"text": "Barzilay and compare the OSO with just 20 alternative orderings, often sampled out of several millions.", "labels": [], "entities": [{"text": "OSO", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.82399582862854}]}, {"text": "On the other hand, enumerate exhaustively each possible ordering, which might become impractical as the search space grows factorially.", "labels": [], "entities": []}, {"text": "We overcame these problems by using a large random sample for the texts which consist of more than 10 sentences as suggested in.", "labels": [], "entities": []}, {"text": "Equally important is the emphasis we placed on the use of statistical tests, which were not deployed by either Barzilay and Lee or Barzilay and Lapata.", "labels": [], "entities": []}, {"text": "Lapata presented a methodology for automatically evaluating generated orderings on the basis of their distance from observed sentence orderings in a corpus.", "labels": [], "entities": []}, {"text": "A measure of rank correlation (called Kendall's \u03c4), which was subsequently shown to correlate reliably with human ratings and reading times), was used to estimate the distance between orderings.", "labels": [], "entities": [{"text": "rank correlation", "start_pos": 13, "end_pos": 29, "type": "METRIC", "confidence": 0.7218613028526306}, {"text": "Kendall's \u03c4)", "start_pos": 38, "end_pos": 50, "type": "METRIC", "confidence": 0.7241455018520355}]}, {"text": "Whereas \u03c4 estimates how close the predictions of a metric are to several original orderings, we measure how likely a metric is to lead to an ordering different than the OSO.", "labels": [], "entities": [{"text": "OSO", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.9022361040115356}]}, {"text": "Taking into account more than one OSO for information ordering is the main strength of Lapata's method, but to do this one needs to ask several humans to order the same set of sentences ().", "labels": [], "entities": [{"text": "information ordering", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7852792143821716}]}, {"text": "conducted an experiment in the MPIRO domain using Lapata's methodology which supplements the work reported in this article.", "labels": [], "entities": [{"text": "MPIRO domain", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9653453230857849}]}, {"text": "However, such an approach is less practical for much larger collections of texts such as NEWS and ACCS.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.9356333613395691}, {"text": "ACCS", "start_pos": 98, "end_pos": 102, "type": "DATASET", "confidence": 0.49058276414871216}]}, {"text": "This is presumably the reason why use ranking accuracy instead of \u03c4 in their evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.8069028258323669}]}, {"text": "Our work investigates how the coherence score of the OSO compares to the scores of alternative orderings of the sentences that the OSO consists of.", "labels": [], "entities": []}, {"text": "As noticed, this question is crucial from an information ordering viewpoint, but was not taken into account by any previous corpus-based study of centering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7123769372701645}]}, {"text": "also suggested that Rule 2 should be tested by examining \"alternative multi-utterance sequences that differentially realize the same content.\"", "labels": [], "entities": []}, {"text": "We are the first to have pursued this research objective in the evaluation of centering for information ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7653826475143433}]}, {"text": "observed that there remained a large number of NOCBs under every instantiation of centering they tested and concluded that centering is inadequate as a coherence model.", "labels": [], "entities": []}, {"text": "However, the frequency of NOCBs does not necessarily provide adequate indication of how appropriate NOCBs (and centering in general) are for information ordering.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 141, "end_pos": 161, "type": "TASK", "confidence": 0.8613113760948181}]}, {"text": "Although over 50% of the transitions in GNOME-LAB are NOCBs, the average classification error rate of approximately 20% for M.NOCB suggests that the OSO tends to be in greater agreement with the preference to avoid NOCBs than 80% of the alternative orderings.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 73, "end_pos": 98, "type": "METRIC", "confidence": 0.7682143847147623}, {"text": "OSO", "start_pos": 149, "end_pos": 152, "type": "DATASET", "confidence": 0.7466917634010315}]}, {"text": "Thus, it appears that the observed ordering in the corpus does optimize with respect to the number of potential NOCBs to a great extent.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 7  Average classification error rate for the centering-based metrics in each corpus.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 18, "end_pos": 43, "type": "METRIC", "confidence": 0.7755970656871796}]}, {"text": " Table 8  Comparing M.NOCB with M.CHEAP, M.KP, and M.BFP in each corpus.", "labels": [], "entities": []}]}