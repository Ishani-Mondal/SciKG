{"title": [{"text": "Exploiting Semantic Role Resources for Preposition Disambiguation", "labels": [], "entities": [{"text": "Preposition Disambiguation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8941389322280884}]}], "abstractContent": [{"text": "This article describes how semantic role resources can be exploited for preposition disambigua-tion.", "labels": [], "entities": []}, {"text": "The main resources include the semantic role annotations provided by the Penn Treebank and FrameNet tagged corpora.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 73, "end_pos": 86, "type": "DATASET", "confidence": 0.9939276874065399}, {"text": "FrameNet tagged corpora", "start_pos": 91, "end_pos": 114, "type": "DATASET", "confidence": 0.7374468843142191}]}, {"text": "The resources also include the assertions contained in the Fac-totum knowledge base, as well as information from Cyc and Conceptual Graphs.", "labels": [], "entities": [{"text": "Fac-totum knowledge base", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.9424418409665426}]}, {"text": "A common inventory is derived from these in support of definition analysis, which is the motivation for this work.", "labels": [], "entities": [{"text": "definition analysis", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.9871458411216736}]}, {"text": "The disambiguation concentrates on relations indicated by prepositional phrases, and is framed as word-sense disambiguation for the preposition in question.", "labels": [], "entities": []}, {"text": "A new type of feature for word-sense disambiguation is introduced, using WordNet hypernyms as collocations rather than just words.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7250668257474899}]}, {"text": "Various experiments over the Penn Treebank and FrameNet data are presented, including prepositions classified separately versus together, and illustrating the effects of filtering.", "labels": [], "entities": [{"text": "Penn Treebank and FrameNet data", "start_pos": 29, "end_pos": 60, "type": "DATASET", "confidence": 0.8389613509178162}]}, {"text": "Similar experimentation is done over the Factotum data, including a method for inferring likely preposition usage from corpora, as knowledge bases do not generally indicate how relationships are expressed in English (in contrast to the explicit annotations on this in the Penn Treebank and FrameNet).", "labels": [], "entities": [{"text": "Factotum data", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9668512344360352}, {"text": "Penn Treebank", "start_pos": 272, "end_pos": 285, "type": "DATASET", "confidence": 0.9916897118091583}]}, {"text": "Other experiments are included with the FrameNet data mapped into the common relation inventory developed for definition analysis, illustrating how preposition disambiguation might be applied in lexical acquisition.", "labels": [], "entities": [{"text": "FrameNet data mapped", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.9123495221138}, {"text": "definition analysis", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.9689815938472748}]}], "introductionContent": [{"text": "English prepositions convey important relations in text.", "labels": [], "entities": []}, {"text": "When used as verbal adjuncts, they are the principal means of conveying semantic roles for the supporting entities described by the predicate.", "labels": [], "entities": []}, {"text": "Preposition disambiguation is a challenging problem.", "labels": [], "entities": [{"text": "Preposition disambiguation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9017856419086456}]}, {"text": "First, prepositions are highly polysemous.", "labels": [], "entities": []}, {"text": "A typical collegiate dictionary has dozens of senses for each of the common prepositions.", "labels": [], "entities": []}, {"text": "Second, the senses of prepositions tend to be closely related to one another.", "labels": [], "entities": []}, {"text": "For instance, there are three duplicate role assignments among the twenty senses for of in The Preposition Project), a resource containing semantic annotations for common prepositions.", "labels": [], "entities": []}, {"text": "Consider the disambiguation of the usages of on in the following sentences: (1) The cut should be blocked on procedural grounds.", "labels": [], "entities": []}, {"text": "(2) The industry already operates on very thin margins.", "labels": [], "entities": []}, {"text": "The choice between the purpose and manner meanings for on in these sentences is difficult.", "labels": [], "entities": []}, {"text": "The purpose meaning seems preferred for sentence 1, as grounds is a type of justification.", "labels": [], "entities": []}, {"text": "For sentence 2, the choice is even less clear, though the manner meaning seems preferred.", "labels": [], "entities": []}, {"text": "This article presents anew method for disambiguating prepositions using information learned from annotated corpora as well as knowledge stored in declarative lexical resources.", "labels": [], "entities": [{"text": "disambiguating prepositions", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.8849601745605469}]}, {"text": "The approach allows for better coverage and finer distinctions than in previous work in preposition disambiguation.", "labels": [], "entities": [{"text": "coverage", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9573969841003418}, {"text": "preposition disambiguation", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.8299661874771118}]}, {"text": "For instance, a traditional approach would involve manually developing rules for on that specify the semantic type of objects associated with the different senses (e.g., time for temporal).", "labels": [], "entities": []}, {"text": "Instead, we infer this based on lexical associations learned from annotated corpora.", "labels": [], "entities": []}, {"text": "The motivation for preposition disambiguation is to support a system for lexical acquisition.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.804219126701355}, {"text": "lexical acquisition", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7319947183132172}]}, {"text": "The focus of the system is to acquire distinguishing information for the concepts serving to define words.", "labels": [], "entities": []}, {"text": "Large-scale semantic lexicons mainly emphasize the taxonomic relations among the underlying concepts (e.g., is-a and partof ), and often lack sufficient differentiation among similar concepts (e.g., via attributes or functional relations such as is-used-for).", "labels": [], "entities": []}, {"text": "For example, in WordNet (), the standard lexical resource for natural language processing, the only relations for beagle and Afghan are that they are both a type of hound.", "labels": [], "entities": []}, {"text": "Although the size difference can be inferred from the definitions, it is not represented in the WordNet semantic network.", "labels": [], "entities": [{"text": "WordNet semantic network", "start_pos": 96, "end_pos": 120, "type": "DATASET", "confidence": 0.9421850045522054}]}, {"text": "In WordNet, words are grouped into synonym sets called synsets, which represent the underlying concepts and serve as nodes in a semantic network.", "labels": [], "entities": []}, {"text": "Synsets are ordered into a hierarchy using the hypernym relation (i.e., is-a).", "labels": [], "entities": []}, {"text": "There are several other semantic relations, such as part-whole, is-similar-to, and domain-of . Nonetheless, in version 2.1 of WordNet, about 30% of the synsets for noun entries are not explicitly distinguished from sibling synsets via semantic relations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 126, "end_pos": 133, "type": "DATASET", "confidence": 0.9496448636054993}]}, {"text": "To address such coverage problems in lexicons, we have developed an empirical approach to lexical acquisition, building upon earlier knowledge-based approaches in dictionary definition analysis.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7328863739967346}, {"text": "dictionary definition analysis", "start_pos": 163, "end_pos": 193, "type": "TASK", "confidence": 0.8470173279444376}]}, {"text": "This involves a two-step process: Definitions are first analyzed with a broad-coverage parser, and then the resulting syntactic relationships are disambiguated using statistical classification.", "labels": [], "entities": []}, {"text": "A crucial part of this process is the disambiguation of prepositions, exploiting online resources with semantic role usage information.", "labels": [], "entities": []}, {"text": "The main resources are the Penn Treebank (PTB; and FrameNet (Fillmore, Wooters, and Baker 2001), two popular corpora providing rich annotations on English text, such as the semantic roles associated with prepositional phrases in context.", "labels": [], "entities": [{"text": "Penn Treebank (PTB", "start_pos": 27, "end_pos": 45, "type": "DATASET", "confidence": 0.9169062227010727}]}, {"text": "In addition to the semantic role annotations from PTB and FrameNet, traditional knowledge bases (KBs) are utilized to provide training data for the relation classification.", "labels": [], "entities": [{"text": "PTB", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.933376669883728}, {"text": "relation classification", "start_pos": 148, "end_pos": 171, "type": "TASK", "confidence": 0.8208445906639099}]}, {"text": "In particular, the Factotum KB is used to provide additional training data for prepositions that are used to convey particular relationships.", "labels": [], "entities": [{"text": "Factotum KB", "start_pos": 19, "end_pos": 30, "type": "DATASET", "confidence": 0.7514689266681671}]}, {"text": "Information on preposition usage is not explicitly encoded in Factotum, so anew corpus analysis technique is employed to infer the associations.", "labels": [], "entities": [{"text": "Factotum", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.8612678050994873}]}, {"text": "Details on the lexical acquisition process, including application and evaluation, can be found in O'.", "labels": [], "entities": [{"text": "lexical acquisition process", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7723110119501749}, {"text": "O'.", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.9102944533030192}]}, {"text": "This article focuses on the aspects of this method relevant to the processing of prepositions.", "labels": [], "entities": []}, {"text": "In particular, here we specifically address preposition disambiguation using semantic role annotations from PTB, FrameNet, and Factotum.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.8561679422855377}, {"text": "PTB", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.950333833694458}]}, {"text": "In each case, classification experiments are presented using the respective resources as training data with evaluation via 10-fold cross validation.", "labels": [], "entities": []}, {"text": "This article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents background information on the relation inventories used during classification, including one developed specifically for definition analysis.", "labels": [], "entities": [{"text": "classification", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.9622143507003784}, {"text": "definition analysis", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.9785014986991882}]}, {"text": "Section 3 discusses the relation classifiers in depth with results given for four different inventories.", "labels": [], "entities": []}, {"text": "Section 4 discusses related work in relation disambiguation, and Section 5 presents our conclusions.", "labels": [], "entities": [{"text": "relation disambiguation", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.8345431387424469}]}], "datasetContent": [{"text": "A supervised approach for word-sense disambiguation is used following.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7443742752075195}]}, {"text": "For each experiment, stratified 10-fold cross validation is used: The classifiers are repeatedly trained on 90% of the data and tested on the remainder, with the test sets randomly selected to form a partition.", "labels": [], "entities": []}, {"text": "The results described here were obtained using the settings in, which are similar to the settings used by O' in the third Senseval competition.", "labels": [], "entities": [{"text": "O' in the third Senseval competition", "start_pos": 106, "end_pos": 142, "type": "DATASET", "confidence": 0.8652266689709255}]}, {"text": "The top systems from recent Senseval competitions) use a variety of lexical features for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.8404293656349182}]}, {"text": "Words in the immediate context (Word\u00b1i) and their parts of speech (POS\u00b1i) are standard features.", "labels": [], "entities": []}, {"text": "Word collocations are also common, but there are various ways of organizing collocations into features.", "labels": [], "entities": []}, {"text": "We use the simple approach of having a single binary feature per sense (e.g., role) that is set true whenever any of the associated collocation words for that sense are encountered (i.e., per-class-binary).", "labels": [], "entities": []}, {"text": "The main difference of our approach from more typical WSD systems) concerns the hypernym collocations.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.8939068913459778}]}, {"text": "The collocation context section of shows that word collocations can occur anywhere in the sentence, whereas hypernym collocations must occur within five words of the target  The first set of experiments deals with preposition disambiguation using PTB.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 214, "end_pos": 240, "type": "TASK", "confidence": 0.7727200090885162}]}, {"text": "When deriving training data from PTB via the parse tree annotations, the functional tags associated with prepositional phrases are converted into preposition sense tags.", "labels": [], "entities": []}, {"text": "Consider the following excerpt from the sample annotation for PTB shown earlier: Treating temporal as the preposition sense yields the following annotation: In TMP 1982, Sports & Recreation's managers ...", "labels": [], "entities": [{"text": "PTB", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.7458599805831909}, {"text": "TMP 1982, Sports & Recreation's managers", "start_pos": 160, "end_pos": 200, "type": "DATASET", "confidence": 0.7916606888175011}]}, {"text": "The relative frequencies of the roles in the PTB annotations for PPs are shown in Table 9.", "labels": [], "entities": []}, {"text": "As can be seen, several of the roles do not occur often with PPs (e.g., extent).", "labels": [], "entities": [{"text": "extent", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9795452356338501}]}, {"text": "This somewhat skewed distribution makes for an easier classification task than the one for FrameNet.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 91, "end_pos": 99, "type": "DATASET", "confidence": 0.885680079460144}]}, {"text": "3.2.1 Illustration with \"at.\"", "labels": [], "entities": []}, {"text": "As an illustration of the probabilities associated with classbased collocations, consider the differences in the prior versus class-based conditional probabilities for the semantic roles of the preposition at in the Penn Treebank (version II).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 216, "end_pos": 229, "type": "DATASET", "confidence": 0.992446631193161}]}, {"text": "shows the global probabilities for the roles assigned to at, along with conditional probabilities for these roles given that certain high-level WordNet synsets occur in the context.", "labels": [], "entities": []}, {"text": "Ina context referring to a concrete concept (i.e., entity#1), the difference in the probability distributions for the locative and temporal roles shows that the locative interpretation becomes even more likely.", "labels": [], "entities": []}, {"text": "In contrast, in a context referring to an abstract concept (i.e., abstraction#6), the difference in the probability distributions for the same roles shows that the temporal interpretation becomes more likely.", "labels": [], "entities": []}, {"text": "Therefore, these class-based lexical associations capture commonsense usages of the preposition at.", "labels": [], "entities": []}, {"text": "The second set of experiments perform preposition disambiguation using FrameNet.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.8520042300224304}, {"text": "FrameNet", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9490889310836792}]}, {"text": "A similar preposition word-sense disambiguation experiment is carried out over the FrameNet semantic role annotations involving prepositional phrases.", "labels": [], "entities": [{"text": "preposition word-sense disambiguation", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.6340254743893942}, {"text": "FrameNet semantic role annotations", "start_pos": 83, "end_pos": 117, "type": "DATASET", "confidence": 0.8478552103042603}]}, {"text": "Consider the sample annotation shown earlier: (8) Hewlett-Packard Co has rolled out anew range of ISDN connectivity enabling \ud97b\udf59C FE=\"Communicator\" PT=\"NP\"\ud97b\udf59standalone workstations\ud97b\udf59/C\ud97b\udf59 to \ud97b\udf59C TARGET=\"y\"\ud97b\udf59communicate\ud97b\udf59/C\ud97b\udf59 \ud97b\udf59C FE=\"Medium\" PT=\"PP\"\ud97b\udf59over public or private ISDN networks\ud97b\udf59/C\ud97b\udf59.", "labels": [], "entities": [{"text": "FE", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.8299106359481812}, {"text": "FE", "start_pos": 218, "end_pos": 220, "type": "METRIC", "confidence": 0.9313412308692932}]}, {"text": "The prepositional phrase annotation is isolated and treated as the sense of the preposition.", "labels": [], "entities": []}, {"text": "This yields the following sense annotation: (9) Hewlett-Packard Co has rolled out anew range of ISDN connectivity enabling standalone workstations to communicate over Medium public or private ISDN networks.", "labels": [], "entities": []}, {"text": "shows the distribution of common roles assigned to prepositional phrases.", "labels": [], "entities": []}, {"text": "The topic role is the most frequent case not directly covered in PTB.", "labels": [], "entities": [{"text": "PTB", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.6109164357185364}]}, {"text": "for the most frequent roles out of the 124 cases that were assigned to at, along with the conditional probabilities for these roles given that certain high-level WordNet synsets occur in the context.", "labels": [], "entities": []}, {"text": "Ina context referring to concrete entities, the role place becomes more prominent.", "labels": [], "entities": []}, {"text": "However, in an abstract context, the role time becomes more prominent.", "labels": [], "entities": []}, {"text": "Thus, similar behavior to that noted for PTB in Section 3.2.1 occurs with FrameNet.", "labels": [], "entities": [{"text": "PTB", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.863313615322113}, {"text": "FrameNet", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.9229193925857544}]}, {"text": "shows the results of classification when all of the prepositions are classified together.", "labels": [], "entities": []}, {"text": "Due to the exorbitant number of roles (641), the overall results are low.", "labels": [], "entities": []}, {"text": "However, the combined collocation approach still shows slight improvement (23.3% versus 23.1%).", "labels": [], "entities": []}, {"text": "The FrameNet inventory contains many low-frequency relations  Prior and posterior probabilities of roles for \"at\" in FrameNet.", "labels": [], "entities": [{"text": "FrameNet inventory", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8467909097671509}, {"text": "FrameNet", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.8903905749320984}]}, {"text": "Only the top 5 of 641 applicable roles are shown.", "labels": [], "entities": []}, {"text": "P(R) is the relative frequency for relation.", "labels": [], "entities": [{"text": "P(R)", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9331542402505875}]}, {"text": "P(R|S) is the probability of the relation given that the synset occurs in the immediate context of at.", "labels": [], "entities": []}, {"text": "RPC R,S is the relative percentage change: (P(R|S) \u2212 P(R))/P(R).  that complicate this type of classification.", "labels": [], "entities": [{"text": "RPC R,S", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9168742597103119}]}, {"text": "By filtering out relations that occur in less than 1% of the role occurrences for prepositional phrases, substantial improvement results, as shown in.", "labels": [], "entities": []}, {"text": "Even with filtering, the classification is challenging (e.g., 18 classes with entropy 3.82).", "labels": [], "entities": []}, {"text": "also shows the per-class statistics, indicating that the means and place roles are posing difficulties for classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 107, "end_pos": 121, "type": "TASK", "confidence": 0.964567244052887}]}, {"text": "shows the results when using individual classifiers, ordered by entropy.", "labels": [], "entities": []}, {"text": "This illustrates that the role distributions are more complicated than those for PTB, yielding higher entropy values on average.", "labels": [], "entities": [{"text": "PTB", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.7798510193824768}]}, {"text": "In all, there are over 360 prepositions with annotations, 92 with tenor more instances each.", "labels": [], "entities": []}, {"text": "(Several of the low-frequency cases are actually adverbs, such as anywhere, but are treated as prepositions during the annotation extraction.)", "labels": [], "entities": []}, {"text": "The results show that the word collocations produce slightly better results: 67.8 versus 66.0 for combined collocations.", "labels": [], "entities": []}, {"text": "Unlike the case with PTB, the single-classifier performance is below that of the individual classifiers.", "labels": [], "entities": [{"text": "PTB", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.8391374349594116}]}, {"text": "This is due to the fine-grained nature of the role inventory.", "labels": [], "entities": []}, {"text": "When all the roles are considered together, prepositions are sometimes being incorrectly classified using roles that have not been assigned to them in the training data.", "labels": [], "entities": []}, {"text": "This occurs when contextual clues are stronger fora commonly used role than for the appropriate one.", "labels": [], "entities": []}, {"text": "Given PTB's small role inventory, this problem does not occur in the corresponding experiments.", "labels": [], "entities": [{"text": "PTB", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.7239832282066345}]}, {"text": "The third set of experiments deals with preposition disambiguation using Factotum.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.8473867774009705}, {"text": "Factotum", "start_pos": 73, "end_pos": 81, "type": "DATASET", "confidence": 0.7908211350440979}]}, {"text": "Note that Factotum does not indicate the way the relationships are expressed in English.", "labels": [], "entities": [{"text": "Factotum", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8814032077789307}]}, {"text": "Similarly, WordNet does not indicate this, but it does include definition glosses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.9782233834266663}]}, {"text": "For example, Factotum: \ud97b\udf59drying, is-function-of , drier\ud97b\udf59 WordNet: dry alter remove the moisture from and make dry dryer appliance an appliance that removes moisture These definition glosses might be useful in certain cases for inferring the relation markers (i.e., generalized case markers).", "labels": [], "entities": [{"text": "\ud97b\udf59", "start_pos": 54, "end_pos": 55, "type": "DATASET", "confidence": 0.971947968006134}, {"text": "WordNet", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.6101709604263306}]}, {"text": "As is, Factotum cannot be used to provide training data for learning how the relations are expressed in English.", "labels": [], "entities": [{"text": "Factotum", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.5644466876983643}]}, {"text": "This contrasts with corpusbased annotations, such as PTB ( and FrameNet, where the relationships are marked in context.", "labels": [], "entities": [{"text": "PTB", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.9230493903160095}]}, {"text": "The last set of experiments investigate preposition disambiguation using FrameNet mapped into a reduced semantic role inventory.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.8271907269954681}]}, {"text": "For the application to lexical acquisition, the semantic role annotations are converted into the common relation inventory discussed in Section 2.5.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7717273831367493}]}, {"text": "To apply the common inventory to the FrameNet data, annotations using the 641 FrameNet relations (see) need to be mapped into those  Accuracy.", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.9204578697681427}, {"text": "Accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9220126867294312}]}, {"text": "Results for the classification of the FrameNet data mapped into the common inventory are shown in.", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.8528996407985687}]}, {"text": "As can be seen, the performance is well above that of the full classification over FrameNet without filtering (see).", "labels": [], "entities": []}, {"text": "Although the low-frequency role filtering yields the highest performance (see), this comes at the expense of having half of the training instances discarded.", "labels": [], "entities": [{"text": "role filtering", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.8486528992652893}]}, {"text": "Corpus annotations area costly resource, so such waste is undesirable.", "labels": [], "entities": []}, {"text": "also shows the per-class statistics, indicating that the means, direction, and part roles are handled poorly by the classifier.", "labels": [], "entities": []}, {"text": "The latter two are due to the relatively small training examples for the roles in question, which can be addressed partly by refining the mapping from FrameNet.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 151, "end_pos": 159, "type": "DATASET", "confidence": 0.9011009931564331}]}, {"text": "However, problems classifying the means role occur with all classifiers discussed in this article, suggesting that that role is too subtle to be classified with the feature set currently used.", "labels": [], "entities": []}, {"text": "The results in also illustrate that the reduced, common-role inventory has an additional advantage of improving performance in the classification, compared to a cascaded approach.", "labels": [], "entities": []}, {"text": "This occurs because several of the miscellaneous roles in FrameNet cover subtle distinctions that are not relevant for definition analysis (e.g., cognizer and addressee).", "labels": [], "entities": [{"text": "definition analysis", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.8890551626682281}]}, {"text": "The common inventory therefore strikes a balance between the overly general roles in PTB, which are easy to classify, and the overly specialized roles in FrameNet, which are quite difficult to classify.", "labels": [], "entities": [{"text": "PTB", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.9106401801109314}, {"text": "FrameNet", "start_pos": 154, "end_pos": 162, "type": "DATASET", "confidence": 0.8698054552078247}]}, {"text": "Nonetheless, a certain degree of classification difficulty is inevitable in order for the inventory to provide adequate coverage of the different distinctions present in dictionary definitions.", "labels": [], "entities": []}, {"text": "Note that, by using the annotations from PTB and FrameNet, the end result is a general-purpose classifier, not one tied into dictionary text.", "labels": [], "entities": [{"text": "PTB", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.9783697724342346}, {"text": "FrameNet", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8648881316184998}]}, {"text": "Thus, it is useful for other tasks besides definition analysis.", "labels": [], "entities": [{"text": "definition analysis", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.9859840273857117}]}, {"text": "This classifier was used to disambiguate prepositions in the lexical acquisition system we developed at NMSU (O'Hara 2005).", "labels": [], "entities": [{"text": "NMSU (O'Hara 2005)", "start_pos": 104, "end_pos": 122, "type": "DATASET", "confidence": 0.8539295554161072}]}, {"text": "Evaluation of the resulting distinctions was performed by having the output of the system rated by human judges.", "labels": [], "entities": []}, {"text": "Manually corrected results were also evaluated by the same judges.", "labels": [], "entities": []}, {"text": "The overall ratings are not high in both cases, suggesting that some of the distinctions being made are subtle.", "labels": [], "entities": []}, {"text": "For instance, for \"counterintelligence achieved by deleting any information of value\" from the definition of censoring, means is the preferred role for by, but manner is acceptable.", "labels": [], "entities": []}, {"text": "Likewise, characteristic is the preferred role for of, but category is interpretable.", "labels": [], "entities": []}, {"text": "Thus, the judges differed considerably on these cases.", "labels": [], "entities": []}, {"text": "However, as the ratings for the uncorrected output were close to those for the corrected output, the approach is promising to use for lexical acquisition.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.8100216686725616}]}, {"text": "If desired, the per-role accuracy results shown in could be incorporated as confidence values assigned to particular relationships extracted from definitions (e.g., 81% for those with source but only 21% when means used).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9157122373580933}]}], "tableCaptions": [{"text": " Table 10  Prior and posterior probabilities of roles for \"at\" in the Penn Treebank. P(R) is the relative frequency.  P(R|S) is the probability of the relation given that the synset occurs in the immediate context of  at. RPC R,S is the relative percentage change: (P(R|S) \u2212 P(R))/P(R).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.9961355924606323}]}, {"text": " Table 11  Overall preposition disambiguation results over Penn Treebank roles. A single classifier is used for all  the prepositions. # Instances is the number of role annotations. # Classes is the number of distinct  roles. Entropy measures non-uniformity of the role distributions. Baseline is estimated by the  most-frequent role. The Word Only experiment uses just word collocations, Hypernym Only just  uses hypernym collocations, and Both uses both types of collocations. Accuracy is average for  percent correct over ten trials in cross validation. STDEV is the standard deviation over the trials.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.724801629781723}, {"text": "Penn Treebank", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9824607968330383}, {"text": "Baseline", "start_pos": 285, "end_pos": 293, "type": "METRIC", "confidence": 0.9602487087249756}, {"text": "Accuracy", "start_pos": 479, "end_pos": 487, "type": "METRIC", "confidence": 0.9991937279701233}, {"text": "STDEV", "start_pos": 557, "end_pos": 562, "type": "METRIC", "confidence": 0.9897823333740234}]}, {"text": " Table 12  Per-preposition disambiguation results over Penn Treebank roles. A separate classifier is used for each  preposition, excluding roles with less than 1% relative frequency. Freq gives the preposition  frequency, and Roles the number of senses. Entropy measures data set uniformity, and Baseline  selects most common role. The Word and Hypernym columns show results when including just  word and hypernym collocations respectively, whereas Both includes both types. Each column  shows averages for percent correct over ten trials. The Mean row averages the values of the  individual experiments.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.9831198751926422}, {"text": "Freq", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.9507913589477539}, {"text": "Mean row", "start_pos": 544, "end_pos": 552, "type": "METRIC", "confidence": 0.9636744856834412}]}, {"text": " Table 13  Most common FrameNet semantic roles for PPs. Relative frequencies for roles assigned to  prepositional phrases in version 1.3 (66,038 instances), omitting cases below 0.01.", "labels": [], "entities": []}, {"text": " Table 15  Preposition disambiguation with all FrameNet roles. All 641 roles are considered. Entropy measures  data set uniformity, and Baseline selects most common role.", "labels": [], "entities": []}, {"text": " Table 16. Even with filtering, the classification is challenging (e.g., 18 classes  with entropy 3.82).", "labels": [], "entities": []}, {"text": " Table 16  Overall results for preposition disambiguation with common FrameNet roles. Excludes roles with less  than 1% relative frequency. Entropy measures data set uniformity, and Baseline selects most  common role. Detailed per-class statistics are also included, averaged over the 10 folds.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.8447097539901733}]}, {"text": " Table 17  Per-preposition disambiguation results over FrameNet roles. A separate classifier is used for each  preposition, excluding roles with less than 1% relative frequency. Freq gives the preposition  frequency, and Roles the number of senses. Entropy measures data set uniformity, and Baseline  selects most common role. The Word and Hypernym columns show results when including just  word and hypernym collocations, respectively, whereas Both includes both types. Each column  shows averages for percent correct over ten trials. The Mean row averages the values of the  individual experiments.", "labels": [], "entities": [{"text": "Freq", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.8132762908935547}, {"text": "Mean row", "start_pos": 540, "end_pos": 548, "type": "METRIC", "confidence": 0.9620755016803741}]}, {"text": " Table 8. Results for the classification of the  FrameNet data mapped into the common inventory are shown in", "labels": [], "entities": [{"text": "FrameNet data mapped", "start_pos": 49, "end_pos": 69, "type": "DATASET", "confidence": 0.8810331026713053}]}, {"text": " Table 19. As can  be seen, the performance is well above that of the full classification over FrameNet  without filtering (see", "labels": [], "entities": []}, {"text": " Table 19  Results for preposition disambiguation with common roles. The FrameNet annotations are mapped  into the common inventory from Table 8. Entropy measures data set uniformity, and Baseline  selects most common role. Detailed per-class statistics are also included, averaged over the  10 folds.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.8181330859661102}]}]}