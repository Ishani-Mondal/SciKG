{"title": [{"text": "Combining Generative and Discriminative Model Scores for Distant Supervision", "labels": [], "entities": [{"text": "Distant Supervision", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.9230688214302063}]}], "abstractContent": [{"text": "Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8581542074680328}]}, {"text": "In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data.", "labels": [], "entities": []}, {"text": "The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting.", "labels": [], "entities": []}, {"text": "A simple linear interpolation of the model scores performs better than a parameter-free scheme based on non-dominated sorting.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relation extraction is the task of finding relational facts in unstructured text and putting them into a structured (tabularized) knowledge base.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9547209143638611}]}, {"text": "Training machine learning algorithms for relation extraction requires training data.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.9012873470783234}]}, {"text": "If the set of relations is prespecified, the training data needs to be labeled with those relations.", "labels": [], "entities": []}, {"text": "Manual annotation of training data is laborious and costly, however, the knowledge base may already partially be filled with instances from the relations.", "labels": [], "entities": []}, {"text": "This is utilized by a scheme known as distant supervision (DS) (: text is automatically labeled by aligning (matching) pairs of entities that are contained in a knowledge base with their textual occurrences.", "labels": [], "entities": [{"text": "distant supervision (DS)", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.7045564174652099}]}, {"text": "Whenever such a match is encountered, the surrounding context (sentence) is assumed to express the relation. is contained in the knowledge base, one matching context could be: Michael Jackson was born in Gary ...", "labels": [], "entities": []}], "datasetContent": [{"text": "The maximum-likelihood estimator (MLE) baseline scores patterns by the relative frequency they occur with a certain relation.", "labels": [], "entities": []}, {"text": "The hierarchical topic (hier orig) as described in increases the scores undermost metrics, however the increase is only significant for p@5 and p@10.", "labels": [], "entities": []}, {"text": "The feature-based extension of the topic model (hier feat) has significantly better ranking quality.", "labels": [], "entities": []}, {"text": "Slightly better scores are obtained by the at-leastone perceptron learner.", "labels": [], "entities": []}, {"text": "It is interesting to see that the model combinations both by non-dominated sorting perc+hier (pareto) as well as uniform interpolation perc+hier (itpl) give a further increase in ranking: Ranking quality of extracted facts.", "labels": [], "entities": []}, {"text": "Significance (paired t-test, p < 0.05) w.r.t.", "labels": [], "entities": []}, {"text": "MLE(*) and hier orig( \u2020). quality.", "labels": [], "entities": [{"text": "MLE", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8587543368339539}, {"text": "quality", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9873036742210388}]}, {"text": "The simpler interpolation scheme generally works best.", "labels": [], "entities": []}, {"text": "shows the Precision/Recall curves of the basic models and the linear interpolation.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9935936331748962}, {"text": "Recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.696941077709198}]}, {"text": "On the P/R curve, the linear interpolation is equal or better than the single methods on all recall levels.", "labels": [], "entities": [{"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9843732118606567}]}, {"text": "We evaluate the extraction quality of the induced perc+hier (itpl) patterns in an end-to-end setting.", "labels": [], "entities": []}, {"text": "We use the evaluation setting of () and the results obtained with their pipeline for MIMLRE and their re-implementation of MultiR as a point of reference.", "labels": [], "entities": [{"text": "MIMLRE", "start_pos": 85, "end_pos": 91, "type": "DATASET", "confidence": 0.7687619924545288}]}, {"text": "In evaluation is done using a subset of queries from the TAC KBP 2010 and 2011 evaluation.", "labels": [], "entities": [{"text": "TAC KBP 2010 and 2011 evaluation", "start_pos": 57, "end_pos": 89, "type": "DATASET", "confidence": 0.9375859598318735}]}, {"text": "The source corpus is the TAC KBP source corpus and a 2010 Wikipedia dump.", "labels": [], "entities": [{"text": "TAC KBP source corpus and a 2010 Wikipedia dump", "start_pos": 25, "end_pos": 72, "type": "DATASET", "confidence": 0.7562312119536929}]}, {"text": "Only those answers are considered in scoring that are contained in a list of possible answers from their candidates (reducing the number of gold answers from 1601 to 576 and thereby considerably increasing the value of reported recall).", "labels": [], "entities": [{"text": "recall", "start_pos": 228, "end_pos": 234, "type": "METRIC", "confidence": 0.9446706175804138}]}, {"text": "For evaluating our patterns, we take the same queries for testing as shows top-ranked patterns for per:title and org:top members employees, the two relations with most answers in the gold annotations.", "labels": [], "entities": []}, {"text": "For maximum likelihood estimation the score is 1.0 if the patterns occurs only with the relation in question -this includes all cases where the pattern is only found once in the corpus.", "labels": [], "entities": []}, {"text": "While this could be circumvented by frequency thresholding, we leave the long tail of the data as it is and let the algorithm deal with both frequent and infrequent patterns.", "labels": [], "entities": []}, {"text": "One can see that while the maximum likelihood patterns contain some reasonable relational contexts, they are less prototypical and more prone to distant supervision errors.", "labels": [], "entities": []}, {"text": "The patterns scored high by the proposed combination generalize better, variation at the top is achieved by re-combining elements that carry relational meaning (\"is an\", \"vice president\", \"president director\") or are closely correlated to the particular relation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Ranking quality of extracted facts. Significance  (paired t-test, p < 0.05) w.r.t. MLE(*) and hier orig( \u2020).", "labels": [], "entities": [{"text": "MLE", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9961714148521423}]}, {"text": " Table 2: TAC Scores on (Surdeanu et al., 2012) queries.", "labels": [], "entities": [{"text": "TAC Scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8735589981079102}, {"text": "Surdeanu et al., 2012) queries", "start_pos": 25, "end_pos": 55, "type": "DATASET", "confidence": 0.6884716749191284}]}]}