{"title": [{"text": "Adaptor Grammars for Learning Non-Concatenative Morphology", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper contributes an approach for expressing non-concatenative morphological phenomena, such as stem derivation in Semitic languages, in terms of a mildly context-sensitive grammar formalism.", "labels": [], "entities": []}, {"text": "This offers a convenient level of modelling abstraction while remaining computationally tractable.", "labels": [], "entities": []}, {"text": "The nonparametric Bayesian framework of adaptor grammars is extended to this richer grammar formalism to propose a prob-abilistic model that can learn word segmenta-tion and morpheme lexicons, including ones with discontiguous strings as elements, from unannotated data.", "labels": [], "entities": []}, {"text": "Our experiments on He-brew and three variants of Arabic data find that the additional expressiveness to capture roots and templates as atomic units improves the quality of concatenative segmentation and stem identification.", "labels": [], "entities": [{"text": "stem identification", "start_pos": 203, "end_pos": 222, "type": "TASK", "confidence": 0.7471559643745422}]}, {"text": "We obtain 74% accuracy in identifying triliteral Hebrew roots, while performing morphological segmentation with an F1-score of 78.1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996209144592285}, {"text": "identifying triliteral Hebrew roots", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.780691608786583}, {"text": "morphological segmentation", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.7397982180118561}, {"text": "F1-score", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9995046854019165}]}], "introductionContent": [{"text": "Unsupervised learning of morphology is the task of acquiring, from unannotated data, the intra-word building blocks of a language and the rules by which they combine to form words.", "labels": [], "entities": [{"text": "Unsupervised learning of morphology", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6734278276562691}]}, {"text": "This task is of interest both as a gateway for studying language acquisition in humans and as away of producing morphological analyses that are of practical use in a variety of natural language processing tasks, including machine translation, parsing and information retrieval.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 222, "end_pos": 241, "type": "TASK", "confidence": 0.8062210083007812}, {"text": "parsing", "start_pos": 243, "end_pos": 250, "type": "TASK", "confidence": 0.8986536860466003}, {"text": "information retrieval", "start_pos": 255, "end_pos": 276, "type": "TASK", "confidence": 0.7761074602603912}]}, {"text": "A particularly interesting version of the morphology learning problem comes from languages that use templatic morphology, such as Arabic, Hebrew and Amharic.", "labels": [], "entities": []}, {"text": "These Semitic languages derive verb and noun stems by interspersing abstract root morphemes into templatic structures in a nonconcatenative way.", "labels": [], "entities": []}, {"text": "For example, the Arabic root k\u00b7t\u00b7b can combine with the template (i-a) to derive the noun stem kitab (book).", "labels": [], "entities": []}, {"text": "Established morphological analysers typically ignore this process and simply view the derived stems as elementary units, or their account of it coincides with a requirement for extensive linguistic knowledge and hand-crafting of rules (.", "labels": [], "entities": []}, {"text": "The former approach is bound to suffer from vocabulary coverage issues, while the latter clearly does not transfer easily across languages.", "labels": [], "entities": []}, {"text": "The practical appeal of unsupervised learning of templatic morphology is that it can overcome these shortcomings.", "labels": [], "entities": [{"text": "templatic morphology", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7523902952671051}]}, {"text": "Unsupervised learning of concatenative morphology has received extensive attention, partly driven by the MorphoChallenge () in recent years, but that is not the case for root-templatic morphology.", "labels": [], "entities": [{"text": "MorphoChallenge", "start_pos": 105, "end_pos": 120, "type": "DATASET", "confidence": 0.8804728388786316}]}, {"text": "In this paper we present a model-based method that learns concatenative and root-templatic morphology in a unified framework.", "labels": [], "entities": []}, {"text": "We build on two disparate strands of work from the literature: Firstly, we apply simple Range Concatenating Grammars (SRCGs)) to parse contiguous and discontiguous morphemes from an input string.", "labels": [], "entities": []}, {"text": "These grammars are mildly-context sensitive, a superset of context-free grammars that retains polynomial parsing time-complexity.", "labels": [], "entities": []}, {"text": "Secondly, we generalise the nonparametric Bayesian learning framework of adaptor grammars to SRCGs.", "labels": [], "entities": []}, {"text": "1 This should also be rel-evant to other applications of probabilistic SRCGs, e.g. in parsing, translation) and genetics ().", "labels": [], "entities": [{"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9728888869285583}, {"text": "translation", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.7381516695022583}]}, {"text": "In addition to unannotated data, our method requires as input a minimal set of high-level grammar rules that encode basic intuitions of the morphology.", "labels": [], "entities": []}, {"text": "This is where there would be room to become very language specific.", "labels": [], "entities": []}, {"text": "Our aim, however, is not to obtain a best-published result in a particular language, but rather to create a method that is applicable across a variety of morphological processes.", "labels": [], "entities": []}, {"text": "The specific rules used in our empirical evaluation on Arabic and Hebrew therefore contain hardly any explicit linguistic knowledge about the languages and are applicable across the family of Semitic languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our model on standard Arabic, Quranic Arabic and Hebrew in terms of segmentation quality and lexicon induction ability.", "labels": [], "entities": []}, {"text": "These languages share various properties, including morphology and lexical cognates, but are sufficiently different so as to require manual intervention when transferring rulebased morphological analysers across languages.", "labels": [], "entities": []}, {"text": "A key question in this evaluation is therefore whether an appropriate instantiation of our model successfully generalises across related languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics, including average number  of morphemes (m/w) and characters (c/w) per word,  and total surface-realised roots of length 3 or 4.", "labels": [], "entities": []}, {"text": " Table 2: Morpheme lexicon induction quality. F1-scores for lexicons induced from the most probable parse  of each different dataset under each models.  \u2020 42.4 was obtained by taking the union of R3 and T3 items to  match the way the model used them (see  \u00a76.4).", "labels": [], "entities": [{"text": "Morpheme lexicon induction", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7569623390833536}, {"text": "F1-scores", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9982238411903381}]}, {"text": " Table 3: Segmentation quality in SBF1. The QU", "labels": [], "entities": [{"text": "SBF1", "start_pos": 34, "end_pos": 38, "type": "TASK", "confidence": 0.7386847734451294}, {"text": "QU", "start_pos": 44, "end_pos": 46, "type": "DATASET", "confidence": 0.49332326650619507}]}]}