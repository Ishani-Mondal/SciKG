{"title": [{"text": "Efficient Higher-Order CRFs for Morphological Tagging", "labels": [], "entities": [{"text": "Morphological Tagging", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.8886240422725677}]}], "abstractContent": [{"text": "Training higher-order conditional random fields is prohibitive for huge tag sets.", "labels": [], "entities": []}, {"text": "We present an approximated conditional random field using coarse-to-fine decoding and early updating.", "labels": [], "entities": []}, {"text": "We show that our implementation yields fast and accurate morphological taggers across six languages with different morphological properties and that across languages higher-order models give significant improvements over 1 st-order models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conditional Random Fields (CRFs) () are arguably one of the best performing sequence prediction models for many Natural Language Processing (NLP) tasks.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.6999654322862625}]}, {"text": "During CRF training forward-backward computations, a form of dynamic programming, dominate the asymptotic runtime.", "labels": [], "entities": [{"text": "CRF", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9694707989692688}]}, {"text": "The training and also decoding times thus depend polynomially on the size of the tagset and exponentially on the order of the CRF.", "labels": [], "entities": []}, {"text": "This probably explains why CRFs, despite their outstanding accuracy, normally only are applied to tasks with small tagsets such as Named Entity Recognition and Chunking; if they are applied to tasks with bigger tagsets -e.g., to part-of-speech (POS) tagging for English -then they generally are used as 1 st -order models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9949087500572205}, {"text": "Named Entity Recognition", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.6683078408241272}]}, {"text": "In this paper, we demonstrate that fast and accurate CRF training and tagging is possible for large tagsets of even thousands of tags by approximating the CRF objective function using coarse-to-fine decoding.", "labels": [], "entities": [{"text": "CRF training", "start_pos": 53, "end_pos": 65, "type": "TASK", "confidence": 0.907629132270813}, {"text": "tagging", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.9132675528526306}]}, {"text": "Our pruned CRF (PCRF) model has much smaller runtime than higher-order CRF models and may thus lead to an even broader application of CRFs across NLP tagging tasks.", "labels": [], "entities": [{"text": "NLP tagging tasks", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.8356484572092692}]}, {"text": "We use POS tagging and combined POS and morphological (POS+MORPH) tagging to demonstrate the properties and benefits of our approach.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.6866148114204407}]}, {"text": "POS+MORPH disambiguation is an important preprocessing step for syntactic parsing.", "labels": [], "entities": [{"text": "POS+MORPH disambiguation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5908161550760269}, {"text": "syntactic parsing", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7881005108356476}]}, {"text": "It is usually tackled by applying sequence prediction.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8413265943527222}]}, {"text": "POS+MORPH tagging is also a good example of a task where CRFs are rarely applied as the tagsets are often so big that even 1 st -order dynamic programming is too expensive.", "labels": [], "entities": [{"text": "POS+MORPH tagging", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.5205633118748665}]}, {"text": "A workaround is to restrict the possible tag candidates per position by using either morphological analyzers (MAs), dictionaries or heuristics.", "labels": [], "entities": []}, {"text": "In this paper, however we show that when using pruning (i.e., PCRFs), CRFs can be trained in reasonable time, which makes hard constraints unnecessary.", "labels": [], "entities": []}, {"text": "In this paper, we run successful experiments on six languages with different morphological properties; we interpret this as evidence that our approach is a general solution to the problem of POS+MORPH tagging.", "labels": [], "entities": [{"text": "POS+MORPH tagging", "start_pos": 191, "end_pos": 208, "type": "TASK", "confidence": 0.5954828858375549}]}, {"text": "The tagsets in our experiments range from small sizes of 12 to large sizes of up to 1811.", "labels": [], "entities": []}, {"text": "We will see that even for the smallest tagset, PCRFs need only 40% of the training time of standard CRFs.", "labels": [], "entities": []}, {"text": "For the bigger tagset sizes we can reduce training times from several days to several hours.", "labels": [], "entities": []}, {"text": "We will also show that training higher-order PCRF models takes only several minutes longer than training 1 st -order models and -depending on the language -may lead to substantial accuracy im- provements.", "labels": [], "entities": [{"text": "accuracy im- provements", "start_pos": 180, "end_pos": 203, "type": "METRIC", "confidence": 0.8806163221597672}]}, {"text": "For example in German POS+MORPH tagging, a 1 st -order model (trained in 32 minutes) achieves an accuracy of 88.96 while a 3 rd -order model (trained in 35 minutes) achieves an accuracy of 90.60.", "labels": [], "entities": [{"text": "POS+MORPH tagging", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.5365050137042999}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.99907386302948}, {"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9987632036209106}]}, {"text": "The remainder of the paper is structured as follows: Section 2 describes our CRF implementation 1 and the feature set used.", "labels": [], "entities": []}, {"text": "Section 3 summarizes related work on tagging with CRFs, efficient CRF tagging and coarse-to-fine decoding.", "labels": [], "entities": [{"text": "tagging", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.9769834876060486}, {"text": "CRF tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8504797220230103}]}, {"text": "Section 4 describes experiments on POS tagging and POS+MORPH tagging and Section 5 summarizes the main contributions of the paper.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.7569315731525421}, {"text": "POS+MORPH tagging", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.5592243000864983}]}], "datasetContent": [{"text": "We run POS+MORPH tagging experiments on Arabic (ar), Czech (cs), Spanish (es), German (de) and Hungarian (hu).", "labels": [], "entities": [{"text": "POS+MORPH tagging", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.6274474412202835}]}, {"text": "The following table shows the typetoken (T/T) ratio, the average number of tags of every word form that occurs more than once in the training set (A) and the number of tags of the most ambiguous word form ( \u02c6 A): Arabic is a Semitic language with nonconcatenative morphology.", "labels": [], "entities": [{"text": "typetoken (T/T) ratio", "start_pos": 30, "end_pos": 51, "type": "METRIC", "confidence": 0.8940498658588955}]}, {"text": "An additional difficulty is that vowels are often not written in Arabic script.", "labels": [], "entities": []}, {"text": "This introduces a high number of ambiguities; on the other hand it reduces the type-token ratio, which generally makes learning easier.", "labels": [], "entities": []}, {"text": "In this paper, we work with the transliteration of Arabic provided in the Penn Arabic Treebank.", "labels": [], "entities": [{"text": "Penn Arabic Treebank", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.989222009976705}]}, {"text": "Czech is a highly inflecting Slavic language with a large number of morphological features.", "labels": [], "entities": []}, {"text": "Spanish is a Romance language.", "labels": [], "entities": []}, {"text": "Based on the statistics above we can see that it has few POS+MORPH ambiguities.", "labels": [], "entities": [{"text": "POS+MORPH ambiguities", "start_pos": 57, "end_pos": 78, "type": "METRIC", "confidence": 0.8387582004070282}]}, {"text": "It is also the language with the smallest tagset and the only language in our setup that -with a few exceptions -does not mark case.", "labels": [], "entities": []}, {"text": "German is a Germanic language andbased on the statistics above -the language with the most ambiguous morphology.", "labels": [], "entities": []}, {"text": "The reason is that it only has a small number of inflectional suffixes.", "labels": [], "entities": []}, {"text": "The total number of nominal inflectional suffixes for example is five.", "labels": [], "entities": []}, {"text": "A good example fora highly ambiguous suffix is \"en\", which is a marker for infinitive verb forms, for the 1 stand 3 rd person plural and for the polite 2 nd person singular.", "labels": [], "entities": []}, {"text": "Additionally, it marks plural nouns of all cases and singular nouns in genitive, dative and accusative case.", "labels": [], "entities": []}, {"text": "Hungarian is a Finno-Ugric language with an agglutinative morphology; this results in a high typetoken ratio, but also the lowest level of word form ambiguity among the selected languages.", "labels": [], "entities": [{"text": "typetoken ratio", "start_pos": 93, "end_pos": 108, "type": "METRIC", "confidence": 0.8612628877162933}]}, {"text": "POS tagging experiments are run on all the languages above and also on English.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7838186323642731}]}, {"text": "Ina first experiment we evaluate the speed and accuracy of CRFs and PCRFs on the POS tagsets.", "labels": [], "entities": [{"text": "speed", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9656837582588196}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.998623251914978}, {"text": "POS tagsets", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.8966397643089294}]}, {"text": "As shown in the tagset sizes range from 12 for Czech and Spanish to 54 and 57 for German and Hungarian, with Arabic (38) and English (45) in between.", "labels": [], "entities": []}, {"text": "The results of our experiments are given in.", "labels": [], "entities": []}, {"text": "For the 1 st -order models, we observe speed-ups in training time from 2.3 to 31 at no loss inaccuracy.", "labels": [], "entities": []}, {"text": "For all languages, training pruned higher-order models is faster than training unpruned 1 st -order models and yields more accurate models.", "labels": [], "entities": []}, {"text": "Accuracy improvements range from 0.08 for Hungarian to 0.25 for German.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9755514860153198}]}, {"text": "We can conclude that for small and medium tagset sizes PCRFs give substantial improvements in both training and decoding speed and thus allow for higher-order tagging, which for all languages leads to significant 4 accuracy improvements.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.9933214783668518}]}, {"text": "Ideally, for the full POS+MORPH tagset we would also compare our results to an unpruned CRF, but our implementation turned out to be too slow to do the required number of experiments.", "labels": [], "entities": [{"text": "POS+MORPH tagset", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.665216252207756}]}, {"text": "For German, the model processed \u2248 0.1 sentences per second during training; so running 10 SGD iterations on the 40,472 sentences would take more than a month.", "labels": [], "entities": []}, {"text": "We therefore compare our model against models that perform oracle pruning, which means we perform standard pruning, but always keep the gold candidate in the lattice.", "labels": [], "entities": []}, {"text": "The oracle pruning is applied during training and testing on the development set.", "labels": [], "entities": []}, {"text": "The oracle model performance is thus an upper bound for the performance of an unpruned CRF.", "labels": [], "entities": []}, {"text": "The most interesting pruning step happens at the 0-order level when we reduce from hundreds of candidates to just a couple.", "labels": [], "entities": []}, {"text": "shows the results for 1 st -order CRFs.", "labels": [], "entities": []}, {"text": "We can roughly group the five languages into three groups: for Spanish and Hungarian the damage is negligible, for Arabic we see a small decrease of 0.07 and only for Czech and German we observe considerable differences of 0.14 and 0.37.", "labels": [], "entities": []}, {"text": "Surprisingly, doubling the number of candidates per position does not lead to significant improvements.", "labels": [], "entities": []}, {"text": "We can conclude that except for Czech and German losses due to pruning are insignificant.", "labels": [], "entities": []}, {"text": "One argument for PCRFs is that while they might be less accurate than standard CRFs they allow to train higher-order models, which in turn might be more accurate than their standard lower-order counterparts.", "labels": [], "entities": []}, {"text": "In this section, we investigate how big the improvements of higher-order models are.", "labels": [], "entities": []}, {"text": "The results are given in the following: Accuracies for models with and without oracle pruning.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9885409474372864}]}, {"text": "* indicates models significantly worse than the oracle model.", "labels": [], "entities": []}, {"text": "We see that 2 nd -order models give improvements for all languages.", "labels": [], "entities": []}, {"text": "For Spanish and Hungarian we see minor improvements \u2264 0.1.", "labels": [], "entities": []}, {"text": "For Czech we see a moderate improvement of 0.61 and for Arabic and German we observe substantial improvements of 0.96 and 1.31.", "labels": [], "entities": []}, {"text": "An analysis on the development set revealed that for all three languages, case is the morphological feature that benefits most from higher-order models.", "labels": [], "entities": []}, {"text": "A possible explanation is that case has a high correlation with syntactic relations and is thus affected by long-distance dependencies.", "labels": [], "entities": []}, {"text": "German is the only language where fourgram models give an additional improvement over trigram models.", "labels": [], "entities": []}, {"text": "The reason seem to be sentences with longrange dependencies, e.g., \"Die Rebellen haben kein L\u00f6segeld verlangt\" (The rebels have not demanded any ransom); \"verlangt\" (demanded) is a past particple that is separated from the auxilary verb \"haben\" (have).", "labels": [], "entities": []}, {"text": "The 2 nd -order model does not consider enough context and misclassifies \"verlangt\" as a finite verb form, while the 3 rd -order model tags it correctly.", "labels": [], "entities": []}, {"text": "We can also conclude that the improvements for higher-order models are always higher than the loss we estimated in the oracle experiments.", "labels": [], "entities": []}, {"text": "More precisely we see that if a language has a low number of word form ambiguities (e.g., Hungarian) we observe a small loss during 0-order pruning but we also have to expect less of an improvement when increasing the order of the model.", "labels": [], "entities": []}, {"text": "For languages with a high number of word form ambiguities (e.g., German) we must anticipate some loss during 0-order pruning, but we also see substantial benefits for higher-order models.", "labels": [], "entities": []}, {"text": "Surprisingly, we found that higher-order PCRF models can also avoid the pruning errors of lowerorder models.", "labels": [], "entities": []}, {"text": "Here is an example from the German data.", "labels": [], "entities": [{"text": "German data", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9609116613864899}]}, {"text": "The word \"Januar\" (January) is ambiguous: in the training set, it occurs 108 times as dative, 9 times as accusative and only 5 times as nominative.", "labels": [], "entities": [{"text": "Januar\" (January)", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.4551257789134979}]}, {"text": "The development set contains 48 nominative instances of \"Januar\" in datelines at the end of news articles, e.g., \"TEL AVIV, 3. Januar\".", "labels": [], "entities": [{"text": "TEL AVIV, 3. Januar", "start_pos": 114, "end_pos": 133, "type": "DATASET", "confidence": 0.6744309306144715}]}, {"text": "For these 48 occurrences, (i) the oracle model in selects the correct case nominative, (ii) the 1 st -order PCRF model selects the incorrect case accusative, and (iii) the 2 ndand 3 rd -order models select -unlike the 1 st -order model -the correct case nominative.", "labels": [], "entities": []}, {"text": "Our interpretation is that the correct nominative reading is pruned from the 0-order lattice.", "labels": [], "entities": []}, {"text": "However, the higher-order models can put less weight on 0-order features as they have access to more context to disambiguate the sequence.", "labels": [], "entities": []}, {"text": "The lower weights of order-0 result in a more uniform posterior distribution and the nominative reading is not pruned from the lattice.", "labels": [], "entities": []}, {"text": "In this section we compare the improvements of higher-order models when used with MAs.", "labels": [], "entities": []}, {"text": "The re-     Plus and minus indicate models that are significantly better or worse than MA1.", "labels": [], "entities": [{"text": "re-     Plus and minus", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.7783597707748413}, {"text": "MA1", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.8992923498153687}]}, {"text": "We can see that the improvements due to higher-order models are orthogonal to the improvements due to MAs for all languages.", "labels": [], "entities": []}, {"text": "This was to be expected as MAs provide additional lexical knowledge while higher-order models provide additional information about the context.", "labels": [], "entities": []}, {"text": "For Arabic and German the improvements of higher-order models are bigger than the improvements due to MAs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Training set statistics. Out-Of-Vocabulary (OOV) rate is regarding the development sets.", "labels": [], "entities": [{"text": "Out-Of-Vocabulary (OOV) rate", "start_pos": 35, "end_pos": 63, "type": "METRIC", "confidence": 0.9742156147956849}]}, {"text": " Table 2: POS tagging experiments with pruned and unpruned CRFs with different orders n. For every language the  training time in minutes (TT) and the POS accuracy (ACC) are given. * indicates models significantly better than CRF  (first line).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8462261855602264}, {"text": "training time in minutes (TT)", "start_pos": 113, "end_pos": 142, "type": "METRIC", "confidence": 0.8041921598570687}, {"text": "POS accuracy (ACC)", "start_pos": 151, "end_pos": 169, "type": "METRIC", "confidence": 0.8702913880348205}]}, {"text": " Table 3: Accuracies for models with and without oracle pruning. * indicates models significantly worse than the oracle  model.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9988677501678467}]}, {"text": " Table 4: Development results for POS tagging. Given are training times in minutes (TT) and accuracies (ACC).  Best baseline results are underlined and the overall best results bold. * indicates a significant difference (positive or  negative) between the best baseline and a PCRF model.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.9363465309143066}, {"text": "training times in minutes (TT)", "start_pos": 57, "end_pos": 87, "type": "METRIC", "confidence": 0.7551315171377999}, {"text": "accuracies (ACC)", "start_pos": 92, "end_pos": 108, "type": "METRIC", "confidence": 0.9032591134309769}]}, {"text": " Table 5: Test results for POS tagging. Best baseline results are underlined and the overall best results bold. * indicates  a significant difference between the best baseline and a PCRF model.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.8564299941062927}]}, {"text": " Table 6: Development results for POS+MORPH tagging. Given are training times in minutes (TT) and accuracies  (ACC). Best baseline results are underlined and the overall best results bold. * indicates a significant difference  between the best baseline and a PCRF model.", "labels": [], "entities": [{"text": "POS+MORPH tagging", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.672026202082634}, {"text": "training times in minutes (TT)", "start_pos": 63, "end_pos": 93, "type": "METRIC", "confidence": 0.8255638395036969}, {"text": "accuracies  (ACC)", "start_pos": 98, "end_pos": 115, "type": "METRIC", "confidence": 0.870899572968483}]}, {"text": " Table 7: Test results for POS+MORPH tagging. Best baseline results are underlined and the overall best results bold.  * indicates a significant difference between the best baseline and a PCRF model.", "labels": [], "entities": [{"text": "POS+MORPH tagging", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.6524932980537415}]}]}