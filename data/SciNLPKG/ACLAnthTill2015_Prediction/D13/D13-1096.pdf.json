{"title": [{"text": "A Dataset for Research on Short-Text Conversation *", "labels": [], "entities": [{"text": "Short-Text Conversation", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7218431830406189}]}], "abstractContent": [{"text": "Natural language conversation is widely regarded as a highly difficult problem, which is usually attacked with either rule-based or learning-based models.", "labels": [], "entities": [{"text": "Natural language conversation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6658356388409933}]}, {"text": "In this paper we propose a retrieval-based automatic response model for short-text conversation, to exploit the vast amount of short conversation instances available on social media.", "labels": [], "entities": []}, {"text": "For this purpose we introduce a dataset of short-text conversation based on the real-world instances from Sina Weibo (a popular Chinese mi-croblog service), which will be soon released to public.", "labels": [], "entities": []}, {"text": "This dataset provides rich collection of instances for the research on finding natural and relevant short responses to a given short text, and useful for both training and testing of conversation models.", "labels": [], "entities": []}, {"text": "This dataset consists of both naturally formed conversations , manually labeled data, and a large repository of candidate responses.", "labels": [], "entities": []}, {"text": "Our preliminary experiments demonstrate that the simple retrieval-based conversation model performs reasonably well when combined with the rich instances in our dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language conversation is one of the holy grail of artificial intelligence, and has been taken as the original form of the celebrated Turing test.", "labels": [], "entities": [{"text": "Natural language conversation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6592248876889547}]}, {"text": "Previous effort in this direction has largely focused on analyzing the text and modeling the state of the conversation through dialogue models, while in this pa- * The work is done when the first author worked as intern at Noah's Ark Lab, Huawei Techologies.", "labels": [], "entities": [{"text": "Huawei Techologies", "start_pos": 239, "end_pos": 257, "type": "DATASET", "confidence": 0.8829510807991028}]}, {"text": "per we take one step back and focus on a much easier task of finding the response fora given short text.", "labels": [], "entities": []}, {"text": "This task is in clear contrast with previous effort in dialogue modeling in the following two aspects \u2022 we do not consider the context or history of conversations, and assume that the given short text is self-contained; \u2022 we only require the response to be natural, relevant, and human-like, and do not require it to contain particular opinion, content, or to be of particular style.", "labels": [], "entities": [{"text": "dialogue modeling", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.8544076085090637}]}, {"text": "This task is much simpler than modeling a complete dialogue session (e.g., as proposed in Turing test), and probably not enough for real conversation scenario which requires often several rounds of interactions (e.g., automatic question answering system as in ().", "labels": [], "entities": [{"text": "question answering", "start_pos": 228, "end_pos": 246, "type": "TASK", "confidence": 0.6898662447929382}]}, {"text": "However it can shed important light on understanding the complicated mechanism of the interaction between an utterance and its response.", "labels": [], "entities": []}, {"text": "The research in this direction will not only instantly help the applications of short session dialogue such as automatic message replying on mobile phone and the chatbot employed in voice assistant like Siri 1 , but also it will eventually benefit the modeling of dialogues in a more general setting.", "labels": [], "entities": [{"text": "automatic message replying", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.6851734519004822}]}, {"text": "Previous effort in modeling lengthy dialogues focused either on rule-based or learning-based models;.", "labels": [], "entities": []}, {"text": "This category of approaches require relatively less data (e.g. reinforcement learning based) for training or no training at all, but much manual effort in designing the rules or the particular learning algorithms.", "labels": [], "entities": []}, {"text": "In this paper, we propose to attack this problem using an alternative approach, by leveraging the vast amount of training data available from the social media.", "labels": [], "entities": []}, {"text": "Similar ideas have appeared in as an initial step for training a chatbot.", "labels": [], "entities": []}, {"text": "With the emergence of social media, especially microblogs such as Twitter, in the past decade, they have become an important form of communication for many people.", "labels": [], "entities": []}, {"text": "As the result, it has collected conversation history with volume previously unthinkable, which brings opportunity for attacking the conversation problem from a whole new angle.", "labels": [], "entities": []}, {"text": "More specifically, instead of generating a response to an utterance, we pick a massive suitable one from the candidate set.", "labels": [], "entities": []}, {"text": "The hope is, with a reasonable retrieval model and a large enough candidate set, the system can produce fairly natural and appropriate responses.", "labels": [], "entities": []}, {"text": "This retrieval-based model is somewhat like nonparametric model in machine learning communities, which performs well only when we have abundant data.", "labels": [], "entities": []}, {"text": "In our model, it needs only a relatively small labeled dataset for training the retrieval model, but requires a rather large unlabeled set (e.g., one million instances) for candidate responses.", "labels": [], "entities": []}, {"text": "To further promote the research in similar direction, we create a dataset for training and testing the retrieval model, with a candidate responses set of reasonable size.", "labels": [], "entities": []}, {"text": "Sina Weibo is the most popular Twitterlike microblog service in China, hosting over 500 million registered users and generating over 100 million messages per day 2 . As almost all microblog services, Sina Weibo allows users to comment on a published post 3 , which forms a natural one-round conversation.", "labels": [], "entities": [{"text": "Sina Weibo", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.910211056470871}]}, {"text": "Due to the great abundance of those (post, response) pairs, it provides an ideal data source and test bed for one-round conversation.", "labels": [], "entities": []}, {"text": "We will make this dataset publicly available in the near future.", "labels": [], "entities": []}, {"text": "2 http://en.wikipedia.org/wiki/Sina_Weibo 3 Actually it also allows users to comment on other users' comments, but we will not consider that in the dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset consists of three parts, as illustrated in.", "labels": [], "entities": []}, {"text": "Part 1 contains the original (post, response) pairs, indicated by the dark-grey section in.", "labels": [], "entities": []}, {"text": "Part 2, indicated by the light-gray section in, consists labeled (post, response) pairs for some Weibo posts, including positive and negative examples.", "labels": [], "entities": []}, {"text": "Part 3 collects all the responses, including but not limited to the responses in Part 1 and 2.", "labels": [], "entities": []}, {"text": "Some of the basic statistics are summarized in  Original (Post, Response) Pairs This part of dataset gives (post, response) pairs naturally presented in the microblog service.", "labels": [], "entities": []}, {"text": "In other words, we create a (post, response) pair there when the response is actually given to the post in Sina Weibo.", "labels": [], "entities": [{"text": "Sina Weibo", "start_pos": 107, "end_pos": 117, "type": "DATASET", "confidence": 0.8289215266704559}]}, {"text": "The part of data is noisy since the responses given to a Weibo post could still be inappropriate for different reasons, for example, they could be spams or targeting some responses given earlier.", "labels": [], "entities": [{"text": "Weibo post", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.9448070228099823}]}, {"text": "We have 628, 833 pairs.", "labels": [], "entities": []}, {"text": "Labeled Pairs This part of data contains the (post, response) pairs that are labeled by human.", "labels": [], "entities": []}, {"text": "Note that 1) the labeling is only on a small subset of posts, and 2) for each selected post, the labeled responses are not originally given to it.", "labels": [], "entities": []}, {"text": "The labeling is done in an active manner (see Section 4 for more details), so the obtained labels are much more informative than the those on randomly selected pairs (over 98% of which are negative).", "labels": [], "entities": []}, {"text": "This part of data can be directly used for training and testing of retrieval-based response models.", "labels": [], "entities": []}, {"text": "We have labeled 422 posts and for each of them, about 30 candidate responses.", "labels": [], "entities": []}, {"text": "Responses This part of dataset contains only responses, but they are not necessarily fora certain post.", "labels": [], "entities": []}, {"text": "These extra responses are mainly filtered out by our data cleaning strategy (see Section 4.2) for original (post, response) pairs, including those from filtered-out Weibo posts and those addressing other responses.", "labels": [], "entities": []}, {"text": "Nevertheless, those responses are still valid candidate for responses.", "labels": [], "entities": []}, {"text": "We have about 1.5 million responses in the dataset.", "labels": [], "entities": []}, {"text": "Our data can be used for training and testing of retrieval-based response model, or just as a bank of responses.", "labels": [], "entities": []}, {"text": "More specifically, it can be used in at least the following three ways.", "labels": [], "entities": []}, {"text": "Training Low-level Matching Features The rather abundant original (post, response) pairs provide rather rich supervision signal for learning different matching patterns between a post and a response.", "labels": [], "entities": []}, {"text": "These matching patterns could be of dif- ferent levels.", "labels": [], "entities": []}, {"text": "For example, one may discover from the data that when the word \"Hawaii\" occurs in the post, the response are more likely to contain words like \"trip\", \"flight\", or \"Honolulu\".", "labels": [], "entities": []}, {"text": "On a slightly more abstract level, one may learn that when an entity name is mentioned in the post, it tends to be mentioned again in the response.", "labels": [], "entities": []}, {"text": "More complicated matching pattern could also be learned.", "labels": [], "entities": []}, {"text": "For example, the response to a post asking \"how to\" is statistically longer than average responses.", "labels": [], "entities": []}, {"text": "As a particular case, Ritter et al.", "labels": [], "entities": []}, {"text": "(2011) applied translation model () on similar parallel data extracted from Twitter in order to extract the word-to-word correlation.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9617732167243958}]}, {"text": "Please note that with more sophisticated natural language processing, we can go beyond bag-of-words for more complicated correspondence between post and response.", "labels": [], "entities": []}, {"text": "Training Automatic Response Models Although the original (post, response) pairs are rather abundant, they are not enough for discriminative training and testing of retrieval models, for the following reasons.", "labels": [], "entities": []}, {"text": "In the labeled pairs, both positive and negative ones are ranked high by some baseline models, and hence more difficult to tell apart.", "labels": [], "entities": []}, {"text": "This supervision will naturally tune the model parameters to find the real good responses from the seemingly good ones.", "labels": [], "entities": []}, {"text": "Please note that without the labeled negative pairs, we need to generate negative pairs with randomly chosen responses, which inmost of the cases are too easy to differentiate by the ranking model and cannot fully tune the model parameters.", "labels": [], "entities": []}, {"text": "This intuition has been empirically verified by our experiments.", "labels": [], "entities": []}, {"text": "Testing Automatic Response Models In testing a retrieval-based system, although we can simply use the original responses associated with the query post as positive and treat all the others as negative, this strategy suffers from the problem of spurious negative examples.", "labels": [], "entities": []}, {"text": "In other words, with a reasonably good model, the retrieved responses are often good even if they are not the original ones, which brings significant bias to the evaluation.", "labels": [], "entities": []}, {"text": "With the labeled pairs, this problem can be solved if we limit the testing only in the small pool of labeled responses.", "labels": [], "entities": []}, {"text": "Our dataset can also be used for other researches related to short-text conversations, namely anaphora resolution, sentiment analysis, and speech act analysis, based on the large collection of original (post, response) pairs.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7153697162866592}, {"text": "sentiment analysis", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.9475900232791901}, {"text": "speech act analysis", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.6322252750396729}]}, {"text": "For example, to determine the sentiment of a response, one needs to consider both the original post as well as the observed interaction between the two.", "labels": [], "entities": []}, {"text": "In, if we want to understand user's sentiment towards the \"invited talk\" mentioned in the post, the two responses should betaken as positive, although the sentiment in the mere responses is either negative or neutral.", "labels": [], "entities": []}, {"text": "The (post, comment) pairs are sampled from the Sina Weibo posts published by users in a loosely connected community and the comments they received (may not be from this community).", "labels": [], "entities": [{"text": "Sina Weibo posts published", "start_pos": 47, "end_pos": 73, "type": "DATASET", "confidence": 0.8414259403944016}]}, {"text": "This community is mainly posed of professors, researchers, and students of natural language processing (NLP) and related areas in China, and the users commonly followed them.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.7466706136862437}]}, {"text": "The creation process of the dataset, as illustrated in, consists of three consecutive steps: 1) crawling the community of users, 2) crawling their Weibo posts and their responses, 3) cleaning the data, with more details described in the remainder of this section.", "labels": [], "entities": []}, {"text": "We perform experiments on the proposed dataset to test our retrieval-based model as an algorithm for automatically generating response.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Some statistics of the dataset", "labels": [], "entities": []}]}