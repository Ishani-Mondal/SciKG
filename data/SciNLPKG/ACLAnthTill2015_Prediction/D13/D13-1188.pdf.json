{"title": [{"text": "Opinion Mining in Newspaper Articles by Entropy-based Word Connections", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7856910228729248}, {"text": "Entropy-based Word Connections", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.5242897222439448}]}], "abstractContent": [{"text": "Avery valuable piece of information in newspaper articles is the tonality of extracted statements.", "labels": [], "entities": []}, {"text": "For the analysis of tonality of newspaper articles either a big human effort is needed, when it is carried out by media analysts, or an automated approach which has to be as accurate as possible fora Media Response Analysis (MRA).", "labels": [], "entities": [{"text": "analysis of tonality of newspaper articles", "start_pos": 8, "end_pos": 50, "type": "TASK", "confidence": 0.8932979106903076}, {"text": "Media Response Analysis (MRA)", "start_pos": 200, "end_pos": 229, "type": "TASK", "confidence": 0.7806971122821172}]}, {"text": "To this end, we will compare several state-of-the-art approaches for Opinion Mining in newspaper articles in this paper.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.9486854076385498}]}, {"text": "Furthermore, we will introduce anew technique to extract entropy-based word connections which identifies the word combinations which create atonality.", "labels": [], "entities": []}, {"text": "In the evaluation , we use two different corpora consisting of news articles, by which we show that the new approach achieves better results than the four state-of-the-art methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Web keeps many potentially valuable opinions in news articles which are partly new online articles or uploaded print media articles.", "labels": [], "entities": []}, {"text": "Many companies or organisations such as political parties or even distinguished public figures perform a Media Response Analysis (MRA) () in order to analyse the output of their effort in public relations.", "labels": [], "entities": [{"text": "Media Response Analysis (MRA)", "start_pos": 105, "end_pos": 134, "type": "TASK", "confidence": 0.5017816126346588}]}, {"text": "So, an opinion-oriented analysis of news articles is important, because the tonality () is the key indicator of a MRA.", "labels": [], "entities": [{"text": "MRA", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.8706234693527222}]}, {"text": "A purely manual solution implies a big human effort for so-called media analysts, because they have to read and rate approx. 200 to 800 news articles each week.", "labels": [], "entities": []}, {"text": "As a consequence, an automated Opinion Mining solution is very attractive.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7445207834243774}]}, {"text": "At the same time, Opinion Mining in newspaper articles appears to be difficult, because not all parts of news articles are as subjective ( as reviews, for example.", "labels": [], "entities": [{"text": "Opinion Mining in newspaper articles", "start_pos": 18, "end_pos": 54, "type": "TASK", "confidence": 0.8060205221176148}]}, {"text": "Also, different parts of one article can contain different opinions (.", "labels": [], "entities": []}, {"text": "Therefore, we work with extracted statements of news articles, in which a sequence of consecutive sentences has the same tonality value.", "labels": [], "entities": []}, {"text": "At the same time, some approaches focus more on differentiating only between positive and negative news and leave out neutral examples).", "labels": [], "entities": []}, {"text": "Conversely, we have noticed that even if the used words in the news domain are quite similar, the tonality which the words express can be different, especially if neutral examples are involved (cf. section 3.1).", "labels": [], "entities": []}, {"text": "We propose this task formulation: Problem definition: Let s \u2286 d be a statement and document d represents a newspaper article.", "labels": [], "entities": []}, {"text": "The task is to determine the tonality y fora given statement s, consisting of k words: t : s = (w 1 , w 2 , ..., wk ) \u2192 y \u2208 {positive,neutral,negative} Normally, a statement consists of one up to four sentences.", "labels": [], "entities": []}, {"text": "But also longer statements are possible, but they appear less frequently in a MRA.", "labels": [], "entities": [{"text": "MRA", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.7431651949882507}]}, {"text": "An automated approach ( for the extraction of statements already exists.", "labels": [], "entities": []}, {"text": "The approach applies machine learning to extract relevant sentences from a collection of news articles and combine them to statements.", "labels": [], "entities": []}, {"text": "So, we concentrate on the tonality classification, which is not provided by the approach for the statements extraction ().", "labels": [], "entities": [{"text": "statements extraction", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7247398048639297}]}, {"text": "Furthermore, we define the polarity of sentiment as the distinction between positive and negative sentiment and the subjectivity as the distinction between subjective (positive and negative) statements and neutral statements.", "labels": [], "entities": []}, {"text": "The following example is a positive statement from an article in The Telegraph (8th Aug 2012) which deals with the prospects of British companies in Africa: \u2022 Example statement (positive): There are structural factors behind the African growth story: a growing and sizeable population which is increasingly urbanised with disposable income; growing political stability; and a financial services industry that is still in its infancy.", "labels": [], "entities": [{"text": "The Telegraph (8th Aug 2012)", "start_pos": 65, "end_pos": 93, "type": "DATASET", "confidence": 0.9296209812164307}]}, {"text": "The so-called pressrelations dataset (), which represents a publicly available corpus 1 of a MRA on German news articles, contains 1,521 annotated statements.", "labels": [], "entities": [{"text": "pressrelations dataset", "start_pos": 14, "end_pos": 36, "type": "DATASET", "confidence": 0.8029466569423676}]}, {"text": "Since this is the only publicly available corpus of a MRA as far as we know, we perform our experiments in German.", "labels": [], "entities": [{"text": "MRA", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9423679709434509}]}, {"text": "We are aware of the fact that viewpoints play a significant role in a newspaper, but since we concentrate on the determination of the tonality, the extraction of viewpoints can be solved in a separate step.", "labels": [], "entities": []}, {"text": "This is possible, because the tonality of a statement can be determined without knowledge of the viewpoint in almost all cases.", "labels": [], "entities": []}, {"text": "The only exception is a statement with multiple viewpoints and different tonalities, but these statements are very rare (cf. also section 4.1).", "labels": [], "entities": []}, {"text": "Our approach learns a graph from an annotated collection of statements, in which nodes and edges model tonality-bearing word connections.", "labels": [], "entities": []}, {"text": "For unseen statements, we recognize subgraphs of the learned graph, compare two weighting methods for extracting different tonality features, and classify the statements by a support vector machine.", "labels": [], "entities": []}, {"text": "In this paper, we describe four state-of-the-art techniques for Opinion Mining in the next section about related work.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.9388370215892792}]}, {"text": "In the third section, we introduce our graph-based and entropy-based approach to calculate the tonality features T . We will evaluate our approach against the state-of-the-art methods in section 4, before we conclude in the last section.", "labels": [], "entities": []}, {"text": "1 http://www.pressrelations.de/research/", "labels": [], "entities": []}], "datasetContent": [{"text": "We use two different datasets for our evaluation: The pressrelations dataset 3 (called PDS) contains 1,521 statements (446 positive, 492 neutral, 583 negative), and areal world dataset contains 8,500 statements (2,125 positive, 2,125 negative, 4,250 neutral) from 5,352 news items about a financial service provider, the so-called Finance dataset.", "labels": [], "entities": [{"text": "pressrelations dataset", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.7251381874084473}, {"text": "Finance dataset", "start_pos": 331, "end_pos": 346, "type": "DATASET", "confidence": 0.954705685377121}]}, {"text": "Up to ten media analysts (professional experts in the field of MRA) annotate the extracted statements with atonality.", "labels": [], "entities": [{"text": "MRA", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9582072496414185}]}, {"text": "We have investigated their inter-annotator agreement.", "labels": [], "entities": []}, {"text": "So, four analysts annotate the same statements from a small part of the statements.", "labels": [], "entities": []}, {"text": "They achieve an agreement of 81.8% by using the simple accuracy metric.", "labels": [], "entities": [{"text": "agreement", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9984787106513977}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9782479405403137}]}, {"text": "The PDS has an inter-annotator agreement of 88.06% (Cohen's kappa) ().", "labels": [], "entities": [{"text": "PDS", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8740564584732056}]}, {"text": "We do not use the viewpoint information contained in the PDS.", "labels": [], "entities": [{"text": "PDS", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.8218474984169006}]}, {"text": "This is not a problem, because the tonality of statements can be estimated without knowledge of the viewpoint in the most cases.", "labels": [], "entities": []}, {"text": "Nevertheless, a statement can have two different viewpoints in a MRA.", "labels": [], "entities": [{"text": "MRA", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.8331772089004517}]}, {"text": "This is the case for 116 statements (approx. 7.62%) of the pressrelations dataset 3 http://www.pressrelations.de/research/ and 279 statements of the Finance dataset (approx. 3.28%).", "labels": [], "entities": [{"text": "pressrelations dataset", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.931385725736618}, {"text": "Finance dataset", "start_pos": 149, "end_pos": 164, "type": "DATASET", "confidence": 0.9753634035587311}]}, {"text": "Statements can have two different tonalities for different viewpoints, but this is rarely the case (for less than 3.56% of the pressrelations statements and less than 0.17% of the statements of the Finance dataset).", "labels": [], "entities": [{"text": "Finance dataset", "start_pos": 198, "end_pos": 213, "type": "DATASET", "confidence": 0.9720637798309326}]}, {"text": "One of these examples is the following statement, which is a translated statement of the PDS: \u2022 Example: The logical consequence would be a substantial increase of the subsidies, which the SPD fraction has demanded several times.", "labels": [], "entities": [{"text": "PDS", "start_pos": 89, "end_pos": 92, "type": "DATASET", "confidence": 0.8622978925704956}]}, {"text": "At the time of the creation of this dataset, the SPD is the biggest opposing party of the CDU in Germany.", "labels": [], "entities": []}, {"text": "The CDU is the governing party under its chairwoman Chancellor Merkel.", "labels": [], "entities": []}, {"text": "We keep these statements within the dataset, because this case can occur in a MRA.", "labels": [], "entities": []}, {"text": "However, we will show that this situation does not irritate our approach too much.", "labels": [], "entities": []}, {"text": "We use approx. 30% of the statements, that is 420 statements (the first 140 positive, neutral, or negative statements) or 2,500 statements (the first 625 positive or negative and the first 1,250 neutral statements) in order to create our graph (the graph has 41,470 or 154,001 edges, resp.).", "labels": [], "entities": []}, {"text": "For POS-tagging, identification of negations, and lemmatisation, we apply the TreeTagger (.", "labels": [], "entities": [{"text": "identification of negations", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.8964127898216248}]}, {"text": "Unless otherwise stated, 20% of the remaining statements (220 and 1,200 statements) are the training set for the SVM and the rest is test set.", "labels": [], "entities": [{"text": "SVM", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.7910912036895752}]}, {"text": "The size of the testis so large, because we are aiming at areal significance of the solution which can actually be operated in practice.", "labels": [], "entities": []}, {"text": "To create the lexicon of subjectivity clues for the method of, all words which appear more often in neutral statements get the prior polarity neutral.", "labels": [], "entities": []}, {"text": "For all other words, we calculate the number of appearances in positive statements minus the appearances in negative statements divided by all appearances.", "labels": [], "entities": []}, {"text": "A positive word has a value of over 0.2, a negative word has a value of less than -0.2 and the rest has the prior polarity both.", "labels": [], "entities": []}, {"text": "A positive word with a value above 0.6 belongs to the reliability class strongsubj, the other positive words are weaksubj.", "labels": [], "entities": []}, {"text": "We treat the negative words analogously.", "labels": [], "entities": []}, {"text": "We use the Stanford Parser for German ( to calculate the dependency trees for the sentences (, in order to extract the General Modification Features, the Polarity Modification Features and the Structure Features.", "labels": [], "entities": []}, {"text": "The lists of intensifiers, copular verbs, modals, negations, and polarity shifters are translated by a domain expert, who also added such elements which are not direct translations, but have the same function.", "labels": [], "entities": []}, {"text": "The result of this method is a classification of words and phrases.", "labels": [], "entities": [{"text": "classification of words and phrases", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.7895957231521606}]}, {"text": "Thus, fora statement classification, we classify the words of the statements and the class of the most frequently used words is the class of the statement (ambiguous statements are classified as the most frequent class).", "labels": [], "entities": [{"text": "statement classification", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.7559688985347748}]}, {"text": "According to the authors, we apply the best machine learning techniques for the word classification (BoosTexter for tonality classification and Ripper for Subjectivity Analysis with parameters as in ().", "labels": [], "entities": [{"text": "word classification", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7521572411060333}, {"text": "tonality classification", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.6870087683200836}]}, {"text": "For Opinion Observer (), we also identify neutral words if they appear more often in neutral than in subjective statements and subjective words are positive if they appear more often in positive than in negative statements and vice versa for negative words.", "labels": [], "entities": []}, {"text": "In contrast to Opinion Mining in customer reviews, we exchange product features through statements and calculate the orientation of opinions for all statements with their opinion orientation algorithm.", "labels": [], "entities": []}, {"text": "For this purpose, we adapt the negation rules, the but-clause rule, the inter-sentence conjunction rule, and the \"too\" rules for German (by translating important words such as \"but\" or the negations).", "labels": [], "entities": []}, {"text": "SO-CAL (Taboada et al., 2011) needs dictionaries with sentiment values from -5 to +5 with intervals of one.", "labels": [], "entities": []}, {"text": "Thus, we use the same scores as the Wilson method and a word with a value above 0.818 to 1 gets a sentiment score of +5 and soon.", "labels": [], "entities": []}, {"text": "This means, that neutral words also exist.", "labels": [], "entities": []}, {"text": "Our domain expert translated the list of intensifiers (amplifiers and downtoners) and negations, as well as the expert also added missing elements.", "labels": [], "entities": []}, {"text": "The authors propose two approaches for the negation search.", "labels": [], "entities": [{"text": "negation search", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.9827479124069214}]}, {"text": "We use the second, more conservative approach, because this approach works better according to the authors.", "labels": [], "entities": []}, {"text": "Also, we use the value 4 for the negation shift.", "labels": [], "entities": []}, {"text": "Furthermore, we implement the algorithm of irrealis blocking and translate the list of irrealis markers (modal verbs, conditional markers, negative polarity items, private-state verbs).", "labels": [], "entities": [{"text": "irrealis blocking", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.6936741322278976}]}, {"text": "For all dictionary-based methods (Wilson, Opinion Observer, SO-CAL), we also evaluate an additional variant which use a sentiment dictionary and not the statements which we use to construct the graphs on each fold.", "labels": [], "entities": []}, {"text": "We apply the SentiWS () for this purpose.", "labels": [], "entities": []}, {"text": "As the SentiWS has sentiment values between \u22121 and 1, we apply similar procedures to construct the method-specific dictionaries as described above: For SO-CAL, it is the same procedure by using the SentiWS values, positive words has a score above 0.33 for Wilson and Opinion Observer, strongsubj words have an absolute value above 0.66 and soon.", "labels": [], "entities": [{"text": "Wilson and Opinion Observer", "start_pos": 256, "end_pos": 283, "type": "DATASET", "confidence": 0.8102377504110336}]}, {"text": "The methods are denoted as method (dictionary).", "labels": [], "entities": []}, {"text": "RSUMM (Sarvabhotla et al., 2011) needs less specific adaptation, because only a sentence splitter and a tokenizer are needed.", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7222898304462433}]}, {"text": "So, RSUMM is very language-independent.", "labels": [], "entities": []}, {"text": "We test two versions of this method: one includes the optimization step to estimate the best values for X and Y (notated as RSUMM(X%, Y%)) and the other version (RSUMM(100%)) does without this step, because we believe that every sentence is important in the statements and also because more words mean more information about the tonality in our domain.", "labels": [], "entities": []}, {"text": "We use the sets for the creation of the graphs and lexicons as the validation dataset (VDS)) and the subjectivity dataset (SDS)).", "labels": [], "entities": []}, {"text": "As in), we apply the SVMLight package 4 for classification.", "labels": [], "entities": [{"text": "SVMLight package 4", "start_pos": 21, "end_pos": 39, "type": "DATASET", "confidence": 0.9389126102129618}]}, {"text": "Opinion Observer ( and SO-CAL (Taboada et al., 2011) do not use supervised learning.", "labels": [], "entities": []}, {"text": "Therefore, we have also added our SVM in order to classify the statements based on the scores of Opinion Observer and SO-CAL (as shown in tables with (+ SVM)). and 4 (left side) show the results on the pressrelations dataset (PDS) and table 3 and 4 (right side) show the results on Finance.", "labels": [], "entities": [{"text": "pressrelations dataset (PDS)", "start_pos": 202, "end_pos": 230, "type": "DATASET", "confidence": 0.7943596482276917}, {"text": "Finance", "start_pos": 282, "end_pos": 289, "type": "DATASET", "confidence": 0.8984667062759399}]}, {"text": "present the tonality classification (positive, neutral, negative) and table 4 displays the Subjectivity Analysis (subjective, neutral).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the experiments on the PDS", "labels": [], "entities": [{"text": "PDS", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.5548077821731567}]}, {"text": " Table 3: Results of the experiments on Finance", "labels": [], "entities": []}, {"text": " Table 4: Subjectivity Analysis on PDS (left side) and on Finance (right side)", "labels": [], "entities": [{"text": "Finance", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9607493281364441}]}, {"text": " Table 5: Different sizes of the training set and the dictionaries/graphs", "labels": [], "entities": []}]}