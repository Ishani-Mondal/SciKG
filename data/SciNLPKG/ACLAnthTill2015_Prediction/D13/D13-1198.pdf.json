{"title": [], "abstractContent": [{"text": "The problem to replace a word with a synonym that fits well in its sentential context is known as the lexical substitution task.", "labels": [], "entities": []}, {"text": "In this paper, we tackle this task as a supervised ranking problem.", "labels": [], "entities": []}, {"text": "Given a dataset of target words, their sentential contexts and the potential substitutions for the target words, the goal is to train a model that accurately ranks the candidate substitutions based on their contex-tual fitness.", "labels": [], "entities": []}, {"text": "As a key contribution, we cus-tomize and evaluate several learning-to-rank models to the lexical substitution task, including classification-based and regression-based approaches.", "labels": [], "entities": []}, {"text": "On two datasets widely used for lexical substitution, our best models significantly advance the state-of-the-art.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7156592309474945}]}], "introductionContent": [{"text": "The task to generate lexical substitutions in context, i.e., to replace words in a sentence without changing its meaning, has become an increasingly popular research topic.", "labels": [], "entities": []}, {"text": "This task is used, e.g. to evaluate semantic models with regard to their accuracy in modeling word meaning in context.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9947064518928528}]}, {"text": "Moreover, it provides a basis of NLP applications in many fields, including linguistic steganography (;, semantic text similarity () and plagiarism detection ().", "labels": [], "entities": [{"text": "linguistic steganography", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.7187772691249847}, {"text": "semantic text similarity", "start_pos": 105, "end_pos": 129, "type": "TASK", "confidence": 0.6815405885378519}, {"text": "plagiarism detection", "start_pos": 137, "end_pos": 157, "type": "TASK", "confidence": 0.7292169034481049}]}, {"text": "While closely related to WSD, lexical substitution does not rely on explicitly defined sense inventories (): the possible substitutions reflect all conceivable senses of the word, and the correct sense has to be ascertained to provide an accurate substitution.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9085170030593872}, {"text": "lexical substitution", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.7138399332761765}]}, {"text": "While a few lexical sample datasets) with humanprovided substitutions exist and can be used to evaluate different lexical paraphrasing approaches, a practically useful system must also be able to rephrase unseen words, i.e., any word for which a list of synonyms is provided.", "labels": [], "entities": []}, {"text": "Correspondingly, unsupervised and knowledge-based approaches that are not directly dependent on any training material, prevailed in the SemEval 2007 shared task on English Lexical Substitution and dominated follow-up work.", "labels": [], "entities": [{"text": "SemEval 2007 shared task on English Lexical Substitution", "start_pos": 136, "end_pos": 192, "type": "TASK", "confidence": 0.7102179974317551}]}, {"text": "The only supervised approach is limited to the combination of several knowledge-based lexical substitution models based on different underlying lexicons.", "labels": [], "entities": []}, {"text": "A recent work by describes a tailor-made supervised system based on delexicalized features that -unlike earlier supervised approaches, and similar to unsupervised and knowledge-based methods proposed for this taskis able to generalize to an open vocabulary.", "labels": [], "entities": []}, {"text": "For each target word to paraphrase, they first compute a set of substitution candidates using WordNet: all synonyms from all of the target word's WordNet synsets, together with the words from synsets in similar to, entailment and also see relation to these synsets are considered as potential substitutions.", "labels": [], "entities": [{"text": "paraphrase", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.9619000554084778}, {"text": "WordNet", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.9791361689567566}]}, {"text": "Each candidate then constitutes a training (or test) example, and these instances are characterized using non-lexical features from heterogeneous evidence such as lexical-semantic resources and distributional similarity, n-gram counts and shallow syntactic features computed on large, unannotated background corpora.", "labels": [], "entities": []}, {"text": "The goal is then i) to predict how well a particular candidate fits in the original context, and ii) given these predictions for each of the candidates, to correctly order the elements of the candidate set according to their contextual fitness.", "labels": [], "entities": []}, {"text": "That is, a model is successful if it prioritizes plausible substitutions ahead of less likely synonyms (given the context).", "labels": [], "entities": []}, {"text": "This model is able to generate paraphrases for target words not contained in the training material.", "labels": [], "entities": []}, {"text": "This favorable property is achieved using only such features (e.g. local n-gram frequencies in context) that are meaningfully comparable across the different target words and candidate substitutions they are computed from.", "labels": [], "entities": []}, {"text": "More importantly, their model also provides superior ranking results compared to state of the art unsupervised and knowledge based approaches and therefore it defines the current state of the art for open vocabulary lexical substitution.", "labels": [], "entities": [{"text": "open vocabulary lexical substitution", "start_pos": 200, "end_pos": 236, "type": "TASK", "confidence": 0.7499873787164688}]}, {"text": "Motivated by the findings of, we address lexical substitution as a supervised learning problem, and go beyond their approach from a methodological point of view.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7162200510501862}]}, {"text": "Our experiments show that the performance on the lexical substitution task is strongly influenced by the way in which this task is formalized as a machine learning problem (i.e., as binary or multi-class classification or regression) and by the learning method used to solve this problem.", "labels": [], "entities": []}, {"text": "As a result, we are able to report the best performances on this task for two standard datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "Here we introduce the datasets, experimental setup and evaluation measures used in our experiments.", "labels": [], "entities": []}, {"text": "Since space restrictions prohibit a comprehensive exposition, we only provide the most essential information and refer to, whose experimental setup we adopted, for further details.", "labels": [], "entities": []}, {"text": "We use two prominent datasets for lexical substitution.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7320396453142166}]}, {"text": "The LexSub dataset introduced in the Lexical Substitution task at contains 2002 sentences fora total of 201 target words (from all parts of speech), and lexical substitutions assigned (to each target word and sentence pair) by 5 native speaker annotators.", "labels": [], "entities": [{"text": "LexSub dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9789059460163116}, {"text": "Lexical Substitution task", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.8905084530512491}]}, {"text": "The second dataset, TWSI (Biemann, 2012) , consists of 24,647 sentences fora total of 1,012 target nouns, and lexical substitu-tions for each target word in context resulting from a crowdsourced annotation process.", "labels": [], "entities": [{"text": "TWSI (Biemann, 2012)", "start_pos": 20, "end_pos": 40, "type": "DATASET", "confidence": 0.8050091167291006}]}, {"text": "For each sentence in each dataset, the annotators provided as many substitutions for the target word as they found appropriate in the context.", "labels": [], "entities": []}, {"text": "Each substitution is then labeled by the number of annotators who listed that word as a good lexical substitution.", "labels": [], "entities": []}, {"text": "On both datasets, we conduct experiments using a 10-fold cross validation process, and evaluate all learning algorithms on the same train/test splits.", "labels": [], "entities": []}, {"text": "The datasets are randomly split into 10 equal-sized folds on the target word level, such that all examples fora particular target word fall into either the training or the test set, but never both.", "labels": [], "entities": []}, {"text": "This way, we make sure to evaluate the models on target words not seen during training, thereby mimicking an open vocabulary paraphrasing system: at testing time, paraphrases are ranked for unseen target words, similarly as the models would rank paraphrases for any words (not necessarily contained in the dataset).", "labels": [], "entities": []}, {"text": "For algorithms with tunable parameters, we further divide the training sets into a training and a validation part to find the best parameter settings.", "labels": [], "entities": []}, {"text": "For evaluation, we use Generalized Average Precision (GAP) () and Precision at 1 (P@1), i.e., the percentage of correct paraphrases at rank 1.", "labels": [], "entities": [{"text": "Generalized Average Precision (GAP)", "start_pos": 23, "end_pos": 58, "type": "METRIC", "confidence": 0.9376050432523092}, {"text": "Precision at 1 (P@1)", "start_pos": 66, "end_pos": 86, "type": "METRIC", "confidence": 0.7953295037150383}]}, {"text": "In all experiments, we used the features described in, implemented precisely as proposed by the original work.", "labels": [], "entities": []}, {"text": "Each (sentence, target word, substitution) triplet represents an instance, and the feature values are computed from the sentence context, the target word and the substitution word.", "labels": [], "entities": []}, {"text": "The features used fall into four major categories.", "labels": [], "entities": []}, {"text": "The most important features describe the syntagmatic coherence of the substitution in context, measured as local n-gram frequencies obtained from web data.", "labels": [], "entities": []}, {"text": "The frequency fora 1-5gram context with the substitution word is computed and normalized with respect to either 1) the frequency of the original context (with the target word) or 2) the sum of frequencies observed for all possible substitutions.", "labels": [], "entities": []}, {"text": "A third feature computes similar frequencies for the substitution and the target word observed in the local context (as part of a conjunctive phrase).", "labels": [], "entities": []}, {"text": "A second group of features describe the (nonpositional, i.e. non-local) distributional similarity of the target and its candidate substitution in terms of sentence level co-occurrence statistics collected from newspaper texts: 1) How many words from the sentence appear in the top 1000 salient words listed for the candidate substitution in a distributional thesaurus, 2) how similar the top K salient words lists are for the candidate and the target word, 3) how similar the 2nd order distributional profiles are for candidate and target, etc.", "labels": [], "entities": []}, {"text": "All these features are carefully normalized so that values compare well accross different words and contexts.", "labels": [], "entities": []}, {"text": "Another set of features capture the properties of the target and candidate word in WordNet, such as their 1) number of senses, 2) how frequent senses are synonymous and 3) the lowest common ancestor (and all synsets up) for the candidate and target word in the WordNet hierarchy (represented as a nominal feature, by the ID of these synsets).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.9689568281173706}]}, {"text": "Lastly a group of features capture shallow syntactic patterns of the target word and its local context in the form of 1) part of speech patterns (trigrams) in a sliding window around the target word using main POS categories, i.e. only the first letter of the Penn Treebank codes, and 2) the detailed POS code of the candidate word assigned by a POS tagger.", "labels": [], "entities": [{"text": "Penn Treebank codes", "start_pos": 260, "end_pos": 279, "type": "DATASET", "confidence": 0.9887334307034811}]}, {"text": "We omit a mathematically precise description of these features for space reasons and refer the reader to fora more formal and detailed description of the feature functions.", "labels": [], "entities": []}, {"text": "Importantly, these delexicalized features are numerically comparable across the different target words and candidate substitutions they are computed from.", "labels": [], "entities": []}, {"text": "This property enables the models to generalize over the words in the datasets and thus enables a supervised, all-words lexical substitution system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: GAP and p@1 values, with significant improve- ments over the performance of MaxEnt marked in bold.", "labels": [], "entities": [{"text": "GAP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8733382821083069}, {"text": "improve- ments", "start_pos": 47, "end_pos": 61, "type": "METRIC", "confidence": 0.9033886790275574}, {"text": "MaxEnt", "start_pos": 86, "end_pos": 92, "type": "DATASET", "confidence": 0.8930267095565796}]}, {"text": " Table 2: Comparison to previous studies (dataset LexSub,  candidates Gold).", "labels": [], "entities": [{"text": "LexSub", "start_pos": 50, "end_pos": 56, "type": "DATASET", "confidence": 0.832317590713501}]}]}