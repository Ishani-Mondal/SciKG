{"title": [{"text": "Online Learning for Inexact Hypergraph Search", "labels": [], "entities": []}], "abstractContent": [{"text": "Online learning algorithms like the percep-tron are widely used for structured prediction tasks.", "labels": [], "entities": [{"text": "structured prediction tasks", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.712806781133016}]}, {"text": "For sequential search problems, like left-to-right tagging and parsing, beam search has been successfully combined with perceptron variants that accommodate search errors (Collins and Roark, 2004; Huang et al., 2012).", "labels": [], "entities": [{"text": "parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9247382879257202}]}, {"text": "However, perceptron training with inexact search is less studied for bottom-up parsing and, more generally, inference over hypergraphs.", "labels": [], "entities": [{"text": "bottom-up parsing", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.5645476877689362}]}, {"text": "In this paper, we generalize the violation-fixing perceptron of Huang et al.", "labels": [], "entities": []}, {"text": "(2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012).", "labels": [], "entities": []}, {"text": "This results in the highest reported scores on WSJ evaluation set (UAS 93.50% and LAS 92.41% respectively) without the aid of additional resources.", "labels": [], "entities": [{"text": "WSJ evaluation set", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.9075516661008199}, {"text": "UAS 93.50", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.5988011658191681}, {"text": "LAS", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9800798296928406}]}], "introductionContent": [{"text": "Structured prediction problems generally deal with exponentially many outputs, often making exact search infeasible.", "labels": [], "entities": [{"text": "Structured prediction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8774756491184235}]}, {"text": "For sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown to be a powerful combination ().", "labels": [], "entities": [{"text": "tagging", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9761254191398621}]}, {"text": "However, sequential search algorithms, and in particular left-to-right beam search (, squeeze inference into a very narrow space.", "labels": [], "entities": []}, {"text": "To address this, formulated constituency parsing as approximate bottom-up inference in order to compactly represent an exponential number of outputs while scoring features of arbitrary scope.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.9079113602638245}]}, {"text": "This idea was adapted to graph-based dependency parsers by and shown to outperform left-to-right beam search.", "labels": [], "entities": []}, {"text": "Both these examples, bottom-up approximate dependency and constituency parsing, can be viewed as specific instances of inexact hypergraph search.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.8467491269111633}]}, {"text": "Typically, the approximation is accomplished by cube-pruning throughout the hypergraph.", "labels": [], "entities": []}, {"text": "Unfortunately, as the scope of features at each node increases, the inexactness of search and its negative impact on learning can potentially be exacerbated.", "labels": [], "entities": []}, {"text": "Unlike sequential search, the impact on learning of approximate hypergraph search -as well as methods to mitigate any ill effects -has not been studied.", "labels": [], "entities": []}, {"text": "Motivated by this, we develop online learning algorithms for inexact hypergraph search by generalizing the violation-fixing percepron of.", "labels": [], "entities": [{"text": "hypergraph search", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.707048237323761}]}, {"text": "We empirically validate the benefit of this approach within the cube-pruning dependency parser of.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran a number of experiments on the cubepruning dependency parser of, whose search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the Eisner algorithm.", "labels": [], "entities": [{"text": "cubepruning dependency parser", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.6615347663561503}]}, {"text": "The feature templates we used area superset of.", "labels": [], "entities": []}, {"text": "These features include first-, second-, and third-order features and their labeled counterparts, as well as valency features.", "labels": [], "entities": []}, {"text": "In addition, we also included a feature template from.", "labels": [], "entities": []}, {"text": "This template examines the leftmost child and the rightmost child of a modifier simultaneously.", "labels": [], "entities": []}, {"text": "All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head.", "labels": [], "entities": []}, {"text": "We trained the parser with hamming-loss-augmented MIRA), following.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.8691065907478333}]}, {"text": "Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used abeam of size 6 per node.", "labels": [], "entities": [{"text": "English validation data", "start_pos": 24, "end_pos": 47, "type": "DATASET", "confidence": 0.6891041894753774}, {"text": "MIRA", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.7114761471748352}]}, {"text": "To speedup the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time ().", "labels": [], "entities": []}, {"text": "We followed to train the first-order model to minimize filter loss with respect to max-marginal filtering.", "labels": [], "entities": []}, {"text": "On the English validation corpus, the filtering model pruned 80% of arcs while keeping the oracle unlabeled attachment score above 99.50%.", "labels": [], "entities": [{"text": "English validation corpus", "start_pos": 7, "end_pos": 32, "type": "DATASET", "confidence": 0.8546340068181356}]}, {"text": "During training only, we insert the gold tree into the hypergraph if it was mistakenly pruned.", "labels": [], "entities": []}, {"text": "This ensures that the gold nodes are always available, which is required for model updates.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parsing results on test sets of the Penn Treebank and CTB-5. UAS and LAS are measured on all tokens except  punctuations. We also include the tokens per second numbers for different parsers whenever available, although the  numbers from other papers were obtained on different machines. Speed numbers marked with  \u2020 were converted from  sentences per second.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9948220252990723}, {"text": "UAS", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.996954083442688}, {"text": "LAS", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9915453791618347}]}, {"text": " Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years,  we use the 2006 data set. The best results with  \u2020 are the maximum in the following papers: Buchholz and Marsi  (2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For  consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is  our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011  reimplementation and different update strategies from this paper.", "labels": [], "entities": [{"text": "CoNLL 2006/2007 shared tasks", "start_pos": 45, "end_pos": 73, "type": "DATASET", "confidence": 0.8709865907828013}, {"text": "CoNLL 2006 evaluation script", "start_pos": 394, "end_pos": 422, "type": "DATASET", "confidence": 0.9108627885580063}]}]}