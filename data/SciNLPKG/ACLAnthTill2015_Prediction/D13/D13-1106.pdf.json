{"title": [{"text": "Joint Language and Translation Modeling with Recurrent Neural Networks", "labels": [], "entities": [{"text": "Joint Language and Translation Modeling", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6249364674091339}]}], "abstractContent": [{"text": "We present a joint language and translation model based on a recurrent neural network which predicts target words based on an unbounded history of both source and target words.", "labels": [], "entities": []}, {"text": "The weaker independence assumptions of this model result in a vastly larger search space compared to related feed-forward-based language or translation models.", "labels": [], "entities": []}, {"text": "We tackle this issue with anew lattice rescor-ing algorithm and demonstrate its effectiveness empirically.", "labels": [], "entities": []}, {"text": "Our joint model builds on a well known recurrent neural network language model (Mikolov, 2012) augmented by a layer of additional inputs from the source language.", "labels": [], "entities": []}, {"text": "We show competitive accuracy compared to the traditional channel model features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9875534772872925}]}, {"text": "Our best results improve the output of a system trained on WMT 2012 French-English data by up to 1.5 BLEU, and by 1.1 BLEU on average across several test sets.", "labels": [], "entities": [{"text": "WMT 2012 French-English data", "start_pos": 59, "end_pos": 87, "type": "DATASET", "confidence": 0.9363533407449722}, {"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9992790818214417}, {"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.99828040599823}]}], "introductionContent": [{"text": "Recently, several feed-forward neural networkbased language and translation models have achieved impressive accuracy improvements on statistical machine translation tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9982798099517822}, {"text": "statistical machine translation tasks", "start_pos": 133, "end_pos": 170, "type": "TASK", "confidence": 0.7174670100212097}]}, {"text": "In this paper we focus on recurrent neural network architectures, which have recently advanced the state of the art in language modeling (, outperforming multi-layer feed-forward based networks in both perplexity and word error rate in speech recognition ().", "labels": [], "entities": [{"text": "language modeling", "start_pos": 119, "end_pos": 136, "type": "TASK", "confidence": 0.7221802771091461}, {"text": "speech recognition", "start_pos": 236, "end_pos": 254, "type": "TASK", "confidence": 0.6684142500162125}]}, {"text": "The major attraction of recurrent architectures is their potential to capture long-span dependencies since predictions are based on an unbounded history of previous words.", "labels": [], "entities": []}, {"text": "This is in contrast to feed-forward networks as well as conventional n-gram models, both of which are limited to fixed-length contexts.", "labels": [], "entities": []}, {"text": "Building on the success of recurrent architectures, we base our joint language and translation model on an extension of the recurrent neural network language model) that introduces a layer of additional inputs ( \u00a72).", "labels": [], "entities": []}, {"text": "Most previous work on neural networks for speech recognition or machine translation used a rescoring setup based on n-best lists () for evaluation, thereby sidestepping the algorithmic and engineering challenges of direct decoder-integration.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7436657547950745}, {"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.6951594203710556}]}, {"text": "Instead, we exploit lattices, which offer a much richer representation of the decoder output, since they compactly encode an exponential number of translation hypotheses in polynomial space.", "labels": [], "entities": []}, {"text": "In contrast, n-best lists are typically very redundant, representing only a few combinations of top scoring arcs in the lattice.", "labels": [], "entities": []}, {"text": "A major challenge in lattice rescoring with a recurrent neural network model is the effect of the unbounded history on search since the usual dynamic programming assumptions which are exploited for efficiency do not holdup anymore.", "labels": [], "entities": [{"text": "lattice rescoring", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7438603043556213}]}, {"text": "We apply a novel algorithm to the task of rescoring with an unbounded language model and empirically demonstrate its effectiveness ( \u00a73).", "labels": [], "entities": []}, {"text": "The algorithm proves robust, leading to significant improvements with the recurrent neural network language model over a competitive n-gram baseline across several language pairs.", "labels": [], "entities": []}, {"text": "We even observe consistent gains when pairing the model with a large n-gram model trained on up to 575 times more data, demonstrating that the model provides complementary information ( \u00a74).", "labels": [], "entities": []}, {"text": "Our joint modeling approach is based on adding a continuous space representation of the foreign sentence as an additional input to the recurrent neural network language model.", "labels": [], "entities": []}, {"text": "With this extension, the language model can measure the consistency between the source and target words in a contextsensitive way.", "labels": [], "entities": []}, {"text": "The model effectively combines the functionality of both the traditional channel and language model features.", "labels": [], "entities": []}, {"text": "We test the power of this new model by using it as the only source of traditional channel information.", "labels": [], "entities": []}, {"text": "Overall, we find that the model achieves accuracy competitive with the older channel model features and that it can improve over the gains observed with the recurrent neural network language model ( \u00a75).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9992771744728088}]}], "datasetContent": [{"text": "Recurrent neural network language models have previously only been used in n-best rescoring settings and on small-scale tasks with baseline language models trained on only 17.5m words.", "labels": [], "entities": []}, {"text": "We extend this work by experimenting on lattices using strong baselines with ngram models trained on over one billion words and by evaluating on a number of language pairs.", "labels": [], "entities": []}, {"text": "We experiment with an in-house phrasebased system similar to Moses (, scoring translations by a set of common features including maximum likelihood estimates of source given target mappings p M LE (e|f ) and vice versa p M LE (f |e), as well as lexical weighting estimates p LW (e|f ) and p LW (f |e), word and phrasepenalties, a linear distortion feature and a lexicalized reordering feature.", "labels": [], "entities": []}, {"text": "Log-linear weights are estimated with minimum error rate training.", "labels": [], "entities": []}, {"text": "We use training and test data from the WMT 2012 campaign and report results on French-English, German-English and EnglishGerman.", "labels": [], "entities": [{"text": "WMT 2012 campaign", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.724383552869161}]}, {"text": "Translation models are estimated on 102m words of parallel data for French-English, 91m words for German-English and English-German; between 3.5-5m words are newswire, depending on the language pair, and the remainder are parliamentary proceedings.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9478650689125061}]}, {"text": "The baseline systems use two 5-gram modified Kneser-Ney language models; the first is estimated on the target-side of the parallel data, while the second is based on a large newswire corpus released as part of the WMT campaign.", "labels": [], "entities": [{"text": "WMT campaign", "start_pos": 214, "end_pos": 226, "type": "DATASET", "confidence": 0.6902278065681458}]}, {"text": "For FrenchEnglish and German-English we use a language model based on 1.15bn words, and for EnglishGerman we train a model on 327m words.", "labels": [], "entities": []}, {"text": "We evaluate on the newswire test sets from 2010-2011 containing between 2034-3003 sentences.", "labels": [], "entities": [{"text": "newswire test sets from 2010-2011", "start_pos": 19, "end_pos": 52, "type": "DATASET", "confidence": 0.9533401727676392}]}, {"text": "Log-linear weights are estimated on the 2009 data set comprising 2525 sentences.", "labels": [], "entities": [{"text": "2009 data set", "start_pos": 40, "end_pos": 53, "type": "DATASET", "confidence": 0.8674470782279968}]}, {"text": "We rescore the lattices produced by the baseline systems with an aggressive but effective context beam of k = 1 that did not harm accuracy in preliminary experiments ( \u00a73).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9987245202064514}]}, {"text": "The vocabularies of the language models are comprised of the words in the training set after removing singletons.", "labels": [], "entities": []}, {"text": "We obtain word-classes using aversion of Brown-Clustering with an additional regularization term to optimize the runtime of the language model ().", "labels": [], "entities": []}, {"text": "Direct connections use maximum entropy features over unigrams, bigrams and trigrams ( ).", "labels": [], "entities": []}, {"text": "We use the standard settings for the model with the default learning rate \u03b1 = 0.1 that decays exponentially if the validation set entropy does not increase after each epoch.", "labels": [], "entities": []}, {"text": "Back propagation through time computes error gradients over the past twenty time steps.", "labels": [], "entities": []}, {"text": "Training is stopped after 20 epochs or when the validation entropy does not decrease over two epochs.", "labels": [], "entities": [{"text": "validation entropy", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8601637184619904}]}, {"text": "We experiment with varying training data sizes and randomly draw the data from the same corpora used for the baseline systems.", "labels": [], "entities": []}, {"text": "Throughout, we use a hidden layer size of 100 which provided a good trade-off between time and accuracy in initial experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9974609613418579}]}, {"text": "In the next set of experiments, we turn to the joint language and translation model, an extension of the recurrent neural network language model with additional inputs for the foreign sentence.", "labels": [], "entities": []}, {"text": "We first introduce two continuous space representations of the foreign sentence ( \u00a75.1).", "labels": [], "entities": []}, {"text": "Using these representations we evaluate the accuracy of the joint model in the lattice rescoring setup and compare against the traditional translation channel model features ( \u00a75.2    train a transform between the source words and the reference representations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9995391368865967}]}, {"text": "This leads to the best results improving 1.5 BLEU over the 1-best decoder output and adding 0.2 BLEU on average to the gains achieved by the recurrent language model ( \u00a75.4).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.997217059135437}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9976873397827148}]}, {"text": "Conventional language models can be trained on monolingual or bilingual data; however, the joint model can only be trained on the latter.", "labels": [], "entities": []}, {"text": "In order to control for data size effects, we restrict training of all models, including the baseline n-gram model, to the target side of the parallel corpus, about 102m words for French-English.", "labels": [], "entities": []}, {"text": "Furthermore we train recurrent models only on the newswire portion (about 3.5m words for training and 250k words for validation) since initial experiments showed comparable results to using the full parallel corpus, available to the baseline.", "labels": [], "entities": []}, {"text": "This is reasonable since the test data is newswire.", "labels": [], "entities": []}, {"text": "Also, it allows for more rapid experimentation.", "labels": [], "entities": []}, {"text": "The previous section examined the effect of a set of basic foreign sentence representations.", "labels": [], "entities": []}, {"text": "Although we find some benefit from these representations, the differences are not large.", "labels": [], "entities": []}, {"text": "One might naturally ask whether there is greater potential upside from this channel model.", "labels": [], "entities": []}, {"text": "Therefore we turn to measuring the upper bound on accuracy for the joint approach as a whole.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9996517896652222}]}, {"text": "Specifically, we would like to find abound on accuracy given an ideal representation of the source sentence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.998958945274353}]}, {"text": "To answer this question, we conducted an experiment where the joint model has access to an LSA representation of the reference translation.", "labels": [], "entities": []}, {"text": "shows that the joint approach has an oracle accuracy of up to 4.3 BLEU above the baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9721022844314575}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9986500144004822}]}, {"text": "This clearly confirms that the joint approach can exploit the additional information to improve BLEU, given a good enough representation of the foreign sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.998759388923645}]}, {"text": "In terms of perplexity, we see an improvement of up to 65% over the target-only model.", "labels": [], "entities": []}, {"text": "It should be noted that since LSA representations are computed on reference words, perplexity no longer has its standard meaning.", "labels": [], "entities": []}, {"text": "29.5 76: Oracle accuracy of the joint model when using an LSA encoding of the references, measured on the news2011 French-English task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9959651231765747}, {"text": "news2011 French-English task", "start_pos": 106, "end_pos": 134, "type": "DATASET", "confidence": 0.8684482971827189}]}], "tableCaptions": [{"text": " Table 1: Rescoring n-best lists and lattices with various  language model beam widths k. Accuracy is based on  the news2011 French-English task. Timing results are in  addition to the baseline.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9991825222969055}]}, {"text": " Table 2: French-English results when rescoring with the recurrent neural network language model; the baseline relies  on an n-gram model trained on 1.15bn words.", "labels": [], "entities": []}, {"text": " Table 3: German-English results when rescoring with the recurrent neural network language model.", "labels": [], "entities": []}, {"text": " Table 4: English-German results when rescoring with the recurrent neural network language model; the baseline relies  on an n-gram model trained on 327m words.", "labels": [], "entities": []}, {"text": " Table 5: Translation accuracy of the joint model with various encodings of the foreign sentence measured on the  French-English task. Perplexity (PPL) is based on news2011.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9396455883979797}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9219865798950195}, {"text": ". Perplexity (PPL)", "start_pos": 133, "end_pos": 151, "type": "METRIC", "confidence": 0.8802889108657836}]}, {"text": " Table 7: Oracle accuracy of the joint model when us- ing an LSA encoding of the references, measured on the  news2011 French-English task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9959073066711426}, {"text": "news2011 French-English task", "start_pos": 110, "end_pos": 138, "type": "DATASET", "confidence": 0.8840221563975016}]}, {"text": " Table 8: Translation accuracy of the joint model with a source-target transform, measured on the French-English task.  Perplexity (PPL) is based on news2011; differences to target-only are significant at the p < 0.001 level.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9479730725288391}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9050673842430115}, {"text": ".  Perplexity (PPL)", "start_pos": 117, "end_pos": 136, "type": "METRIC", "confidence": 0.8341171383857727}]}]}