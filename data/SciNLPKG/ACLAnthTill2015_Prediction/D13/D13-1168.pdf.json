{"title": [{"text": "A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew language pair agnostic approach to inducing bilingual vector spaces from non-parallel data without any other resource in a bootstrapping fashion.", "labels": [], "entities": []}, {"text": "The paper systematically introduces and describes all key elements of the bootstrapping procedure: (1) starting point or seed lexicon, (2) the confidence estimation and selection of new dimensions of the space, and (3) convergence.", "labels": [], "entities": [{"text": "convergence", "start_pos": 219, "end_pos": 230, "type": "METRIC", "confidence": 0.9562945365905762}]}, {"text": "We test the quality of the induced bilingual vector spaces, and analyze the influence of the different components of the bootstrapping approach in the task of bilingual lexicon extraction (BLE) for two language pairs.", "labels": [], "entities": [{"text": "bilingual lexicon extraction (BLE)", "start_pos": 159, "end_pos": 193, "type": "TASK", "confidence": 0.7699946661790212}]}, {"text": "Results reveal that, contrary to conclusions from prior work, the seeding of the bootstrapping process has a heavy impact on the quality of the learned lexicons.", "labels": [], "entities": []}, {"text": "We also show that our approach outperforms the best performing fully corpus-based BLE methods on these test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bilingual lexicons serve as an indispensable source of knowledge for various cross-lingual tasks such as cross-lingual information retrieval () or statistical machine translation.", "labels": [], "entities": [{"text": "cross-lingual information retrieval", "start_pos": 105, "end_pos": 140, "type": "TASK", "confidence": 0.6423855622609457}, {"text": "statistical machine translation", "start_pos": 147, "end_pos": 178, "type": "TASK", "confidence": 0.7467430432637533}]}, {"text": "Additionally, they area crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language maybe transferred to another.", "labels": [], "entities": [{"text": "cross-lingual knowledge transfer", "start_pos": 45, "end_pos": 77, "type": "TASK", "confidence": 0.7166021863619486}]}, {"text": "The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling), parsing), POS tagging (), etc.", "labels": [], "entities": [{"text": "transfer or annotation projection", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.6818203404545784}, {"text": "semantic role labeling", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.6539409955342611}, {"text": "parsing", "start_pos": 158, "end_pos": 165, "type": "TASK", "confidence": 0.9708526730537415}, {"text": "POS tagging", "start_pos": 168, "end_pos": 179, "type": "TASK", "confidence": 0.8606283962726593}]}, {"text": "Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established.", "labels": [], "entities": [{"text": "automatic bilingual lexicon extraction (BLE)", "start_pos": 15, "end_pos": 59, "type": "TASK", "confidence": 0.6856142835957664}, {"text": "word alignment", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.6906895190477371}]}, {"text": "However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g.,;).", "labels": [], "entities": []}, {"text": "The models that rely on non-parallel data typically represent each word by a high-dimensional vector in a feature vector space, where the dimensions of the vector are its context features.", "labels": [], "entities": []}, {"text": "The context features are typically words co-occurring with the word in a predefined context.", "labels": [], "entities": []}, {"text": "The similarity of two words, w S 1 given in the source language L S with vocabulary V Sand w T 2 in the target language L T with vocabulary VT is then computed as sim(w S 1 , w T 2 ) = SF (cv(w S 1 ), cv(w T 2 )).", "labels": [], "entities": []}, {"text": "cv(w S 1 ) = [sc S 1 (c 1 ), . .", "labels": [], "entities": []}, {"text": ", sc S 1 (c N )] is a context vector for w S 1 with N context features ck , where sc S 1 (c k ) denotes the score for w S 1 associated with context feature ck (similar for w T 2 ).", "labels": [], "entities": []}, {"text": "SF is a similarity function (e.g., cosine, the Kullback-Leibler divergence, the Jaccard index) operating on the context vectors).", "labels": [], "entities": []}, {"text": "When operating with 2 languages, the context features cannot be compared directly.", "labels": [], "entities": []}, {"text": "Therefore, in order to compare the feature vectors cv(w S 1 ) and cv(w T 2 ), the context features need to span a shared bilingual vector space.", "labels": [], "entities": []}, {"text": "The standard way of building a bilingual vector space is to use bilingual lexicon entries) as dimensions of the space.", "labels": [], "entities": []}, {"text": "However, there seems to bean apparent flaw in logic, since the methods assume that there exist readily available bilingual lexicons that are then used to induce bilingual lexicons!", "labels": [], "entities": []}, {"text": "Therefore, the focus of the researchers has turned to designing BLE methods that do not rely on any external translation resources such as machine-readable bilingual lexicons and parallel corpora ().", "labels": [], "entities": [{"text": "BLE", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.7595553994178772}]}, {"text": "In order to circumvent this issue, one line of recent work aims to bootstrap high-quality bilingual vector spaces from a small initial seed lexicon.", "labels": [], "entities": []}, {"text": "The seed lexicon is constructed by harvesting identical or similarly spelled words across languages (, and it spans the initial bilingual vector space.", "labels": [], "entities": []}, {"text": "The space is then gradually enriched with new dimensions/axes during the bootstrapping procedure.", "labels": [], "entities": []}, {"text": "The bootstrapping process has already proven its validity in inducing bilingual lexicons for closely similar languages such as Spanish-Portuguese or Croatian-Slovene), but it still lacks further generalization to more distant language pairs.", "labels": [], "entities": []}, {"text": "The main goal of this paper is to shed new light on the bootstrapping approaches to bilingual lexicon extraction, and to construct a language pair agnostic bootstrapping method that is able to build highquality bilingual vector spaces that consequently lead to high-quality bilingual lexicons for more distant language pairs where orthographic similarity is not sufficient to seed bilingual vector spaces.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.6917244791984558}]}, {"text": "We aim to answer the following key questions: \u2022 How to seed bilingual vector spaces besides using only orthographically similar words?", "labels": [], "entities": []}, {"text": "\u2022 Is it better to seed bilingual spaces with translation pairs/dimensions that are frequent in the corpus, and does the frequency matter at all?", "labels": [], "entities": []}, {"text": "Does the size of the initial seed lexicon matter?", "labels": [], "entities": []}, {"text": "\u2022 How to enrich bilingual vector spaces with only highly reliable dimensions in order to prevent semantic drift?", "labels": [], "entities": [{"text": "semantic drift", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.7898561060428619}]}, {"text": "With respect to these questions, the main contributions of this article are: \u2022 We present a complete overview of the framework of bootstrapping bilingual vector spaces from non-parallel data without any additional resources.", "labels": [], "entities": []}, {"text": "We dissect the bootstrapping process and describe all its key components.", "labels": [], "entities": []}, {"text": "\u2022 We introduce anew way of seeding the bootstrapping procedure that does not rely on any orthographic clues and that yields bilingual vector spaces of higher quality.", "labels": [], "entities": []}, {"text": "We analyze the impact of different seed lexicons on the quality of induced bilingual vector spaces.", "labels": [], "entities": []}, {"text": "\u2022 We show that in the setting without any external translation resources, our bootstrapping approach yields lexicons that outperform the best performing corpus-based BLE methods on standard test datasets for 2 language pairs.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: ES-EN: Results with different sizes of the seed lexicon. The number in the parentheses denotes the number  of dimensions in the bilingual space after the bootstrapping procedure converges. The seeding method is SEED-RB.", "labels": [], "entities": [{"text": "ES-EN", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8753986358642578}, {"text": "SEED-RB", "start_pos": 221, "end_pos": 228, "type": "METRIC", "confidence": 0.8531659245491028}]}, {"text": " Table 2: IT-EN: Results with different sizes of the seed lexicon. The number in the parentheses denotes the number of  dimensions in the bilingual space after the bootstrapping procedure converges. The seeding method is SEED-RB.", "labels": [], "entities": [{"text": "SEED-RB", "start_pos": 221, "end_pos": 228, "type": "METRIC", "confidence": 0.8580157160758972}]}]}