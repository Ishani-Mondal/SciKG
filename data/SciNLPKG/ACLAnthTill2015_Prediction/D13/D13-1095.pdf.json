{"title": [{"text": "Japanese Zero Reference Resolution Considering Exophora and Author/Reader Mentions", "labels": [], "entities": [{"text": "Japanese Zero Reference Resolution", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7310895025730133}]}], "abstractContent": [{"text": "In Japanese, zero references often occur and many of them are categorized into zero ex-ophora, in which a referent is not mentioned in the document.", "labels": [], "entities": []}, {"text": "However, previous studies have focused on only zero endophora, in which a referent explicitly appears.", "labels": [], "entities": []}, {"text": "We present a zero reference resolution model considering zero exophora and author/reader of a document.", "labels": [], "entities": []}, {"text": "To deal with zero exophora, our model adds pseudo entities corresponding to zero exophora to candidate referents of zero pronouns.", "labels": [], "entities": []}, {"text": "In addition, we automatically detect mentions that refer to the author and reader of a document by using lexico-syntactic patterns.", "labels": [], "entities": []}, {"text": "We represent their particular behavior in a discourse as a feature vector of a machine learning model.", "labels": [], "entities": []}, {"text": "The experimental results demonstrate the effectiveness of our model for not only zero exophora but also zero endophora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Zero reference resolution is the task of detecting and identifying omitted arguments of a predicate.", "labels": [], "entities": [{"text": "Zero reference resolution", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6474276582400004}, {"text": "detecting and identifying omitted arguments of a predicate", "start_pos": 41, "end_pos": 99, "type": "TASK", "confidence": 0.706862285733223}]}, {"text": "Since the arguments are often omitted in Japanese, zero reference resolution is essential in a wide range of Japanese natural language processing (NLP) applications such as information retrieval and machine translation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 173, "end_pos": 194, "type": "TASK", "confidence": 0.8061285614967346}, {"text": "machine translation", "start_pos": 199, "end_pos": 218, "type": "TASK", "confidence": 0.7945951223373413}]}, {"text": "For example, in example (1) , the accusative argument of the predicate \"\" (eat) is omitted . The omitted argument is called a zero pronoun.", "labels": [], "entities": []}, {"text": "In this example, the zero pronoun refers to \"\" (pasta).", "labels": [], "entities": []}, {"text": "Zero reference resolution is divided into two subtasks: zero pronoun detection and referent identification.", "labels": [], "entities": [{"text": "Zero reference resolution", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7234064936637878}, {"text": "zero pronoun detection", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.6679844657580057}, {"text": "referent identification", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.8198375403881073}]}, {"text": "Zero pronoun detection is the task that detects omitted zero pronouns from a document.", "labels": [], "entities": [{"text": "Zero pronoun detection", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6762780944506327}]}, {"text": "In example (1), this task detects that there are the zero pronouns in the accusative and nominative cases of \"\" (eat) and there is no zero pronoun in the dative case of \"\".", "labels": [], "entities": []}, {"text": "Referent identification is the task that identifies the referent of a zero pronoun.", "labels": [], "entities": [{"text": "Referent identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8795100748538971}]}, {"text": "In example (1), this task identifies that the referent of the zero pronoun in the accusative case of \"\" is \"\" (pasta).", "labels": [], "entities": []}, {"text": "These two subtasks are often resolved simultaneously and our proposed model is a unified model.", "labels": [], "entities": []}, {"text": "Many previous studies) have treated only zero endophora, which is a phenomenon that a referent is mentioned in a document, such as \"\" (pasta) in example (1).", "labels": [], "entities": []}, {"text": "However, zero exophora, which is a phenomenon that a referent does not appear in a document, often occurs in Japanese when a referent is an author or reader of a document or an indefinite pronoun.", "labels": [], "entities": []}, {"text": "For example, in example (1), the referent of the zero pronoun of the nominative case of \"\" (eat) is the author of  Similarly, in example (2), the referent of the zero pronoun of the nominative case of \"\" (can see) is an unspecified person.", "labels": [], "entities": []}, {"text": "Most previous studies have neglected zero exophora, as though a zero pronoun does not exist in a sentence.", "labels": [], "entities": []}, {"text": "However, such a rough approximation has impeded the zero reference resolution research.", "labels": [], "entities": [{"text": "zero reference resolution", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.5882565379142761}]}, {"text": "In, in \"zero exophora,\" the dative case of the predicate has the zero pronoun, but in \"no zero reference,\" the dative case of the predicate does not have a zero pronoun.", "labels": [], "entities": []}, {"text": "Treating them with no distinction causes a decrease inaccuracy of machine learning-based zero pronoun detection due to a gap between the valency of a predicate and observed arguments of the predicate.", "labels": [], "entities": [{"text": "machine learning-based zero pronoun detection", "start_pos": 66, "end_pos": 111, "type": "TASK", "confidence": 0.6484073221683502}]}, {"text": "In this work, to deal with zero exophora explicitly, we provide pseudo entities such as, and as candidate referents of zero pronouns.", "labels": [], "entities": []}, {"text": "In the referent identification, selectional preferences of a predicate () and contextual information () have been widely used.", "labels": [], "entities": [{"text": "referent identification", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8506346344947815}]}, {"text": "The author and reader (A/R) of a document have not been used for contextual clues because the A/R rarely appear in the discourse in corpora based on newspaper articles, which are main targets of the previous studies.", "labels": [], "entities": []}, {"text": "However, in other domain documents such as blog articles and shopping sites, the A/R often appear in the discourse.", "labels": [], "entities": [{"text": "A/R", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.8706212043762207}]}, {"text": "The A/R tend to be omitted and there are many clues for the referent identification about the A/R such as honorific expressions and modality expressions.", "labels": [], "entities": []}, {"text": "Therefore, it is important to deal with the A/R of a document explicitly for the referent identification.", "labels": [], "entities": [{"text": "A/R", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.8944851557413737}, {"text": "referent identification", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.7632983028888702}]}, {"text": "The A/R appear as not only the exophora but also the endophora.", "labels": [], "entities": []}, {"text": "In example (3), \"\" (I), which is explicitly mentioned in the document, is the author of the document and \"\" (you all) is the reader.", "labels": [], "entities": []}, {"text": "In this paper, we call these expressions, which refer to the author and reader, author mention and reader mention.", "labels": [], "entities": []}, {"text": "We treat them explicitly to improve the performance of zero reference resolution.", "labels": [], "entities": []}, {"text": "Since the A/R are mentioned as various expressions besides personal pronouns in Japanese, it is difficult to detect the A/R mentions based merely on lexical information.", "labels": [], "entities": []}, {"text": "In this work, we automatically detect the A/R mentions by using a learning-to-rank algorithm) that uses lexico-syntactic patterns as features.", "labels": [], "entities": []}, {"text": "Once the A/R mentions can be detected, their information is useful for the referent identification.", "labels": [], "entities": [{"text": "referent identification", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.8980239927768707}]}, {"text": "The A/R mentions have both a property of the discourse element mentioned in a document and a property of the zero exophoric A/R.", "labels": [], "entities": []}, {"text": "In the first sentence of example (3), it can be estimated that the referent of the zero pronoun of the nominative case of \" \" (will go) from a contextual clue that \"\" (I) is the topic of this sentence and a syntactic clues that \" \" (I) depends on \"\" (have thought) over the predicate \"\" (will go).", "labels": [], "entities": []}, {"text": "3 Such contextual clues can be available only for the discourse entities that are mentioned explicitly.", "labels": [], "entities": []}, {"text": "On the other hand, in the second sentence, since \" \" (let me know) is a request form, it can be assumed that the referent of the zero pronoun of the nominative case is \"\" (I), which is the author, and the one of the dative case is \"\" (you all), which is the reader.", "labels": [], "entities": []}, {"text": "The clues such as request forms, honorific expressions and modality expressions are available for the author and reader.", "labels": [], "entities": []}, {"text": "In this work, to represent such aspect of the A/R mentions, both the endophora and exophora features are given to them.", "labels": [], "entities": []}, {"text": "In this paper, we propose a zero reference resolution model considering the zero exophora and the author/reader mentions, which resolves the zero reference as apart of a predicate-argument structure analysis.", "labels": [], "entities": [{"text": "zero reference resolution", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.7224661111831665}]}], "datasetContent": [{"text": "We used 1,000 documents from DDLC and performed 5-fold cross-validation.", "labels": [], "entities": [{"text": "DDLC", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.9235569834709167}]}, {"text": "1,440 zero endophora and 1,935 zero exophora are annotated in these documents.", "labels": [], "entities": []}, {"text": "258 documens are annotated with author mentions and 105 documens are annotated with reader mentions.", "labels": [], "entities": []}, {"text": "We used gold-standard (manually annotated) morphemes, named entities, dependency structures and coreference relations to focus on the A/R detection and the zero reference resolution.", "labels": [], "entities": []}, {"text": "We used SV M rank7 for the learning-to-rank method of the A/R detection and the PAS analysis.   are given by the syntactic parser KNP.", "labels": [], "entities": [{"text": "A/R detection", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.5377387255430222}, {"text": "PAS analysis.", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.8626633584499359}]}], "tableCaptions": [{"text": " Table 6: Result of the author mention detection", "labels": [], "entities": []}, {"text": " Table 7: Result of the reader mention detection", "labels": [], "entities": []}, {"text": " Table 8: Results of zero endophora resolution", "labels": [], "entities": [{"text": "zero endophora resolution", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.6035428643226624}]}, {"text": " Table 9: Results of zero reference resolution", "labels": [], "entities": []}]}