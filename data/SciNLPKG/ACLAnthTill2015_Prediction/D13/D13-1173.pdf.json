{"title": [{"text": "Dependency-Based Decipherment for Resource-Limited Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7204213589429855}]}], "abstractContent": [{"text": "We introduce dependency relations into deciphering foreign languages and show that dependency relations help improve the state-of-the-art deciphering accuracy by over 500%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9912028312683105}]}, {"text": "We learn a translation lexicon from large amounts of genuinely nonparallel data with decipherment to improve a phrase-based machine translation system trained with limited parallel data.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 111, "end_pos": 143, "type": "TASK", "confidence": 0.6226001779238383}]}, {"text": "In experiments, we observe BLEU gains of 1.2 to 1.8 across three different test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9993100166320801}]}], "introductionContent": [{"text": "State-of-the-art machine translation (MT) systems apply statistical techniques to learn translation rules from large amounts of parallel data.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.877727746963501}]}, {"text": "However, parallel data is limited for many language pairs and domains.", "labels": [], "entities": []}, {"text": "In general, it is easier to obtain nonparallel data.", "labels": [], "entities": []}, {"text": "The ability to build a machine translation system using monolingual data could alleviate problems caused by insufficient parallel data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7270321846008301}]}, {"text": "Towards building a machine translation system without a parallel corpus, use nonparallel data to estimate parameters fora large scale MT system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7249490022659302}, {"text": "MT", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.979423463344574}]}, {"text": "Other work tries to learn full MT systems using only nonparallel data through decipherment (.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9812527298927307}]}, {"text": "However, the performance of such systems is poor compared with those trained with parallel data.", "labels": [], "entities": []}, {"text": "Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel corpora with nonparallel data.", "labels": [], "entities": []}, {"text": "successfully apply decipherment to learn a domain specific translation lexicon from monolingual data to improve out-ofdomain machine translation.", "labels": [], "entities": [{"text": "out-ofdomain machine translation", "start_pos": 112, "end_pos": 144, "type": "TASK", "confidence": 0.682641843954722}]}, {"text": "Although their approach works well for Spanish/French, they do not show whether their approach works for other language pairs.", "labels": [], "entities": []}, {"text": "Moreover, the nonparallel data used in their experiments is created from a parallel corpus.", "labels": [], "entities": []}, {"text": "Such highly comparable data is difficult to obtain in reality.", "labels": [], "entities": []}, {"text": "In this work, we improve previous work by using genuinely nonparallel data, and propose a framework to improve a machine translation system trained with a small amount of parallel data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.7659986615180969}]}, {"text": "As shown in, we use a lexicon learned from decipherment to improve translations of both observed and out-of-vocabulary (OOV) words.", "labels": [], "entities": []}, {"text": "The main contributions of this work are: \u2022 We extract bigrams based on dependency relations for decipherment, which improves the state-of-the-art deciphering accuracy by over 500%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9937036633491516}]}, {"text": "\u2022 We demonstrate how to improve translations of words observed in parallel data by using a translation lexicon obtained from large amounts of nonparallel data.", "labels": [], "entities": [{"text": "translations of words observed in parallel", "start_pos": 32, "end_pos": 74, "type": "TASK", "confidence": 0.8282603224118551}]}, {"text": "\u2022 We show that decipherment is able to find correct translations for OOV words.", "labels": [], "entities": []}, {"text": "\u2022 We use a translation lexicon learned by deciphering large amounts of nonparallel data to improve a phrase-based MT system trained with limited amounts of parallel data.", "labels": [], "entities": [{"text": "MT", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.868640661239624}]}, {"text": "In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9985462427139282}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Size of training, tuning, and testing data in num- ber of tokens", "labels": [], "entities": []}, {"text": " Table 4: Systems that use translation lexicons learned from decipherment show consistent improvement over the  baseline system across tuning and testing sets. The best system, Decipher-COMB, achieves as much as 1.8 BLEU  point gain on the 2010 news test set.", "labels": [], "entities": [{"text": "BLEU  point gain", "start_pos": 216, "end_pos": 232, "type": "METRIC", "confidence": 0.9733895659446716}, {"text": "2010 news test set", "start_pos": 240, "end_pos": 258, "type": "DATASET", "confidence": 0.8849712014198303}]}]}