{"title": [{"text": "Unsupervised Induction of Cross-lingual Semantic Relations", "labels": [], "entities": [{"text": "Unsupervised Induction of Cross-lingual Semantic Relations", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.5850569208463033}]}], "abstractContent": [{"text": "Creating a language-independent meaning representation would benefit many cross-lingual NLP tasks.", "labels": [], "entities": []}, {"text": "We introduce the first un-supervised approach to this problem, learning clusters of semantically equivalent English and French relations between referring expressions , based on their named-entity arguments in large monolingual corpora.", "labels": [], "entities": []}, {"text": "The clusters can be used as language-independent semantic relations, by mapping clustered expressions in different languages onto the same relation.", "labels": [], "entities": []}, {"text": "Our approach needs no parallel text for training , but outperforms a baseline that uses machine translation on a cross-lingual question answering task.", "labels": [], "entities": [{"text": "cross-lingual question answering task", "start_pos": 113, "end_pos": 150, "type": "TASK", "confidence": 0.693631611764431}]}, {"text": "We also show how to use the semantics to improve the accuracy of machine translation, by using it in a simple reranker.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9979945421218872}, {"text": "machine translation", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7066640704870224}]}], "introductionContent": [{"text": "Identifying a language-independent semantics is a major long term goal of computational linguistics, and is interesting both theoretically and for practical applications.", "labels": [], "entities": [{"text": "Identifying a language-independent semantics", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7864671051502228}, {"text": "computational linguistics", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.73673415184021}]}, {"text": "It assumes that semantically equivalent sentences in any language can be mapped onto a common meaning representation.", "labels": [], "entities": []}, {"text": "Such a representation would be of great utility for tasks such as translation, relation extraction, summarization, question answering, and information retrieval.", "labels": [], "entities": [{"text": "translation", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.9804279208183289}, {"text": "relation extraction", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8315203487873077}, {"text": "summarization", "start_pos": 100, "end_pos": 113, "type": "TASK", "confidence": 0.9880545735359192}, {"text": "question answering", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.8815986216068268}, {"text": "information retrieval", "start_pos": 139, "end_pos": 160, "type": "TASK", "confidence": 0.8277886211872101}]}, {"text": "Regardless of whether it is even possible to create such a semantics, we show that an incomplete version can be useful for downstream tasks.", "labels": [], "entities": []}, {"text": "Semantic machine translation aims to map a source language to a language-independent meaning representation, and then generate the target language translation from this.", "labels": [], "entities": [{"text": "Semantic machine translation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6657744844754537}]}, {"text": "It is hoped this would alleviate the difficulties of simpler models when translating between languages with very different word ordering and syntax.", "labels": [], "entities": []}, {"text": "Despite many attempts to define interlingual representations, state-of-the-art machine translation still uses phrase-based models (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7251185178756714}]}, {"text": "The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express ().", "labels": [], "entities": []}, {"text": "Our approach avoids this problem by utilizing the methods of distributional semantics.", "labels": [], "entities": []}, {"text": "Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments)-for example learning that X wrote Y and X is the author of Y are equivalent if they appear in a corpus with similar (X, Y) argumentpairs such as {(Shakespeare, Macbeth), (Dickens, Oliver Twist)}.", "labels": [], "entities": []}, {"text": "We extend this to the multilingual case, aiming to also map the French equivalents X a \u00b4 ecrit Y and Y est un roman de X onto the same cluster as the English paraphrases.", "labels": [], "entities": []}, {"text": "Conceptually, we treat a foreign expression as a paraphrase of an English expression.", "labels": [], "entities": []}, {"text": "The cluster identifier can be used as a predicate in a logical form, suggesting that the fundamental predicates of an interlingua can be learnt in an unsupervised manner via clustering.", "labels": [], "entities": []}, {"text": "In this paper we focus on learning binary relations between named entities.", "labels": [], "entities": []}, {"text": "This problem is much simpler than attempting complete interlingual semantic interpretation, but the approach could be generalized.", "labels": [], "entities": [{"text": "interlingual semantic interpretation", "start_pos": 54, "end_pos": 90, "type": "TASK", "confidence": 0.6767851710319519}]}, {"text": "This class of expressions has proved extremely useful in the monolingual case, with direct applications for question answering and relation extraction), and we demonstrate how to use them to improve machine translation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.8656328022480011}, {"text": "relation extraction", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8297983109951019}, {"text": "machine translation", "start_pos": 199, "end_pos": 218, "type": "TASK", "confidence": 0.7842405438423157}]}, {"text": "It is important to be able to extract knowledge across languages, as many facts will not be expressed in all languages-either due to lesscomplete encyclopedias being available in some languages, or facts being most relevant to a single country.", "labels": [], "entities": []}, {"text": "In contrast to most previous work on machine translation and cross-lingual clustering, our method requires no parallel text (see Section 8 for discussion of some exceptions).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7955929338932037}, {"text": "cross-lingual clustering", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.6937092542648315}]}, {"text": "It instead exploits an alignment between named-entities in different languages.", "labels": [], "entities": []}, {"text": "The limited size of parallel corpora is a significant bottleneck for machine translation, whereas our approach can be used on much larger monolingual corpora.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7768092155456543}]}, {"text": "This means it is potentially useful for language-pairs where little parallel text is available, for domain adaptation, or for semisupervised approaches.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7849695682525635}]}], "datasetContent": [{"text": "We evaluate our system on English and French, using Wikipedia for corpora.", "labels": [], "entities": []}, {"text": "The English corpus is POS-tagged and CCG-parsed with the C&C tools Data: Sets of monolingual relation clusters R L1 and R L2 Result: An alignment between the monolingual clusters AA \u2190\u2212 {}; while R L1 = {} \u2227 R L2 = {} do (r1, r2) \u2190\u2212 arg max sim(r1, r2);.", "labels": [], "entities": []}, {"text": "We find that the cross-lingual clusters typically contain more French expressions than English, possibly due to the differing sizes of the corpora-adjusting the parameters in Section 5 results in larger clusters, but introduces noise.", "labels": [], "entities": []}, {"text": "We evaluate our system on a cross-lingual question answering task, similar to monolingual QA evaluations by and.", "labels": [], "entities": [{"text": "cross-lingual question answering task", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.6904125511646271}]}, {"text": "A question is asked in language L, and is answered by the system from a corpus of language L'.", "labels": [], "entities": []}, {"text": "Human annotators are shown the question, answer entity, and the sentence that provided the answer, and are then asked whether the answer is a reasonable conclusion based on the sentence.", "labels": [], "entities": []}, {"text": "Whilst this task is much easier than full translation, it is both a practical application for our approach, and a reasonably direct extrinsic evaluation for our cross-lingual clusters.", "labels": [], "entities": [{"text": "full translation", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.6463230550289154}]}, {"text": "Following and, the question dataset is automatically generated from the corpus.", "labels": [], "entities": []}, {"text": "This approach has the advantage of evaluating on expressions in proportion to their corpus frequency, so understanding frequent expressions is more important than rare ones.", "labels": [], "entities": []}, {"text": "We then sample 1000 questions for each language, by extracting binary relations matching cer- , and removing one of the arguments.", "labels": [], "entities": []}, {"text": "For example, from the sentence Obama lives in Washington we create the questions X lives in Washington?, and Obama lives in X?.", "labels": [], "entities": []}, {"text": "3 Answers are judged by fluent bilingual humans, and do not have to match the entity that originally instantiated X.", "labels": [], "entities": []}, {"text": "Multiple answers can be returned for the same question.", "labels": [], "entities": []}, {"text": "Our system attempts this task by mapping both the question and candidate answer sentences (which will be in a different language to the question) onto a logical form using the clusters, and determining whether they express the same relation.", "labels": [], "entities": []}, {"text": "This tests the ability of our approach to cluster expressions into those which are semantically equivalent between languages.", "labels": [], "entities": []}, {"text": "It is possible for entities to have multiple types (see Section 4.2), and answers are ranked by the number of types in which the entailment relation is predicted to hold.", "labels": [], "entities": []}, {"text": "Questions are given in a declarative form, to make the tasks simpler for the machine translation baseline.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.6918483376502991}]}, {"text": "We found the machine translation performed poorly on questions such as What is Obama the president of?, as inverted word-orders and long-range dependencies are difficult to handle with re-ordering models and language models (though are straightforward to handle fora CCG system ).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.718677282333374}]}, {"text": "We find that machine translation performs much better on declarative equivalents, such as: Obama is the president of X.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.773655503988266}]}, {"text": "Ultimately, we would like to be able to translate using semantic parsing with cross-lingual clusters.", "labels": [], "entities": [{"text": "translate", "start_pos": 40, "end_pos": 49, "type": "TASK", "confidence": 0.9654875993728638}, {"text": "semantic parsing", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7018606513738632}]}, {"text": "As a step towards this, we investigated whether we could rerank the output of a machine translation system, on the basis of whether the semantic parse of the source sentence is consistent with that of candidate translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7312978208065033}]}, {"text": "We sample French sentences where we can produce a semantic parse (i.e. we can extract a predicate between named entities that maps to a cross-lingual cluster).", "labels": [], "entities": []}, {"text": "These sentences are translated to English using Moses, taking the 50-best list, and semantic parses are produced for each of these.", "labels": [], "entities": []}, {"text": "If the semantic parse for the 1-best translation does not match the source semantic parse, we take the parse from the 50-best list that most closely matches it-otherwise we discard the sentence from our evaluation, as our semantics agrees with the machine-translation.", "labels": [], "entities": []}, {"text": "To ensure that the evaluation focuses on the clusters, we try to exclude several other factors that might affect the results.", "labels": [], "entities": []}, {"text": "The coverage of our CCG parsing and semantic analysis drops significantly on noisy translated sentences, and potentially acts as a language model by failing to produce any semantic parse on ungrammatical output sentences.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.719242513179779}, {"text": "semantic analysis", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.6892621070146561}]}, {"text": "We therefore only consider sentences where we can produce a semantic parse for the 1-best machine translation output.", "labels": [], "entities": []}, {"text": "We also try to avoid penalizing the machinetranslation system for failing to translate named entities correctly, so we do not attempt to rerank sentences where the entities from the source sentence are not present in the 1-best translation.", "labels": [], "entities": []}, {"text": "Human annotators were shown the source sentence, the 1-best translation, and the translation chosen by the reranker (the translations were shown in a random order).", "labels": [], "entities": []}, {"text": "To focus the evaluation on the semantic relations we are modelling, we ask the annotators which sentence best preserves the meaning between the named entities that have different relations Percentage of translations preferred 1-best Moses translation 5% Cluster-based Reranker 39% No preference 56%: Human preference judgements for the translation reranking experiment, based on a sample of 87 sentences.", "labels": [], "entities": []}, {"text": "Results show the percentage of sentences for which the annotators preferred the original translation, the reranked translation, or neither.", "labels": [], "entities": []}, {"text": "As discussed in the text, results where annotators had no preference were typically due to syntactic parse errors.", "labels": [], "entities": []}, {"text": "This avoids our system being penalized for choosing a translation that is worse in aspects other than the relations it is modelling.", "labels": [], "entities": []}, {"text": "An example is shown in.", "labels": [], "entities": []}, {"text": "The data was annotated jointly by two fluent bilingual speakers, who reported high agreement on this task.", "labels": [], "entities": []}, {"text": "Results are shown in, and are highly encouraging, with the original Moses output being preferred to the reranked translation in only 5% of cases where our model makes a positive prediction.", "labels": [], "entities": []}, {"text": "Inspecting the results, we see that many of the cases where the annotators had no preference were caused by syntactic parse errors.", "labels": [], "entities": []}, {"text": "For example, if the 1-best translation is correct, but a prepositional phrase is incorrectly attached, it will appear to have an incorrect semantics.", "labels": [], "entities": []}, {"text": "A similar translation in the 50-best list maybe correctly parsed, and consequently selected by our reranker.", "labels": [], "entities": []}, {"text": "However, a human will have no preference between these translations.", "labels": [], "entities": []}, {"text": "Incorporating K-Best parsing into our pipeline may help mitigate against such cases.", "labels": [], "entities": [{"text": "K-Best parsing", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.6591413617134094}]}, {"text": "This preliminary experiment suggests that there is potential for future improvements in machine translation using cross-lingual distributional semantics.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.8125489354133606}]}, {"text": "The system only attempts to rerank a very small proportion of sentences, but we believe the coverage could be greatly improved by including relations between common nouns (rather than just namedentities)-future work should explore this.", "labels": [], "entities": [{"text": "coverage", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9632753133773804}]}], "tableCaptions": [{"text": " Table 2: Example questions correctly answered using our clusters, with the answer entity highlighted in bold.", "labels": [], "entities": []}]}