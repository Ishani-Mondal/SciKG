{"title": [{"text": "Learning Topics and Positions from Debatepedia", "labels": [], "entities": [{"text": "Debatepedia", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.6002703905105591}]}], "abstractContent": [{"text": "We explore Debatepedia, a community-authored encyclopedia of sociopolitical debates , as evidence for inferring a low-dimensional, human-interpretable representation in the domain of issues and positions.", "labels": [], "entities": []}, {"text": "We introduce a generative model positing latent topics and cross-cutting positions that gives special treatment to person mentions and opinion words.", "labels": [], "entities": []}, {"text": "We evaluate the resulting repre-sentation's usefulness in attaching opinionated documents to arguments and its consistency with human judgments about positions.", "labels": [], "entities": []}], "introductionContent": [{"text": "The social web has evolved into a forum for large portions of the population to discuss and debate complex issues of societal importance.", "labels": [], "entities": []}, {"text": "Websites like Debatepedia, an online, community-authored encyclopedia of debates ( \u00a72), seek to organize some of this exchange into structured information resources that summarize arguments and link externally to texts (editorials, blog posts, etc.) that express and evoke them.", "labels": [], "entities": []}, {"text": "Empirical NLP, we propose, has a role to play in creating a more compact and easilyinterpretable way to understand the opinion space.", "labels": [], "entities": []}, {"text": "In particular, we envision applications to computational journalism, where there is high demand for transformation of and pattern discovery in unmanageable, unstructured, evolving data (including text) to inform the public.", "labels": [], "entities": [{"text": "computational journalism", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.7643675208091736}, {"text": "pattern discovery", "start_pos": 122, "end_pos": 139, "type": "TASK", "confidence": 0.7201084196567535}]}, {"text": "In this paper, we develop a generative model for discovering such a representation ( \u00a73), using Debatepedia as a corpus of evidence.", "labels": [], "entities": []}, {"text": "We draw inspiration from and Ahmed and 1 http://dbp.idebate.org, who used generative models to infer topics-distributions over words-and other wordassociated variables representing perspectives or ideologies.", "labels": [], "entities": []}, {"text": "We view topics as lexicons, and propose that grounding a topic model with evidence beyond bags of words can lead to more lexicon-like representations.", "labels": [], "entities": []}, {"text": "Specifically, our generative topic model grounds topics using the hierarchical organization of arguments within Debatepedia.", "labels": [], "entities": [{"text": "generative topic", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.9060758054256439}]}, {"text": "Further, we use named entity recognition as a preprocessing step, an existing sentiment lexicon to construct an informed prior, and we incorporate a latent, discrete position variable that cuts across debates.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7024945219357809}]}, {"text": "We evaluate the model informally and formally ( \u00a74).", "labels": [], "entities": []}, {"text": "Subjectively, the model identifies reasonable topic and perspective terms, and it associates topics sensibly with important public figures.", "labels": [], "entities": []}, {"text": "In quantitative evaluations, we find the model's representation superior to topics from vanilla latent Dirichlet allocation () and the joint sentiment topic model () in matching external texts to debates.", "labels": [], "entities": []}, {"text": "Further, the position variables can be used to infer the side of an argument within a debate; our model performs with an accuracy of 86% on position prediction of the debate argument.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9992606043815613}]}, {"text": "The cross-cutting position variable is not especially consistent with human judgments, suggesting that further knowledge sources maybe required to improve interpretability across issues.", "labels": [], "entities": []}], "datasetContent": [{"text": "Recall that the aim of this work is to infer a lowdimensional representation of debate text.", "labels": [], "entities": []}, {"text": "We estimated our model on the Debatepedia debates (not including hyperlinked articles), and conducted several evaluations of the model, each considering a different aspect of the goal.", "labels": [], "entities": [{"text": "Debatepedia debates", "start_pos": 30, "end_pos": 49, "type": "DATASET", "confidence": 0.9058388471603394}]}, {"text": "We exploit external articles hyperlinked from Debatepedia described in \u00a72 as supporting texts for arguments, treating each one's association to an argument as variable to be predicted.", "labels": [], "entities": []}, {"text": "Firstly, we evaluate our model on the article associating task.", "labels": [], "entities": []}, {"text": "Secondly, we evaluate our model on the position prediction task.", "labels": [], "entities": [{"text": "position prediction task", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.8587127923965454}]}, {"text": "Then, we compare our model's positional assignment of arguments to human annotated clusterings.", "labels": [], "entities": []}, {"text": "Finally, we present qualitative discussion.", "labels": [], "entities": []}], "tableCaptions": []}