{"title": [{"text": "Of words, eyes and brains: Correlating image-based distributional semantic models with neural representations of concepts", "labels": [], "entities": []}], "abstractContent": [{"text": "Traditional distributional semantic models extract word meaning representations from co-occurrence patterns of words in text corpora.", "labels": [], "entities": []}, {"text": "Recently, the distributional approach has been extended to models that record the co-occurrence of words with visual features in image collections.", "labels": [], "entities": []}, {"text": "These image-based models should be complementary to text-based ones, providing a more cognitively plausible view of meaning grounded in visual perception.", "labels": [], "entities": []}, {"text": "In this study, we test whether image-based models capture the semantic patterns that emerge from fMRI recordings of the neural signal.", "labels": [], "entities": []}, {"text": "Our results indicate that, indeed, there is a significant correlation between image-based and brain-based semantic similarities, and that image-based models complement text-based ones, so that the best correlations are achieved when the two modalities are combined.", "labels": [], "entities": []}, {"text": "Despite some unsatisfactory, but explained outcomes (in particular, failure to detect differential association of models with brain areas), the results show, on the one hand, that image-based distributional semantic models can be a precious new tool to explore semantic representation in the brain, and, on the other, that neural data can be used as the ultimate test set to validate artificial semantic models in terms of their cognitive plausibility.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many recent neuroscientific studies have brought support to the view that concepts are represented in terms of patterns of neural activation over broad areas, naturally encoded as vectors in a neural semantic space ().", "labels": [], "entities": []}, {"text": "Similar representations are also widely used in computational linguistics, and in particular in distributional semantics, that captures meaning in terms of vectors recording the patterns of co-occurrence of words in large corpora, under the hypothesis that words that occur in similar contexts are similar in meaning.", "labels": [], "entities": []}, {"text": "Since the seminal work of, there has thus being interest in investigating whether corpus-harvested semantic representations can contribute to the study of concepts in the brain.", "labels": [], "entities": []}, {"text": "The relation is mutually beneficial: From the point of view of brain activity decoding, a strong correlation between corpus-based and brain-derived conceptual representations would mean that we could use the former (much easier to construct on a very large scale) to make inferences about the second: e.g., using corpus-based representations to reconstruct the likely neural signal associated to words we have no direct brain data for.", "labels": [], "entities": []}, {"text": "From the point of view of computational linguistics, neural data provide the ultimate testing ground for models that strive to capture important aspects of human semantic memory (much more so than the commonly used explicit semantic rating benchmarks).", "labels": [], "entities": []}, {"text": "If we found that a corpus-based model of meaning can make nontrivial predictions about the structure of the semantic space in the brain, that would make a pretty strong case for the intriguing idea that the model is approximating, in interesting ways, the way in which humans acquire and represent semantic knowledge.", "labels": [], "entities": []}, {"text": "We take as our starting point the extensive experiments reported in, who showed that purely corpus-based distributional models are at least as good at brain signal prediction tasks as earlier models that made use of manually-generated or controlled knowledge sources, and we evaluate a very recent type of distributional model, namely one that is not extracted from textual data but from image collections through automated visual feature extraction techniques.", "labels": [], "entities": [{"text": "brain signal prediction", "start_pos": 151, "end_pos": 174, "type": "TASK", "confidence": 0.7243382136027018}]}, {"text": "It has been argued that this new generation of image-based distributional models) provides a more realistic view of meaning, since humans obviously acquire a large proportion of their semantic knowledge from perceptual data.", "labels": [], "entities": []}, {"text": "The first question that we ask, thus, is whether the more \"grounded\" image-based models can help us in interpreting conceptual representations in the brain.", "labels": [], "entities": [{"text": "interpreting conceptual representations", "start_pos": 103, "end_pos": 142, "type": "TASK", "confidence": 0.8703704675038656}]}, {"text": "More specifically, we will compare the performance of different image-based representations, and we will test whether text-and image-based representations are complementary, so that when used together they can better account for patterns in neural data.", "labels": [], "entities": []}, {"text": "Finally, we will check for differences between anatomical regions in the degree to which text and/or image models are effective, as one might expect given the well-known functional specializations of different anatomical regions.", "labels": [], "entities": []}], "datasetContent": [{"text": "A question is posed over how to evaluate the relationship between the different distributional models and brain data.", "labels": [], "entities": []}, {"text": "Comparing each model's predictive performance using the same strategy as Mitchell et al.", "labels": [], "entities": []}, {"text": "(2008) (also followed by) is one possibility: they used multiple regression to relate distributional codes to individual voxel activations, thus allowing brain states to be estimated from previously unseen distributional codes.", "labels": [], "entities": []}, {"text": "Regression models were trained on 58/60 words and in testing the regression models estimated the brain state associated with the 2 unseen distributional codes.", "labels": [], "entities": [{"text": "Regression", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.924263060092926}]}, {"text": "The predicted brain states were compared with the actual fMRI data, and the process repeated for each permutation of left-out words, to build a metric of prediction accuracy.", "labels": [], "entities": [{"text": "fMRI data", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.8233892619609833}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9376956224441528}]}, {"text": "For our purposes, a fair comparison of models using this strategy is complicated by differences in dimensionality between both semantic models and lobes (which we compare to other lobes) in association with the comparatively small number of words in the fMRI data set.", "labels": [], "entities": [{"text": "fMRI data set", "start_pos": 254, "end_pos": 267, "type": "DATASET", "confidence": 0.9752782384554545}]}, {"text": "Large dimensionality models risk overfitting the data, and it is a nuisance to try to reliably correct for the effects of overfitting in performance comparisons.", "labels": [], "entities": []}, {"text": "Not least, to thoroughly evaluate all possible cross-validation permutations is demanding in processing time, and we have many models to compare.", "labels": [], "entities": []}, {"text": "An alternative approach, and that which we have adopted, is representational similarity analysis (.", "labels": [], "entities": [{"text": "representational similarity analysis", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.7963394323984782}]}, {"text": "Representational similarity analysis circumvents the previous problems by abstracting each fMRI/distributional data source to a common structure capturing the interrelationships between each pair of data items (e.g., words).", "labels": [], "entities": [{"text": "Representational similarity analysis", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8826593359311422}]}, {"text": "Specifically, for each model/participant's fMRI data/anatomical region, the similarity structure was evaluated by taking the pairwise correlation (Pearson's correlation coefficient) between all unique category or word combinations.", "labels": [], "entities": [{"text": "pairwise correlation (Pearson's correlation coefficient)", "start_pos": 125, "end_pos": 181, "type": "METRIC", "confidence": 0.7456868700683117}]}, {"text": "This produced a list of 55 category pair correlations and 121 word pair correlations for each data source.", "labels": [], "entities": []}, {"text": "For all brain data, correlation lists were averaged across the nine participants to produce a single list of mean word pair correlations and a single list of mean category pair correlations for each anatomical region and the whole brain.", "labels": [], "entities": []}, {"text": "Then to provide a measure of similarity between models and brain data, the correlation lists for respective data sources were themselves correlated using Spearman's rank correlation.", "labels": [], "entities": []}, {"text": "Statistical significance was tested using a permutation test: The word-pair (or category-pair) labels were randomly shuffled 10,000 times to estimate a null distribution when the two similarity lists are not correlated.", "labels": [], "entities": []}, {"text": "The p-value is calculated as the proportion of random correlation coefficients that are greater than or equal to the observed coefficient.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Matrix of correlations between each pairwise combination of distributional semantic models and brain data.  Correlations correspond to the pairwise similarity between the 51 words. In each column the first value corresponds  to Spearman's rank correlation coefficient and the value in parenthesis is the p-value.", "labels": [], "entities": []}]}