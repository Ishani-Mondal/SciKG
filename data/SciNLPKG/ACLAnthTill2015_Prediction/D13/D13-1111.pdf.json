{"title": [{"text": "A Systematic Exploration of Diversity in Machine Translation", "labels": [], "entities": [{"text": "Systematic Exploration of Diversity in Machine Translation", "start_pos": 2, "end_pos": 60, "type": "TASK", "confidence": 0.7116218507289886}]}], "abstractContent": [{"text": "This paper addresses the problem of producing a diverse set of plausible translations.", "labels": [], "entities": []}, {"text": "We present a simple procedure that can be used with any statistical machine translation (MT) system.", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 56, "end_pos": 92, "type": "TASK", "confidence": 0.7659684866666794}]}, {"text": "We explore three ways of using diverse translations: (1) system combination, (2) discriminative reranking with rich features, and (3) a novel post-editing scenario in which multiple translations are presented to users.", "labels": [], "entities": []}, {"text": "We find that diversity can improve performance on these tasks, especially for sentences that are difficult for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9896408915519714}]}], "introductionContent": [{"text": "From the perspective of user interaction, the ideal machine translator is an agent that reads documents in one language and produces accurate, high quality translations in another.", "labels": [], "entities": []}, {"text": "This interaction ideal has been implicit in machine translation (MT) research since the field's inception.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.8497855842113495}]}, {"text": "It is the way we interact with commercial MT services (such as Google Translate and Microsoft Translator), and the way MT systems are evaluated (.", "labels": [], "entities": [{"text": "MT", "start_pos": 119, "end_pos": 121, "type": "TASK", "confidence": 0.965785801410675}]}, {"text": "Unfortunately, when areal, imperfect MT system makes an error, the user is left trying to guess what the original sentence means.", "labels": [], "entities": [{"text": "MT", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9676588177680969}]}, {"text": "In contrast, when we look at the way other computer systems consume output from MT systems (or similarly unreliable tools), we see a different pattern.", "labels": [], "entities": []}, {"text": "Ina pipeline setting it is commonplace to propagate not just a singlebest output but the M -best hypotheses (.", "labels": [], "entities": []}, {"text": "Multiple solutions are also used for reranking), tuning, minimum Bayes risk decoding (), and system combination (.", "labels": [], "entities": []}, {"text": "When dealing with error-prone systems, knowing about alternatives has benefits over relying on only a single output (.", "labels": [], "entities": []}, {"text": "Unfortunately, M -best lists area poor surrogate for structured output spaces (.", "labels": [], "entities": []}, {"text": "In MT, for example, many translations on M -best lists are extremely similar, often differing only by a single punctuation mark or minor morphological variation.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.878236711025238}, {"text": "M -best lists", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.6073296144604683}]}, {"text": "Recent work has explored reasoning about sets using packed representations such as lattices and hypergraphs (), or sampling translations proportional to their probability.", "labels": [], "entities": []}, {"text": "We argue that the implicit goal behind these techniques is to better explore the output space by introducing diversity into the surrogate set.", "labels": [], "entities": []}, {"text": "In this work, we elevate diversity to a first-class status and directly address the problem of generating a set of diverse, plausible translations.", "labels": [], "entities": []}, {"text": "We use the recently proposed technique of, which produces diverse M -best solutions from a probabilistic model using a generic dissimilarity function \u2206(\u00b7, \u00b7) that specifies how two solutions differ.", "labels": [], "entities": []}, {"text": "Our first contribution is a family of dissimilarity functions for MT that admit simple algorithms for generating diverse translations.", "labels": [], "entities": [{"text": "MT", "start_pos": 66, "end_pos": 68, "type": "TASK", "confidence": 0.9646961688995361}]}, {"text": "Other contributions are empirical: we show that diverse translations can lead to improvements for system combination and discriminative reranking.", "labels": [], "entities": [{"text": "system combination", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7143861949443817}]}, {"text": "We also perform a novel human post-editing evaluation in order to measure whether diverse translations can help users make sense of noisy MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 138, "end_pos": 147, "type": "TASK", "confidence": 0.8834104835987091}]}, {"text": "We find that diverse translations can help post-editors produce better outputs for sentences that are the most difficult for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 125, "end_pos": 127, "type": "TASK", "confidence": 0.9871463775634766}]}, {"text": "While we focus on machine translation in this paper, we note that our approach is applicable to other structure prediction problems in NLP.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7772698700428009}, {"text": "structure prediction", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.7452342510223389}]}], "datasetContent": [{"text": "We now embark on an extensive empirical evaluation of the framework presented above.", "labels": [], "entities": []}, {"text": "We begin by analyzing our diverse sets of translations, showing how they differ from standard M -best lists (Section 6), followed by three tasks that illustrate how diversity can be exploited to improve translation quality: system combination (Section 7), discriminative reranking (Section 8), and a novel human postediting task (Section 9).", "labels": [], "entities": []}, {"text": "In the remainder of this section, we describe details of our experimental setup.", "labels": [], "entities": []}, {"text": "We use three language pairs: Arabic-to-English (AR\u2192EN), Chinese-to-English (ZH\u2192EN), and German-to-English (DE\u2192EN).", "labels": [], "entities": []}, {"text": "For AR\u2192EN and DE\u2192EN, we used a phrase-based model () and for ZH\u2192EN we used a hierarchical phrase-based model.", "labels": [], "entities": []}, {"text": "Each language pair has two tuning and one test set: TUNE1 is used for tuning the baseline systems with minimum error rate training (MERT; Och, 2003), TUNE2 is used for training system combiners and rerankers, and TEST is used for evaluation.", "labels": [], "entities": [{"text": "TUNE1", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9337079524993896}, {"text": "MERT; Och, 2003)", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.6703699578841528}, {"text": "TEST", "start_pos": 213, "end_pos": 217, "type": "METRIC", "confidence": 0.9695185422897339}]}, {"text": "There are four references for AR\u2192EN and ZH\u2192EN and one for DE\u2192EN.", "labels": [], "entities": [{"text": "AR", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.9221803545951843}]}, {"text": "For AR\u2192EN, we used data provided by the LDC for the NIST evaluations, which includes 3.3M sentences of UN data and 982K sentences from other (mostly news) sources.", "labels": [], "entities": [{"text": "NIST", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9185190200805664}]}, {"text": "Arabic text was preprocessed using an HMM segmenter that splits attached prepositional phrases, personal pronouns, and the future marker ().", "labels": [], "entities": []}, {"text": "The common stylistic sentence-initial w+ (and) clitic was removed.", "labels": [], "entities": []}, {"text": "The resulting corpus contained 130M Arabic tokens and 130M English tokens.", "labels": [], "entities": []}, {"text": "We used the NIST MT06 test set as TUNE1, a 764-sentence subset of MT05 as TUNE2, and MT08 as TEST.", "labels": [], "entities": [{"text": "NIST MT06 test set", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.8867151141166687}, {"text": "TUNE1", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.8665996789932251}, {"text": "MT05", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.9185296297073364}, {"text": "MT08", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.8731592893600464}]}, {"text": "For ZH\u2192EN, we used 303k sentence pairs from the FBIS corpus (LDC2003E14).", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9703060984611511}]}, {"text": "We segmented the Chinese data using the Stanford Chinese segmenter () in \"CTB\" mode, giving us 7.9M Chinese tokens and 9.4M English tokens.", "labels": [], "entities": []}, {"text": "We used the NIST MT02 test set as TUNE1, MT05 as TUNE2, and MT03 as TEST.", "labels": [], "entities": [{"text": "NIST MT02 test set", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.8743553161621094}, {"text": "TUNE1", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.8389576077461243}, {"text": "MT05", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.8176979422569275}, {"text": "MT03", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.8869562745094299}, {"text": "TEST", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.7272347807884216}]}, {"text": "For DE\u2192EN, we used data released for the WMT2011 shared task).", "labels": [], "entities": [{"text": "WMT2011", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.8538997769355774}]}, {"text": "German compound words were split using a CRF segmenter.", "labels": [], "entities": []}, {"text": "We used the WMT2010 test set as TUNE1, the 2009 test set as TUNE2, and the 2011 test set as TEST.", "labels": [], "entities": [{"text": "WMT2010 test set", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.977712074915568}, {"text": "TUNE1", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.5224463939666748}, {"text": "TUNE2", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.6365020275115967}, {"text": "TEST", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.6929441094398499}]}, {"text": "One way to evaluate the quality of our diverse lists is to use them in system combination, as was similarly done by Devlin and Matsoukas (2012) and.", "labels": [], "entities": []}, {"text": "We use the system combination framework of, which has an open-source implementation).", "labels": [], "entities": []}, {"text": "We use our baseline systems (trained on TUNE1) to generate lists for system combination on TUNE2 and TEST.", "labels": [], "entities": [{"text": "TUNE1", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.9074414372444153}, {"text": "TUNE2", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.8932565450668335}, {"text": "TEST", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8874574303627014}]}, {"text": "We compare M -best lists, unique M -best lists, and M -diverse lists, with M \u2208 {10, 15, 20}.", "labels": [], "entities": []}, {"text": "5 For each choice of list type and M , we trained the system combiner on TUNE2 and tested on TEST with the learned parameters.", "labels": [], "entities": [{"text": "M", "start_pos": 35, "end_pos": 36, "type": "METRIC", "confidence": 0.9802811741828918}, {"text": "TUNE2", "start_pos": 73, "end_pos": 78, "type": "DATASET", "confidence": 0.9161430597305298}, {"text": "TEST", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.49921154975891113}]}, {"text": "System combination hyperparameters (whether to use feature length normalization; the size of the k-best lists generated by the system combiner during tuning, k \u2208 {300, 600}) were chosen to maximize BLEU on TUNE 200 . Also, we removed the individual features from the default feature set because they correspond to individual systems in the combination; they did not seem appropriate for us since our hypotheses all come from the same system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 198, "end_pos": 202, "type": "METRIC", "confidence": 0.9991469383239746}, {"text": "TUNE 200", "start_pos": 206, "end_pos": 214, "type": "DATASET", "confidence": 0.9001218676567078}]}, {"text": "The results are shown in: System combination results (%BLEU on quartiles of TEST, M = 15).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.999529242515564}, {"text": "TEST", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.8520210981369019}, {"text": "M", "start_pos": 82, "end_pos": 83, "type": "METRIC", "confidence": 0.968602180480957}]}, {"text": "Source sentences were divided into quartiles (numbered \"qn\") according to BLEU+1 of the 1-best translations of the baseline system.", "labels": [], "entities": [{"text": "BLEU+1", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9642457564671835}]}, {"text": "Highest score in each column is bold.", "labels": [], "entities": []}, {"text": "gains are similar to those seen by Devlin and Matsoukas, but use our simpler dissimilarity function.", "labels": [], "entities": []}, {"text": "For DE\u2192EN, results are similar for all settings and do not show much improvement from system combination.", "labels": [], "entities": [{"text": "DE", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.8303905725479126}]}, {"text": "In, we breakdown the scores according to 1-best BLEU+1 quartiles, as done in.", "labels": [], "entities": [{"text": "BLEU+1 quartiles", "start_pos": 48, "end_pos": 64, "type": "METRIC", "confidence": 0.9188163429498672}]}, {"text": "In general, we find the largest gains for the low-BLEU translations.", "labels": [], "entities": []}, {"text": "For the two worst BLEU quartiles, we see gains of 1.2 to 2.5 BLEU points, while the gains shrink or disappear entirely for the best quartile.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9965779185295105}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9987127780914307}]}, {"text": "This maybe a worthwhile trade-off: a large improvement in the worst translations maybe more significant to users than a smaller degredation on sentences that are already being translated well.", "labels": [], "entities": []}, {"text": "In addition, quality estimation () could be used to automatically determine the BLEU quartile for each sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9980297684669495}]}, {"text": "Then system combination of diverse translations might be used only when the 1-best translation is predicted to be of low quality.", "labels": [], "entities": []}, {"text": "We now turn to discriminative reranking, which has frequently been used to easily add rich features to a model.", "labels": [], "entities": []}, {"text": "It has been used for MT with varying de-6 They reported +0.8 BLEU from system combination for AR\u2192EN, and saw a further +0.5-0.7 from their new features.", "labels": [], "entities": [{"text": "MT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9852288365364075}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9973661303520203}]}, {"text": "gree of success (; some have attributed its mixed results to alack of diversity in the M -best lists traditionally used.", "labels": [], "entities": []}, {"text": "We propose diverse lists as away to address this concern.", "labels": [], "entities": []}, {"text": "We wanted to determine whether diverse translations could be helpful to users struggling to understand the output of an imperfect MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 130, "end_pos": 132, "type": "TASK", "confidence": 0.9740987420082092}]}, {"text": "We consider a post-editing task in which users are presented with translation output without the source sentence, and are asked to improve it.", "labels": [], "entities": []}, {"text": "This setting has been studied; e.g., presented evidence that monolingual speakers could often produce improved translations for this task, occasionally reaching the level of an expert translator.", "labels": [], "entities": []}, {"text": "Here, we use a novel variation of this task in which multiple translations are shown to editors.", "labels": [], "entities": []}, {"text": "We compare the use of entries from an M -best list and entries from a diverse list.", "labels": [], "entities": []}, {"text": "Again, the original source sentence is not provided.", "labels": [], "entities": []}, {"text": "Our goal is to determine whether multiple, diverse translations can help users to more accurately guess the meaning of the original sentence than entries from a standard M -best list.", "labels": [], "entities": []}, {"text": "If so, commercial MT systems might permit users to request additional diverse translations for those sentences whose model-best translations are difficult to understand.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9766212105751038}]}], "tableCaptions": [{"text": " Table 1: Oracle BLEU scores on TEST for various sizes  of M -best and diverse lists. Unique lists were obtained  from 1,000-best lists and therefore may not contain the  target number of unique translations for all sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9925306439399719}, {"text": "TEST", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.5335721373558044}]}, {"text": " Table 2: System combination results (%BLEU on TEST). Size of lists is M \u2208 {10, 15, 20}. Highest score in each  column is bold.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9994020462036133}, {"text": "TEST", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9506412744522095}]}, {"text": " Table 3: System combination results (%BLEU on quartiles of TEST, M = 15). Source sentences were divided into  quartiles (numbered \"qn\") according to BLEU+1 of the 1-best translations of the baseline system. Highest score in  each column is bold.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9991769194602966}, {"text": "TEST", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.5780309438705444}, {"text": "BLEU", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.9987198114395142}]}, {"text": " Table 4: Reranking results (%BLEU on TEST).", "labels": [], "entities": [{"text": "Reranking", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9810342192649841}, {"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9995831847190857}, {"text": "TEST", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9658081531524658}]}]}