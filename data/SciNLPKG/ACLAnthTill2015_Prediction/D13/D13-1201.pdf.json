{"title": [], "abstractContent": [{"text": "Minimum Error Rate Training (MERT) remains one of the preferred methods for tuning linear parameters in machine translation systems, yet it faces significant issues.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT", "start_pos": 0, "end_pos": 33, "type": "METRIC", "confidence": 0.8273353278636932}, {"text": "machine translation", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7582880258560181}]}, {"text": "First, MERT is an unregularized learner and is therefore prone to overfitting.", "labels": [], "entities": []}, {"text": "Second, it is commonly used on a noisy, non-convex loss function that becomes more difficult to optimize as the number of parameters increases.", "labels": [], "entities": []}, {"text": "To address these issues, we study the addition of a regularization term to the MERT objective function.", "labels": [], "entities": [{"text": "MERT objective", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.5174170732498169}]}, {"text": "Since standard regularizers such as 2 are inapplicable to MERT due to the scale invariance of its objective function, we turn to two regularizers-0 and a modification of 2-and present methods for efficiently integrating them during search.", "labels": [], "entities": []}, {"text": "To improve search in large parameter spaces, we also present anew direction finding algorithm that uses the gradient of expected BLEU to orient MERT's exact line searches.", "labels": [], "entities": [{"text": "direction finding", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.8836933076381683}, {"text": "BLEU", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9983857870101929}]}, {"text": "Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets.", "labels": [], "entities": [{"text": "PRO", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.5859149098396301}]}], "introductionContent": [{"text": "Minimum Error Rate Training emerged a decade ago as a superior training method for small numbers of linear model parameters of machine translation systems, improving over prior work using maximum likelihood criteria).", "labels": [], "entities": [{"text": "Minimum Error Rate", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.6515056391557058}, {"text": "machine translation", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.7416559457778931}]}, {"text": "This technique quickly rose to prominence, becoming standard in many research and commercial MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.9936981797218323}]}, {"text": "Variants operating over lattices () or hypergraphs ( were subsequently developed, with the benefit of reducing the approximation error from n-best lists.", "labels": [], "entities": []}, {"text": "The primary advantages of MERT are twofold.", "labels": [], "entities": [{"text": "MERT", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.780800461769104}]}, {"text": "It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9991291165351868}]}, {"text": "Secondly, it offers a globally optimal line search.", "labels": [], "entities": []}, {"text": "Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of features, due to its non-convex loss function and its lack of regularization.", "labels": [], "entities": [{"text": "MERT", "start_pos": 67, "end_pos": 71, "type": "TASK", "confidence": 0.7416585683822632}]}, {"text": "These challenges have prompted some researchers to move away from MERT, in favor of linearly decomposable approximations of the evaluation metric (, which correspond to easier optimization problems and which naturally incorporate regularization.", "labels": [], "entities": [{"text": "MERT", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.44387373328208923}]}, {"text": "In particular, recent work () has shown that adding thousands or tens of thousands of features can improve MT quality when weights are optimized using a margin-based approximation.", "labels": [], "entities": [{"text": "MT", "start_pos": 107, "end_pos": 109, "type": "TASK", "confidence": 0.9957340359687805}]}, {"text": "On simulated datasets, found that conventional MERT struggles to find reasonable parameter vectors, where a smooth loss function based on Pairwise Ranking Optimization (PRO) performs much better; on real data, this PRO method appears at least as good as MERT on small feature sets, and also scales better as the number of features increases.", "labels": [], "entities": [{"text": "MERT", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.953184962272644}]}, {"text": "In this paper, we seek to preserve the advantages of MERT while addressing its shortcomings in terms of regularization and search.", "labels": [], "entities": [{"text": "MERT", "start_pos": 53, "end_pos": 57, "type": "TASK", "confidence": 0.524002194404602}]}, {"text": "The idea of adding a regularization term to the MERT objective function can be perplexing at first, because the most common regularizers, such as 1 and 2 , are not directly applicable to MERT.", "labels": [], "entities": [{"text": "MERT objective", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7511861324310303}, {"text": "MERT", "start_pos": 187, "end_pos": 191, "type": "TASK", "confidence": 0.7521793246269226}]}, {"text": "Indeed, these regularizers are scale sensitive, while the MERT objective function is not: scaling the weight vector neither changes the predictions of the linear model nor affects the error count.", "labels": [], "entities": [{"text": "MERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.8228170275688171}]}, {"text": "Hence, MERT can hedge any regularization penalty by maximally scaling down linear model weights.", "labels": [], "entities": []}, {"text": "The first contribution of this paper is to analyze various forms of regularization that are not susceptible to this scaling problem.", "labels": [], "entities": []}, {"text": "We analyze and experiment with 0 , a form of regularization that is scale insensitive.", "labels": [], "entities": []}, {"text": "We also present new parameterizations of 2 regularization, where we apply 2 regularization to scale-senstive linear transforms of the original linear model.", "labels": [], "entities": []}, {"text": "In addition, we introduce efficient methods of incorporating regularization in's exact line searches.", "labels": [], "entities": []}, {"text": "For all of these regularizers, our methods let us find the true optimum of the regularized objective function along the line.", "labels": [], "entities": []}, {"text": "Finally, we address the issue of searching in a high-dimensional space by using the gradient of expected BLEU () to find better search directions for our line searches.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9989509582519531}]}, {"text": "This direction finder addresses one of the serious concerns raised by: MERT widely failed to reach the optimum of a synthetic linear objective function.", "labels": [], "entities": [{"text": "direction finder", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.7327290773391724}, {"text": "MERT", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.4546569585800171}]}, {"text": "In replicating Hopkins and May's experiments, we confirm that existing search algorithms for MERT-including coordinate ascent, Powell's algorithm, and random direction sets)-perform poorly in this experimental condition.", "labels": [], "entities": [{"text": "MERT-including coordinate ascent", "start_pos": 93, "end_pos": 125, "type": "TASK", "confidence": 0.8685353795687357}]}, {"text": "However, when using our gradient-based direction finder, MERT has no problem finding the true optimum even in a 1000-dimensional space.", "labels": [], "entities": [{"text": "direction finder", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.735769510269165}, {"text": "MERT", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.6836182475090027}]}, {"text": "Our results suggest that the combination of a regularized objective function and a gradient-informed line search algorithm enables MERT to scale well with a large number of features.", "labels": [], "entities": [{"text": "MERT", "start_pos": 131, "end_pos": 135, "type": "TASK", "confidence": 0.775693416595459}]}, {"text": "Experiments with up to 3600 features show that these extensions of MERT yield results comparable to), a parameter tuning method known to be effective with large feature sets.", "labels": [], "entities": [{"text": "MERT", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.5914732813835144}]}], "datasetContent": [{"text": "Following Hopkins and May (2011), our experimental setup utilizes both real and synthetic data.", "labels": [], "entities": []}, {"text": "The motivation for using synthetic data is that it is away of gauging the quality of optimization methods, since the data is constructed knowing the global optimum.", "labels": [], "entities": []}, {"text": "Hopkins and May also note that the use of an objective function that is linear in some gold weight vector makes the search much simpler than in areal translation setting, and they suggest that a learner that performs poorly in such a simple scenario has little hope of succeeding in a more complex one.", "labels": [], "entities": [{"text": "areal translation", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.6993865072727203}]}, {"text": "The setup of our synthetic data experiment is almost the same as that performed by.", "labels": [], "entities": []}, {"text": "We generate feature vectors of dimensionality ranging from 10 to 1000.", "labels": [], "entities": []}, {"text": "These features are generated by drawing random numbers uniformly in the interval.", "labels": [], "entities": []}, {"text": "This synthetic dataset consists of S=1000 source \"sentences\", and M=500 \"translation\" hypotheses for each sentence.", "labels": [], "entities": []}, {"text": "A pseudo \"BLEU\" score is then computed for each hypothesis, by computing the dot product between a predefined gold weight vector w * and each feature vector h s,m . By this linear construction, w * is guaranteed to be a global optimum.", "labels": [], "entities": [{"text": "BLEU\" score", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9549147884051005}]}, {"text": "The pseudo-BLEU score is normalized for each M -best list, so that the translation with highest model score according tow * has a BLEU score of 1, and so that the translation with lowest model score for the sentence gets a BLEU of zero.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9789426922798157}, {"text": "BLEU", "start_pos": 223, "end_pos": 227, "type": "METRIC", "confidence": 0.9989951252937317}]}, {"text": "This normalization has no impact on search, but makes results more interpretable.", "labels": [], "entities": []}, {"text": "For our translation experiments, we use multistack phrase-based decoding (.", "labels": [], "entities": []}, {"text": "We report results for two feature sets: non-linear features induced using Gradient Boosting Machines ( and sparse lexicalized reordering features.", "labels": [], "entities": []}, {"text": "We exploit these feature sets (GBM and SparseHRM, respectively) in two distinct experimental conditions, which we detail in the two next paragraphs.", "labels": [], "entities": [{"text": "GBM", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.630101203918457}, {"text": "SparseHRM", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.48385652899742126}]}, {"text": "Both GBM and SparseHRM augment baseline features similar to Moses': relative frequency and lexicalized phrase translation scores for both translation directions; one or two language model features, depending on the language pair; distortion penalty; word and phrase count; six lexicalized reordering features.", "labels": [], "entities": [{"text": "GBM", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.7440637350082397}, {"text": "phrase translation", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.691172868013382}]}, {"text": "For both experimental conditions, phrase tables have maximum phrase length of 7 words on either side.", "labels": [], "entities": []}, {"text": "In reference to, we used the training set (Train) for extracting phrase tables and language models; the Tune set for optimization with MERT or PRO; the Dev set for selecting hyperparameters of PRO and regularized MERT; and the Test set for reporting final results.", "labels": [], "entities": []}, {"text": "In each experimental condition, we first trained weights for the base feature sets, and then decoded the Tune, Dev, and Test datasets, generating 500-best lists for each set.", "labels": [], "entities": []}, {"text": "All results report reranking performance on these lists with different feature sets and optimization methods, based on lower-cased BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9979655742645264}]}, {"text": "The GBM feature set ( consists of about 230 features automatically induced using decision tree weak learners, which derive features using various word-level, phrase-level, and morphological attributes.", "labels": [], "entities": [{"text": "GBM feature set", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9232022364934286}]}, {"text": "For Chinese-English, the training corpus consists of approximately one million sentence pairs from the FBIS and Hong Kong portions of the LDC data for the NIST MT evaluation and the Tune and Test sets are from NIST competitions.", "labels": [], "entities": [{"text": "FBIS", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.9033626914024353}, {"text": "LDC data", "start_pos": 138, "end_pos": 146, "type": "DATASET", "confidence": 0.776530385017395}, {"text": "NIST MT evaluation", "start_pos": 155, "end_pos": 173, "type": "DATASET", "confidence": 0.7678163448969523}]}, {"text": "A 4-gram language model was trained on the Xinhua portion of the English Gigaword corpus and on the target side of the bitext.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 65, "end_pos": 88, "type": "DATASET", "confidence": 0.8667722741762797}]}, {"text": "For Finnish-English we used a dataset from a technical domain of software manuals.", "labels": [], "entities": []}, {"text": "For this language pair we used two language models: one very large model trained on billions of words, and another language model trained from the target side of the parallel training set.", "labels": [], "entities": []}, {"text": "The SparseHRM set (Cherry, 2013) contains 3600 sparse reordering features.", "labels": [], "entities": [{"text": "SparseHRM set (Cherry, 2013)", "start_pos": 4, "end_pos": 32, "type": "DATASET", "confidence": 0.9373703939574105}]}, {"text": "For each phrase, the features take the form of indicators describing its orientation in the derivation, and its lexical content in terms of word clusters or frequent words.", "labels": [], "entities": []}, {"text": "Figure 2: Change in BLEU score and cosine similarity to the gold weight vector w * as the number of features increases, using the noisy synthetic experiments.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9800378382205963}]}, {"text": "The gradient-based direction finding method is barely affected by the noise.", "labels": [], "entities": [{"text": "direction finding", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8257521390914917}]}, {"text": "The increase of the number of dimensions enables our direction finder to find a slightly better optimum, which moved away from w * due to noise.", "labels": [], "entities": [{"text": "direction finder", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.8982241451740265}]}, {"text": "language models were trained on the target side of the parallel training data for both Arabic and Chinese.", "labels": [], "entities": []}, {"text": "The Chinese systems development set is taken from the NIST mt05 evaluation set, augmented with some material reserved from our NIST training corpora in order to better cover newsgroup and weblog domains.", "labels": [], "entities": [{"text": "Chinese systems development set", "start_pos": 4, "end_pos": 35, "type": "DATASET", "confidence": 0.616310141980648}, {"text": "NIST mt05 evaluation set", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.9681604504585266}, {"text": "NIST training corpora", "start_pos": 127, "end_pos": 148, "type": "DATASET", "confidence": 0.9194809198379517}]}], "tableCaptions": [{"text": " Table 1: Datasets for the two experimental conditions.", "labels": [], "entities": []}, {"text": " Table 2: BLEU scores for GBM features. Model parameters were optimized on the Tune set. For PRO and regularized  MERT, we optimized with different hyperparameters (regularization weight, etc.), and retained for each experimental  condition the model that worked best on Dev. The table shows the performance of these retained models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9983174800872803}, {"text": "Tune set", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.8685246109962463}, {"text": "MERT", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.7714411020278931}]}, {"text": " Table 3: BLEU scores for SparseHRM features. Notes in", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986359477043152}]}]}