{"title": [], "abstractContent": [{"text": "Wikification, commonly referred to as Disam-biguation to Wikipedia (D2W), is the task of identifying concepts and entities in text and disambiguating them into the most specific corresponding Wikipedia pages.", "labels": [], "entities": [{"text": "Disam-biguation to Wikipedia (D2W)", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.4782201200723648}]}, {"text": "Previous approaches to D2W focused on the use of local and global statistics over the given text, Wikipedia articles and its link structures, to evaluate context compatibility among a list of probable candidates.", "labels": [], "entities": []}, {"text": "However, these methods fail (often, embarrassingly), when some level of text understanding is needed to support Wikification.", "labels": [], "entities": []}, {"text": "In this paper we introduce a novel approach to Wikification by incorporating , along with statistical methods, richer relational analysis of the text.", "labels": [], "entities": []}, {"text": "We provide an extensible, efficient and modular Integer Linear Programming (ILP) formulation of Wik-ification that incorporates the entity-relation inference problem, and show that the ability to identify relations in text helps both candidate generation and ranking Wikipedia titles considerably.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 234, "end_pos": 254, "type": "TASK", "confidence": 0.7356379628181458}]}, {"text": "Our results show significant improvements in both Wikification and the TAC Entity Linking task.", "labels": [], "entities": [{"text": "TAC Entity Linking task", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.8297874182462692}]}], "introductionContent": [{"text": "Wikification (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion.", "labels": [], "entities": [{"text": "Wikification (D2W)", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8017807602882385}, {"text": "knowledge expansion", "start_pos": 288, "end_pos": 307, "type": "TASK", "confidence": 0.7287114262580872}]}, {"text": "D2W has been studied extensively recently) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution ) to entity linking and knowledge population.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.8086451292037964}, {"text": "Knowledge Acquisition", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.68455870449543}, {"text": "coreference resolution", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.8811208605766296}, {"text": "entity linking", "start_pos": 186, "end_pos": 200, "type": "TASK", "confidence": 0.8132595419883728}]}, {"text": "Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T ; this mapping needs to take into account our understanding of the text as well as background knowledge that is often needed to determine the most appropriate title.", "labels": [], "entities": []}, {"text": "We also allow a special NIL title that captures all mentions that are outside Wikipedia.", "labels": [], "entities": []}, {"text": "Earlier approaches treated this task as a wordsense disambiguation (WSD) problem, which was later enhanced with a certain level of global reasoning, but essentially all approaches focused on generic statistical features in order to achieve robust disambiguation.", "labels": [], "entities": [{"text": "wordsense disambiguation (WSD)", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.8199202537536621}]}, {"text": "It was shown that by disambiguating to the most likely title for every surface, independently maximizing the conditional probability Pr(title|surf ace), we already achieve a very competitive baseline on several Wikification datasets ).", "labels": [], "entities": [{"text": "conditional probability Pr", "start_pos": 109, "end_pos": 135, "type": "METRIC", "confidence": 0.7349996964136759}, {"text": "Wikification datasets", "start_pos": 211, "end_pos": 232, "type": "DATASET", "confidence": 0.9444833695888519}]}, {"text": "This strong statistical baseline makes use of the relatively comprehensive coverage of the existing Wikipedia links from surface strings to Wikipedia titles.", "labels": [], "entities": []}, {"text": "Although more involved statistical features are required in order to make substantial improvements, global features such as context TF-IDF, better string similarity, etc., statistics-based Wikification systems give a fairly coherent set of disambiguation when sufficient context is available.", "labels": [], "entities": []}, {"text": "Consider the following example: Earth's biosphere then significantly altered the atmospheric and other basic physical conditions, which enabled the proliferation of organisms.", "labels": [], "entities": []}, {"text": "The atmosphere is composed of 78.09% nitrogen, 20.95% oxygen, 0.93% argon, 0.039% carbon dioxide, and small amounts of...", "labels": [], "entities": []}, {"text": "The baseline system we adopted ), one of the best Wikification systems, already disambiguates atmosphere correctly to the title Earth's atmosphere instead of the more general title Atmosphere, making use of the concept Earth in its local context to resolve the mention to the more specific title that better coheres with the topic.", "labels": [], "entities": []}, {"text": "However, consider the following example: Ex.", "labels": [], "entities": []}, {"text": "1 \"As Mubarak, the wife of deposed Egyptian President Hosni Mubarak got older, her influence...\"", "labels": [], "entities": []}, {"text": "The bold faced name should be mapped to Suzanne Mubarak, but all existing Wikification systems map both names in this sentence to the dominant page (the most linked page) of Hosni Mubarak, failing to understand the relation between them, which should prevent them from being mapped to the same page.", "labels": [], "entities": []}, {"text": "A certain level of text understanding is required even to be able to generate a good list of title candidates.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7620435059070587}]}, {"text": "For example, in: Ex.", "labels": [], "entities": []}, {"text": "2 \"...ousted longtime Yugoslav President Slobodan Milo\u0161evi\u00b4Milo\u0161evi\u00b4c in October.", "labels": [], "entities": []}, {"text": "Mr. Milo\u0161evi\u00b4Milo\u0161evi\u00b4c's Socialist Party...\" the bold-faced concept should be mapped to the page of the Socialist Party of Serbia, which is far down the list of titles that could be related to \"Socialist Party\"; making this title a likely candidate requires understanding the possessive relation with Milo\u0161evi\u00b4Milo\u0161evi\u00b4c and then making the knowledge-informed decision that he is more related to Socialist Party of Serbia than any other possible titles.", "labels": [], "entities": []}, {"text": "3 \"James Senn, director of Robinson College's Center for Global Business Leadership at Georgia State University...\" we must link Robinson College to J.", "labels": [], "entities": [{"text": "Robinson College", "start_pos": 129, "end_pos": 145, "type": "DATASET", "confidence": 0.8950743079185486}]}, {"text": "Mack Robinson College of Business which is located at Georgia State University instead of Robinson College, Cambridge, which is the only probable title linked by the surface Robinson College in the version of the Wikipedia dump we used.", "labels": [], "entities": [{"text": "Mack Robinson College of Business", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.7819049537181855}, {"text": "Robinson College, Cambridge", "start_pos": 90, "end_pos": 117, "type": "DATASET", "confidence": 0.8513846844434738}]}, {"text": "These examples further illustrate that, along with understanding the relation expressed in the text, we need to access background knowledge sources and to deal with variability in surface representation across the text, Wikipedia, and knowledge, in order to reliably address the Wikification problem.", "labels": [], "entities": []}, {"text": "In this paper we focus on understanding those natural language constructs that will allow eliminating these \"obvious\" (to a human reader) mistakes from Wikification.", "labels": [], "entities": []}, {"text": "In particular, we focus on resolving coreference and a collection of local syntacticosemantic relations (Chan and Roth, 2011); better understanding the relational structure of the text allows us to generate title candidates more accurately given the text, rank these candidates better and determine when a mention in text has no corresponding title in Wikipedia and should be mapped to NIL, a key problem in Wikification.", "labels": [], "entities": []}, {"text": "Moreover, it allows us to access external knowledge based resources more effectively in order to support these decisions.", "labels": [], "entities": []}, {"text": "We incorporate the outcome of our relational analysis, along with the associated features extracted from external sources and the \"standard\" wikification statistical features, into an ILP-based inference framework that globally determines the best assignment of mentions to titles in a given document.", "labels": [], "entities": []}, {"text": "We show that by leveraging a better understanding of the textual relations, we can substantially improve the Wikification performance.", "labels": [], "entities": []}, {"text": "Our system significantly outperforms all the top Wikification systems on the widely adopted standard datasets and shows state-of-the-art results when evaluated (without being trained directly) on the TAC 2011 Entity Linking task.", "labels": [], "entities": [{"text": "TAC 2011 Entity Linking task", "start_pos": 200, "end_pos": 228, "type": "TASK", "confidence": 0.7948751449584961}]}], "datasetContent": [{"text": "This section describes our experimental evaluation.", "labels": [], "entities": []}, {"text": "We compare our system against the top D2W systems and perform several experiments to analyze and better understand the power of our approach.", "labels": [], "entities": []}, {"text": "We based our work on the GLOW system from ) to initialize the candidates and corresponding priors s k i in our objective function.", "labels": [], "entities": []}, {"text": "Both the baseline system and our new system are publicly available 4 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on Wikification datasets, BOT F1  Performance. Our system, Relational Inference (RI) ex- hibits significant improvements over M&W (Milne and  Witten, 2008) and R&R (Ratinov et al., 2011).", "labels": [], "entities": [{"text": "BOT F1  Performance", "start_pos": 48, "end_pos": 67, "type": "METRIC", "confidence": 0.7752522428830465}]}, {"text": " Table 2: Ablation study on Wikification datasets, BOT F1  Performance", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9913849830627441}, {"text": "Wikification datasets", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.9632786512374878}, {"text": "BOT F1  Performance", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.6770212550957998}]}, {"text": " Table 3: TAC2011 Entity Linking performance. MA is  Micro-Average. LLC (Monahan et al., 2011) is the best  performing system in terms of B 3 F1 while MS-MLI  (Cucerzan, 2011) is the best in terms of Micro-Average.  Cogcomp (Ratinov", "labels": [], "entities": [{"text": "TAC2011 Entity Linking", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6262135605017344}, {"text": "MA", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.9548997282981873}, {"text": "B 3 F1", "start_pos": 138, "end_pos": 144, "type": "METRIC", "confidence": 0.9587852954864502}, {"text": "Micro-Average", "start_pos": 200, "end_pos": 213, "type": "METRIC", "confidence": 0.7627760767936707}]}]}