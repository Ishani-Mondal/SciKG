{"title": [{"text": "Translation with Source Constituency and Dependency Trees", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9281247854232788}]}], "abstractContent": [{"text": "We present a novel translation model, which simultaneously exploits the constituency and dependency trees on the source side, to combine the advantages of two types of trees.", "labels": [], "entities": []}, {"text": "We take head-dependents relations of dependency trees as backbone and incorporate phrasal nodes of constituency trees as the source side of our translation rules, and the target side as strings.", "labels": [], "entities": []}, {"text": "Our rules hold the property of long distance reorderings and the compatibility with phrases.", "labels": [], "entities": []}, {"text": "Large-scale experimental results show that our model achieves significantly improvements over the constituency-to-string (+2.45 BLEU on average) and dependency-to-string (+0.91 BLEU on average) models , which only employ single type of trees, and significantly outperforms the state-of-the-art hierarchical phrase-based model (+1.12 BLEU on average), on three Chinese-English NIST test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9791311025619507}, {"text": "BLEU", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.8818670511245728}, {"text": "BLEU", "start_pos": 333, "end_pos": 337, "type": "METRIC", "confidence": 0.9770903587341309}, {"text": "NIST test sets", "start_pos": 376, "end_pos": 390, "type": "DATASET", "confidence": 0.8900250991185507}]}], "introductionContent": [{"text": "In recent years, syntax-based models have become a hot topic in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.7275658945242564}]}, {"text": "According to the linguistic structures, these models can be broadly divided into two categories: constituencybased models), and dependency-based models).", "labels": [], "entities": []}, {"text": "These two kinds of models have their own advantages, as they capture different linguistic phenomena.", "labels": [], "entities": []}, {"text": "Constituency trees describe how words and sequences of words combine to form constituents, and constituency-based models show better compatibility with phrases.", "labels": [], "entities": []}, {"text": "However, dependency trees describe the grammatical relation between words of the sentence, and represent long distance dependencies in a concise manner.", "labels": [], "entities": []}, {"text": "Dependency-based models, such as dependency-to-string model), exhibit better capability of long distance reorderings.", "labels": [], "entities": []}, {"text": "In this paper, we propose to combine the advantages of source side constituency and dependency trees.", "labels": [], "entities": []}, {"text": "Since the dependency tree is structurally simpler and directly represents long distance dependencies, we take dependency trees as the backbone and incorporate constituents to them.", "labels": [], "entities": []}, {"text": "Our model employs rules that represent the source side as head-dependents relations which are incorporated with constituency phrasal nodes, and the target side as strings.", "labels": [], "entities": []}, {"text": "A head-dependents relation) is composed of ahead and all its dependents in dependency trees, and it encodes phrase pattern and sentence pattern (typically long distance reordering relations).", "labels": [], "entities": []}, {"text": "With the advantages of head-dependents relations, the translation rules of our model hold the property of long distance reorderings and the compatibility with phrases.", "labels": [], "entities": []}, {"text": "Our new model (Section 2) extracts rules from word-aligned pairs of source trees (constituency and dependency) and target strings (Section 3), and translate source trees into target strings by employing a bottom-up chart-based algorithm (Section 4).", "labels": [], "entities": []}, {"text": "Compared with the constituency-to-string () and dependency-to-string () models that only employ a single type of trees, our Figure 1: Illustration of phrases that cannot be captured by a dependency tree (b) while captured by a constituency tree (a), where the bold phrasal nodes NP 1 , VP 2 , VP 3 indicate the phrases which cannot be captured by dependency syntactic phrases.", "labels": [], "entities": []}, {"text": "(c) is the corresponding bilingual sentences.", "labels": [], "entities": []}, {"text": "The subscripts of phrasal nodes are used for distinguishing the nodes with same phrasal categories.", "labels": [], "entities": []}, {"text": "approach yields encouraging results by exploiting two types of trees.", "labels": [], "entities": []}, {"text": "Large-scale experiments (Section 5) on Chinese-English translation show that our model significantly outperforms the state-ofthe-art single constituency-to-string model by averaged +2.45 BLEU points, dependency-to-string model by averaged +0.91 BLEU points, and hierarchical phrase-based model) by averaged +1.12 BLEU points, on three Chinese-English NIST test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 187, "end_pos": 191, "type": "METRIC", "confidence": 0.9937030673027039}, {"text": "BLEU", "start_pos": 313, "end_pos": 317, "type": "METRIC", "confidence": 0.9918745160102844}, {"text": "NIST test sets", "start_pos": 351, "end_pos": 365, "type": "DATASET", "confidence": 0.9174802501996359}]}], "datasetContent": [{"text": "We evaluated the performance of our model by comparing with hierarchical phrase-based model, constituency-to-string model () and dependency-to-string model) on Chinese-English translation.", "labels": [], "entities": []}, {"text": "First, we describe data preparation (Section 5.1) and systems (Section 5.2).", "labels": [], "entities": [{"text": "data preparation", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.7510871589183807}]}, {"text": "Then, we validate that our model significantly outperforms all the other baseline models (Section 5.3).", "labels": [], "entities": []}, {"text": "Finally, we give detail analysis (Section 5.4).", "labels": [], "entities": [{"text": "detail", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9881510734558105}]}], "tableCaptions": [{"text": " Table 1: Statistics of the extracted rules on training data and the BLEU scores (%) on the test sets of different systems.  The \"+\" denotes that the rules are composed of syntactic translation rules and bilingual phrases (32.5M). The \"*\"  denotes that the results are significantly better than all the other systems (p<0.01).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9995917677879333}]}]}