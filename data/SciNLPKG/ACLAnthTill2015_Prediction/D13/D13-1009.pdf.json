{"title": [{"text": "Question Difficulty Estimation in Community Question Answering Services *", "labels": [], "entities": [{"text": "Question Difficulty Estimation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.796545018752416}, {"text": "Community Question Answering", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.5891396204630533}]}], "abstractContent": [{"text": "In this paper, we address the problem of estimating question difficulty in community question answering services.", "labels": [], "entities": [{"text": "estimating question difficulty", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.7551580270131429}, {"text": "community question answering", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.5935705900192261}]}, {"text": "We propose a competition-based model for estimating question difficulty by leveraging pairwise comparisons between questions and users.", "labels": [], "entities": [{"text": "estimating question difficulty", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.8229955832163492}]}, {"text": "Our experimental results show that our model significantly outperforms a PageRank-based approach.", "labels": [], "entities": []}, {"text": "Most importantly, our analysis shows that the text of question descriptions reflects the question difficulty.", "labels": [], "entities": []}, {"text": "This implies the possibility of predicting question difficulty from the text of question descriptions.", "labels": [], "entities": [{"text": "predicting question difficulty", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.8401445150375366}]}], "introductionContent": [{"text": "In recent years, community question answering (C-QA) services such as Stackoverflow and Yahoo!", "labels": [], "entities": [{"text": "community question answering (C-QA)", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.7728176911671957}]}, {"text": "Answers 2 have seen rapid growth.", "labels": [], "entities": []}, {"text": "A great deal of research effort has been conducted on CQA, including: (1) question search (; (2) answer quality estimation (; (3) user expertise estimation); and (4) question routing ( However, less attention has been paid to question difficulty estimation in CQA.", "labels": [], "entities": [{"text": "question search", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.7519881427288055}, {"text": "answer quality estimation", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.5454376935958862}, {"text": "question routing", "start_pos": 166, "end_pos": 182, "type": "TASK", "confidence": 0.8244361281394958}, {"text": "question difficulty estimation", "start_pos": 226, "end_pos": 256, "type": "TASK", "confidence": 0.5771941244602203}]}, {"text": "Question difficulty estimation can benefit many applications: (1) Experts are usually under time constraints.", "labels": [], "entities": [{"text": "Question difficulty estimation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7247844735781351}]}, {"text": "We do not want to bore experts by routing every question (including both easy and hard ones) to them.", "labels": [], "entities": []}, {"text": "Assigning questions to experts by matching question difficulty with expertise level, not just question topic, will make better use of the experts' time and expertise.", "labels": [], "entities": []}, {"text": "(2) found that winning the point awards offered by the reputation system is a driving factor in user participation in CQA.", "labels": [], "entities": []}, {"text": "Question difficulty estimation would be helpful in designing a better incentive mechanism by assigning higher point awards to more difficult questions.", "labels": [], "entities": [{"text": "Question difficulty estimation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6119450827439626}]}, {"text": "(3) Question difficulty estimation can help analyze user behavior in CQA, since users may make strategic choices when encountering questions of different difficulty levels.", "labels": [], "entities": [{"text": "Question difficulty estimation", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.656223734219869}]}, {"text": "To the best of our knowledge, not much research has been conducted on the problem of estimating question difficulty in CQA.", "labels": [], "entities": [{"text": "estimating question difficulty", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.7451875607172648}]}, {"text": "The most relevant work is a PageRank-based approach proposed by to estimate task difficulty in crowdsourcing contest services.", "labels": [], "entities": []}, {"text": "Their key idea is to construct a graph of tasks: creating an edge from a task t 1 to a task t 2 when a user u wins task t 1 but loses task t 2 , implying that task t 2 is likely to be more difficult than task t 1 . Then the standard PageRank algorithm is employed on the task graph to estimate PageRank score (i.e., difficulty score) of each task.", "labels": [], "entities": [{"text": "difficulty score)", "start_pos": 316, "end_pos": 333, "type": "METRIC", "confidence": 0.9670817255973816}]}, {"text": "This approach implicitly assumes that task difficulty is the only factor affecting the outcomes of competitions (i.e. the best answer).", "labels": [], "entities": []}, {"text": "However, the outcomes of competitions depend on both the difficulty levels of tasks and the expertise levels of competitors (i.e. other answerers).", "labels": [], "entities": []}, {"text": "Inspired by , we propose a competition-based approach which jointly models question difficulty and user expertise level.", "labels": [], "entities": []}, {"text": "Our approach is based on two intuitive assumptions: given a question answering thread, the difficulty score of the question is higher than the expertise score of the asker, but lower than that of the best answerer; (2) the expertise score of the best answerer is higher than that of the asker as well as all other answerers.", "labels": [], "entities": [{"text": "question answering thread", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.7706271211306254}, {"text": "difficulty score", "start_pos": 91, "end_pos": 107, "type": "METRIC", "confidence": 0.9569301009178162}]}, {"text": "Given the two assumptions, we can determine the question difficulty score and user expertise score through pairwise comparisons between (1) a question and an asker, (2) a question and a best answerer, (3) a best answerer and an asker, and (4) a best answerer and all other non-best answerers.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: \u2022 We propose a competition-based approach to estimate question difficulty (Sec. 2).", "labels": [], "entities": [{"text": "estimate question difficulty", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.8945901989936829}]}, {"text": "Our model significantly outperforms the PageRank-based approach () for estimating question difficulty on the data of Stack Overflow (Sec. 3.2).", "labels": [], "entities": []}, {"text": "\u2022 Additionally, we calibrate question difficulty scores across two CQA services to verify the effectiveness of our model (Sec. 3.3).", "labels": [], "entities": []}, {"text": "\u2022 Most importantly, we demonstrate that different words or tags in the question descriptions indicate question difficulty levels.", "labels": [], "entities": []}, {"text": "This implies the possibility of predicting question difficulty purely from the text of question descriptions (Sec. 3.4).", "labels": [], "entities": [{"text": "predicting question difficulty", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.8896861871083578}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The statistics of the data sets.", "labels": [], "entities": []}]}