{"title": [{"text": "A multi-Teraflop Constituency Parser using GPUs", "labels": [], "entities": []}], "abstractContent": [{"text": "Constituency parsing with rich grammars remains a computational challenge.", "labels": [], "entities": [{"text": "Constituency parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8054631352424622}]}, {"text": "Graphics Processing Units (GPUs) have previously been used to accelerate CKY chart evaluation , but gains over CPU parsers were modest.", "labels": [], "entities": [{"text": "CKY chart evaluation", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.7448249657948812}]}, {"text": "In this paper, we describe a collection of new techniques that enable chart evaluation at close to the GPU's practical maximum speed (a Teraflop), or around a half-trillion rule evaluations per second.", "labels": [], "entities": [{"text": "chart evaluation", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.6687149703502655}, {"text": "GPU", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.9562269449234009}]}, {"text": "Net parser performance on a 4-GPU system is over 1 thousand length-30 sentences/second (1 trillion rules/sec), and 400 general sentences/second for the Berkeley Parser Grammar.", "labels": [], "entities": []}, {"text": "The techniques we introduce include grammar compilation, recursive symbol blocking, and cache-sharing.", "labels": [], "entities": [{"text": "grammar compilation", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7979736030101776}, {"text": "recursive symbol blocking", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.6726054151852926}]}], "introductionContent": [{"text": "Constituency parsing with high accuracy (e.g. latent variable) grammars remains a computational challenge.", "labels": [], "entities": [{"text": "Constituency parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7904495000839233}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9897288084030151}]}, {"text": "The O(Gs 3 ) complexity of full CKY parsing fora grammar with G rules and sentence lengths, is daunting.", "labels": [], "entities": [{"text": "O(Gs 3 ) complexity", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.9020086526870728}, {"text": "CKY parsing fora grammar", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.7911212593317032}]}, {"text": "Even with a host of pruning heuristics, the high cost of constituency parsing limits its uses.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.8212220072746277}]}, {"text": "The most recent Berkeley latent variable grammar for instance, has 1.7 million rules and requires about a billion rule evaluations for inside scoring of a single length-30 sentence.", "labels": [], "entities": []}, {"text": "GPUs have previously been used to accelerate CKY evaluation, but gains over CPU parsers were modest.", "labels": [], "entities": [{"text": "CKY evaluation", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.8374719321727753}]}, {"text": "e.g. in a GPU parser is described for the Berkeley Parser grammar which achieves 5 sentences per second on the first 1000 sentences of Penn Treebank section 22, which is comparable with the best CPU parsers.", "labels": [], "entities": [{"text": "Penn Treebank section 22", "start_pos": 135, "end_pos": 159, "type": "DATASET", "confidence": 0.9864235669374466}]}, {"text": "Our parser achieves 120 sentences/second per GPU for this sentence set, and over 250 sentences/sec on length \u2264 30 sentences.", "labels": [], "entities": []}, {"text": "These results use a Berkeley Grammar approximately twice as big as, an apparent 50x improvement.", "labels": [], "entities": [{"text": "Berkeley Grammar", "start_pos": 20, "end_pos": 36, "type": "DATASET", "confidence": 0.9257535040378571}]}, {"text": "On a 4-GPU system, we achieve 1000 sentences/sec for length \u2264 30 sentences.", "labels": [], "entities": []}, {"text": "This is 2 orders of magnitude faster than CPU implementations that rely heavily on pruning, and 5 orders of magnitude faster than full CKY evaluation on a CPU.", "labels": [], "entities": []}, {"text": "Key to these results is a collection of new techniques that enable GPU parsing at close to the GPU's practical maximum speed (a Teraflop for recent GPUs), or around a half-trillion rule evaluations per second.", "labels": [], "entities": [{"text": "GPU parsing", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.6207755208015442}]}, {"text": "The techniques are: 1.", "labels": [], "entities": []}, {"text": "Grammar compilation, which allows registerto-register code for application of grammar rules.", "labels": [], "entities": [{"text": "Grammar compilation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7693061232566833}]}, {"text": "This gives an order of magnitude (10x) speedup over alternative approaches that use shared memory.", "labels": [], "entities": []}, {"text": "2. Symbol/rule blocking of the grammar to respect register, constant and instruction cache limits.", "labels": [], "entities": [{"text": "Symbol/rule blocking", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.6235094219446182}]}, {"text": "This is precondition for 1 above, and the details of the partitioning have a big (> 4x) effect on performance.", "labels": [], "entities": []}, {"text": "3. Sub-block partitioning to distribute rules across the stream processors of the GPU and allow L2 cache acceleration.", "labels": [], "entities": [{"text": "Sub-block partitioning", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.6875031888484955}]}, {"text": "A factor of 2 improvement.", "labels": [], "entities": []}, {"text": "The code generated by our parser comes close to the theoretical limits of the GPU.", "labels": [], "entities": [{"text": "GPU", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.9575504064559937}]}, {"text": "80% of grammar rules are evaluated using a single-cycle register-to-register instruction.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parser was tested in an desktop computer with one Intel E5-2650 processor, 64 GB ram, and 2 GTX-690 dual GPUs (effectively 4 GTX-680 GPUs).", "labels": [], "entities": []}, {"text": "The high-level parser code is written in a matrix library in the Scala language, which access GPU code through JNI and using the JCUDA wrapper library for CUDA TM . XX-kernel throughput was 900 Gflops per GPU for sum-product calculation (which uses a single FMA for most rules) and 700 Gflops per GPU for max-sum calculations (which requires two instructions for most rules).", "labels": [], "entities": [{"text": "JCUDA wrapper", "start_pos": 129, "end_pos": 142, "type": "DATASET", "confidence": 0.86848384141922}, {"text": "sum-product calculation", "start_pos": 213, "end_pos": 236, "type": "TASK", "confidence": 0.7850763201713562}]}, {"text": "Net parser throughput including max-sum CKY evaluation, Viterbi scoring traspose-copy etc was between 500 and 600 gigaflops per GPU, or about 2 teraflops total.", "labels": [], "entities": [{"text": "CKY evaluation", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.6012553125619888}]}, {"text": "Parsing max-length-30 sentences from the Penn Treebank test set ran at 250 sentences/sec per GPU, or 1000 sentences/sec total.", "labels": [], "entities": [{"text": "Penn Treebank test set", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.9953993707895279}]}, {"text": "General sentences were parsed at about half this rate, 120 sentences/sec per GPU, or 480 sentences/sec for the system.", "labels": [], "entities": [{"text": "GPU", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.9630473852157593}]}], "tableCaptions": [{"text": " Table 1: Instructions per cycle per SMX in generation 3.0  and 3.5 Kepler TM devices", "labels": [], "entities": []}]}