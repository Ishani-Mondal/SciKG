{"title": [{"text": "Discourse Level Explanatory Relation Extraction from Product Reviews Using First-order Logic", "labels": [], "entities": [{"text": "Discourse Level Explanatory Relation Extraction from Product Reviews", "start_pos": 0, "end_pos": 68, "type": "TASK", "confidence": 0.7337188459932804}]}], "abstractContent": [{"text": "Explanatory sentences are employed to clarify reasons, details, facts, and soon.", "labels": [], "entities": []}, {"text": "High quality online product reviews usually include not only positive or negative opinions, but also a variety of explanations of why these opinions were given.", "labels": [], "entities": []}, {"text": "These explanations can help readers get easily comprehensible information of the discussed products and aspects.", "labels": [], "entities": []}, {"text": "Moreover, explanatory relations can also benefit sentiment analysis applications.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9651644229888916}]}, {"text": "In this work, we focus on the task of identifying subjective text segments and extracting their corresponding explanations from product reviews in discourse level.", "labels": [], "entities": []}, {"text": "We propose a novel joint extraction method using first-order logic to model rich linguistic features and long distance constraints.", "labels": [], "entities": [{"text": "joint extraction", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.7329060733318329}]}, {"text": "Experimental results demonstrate the effectiveness of the proposed method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Through analyzing product reviews with high helpfulness ratings assigned by readers, we find that a large number of explanatory sentences are used to clarify the causes, details, or consequences of opinions.", "labels": [], "entities": []}, {"text": "According to the statistic based on the dataset we crawled from a popular product review website, more than 56.1% opinion expressions are further explained by other sentences.", "labels": [], "entities": []}, {"text": "Since most consumers are not experts, these explanations would bring lots of helpful and easy comprehension information for them.", "labels": [], "entities": []}, {"text": "Suggestions about writing a product review also advise authors to include not only whether they like or dislike a product, but also why.", "labels": [], "entities": []}, {"text": "For example, let us consider the following snippets extracted from online reviews: Example 1: TVs with lower refresh rates may suffer from motion blur.", "labels": [], "entities": []}, {"text": "If you're watching a fast-paced football game, for example, you may notice a bit of blurring as the players runaround the field.", "labels": [], "entities": []}, {"text": "Example 2: The LED screen is highly reflective.", "labels": [], "entities": []}, {"text": "The reflection of my own face makes it very hard to seethe subject I am trying to shoot.", "labels": [], "entities": []}, {"text": "The first sentence of example 1 expresses negative opinion about refresh rate, which is one of the most important attributes of TV.", "labels": [], "entities": [{"text": "refresh rate", "start_pos": 65, "end_pos": 77, "type": "METRIC", "confidence": 0.907151609659195}]}, {"text": "The second sentence describes the consequence of it through an example.", "labels": [], "entities": []}, {"text": "In example 2, detail descriptions are used to explain the reflection problem of the camera screen.", "labels": [], "entities": []}, {"text": "Although, explanations provide valuable information, to the best of our knowledge, there is no existing work that deals with explanation extraction for opinions in discourse level.", "labels": [], "entities": [{"text": "explanation extraction", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.7549823224544525}]}, {"text": "We think that if explanatory relations can be automatically identified from reviews, sentiment analysis applications may benefit from it.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.953462690114975}]}, {"text": "Existing opinion mining approaches mainly focus on subjective text.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7334481328725815}]}, {"text": "They try to determine the subjectivity and polarity of fragments of documents (e.g. a paragraph, a sentence, a phrase and a word) (;).", "labels": [], "entities": []}, {"text": "Fine-grained methods were also introduced to extract opinion holder, opinion expression, opinion target, and other opinion elements ( reviews-guidelines 2011;.", "labels": [], "entities": []}, {"text": "Major research directions and challenges of sentiment analysis can also be found in surveys.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.9583653807640076}]}, {"text": "In this work, we aim to identify subjective text segments and extract their corresponding explanations from product reviews in discourse level.", "labels": [], "entities": []}, {"text": "We propose to use Markov Logic Networks (ML-N) () to learn the joint model for subjective classification and explanatory relation extraction.", "labels": [], "entities": [{"text": "explanatory relation extraction", "start_pos": 109, "end_pos": 140, "type": "TASK", "confidence": 0.6502987444400787}]}, {"text": "MLN has been applied in several natural language processing tasks () and demonstrated its advantages.", "labels": [], "entities": []}, {"text": "It can easily incorporate rich linguistic features and global constraints by designing various logic formulas, which can also be viewed as templates or rules.", "labels": [], "entities": []}, {"text": "Logic formulas are combined in a probabilistic framework to model soft constraints.", "labels": [], "entities": []}, {"text": "Hence, the proposed approach can benefit a lot from this framework.", "labels": [], "entities": []}, {"text": "To evaluate the proposed method, we crawled a large number of product reviews and constructed a labeled corpus through Amazon's Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 119, "end_pos": 143, "type": "DATASET", "confidence": 0.834923580288887}]}, {"text": "Two tasks were deployed for labeling the corpus.", "labels": [], "entities": []}, {"text": "We compared the proposed method with state-ofthe-art methods on the dataset.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate that the proposed approach can achieve better performance than state-of-the-art methods.", "labels": [], "entities": []}, {"text": "The remaining part of this paper is organized as follows: In Section 2, we define the problem and give some examples to show the challenges of this task.", "labels": [], "entities": []}, {"text": "Section 3 describes the proposed MLN based method.", "labels": [], "entities": [{"text": "MLN", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9532181024551392}]}, {"text": "Dataset construction, experimental results and analyses are given in Section 4.", "labels": [], "entities": [{"text": "Dataset construction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7928920388221741}]}, {"text": "In Section 5, we present the related work and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Stanford parser () is used for extracting features from dependency parse trees.", "labels": [], "entities": []}, {"text": "For resolving Markov logic network, we use the toolkit thebeast 7 . The detailed setting of thebeast engine is as follows: The inference algorithm is the MAP inference with a cutting plane approach.", "labels": [], "entities": []}, {"text": "For parameter learning, the weights for formulas are updated by an online learning algorithm with MIRA update rule.", "labels": [], "entities": [{"text": "parameter learning", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7320635318756104}, {"text": "MIRA update rule", "start_pos": 98, "end_pos": 114, "type": "METRIC", "confidence": 0.9457670648892721}]}, {"text": "All the initial weights are set to zeros.", "labels": [], "entities": []}, {"text": "The number of iterations is set to 10 epochs.", "labels": [], "entities": []}, {"text": "Evaluation metrics used for subjectivity classification and relation extraction throughout the experiments include: Precision, Recall, and F1-score.", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.822903037071228}, {"text": "relation extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8907525837421417}, {"text": "Precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9990541338920593}, {"text": "Recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9914612770080566}, {"text": "F1-score", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9986213445663452}]}, {"text": "We randomly select 80% reviews as training set and the others as testing set.", "labels": [], "entities": []}, {"text": "Since the dataset is newly created for this task, to compare the performance of the proposed method to other models, we also reimplemented several state-7 http://code.google.com/p/thebeast of-the-art methods for comparison.", "labels": [], "entities": []}, {"text": "\u2022 CRF-Subj: We follow the method proposed by, which regard the subjectivity of all clauses throughout a paragraph as a sequential flow of sentiments and use CRFs to model it.", "labels": [], "entities": []}, {"text": "The feature sets are similar as the local formulas for MLN including words, POS tags, dependency relations, and opinion lexicon.", "labels": [], "entities": []}, {"text": "\u2022 RAE-Subj: Socher et al. proposed to use recursive autoencoders for sentence-level predication of sentiment label distributions.", "labels": [], "entities": [{"text": "RAE-Subj", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.6080394983291626}, {"text": "sentence-level predication of sentiment label distributions", "start_pos": 69, "end_pos": 128, "type": "TASK", "confidence": 0.7943058808644613}]}, {"text": "To compare with it, we also reimplement their method without any hand designed lexicon.", "labels": [], "entities": []}, {"text": "\u2022 PDTB-Rel: For discourse relation extraction, we use \"PDTB-Styled End-to-End Discourse Parser\" (  to extract discourse level relations as baseline.", "labels": [], "entities": [{"text": "discourse relation extraction", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.7196665008862814}]}, {"text": "Since it is a general discourse relations identification algorithms, \"Cause\", \"Pragmatic Cause\", \"Instantiation\", and \"Restatement\" relation types are treated as explanatory relation in this work.", "labels": [], "entities": [{"text": "discourse relations identification", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.7072618206342062}]}, {"text": "\u2022 SVM-Rel: We also use LibSVM ( to classify the relations between clauses.", "labels": [], "entities": []}, {"text": "Following the configurations reported by, we use linear kernel and probability estimation to model it. shows the comparisons of the proposed method with the state-of-the-art systems on subjectivity classification and explanatory relation extraction.", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 185, "end_pos": 212, "type": "TASK", "confidence": 0.7654312551021576}, {"text": "explanatory relation extraction", "start_pos": 217, "end_pos": 248, "type": "TASK", "confidence": 0.6584954659144083}]}, {"text": "From the results, we can observe that recursive autoencoders based subjectivity classification method achieves slightly better performance than our method and conditional random fields based method.", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.7282686829566956}]}, {"text": "The performances of the proposed method are similar as CRFs'.", "labels": [], "entities": []}, {"text": "We think that the main reason is that only lexical features are used in MLN models for subjective classification.", "labels": [], "entities": [{"text": "subjective classification", "start_pos": 87, "end_pos": 112, "type": "TASK", "confidence": 0.6347394585609436}]}, {"text": "However, conditional random fields consider not only lexical information but also inference of the contexts of sentences.", "labels": [], "entities": []}, {"text": "RAE method learns vector space representations for multi-word phrases and uses compositional semantics to understand sentiment.", "labels": [], "entities": [{"text": "RAE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8269152045249939}]}, {"text": "For evaluating the performance of relation extraction, we combine the results of RAE with PDTBRel and SVM-Rel.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8862574100494385}, {"text": "RAE", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.5846555829048157}, {"text": "PDTBRel", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.7303824424743652}]}, {"text": "For all the subjective clauses identified by RAE, PDTB-Rel and SVM-Rel are used to extract corresponding explanatory clauses.", "labels": [], "entities": [{"text": "RAE", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.7088103890419006}]}, {"text": "The results are shown in the last three rows in the.", "labels": [], "entities": []}, {"text": "From the results, we can observe that the proposed joint model achieves best F1 score and precision among all methods.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9700084626674652}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9989292025566101}]}, {"text": "Although the proposed method achieve slightly worse result in processing subjectivity classification.", "labels": [], "entities": [{"text": "processing subjectivity classification", "start_pos": 62, "end_pos": 100, "type": "TASK", "confidence": 0.7327269911766052}]}, {"text": "We think that the error propagation is the main reason for worse results of cascaded methods.", "labels": [], "entities": []}, {"text": "The relative improvement of MLN over SVM-Rel is more than 33.4%.", "labels": [], "entities": [{"text": "MLN", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9115495681762695}]}], "tableCaptions": [{"text": " Table 3: Performance comparisons between the proposed  method and state-of-the-art methods. \"MLN\" represents  the method proposed in this work.", "labels": [], "entities": []}, {"text": " Table 4. The first  row shows the result of the MLN based method with  all observed predicates and local formulas. From the  results we can observe that the observed predicates  which are not used in the local formulas for sub- jectivity classification also impact the performance  of subjectivity classification. We think that the per- formance is effected by the global formulas, which  combine the procedure of subjectivity classification", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 286, "end_pos": 313, "type": "TASK", "confidence": 0.7694338858127594}, {"text": "subjectivity classification", "start_pos": 415, "end_pos": 442, "type": "TASK", "confidence": 0.7063248157501221}]}, {"text": " Table 4: Performance comparisons of different observed predicates", "labels": [], "entities": []}]}