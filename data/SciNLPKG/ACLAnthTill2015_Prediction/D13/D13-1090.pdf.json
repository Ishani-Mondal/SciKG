{"title": [{"text": "Discriminative Improvements to Distributional Sentence Similarity", "labels": [], "entities": [{"text": "Distributional Sentence Similarity", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.8486411968866984}]}], "abstractContent": [{"text": "Matrix and tensor factorization have been applied to a number of semantic relatedness tasks, including paraphrase identification.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 103, "end_pos": 128, "type": "TASK", "confidence": 0.9223292171955109}]}, {"text": "The key idea is that similarity in the latent space implies semantic relatedness.", "labels": [], "entities": []}, {"text": "We describe three ways in which labeled data can improve the accuracy of these approaches on paraphrase classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9989593029022217}, {"text": "paraphrase classification", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.936484158039093}]}, {"text": "First, we design anew discriminative term-weighting metric called TF-KLD, which outperforms TF-IDF.", "labels": [], "entities": []}, {"text": "Next, we show that using the latent representation from matrix factorization as features in a classification algorithm substantially improves accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9972438812255859}]}, {"text": "Finally, we combine latent features with fine-grained n-gram overlap features , yielding performance that is 3% more accurate than the prior state-of-the-art.", "labels": [], "entities": [{"text": "accurate", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.973063588142395}]}], "introductionContent": [{"text": "Measuring the semantic similarity of short units of text is fundamental to many natural language processing tasks, from evaluating machine translation () to grouping redundant event mentions in social media).", "labels": [], "entities": [{"text": "evaluating machine translation", "start_pos": 120, "end_pos": 150, "type": "TASK", "confidence": 0.6656530300776163}, {"text": "grouping redundant event mentions in social media", "start_pos": 157, "end_pos": 206, "type": "TASK", "confidence": 0.8757977911404201}]}, {"text": "The task is challenging because of the infinitely diverse set of possible linguistic realizations for any idea, and because of the short length of individual sentences, which means that standard bag-of-words representations will be hopelessly sparse.", "labels": [], "entities": []}, {"text": "Distributional methods address this problem by transforming the high-dimensional bag-of-words representation into a lower-dimensional latent space.", "labels": [], "entities": []}, {"text": "This can be accomplished by factoring a matrix or tensor of term-context counts; proximity in the induced latent space has been shown to correlate with semantic similarity ().", "labels": [], "entities": []}, {"text": "However, factoring the term-context matrix means throwing away a considerable amount of information, as the original matrix of size M \u00d7 N (number of instances by number of features) is factored into two smaller matrices of size M \u00d7 K and N \u00d7 K, with K M, N . If the factorization does not take into account labeled data about semantic similarity, important information can be lost.", "labels": [], "entities": []}, {"text": "In this paper, we show how labeled data can considerably improve distributional methods for measuring semantic similarity.", "labels": [], "entities": []}, {"text": "First, we develop anew discriminative term-weighting metric called TF-KLD, which is applied to the term-context matrix before factorization.", "labels": [], "entities": []}, {"text": "On a standard paraphrase identification task (), this method improves on both traditional TF-IDF and Weighted).", "labels": [], "entities": [{"text": "paraphrase identification task", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.8608813683191935}]}, {"text": "Next, we convert the latent representations of each sentence pair into a feature vector, which is used as input to a linear SVM classifier.", "labels": [], "entities": []}, {"text": "This yields further improvements and substantially outperforms the current state-of-the-art on paraphrase classification.", "labels": [], "entities": [{"text": "paraphrase classification", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.9442236721515656}]}, {"text": "We then add \"finegrained\" features about the lexical similarity of the sentence pair.", "labels": [], "entities": []}, {"text": "The combination of latent and finegrained features yields further improvements inaccuracy, demonstrating that these feature sets provide complementary information on semantic similarity.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments test the utility of the TF-KLD weighting towards paraphrase classification, using the Microsoft Research Paraphrase Corpus ().", "labels": [], "entities": [{"text": "paraphrase classification", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.9348205626010895}, {"text": "Microsoft Research Paraphrase Corpus", "start_pos": 102, "end_pos": 138, "type": "DATASET", "confidence": 0.9200769066810608}]}, {"text": "The training set contains 2753 true paraphrase pairs and 1323 false paraphrase pairs; the test set contains 1147 and 578 pairs, respectively.", "labels": [], "entities": []}, {"text": "The TF-KLD weights are constructed from only the training set, while matrix factorizations are per-formed on the entire corpus.", "labels": [], "entities": []}, {"text": "Matrix factorization on both training and (unlabeled) test data can be viewed as a form of transductive learning (), where we assume access to unlabeled test set instances.", "labels": [], "entities": []}, {"text": "We also consider an inductive setting, where we construct the basis of the latent space from only the training set, and then project the test set onto this basis to find the corresponding latent representation.", "labels": [], "entities": []}, {"text": "The performance differences between the transductive and inductive settings were generally between 0.5% and 1%, as noted in detail below.", "labels": [], "entities": []}, {"text": "We reiterate that the TF-KLD weights are never computed from test set data.", "labels": [], "entities": []}, {"text": "Prior work on this dataset is described in section 2.", "labels": [], "entities": []}, {"text": "To our knowledge, the current state-of-theart is a supervised system that combines several machine translation metrics (), but we also compare with state-of-the-art unsupervised matrix factorization work).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Similarity-based paraphrase identification accuracy. Results for WTMF are reprinted from the paper by Guo  and Diab (2012).", "labels": [], "entities": [{"text": "Similarity-based paraphrase identification", "start_pos": 10, "end_pos": 52, "type": "TASK", "confidence": 0.5947085420290629}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9313674569129944}, {"text": "WTMF", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.6530046463012695}]}, {"text": " Table 3: Supervised classification. Results from prior work are reprinted.", "labels": [], "entities": [{"text": "Supervised classification", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8210802376270294}]}]}