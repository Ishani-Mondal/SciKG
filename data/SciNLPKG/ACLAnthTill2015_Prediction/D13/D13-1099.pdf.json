{"title": [{"text": "Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features", "labels": [], "entities": [{"text": "Negation and Speculation Scope Detection", "start_pos": 18, "end_pos": 58, "type": "TASK", "confidence": 0.6133415520191192}]}], "abstractContent": [{"text": "Scope detection is a key task in information extraction.", "labels": [], "entities": [{"text": "Scope detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9676885604858398}, {"text": "information extraction", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.8979036211967468}]}, {"text": "This paper proposes anew approach for tree kernel-based scope detection by using the structured syntactic parse information.", "labels": [], "entities": [{"text": "tree kernel-based scope detection", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.650925487279892}]}, {"text": "In addition , we have explored the way of selecting compatible features for different part-of-speech cues.", "labels": [], "entities": []}, {"text": "Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.846258133649826}]}, {"text": "Compared with the state of the art scope detection systems, our system achieves substantial improvement.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.9041528403759003}]}], "introductionContent": [{"text": "The task of scope detection is to detect the linguistic scope dominated by a specific cue.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.8854889571666718}]}, {"text": "Current researches in this field focus on two semantic aspects: negation and speculation.", "labels": [], "entities": []}, {"text": "The negative scope detection is to detect the linguistic scope which is repudiated by a negative word (viz., negative cue, e.g., \"not\").", "labels": [], "entities": [{"text": "negative scope detection", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6572918693224589}]}, {"text": "In other side, the speculative scope detection is to detect the uncertain part in a sentence corresponding to the speculative word (viz., speculative cue, e.g., \"seems\").", "labels": [], "entities": [{"text": "speculative scope detection", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.8326937357584635}]}, {"text": "See the sentence 1) below, the negative cue \"not\" dominates the scope of \"not expensive\".", "labels": [], "entities": []}, {"text": "Similarly, the speculative cue \"possible\" in sentence 2) dominates the uncertain scope \"the possible future scenarios\".", "labels": [], "entities": []}, {"text": "1) The chair is The negative and speculative scope detection task consists of two basic stages.", "labels": [], "entities": [{"text": "speculative scope detection task", "start_pos": 33, "end_pos": 65, "type": "TASK", "confidence": 0.6880058571696281}]}, {"text": "The first one is to identify the sentences involving negative or speculative meaning.", "labels": [], "entities": []}, {"text": "The second stage is to detect the linguistic scope of the cue in sentences (.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the second stage.", "labels": [], "entities": []}, {"text": "That is, by given golden cues, we detect their linguistic scopes.", "labels": [], "entities": []}, {"text": "We propose a tree kernel-based negation and speculation scope detection with structured syntactic parse features.", "labels": [], "entities": [{"text": "negation and speculation scope detection", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.6067392289638519}]}, {"text": "In detail, we regard the scope detection task as a binary classification issue, which is to classify the tokens in a sentence as being inside or outside the scope.", "labels": [], "entities": [{"text": "scope detection task", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.822862982749939}]}, {"text": "In the basic framework, we focus on the analysis and application of structured syntactic parse features as follows: Both constituent and dependency syntactic features have been proved to be effective in scope detection ().", "labels": [], "entities": [{"text": "scope detection", "start_pos": 203, "end_pos": 218, "type": "TASK", "confidence": 0.8396070599555969}]}, {"text": "However, these flat features are hardly to reflect the information implicit in syntactic parse tree structures.", "labels": [], "entities": []}, {"text": "Our intuition is that the segments of the syntactic parse tree around a negative or speculative cue is effective for scope detection.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.9726360738277435}]}, {"text": "The related structures normally underlay the indirect clues to identify the relations between cues and their scopes, e.g., in sentence 1), \"but something\", as a frequently co-occurred syntactic structure with \"not something\", is an effective clue to determine the linguistic scope of \"not\".", "labels": [], "entities": []}, {"text": "The tree kernel classifier) based on support vector machines uses a kernel function between two trees, affording a comparison between their substructures.", "labels": [], "entities": []}, {"text": "Therefore, a tree kernel-based scope detection approach with structured syntactic parse tree is employed.", "labels": [], "entities": [{"text": "tree kernel-based scope detection", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.621035747230053}]}, {"text": "The tree kernel has been already proved to be effective in semantic role labeling) and relation extraction ().", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7189745704332987}, {"text": "relation extraction", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.9317407011985779}]}, {"text": "In addition, the empirical observation shows that features have imbalanced efficiency for scope classification, which is normally affected by the part-of-speech (abbr., POS) of cues.", "labels": [], "entities": [{"text": "scope classification", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.8704492747783661}]}, {"text": "Hence, we build the discriminative classifiers for each kind of POS of cues, then explore and select the most compatible features for them.", "labels": [], "entities": []}, {"text": "We construct a scope detection system by using the structured syntactic parse features based tree kernel classification.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.8442315757274628}]}, {"text": "Compared with the state of the art scope detection systems, our system achieves the performance of accuracy 76.90% on negation and 84.21% on speculation (on Abstracts sub-corpus).", "labels": [], "entities": [{"text": "scope detection", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7981113493442535}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9995461106300354}, {"text": "negation", "start_pos": 118, "end_pos": 126, "type": "TASK", "confidence": 0.9377614259719849}]}, {"text": "Additionally, we test our system on different sub-corpus (Clinical Reports and Full Papers).", "labels": [], "entities": []}, {"text": "The results show that our approach has better cross-domain performance.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces the corpus and corresponding usage in our experiments.", "labels": [], "entities": []}, {"text": "Section 4 describes our approach and the experiments are presented in Section 5.", "labels": [], "entities": []}, {"text": "Finally, there is a conclusion in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Considering the effectiveness of different features, we have split the Abstracts sub-corpus into 5 equal parts, within which 2 parts are used for feature selection (Feature Selection Data) and the rest for the scope detection experiments (Scope Detection Data).", "labels": [], "entities": [{"text": "Abstracts sub-corpus", "start_pos": 71, "end_pos": 91, "type": "DATASET", "confidence": 0.9202144742012024}, {"text": "scope detection", "start_pos": 210, "end_pos": 225, "type": "TASK", "confidence": 0.8710486888885498}]}, {"text": "The Feature Selection Data are divided into 5 equal parts, within which 4 parts for training and the rest for developing.", "labels": [], "entities": []}, {"text": "In our scope detection experiments, we divide the Scope Detection Data into 10 folds randomly, so as to perform 10-fold cross validation.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 7, "end_pos": 22, "type": "TASK", "confidence": 0.8202442228794098}, {"text": "Scope Detection", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.8392621576786041}]}, {"text": "As the experiment data is easily confusable, illustrates the allocation.", "labels": [], "entities": []}, {"text": "Checking the validity of our method, we use the Abstracts sub-corpus in Section 5.2, 5.3 and 5.4, while in Section 5.5 we use all of the three subcorpora (Abstracts, Full Papers, and Clinical Reports) to test the robustness of our system when applied to different text types within the same domain.", "labels": [], "entities": [{"text": "Abstracts sub-corpus", "start_pos": 48, "end_pos": 68, "type": "DATASET", "confidence": 0.8942619264125824}]}, {"text": "The evaluation is made using the precision, recall and their harmonic mean, F1-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9997187256813049}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9995946288108826}, {"text": "F1-score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.994835376739502}]}, {"text": "Additionally, we report the accuracy in PCS (Percentage of Correct Scopes) applied in CoNLL'2010, within which a scope is fully correct if all tokens in a sentence have been assigned to the correct scope class fora given cue.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9996458292007446}, {"text": "CoNLL'2010", "start_pos": 86, "end_pos": 96, "type": "DATASET", "confidence": 0.8783237934112549}]}, {"text": "The evaluation in terms of precision and recall measures takes a token as a unit, whereas the evaluation in terms of PCS takes a scope as a unit.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9990572333335876}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9976643323898315}]}, {"text": "The key toolkits for scope classification include: Constituent and Dependency Parser: All the sentences in BioScope corpus are tokenized and parsed using the Berkeley Parser (Petrov et al, 2007) 2 which have been trained on the GENIA TreeBank 1.0) 3 , a bracketed corpus in PTB style.", "labels": [], "entities": [{"text": "scope classification", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.7308681905269623}, {"text": "BioScope corpus", "start_pos": 107, "end_pos": 122, "type": "DATASET", "confidence": 0.8514730632305145}, {"text": "GENIA TreeBank 1.0) 3", "start_pos": 228, "end_pos": 249, "type": "DATASET", "confidence": 0.9665235638618469}]}, {"text": "10-fold cross-validation on GTB1.0 shows that the parser achieves 87.12% in F1-score.", "labels": [], "entities": [{"text": "GTB1.0", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.9223002195358276}, {"text": "F1-score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9980757236480713}]}, {"text": "On the other hand, we obtain the dependency relations by the Stanford Dependencies Parser . Support Vector Machine Classifier: SVM Light5 is selected as our classifier, which provides away to combine the tree kernels with the default and custom SVM Light kernels.", "labels": [], "entities": []}, {"text": "We use the default parameter computed by SVM Light . Besides, according to the guideline of the BioScope corpus, scope must be a continuous chunk.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 96, "end_pos": 111, "type": "DATASET", "confidence": 0.8700497150421143}]}, {"text": "The scope classifier may result in discontinuous blocks, as each token maybe classified inside or outside the scope.", "labels": [], "entities": []}, {"text": "Therefore, we perform the rule based post-processing algorithm proposed by to obtain continuous scopes.", "labels": [], "entities": []}, {"text": "To get the final performance of our approach, we train the classifiers respectively by different effective features in Section 4.1 for POS kinds of cues, and use the structured syntactic parse features in Section 4.2 on Abstracts sub-corpus by performing 10-fold cross validation..", "labels": [], "entities": []}, {"text": "Performance comparison of our system with the state-of-the-art ones in PCS.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Statistics for our corpus in BioScope.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.7897710204124451}]}, {"text": " Table 5. Distribution of different POSs of specula- tive cues in Abstracts sub-corpus.", "labels": [], "entities": [{"text": "Abstracts", "start_pos": 66, "end_pos": 75, "type": "DATASET", "confidence": 0.8831495046615601}]}, {"text": " Table 6. Performance of flat syntactic features.  The results also show that the speculative scope  detection achieves higher performance (16.98%  higher in PCS) (\u03c7 2 ; p < 0.01) than the negation  scope detection. The main reason is that although  the average sentence length of negation and specu- lation are comparable", "labels": [], "entities": [{"text": "speculative scope  detection", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.6914070248603821}, {"text": "negation  scope detection", "start_pos": 189, "end_pos": 214, "type": "TASK", "confidence": 0.8817771077156067}]}, {"text": " Table 7. Performance of structured syntactic parse  features on negation.", "labels": [], "entities": []}, {"text": " Table 9. Performances of POS based classification.", "labels": [], "entities": [{"text": "POS based classification", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.7891148527463278}]}, {"text": " Table 11. Performance comparison of our system  with the state-of-the-art ones in PCS.", "labels": [], "entities": []}]}