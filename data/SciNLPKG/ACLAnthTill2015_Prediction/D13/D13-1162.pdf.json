{"title": [{"text": "Classifying Message Board Posts with an Extracted Lexicon of Patient Attributes", "labels": [], "entities": [{"text": "Classifying Message Board Posts with an Extracted Lexicon of Patient Attributes", "start_pos": 0, "end_pos": 79, "type": "TASK", "confidence": 0.7244699461893602}]}], "abstractContent": [{"text": "The goal of our research is to distinguish veterinary message board posts that describe a case involving a specific patient from posts that ask a general question.", "labels": [], "entities": []}, {"text": "We create a text classifier that incorporates automatically generated attribute lists for veterinary patients to tackle this problem.", "labels": [], "entities": []}, {"text": "Using a small amount of annotated data, we train an information extraction (IE) system to identify veterinary patient attributes.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.8174791097640991}]}, {"text": "We then apply the IE system to a large collection of unannotated texts to produce a lexicon of veterinary patient attribute terms.", "labels": [], "entities": [{"text": "IE", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.7761363387107849}]}, {"text": "Our experimental results show that using the learned attribute lists to encode patient information in the text classifier yields improved performance on this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our research focuses on the problem of classifying message board posts in the domain of veterinary medicine.", "labels": [], "entities": [{"text": "classifying message board posts", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.8943300694227219}]}, {"text": "Most of the posts in our corpus discuss a case involving a specific patient, which we will call patient-specific posts.", "labels": [], "entities": []}, {"text": "But there are also posts that ask a general question, for example to seek advice about different medications, information about new procedures, or how to perform a test.", "labels": [], "entities": []}, {"text": "Our goal is to distinguish the patient-specific posts from general posts so that they can be automatically routed to different message board folders.", "labels": [], "entities": []}, {"text": "Distinguishing patient-specific posts from general posts is a challenging problem for two reasons.", "labels": [], "entities": []}, {"text": "First, virtually any medical topic can appear in either type of post, so the vocabulary is very similar.", "labels": [], "entities": []}, {"text": "Second, a highly skewed distribution exists between patientspecific posts and general posts.", "labels": [], "entities": []}, {"text": "Almost 90% of the posts in our data are about specific patients.", "labels": [], "entities": []}, {"text": "With such a highly skewed distribution, it would seem logical to focus on recognizing instances of the minority class.", "labels": [], "entities": []}, {"text": "But the distinguishing characteristic of a general post is the absence of a patient.", "labels": [], "entities": []}, {"text": "Two nearly identical posts belong in different categories if one mentions a patient and the other does not.", "labels": [], "entities": []}, {"text": "Consequently, our aim is to create features that identify references to a specific patient and use these to more accurately distinguish the two types of posts.", "labels": [], "entities": []}, {"text": "Our research explores the use of information extraction (IE) techniques to automatically identify common attributes of veterinary patients, which we use to encode patient information in a text classifier.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8683048605918884}]}, {"text": "Our approach involves three phases.", "labels": [], "entities": []}, {"text": "First, we train a conditional random fields (CRF) tagger to identify seven common types of attributes that are often ascribed to veterinary patients: SPECIES/BREED, NAME, AGE, GENDER, WEIGHT, POSSESSOR, and DISEASE/SYMPTOM.", "labels": [], "entities": [{"text": "SPECIES", "start_pos": 150, "end_pos": 157, "type": "METRIC", "confidence": 0.9900320768356323}, {"text": "BREED", "start_pos": 158, "end_pos": 163, "type": "METRIC", "confidence": 0.6866299510002136}, {"text": "NAME", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.9893921613693237}, {"text": "AGE", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.9948790073394775}, {"text": "GENDER", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9130722880363464}, {"text": "WEIGHT", "start_pos": 184, "end_pos": 190, "type": "METRIC", "confidence": 0.8709664344787598}, {"text": "POSSESSOR", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.9164170622825623}]}, {"text": "Second, we apply the CRF tagger to a large set of unannotated message board posts, collect its extractions, and harvest the most frequently extracted terms to create a Veterinary Patient Attribute (VPA) Lexicon.", "labels": [], "entities": []}, {"text": "Finally, we define three types of features that exploit the harvested VPA lexicon.", "labels": [], "entities": []}, {"text": "These features represent the patient attribute terms, types, and combinations of them to help the classifier determine whether a post is discussing a specific patient.", "labels": [], "entities": []}, {"text": "We conduct experiments which show that the extracted patient attribute information improves text classification performance on this task.", "labels": [], "entities": [{"text": "text classification", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.77293860912323}]}], "datasetContent": [{"text": "To create a blind test set for evaluation, our annotators labeled an additional 500 posts as patientspecific or general.", "labels": [], "entities": []}, {"text": "Specifically, they labeled those 500 posts with PI sentences.", "labels": [], "entities": []}, {"text": "The absence of a PI sentence meant that the post was general.", "labels": [], "entities": []}, {"text": "Of the 500 texts, 48 (9.6%) were labeled as general posts.", "labels": [], "entities": []}, {"text": "We evaluated the performance of the PI sentence classifier on this test set and found that it achieved 88% accuracy at identifying patient introductory sentences.", "labels": [], "entities": [{"text": "PI sentence classifier", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7083098491032919}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9991648197174072}, {"text": "identifying patient introductory sentences", "start_pos": 119, "end_pos": 161, "type": "TASK", "confidence": 0.7530048936605453}]}, {"text": "We then conducted a series of experiments for the document classification task: distinguishing patientspecific message board posts from general posts.", "labels": [], "entities": [{"text": "document classification task", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.8487052122751871}]}, {"text": "All of our experiments used support vector machine (SVM) classifiers with a linear kernel, and ran 10-fold cross validation on our blind test set of 500 posts.", "labels": [], "entities": []}, {"text": "We report Recall (%), Precision (%), and F score (%) results for the patient-specific posts and general posts separately, and for the macro-averaged score across both classes.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9990501999855042}, {"text": "Precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9940183162689209}, {"text": "F score (%)", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.9787489573160807}]}, {"text": "For the sake of completeness, we also show overall Accuracy (%) results.", "labels": [], "entities": [{"text": "completeness", "start_pos": 16, "end_pos": 28, "type": "METRIC", "confidence": 0.9895051121711731}, {"text": "Accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9997509121894836}]}, {"text": "However, we will focus attention on the results for the general posts, since our main goal is to improve performance at recognizing this minority class.", "labels": [], "entities": []}, {"text": "As a baseline, we created SVM classifiers using unigram features.", "labels": [], "entities": [{"text": "SVM classifiers", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7763891220092773}]}, {"text": "We tried binary, frequency, and tf-idf feature values.", "labels": [], "entities": []}, {"text": "The first three rows of show that binary feature values performed the best, yielding a macro-averaged F score of 81% but identifying only 54% of the general posts.", "labels": [], "entities": [{"text": "F score", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9723914861679077}]}, {"text": "The middle section of shows the performance of SVM classifiers using our patient attribute features.", "labels": [], "entities": [{"text": "SVM classifiers", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.8842626810073853}]}, {"text": "We conducted three experiments: applying the CRF tagger to PI sentences (per its design), and labeling words with the VPA lexicon either on all sentences or only on PI sentences (as identified by the PI sentence classifier).", "labels": [], "entities": []}, {"text": "The CRF features produced extremely low recall and precision on the general posts.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9997001886367798}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9994786381721497}]}, {"text": "The VPA lexicon performed best when applied only to PI sentences and produced much higher recall than all of the other classifiers, although with lower precision than the two  The bottom section of shows results for classifiers with both unigrams (binary) and patient attribute features.", "labels": [], "entities": [{"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9990934133529663}, {"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9938285946846008}]}, {"text": "Using the CRF features increases recall on the general posts from 54 \u2192 60, but decreases precision from 79 \u2192 71.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9995039701461792}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9993577599525452}]}, {"text": "Using the patient attribute features from the VPA lexicon yields a substantial improvement.", "labels": [], "entities": [{"text": "VPA lexicon", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.6946593821048737}]}, {"text": "Recall improves from 54 \u2192 79 and precision is just one point lower.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9880471229553223}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9998440742492676}]}, {"text": "Overall, the macro-averaged F score across the two categories jumps from 81% to 88%.", "labels": [], "entities": [{"text": "F score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9774481952190399}]}, {"text": "We performed paired bootstrap testing) to determine whether the SVM with unigrams and VPA lexicon features is statistically significantly better than the best SVM with only unigram features (binary).", "labels": [], "entities": []}, {"text": "The SVM with unigrams and VPA lexicon features produces significantly better F scores at the p < 0.05 level for general post classification as well as the macro average.", "labels": [], "entities": [{"text": "F", "start_pos": 77, "end_pos": 78, "type": "METRIC", "confidence": 0.9987986087799072}, {"text": "general post classification", "start_pos": 112, "end_pos": 139, "type": "TASK", "confidence": 0.699234406153361}]}, {"text": "The F score for patient-specific classification and overall accuracy are statistically significant at the p < 0.10 level.", "labels": [], "entities": [{"text": "F score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9887748062610626}, {"text": "patient-specific classification", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.7108202278614044}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9884191751480103}]}, {"text": "Finally, we did an analysis to understand why the VPA lexicon was so much more effective than the CRF tagger when used to create features for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.798118382692337}]}, {"text": "shows the number of words in PI sentences (identified by the classifier) of the test set that were labeled as patient attributes by the CRF tagger or the VPA lexicon.", "labels": [], "entities": []}, {"text": "The VPA lexicon clearly labeled many more terms, and the additional coverage made a big difference for the text classifier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Patient Attribute Tagger Evaluation", "labels": [], "entities": [{"text": "Patient Attribute Tagger Evaluation", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.8581801801919937}]}, {"text": " Table 4: Number of Attributes Labeled in Test Set", "labels": [], "entities": []}]}