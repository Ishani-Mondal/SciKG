{"title": [{"text": "Document Summarization via Guided Sentence Compression", "labels": [], "entities": [{"text": "Document Summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8726359307765961}]}], "abstractContent": [{"text": "Joint compression and summarization has been used recently to generate high quality summaries.", "labels": [], "entities": [{"text": "Joint compression", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8185429871082306}, {"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.9776613116264343}]}, {"text": "However, such word-based joint optimization is computationally expensive.", "labels": [], "entities": [{"text": "word-based joint optimization", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.6134754319985708}]}, {"text": "In this paper we adopt the 'sentence compression + sentence selection' pipeline approach for compressive summarization, but propose to perform summary guided compression, rather than generic sentence-based compression.", "labels": [], "entities": [{"text": "sentence compression + sentence selection", "start_pos": 28, "end_pos": 69, "type": "TASK", "confidence": 0.7985417366027832}, {"text": "compressive summarization", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.6476656794548035}, {"text": "summary guided compression", "start_pos": 143, "end_pos": 169, "type": "TASK", "confidence": 0.6629893680413564}]}, {"text": "To create an annotated corpus, the human anno-tators were asked to compress sentences while explicitly given the important summary words in the sentences.", "labels": [], "entities": []}, {"text": "Using this corpus, we train a supervised sentence compression model using a set of word-, syntax-, and document-level features.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7408585846424103}]}, {"text": "During summarization, we use multiple compressed sentences in the integer linear programming framework to select salient summary sentences.", "labels": [], "entities": [{"text": "summarization", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.9801838994026184}]}, {"text": "Our results on the TAC 2008 and 2011 summarization data sets show that by incorporating the guided sentence compression model, our summarization system can yield significant performance gain as compared to the state-of-the-art.", "labels": [], "entities": [{"text": "TAC 2008 and 2011 summarization data sets", "start_pos": 19, "end_pos": 60, "type": "DATASET", "confidence": 0.9240931017058236}, {"text": "sentence compression", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.7128282934427261}]}], "introductionContent": [{"text": "Automatic summarization can be broadly divided into two categories: extractive and abstractive summarization.", "labels": [], "entities": [{"text": "Automatic summarization", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5911595374345779}]}, {"text": "Extractive summarization focuses on selecting the salient sentences from the document collection and concatenating them to form a summary; while abstractive summarization is generally considered more difficult, involving sophisticated techniques for meaning representation, content planning, surface realization, etc., and the \"true abstractive summarization remains a researcher's dream\" ().", "labels": [], "entities": [{"text": "Extractive summarization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8468243181705475}, {"text": "meaning representation", "start_pos": 250, "end_pos": 272, "type": "TASK", "confidence": 0.7112270444631577}, {"text": "surface realization", "start_pos": 292, "end_pos": 311, "type": "TASK", "confidence": 0.7837607264518738}]}, {"text": "There has been a surge of interest in recent years on generating compressed document summaries as a viable step towards abstractive summarization.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.6317015886306763}]}, {"text": "These compressive summaries often contain more information than sentence-based extractive summaries since they can remove insignificant sentence constituents and make space for more salient information that is otherwise dropped due to the summary length constraint.", "labels": [], "entities": [{"text": "sentence-based extractive summaries", "start_pos": 64, "end_pos": 99, "type": "TASK", "confidence": 0.6515767276287079}]}, {"text": "Two general strategies have been used for compressive summarization.", "labels": [], "entities": [{"text": "compressive summarization", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.930328905582428}]}, {"text": "One is a pipeline approach, where sentence-based extractive summarization is followed or proceeded by sentence compression.", "labels": [], "entities": [{"text": "sentence-based extractive summarization", "start_pos": 34, "end_pos": 73, "type": "TASK", "confidence": 0.5889828503131866}, {"text": "sentence compression", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.7140431851148605}]}, {"text": "Another line of work uses joint compression and summarization.", "labels": [], "entities": [{"text": "joint compression", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7880695760250092}, {"text": "summarization", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.9775047898292542}]}, {"text": "They have been shown to achieve promising performance.", "labels": [], "entities": []}, {"text": "One popular approach for such joint compression and summarization is via integer linear programming (ILP).", "labels": [], "entities": [{"text": "joint compression", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7544624209403992}, {"text": "summarization", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.8771406412124634}]}, {"text": "However, since words are the units in the optimization framework, solving this ILP problem can be expensive.", "labels": [], "entities": []}, {"text": "In this study, we use the pipeline compression and summarization method because of its computational efficiency.", "labels": [], "entities": [{"text": "pipeline compression and summarization", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.7008645534515381}]}, {"text": "Prior work using such pipeline methods simply uses generic sentence-based compression for each sentence in the documents, no matter whether compression is done before or after summary sentence extraction.", "labels": [], "entities": [{"text": "summary sentence extraction", "start_pos": 176, "end_pos": 203, "type": "TASK", "confidence": 0.6844310164451599}]}, {"text": "We propose to use sum-mary guided compression combined with ILP-based sentence selection for summarization in this paper.", "labels": [], "entities": [{"text": "sum-mary guided compression", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.6850304106871287}, {"text": "ILP-based sentence selection", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.5407261153062185}, {"text": "summarization", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.9767606258392334}]}, {"text": "We create a compression corpus for this purpose.", "labels": [], "entities": []}, {"text": "Using human summaries fora set of documents, we identify salient words in the sentences.", "labels": [], "entities": []}, {"text": "During annotation, the human annotators are given these salient words and asked to generate compressed sentences.", "labels": [], "entities": []}, {"text": "We expect such \"guided\" sentence compression is beneficial for the pipeline compression and summarization task.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7390815019607544}, {"text": "pipeline compression", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.783896803855896}, {"text": "summarization", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.9680814743041992}]}, {"text": "In addition, previous research on joint modeling for compression and summarization suggested that the labeled extraction and compression data sets would be helpful for learning a better joint model.", "labels": [], "entities": [{"text": "summarization", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.9404452443122864}]}, {"text": "We hope that our work on this guided compression will also be of benefit to the future joint modeling studies.", "labels": [], "entities": [{"text": "guided compression", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.653951108455658}]}, {"text": "Using our created compression data, we train a supervised compression model using a variety of word-, sentence-, and document-level features.", "labels": [], "entities": []}, {"text": "During summarization, we generate multiple compression candidates for each sentence, and use the ILP framework to select compressed summary sentences.", "labels": [], "entities": [{"text": "summarization", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.9759601950645447}]}, {"text": "In addition, we also propose to apply a preselection step to select some important sentences, which can both speedup the summarization system and improve performance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 121, "end_pos": 134, "type": "TASK", "confidence": 0.9797338843345642}]}, {"text": "We evaluate our proposed summarization approach on the TAC 2008 and 2011 data sets using the standard ROUGE metric).", "labels": [], "entities": [{"text": "summarization", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9551786184310913}, {"text": "TAC 2008 and 2011 data sets", "start_pos": 55, "end_pos": 82, "type": "DATASET", "confidence": 0.9617881774902344}, {"text": "ROUGE", "start_pos": 102, "end_pos": 107, "type": "METRIC", "confidence": 0.890009343624115}]}, {"text": "Our results show that by incorporating a guided sentence compression model, our summarization system can yield significant performance gain as compared to the state-of-the-art reported results.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7204687744379044}]}], "datasetContent": [{"text": "For our experiments, we use the standard TAC data sets , which have been used in the NIST competitions and in other summarization studies.", "labels": [], "entities": [{"text": "TAC data sets", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.8492014010747274}, {"text": "NIST competitions", "start_pos": 85, "end_pos": 102, "type": "DATASET", "confidence": 0.8978361785411835}, {"text": "summarization", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.9639719128608704}]}, {"text": "In particular, we used the TAC 2010 data set for creating the guided compression corpus and training the SVR pre-selection model, the TAC 2009 data set as development set for parameter tuning, and the TAC 2008 and 2011 data sets as the test set for reporting the final summarization results.", "labels": [], "entities": [{"text": "TAC 2010 data set", "start_pos": 27, "end_pos": 44, "type": "DATASET", "confidence": 0.9587240219116211}, {"text": "TAC 2009 data set", "start_pos": 134, "end_pos": 151, "type": "DATASET", "confidence": 0.9671279937028885}, {"text": "TAC 2008 and 2011 data sets", "start_pos": 201, "end_pos": 228, "type": "DATASET", "confidence": 0.9382230540116628}]}, {"text": "We compare our pipeline summarization system against three recent studies, which have reported some of the highest published results on this task.", "labels": [], "entities": [{"text": "pipeline summarization", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.6081725656986237}]}, {"text": "introduce a joint model for sentence extraction and compression.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8095460534095764}]}, {"text": "The model is trained using a margin-based objective whose loss captures the end summary quality; Woodsend and Lapata (2012) learn individual summary aspects from data, e.g., informativeness, succinctness, grammaticality, stylistic writing conventions, and jointly optimize the outcome in an integer linear programming framework.", "labels": [], "entities": []}, {"text": "exploit category-specific information for multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6634363234043121}]}, {"text": "In addition to the three previous studies, we also report the best achieved results in the TAC competitions.", "labels": [], "entities": [{"text": "TAC competitions", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.5887049734592438}]}], "tableCaptions": [{"text": " Table 3: Results on the TAC 2008 data set. \"Our Sys- tem\" uses the SVR-based sentence pre-selection + guided  compression + ILP-based summary sentence selection.  \"Our System w/ Generic Comp\" uses the pre-selection +  generic compression + ILP summary sentence selection  setting. \"CompR\" represents the compression ratio, i.e.,  percentage of dropped words.  \u2020 represents our system  outperforms the best previous result at the 95% signifi- cance level.", "labels": [], "entities": [{"text": "TAC 2008 data set", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9546859711408615}]}, {"text": " Table 4: Results on the TAC 2011 data set. The systems  use the same settings as for the TAC 2008 data set.", "labels": [], "entities": [{"text": "TAC 2011 data set", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9457431733608246}, {"text": "TAC 2008 data set", "start_pos": 90, "end_pos": 107, "type": "DATASET", "confidence": 0.9464233964681625}]}, {"text": " Table 5: Average running time of our system, w/ or w/o  the sentence pre-selection step. Experiments conducted  on the TAC 2011 data set. Running time refers only to  the execution time of the ILP module for each topic.", "labels": [], "entities": [{"text": "TAC 2011 data set", "start_pos": 120, "end_pos": 137, "type": "DATASET", "confidence": 0.9789119362831116}]}]}