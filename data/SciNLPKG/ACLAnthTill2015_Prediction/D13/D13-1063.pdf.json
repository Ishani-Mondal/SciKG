{"title": [], "abstractContent": [{"text": "Studies of the graph of dictionary definitions (DD) (Picard et al., 2009; Levary et al., 2012) have revealed strong semantic coherence of local topological structures.", "labels": [], "entities": [{"text": "dictionary definitions (DD)", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.7038033604621887}]}, {"text": "The techniques used in these papers are simple and the main results are found by understanding the structure of cycles in the directed graph (where words point to definitions).", "labels": [], "entities": []}, {"text": "Based on our earlier work (Levary et al., 2012), we study a different class of word definitions, namely those of the Free Association (FA) dataset (Nelson et al., 2004).", "labels": [], "entities": [{"text": "Free Association (FA) dataset", "start_pos": 117, "end_pos": 146, "type": "DATASET", "confidence": 0.6118668466806412}]}, {"text": "These are responses by subjects to a cue word, which are then summarized by a directed, free association graph.", "labels": [], "entities": []}, {"text": "We find that the structure of this network is quite different from both the Wordnet and the dictionary networks.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9676116704940796}]}, {"text": "This difference can be explained by the very nature of free association as compared to the more \"logical\" construction of dictionaries.", "labels": [], "entities": []}, {"text": "It thus sheds some (quantitative) light on the psychology of free association.", "labels": [], "entities": []}, {"text": "In NLP, semantic groups or clusters are interesting for various applications such as word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 85, "end_pos": 110, "type": "TASK", "confidence": 0.7726507385571798}]}, {"text": "The FA graph is tighter than the DD graph, because of the large number of triangles.", "labels": [], "entities": [{"text": "FA graph", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.6053462624549866}]}, {"text": "This also makes drift of meaning quite measurable so that FA graphs provide a quantitative measure of the semantic coherence of small groups of words.", "labels": [], "entities": []}], "introductionContent": [{"text": "The computer study of semantic networks has been around since the advent of computers and has been used to study semantic relations between concepts and for analyzing semantic data.", "labels": [], "entities": []}, {"text": "Traditionally, a popular lexical database of English is Wordnet, which organizes the semantic network in terms of graph theory.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9639144539833069}]}, {"text": "In contrast to manual approaches, the automatic analysis of semantically interesting graph structures of language has received increasing attention.", "labels": [], "entities": [{"text": "automatic analysis of semantically interesting graph structures", "start_pos": 38, "end_pos": 101, "type": "TASK", "confidence": 0.7483665559973035}]}, {"text": "For example, it has become clear more recently that cycles and triangles play an important role in semantic networks, see e.g.,).", "labels": [], "entities": []}, {"text": "These results suggest that the underlying semantic structure of language maybe discovered through graph-theoretical methods.", "labels": [], "entities": []}, {"text": "This is inline with similar findings in much wider realms than NLP ().", "labels": [], "entities": []}, {"text": "In this paper, we compare two different types of association networks.", "labels": [], "entities": []}, {"text": "The first network is constructed from an English dictionary (DD), the second from a free association (FA) database ).", "labels": [], "entities": []}, {"text": "We represent both datasets through directed graphs.", "labels": [], "entities": []}, {"text": "For DD, the nodes are words and the directed edges point from a word to its definition(s).", "labels": [], "entities": []}, {"text": "For FA, the nodes are again words, and each cue word has a directed edge to each association it elicits.", "labels": [], "entities": [{"text": "FA", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.955242931842804}]}, {"text": "Although the links in these graphs were not constructed by following a rational centralized process, their graph exhibits very specific features and we concentrate on the study of its topological properties.", "labels": [], "entities": []}, {"text": "We will show that these graphs are quite different in global and local structure, and we interpret this as a reflection of the different nature of DD vs. FA.", "labels": [], "entities": [{"text": "FA", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.7668927907943726}]}, {"text": "The first is an objective set of rela-tions between words and their meaning, as explained by other words, while the second reveals the nature of subjective reactions to cue words by individuals.", "labels": [], "entities": []}, {"text": "This matter of fact is reflected by several quantitative differences in the structure of the corresponding graphs.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is an empirical analysis of the way semantic knowledge is structured, comparing two different types of association networks (DD and FA).", "labels": [], "entities": [{"text": "FA", "start_pos": 168, "end_pos": 170, "type": "METRIC", "confidence": 0.9341610074043274}]}, {"text": "We conduct a mathematical analysis of the structure of the graphs to show that the way humans express their thoughts exhibits structural properties in which one can find semantic patterns.", "labels": [], "entities": []}, {"text": "We show that a simple graph-based approach can leverage the information encoded in free association to narrow down the ambiguity of meaning, resulting in precise semantic groups.", "labels": [], "entities": []}, {"text": "In particular, we find that the main strongly connected component of the FA graph (the so-called core) is very cyclic in nature and contains a large predominance of short cycles (i.e., co-links and triangles).", "labels": [], "entities": [{"text": "FA graph", "start_pos": 73, "end_pos": 81, "type": "DATASET", "confidence": 0.7410007417201996}]}, {"text": "In contrast to the DD graph, bunches of triangles form well-delimited lexical fields of collective semantic knowledge.", "labels": [], "entities": []}, {"text": "This property maybe promising for downstream tasks.", "labels": [], "entities": []}, {"text": "Further, the methods developed in this paper maybe applicable to graph representations that occur in other problems such as word sense disambiguation (e.g.,) or sentiment polarity induction.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 124, "end_pos": 149, "type": "TASK", "confidence": 0.6658398707707723}, {"text": "sentiment polarity induction", "start_pos": 161, "end_pos": 189, "type": "TASK", "confidence": 0.8699304461479187}]}, {"text": "To show the semantic coherence of these lexical fields of the FA graph, we perform an experiment with human raters and find that cycles are strongly semantically connected even when compared to close neighbors in the graph.", "labels": [], "entities": [{"text": "FA graph", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.8080033361911774}]}, {"text": "The reader might wonder why sets of pairwise associations can lead to any interesting structure.", "labels": [], "entities": []}, {"text": "One of the deep results in graph theory,, is that in sparse graphs, i.e., in graphs with few links per node, the number of triangles is extremely rare.", "labels": [], "entities": [{"text": "graph theory", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.7529475092887878}]}, {"text": "Therefore, if one does find many triangles in a graph, they must be not only a signal of non-randomness, but carry relevant information about the domain of research as shown earlier).", "labels": [], "entities": []}], "datasetContent": [{"text": "This dataset is one of the largest existing databases of free associations (FA) and has been collected at the University of South Florida since 1973 by researchers in psychology ( ).", "labels": [], "entities": []}, {"text": "Over the years, more than 6'000 participants produced about 750'000 responses to 5'019 stimulus words.", "labels": [], "entities": []}, {"text": "The procedure for collecting the data is called discrete association task and consists in asking participants to give the first word that comes to mind (target) when presented a stimulus word (cue).", "labels": [], "entities": []}, {"text": "For creating the initial set of stimulus words, the Jenkins and Palermo word association norms) proved useful but too limited as they consist of only 200 words.", "labels": [], "entities": []}, {"text": "For this reason, additional words have been regularly added to the pool of normed words, unfortunately without well established rules being followed.", "labels": [], "entities": []}, {"text": "For instance, some were selected as potentially interesting cues, some were added as responses to the first sets of cues and, some others were collected for supporting new studies on verbs.", "labels": [], "entities": []}, {"text": "We still work with this database, because of its breadth.", "labels": [], "entities": []}, {"text": "The final pool of stimuli comprises 5'019 words of which 76% are nouns, 13% adjectives, and 7% verbs.", "labels": [], "entities": []}, {"text": "A word association is said to be normed when the target is also part of the set of norms, i.e., a cue.", "labels": [], "entities": []}, {"text": "The USF dataset of free associations contains 72'176 cue-target pairs, 63'619 of which are normed.", "labels": [], "entities": [{"text": "USF dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9655268788337708}]}, {"text": "As an example, the association puberty-sex is normed whereas the association puberty-thirteen is not, because thirteen is not a cue.", "labels": [], "entities": []}, {"text": "To validate our findings, we conducted an empirical evaluation through human annotators.", "labels": [], "entities": []}, {"text": "Starting from the 1'204 4-groups, we designed the following experiment: We corrupt the groups by exchanging one of the 4 elements with a randomly chosen word at a distance from the group of 1, 2, and \"infinity\" (i.e., any word of the whole core).", "labels": [], "entities": []}, {"text": "We presented 100 random samples for each of the 3 distances as well as 100 unperturbed groups (original) to annotators at Amazon Mechanical Turk 1 , asking which word fits the group the least.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk 1", "start_pos": 122, "end_pos": 146, "type": "DATASET", "confidence": 0.981134444475174}]}, {"text": "Intuitively, the closer the randomly chosen words get to the group, the closer the distribution of the votes for each sample should be to the uniform distribution.", "labels": [], "entities": []}, {"text": "We collected 10 votes for each of the 4 problems of 100 random samples.", "labels": [], "entities": []}, {"text": "We calculated accuracy (i.e., the relative frequency of correctly identified random words) for the 3 random confounder experiments and Fleiss' \u03ba.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9995241165161133}]}, {"text": "Further, we used the Kolmogorov-Smirnov (KS) test for how uniform the label distribution is, reporting the relative frequency of samples that are significantly (p < 0.05) different from the uniform distribution.", "labels": [], "entities": []}, {"text": "The results of this experiment are summarized in Table 2 and show clearly that the certainty about the \"odd man out\" increases together with the distance.", "labels": [], "entities": [{"text": "certainty", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9973281621932983}]}, {"text": "The Edinburgh Associative Thesaurus (EAT) () is a large dataset of free associations.", "labels": [], "entities": [{"text": "Edinburgh Associative Thesaurus (EAT)", "start_pos": 4, "end_pos": 41, "type": "DATASET", "confidence": 0.9152997136116028}]}, {"text": "We extract the EAT FA seed-crux with the previously described methods.", "labels": [], "entities": [{"text": "EAT FA seed-crux", "start_pos": 15, "end_pos": 31, "type": "DATASET", "confidence": 0.750115970770518}]}, {"text": "We start by generating the initial graph (23'219 vertices and 325'589 edges), then extract its core (7'754 vertices and 247'172 edges) and its seed 1 http://www.mturk.com.", "labels": [], "entities": []}, {"text": "It is interesting to notice at this stage that the EAT seed contains 74% of the words belonging to the USF seed.", "labels": [], "entities": [{"text": "EAT seed", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.8263782858848572}, {"text": "USF seed", "start_pos": 103, "end_pos": 111, "type": "DATASET", "confidence": 0.9643689393997192}]}, {"text": "After generating the seed-crux which contains 63'363 vertices, 6'825'731 edges, and 342'490 maximal cliques, we finally obtain 40'998 lists of words.", "labels": [], "entities": []}, {"text": "These lists comprise between 4 and 233 words but 80% of them have a relatively small size between 4 and 20.", "labels": [], "entities": []}, {"text": "Although we find exceptions for this graph, most of the extracted lists again form well-delimited lexical fields (e.g., (health, resort, spa, bath, salts) or (god, devil, angel, satan).", "labels": [], "entities": []}, {"text": "Comparing the two association experiments, we see that the local topologies are quite similar.", "labels": [], "entities": []}, {"text": "Both FA cores have a high density of connected triangles, whereas cycles in the DD graph tend to be longer and most triangles are isolated.", "labels": [], "entities": []}, {"text": "This can be attributed to the different ways in which DD and FA are obtained, the former being built rationally by following a humanly-driven process and the latter reflecting an implicit collective semantic knowledge.", "labels": [], "entities": [{"text": "FA", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9845974445343018}]}], "tableCaptions": [{"text": " Table 1: Comparison FA vs DD", "labels": [], "entities": [{"text": "FA", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.5678095817565918}]}]}