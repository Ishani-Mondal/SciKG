{"title": [{"text": "A Walk-based Semantically Enriched Tree Kernel Over Distributed Word Representations", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose a walk-based graph kernel that generalizes the notion of tree-kernels to continuous spaces.", "labels": [], "entities": []}, {"text": "Our proposed approach subsumes a general framework for word-similarity, and in particular, provides a flexible way to incorporate distributed representations.", "labels": [], "entities": []}, {"text": "Using vector representations, such an approach captures both distributional semantic similarities among words as well as the structural relations between them (encoded as the structure of the parse tree).", "labels": [], "entities": []}, {"text": "We show an efficient formulation to compute this kernel using simple matrix operations.", "labels": [], "entities": []}, {"text": "We present our results on three diverse NLP tasks, showing state-of-the-art results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Capturing semantic similarity between sentences is a fundamental issue in NLP, with applications in a wide range of tasks.", "labels": [], "entities": [{"text": "Capturing semantic similarity between sentences", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.9316197752952575}]}, {"text": "Previously, tree kernels based on common substructures have been used to model similarity between parse trees).", "labels": [], "entities": []}, {"text": "These kernels encode a high number of latent syntactic features within a concise representation, and compute the similarity between two parse trees based on the matching of node-labels (words, POS tags, etc.), as well as the overlap of tree structures.", "labels": [], "entities": []}, {"text": "While this is sufficient to capture syntactic similarity, it does not capture semantic similarity very well, even when using discrete semantic types as node labels.", "labels": [], "entities": []}, {"text": "This constrains the utility of many traditional tree kernels in two ways: i) two sentences that are syntactically identical, but have no semantic similarity can receive a high matching score (see, top) while ii) two sentences with only local syntactic overlap, but high semantic similarity can receive low scores (see, bottom).", "labels": [], "entities": []}, {"text": "In contrast, distributional vector representations of words have been successful in capturing finegrained semantics, but lack syntactic knowledge.", "labels": [], "entities": []}, {"text": "Resources such as Wordnet, dictionaries and ontologies that encode different semantic perspectives can also provide additional knowledge infusion.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9571117758750916}]}, {"text": "In this paper, we describe a generic walk-based graph kernel for dependency parse trees that subsumes general notions of word-similarity, while focusing on vector representations of words to capture lexical semantics.", "labels": [], "entities": [{"text": "dependency parse trees", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7817218701044718}]}, {"text": "Through a convolutional framework, our approach takes into account the distributional semantic similarities between words in a sentence as well as the structure of the parse tree.", "labels": [], "entities": []}, {"text": "Our main contributions are: 1.", "labels": [], "entities": []}, {"text": "We present anew graph kernel for NLP that extends to distributed word representations, and diverse word similarity measures.", "labels": [], "entities": []}, {"text": "2. Our proposed approach provides a flexible framework for incorporating both syntax and semantics of sentence level constructions.", "labels": [], "entities": []}, {"text": "3. Our generic kernel shows state-of-the-art performance on three eclectic NLP tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the Vector Tree Kernel (VTK) on three NLP tasks.", "labels": [], "entities": [{"text": "Vector Tree Kernel (VTK)", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6162760456403097}]}, {"text": "We create dependency trees using the FANSE parser (), and use distribution-based SENNA word embeddings by as word representations.", "labels": [], "entities": [{"text": "FANSE", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.7388962507247925}]}, {"text": "These embeddings provide low-dimensional vector representations of words, while encoding distributional semantic characteristics.", "labels": [], "entities": []}, {"text": "We use LibSVM for classification.", "labels": [], "entities": [{"text": "LibSVM", "start_pos": 7, "end_pos": 13, "type": "DATASET", "confidence": 0.9192603230476379}]}, {"text": "For sake of brevity, we only report results for the best performing kernel.", "labels": [], "entities": []}, {"text": "We first consider the Cornell Sentence Polarity dataset by.", "labels": [], "entities": [{"text": "Cornell Sentence Polarity dataset", "start_pos": 22, "end_pos": 55, "type": "DATASET", "confidence": 0.9036522060632706}]}, {"text": "The task is to identify the polarity of a given sentence.", "labels": [], "entities": []}, {"text": "The data consists of 5331 sentences from positive and negative movie reviews.", "labels": [], "entities": []}, {"text": "Many phrases denoting sentiments are lexically ambiguous (cf. \"terribly entertaining\" vs \"terribly written\"), so simple lexical approaches are not expected to work well here, while syntactic context could help disambiguation.", "labels": [], "entities": []}, {"text": "Next, we try our approach on the MSR paraphrase corpus.", "labels": [], "entities": [{"text": "MSR paraphrase corpus", "start_pos": 33, "end_pos": 54, "type": "DATASET", "confidence": 0.7333945234616598}]}, {"text": "The data contains a training set of 4077 pairs of sentences, annotated as paraphrases and non-paraphrases, and a test-set of 1726 sentence pairs.", "labels": [], "entities": []}, {"text": "Each instance consists of a pair of sentences, so the VTK cannot be directly used by a kernel machine for classification.", "labels": [], "entities": [{"text": "VTK", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8712035417556763}]}, {"text": "Instead, we generate 16 kernel values based for each pair on different parameter settings of the kernel, and feed these as features to a linear SVM.", "labels": [], "entities": []}, {"text": "We finally look at the annotated Metaphor corpus by).", "labels": [], "entities": [{"text": "Metaphor corpus", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.8678143322467804}]}, {"text": "The dataset consists of sentences with specified target phrases.", "labels": [], "entities": []}, {"text": "The task here is to classify the target use as literal or metaphorical.", "labels": [], "entities": []}, {"text": "We focus on target phrases by upweighting walks that pass through target nodes.", "labels": [], "entities": []}, {"text": "This is done by simply multiplying the corresponding entries in the adjacency matrix by a constant factor.: Results on Sentence Polarity dataset On the polarity data set, Vector Tree Kernel (VTK) significantly outperforms the state-of-the-art method by Carrillo de, who use a hybrid model incorporating databases of affective lexicons, and also explicitly model the effect of negation and quantifiers (see).", "labels": [], "entities": [{"text": "Sentence Polarity dataset", "start_pos": 119, "end_pos": 144, "type": "DATASET", "confidence": 0.6354625225067139}]}, {"text": "Lexical approaches using pairwise semantic similarity of SENNA embeddings (DSM), as well as Wordnet Affective Database-based (WNA) labels perform poorly (Carrillo de, showing the importance of syntax for this particular problem.", "labels": [], "entities": []}, {"text": "On the other hand, a syntactic tree kernel (SSTK) that ignores distributional semantic similarity between words, fails as expected.", "labels": [], "entities": []}, {"text": "On the MSR paraphrase corpus, VTK performs competitively against state-of-the-art-methods.", "labels": [], "entities": [{"text": "VTK", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.657573401927948}]}, {"text": "We expected paraphrasing to be challenging to our method, since it can involve little syntactic overlap.", "labels": [], "entities": []}, {"text": "However, data analysis reveals that the corpus generally contains sentence pairs with high syntactic similarity.", "labels": [], "entities": []}, {"text": "Results for this task are encouraging since ours is a general approach, while other systems use multiple task-specific features like semantic role labels, active-passive voice conversion, and synonymy resolution.", "labels": [], "entities": [{"text": "active-passive voice conversion", "start_pos": 155, "end_pos": 186, "type": "TASK", "confidence": 0.7406689723332723}, {"text": "synonymy resolution", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.7006334215402603}]}, {"text": "In the future, incorporating such features to VTK should further improve results for this task .: Results on Metaphor dataset On the Metaphor corpus, VTK improves the previous score by, whose approach uses an conjunction of lexical and syntactic tree kernels), and distributional vectors.", "labels": [], "entities": [{"text": "VTK", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.9103330373764038}, {"text": "Metaphor dataset", "start_pos": 109, "end_pos": 125, "type": "DATASET", "confidence": 0.804745078086853}, {"text": "Metaphor corpus", "start_pos": 133, "end_pos": 148, "type": "DATASET", "confidence": 0.8234916925430298}]}, {"text": "VTK identified several templates of metaphor usage such as \"warm heart\" and \"cold shoulder\".", "labels": [], "entities": [{"text": "VTK", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9636027216911316}]}, {"text": "We look towards approaches for automatedly mining such metaphor patterns from a corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on Sentence Polarity dataset  On the polarity data set, Vector Tree Kernel  (VTK) significantly outperforms the state-of-the-art  method by Carrillo de", "labels": [], "entities": [{"text": "Sentence Polarity", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.8523375391960144}]}, {"text": " Table 3: Results on MSR Paraphrase corpus", "labels": [], "entities": [{"text": "MSR Paraphrase", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.9074594080448151}]}, {"text": " Table 4: Results on Metaphor dataset  On the Metaphor corpus, VTK improves the pre- vious score by", "labels": [], "entities": [{"text": "Metaphor dataset", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.7717578709125519}, {"text": "Metaphor corpus", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.9337430000305176}, {"text": "VTK", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.6100141406059265}]}]}