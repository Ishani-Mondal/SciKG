{"title": [], "abstractContent": [{"text": "Animacy detection is a problem whose solution has been shown to be beneficial fora number of syntactic and semantic tasks.", "labels": [], "entities": [{"text": "Animacy detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9066499471664429}]}, {"text": "We present a state-of-the-art system for this task which uses a number of simple classifiers with heterogeneous data sources in a voting scheme.", "labels": [], "entities": []}, {"text": "We show how this framework can give us direct insight into the behavior of the system, allowing us to more easily diagnose sources of error.", "labels": [], "entities": []}], "introductionContent": [{"text": "Animacy detection has proven useful fora variety of syntactic and semantic tasks, such as anaphora and coreference resolution, verb argument disambiguation) and dependency parsing.", "labels": [], "entities": [{"text": "Animacy detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.870110422372818}, {"text": "coreference resolution", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7836985886096954}, {"text": "verb argument disambiguation", "start_pos": 127, "end_pos": 155, "type": "TASK", "confidence": 0.6786994934082031}, {"text": "dependency parsing", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.8654754161834717}]}, {"text": "Existing approaches for animacy detection typically rely on two types of information: linguistic databases, and syntactic cues observed from the corpus.", "labels": [], "entities": [{"text": "animacy detection", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.8772051930427551}]}, {"text": "They usually combine two types of approaches: rule based systems, and machine learning techniques.", "labels": [], "entities": []}, {"text": "In this paper we explore a slightly different angle: we wish to design an animacy detector whose decisions are interpretable and correctable, so that downstream semantic modeling systems can revisit those decisions as needed.", "labels": [], "entities": []}, {"text": "Thus here, we avoid defining a large number of features and then using a machine learning method such as boosted trees, since such methods, although powerful, result in hard-tointerpret systems.", "labels": [], "entities": []}, {"text": "Instead, we explore combining interpretable voting models using machine learning * Work performed while visiting Microsoft Research.", "labels": [], "entities": []}, {"text": "only to reweight their votes.", "labels": [], "entities": []}, {"text": "We show that such an approach can indeed result in a high performing system, with animacy detection accuracies in the mid 90% range, which compares well with other reported rates.", "labels": [], "entities": [{"text": "animacy detection accuracies", "start_pos": 82, "end_pos": 110, "type": "METRIC", "confidence": 0.8926401535669962}]}, {"text": "Ensemble methods are well known (see for example, Dietterich (2000)) but our focus here is on using them for interpretability while still maintaining accuracy.", "labels": [], "entities": [{"text": "interpretability", "start_pos": 109, "end_pos": 125, "type": "TASK", "confidence": 0.9667297601699829}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9958602786064148}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy of various individual voters on the test  set. Abstentions are counted as errors. Note that Transfer  depends on a secondary source for classification, and is  therefore not listed here.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9905487895011902}, {"text": "Abstentions", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.9872272610664368}, {"text": "Transfer", "start_pos": 111, "end_pos": 119, "type": "TASK", "confidence": 0.9474369883537292}]}, {"text": " Table 2: Accuracy of various combinations of voters  among Name (N), Anaphora Design (AD), List (L),  WordNet (WN), WordSim (WS), Dictionary (D), and  Transfer (T) under majority voting and SVM schemes.  Bold indicates a statistically significant difference over  the next lower bolded entry with p < 0.01, for the SVM.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9847853183746338}, {"text": "WordSim", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.8763074278831482}]}, {"text": " Table 3: Test accuracy when leaving out various voters,  using both majority vote and and reweighting. Bold indi- cates statistical significance over the next lower bold line  with p < 0.01.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9995589852333069}, {"text": "Bold indi- cates statistical significance", "start_pos": 104, "end_pos": 145, "type": "METRIC", "confidence": 0.7166484097639719}]}, {"text": " Table 4: Errors column: number of errors on train and  test where a source voted incorrectly, and was thus at  least in part responsible for an error of the overall sys- tem. Critical column: number of errors on train and test  where a source voted incorrectly, and in addition cast a  deciding vote. Results are for majority vote.", "labels": [], "entities": [{"text": "Errors", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9917186498641968}]}]}