{"title": [{"text": "Unsupervised Induction of Contingent Event Pairs from Film Scenes", "labels": [], "entities": [{"text": "Unsupervised Induction of Contingent Event Pairs from Film Scenes", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.6082082092761993}]}], "abstractContent": [{"text": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning.", "labels": [], "entities": []}, {"text": "Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the CONTINGENT discourse relation, or as a type of common-sense causal reasoning.", "labels": [], "entities": []}, {"text": "Our approach is to model likelihood between events by drawing on several of these lines of previous work.", "labels": [], "entities": []}, {"text": "We implement and evaluate different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another.", "labels": [], "entities": []}, {"text": "We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments of contingency.", "labels": [], "entities": []}, {"text": "Our results indicate that the use of web search counts increases the average accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75.15% without web search.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9957005381584167}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9974990487098694}]}], "introductionContent": [{"text": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning).", "labels": [], "entities": []}, {"text": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles).", "labels": [], "entities": []}, {"text": "DOUGLAS QUAIL and his wife KRISTEN, are asleep in bed.", "labels": [], "entities": [{"text": "DOUGLAS QUAIL", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.5759597420692444}, {"text": "KRISTEN", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9864077568054199}]}, {"text": "Gradually the room lights brighten.", "labels": [], "entities": []}, {"text": "the clock chimes and begins speaking in a soft, feminine voice.", "labels": [], "entities": []}, {"text": "Shortly, the clock chimes again.", "labels": [], "entities": []}, {"text": "Maddeningly, the clock chimes a third time.", "labels": [], "entities": []}, {"text": "CLOCK (continuing)Tick, tock -.", "labels": [], "entities": [{"text": "CLOCK", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8564754128456116}, {"text": "Tick", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.7582549452781677}]}, {"text": "Quail reaches out and shuts the clock off.", "labels": [], "entities": []}, {"text": "Then he sits up in bed.", "labels": [], "entities": []}, {"text": "He swings his legs out from under the covers and sits on the edge of the bed.", "labels": [], "entities": []}, {"text": "He puts on his glasses and sits, lost in thought.", "labels": [], "entities": []}, {"text": "He is a good-looking but conventional man in his early thirties.", "labels": [], "entities": []}, {"text": "He seems rather in awe of his wife, who is attractive and rather off-hand towards him.", "labels": [], "entities": []}, {"text": "Kirsten pulls on her robe, lights a cigarette, sits fishing for her slippers.", "labels": [], "entities": []}, {"text": "Recent work in NLP has tackled the inference of relations between events from abroad range of perspectives: (1) as inference of a discourse relations (e.g. the Penn Discourse Treebank (PDTB) CON-TINGENT relation and its specializations); (2) as a type of commonsense reasoning; (3) as part of text understanding to support question-answering; and (4) as way of learning script-like or plot-like knowledge structures.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB) CON-TINGENT relation", "start_pos": 160, "end_pos": 211, "type": "DATASET", "confidence": 0.9468079954385757}]}, {"text": "All these lines of work aim to model narrative understanding, i.e. to enable systems to infer which events are likely to have happened even though they have not been mentioned in the text (, and which events are likely to happen in the future.", "labels": [], "entities": []}, {"text": "Such knowledge has practical applications in commonsense reasoning, infor-mation retrieval, question answering, narrative understanding and inferring discourse relations.", "labels": [], "entities": [{"text": "commonsense reasoning", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.8941620290279388}, {"text": "infor-mation retrieval", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.7604575455188751}, {"text": "question answering", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.9161905348300934}, {"text": "narrative understanding", "start_pos": 112, "end_pos": 135, "type": "TASK", "confidence": 0.7338107377290726}]}, {"text": "We model this likelihood between events by drawing on the PTDB's general definition of the CONTINGENT relation, which encapsulates relations elsewhere called CAUSE, CONDITION and ENABLE-MENT (.", "labels": [], "entities": [{"text": "PTDB", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9542019963264465}, {"text": "CONTINGENT", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9618919491767883}, {"text": "ENABLE-MENT", "start_pos": 179, "end_pos": 190, "type": "METRIC", "confidence": 0.9552986025810242}]}, {"text": "Our aim in this paper is to implement and evaluate a range of different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another.", "labels": [], "entities": []}, {"text": "We first utilize a corpus of scene descriptions from films because they are guaranteed to have an explicit narrative structure.", "labels": [], "entities": []}, {"text": "Moreover, screenplay scene descriptions tend to be told in temporal order, which makes them a good resource for learning about contingencies between events.", "labels": [], "entities": []}, {"text": "In addition, scenes in film represent many typical sequences from real life, while providing a rich source of event clusters related to battles, love and mystery.", "labels": [], "entities": []}, {"text": "We carryout separate experiments for the action movie genre and the romance movie genre.", "labels": [], "entities": []}, {"text": "For example, in the scene from Total Recall, from the action movie genre (See), we might learn that the event of sits up is CONTINGENT on the event of clock chimes.", "labels": [], "entities": [{"text": "Total Recall", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.5709830224514008}, {"text": "CONTINGENT", "start_pos": 124, "end_pos": 134, "type": "METRIC", "confidence": 0.9359737038612366}]}, {"text": "The subset of the corpus we use comprises 123,869 total unique event pairs.", "labels": [], "entities": []}, {"text": "We produce initial scalar estimates of potential CONTINGENCY between events using four previously defined measures of distributional cooccurrence.", "labels": [], "entities": []}, {"text": "We then refine these estimates through web searches that explicitly model the patterns of narrative event sequences that were previously observed to be likely within a particular genre.", "labels": [], "entities": []}, {"text": "There are several advantages of this method: (1) events in the same genre tend to be more similar than events across genres, so less data is needed to estimate co-occurrence; (2) film scenes are typically narrated via simple tenses in the correct temporal order, which allows the ordering of events to contribute to the estimation of the CONTINGENCY relation; (3) The web counts focus on validating event pairs already deemed to be likely to be CONTINGENT in the smaller, more controlled, film scene corpus.", "labels": [], "entities": []}, {"text": "To test our method, we conduct perceptual experiments with human subjects on Mechanical Turk by asking them to select which of two pairs of events are the most likely.", "labels": [], "entities": [{"text": "Mechanical Turk", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.8819023072719574}]}, {"text": "For example, given the scene from Total Recall in, Mechanical Turkers are asked to select whether the sequential event pair clock chimes, sits up is more likely than clock chimes followed by a randomly selected event from the action film genre.", "labels": [], "entities": [{"text": "Total Recall", "start_pos": 34, "end_pos": 46, "type": "TASK", "confidence": 0.5500783324241638}]}, {"text": "Our experimental data and annotations are available at http://nlds.", "labels": [], "entities": []}, {"text": "soe.ucsc.edu/data/EventPairs.", "labels": [], "entities": []}, {"text": "2 describes our experimental method in detail.", "labels": [], "entities": []}, {"text": "3 describes how we setup our evaluation experiments and the results.", "labels": [], "entities": []}, {"text": "We show that none of the methods from previous work perform better on our data than 75.15% average accuracy as measured by human perceptions of CONTINGENCY.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9967054724693298}]}, {"text": "But after web search refinement, we achieve an average accuracy of 85.64%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9995736479759216}]}, {"text": "We delay a more detailed comparison to previous work to Sec.", "labels": [], "entities": []}, {"text": "4 where we summarize our results and compare previous work to our own.", "labels": [], "entities": [{"text": "summarize", "start_pos": 11, "end_pos": 20, "type": "TASK", "confidence": 0.971805214881897}]}], "datasetContent": [{"text": "Our method uses a combination of estimating the likelihood of a CONTINGENT relation between events in a corpus of film scenes (, with estimates then revised through web search.", "labels": [], "entities": [{"text": "CONTINGENT", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.7932471036911011}]}, {"text": "Our experiments are based on two subsets of 862 film screen plays collected from the IMSDb website using its ontology of film genres (): a set of action movies of 115 screenplays totalling 748 MB, and a set of romance movies of 71 screenplays totalling 390 MB.", "labels": [], "entities": [{"text": "IMSDb website", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.9328663945198059}]}, {"text": "provided an example scene from the action movie genre from the IMSDb corpus.", "labels": [], "entities": [{"text": "IMSDb corpus", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.9649301767349243}]}, {"text": "We assume that the relation we are aiming to learn is the PDTB CONTINGENT relation, which is defined as a relation that exists when one of the situations described in the text spans that are identified as the two arguments of the relation, i.e. Arg1 and Arg2, causally influences the other ().", "labels": [], "entities": [{"text": "PDTB", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.407108873128891}, {"text": "CONTINGENT", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.6611733436584473}, {"text": "Arg2", "start_pos": 254, "end_pos": 258, "type": "METRIC", "confidence": 0.8445916175842285}]}, {"text": "As Girju notes, it is notoriously difficult to define causality without making the definition circular, but we follow Beamer and Girju's work in assuming that if events A, B are causally related then B should occur less frequently when it is not preceded by A and that B \u2192A should be much less frequent than A \u2192 B.", "labels": [], "entities": []}, {"text": "We assume that both the CAUSE and CONDITION subtypes of the CONTIN-GENCY relation will result in pairs of events that are likely to occur together and in a particular order.", "labels": [], "entities": [{"text": "CAUSE", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.8208663463592529}, {"text": "CONDITION", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.7830507159233093}]}, {"text": "In particular we assume that the subtypes of the PDTB taxonomy of Contingency.Cause.Reason and Contingency.Cause.Result are the most likely to occur together as noted in previous work.", "labels": [], "entities": []}, {"text": "Other related work has made use of discourse connectives or discourse taggers (implicit discourse relations) to provide additional evidence of CONTINGENCY), but we do not because the results have been mixed.", "labels": [], "entities": [{"text": "CONTINGENCY", "start_pos": 143, "end_pos": 154, "type": "METRIC", "confidence": 0.8491376638412476}]}, {"text": "In particular these discourse taggers are trained on The Wall Street Journal (WSJ) and are unlikely to work well on our data.", "labels": [], "entities": [{"text": "discourse taggers", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7582954466342926}, {"text": "The Wall Street Journal (WSJ)", "start_pos": 53, "end_pos": 82, "type": "DATASET", "confidence": 0.8965168680463519}]}, {"text": "We define an event as a verb lemma with its subject and object.", "labels": [], "entities": []}, {"text": "Two events are considered equal if they have the same verb.", "labels": [], "entities": []}, {"text": "We do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same surface verb, in some cases with a restriction that the dependency relations should also be the same.", "labels": [], "entities": []}, {"text": "Word sense ambiguities are also reduced in specific genres (Action and Romance) of film scenes.", "labels": [], "entities": []}, {"text": "Our method for estimating the likelihood of a CONTINGENT relations between events consists of four steps: We use Stanford CoreNLP to annotate the corpus document by document and store the annotated text in XML format (Sec. 2.1); 4.", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 113, "end_pos": 129, "type": "DATASET", "confidence": 0.9113985300064087}]}, {"text": "WEB SEARCH REFINEMENT: We select the top 100 event pairs calculated by each contingency measure, and construct a RANDOM EVENT PAIR (REP) for each PCEP that preserves the first element of the PCEP, and replaces the second element with another event selected randomly from within the same genre.", "labels": [], "entities": [{"text": "WEB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5831344127655029}, {"text": "SEARCH", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.8524525761604309}, {"text": "REFINEMENT", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.6438397169113159}, {"text": "RANDOM EVENT PAIR (REP)", "start_pos": 113, "end_pos": 136, "type": "METRIC", "confidence": 0.9204472700754801}]}, {"text": "We then define web search patterns for both PCEP and REPs and compare the counts (Sec. 2.4).", "labels": [], "entities": []}, {"text": "While other work uses a range of methods for evaluating accuracy, to our knowledge our work is the first to use human judgments from Mechanical Turk to evaluate the accuracy of the learned PCEPs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9946470856666565}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9943221807479858}]}, {"text": "We first describe the evaluation setup in Sec.", "labels": [], "entities": []}, {"text": "3.1 and then report the results in Sec.", "labels": [], "entities": []}, {"text": "3.2  We used three different types of HITs (Human Intelligence Tasks) on Mechanical Turk for our evaluation.", "labels": [], "entities": []}, {"text": "Two of the HITS are in and.", "labels": [], "entities": [{"text": "HITS", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.6889504194259644}]}, {"text": "The differences in the different types of HITS involve: (1) whether the arguments of events were given in the HIT, as in and: whether the Turkers were told that the order of the events mattered, as in.", "labels": [], "entities": [{"text": "HIT", "start_pos": 110, "end_pos": 113, "type": "DATASET", "confidence": 0.7275768518447876}]}, {"text": "We initially thought that providing the arguments to the events as shown in would help Turkers to reason about which event was more likely.", "labels": [], "entities": []}, {"text": "We tested this hypothesis only in the action genre for the Causal Potential Measure.", "labels": [], "entities": []}, {"text": "For CP, Bigram and Protag the order of events always matters.", "labels": [], "entities": [{"text": "CP", "start_pos": 4, "end_pos": 6, "type": "DATASET", "confidence": 0.8338308930397034}, {"text": "Bigram", "start_pos": 8, "end_pos": 14, "type": "DATASET", "confidence": 0.8583781719207764}, {"text": "Protag", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.8842660188674927}]}, {"text": "For the PMI task, the order of the events doesn't matter because PMI is asymmetric measure.", "labels": [], "entities": [{"text": "PMI task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.931619256734848}]}, {"text": "illustrates the instructions that were given with the HIT when the event order doesn't matter.", "labels": [], "entities": []}, {"text": "In all the other cases, the instructions that were given with the HIT are those in where the Turkers are instructed to pay attention to the order of the events.", "labels": [], "entities": []}, {"text": "For all types of HITS, for all measures of CON-TINGENCY, we setup the task as a choice over two alternatives, where for each predicted contingent pair (PCEP), we generate a random event pair (REP), with the first event the same and the second one randomly chosen from all the events in the same film genre.", "labels": [], "entities": [{"text": "CON-TINGENCY", "start_pos": 43, "end_pos": 55, "type": "METRIC", "confidence": 0.7523363828659058}]}, {"text": "The REPs are constructed the same way as we construct REPs for web search refinement, as illustrated by.", "labels": [], "entities": [{"text": "web search refinement", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.6378575265407562}]}, {"text": "This is illustrated in both.", "labels": [], "entities": []}, {"text": "For all types of HITS, we ask 15 Turkers from a pre-qualified group to select which pair (the PCEP or the REP) is more likely to occur together.", "labels": [], "entities": [{"text": "REP", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.903013288974762}]}, {"text": "Thus, the framing of these Mechanical Turk tasks only assumes that the average person knows how the world works; we do not ask them to explicitly reason about causality as other work does).", "labels": [], "entities": [{"text": "Mechanical Turk tasks", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.7304585079352061}]}, {"text": "For each measure of CONTINGENCY, we take 100 event pairs with highest PCEP scores, and put them in 5 HITs with twenty items per HIT.", "labels": [], "entities": [{"text": "CONTINGENCY", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.8701251149177551}, {"text": "PCEP scores", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9565925300121307}]}, {"text": "Previous work has shown that for many common NLP tasks, 7 Turkers' average score can match expert annotations ().", "labels": [], "entities": [{"text": "Turkers' average score", "start_pos": 58, "end_pos": 80, "type": "METRIC", "confidence": 0.782302717367808}]}, {"text": "However, we use 15 Turkers because we had no gold-standard data and because we were not sure how difficult the task is.", "labels": [], "entities": []}, {"text": "To calculate the accuracy of each method, we computed the average correlation coefficient between each pair of raters and eliminate the 5 lowest scoring workers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9996484518051147}, {"text": "average correlation coefficient", "start_pos": 58, "end_pos": 89, "type": "METRIC", "confidence": 0.7237263917922974}]}, {"text": "We then used the perceptions of the 10 remaining workers to calculate accuracy as # of correct answers / total # of answers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9996048808097839}]}, {"text": "In general, deciding when a MTurk worker is unreliable when the data is subjective is a difficult problem.", "labels": [], "entities": []}, {"text": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sample web search patterns and values used in web search refinement algorithm from action genre", "labels": [], "entities": [{"text": "Sample web search patterns", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8880078047513962}]}, {"text": " Table 2: Evaluation results for the top 100 event pairs using all methods.", "labels": [], "entities": []}]}