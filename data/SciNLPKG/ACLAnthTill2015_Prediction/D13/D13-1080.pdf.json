{"title": [{"text": "Improving Learning and Inference in a Large Knowledge-base using Latent Syntactic Cues", "labels": [], "entities": [{"text": "Improving Learning and Inference", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8680504858493805}]}], "abstractContent": [{"text": "Automatically constructed Knowledge Bases (KBs) are often incomplete and there is a genuine need to improve their coverage.", "labels": [], "entities": []}, {"text": "Path Ranking Algorithm (PRA) is a recently proposed method which aims to improve KB coverage by performing inference directly over the KB graph.", "labels": [], "entities": [{"text": "Path Ranking Algorithm (PRA)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6276297718286514}, {"text": "KB coverage", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.7286807894706726}]}, {"text": "For the first time, we demonstrate that addition of edges labeled with latent features mined from a large dependency parsed corpus of 500 million Web documents can significantly outperform previous PRA-based approaches on the KB inference task.", "labels": [], "entities": []}, {"text": "We present extensive experimental results validating this finding.", "labels": [], "entities": []}, {"text": "The resources presented in this paper are publicly available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the last few years, several large scale Knowledge Bases (KBs) such as Freebase (), NELL, and YAGO () have been developed.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9698636531829834}]}, {"text": "Each such KB consists of millions of facts (e.g., (Tiger Woods, playsSport, Golf )) spanning over multiple relations.", "labels": [], "entities": [{"text": "playsSport", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.9643849730491638}]}, {"text": "Unfortunately, these KBs are often incomplete and there is a need to increase their coverage of facts to make them useful in practical applications.", "labels": [], "entities": []}, {"text": "A strategy to increase coverage might be to perform inference directly over the KB represented as a graph.", "labels": [], "entities": []}, {"text": "For example, if the KB contained the following facts, (Tiger Woods, participatesIn, PGA Tour)) and (Golf, sportOfTournament, PGA Tour), then by putting these two facts together, we could potentially infer that (Tiger Woods, playsSport, Golf ).", "labels": [], "entities": [{"text": "participatesIn", "start_pos": 68, "end_pos": 82, "type": "DATASET", "confidence": 0.9584198594093323}, {"text": "PGA Tour", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.8357288837432861}, {"text": "PGA Tour", "start_pos": 125, "end_pos": 133, "type": "DATASET", "confidence": 0.7508175671100616}, {"text": "playsSport", "start_pos": 224, "end_pos": 234, "type": "DATASET", "confidence": 0.9389609694480896}]}, {"text": "The) to discover relationships between Alex Rodriguez and World Series.", "labels": [], "entities": [{"text": "World Series", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9297961592674255}]}, {"text": "Edges with latent labels can improve inference performance by reducing data sparsity.", "labels": [], "entities": []}, {"text": "See Section 1.1 for details.", "labels": [], "entities": []}, {"text": "recently proposed Path Ranking Algorithm (PRA) performs such inference by automatically learning semantic inference rules over the KB ().", "labels": [], "entities": []}, {"text": "PRA uses features based off of sequences of edge types, e.g., playsSport, sportOfTournament, to predict missing facts in the KB.", "labels": [], "entities": []}, {"text": "PRA was extended by) to perform inference over a KB augmented with dependency parsed sentences.", "labels": [], "entities": [{"text": "PRA", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.691228449344635}]}, {"text": "While this opens up the possibility of learning syntactic-semantic inference rules, the set of syntactic edge labels used are just the unlexicalized dependency role labels (e.g., nobj, dobj, etc., without the corresponding words), thereby limiting overall expressitivity of the learned inference rules.", "labels": [], "entities": []}, {"text": "To overcome this limitation, in this paper we augment the KB graph by adding edges with more expressive lexicalized syntactic labels (where the labels are words instead of dependen-cies).", "labels": [], "entities": []}, {"text": "These additional edges, e.g., (Alex Rodriguez, \"plays for\", NY Yankees), are mined by extracting 600 million Subject-Verb-Object (SVO) triples from a large corpus of 500m dependency parsed documents, which would have been prohibitively expensive to add directly as in (.", "labels": [], "entities": [{"text": "NY Yankees)", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9329654574394226}]}, {"text": "In order to overcome the explosion of path features and data sparsity, we derive edge labels by learning latent embeddings of the lexicalized edges.", "labels": [], "entities": []}, {"text": "Through extensive experiments on real world datasets, we demonstrate effectiveness of the proposed approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compared the various methods using 15 NELL relations.", "labels": [], "entities": []}, {"text": "For each relation, we split NELL's known relation instances into 90% training and 10% testing.", "labels": [], "entities": []}, {"text": "For each method, we then selected 750 path features and trained the model, as described in Section 3, using GraphChi () to perform the random walk graph computations.", "labels": [], "entities": [{"text": "GraphChi", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.7785744667053223}]}, {"text": "To evaluate the model, we took all source nodes in the testing data and used the model to predict target nodes.", "labels": [], "entities": []}, {"text": "We report the precision and recall (on the set of known target nodes) of the set of predictions for each model that are above a certain confidence threshold.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.999685525894165}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9992856383323669}]}, {"text": "Because we used strong regularization, we picked for our threshold a model score of 0.405, corresponding to 60% probability of the relation instance being true; values higher than this left many relations without any predictions.", "labels": [], "entities": []}, {"text": "As can be seen in the table, PRA syntactic on average performs slightly worse than PRA.", "labels": [], "entities": [{"text": "PRA syntactic", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.9025757014751434}]}, {"text": "While the extra syntactic features are very informative for some relations, they also introduce a lot of sparsity, which makes the model perform worse on other relations.", "labels": [], "entities": []}, {"text": "When using latent factorization methods to reduce the sparsity of the syntactic features, we see a significant improvement in performance.", "labels": [], "entities": []}, {"text": "PRA latentc has a 45% reduction in precision errors vs. PRA while maintaining the same recall, and PRA latent d reduces precision errors by 35% while improving recall by 27%.", "labels": [], "entities": [{"text": "precision errors", "start_pos": 35, "end_pos": 51, "type": "METRIC", "confidence": 0.9786353409290314}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9978278279304504}, {"text": "precision errors", "start_pos": 120, "end_pos": 136, "type": "METRIC", "confidence": 0.9861389994621277}, {"text": "recall", "start_pos": 160, "end_pos": 166, "type": "METRIC", "confidence": 0.9991126656532288}]}, {"text": "Section 4.1 contains some qualitative analysis of how sparsity is reduced with the latent methods.", "labels": [], "entities": []}, {"text": "As apiece quanti- tative analysis, there were 908 possible path types found in the feature selection step with PRA on the relation cityLiesOnRiver (of which we then selected 750).", "labels": [], "entities": [{"text": "PRA", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9554754495620728}]}, {"text": "For PRA syntactic , there were 73,820, while PRA latentc had 47,554 and PRA latent d had 58,414.", "labels": [], "entities": []}, {"text": "shows F1 scores for each model on each relation, and shows representative Precision-Recall plots for two NELL relations.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.977687656879425}, {"text": "Precision-Recall", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.9846151471138}, {"text": "NELL relations", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.8109511137008667}]}, {"text": "In both cases, we find that PRA latent d significantly outperforms other baselines.", "labels": [], "entities": [{"text": "PRA latent d", "start_pos": 28, "end_pos": 40, "type": "METRIC", "confidence": 0.7439609169960022}]}], "tableCaptions": [{"text": " Table 1: Comparison of performance of different variants  of PRA micro averaged across 15 NELL relations. We  find that use of latent edge labels, in particular the pro- posed approach PRA latent d , significantly outperforms  other approaches. This is our main result. (See Section 4)", "labels": [], "entities": []}, {"text": " Table 2: F1 performance of different variants of PRA for all 15 relations tested.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995203018188477}]}]}