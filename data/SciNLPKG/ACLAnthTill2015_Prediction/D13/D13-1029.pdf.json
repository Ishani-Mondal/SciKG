{"title": [{"text": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 6, "end_pos": 28, "type": "TASK", "confidence": 0.7668973803520203}, {"text": "Named-Entity Linking", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.6603119671344757}, {"text": "Sieves", "start_pos": 70, "end_pos": 76, "type": "TASK", "confidence": 0.5638388395309448}]}], "abstractContent": [{"text": "Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.9607908427715302}]}, {"text": "Errors in named-entity linking (NEL), on the other hand, are often caused by superficial modeling of entity context.", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9357021450996399}, {"text": "named-entity linking (NEL)", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8625979363918305}]}, {"text": "This paper demonstrates that these two tasks are complementary.", "labels": [], "entities": []}, {"text": "We introduce NECO, anew model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each.", "labels": [], "entities": [{"text": "named entity linking", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.652744323015213}, {"text": "coreference resolution", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.9665933847427368}]}, {"text": "NECO extends the Stanford determinis-tic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves.", "labels": [], "entities": [{"text": "NECO", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9416387677192688}]}, {"text": "Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters.", "labels": [], "entities": []}, {"text": "Experiments show consistent improvements across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data.", "labels": [], "entities": [{"text": "MUC coreference error", "start_pos": 130, "end_pos": 151, "type": "TASK", "confidence": 0.6906799475351969}, {"text": "F1 NEL error", "start_pos": 180, "end_pos": 192, "type": "METRIC", "confidence": 0.9514642357826233}, {"text": "ACE 2004 newswire data", "start_pos": 196, "end_pos": 218, "type": "DATASET", "confidence": 0.9549756944179535}]}], "introductionContent": [{"text": "Coreference resolution and named-entity linking are closely related problems, but have been largely studied in isolation.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9360456466674805}, {"text": "named-entity linking", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.7064747959375381}]}, {"text": "This paper demonstrates that they are complementary by introducing a simple joint model that improves performance on both tasks.", "labels": [], "entities": []}, {"text": "Coreference resolution is the task of determining when two textual mentions name the same individ-  ual.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9130193293094635}]}, {"text": "The biggest challenge in coreference resolution -accounting for 42% of errors in the stateof-the-art Stanford system -is the inability to reason effectively about background semantic knowledge (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.9706988632678986}]}, {"text": "For example, consider the sentence in.", "labels": [], "entities": []}, {"text": "\"President\" refers to \"Donald Tsang\" and \"the park\" refers to \"Hong Kong Disneyland,\" but automated algorithms typically lack the background knowledge to draw such inferences.", "labels": [], "entities": []}, {"text": "Incorporating knowledge is challenging, and many efforts to do so have actually hurt performance, e.g. ().", "labels": [], "entities": []}, {"text": "Named-entity linking (NEL) is the task of matching textual mentions to corresponding entities in a knowledge base, such as Wikipedia or Freebase.", "labels": [], "entities": [{"text": "Named-entity linking (NEL)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8492958307266235}]}, {"text": "Such links provide rich sources of semantic knowledge about entity attributes -Freebase includes president as Tsang's title and Disneyland as having the attribute park.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.9642056822776794}, {"text": "president", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.9089983105659485}]}, {"text": "But NEL is itself a challenging problem, and finding the correct link requires disambiguating based on the mention string and often non-local contextual features.", "labels": [], "entities": []}, {"text": "For example, \"Michael Eisner\" is relatively unambiguous but the isolated mention \"Eisner\" is more challenging.", "labels": [], "entities": []}, {"text": "However, these mentions could be clustered with a coreference model, allowing for improved NEL through link propagation from the easier mentions.", "labels": [], "entities": [{"text": "NEL through link propagation", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.8688538670539856}]}, {"text": "We present NECO, anew algorithm for jointly solving named entity linking and coreference resolution.", "labels": [], "entities": [{"text": "NECO", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.7632331252098083}, {"text": "solving named entity linking", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.5900224074721336}, {"text": "coreference resolution", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.9379000067710876}]}, {"text": "Our work is related to that of, which also uses knowledge derived from an NEL system to improve coreference.", "labels": [], "entities": []}, {"text": "However, NECO is the first joint model we know of, is purely deterministic with no learning phase, does automatic mention detection, and improves performance on both tasks.", "labels": [], "entities": [{"text": "NECO", "start_pos": 9, "end_pos": 13, "type": "TASK", "confidence": 0.6927921175956726}, {"text": "mention detection", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.648807018995285}]}, {"text": "NECO extends the Stanford's sieve-based model, in which a high recall mention detection phase is followed by a sequence of cluster merging operations ordered by decreasing precision.", "labels": [], "entities": [{"text": "NECO", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8941593766212463}, {"text": "recall mention detection", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.8198049863179525}, {"text": "precision", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.991524338722229}]}, {"text": "At each step, it merges two clusters only if all available information about their respective entities is consistent.", "labels": [], "entities": []}, {"text": "We use NEL to increase recall during the mention detection phase and introduce two new cluster-merging sieves, which compare the Freebase attributes of entities.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9982415437698364}, {"text": "mention detection phase", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.7956627209981283}]}, {"text": "NECO also improves NEL by initially favoring high precision linking results and then propagating links and attributes as clusters are formed.", "labels": [], "entities": [{"text": "NECO", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9105858206748962}, {"text": "NEL", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9056714773178101}]}, {"text": "In summary we make the following contributions: \u2022 We introduce NECO, a novel, joint approach to solving coreference and NEL, demonstrating that these tasks are complementary by achieving joint error reduction.", "labels": [], "entities": [{"text": "NEL", "start_pos": 120, "end_pos": 123, "type": "TASK", "confidence": 0.9081113934516907}]}, {"text": "\u2022 We present experiments showing improved performance at coreference resolution, given both gold and automatic mention detection: e.g., 6.2 point improvement in MUC recall on ACE 2004 newswire text and 3.1 point improvement in MUC precision the CoNLL 2011 test set.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.9453049004077911}, {"text": "automatic mention detection", "start_pos": 101, "end_pos": 128, "type": "METRIC", "confidence": 0.8314246932665507}, {"text": "recall", "start_pos": 165, "end_pos": 171, "type": "METRIC", "confidence": 0.8982577323913574}, {"text": "ACE 2004 newswire text", "start_pos": 175, "end_pos": 197, "type": "DATASET", "confidence": 0.9477255791425705}, {"text": "precision", "start_pos": 231, "end_pos": 240, "type": "METRIC", "confidence": 0.8195828199386597}, {"text": "CoNLL 2011 test set", "start_pos": 245, "end_pos": 264, "type": "DATASET", "confidence": 0.9757472723722458}]}, {"text": "\u2022 NECO also leads to better performance at named-entity linking, given both gold and automatic linking, improving F1 from 61.7% to 69.2% on a newly labeled test set.", "labels": [], "entities": [{"text": "NECO", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.6554554104804993}, {"text": "named-entity linking", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.6608349978923798}, {"text": "F1", "start_pos": 114, "end_pos": 116, "type": "METRIC", "confidence": 0.999578058719635}]}], "datasetContent": [{"text": "Core Components and Baselines The Stanford sieve-based coreference system (, the GLOW NEL system), and WikipediaMiner (Milne and Witten, 2008) provide core functionality for our joint model, and are also the state-of-the-art baselines against which we measure performance.", "labels": [], "entities": [{"text": "WikipediaMiner", "start_pos": 103, "end_pos": 117, "type": "DATASET", "confidence": 0.9397258758544922}]}, {"text": "Parameter Settings Based on performance on the development set, we set the GLOW's confidence parameter to 1.0 and WikipediaMiner's to 0.4 to assure high-precision NEL.", "labels": [], "entities": [{"text": "GLOW's confidence parameter", "start_pos": 75, "end_pos": 102, "type": "METRIC", "confidence": 0.7143924832344055}, {"text": "NEL", "start_pos": 163, "end_pos": 166, "type": "TASK", "confidence": 0.9686384797096252}]}, {"text": "We also optimized for the set of fine-grained attributes to import from Wikipedia and Freebase, and the best way to incorporate the NEL constraints into the sieve architecture.", "labels": [], "entities": []}, {"text": "Datasets We report results on the following three datasets: ACE\uf732\uf730\uf730\uf734-NWIRE, CONLL\uf732\uf730\uf731\uf731, and ACE\uf732\uf730\uf730\uf734-NWIRE-NEL.", "labels": [], "entities": [{"text": "ACE\uf732\uf730\uf730\uf734-NWIRE", "start_pos": 60, "end_pos": 73, "type": "DATASET", "confidence": 0.7682665387789408}, {"text": "CONLL", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.6006035208702087}]}, {"text": "ACE\uf732\uf730\uf730\uf734-NWIRE, the newswire subset of the ACE 2004 corpus), includes 128 documents.", "labels": [], "entities": [{"text": "ACE\uf732\uf730\uf730\uf734-NWIRE", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9093193610509237}, {"text": "ACE 2004 corpus", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.8997800946235657}]}, {"text": "The CONLL\uf732\uf730\uf731\uf731 coreference dataset includes text from five different domains: broadcast conversation (BC), broadcast news (BN), magazine (MZ), newswire (NW), and web data (WB)).", "labels": [], "entities": [{"text": "CONLL\uf732\uf730\uf731\uf731 coreference dataset", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.8422245234251022}]}, {"text": "The broadcast conversation and broadcast news domains consist of transcripts, whereas magazine and newswire contain more standard written text.", "labels": [], "entities": []}, {"text": "The development data includes 303 documents and the test data includes 322 documents.", "labels": [], "entities": []}, {"text": "We created ACE\uf732\uf730\uf730\uf734-NWIRE-NEL by taking a subset of ACE\uf732\uf730\uf730\uf734-NWIRE and annotating with gold-standard entity links.", "labels": [], "entities": [{"text": "ACE\uf732\uf730\uf730\uf734-NWIRE", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.794871985912323}]}, {"text": "We segment and link all the expressions in text that refer to Wikipedia pages, allowing for nested linking.", "labels": [], "entities": []}, {"text": "For instance, both the phrase \"Hong Kong Disneyland,\" and the sub-phrase \"Hong Kong\" are linked.", "labels": [], "entities": [{"text": "Hong Kong Disneyland", "start_pos": 31, "end_pos": 51, "type": "DATASET", "confidence": 0.8495713075002035}]}, {"text": "This dataset includes 12 documents and 350 linked entities.", "labels": [], "entities": []}, {"text": "Metrics We evaluate our system using MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), and pairwise scores.", "labels": [], "entities": [{"text": "MUC", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.574907124042511}, {"text": "B 3", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9711054265499115}]}, {"text": "MUC is a link-based metric which measures how many clusters need to be merged to cover the gold clusters and favors larger clusters; B 3 computes the proportion of intersection between predicted and gold clusters for every mention and favors singletons coreference software for ACE2004 and using the CoNLL scorer for the CoNLL 2011 dataset.", "labels": [], "entities": [{"text": "MUC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6661021709442139}, {"text": "ACE2004", "start_pos": 278, "end_pos": 285, "type": "DATASET", "confidence": 0.9351446032524109}, {"text": "CoNLL 2011 dataset", "start_pos": 321, "end_pos": 339, "type": "DATASET", "confidence": 0.9436869223912557}]}, {"text": "We first look at NECO's performance at coreference resolution and then evaluate its ability at NEL.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9488950073719025}, {"text": "NEL", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.7946950793266296}]}], "tableCaptions": [{"text": " Table 1: Coreference results on ACE\uf732\uf730\uf730\uf734-NWIRE with predicted mentions and automatic linking.", "labels": [], "entities": [{"text": "ACE\uf732\uf730\uf730\uf734-NWIRE", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.5458004474639893}]}, {"text": " Table 3: Coreference results on the individual categories of CoNLL 2011 development data. (BC=broadcast conver- sation, BN=broadcast news, MZ=magazine, NW=newswire)", "labels": [], "entities": [{"text": "CoNLL 2011 development data", "start_pos": 62, "end_pos": 89, "type": "DATASET", "confidence": 0.9486353993415833}, {"text": "BN", "start_pos": 121, "end_pos": 123, "type": "METRIC", "confidence": 0.9418185353279114}]}, {"text": " Table 2: Coreference results on CoNLL 2011 develop- ment and test data, using predicted mentions. Rows de- noted with * indicate runs using the fully automated Stan- ford CoreNLP pipeline rather than the predicted annota- tions provided with the CoNLL data. Given the relatively  close results, we ran the Mann-Whitney U test for this  table; values with the + superscript are significant with  p < 0.05.", "labels": [], "entities": [{"text": "CoNLL 2011 develop- ment and test data", "start_pos": 33, "end_pos": 71, "type": "DATASET", "confidence": 0.8726241067051888}, {"text": "CoNLL data", "start_pos": 247, "end_pos": 257, "type": "DATASET", "confidence": 0.9655022323131561}]}, {"text": " Table 4: Coreference results on ACE\uf732\uf730\uf730\uf734-NWIRE-NEL with gold and predicted mentions and gold or automatic linking.", "labels": [], "entities": [{"text": "ACE\uf732\uf730\uf730\uf734-NWIRE-NEL", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.5312866866588593}]}, {"text": " Table 5: Coreference results on ACE\uf732\uf730\uf730\uf734-NWIRE with gold mentions and automatic linking.", "labels": [], "entities": [{"text": "ACE\uf732\uf730\uf730\uf734-NWIRE", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.5955792665481567}]}, {"text": " Table 6: NEL performance of our system and the ensem- ble baseline linker on ACE\uf732\uf730\uf730\uf734-NWIRE-NEL.", "labels": [], "entities": [{"text": "NEL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9761431217193604}, {"text": "ACE\uf732\uf730\uf730\uf734-NWIRE-NEL", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.7371633251508077}]}]}