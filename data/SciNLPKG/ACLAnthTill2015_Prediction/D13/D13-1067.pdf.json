{"title": [{"text": "Collective Personal Profile Summarization with Social Networks", "labels": [], "entities": [{"text": "Summarization", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8255033493041992}]}], "abstractContent": [{"text": "Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising.", "labels": [], "entities": [{"text": "talent recommendation", "start_pos": 137, "end_pos": 158, "type": "TASK", "confidence": 0.7237121760845184}]}, {"text": "However, personal profiles usually lack organization confronted with the large amount of available information.", "labels": [], "entities": []}, {"text": "Therefore, it is always a challenge for people to find desired information from them.", "labels": [], "entities": []}, {"text": "In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks.", "labels": [], "entities": [{"text": "personal profile summarization", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6633890469868978}]}, {"text": "Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and co-corporation) tend to have similar experience and summaries.", "labels": [], "entities": []}, {"text": "To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors.", "labels": [], "entities": []}, {"text": "Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Web 2.0 has empowered people to actively interact with each other, forming social networks around mutually interesting information and publishing a large amount of useful user-generated content (UGC) online.", "labels": [], "entities": []}, {"text": "One popular and important type of UGC is the personal profile, where people post detailed * Corresponding author information on online portals about their education, experiences and other personal information.", "labels": [], "entities": []}, {"text": "Social websites like Facebook.com and LinkedIn.com have created a viable business as profile portals, with the popularity and success partially attributed to their comprehensive personal profiles.", "labels": [], "entities": []}, {"text": "Generally, online personal profiles provide valuable resources for businesses, especially for human resource managers to find talents, and help people connect with others of similar backgrounds (.", "labels": [], "entities": []}, {"text": "However, as there is always large-scale information of experience and education fields, it is hardly for us to find useful information from the profile.", "labels": [], "entities": []}, {"text": "Therefore, it is always a challenge for people to find desired information from them.", "labels": [], "entities": []}, {"text": "For this regard, it is highly desirable to develop reliable methods to generate a summary of a person through his profile automatically.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first research that explores automatic summarization of personal profiles in social media.", "labels": [], "entities": [{"text": "summarization of personal profiles in social media", "start_pos": 81, "end_pos": 131, "type": "TASK", "confidence": 0.8307948112487793}]}, {"text": "A straightforward approach is to consider personal profile summarization as a traditional document summarization problem, which treating each personal profile independently and generate a summary for each personal profile individually.", "labels": [], "entities": [{"text": "personal profile summarization", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6808388531208038}, {"text": "document summarization", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.7176116108894348}]}, {"text": "For example, the well-known extraction and ranking approaches (e.g. PageRank, HITS) extract a certain amount of important sentences from a document according to some ranking measurements to form a summary ().", "labels": [], "entities": [{"text": "PageRank", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.9357199668884277}]}, {"text": "However, such straightforward approaches are not sufficient to benefit from the carrier of personal profiles.", "labels": [], "entities": []}, {"text": "As the centroid of social networking, people are usually connected to others with similar background in social media.", "labels": [], "entities": []}, {"text": "Therefore, it is reasonable to leverage social connection to improve the performance of profile summarizing.", "labels": [], "entities": []}, {"text": "For example if there are co-major, co-university, co-corporation or other academic and business relationships between two persons, we consider them sharing similar experience and having similar summaries.", "labels": [], "entities": []}, {"text": "The remaining challenge is how to incorporate both the profile textual information and the connection knowledge in the social networks.", "labels": [], "entities": []}, {"text": "In this study, we propose a collective factor graph model (CoFG) to summarize the text of personal profile in social networks with local textual information and social connection information.", "labels": [], "entities": []}, {"text": "The CoFG framework utilizes both the local textual attribute functions of an individual person and the social connection factor between different persons to collectively summarize personal profile on one person.", "labels": [], "entities": []}, {"text": "In this study, we treat the profile summarization as a supervised learning task.", "labels": [], "entities": []}, {"text": "Specifically, we model each sentence of the profile as a vector.", "labels": [], "entities": []}, {"text": "In the training phase, we use the vectors with the social connection between each person to build the CoFG model; while in the testing phase, we perform collective inference for the importance of each sentence and select a subset of sentences as the summary according to the trained model.", "labels": [], "entities": []}, {"text": "Evaluation on a large-scale data from LinkedIn.com indicates that our proposed joint model and social connection information improve the performance of profile summarization.", "labels": [], "entities": []}, {"text": "The remainder of our paper is structured as follows.", "labels": [], "entities": []}, {"text": "We go over the related work in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce the data we collected from LinkedIn.com and the annotated corpus we constructed.", "labels": [], "entities": []}, {"text": "In Section 4, we present some motivational analysis.", "labels": [], "entities": []}, {"text": "In Section 5, we explain our proposed model and describe algorithms for parameter estimation and prediction.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.6613932847976685}]}, {"text": "In Section 6, we present our experimental results.", "labels": [], "entities": []}, {"text": "We sum up our work and discuss future directions in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the settings of our experiment and present the experimental results of our proposed CoFG model.", "labels": [], "entities": []}, {"text": "In the experiment, we use the corpus collected from LinkedIn.com that contains 497 profiles (see more details in Section 3).", "labels": [], "entities": []}, {"text": "The existing summaries in these profiles are served as the reference summary (the standard answers).", "labels": [], "entities": []}, {"text": "As discussed in subsection 3.3, the average length of summary is about 40 words.", "labels": [], "entities": [{"text": "length", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.8177450895309448}]}, {"text": "Thus, we extract 40 words to construct the summary for each profile.", "labels": [], "entities": []}, {"text": "We use 200 personal profiles as the testing data, and the remaining ones as the training data.", "labels": [], "entities": []}, {"text": "We use the ROUGE-1.5.5 (Lin and Hovy, 2004) toolkit for evaluation, a popular tool that has been widely adopted by several evaluations such as DUC and TAC (.", "labels": [], "entities": [{"text": "ROUGE-1.5.5", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.8511034846305847}, {"text": "DUC", "start_pos": 143, "end_pos": 146, "type": "DATASET", "confidence": 0.9065393209457397}, {"text": "TAC", "start_pos": 151, "end_pos": 154, "type": "DATASET", "confidence": 0.6644434332847595}]}, {"text": "We provide four of the ROUGE F-measure scores in the experimental results: ROUGE-2 (bigrambased), ROUGE-L (based on longest common subsequences), ROUGE-W (based on weighted longest common subsequence, weight=1.2), and ROUGE-SU4 (based on skip bigram with a maximum skip distance of 4).", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.8850420117378235}, {"text": "ROUGE-L", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.8841248750686646}, {"text": "ROUGE-W", "start_pos": 146, "end_pos": 153, "type": "METRIC", "confidence": 0.8625666499137878}, {"text": "ROUGE-SU4", "start_pos": 218, "end_pos": 227, "type": "METRIC", "confidence": 0.7378018498420715}]}, {"text": "We compare the proposed CoFG approach with three baselines illustrated as follows: \uf0d8 Random: we randomly select sentences of each profile to generate the summary for the profile.", "labels": [], "entities": []}, {"text": "\uf0d8 HITS: we employ the HITS algorithm to perform profile summarization (.", "labels": [], "entities": [{"text": "\uf0d8", "start_pos": 0, "end_pos": 1, "type": "DATASET", "confidence": 0.8683092594146729}, {"text": "HITS", "start_pos": 2, "end_pos": 6, "type": "DATASET", "confidence": 0.6496091485023499}, {"text": "profile summarization", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.5964223146438599}]}, {"text": "In detail, we first consider the words as hubs the sentences as authorities; Then, we rank the sentences with the authorities' scores for each profile individually; Finally, the highest ranked sentences are chosen to constitute the summary.", "labels": [], "entities": []}, {"text": "\uf0d8 PageRank: we employ the PageRank algorithm to perform profile summarization (.", "labels": [], "entities": [{"text": "\uf0d8 PageRank", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.6600305736064911}, {"text": "profile summarization", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.5659283697605133}]}, {"text": "In detail, we first connect the sentences of the profile with cosine textbased similar measure to construct a graph; Then, we apply PageRank algorithm to rank the sentence through the graph for each profile individually; Finally, the highest ranked sentences are chosen to constitute the summary.", "labels": [], "entities": []}, {"text": "\uf0d8 MaxEnt: as a supervised learning approach, maximum entropy uses textual attribute as features to train a classification model.", "labels": [], "entities": []}, {"text": "Then, the classification model is employed to predict which sentences can be selected to generate the summary.", "labels": [], "entities": []}, {"text": "For the implementation of MaxEnt, we employ the tool of mallent toolkits 4 . shows the comparison results of our approach (CoFG) and the baseline approaches.", "labels": [], "entities": []}, {"text": "From, we can see that 1) either HITS or PageRank outperforms the approach of random selection; 2) The supervised approach i.e. MaxEnt, outperforms both the HITS algorithm and the PageRank approach; 3) CoFG model performs best and it greatly outperforms both the unsupervised and supervised learning baseline approaches in terms of the ROUGE-2 F-measure score.", "labels": [], "entities": [{"text": "ROUGE-2 F-measure score", "start_pos": 335, "end_pos": 358, "type": "METRIC", "confidence": 0.8010683655738831}]}, {"text": "This result verifies the effectiveness of considering the social connection between the sentences in different profiles, shows the performance of our proposed CoFG model with different sizes of training data.", "labels": [], "entities": []}, {"text": "From, we can see that CoFG model with social connection always performs better than MaxEnt, and the performance of our approach descends slowly when the training dataset becomes small.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.8577172160148621}]}, {"text": "Specifically, the performance of CoFG using only 10% training data achieves better performance than MaxEnt using 100% training data.", "labels": [], "entities": []}, {"text": "shows the contribution of the social edges with CoFG.", "labels": [], "entities": [{"text": "CoFG", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.640964925289154}]}, {"text": "Specifically, CoFG is our proposed approach with both education and experience information, CoFG-edu means that the CoFG model considers the social edges of education field (co_major, co_univ) only, and CoFG-exp means that the CoFG model considers the social edges of work experience field (co_title, co_corp) only.", "labels": [], "entities": []}, {"text": "MaxEnt can be considered as using textual information only.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.901366114616394}]}], "tableCaptions": [{"text": " Table 1: Statistics of major fields in our data set, i.e. the  number of non-empty fields and the average length for  each field", "labels": [], "entities": []}, {"text": " Table 4: Performances of different approaches to profile summarization in terms of different measurements", "labels": [], "entities": [{"text": "profile summarization", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.6535668969154358}]}]}