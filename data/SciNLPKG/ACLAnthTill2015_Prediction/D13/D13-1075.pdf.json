{"title": [{"text": "With blinkers on: robust prediction of eye movements across readers", "labels": [], "entities": []}], "abstractContent": [{"text": "Nilsson and Nivre (2009) introduced a tree-based model of persons' eye movements in reading.", "labels": [], "entities": []}, {"text": "The individual variation between readers reportedly made application across readers impossible.", "labels": [], "entities": [{"text": "application", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.9783706665039062}]}, {"text": "While a tree-based model seems plausible for eye movements, we show that competitive results can be obtained with a linear CRF model.", "labels": [], "entities": []}, {"text": "Increasing the inductive bias also makes learning across readers possible.", "labels": [], "entities": []}, {"text": "In fact we observe next-to-no performance drop when evaluating models trained on gaze records of multiple readers on new readers.", "labels": [], "entities": []}], "introductionContent": [{"text": "When we read a text, our gaze does not move smoothly and continuously along its lines.", "labels": [], "entities": []}, {"text": "Rather, our eyes fixate at a word, then skip a few words, to jump to anew fixation point.", "labels": [], "entities": []}, {"text": "Such rapid eye movements are called saccades.", "labels": [], "entities": []}, {"text": "Sometimes we even jump backwards.", "labels": [], "entities": []}, {"text": "Backward saccades are called regressions.", "labels": [], "entities": []}, {"text": "Gaze can be recorded using eye tracking devices).", "labels": [], "entities": []}, {"text": "Since eye movements in reading give us important information about what readers find complicated in a text, and what readers find completely predictable, predicting eye movements on new texts has many practical applications in text-to-text generation and human computer interaction, for example.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 227, "end_pos": 250, "type": "TASK", "confidence": 0.729655310511589}]}, {"text": "The problem of predicting eye movements in reading is, fora reader r i and a given sequence of word tokens w 1 . .", "labels": [], "entities": []}, {"text": "w n , to predict a set of fixation points F \u2286 {w 1 , . .", "labels": [], "entities": []}, {"text": ", w n }, i.e., the fixation points of r i 's gaze.", "labels": [], "entities": []}, {"text": "For each token w j , the reader r i may skip w j or fixate at w j . Models are evaluated on recordings of human reading obtained using eye tracking devices.", "labels": [], "entities": []}, {"text": "The supervised prediction problem that we consider in this paper, also uses eye tracking data for learning models of eye movement.", "labels": [], "entities": [{"text": "supervised prediction", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7356626987457275}]}, {"text": "Nilsson and Nivre (2009) first introduced this supervised learning task and used the Dundee corpus to train and evaluate a tree-based model, essentially treating the problem of predicting eye movements in reading as transition-based dependency parsing.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.990657776594162}, {"text": "transition-based dependency parsing", "start_pos": 216, "end_pos": 251, "type": "TASK", "confidence": 0.6503420472145081}]}, {"text": "We follow in modeling only forward saccades and not regressions and refixations.", "labels": [], "entities": []}, {"text": "While try to model a subset of regressions and refixations, they do not evaluate this part of their model focusing only on fixation accuracy and distribution accuracy, i.e., they evaluate how well they predict a set of fixation points rather than a sequence of points in order.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.7959128022193909}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.6229159235954285}]}, {"text": "This enables us to model eye movements in reading as a sequential problem of determining the length of forward saccades, increasing the inductive bias of our learning algorithm in a motivated way.", "labels": [], "entities": []}, {"text": "Note that because we work with visual input, we do not tokenize our input in our experiments, i.e., punctuation does not count as input tokens.", "labels": [], "entities": []}, {"text": "Example presents an example sentence and gaze records from the Dundee corpus.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.9928522706031799}]}, {"text": "The Dundee corpus contains gaze records of 10 readers in total.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9942637383937836}]}, {"text": "Note that there is little consensus on what words are skipped.", "labels": [], "entities": []}, {"text": "5/10 readers skip the first word.", "labels": [], "entities": []}, {"text": "Generally, closed class items (prepositions, copulae, quantifiers) seem to be skipped more open, but we do see a lot of individual variation.", "labels": [], "entities": []}, {"text": "While others for this reason have refrained from evaluation across readers we show that our model predicts gaze better across readers than a previously proposed model) does training and evaluating on the same readers.", "labels": [], "entities": []}, {"text": "A final observation is that fixations are very frequent at the word level -in fact, even skilled readers make 94 fixations per 100 words) -which motivates using F 1 -score of skips as metric.", "labels": [], "entities": [{"text": "F 1 -score of skips", "start_pos": 161, "end_pos": 180, "type": "METRIC", "confidence": 0.9504099686940511}]}, {"text": "We follow in reporting word-level accuracy, but find it particularly interesting that the simple model proposed here outperforms previous models by a large margin in F 1 -score over skips.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9491543173789978}, {"text": "F 1 -score", "start_pos": 166, "end_pos": 176, "type": "METRIC", "confidence": 0.9719061255455017}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Comparison between NN09 and our model.", "labels": [], "entities": [{"text": "NN09", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.9476624131202698}]}, {"text": " Table 3: Results learning across readers. Bold-faced numbers better than when training on same reader", "labels": [], "entities": []}]}