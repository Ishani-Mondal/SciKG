{"title": [{"text": "Orthonormal Explicit Topic Analysis for Cross-lingual Document Matching", "labels": [], "entities": [{"text": "Orthonormal Explicit Topic Analysis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5902085900306702}, {"text": "Cross-lingual Document Matching", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.8713009556134542}]}], "abstractContent": [{"text": "Cross-lingual topic modelling has applications in machine translation, word sense disam-biguation and terminology alignment.", "labels": [], "entities": [{"text": "Cross-lingual topic modelling", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6964404582977295}, {"text": "machine translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.82957923412323}, {"text": "word sense disam-biguation", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.7024558981259664}, {"text": "terminology alignment", "start_pos": 102, "end_pos": 123, "type": "TASK", "confidence": 0.9146374464035034}]}, {"text": "Multilingual extensions of approaches based on latent (LSI), generative (LDA, PLSI) as well as explicit (ESA) topic modelling can induce an interlingual topic space allowing documents in different languages to be mapped into the same space and thus to be compared across languages.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel approach that combines latent and explicit topic modelling approaches in the sense that it builds on a set of explicitly defined topics , but then computes latent relations between these.", "labels": [], "entities": []}, {"text": "Thus, the method combines the benefits of both explicit and latent topic modelling approaches.", "labels": [], "entities": []}, {"text": "We show that on a cross-lingual mate retrieval task, our model significantly outperforms LDA, LSI, and ESA, as well as a baseline that translates every word in a document into the target language.", "labels": [], "entities": [{"text": "cross-lingual mate retrieval task", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.677891306579113}]}], "introductionContent": [{"text": "Cross-lingual document matching is the task of, given a query document in some source language, estimating the similarity to a document in some target language.", "labels": [], "entities": [{"text": "Cross-lingual document matching", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6686559816201528}]}, {"text": "This task has important applications in machine translation (, word sense disambiguation ( and ontology alignment ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8561619818210602}, {"text": "word sense disambiguation", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.7040590643882751}, {"text": "ontology alignment", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.8000922799110413}]}, {"text": "An approach that has become quite popular in recent years for cross-lingual document matching is Explicit Semantics Analysis (ESA,) and its cross-lingual extension CL-ESA ().", "labels": [], "entities": [{"text": "cross-lingual document matching", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6270550489425659}, {"text": "Explicit Semantics Analysis (ESA", "start_pos": 97, "end_pos": 129, "type": "TASK", "confidence": 0.6882853031158447}]}, {"text": "ESA indexes documents by mapping them into a topic space defined by their similarity to predefined explicit topics -generally articles from an encyclopaedia -in such away that there is a one-to-one correspondence between topics and encyclopedic entries.", "labels": [], "entities": [{"text": "ESA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8972558379173279}]}, {"text": "CL-ESA extends this to the multilingual case by exploiting a background document collection that is aligned across languages, such as Wikipedia.", "labels": [], "entities": []}, {"text": "A feature of ESA and its extension CL-ESA is that, in contrast to latent (e.g. LSI,) or generative topic models (such as LDA,), it requires no training and, nevertheless, has been demonstrated to outperform LSI and LDA on crosslingual retrieval tasks (.", "labels": [], "entities": []}, {"text": "A key choice in Explicit Semantic Analysis is the document space that will act as the topic space.", "labels": [], "entities": [{"text": "Explicit Semantic Analysis", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.7704663674036661}]}, {"text": "The standard choice is to regard all articles from a background document collection -Wikipedia articles area typical choice -as the topic space.", "labels": [], "entities": []}, {"text": "However, it is crucial to ensure that these topics cover the semantic space evenly and completely.", "labels": [], "entities": []}, {"text": "In this paper, we present an alternative approach where we remap the semantic space defined by the topics in such a manner that it is orthonormal.", "labels": [], "entities": []}, {"text": "In this way, each document is mapped to a topic that is distinct from all other topics.", "labels": [], "entities": []}, {"text": "Such a mapping can be considered as equivalent to a variant of Latent Semantic Indexing (LSI) with the main difference that our model exploits the matrix that maps topic vectors back into document space, which is normally discarded in LSI-based approaches.", "labels": [], "entities": [{"text": "Latent Semantic Indexing (LSI)", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.6648314992586771}]}, {"text": "We dub our model ONETA (OrthoNormal Explicit Topic Analysis) and empirically show that on a cross-lingual retrieval task it outperforms ESA, LSI, and Latent Dirichlet Allocation (LDA) as well as a baseline consisting of translating each word into the target language, thus reducing the task to a standard monolingual matching task.", "labels": [], "entities": [{"text": "ONETA", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.7196016907691956}]}, {"text": "In particular, we quantify the effect of different approximation techniques for computing the orthonormal basis and investigate the effect of various methods for the normalization of frequency vectors.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows: we situate our work in the general context of related work on topic models for cross-lingual document matching in Section 2.", "labels": [], "entities": [{"text": "cross-lingual document matching", "start_pos": 121, "end_pos": 152, "type": "TASK", "confidence": 0.6272931496302286}]}, {"text": "We present our model in Section 3 and present our experimental results and discuss these results in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, we consider a cross-lingual mate retrieval task from English/Spanish on the basis of Wikipedia as aligned corpus.", "labels": [], "entities": [{"text": "cross-lingual mate retrieval task", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.6978173777461052}]}, {"text": "The goal is to, for each document of a test set, retrieve the aligned document or mate.", "labels": [], "entities": []}, {"text": "For each test document, on the basis of 958 n/a n/a: Result on large-scale mate-finding studies for English to Spanish matching the similarity of the query document to all indexed documents, we compute the value rank i indicating at which position the mate of the i th document occurs.", "labels": [], "entities": []}, {"text": "We use two metrics: Top-k Precision, defined as the percentage of documents for which the mate is retrieved among the first k elements, and Minimum Reciprocal Rank, defined as For our experiments, we first extracted a subset of documents (every 20th) from Wikipedia, filtering this set down to only those that have aligned pages in both English and Spanish with a minimum length of 100 words.", "labels": [], "entities": [{"text": "Precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.8261716365814209}, {"text": "Minimum Reciprocal Rank", "start_pos": 140, "end_pos": 163, "type": "METRIC", "confidence": 0.8941725492477417}]}, {"text": "This gives us 10,369 aligned documents in total, which form the background document collection B.", "labels": [], "entities": []}, {"text": "We split this data into a training and test set of 9,332 and 1,037 documents, respectively.", "labels": [], "entities": []}, {"text": "We then removed all words whose total frequencies were below 50.", "labels": [], "entities": []}, {"text": "This resulted in corpus of 6.7 millions words in English and 4.2 million words in Spanish.", "labels": [], "entities": []}, {"text": "Normalization Methods: In order to investigate the impact of different normalization methods, we ran small-scale experiments using the first 500 documents from our dataset to train ONETA and then evaluate the resulting models on the mate-finding task on 100 unseen documents.", "labels": [], "entities": [{"text": "ONETA", "start_pos": 181, "end_pos": 186, "type": "DATASET", "confidence": 0.7526946663856506}]}, {"text": "The results are presented in, which shows the Top-1 Precision for the different normalization methods.", "labels": [], "entities": [{"text": "Precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.8721383810043335}]}, {"text": "We see that the effect of applying document normalization in all cases improves the quality of the overall result.", "labels": [], "entities": [{"text": "document normalization", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.6812193095684052}]}, {"text": "Surprisingly, we do not seethe same result for frequency normalization yielding the best result for the case where we do no normalization at all 5 . In the remaining experiments we thus employ document normalization and no term frequency normalization.", "labels": [], "entities": []}, {"text": "Approximation Methods: In order to evaluate the different approximation methods, we experimentally compare 4 different approximation methods: standard LSI, ON-Eigen (Equation 1), Explicit LSI (Equation 2), L-Solve (Equation 3) on the same small-scale corpus.", "labels": [], "entities": [{"text": "Approximation", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9573794007301331}]}, {"text": "For convenience we plot an approximation rate which is either K or N 1 depending on method; at K = 500 and N 1 = 500, these approximations become exact.", "labels": [], "entities": []}, {"text": "We also observe the effects of approximation and see that the performance increases steadily as we increase the computational factor.", "labels": [], "entities": []}, {"text": "We see that the orthonormal eigenvector (Equation 1) method and the L-solve (Equation 3) method are clearly similar in approximation quality.", "labels": [], "entities": []}, {"text": "We see that the explicit LSI method (Equation 2) and the LSI method both perform significantly worse for most of the approxi-mation amounts.", "labels": [], "entities": []}, {"text": "Explicit LSI is worse than the other approximations as it first maps the test documents into a K-dimensional LSI topic space, before mapping back into the N -dimensional explicit space.", "labels": [], "entities": []}, {"text": "As expected this performs worse than standard LSI for all but high values of K as there is significant error in both mappings.", "labels": [], "entities": []}, {"text": "We also see that the (CL-)ESA baseline, which is very low due to the small number of documents, is improved upon by even the least approximation of orthonormalization.", "labels": [], "entities": []}, {"text": "In the remaining of this section, we report results using the LSolve method as it has a very good performance and is computationally less expensive than ON-Eigen.", "labels": [], "entities": []}, {"text": "Evaluation and Comparison: We compare ONETA using the L-Solve method with N 1 values from 1000 to 9000 topics with (CL-)ESA (using SQRT normalization), LDA (using 1000 topics) and LSI (using 4000 topics).", "labels": [], "entities": [{"text": "ONETA", "start_pos": 38, "end_pos": 43, "type": "TASK", "confidence": 0.6262966990470886}]}, {"text": "We choose the largest topic count for LSI and LDA we could to provide the best possible comparison.", "labels": [], "entities": []}, {"text": "For LSI, the choice of K was determined on the basis of operating system memory limits, while for LDA we experimented with higher values for K without any performance improvement, likely due to overfitting.", "labels": [], "entities": []}, {"text": "We also stress that for L-Solve ONETA, N 1 is not the topic count but an approximation rate of the mapping.", "labels": [], "entities": [{"text": "L-Solve ONETA", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.30683861672878265}]}, {"text": "In all settings we use N topics as with standard ESA, and so should not be considered directly comparable to the K values of these methods.", "labels": [], "entities": []}, {"text": "We also compare to a baseline system that relies on word-by-word translation, where we use the most likely single translation of a word as given by a phrase table generated by the Moses system () on the EuroParl corpus (.", "labels": [], "entities": [{"text": "word-by-word translation", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7715954780578613}, {"text": "EuroParl corpus", "start_pos": 203, "end_pos": 218, "type": "DATASET", "confidence": 0.9952485263347626}]}, {"text": "Top 1, Top 5 and Top 10 Precision as well as Mean Reciprocal Rank are reported in.", "labels": [], "entities": [{"text": "Precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9841130375862122}, {"text": "Mean Reciprocal Rank", "start_pos": 45, "end_pos": 65, "type": "METRIC", "confidence": 0.9240214824676514}]}, {"text": "Interestingly, even fora small number of documents (e.g., N 1 = 6000) our results improve both the word-translation baseline as well as all other topic models, ESA, LDA and LSI in particular.", "labels": [], "entities": []}, {"text": "We note that at this level the method is still efficiently computable and calculating the inverse in practice takes less time than training the Moses system.", "labels": [], "entities": []}, {"text": "The significance for results (N 1 \u2265 7000) have been tested by means of a bootstrap resampling significance test, finding out that our results significantly improve on the translation baseline at a 99% level.", "labels": [], "entities": [{"text": "significance", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9642958045005798}]}, {"text": "Further, we consider a straightforward combination of our method with the translation system consisting of appending the topic vectors and the translation frequency vectors, weighted by the relative average norms of the vectors.", "labels": [], "entities": []}, {"text": "We see that in this case the translations continue to improve the performance of the system (albeit not significantly), suggesting a clear potential for this system to help in improving machine translation results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7943903803825378}]}, {"text": "While we have presented results for English and Spanish here, similar results were obtained for the German and French case but are not presented here due to space limitations.", "labels": [], "entities": []}, {"text": "In we also include the user time and peak resident memory of each of these processes, measured on an 8 Core Intel Xeon 2.50 GHz server.", "labels": [], "entities": []}, {"text": "We do not include the results for Word Translation as many hours were spent learning a phrase table, which includes translations for many phrases not in the test set.", "labels": [], "entities": [{"text": "Word Translation", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7778643071651459}]}, {"text": "We see that the ONETA method significantly outperforms LSI and LDA in terms of speed and memory consumption.", "labels": [], "entities": [{"text": "ONETA", "start_pos": 16, "end_pos": 21, "type": "TASK", "confidence": 0.6965541839599609}]}, {"text": "This is inline with the theoretical calculations presented earlier where we argued that inverting the N \u00d7 N dense matrix X TX when W N is computationally lighter than finding an eigendecomposition of the W \u00d7 W sparse matrix XX T . In addition, as we do not multiply (X T X) \u22121 and X T , we do not need to allocate a large W \u00d7 K matrix in memory as with LSI and LDA.", "labels": [], "entities": []}, {"text": "The implementations of ESA, ONETA, LSI and LDA used as well as the data for the experiments are available at http://github.com/jmccrae/oneta.", "labels": [], "entities": [{"text": "ESA", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.8958629369735718}, {"text": "ONETA", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.5816591382026672}]}], "tableCaptions": [{"text": " Table 1: Effect of Term Frequency and Document Nor- malization on Top-1 Precision", "labels": [], "entities": [{"text": "Nor- malization", "start_pos": 48, "end_pos": 63, "type": "METRIC", "confidence": 0.7769376039505005}]}, {"text": " Table 2: Result on large-scale mate-finding studies for English to Spanish matching", "labels": [], "entities": []}]}