{"title": [{"text": "Event-based Time Label Propagation for Automatic Dating of News Articles", "labels": [], "entities": [{"text": "Automatic Dating of News Articles", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.8453888654708862}]}], "abstractContent": [{"text": "Since many applications such as timeline summaries and temporal IR involving temporal analysis rely on document timestamps, the task of automatic dating of documents has been increasingly important.", "labels": [], "entities": [{"text": "timeline summaries", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7052365243434906}, {"text": "temporal IR", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.5981002599000931}, {"text": "automatic dating of documents", "start_pos": 136, "end_pos": 165, "type": "TASK", "confidence": 0.6906483471393585}]}, {"text": "Instead of using feature-based methods as conventional models , our method attempts to date documents in a year level by exploiting relative temporal relations between documents and events, which are very effective for dating documents.", "labels": [], "entities": []}, {"text": "Based on this intuition, we proposed an event-based time label propagation model called confidence boosting in which time label information can be propagated between documents and events on a bipartite graph.", "labels": [], "entities": [{"text": "event-based time label propagation", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.617918349802494}]}, {"text": "The experiments show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-of-the-art method for this task especially when the size of the training set is small.", "labels": [], "entities": [{"text": "event-based propagation", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.6709857881069183}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9794697761535645}]}], "introductionContent": [{"text": "Time is an important dimension of any information space and can be useful in information retrieval, question-answering systems and timeline summaries.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.7676056027412415}, {"text": "timeline summaries", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.6423522680997849}]}, {"text": "In the applications involving temporal analysis, document timestamps are very useful.", "labels": [], "entities": [{"text": "temporal analysis", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7227311134338379}]}, {"text": "For instance, temporal information retrieval models take into consideration the document's creation time for document retrieval and ranking) for better dealing with time-sensitive queries; some infor- * Corresponding author mation retrieval applications such as Google Scholar can list articles published during the time a user specifies for better satisfying users' needs.", "labels": [], "entities": [{"text": "temporal information retrieval", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.6678446332613627}, {"text": "document retrieval", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.6998414993286133}, {"text": "Corresponding author mation retrieval", "start_pos": 203, "end_pos": 240, "type": "TASK", "confidence": 0.6058782041072845}]}, {"text": "In addition, timeline summarization techniques () and some event-event ordering models) also rely on the timestamps.", "labels": [], "entities": [{"text": "timeline summarization", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7736348807811737}]}, {"text": "Unfortunately, many documents on the web do not have a credible timestamp, as Chambers (2012) reported.", "labels": [], "entities": []}, {"text": "Therefore, it is significant to date documents, that is to predict document creation time.", "labels": [], "entities": []}, {"text": "One typical method for dating document is based on temporal language models, which were first used for dating by.", "labels": [], "entities": []}, {"text": "They learned language models (unigram) for specific time periods and scored articles with normalized log-likelihood ratio scores.", "labels": [], "entities": []}, {"text": "The other typical approach for the task was proposed by Nathanael Chambers.", "labels": [], "entities": []}, {"text": "In Chambers's work, discriminative classifiers -maximum entropy (MaxEnt) classifiers were used by incorporating linguistic features and temporal constraints for training, which outperforms the previous temporal language models on a subset of Gigaword Corpus (.", "labels": [], "entities": [{"text": "Gigaword Corpus", "start_pos": 242, "end_pos": 257, "type": "DATASET", "confidence": 0.935169905424118}]}, {"text": "However, the conventional methods have some limitations because they predict creation time of documents mainly based on feature-based models without understanding content of documents, which may lead to wrong predictions in some cases.", "labels": [], "entities": []}, {"text": "For instance, assume that D1 and D2 are documents whose content is given as follows: (D1) Sudan last year accused Eritrea of backing an offensive by rebels in the eastern border region.", "labels": [], "entities": []}, {"text": "(D2) Two years ago, Sudan accused Eritrea of backing an offensive by rebels in the eastern border region.", "labels": [], "entities": []}, {"text": "Since D1 and D2 share many important features, the previous dating methods are very likely to predict the same timestamp for the two documents.", "labels": [], "entities": []}, {"text": "However, it will be easy to infer that the creation time of D1 should be one year earlier than that of D2 if we analyze the content of the two documents.", "labels": [], "entities": []}, {"text": "Unlike the previous methods, this paper exploits relative temporal relations between events and documents for dating documents on the basis of an understanding of document content.", "labels": [], "entities": []}, {"text": "It is known that each event in a news article has a relative temporal relation with the document.", "labels": [], "entities": []}, {"text": "By analyzing the relative temporal relation, time of the event can be known if we know the document timestamp; on the other hand, if the time of an event is known, it can also be used to predict the creation time of documents mentioning the event, which can be best demonstrated with the above-mentioned example of D1 and D2.", "labels": [], "entities": []}, {"text": "In the example, \"last year\" is an important cue to infer that the event mentioned by the documents occurred in 2002 if we know the timestamp of D1 is 2003.", "labels": [], "entities": []}, {"text": "With the information that the event occurred in 2002, it can also be inferred from the temporal expression \"Two years ago\" that D2 was written in 2004.", "labels": [], "entities": []}, {"text": "In this way, the timestamp of the labeled document (D1) is propagated to the unlabeled document (D2) through the event both of them mention, which is the main intuition of this paper.", "labels": [], "entities": []}, {"text": "In fact, this intuition seems practical to date documents on the web because web data is very redundant.", "labels": [], "entities": []}, {"text": "Many documents on the web can be connected via events because an event is usually mentioned by different documents.", "labels": [], "entities": []}, {"text": "According to our analysis of a collection of news articles spanning 5 years, it is found that an event is mentioned by 3.44 news articles on average; on the other hand, a document usually refers to multiple events.", "labels": [], "entities": []}, {"text": "Therefore, if one knows a document timestamp, time of events the document mentions can be obtained by analyzing the relative temporal relations between the document and the events.", "labels": [], "entities": []}, {"text": "Likewise, if the time of an event is known, then it can be used to predict creation time of the documents which mention it.", "labels": [], "entities": []}, {"text": "Based on the intuition, we proposed an eventbased time label propagation model called confidence boosting in which timestamps are propagated according to relative temporal relations between documents and events.", "labels": [], "entities": [{"text": "eventbased time label propagation", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.6020796969532967}]}, {"text": "In this way, documents can be dated with an understanding of content so that this model can date document more credibly.", "labels": [], "entities": []}, {"text": "To our knowledge, it is the first time that the relative temporal relations between documents and events are exploited for dating documents, which is proved to be effective by the experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the performance of our time label propagation models and different automatic document dating models on the Gigaword dataset.", "labels": [], "entities": [{"text": "time label propagation", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.5855128864447275}, {"text": "Gigaword dataset", "start_pos": 136, "end_pos": 152, "type": "DATASET", "confidence": 0.9821919798851013}]}, {"text": "We first present the experimental setting.", "labels": [], "entities": []}, {"text": "Then we show experimental results and perform an analysis.", "labels": [], "entities": []}, {"text": "Dataset To simulate the environment of the web where data is very redundant, we use all documents written in April, June, July and September of of Gigaword Corpus as dataset instead of sampling a subset of documents from each period.", "labels": [], "entities": [{"text": "Gigaword Corpus", "start_pos": 147, "end_pos": 162, "type": "DATASET", "confidence": 0.9448152780532837}]}, {"text": "The dataset contains 900,199 news articles.", "labels": [], "entities": []}, {"text": "Pre-processing Many extractions extracted by ReVerb are short and uninformative and do not carry any valuable information for propagating temporal information.", "labels": [], "entities": []}, {"text": "Also, some extractions do not refer to events which already happened.", "labels": [], "entities": []}, {"text": "These extractions may affect the performance of event coreference resolution and the rule-based method proposed in Section 3.1.1 for mining relative temporal relations.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.814085066318512}]}, {"text": "Therefore, we filter out these undesirable extractions in advance with a rule-based method.", "labels": [], "entities": []}, {"text": "The rules are shown in table 3.", "labels": [], "entities": []}, {"text": "This preprocessing removes large numbers of \"bad\" extractions which are undesirable for our task.", "labels": [], "entities": []}, {"text": "As a result, not only computation efficiency but also precision of event coreference resolution will be improved.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9996895790100098}, {"text": "event coreference resolution", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.822401205698649}]}, {"text": "Prop Ratio = #ReachedDocN odes #LabeledDocN odes Prop Accuracy = #CorrectDocN odes \u2212 #LabeledDocN odes #ReachedDocN odes \u2212 #LabeledDocN odes where #LabeledDocN odes is the number of initially labeled document nodes which are documents in the training set and #ReachedDocN odes is the number of document nodes labeled when the propagation process ends.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9787341356277466}]}, {"text": "Note that prop ratio and accuracy in table 5 are the mean of the prop ratio and accuracy of the five groups of experiments.", "labels": [], "entities": [{"text": "prop ratio", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8837678134441376}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9988641738891602}, {"text": "prop ratio", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9467969238758087}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9988150596618652}]}, {"text": "It is clear that confidence boosting model improves the prop accuracy over BFS-based model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9008734822273254}]}, {"text": "When only 1,000 documents are initially labeled with timestamps, the confidence boosting model can propagate their timestamps to more than 400,000 documents with an accuracy of 0.494, approximately 12.8% relative improvement over the BFS counterpart, which proves effectiveness of the confidence boosting model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9989325404167175}]}, {"text": "However, as shown in table 5, hardly can the propagation process propagate timestamps to all documents.", "labels": [], "entities": []}, {"text": "One reason is that the number of document nodes on the bipartite graph is only 550,124, approximately 61.1% of all documents.", "labels": [], "entities": []}, {"text": "The other documents may not mention events which are also mentioned by other documents, which means they are isolate and thus are excluded from the bipartite graph.", "labels": [], "entities": []}, {"text": "Also, the event coreference resolution phase does not guarantee finding all coreferential extractions; in other words, recall of event coreference resolution is not 100%.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.6868432561556498}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9985981583595276}, {"text": "event coreference resolution", "start_pos": 129, "end_pos": 157, "type": "TASK", "confidence": 0.55307603875796}]}, {"text": "The other reason is that some documents are unreachable from the initially labeled nodes even if they are in the bipartite graph.", "labels": [], "entities": []}, {"text": "The overall accuracy of different dating models is shown in table 6.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995786547660828}]}, {"text": "As with table 5, overall accuracy in table 6 is the average performance of models in the five groups of experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995458722114563}]}, {"text": "As reported by Nathanael Chambers (2012), the discriminative classifier performs much better than the temporal language models on the Gigaword dataset.", "labels": [], "entities": [{"text": "Gigaword dataset", "start_pos": 134, "end_pos": 150, "type": "DATASET", "confidence": 0.9766398966312408}]}, {"text": "In the case of 500,000 training examples, the Maxent classifier using unigram features outperforms the temporal language models by 40.5% relative accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9952300786972046}]}, {"text": "If the size of the training set is large enough, named entities and linguistic features as well as temporal constraints will improve the overall accuracy significantly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9987371563911438}]}, {"text": "However, if the size of the training set is small, these features will not result in much improvement.", "labels": [], "entities": []}, {"text": "Compared with the previous models, the propagation models predict the document timestamps much more accurately especially in the case where the size of the training set is small.", "labels": [], "entities": []}, {"text": "When the size of the training set is 1,000, our BFS-based model and confidence boosting model combined with the MaxEnt classifier outperform Chambers's joint model which is considered the state-of-the-art model for the task of automatic dating of documents by 38.7% and 46.8% relative accuracy respectively.", "labels": [], "entities": [{"text": "BFS-based", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.8365347385406494}, {"text": "automatic dating of documents", "start_pos": 227, "end_pos": 256, "type": "TASK", "confidence": 0.7804174721240997}, {"text": "accuracy", "start_pos": 285, "end_pos": 293, "type": "METRIC", "confidence": 0.9963698387145996}]}, {"text": "This is because the feature-based methods are not very reliable especially when the size of the training set is small.", "labels": [], "entities": []}, {"text": "In contrast, our propagation models can predict timestamps of documents with an understanding of document content, which allows our method to date documents more credibly than the baseline methods.", "labels": [], "entities": []}, {"text": "Also, by comparing, it can be found that prop accuracy is almost always higher than overall accuracy, which also verifies that the propagation models are more credible for dating document than the feature-based models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9598707556724548}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9976462721824646}]}, {"text": "Moreover, data is so redundant that a great number of documents can be connected with events they share.", "labels": [], "entities": []}, {"text": "Therefore, even if a small number of documents are labeled, the labeled information can be propagated to large numbers of articles through the connections between documents and events according to relative time relations.", "labels": [], "entities": []}, {"text": "Even if the size of the training set is large, e.g. 500,000, our propagation models still outperform the state-of-the-art dating method.", "labels": [], "entities": []}, {"text": "Additionally, some event nodes on the bipartite graph maybe labeled with a timestamp during the process of propagation as a byproduct.", "labels": [], "entities": []}, {"text": "The temporal information of the events would be useful for other temporal analysis tasks.", "labels": [], "entities": [{"text": "temporal analysis", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.6904551535844803}]}], "tableCaptions": [{"text": " Table 2: Accuracy of the four cases", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987772107124329}]}, {"text": " Table 6: Overall accuracy of dating models", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9992207288742065}]}]}