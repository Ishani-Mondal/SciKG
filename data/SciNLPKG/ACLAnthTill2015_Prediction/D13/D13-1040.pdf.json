{"title": [{"text": "Unsupervised Relation Extraction with General Domain Knowledge", "labels": [], "entities": [{"text": "Unsupervised Relation Extraction", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.694260855515798}]}], "abstractContent": [{"text": "In this paper we present an unsupervised approach to relational information extraction.", "labels": [], "entities": [{"text": "relational information extraction", "start_pos": 53, "end_pos": 86, "type": "TASK", "confidence": 0.8324886163075765}]}, {"text": "Our model partitions tuples representing an observed syntactic relationship between two named entities (e.g., \"X was born in Y\" and \"X is from Y\") into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located).", "labels": [], "entities": []}, {"text": "Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 170, "end_pos": 194, "type": "TASK", "confidence": 0.8948647379875183}]}, {"text": "Evaluation results on the ACE 2007 English Relation Detection and Categoriza-tion (RDC) task show that our model outper-forms competitive unsupervised approaches by a wide margin and is able to produce clusters shaped by both the data and the rules.", "labels": [], "entities": [{"text": "ACE 2007 English Relation Detection and Categoriza-tion (RDC) task", "start_pos": 26, "end_pos": 92, "type": "TASK", "confidence": 0.8360626697540283}]}], "introductionContent": [{"text": "Information extraction (IE) is becoming increasingly useful as a form of shallow semantic analysis.", "labels": [], "entities": [{"text": "Information extraction (IE)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8771248459815979}, {"text": "shallow semantic analysis", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.6842236618200938}]}, {"text": "Learning relational facts from text is one of the core tasks of IE and has applications in a variety of fields including summarization, question answering, and information retrieval.", "labels": [], "entities": [{"text": "IE", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9862485527992249}, {"text": "summarization", "start_pos": 121, "end_pos": 134, "type": "TASK", "confidence": 0.9922109842300415}, {"text": "question answering", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.8672937154769897}, {"text": "information retrieval", "start_pos": 160, "end_pos": 181, "type": "TASK", "confidence": 0.8139962553977966}]}, {"text": "Previous work) has traditionally relied on extensive human involvement (e.g., hand-annotated training instances, manual pattern extraction rules, hand-picked seeds).", "labels": [], "entities": [{"text": "pattern extraction rules", "start_pos": 120, "end_pos": 144, "type": "TASK", "confidence": 0.7698448002338409}]}, {"text": "Standard supervised techniques can yield high performance when large amounts of hand-labeled data are available fora fixed inventory of relation types (e.g., Employment, Located), however, extraction systems do not easily generalize beyond their training domains and often must be re-engineered for each application.", "labels": [], "entities": []}, {"text": "Unsupervised approaches offer a promising alternative which could lead to significant resource savings and more portable extraction systems.", "labels": [], "entities": []}, {"text": "It therefore comes as no surprise that latent topic analysis methods have been used fora variety of IE tasks., for example, propose a series of topic models which perform relation discovery by clustering tuples representing an observed syntactic relationship between two named entities (e.g., \"X was born in Y\" and \"X is from Y\").", "labels": [], "entities": [{"text": "topic analysis", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7375343143939972}, {"text": "IE tasks.", "start_pos": 100, "end_pos": 109, "type": "TASK", "confidence": 0.9167307913303375}, {"text": "relation discovery", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.8452644646167755}]}, {"text": "The clusters correspond to semantic relations whose number or type is not known in advance.", "labels": [], "entities": []}, {"text": "Their models depart from standard Latent Dirichlet Allocation () in that a document consists of relation tuples rather than individual words; moreover, tuples have features each of which is generated independently from a hidden relation (e.g., the words corresponding to the first and second entities, the type and order of the named entities).", "labels": [], "entities": []}, {"text": "Since these features are local, they cannot capture more global constraints pertaining to the relation extraction task.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 94, "end_pos": 118, "type": "TASK", "confidence": 0.8477939565976461}]}, {"text": "Such constraints may take the form of restrictions on which tuples should be clustered together or not.", "labels": [], "entities": []}, {"text": "For instance, different types of named entities maybe indicative of different relations (ORG-LOC entities often express a Location relation whereas PER-PER entities express Business or Family relations) and thus tuples bearing these entities should not be grouped together.", "labels": [], "entities": [{"text": "ORG-LOC", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.9431019425392151}]}, {"text": "Another example are tuples with identical or similar features which intuitively should be clustered together.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised approach to relation extraction which does not re-quire any relation-specific training data and allows to incorporate global constraints general expressing domain knowledge.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.9101534783840179}]}, {"text": "We encode domain knowledge as First Order Logic (FOL) rules and automatically integrate them with a topic model to produce clusters shaped by the data and the constraints at hand.", "labels": [], "entities": []}, {"text": "Specifically, we extend the Fold-all (FirstOrder Logic latent Dirichlet Allocation) framework) to the relation extraction task, explain how to incorporate meaningful constraints, and develop a scalable inference technique.", "labels": [], "entities": [{"text": "Fold-all", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.8849695920944214}, {"text": "relation extraction task", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.8857950965563456}]}, {"text": "In the presence of multiple candidate relation decompositions fora given corpus, domain knowledge can steer the model towards relations which are best aligned with user and task modeling goals.", "labels": [], "entities": []}, {"text": "We also argue that a general mechanism for encoding additional modeling assumptions and side information can lessen the need for \"custom\" relation extraction model variants.", "labels": [], "entities": [{"text": "relation extraction model", "start_pos": 138, "end_pos": 163, "type": "TASK", "confidence": 0.7878125111262003}]}, {"text": "Experimental results on the dataset show that our model outperforms competitive unsupervised approaches by a wide margin and is able to uncover meaningful relations with only two general rule types.", "labels": [], "entities": []}, {"text": "Our contributions in this work are three-fold: anew model that modifies the Fold-all framework and extends it to the relation extraction task; anew formalization of the logic rules applicable to topic models defined over a rich set of features; and a proposal for mining the logic rules automatically from a corpus contrary to who employ manually crafted seeds.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 117, "end_pos": 141, "type": "TASK", "confidence": 0.8072507580121359}]}], "datasetContent": [{"text": "Data We trained our model on the New York Times (years Cannot-link Tuple named entities were automatically recognized and labeled with PER, ORG, LOC, and MISC ().", "labels": [], "entities": [{"text": "New York Times", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.802534818649292}, {"text": "PER", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.9980948567390442}, {"text": "ORG", "start_pos": 140, "end_pos": 143, "type": "METRIC", "confidence": 0.9804787039756775}, {"text": "LOC", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.9332048296928406}, {"text": "MISC", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9801795482635498}]}, {"text": "Dependency paths for each pair of named entity mentions were extracted from the output of the MaltParser ().", "labels": [], "entities": []}, {"text": "In our experiments, we discarded tuples with paths longer than 10 edges ().", "labels": [], "entities": []}, {"text": "We evaluated our model on the test partition of the ACE 2007 (English) RDC dataset which is labeled with gold standard entity mentions and their relations.", "labels": [], "entities": [{"text": "ACE 2007 (English) RDC dataset", "start_pos": 52, "end_pos": 82, "type": "DATASET", "confidence": 0.9602451920509338}]}, {"text": "There are six general relation types and 18 subtypes.", "labels": [], "entities": []}, {"text": "We used 25% of the ACE training partition as a development set for parameter tuning.", "labels": [], "entities": [{"text": "ACE training partition", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.9165494640668234}, {"text": "parameter tuning", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.6914754956960678}]}, {"text": "Logic Rule Extraction We automatically extracted logic rules from the New York Times (NYT) corpus as follows.", "labels": [], "entities": [{"text": "Logic Rule Extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6429173250993093}, {"text": "New York Times (NYT) corpus", "start_pos": 70, "end_pos": 97, "type": "DATASET", "confidence": 0.7324113845825195}]}, {"text": "The intuition behind Must-link rules is that tuples with common features should cluster together.", "labels": [], "entities": []}, {"text": "Although we do not know which features would yield the best rules, we naively assume that good features are frequently co-occurring features.", "labels": [], "entities": []}, {"text": "Using the log-likelihood ratio, we first discarded low confidence feature co-occurrences (p < 0.05).", "labels": [], "entities": []}, {"text": "Two features co-occur if they are both found within the same sentence.", "labels": [], "entities": []}, {"text": "We then sorted the remaining co-occurrences by their frequency and retained the N -best ones.", "labels": [], "entities": []}, {"text": "We only considered unigram and bigram features since higher-order ones tend to be sparse.", "labels": [], "entities": []}, {"text": "An example of a bigram feature would be (PATH:\u2190nsubj\u2190grow\u2192prep\u2192in\u2192pobj\u2192, DEST:Chicago).", "labels": [], "entities": []}, {"text": "The main intuition behind Cannot-link rules is that tuples without any common features should not cluster together.", "labels": [], "entities": []}, {"text": "So, if two features never co-occur, they probably express different relations.", "labels": [], "entities": []}, {"text": "For every unigram and bigram feature in the respective N -best list, we find the features it does not co-occur within the NYT corpus.", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 122, "end_pos": 132, "type": "DATASET", "confidence": 0.9684724509716034}]}, {"text": "For example, NEPAIR:PER-LOC does not co-occur with DEST:Yankees and the bigram DEST:United Nations, NEPAIR:PER-ORG does not co-occur with SOURCE:Mr. Bush, NEPAIR:PER-LOC.", "labels": [], "entities": [{"text": "DEST:Yankees and the bigram DEST:United Nations", "start_pos": 51, "end_pos": 98, "type": "TASK", "confidence": 0.5910204410552978}]}, {"text": "Cannotlink rules are then based on such non-co-occurring feature pairs.", "labels": [], "entities": []}, {"text": "We optimized N empirically on the development set.", "labels": [], "entities": []}, {"text": "We experimented with values ranging from 20 to 500.", "labels": [], "entities": []}, {"text": "We obtained 20 Must-link rules for coarsegrained relations and 400 rules for their subtypes.", "labels": [], "entities": []}, {"text": "We extracted 1,814 Cannot-link rules for general relations (N = 50) and 34,522 rules for subtypes (N = 400).", "labels": [], "entities": []}, {"text": "The number of features involved in the Must-link rules was 25 for coarse-grained relations and 422 for fine-grained relations.", "labels": [], "entities": []}, {"text": "For Cannot-link rules, 62 features were involved in coarse-grained relations and 422 in fine-grained relations.", "labels": [], "entities": []}, {"text": "Examples of the rules we extracted are shown in.", "labels": [], "entities": []}, {"text": "The first rule in the upper half of the table states that tuples must cluster together if their source and target entities are PER and contain the trigger word wife in their dependency path.", "labels": [], "entities": [{"text": "PER", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9313375949859619}]}, {"text": "The second rule is similar, the source entity here is PER, the target LOC and the trigger word is die.", "labels": [], "entities": [{"text": "PER", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9830175638198853}, {"text": "LOC", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.889796793460846}]}, {"text": "According to the third rule, tuples featuring the path PATH:\u2190nsubj\u2190die\u2192prep\u2192in\u2192pobj\u2192 should be in the same cluster.", "labels": [], "entities": []}, {"text": "The fourth rule forces tuples whose source entity is Kobe and target entity is Lakers to cluster together.", "labels": [], "entities": [{"text": "Kobe", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.8708744049072266}]}, {"text": "The second half of the table illustrates Cannot-link tuple rules.", "labels": [], "entities": []}, {"text": "The first rule prevents tuples with ORG-LOC entities to cluster to-gether with PER-PER tuples.", "labels": [], "entities": []}, {"text": "The second rule states that we cannot link LOC-LOC tuples with those whose trigger word is president, and soon.", "labels": [], "entities": []}, {"text": "Parameter Tuning Our framework has several parameters that must be adjusted for an optimal clustering solution.", "labels": [], "entities": []}, {"text": "These include the hyperparameters \u03b1 and \u03b2 as well as the number of clusters.", "labels": [], "entities": []}, {"text": "In addition, we have to assign a weight to each FOL rule grounding.", "labels": [], "entities": [{"text": "FOL rule grounding", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.6328848004341125}]}, {"text": "An exhaustive search on the hyperparameters and rule weights is not possible.", "labels": [], "entities": []}, {"text": "We therefore followed a step-wise approximation procedure.", "labels": [], "entities": []}, {"text": "First, we find the best \u03b1 and \u03b2 values, whilst varying the number of clusters.", "labels": [], "entities": []}, {"text": "Once we have the best hyperparameters for each clustering, we set the weights for the FOL rules.", "labels": [], "entities": [{"text": "FOL", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.8591906428337097}]}, {"text": "We varied the number of relations from 5 to 50.", "labels": [], "entities": []}, {"text": "These values were optimized separately for coarse-and fine-grained relations.", "labels": [], "entities": []}, {"text": "shows the optimal number of clusters for different model variants and relation types.", "labels": [], "entities": []}, {"text": "The FOL weights can also make a difference in the final output; the bigger the weight the more times the rule will be sampled in the Mirror Descent algorithm.", "labels": [], "entities": [{"text": "FOL", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9869847893714905}, {"text": "Mirror Descent", "start_pos": 133, "end_pos": 147, "type": "TASK", "confidence": 0.7222227454185486}]}, {"text": "We experimented with two weighting schemes: (a) we gave a weight of 1 or 0.5 to each rule grounding and (b) we scaled the weights so as to make their contribution comparable to relational LDA.", "labels": [], "entities": [{"text": "relational LDA", "start_pos": 177, "end_pos": 191, "type": "TASK", "confidence": 0.6057136952877045}]}, {"text": "We obtained best results on the development set with the former scheme.", "labels": [], "entities": []}, {"text": "Baselines We compared our FOL relational LDA model against standard LDA ( and relational LDA without the FOL component.", "labels": [], "entities": []}, {"text": "In the case of standard LDA, we estimated topics (relations) over words, and used the context of the entity mentions pairs as a bag of words feature to select the most likely cluster attest time.", "labels": [], "entities": []}, {"text": "Parameters for LDA and relational LDA were optimized following the same parameter tuning procedure described above.", "labels": [], "entities": []}, {"text": "We also compared our model against the unsupervised method introduced in.", "labels": [], "entities": []}, {"text": "Their key idea is to cluster pairs of co-occurring named entities according to the similarity of their surrounding contexts.", "labels": [], "entities": []}, {"text": "Following their approach, we measured context similarity using the vector space model and the cosine metric and grouped NE pairs into clusters using a complete linkage hierarchical clustering algorithm.", "labels": [], "entities": []}, {"text": "We adopted the same parameter values as detailed in their paper (e.g., cosine similarity threshold, length of context vectors).", "labels": [], "entities": [{"text": "cosine similarity threshold", "start_pos": 71, "end_pos": 98, "type": "METRIC", "confidence": 0.7936193346977234}]}, {"text": "At test time, instances were assigned to the relation cluster most similar to them (according to the cosine measure).", "labels": [], "entities": []}, {"text": "Evaluation We evaluated the clusters obtained by our model and the comparison systems using the Fscore measure introduced in the; it is the harmonic mean of precision and recall defined as the number of correct members of a cluster divided by the number of items in the cluster and the number of items in the gold-standard class, respectively.", "labels": [], "entities": [{"text": "Fscore measure", "start_pos": 96, "end_pos": 110, "type": "METRIC", "confidence": 0.9665412306785583}, {"text": "precision", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9885608553886414}, {"text": "recall", "start_pos": 171, "end_pos": 177, "type": "METRIC", "confidence": 0.9986714124679565}]}], "tableCaptions": []}