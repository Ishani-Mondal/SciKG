{"title": [{"text": "A Constrained Latent Variable Model for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.969863086938858}]}], "abstractContent": [{"text": "Coreference resolution is a well known clustering task in Natural Language Processing.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9135579168796539}]}, {"text": "In this paper, we describe the Latent Left Linking model (L 3 M), a novel, principled, and linguistically motivated latent structured prediction approach to coreference resolution.", "labels": [], "entities": [{"text": "Latent Left Linking", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.5754052897294363}, {"text": "coreference resolution", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.9611338973045349}]}, {"text": "We show that L 3 M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning.", "labels": [], "entities": []}, {"text": "Experiments on ACE and Ontonotes data show that L 3 M and its constrained version , CL 3 M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.", "labels": [], "entities": [{"text": "ACE", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.9266400337219238}, {"text": "Ontonotes data", "start_pos": 23, "end_pos": 37, "type": "DATASET", "confidence": 0.8789774477481842}]}], "introductionContent": [{"text": "Coreference resolution is a challenging task, that involves identification and clustering of noun phrases mentions that refer to the same real-world entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9315253496170044}, {"text": "identification and clustering of noun phrases mentions", "start_pos": 60, "end_pos": 114, "type": "TASK", "confidence": 0.7698815294674465}]}, {"text": "Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.9682276844978333}]}, {"text": "Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment.", "labels": [], "entities": []}, {"text": "The most popular of these frameworks is the pairwise mention model (, which learns a compatibility score of mention-pairs and uses these pairwise scores to obtain a global clustering.", "labels": [], "entities": []}, {"text": "Recently, efforts have been made) to consider models that capture higher order interactions, in particular, between mentions and previously identified entities (that is, between mentions and clusters).", "labels": [], "entities": []}, {"text": "While such models are potentially more expressive, they are largely based on heuristics to achieve computational tractability.", "labels": [], "entities": []}, {"text": "This paper focuses on a novel and principled machine learning framework that pushes the state-ofthe-art while operating at a mention-pair granularity.", "labels": [], "entities": []}, {"text": "We present two models -the Latent Left-Linking Model (L 3 M), and aversion of that is augmented with domain knowledge-based constraints, the Constrained Latent Left-Linking Model (CL 3 M).", "labels": [], "entities": []}, {"text": "L 3 M admits efficient inference, linking each mention to a previously occurring mention to its left, much like the existing best-left-link inference models (.", "labels": [], "entities": []}, {"text": "However, unlike previous best-link techniques, learning in our case is performed jointly with decoding -we present a novel latent structural SVM approach, optimized using a fast stochastic gradient-based technique.", "labels": [], "entities": []}, {"text": "Furthermore, we present a probabilistic generalization of L 3 M that is more expressive in that it is capable of considering mention-entity interactions using scores at the mention-pair granularity.", "labels": [], "entities": []}, {"text": "We augment this model with a temperature-like parameter () to provide additional flexibility.", "labels": [], "entities": []}, {"text": "CL 3 M augments L 3 M with knowledge-based constraints following.", "labels": [], "entities": []}, {"text": "This capability is very desirable as shown by the success of the rule-based deterministic approach of in the CoNLL shared task 2011).", "labels": [], "entities": [{"text": "CoNLL shared task 2011", "start_pos": 109, "end_pos": 131, "type": "DATASET", "confidence": 0.831431120634079}]}, {"text": "In L 3 M, domain-specific constraints are incorporated into learning and inference in a straightforward way.", "labels": [], "entities": []}, {"text": "CL 3 M scores a mention's contribution to its cluster by combining the corresponding score of the underlying L 3 M model with that from a set of constraints.", "labels": [], "entities": []}, {"text": "Most importantly, in our experiments on benchmark coreference datasets, we show that CL 3 M, with just five constraints, compares favorably with other, more complicated, state-of-the-art algorithms on a variety of evaluation metrics.", "labels": [], "entities": []}, {"text": "Overall, the main contribution of this paper is a principled machine learning model operating at mention-pair granularity, using easy to implement constraint-augmented inference and learning, that yields competitive results on coreference resolution on Ontonotes-5.0 (Pradhan et al., 2012) and ACE 2004).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 227, "end_pos": 249, "type": "TASK", "confidence": 0.9012081921100616}, {"text": "Ontonotes-5.0", "start_pos": 253, "end_pos": 266, "type": "DATASET", "confidence": 0.8811026215553284}, {"text": "ACE 2004", "start_pos": 294, "end_pos": 302, "type": "DATASET", "confidence": 0.9617596566677094}]}], "datasetContent": [{"text": "In this section, we present our experiments on the two commonly used benchmarks for coreference -Ontonotes-5.0 (Pradhan et al., 2012) and ACE 2004.", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 138, "end_pos": 146, "type": "DATASET", "confidence": 0.9370032846927643}]}, {"text": "exhibits our bottom line results: CL 3 M achieves the best result reported on Ontonotes-5.0 development set and essentially ties with) on the test set.", "labels": [], "entities": [{"text": "Ontonotes-5.0 development set", "start_pos": 78, "end_pos": 107, "type": "DATASET", "confidence": 0.9548864364624023}]}, {"text": "As shown in, CL 3 M is also the best algorithm on ACE and when evaluated on the gold mentions of Ontonotes.", "labels": [], "entities": [{"text": "ACE", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.8634717464447021}, {"text": "Ontonotes", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.9543054103851318}]}, {"text": "We show that CL 3 M performs particularly well on clusters containing named entity mentions, which are more important for many information extraction applications.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.7959630489349365}]}, {"text": "In the rest of this section, after describing our experimental setting, we provide careful analysis of our algorithms and compare them to competitive coreference approaches in the literature.", "labels": [], "entities": []}, {"text": "Classifier details: For each of the pairwise approaches, we assume the pairwise score is given by w\u00b7\u03c6(\u00b7, \u00b7)+t where \u03c6 are the features, w is the weight vector learned by the approach, and t is a threshold which we set to 0 during learning (as in Eq.), but use a tuned value (tuned on a development set) during testing.", "labels": [], "entities": []}, {"text": "For learning with L 3 M, we do stochastic gradient descent with 5 passes over the data.", "labels": [], "entities": []}, {"text": "Empirically, we observe that this is enough to generate a stable model.", "labels": [], "entities": []}, {"text": "For PL 3 M, we tune the value of \u03b3 using the development set picking the best \u03b3 from {0.0, 0.2, . .", "labels": [], "entities": []}, {"text": "Recall that when \u03b3 = 0, PL 3 M is the same as L 3 M.", "labels": [], "entities": []}, {"text": "We refer to L 3 M and PL 3 M with incorporating constraints during inference as CL 3 M and CPL 3 M (Sec. 3.4), respectively.", "labels": [], "entities": []}, {"text": "Metrics: We compare the systems using three popular metrics for coreference -MUC (, BCUB (, and Entity-based CEAF (CEAF e ) (.", "labels": [], "entities": [{"text": "BCUB", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.7141305804252625}]}, {"text": "Following, the CoNLL shared tasks (, we use the average F1 scores of these three metrics as the main metric of comparison.", "labels": [], "entities": [{"text": "CoNLL shared tasks", "start_pos": 15, "end_pos": 33, "type": "DATASET", "confidence": 0.7578564484914144}, {"text": "F1", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9980925917625427}]}, {"text": "Features: We build our system on the publicly available Illinois-Coref system 1 primarily because it contains a rich set of features presented in and (the latter adds features for pronominal anaphora resolution).", "labels": [], "entities": [{"text": "Illinois-Coref system 1", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.9676651557286581}, {"text": "pronominal anaphora resolution", "start_pos": 180, "end_pos": 210, "type": "TASK", "confidence": 0.6753629247347513}]}, {"text": "We also compare with the Best-Left-Link approach described by.", "labels": [], "entities": []}, {"text": "Constraints: We consider the following constraints in CL 3 M and CPL 3 M.", "labels": [], "entities": []}, {"text": "\u2022 SameSpan: two mentions must be linked to each other if they share the same surface text span and the number of words in the text span is larger than a threshold (set as 5 in our implementation).", "labels": [], "entities": []}, {"text": "\u2022 SameDetNom: two mentions must be linked to each other if both mentions start with a determiner and the wordnet-based similarity score between the mention head words is above a threshold (set to 0.8).", "labels": [], "entities": []}, {"text": "\u2022 SameProperName: two mentions must be linked if they are both proper names and the similarity score measured by a named entitybased similarity metric, Illinois NESim 2 , are higher than a threshold (set to 0.8).", "labels": [], "entities": [{"text": "Illinois NESim 2", "start_pos": 152, "end_pos": 168, "type": "DATASET", "confidence": 0.8807177344957987}]}, {"text": "For a person entity we add additional rules to extract the first name, last name and professional title as properties.", "labels": [], "entities": []}, {"text": "\u2022 ModifierMismatch: the constraint prevents two mentions to be linked if the head modifiers conflict.", "labels": [], "entities": []}, {"text": "For example, the constraint prevents \"northern Taiwan\" from linking to \"southern Taiwan\".", "labels": [], "entities": []}, {"text": "We gather a list of mutual exclusive modifiers from the training data.", "labels": [], "entities": []}, {"text": "\u2022 PropertyMismatch: the constraint prevents two mentions to be linked if their properties conflict.", "labels": [], "entities": []}, {"text": "For example, it prevents male pronouns to link to female pronouns and \"Mr. Clinton\" to link to \"Mrs. Clinton\" by checking the gender property.", "labels": [], "entities": []}, {"text": "The properties we consider are gender, number, professional title and the na- 67.12 71.18 46.84 61.71 66.4 71.8 48.8 62.3: Performance on OntoNotes-5.0 with predicted mentions.", "labels": [], "entities": []}, {"text": "We report the F1 scores (%) on various coreference metrics (MUC, BCUB, CEAF).", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9830445945262909}, {"text": "MUC", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.8609621524810791}, {"text": "BCUB", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.7581738233566284}]}, {"text": "The column AVG shows the average scores of the three.", "labels": [], "entities": [{"text": "AVG", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9978770017623901}]}, {"text": "We observe that PL 3 M and CPL 3 M (see Sec. 4) yields the same performance as L 3 M and CL 3 M, respectively as the tuned \u03b3 for all the datasets turned out to be 0. tionality.", "labels": [], "entities": []}, {"text": "While the \"must-link\" constraints described in the paper can be treated as features, due to their high precision, treating them as hard constraints (set \u03c1 to a high value) is a safe and direct way to inject human knowledge into the learning model.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9887107014656067}]}, {"text": "Moreover, our framework allows a constraint to use information from previous decisions (such as \"cannot-link\" constraints).", "labels": [], "entities": []}, {"text": "Treating such constraints as features will complicate the learning model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on OntoNotes-5.0 with predicted  mentions. We report the F1 scores (%) on various coref- erence metrics (MUC, BCUB, CEAF). The column AVG  shows the average scores of the three. We observe that  PL 3 M and CPL 3 M (see Sec. 4) yields the same perfor- mance as L 3 M and CL 3 M, respectively as the tuned \u03b3 for  all the datasets turned out to be 0.", "labels": [], "entities": [{"text": "F1", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9992964267730713}, {"text": "BCUB", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.932736337184906}, {"text": "AVG", "start_pos": 156, "end_pos": 159, "type": "METRIC", "confidence": 0.9961743354797363}]}, {"text": " Table 2: Performance on named entities for OntoNotes- 5.0 data. We compare our system to Fernandes (Fernan- des et al., 2012) and Stanford (Lee et al., 2013) systems.", "labels": [], "entities": [{"text": "OntoNotes- 5.0 data", "start_pos": 44, "end_pos": 63, "type": "DATASET", "confidence": 0.6892682015895844}, {"text": "Fernandes (Fernan- des et al., 2012) and Stanford (Lee et al., 2013)", "start_pos": 90, "end_pos": 158, "type": "DATASET", "confidence": 0.8497871725182784}]}, {"text": " Table 3: Performance on ACE 2004 and OntoNotes-5.0.  All-Link-Red. is based on correlational clustering; Span- ning is based on latent spanning forest based clustering  (see Sec. 2). Our proposed approach is L 3 M (Sec. 3) and  PL 3 M (sec. 4). CL 3 M and CPL 3 M are the version with  incorporating constraints.", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.874399721622467}]}, {"text": " Table 4: Ablation study on constraints. We first show  cumulative performance on OntoNotes-5.0 data with pre- dicted mentions as constraints are added one at a time into  the coreference system. Then we demonstrate the value  of individual constraints by leaving out one constraint at  each time.", "labels": [], "entities": [{"text": "OntoNotes-5.0 data", "start_pos": 82, "end_pos": 100, "type": "DATASET", "confidence": 0.87298783659935}]}]}