{"title": [{"text": "Effectiveness and Efficiency of Open Relation Extraction", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9719313383102417}, {"text": "Open Relation Extraction", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.8417025009791056}]}], "abstractContent": [{"text": "A large number of Open Relation Extraction approaches have been proposed recently, covering a wide range of NLP machinery, from \"shallow\" (e.g., part-of-speech tagging) to \"deep\" (e.g., semantic role labeling-SRL).", "labels": [], "entities": [{"text": "Open Relation Extraction", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.7961394588152567}, {"text": "part-of-speech tagging)", "start_pos": 145, "end_pos": 168, "type": "TASK", "confidence": 0.7972829739252726}, {"text": "semantic role labeling-SRL", "start_pos": 186, "end_pos": 212, "type": "TASK", "confidence": 0.6208217839399973}]}, {"text": "A natural question then is what is the trade-off between NLP depth (and associated computational cost) versus effectiveness.", "labels": [], "entities": []}, {"text": "This paper presents a fair and objective experimental comparison of 8 state-of-the-art approaches over 5 different datasets, and sheds some light on the issue.", "labels": [], "entities": []}, {"text": "The paper also describes a novel method, EXEMPLAR, which adapts ideas from SRL to less costly NLP machinery, resulting in substantial gains both in efficiency and effectiveness , over binary and n-ary relation extraction tasks.", "labels": [], "entities": [{"text": "n-ary relation extraction", "start_pos": 195, "end_pos": 220, "type": "TASK", "confidence": 0.6697464982668558}]}], "introductionContent": [{"text": "Open Relation Extraction (ORE) () has become prevalent over traditional relation extraction methods, especially on the Web, because of the intrinsic difficulty in training individual extractors for every single relation.", "labels": [], "entities": [{"text": "Open Relation Extraction (ORE)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7565363297859827}, {"text": "relation extraction", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.786332756280899}]}, {"text": "Broadly speaking, existing ORE approaches can be grouped according to the level of sophistication of the NLP techniques they rely upon: (1) shallow parsing, (2) dependency parsing and (3) semantic role labelling (SRL).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.8266226351261139}, {"text": "semantic role labelling (SRL)", "start_pos": 188, "end_pos": 217, "type": "TASK", "confidence": 0.6985678176085154}]}, {"text": "Shallow methods annotate the sentences with part-of-speech (POS) tags and the ORE approaches in this category, such as ReVerb) and SONEX (, identify relations by matching patterns over such tags.", "labels": [], "entities": [{"text": "ORE", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9919599890708923}]}, {"text": "Dependency parsing gives unambiguous relations among each word in the sentence, and the ORE approaches in this category such as PATTY (), OLLIE (, and TreeKernel () identify whole subtrees connecting the relation predicate and its arguments.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7952894866466522}, {"text": "ORE", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9937915205955505}, {"text": "PATTY", "start_pos": 128, "end_pos": 133, "type": "METRIC", "confidence": 0.9722583293914795}, {"text": "OLLIE", "start_pos": 138, "end_pos": 143, "type": "METRIC", "confidence": 0.9900740385055542}]}, {"text": "Finally, semantic annotators, such as Lund) and SwiRL (, add roles to each node in a parse tree, enabling ORE approaches that identify the precise connection between each argument and the predicate in a relation, independently.", "labels": [], "entities": []}, {"text": "The first contribution of the paper is an objective and fair experimental comparison of the stateof-the-art in ORE, on 5 datasets with varying degree of \"difficulty\".", "labels": [], "entities": [{"text": "ORE", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.4637181758880615}]}, {"text": "Of these, 4 datasets were annotated manually, covering both well-formed sentences, from the New York Times (NYT) and the Penn Treebank, as well as mixed-quality sentences from a popular Web corpus.", "labels": [], "entities": [{"text": "New York Times (NYT)", "start_pos": 92, "end_pos": 112, "type": "DATASET", "confidence": 0.662572572628657}, {"text": "Penn Treebank", "start_pos": 121, "end_pos": 134, "type": "DATASET", "confidence": 0.8216967284679413}]}, {"text": "A much larger corpus with 12,000 sentences from NYT, automatically annotated is also used.", "labels": [], "entities": [{"text": "NYT", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.9031514525413513}]}, {"text": "Another experiment focuses on n-ary relation extractions separately.", "labels": [], "entities": [{"text": "n-ary relation extractions", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.6860126654307047}]}, {"text": "The results show, as expected, that the three broad classes above are separated by orders of magnitude when it comes to throughput.", "labels": [], "entities": []}, {"text": "Shallow methods handle ten times more sentences than dependency parsing methods, which in turn handle ten times more sentences than semantic parsing methods.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.755621999502182}, {"text": "semantic parsing", "start_pos": 132, "end_pos": 148, "type": "TASK", "confidence": 0.759571760892868}]}, {"text": "Nevertheless, the costbenefit trade-off is not as simple; and the higher computation cost of dependency or semantic parsing does not always pays off with higher effectiveness.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.7084783762693405}]}, {"text": "The second contribution of the paper is anew ORE method, called EXEMPLAR, which applies a key idea in semantic approaches (namely, to iden-tify the precise connection between the argument and the predicate words in a relation) over a dependency parse tree (i.e., without applying SRL).", "labels": [], "entities": [{"text": "ORE", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9841312766075134}]}, {"text": "The goal is to achieve the higher accuracy of the semantic approaches at the lower computational cost of the dependency parsing approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9988627433776855}, {"text": "dependency parsing", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.756758064031601}]}, {"text": "EXEMPLAR is a rule-based system derived from a careful study of all dependency types identified by the Stanford parser.", "labels": [], "entities": []}, {"text": "(Note, however, that other parsers can be used, as shown later on.)", "labels": [], "entities": []}, {"text": "EXEMPLAR works for both binary and n-ary relations, and is evaluated separately in each case.", "labels": [], "entities": []}, {"text": "For binary relations, EXEMPLAR outperforms all previous methods in terms of accuracy, losing to the shallow methods only in terms of throughput.", "labels": [], "entities": [{"text": "EXEMPLAR", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9475669264793396}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9993267059326172}]}, {"text": "As for n-ary relations, EXEMPLAR outperforms the methods that support this kind of extraction.", "labels": [], "entities": [{"text": "EXEMPLAR", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8365635871887207}]}], "datasetContent": [{"text": "This section compares the effectiveness and efficiency of the following ORE methods: ReVerb,).", "labels": [], "entities": [{"text": "ORE", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.8827236890792847}, {"text": "ReVerb", "start_pos": 85, "end_pos": 91, "type": "DATASET", "confidence": 0.5745770931243896}]}], "tableCaptions": [{"text": " Table 1: Binary relation datasets.", "labels": [], "entities": []}, {"text": " Table 2: Results for the task of extracting binary relations. Methods are ordered by computing time per  sentence (in seconds). Best results for each column are underlined and marked in bold, for clarity.", "labels": [], "entities": [{"text": "clarity", "start_pos": 197, "end_pos": 204, "type": "METRIC", "confidence": 0.9678529500961304}]}, {"text": " Table 3: Results for n-ary relations.", "labels": [], "entities": []}]}