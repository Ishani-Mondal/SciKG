{"title": [{"text": "Source-Side Classifier Preordering for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.8095448613166809}]}], "abstractContent": [{"text": "We present a simple and novel classifier-based preordering approach.", "labels": [], "entities": []}, {"text": "Unlike existing pre-ordering models, we train feature-rich dis-criminative classifiers that directly predict the target-side word order.", "labels": [], "entities": []}, {"text": "Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long-distance reorderings using the structure of the parse tree, while utilizing a discrimina-tive model with a rich set of features, including lexical features.", "labels": [], "entities": []}, {"text": "We present extensive experiments on 22 language pairs, including pre-ordering into English from 7 other languages.", "labels": [], "entities": []}, {"text": "We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9988356232643127}, {"text": "WMT 2010 shared task", "start_pos": 66, "end_pos": 86, "type": "DATASET", "confidence": 0.8316856920719147}]}, {"text": "For languages from different families the improvements often exceed 2 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9988811612129211}]}, {"text": "Many of these gains are also significant inhuman evaluations .", "labels": [], "entities": []}], "introductionContent": [{"text": "Generating the appropriate word order for the target language has been one of the fundamental problems in machine translation since the ground setting work of.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7896728515625}]}, {"text": "Lexical reordering approaches) add a reordering component to standard phrase-based translation systems (.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6653009355068207}]}, {"text": "Because the reordering model is trained discriminatively, it can use a rich set of lexical features.", "labels": [], "entities": []}, {"text": "However, it only has access to the local context which oftentimes is insufficient to make the long-distance reordering decisions that are necessary for language pairs with significantly different word order.", "labels": [], "entities": []}, {"text": "Preordering (sometimes called pre-reordering or simply reordering) approaches () preprocess the input in such away that the words on the source side appear closer to their final positions on the target side.", "labels": [], "entities": [{"text": "Preordering", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9349972009658813}]}, {"text": "Because preordering is performed prior to word alignment, it can improve the alignment process and can then be combined with any subsequent translation model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.770899623632431}]}, {"text": "Most preordering models use a source-side syntactic parser and perform a series of tree transformations.", "labels": [], "entities": []}, {"text": "Approaches that do not use a parser exist as well and typically induce a hierarchical representation that also allows them to perform longdistance changes.", "labels": [], "entities": []}, {"text": "Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data.", "labels": [], "entities": []}, {"text": "One common type of tree transformation are rewrite rules.", "labels": [], "entities": []}, {"text": "These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun).", "labels": [], "entities": []}, {"text": "These rules can be designed manually ( or learned from data ().", "labels": [], "entities": []}, {"text": "Another type of tree transformations uses ranking functions to implement precedence-based reordering.", "labels": [], "entities": []}, {"text": "Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language.", "labels": [], "entities": []}, {"text": "The reordering operation is then to sort the words according to their assigned values.", "labels": [], "entities": []}, {"text": "The ranking function can be designed manually () or trained from data (.", "labels": [], "entities": []}, {"text": "This approach is particularly effective for Subject-Object-Verb (SOV) languages.", "labels": [], "entities": []}, {"text": "In this work we present a simple classifier-based preordering model.", "labels": [], "entities": []}, {"text": "Our model operates over dependency parse trees and is therefore able to perform long-distance reordering decisions, as is typical for preordering models.", "labels": [], "entities": []}, {"text": "But instead of deterministic rules or ranking functions, we use discriminative classifiers to directly predict the final word order, using rich (bi-)lexical and syntactic features.", "labels": [], "entities": []}, {"text": "The first model uses a classifier to directly predict the permutation order in which a family of words (a headword and all its children) will appear on the target side.", "labels": [], "entities": []}, {"text": "This approach is similar in spirit to the work of, except that they use constituency parse trees and consider only nodes with 2 or 3 children.", "labels": [], "entities": []}, {"text": "We instead work with dependency trees and consider much larger head-children sets.", "labels": [], "entities": []}, {"text": "Our second model is designed to decompose the exponential search space of all possible permutations.", "labels": [], "entities": []}, {"text": "The prediction task is broken into two separate steps.", "labels": [], "entities": [{"text": "prediction task", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9037667810916901}]}, {"text": "In the first step, for each child word a binary classifier decides whether it appears before or after its parent in the target language.", "labels": [], "entities": []}, {"text": "In the second step, we predict the best order of the words on each side of the parent.", "labels": [], "entities": []}, {"text": "We show that the second approach is never worse than the first one and sometimes significantly better.", "labels": [], "entities": []}, {"text": "We present experiments on 22 language pairs from different language families using our preordering approach in a phrase-based system, as well as a forest-to-string system ).", "labels": [], "entities": []}, {"text": "Ina first set of experiments, we use the WMT 2010 shared task data) and show significant improvements of up to 1.4 BLEU () on three out of eight language pairs.", "labels": [], "entities": [{"text": "WMT 2010 shared task data", "start_pos": 41, "end_pos": 66, "type": "DATASET", "confidence": 0.9222595453262329}, {"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9965787529945374}]}, {"text": "Ina second set of experiments, we use automatically mined parallel data from the web and build translation systems for languages from various language families.", "labels": [], "entities": []}, {"text": "We obtain especially big improvements in translation quality (2-7 BLEU) when the language pairs have divergent word order (for example English to Indonesian, Japanese, Korean or Malay).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.99704509973526}]}, {"text": "In our experiments on English to and from Hungarian, Dutch, and Portuguese translation, we find that we can obtain consistent improvements in both translation directions.", "labels": [], "entities": [{"text": "English to and from Hungarian, Dutch, and Portuguese translation", "start_pos": 22, "end_pos": 86, "type": "TASK", "confidence": 0.5648239850997925}]}, {"text": "To additionally verify our improvements we use human raters, who confirm the significance of the BLEU score improvements.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.974980354309082}]}, {"text": "Finally, we compare training the preordering classifiers on small amounts of manually aligned data to training on large quantities of automatically aligned data for English to Arabic, Hebrew, and Japanese.", "labels": [], "entities": []}, {"text": "When evaluated on a pure reordering task, the models trained on manually aligned data perform slightly better, but similar BLEU scores are obtained in both scenarios on an end-to-end translation task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9993509650230408}]}], "datasetContent": [{"text": "To provide a through evaluation of our approach, we conduct experiments on two sets of data and with two translation systems.", "labels": [], "entities": []}, {"text": "The first translation system is a phrase-based system ().", "labels": [], "entities": []}, {"text": "In addition to the regular distance distortion model, we incorporate a maximum entropy based lexicalized phrase reordering model ().", "labels": [], "entities": []}, {"text": "Our second system is a forest-to-string system ).", "labels": [], "entities": []}, {"text": "The forest-to-string system uses a onebest parse tree but factorizes it into a packed forest of binary elementary trees -hence the name forestto-string rather than tree-to-string.", "labels": [], "entities": []}, {"text": "The systems are configured and tuned for each language pair to produce the best results.", "labels": [], "entities": []}, {"text": "We then add our 1-step and 2-step preordering classifiers as preprocessing steps at training and test time.", "labels": [], "entities": []}, {"text": "We train the reordering classifiers on up to 15M training instances.", "labels": [], "entities": []}, {"text": "We train separate classifiers for every number of involved words, and restrict each one to the K = 20 most frequent outcomes.", "labels": [], "entities": []}, {"text": "In our implementation, in the 1-step approach we did not do any reordering for nodes with 7 or more children.", "labels": [], "entities": []}, {"text": "In the 2-step approach we did not reorder the children on either side of the head if there were 7 or more of them.", "labels": [], "entities": []}, {"text": "Even though there was no technical reason that prevented us from raising the thresholds, there was no good reason to do so.", "labels": [], "entities": []}, {"text": "There were very few cases where children were not reordered because of these thresholds, many of them corresponded to bad parses, and they had very little impact on the final scores.", "labels": [], "entities": []}, {"text": "Thus, for the 1-step approach we had 6 classifiers: 1 binary classifier fora head and a single child and 5 multi-class classifiers for 3-7 words.", "labels": [], "entities": []}, {"text": "For the 2-step approach we had 11 classifiers: 1 pivot classifier, 5 classifiers for words before the head, and 5 for words after the head.", "labels": [], "entities": []}, {"text": "For a direct comparison to a strong preordering system, we compare to the system of Genzel, which learns a set of unlexicalized reordering rules from automatically aligned data by minimizing the number of crossing alignments.", "labels": [], "entities": []}, {"text": "We used a sliding window of size 3 and tried all three of their variants.", "labels": [], "entities": []}, {"text": "There were about 40-50 rules per language pair.", "labels": [], "entities": []}, {"text": "While conceptually possible, it is not practical to learn more rules (including lexicalized rules) with this system, because of the computational complexity of the learning algorithm and the incremental nature in which the rules are learned and applied.", "labels": [], "entities": []}, {"text": "We use case-sensitive BLEU ( to assess translation quality.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9809193015098572}]}, {"text": "For Japanese and Korean we use character-level BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9848040342330933}]}, {"text": "We use bootstrap resampling to compute confidence intervals.", "labels": [], "entities": []}, {"text": "Additionally, we also conduct a side-by-side human evaluation on 750 sentences for each language pair (sampled from the same sentences used for computing BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9298948049545288}]}, {"text": "For each sentence, we ask bilingual annotators to compare the translations from two different systems and say whether one is better, leading to three possible scores of -1, 0, and +1.", "labels": [], "entities": []}, {"text": "We focus on this relative comparison since absolute scores are difficult to calibrate across languages and raters.", "labels": [], "entities": []}, {"text": "shows our treebank sources and parsing accuracies.", "labels": [], "entities": []}, {"text": "For English, we use the updated WSJ with OntoNotes-style annotations converted to Stanford dependencies (de).", "labels": [], "entities": [{"text": "WSJ", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.9437111616134644}]}, {"text": "The remaining treebanks are all available in dependency format.", "labels": [], "entities": []}, {"text": "In all cases, we apply a set of heuristics to the treebank data to make the tokenization as similar as possible to the one of the bitext.", "labels": [], "entities": []}, {"text": "Our heuristics can split treebank tokens but do not merge treebank tokens.", "labels": [], "entities": []}, {"text": "We found that adjusting the treebank tokenization is crucial for obtaining good results.", "labels": [], "entities": []}, {"text": "However, this makes the reported parsing accuracies not comparable to other numbers in the literature.", "labels": [], "entities": []}, {"text": "When necessary, we projectivize the treebanks by raising arcs until the tree becomes projective, as described in Nivre and Nilsson (2005); we do not reconstruct non-projective arcs at parsing time, since our subsequent systems expect projective trees.", "labels": [], "entities": []}, {"text": "Due to the large number of experiments and language pairs we divide the experiments into groups and discuss each in turn.", "labels": [], "entities": []}, {"text": "We only include the results from the forest-to-string system when they are better than the phrase-based results.", "labels": [], "entities": []}, {"text": "We use * to denote results from the forest-to-string system.) never hurts and is thus included in all systems.", "labels": [], "entities": []}, {"text": "Overall, our results area little better than the best results of the WMT 2010 shared task for two language pairs and within reach of the best results inmost other cases.", "labels": [], "entities": [{"text": "WMT 2010 shared task", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.5955193787813187}]}, {"text": "The 2-step classifier preordering approach provides statistically significant improvements over the lexical reordering baseline on three out of the eight language pairs: English-Spanish (en-es: 1.4 BLEU), German-English (de-en: 1.2 BLEU), and EnglishFrench (en-fr: 1.0 BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 198, "end_pos": 202, "type": "METRIC", "confidence": 0.9778303503990173}, {"text": "BLEU", "start_pos": 232, "end_pos": 236, "type": "METRIC", "confidence": 0.9838512539863586}, {"text": "BLEU", "start_pos": 269, "end_pos": 273, "type": "METRIC", "confidence": 0.9640164375305176}]}, {"text": "These improvements are significant in our human side-by-side evaluation.", "labels": [], "entities": []}, {"text": "We also observe gains when combining our preordering approach with the forest-to-string system for English-Spanish and German-English.", "labels": [], "entities": []}, {"text": "While the forest-to-string system is capable of performing long distance reordering in the decoder, it appears that an explicitly trained lexicalized preordering model can provide complementary benefits.", "labels": [], "entities": []}, {"text": "These benefits are especially pronounced for German-English where long distance verb movement is essential.", "labels": [], "entities": [{"text": "long distance verb movement", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6854973584413528}]}, {"text": "For the romance languages (Spanish and French), word ordering depends highly on lexical choice which is captured by the lexical features in our classifiers.: BLEU scores on the WMT 2010 setup.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.7643155157566071}, {"text": "BLEU", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.9989312291145325}, {"text": "WMT 2010 setup", "start_pos": 177, "end_pos": 191, "type": "DATASET", "confidence": 0.964272677898407}]}, {"text": "Results from the forest-to-string system are marked with * and are only included when better than the phrase-based results.", "labels": [], "entities": []}, {"text": "The base system includes a distance distortion model; the lexical system adds lexical reordering; rule is the rule preordering system of Genzel plus lexical reordering; 1-step and 2-step are our classifier-based systems plus lexical reordering.", "labels": [], "entities": []}, {"text": "Bolded results are statistically significantly better than non-bolded results as measured by a bootstrap sample test with a 99% confidence interval.", "labels": [], "entities": []}, {"text": "Human evals are conducted only where indicated; we use \u2660 and \u2663 to indicate a significantly better result than and in the human eval at 95%.", "labels": [], "entities": [{"text": "\u2660", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.9923654198646545}]}, {"text": "Also included are the best results from the WMT 2010 task.", "labels": [], "entities": [{"text": "WMT 2010 task", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.6568495233853658}]}, {"text": "Compared to a state-of-the-art preordering system, the automatic rule extraction system of Genzel (2010), we observe significant gains in several cases and no losses at all.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7143514156341553}]}, {"text": "The improvements on English-Spanish are significant also in the human evaluation, while the English-French improvements are positive, but not statistically significant.", "labels": [], "entities": []}, {"text": "Comparing the different languages, Czech (cs) appears the most immune to improvements from preordering (and lexical reordering).", "labels": [], "entities": [{"text": "preordering", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.9371405839920044}]}, {"text": "One possible explanation is that Czech has a relatively free word order with a default SVO structure.", "labels": [], "entities": []}, {"text": "It is therefore difficult to learn reordering changes from English to Czech.", "labels": [], "entities": []}, {"text": "Additionally, the accuracy (LAS) of our Czech parser is by far the lowest of all parsers that we used, potentially limiting the benefits that can be obtained when translating from Czech into English.", "labels": [], "entities": [{"text": "accuracy (LAS)", "start_pos": 18, "end_pos": 32, "type": "METRIC", "confidence": 0.9160354882478714}]}, {"text": "On this setup there is fairly little difference in performance between the 1-step and 2-step approaches.", "labels": [], "entities": []}, {"text": "The main benefit of the 2-step approach is compactness: the set of 2-step classifiers has about half the number of non-zero features as the 1-step classifiers.", "labels": [], "entities": []}, {"text": "shows our first set of results on the additional languages, including some languages with a wide disparity in word order relative to English.", "labels": [], "entities": []}, {"text": "The SOV languages Korean (ko) and Japanese (ja) benefit the most from preordering and gain more than 7 BLEU relative to the phrase-based baseline and still more than 3 BLEU for the forest-to-string system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9970707893371582}, {"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9961512684822083}]}, {"text": "Similar improvements were reported by with manual reordering rules.", "labels": [], "entities": []}, {"text": "Indonesian (id) and Malay (ms) are next with gains of 2.5 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9989834427833557}]}, {"text": "Malay does not have a grammatical subject in the sense that English does, but instead uses a concept of an agent and an object, whose order is determined by the voice of the verb.", "labels": [], "entities": []}, {"text": "It appears that our classifiers have learned to model some of these highly lexical, but systematic ordering preferences.", "labels": [], "entities": []}, {"text": "Welsh (cy) and Irish (ga) as VSO languages also exhibit large gains of 2.1 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9980979561805725}]}, {"text": "For Arabic (ar) and Hebrew (iw), the gains are smaller, but still significant and exceed 1 BLEU relative to the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9993864297866821}]}, {"text": "The benefits of our 2-step approach over the 1-step approach become apparent on this set of languages where reordering is most important.", "labels": [], "entities": []}, {"text": "By predicting the target word order in two steps, we reduce sparsity and make two easier decisions in place of a single difficult high entropy decision.", "labels": [], "entities": []}, {"text": "Indeed, the 2-step approach produces improvements over the 1-step approach on five out of nine language pairs.", "labels": [], "entities": []}, {"text": "The improvements are as large as 0.9 BLEU for Korean and 0.5 BLEU for Japanese and Welsh.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9983136653900146}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9971687197685242}]}, {"text": "We performed human evaluation for all language pairs with a noticeable BLEU gain for the 2-step system over base rule 1-step 2-step en-ar 11.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9996302127838135}]}, {"text": "The human judgments exactly agree with the results of the BLEU significance tests.", "labels": [], "entities": [{"text": "BLEU significance", "start_pos": 58, "end_pos": 75, "type": "METRIC", "confidence": 0.9265649616718292}]}, {"text": "The gains relative to the rule reordering system of Genzel (2010) and the no-preordering baseline are even larger and therefore clearly also significant.", "labels": [], "entities": []}, {"text": "In we show results for Hungarian (hu), Dutch (nl), and Portuguese (pt).", "labels": [], "entities": []}, {"text": "In all cases but English-Hungarian we observe significant improvements over the no preordering baseline.", "labels": [], "entities": []}, {"text": "It should be noted that the gains are not symmetric -sometimes there are larger gains for translating out of English, while for Hungarian the gains are higher for translating into English.", "labels": [], "entities": [{"text": "translating out of English", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.8898268193006516}]}, {"text": "Hungarian has a free word order which is difficult to predict which might partially explain why there are no improvements for translating into Hungarian.", "labels": [], "entities": []}, {"text": "For Dutch-English, the forest-tostring system yields the best results, which was also the case for German-English, further supporting the observation that combining different types of syntactic reordering approaches can be beneficial.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parsing accuracies on the retokenized treebanks.  UAS is unlabeled attachment score, LAS is labeled at- tachment score, and POS is part-of-speech tagging accu- racy. The treebank sources are (1): Marcus et al. (1993)  + Judge et al. (2006) + Petrov and McDonald (2012), (2):  Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4):  McDonald et al. (2013), (5): Abeill\u00e9 et al. (2003).", "labels": [], "entities": [{"text": "UAS", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9859291911125183}, {"text": "LAS", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.9834091663360596}, {"text": "POS", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9530512094497681}]}, {"text": " Table 2: BLEU scores on the WMT 2010 setup. Results from the forest-to-string system are marked with * and are  only included when better than the phrase-based results. The base system includes a distance distortion model; the  lexical system adds lexical reordering; rule is the rule preordering system of Genzel", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.998957633972168}, {"text": "WMT 2010 setup", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.8806619048118591}, {"text": "Genzel", "start_pos": 308, "end_pos": 314, "type": "DATASET", "confidence": 0.7888851761817932}]}, {"text": " Table 3: BLEU scores for language from various lan- guage families: Arabic (ar), Welsh (cy), Irish (ga), In- donesian (id), Hebrew (iw), Japanese (ja), Korean (ko),  and Malay (ms). Lexical reordering is not included in  any of the systems. Bolded results are significant at 99%.  \u2663 is significantly better than in a human eval at 95%.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9985346794128418}, {"text": "\u2663", "start_pos": 282, "end_pos": 283, "type": "METRIC", "confidence": 0.9947138428688049}]}, {"text": " Table 4: BLEU scores for translating to and from En- glish for: Hungarian (hu), Dutch (nl), and Portuguese  (pt). Lexical reordering is not used for any language pair.  Bolded results are significant at 99%.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992092847824097}, {"text": "translating to and from En- glish", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.8480795877320426}]}, {"text": " Table 5: Preordering accuracy for the 2-step classifiers using manual alignments vs. automatic alignments. Fuzzy  refers to the metric defined in Talbot et al. (2011) and exact is the percentage of sentences with a perfect preordering.", "labels": [], "entities": [{"text": "Preordering", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9830548763275146}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.911090612411499}, {"text": "Fuzzy", "start_pos": 108, "end_pos": 113, "type": "METRIC", "confidence": 0.8646551966667175}, {"text": "exact", "start_pos": 172, "end_pos": 177, "type": "METRIC", "confidence": 0.9926250576972961}]}]}