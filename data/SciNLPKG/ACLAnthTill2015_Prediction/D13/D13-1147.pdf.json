{"title": [{"text": "Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models", "labels": [], "entities": [{"text": "Detecting Compositionality of Multi-Word Expressions", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.807258152961731}]}], "abstractContent": [{"text": "We present a novel unsupervised approach to detecting the compositionality of multi-word expressions.", "labels": [], "entities": [{"text": "detecting the compositionality of multi-word expressions", "start_pos": 44, "end_pos": 100, "type": "TASK", "confidence": 0.8640928963820139}]}, {"text": "We compute the compositional-ity of a phrase through substituting the constituent words with their \"neighbours\" in a semantic vector space and averaging over the distance between the original phrase and the substituted neighbour phrases.", "labels": [], "entities": []}, {"text": "Several methods of obtaining neighbours are presented.", "labels": [], "entities": []}, {"text": "The results are compared to existing supervised results and achieve state-of-the-art performance on a verb-object dataset of human compositionality ratings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multi-word expressions (MWEs) are defined as \"idiosyncratic interpretations that crossword boundaries\").", "labels": [], "entities": [{"text": "Multi-word expressions (MWEs)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6079383432865143}]}, {"text": "They tend to have a standard syntactic structure but are often semantically non-compositional; i.e. their meaning is not fully determined by their syntactic structure and the meanings of their constituents.", "labels": [], "entities": []}, {"text": "A classic example is kick the bucket, which means to die rather than to hit a bucket with the foot.", "labels": [], "entities": []}, {"text": "These types of expressions account fora large proportion of day-to-day language interactions () and present a significant problem for natural language processing systems ().", "labels": [], "entities": []}, {"text": "This paper presents a novel unsupervised approach to detecting the compositionality of MWEs, specifically of verb-noun collocations.", "labels": [], "entities": [{"text": "detecting the compositionality of MWEs", "start_pos": 53, "end_pos": 91, "type": "TASK", "confidence": 0.7987667441368103}]}, {"text": "The idea is that we can recognize compositional phrases by substituting related words for constituent words in the phrase: if the result of a substitution yields a meaningful phrase, its individual constituents are likely to contribute toward the overall meaning of the phrase.", "labels": [], "entities": []}, {"text": "Conversely, if a substitution yields a non-sensical phrase, its constituents are likely to contribute lessor not at all to the overall meaning of the phrase.", "labels": [], "entities": []}, {"text": "For the phrase eat her hat, for example, we might consider the following substituted phrases: 1.", "labels": [], "entities": []}, {"text": "eat her trousers Both phrases are semantically anomalous, implying that eat hat is a highly non-compositional verb-noun collocation.", "labels": [], "entities": []}, {"text": "Following a similar procedure for eat apple, however, would not lead to an anomaly: consume apple and eat pear are perfectly meaningful, leading us to believe that eat apple is compositional.", "labels": [], "entities": []}, {"text": "In the context of distributional models, this idea can be formalised in terms of vector spaces: the average distance between a phrase vector and its substituted phrase vectors is related to its compositionality.", "labels": [], "entities": []}, {"text": "Since we are relying on the relative distances of phrases in semantic space, we require a method for computing vectors for phrases.", "labels": [], "entities": []}, {"text": "We experimented with a number of composition operators from, in order to compose constituent word vectors into phrase vectors.", "labels": [], "entities": []}, {"text": "The relation between phrase vectors and substituted phrase vectors is most pronounced in the case of pointwise multiplication, which has the effect of placing semantically anomalous phrases relatively close together in space (since the vectors for the constituent words have little in common), whereas the semantically meaningful phrases are further apart.", "labels": [], "entities": []}, {"text": "This implies that compositional phrases are less similar to their neighbours, which is to say that the greater the average distance between a phrase vector and its substituted phrase vectors, the greater its compositionality.", "labels": [], "entities": []}, {"text": "The contribution of this short focused research paper is a novel approach to detecting the compositionality of multi-word expressions that makes full use of the ability of semantic vector space models to calculate distances between words and phrases.", "labels": [], "entities": [{"text": "detecting the compositionality of multi-word expressions", "start_pos": 77, "end_pos": 133, "type": "TASK", "confidence": 0.8657925128936768}]}, {"text": "Using this unsupervised approach, we achieve state-of-theart performance in a direct comparison with existing supervised methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "The verb-noun collocation dataset from Venkatapathy and, which consists of 765 verbobject pairs with human compositionality ratings, was used for evaluation.", "labels": [], "entities": []}, {"text": "Venkatapathy & Joshi used a support vector machine (SVM) to obtain a Spearman \u03c1 s correlation of 0.448.", "labels": [], "entities": [{"text": "Spearman \u03c1 s correlation", "start_pos": 69, "end_pos": 93, "type": "METRIC", "confidence": 0.9075154215097427}]}, {"text": "They employed a variety of features ranging from frequency to LSAderived similarity measures and used 10% of the dataset as training data with tenfold cross-validation.", "labels": [], "entities": [{"text": "LSAderived similarity", "start_pos": 62, "end_pos": 83, "type": "METRIC", "confidence": 0.7729028165340424}]}, {"text": "used the same dataset and expanded on the original approach by adding WordNet and distributional prototypes to the SVM, achieving a \u03c1 s correlation of 0.454.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.9585074782371521}]}, {"text": "The distributional vectors for our experiments were constructed from the ukWaC corpus ().", "labels": [], "entities": [{"text": "ukWaC corpus", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.9926315248012543}]}, {"text": "Vectors were obtained using a standard window method (with a window size of 5) and the 50,000 most frequent context words as features, with stopwords removed.", "labels": [], "entities": []}, {"text": "We also experimented with syntax-based co-occurrence features extracted from a dependency-parsed version of ukWaC, but in agreement with results obtained by Schulte im for predicting compositionality in German, the window-based co-occurrence method produced better results.", "labels": [], "entities": [{"text": "ukWaC", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.9367151260375977}, {"text": "predicting compositionality", "start_pos": 172, "end_pos": 199, "type": "TASK", "confidence": 0.8474044799804688}]}, {"text": "We tried several weighting schemes from the literature, such as t-test, positive mutual information () and the ratio of the probability of the context word given the target word 1 to the context word's overall probability (.", "labels": [], "entities": []}, {"text": "We found that a tf-idf variant called LTU yielded the best results, defined as follows (): where f ij is the number of times that the target word and context word co-occur in the same window, n j is the context word frequency, N is the total frequency and |context word| is the total number of occurrences of a context word.", "labels": [], "entities": []}, {"text": "Distance is calculated using the standard cosine measure: where v 1 and v 2 are vectors in the semantic vector space model.", "labels": [], "entities": [{"text": "Distance", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9332627654075623}]}], "tableCaptions": [{"text": " Table 1: Example take breath", "labels": [], "entities": []}, {"text": " Table 2: Example lend money", "labels": [], "entities": []}, {"text": " Table 3: Spearman \u03c1 s results", "labels": [], "entities": [{"text": "Spearman \u03c1", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.7862405478954315}]}]}