{"title": [], "abstractContent": [{"text": "We present Multi-Relational Latent Semantic Analysis (MRLSA) which generalizes Latent Semantic Analysis (LSA).", "labels": [], "entities": [{"text": "Multi-Relational Latent Semantic Analysis (MRLSA", "start_pos": 11, "end_pos": 59, "type": "TASK", "confidence": 0.6705489059289297}, {"text": "Latent Semantic Analysis (LSA)", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.7661942342917124}]}, {"text": "MRLSA provides an elegant approach to combining multiple relations between words by constructing a 3-way tensor.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7797667384147644}]}, {"text": "Similar to LSA, a low-rank approximation of the tensor is derived using a tensor decomposition.", "labels": [], "entities": []}, {"text": "Each word in the vocabulary is thus represented by a vector in the latent semantic space and each relation is captured by a latent square matrix.", "labels": [], "entities": []}, {"text": "The degree of two words having a specific relation can then be measured through simple linear algebraic operations.", "labels": [], "entities": []}, {"text": "We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves state-of-the-art performance on existing benchmark datasets for two relations, antonymy and is-a.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 115, "end_pos": 120, "type": "TASK", "confidence": 0.7240561842918396}]}], "introductionContent": [{"text": "Continuous semantic space representations have proven successful in a wide variety of NLP and IR applications, such as document clustering () and cross-lingual document retrieval () at the document level and sentential semantics) and syntactic parsing) at the sentence level.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7648546993732452}, {"text": "cross-lingual document retrieval", "start_pos": 146, "end_pos": 178, "type": "TASK", "confidence": 0.6150821149349213}, {"text": "syntactic parsing", "start_pos": 234, "end_pos": 251, "type": "TASK", "confidence": 0.7405502796173096}]}, {"text": "Such representations also play an important role in applications for lexical semantics, such as word sense disambiguation, measuring word * Work conducted while interning at Microsoft Research.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 96, "end_pos": 121, "type": "TASK", "confidence": 0.763793408870697}]}, {"text": "similarity) and relational similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9162521362304688}]}, {"text": "In many of these applications, Latent Semantic Analysis (LSA)) has been widely used, serving as a fundamental component or as a strong baseline.", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA))", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.7424602011839548}]}, {"text": "LSA operates by mapping text objects, typically documents and words, to a latent semantic space.", "labels": [], "entities": []}, {"text": "The proximity of the vectors in this space implies that the original text objects are semantically related.", "labels": [], "entities": []}, {"text": "However, one well-known limitation of LSA is that it is unable to differentiate fine-grained relations.", "labels": [], "entities": []}, {"text": "For instance, when applied to lexical semantics, synonyms and antonyms may both be assigned high similarity scores).", "labels": [], "entities": []}, {"text": "Asymmetric relations like hyponyms and hypernyms also cannot be differentiated.", "labels": [], "entities": []}, {"text": "Although there exists some recent work, such as PILSA which tries to overcome this weakness of LSA by introducing the notion of polarity ( . This extension, however, can only handle two opposing relations (e.g., synonyms and antonyms), leaving open the challenge of encoding multiple relations.", "labels": [], "entities": [{"text": "PILSA", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.8006269335746765}]}, {"text": "In this paper, we propose Multi-Relational Latent Semantic Analysis (MRLSA), which strictly generalizes LSA to incorporate information of multiple relations concurrently.", "labels": [], "entities": [{"text": "Multi-Relational Latent Semantic Analysis (MRLSA)", "start_pos": 26, "end_pos": 75, "type": "TASK", "confidence": 0.6786685032503945}]}, {"text": "Similar to LSA or PILSA when applied to lexical semantics, each word is still mapped to a vector in the latent space.", "labels": [], "entities": []}, {"text": "However, when measuring whether two words have a specific relation (e.g., antonymy or is-a), the word vectors will be mapped to anew space according to the relation where the degree of having this relation will be judged by cosine similarity.", "labels": [], "entities": []}, {"text": "The raw data construction in MRLSA is straightforward and similar to the document-term matrix in LSA.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 29, "end_pos": 34, "type": "TASK", "confidence": 0.6506410837173462}]}, {"text": "However, instead of using one matrix to capture all relations, we extend the representation to a 3-way tensor.", "labels": [], "entities": []}, {"text": "Each slice corresponds to the document-term matrix in the original LSA design but fora specific relation.", "labels": [], "entities": []}, {"text": "Analogous to LSA, the whole linear transformation mapping is derived through tensor decomposition, which provides a low-rank approximation of the original tensor.", "labels": [], "entities": [{"text": "tensor decomposition", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.7866430878639221}]}, {"text": "As a result, previously unseen relations between two words can be discovered, and the information encoded in other relations can influence the construction of the latent representations, and thus potentially improves the overall quality.", "labels": [], "entities": []}, {"text": "In addition, the information in different slices can come from heterogeneous sources (conceptually similar to (), which not only improves the model, but also extends the word coverage in a reliable way.", "labels": [], "entities": []}, {"text": "We provide empirical evidence that MRLSA is effective using two different word relations: antonymy and is-a.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 35, "end_pos": 40, "type": "TASK", "confidence": 0.8451027870178223}]}, {"text": "We use the benchmark GRE test of closestopposites ( to show that MRLSA performs comparably to PILSA, which was the pervious state-of-the-art approach on this problem, when given the same amount of information.", "labels": [], "entities": [{"text": "GRE", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9853197336196899}, {"text": "MRLSA", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.9440160989761353}, {"text": "PILSA", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.9790220856666565}]}, {"text": "In addition, when other words and relations are available, potentially from additional resources, MRLSA is able to outperform previous methods significantly.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 98, "end_pos": 103, "type": "TASK", "confidence": 0.8218284249305725}]}, {"text": "We use the is-a relation to demonstrate that MRLSA is capable of handling asymmetric relations.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 45, "end_pos": 50, "type": "TASK", "confidence": 0.5580244660377502}]}, {"text": "We take the list of word pairs from the Class-Inclusion (i.e., is-a) relations in, and use our model to measure the degree of two words have this relation.", "labels": [], "entities": []}, {"text": "The measures derived from our model correlate with human judgement better than the best system that participated in the task.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first survey some related work in Section 2, followed by a more detailed description of LSA and PILSA in Section 3.", "labels": [], "entities": [{"text": "LSA", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.43754255771636963}, {"text": "PILSA", "start_pos": 99, "end_pos": 104, "type": "METRIC", "confidence": 0.7000914812088013}]}, {"text": "Our proposed model, MRLSA, is presented in Section 4.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.6653950214385986}]}, {"text": "Section 5 presents our experimental results.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate MRLSA on two tasks: answering the closest-opposite GRE questions and measuring degrees of various class-inclusion (i.e., is-a) relations.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 12, "end_pos": 17, "type": "TASK", "confidence": 0.6087301969528198}, {"text": "GRE", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9032638669013977}]}, {"text": "In both tasks, we design the experiments to empirically validate the following claims.", "labels": [], "entities": []}, {"text": "When encoding two opposite relations from the same source, MRLSA performs comparably to PILSA.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.8439697623252869}]}, {"text": "However, MRLSA generalizes LSA to model multiple relations, which could be obtained from both homogeneous and heterogeneous data sources.", "labels": [], "entities": [{"text": "MRLSA", "start_pos": 9, "end_pos": 14, "type": "TASK", "confidence": 0.7874787449836731}]}, {"text": "As a result, the performance of a target task can be further improved.", "labels": [], "entities": []}, {"text": "We construct the raw tensors to encode a particular relation in each slice based on two data sources.", "labels": [], "entities": []}, {"text": "Encarta The Encarta thesaurus is developed by Bloomsbury Publishing Plc 2 . For each target word, it provides a list of synonyms and antonyms.", "labels": [], "entities": [{"text": "Bloomsbury Publishing Plc 2", "start_pos": 46, "end_pos": 73, "type": "DATASET", "confidence": 0.9745157361030579}]}, {"text": "We use the same version of the thesaurus as in , which contains about 47k words and a vocabulary list of approximately 50k words.", "labels": [], "entities": []}, {"text": "WordNet We use four types of relations from WordNet: synonymy, antonymy, hypernymy and hyponymy.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9679418206214905}, {"text": "WordNet", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9424541592597961}]}, {"text": "The number of target words and the size of the vocabulary in our version are 117,791 and 149,400, respectively.", "labels": [], "entities": []}, {"text": "WordNet has better vocabulary coverage, but fewer antonym pairs.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.979496955871582}]}, {"text": "For instance, the WordNet antonym slice contains only 46,945 nonzero entries, while the Encarta antonym slice has 129,733.", "labels": [], "entities": [{"text": "WordNet antonym slice", "start_pos": 18, "end_pos": 39, "type": "DATASET", "confidence": 0.9549161593119303}, {"text": "Encarta antonym slice", "start_pos": 88, "end_pos": 109, "type": "DATASET", "confidence": 0.916764497756958}]}, {"text": "We apply a memory-efficient Tucker decomposition algorithm implemented in tensor toolbox v2.", "labels": [], "entities": []}, {"text": "The largest tensor considered in this paper can be decomposed in about 3 hours using less than 4GB of memory with a commodity PC.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: GRE antonym test results of models based on Encarta and WordNet data in precision, recall and F 1 .  RawTensor evaluates the performance of the tensor with 2 slices encoding synonyms and antonyms be- fore decomposition (see Eq.", "labels": [], "entities": [{"text": "WordNet data", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.9063354730606079}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9991806149482727}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9987775683403015}, {"text": "F 1", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9918041527271271}]}, {"text": " Table 2: Results of measuring the class-inclusion (is-a) relations in MaxDiff accuracy (see text for de- tail). RawTensor has synonym and hyponym slices and measures the degree of is-a relation using Eq. (5).  MRLSA:Syn+Hypo factors the raw tensor and judges the relation by Eq. (6). The constructions of  MRLSA:4-layers and MRLSA:WordNet+Encarta are the same as in Sec. 5.2 (see the caption of", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9127632975578308}]}]}