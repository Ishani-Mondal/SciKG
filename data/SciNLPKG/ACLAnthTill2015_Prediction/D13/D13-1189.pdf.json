{"title": [{"text": "Collective Opinion Target Extraction in Chinese Microblogs", "labels": [], "entities": [{"text": "Collective Opinion Target Extraction", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5526493787765503}, {"text": "Chinese Microblogs", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.6717754006385803}]}], "abstractContent": [{"text": "Microblog messages pose severe challenges for current sentiment analysis techniques due to some inherent characteristics such as the length limit and informal writing style.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.9497385919094086}]}, {"text": "In this paper, we study the problem of extracting opinion targets of Chinese microblog messages.", "labels": [], "entities": [{"text": "extracting opinion targets of Chinese microblog messages", "start_pos": 39, "end_pos": 95, "type": "TASK", "confidence": 0.8000382014683315}]}, {"text": "Such fine-grained word-level task has not been well investigated in microblogs yet.", "labels": [], "entities": []}, {"text": "We propose an unsupervised label propagation algorithm to address the problem.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7364841997623444}]}, {"text": "The opinion targets of all messages in a topic are collectively extracted based on the assumption that similar messages may focus on similar opinion targets.", "labels": [], "entities": []}, {"text": "Topics in microblogs are identified by hashtags or using clustering algorithms.", "labels": [], "entities": []}, {"text": "Experimental results on Chinese microblogs show the effectiveness of our framework and algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Microblogging services such as Twitter 1 , Sina Weibo 2 and Tencent Weibo have swept across the globe in recent years.", "labels": [], "entities": [{"text": "Sina Weibo 2", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.8549007773399353}]}, {"text": "Users of microblogs range from celebrities to ordinary people, who usually express their emotions or attitudes towards abroad range of topics.", "labels": [], "entities": []}, {"text": "It is reported that there are more than 340 million tweets per day on Twitter and more than 200 million on Sina Weibo.", "labels": [], "entities": [{"text": "Sina Weibo", "start_pos": 107, "end_pos": 117, "type": "DATASET", "confidence": 0.9181268513202667}]}, {"text": "A tweet means a post on Twitter.", "labels": [], "entities": []}, {"text": "Since we mainly focus on Chinese microblogs instead of Twitter in this paper, we will refer to a post as a message.", "labels": [], "entities": []}, {"text": "Each message is limited to 140 Chinese characters and usually contains several sentences.", "labels": [], "entities": []}, {"text": "* Xiaojun Wan is the corresponding author.", "labels": [], "entities": []}, {"text": "1 https://twitter.com 2 http://weibo.com/ 3 http://t.qq.com/ Currently, researches on microblog sentiment analysis have been conducted on polarity classification () and have been proved to be useful in many applications, such as opinion polling (, election prediction ( and even stock market prediction).", "labels": [], "entities": [{"text": "microblog sentiment analysis", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.7987518707911173}, {"text": "polarity classification", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.7747274935245514}, {"text": "opinion polling", "start_pos": 229, "end_pos": 244, "type": "TASK", "confidence": 0.7848646938800812}, {"text": "election prediction", "start_pos": 248, "end_pos": 267, "type": "TASK", "confidence": 0.7403350919485092}, {"text": "stock market prediction", "start_pos": 279, "end_pos": 302, "type": "TASK", "confidence": 0.6084607044855753}]}, {"text": "However, classifying microblog texts at the sentence level is often insufficient for applications because it does not identify the opinion targets.", "labels": [], "entities": []}, {"text": "In this paper, we will study the task of opinion target extraction for Chinese microblog messages.", "labels": [], "entities": [{"text": "opinion target extraction", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.6904186209042867}]}, {"text": "Opinion target extraction aims to find the object to which the opinion is expressed.", "labels": [], "entities": [{"text": "Opinion target extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6727780203024546}]}, {"text": "For example, in the sentence \"The sound quality is good!\", \"sound quality\" is the opinion target.", "labels": [], "entities": []}, {"text": "This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects ().", "labels": [], "entities": []}, {"text": "Most of the opinion target extraction approaches rely on dependency parsing ( and are regarded as a domain-dependent task ().", "labels": [], "entities": [{"text": "opinion target extraction", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7192444403966268}, {"text": "dependency parsing", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7827532887458801}]}, {"text": "However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics.", "labels": [], "entities": []}, {"text": "Studies show that one of the state-of-the-art partof-speech taggers -OpenNLP only achieves the accuracy of 74% on tweets ( ).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9989610910415649}]}, {"text": "The syntactic analysis tool that generates dependency relation may perform even worse.", "labels": [], "entities": []}, {"text": "Besides, microblog messages may express opinion in different ways and do not always contain opinion words, which lowers the performance of methods utilizing opinion words to find opinion targets.", "labels": [], "entities": []}, {"text": "In this study, we propose an unsupervised method to collectively extract the opinion targets from opinionated sentences in the same topic.", "labels": [], "entities": []}, {"text": "Topics are directly identified by hashtags.", "labels": [], "entities": []}, {"text": "We first present a dynamic programming based segmentation algorithm for Chinese hashtag segmentation.", "labels": [], "entities": [{"text": "Chinese hashtag segmentation", "start_pos": 72, "end_pos": 100, "type": "TASK", "confidence": 0.6351100007692972}]}, {"text": "By leveraging the contents in a topic, our segmentation algorithm can successfully identify out-ofvocabulary words and achieve promising results.", "labels": [], "entities": []}, {"text": "Afterwards, all the noun phrases in each sentence and the hashtag segments are extracted as opinion target candidates.", "labels": [], "entities": []}, {"text": "We propose an unsupervised label propagation algorithm to collectively rank the candidates of all sentences based on the assumption that similar sentences in a topic may share the same opinion targets.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7774812579154968}]}, {"text": "Finally, for each sentence, the candidate which gets the highest score after unsupervised label propagation is selected as the opinion target.", "labels": [], "entities": []}, {"text": "Our contributions in this study are summarized as follows: 1) our method considers not only the explicit opinion targets within the sentence but also the implicit opinion targets in the hashtag or mentioned in the previous sentence.", "labels": [], "entities": []}, {"text": "2) We develop an efficient algorithm to segment Chinese hashtags.", "labels": [], "entities": [{"text": "segment Chinese hashtags", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.7758775949478149}]}, {"text": "It can successfully identify out-ofvocabulary words by leveraging contextual information and help to improve the segmentation performance of the messages in the topic.", "labels": [], "entities": []}, {"text": "3) We develop an unsupervised label propagation algorithm for collective opinion target extraction.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7319582551717758}, {"text": "collective opinion target extraction", "start_pos": 62, "end_pos": 98, "type": "TASK", "confidence": 0.6994573175907135}]}, {"text": "Label propagation () aims to spread label distributions from a small training set throughout the graph.", "labels": [], "entities": [{"text": "Label propagation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8115888237953186}]}, {"text": "However, our unsupervised algorithm leverages the connection between two adjacent unlabeled nodes to find the correct labels for both of them.", "labels": [], "entities": []}, {"text": "The proposed unsupervised method does not need any training corpus which will cost much human labor especially for fine-grained annotation.", "labels": [], "entities": []}, {"text": "4) To the best of our knowledge, the task of opinion target extraction in microblogs has not been well studied yet.", "labels": [], "entities": [{"text": "opinion target extraction", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6432960132757822}]}, {"text": "It is more challenging than microblog sentiment classification and opinion target extraction in review texts.", "labels": [], "entities": [{"text": "microblog sentiment classification", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.7241086661815643}, {"text": "opinion target extraction", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.668923407793045}]}], "datasetContent": [{"text": "We use the dataset from the 2012 Chinese Microblog Sentiment Analysis Evaluation (CMSAE) held by China Computer Federation (CCF).", "labels": [], "entities": [{"text": "Chinese Microblog Sentiment Analysis Evaluation (CMSAE) held by China Computer Federation (CCF)", "start_pos": 33, "end_pos": 128, "type": "TASK", "confidence": 0.6278970055282116}]}, {"text": "There are three tasks in the evaluation: subjectivity classification, polarity classification and opinion target extraction.", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.7179226875305176}, {"text": "polarity classification", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.7146972417831421}, {"text": "opinion target extraction", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.6320730348428091}]}, {"text": "The dataset contains 20 topics collected from Tencent Weibo, a popular Chinese microblogging website.", "labels": [], "entities": []}, {"text": "All the messages in a topic contain the same hashtag.", "labels": [], "entities": []}, {"text": "The dataset has a total http://tcci.ccf.org.cn/conference/2012/pages/page04_eva. html.", "labels": [], "entities": []}, {"text": "The dataset can also be publicly accessed on the website. of 17518 messages and 31675 sentences.", "labels": [], "entities": []}, {"text": "In each topic, 100 messages are manually annotated with subjectivity, polarity and opinion targets.", "labels": [], "entities": []}, {"text": "A total of 2361opinion targets are annotated for 2152 opinionated sentences.", "labels": [], "entities": []}, {"text": "Precision, recall and F-measure are used in the evaluation.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.995665967464447}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9992431402206421}, {"text": "F-measure", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9991200566291809}]}, {"text": "Since expression boundaries are hard to define exactly in annotation guidelines (), both the strict evaluation metric and the soft evaluation metric are used in CMSAE.", "labels": [], "entities": []}, {"text": "Strict Evaluation: For a proposed opinion target, it is regarded as correct only if it covers the same span with the annotation result.", "labels": [], "entities": []}, {"text": "Note that, in CMSAE, an opinion target should be proposed along with its polarity.", "labels": [], "entities": [{"text": "CMSAE", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.8882433772087097}]}, {"text": "The correctness of the polarity is also necessary.", "labels": [], "entities": [{"text": "correctness", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9844314455986023}]}, {"text": "Soft Evaluation: The soft evaluation metric presented in) is adopted by CMSAE.", "labels": [], "entities": [{"text": "CMSAE", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.9536269307136536}]}, {"text": "The span coverage c between each pair of the proposed target span sand the gold standard span s' is calculated as follows, In Equation 12, the operator |\u00b7 | counts Chinese characters, and the intersection \u2229 gives the set of characters that two spans have in common.", "labels": [], "entities": []}, {"text": "Using the span coverage, the span set coverage C of a set of spans S with respect to another set S' The soft precision P and recall R of a proposed set of spans\u02c6Sspans\u02c6 spans\u02c6S with respect to a gold standard set S is defined as follows: Note that the operator |\u00b7 | counts spans in Equation 14.", "labels": [], "entities": [{"text": "soft precision P", "start_pos": 104, "end_pos": 120, "type": "METRIC", "confidence": 0.7948817809422811}, {"text": "recall R", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9728560149669647}]}, {"text": "The soft F-measure is the harmonic mean of soft precision and recall.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9043534398078918}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9850929379463196}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9966212511062622}]}], "tableCaptions": [{"text": " Table 3. Comparison results with baseline methods (only gold-standard opinionated sentences are used)", "labels": [], "entities": []}, {"text": " Table 2. Comparison results with CMSAE teams (with subjectivity and polarity classification in advance)", "labels": [], "entities": [{"text": "CMSAE", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.9078264832496643}]}, {"text": " Table 4. The second column shows  the number of all extracted candidates for all the  opinionated sentences by different methods. The  third column shows the number of correct opinion  targets among them. We can find that the two rule- based models both outperform Berkeley Parser  and our HS+Rule method finds 14% more correct  opinion targets than Rule. It proves the effective- ness of our hashtag segmentation algorithm. The", "labels": [], "entities": [{"text": "hashtag segmentation", "start_pos": 394, "end_pos": 414, "type": "TASK", "confidence": 0.7120862156152725}]}, {"text": " Table 3.  The above results reveal that our proposed unsu- pervised label propagation algorithm works well  in pseudo topics and the performance can be in- creased with better clustering results. Therefore,  we can try to incorporate other social network in- formation to improve the message clustering per- formance, which will be studied in our future  work.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7683407962322235}]}, {"text": " Table 5. Performance of clustering and opinion  target extraction", "labels": [], "entities": [{"text": "opinion  target extraction", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.6617206931114197}]}]}