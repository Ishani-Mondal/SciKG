{"title": [{"text": "Flexible and Efficient Hypergraph Interactions for Joint Hierarchical and Forest-to-String Decoding *", "labels": [], "entities": []}], "abstractContent": [{"text": "Machine translation benefits from system combination.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7808935940265656}]}, {"text": "We propose flexible interaction of hypergraphs as a novel technique combining different translation models within one de-coder.", "labels": [], "entities": []}, {"text": "We introduce features controlling the interactions between the two systems and explore three interaction schemes of hiero and forest-to-string models-specification, generalization , and interchange.", "labels": [], "entities": []}, {"text": "The experiments are carried out on large training data with strong baselines utilizing rich sets of dense and sparse features.", "labels": [], "entities": []}, {"text": "All three schemes significantly improve results of any single system on four testsets.", "labels": [], "entities": []}, {"text": "We find that specification-a more constrained scheme that almost entirely uses forest-to-string rules, but optionally uses hiero rules for shorter spans-comes out as the strongest, yielding improvement up to 0.9 (Ter-Bleu)/2 points.", "labels": [], "entities": []}, {"text": "We also provide a detailed experimental and qualitative analysis of the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have witnessed the success of various statistical machine translation (SMT) models using different levels of linguistic knowledgephrase (, hiero, and syntax-based (;).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 51, "end_pos": 88, "type": "TASK", "confidence": 0.7805000940958658}]}, {"text": "System combination became a promising way of building up synergy from different SMT systems and their specific merits.", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9788845777511597}]}, {"text": "Numerous efforts that have been proposed in this field recently can be broadly divided into two cat- * M.", "labels": [], "entities": []}, {"text": "M. contributed equally to this work.", "labels": [], "entities": []}, {"text": "egories: Offline system combination () aims at producing consensus translations from the outputs of multiple individual systems.", "labels": [], "entities": []}, {"text": "Those outputs usually contain k-best lists of translations, which only explore a small portion of the entire search space of each system.", "labels": [], "entities": []}, {"text": "This issue is well addressed in joint decoding (), or online system combination, showing comparable improvements to the offline combination methods.", "labels": [], "entities": []}, {"text": "Rather than finding consensus translations from the outputs of individual systems, joint decoding works with different grammars at the decoding time.", "labels": [], "entities": []}, {"text": "Although limited to individual systems sharing the same search paradigm (e.g. left-to-right or bottom-up), joint decoding offers many potential advatages: search through a larger space, better efficiency, features designed once for all subsystems, potential cross-system features, online sharing of partial hypotheses, and many others.", "labels": [], "entities": []}, {"text": "Different approaches have different strengths in general-hiero rules are believed to provide reliable lexical coverage, while tree-to-string rules are good at non-local reorderings.", "labels": [], "entities": []}, {"text": "Different contexts present different challenges-noun phrases usually follow the adjacency principle, while verb phrases require more challenging reorderings.", "labels": [], "entities": []}, {"text": "In this work, we study different schemes of interaction between translation models, reflecting their specific strengths at different (syntactic) contexts.", "labels": [], "entities": []}, {"text": "We make five new contributions: First, we propose a framework for joint decoding by means of flexible combination of translation hypergraphs, allowing for detailed con-trol of interactions between the different systems using soft constraints (Section 3).", "labels": [], "entities": []}, {"text": "Second, we study three interaction schemesspecial cases of joint decoding: generalization, specification, and interchange (Section 3.3).", "labels": [], "entities": []}, {"text": "Third, instead of using a tree-to-string system, we use a much stronger forest-to-string system with fuzzy match of nonterminal categories (Section 2.1).", "labels": [], "entities": []}, {"text": "Fourth, we train strong systems on a largescale data set, and test all methods on four test sets.", "labels": [], "entities": []}, {"text": "Experimental results (Section 6) show that our new approach brings improvement of up to 0.9 points in terms of (Ter \u2212 Bleu)/2 over the best single system.", "labels": [], "entities": [{"text": "Ter \u2212 Bleu)/2", "start_pos": 112, "end_pos": 125, "type": "METRIC", "confidence": 0.8149587631225585}]}, {"text": "Fifth, we conduct a comprehensive experimental analysis, and find that joint decoding actually prefers tree-to-string rules in both shorter and longer spans.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: We briefly review the individual models in Section 2, describe the method of joint decoding using three alternative interaction schemes in Section 3, describe the features controlling the interactions and fuzzy match in Section 4, review the related work in Section 5, and finally, describe our experiments and give detailed discussion of the results in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the setup, present results, and analyze the experiments.", "labels": [], "entities": []}, {"text": "Finally, we propose future directions of research.", "labels": [], "entities": []}, {"text": "Here we allow U = W, which can be viewed in such away that exact match is a special case of fuzzy match.", "labels": [], "entities": []}, {"text": "We also carried out an alternative experiment with only three fuzzy match features estimated from the training data parse forest by Na\u00a8\u0131veNa\u00a8\u0131ve Bayes by observing all spans in the training data, accumulating counts C s (U) and C s (U, W) of nonterminals (or pairs of nonterminals) heading the same span s.", "labels": [], "entities": [{"text": "training data parse forest", "start_pos": 102, "end_pos": 128, "type": "DATASET", "confidence": 0.7939042299985886}]}, {"text": "The first two features (one for each direction) are based on conditional probabilities: The third feature is based on joint probability: The average performance drops by 0.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: All results of single and joint decoding systems.", "labels": [], "entities": []}, {"text": " Table 3: Examples of specification, generalization, and interchange weights. POS tags in italics.", "labels": [], "entities": []}, {"text": " Table 5: Rule interactions on GALE-web test set.", "labels": [], "entities": [{"text": "GALE-web test set", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9022612770398458}]}, {"text": " Table 4: Rule counts on GALE-web test set.", "labels": [], "entities": [{"text": "GALE-web test set", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9048572778701782}]}]}