{"title": [], "abstractContent": [{"text": "The identification of pseudepigraphic texts-texts not written by the authors to which they are attributed-has important historical, forensic and commercial applications.", "labels": [], "entities": [{"text": "identification of pseudepigraphic texts-texts not written by the authors", "start_pos": 4, "end_pos": 76, "type": "TASK", "confidence": 0.8329975538783603}]}, {"text": "We introduce an unsupervised technique for identifying pseudepigrapha.", "labels": [], "entities": [{"text": "identifying pseudepigrapha", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.7790597379207611}]}, {"text": "The idea is to identify textual outliers in a corpus based on the pair-wise similarities of all documents in the corpus.", "labels": [], "entities": []}, {"text": "The crucial point is that document similarity not be measured in any of the standard ways but rather be based on the output of a recently introduced algorithm for authorship verification.", "labels": [], "entities": [{"text": "similarity", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.8439279198646545}, {"text": "authorship verification", "start_pos": 163, "end_pos": 186, "type": "TASK", "confidence": 0.9106906354427338}]}, {"text": "The proposed method strongly outperforms existing techniques in systematic experiments on a blog corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Shakespeare attribution problem is centuries old and shows no signs of abating.", "labels": [], "entities": [{"text": "Shakespeare attribution", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6489017903804779}]}, {"text": "Some scholars argue that some, or even all, of Shakespeare's works were not actually written by him.", "labels": [], "entities": []}, {"text": "The most mainstream theory -and the one that interests us here -is that most of the works were written by Shakespeare, but that several of them were not.", "labels": [], "entities": []}, {"text": "Could modern methods of computational authorship attribution be used to detect which, if any, of the works attributed to Shakespeare were not written by him?", "labels": [], "entities": [{"text": "computational authorship attribution", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.6246733566125234}]}, {"text": "More generally, this paper deals with the unsupervised problem of detecting pseudepigrapha: documents in a supposedly single-author corpus that were not actually written by the corpus's presumed author.", "labels": [], "entities": []}, {"text": "Studies as early as, have observed that texts by a single author tend to be somewhat homogeneous in style.", "labels": [], "entities": []}, {"text": "If this is indeed the case, we would expect that pseudepigrapha would be detectable as outliers.", "labels": [], "entities": []}, {"text": "Identifying such outlier texts is, of course, a special case of general outlier identification, one of the central tasks of statistics.", "labels": [], "entities": [{"text": "Identifying such outlier texts", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8458946049213409}, {"text": "general outlier identification", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.6004370947678884}]}, {"text": "We will thus consider the pseudepigrapha problem in the context of the more general outlier detection problem.", "labels": [], "entities": [{"text": "outlier detection", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7674382925033569}]}, {"text": "Typically, research on textual outliers assumes that we have a corpus of known authentic documents and are asked to decide if a specified other document is authentic or not.", "labels": [], "entities": []}, {"text": "One crucial aspect of our problem is that we do not assume that any specific text in a corpus is known a priori to be authentic or pseudepigraphic; we can assume only that most of the documents in the corpus are authentic.", "labels": [], "entities": []}, {"text": "The method we introduce in this paper builds on the approach of for determining if two documents are by the same author.", "labels": [], "entities": []}, {"text": "We apply that method to every pair of documents in a corpus and use properties of the resulting adjacency graph to identify outliers.", "labels": [], "entities": []}, {"text": "In the following section, we briefly outline previous work.", "labels": [], "entities": []}, {"text": "In Section 3 we provide a framework for outlier detection and in Section 4 we describe our method.", "labels": [], "entities": [{"text": "outlier detection", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7144591957330704}]}, {"text": "In Section 5 we describe the experimental setting and give results and in Section 6 we present results for the plays of Shakespeare.", "labels": [], "entities": []}], "datasetContent": [{"text": "We begin by assembling a corpus consisting of 3540 blog posts written by 156 different bloggers.", "labels": [], "entities": []}, {"text": "The blogs are taken from the blog corpus assembled by for use in authorship attribution tasks.", "labels": [], "entities": []}, {"text": "Each of the blogs was written in English by a single author in 2004 and each post consists of 1000 words (excess is truncated).", "labels": [], "entities": []}, {"text": "For our initial experiments, each trial consists of 10 blog posts, all but p of which are by a single blogger.", "labels": [], "entities": []}, {"text": "The number of pseudepigraphic documents, p, is chosen from a uniform distribution over the set {0,1,2,3}.", "labels": [], "entities": []}, {"text": "Our task is to identify which, if any, documents in the set are not by the main author of the set.", "labels": [], "entities": []}, {"text": "The pseudepigraphic documents might be written by a single author or by multiple authors.", "labels": [], "entities": []}, {"text": "To measure the performance of a given similarity measure sim, we do the following in each trial: 1.", "labels": [], "entities": []}, {"text": "Represent each document in the trial set D in terms of BOW.", "labels": [], "entities": [{"text": "BOW", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9971056580543518}]}, {"text": "2. Measure the similarity of each pair of documents in the trial set using the similarity measure sim.", "labels": [], "entities": []}, {"text": "3. Using some aggregation function agg, compute for each document d i : (where \u03b8 is a parameter ).", "labels": [], "entities": []}, {"text": "Our objective is to show that results using second-order similarity are stronger than those using first-order similarity.", "labels": [], "entities": []}, {"text": "Before we do this, we need to determine the best aggregation function to use in our experiments.", "labels": [], "entities": []}, {"text": "In, we show recall-precision breakeven values (for the outlier class) over 250 independent trials, for each of our four first-order similarity measures (inverse Euclidean, inverse Manhattan, cosine, min-max) used in conjunction with each of four aggregation functions (centroid, mean, k-NN mean, median).", "labels": [], "entities": [{"text": "recall-precision breakeven", "start_pos": 12, "end_pos": 38, "type": "METRIC", "confidence": 0.8394677937030792}]}, {"text": "As is evident, k-NN is the best aggregation function in each case.", "labels": [], "entities": []}, {"text": "We will give these baseline methods an advantage by using k-NN as our aggregation function in all our subsequent experiments.", "labels": [], "entities": []}, {"text": "We are now ready to perform our main experiment.", "labels": [], "entities": []}, {"text": "We use BOW as our feature set and k-NN as our aggregation function.", "labels": [], "entities": [{"text": "BOW", "start_pos": 7, "end_pos": 10, "type": "METRIC", "confidence": 0.9890455007553101}]}, {"text": "We use 500 random blog posts as our impostor set.", "labels": [], "entities": []}, {"text": "In, we show recall-precision curves for outlier documents over 250 independent trials, as just described, using four first-order similarity measures as well our second-order similarity measure using each of the four as abase measure.", "labels": [], "entities": [{"text": "recall-precision", "start_pos": 12, "end_pos": 28, "type": "METRIC", "confidence": 0.9965236783027649}]}, {"text": "As can be seen, even the worst second-order similarity measure significantly outperforms all the standard first-order measures.", "labels": [], "entities": []}, {"text": "In, we show the breakeven values for each measure, pairing each first-order measure with the second-order measure that uses it as abase.", "labels": [], "entities": [{"text": "breakeven", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9530773758888245}]}, {"text": "Clearly, the mere use of a second-order method improves results, regardless of the base measure.", "labels": [], "entities": []}], "tableCaptions": []}