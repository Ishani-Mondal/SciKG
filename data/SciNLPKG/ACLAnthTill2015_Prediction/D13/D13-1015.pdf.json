{"title": [{"text": "Studying the recursive behaviour of adjectival modification with compositional distributional semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "In this study, we use compositional distribu-tional semantic methods to investigate restrictions in adjective ordering.", "labels": [], "entities": []}, {"text": "Specifically, we focus on properties distinguishing Adjective-Adjective-Noun phrases in which there is flexibility in the adjective ordering from those bound to a rigid order.", "labels": [], "entities": []}, {"text": "We explore a number of measures extracted from the distributional representation of AAN phrases which may indicate a word order restriction.", "labels": [], "entities": []}, {"text": "We find that we are able to distinguish the relevant classes and the correct order based primarily on the degree of modification of the adjectives.", "labels": [], "entities": []}, {"text": "Our results offer fresh insight into the semantic properties that determine adjective ordering, building abridge between syntax and distri-butional semantics.", "labels": [], "entities": [{"text": "adjective ordering", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7295450270175934}]}], "introductionContent": [{"text": "A prominent approach for representing the meaning of a word in Natural Language Processing (NLP) is to treat it as a numerical vector that codes the pattern of co-occurrence of that word with other expressions in a large corpus of language.", "labels": [], "entities": [{"text": "representing the meaning of a word in Natural Language Processing (NLP)", "start_pos": 25, "end_pos": 96, "type": "TASK", "confidence": 0.718710699906716}]}, {"text": "This approach to semantics (sometimes called distributional semantics) scales well to large lexicons and does not require words to be manually disambiguated.", "labels": [], "entities": []}, {"text": "Until recently, however, this method had been almost exclusively limited to the level of single content words (nouns, adjectives, verbs), and had not directly addressed the problem of compositionality), the crucial property of natural language which allows speakers to derive the meaning of a complex linguistic constituent from the meaning of its immediate syntactic subconstituents.", "labels": [], "entities": []}, {"text": "Several recent proposals have strived to extend distributional semantics with a component that also generates vectors for complex linguistic constituents, using compositional operations in the vector space ().", "labels": [], "entities": []}, {"text": "All of these approaches construct distributional representations for novel phrases starting from the corpusderived vectors for their lexical constituents and exploiting the geometric quality of the representation.", "labels": [], "entities": []}, {"text": "Such methods are able to capture complex semantic information of adjective-noun (AN) phrases, such as characterizing modification, and can detect semantic deviance in novel phrases).", "labels": [], "entities": [{"text": "characterizing modification", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.956791341304779}]}, {"text": "Furthermore, these methods are naturally recursive: they can derive a representation not only for, e.g., red car, but also for new red car, fast new red car, etc.", "labels": [], "entities": []}, {"text": "This aspect is appealing since trying to extract meaningful representations for all recursive phrases directly from a corpus will result in a problem of sparsity, since most large phrases will never occur in any finite sample.", "labels": [], "entities": []}, {"text": "Once we start seriously looking into recursive modification, however, the issue of modifier ordering restrictions naturally arises.", "labels": [], "entities": []}, {"text": "Such restrictions have often been discussed in the theoretical linguistic literature), and have become one of the key in-gredients of the 'cartographic' approach to syntax.", "labels": [], "entities": []}, {"text": "In this paradigm, the ordering is derived by assigning semantically different classes of modifiers to the specifiers of distinct functional projections, whose sequence is hard-wired.", "labels": [], "entities": []}, {"text": "While it is accepted that in different languages movement can lead to a principled rearrangement of the linear order of the modifiers), one key assumption of the cartographic literature is that exactly one intonationally unmarked order for stacked adjectives should be possible in languages like English.", "labels": [], "entities": []}, {"text": "The possibility of alternative orders, when discussed at all, is attributed to the presence of idioms (high American building, but American high officer), to asyndetic conjunctive meanings (e.g. new creative idea parsed as , or to semantic category ambiguity for any adjective which appears in different orders (see Cinque (2004) for discussion).", "labels": [], "entities": []}, {"text": "In this study, we show that the existence of both rigid and flexible order cases is robustly attested at least for adjectival modification, and that flexible ordering is unlikely to reduce to idioms, coordination or ambiguity.", "labels": [], "entities": [{"text": "adjectival modification", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.7169948816299438}]}, {"text": "Moreover, we show that at least for some recursively constructed adjective-adjectivenoun phrases (AANs) we can extract meaningful representations from the corpus, approximating them reasonably well by means of compositional distributional semantic models, and that the semantic information contained in these models characterizes which AA will have rigid order (as with rapid social change vs. *social rapid change), or flexible order (e.g. total estimated population vs. estimated total population).", "labels": [], "entities": []}, {"text": "In the former case, we find that the same distributional semantic cues discriminate between correct and wrong orders.", "labels": [], "entities": []}, {"text": "To achieve these goals, we consider various properties of the distributional representation of AANs (both corpus-extracted and compositionallyderived), and explore their correlation with restrictions in adjective ordering.", "labels": [], "entities": []}, {"text": "We conclude that measures that quantify the degree to which the modifiers have an impact on the distributional meaning of the AAN can be good predictors of ordering restrictions in AANs.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Correlation scores (Spearman's \u03c1, all signif- icant at p <0.001) between cosines of corpus-extracted  or model-generated AN vectors and phrase similarity rat- ings collected in Mitchell and Lapata (2010), as well as  best reported results from Mitchell & Lapata (M&L).", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9538272023200989}, {"text": "Spearman's \u03c1", "start_pos": 30, "end_pos": 42, "type": "METRIC", "confidence": 0.7498738765716553}]}, {"text": " Table 3: Mean cosine similarities between the corpus- extracted and model-generated gold AAN vectors. All  pairwise differences between models are significant ac- cording to Bonferroni-corrected paired t-tests (p<0.001).", "labels": [], "entities": [{"text": "ac- cording", "start_pos": 160, "end_pos": 171, "type": "METRIC", "confidence": 0.9237449169158936}]}, {"text": " Table 4: Flexible vs. Rigid Order AANs. t-normalized  differences between flexible order (FO) and rigid order  (FO) mean cosines (or mean \u2206PMI values) for corpus- extracted and model-generated vectors. For significant  differences (p<0.05 after Bonferroni correction), the last  column reports whether mean cosine (or \u2206PMI) is larger  for flexible order (FO) or rigid order (RO) class.", "labels": [], "entities": []}]}