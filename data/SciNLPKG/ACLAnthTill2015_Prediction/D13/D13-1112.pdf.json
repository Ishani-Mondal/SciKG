{"title": [{"text": "Max-Violation Perceptron and Forced Decoding for Scalable MT Training", "labels": [], "entities": [{"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.7693953514099121}]}], "abstractContent": [{"text": "While large-scale discriminative training has triumphed in many NLP problems, its definite success on machine translation has been largely elusive.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.8303504884243011}]}, {"text": "Most recent efforts along this line are not scalable (training on the small dev set with features from top \u223c100 most frequent words) and overly complicated.", "labels": [], "entities": []}, {"text": "We instead present a very simple yet theoretically motivated approach by extending the recent framework of \"violation-fixing perceptron\", using forced decoding to compute the target derivations.", "labels": [], "entities": []}, {"text": "Extensive phrase-based translation experiments on both Chinese-to-English and Spanish-to-English tasks show substantial gains in BLEU by up to +2.3/+2.0 on dev/test over MERT, thanks to 20M+ sparse features.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.5906721502542496}, {"text": "BLEU", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9980965256690979}]}, {"text": "This is the first successful effort of large-scale online discriminative training for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9935929179191589}]}], "introductionContent": [{"text": "Large-scale discriminative training has witnessed great success in many NLP problems such as parsing () and tagging), but not yet for machine translation (MT) despite numerous recent efforts.", "labels": [], "entities": [{"text": "parsing", "start_pos": 93, "end_pos": 100, "type": "TASK", "confidence": 0.943374752998352}, {"text": "tagging", "start_pos": 108, "end_pos": 115, "type": "TASK", "confidence": 0.8083957433700562}, {"text": "machine translation (MT)", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.8366345047950745}]}, {"text": "Due to scalability issues, most of these recent methods can only train on a small dev set of about a thousand sentences rather than on the full training set, and only with 2,000-10,000 rather \"dense-like\" features (either unlexicalized or only considering highest-frequency words), as in MIRA (,, and RAMP (.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 288, "end_pos": 292, "type": "DATASET", "confidence": 0.5077818036079407}, {"text": "RAMP", "start_pos": 301, "end_pos": 305, "type": "METRIC", "confidence": 0.7068530321121216}]}, {"text": "However, it is well-known that the most important features for NLP are lexicalized, most of which cannot * Work done while visiting City University of New York.", "labels": [], "entities": []}, {"text": "be seen on a small dataset.", "labels": [], "entities": []}, {"text": "Furthermore, these methods often involve complicated loss functions and intricate choices of the \"target\" derivations to update towards or against (e.g. k-best/forest oracles, or hope/fear derivations), and are thus hard to replicate.", "labels": [], "entities": []}, {"text": "As a result, the classical method of MERT remains the default training algorithm for MT even though it can only tune a handful of dense features.", "labels": [], "entities": [{"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.991174578666687}]}, {"text": "See also Section 6 for other related work.", "labels": [], "entities": []}, {"text": "As a notable exception, do train a structured perceptron model on the training data with sparse features, but fail to outperform MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 129, "end_pos": 133, "type": "DATASET", "confidence": 0.5030988454818726}]}, {"text": "We argue this is because structured perceptron, like many structured learning algorithms such as CRF and MIRA, assumes exact search, and search errors inevitably break theoretical properties such as convergence ( . Empirically, it is now well accepted that standard perceptron performs poorly when search error is severe ().", "labels": [], "entities": [{"text": "MIRA", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.6475151181221008}]}, {"text": "To address the search error problem we propose a very simple approach based on the recent framework of \"violation-fixing perceptron\" (  which is designed specifically for inexact search, with a theoretical convergence guarantee and excellent empirical performance on beam search parsing and tagging.", "labels": [], "entities": [{"text": "beam search parsing", "start_pos": 267, "end_pos": 286, "type": "TASK", "confidence": 0.6901218493779501}]}, {"text": "The basic idea is to update when search error happens, rather than at the end of the search.", "labels": [], "entities": []}, {"text": "To adapt it to MT, we extend this framework to handle latent variables corresponding to the hidden derivations.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9040229320526123}]}, {"text": "We update towards \"gold-standard\" derivations computed by forced decoding so that each derivation leads to the exact reference translation.", "labels": [], "entities": []}, {"text": "Forced decoding is also used as away of data selection, since those reachable sentence pairs are generally more literal and of higher quality, which the training should focus on.", "labels": [], "entities": [{"text": "data selection", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.760545015335083}]}, {"text": "When the reachable subset is small for some language pairs, we augment it by including reachable prefix-pairs when the full sentence pair is not.", "labels": [], "entities": []}, {"text": "We make the following contributions: 1.", "labels": [], "entities": []}, {"text": "Our work is the first successful effort to scale online structured learning to a large portion of the training data (as opposed to the dev set).", "labels": [], "entities": []}, {"text": "2. Our work is the first to use a principled learning method customized for inexact search which updates on partial derivations rather than full ones in order to fix search errors.", "labels": [], "entities": []}, {"text": "We adapt it to MT using latent variables for derivations.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9246317744255066}]}, {"text": "3. Contrary to the common wisdom, we show that simply updating towards the exact reference translation is helpful, which is much simpler than k-best/forest oracles or loss-augmented (e.g. hope/fear) derivations, avoiding sentencelevel BLEU scores or other loss functions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 235, "end_pos": 239, "type": "METRIC", "confidence": 0.9757078289985657}]}, {"text": "4. We present a convincing analysis that it is the search errors and standard perceptron's inability to deal with them that prevent previous work, esp., from succeeding.", "labels": [], "entities": []}, {"text": "5. Scaling to the training data enables us to engineer a very rich feature set of sparse, lexicalized, and non-local features, and we propose various ways to alleviate overfitting.", "labels": [], "entities": []}, {"text": "For simplicity and efficiency reasons, in this paper we use phrase-based translation, but our method has the potential to be applicable to other translation paradigms.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.7800018787384033}]}, {"text": "Extensive experiments on both Chineseto-English and Spanish-to-English tasks show statistically significant gains in BLEU by up to +2.3/+2.0 on dev/test over MERT, and up to +1.5/+1.5 over PRO, thanks to 20M+ sparse features.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.9988396763801575}, {"text": "MERT", "start_pos": 158, "end_pos": 162, "type": "DATASET", "confidence": 0.5849018692970276}, {"text": "PRO", "start_pos": 189, "end_pos": 192, "type": "DATASET", "confidence": 0.7902595400810242}]}], "datasetContent": [{"text": "In order to test our approach in different language pairs, we conduct three experiments, shown in Table 2, on two significantly different language pairs (long vs. short distance reorderings), Chinese-toEnglish (CH-EN) and Spanish-to-English (SP-EN).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Various levels of backoff for WordEdges fea- tures. Class size is estimated on the small Chinese- English dataset (Sec. 5.3). The POS tagsets are ICT- CLAS for Chinese (Zhang et al., 2003) and Penn Tree- bank for English (Marcus et al., 1993).", "labels": [], "entities": [{"text": "Penn Tree- bank", "start_pos": 203, "end_pos": 218, "type": "DATASET", "confidence": 0.9198519140481949}]}, {"text": " Table 2: Overview of all experiments. The \u2206BLEU column shows the absolute improvements of our method MAX- FORCE on dev/test sets over MERT. The Chinese datasets also use prefix-pairs in training (see", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9833582043647766}, {"text": "MAX- FORCE", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.826124886671702}, {"text": "Chinese datasets", "start_pos": 145, "end_pos": 161, "type": "DATASET", "confidence": 0.7087263613939285}]}, {"text": " Table 3: Ratio of sentence reachability and word cover- age on the two CH-EN training data (distortion limit: 6).", "labels": [], "entities": [{"text": "sentence reachability", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.7213419377803802}, {"text": "word cover- age", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.6656839400529861}, {"text": "CH-EN training data", "start_pos": 72, "end_pos": 91, "type": "DATASET", "confidence": 0.8337869445482889}]}, {"text": " Table 4: Feature counts and incremental BLEU improve- ments. MAXFORCE with all features is +2.2 over MERT.", "labels": [], "entities": [{"text": "BLEU improve- ments", "start_pos": 41, "end_pos": 60, "type": "METRIC", "confidence": 0.9579481780529022}, {"text": "MAXFORCE", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9003662467002869}, {"text": "MERT", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.5137056112289429}]}, {"text": " Table 5: BLEU scores (with four references) using the  large CH-EN data. Our approach is +2.3/2.0 over MERT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990220069885254}, {"text": "CH-EN data", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.8587087988853455}, {"text": "MERT", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.645481288433075}]}, {"text": " Table 6: BLEU scores (with one reference) on SP-EN.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991946816444397}]}]}