{"title": [{"text": "Decipherment with a Million Random Restarts", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper investigates the utility and effect of running numerous random restarts when using EM to attack decipherment problems.", "labels": [], "entities": []}, {"text": "We find that simple decipherment models are able to crack homophonic substitution ciphers with high accuracy if a large number of random restarts are used but almost completely fail with only a few random restarts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9973320960998535}]}, {"text": "For particularly difficult homophonic ciphers, we find that big gains inaccuracy are to be had by running upwards of 100K random restarts, which we accomplish efficiently using a GPU-based parallel implementation.", "labels": [], "entities": []}, {"text": "We run a series of experiments using millions of random restarts in order to investigate other empirical properties of decipherment problems, including the famously uncracked Zodiac 340.", "labels": [], "entities": []}], "introductionContent": [{"text": "What can a million restarts do for decipherment?", "labels": [], "entities": []}, {"text": "EM frequently gets stuck in local optima, so running between ten and a hundred random restarts is common practice ().", "labels": [], "entities": [{"text": "EM", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.5490109920501709}]}, {"text": "But, how important are random restarts and how many random restarts does it take to saturate gains in accuracy?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9987986087799072}]}, {"text": "We find that the answer depends on the cipher.", "labels": [], "entities": []}, {"text": "We look at both Zodiac 408, a famous homophonic substitution cipher, and a more difficult homophonic cipher constructed to match properties of the famously unsolved Zodiac 340.", "labels": [], "entities": []}, {"text": "Gains inaccuracy saturate after only a hundred random restarts for Zodiac 408, but for the constructed cipher we see large gains inaccuracy even as we scale the number of random restarts up into the hundred thousands.", "labels": [], "entities": []}, {"text": "In both cases the difference between few and many random restarts is the difference between almost complete failure and successful decipherment.", "labels": [], "entities": []}, {"text": "We also find that millions of random restarts can be helpful for performing exploratory analysis.", "labels": [], "entities": [{"text": "exploratory analysis", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.8376934826374054}]}, {"text": "We look at some empirical properties of decipherment problems, visualizing the distribution of local optima encountered by EM both in a successful decipherment of a homophonic cipher and in an unsuccessful attempt to decipher Zodiac 340.", "labels": [], "entities": []}, {"text": "Finally, we attack a series of ciphers generated to match properties of Zodiac 340 and use the results to argue that Zodiac 340 is likely not a homophonic cipher under the commonly assumed linearization order.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran experiments on several homophonic substitution ciphers: some produced by the infamous Zodiac killer and others that were automatically generated to be similar to the Zodiac ciphers.", "labels": [], "entities": []}, {"text": "In each of these experiments, we ran numerous random restarts; and in all cases we chose the random restart that attained the highest model score in order to produce the final decode.", "labels": [], "entities": []}, {"text": "The specifics of how random restarts are produced is usually considered a detail; however, in this work it is important to describe the process precisely.", "labels": [], "entities": []}, {"text": "In order to generate random restarts, we sampled emission parameters by drawing uniformly at random from the interval and then normalizing.", "labels": [], "entities": []}, {"text": "The corresponding distribution on the multinomial emission parameters is mildly concentrated at the center of the simplex.", "labels": [], "entities": []}, {"text": "For each random restart, we ran EM for 200 itera- We used a single workstation with three NVIDIA GTX 580 GPUs.", "labels": [], "entities": [{"text": "EM", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.8154419660568237}]}, {"text": "These are consumer graphics cards introduced in 2011.", "labels": [], "entities": []}, {"text": "We also ran experiments where emission parameters were drawn from Dirichlet distributions with various concentration parameter settings.", "labels": [], "entities": []}, {"text": "We noticed little effect so long as the distribution did not favor the corners of the simplex.", "labels": [], "entities": []}, {"text": "If the distribution did favor the corners of the simplex, decipherment results deteriorated sharply. tions.", "labels": [], "entities": []}, {"text": "We found that smoothing EM was important for good performance.", "labels": [], "entities": [{"text": "smoothing EM", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.8052775263786316}]}, {"text": "We added a smoothing constant of 0.1 to the expected emission counts before each M-step.", "labels": [], "entities": []}, {"text": "We tuned this value on a small held outset of automatically generated ciphers.", "labels": [], "entities": []}, {"text": "In all experiments we used a trigram character language model that was linearly interpolated from character unigram, bigram, and trigram counts extracted from both the Google N-gram dataset) and a small corpus (about 2K words) of plaintext messages authored by the Zodiac killer.", "labels": [], "entities": [{"text": "Google N-gram dataset", "start_pos": 168, "end_pos": 189, "type": "DATASET", "confidence": 0.680664579073588}]}], "tableCaptions": []}