{"title": [{"text": "A Joint Learning Model of Word Segmentation, Lexical Acquisition, and Phonetic Variability", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7492858171463013}]}], "abstractContent": [{"text": "We present a cognitive model of early lexical acquisition which jointly performs word segmentation and learns an explicit model of phonetic variation.", "labels": [], "entities": [{"text": "early lexical acquisition", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.6390478213628134}, {"text": "word segmentation", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7224008291959763}]}, {"text": "We define the model as a Bayesian noisy channel; we sample segmen-tations and word forms simultaneously from the posterior, using beam sampling to control the size of the search space.", "labels": [], "entities": []}, {"text": "Compared to a pipelined approach in which segmentation is performed first, our model is qualitatively more similar to human learners.", "labels": [], "entities": []}, {"text": "On data with variable pronunciations, the pipelined approach learns to treat syllables or morphemes as words.", "labels": [], "entities": []}, {"text": "In contrast, our joint model, like infant learners, tends to learn multiword collocations.", "labels": [], "entities": []}, {"text": "We also conduct analyses of the phonetic variations that the model learns to accept and its patterns of word recognition errors, and relate these to developmental evidence.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.7204003930091858}]}], "introductionContent": [{"text": "By the end of their first year, infants have acquired many of the basic elements of their native language.", "labels": [], "entities": []}, {"text": "Their sensitivity to phonetic contrasts has become language-specific, and they have begun detecting words in fluent speech) and learning word meanings).", "labels": [], "entities": []}, {"text": "These developmental cooccurrences lead some researchers to propose that phonetic and word learning occur jointly, each one informing the other.", "labels": [], "entities": []}, {"text": "Previous computational models capture some aspects of this joint learning problem, but typically simplify the problem considerably, either by assuming an unrealistic degree of phonetic regularity for word segmentation) or assuming pre-segmented input for phonetic and lexical acquisition.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 200, "end_pos": 217, "type": "TASK", "confidence": 0.7073193937540054}, {"text": "phonetic and lexical acquisition", "start_pos": 255, "end_pos": 287, "type": "TASK", "confidence": 0.7149462252855301}]}, {"text": "This paper presents, to our knowledge, the first broadcoverage model that learns to segment phonetically variable input into words, while simultaneously learning an explicit model of phonetic variation that allows it to cluster together segmented tokens with different phonetic realizations (e.g., and) into lexical items (/ju/).", "labels": [], "entities": []}, {"text": "We base our model on the Bayesian word segmentation model of (henceforth GGJ), using a noisy-channel setup where phonetic variation is introduced by a finite-state transducer (.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7074118554592133}]}, {"text": "This integrated model allows us to examine how solving the word segmentation problem should affect infants' strategies for learning about phonetic variability and how phonetic learning can allow word segmentation to proceed in ways that mimic the idealized input used in previous models.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.713211864233017}, {"text": "word segmentation", "start_pos": 195, "end_pos": 212, "type": "TASK", "confidence": 0.7157397866249084}]}, {"text": "In particular, although the GGJ model achieves high segmentation accuracy on phonemic (nonvariable) input and makes errors that are qualitatively similar to human learners (tending to undersegment the input), its accuracy drops considerably on phonetically noisy data and it tends to oversegment rather than undersegment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9653075933456421}, {"text": "accuracy", "start_pos": 213, "end_pos": 221, "type": "METRIC", "confidence": 0.9960969090461731}]}, {"text": "Here, we demonstrate that when the model is augmented to account for phonetic variability, it is able to learn common phonetic changes and by doing so, its accuracy improves and its errors return to the more human-like undersegmentation pattern.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9988102912902832}]}, {"text": "In addition, we find small improvements in lexicon accuracy over a pipeline model that segments first and then performs lexical-phonetic learning (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9627328515052795}]}, {"text": "We analyze the model's phonetic and lexical representations in detail, drawing comparisons to experimental results on adult and infant speech processing.", "labels": [], "entities": []}, {"text": "Taken together, our results support the idea that a Bayesian model that jointly performs word segmentation and phonetic learning provides a plausible explanation for many aspects of early phonetic and word learning in infants.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7233808785676956}]}], "datasetContent": [{"text": "We use the corpus released by, which contains 9790 child-directed English utterances originally from the Bernstein-Ratner corpus and later transcribed phonemically.", "labels": [], "entities": []}, {"text": "This standard word segmentation dataset was modified by to include phonetic variation by assigning each token a pronunciation independently selected from the empirical distribution of pronunciations of that word type in the closely-transcribed Buckeye Speech Corpus (.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7308812141418457}, {"text": "Buckeye Speech Corpus", "start_pos": 244, "end_pos": 265, "type": "DATASET", "confidence": 0.9026555021603903}]}, {"text": "Following previous work, we holdout the last 1790 utterances as unseen test data during development.", "labels": [], "entities": []}, {"text": "In the results presented here, we run the model on all 9790 utterances but score only these 1790.", "labels": [], "entities": []}, {"text": "We average results over 5 runs of the model with different random seeds.", "labels": [], "entities": []}, {"text": "We use standard metrics for segmentation and lexicon recovery.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.9657031893730164}, {"text": "lexicon recovery", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7133323103189468}]}, {"text": "For segmentation, we report precision, recall and F-score for word boundaries (bds), and for the positions of word tokens in the surface string (srf ; both boundaries must be correct).", "labels": [], "entities": [{"text": "segmentation", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9670047760009766}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.999601423740387}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9995597004890442}, {"text": "F-score", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9986120462417603}]}, {"text": "For normalization of the pronunciation variation, we follow in measuring how well the system clusters together variant pronunciations of the same lexical item, without insisting that the intended form the system proposes for them match the one in our corpus.", "labels": [], "entities": [{"text": "normalization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9702666401863098}]}, {"text": "For example, if the system correctly clusters and together but assigns them the incorrect intended form /jI/, we can still give credit to this cluster if it is the one that overlaps best with the gold-standard /ju/ cluster.", "labels": [], "entities": []}, {"text": "To compute these scores, we find the optimal one-to-one mapping between our clusters of pronunciations and the true lexical entries, then report scores for mapped tokens (mtk; boundaries and mapping to gold standard cluster must be correct) and mapped types: Mean segmentation (bds, srf ) and normalization (mtk, mlx) scores on the test set over 5 runs.", "labels": [], "entities": []}, {"text": "Parentheses show min and max scores as differences from the mean.", "labels": [], "entities": [{"text": "min and max scores", "start_pos": 17, "end_pos": 35, "type": "METRIC", "confidence": 0.8536834865808487}]}], "tableCaptions": [{"text": " Table 3: Forms proposed with frequency > 10 for  gold-standard tokens of \"you\" in one sample from EM- transducer and segment-only (GGJ) system.", "labels": [], "entities": []}]}