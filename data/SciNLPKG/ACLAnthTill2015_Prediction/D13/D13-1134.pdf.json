{"title": [{"text": "Predicting the resolution of referring expressions from user behavior", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a statistical model for predicting how the user of an interactive, situated NLP system resolved a referring expression.", "labels": [], "entities": []}, {"text": "The model makes an initial prediction based on the meaning of the utterance, and revises it continuously based on the user's behavior.", "labels": [], "entities": []}, {"text": "The combined model outperforms its components in predicting reference resolution and when to give feedback.", "labels": [], "entities": [{"text": "predicting reference resolution", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.7558942437171936}]}], "introductionContent": [{"text": "Speakers and listeners in natural communication are engaged in a highly interactive process.", "labels": [], "entities": []}, {"text": "In order to achieve some communicative goal, the speaker will perform an utterance which they believe has a high chance of achieving that goal.", "labels": [], "entities": []}, {"text": "They will then monitor the listener's behavior to see whether this goal is actually being achieved.", "labels": [], "entities": []}, {"text": "This process is a core part of what is commonly called grounding in the dialogue literature (see e.g.).", "labels": [], "entities": []}, {"text": "Interactive computer systems that are to carryout an effective and efficient conversation with a user must model this grounding process, and should ideally respond to the user's observed behavior in real time.", "labels": [], "entities": []}, {"text": "For instance, if the user of a pedestrian navigation system takes a wrong turn, the system should interpret this as evidence of misunderstanding and bring the user back on track.", "labels": [], "entities": []}, {"text": "We focus hereon the problem of predicting how the user has resolved a referring expression (RE) that was generated by the system, i.e. a noun phrase that is intended to identify some object uniquely to the listener.", "labels": [], "entities": [{"text": "predicting how the user has resolved a referring expression (RE) that was generated by the system, i.e. a noun phrase that is intended to identify some object uniquely to the listener", "start_pos": 31, "end_pos": 214, "type": "Description", "confidence": 0.6911691059084499}]}, {"text": "A number of authors have recently offered statistical models for parts of this problem. and  have presented log-linear models for predicting how the listener will resolve a given RE in a given scene; however, these models do not update the probability model based on observing the user's reactions.,, and all predict what the listener understood based on their behavior, but do not consider the RE itself in the model.", "labels": [], "entities": []}, {"text": "The models of and aim at explaining the effect of implicatures on the listener's RE resolution process in terms of hypothesized interactions, but do not actually support a realtime interaction between a system and a user.", "labels": [], "entities": [{"text": "RE resolution", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.9457041621208191}]}, {"text": "In this paper, we show how to predict how the listener has resolved an RE by combining a statistical model of RE resolution based on the RE itself with a statistical model of RE resolution based on the listener's behavior.", "labels": [], "entities": [{"text": "RE resolution", "start_pos": 110, "end_pos": 123, "type": "TASK", "confidence": 0.7589679658412933}, {"text": "RE resolution", "start_pos": 175, "end_pos": 188, "type": "TASK", "confidence": 0.7102371752262115}]}, {"text": "To our knowledge, this is the first approach to combine two such models explicitly.", "labels": [], "entities": []}, {"text": "We consider the RE grounding problem in the context of interactive, situated natural language generation (NLG) for the GIVE Challenge (, where NLG systems must generate realtime instructions in virtual 3D environments.", "labels": [], "entities": [{"text": "RE grounding", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.9362955391407013}, {"text": "interactive, situated natural language generation (NLG)", "start_pos": 55, "end_pos": 110, "type": "TASK", "confidence": 0.7857711513837179}]}, {"text": "Our evaluation is based on interaction corpora from the GIVE-2 and GIVE-2.5 Challenges, which contain the systems' utterances along with the behavior of human hearers in response to these utterances.", "labels": [], "entities": [{"text": "GIVE-2", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.9357722997665405}, {"text": "GIVE-2.5 Challenges", "start_pos": 67, "end_pos": 86, "type": "DATASET", "confidence": 0.8215149343013763}]}, {"text": "We find that the combined model predicts RE resolution more accurately than each of the two component models alone.", "labels": [], "entities": [{"text": "RE resolution", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.4961990416049957}]}, {"text": "We see this as a first step towards implementing an actual interactive system that performs human-like grounding based on our RE resolution model.", "labels": [], "entities": [{"text": "RE resolution", "start_pos": 126, "end_pos": 139, "type": "TASK", "confidence": 0.8775489032268524}]}], "datasetContent": [{"text": "Data We evaluated our model using data from the GIVE-2 () and the GIVE-2.5 Challenges (Striegnitz et al., 2011), obtained from GIVE Organizers (2012).", "labels": [], "entities": [{"text": "GIVE-2", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.9472833275794983}, {"text": "GIVE-2.5", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.878789484500885}, {"text": "GIVE Organizers (2012)", "start_pos": 127, "end_pos": 149, "type": "DATASET", "confidence": 0.9107191920280456}]}, {"text": "These datasets constitute interaction corpora, in which the IF's activities in the virtual environment were recorded along with the utterances automatically generated by the participating NLG systems.", "labels": [], "entities": []}, {"text": "The data consists of 1833 games for GIVE-2 and 687 games for GIVE-2.5.", "labels": [], "entities": [{"text": "GIVE-2", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.9536644816398621}, {"text": "GIVE-2.5", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.9782277345657349}]}, {"text": "To extract training data for our model from the GIVE-2.5 data, we first identified moments in the recorded data where the IF pressed a button.", "labels": [], "entities": [{"text": "GIVE-2.5 data", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.8717881441116333}]}, {"text": "From these, we discarded all instances from the tutorial phase of the GIVE game and those that happened within 200 ms after the previous utterance, as these clearly didn't happen in response to it.", "labels": [], "entities": [{"text": "GIVE game", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.7582499980926514}]}, {"text": "This yielded 6478 training instances for p obs , each consisting of \u03c3 at 1 second before the action, and the button a which the IF pressed.", "labels": [], "entities": []}, {"text": "We chosen = 4 for representing \u03c3, except to ensure that the features only considered IF behavior that happened in response to an utterance.", "labels": [], "entities": []}, {"text": "We achieved this by reducing n for the first few frames after each utterance, such that the time of \u03c3 n was always after the time of the utterance.", "labels": [], "entities": []}, {"text": "Finally, we selected those instances which are episodes in the sense of Section 2, i.e. those in which the last utterance before the action contained an RE r.", "labels": [], "entities": [{"text": "RE r", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9818153977394104}]}, {"text": "This gave us 3414 training instances for p sem , each consisting of a, r, the time t 0 of the utterance, and the world state sat time t 0 . We obtained test instances from the GIVE-2 data in the same way.", "labels": [], "entities": [{"text": "GIVE-2 data", "start_pos": 176, "end_pos": 187, "type": "DATASET", "confidence": 0.9457731246948242}]}, {"text": "This yielded 5028 instances, each representing an episode.", "labels": [], "entities": []}, {"text": "We chose GIVE-2 for testing because the mean episode length is higher (3.3s, vs. 2.0s in GIVE-2.5), thus making the evaluation more challenging.", "labels": [], "entities": [{"text": "GIVE-2", "start_pos": 9, "end_pos": 15, "type": "DATASET", "confidence": 0.939556896686554}, {"text": "mean episode length", "start_pos": 40, "end_pos": 59, "type": "METRIC", "confidence": 0.6784569323062897}, {"text": "GIVE-2.5", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9171240329742432}]}, {"text": "Feature selection was done using the training data and a similar dataset from.", "labels": [], "entities": [{"text": "Feature selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7991648614406586}]}, {"text": "Note that the test data and training data are based on distinct sets of three virtual environ- ments each, and were obtained with different NLG systems and users.", "labels": [], "entities": []}, {"text": "This demonstrates the ability of our model to generalize to unseen environments.", "labels": [], "entities": []}, {"text": "An example video showing our models' predictions on some training episodes can be found at http://tinyurl.com/re-demo-v.", "labels": [], "entities": []}, {"text": "Prediction accuracy We first evaluated the ability of our model to predict the button to which the IF resolved each RE.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8154785633087158}, {"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.5137718319892883}, {"text": "RE", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.6564716100692749}]}, {"text": "For each test instance r, s, \u03c3, a, we compare the object returned by arg max a p(a|r, s, \u03c3(t)) to the one manipulated by the IF.", "labels": [], "entities": []}, {"text": "We call the proportion of correctly classified instances the prediction accuracy.", "labels": [], "entities": [{"text": "prediction", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.5150746703147888}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.780494749546051}]}, {"text": "compares our model's prediction accuracy to that of several baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8332729339599609}]}, {"text": "We plot prediction accuracy as a function of the time at which the model is queried fora prediction, by evaluating at 3s, 2s, 1s, and 0s before the button press.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9448278546333313}]}, {"text": "The graph is based on the 2094 test instances with an episode length of at least three seconds, to ensure that results for different prediction times are comparable.", "labels": [], "entities": []}, {"text": "As expected, prediction accuracy increases as we approach the time of the action.", "labels": [], "entities": [{"text": "prediction", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.8676503300666809}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9830906391143799}]}, {"text": "Furthermore, the combined model outperforms both p sem and p obs reliably.", "labels": [], "entities": []}, {"text": "This indicates that the component models pro-vide complementary useful information.", "labels": [], "entities": []}, {"text": "Our model also outperforms two more baselines: KGSC predicts that the IF will press the button with the minimal overall distance, which is the distance metric used by the \"movement-based system\" of; random visible selects a random button from the ones that are currently visible to the IF.", "labels": [], "entities": []}, {"text": "The fact that this last baseline does not approach 1 at action time suggests that multiple buttons tend to be visible when the IF presses one, confirming that the prediction task is not trivial.", "labels": [], "entities": []}, {"text": "Correctly predicting the button that the IF will press is especially useful, and challenging, in those cases where the IF pressed a different button than the one the NLG system intended.", "labels": [], "entities": []}, {"text": "shows a closer look at the 125 unsuccessful episodes of at least three seconds in the test data.", "labels": [], "entities": []}, {"text": "These tend to be hard instances, and thus as expected, prediction accuracy drops for all systems.", "labels": [], "entities": [{"text": "prediction", "start_pos": 55, "end_pos": 65, "type": "TASK", "confidence": 0.937518298625946}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9767664670944214}]}, {"text": "However, by integrating semantic and observational information, the combined model compensates better for this than all other systems, with an accuracy of 37.6% against 31.2% for each individual component.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.999275267124176}]}, {"text": "Feedback appropriateness Second, we evaluated the ability of our model to predict whether the user misunderstood the RE and requires feedback.", "labels": [], "entities": [{"text": "RE", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.7354447841644287}]}, {"text": "For all the above models, we assumed a simple feedback mechanism which predicts that the user misunderstood the RE if p(a ) \u2212 p(a * ) > \u03b8 for some object a = a * , where \u03b8 is a confidence threshold; we used \u03b8 = 0.1 here.", "labels": [], "entities": [{"text": "RE", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9529376029968262}]}, {"text": "We can thus test on recorded data in which no actual feedback can be given anymore.", "labels": [], "entities": []}, {"text": "We evaluated the models on the 848 test episodes of at least 3s in which the NLG systems logged the button they tried to refer to.", "labels": [], "entities": []}, {"text": "The results are shown in in terms of F1 measure.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9771741330623627}]}, {"text": "Here precision is the proportion of instances in which the IF pressed the wrong button (i.e., where feedback should have been given) among the instances where the model actually suggested feedback.", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9995467066764832}]}, {"text": "Recall is the proportion of instances in which the model suggested feedback among the instances where the IF pressed the wrong button.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9880453944206238}]}, {"text": "Again, the combined model outperforms its components and the baselines, primarily due to increased recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9993426203727722}]}, {"text": "The difference is particularly pronounced early on, which would be useful in giving timely feedback in an actual real-time system.", "labels": [], "entities": []}], "tableCaptions": []}