{"title": [{"text": "Exploiting Zero Pronouns to Improve Chinese Coreference Resolution", "labels": [], "entities": [{"text": "Improve Chinese Coreference Resolution", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.8313911110162735}]}], "abstractContent": [{"text": "Coreference resolution plays a critical role in discourse analysis.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8927569091320038}, {"text": "discourse analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7271212786436081}]}, {"text": "This paper focuses on exploiting zero pronouns to improve Chi-nese coreference resolution.", "labels": [], "entities": [{"text": "Chi-nese coreference resolution", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.7270950476328532}]}, {"text": "In particular, a simplified semantic role labeling framework is proposed to identify clauses and to detect zero pronouns effectively, and two effective methods (refining syntactic parser and refining learning example generation) are employed to exploit zero pronouns for Chinese coreference resolution.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7076895435651144}, {"text": "Chinese coreference resolution", "start_pos": 271, "end_pos": 301, "type": "TASK", "confidence": 0.7886670033137003}]}, {"text": "Evaluation on the CoNLL-2012 shared task data set shows that zero pronouns can significantly improve Chinese coreference resolution.", "labels": [], "entities": [{"text": "CoNLL-2012 shared task data set", "start_pos": 18, "end_pos": 49, "type": "DATASET", "confidence": 0.8966101169586181}, {"text": "Chinese coreference resolution", "start_pos": 101, "end_pos": 131, "type": "TASK", "confidence": 0.9041797518730164}]}], "introductionContent": [{"text": "As one of the most important tasks in discourse analysis, coreference resolution aims to link a given mention (i.e., entity or event) to its co-referring expression in a text and has been a focus of research in natural language processing (NLP) for decades.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7257572114467621}, {"text": "coreference resolution", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.962411642074585}, {"text": "natural language processing (NLP)", "start_pos": 211, "end_pos": 244, "type": "TASK", "confidence": 0.7646500170230865}]}, {"text": "Over the last decade, various machine learning techniques have been applied to coreference resolution and have performed reasonably well (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.9737169742584229}]}, {"text": "Current techniques rely primarily on surface level features such as string match, syntactic features such as apposition, and shallow semantic features such as number, gender, semantic class, etc.", "labels": [], "entities": []}, {"text": "Despite similarities between Chinese and English, there are differences that have a significant impact on coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.9699236154556274}]}, {"text": "In this paper, we focus on exploiting one of the key characteristics of Chinese text, zero pronouns (ZPs), to improve Chinese coreference resolution.", "labels": [], "entities": [{"text": "Chinese coreference resolution", "start_pos": 118, "end_pos": 148, "type": "TASK", "confidence": 0.7080682118733724}]}, {"text": "In particular, a simplified semantic role labeling (SRL) framework is proposed to identify Chinese clauses and to detect zero pronouns effectively, and two effective methods are employed to exploit zero pronouns for Chinese coreference resolution.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.8208729227383932}, {"text": "Chinese coreference resolution", "start_pos": 216, "end_pos": 246, "type": "TASK", "confidence": 0.7618125677108765}]}, {"text": "Experimental results show the effectiveness of our approach in improving the performance of Chinese coreference resolution.", "labels": [], "entities": [{"text": "Chinese coreference resolution", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.6704640686511993}]}, {"text": "Our work is novel in that it is the first work that incorporates the use of zero pronouns to significantly improve Chinese coreference resolution The rest of this paper is organized as follows.", "labels": [], "entities": [{"text": "Chinese coreference resolution", "start_pos": 115, "end_pos": 145, "type": "TASK", "confidence": 0.8040435711542765}]}, {"text": "Section 2 describes our baseline Chinese coreference resolution system.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.8857959508895874}]}, {"text": "Section 3 motivates how the detection of zero pronouns can improve Chinese coreference resolution, using an illustrating example.", "labels": [], "entities": [{"text": "Chinese coreference resolution", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.801718533039093}]}, {"text": "Section 4 presents our approach to detect zero pronouns.", "labels": [], "entities": []}, {"text": "Section 5 proposes two methods to exploit zero pronouns to improve Chinese coreference resolution, based on a corpus study and preliminary experiments.", "labels": [], "entities": [{"text": "Chinese coreference resolution", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.8274572094281515}]}, {"text": "Section 6 briefly outlines the related work.", "labels": [], "entities": []}, {"text": "Finally, we conclude our work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "For fair comparison, all our experiments in this subsection have been conducted using the same experimental settings as our baseline system.", "labels": [], "entities": []}, {"text": "When compared to our baseline system, all improvements are statistically significant (p < 0.005).", "labels": [], "entities": []}, {"text": "lists the coreference resolution performance incorporating automatically detected zero pronouns.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9343501031398773}]}, {"text": "The results show that: \u2022 Using automatically detected zero pronouns achieves better performance under all experimental settings.", "labels": [], "entities": []}, {"text": "In particular, using automatic mentions, performance improves by 3.31%,: Performance of our Chinese coreference resolution system incorporating zero pronouns contribution of zero pronouns is only 0.24% in average F-measure.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.7088163495063782}, {"text": "F-measure", "start_pos": 213, "end_pos": 222, "type": "METRIC", "confidence": 0.9338393807411194}]}, {"text": "This is because employing either gold mention boundaries or gold mentions improves parsing performance.", "labels": [], "entities": []}, {"text": "\u2022 Our system incorporating zero pronouns outperforms the three best systems in the CoNLL-2012 shared task when using automatic mentions or gold mention boundaries.", "labels": [], "entities": [{"text": "CoNLL-2012 shared task", "start_pos": 83, "end_pos": 105, "type": "DATASET", "confidence": 0.7986470858256022}]}, {"text": "Using gold mentions, our average F-measure is slightly lower than that of Chen and Ng (2012).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9989508390426636}]}, {"text": "5 presents the contribution of our two methods of exploiting zero pronouns and the impact of gold-standard zero pronouns.", "labels": [], "entities": []}, {"text": "We conclude that: \u2022 Both the refined parser and refined example generation improve performance.", "labels": [], "entities": []}, {"text": "While the refined parser improves the recall of mention detection and coreference resolution, refined example generation contributes more to precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9950249791145325}, {"text": "mention detection", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.6881517320871353}, {"text": "coreference resolution", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.9292484223842621}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9974114298820496}]}, {"text": "Combining these two methods further improves coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.9694961309432983}]}, {"text": "\u2022 There is a performance gap of 6.01%, 4.08%, and 3.19% in F-measure on the MUC, BCUBED, and CEAF evaluation metric, respectively, between the coreference resolution system with gold-standard zero pronouns and without zero pronouns.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9989184141159058}, {"text": "MUC", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.9088681936264038}, {"text": "BCUBED", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.7457501888275146}, {"text": "CEAF evaluation metric", "start_pos": 93, "end_pos": 115, "type": "DATASET", "confidence": 0.8468402425448099}, {"text": "coreference resolution", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.8563409745693207}]}, {"text": "This suggests the usefulness of zero pronoun detection in Chinese coreference resolution.", "labels": [], "entities": [{"text": "zero pronoun detection", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.7076135675112406}, {"text": "Chinese coreference resolution", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.7380915681521097}]}, {"text": "\u2022 Our proposed methods incorporating automatic zero pronouns reduce the performance gap by about half.", "labels": [], "entities": []}, {"text": "This shows the effectiveness of our proposed methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performance of anaphoricity determination on  the CoNLL-2012 test set", "labels": [], "entities": [{"text": "CoNLL-2012 test set", "start_pos": 60, "end_pos": 79, "type": "DATASET", "confidence": 0.9594729741414388}]}, {"text": " Table 4: Performance of our Chinese coreference resolu- tion system on the CoNLL-2012 test set", "labels": [], "entities": [{"text": "coreference resolu- tion", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.5197472646832466}, {"text": "CoNLL-2012 test set", "start_pos": 76, "end_pos": 95, "type": "DATASET", "confidence": 0.9784018596013387}]}, {"text": " Table 5: Performance (F-measure) of the three best Chinese coreference resolution systems on the CoNLL-2012 test  set", "labels": [], "entities": [{"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9947822690010071}, {"text": "coreference resolution", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.8781735599040985}, {"text": "CoNLL-2012 test  set", "start_pos": 98, "end_pos": 118, "type": "DATASET", "confidence": 0.9712362686793009}]}, {"text": " Table 9: Contributions of the two methods of incorporating zero pronouns and the impact of gold zero pronouns  (RP: refining parser using auto zero pronouns, REG: refining example generation using auto zero pronouns, AZPs:  combining both RP and REG using auto zero pronouns, and GZPs: combining both RP and REG using gold zero  pronouns)", "labels": [], "entities": []}]}