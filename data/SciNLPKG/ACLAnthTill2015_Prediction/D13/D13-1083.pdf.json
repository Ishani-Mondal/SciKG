{"title": [{"text": "A Corpus Level MIRA Tuning Strategy for Machine Translation", "labels": [], "entities": [{"text": "MIRA Tuning", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.6120742410421371}, {"text": "Machine Translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8155965209007263}]}], "abstractContent": [{"text": "MIRA based tuning methods have been widely used in statistical machine translation (SMT) system with a large number of features.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 51, "end_pos": 88, "type": "TASK", "confidence": 0.8063713560501734}]}, {"text": "Since the corpus-level BLEU is not de-composable, these MIRA approaches usually define a variety of heuristic-driven sentence-level BLEUs in their model losses.", "labels": [], "entities": []}, {"text": "Instead, we present anew MIRA method, which employs an exact corpus-level BLEU to compute the model loss.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.8090489506721497}, {"text": "BLEU", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9840675592422485}]}, {"text": "Our method is simpler in implementation.", "labels": [], "entities": []}, {"text": "Experiments on Chinese-to-English translation show its effectiveness over two state-of-the-art MIRA implementations.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.6323169320821762}, {"text": "MIRA", "start_pos": 95, "end_pos": 99, "type": "TASK", "confidence": 0.6304055452346802}]}], "introductionContent": [{"text": "Margin infused relaxed algorithm (MIRA) has been widely adopted for the parameter optimization in SMT with a large feature size (.", "labels": [], "entities": [{"text": "Margin infused relaxed algorithm (MIRA", "start_pos": 0, "end_pos": 38, "type": "METRIC", "confidence": 0.7930348714192709}, {"text": "parameter optimization", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7744769752025604}, {"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9658796787261963}]}, {"text": "Since BLEU is defined on the corpus, and not decomposed into sentences, most MIRA approaches consider a variety of sentence-level BLEUs for the model losses, many of which are heuristic-driven (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.992352306842804}]}, {"text": "The sentence-level BLEU appearing in the objective is generally based on a pseudo-document, which may not precisely reflect the corpus-level BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9011302590370178}, {"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.8896756172180176}]}, {"text": "We believe that this mismatch could potentially harm the performance.", "labels": [], "entities": []}, {"text": "To avoid the sentence BLEU, the work in proposed to process sentences in small batches.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9857026934623718}]}, {"text": "The authors adopted a Gibbs sampling () technique to search the hope and fear hypotheses, and they did not compare with MIRA.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.5373539924621582}]}, {"text": "also tuned the parameters with small batches of sentences and optimized a hinge loss not explicitly related to BLEU using stochastic gradient descent.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.996178388595581}]}, {"text": "Both approaches introduced additional complexities over baseline MIRA approaches.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.9422422051429749}]}, {"text": "In contrast, we propose a remarkably simple but efficient batch MIRA approach which exploits the exact corpus-level BLEU to compute model losses.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 64, "end_pos": 68, "type": "TASK", "confidence": 0.8818455934524536}, {"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9764304757118225}]}, {"text": "We search fora hope and a fear hypotheses for the corpus with a straightforward approach and minimize the structured hinge loss defined on them.", "labels": [], "entities": []}, {"text": "The experiments show that our method consistently outperforms two state-of-the-art MIRAs in Chinese-toEnglish translation tasks with a moderate margin.", "labels": [], "entities": [{"text": "MIRAs", "start_pos": 83, "end_pos": 88, "type": "METRIC", "confidence": 0.8857890367507935}, {"text": "Chinese-toEnglish translation tasks", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.6345541377862295}]}], "datasetContent": [{"text": "We first evaluate c-MIRA in a iterative batch tuning procedure in a Chinese-to-English machine translation system with 228 features.", "labels": [], "entities": [{"text": "Chinese-to-English machine translation", "start_pos": 68, "end_pos": 106, "type": "TASK", "confidence": 0.6511921882629395}]}, {"text": "Second, we show c-MIRA is also effective in the re-ranking task with more than 50,000 features.", "labels": [], "entities": []}, {"text": "In both experiments, we compare c-MIRA and three baselines: (1) MERT (Och, 2003), (2) Chiang et al.'s MIRA (MIRA 1 ) in (.", "labels": [], "entities": [{"text": "MERT", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9972500205039978}, {"text": "MIRA (MIRA 1 )", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.7704572200775146}]}, {"text": "batch-MIRA (MIRA 2 ) in (Cherry and Foster, 2012).", "labels": [], "entities": [{"text": "MIRA 2 ) in (Cherry and Foster, 2012)", "start_pos": 12, "end_pos": 49, "type": "DATASET", "confidence": 0.7633372084660963}]}, {"text": "Here, we roughly choose C with the best BLEU on dev set, from {0.1, 0.01, 0.001, 0.0001, 0.00001}.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.998274564743042}]}, {"text": "We convert Chiang et al.'s MIRA to the batch mode described in section 3.1.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.3785478472709656}]}, {"text": "So the only difference between MIRA 1 and MIRA 2 is: MIRA 1 obtains multiple constraints before optimization, while MIRA 2 only uses one constraint.", "labels": [], "entities": []}, {"text": "We implement MERT and MIRA 1 , and directly use MIRA 2 from Moses (.", "labels": [], "entities": [{"text": "MERT", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9189279079437256}, {"text": "MIRA 1", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9488286972045898}, {"text": "MIRA 2", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9223023653030396}]}, {"text": "We conduct experiments in a server of 8-cores with 2.5GHz Opteron.", "labels": [], "entities": []}, {"text": "We set the maximum number of epochs as we generally do not observe an obvious increase on the dev set BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9925857186317444}]}, {"text": "The epoch size for MIRA 1 and MIRA 2 is 40, while the one for c-MIRA is 400.", "labels": [], "entities": [{"text": "epoch size", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9257834851741791}, {"text": "MIRA", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.5104119777679443}, {"text": "MIRA", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.4020828604698181}]}, {"text": "c-MIRA runs more epochs, because we update the parameters by much fewer times.", "labels": [], "entities": []}, {"text": "However, we can implement Line 3\u223c8 in Algorithm 1 in multi-thread (we use eight threads in the following experiments), which makes our algorithm much faster.", "labels": [], "entities": []}, {"text": "Also, we increase the epoch sizes of MIRA 1 and MIRA 2 to 400, and find there is no improvement on their performance.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.6303526163101196}, {"text": "MIRA", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.5520647764205933}]}, {"text": "The baseline system is a state-of-the-art hierarchical phrase-based system, and trained on six million parallel sentences corpora available to the DARPA BOLT Chinese-English task.", "labels": [], "entities": [{"text": "DARPA BOLT Chinese-English task", "start_pos": 147, "end_pos": 178, "type": "TASK", "confidence": 0.437747061252594}]}, {"text": "This system includes 51 dense features (including translation probabilities, provenance features, etc.) and about 50k sparse features (mostly lexical and fertility-based).", "labels": [], "entities": []}, {"text": "The language model is a six-gram model trained on a 10 billion words monolingual corpus, including the English side of our parallel corpora plus other corpora such as Gigaword (LDC2011T07) and Google News.", "labels": [], "entities": [{"text": "Gigaword (LDC2011T07)", "start_pos": 167, "end_pos": 188, "type": "DATASET", "confidence": 0.8243503123521805}]}, {"text": "We use 1275 sentences for tuning and 1239 sentences for testing from the LDC2010E30 corpus respectively.", "labels": [], "entities": [{"text": "LDC2010E30 corpus", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.9887446761131287}]}, {"text": "There are four reference translations for each input sentence in both tuning and testing datasets.", "labels": [], "entities": []}, {"text": "We use a N-best list which is an intermediate out-   put of the baseline system optimized on TER-BLEU instead of BLEU.", "labels": [], "entities": [{"text": "TER-BLEU", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9572457671165466}, {"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9953769445419312}]}, {"text": "Before the re-ranking task, the initial BLEUs of the top-1 hypotheses on the tuning and testing set are 31.45 and 30.56.", "labels": [], "entities": [{"text": "BLEUs", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.998335063457489}]}, {"text": "The average numbers of hypotheses per sentence are about 200 and 500, respectively for the tuning and testing sets.", "labels": [], "entities": []}, {"text": "Again, we use the best epoch on the tuning set for testing.", "labels": [], "entities": []}, {"text": "The BLEUs on dev and test sets are reported in.", "labels": [], "entities": [{"text": "BLEUs", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9983003735542297}]}, {"text": "We observe that the effectiveness of c-MIRA is not harmed as the feature size is scaled up.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEUs (%) on the dev and test sets with 8 dense  features only and all features. The significant symbols (+  at 0.05 level) are compared with MIRA 2", "labels": [], "entities": [{"text": "BLEUs", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9995402097702026}, {"text": "MIRA", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.8103976249694824}]}, {"text": " Table 3: BLEUs (%) on re-ranking experiments.", "labels": [], "entities": [{"text": "BLEUs", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9996001124382019}]}, {"text": " Table 4: Times of updating model parameters.", "labels": [], "entities": []}]}