{"title": [{"text": "Semi-Supervised Representation Learning for Cross-Lingual Text Classification", "labels": [], "entities": [{"text": "Cross-Lingual Text Classification", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.76395583152771}]}], "abstractContent": [{"text": "Cross-lingual adaptation aims to learn a prediction model in a label-scarce target language by exploiting labeled data from a label-rich source language.", "labels": [], "entities": [{"text": "Cross-lingual adaptation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.826954185962677}]}, {"text": "An effective cross-lingual adaptation system can substantially reduce the manual annotation effort required in many natural language processing tasks.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew cross-lingual adaptation approach for document classification based on learning cross-lingual discrim-inative distributed representations of words.", "labels": [], "entities": [{"text": "document classification", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.7237942814826965}]}, {"text": "Specifically, we propose to maximize the log-likelihood of the documents from both language domains under a cross-lingual log-bilinear document model, while minimizing the prediction log-losses of labeled documents.", "labels": [], "entities": []}, {"text": "We conduct extensive experiments on cross-lingual sentiment classification tasks of Amazon product reviews.", "labels": [], "entities": [{"text": "cross-lingual sentiment classification tasks", "start_pos": 36, "end_pos": 80, "type": "TASK", "confidence": 0.7793299183249474}]}, {"text": "Our experimental results demonstrate the efficacy of the proposed cross-lingual adaptation approach.", "labels": [], "entities": [{"text": "cross-lingual adaptation", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.7235497534275055}]}], "introductionContent": [{"text": "With the rapid development of linguistic resources in different languages, developing cross-lingual natural language processing (NLP) systems becomes increasingly important ().", "labels": [], "entities": [{"text": "cross-lingual natural language processing (NLP)", "start_pos": 86, "end_pos": 133, "type": "TASK", "confidence": 0.7170736449105399}]}, {"text": "Recently, cross-lingual adaptation methods have been studied to exploit labeled information from an existing source language domain where labeled training data is abundant for use in a target language domain where annotated training data is scarce.", "labels": [], "entities": []}, {"text": "Previous work has shown that cross-lingual adaptation can greatly reduce labeling effort fora variety of cross language NLP tasks such as document categorization (), genre classification (, and sentiment classification).", "labels": [], "entities": [{"text": "cross-lingual adaptation", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7359769642353058}, {"text": "genre classification", "start_pos": 166, "end_pos": 186, "type": "TASK", "confidence": 0.8258866369724274}, {"text": "sentiment classification", "start_pos": 194, "end_pos": 218, "type": "TASK", "confidence": 0.9205028414726257}]}, {"text": "The fundamental challenge of cross-lingual adaptation stems from alack of overlap between the feature space of the source language data and that of the target language data.", "labels": [], "entities": [{"text": "cross-lingual adaptation", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7859843373298645}]}, {"text": "To address this challenge, previous work in the literature mainly relies on automatic machine translation tools.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.7310853898525238}]}, {"text": "They first translate all the text data from one language domain into the other and then apply techniques such as domain adaptation) and multi-view learning) to achieve cross-lingual adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7043063789606094}, {"text": "cross-lingual adaptation", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.748842716217041}]}, {"text": "However, machine translation tools may not be freely available for all languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7644659578800201}]}, {"text": "Moreover, translating all the text data in one language into the other language is too time-consuming in reality.", "labels": [], "entities": []}, {"text": "As an economic alternative solution, cross-lingual representation learning has recently been used in the literature to learn language-independent representations of the data for cross language text classification.", "labels": [], "entities": [{"text": "cross-lingual representation learning", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.7792840202649435}, {"text": "cross language text classification", "start_pos": 178, "end_pos": 212, "type": "TASK", "confidence": 0.7201519459486008}]}, {"text": "In this paper, we propose to tackle cross language text classification by inducing cross-lingual predictive data representations with both labeled and unlabeled documents from the two language domains.", "labels": [], "entities": [{"text": "cross language text classification", "start_pos": 36, "end_pos": 70, "type": "TASK", "confidence": 0.7441229671239853}]}, {"text": "Specifically, we propose a cross-lingual log-bilinear document model to learn distributed representations of words, which can capture both the semantic sim-ilarities of words across languages and the predictive information with respect to the target classification task.", "labels": [], "entities": []}, {"text": "We conduct the representation learning by maximizing the log-likelihood of all documents from both language domains under the crosslingual log-bilinear document model and minimizing the prediction log-losses of labeled documents.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.9212943911552429}]}, {"text": "We formulate the learning problem as a joint nonconvex minimization problem and solve it using a local optimization algorithm.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of the proposed approach, we conduct experiments on the task of cross language sentiment classification of Amazon product reviews.", "labels": [], "entities": [{"text": "cross language sentiment classification of Amazon product reviews", "start_pos": 94, "end_pos": 159, "type": "TASK", "confidence": 0.72945936024189}]}, {"text": "The empirical results show the proposed approach is very effective for cross-lingual document classification, and outperforms other comparison methods.", "labels": [], "entities": [{"text": "cross-lingual document classification", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.71691366036733}]}], "datasetContent": [{"text": "We empirically evaluate the proposed approach using the cross language sentiment classification tasks of Amazon product reviews in four languages.", "labels": [], "entities": [{"text": "cross language sentiment classification", "start_pos": 56, "end_pos": 95, "type": "TASK", "confidence": 0.6942757591605186}]}, {"text": "In this section, we report our experimental results.", "labels": [], "entities": []}, {"text": "We used the multilingual sentiment classification dataset 1 provided by, which contains Amazon product reviews in four different languages, English (E), French (F), German (G) and Japanese (J).", "labels": [], "entities": [{"text": "multilingual sentiment classification", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.681789755821228}]}, {"text": "The English product reviews were sampled from previous cross-domain sentiment classification datasets (, while the other three language product reviews were crawled from Amazon by the authors in November 2009.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.661787619193395}]}, {"text": "In the dataset, each language contains three categories of product reviews, Books (B), DVD (D) and Music (M).", "labels": [], "entities": []}, {"text": "Each language-category pair contains a balanced training set and test set, each of which consists of 1000 positive reviews and 1000 negative reviews.", "labels": [], "entities": []}, {"text": "Each review is represented as a unigram bag-of-word feature vector with termfrequency values.", "labels": [], "entities": []}, {"text": "Following the work, we used the original English reviews as the source language while treating the other three languages as target languages.", "labels": [], "entities": []}, {"text": "Thus, we construct nine cross language sentiment classification tasks (GB, GD, GM, FB, FD, FM, JB, JD, JM), one for each target language-category pair.", "labels": [], "entities": [{"text": "cross language sentiment classification", "start_pos": 24, "end_pos": 63, "type": "TASK", "confidence": 0.681012250483036}]}, {"text": "For example, the task GB means that the target language is German and the training and test data are samples from Books reviews.", "labels": [], "entities": [{"text": "GB", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.874771237373352}, {"text": "Books reviews", "start_pos": 114, "end_pos": 127, "type": "DATASET", "confidence": 0.9343295097351074}]}], "tableCaptions": [{"text": " Table 1: Average classification accuracies and standard deviations for the 9 cross-lingual sentiment classification tasks.  The bold format indicates that the difference between the results of CL-RL and MT is significant with p < 0.05 under  a McNemar paired test for labeling disagreements.", "labels": [], "entities": [{"text": "cross-lingual sentiment classification", "start_pos": 78, "end_pos": 116, "type": "TASK", "confidence": 0.6900701920191447}, {"text": "labeling disagreements", "start_pos": 269, "end_pos": 291, "type": "TASK", "confidence": 0.8788357675075531}]}]}