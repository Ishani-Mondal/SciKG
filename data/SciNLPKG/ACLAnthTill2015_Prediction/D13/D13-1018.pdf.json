{"title": [{"text": "Growing Multi-Domain Glossaries from a Few Seeds using Probabilistic Topic Models", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present a minimally-supervised approach to the multi-domain acquisition of wide-coverage glossaries.", "labels": [], "entities": [{"text": "multi-domain acquisition of wide-coverage glossaries", "start_pos": 64, "end_pos": 116, "type": "TASK", "confidence": 0.7894481539726257}]}, {"text": "We start from a small number of hypernymy relation seeds and bootstrap glossaries from the Web for dozens of domains using Probabilis-tic Topic Models.", "labels": [], "entities": []}, {"text": "Our experiments show that we are able to extract high-precision glossaries comprising thousands of terms and definitions .", "labels": [], "entities": []}], "introductionContent": [{"text": "Dictionaries, thesauri and glossaries are useful sources of information for students, scholars and everyday readers, who use them to lookup words of which they either do not know, or have forgotten, the meaning.", "labels": [], "entities": []}, {"text": "With the advent of the Web an increasing number of dictionaries and technical glossaries has been made available online, thereby speeding up the definition search process.", "labels": [], "entities": [{"text": "definition search", "start_pos": 145, "end_pos": 162, "type": "TASK", "confidence": 0.8828192055225372}]}, {"text": "However, finding definitions is not always immediate, especially if the target term pertains to a specialized domain.", "labels": [], "entities": []}, {"text": "Indeed, not even well-known services such as Google Define are able to provide definitions for scientific or technical terms such as taxonomy learning or distant supervision in AI or figure-four leglock and suspended surfboard in wrestling.", "labels": [], "entities": []}, {"text": "Domain-specific knowledge of a definitional nature is not only useful for humans, it is also useful for machines ().", "labels": [], "entities": []}, {"text": "Examples include Natural Language Processing tasks such as Question Answering (, Word Sense Disambiguation () and ontology learning (.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.8314906656742096}, {"text": "Word Sense Disambiguation", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.5391536355018616}]}, {"text": "Unfortunately, most of the Web dictionaries and glossaries available online comprise just a few hundred definitions, and they therefore provide only a partial view of a domain.", "labels": [], "entities": []}, {"text": "This is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.", "labels": [], "entities": []}, {"text": "The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries.", "labels": [], "entities": []}, {"text": "However, these services do not classify textual definitions by domain: they just present the collected definitions for all the possible meanings of a given term.", "labels": [], "entities": []}, {"text": "In order to automatically obtain large domain glossaries, in recent years computational approaches have been developed which extract textual definitions from corpora () or the Web ().", "labels": [], "entities": []}, {"text": "The methods involving corpora start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system.", "labels": [], "entities": []}, {"text": "Web-based methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as \"X is a Y\", along the lines of.", "labels": [], "entities": []}, {"text": "These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9973337650299072}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9992948770523071}]}, {"text": "To address the low-recall issue, recurring cue terms occurring within dictionary and encyclopedic resources can be automatically extracted and incorporated into lexical patterns).", "labels": [], "entities": []}, {"text": "However, this approach is term-specific and does not scale to arbitrary terminologies and domains.", "labels": [], "entities": []}, {"text": "The goal of the new approach outlined in this paper is to enable the automatic harvesting of largescale, full-fledged domain glossaries for dozens of domains, an outcome which should be very useful for both human activities and automatic tasks.", "labels": [], "entities": []}, {"text": "We present ProToDoG (Probabilistic Topics for multi-Domain Glossaries), a framework for growing multi-domain glossaries which has three main novelties: i) minimal human supervision: a small set of hypernymy relation seeds for each domain is used to bootstrap the multi-domain acquisition process; ii) jointness: our approach harvests terms and glosses at the same time; iii) probabilistic topic models are leveraged fora simultaneous, high-precision multi-domain classification of the extracted definitions, with substantial performance improvements over our previous work on glossary bootstrapping, i.e., GlossBoot).", "labels": [], "entities": [{"text": "GlossBoot", "start_pos": 606, "end_pos": 615, "type": "DATASET", "confidence": 0.8448690176010132}]}, {"text": "ProToDog is able to harvest definitions from the Web and thus drop the requirement of large corpora for each domain.", "labels": [], "entities": [{"text": "ProToDog", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.950670063495636}]}, {"text": "Moreover, apart from the need to select a few seeds, it avoids the use of training data or manually defined sets of lexical patterns.", "labels": [], "entities": []}, {"text": "It is thus applicable to virtually any language of interest.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the quality of both terms and glosses, as jointly extracted by ProToDoG.", "labels": [], "entities": [{"text": "ProToDoG", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9752101898193359}]}], "tableCaptions": [{"text": " Table 1: Size of the gold standard and the automatically-acquired glossaries for 10 of the 30 selected domains (t:  number of terms, g: number of glosses).", "labels": [], "entities": []}, {"text": " Table 2: Precision (P), coverage (C), extra-coverage (X), encyclopedic (E) percentages after 5 iterations.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9319925159215927}, {"text": "coverage (C)", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.9366638958454132}, {"text": "extra-coverage (X)", "start_pos": 39, "end_pos": 57, "type": "METRIC", "confidence": 0.9081256240606308}, {"text": "encyclopedic (E) percentages", "start_pos": 59, "end_pos": 87, "type": "METRIC", "confidence": 0.7642570972442627}]}, {"text": " Table 3: Number of domain glosses (from a random sam- ple of 100 gold standard terms per domain) retrieved us- ing Google Define and ProToDoG.", "labels": [], "entities": [{"text": "ProToDoG", "start_pos": 134, "end_pos": 142, "type": "DATASET", "confidence": 0.9421557188034058}]}, {"text": " Table 5: Number and precision of terms and glosses extracted by ProToDoG and TaxoLearn in the Artificial Intelli- gence (AI) and Finance domains.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9439112544059753}, {"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9948427081108093}, {"text": "ProToDoG", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.9778705835342407}]}]}