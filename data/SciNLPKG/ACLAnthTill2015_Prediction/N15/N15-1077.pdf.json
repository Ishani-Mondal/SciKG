{"title": [{"text": "Grounded Semantic Parsing for Complex Knowledge Extraction", "labels": [], "entities": [{"text": "Complex Knowledge Extraction", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.6604584952195486}]}], "abstractContent": [{"text": "Recently, there has been increasing interest in learning semantic parsers with indirect supervision , but existing work focuses almost exclusively on question answering.", "labels": [], "entities": [{"text": "learning semantic parsers", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.6327460706233978}, {"text": "question answering", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.8030190467834473}]}, {"text": "Separately, there have been active pursuits in leveraging databases for distant supervision in information extraction, yet such methods are often limited to binary relations and none can handle nested events.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.8399311602115631}]}, {"text": "In this paper, we generalize distant supervision to complex knowledge extraction, by proposing the first approach to learn a semantic parser for extracting nested event structures without annotated examples, using only a database of such complex events and unannotated text.", "labels": [], "entities": [{"text": "complex knowledge extraction", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.6788148184617361}]}, {"text": "The key idea is to model the annotations as latent variables, and incorporate a prior that favors semantic parses containing known events.", "labels": [], "entities": []}, {"text": "Experiments on the GENIA event extraction dataset show that our approach can learn from and extract complex biological pathway events.", "labels": [], "entities": [{"text": "GENIA event extraction dataset", "start_pos": 19, "end_pos": 49, "type": "DATASET", "confidence": 0.8682751208543777}]}, {"text": "Moreover , when supplied with just five example words per event type, it becomes competitive even among supervised systems, outperform-ing 19 out of 24 teams that participated in the original shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of semantic parsing is to map text into a complete and detailed meaning representation.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7213152647018433}]}, {"text": "Supervised approaches for learning a semantic parser require annotated examples, Complex Event (POS-REG,BCL,(NEG-REG,IL-10,RFLAT))", "labels": [], "entities": []}], "datasetContent": [{"text": "In principle, we can learn GUSPEE from any pathway database.", "labels": [], "entities": []}, {"text": "However, evaluation is challenging as these databases do not contain textual annotations.", "labels": [], "entities": []}, {"text": "Prior work on distant supervision resorted to sampling and annotating new extractions.", "labels": [], "entities": []}, {"text": "This is effective for comparing among distant-supervision systems, but it cannot be used to compare them with supervised learning.", "labels": [], "entities": []}, {"text": "Moreover, as annotation is conducted by the authors or crowdsourcing, consistency and quality are hard to control.", "labels": [], "entities": [{"text": "consistency", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9928008317947388}]}, {"text": "We thus adopted a novel approach to evaluation by simulating a grounded learning scenario using the GENIA event extraction dataset ().", "labels": [], "entities": [{"text": "GENIA event extraction dataset", "start_pos": 100, "end_pos": 130, "type": "DATASET", "confidence": 0.7814048230648041}]}, {"text": "Specifically, we generated a set of complex events from the annotations of training sentences as the database.", "labels": [], "entities": []}, {"text": "The annotations were discarded afterwards and GUSPEE learned from the database and unannotated text alone.", "labels": [], "entities": [{"text": "GUSPEE", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.47379451990127563}]}, {"text": "The learned model was then applied to semantic parsing of test sentences and evaluated on event precision, recall, and F1.", "labels": [], "entities": [{"text": "semantic parsing of test sentences", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.8419957876205444}, {"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.5037215352058411}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9989006519317627}, {"text": "F1", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9994440674781799}]}, {"text": "This evaluation methodology enables us to assess the true accuracy and compare head-to-head with supervised methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9980873465538025}]}, {"text": "GENIA contains 800 abstracts for training and 150 for development.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9564335346221924}]}, {"text": "It also has a test set, but its annotation is not made public.", "labels": [], "entities": []}, {"text": "Therefore, we used the training set for grounded learning and development, and reserved the development set for testing.", "labels": [], "entities": []}, {"text": "The majority events are Regulation (including Positive regulation, Negative regulation).", "labels": [], "entities": []}, {"text": "We processed all sentences using SPLAT (, to conduct tokenization, part-of-speech tagging, and constituency parsing.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.688318207859993}, {"text": "constituency parsing", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.8237608969211578}]}, {"text": "We then postprocessed the parses to obtain Stanford dependencies (de).", "labels": [], "entities": []}, {"text": "During development on the training data, we found the following parameters (Section 3) to perform quite well and used them in all subsequent experiments: \u03ba = 20, W NULL = 4, W RAISE\u2212P = 2, W RAISE\u2212E = \u22126, L 2 prior = 0.1.", "labels": [], "entities": [{"text": "RAISE\u2212P", "start_pos": 176, "end_pos": 183, "type": "METRIC", "confidence": 0.9019906918207804}]}, {"text": "Interestingly, we found that encouraging protein RAISING is beneficial, which probably stems from the fact that proteins are often separated from event triggers by noun modifiers, such as \"the BCL gene\", \"IL-10 protein\".", "labels": [], "entities": [{"text": "RAISING", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.6380731463432312}]}, {"text": "shows GUSPEE's results on GENIA event extraction.", "labels": [], "entities": [{"text": "GUSPEE", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.6198611855506897}, {"text": "GENIA event extraction", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7115427652994791}]}, {"text": "Note that this event-based evaluation is rather stringent, as it considers an event incorrect if one of its argument events is not completely correct, thus an incorrect event will render all its upstream events incorrect.", "labels": [], "entities": []}, {"text": "For comparison, shows the results of MSR11, a state-of-the-art supervised system.", "labels": [], "entities": [{"text": "MSR11", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.7929847836494446}]}, {"text": "MSR11 also provides a upper bound for the supervised version of GUSPEE, as the latter is much less engineered.", "labels": [], "entities": [{"text": "MSR11", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9694311618804932}, {"text": "GUSPEE", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.8005803227424622}]}, {"text": "Not surprisingly, grounded learning with GUS-PEE still lags behind supervised learning.", "labels": [], "entities": [{"text": "GUS-PEE", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.5147123336791992}]}, {"text": "MSR11 used a rich set of features, including POS tags, linear and dependency n-grams, etc.", "labels": [], "entities": [{"text": "MSR11", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9630779027938843}]}, {"text": "Also, it is expected that indirect supervision do not provide as effective signals as direct supervision.", "labels": [], "entities": []}, {"text": "However, the comparison reveals a particularly interesting contrast.", "labels": [], "entities": []}, {"text": "Event types such as Expression, Catabolism, Phosphorylation, and Localization are relatively easy, yet GUSPEE performed rather poorly on them.", "labels": [], "entities": []}, {"text": "Simple events do not admit multiple arguments, so they appear less often in the virtual evidence, and grounded learning has difficulty learning these event types, especially their triggers.", "labels": [], "entities": []}, {"text": "In light of this, it's actually remarkable that GUSPEE still learned a substantial portion of them.", "labels": [], "entities": [{"text": "GUSPEE", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.6411793828010559}]}], "tableCaptions": [{"text": " Table 1: GENIA event extraction results of GUSPEE", "labels": [], "entities": [{"text": "GENIA event extraction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.590864916642507}, {"text": "GUSPEE", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.6184603571891785}]}, {"text": " Table 2: GENIA event extraction results of state-of-the- art supervised system MSR11 (Quirk et al., 2011).", "labels": [], "entities": [{"text": "GENIA event extraction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.5914689699808756}]}, {"text": " Table 3: GENIA event extraction results of GUSPEE  with five prototype words per event type", "labels": [], "entities": [{"text": "GENIA event extraction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6090352137883505}, {"text": "GUSPEE", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.7455651760101318}]}, {"text": " Table 4: Classification results on GENIA when events are  simplified to binary relations for distant supervision.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8430498242378235}]}]}