{"title": [{"text": "Learning Knowledge Graphs for Question Answering through Conversational Dialog", "labels": [], "entities": [{"text": "Question Answering through Conversational Dialog", "start_pos": 30, "end_pos": 78, "type": "TASK", "confidence": 0.6764048039913177}]}], "abstractContent": [{"text": "We describe how a question-answering system can learn about its domain from conversational dialogs.", "labels": [], "entities": []}, {"text": "Our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (KG), and uses the graph to solve questions.", "labels": [], "entities": []}, {"text": "We are the first to acquire knowledge for question-answering from open, natural language dialogs without a fixed ontology or domain model that predetermines what users can say.", "labels": [], "entities": []}, {"text": "Our relation-based strategies complete more successful dialogs than a query expansion baseline, our task-driven relations are more effective for solving science questions than relations from general knowledge sources, and our method is practical enough to generalize to other domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our goal is a question-answering (QA) system that learns about its domain from users in open, natural language dialogs.", "labels": [], "entities": []}, {"text": "Dialog learning interfaces built on top of existing QA systems can complement and refine knowledge acquired from other sources.", "labels": [], "entities": []}, {"text": "Even large QA systems such as) that utilize heavy domain engineering could benefit from focused dialogs to dynamically improve their knowledge.", "labels": [], "entities": []}, {"text": "A successful QA system requires domain knowledge.", "labels": [], "entities": [{"text": "QA", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9410542845726013}]}, {"text": "For example, 4th grade science questions are difficult since they often exclude knowledge necessary to relate answers to known facts.", "labels": [], "entities": []}, {"text": "The question in asks if an iron nail conducts electricity; S1: Here's the question: Which object is the best conductor of electricity?", "labels": [], "entities": []}, {"text": "(A) a wax crayon (B) a plastic spoon (C) a rubber eraser (D) an iron nail.", "labels": [], "entities": []}, {"text": "I'm not sure of the answer.", "labels": [], "entities": []}, {"text": "What do you think the answer is?", "labels": [], "entities": []}, {"text": "U1: iron nail S2: Why do you think the answer is (D) an iron nail?", "labels": [], "entities": []}, {"text": "U2: electricity goes through metal S3: I know \"metals are shiny and good conductors of electricity and heat,\" does that mean that the answer is (D) an iron nail?", "labels": [], "entities": []}, {"text": "U3: yeah S4: Okay, great.", "labels": [], "entities": []}, {"text": "What's the relationship between 'electricity' and 'iron', if any?", "labels": [], "entities": []}, {"text": "U4: iron conducts electricity because its metal S5: Okay, great, I get it!", "labels": [], "entities": []}, {"text": "The answer is (D) an iron nail the system only knows that metal conducts electricity, and it needs to learn that iron is a metal in order to answer the question with the relevant fact.", "labels": [], "entities": []}, {"text": "Our dialog system, KNOWBOT, conducts dialogs about science questions and learns how concepts in each question relate to propositions in a corpus of science facts.", "labels": [], "entities": [{"text": "KNOWBOT", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.8459660410881042}]}, {"text": "KNOWBOT presents its user with a question (line S1 in), prompts them to choose and explain their answer, and extracts relations -any semantic relationship between two con-cepts, such as metal to iron (line U4 in) -that increase its confidence in the user's answer.", "labels": [], "entities": []}, {"text": "Relation extraction systems such as NELL) use ontologies to predetermine valid relation types and arguments, then scan text to fill the ontology with facts.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8590531349182129}]}, {"text": "Open Information Extraction) avoids fixed ontologies with domain-independent linguistic features, distant supervision, and redundancy, but requires web-scale text and doesn't improve with interaction.", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5784539580345154}]}, {"text": "Like Open IE, we extract relations without predetermined types, but are the first to do so from dialog.", "labels": [], "entities": []}, {"text": "KNOWBOT is an open dialog system, which means a user utterance may progress the dialog task even if its underlying action is not explicitly represented in a dialog model.", "labels": [], "entities": [{"text": "KNOWBOT", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8613194227218628}]}, {"text": "This lets KNOWBOT quickly bootstrap domain knowledge from users without significant engineering overhead.", "labels": [], "entities": []}, {"text": "Dialogdriven extraction produces effective relations without annotation, improves after each interaction, acquires relations useful on a particular task, and embeds relations in a rich dialog context.", "labels": [], "entities": [{"text": "Dialogdriven extraction", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8957560658454895}]}, {"text": "Users successfully correct the system in approximately 50% of dialogs even without a predetermined dialog model.", "labels": [], "entities": [{"text": "correct", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9436705112457275}]}, {"text": "A baseline query expansion ( strategy that bases decisions on the acquisition of new keywords instead of new relations results in only a 5% success rate.", "labels": [], "entities": []}, {"text": "In comparison to paraphrase relations from general knowledge bases, relations acquired by our method are more effective as domain knowledge, demonstrating that we successfully learn from real users.", "labels": [], "entities": []}, {"text": "Our contributions include: 1.", "labels": [], "entities": []}, {"text": "The first end-to-end system to construct knowledge graphs for question-answering through conversational dialog.", "labels": [], "entities": []}, {"text": "2. A generalizable method to represent the meaning of user utterances without a dialog model when task progression can be computed as a function of extracted relations.", "labels": [], "entities": []}, {"text": "3. A novel data set of real user dialogs in which users correct a QA system's answer, together with knowledge graphs representing the important concepts and relations in each question, labeled with rich dialog features.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our first experiment compares mixed-initiative and user-initiative strategies (section 3.2) to a baseline interactive query expansion (section 4.1).", "labels": [], "entities": []}, {"text": "The purpose of this experiment is to investigate whether users can successfully complete our complex dialog task even though we don't use a trained semantic parser for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 168, "end_pos": 198, "type": "TASK", "confidence": 0.705971340338389}]}, {"text": "Dialogs were conducted through a web browser.", "labels": [], "entities": []}, {"text": "Users were colleagues and interns at the Allen Institute for Artificial Intelligence, and so were familiar with the question-answering task but were not expert annotators.", "labels": [], "entities": []}, {"text": "Users were invited to converse with the system of their choice, and to move onto anew question if they felt the dialog was not progressing.", "labels": [], "entities": []}, {"text": "Individual dialog sessions were anonymous.", "labels": [], "entities": []}, {"text": "The system starts each dialog with an empty knowledge graph, using only identity relations to select its answer.", "labels": [], "entities": []}, {"text": "This default answer is correct on 44 of the 107 questions, and an additional 10 questions have no associated supporting sentence for the correct answer in SCITEXT.", "labels": [], "entities": []}, {"text": "We run dialogs for the remaining 53 questions, for which each answer candidate has 80 supporting sentences in SCITEXT on average.", "labels": [], "entities": []}, {"text": "A successful dialog terminates when the system extracts enough novel relations from the user that the correct answer has the highest alignment score with one of its supporting sentences.", "labels": [], "entities": [{"text": "alignment score", "start_pos": 133, "end_pos": 148, "type": "METRIC", "confidence": 0.9684567451477051}]}, {"text": "Experiment 1 evaluated whether users could successfully complete our dialog task.", "labels": [], "entities": []}, {"text": "Next, we evaluate whether the total output of our system, all relations acquired during all 431 conducted dialogs, represents useful domain knowledge on this task.", "labels": [], "entities": []}, {"text": "We evaluate on questions for which dialogs have been held to investigate whether it's possible to learn any domain knowledge from natural language conversation without a dialog model, irrespective of overfitting.", "labels": [], "entities": []}, {"text": "We then use cross-validation to test if knowledge transfers between questions.", "labels": [], "entities": []}, {"text": "As described in section 2, our QA system decomposes each question/answer pair into a true/false statement and chooses as its answer the statement among the four that has the best supporting sentence in a text corpus.", "labels": [], "entities": []}, {"text": "Equation (1) scores each questionanswer statement by using domain relations to align question concepts to support concepts.", "labels": [], "entities": []}, {"text": "The next section describes sources of domain relations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of knowledge acquisition strate-", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.6594734042882919}]}]}