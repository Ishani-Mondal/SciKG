{"title": [{"text": "TopicCheck: Interactive Alignment for Assessing Topic Model Stability", "labels": [], "entities": [{"text": "Interactive Alignment", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.6558226943016052}, {"text": "Assessing Topic Model Stability", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.7380890548229218}]}], "abstractContent": [{"text": "Content analysis, a widely-applied social science research method, is increasingly being supplemented by topic modeling.", "labels": [], "entities": [{"text": "Content analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8247998654842377}]}, {"text": "However, while the discourse on content analysis centers heavily on reproducibility, computer scientists often focus more on scalability and lesson coding reliability, leading to growing skepticism on the usefulness of topic models for automated content analysis.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7243871539831161}, {"text": "automated content analysis", "start_pos": 236, "end_pos": 262, "type": "TASK", "confidence": 0.7410627206166586}]}, {"text": "In response, we introduce TopicCheck, an interactive tool for assessing topic model stability.", "labels": [], "entities": []}, {"text": "First, from established guidelines on reproducible content analysis, we distill a set of design requirements on how to computationally assess the stability of an automated coding process.", "labels": [], "entities": [{"text": "reproducible content analysis", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.7280474702517191}]}, {"text": "Second, we devise an interactive alignment algorithm for matching latent topics from multiple models, and enable sensitivity evaluation across a large number of models.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate that our tool enables social scientists to gain novel insights into three active research questions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Content analysis -the examination and systematic categorization of written texts -is a fundamental and widely-applied research method in the social sciences and humanities, found in one third of all articles published in major communication journals.", "labels": [], "entities": [{"text": "Content analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7339405119419098}]}, {"text": "Initial reading and coding, two labor- * Work completed while at Stanford University and the University of Washington, and submitted while at the Allen Institute for Artificial Intelligence.", "labels": [], "entities": []}, {"text": "\u2020 These authors contributed equally to this paper.", "labels": [], "entities": []}, {"text": "intensive steps in the analysis process, are increasingly replaced by computational approaches such as statistical topic modeling).", "labels": [], "entities": [{"text": "statistical topic modeling", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.7513392766316732}]}, {"text": "However, while the discourse on content analysis overwhelmingly centers around the reproducibility and generalizability of a coding scheme), computer scientists tend to focus more on increasing the scale of analysis and lesson establishing coding reliability.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7022016644477844}]}, {"text": "Machine-generated latent topics are often taken on faith to be a truthful and consistent representation of the underlying corpus, but in practice exhibit significant variations among models or modeling runs.", "labels": [], "entities": []}, {"text": "These unquantified uncertainties fuel growing skepticism and hamper the continued adoption () of topic models for automated content analysis.", "labels": [], "entities": [{"text": "automated content analysis", "start_pos": 114, "end_pos": 140, "type": "TASK", "confidence": 0.6849815050760905}]}, {"text": "In response, we introduce TopicCheck, an interactive tool for assessing the stability of topic models.", "labels": [], "entities": []}, {"text": "Our threefold contributions are as follows.", "labels": [], "entities": []}, {"text": "First, from established guidelines on reproducible content analysis, we distill a set of design requirements on how to computationally assess the stability of an automated coding process.", "labels": [], "entities": [{"text": "reproducible content analysis", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.7280474702517191}]}, {"text": "We advocate for the use of multiple models for analysis, a user-driven approach to identify acceptable levels of coding uncertainty, and providing users with the capability to inspect model output at all levels of detail.", "labels": [], "entities": []}, {"text": "Second, we devise an interactive up-to-one alignment algorithm for assessing topic model stability.", "labels": [], "entities": []}, {"text": "Through repeated applications of a topic model to generate multiple outputs, our tool allows users to inspect whether the model consistently uncover the same set of concepts.", "labels": [], "entities": []}, {"text": "We allow users to interactively define groupings of matching topics, and present the aligned topics using an informative tabular layout, so that users can quickly identify stable topical groupings as well as any inconsistencies.", "labels": [], "entities": []}, {"text": "Finally, in three case studies, we demonstrate that our tool allows social scientists to gain novel insights into active and ongoing research questions.", "labels": [], "entities": []}, {"text": "We provide an in-depth look at the multi-modality of topic models.", "labels": [], "entities": []}, {"text": "We document how text pre-processing alters topical compositions, causing shifts in definitions and the removal of select topics.", "labels": [], "entities": []}, {"text": "We report on how TopicCheck supports the validity of newlyproposed communication research methods.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}