{"title": [{"text": "Active Learning with Rationales for Text Classification", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8161169588565826}]}], "abstractContent": [{"text": "We present a simple and yet effective approach that can incorporate rationales elicited from annotators into the training of any off-the-shelf classifier.", "labels": [], "entities": []}, {"text": "We show that our simple approach is effective for multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes, logistic regression, and support vector machines.", "labels": [], "entities": []}, {"text": "We additionally present an active learning method tailored specifically for the learning with rationales framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "Annotating documents for supervised learning is a tedious, laborious, and time consuming task for humans.", "labels": [], "entities": []}, {"text": "Given huge amounts of unlabeled documents, it is impractical for annotators to go over each document and provide a label.", "labels": [], "entities": []}, {"text": "To reduce the annotation time and effort, various approaches such as semi-supervised learning) that utilizes both labeled and unlabeled data, and active learning) that carefully chooses instances for annotation have been developed.", "labels": [], "entities": []}, {"text": "To further minimize the human effort, recent work looked at eliciting domain knowledge, such as rationales and feature annotations, from the annotators instead of just the labels of documents.", "labels": [], "entities": []}, {"text": "One of the bottlenecks in eliciting domain knowledge from annotators is that the traditional supervised learning approaches cannot readily handle the elicited rich feedback.", "labels": [], "entities": []}, {"text": "To address this issue, many methods have been developed that are classifierspecific.", "labels": [], "entities": []}, {"text": "Examples include knowledge-based neural networks (e.g.,,, (), knowledgebased support vector machines (), pooling multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes ( , incorporating constraints into the training of na\u00a8\u0131vena\u00a8\u0131ve Bayes (, and converting rationales and feature annotations into constraints for support vector machines (e.g.,) and ().", "labels": [], "entities": []}, {"text": "Being classifier-specific limits their applicability when one wants to test a different classifier for his/her domain, necessitating an approach that can be utilized by several off-the-shelf classifiers.", "labels": [], "entities": []}, {"text": "In this paper we present a simple and yet effective approach that can incorporate the elicited rationales in the form of feature annotations into the training of any off-the-shelf classifier.", "labels": [], "entities": []}, {"text": "We empirically show that it is effective at incorporating rationales into the learning of na\u00a8\u0131vena\u00a8\u0131ve Bayes, logistic regression, and support vector machines using four text categorization datasets.", "labels": [], "entities": []}, {"text": "We further discuss a novel active learning strategy specifically geared towards the learning with rationales framework and empirically show that it improves over traditional active learning.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we provide a brief background on eliciting rationales in the context of active learning.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our approach for incorporating rationales into the training of classifiers and compare learning without rationales and learning with rationales.", "labels": [], "entities": []}, {"text": "In Section 4, we present an active learning method using the learning with rationales framework and present relevant results.", "labels": [], "entities": []}, {"text": "Finally, we discuss limitations and future work in Section 5, related work in Section 6, and conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we first describe the settings, datasets, and classifiers used for our experiments and how we simulated a human labeler to provide rationales.", "labels": [], "entities": []}, {"text": "Then, we present the results comparing the learning curves achieved with learning without rationales (Lw/oR) and learning with rationales (LwR).", "labels": [], "entities": []}, {"text": "We used the same four text datasets and evaluated our method UNC-PC using multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes, logistic regression, and support vector machines.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.9864993095397949}]}, {"text": "For the active learning strategies, we used a bootstrap of 10 random documents, and labeled five documents at each round of active learning.", "labels": [], "entities": []}, {"text": "We used a budget of 200 documents for all methods.", "labels": [], "entities": []}, {"text": "UNC simply picks the top five uncertain documents, whereas UNC-PC looks at top 20 uncertain documents and picks five uncertain documents giving preference to the conflicting cases (type 3) over the non-conflicting cases (type1 and type2).", "labels": [], "entities": [{"text": "UNC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9820928573608398}, {"text": "UNC-PC", "start_pos": 59, "end_pos": 65, "type": "DATASET", "confidence": 0.9259729981422424}]}, {"text": "We repeated each experiment 10 times starting with a different bootstrap at each trial and report the average results.", "labels": [], "entities": []}, {"text": "In we show the learning curves comparing UNC-PC with UNC for multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 41, "end_pos": 47, "type": "DATASET", "confidence": 0.9526963829994202}, {"text": "UNC", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.9712594747543335}]}, {"text": "(Logistic regression and SVM curves are omitted due to space.)", "labels": [], "entities": []}, {"text": "Since the results for LwR using tf-idf representation are better than the results using the binary representation, we compared UNC-PC to UNC for LwR using only the tf-idf representation.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 127, "end_pos": 133, "type": "DATASET", "confidence": 0.9746100306510925}, {"text": "UNC", "start_pos": 137, "end_pos": 140, "type": "DATASET", "confidence": 0.9309927821159363}]}, {"text": "We see that for multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes, UNC-PC improves over traditional uncertainty, UNC, on two datasets, and hurts performance on one dataset.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.778168797492981}, {"text": "UNC", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.7877251505851746}]}, {"text": "Next, we discuss the significance results for all classifiers.", "labels": [], "entities": []}, {"text": "shows the paired t-test results comparing the learning curves of UNC-PC with the learning curves of UNC at each step of the active learning (i.e, if the average of one learning curve is significantly better or worse than the average of the learning curve of the other).", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 65, "end_pos": 71, "type": "DATASET", "confidence": 0.979330837726593}, {"text": "UNC", "start_pos": 100, "end_pos": 103, "type": "DATASET", "confidence": 0.9758700132369995}]}, {"text": "If UNC-PC has a higher average AUC than UNC with a t-test significance level of 0.05 or better, it is a Win (W), if it has significantly lower performance, it is a Loss (L), and if the difference is not statistically significant, the result is a Tie (T).", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.9617963433265686}, {"text": "AUC", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9619830846786499}, {"text": "UNC", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.9697955250740051}, {"text": "t-test significance level", "start_pos": 51, "end_pos": 76, "type": "METRIC", "confidence": 0.8292375008265177}, {"text": "Win (W)", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9525758922100067}, {"text": "Loss (L)", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9552521705627441}, {"text": "Tie (T)", "start_pos": 246, "end_pos": 253, "type": "METRIC", "confidence": 0.9600493609905243}]}, {"text": "Using multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes, UNC-PC wins over UNC for two of the datasets (IMDB and WvsH), does not cause any significant changes for Nova (ties all the time), and loses for SRAA.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.8965915441513062}, {"text": "UNC", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.9688762426376343}, {"text": "IMDB", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.8539606332778931}, {"text": "Nova", "start_pos": 143, "end_pos": 147, "type": "DATASET", "confidence": 0.9333094954490662}, {"text": "SRAA", "start_pos": 183, "end_pos": 187, "type": "DATASET", "confidence": 0.8528727293014526}]}, {"text": "Using logistic regression, UNC-PC wins for two datasets (Nova and SRAA), ties for WvsH and loses for IMDB.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.8871583938598633}, {"text": "Nova", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.9193660020828247}, {"text": "WvsH", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.5764291286468506}, {"text": "IMDB", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.7441961765289307}]}, {"text": "Using support vector machines, UNC-PC wins for three datasets (Nova, SRAA, and WvsH) and loses for IMDB.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.8196289539337158}, {"text": "Nova", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.9367823004722595}, {"text": "IMDB", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.9050015807151794}]}, {"text": "The t-test results show that UNC-PC often improves learning over UNC.", "labels": [], "entities": [{"text": "UNC-PC", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.8580974340438843}, {"text": "UNC", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9597510695457458}]}], "tableCaptions": []}