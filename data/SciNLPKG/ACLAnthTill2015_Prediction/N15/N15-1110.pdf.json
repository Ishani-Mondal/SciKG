{"title": [{"text": "Matching Citation Text and Cited Spans in Biomedical Literature: a Search-Oriented Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "Citation sentences (citances) to a reference article have been extensively studied for sum-marization tasks.", "labels": [], "entities": []}, {"text": "However, citances might not accurately represent the content of the cited article, as they often fail to capture the context of the reported findings and can be affected by epistemic value drift.", "labels": [], "entities": []}, {"text": "Following the intuition behind the TAC (Text Analysis Conference) 2014 Biomedical Summarization track, we propose a system that identifies text spans in the reference article that are related to a given citance.", "labels": [], "entities": [{"text": "TAC (Text Analysis Conference) 2014 Biomedical Summarization", "start_pos": 35, "end_pos": 95, "type": "TASK", "confidence": 0.6556634803613027}]}, {"text": "We refer to this problem as citance-reference spans matching.", "labels": [], "entities": [{"text": "citance-reference spans matching", "start_pos": 28, "end_pos": 60, "type": "TASK", "confidence": 0.6447054048379263}]}, {"text": "We approach the problem as a retrieval task; in this paper, we detail a comparison of different ci-tance reformulation methods and their combinations.", "labels": [], "entities": [{"text": "ci-tance reformulation", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.7031867802143097}]}, {"text": "While our results show improvement over the baseline (up to 25.9%), their absolute magnitude implies that there is ample room for future improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "The size of scientific literature has increased dramatically during recent decades.", "labels": [], "entities": []}, {"text": "In biomedical domain for example, PubMed -the largest repository of biomedical literature -contains more than 24 million articles.", "labels": [], "entities": []}, {"text": "Thus, there is a need for concise presentation of important findings in the scientific articles being published.", "labels": [], "entities": []}, {"text": "Text summarization of scientific articles is a method for such presentation.", "labels": [], "entities": [{"text": "Text summarization of scientific articles", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.839867091178894}]}, {"text": "One obvious form of scientific summaries, is the abstract of the articles.", "labels": [], "entities": []}, {"text": "Another type of scientific summaries relates to citance-based summaries which are summaries created using the set of citations to a reference article.", "labels": [], "entities": []}, {"text": "This kind of summary covers some aspects of the reference article which might not be present in its abstract (.", "labels": [], "entities": []}, {"text": "Citances often cover important and novel insights about findings or aspects of a paper that others Reference Article): \"These miRNAs neutralize p53-mediated CDK inhibition, possibly through direct inhibition of the expression of the tumor suppressor LATS2.\"", "labels": [], "entities": [{"text": "miRNAs neutralize p53-mediated CDK inhibition", "start_pos": 126, "end_pos": 171, "type": "TASK", "confidence": 0.6191012918949127}]}, {"text": "Citing Article): \"Two oncogenic miRNAs, miR-372 and miR-373, directly inhibit the expression of Lats2, thereby allowing tumorigenic growth in the presence of p53 ().\"", "labels": [], "entities": []}, {"text": "Figure 1: Example of epistemic value drift from).", "labels": [], "entities": []}, {"text": "The claim in) becomes fact in have found interesting; thus, they capture contributions that had an impact on the research community (.", "labels": [], "entities": []}, {"text": "In the past, many have focused on citance extraction and citance-based summarization.", "labels": [], "entities": [{"text": "citance extraction", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8393594026565552}]}, {"text": "Example of citance extraction include, who used a machine learning approach with linguistic, lexical, statistical and positional features, and (), who studied a coreference resolution based approach.", "labels": [], "entities": [{"text": "citance extraction", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.819381594657898}, {"text": "coreference resolution", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.8065891861915588}]}, {"text": "Citance extraction has been also studied in the context of automatic summarization.", "labels": [], "entities": [{"text": "Citance extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8989580571651459}, {"text": "summarization", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.7914229035377502}]}, {"text": "For example, proposed a framework based on probabilistic inference to identify citances, while (Abu-Jbara and Radev, 2011) approached the problem as a classification task.", "labels": [], "entities": []}, {"text": "In the biomedical domain, the use of citances was first studied by).", "labels": [], "entities": []}, {"text": "While useful, citances by themselves lack the appropriate evidence to capture the exact content of the original paper, such as circumstances, data and assumptions under which certain findings were obtained.", "labels": [], "entities": []}, {"text": "Citance-based summaries might also modify the epistemic value of a claim presented in the cited work; that is, they might report a preliminary result or a claim as a definite fact (example in.", "labels": [], "entities": []}, {"text": "Recently, anew track at TAC has been introduced to explore ways to generate better citance-based summaries . One way to achieve this, is to link citances to text spans in the reference article to obtain a more informative collection of sentences representing the reference article (figure 2).", "labels": [], "entities": [{"text": "TAC", "start_pos": 24, "end_pos": 27, "type": "DATASET", "confidence": 0.8737151026725769}]}, {"text": "A framework designed to solve such problem requires two components: (i) a method to identify the most relevant spans of text in the reference text and (ii) a system to automatically generate a summary given a set of citances and reference spans.", "labels": [], "entities": []}, {"text": "In this paper, we propose an information retrieval approach designed to address the first task.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8540650308132172}]}, {"text": "We explore the impact of several query reformulation techniques -some domain independent, others tailored to biomedical literature -on the performance of the system.", "labels": [], "entities": [{"text": "query reformulation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7766384482383728}]}, {"text": "Furthermore, we apply combined reformulations, which yields an additional improvement over any single method (25% over the baseline).", "labels": [], "entities": []}, {"text": "As a related area, passage retrieval in biomedical articles has been studied in the context of the genomics track and in following efforts ().", "labels": [], "entities": [{"text": "passage retrieval in biomedical articles", "start_pos": 19, "end_pos": 59, "type": "TASK", "confidence": 0.9175796270370483}]}, {"text": "In these works, the goal is to find passages that relate to a given term or keyword (e.g. GeneRIF).", "labels": [], "entities": []}, {"text": "In contrast, our system considers citances as queries, which are substantially longer than keyword-based queries and have a syntactical structure.", "labels": [], "entities": []}, {"text": "In summary, our contributions are: (i) A search-based, unsupervised (thus easily scalable to other domains) approach to citance-reference spans matching and (ii) adaptation of various query reformulation techniques for the citatnce-refrence span matching.", "labels": [], "entities": [{"text": "citance-reference spans matching", "start_pos": 120, "end_pos": 152, "type": "TASK", "confidence": 0.6277262965838114}, {"text": "citatnce-refrence span matching", "start_pos": 223, "end_pos": 254, "type": "TASK", "confidence": 0.6941710114479065}]}], "datasetContent": [{"text": "The system was evaluated on TAC 2014 Biomedical Summarization track training dataset.", "labels": [], "entities": [{"text": "TAC 2014 Biomedical Summarization track training dataset", "start_pos": 28, "end_pos": 84, "type": "DATASET", "confidence": 0.8713820321219308}]}, {"text": "It consists of 20 topics, each of which contains between 10 to 20 citing articles and 1 reference article.", "labels": [], "entities": []}, {"text": "For each topic, four domain experts were asked to identify the appropriate reference spans for each citance in the reference text.", "labels": [], "entities": []}, {"text": "To better understand the dataset, we analyzed the agreement between annotators (table 1).", "labels": [], "entities": []}, {"text": "This table shows that the overall agreement is relatively low.", "labels": [], "entities": [{"text": "agreement", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9865401387214661}]}, {"text": "We used two sets of metrics for evaluation of the task.", "labels": [], "entities": []}, {"text": "The first one is based on the weighted overlaps between the retrieved spans and the correct spans designated by annotators and is meant to reward spans overlapping with the ground truth.", "labels": [], "entities": []}, {"text": "Weighted recall and precision fora system returning span S with respect to a set of M annotators, consisting of gold spans G 1 , ..., GM are defined as follows: The overall score of the system is the mean F-1 (harmonic mean of the weighted precision and recall) overall the topics.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9906622767448425}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.992565393447876}, {"text": "F-1", "start_pos": 205, "end_pos": 208, "type": "METRIC", "confidence": 0.9757330417633057}, {"text": "precision", "start_pos": 240, "end_pos": 249, "type": "METRIC", "confidence": 0.9223302006721497}, {"text": "recall", "start_pos": 254, "end_pos": 260, "type": "METRIC", "confidence": 0.9371455311775208}]}, {"text": "Based on the weighted F-1 score, a method could be penalized for retrieving any spans that are not indicated as gold spans by the annotators.", "labels": [], "entities": [{"text": "F-1 score", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.961836963891983}]}, {"text": "Even if those spans are semantically similar to the gold spans, they will not receive any score.", "labels": [], "entities": []}, {"text": "This is not ideal because, as the high disagreement shown in table 1 implies, gold spans by offset locations are highly controversial.", "labels": [], "entities": []}, {"text": "For this reason, we also considered ROUGE-L) as another evaluation metric, as it rewards a method for retrieving spans that are similar to the gold spans.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9936756491661072}]}, {"text": "Specifically, ROUGE-L, takes into account the sentence similarity by considering the longest in sequence n-grams between the retrieved spans and gold spans.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9718269109725952}]}], "tableCaptions": [{"text": " Table 1: Levels of agreement between annotators. The  4 annotators fully agree on just 2 of the 313 annotations.  In most cases, a majority (3 annotators) or a minority (2  annotators) agrees on a portion of reference spans, indi- cating that the task is not trivial even for domain experts.", "labels": [], "entities": []}, {"text": " Table 2: Results for reference span matching; KW: reduction using KeyWords; NP: reduction using Noun Phrases;  UMLS-expand: expansion using UMLS; UMLS-reduce: reduction using UMLS; * (**) indicates statistical significance  at p < 0.05 (p < 0.01) using student's t-test over the baseline.", "labels": [], "entities": [{"text": "reference span matching", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.6768770813941956}]}]}