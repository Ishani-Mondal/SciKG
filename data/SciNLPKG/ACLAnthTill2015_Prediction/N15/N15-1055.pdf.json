{"title": [{"text": "Robust Morphological Tagging with Word Representations", "labels": [], "entities": [{"text": "Robust Morphological Tagging with Word Representations", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.7120229403177897}]}], "abstractContent": [{"text": "We present a comparative investigation of word representations for part-of-speech (POS) and morphological tagging, focusing on scenarios with considerable differences between training and test data where a robust approach is necessary.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.7343004047870636}]}, {"text": "Instead of adapting the model towards a specific domain we aim to build a robust model across domains.", "labels": [], "entities": []}, {"text": "We developed a test suite for robust tagging consisting of six languages and different domains.", "labels": [], "entities": []}, {"text": "We find that representations similar to Brown clusters perform best for POS tagging and that word representations based on linguistic morphological analyzers perform best for morphological tagging .", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.8470850586891174}, {"text": "morphological tagging", "start_pos": 175, "end_pos": 196, "type": "TASK", "confidence": 0.6831143349409103}]}], "introductionContent": [{"text": "Most natural language processing (NLP) tasks can be better solved if a preprocessor tags each word in the natural language input with a label like \"noun, singular\" or \"verb, past tense\" that gives some indication of the syntactic role that the word plays in its context.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 5, "end_pos": 38, "type": "TASK", "confidence": 0.7991448839505514}]}, {"text": "The most common form of such preprocessing is POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.7180013805627823}]}, {"text": "However, for morphologically rich languages, a large subset of the languages of the world, POS tagging in its original form -where labels are syntactic categories with little or no morphological information -does not make much sense.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.8260208368301392}]}, {"text": "The reason is that POS and morphological properties are mutually dependent, so solving only one task or solving the tasks sequentially is inadequate.", "labels": [], "entities": []}, {"text": "The most important dependence of this type is that POS can be read off morphology in many cases; e.g., the morphological suffix \"-iste\" is a reliable indicator of the informal second person singular preterite indicative form of a verb in Spanish.", "labels": [], "entities": [{"text": "POS", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8625832200050354}]}, {"text": "In what follows, we use the term \"morphological tagging\" to refer to \"morphological and POS tagging\" since morphological tags generally include POS information.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.6769132763147354}]}, {"text": "The importance of morphological tagging as part of the computational linguistics processing pipeline motivated us to conduct the research reported in this paper.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.6943180710077286}, {"text": "computational linguistics processing", "start_pos": 55, "end_pos": 91, "type": "TASK", "confidence": 0.7157327731450399}]}, {"text": "The specific setting that we address is increasingly recognized as the setting in which most practical NLP takes place: We look at scenarios with considerable differences between the training data and the application data, i.e., between the data that the tagger is trained on and the data that it is applied to.", "labels": [], "entities": []}, {"text": "This type of scenario is frequent because of the great diversity and variability of natural language and because of the high cost of annotation -which makes it impossible to create large training sets for each new domain.", "labels": [], "entities": []}, {"text": "For this reason, we address morphological tagging in a setting in which training and application data differ.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.6830027401447296}]}, {"text": "The most common approach to this setting is domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.8375347852706909}]}, {"text": "Domain adaptation has been demonstrated to have good performance in scenarios with differently distributed training/test data.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8018214106559753}]}, {"text": "However, it has two disadvantages.", "labels": [], "entities": []}, {"text": "First, it requires the availability of data from the target domain.", "labels": [], "entities": []}, {"text": "Second, we need to do some extra work in domain adaptation -consisting of taking target domain data and using it to adapt our NLP system to the target domain -and we end up with a number of different versions of our NLP system.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7527284026145935}]}, {"text": "The extra work required and the pro-liferation of different versions increase the possibility of errors and increase the complexity of deploying NLP technology.", "labels": [], "entities": []}, {"text": "Similar to other recent work, we therefore take an approach that is different from domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.7798684239387512}]}, {"text": "We build a system that is robust across domains without any modification.", "labels": [], "entities": []}, {"text": "As a result, no extra work is required when the system is applied to anew domain: there is only one system and we can use it for all domains.", "labels": [], "entities": []}, {"text": "The key to making NLP components robust across domains is the use of powerful domain-independent representations for words.", "labels": [], "entities": []}, {"text": "One of the main contributions of this paper is that we compare the performance of the most important representations that can be used for this purpose.", "labels": [], "entities": []}, {"text": "We find that two of these are best suited for robust tagging.", "labels": [], "entities": [{"text": "robust tagging", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.49903182685375214}]}, {"text": "MarLiN) clusters -a derivative of Brown clusters -perform best for POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.7946284711360931}]}, {"text": "MarLiN clusters are also an order of magnitude more efficient to induce than the original Brown clusters.", "labels": [], "entities": []}, {"text": "We provide an open source implementation of MarLiN clustering as part of this publication (Section 8).", "labels": [], "entities": [{"text": "MarLiN clustering", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7487548589706421}]}, {"text": "We compare the word representations to Morphological Analyzers (MAs), which are finite-state transducers that find the stems of a form and use them to derive all its possible morphological readings.", "labels": [], "entities": []}, {"text": "MAs produce the best results in our experiments on morphological tagging.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.7493237257003784}]}, {"text": "Our initial expectation was that domain differences and lack of coverage would put manually created MAs at a disadvantage when compared to learning algorithms that are run on very large text corpora.", "labels": [], "entities": []}, {"text": "However, our results clearly show that MA-based representations are the best representations to use for robust morphological tagging.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.6007895767688751}]}, {"text": "The motivation for our work is that both morphological tagging and the \"robust\" application setting are important areas of research in NLP.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7438682317733765}]}, {"text": "To support this research, we created an extensive evaluation set for six languages.", "labels": [], "entities": []}, {"text": "This involved identifying morphologically rich languages in which usable data sets with different distributional properties were available, designing mappings between different tag sets, organizing a manual annotation effort for one of the six languages and preparing large \"general\" (not domain-specific) data sets for unsupervised learning of word representations.", "labels": [], "entities": []}, {"text": "The preparation and publication (Section 8) of this test suite is in itself a significant contribution.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses related work.", "labels": [], "entities": []}, {"text": "Section 3 presents the representations we tested.", "labels": [], "entities": []}, {"text": "Section 4 describes the data sets and the annotation and conversion efforts required to create the in-domain (ID) and out-of-domain (OOD) data sets.", "labels": [], "entities": []}, {"text": "In Section 5, we describe the experiments and discuss our findings.", "labels": [], "entities": []}, {"text": "In Section 6, we provide an analysis of our results.", "labels": [], "entities": []}, {"text": "Section 7 summarizes our findings and contributions.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all our experiments we use) a joint POS and morphological tagger.", "labels": [], "entities": []}, {"text": "The CRF tagger employs a pruning strategy on forward-backward lattices to efficiently handle big tag sets and higher orders.", "labels": [], "entities": [{"text": "CRF tagger", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.7182230353355408}]}, {"text": "Its feature set is similar to and and includes prefixes, suffixes, immediate lexical context and shape features based on capitalization, special characters and digits.", "labels": [], "entities": []}, {"text": "MarMoT was shown to be a competitive POS and morphological tagger czechtok/ 6 For statistics of the unlabeled data sets cf. across six languages.", "labels": [], "entities": [{"text": "MarMoT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8998011946678162}]}, {"text": "In order to make sure that it is also robust in an OOD setup we compare it to the two popular taggers SVMTool () and Morfette ().", "labels": [], "entities": [{"text": "SVMTool", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.8335315585136414}]}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "MarMoT uses stochastic gradient descent and produces different results in each training run.", "labels": [], "entities": [{"text": "MarMoT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9226083755493164}]}, {"text": "We therefore always report the average of five runs.", "labels": [], "entities": [{"text": "average", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9617392420768738}]}, {"text": "The OOD numbers are macro-averages over the different OOD data sets of a language.", "labels": [], "entities": [{"text": "OOD data sets", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.7865587572256724}]}, {"text": "The tables in this paper are based on the development sets; the only exception to this is, which is based on the test set.", "labels": [], "entities": []}, {"text": "MarMoT outperforms SVMTool and Morfette on every language and setup (ID / OOD) except for the Spanish OOD data set.", "labels": [], "entities": [{"text": "MarMoT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.6790491342544556}, {"text": "Spanish OOD data set", "start_pos": 94, "end_pos": 114, "type": "DATASET", "confidence": 0.8025822937488556}]}, {"text": "For Czech, German and Latin the improvements over the best baseline are >1.", "labels": [], "entities": []}, {"text": "Different orders of MarMoT behave as expected: higher-order models (order>1) outperform first-order models.", "labels": [], "entities": [{"text": "MarMoT", "start_pos": 20, "end_pos": 26, "type": "DATASET", "confidence": 0.8214482069015503}]}, {"text": "The only exception to this is Latin.", "labels": [], "entities": []}, {"text": "This suggests a drastic difference of the tag transition probabilities between the Latin ID and OOD data sets.", "labels": [], "entities": [{"text": "OOD data sets", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.8732578754425049}]}, {"text": "Given the results in and for simplicity we use an second-order MarMoT model in all subsequent experiments.", "labels": [], "entities": []}, {"text": "We first compare different implementations of LM-based clustering.", "labels": [], "entities": [{"text": "LM-based clustering", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8156980276107788}]}, {"text": "The implementation of Brown clustering by is most commonly used.", "labels": [], "entities": [{"text": "Brown clustering", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.5276954472064972}]}, {"text": "Its hierarchical binary structure can be used to extract clusterings of varying granularity by selecting different prefixes of the path from the root to a specific word form.", "labels": [], "entities": []}, {"text": "Following other work, we induce 1000 clusters and select path lengths 4, 6, 10 and 20.", "labels": [], "entities": []}, {"text": "We call this representation Brown path.", "labels": [], "entities": []}, {"text": "We compare Brown path to mkcls 10 (Och, 1999) and MarLiN.", "labels": [], "entities": [{"text": "MarLiN", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.6936098337173462}]}, {"text": "These implementations just induce flat clusterings of a certain size; we thus run them for cluster sizes 100, 200, 500 and 1000 to also obtain cluster ids of different sizes.", "labels": [], "entities": []}, {"text": "The cluster sizes roughly resemble the granularity obtained in Brown path . We call the corresponding mod- MarMoT MarMoT MarMoT  For German the Brown algorithm takes \u2248 5000 min, mkcls \u2248 2000 min and MarLiN \u2248 500 min.", "labels": [], "entities": [{"text": "MarMoT MarMoT MarMoT", "start_pos": 107, "end_pos": 127, "type": "DATASET", "confidence": 0.5557185411453247}, {"text": "MarLiN", "start_pos": 199, "end_pos": 205, "type": "METRIC", "confidence": 0.9048931002616882}]}, {"text": "shows that the absolute differences between systems are small, but overall MarLiN and mkcls are better.", "labels": [], "entities": [{"text": "MarLiN", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.5514030456542969}]}, {"text": "We conclude that systems based on the algorithm of are slightly more accurate for tagging and are several times faster than the more frequently used version of.", "labels": [], "entities": [{"text": "tagging", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.9751737117767334}]}, {"text": "We thus use MarLiN for the remainder of this paper.", "labels": [], "entities": [{"text": "MarLiN", "start_pos": 12, "end_pos": 18, "type": "DATASET", "confidence": 0.5358299016952515}]}, {"text": "We compare MarLiN with the implementation of CW by Al-.", "labels": [], "entities": [{"text": "MarLiN", "start_pos": 11, "end_pos": 17, "type": "DATASET", "confidence": 0.7275413274765015}]}, {"text": "They extracted 64-dimensional representations for only the most frequent 100,000 word forms.", "labels": [], "entities": []}, {"text": "To make the comparison fair, we use the intersection of our and their representation vocabularies.", "labels": [], "entities": []}, {"text": "The results in   best in 15 out of 22 cases and significantly better in eight.", "labels": [], "entities": []}, {"text": "CW is best in 9 out of 22 cases and significantly better in two.", "labels": [], "entities": [{"text": "CW", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.7367621660232544}]}, {"text": "We conclude that LM-based representations are more suited for tagging as they can be induced faster, are smaller and give better results.", "labels": [], "entities": [{"text": "tagging", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.9721131324768066}]}, {"text": "For the SVDbased representation we use feature ranks out of {500, 1000} and dimensions out of {50, 100, 200, 500}.", "labels": [], "entities": []}, {"text": "We found that l1-normalizing the vectors before and after the SVD improved results slightly.", "labels": [], "entities": []}, {"text": "For the accumulated tag counts (ACT) we annotate the data with our baseline model and extract wordtag probabilities.", "labels": [], "entities": [{"text": "accumulated tag counts (ACT)", "start_pos": 8, "end_pos": 36, "type": "METRIC", "confidence": 0.7416272461414337}]}, {"text": "The probabilities are then used as sparse real-valued features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Baseline experiments comparing MarMoT models of different orders with Morfette and SVMTool. Num- bers denote average accuracies on ID and OOD development sets on the full morphological tagging task. A result  significantly better than the other four ID (resp. OOD) results in its row is marked with  * .", "labels": [], "entities": []}, {"text": " Table 2: Tagging results for LM-based models", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9873315691947937}]}, {"text": " Table 3: Tagging results for CW", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9859116077423096}]}, {"text": " Table 4: Tagging results for the baseline and four different representations", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9767743945121765}]}, {"text": " Table 5: Test set results for: baseline, MarLiN, MA", "labels": [], "entities": [{"text": "MarLiN", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.9043680429458618}, {"text": "MA", "start_pos": 50, "end_pos": 52, "type": "DATASET", "confidence": 0.5598564147949219}]}, {"text": " Table 6: Improvement compared to the baseline for dif- ferent frequency ranges of words on OOD", "labels": [], "entities": [{"text": "OOD", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.7357690930366516}]}]}