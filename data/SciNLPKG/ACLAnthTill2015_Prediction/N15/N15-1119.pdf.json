{"title": [{"text": "Unsupervised Entity Linking with Abstract Meaning Representation", "labels": [], "entities": [{"text": "Unsupervised Entity Linking with Abstract Meaning Representation", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.6156467965670994}]}], "abstractContent": [{"text": "Most successful Entity Linking (EL) methods aim to link mentions to their referent entities in a structured Knowledge Base (KB) by comparing their respective contexts, often using similarity measures.", "labels": [], "entities": [{"text": "Entity Linking (EL)", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.8251292705535889}]}, {"text": "While the KB structure is given, current methods have suffered from impoverished information representations on the mention side.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate the effectiveness of Abstract Meaning Representation (AMR) (Banarescu et al., 2013) to select high quality sets of entity \"collaborators\" to feed a simple similarity measure (Jaccard) to link entity mentions.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.7021700441837311}, {"text": "similarity measure (Jaccard)", "start_pos": 185, "end_pos": 213, "type": "METRIC", "confidence": 0.6919540762901306}]}, {"text": "Experimental results show that AMR captures contextual properties discriminative enough to make linking decisions, without the need for EL training data, and that system with AMR parsing output outperforms hand labeled traditional semantic roles as context representation for EL.", "labels": [], "entities": [{"text": "AMR", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9009261131286621}, {"text": "AMR parsing", "start_pos": 175, "end_pos": 186, "type": "TASK", "confidence": 0.6840423345565796}]}, {"text": "Finally, we show promising preliminary results for using AMR to select sets of \"coherent\" entity mentions for collective entity linking 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "The Entity Linking (EL) task () aims at automatically linking each named entity mention appearing in a source text document to its unique referent in a target knowledge base (KB).", "labels": [], "entities": [{"text": "Entity Linking (EL) task", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8098241090774536}]}, {"text": "For example, consider the following sentence posted to a discussion forum during the 2012 U.S. presidential election: \"Where would McCain be without Sarah?\".", "labels": [], "entities": []}, {"text": "An Entity Linker should link the entity mentions \"McCain\" and \"Sarah\" to the entities John McCain and Sarah Palin, respectively, which serve as unique identifiers for the real people.", "labels": [], "entities": []}, {"text": "A typical EL system works as follows.", "labels": [], "entities": []}, {"text": "Given a mention m (a string in a source document), the top N most likely entity referents from the KB are enumerated based on prior knowledge about which entities are most likely referred to using m.", "labels": [], "entities": []}, {"text": "The candidate entities are re-ranked to ultimately link each mention to the top entity in its candidate list.", "labels": [], "entities": []}, {"text": "Reranking consists of two key elements: context representation and context comparison.", "labels": [], "entities": [{"text": "Reranking", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.8646755218505859}, {"text": "context representation", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7561080157756805}, {"text": "context comparison", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.771977037191391}]}, {"text": "For a given mention, candidate entities are re-ranked based on a comparison of information obtained from the context of m with known structured and/or unstructured information associated with the top N KB entities, which can be considered the \"context\" of the KB entity 2 . The basic intuition is that the entity referents of m and related mentions should be similarly connected in the KB.", "labels": [], "entities": []}, {"text": "However, there might be many entity mentions in the context of a target entity mention that could potentially be leveraged for disambiguation.", "labels": [], "entities": []}, {"text": "In this paper, we show that a deeper semantic knowledge representation -including the Abstract Meaning Representation (AMR) () -can capture contextual properties that are discriminative enough to disambiguate entity mentions that current state-of-the-art systems cannot handle, without the need for EL training data.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 86, "end_pos": 123, "type": "TASK", "confidence": 0.6667948514223099}]}, {"text": "Specifically, fora given entity mention, using AMR provides a rich context representation, facilitating the selection of an optimal set of collaborator entity mentions, i.e., those co-occurring mentions most useful for disambiguation.", "labels": [], "entities": [{"text": "AMR", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.6631675362586975}]}, {"text": "In previous approaches, collaborator sets have tended to be too narrow or too broad, introducing noise.", "labels": [], "entities": []}, {"text": "We then use unsupervised graph inference for context comparison, achieving results comparable with state-of-the-art supervised methods and substantially outperforming context representation based on traditional Semantic Role Labeling.", "labels": [], "entities": [{"text": "context comparison", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8180826902389526}, {"text": "Semantic Role Labeling", "start_pos": 211, "end_pos": 233, "type": "TASK", "confidence": 0.747472087542216}]}, {"text": "In addition, most state-of-the-art EL approaches now rely on collective inference, where a set of coherent mentions are linked simultaneously by choosing an \"optimal\" or maximally \"coherent\" set of named entity targets -one target entity for each mention in the coherent set.", "labels": [], "entities": []}, {"text": "We show preliminary results suggesting that AMR is effective for the partitioning of all mentions in a document into coherent sets for collective linking.", "labels": [], "entities": [{"text": "AMR", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.5976735949516296}, {"text": "partitioning of all mentions in a document", "start_pos": 69, "end_pos": 111, "type": "TASK", "confidence": 0.7993095942905971}]}, {"text": "We evaluate our approach using both human and automatic AMR annotation, limiting target named entity types to person (PER), organization (ORG), and geo-political entities (GPE) 3 .", "labels": [], "entities": [{"text": "AMR annotation", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.8481130003929138}]}], "datasetContent": [{"text": "We focus primarily on context collaborator based reranking results.", "labels": [], "entities": []}, {"text": "We compare our results with several baseline and state-of-the-art approaches in.", "labels": [], "entities": []}, {"text": "In we present preliminary results for collective linking.", "labels": [], "entities": []}, {"text": "Our Unsupervised Context Collaborator Approach substantially outperforms the popularity based methods.", "labels": [], "entities": []}, {"text": "More importantly, we see that AMR provides the best context representation for collaborator selection.", "labels": [], "entities": []}, {"text": "Even system AMR outperformed not only baseline co-occurrence based collaborator selection methods, but also outperforms the collaborator selection method based on human annotated core semantic roles.", "labels": [], "entities": []}, {"text": "depicts accuracy increases as more AMR annotation is used in selecting collaborators.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9348993897438049}]}, {"text": "From the commonness baseline, additional knowledge about individual names leads to substantial gains followed by additional gains after incorporating links denoting semantic roles.", "labels": [], "entities": []}, {"text": "Note that coreference here includes cross-sentence co-reference not based on AMR.", "labels": [], "entities": [{"text": "coreference", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9556489586830139}, {"text": "AMR", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.8219280242919922}]}, {"text": "Furthermore, the results using human annotated AMR outperform the state-of-the-art supervised methods trained from a large scale EL training corpus, which rely on collective inference . These results all verify the importance of incorporating a wider range of deep knowledge.", "labels": [], "entities": [{"text": "EL training corpus", "start_pos": 129, "end_pos": 147, "type": "DATASET", "confidence": 0.6542344391345978}]}, {"text": "Finally,  context coherence method is used where possible (i.e., those 215 mentions that are members of coherent sets according to our criteria as described in Section 3.5), and the context collaborator approach based on human AMR annotation is applied elsewhere.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Total # of Entity Mentions in Test Set", "labels": [], "entities": [{"text": "Total # of Entity Mentions", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.9029609799385071}]}, {"text": " Table 2: Accuracy (%) on Test Set (1613 mentions)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995827078819275}, {"text": "Test Set (1613 mentions", "start_pos": 26, "end_pos": 49, "type": "DATASET", "confidence": 0.8216683506965637}]}]}