{"title": [{"text": "Lexicon-Free Conversational Speech Recognition with Neural Networks", "labels": [], "entities": [{"text": "Lexicon-Free Conversational Speech Recognition", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.5344650000333786}]}], "abstractContent": [{"text": "We present an approach to speech recognition that uses only a neural network to map acoustic input to characters, a character-level language model, and abeam search decoding procedure.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7970100045204163}]}, {"text": "This approach eliminates much of the complex infrastructure of modern speech recognition systems, making it possible to directly train a speech recognizer using errors generated by spoken language understanding tasks.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.7436809241771698}, {"text": "speech recognizer", "start_pos": 137, "end_pos": 154, "type": "TASK", "confidence": 0.7145597338676453}]}, {"text": "The system naturally handles out of vocabulary words and spoken word fragments.", "labels": [], "entities": []}, {"text": "We demonstrate our approach using the challenging Switchboard telephone conversation transcription task, achieving a word error rate competitive with existing base-line systems.", "labels": [], "entities": [{"text": "Switchboard telephone conversation transcription task", "start_pos": 50, "end_pos": 103, "type": "TASK", "confidence": 0.7792649507522583}, {"text": "word error rate", "start_pos": 117, "end_pos": 132, "type": "METRIC", "confidence": 0.6816763579845428}]}, {"text": "To our knowledge, this is the first entirely neural-network-based system to achieve strong speech transcription results on a conversational speech task.", "labels": [], "entities": []}, {"text": "We analyze qualitative differences between transcriptions produced by our lexicon-free approach and transcriptions produced by a standard speech recognition system.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the impact of large context neural network character language models as compared to standard n-gram models within our framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "Users increasingly interact with natural language understanding systems via conversational speech interfaces.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.7270426750183105}]}, {"text": "Google Now, Microsoft Cortana, and Apple Siri are all systems which rely on spoken language understanding (SLU), where transcribing * Authors contributed equally.", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.768865704536438}]}, {"text": "speech is a single step within a larger system.", "labels": [], "entities": []}, {"text": "Building such systems is difficult because spontaneous, conversational speech naturally contains repetitions, disfluencies, partial words, and out of vocabulary (OOV) words).", "labels": [], "entities": []}, {"text": "Moreover, SLU systems must be robust to transcription errors, which can be quite high depending on the task and domain.", "labels": [], "entities": []}, {"text": "Modern systems for large vocabulary continuous speech recognition (LVCSR) use hidden Markov models (HMMs) to handle sequence processing, word-level language models, and a pronunciation lexicon to map words into phonetic pronunciations.", "labels": [], "entities": [{"text": "large vocabulary continuous speech recognition (LVCSR)", "start_pos": 19, "end_pos": 73, "type": "TASK", "confidence": 0.7575969882309437}]}, {"text": "Traditional systems use Gaussian mixture models (GMMs) to build a mapping from sub-phonetic states to audio input features.", "labels": [], "entities": []}, {"text": "The resulting speech recognition system contains many sub-components, linguistic assumptions, and typically over ten thousand lines of source code.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7049441784620285}]}, {"text": "Within the past few years LVCSR systems improved by replacing GMMs with deep neural networks (DNNs), drawing on early work on with hybrid GMM-NN architectures.", "labels": [], "entities": []}, {"text": "Both HMM-GMM and HMM-DNN systems remain difficult to build, and nearly impossible to efficiently optimize for downstream SLU tasks.", "labels": [], "entities": []}, {"text": "As a result, SLU researchers typically operate on an n-best list of possible transcriptions and treat the LVCSR system as a black box.", "labels": [], "entities": []}, {"text": "Recently demonstrated an approach to LVCSR using a neural network trained with the connectionist temporal classification (CTC) loss function ().", "labels": [], "entities": [{"text": "connectionist temporal classification (CTC)", "start_pos": 83, "end_pos": 126, "type": "TASK", "confidence": 0.699351966381073}]}, {"text": "Us-ing the CTC loss function the authors built a neural network which directly maps audio input features to a sequence of characters.", "labels": [], "entities": []}, {"text": "By re-ranking word-level n-best lists generated from an HMM-DNN system the authors obtained competitive results on the Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 119, "end_pos": 145, "type": "DATASET", "confidence": 0.977043628692627}]}, {"text": "Our work builds upon the foundation introduced by.", "labels": [], "entities": []}, {"text": "Rather than reasoning at the word level, we train and decode our system by reasoning entirely at the character-level.", "labels": [], "entities": []}, {"text": "By reasoning over characters we eliminate the need fora lexicon, and enable transcribing new words, fragments, and disfluencies.", "labels": [], "entities": [{"text": "transcribing new words, fragments, and disfluencies", "start_pos": 76, "end_pos": 127, "type": "TASK", "confidence": 0.7245532795786858}]}, {"text": "We train a deep bidirectional recurrent neural network (DBRNN) to directly map acoustic input to characters using the CTC loss function introduced by.", "labels": [], "entities": []}, {"text": "We are able to efficiently and accurately perform transcription using only our DBRNN and a character-level language model (CLM), whereas previous work relied on n-best lists from a baseline HMM-DNN system.", "labels": [], "entities": []}, {"text": "On the challenging Switchboard telephone conversation transcription task, our approach achieves a word error rate competitive with existing baseline HMM-GMM systems.", "labels": [], "entities": [{"text": "Switchboard telephone conversation transcription task", "start_pos": 19, "end_pos": 72, "type": "TASK", "confidence": 0.8466057300567627}, {"text": "word error rate", "start_pos": 98, "end_pos": 113, "type": "METRIC", "confidence": 0.7231444517771403}]}, {"text": "To our knowledge, this is the first entirely neural-networkbased system to achieve strong speech transcription results on a conversational speech task.", "labels": [], "entities": []}, {"text": "Section 2 reviews the CTC loss function and describes the neural network architecture we use.", "labels": [], "entities": []}, {"text": "Section 3 presents our approach to efficiently perform first-pass decoding using a neural network for character probabilities and a character language model.", "labels": [], "entities": []}, {"text": "Section 4 presents experiments on the Switchboard corpus to compare our approach to existing LVCSR systems, and evaluates the impact of different language models.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 38, "end_pos": 56, "type": "DATASET", "confidence": 0.7502241432666779}]}, {"text": "In Section 5, we offer insight on how the CTC-trained system performs speech recognition as compared to a standard HMM-GMM model, and finally conclude in Section 6.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.8054037094116211}]}], "datasetContent": [{"text": "We perform LVCSR experiments on the 300 hour Switchboard conversational telephone speech corpus (LDC97S62).", "labels": [], "entities": [{"text": "Switchboard conversational telephone speech corpus (LDC97S62)", "start_pos": 45, "end_pos": 106, "type": "DATASET", "confidence": 0.6658869162201881}]}, {"text": "Switchboard utterances are taken from approximately 2,400 conversations among 543 speakers.", "labels": [], "entities": []}, {"text": "Each pair of speakers had never met, and converse no more than once about a given topic chosen randomly from a set of 50 possible topics.", "labels": [], "entities": []}, {"text": "Utterances exhibit many rich, complex phenomena that make spoken language understanding difficult.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.8134697477022806}]}, {"text": "Table 2 shows example transcripts from the corpus.", "labels": [], "entities": []}, {"text": "For evaluation, we report word error rate (WER) and character error rate (CER) on the HUB5 Eval2000 dataset (LDC2002S09).", "labels": [], "entities": [{"text": "word error rate (WER)", "start_pos": 26, "end_pos": 47, "type": "METRIC", "confidence": 0.9125607113043467}, {"text": "character error rate (CER)", "start_pos": 52, "end_pos": 78, "type": "METRIC", "confidence": 0.9482163786888123}, {"text": "HUB5 Eval2000 dataset (LDC2002S09)", "start_pos": 86, "end_pos": 120, "type": "DATASET", "confidence": 0.9142491618792216}]}, {"text": "This test set consists of two subsets, Switchboard and CallHome.", "labels": [], "entities": [{"text": "CallHome", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.9415891170501709}]}, {"text": "The CallHome subset represents a mismatched test condition as it was collected from phone conversations among family and friends rather than strangers directed to discuss a particular topic.", "labels": [], "entities": [{"text": "CallHome subset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.908732533454895}]}, {"text": "The mismatch makes the CallHome subset quite difficult overall.", "labels": [], "entities": [{"text": "CallHome subset", "start_pos": 23, "end_pos": 38, "type": "DATASET", "confidence": 0.9367124736309052}]}, {"text": "The Switchboard evaluation subset is substantially easier, and represents a better match of test data to our training corpus.", "labels": [], "entities": []}, {"text": "We report WER and CER on the test set as a whole, and additionally report WER for each subset individually.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.990920901298523}, {"text": "CER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9866467714309692}, {"text": "WER", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9948838353157043}]}], "tableCaptions": [{"text": " Table 1: Character error rate (CER) and word er- ror rate results on the Eval2000 test set. We re- port word error rates on the full test set (EV) which  consists of the Switchboard (SWBD) and CallHome  (CH) subsets. As baseline systems we use an HMM- GMM system and HMM-DNN system. We evaluate  our DBRNN trained using CTC by decoding with  several character-level language models: 5-gram, 7- gram, densely connected neural networks with 1 and  3 hidden layers (NN-1, and NN-3), as well as recur- rent neural networks s with 1 and 3 hidden layers.  We additionally include results from a state-of-the- art HMM-based system (HMM-DNN-SHF) which  does not report performance on all metrics we eval- uate (NR).", "labels": [], "entities": [{"text": "Character error rate (CER)", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.8107826411724091}, {"text": "word er- ror rate", "start_pos": 41, "end_pos": 58, "type": "METRIC", "confidence": 0.8609658002853393}, {"text": "Eval2000 test set", "start_pos": 74, "end_pos": 91, "type": "DATASET", "confidence": 0.9640695651372274}]}, {"text": " Table 2: Example test set utterances with a ground truth transcription and hypotheses from our method  (CTC+CLM) and a baseline HMM-GMM system of comparable overall WER. The words fidelity and  barometer are not in the lexicon of the HMM-GMM system.", "labels": [], "entities": [{"text": "WER", "start_pos": 166, "end_pos": 169, "type": "METRIC", "confidence": 0.9966741800308228}, {"text": "barometer", "start_pos": 195, "end_pos": 204, "type": "METRIC", "confidence": 0.9385510683059692}]}]}