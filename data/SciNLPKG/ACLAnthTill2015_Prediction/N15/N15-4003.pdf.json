{"title": [{"text": "The Logic of AMR: Practical, Unified, Graph-Based Sentence Semantics for NLP in Denver, Colorado", "labels": [], "entities": []}], "abstractContent": [{"text": "The Abstract Meaning Representation formalism is rapidly emerging as an important practical form of structured sentence semantics which, thanks to the availability of large-scale annotated corpora, has potential as a convergence point for NLP research.", "labels": [], "entities": [{"text": "Abstract Meaning Representation formalism", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.7564496248960495}]}, {"text": "This tutorial unmasks the design philosophy, data creation process, and existing algorithms for AMR semantics.", "labels": [], "entities": [{"text": "AMR semantics", "start_pos": 96, "end_pos": 109, "type": "TASK", "confidence": 0.9000336825847626}]}, {"text": "It is intended for anyone interested in working with AMR data, including parsing text into AMRs, generating text from AMRs, and applying AMRs to tasks such as machine translation and summarization.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.8103284537792206}, {"text": "summarization", "start_pos": 183, "end_pos": 196, "type": "TASK", "confidence": 0.903163731098175}]}, {"text": "The goals of this tutorial are twofold.", "labels": [], "entities": []}, {"text": "First, it will describe the nature and design principles behind the representation, and demonstrate that it can be practical for annotation.", "labels": [], "entities": []}, {"text": "In Part I: The AMR Formalism, participants will be coached in the basics of annotation so that, when working with AMR data in the future, they will appreciate the benefits and limitations of the process by which it was created.", "labels": [], "entities": [{"text": "AMR Formalism", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.8229888081550598}, {"text": "AMR data", "start_pos": 114, "end_pos": 122, "type": "DATASET", "confidence": 0.840630978345871}]}, {"text": "Second, the tutorial will survey the state of the art for computation with AMRs.", "labels": [], "entities": [{"text": "AMRs", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.7562286853790283}]}, {"text": "Part II: Algorithms and Applications will focus on the task of parsing English text into AMR graphs, which requires algorithms for alignment, for structured prediction, and for statistical learning.", "labels": [], "entities": [{"text": "parsing English text into AMR graphs", "start_pos": 63, "end_pos": 99, "type": "TASK", "confidence": 0.8111250400543213}, {"text": "alignment", "start_pos": 131, "end_pos": 140, "type": "TASK", "confidence": 0.9654052257537842}, {"text": "structured prediction", "start_pos": 146, "end_pos": 167, "type": "TASK", "confidence": 0.7182426154613495}, {"text": "statistical learning", "start_pos": 177, "end_pos": 197, "type": "TASK", "confidence": 0.8523624837398529}]}, {"text": "The tutorial will also address graph grammar formalisms that have been recently developed, and future applications such as AMR-based machine translation and summarization.", "labels": [], "entities": [{"text": "AMR-based machine translation", "start_pos": 123, "end_pos": 152, "type": "TASK", "confidence": 0.7548426985740662}, {"text": "summarization", "start_pos": 157, "end_pos": 170, "type": "TASK", "confidence": 0.8710814714431763}]}, {"text": "Participants with laptops are encouraged to bring them to the tutorial.", "labels": [], "entities": []}, {"text": "Instructors Part I: The AMR Formalism Nathan Schneider is an annotation schemer and computational modeler for natural language.", "labels": [], "entities": [{"text": "AMR Formalism Nathan Schneider", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6890649050474167}]}, {"text": "He has been involved in the design of the AMR formalism since 2012, when he interned with Kevin Knight at ISI.", "labels": [], "entities": []}, {"text": "His 2014 dissertation introduced a coarse-grained representation for lexical semantics that facilitates rapid annotation and is practical for broad-coverage statistical NLP.", "labels": [], "entities": []}, {"text": "He has also worked on semantic parsing for the FrameNet representation and other forms of syntactic/semantic annotation and processing for social media text.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7234706431627274}]}, {"text": "For most of these projects, he led the design of the annotation scheme, guidelines, and workflows, and the training and supervision of annotators.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}