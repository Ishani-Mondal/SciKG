{"title": [{"text": "Morphological Modeling for Machine Translation of English-Iraqi Arabic Spoken Dialogs", "labels": [], "entities": [{"text": "Morphological Modeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7608299255371094}, {"text": "Machine Translation of English-Iraqi Arabic Spoken Dialogs", "start_pos": 27, "end_pos": 85, "type": "TASK", "confidence": 0.8508898956435067}]}], "abstractContent": [{"text": "This paper addresses the problem of morphological modeling in statistical speech-to-speech translation for English to Iraqi Ara-bic.", "labels": [], "entities": [{"text": "morphological modeling", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7292752265930176}, {"text": "statistical speech-to-speech translation", "start_pos": 62, "end_pos": 102, "type": "TASK", "confidence": 0.6139061947663625}]}, {"text": "An analysis of user data from a real-time MT-based dialog system showed that generating correct verbal inflections is a key problem for this language pair.", "labels": [], "entities": [{"text": "MT-based dialog", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.9036805927753448}]}, {"text": "We approach this problem by enriching the training data with morphological information derived from source-side dependency parses.", "labels": [], "entities": []}, {"text": "We analyze the performance of several parsers as well as the effect on different types of translation models.", "labels": [], "entities": []}, {"text": "Our method achieves an improvement of more than a full BLEU point and a significant increase in verbal inflection accuracy; at the same time, it is computationally inexpensive and does not rely on target-language linguistic tools.", "labels": [], "entities": [{"text": "BLEU point", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.974670946598053}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9042870402336121}]}], "introductionContent": [{"text": "SMT from a morphologically poor language like English into a language with richer morphology continues to be a problem, in particular when training data is sparse and/or the SMT system has insufficient modeling capabilities for morphological variation in the target language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9918986558914185}, {"text": "SMT", "start_pos": 174, "end_pos": 177, "type": "TASK", "confidence": 0.9689019918441772}]}, {"text": "Most previous approaches to this problem have utilized a translate-and-inflect method, where a first-pass SMT system is trained on lemmatized forms, and the correct inflection for every word is predicted in a second pass by statistical classifiers trained on a combination of source and target language features.", "labels": [], "entities": [{"text": "SMT", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9580461382865906}]}, {"text": "This paper looks at morphological modeling from a different perspective, namely to improve SMT in a real-time speechto-speech translation system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9961560368537903}, {"text": "speechto-speech translation", "start_pos": 110, "end_pos": 137, "type": "TASK", "confidence": 0.6996512562036514}]}, {"text": "Our focus is on resolving those morphological translation errors that are most likely to cause confusions and misunderstandings in machine-translation mediated human-human dialogs.", "labels": [], "entities": []}, {"text": "Due to the constraints imposed by a realtime system, previous approaches that rely on elaborate feature sets and multi-pass processing strategies are unsuitable for this problem.", "labels": [], "entities": []}, {"text": "The language pair of interest in this study is English and Iraqi Arabic (IA).", "labels": [], "entities": [{"text": "Iraqi Arabic (IA)", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.4927674174308777}]}, {"text": "The latter is a spoken dialect of Arabic with few existing linguistic resources.", "labels": [], "entities": []}, {"text": "We therefore develop a low-resource approach that relies on sourceside dependency parses only.", "labels": [], "entities": [{"text": "sourceside dependency parses", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.6459396878878275}]}, {"text": "We analyze its performance in combination with different types of parsers and different translation models.", "labels": [], "entities": []}, {"text": "Results show a significant improvement in translation performance in both automatic and manual evaluations.", "labels": [], "entities": [{"text": "translation", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.9759593605995178}]}, {"text": "Moreover, the proposed method is sufficiently fast fora realtime system.", "labels": [], "entities": []}], "datasetContent": [{"text": "Results in show the comparison between the baseline, different parsers, and the combined system.", "labels": [], "entities": []}, {"text": "We see that verbal inflection accuracy increases substantially from the baseline performance and is best for the Macaon parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9760593175888062}]}, {"text": "Improvements over the baseline system without morphology are statistically significant; differences between the individual parsers are not (not, however, that the sample size for manual evaluation was quite small).", "labels": [], "entities": []}, {"text": "BLEU is not affected negatively but even increases slightly -thus, data fragmentation does not seem to be a problem overall.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9858077764511108}]}, {"text": "This maybe due to the nature of the task and domain, which is results in fairly short, simple sentence constructions that can be adequately translated by a concatenation of shorter phrases rather than requiring longer phrases.", "labels": [], "entities": []}, {"text": "Back-off systems (indicated by bo) and the combined system improve BLEU only trivially while decreasing verbal inflection accuracy by varying amounts.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9983928799629211}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.8973692059516907}]}, {"text": "For testing within the dialog system we thus choose the Macaon parser and utilize a standard translation model rather than a backoff model.", "labels": [], "entities": [{"text": "Macaon", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.9383127689361572}]}, {"text": "An added benefit is that the Macaon parser is already used in other components in the dialog system.", "labels": [], "entities": [{"text": "Macaon", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.8967952728271484}]}, {"text": "Using this setup we ran two experiments with dialog system's SMT engine: first, we re-extracted phrases and rules based on the morph-tagged data and reoptimized the feature weights.", "labels": [], "entities": [{"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9620840549468994}]}, {"text": "In the second experiment, we additionally applied the NNJM to the morph-tagged source text.", "labels": [], "entities": []}, {"text": "To this end we include all the morphological variants of the original vocabulary that was used for the NNJM in the untagged baseline system.", "labels": [], "entities": [{"text": "NNJM", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.9017302393913269}]}, {"text": "The morph-tagged data improves the BLEU score under both conditions: in Experiment 1, the improve-ment is almost a full BLEU point (0.91); in Experiment 2 the improvement is even larger (1.13), even though the baseline performance is stronger.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9787823557853699}, {"text": "BLEU point (0.91)", "start_pos": 120, "end_pos": 137, "type": "METRIC", "confidence": 0.9522859811782837}]}, {"text": "Both results are statistically significant at p = 0.05, using a paired bootstrap resampling test.", "labels": [], "entities": []}, {"text": "The combination of morph-tagged data and the more advanced modeling options (sparse features, NNJM) in this system seem to be beneficial.", "labels": [], "entities": []}, {"text": "Improved translation performance may also be captured by the four reference translations as opposed to one in Eval set 1.", "labels": [], "entities": [{"text": "Eval set", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9297628998756409}]}, {"text": "In order to assess the added computation cost  of our procedure we computed the decoding speed of the MT component in the dialog system for both the baseline and the morpho-tag systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.8766610026359558}]}, {"text": "In the baseline MT system (with NNJM) without morphotags, decoding takes 0.01572 seconds per word or 0.15408 seconds per sentence -these numbers were obtained on a Dell Precision M4800 Laptop with a quad-core Intel i7-4930MX Processor and 32GB of RAM.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.931565523147583}]}, {"text": "Morpho-tagging only adds 0.00031 seconds per word or 0.0024 seconds per sentence.", "labels": [], "entities": []}, {"text": "Thus, our procedure is extremely efficient.", "labels": [], "entities": []}, {"text": "An analysis of the remaining morphological translation errors not captured by our approach showed that in about 34% of all cases these were due to part-of-speech tagging or parser errors, i.e. verbs were mistagged as nouns rather than verbs and thus did not receive any morphological tags, or the parser hypothesized wrong dependency relations.", "labels": [], "entities": []}, {"text": "In 53% of the cases the problem is the lack of more extensive discourse or contextual knowledge.", "labels": [], "entities": []}, {"text": "This includes constructions where there is no overt subject fora verb in the current utterance, and the appropriate underlying subject must be inferred from the preceding discourse or from knowledge of the situational context.", "labels": [], "entities": []}, {"text": "This is an instance of the more general problem of control (see e.g., for an overview of research in this area).", "labels": [], "entities": []}, {"text": "It is exemplified by cases such as the following: 1.", "labels": [], "entities": []}, {"text": "The first step is to make sure that all personnel are in your debrief.", "labels": [], "entities": []}, {"text": "Here, the underlying subject of \"to make sure\" could be a range of different candidates (I, you, we, etc.) and must be inferred from context.", "labels": [], "entities": []}, {"text": "2. I can provide up to one platoon to help you guys cordon off the area.", "labels": [], "entities": []}, {"text": "In this case the statistical parser identified I as the subject of help, but platoon is more likely to be the controller and was in fact identified as the underlying subject by the annotator.", "labels": [], "entities": []}, {"text": "Such cases could potentially be resolved during the parsing step by integrating semantic information, e.g. as in ().", "labels": [], "entities": []}, {"text": "However, initial investigations with semantic features in the Macaon parser resulted in a significant slow-down of the parser.", "labels": [], "entities": [{"text": "Macaon", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9252750873565674}]}, {"text": "In other cases, more sophisticated modeling of the entities and their relationships in the situational context will be required.", "labels": [], "entities": []}, {"text": "This clearly is an area for future study.", "labels": [], "entities": []}, {"text": "Finally, in 13% of the cases, mistranslations are caused by a mismatch of number features across languages (e.g. number features for nouns such as family or people).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: BLEU on Eval set 2 using dialog system's SMT  engine.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990161657333374}, {"text": "Eval set 2", "start_pos": 18, "end_pos": 28, "type": "DATASET", "confidence": 0.8850624362627665}]}]}