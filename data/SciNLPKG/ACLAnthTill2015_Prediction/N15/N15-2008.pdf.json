{"title": [{"text": "Initial Steps for Building a Lexicon of Adjectives with Scalemates", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes work in progress to use clustering to create a lexicon of words that engage in the lexico-semantic relationship known as grading.", "labels": [], "entities": []}, {"text": "While other resources like thesauri and taxonomies exist detailing relationships such as synonymy, antonymy, and hyponymy, we do not know of any thorough resource for grading.", "labels": [], "entities": []}, {"text": "This work focuses on identifying the words that may participate in this relationship, paving the way for the creation of a true grading lexicon later.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many common adjectives, like small and tiny, can be defined in terms of intensities of other adjectives.", "labels": [], "entities": []}, {"text": "These relations, known as grading, intensification, magnification and others, are hypothesized to be one of the more important types in a lexicon.", "labels": [], "entities": [{"text": "magnification", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9458174109458923}]}, {"text": "This type of relationship has applications in question answering and ontological representations (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.873586505651474}, {"text": "ontological representations", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.7062724083662033}]}, {"text": "While the existence of this relationship is widely agreed upon, the study of it has fallen far behind that of synonymy, antonymy, and hyponymy, especially in the computational linguistics community.", "labels": [], "entities": []}, {"text": "Recent work has brought renewed attention to this area of research, but there is still no large resource of words that participate in this relationship).", "labels": [], "entities": []}, {"text": "The phenomenon of grading is not the same as gradability, although there is significant overlap among the adjectives that have it.", "labels": [], "entities": []}, {"text": "Gradability refers to an adjective's ability to be combined with adverbs like very or be used in comparative expressions.", "labels": [], "entities": [{"text": "Gradability", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.935701310634613}]}, {"text": "It is possible that words like lukewarm, which are not considered gradable by most linguists, still have the lexico-semantic relation of grading.", "labels": [], "entities": []}, {"text": "Similarly, a word like spotted, which is gradable, and in fact can be viewed on its own scale, does not express the relationship of grading with any other words in English.", "labels": [], "entities": []}, {"text": "There is no agreement on what types of adjectives express this relationship.", "labels": [], "entities": []}, {"text": "Paradis and Kennedy & McNally propose two similar views that were influential to this work.", "labels": [], "entities": []}, {"text": "focus on the structure of scales, whether they are open at both ends (tall, short), closed at both ends (visible, invisible), or a combination of the two (bent, straight and safe, dangerous).", "labels": [], "entities": []}, {"text": "Paradis (1997) on the other hand, defines three classes of gradable adjectives, limit adjectives, extreme adjectives, and scalar adjectives.", "labels": [], "entities": []}, {"text": "For her, dead and alive are gradable adjectives but of the limit variety, meaning there is a definite boundary between the two.", "labels": [], "entities": []}, {"text": "Extreme and scalar adjectives, such as terrible and good respectively, are both conceptualized as being on a scale, although extreme adjectives share some properties with limit adjectives as well.", "labels": [], "entities": []}, {"text": "Paradis also points out that many adjectives can easily have a scalar interpretation, such as someone being very Swedish.", "labels": [], "entities": []}, {"text": "The study of grading has focused on a small number of adjectives).", "labels": [], "entities": []}, {"text": "Many previous approaches of automatically learning the relation have relied on existing ontologies such as WordNet and FrameNet to choose which words occur on scales).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.9733893275260925}]}, {"text": "The issues with using ontologies like these as starting points are pointed out by Van Miltenburg (2015).", "labels": [], "entities": []}, {"text": "He notes that words like difficult and impossible are not grouped together and that limiting scales to WordNet networks prevents ad-hoc scales as introduced by from being studied.", "labels": [], "entities": []}, {"text": "To this we can add our own observation that many times an ontology can be too broad, including puffy, rangy, and large-mouthed under size alongside expected senses of big, small, and others.", "labels": [], "entities": []}, {"text": "Westney investigated what might be necessary fora word to be on a scale while recent work in cognitive science has focused on the acquisition of scalar implicatures in children.", "labels": [], "entities": []}, {"text": "We demonstrate work in progress to cluster adjectives into those that participate in grading and those that do not.", "labels": [], "entities": []}, {"text": "While our metrics do not currently match the supervised solution of), the lack of large amounts of training data encourages us to continue to pursue the unsupervised approach.", "labels": [], "entities": []}, {"text": "Clustering the adjectives is a critical first step to support further research into semantic intensities of adjectives, which is outlined in section 2.", "labels": [], "entities": []}], "datasetContent": [{"text": "As Hatzivassiloglou and Wiebe did, we use the Collins COBUILD Dictionary for our evaluation (.", "labels": [], "entities": [{"text": "Collins COBUILD Dictionary", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.899379829565684}]}, {"text": "The dictionary classifies adjectives as either classifying or qualitative which correspond approximately to non-gradable and gradable.", "labels": [], "entities": []}, {"text": "The distinction here is the narrow sense of gradable, meaning the adjectives can be modified by only scalar modifiers, not maximizers or approximators.", "labels": [], "entities": []}, {"text": "This is the best resource we know of at this time however, and it allows comparisons to earlier work.", "labels": [], "entities": []}, {"text": "We follow Hatzivassiloglou and Wiebe in removing adjectives from the dataset that we could not reliably label as classifying or qualitative when different senses had conflicting labels.", "labels": [], "entities": []}, {"text": "We ran the clustering and anomaly detection on the 500 and 1000 most common adjectives in the Google syntactic ngrams corpus, removing any that were not labeled as an adjective by COBUILD.", "labels": [], "entities": [{"text": "Google syntactic ngrams corpus", "start_pos": 94, "end_pos": 124, "type": "DATASET", "confidence": 0.6832291260361671}, {"text": "COBUILD", "start_pos": 180, "end_pos": 187, "type": "DATASET", "confidence": 0.9450096487998962}]}, {"text": "This gives of datasets of length 427 (237 gradable and 190 non-gradable) and 838 (461 gradable and 377 non-gradable) respectively.", "labels": [], "entities": []}, {"text": "Due to many of the words having conflicting senses, we ran another dataset consisting of only the words for which all senses unanimously chose the same classification.", "labels": [], "entities": []}, {"text": "The results of evaluating the clustering can be seen in.", "labels": [], "entities": []}, {"text": "The data set that should be compared to) who report a precision of .9355, recall of .8224, and accuracy of .8797, is the 500 most frequent adjectives.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.994304358959198}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9997137188911438}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9995520710945129}]}, {"text": "While we don't achieve as high a precision, our recall is much higher.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.999377429485321}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9997976422309875}]}, {"text": "Partial reasons for this could be that using COBUILD is a flawed choice, as it assigns words like far to the classifying class of adjectives in all senses, even though it can be inflected as farther and farthest.", "labels": [], "entities": []}, {"text": "The words that were labeled by COBUILD as non-gradable but clustered as able above absolute actual additional alive available average based central chief chronic comprehensive constant contemporary continuous corresponding criminal current dead dear double east entire equivalent eternal everyday extreme facial far fatal fellow few fewer free front fundamental future gay giant global horizontal identical illegal induced inevitable intermediate known lateral left like logical natural neutral objective occasional ongoing operational overall parallel particular past positive possible potential present previous principal proper pure ready real related responsible right same separate silent single solid special specific subject subsequent sufficient temporary top total traditional ultimate unable unique universal unknown up usual various vertical very whole: Words labeled by COBUILD as non-gradable, but clustered with gradable words in our data gradable by our method from the 500 words dataset using the 1000 most frequent adverbs are shown in.", "labels": [], "entities": [{"text": "COBUILD", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.918876588344574}]}, {"text": "While some of the words are true errors, words like dead and alive are commonly discussed in linguistic literature, with many considering them gradable ().", "labels": [], "entities": []}, {"text": "Other words that were misclustered can easily be placed on a scale, such as silent or everyday.", "labels": [], "entities": []}, {"text": "Ultimately we are using a broader definition of gradable than COBUILD.", "labels": [], "entities": [{"text": "COBUILD", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9446006417274475}]}, {"text": "Additionally it is more likely fora word not traditionally viewed as gradable to appear in gradable context rather than vice-versa.", "labels": [], "entities": []}, {"text": "This leads to a high recall due to the fact that the gradable adjectives rarely appear in non-gradable contexts.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9995809197425842}]}, {"text": "The most interesting outcome is that the use of manual features does not provide an advantage.", "labels": [], "entities": []}, {"text": "This is promising for future work, especially for applications in other languages.", "labels": [], "entities": []}, {"text": "Constructing manual features requires the existence of detailed descriptive grammars for the language in question.", "labels": [], "entities": []}, {"text": "Testing against only the words that were assigned one label in the dictionary performed the worst under all conditions.", "labels": [], "entities": []}, {"text": "This maybe because the distribution of these terms is heavily skewed towards the  less frequent words of the top 1000, rather than any effect from the classification itself.", "labels": [], "entities": []}, {"text": "One group of words that is reliably identified as not having any scalemates are demonyms like American and Swedish.", "labels": [], "entities": []}, {"text": "As another heuristic on our algorithm, we use the list of denonymic names from Wikipedia 1 . We found that 100% of these were correctly excluded from the final list for all feature sets.", "labels": [], "entities": []}, {"text": "While we have no evaluation for the effectiveness of the anomaly detection, the words with the 10 highest LOF are shown in.", "labels": [], "entities": [{"text": "anomaly detection", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7100270986557007}, {"text": "LOF", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9905477166175842}]}, {"text": "Of these, able and logical are identified by COBUILD as classifying adjectives.", "labels": [], "entities": [{"text": "COBUILD", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.9003304839134216}]}, {"text": "If we assume that the synonyms and antonyms given by COBOUILD could be scalemates for these words, we find that only consistent and historic do not have scalemates in the dataset.", "labels": [], "entities": [{"text": "COBOUILD", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.9034571647644043}]}, {"text": "This suggests that at least LOF is not a good estimate of words sharing a scale, and possibly anomaly detection in general.", "labels": [], "entities": [{"text": "LOF", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9940950870513916}, {"text": "anomaly detection", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.6911023855209351}]}], "tableCaptions": [{"text": " Table 1: Co-occurrence matrix from Google syntactic  ngrams corpus", "labels": [], "entities": []}, {"text": " Table 2: Evaluation against COBUILD classifications", "labels": [], "entities": [{"text": "COBUILD classifications", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.6426927447319031}]}, {"text": " Table 3. Of these, able  and logical are identified by COBUILD as classi- fying adjectives. If we assume that the synonyms  and antonyms given by COBOUILD could be scale- mates for these words, we find that only consistent  and historic do not have scalemates in the dataset.  This suggests that at least LOF is not a good esti- mate of words sharing a scale, and possibly anomaly  detection in general.", "labels": [], "entities": [{"text": "COBUILD", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9440014958381653}, {"text": "LOF", "start_pos": 306, "end_pos": 309, "type": "METRIC", "confidence": 0.9265798330307007}]}]}