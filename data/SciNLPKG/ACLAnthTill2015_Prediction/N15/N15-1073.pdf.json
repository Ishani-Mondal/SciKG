{"title": [{"text": "Multitask Learning for Adaptive Quality Estimation of Automatically Transcribed Utterances", "labels": [], "entities": [{"text": "Adaptive Quality Estimation of Automatically Transcribed Utterances", "start_pos": 23, "end_pos": 90, "type": "TASK", "confidence": 0.8588327850614276}]}], "abstractContent": [{"text": "We investigate the problem of predicting the quality of automatic speech recognition (ASR) output under the following rigid constraints: i) reference transcriptions are not available, ii) confidence information about the system that produced the transcriptions is not accessible, and iii) training and test data come from multiple domains.", "labels": [], "entities": [{"text": "predicting the quality of automatic speech recognition (ASR) output", "start_pos": 30, "end_pos": 97, "type": "TASK", "confidence": 0.6839352629401467}]}, {"text": "To cope with these constraints (typical of the constantly increasing amount of automatic transcriptions that can be found on the Web), we propose a domain-adaptive approach based on multitask learning.", "labels": [], "entities": []}, {"text": "Different algorithms and strategies are evaluated with English data coming from four domains, showing that the proposed approach can cope with the limitations of previously proposed single task learning methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "The variety of applications for large vocabulary speech recognition technology (LVCSR) is rapidly growing.", "labels": [], "entities": [{"text": "large vocabulary speech recognition technology (LVCSR)", "start_pos": 32, "end_pos": 86, "type": "TASK", "confidence": 0.6728195399045944}]}, {"text": "For instance, automatic transcriptions are now used, either as-is or as rough material to be checked and corrected by humans, for captioning and subtitling DVD movies, Youtube videos, TV programs and recordings in noisy environments such as meetings and teleconferences.", "labels": [], "entities": []}, {"text": "To enable further integration in these and other scenarios, the improvement of the core automatic speech recognition (ASR) technology should go hand in hand with the development of evaluation methods adequate to address new needs and constraints.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 88, "end_pos": 122, "type": "TASK", "confidence": 0.812735358874003}]}, {"text": "Indeed, the standard evaluation protocol, based on computing the word error rate of transcription hypotheses against reference transcripts, is not always a viable solution.", "labels": [], "entities": []}, {"text": "In terms of needs, the aforementioned applications call for efficient and replicable evaluation methods suitable for real-time processing.", "labels": [], "entities": []}, {"text": "While the availability of manually-created reference transcripts is a core ingredient for system development, tuning and lab testing, their use for on-field evaluation (i.e. during the actual use) is impractical for obvious reasons (i.e. the need of a quick response).", "labels": [], "entities": []}, {"text": "In terms of constraints, the problem is that ASR technology is often used as a black-box, that is, without any knowledge of how the transcriptions are generated.", "labels": [], "entities": [{"text": "ASR", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9879443645477295}]}, {"text": "This calls for techniques capable to estimate ASR output quality under the rigid constraint of having, as a basic source of information, only the spoken utterance (the acoustic signal) and the transcription itself.", "labels": [], "entities": [{"text": "ASR output", "start_pos": 46, "end_pos": 56, "type": "TASK", "confidence": 0.8712714910507202}]}, {"text": "Indeed, the invaluable information provided by current confidence estimation methods (e.g. word posterior probabilities), consensus decoding () and minimum Bayesrisk decoding () is not accessible when evaluating the output of an unknown system.", "labels": [], "entities": []}, {"text": "To cope with these issues,  proposed a reference-free ASR quality estimation (QE) method capable to operate both in a glass-box (i.e. having access to confidence information) and in a black-box fashion (i.e. without any knowledge about the ASR system's inner workings).", "labels": [], "entities": [{"text": "ASR quality estimation (QE)", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.6870525677998861}, {"text": "ASR", "start_pos": 240, "end_pos": 243, "type": "TASK", "confidence": 0.9633635878562927}]}, {"text": "According to the authors, despite the promising evaluation results, the supervised learning approach adopted has a main limitation: the degradation in performance when models are trained on non-homogeneous data that comes from different domains, speakers, or systems.", "labels": [], "entities": []}, {"text": "However, although empirical evidence of this limitation is provided, the robustness of ASR QE systems to the heterogeneity of training and test data is left as an open issue.", "labels": [], "entities": [{"text": "ASR QE", "start_pos": 87, "end_pos": 93, "type": "TASK", "confidence": 0.9397883415222168}]}, {"text": "Filling this gap, which is the goal of this paper, would be a significant step towards real-time ASR output evaluation, and its seamless integration in a number of application frameworks.", "labels": [], "entities": [{"text": "ASR output evaluation", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.9301961461702982}]}, {"text": "Along this direction, we propose and evaluate a supervised domain adaptation technique based on multitask learning.", "labels": [], "entities": []}, {"text": "Our approach aims to exploit training data coming from different \"domains\" (in abroad sense, e.g. different genres, speakers, topics, styles, etc.) and to obtain ASR QE models that are robust to differences with respect to the test data.", "labels": [], "entities": [{"text": "ASR QE", "start_pos": 162, "end_pos": 168, "type": "TASK", "confidence": 0.7818147540092468}]}, {"text": "Experiments are carried outwith English data coming from four domains, and by comparing different algorithms and strategies.", "labels": [], "entities": []}, {"text": "Overall, our contributions can be summarized as follows: \u2022 Multitask learning (MTL) is investigated for the first time in the ASR QE scenario, as away to cope with the dissimilarity between training and test data coming from multiple domains.", "labels": [], "entities": [{"text": "Multitask learning (MTL)", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.6007922172546387}, {"text": "ASR QE", "start_pos": 126, "end_pos": 132, "type": "TASK", "confidence": 0.8493346571922302}]}, {"text": "\u2022 The QE problem is approached both as a regression (assignment of real-valued quality labels) and as a binary classification task (assignment of 'good'/'bad' labels according to a given, arbitrary WER threshold).", "labels": [], "entities": [{"text": "QE problem", "start_pos": 6, "end_pos": 16, "type": "TASK", "confidence": 0.8495227694511414}]}, {"text": "The latter task is introduced as a preliminary study.", "labels": [], "entities": []}, {"text": "\u2022 Results are thoroughly analyzed, considering both the amount of training data coming from the different domains and the relative distance between their distributions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our regression models are evaluated in terms of mean absolute error (MAE).", "labels": [], "entities": [{"text": "mean absolute error (MAE)", "start_pos": 48, "end_pos": 73, "type": "METRIC", "confidence": 0.9107201596101125}]}, {"text": "The MAE, a standard error measure for regression, is the average of the absolute difference between the prediction\u02c6yprediction\u02c6 prediction\u02c6y i of a model and the gold standard response y i for all instances in the test set.", "labels": [], "entities": [{"text": "MAE", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9805768132209778}]}, {"text": "As it is an error measure, lower values indicate better performance.", "labels": [], "entities": []}, {"text": "To handle the imbalanced class distribution, and equally reward the correct classification on both classes, our evaluation is carried out in terms of balanced accuracy (BA -the higher the better), which is computed as the average of the accuracies on the two classes (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9780933856964111}, {"text": "BA", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9821052551269531}]}, {"text": "When the distribution of classes is balanced, BA is equal to the accuracy metric.", "labels": [], "entities": [{"text": "BA", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.9995430707931519}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9993433356285095}]}], "tableCaptions": [{"text": " Table 1: Some characteristics of the four domains.", "labels": [], "entities": []}]}