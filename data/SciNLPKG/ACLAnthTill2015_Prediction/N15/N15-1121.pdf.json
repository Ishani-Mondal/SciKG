{"title": [{"text": "High-Order Low-Rank Tensors for Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.7446681261062622}]}], "abstractContent": [{"text": "This paper introduces a tensor-based approach to semantic role labeling (SRL).", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.799471472700437}]}, {"text": "The motivation behind the approach is to automatically induce a compact feature representation for words and their relations, tailoring them to the task.", "labels": [], "entities": []}, {"text": "In this sense, our dimensionality reduction method provides a clear alternative to the traditional feature engineering approach used in SRL.", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.8166055083274841}, {"text": "SRL", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.9426063895225525}]}, {"text": "To capture meaningful interactions between the argument, predicate, their syntactic path and the corresponding role label, we compress each feature representation first to a lower dimensional space prior to assessing their interactions.", "labels": [], "entities": []}, {"text": "This corresponds to using an overall cross-product feature representation and maintaining associated parameters as a four-way low-rank tensor.", "labels": [], "entities": []}, {"text": "The tensor parameters are optimized for the SRL performance using standard online algorithms.", "labels": [], "entities": [{"text": "SRL", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9770104885101318}]}, {"text": "Our tensor-based approach rivals the best performing system on the CoNLL-2009 shared task.", "labels": [], "entities": [{"text": "CoNLL-2009 shared task", "start_pos": 67, "end_pos": 89, "type": "DATASET", "confidence": 0.8579715490341187}]}, {"text": "In addition, we demonstrate that adding the representation tensor to a competitive tensorfree model yields 2% absolute increase in Fscore.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9986302852630615}]}], "introductionContent": [{"text": "The accuracy of Semantic Role Labeling (SRL) systems depends strongly on the features used by the underlying classifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9987643957138062}, {"text": "Semantic Role Labeling (SRL)", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.7977001070976257}]}, {"text": "For instance, the top performing system on the CoNLL-2009 shared task employs over 50 language-specific templates for feature generation).", "labels": [], "entities": [{"text": "CoNLL-2009 shared task", "start_pos": 47, "end_pos": 69, "type": "DATASET", "confidence": 0.8326088587443033}, {"text": "feature generation", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.7397482097148895}]}, {"text": "The templates are manually created and thus offer specific means of incorporating prior knowledge into the method.", "labels": [], "entities": []}, {"text": "However, finding compact, informative templates is difficult since the relevant signal maybe spread over many correlated features.", "labels": [], "entities": []}, {"text": "Moreover, the use of lexicalized features, which are inevitably sparse, leads to overfitting.", "labels": [], "entities": []}, {"text": "In this case it is advantageous to try to automatically compress the feature set to use a small number of underlying co-varying dimensions.", "labels": [], "entities": []}, {"text": "Dimensionality reduction of this kind can be incorporated into the classifier directly by utilizing tensor calculus.", "labels": [], "entities": [{"text": "Dimensionality reduction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7778431177139282}]}, {"text": "In this paper, we adopt this strategy.", "labels": [], "entities": []}, {"text": "We start by building high-dimensional feature vectors that are subsequently mapped into a lowdimensional representation.", "labels": [], "entities": []}, {"text": "Since this highdimensional representation has to reflect the interaction between different indicators of semantic relations, we construct it as a cross-product of smaller feature vectors that capture distinct facets of semantic dependence: predicate, argument, syntactic path and role label.", "labels": [], "entities": []}, {"text": "By compressing this sparse representation into lower dimensions, we obtain dense representations for words (predicate, argument) and their connecting paths, uncovering meaningful interactions.", "labels": [], "entities": []}, {"text": "The associated parameters are maintained as a four-way low-rank tensor, and optimized for SRL performance.", "labels": [], "entities": [{"text": "SRL", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.984567403793335}]}, {"text": "Tensor modularity enables us to employ standard online algorithms for training.", "labels": [], "entities": []}, {"text": "Our approach to SRL is inspired by recent success of our tensor-based approaches in dependency parsing ( ).", "labels": [], "entities": [{"text": "SRL", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9913195967674255}, {"text": "dependency parsing", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8151105046272278}]}, {"text": "Applying analogous techniques to SRL brings about new challenges, however.", "labels": [], "entities": [{"text": "SRL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9613097310066223}]}, {"text": "The scoring function needs to reflect the highorder interactions between the predicate, argument, their syntactic path and the corresponding role label.", "labels": [], "entities": []}, {"text": "Therefore, we parametrize the scoring function as a four-way tensor.", "labels": [], "entities": []}, {"text": "Generalization to high-order tensors also requires new initialization and update procedures.", "labels": [], "entities": []}, {"text": "For instance, the SVD initialization used in our dependency parsing work results in memory explosion when extending to our 4-way tensor.", "labels": [], "entities": [{"text": "SVD initialization", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7232624590396881}, {"text": "dependency parsing", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7723268270492554}]}, {"text": "Instead, we employ the power method to build the initial tensor from smaller pieces, one rank-1 component at a time.", "labels": [], "entities": []}, {"text": "For learning, in order to optimize an overall non-convex objective function with respect to the tensor parameters, we modify the passive-aggressive algorithm to update all the low-rank components in one step.", "labels": [], "entities": []}, {"text": "The update strategy readily generalizes to any high-order tensor.", "labels": [], "entities": []}, {"text": "We evaluate our tensor-based approach for SRL on the CoNLL-2009 shared task benchmark datasets of five languages: English, German, Chinese, Catalan and Spanish (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9910433292388916}, {"text": "CoNLL-2009 shared task benchmark datasets", "start_pos": 53, "end_pos": 94, "type": "DATASET", "confidence": 0.8929503917694092}]}, {"text": "As a baseline, we use a simple SRL model that relies on a minimal set of standard features.", "labels": [], "entities": [{"text": "SRL", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9043626189231873}]}, {"text": "Our results demonstrate that the tensor-based model outperforms the original SRL model by a significant margin, yielding absolute improvements of 2.1% F 1 score.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9812630812327067}]}, {"text": "We also compare our results against the best performing system on this task ().", "labels": [], "entities": []}, {"text": "On three out of five languages, the tensor-based model outperforms this system.", "labels": [], "entities": []}, {"text": "These results are particularly notable because the system of employs a rich set of language-specific features carefully engineered for this task.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate that using four-way tensor yields better performance than its three-way counterpart, highlighting the importance of modeling the relation between role labels and properties of the path.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset We evaluate our model on the English dataset and other 4 datasets in the CoNLL-2009 shared task (.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9284110367298126}, {"text": "CoNLL-2009 shared task", "start_pos": 81, "end_pos": 103, "type": "DATASET", "confidence": 0.8437655170758566}]}, {"text": "We use the: Predicate/argument atomic features used by our tensor for SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.8931810259819031}]}, {"text": "word stands for the word form (and also lemma), pos stands for the predicted POS tag and voice stands for the voice of the predicate.", "labels": [], "entities": []}, {"text": "The suffixes -l and -r refer to the left and right of the current token respectively.", "labels": [], "entities": []}, {"text": "For example, pos-l means the POS tag to the left of the current word in the sentence.", "labels": [], "entities": []}, {"text": "official split for training, development and testing.", "labels": [], "entities": []}, {"text": "For English, the data is mainly drawn from the Wall Street Journal.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.9662733872731527}]}, {"text": "In addition, a subset of the Brown corpus is used as the secondary out-of-domain test set, in order to evaluate how well the model generalizes to a different domain.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.8203475475311279}]}, {"text": "Following the official practice, we use predicted POS tags, lemmas and morphological analysis provided in the dataset across all our experiments.", "labels": [], "entities": []}, {"text": "The predicates in each sentence are also given during both training and testing.", "labels": [], "entities": []}, {"text": "However, we neither predict nor use the sense for each predicate.", "labels": [], "entities": []}, {"text": "Systems for Comparisons We compare against three systems that achieve the top average performance in the joint syntactic and semantic parsing track of the CoNLL-2009 shared task ().", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 125, "end_pos": 141, "type": "TASK", "confidence": 0.7410798966884613}]}, {"text": "All approaches extensively explored rich features for the SRL task.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 58, "end_pos": 66, "type": "TASK", "confidence": 0.9354862570762634}]}, {"text": "We also compare with the stateof-the-art parser) for English, an improved version of systems participated in CoNLL-2009.", "labels": [], "entities": [{"text": "CoNLL-2009", "start_pos": 109, "end_pos": 119, "type": "DATASET", "confidence": 0.9306580424308777}]}, {"text": "This system combines the pipeline of dependency parser and semantic role labeler with a global reranker.", "labels": [], "entities": []}, {"text": "Finally, we compare with the recent approach which employs distributional word representations for SRL).", "labels": [], "entities": [{"text": "SRL", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9452166557312012}]}, {"text": "We directly obtain the outputs of all these systems from the CoNLL-2009 website 5 or the authors.", "labels": [], "entities": [{"text": "CoNLL-2009 website 5", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.9750113089879354}]}, {"text": "Model Variants Our full model utilizes 4-way tensor component and a standard feature set from.", "labels": [], "entities": []}, {"text": "We also compare against our model without the tensor component, as well as a variant with a 3-way tensor by combining the path and semantic role label parts into a single mode (dimension).", "labels": [], "entities": []}, {"text": "Evaluation Measures Following standard practice in the SRL evaluation, we measure the performance using labeled F-score.", "labels": [], "entities": [{"text": "SRL", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9408810138702393}, {"text": "F-score", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9872166514396667}]}, {"text": "To this end, we apply the evaluation script provided on the official website.", "labels": [], "entities": []}, {"text": "The standard evaluation script considers the predicate sense prediction as a special kind of semantic label.", "labels": [], "entities": [{"text": "predicate sense prediction", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6299141049385071}]}, {"text": "Since we are neither predicting nor using the predicate sense information, we exclude this information inmost of the evaluation.", "labels": [], "entities": []}, {"text": "In addition, we combine the predicate sense classification output of) with our semantic role labeling output, to provide results directly comparable to previous reported numbers.", "labels": [], "entities": [{"text": "predicate sense classification", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.5541771650314331}]}, {"text": "Experimental Details Across all experiments, we fix the rank of the tensor to 50 and train our model fora maximum of 20 epochs.", "labels": [], "entities": []}, {"text": "Following common practice, we average parameters overall iterations.", "labels": [], "entities": []}, {"text": "For each experimental setting, we tune the hyper-parameter \u03b3 \u2208 {0.3, 0.5, 0.7, 0.9} and C \u2208 {0.01, 0.1, 1} on the development set and apply the best model on the test set.", "labels": [], "entities": []}, {"text": "Each model is evaluated on the development set after every epoch to pick the the best number of training epoch.", "labels": [], "entities": []}, {"text": "For the experiments with random initialization on the tensor component, the vectors are initialized as random unit vectors.", "labels": [], "entities": []}, {"text": "We combine our SRL model with our syntactic dependency parser, RBGParser v1.1 ( ), for joint syntactic and semantic parsing.", "labels": [], "entities": [{"text": "joint syntactic and semantic parsing", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.6213662087917328}]}, {"text": "The labeled attachment score (LAS) of RBGParser is 90.4 on English, when we train the \"standard\" model type using the unsupervised word vectors.", "labels": [], "entities": [{"text": "labeled attachment score (LAS)", "start_pos": 4, "end_pos": 34, "type": "METRIC", "confidence": 0.9114656845728556}]}], "tableCaptions": [{"text": " Table 3: SRL labeled F-score of our model variants, and state-of-the-art systems on the CoNLL shared  task. We consider a tensor-free variant of our model, and tensor-based variants that include first-order SRL  features. For the latter, we consider implementations with 3-way and 4-way tensors. Winning systems (with  and without a reranker) are marked in bold. Statistical significance with p < 0.05 is marked with  * .", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.6262026429176331}, {"text": "F-score", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.8204962015151978}, {"text": "CoNLL shared  task", "start_pos": 89, "end_pos": 107, "type": "DATASET", "confidence": 0.8461044828097025}]}, {"text": " Table 4: Semantic labeled F-score excluding predicate senses on 5 languages in the CoNLL-2009 shared  task. Statistical significance with p < 0.05 is marked with  * . Adding the tensor leads to more than 2%  absolute gain on average F-score. Our method with the same feature configuration (a standard set + 4- way tensor) rivals the best CoNLL-2009 system which explores much richer feature sets, language-specific  feature engineering, and n-best parse combination (", "labels": [], "entities": [{"text": "F-score", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9202921986579895}, {"text": "F-score", "start_pos": 234, "end_pos": 241, "type": "METRIC", "confidence": 0.9791065454483032}]}]}