{"title": [{"text": "Enhancing Sumerian Lemmatization by Unsupervised Named-Entity Recognition", "labels": [], "entities": [{"text": "Enhancing Sumerian Lemmatization", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7958837946256002}, {"text": "Named-Entity Recognition", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.7122309803962708}]}], "abstractContent": [{"text": "Lemmatization for the Sumerian language, compared to the modern languages, is much more challenging due to that it is along dead language, highly skilled language experts are extremely scarce and more and more Sume-rian texts are coming out.", "labels": [], "entities": [{"text": "Lemmatization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9210271835327148}]}, {"text": "This paper describes how our unsupervised Sumerian named-entity recognition (NER) system helps to improve the lemmatization of the Cuneiform Digital Library Initiative (CDLI), a specialist database of cuneiform texts, from the Ur III period.", "labels": [], "entities": [{"text": "Sumerian named-entity recognition (NER)", "start_pos": 42, "end_pos": 81, "type": "TASK", "confidence": 0.7496973772843679}]}, {"text": "Experiments show that a promising improvement in personal name annotation in such texts and a substantial reduction inexpert annotation effort can be achieved by leveraging our system with minimal seed annotation.", "labels": [], "entities": [{"text": "personal name annotation", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.6675999363263448}]}], "introductionContent": [{"text": "Because the Sumerian cuneiform writing system is historically the earliest, Sumerian culture is the earliest recorded civilization.", "labels": [], "entities": []}, {"text": "The large number of clay tablets that have been recovered from Mesopotamia reveal \"an almost obsessive concern for the preservation of daily events of the time: the digging of ditches, the care of livestock, the storage of grain, and soon.", "labels": [], "entities": []}, {"text": "Their survival allows insight into the lives of the city dwellers of remote antiquity\".", "labels": [], "entities": []}, {"text": "Today, most cuneiform texts are held in public institutions, but the texts are widely separated both from each other and often from scholars by great distances and expensive journeys.", "labels": [], "entities": []}, {"text": "Current projects like the Digital Library Initiative and the Database of Neo-Sumerian Texts) aim to provide scholars immediate access to virtual collections of tens of thousands of texts.", "labels": [], "entities": []}, {"text": "The Ur III period is particularly abundant in surviving texts.", "labels": [], "entities": []}, {"text": "Because this era was the specialty of our principle informant, an Assyriologist at our home university, we focus on the tablets that are from this era.", "labels": [], "entities": []}, {"text": "The vast majority of these tablets record financial transactions, such as records of cattle deliveries, receipt of metals, repayment of loans, and so forth.", "labels": [], "entities": [{"text": "repayment of loans", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.890623410542806}]}, {"text": "shows a tablet from the CDLI repository.", "labels": [], "entities": [{"text": "CDLI repository", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.967670351266861}]}, {"text": "For expository purposes, we arranged the original cuneiform drawings on the left (which are not input to our computations), with its transliteration (a oneto-one transcription of signs in a cuneiform text to computer readable text) in the middle, and the modern English translation on the right.", "labels": [], "entities": []}, {"text": "The original CDLI data includes transliterations in ASCII format and inline lemmatization markup.", "labels": [], "entities": [{"text": "CDLI data", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.9324061274528503}]}, {"text": "More detail about CDLI data will be introduced in Section 2.", "labels": [], "entities": [{"text": "CDLI data", "start_pos": 18, "end_pos": 27, "type": "DATASET", "confidence": 0.9093091487884521}]}, {"text": "As we can see in, in addition to the provider and recipient of transference, tablets consistently enumerate lists of witnesses (\"sealed by\").", "labels": [], "entities": []}, {"text": "This fact makes the tablet an invaluable resource for the social history of the time since they record, implicitly, on each tablet, lists of persons who knew one another and enjoyed professional relations.", "labels": [], "entities": []}, {"text": "The recovery of personal names on the tablets suggests the possibility of reconstructing social networks of actors in the mercantile class and also, given the overlap, their social network connections to royalty.", "labels": [], "entities": []}, {"text": "Motivated by this perspective, we built an unsupervised Sumerian named-entity recognition (NER) system, also to accommodate the facts of 1) Sumerian is a dead language; 2) the corpus is of a size too large for even a community of scholars to master; 3) the tablets come in many cases damaged by time and the circumstances of their recovery which was, in many cases, looting; 4) new tablets are still being uncovered.", "labels": [], "entities": [{"text": "Sumerian named-entity recognition (NER)", "start_pos": 56, "end_pos": 95, "type": "TASK", "confidence": 0.8093031247456869}]}, {"text": "More detail on our Decision List Co-Train method) can be found in Section 3.", "labels": [], "entities": []}, {"text": "In the process of evaluating our NER sys- tem, we noticed that a major inconsistency between our result and the lemmata in CDLI lies in the annotation of personal names with missing signs in damaged tablets.", "labels": [], "entities": [{"text": "NER sys- tem", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.640804186463356}]}, {"text": "For example, \"szu-[x]-lum\" is not labeled as a name in the lemmata, but our system does so with a high confidence score.", "labels": [], "entities": []}, {"text": "As shown this word contains a damaged sign (indicated by \"\").", "labels": [], "entities": []}, {"text": "Inconsistencies of this kind account for around 50% of the total false positives in our result.", "labels": [], "entities": []}, {"text": "With the help of the Sumerologist at our home university, around 40% of such damaged occurrences have been easily verified as personal names.", "labels": [], "entities": []}, {"text": "This suggests that the original lemmatization is performed by a more critical and conservative approach.", "labels": [], "entities": []}, {"text": "Our work offers a promising automation tool for the annotation task on this corpus by making good recommendations on name candidates to the annotators.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used a 5-fold cross-validation model to train and test our NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.7448919415473938}]}, {"text": "In each fold, we randomly picked 85% of the tablets from the corpus for training and the remaining 15% of the tablets for testing.", "labels": [], "entities": []}, {"text": "With the top 20 new rules from each iteration being added to the decision list, the system produces a decision list of over 2000 rules and approximately 17,000 personal names in these Sumerian texts, after 150 iterations.", "labels": [], "entities": []}, {"text": "When the lemmata is used as the gold standard data set in this experiment, the system achieved 91.4% recall and 39.6% precision score on average from the 5-fold cross-validation.", "labels": [], "entities": [{"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9990206956863403}, {"text": "precision score", "start_pos": 118, "end_pos": 133, "type": "METRIC", "confidence": 0.9763546884059906}]}, {"text": "The low precision motivated us to take a closer look at the cause of the false positives from our system.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9950039982795715}]}, {"text": "Using fold-2 as an example, the system reported 16,657 personal names, and there are 7,406 annotated names in the lemmata.", "labels": [], "entities": []}, {"text": "Among all these 7,406 names, 91.4% has been correctly identified by the system.", "labels": [], "entities": []}, {"text": "However, 60.6% of the names reported by our system are not labeled as names in the lemmata.", "labels": [], "entities": []}, {"text": "Through error analysis, we found that nearly 50% of these false positive names contain\"missing\" or \"damaged\" signs in the transliteration (i.e., annotated as or in the lemmata).", "labels": [], "entities": []}, {"text": "They were therefore not annotated at all in the lemmata, even though their linguistic context clearly shows that they are personal names.", "labels": [], "entities": []}, {"text": "For example, \"szu-x-lum\" in \"giri3 szu-x-lum\" is a word in the testing data labeled as a name by our system after applying one of the seed rules.", "labels": [], "entities": []}, {"text": "However, owing to physical damage to the word in the original tablet (flagged by \"x\" in the lemmata), it is unannotated.", "labels": [], "entities": []}, {"text": "As a result, it's reported as a false positive in the evaluation.", "labels": [], "entities": []}, {"text": "Based on this observation, we asked the Sumeriologist at our home university to verify the \"false positives\" that contain \"missing\" or \"damaged\" signs (marked in the lemmata as either \"unknown\" (part of speech X) or \"unlemmatizable\" (part of speech u)), restricting our concern to damaged signs to limit the imposition on his time.", "labels": [], "entities": []}, {"text": "It turns out that over 40% of such names should have been labeled as a name in the first place.", "labels": [], "entities": []}, {"text": "This elevates the precision to 55.8% from 39.4% without sacrificing the recall, for fold-2 testing data.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9996538162231445}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9994940757751465}]}, {"text": "Similar performance gain is obtained for other folds.", "labels": [], "entities": []}, {"text": "Due to the large number of \"false positives\" and time constraints, we cannot impose on our Assyriologist informant the task of verifying all of the system reported names for us at the moment.", "labels": [], "entities": []}, {"text": "However, the current evaluation result reveals that the systematic lemmatization on CDLI, as discussed in Section 2, follows an extremely conservative approach.", "labels": [], "entities": []}, {"text": "We suspect that the reason for this is to avoid labeling damaged personal names as such is to prevent partial or potentially incorrect sign information from being reused by the morphological analyzer in future runs of the lemmatizer.", "labels": [], "entities": []}, {"text": "Our result suggests that the existing lemmata has its own limitation and should not be fully relied on for evaluation for our NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 126, "end_pos": 134, "type": "TASK", "confidence": 0.92830890417099}]}, {"text": "It also suggests that our NER system can be used for automatic annotation task given that it performs well in recovering names based on the context and spelling features, even with the minimal prior knowledge.", "labels": [], "entities": []}, {"text": "More details of the algorithms and result can be found in (.", "labels": [], "entities": []}], "tableCaptions": []}