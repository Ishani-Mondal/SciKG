{"title": [{"text": "A Preliminary Evaluation of the Impact of Syntactic Structure in Semantic Textual Similarity and Semantic Relatedness Tasks", "labels": [], "entities": [{"text": "Semantic Relatedness Tasks", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.8114006916681925}]}], "abstractContent": [{"text": "The well related tasks of evaluating the Semantic Textual Similarity and Semantic Relat-edness have been under a special attention in NLP community.", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.7507136066754659}, {"text": "Semantic Relat-edness", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.6960631310939789}]}, {"text": "Many different approaches have been proposed, implemented and evaluated at different levels, such as lexical similarity , word/string/POS tags overlapping, semantic modeling (LSA, LDA), etc.", "labels": [], "entities": []}, {"text": "However, at the level of syntactic structure, it is not clear how significant it contributes to the overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9978310465812683}]}, {"text": "In this paper, we make a preliminary evaluation of the impact of the syntactic structure in the tasks by running and analyzing the results from several experiments regarding to how syntactic structure contributes to solving these tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the introduction of Semantic Textual Similarity (STS) task at SemEval 2012 and the Semantic Relatedness (SR) task at SemEval 2014, a large number of participating systems have been developed to resolve the tasks.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task at SemEval 2012", "start_pos": 26, "end_pos": 80, "type": "TASK", "confidence": 0.7734541893005371}, {"text": "Semantic Relatedness (SR) task at SemEval 2014", "start_pos": 89, "end_pos": 135, "type": "TASK", "confidence": 0.8057651321093241}]}, {"text": "The systems must quantifiably identify the degree of similarity, relatedness, respectively, for pair of short pieces of text, like sentences, where the similarity or relatedness is abroad concept and its value is normally obtained by averaging the opinion of several annotators.", "labels": [], "entities": []}, {"text": "A semantic similarity/relatedness score is usually areal number in a semantic scale, in STS, or in SR, in the direction from no relevance to semantic equivalence.", "labels": [], "entities": [{"text": "STS", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.8974888324737549}, {"text": "SR", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.9675277471542358}]}, {"text": "Some examples from the dataset MSRpar of STS 2012 with associated similarity scores (by human judgment) are as below: \u2022 The bird is bathing in the sink. vs. Birdie is washing itself in the water basin.", "labels": [], "entities": [{"text": "MSRpar of STS 2012", "start_pos": 31, "end_pos": 49, "type": "DATASET", "confidence": 0.8739097267389297}, {"text": "similarity", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.8962951302528381}]}, {"text": "(score = 5.0) \u2022 Shares in EDS closed on Thursday at $18.51, again of 6 cents. vs. Shares of EDS closed Thursday at $18.51, up 6 cents on the New York Stock Exchange.", "labels": [], "entities": [{"text": "New York Stock Exchange", "start_pos": 141, "end_pos": 164, "type": "DATASET", "confidence": 0.9124132394790649}]}, {"text": "(score = 3.667) \u2022 Vivendi shares closed 3.8 percent up in Paris at 15.78 euros. vs. Vivendi shares were 0.3 percent up at 15.62 euros in Paris at 0841 GMT.", "labels": [], "entities": []}, {"text": "(score = 2.6) \u2022 John went horseback riding at dawn with a whole group of friends. vs. Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.", "labels": [], "entities": []}, {"text": "(score = 0) From our reading of the literature), most of STS/SR systems rely on pairwise similarity, such as lexical similarity using taxonomies) or distributional semantic models (LDA (), LSA (), ESA (, etc), and word/n-grams overlap as main features to train a support vector machines) regression model (supervised), or use a word-alignment metric (unsupervised) aligning the two given texts to compute their semantic similarity.", "labels": [], "entities": [{"text": "ESA", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.8816078305244446}]}, {"text": "Intuitively, the syntactic structure plays an important role for human being to understand the mean-ing of a given text.", "labels": [], "entities": []}, {"text": "Thus, it also may help to identify the semantic equivalence/relatedness between two given texts.", "labels": [], "entities": []}, {"text": "However, in the STS/SR tasks, very few systems provide evidence of the contribution of syntactic structure in its overall performance.", "labels": [], "entities": [{"text": "STS/SR", "start_pos": 16, "end_pos": 22, "type": "TASK", "confidence": 0.808480699857076}]}, {"text": "Some systems report partially on this issue, for example, iKernels) carried out an analysis on the STS 2012, but not on STS 2013 datasets.", "labels": [], "entities": [{"text": "STS 2012", "start_pos": 99, "end_pos": 107, "type": "DATASET", "confidence": 0.7598685622215271}, {"text": "STS 2013 datasets", "start_pos": 120, "end_pos": 137, "type": "DATASET", "confidence": 0.8347106575965881}]}, {"text": "They found that syntactic structure contributes 0.0271 and 0.0281 points more to the overall performance, from 0.8187 to 0.8458 and 0.8468, for adopting constituency and dependency trees, respectively.", "labels": [], "entities": []}, {"text": "In this paper, we analyze the impact of syntactic structure on the STS 2014 and SICK datasets of STS/SR tasks.", "labels": [], "entities": [{"text": "STS 2014 and SICK datasets of STS/SR tasks", "start_pos": 67, "end_pos": 109, "type": "DATASET", "confidence": 0.7750086426734925}]}, {"text": "We consider three systems which are reported to perform efficiently and effectively on processing syntactic trees using three proposed approaches Syntactic Tree Kernel), Syntactic Generalization ( and Distributed Tree Kernel (.", "labels": [], "entities": [{"text": "Syntactic Generalization", "start_pos": 170, "end_pos": 194, "type": "TASK", "confidence": 0.8773324191570282}, {"text": "Distributed Tree Kernel", "start_pos": 201, "end_pos": 224, "type": "TASK", "confidence": 0.6663579742113749}]}, {"text": "The remainder of the paper is as follows: Section 2 introduces three approaches to exploit the syntactic structure in STS/SR tasks, Section 3 describes Experimental Settings, Section 4 discusses about the Evaluations and Section 5 is the Conclusions and Future Work.", "labels": [], "entities": [{"text": "STS/SR tasks", "start_pos": 118, "end_pos": 130, "type": "TASK", "confidence": 0.6682616770267487}]}], "datasetContent": [{"text": "In this section, we describe the two corpora we use for experiments with several different settings to evaluate the contribution of each syntactic structure approach and in combination with other features in our baseline systems.", "labels": [], "entities": []}, {"text": "We run our experiments on two datasets from two different tasks at SemEval 2014 as follows: \u2022 The SICK dataset) is used in Task# 1 \"Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment\".", "labels": [], "entities": [{"text": "SICK dataset", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.6784378737211227}]}, {"text": "It consists of 10,000 English sentence pairs, built from two paraphrase sets: the 8K ImageFlickr dataset and the STS 2012 Video Descriptions dataset.", "labels": [], "entities": [{"text": "8K ImageFlickr dataset", "start_pos": 82, "end_pos": 104, "type": "DATASET", "confidence": 0.766873816649119}, {"text": "STS 2012 Video Descriptions dataset", "start_pos": 113, "end_pos": 148, "type": "DATASET", "confidence": 0.8538610458374023}]}, {"text": "11,12 Each sentence pair was annotated for relatedness score in scale and entailment relation.", "labels": [], "entities": []}, {"text": "It is split into three parts: Trial (500 pairs), Training (4,500 pairs) and Testing (4,927 pairs).", "labels": [], "entities": [{"text": "Testing", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9646568894386292}]}, {"text": "\u2022 The STS dataset is used in  In this section, we present twelve different settings for experimenting the contribution of syntactic structure individually and in combination with typi-  cal similarity features to the overall performance of computing similarity/relatedness score on SICK and STS datasets.", "labels": [], "entities": [{"text": "STS dataset", "start_pos": 6, "end_pos": 17, "type": "DATASET", "confidence": 0.8066372871398926}, {"text": "STS datasets", "start_pos": 291, "end_pos": 303, "type": "DATASET", "confidence": 0.7058939039707184}]}, {"text": "The results reported here are obtained with Pearson correlation, which is the official measure used in both tasks.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 44, "end_pos": 63, "type": "METRIC", "confidence": 0.9096382558345795}]}, {"text": "We have some discussions from the results in as below: The strong baseline DKPro is superior than the bag-of-word baseline on most of datasets (both STS and SICK), except the tweet-news where their performances are close as the tweet-news dataset contains little or no syntactic information compared to others.", "labels": [], "entities": []}, {"text": "Each syntactic approach is weaker than both baselines.", "labels": [], "entities": []}, {"text": "Though the STK and DTK both use the tree kernel approach, just different representations, the performance is similar only on the dataset images.", "labels": [], "entities": [{"text": "STK", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.864324688911438}, {"text": "DTK", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.803597629070282}]}, {"text": "The STK still performs better than DTK on most of STS datasets, but much lower on SICK dataset.", "labels": [], "entities": [{"text": "STS datasets", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.8207505643367767}, {"text": "SICK dataset", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.8410817086696625}]}, {"text": "This is reasonable as the SICK dataset is created for evaluating distributional semantics which suits the DTK approach.", "labels": [], "entities": [{"text": "SICK dataset", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.7372619807720184}]}, {"text": "Both approaches have some negative results on STS datasets; especially, both methods obtain negative correlation on two datasets \"images\" and \"tweet-news\".", "labels": [], "entities": [{"text": "STS datasets", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8168384432792664}]}, {"text": "It seems that both methods struggle to learn the semantic information (in parsing) extracted http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient from these two datasets.", "labels": [], "entities": []}, {"text": "Moreover, due to the fact that Twitter data is informal text which carries lot of noise created by users, and very different from formal text from other STS datasets, the syntactic approach does not seem to capture correct meaning, thus, the result confirms that syntactic approach is not suitable and beneficial for social media text.", "labels": [], "entities": []}, {"text": "In contrast, the SG performs better than other two approaches to obtain better correlation with human judgment; yet it is still below the bag-of-word baseline (only better on OnWN dataset).", "labels": [], "entities": [{"text": "SG", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9488763809204102}, {"text": "OnWN dataset", "start_pos": 175, "end_pos": 187, "type": "DATASET", "confidence": 0.9810302555561066}]}, {"text": "Hence, using any of these syntactic approaches is not sufficient to solve the STS/SR task as its performance is still lower than the weak baseline.", "labels": [], "entities": [{"text": "STS/SR task", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.8255238682031631}]}, {"text": "Some examples with gold-standard and system scores as below: \u2022 Blue and red plane in mid-air flight. vs. A blue and red airplane while in flight.", "labels": [], "entities": []}, {"text": "The combination of three approaches.", "labels": [], "entities": []}, {"text": "These three methods do not collaborate well on STS datasets, it even decreases the overall performance of the best method SG by a large margin of 8%.", "labels": [], "entities": [{"text": "STS datasets", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.8768291771411896}]}, {"text": "However, it improves the result on SICK dataset by a medium margin around 4%.", "labels": [], "entities": [{"text": "SICK dataset", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.8845705687999725}]}, {"text": "Finally, the combination of three methods still returns a lower result than the weak baseline.", "labels": [], "entities": []}, {"text": "Thus, this combination of syntactic approaches alone cannot solve the STS/SR tasks.", "labels": [], "entities": [{"text": "STS/SR", "start_pos": 70, "end_pos": 76, "type": "TASK", "confidence": 0.6792150338490804}]}, {"text": "The combination of syntactic information and bag-ofword approach more or less improves the performance over the weak baseline.", "labels": [], "entities": []}, {"text": "\u2022 The STK does not improve but has negative impact to the overall performance on STS with a decrease of 4%.", "labels": [], "entities": [{"text": "STK", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.6997925639152527}, {"text": "STS", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.4833202064037323}]}, {"text": "However, it gains a small improvement on SICK of 1%.", "labels": [], "entities": [{"text": "SICK", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9875698685646057}]}, {"text": "\u2022 Though the DTK returns 3.5% better result than STK on STS and slightly improves the performance on SICK for less than 1%, it is 0.5% lower than the weak baseline.", "labels": [], "entities": [{"text": "DTK", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.6748040914535522}]}, {"text": "\u2022 The SG improves the performance 2-12% on most of STS and SICK datasets.", "labels": [], "entities": [{"text": "SG", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9282128810882568}, {"text": "STS and SICK datasets", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.6245699152350426}]}, {"text": "It performs 4-8% better than the weak baseline, but still dramatically 11-14% lower than the DKPro baseline.", "labels": [], "entities": [{"text": "DKPro baseline", "start_pos": 93, "end_pos": 107, "type": "DATASET", "confidence": 0.866491436958313}]}, {"text": "\u2022 The combination of three methods with the bag-of-word results 3-8% better performance than the weak baseline on STS/SICK datasets.", "labels": [], "entities": [{"text": "STS/SICK datasets", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.7027231752872467}]}, {"text": "However, this combination brings negative effect of 0.5% to the overall result on STS in comparison to the performance of SG.", "labels": [], "entities": [{"text": "STS", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.6624854207038879}, {"text": "SG", "start_pos": 122, "end_pos": 124, "type": "TASK", "confidence": 0.8849118947982788}]}, {"text": "Perhaps DKPro baseline consists of several strong features which make syntactic features insignificant in the combination.", "labels": [], "entities": []}, {"text": "Hence, using a strong baseline like DKPro is not a good way to evaluate the significance of syntactic information.", "labels": [], "entities": []}, {"text": "\u2022 The STK gains small improvement on SICK (3%) and some STS datasets (1%), whereas other datasets remain unchanged.", "labels": [], "entities": [{"text": "STS datasets", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.8219943344593048}]}, {"text": "\u2022 The DTK does not have any effect to the result of DKPro standalone.", "labels": [], "entities": []}, {"text": "This shows that DTK has no integration with DKPro features.", "labels": [], "entities": [{"text": "DTK", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.8536010384559631}]}, {"text": "\u2022 The SG only makes slight improvement on SICK (0.2%) and deft-forum (1%), whereas little decrease on other datasets.", "labels": [], "entities": [{"text": "SG", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.8783205151557922}]}, {"text": "This shows that SG does not collaborate well with DKPro either.", "labels": [], "entities": []}, {"text": "\u2022 On STS, this total combination returns few small improvements around 1% on some datasets deft-forum, headlines, tweet-news and mean value, whereas 1-3% better on SICK dataset.", "labels": [], "entities": [{"text": "STS", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.8086903691291809}, {"text": "mean", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9515514373779297}, {"text": "SICK dataset", "start_pos": 164, "end_pos": 176, "type": "DATASET", "confidence": 0.8633167147636414}]}, {"text": "In conclusion, despite the fact that we experiment different methods to exploit syntactic information on different datasets derived from various data sources, the results in confirms the positive impact of syntactic structure in the overall performance on STS/SR tasks.", "labels": [], "entities": [{"text": "STS/SR tasks", "start_pos": 256, "end_pos": 268, "type": "TASK", "confidence": 0.7291087657213211}]}, {"text": "However, syntactic structure does not always work well and effectively on any dataset, it requires a certain level of syntactic presentation in the corpus to exploit.", "labels": [], "entities": [{"text": "syntactic structure", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.8267046511173248}]}, {"text": "In some cases, applying syntactic structure on poor-structured data may cause negative effect to the overall performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experiment Results on STS 2014 and SICK datasets.", "labels": [], "entities": [{"text": "SICK datasets", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.8545454740524292}]}]}