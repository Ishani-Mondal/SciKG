{"title": [{"text": "The Geometry of Statistical Machine Translation", "labels": [], "entities": [{"text": "Geometry of Statistical Machine Translation", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.720708703994751}]}], "abstractContent": [{"text": "Most modern statistical machine translation systems are based on linear statistical models.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.6521358092625936}]}, {"text": "One extremely effective method for estimating the model parameters is minimum error rate training (MERT), which is an efficient form of line optimisation adapted to the highly non-linear objective functions used in machine translation.", "labels": [], "entities": [{"text": "minimum error rate training (MERT", "start_pos": 70, "end_pos": 103, "type": "METRIC", "confidence": 0.8233555456002554}, {"text": "machine translation", "start_pos": 215, "end_pos": 234, "type": "TASK", "confidence": 0.7358653843402863}]}, {"text": "We describe a polynomial-time generalisation of line optimisation that computes the error surface over a plane embedded in parameter space.", "labels": [], "entities": []}, {"text": "The description of this algorithm relies on convex geometry, which is the mathematics of polytopes and their faces.", "labels": [], "entities": []}, {"text": "Using this geometric representation of MERT we investigate whether the optimisation of linear models is tractable in general.", "labels": [], "entities": [{"text": "MERT", "start_pos": 39, "end_pos": 43, "type": "TASK", "confidence": 0.5531260967254639}]}, {"text": "Previous work on finding optimal solutions in MERT (Galley and Quirk, 2011) established a worst-case complexity that was exponential in the number of sentences, in contrast we show that exponential dependence in the worst-case complexity is mainly in the number of features.", "labels": [], "entities": []}, {"text": "Although our work is framed with respect to MERT, the convex geometric description is also applicable to other error-based training methods for linear models.", "labels": [], "entities": [{"text": "MERT", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.4235638380050659}]}, {"text": "We believe our analysis has important ramifications because it suggests that the current trend in building statistical machine translation systems by introducing a very large number of sparse features is inherently not robust.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 107, "end_pos": 138, "type": "TASK", "confidence": 0.6274734338124593}]}], "introductionContent": [{"text": "The linear model of Statistical Machine Translation (SMT)) casts translation as a search for translation hypotheses under a linear combination of weighted features: a source language sentence f is translated as\u00ea as\u02c6as\u00ea(f ; w) = argmax e {wh(e, f )} where translation scores area linear combination of the D \u00d7 1 feature vector h(e, f ) \u2208 RD under the 1 \u00d7 D model parameter vector w.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT))", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.8407538533210754}]}, {"text": "Convex geometry is the mathematics of such linear equations presented as the study of convex polytopes.", "labels": [], "entities": [{"text": "Convex geometry", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7624990344047546}]}, {"text": "We use convex geometry to show that the behaviour of training methods such as MERT), MIRA (),, and others converge with a high feature dimension.", "labels": [], "entities": [{"text": "MERT", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.8520110845565796}, {"text": "MIRA", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9414069652557373}]}, {"text": "In particular we analyse how robustness decreases in linear models as feature dimension increases.", "labels": [], "entities": []}, {"text": "We believe that severe overtraining is a problem in many current linear model formulations due to this lack of robustness.", "labels": [], "entities": []}, {"text": "In the process of building this geometric representation of linear models we discuss algorithms such as the Minkowski sum algorithm and projected MERT (Section 4.2) that could be useful for designing new and more robust training algorithms for SMT and other natural language processing problems.", "labels": [], "entities": [{"text": "MERT", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.8999215364456177}, {"text": "SMT", "start_pos": 244, "end_pos": 247, "type": "TASK", "confidence": 0.9960048794746399}]}], "datasetContent": [], "tableCaptions": []}