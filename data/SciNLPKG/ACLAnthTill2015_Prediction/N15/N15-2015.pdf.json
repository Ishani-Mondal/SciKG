{"title": [{"text": "Improving the Translation of Discourse Markers for Chinese into English", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9828667044639587}, {"text": "Translation of Discourse Markers", "start_pos": 14, "end_pos": 46, "type": "TASK", "confidence": 0.8916967362165451}]}], "abstractContent": [{"text": "Discourse markers (DMs) are ubiquitous cohesive devices used to connect what is said or written.", "labels": [], "entities": [{"text": "Discourse markers (DMs)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6271540224552155}]}, {"text": "However, across languages there is divergence in their usage, placement, and frequency, which is considered to be a major problem for machine translation (MT).", "labels": [], "entities": [{"text": "frequency", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9733313918113708}, {"text": "machine translation (MT)", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.8440022706985474}]}, {"text": "This paper presents an overview of a proposed thesis , exploring the difficulties around DMs in MT, with a focus on Chinese and English.", "labels": [], "entities": [{"text": "DMs", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9801231026649475}, {"text": "MT", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.8974021077156067}]}, {"text": "The thesis will examine two main areas: modelling cohesive devices within sentences and modelling discourse relations (DRs) across sentences.", "labels": [], "entities": []}, {"text": "Initial experiments have shown promising results for building a prediction model that uses linguistically inspired features to help improve word alignments with respect to the implicit use of cohesive devices, which in turn leads to improved hierarchical phrase-based MT.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 140, "end_pos": 155, "type": "TASK", "confidence": 0.7065218240022659}, {"text": "MT", "start_pos": 268, "end_pos": 270, "type": "TASK", "confidence": 0.8123013377189636}]}], "introductionContent": [{"text": "Statistical Machine Translation (SMT) has, in recent years, seen substantial improvements, yet approaches are notable to achieve high quality translations in many cases.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.85231813788414}]}, {"text": "The problem is especially prominent with complex composite sentences and distant language pairs, largely due to computational complexity.", "labels": [], "entities": []}, {"text": "Rather than considering larger discourse segments as a whole, current SMT approaches focus on the translation of single sentences independently, with clauses and short phrases being treated in isolation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9934287667274475}]}, {"text": "DMs are seen as a vital contextual link between discourse segments and could be used to guide translations in order to improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9920468330383301}]}, {"text": "However, they are often translated into the target language in ways that differ from how they are used in the source language).", "labels": [], "entities": []}, {"text": "DMs can also signal numerous DRs and current SMT approaches do not adequately recognise or distinguish between them during the translation process).", "labels": [], "entities": [{"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9857584238052368}]}, {"text": "Recent developments in SMT potentially allow the modelling of wider discourse information, even across sentences, but currently most existing models appear to focus on producing well translated localised sentence fragments, largely ignoring the wider global cohesion.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9935750365257263}]}, {"text": "Five distinct cohesive devices have been identified, but for this thesis the pertinent devices that will be examined are conjunction (DMs) and (endophoric) reference.", "labels": [], "entities": []}, {"text": "Conjunction is pertinent as it encompasses DMs, whilst reference includes pronouns (amongst other elements), which are often connected with the use of DMs (e.g. 'Because John ..., therefore he ...').", "labels": [], "entities": []}, {"text": "The initial focus is on the importance of DMs within sentences, with special attention given to implicit markers (common in Chinese) and a number of related word alignment issues.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 157, "end_pos": 171, "type": "TASK", "confidence": 0.7320517897605896}]}, {"text": "However, the final thesis will cover two main areas: \u2022 Modelling cohesive devices within sentences \u2022 Modelling discourse relations across sentences and wider discourse segments.", "labels": [], "entities": [{"text": "Modelling cohesive devices within sentences", "start_pos": 55, "end_pos": 98, "type": "TASK", "confidence": 0.8854744076728821}, {"text": "Modelling discourse relations", "start_pos": 101, "end_pos": 130, "type": "TASK", "confidence": 0.8848209579785665}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 a survey of related work is conducted.", "labels": [], "entities": []}, {"text": "Section 3 outlines the initial motivation and research including a preliminary corpus analysis.", "labels": [], "entities": []}, {"text": "It covers examples that highlight various problems with the translation of (implicit) DMs, leading to an initial intuition.", "labels": [], "entities": [{"text": "translation of (implicit) DMs", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.8044116795063019}]}, {"text": "Section 4 looks at experiments and word alignment issues following a deeper corpus analysis and discusses how the intuition led towards developing the methodology used to study and improve word alignments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7945311665534973}, {"text": "word alignments", "start_pos": 189, "end_pos": 204, "type": "TASK", "confidence": 0.7296957671642303}]}, {"text": "It also includes the results of the experiments that show positive gains in BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9941442608833313}]}, {"text": "Section 5 provides an outline of the future work that needs to be carried out.", "labels": [], "entities": []}, {"text": "Finally, Section 6 is the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section examines the current ongoing research and experiments that aim to measure the extent of the difficulties caused by DMs.", "labels": [], "entities": [{"text": "DMs", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.962831974029541}]}, {"text": "In particular the focus is on automated word alignments and problems around implicit and misaligned DMs.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.6846272796392441}]}, {"text": "The work discussed in Section 3 highlighted the importance of improving word alignments, and especially how missing alignments around markers can lead to the generation of poorer rules.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 72, "end_pos": 87, "type": "TASK", "confidence": 0.7889916002750397}]}, {"text": "Before progressing onto the experiments an initial baseline system was produced according to detailed criteria).", "labels": [], "entities": []}, {"text": "The initial system was created using the ZH-EN data from the BTE parallel corpus (Paul, 2009) (Section 3).", "labels": [], "entities": [{"text": "ZH-EN data from the BTE parallel corpus (Paul, 2009)", "start_pos": 41, "end_pos": 93, "type": "DATASET", "confidence": 0.865181510647138}]}, {"text": "Fast-Align is used to generate the word alignments and the CDEC decoder () is used for rule extraction and decoding.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.6777967661619186}, {"text": "CDEC decoder", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.9324462711811066}, {"text": "rule extraction", "start_pos": 87, "end_pos": 102, "type": "TASK", "confidence": 0.7934895753860474}]}, {"text": "The baseline and subsequent systems discussed here are hierarchical phrase-based systems for Chinese to English translation.", "labels": [], "entities": [{"text": "Chinese to English translation", "start_pos": 93, "end_pos": 123, "type": "TASK", "confidence": 0.6439416706562042}]}, {"text": "Once the alignments were obtained the next step in the methodology was to examine the misalignment information to determine the occurrence of implicit markers.", "labels": [], "entities": []}, {"text": "A variance list was created 5 that could be used to cross-reference discourse markers with appropriate substitutable words (as per.", "labels": [], "entities": []}, {"text": "Each DM was then examined in turn (automatically) to look at what it had been aligned to.", "labels": [], "entities": []}, {"text": "When the explicit English marker was aligned correctly, according to the variance list, then no change was made.", "labels": [], "entities": []}, {"text": "If the marker was aligned to an unsuitable word, then an artificial marker was placed into the Chinese in the nearest free space to that word.", "labels": [], "entities": []}, {"text": "Finally if the marker was not aligned at all then an artificial marker was inserted into the nearest free space   by number . A percentage of misalignments 7 across all occurrences of individual markers was also calculated.", "labels": [], "entities": []}, {"text": "shows the misalignment percentages for the four given DMs across the three corpora.", "labels": [], "entities": [{"text": "misalignment", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9638292789459229}]}, {"text": "The average sentence length in the BTE Corpus is eight units, in the FBIS corpus it is 30 units, and in the TED corpus it is 29 units.", "labels": [], "entities": [{"text": "BTE Corpus", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.9314172267913818}, {"text": "FBIS corpus", "start_pos": 69, "end_pos": 80, "type": "DATASET", "confidence": 0.8986682891845703}, {"text": "TED corpus", "start_pos": 108, "end_pos": 118, "type": "DATASET", "confidence": 0.8387850224971771}]}, {"text": "The scores show that there is a wide variance in the misalignments across the corpora, with FBIS consistently having the highest error rate, but in all cases the percentage is fairly significant.", "labels": [], "entities": [{"text": "error rate", "start_pos": 129, "end_pos": 139, "type": "METRIC", "confidence": 0.9926515519618988}]}, {"text": "Initially tokens were inserted for single markers at a time, but then finally with tokens for all markers inserted simultaneously.", "labels": [], "entities": []}, {"text": "shows the BLEU scores for all the experiments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999176561832428}]}, {"text": "The first few experiments showed improvements over the baseline of up to +0.30, whereas the final one showed improvements of up to +0.44, which is significant.", "labels": [], "entities": []}, {"text": "After running the experiments the visualisation of a number of word alignments (as per) were examined and a single example of a 'then' sentence was chosen at random.", "labels": [], "entities": []}, {"text": "shows the word alignments fora sentence from the baseline system, and shows the word alignments for", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Misalignment information for the 3 corpora.", "labels": [], "entities": []}, {"text": " Table 3: BLEU Scores for the Experimental Systems", "labels": [], "entities": [{"text": "BLEU Scores", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9732578694820404}]}]}