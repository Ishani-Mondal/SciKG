{"title": [{"text": "Cross-lingual Text Classification Using Topic-Dependent Word Probabilities", "labels": [], "entities": [{"text": "Cross-lingual Text Classification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7025790810585022}]}], "abstractContent": [{"text": "Cross-lingual text classification is a major challenge in natural language processing, since often training data is available in only one language (target language), but not available for the language of the document we want to classify (source language).", "labels": [], "entities": [{"text": "Cross-lingual text classification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6868643860022227}, {"text": "natural language processing", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.66628098487854}]}, {"text": "Here, we propose a method that only requires a bilingual dictionary to bridge the language gap.", "labels": [], "entities": []}, {"text": "Our proposed probabilistic model allows us to estimate translation probabilities that are conditioned on the whole source document.", "labels": [], "entities": []}, {"text": "The assumption of our probabilistic model is that each document can be characterized by a distribution over topics that help to solve the translation ambiguity of single words.", "labels": [], "entities": [{"text": "translation ambiguity of single words", "start_pos": 138, "end_pos": 175, "type": "TASK", "confidence": 0.8029295325279235}]}, {"text": "Using the derived translation probabilities, we then calculate the expected word frequency of each word type in the target language.", "labels": [], "entities": []}, {"text": "Finally , these expected word frequencies can be used to classify the source text with any classi-fier that was trained using only target language documents.", "labels": [], "entities": []}, {"text": "Our experiments confirm the usefulness of our proposed method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text classification is ubiquitous in natural language processing.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8135338127613068}]}, {"text": "It's applications range from simple topic detection, like articles about sport vs articles about computers, to sentimental analysis, and subtle discrimination of Tweets that report the abuse of drugs or the metaphoric use of drugs (\"love is like a drug\").", "labels": [], "entities": [{"text": "topic detection", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.7300465404987335}, {"text": "sentimental analysis", "start_pos": 111, "end_pos": 131, "type": "TASK", "confidence": 0.823549747467041}]}, {"text": "Text classification hugely relies on manually annotated training data in one language.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8583483099937439}]}, {"text": "However, creating training data for each language is expensive, and therefore, we are interested in using training data given in only one language (e.g. English, denoted as target language) to classify text written in a different language (e.g. Chinese, or Japanese, denoted as source language).", "labels": [], "entities": []}, {"text": "Our approach addresses this issue by using a simple bilingual dictionary.", "labels": [], "entities": []}, {"text": "Bilingual dictionaries have the great advantage that they are available often for free , and have good coverage for major languages, like Chinese and Japanese.", "labels": [], "entities": [{"text": "Bilingual dictionaries", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7373440563678741}]}, {"text": "With the help of the dictionary, we calculate the expected frequency of each word in the target language.", "labels": [], "entities": []}, {"text": "Finally, we create a feature vector in the target language that is used as input for the text classifier.", "labels": [], "entities": []}, {"text": "However, due to the translation ambiguity of a word in the source language, it is important to carefully choose the translation probability for calculating the expected frequencies of the target words.", "labels": [], "entities": []}, {"text": "For example, consider a Japanese news article that contains the word (restrict, restrain, in custody), and we want to find out whether the article is about \"foreign policy\" or not.", "labels": [], "entities": []}, {"text": "The most simple method is to use all its English translations, and assume a uniform distribution over them, i.e. {0.33, 0.33 and 0.33}.", "labels": [], "entities": []}, {"text": "However, depending on the topic of the news article, the translation \"in custody\" is more appropriate.", "labels": [], "entities": []}, {"text": "For example, if the article reports about a crime/crime suspect, the translation \"in custody\" is more likely than \"restrict\" and \"restrain\".", "labels": [], "entities": []}, {"text": "Conversely, if the article is about \"military\", the translation \"in custody\" is less likely.", "labels": [], "entities": []}, {"text": "Moreover, an article that is about the topic \"military\" is more likely to belong to the class \"foreign policy\".", "labels": [], "entities": []}, {"text": "This example demonstrates the importance of estimating good translation probabilities in order to improve the clas-sification of the source text.", "labels": [], "entities": []}, {"text": "Therefore, we propose a probabilistic model that uses latent document topics to help improve the translation probabilities fora source document.", "labels": [], "entities": []}, {"text": "Our experiments, on three different pairs of corpora, confirm that our probabilistic model for estimating word translation probabilities is helpful for cross-lingual text classification.", "labels": [], "entities": [{"text": "estimating word translation probabilities", "start_pos": 95, "end_pos": 136, "type": "TASK", "confidence": 0.7966737300157547}, {"text": "cross-lingual text classification", "start_pos": 152, "end_pos": 185, "type": "TASK", "confidence": 0.7474522988001505}]}], "datasetContent": [{"text": "For our experiments we use three pair of corpora denoted by NEWS, WEB, and TWEETS.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.8606619834899902}, {"text": "WEB", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9771899580955505}, {"text": "TWEETS", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9929497241973877}]}, {"text": "The corpora NEWS contains news articles in English and: Shows the break-even point (f1-score) of the proposed method Co and three baselines for each pair of corpora.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.9039987921714783}, {"text": "break-even point (f1-score)", "start_pos": 66, "end_pos": 93, "type": "METRIC", "confidence": 0.9268333792686463}]}, {"text": "Co (freq) and Co (uni) denote the proposed method without estimation of dictionary probabilities, but instead using word frequency and uniform distribution, respectively.", "labels": [], "entities": []}, {"text": "Japanese crawled from Internet news sites during 2012-2013, and were annotated as being related to \"foreign policy\" or not related.", "labels": [], "entities": [{"text": "Japanese crawled from Internet news sites", "start_pos": 0, "end_pos": 41, "type": "DATASET", "confidence": 0.8996563851833344}]}, {"text": "The corpora WEB contains web pages in English and Chinese that are categorized either as \"sport\" or \"computer\" in the Open Directory Project (ODP) 6 crawled in 2013.", "labels": [], "entities": [{"text": "Open Directory Project (ODP) 6 crawled in 2013", "start_pos": 118, "end_pos": 164, "type": "DATASET", "confidence": 0.7040867507457733}]}, {"text": "TWEETS contains tweets in English and Chinese gathered during 2013, classified as related to \"violence\", or not related.", "labels": [], "entities": [{"text": "TWEETS", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9533957839012146}]}, {"text": "We tokenize and stem the words in the English corpora using Senna).", "labels": [], "entities": []}, {"text": "For Chinese and Japanese we use the morphological analyzers described in (, and an inhouse analyzer, respectively.", "labels": [], "entities": []}, {"text": "The Chinese to English dictionary, and the Japanese to English dictionary contains translations for 94351 and 1483440 words, respectively.", "labels": [], "entities": []}, {"text": "For the classification we use LIBSVM (Chang and Lin, 2011) with linear kernel, and the feature representation as suggested in (.", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.559855580329895}]}, {"text": "For the parameter estimation of our proposed model we use EM, as described in Section 3.1 and 3.2.", "labels": [], "entities": [{"text": "EM", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.842592716217041}]}, {"text": "The number of topics was determined by optimizing the f1-measure using only the English training data when applying the probabilistic model to monolingual text classification.", "labels": [], "entities": [{"text": "monolingual text classification", "start_pos": 143, "end_pos": 174, "type": "TASK", "confidence": 0.6152895788351694}]}, {"text": "In order to prevent non-zero probabilities, we use asymmetric Dirichlet prior.", "labels": [], "entities": []}, {"text": "We compare our proposed method \"Co\" to four different baselines that also use solely a bilingual dictionary.", "labels": [], "entities": []}, {"text": "For all methods (baselines and proposed), we use Equation to estimate the expected word frequencies.", "labels": [], "entities": [{"text": "Equation", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9802753329277039}]}, {"text": "The baseline \"Wu et al.\" refers to the method proposed in ().", "labels": [], "entities": []}, {"text": "The baseline \"Freq\" sets the probability p(e|f ) to be proportional to the word frequency in the training data.", "labels": [], "entities": [{"text": "Freq", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9589844346046448}]}, {"text": "Analogously, the baseline \"Uniform\" assumes a uniform probability overall translations off . For measuring the performance of each text classifier we use precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9996591806411743}, {"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.9993473887443542}]}, {"text": "The break-even point and the f1-measure of our proposed method and all baselines are shown in.", "labels": [], "entities": []}, {"text": "As can be seen, our method performs favorable for the NEWS and TWEETS corpora.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.8227198719978333}, {"text": "TWEETS corpora", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.8331024944782257}]}, {"text": "For the WEB corpora pair and our proposed method is at par with the baseline \", and looses slightly to the \"Uniform\" baseline.", "labels": [], "entities": [{"text": "WEB corpora pair", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.8500887354214987}]}, {"text": "For reference, we also show the upper bounds \"CN/JA only\" and \"EN only\" that train and test in the same source and target language, respectively.", "labels": [], "entities": [{"text": "EN", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9414452910423279}]}, {"text": "We also analyzed the contribution of using the word translation probabilities learned in Section 3.2.", "labels": [], "entities": [{"text": "word translation", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.6883514821529388}]}, {"text": "The method \"Co (freq)\" is the same as our proposed method, except that the translation probabilities p(f |e) are not estimated using the method described in Section 3.2, but instead simply uses the word-frequency distribution.", "labels": [], "entities": []}, {"text": "Analogously, the method \"Co (uni)\" is the same as our proposed method, except that p(f |e) is set to the uniform probability for all translations of e.", "labels": [], "entities": []}, {"text": "Limiting the discussion to break-even points, we see, in, an improvement of around 2 percent points for NEWS, but only minor changes in performance for the other two corpora (WEB and TWEETS).", "labels": [], "entities": [{"text": "NEWS", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.8913751840591431}, {"text": "WEB", "start_pos": 175, "end_pos": 178, "type": "METRIC", "confidence": 0.55226069688797}, {"text": "TWEETS", "start_pos": 183, "end_pos": 189, "type": "METRIC", "confidence": 0.5764064788818359}]}, {"text": "Finally, we give an example which shows the translation probabilities for the word (restrict, restrain, custody) for two different source documents in NEWS.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 151, "end_pos": 155, "type": "DATASET", "confidence": 0.9318574666976929}]}, {"text": "The first source document F 1 reports a military action, and is labeled as \"foreign policy\".", "labels": [], "entities": []}, {"text": "The second document F 2 is a news article about terror, and is labeled as \"not foreign policy\".", "labels": [], "entities": []}, {"text": "The results shown in, confirm our intuition, That is the point where precision and recall are equal.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9996379613876343}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9992782473564148}]}, {"text": "These results were acquired using cross-validation. that the translation \"custody\" is more likely in documents related to crime.", "labels": [], "entities": []}, {"text": "e = restrict e = restrain e = custody p(e|f, F1) 0.33 0.10 0.57 p(e|f, F2) 0.02 0.00 0.98: Shows the translation probabilities for the source word f = , within document F 1 (military related, class is \"foreign policy\") and document F 2 (terror related, class is not \"foreign policy\").", "labels": [], "entities": []}], "tableCaptions": []}