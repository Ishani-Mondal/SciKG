{"title": [{"text": "Short Text Understanding by Leveraging Knowledge into Topic Model", "labels": [], "entities": [{"text": "Short Text Understanding", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5869755446910858}]}], "abstractContent": [{"text": "In this paper, we investigate the challenging task of understanding short text (STU task) by jointly considering topic modeling and knowledge incorporation.", "labels": [], "entities": [{"text": "knowledge incorporation", "start_pos": 132, "end_pos": 155, "type": "TASK", "confidence": 0.7325027137994766}]}, {"text": "Knowledge incorporation can solve the content sparsity problem effectively for topic modeling.", "labels": [], "entities": [{"text": "Knowledge incorporation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7267783433198929}, {"text": "topic modeling", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.817526251077652}]}, {"text": "Specifically, the phrase topic model is proposed to leverage the auto-mined knowledge, i.e., the phrases, to guide the generative process of short text.", "labels": [], "entities": [{"text": "generative process of short text", "start_pos": 119, "end_pos": 151, "type": "TASK", "confidence": 0.8485784411430359}]}, {"text": "Experimental results illustrate the effectiveness of the mechanism that utilizes knowledge to improve topic modeling's performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "The explosion of online text content, such as twitter messages, text advertisements, QA community messages and product reviews has given rise to the necessity of understanding these prevalent short texts.", "labels": [], "entities": []}, {"text": "Conventional topic modeling, like PLSA () and LDA ( are widely used for uncovering the hidden topics from text corpus.", "labels": [], "entities": []}, {"text": "However, the sparsity of content in short texts brings new challenges to topic modeling.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.781522661447525}]}, {"text": "In fact, short texts usually do not contain sufficient statistical signals to support many state-ofthe-art approaches for text processing such as topic modeling (.", "labels": [], "entities": [{"text": "text processing", "start_pos": 122, "end_pos": 137, "type": "TASK", "confidence": 0.7175502926111221}, {"text": "topic modeling", "start_pos": 146, "end_pos": 160, "type": "TASK", "confidence": 0.838047206401825}]}, {"text": "Knowledge is indispensable to STU task, where knowledge-based topic model () has attracted more attention recently.", "labels": [], "entities": [{"text": "STU task", "start_pos": 30, "end_pos": 38, "type": "TASK", "confidence": 0.5728192925453186}]}], "datasetContent": [{"text": "Online reviews dataset (, which consists of four domains, is utilized to evaluate our model, where each domain collection contains 500 reviews.", "labels": [], "entities": []}, {"text": "Each review's average length is 20.42.", "labels": [], "entities": []}, {"text": "The statistics of each domain are presented in.", "labels": [], "entities": []}, {"text": "It's worth noting that the Phrase is auto-identified by the key-phrase extraction method.", "labels": [], "entities": [{"text": "key-phrase extraction", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.747116893529892}]}, {"text": "And the Word represents the whole distinct words for those identified key-phrases.", "labels": [], "entities": []}, {"text": "In our paper, we assumed each domain has a single topic model.", "labels": [], "entities": []}, {"text": "For different domain, we think the semantic space is quite different.", "labels": [], "entities": []}, {"text": "So we performed the proposed topic model with respect to different domain.", "labels": [], "entities": []}, {"text": "The number of topics is usually determined by experience, in our experiment, each domain collection contains 500 reviews, we think the number of topics ranging from 2 to 20 is appropriate, and these reviews are sufficient to train a topic model.", "labels": [], "entities": []}, {"text": "We compare our model with four baseline models: non-knowledgeable model LDA, self-contained knowledgeable model BTM, external knowledgebased model GK-LDA ( and DF-LDA (.", "labels": [], "entities": []}, {"text": "Those identified key-phrases are used as must-links in DF-LDA and LR-sets in GK-LDA.", "labels": [], "entities": []}, {"text": "This can ensure the incorporated knowledge upon different models are equal.", "labels": [], "entities": []}, {"text": "illustrates the auto-identified phrases from cellphone dataset.", "labels": [], "entities": []}, {"text": "From this result, we can see key-phrase extraction method can efficiently identify mostly phrases.", "labels": [], "entities": [{"text": "key-phrase extraction", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7778739631175995}]}, {"text": "More than one phrase, for example warranty service and android phone, may appear in a single sentence, and their topic assignments are probably different.", "labels": [], "entities": []}, {"text": "Our proposed phrase topic model(PTM) can well handle this case, which is more well-defined than the assumption of all words within a sentence share one topic.", "labels": [], "entities": []}, {"text": "Our phrase topic model assumes non-phrase term's topic assignment should depend on that of key-phrases in the same text.", "labels": [], "entities": []}, {"text": "This assumption can be clearly confirmed by, for example, Nokia N97 mini is semantic dependent US- B charge cable, the same as company and warranty service.", "labels": [], "entities": [{"text": "Nokia N97 mini", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.9207893013954163}, {"text": "US- B charge", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.6424321979284286}]}, {"text": "For all models, posterior inference was drawn after 1000 Gibbs iterations with an initial burn-in of 800 iterations.", "labels": [], "entities": []}, {"text": "For all models, we set the hyperparameters \u03b1 = 2 and \u03b2 = 0.5.", "labels": [], "entities": []}, {"text": "The evaluation results over Topic Coherence Metric are presented in and.", "labels": [], "entities": []}, {"text": "This figure indicates our model and BTM can get higher topic coherence score than GK-LDA and DF-LDA, which means the self-defined knowledge and the mechanism of knowledge incorporation are effective to topic model.", "labels": [], "entities": []}, {"text": "LDA's performance is acceptable but not stable.", "labels": [], "entities": []}, {"text": "Our model performs better than BTM, which is probably because the rough assumption of BTM on generated biterms.", "labels": [], "entities": [{"text": "BTM", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.7462421655654907}]}, {"text": "From the above analysis, we can see our proposed model can get the best performance.", "labels": [], "entities": []}, {"text": "T-test results show that the performance improvement of our model over baselines is statistically significant on Topic Coherence Metric.", "labels": [], "entities": [{"text": "T-test", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6070307493209839}]}, {"text": "All p-values for t-test are less than 0.00001.", "labels": [], "entities": []}, {"text": "presents the fluctuation of topic coherence when tuning the hyper-parameter \u03b1 and \u03b2.", "labels": [], "entities": []}, {"text": "We can see that the performance fluctuates within a limited range as we vary \u03b1 and \u03b2.", "labels": [], "entities": []}, {"text": "The topic coherence fluctuates between \u2212550 and \u2212950 other than food dataset, which gets less fluctuation range.", "labels": [], "entities": []}, {"text": "shows example topics for each domain, where inconsistent words are highlighted in red.", "labels": [], "entities": []}, {"text": "From this results, we can seethe number of errors in phrase topic model(PTM) is significantly less than LDA, which indicates our proposed topic model is more suitable than LDA for short text.", "labels": [], "entities": [{"text": "LDA", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9866829514503479}]}], "tableCaptions": [{"text": " Table 1.  It's worth noting that the Phrase is auto-identified  by the key-phrase extraction method. And the Word", "labels": [], "entities": [{"text": "key-phrase extraction", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.7425057888031006}, {"text": "Word", "start_pos": 110, "end_pos": 114, "type": "DATASET", "confidence": 0.7278194427490234}]}, {"text": " Table 1: Statistic information of the dataset.", "labels": [], "entities": []}, {"text": " Table 3: Example topics. First row: domain, Second row: inferred topic tag. Errors are highlighted in red.", "labels": [], "entities": []}]}