{"title": [{"text": "A Dynamic Programming Algorithm for Tree Trimming-based Text Summarization ERATO Minato Discrete Structure Manipulation System Project, JST", "labels": [], "entities": [{"text": "Tree Trimming-based Text Summarization ERATO Minato Discrete Structure Manipulation", "start_pos": 36, "end_pos": 119, "type": "TASK", "confidence": 0.7935116092363993}, {"text": "JST", "start_pos": 136, "end_pos": 139, "type": "DATASET", "confidence": 0.6226239800453186}]}], "abstractContent": [{"text": "Tree trimming is the problem of extracting an optimal subtree from an input tree, and sentence extraction and sentence compression methods can be formulated and solved as tree trimming problems.", "labels": [], "entities": [{"text": "Tree trimming", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6941502690315247}, {"text": "sentence extraction", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.7450143098831177}, {"text": "sentence compression", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.7023026347160339}]}, {"text": "Previous approaches require integer linear programming (ILP) solvers to obtain exact solutions.", "labels": [], "entities": [{"text": "integer linear programming (ILP) solvers", "start_pos": 28, "end_pos": 68, "type": "TASK", "confidence": 0.6817648368222373}]}, {"text": "The problem of this approach is that ILP solvers are black-boxes and have no theoretical guarantee as to their computation complexity.", "labels": [], "entities": [{"text": "ILP solvers", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.8983712494373322}]}, {"text": "We propose a dynamic programming (DP) algorithm for tree trimming problems whose running time is O(N L log N), where N is the number of tree nodes and L is the length limit.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.7379668354988098}, {"text": "O", "start_pos": 97, "end_pos": 98, "type": "METRIC", "confidence": 0.9724707007408142}]}, {"text": "Our algorithm exploits the zero-suppressed binary decision diagram (ZDD), a data structure that represents a family of sets as a directed acyclic graph, to represent the set of subtrees in a compact form; the structure of ZDD permits the application of DP to obtain exact solutions, and our algorithm is applicable to different tree trimming problems.", "labels": [], "entities": []}, {"text": "Moreover , experiments show that our algorithm is faster than state-of-the-art ILP solvers, and that it scales well to handle large summariza-tion problems.", "labels": [], "entities": [{"text": "ILP solvers", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.790609747171402}]}], "introductionContent": [{"text": "Extractive text summarization and sentence compression are tasks that basically select a subset of the input set of textual units that is appropriate as a summary or a compressed sentence.", "labels": [], "entities": [{"text": "Extractive text summarization", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7180273433526357}, {"text": "sentence compression", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7205177694559097}]}, {"text": "Current text summarization and sentence compression methods regard the problem of extracting such a subset as a combinatorial optimization problem (e.g.,).", "labels": [], "entities": [{"text": "text summarization", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7250730395317078}, {"text": "sentence compression", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7557761371135712}]}, {"text": "Tree trimming, the problem of finding an optimal subtree of an input tree, is one kind of these combinatorial optimization problems, and it is used in three classes of text summarizations: sentence compression (, single-document summarization (, and the combination of sentence compression and single-document summarization ().", "labels": [], "entities": [{"text": "Tree trimming", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7008333057165146}, {"text": "text summarizations", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.6834947615861893}, {"text": "sentence compression", "start_pos": 189, "end_pos": 209, "type": "TASK", "confidence": 0.7338385879993439}, {"text": "sentence compression", "start_pos": 269, "end_pos": 289, "type": "TASK", "confidence": 0.7108750194311142}]}, {"text": "In these tasks, the set of input textual units is represented as a rooted tree whose nodes correspond to the minimum textual units such as sentences and words.", "labels": [], "entities": []}, {"text": "Next, a subset is made by forming a subtree by trimming the input tree.", "labels": [], "entities": []}, {"text": "Since the optimal trimmed subtree preserves the relationships between textual units, it is a concise representation of the original set that preserves linguistic quality.", "labels": [], "entities": []}, {"text": "A shortcoming of tree trimming-based methods is that they are formulated as integer linear programming (ILP) problems and so an ILP solver is needed to solve them.", "labels": [], "entities": [{"text": "tree trimming-based", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7594878077507019}]}, {"text": "Although modern ILP solvers can solve many instances of tree trimming problems in a short time, there is no theoretical guarantee that they obtain an optimal solution.", "labels": [], "entities": [{"text": "ILP solvers", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.916734904050827}, {"text": "tree trimming", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.7706284523010254}]}, {"text": "Furthermore, even if an optimal solution can be obtained, we cannot estimate the running time.", "labels": [], "entities": []}, {"text": "Estimating the running time is critical for practical applications.", "labels": [], "entities": []}, {"text": "In this paper, we propose a dynamic programming (DP) algorithm for tree trimming problems that focus on text summarization.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 67, "end_pos": 80, "type": "TASK", "confidence": 0.7486508190631866}, {"text": "text summarization", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7192070186138153}]}, {"text": "The algorithm can solve all three different classes of tree trimming problems proposed so far in a unified way, and it can always find an optimal solution in O(N L log N ) time for these problems, where N is the number of nodes of the input tree and L is the length limit.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.8113067150115967}]}, {"text": "The running time of our algorithm only depends on N and Land so is independent of the input trees structure.", "labels": [], "entities": []}, {"text": "Finding an exact solution is important since we can use it to evaluate the performance of heuristic algorithms.", "labels": [], "entities": []}, {"text": "The key idea of our algorithm is to use the zerosuppressed binary decision diagram (ZDD) to represent the set of all subtrees of the input tree.", "labels": [], "entities": []}, {"text": "ZDD is a data structure that represents a family of sets as a directed acyclic graph (DAG).", "labels": [], "entities": []}, {"text": "It can represent a family of sets in compressed form.", "labels": [], "entities": []}, {"text": "We use ZDD to represent the set of subtrees of the input tree, and then run a DP algorithm on the ZDD to obtain the optimal solution that satisfies the length limit.", "labels": [], "entities": []}, {"text": "The algorithm runs in time O(|Z|L), where |Z| is the number of nodes of ZDD, and L is the length limit.", "labels": [], "entities": []}, {"text": "Although the number of ZDD nodes depends on the set we want to represent, we can give theoretical upper bounds when we represent the set of all subtrees of an input tree.", "labels": [], "entities": []}, {"text": "ZDD uses O(N log N ) nodes to represent the set of all subtrees of an N node input tree.", "labels": [], "entities": []}, {"text": "Hence the DP algorithm runs in O(N L log N ) time.", "labels": [], "entities": [{"text": "O", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.9393956661224365}]}, {"text": "The main virtues of the proposed algorithm are that (1) it can always find an exact solution, (2) its running time is theoretically guaranteed, and (3) it can solve the three known tree trimming problems.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 181, "end_pos": 194, "type": "TASK", "confidence": 0.761398047208786}]}, {"text": "Furthermore, our algorithm is fast enough to be practical and scalable.", "labels": [], "entities": []}, {"text": "Since text summarization methods are often applied to large scale inputs (e.g.,), scalability is important.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7026559710502625}]}, {"text": "We compare it to state-of-the-art ILP solvers and confirm that the proposed algorithm can be hundreds of times faster.", "labels": [], "entities": [{"text": "ILP solvers", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.7689011096954346}]}, {"text": "Since our method assumes known formuations for text summarization, the summary created by our algorithm is exactly the same as that obtained by applying previous methods.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7456347048282623}]}, {"text": "However, we believe that algorithmic improvements in computational cost is as important as improvements inaccuracy in order to make better practical systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on the three tree trimming tasks of text summarization, sentence compression, and the combination of summarization and text compression.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7202280461788177}, {"text": "sentence compression", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.7770242691040039}, {"text": "summarization", "start_pos": 124, "end_pos": 137, "type": "TASK", "confidence": 0.9734618663787842}, {"text": "text compression", "start_pos": 142, "end_pos": 158, "type": "TASK", "confidence": 0.6841878592967987}]}, {"text": "For the text summarization experiments, we use the test collection for summarization evaluation contained in the RST Discourse Treebank (RST-DTB)), which is used in the previous work.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.5420544594526291}, {"text": "summarization", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.9652337431907654}, {"text": "RST Discourse Treebank (RST-DTB))", "start_pos": 113, "end_pos": 146, "type": "DATASET", "confidence": 0.8867523570855459}]}, {"text": "The test collection consists of 30 documents with the reference summaries whose length is about 10% of the original document.", "labels": [], "entities": []}, {"text": "We used the same parameters used in the previous papers.", "labels": [], "entities": []}, {"text": "For sentence compression, we use the English compression corpus used in, which consists of 82 news stories selected from the British National Corpus and American News Text Corpus, and consists of more than 1,300 sentences.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8227311074733734}, {"text": "British National Corpus", "start_pos": 125, "end_pos": 148, "type": "DATASET", "confidence": 0.9297187924385071}, {"text": "American News Text Corpus", "start_pos": 153, "end_pos": 178, "type": "DATASET", "confidence": 0.9357025623321533}]}, {"text": "We set the sizes of compressed sentences to be 70% of the original length, which is used in the original paper.", "labels": [], "entities": []}, {"text": "We compare the proposed algorithm to Gurobi 5.5.0, a widely used commercial ILP solver 2 . It was run in the default settings and we used singlethread mode.", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 76, "end_pos": 86, "type": "TASK", "confidence": 0.8299683034420013}]}, {"text": "We run Gurobi until it finds an optimal solution.", "labels": [], "entities": []}, {"text": "Our algorithm was implemented in C++, and all experiments were conducted on a Linux machine with a Xeon E5-2670 2.60 GHz CPU and 192 GB RAM.", "labels": [], "entities": []}, {"text": "compares the running time of our algorithm (includes ZDD construction time) and Gurobi.", "labels": [], "entities": [{"text": "Gurobi", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9938983917236328}]}, {"text": "Each plotted marker in the figures represents a test instance, and if the position of a marker is below the dashed line, it means that our method is faster than Gurobi.", "labels": [], "entities": []}, {"text": "We can see that our method is always faster than Gurobi; it was, at most, 300, 10, and 50 times faster in sentence extraction, sentence compression, and extraction & compression, respectively.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7890245020389557}, {"text": "sentence compression", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.7832026481628418}, {"text": "extraction & compression", "start_pos": 153, "end_pos": 177, "type": "TASK", "confidence": 0.7376606265703837}]}, {"text": "shows the relation between the input tree size and the ZDD construction times, and the relation between the input tree size and converted ZDD size respectively.", "labels": [], "entities": []}, {"text": "These results show that both ZDD sizes and construction time were linear to the number of input tree nodes.", "labels": [], "entities": []}, {"text": "The number of ZDD nodes looks like smaller than the O(N log N ) bounds for multirooted trees and nested trees.", "labels": [], "entities": [{"text": "O", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.9453941583633423}]}, {"text": "This result is caused since the set of root candidate nodes R is small comparing with N fora typical input document.", "labels": [], "entities": []}, {"text": "Next we conduct experiments to assess the scalability of the proposed method by solving problems with different input sizes.", "labels": [], "entities": []}, {"text": "We choose the nested tree  trimming problem since it is the most complex problem.", "labels": [], "entities": [{"text": "nested tree  trimming", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.7189707557360331}]}, {"text": "We make a large artificial nested tree by concatenating outer-trees of the nested trees of 30 RST-DT datasets.", "labels": [], "entities": [{"text": "RST-DT datasets", "start_pos": 94, "end_pos": 109, "type": "DATASET", "confidence": 0.7981412708759308}]}, {"text": "The results are shown in, and it shows that out method scales well with large inputs comparing with Gurobi.", "labels": [], "entities": []}], "tableCaptions": []}