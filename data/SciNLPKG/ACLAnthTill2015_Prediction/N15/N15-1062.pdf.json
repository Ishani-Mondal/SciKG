{"title": [], "abstractContent": [{"text": "Linguistic borrowing is the phenomenon of transferring linguistic constructions (lexical, phonological, morphological, and syntactic) from a \"donor\" language to a \"recipient\" language as a result of contacts between communities speaking different languages.", "labels": [], "entities": [{"text": "Linguistic borrowing is the phenomenon of transferring linguistic constructions (lexical, phonological, morphological, and syntactic) from a \"donor\" language to a \"recipient\" language as a result of contacts between communities speaking different languages", "start_pos": 0, "end_pos": 256, "type": "Description", "confidence": 0.8356531516807836}]}, {"text": "Borrowed words are found in all languages, and-in contrast to cognate relationships-borrowing relationships may exist across unrelated languages (for example, about 40% of Swahili's vocabulary is borrowed from Arabic).", "labels": [], "entities": []}, {"text": "In this paper, we develop a model of morpho-phonological transformations across languages with features based on universal constraints from Optimality Theory (OT).", "labels": [], "entities": []}, {"text": "Compared to several standard-but linguistically na\u00efve-baselines, our OT-inspired model obtains good performance with only a few dozen training examples, making this a cost-effective strategy for sharing lexical information across languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "We may imagine that globalization is a modern phenomenon, but the lexicons of the world's languages attest to the fact that robust interaction between communities of speakers of different languages is widespread throughout history.", "labels": [], "entities": []}, {"text": "Language contact breeds linguistic borrowing-a phenomenon as old as language itself-adoption and nativization of phonemes, morphemes, words, and syntactic constructions from another language).", "labels": [], "entities": []}, {"text": "Contact-induced borrowing is a fundamental research topic in linguistics; however, in computational linguistics, very limited work has addressed modeling this phenomenon.", "labels": [], "entities": []}, {"text": "The problem we address is the identification of plausible donor words (in the donor language) given a loanword (in the recipient language), and vice versa, identification of loanwords given a donor.", "labels": [], "entities": [{"text": "identification of plausible donor words", "start_pos": 30, "end_pos": 69, "type": "TASK", "confidence": 0.8009252667427063}]}, {"text": "For example, given a Swahili loanword safari 'journey', our model identifies its Arabic donor (sfryh) 'journey' ( \u00a72).", "labels": [], "entities": []}, {"text": "Although at a high level, this is an instance of the well-known problem of modeling string transductions, our interest is being able to identify correspondences across languages with minimal supervision, so as to make the technique applicable in low-resource settings.", "labels": [], "entities": [{"text": "modeling string transductions", "start_pos": 75, "end_pos": 104, "type": "TASK", "confidence": 0.6308358709017435}]}, {"text": "To reduce the supervision burden, we propose a model that includes awareness of the morpho-phonological repair strategies that native speakers of a language subconsciously employ to adapt a loanword to phonological constraints of the recipient language ( \u00a73).", "labels": [], "entities": []}, {"text": "To this end, we use constraint-based theories of phonology, as exemplified by Optimality Theory (OT), which noncomputational linguistic work has demonstrated to be particularly well suited to account for phonologically complex borrowing processes.", "labels": [], "entities": [{"text": "Optimality Theory (OT)", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6733539223670959}]}, {"text": "We operationalize OT constraints as features in our borrowing model ( \u00a74).", "labels": [], "entities": []}, {"text": "We conduct a case study on Arabic and Swahili, two unrelated languages with along history of contact; we then apply the model to additional language pairs ( \u00a75).", "labels": [], "entities": []}, {"text": "The proposed approach significantly outperforms transliteration and cognate discovery models ( \u00a76).", "labels": [], "entities": []}, {"text": "Figure 1: Our morpho-phonological borrowing model conceptually has three main parts: (1) conversion of orthographic word forms to pronunciations in IPA format; (2) generation of loanword pronunciation candidates; (3) ranking of generated candidates using Optimality-Theoretic constraints.", "labels": [], "entities": [{"text": "generation of loanword pronunciation candidates", "start_pos": 164, "end_pos": 211, "type": "TASK", "confidence": 0.7878521680831909}]}, {"text": "Part (1) and (2) are rule-based, (1) uses pronunciation dictionaries, (2) is based on prior linguistic studies; part (3) is learned.", "labels": [], "entities": []}, {"text": "In (3) we learn OT constraint weights from a few dozen automatically extracted training examples.", "labels": [], "entities": [{"text": "OT constraint", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.8827866911888123}]}], "datasetContent": [{"text": "Our experimental setup is defined as follows.", "labels": [], "entities": []}, {"text": "The input to the borrowing model is a loanword candidate in Swahili/Romanian, 8 the outputs are plausible donor words in the Arabic/French monolingual lexicon (i.e., any word in pronunciation dictionary).", "labels": [], "entities": []}, {"text": "We train the borrowing model using a small set of training examples, and then evaluate it using a held-out test set.", "labels": [], "entities": []}, {"text": "In the rest of this section we describe in detail our datasets, tools, and experimental results.", "labels": [], "entities": []}, {"text": "Resources We employ Arabic-English and Swahili-English bitexts to extract a training set (corpora of sizes 5.4M and 14K sentence pairs, respectively), using a cognate discovery technique).", "labels": [], "entities": []}, {"text": "Phonetically and semantically similar strings are classified as cognates; phonetic similarity is the string similarity between phonetic representations, and semantic similarly is approximated by translation.", "labels": [], "entities": []}, {"text": "We thereby extract Arabic Our model does not provide a mechanism for identifying loanwords in the recipient language; we only model the borrowing process.", "labels": [], "entities": []}, {"text": "Classifying loanwords in the recipient language is an interesting but ultimately different problem: the ontological status of words in a lexicon is a difficult problem, even for human experts, however, knowledge of cross-lingual correspondences is a valuable feature, and as such, our work can be understood as enabling this.", "labels": [], "entities": [{"text": "Classifying loanwords in the recipient language", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8427120248476664}]}, {"text": "This cognate discovery technique is sufficient to extract a small training set, but is not generally applicable, as it requires and Swahili pairs a, s that are phonetically similar ( \u2206(a,s) min(|a|,|s|) < 0.5) where \u2206(a, s) is the Levenshtein distance between a and sand that are aligned to the same English word e.", "labels": [], "entities": []}, {"text": "FastAlign () is used for word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7703840434551239}]}, {"text": "Given an extracted word pair a, s, we also extract word pairs {{a , s} for all proper Arabic words a which share the same lemma with a producing on average 33 Arabic types per Swahili type.", "labels": [], "entities": []}, {"text": "We use MADA () for Arabic morphological expansion.", "labels": [], "entities": [{"text": "MADA", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.8040831089019775}, {"text": "Arabic morphological expansion", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.5748640596866608}]}, {"text": "From the resulting dataset of 490 extracted ArabicSwahili borrowing examples, we set aside randomly sampled 73 examples (15%) for evaluation, and use the remaining 417 examples for model parameter optimization.", "labels": [], "entities": [{"text": "model parameter optimization", "start_pos": 181, "end_pos": 209, "type": "TASK", "confidence": 0.6231428782145182}]}, {"text": "For French-Romanian language pair, we use an existing small annotated set of borrowing examples, with 282 training and 50 (15%) randomly sampled test examples.", "labels": [], "entities": []}, {"text": "We use pyfst-a Python interface to OpenFst-for the borrowing model implementation.", "labels": [], "entities": [{"text": "borrowing model", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.8919440507888794}]}, {"text": "Baselines We compare our model to several baselines.", "labels": [], "entities": []}, {"text": "In the Levenshtein (L) distance baselines we chose the closest word (either surface or pronunciation-based).", "labels": [], "entities": [{"text": "Levenshtein (L) distance baselines", "start_pos": 7, "end_pos": 41, "type": "METRIC", "confidence": 0.7424384951591492}]}, {"text": "In the Levenshtein-weighted (L-W) baselines, we evaluate a variant of the Levenshtein distance tuned to identify cognates (); this method was identified by among the top three cognate identification methods.", "labels": [], "entities": []}, {"text": "In the CRF baselines we generate plausible \"transliterations\" of the input Swahili (or Romanian) words in the donor lexicon using the model of, with multiple references in a lattice and without reranking.", "labels": [], "entities": [{"text": "CRF baselines", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.8255627453327179}]}, {"text": "The CRF transliteration model is a linear-chain CRF where we label each source character with a sequence of target characters.", "labels": [], "entities": []}, {"text": "The features are label unigrams, label bigrams, and label parallel corpora or manually constructed dictionaries to measure semantic similarity.", "labels": [], "entities": []}, {"text": "Large parallel corpora are unavailable for most language pairs, including Swahili-English.", "labels": [], "entities": []}, {"text": "In each training/test example one Swahili word corresponds to all extracted Arabic donor words.", "labels": [], "entities": []}, {"text": "conjoined with a moving window of source characters.", "labels": [], "entities": []}, {"text": "In the OT-uniform baseline, we evaluate the accuracy of the borrowing model with uniform weights, thus shortest paths in the loanwords transducer will be forms violating the fewest constraints.", "labels": [], "entities": [{"text": "OT-uniform baseline", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.7328259348869324}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9993719458580017}]}, {"text": "Evaluation In addition to predictive accuracy on all models (if a model produces multiple hypotheses with the same 1-best weight, we count the proportion of correct outputs in this set), we evaluate two particular aspects of our proposed model: (1) appropriateness of the model family, and (2) the quality of the learned OT constraint weights.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9800951480865479}]}, {"text": "The first aspect is designed to evaluate whether the morpho-phonological transformations implemented in the model are required and sufficient to generate loanwords from the donor inputs.", "labels": [], "entities": []}, {"text": "We report two evaluation measures: model reachability and ambiguity.", "labels": [], "entities": []}, {"text": "Reachability is a percentage of test samples that are reachable (i.e., there is a path from the input test example to a correct output) in the loanword transducer.", "labels": [], "entities": []}, {"text": "A na\u00efve model which generates all possible strings would score 100% reachability, but it will be hard to set the model parameters such that it discriminates between good and bad candidates.", "labels": [], "entities": []}, {"text": "In order to capture this trade-off, we also report the inherent ambiguity of our model, which is the average number of outputs potentially generated per input.", "labels": [], "entities": []}, {"text": "A generic ArabicSwahili transducer, for example, has an ambiguity of 786,998-the size of the Arabic pronunciation lexicon.", "labels": [], "entities": [{"text": "ambiguity", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9866859912872314}]}, {"text": "Results The borrowing model reachability and ambiguity are listed in table 3.", "labels": [], "entities": []}, {"text": "The model obtains high reachability, while significantly reducing the average number of possible outputs per input: in Arabic from 787K to 857 words, in French from 62K to 12.", "labels": [], "entities": []}, {"text": "This result shows that the loanword transducer design, based on the prior linguistic analysis, is a plausible model of word borrowing.", "labels": [], "entities": [{"text": "word borrowing", "start_pos": 119, "end_pos": 133, "type": "TASK", "confidence": 0.7553263604640961}]}, {"text": "Yet, there are on average 33 correct Arabic words out of the possible 857 outputs, thus the second part of the model-OT constraint weights optimization-is crucial.", "labels": [], "entities": []}, {"text": "show how challenging the task of modeling lexical borrowing between two distinct languages is, and importantly, that orthographic and phonetic baselines including the stateof-the-art generative model of transliteration are not suitable for this task.", "labels": [], "entities": []}, {"text": "Phonetic baselines for Arabic-AR-SW FR-RO Reachability 87.7% 82.0% Ambiguity 857 12: The evaluation of the borrowing model accuracy.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9969983100891113}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9888641834259033}]}, {"text": "The baselines are orthographic (surface) and phonetic (based on pronunciation lexicon) Levenshtein distance (L), heuristic Levenshtein distance with lower penalty on vowel updates and similar letter/phone substitutions (L-W), CRF transliteration, and our model with uniform (OT-U) and learned OT constraint weights assignment.", "labels": [], "entities": [{"text": "Levenshtein distance (L)", "start_pos": 87, "end_pos": 111, "type": "METRIC", "confidence": 0.9035851001739502}]}, {"text": "Swahili perform better than orthographic ones, but substantially worse than OT-based models, even if OT constraints are not weighted.", "labels": [], "entities": []}, {"text": "Crucially, the performance of the borrowing model with the learned OT weights corroborates the assumption made in numerous linguistic accounts that OT is an adequate analysis of the lexical borrowing phenomenon.", "labels": [], "entities": []}, {"text": "highly in the French-Romanian model, where vowel insertion is rare.", "labels": [], "entities": [{"text": "vowel insertion", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.6470344960689545}]}, {"text": "A second interesting by-product of our model is an inferred syllabification.", "labels": [], "entities": []}, {"text": "While we did not conduct a systematic quantitative evaluation, higher-ranked Swahili outputs tend to contain linguistically plausible syllabifications, although the syllabification transducer inserts optional syllable boundaries between every pair of phones.", "labels": [], "entities": []}, {"text": "This result further attests to the plausible constraint ranking learned by the model.", "labels": [], "entities": []}, {"text": "Example Swahili syllabifications 14 along with the OT constraint violations produced by the borrowing model are depicted in table 5.", "labels": [], "entities": [{"text": "OT constraint violations", "start_pos": 51, "end_pos": 75, "type": "METRIC", "confidence": 0.7343417207400004}]}], "tableCaptions": [{"text": " Table 3: The evaluation of the borrowing model design.  Reachability is a percentage of donor-recipient pairs that  are reachable from a donor to a recipient language. Am- biguity is an average number of outputs that the model  generates per one input.", "labels": [], "entities": [{"text": "Am- biguity", "start_pos": 169, "end_pos": 180, "type": "METRIC", "confidence": 0.9349929292996725}]}, {"text": " Table 4: The evaluation of the borrowing model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9869406819343567}]}]}