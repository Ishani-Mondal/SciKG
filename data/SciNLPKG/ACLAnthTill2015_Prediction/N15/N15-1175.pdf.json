{"title": [{"text": "A Comparison of Update Strategies for Large-Scale Maximum Expected BLEU Training", "labels": [], "entities": [{"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9588733911514282}]}], "abstractContent": [{"text": "This work presents a flexible and efficient discriminative training approach for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.7617294291655222}]}, {"text": "We propose to use the RPROP algorithm for optimizing a maximum expected BLEU objective and experimentally compare it to several other updating schemes.", "labels": [], "entities": [{"text": "RPROP", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.8117543458938599}, {"text": "BLEU objective", "start_pos": 72, "end_pos": 86, "type": "METRIC", "confidence": 0.9761636257171631}]}, {"text": "It proves to be more efficient and effective than the previously proposed growth transformation technique and also yields better results than stochastic gradient descent and AdaGrad.", "labels": [], "entities": []}, {"text": "We also report strong empirical results on two large scale tasks, namely BOLT Chinese\u2192English and WMT German\u2192English, where our final systems outperform results reported by Setiawan and Zhou (2013) and on matrix.statmt.org.", "labels": [], "entities": [{"text": "BOLT", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9204889535903931}, {"text": "WMT German\u2192English", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.6646053045988083}]}, {"text": "On the WMT task, discriminative training is performed on the full training data of 4M sentence pairs, which is unsurpassed in the literature .", "labels": [], "entities": [{"text": "WMT task", "start_pos": 7, "end_pos": 15, "type": "TASK", "confidence": 0.8953293859958649}]}], "introductionContent": [{"text": "The main advantage of learning parameters in a discriminative fashion is the possibility to directly optimize towards a quality or error measure on the task that is being performed.", "labels": [], "entities": []}, {"text": "This stands in contrast to the generative approach, where parameters are chosen to maximize likelihood under a generative story, which often bears little correspondence with the actual application of the model.", "labels": [], "entities": [{"text": "generative", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.9747084379196167}]}, {"text": "In statistical machine translation (SMT), extending the generative noisy-channel formulation) as a discriminative, log-linear combination of multiple models has become the state of the art.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8201005856196085}]}, {"text": "However, most of the component models are still estimated by heuristics or generative training.", "labels": [], "entities": []}, {"text": "In this paper, a flexible, efficient and easy to implement discriminative training scheme for SMT is presented.", "labels": [], "entities": [{"text": "SMT", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9957695007324219}]}, {"text": "It can be applied to any kind and any number of features.", "labels": [], "entities": []}, {"text": "We use the RPROP algorithm to optimize a maximum expected BLEU objective.", "labels": [], "entities": [{"text": "RPROP", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.8216131925582886}, {"text": "BLEU objective", "start_pos": 58, "end_pos": 72, "type": "METRIC", "confidence": 0.9709456264972687}]}, {"text": "n-best lists approximate the infeasibly large space of translation hypotheses.", "labels": [], "entities": []}, {"text": "They are generated with the application of leave-one-out to make them more representative with respect to unseen data.", "labels": [], "entities": []}, {"text": "We make the following main contributions: 1.", "labels": [], "entities": []}, {"text": "We propose to apply the RPROP algorithm for maximum expected BLEU training and perform an experimental comparison with growth transformation (GT), stochastic gradient descent () and AdaGrad (.", "labels": [], "entities": [{"text": "RPROP", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.8486347198486328}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9880114197731018}, {"text": "AdaGrad", "start_pos": 182, "end_pos": 189, "type": "DATASET", "confidence": 0.7915138006210327}]}, {"text": "RPROP yields superior performance, reaching a total improvement of 1.2 BLEU points over our IWSLT German\u2192English baseline using 5.22M features.", "labels": [], "entities": [{"text": "RPROP", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8005059957504272}, {"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.999458372592926}, {"text": "IWSLT German\u2192English baseline", "start_pos": 92, "end_pos": 121, "type": "DATASET", "confidence": 0.8375141978263855}]}], "datasetContent": [{"text": "In terms of BLEU RPROP performs best, followed by AdaGrad, GT and SGD, where the RPROPAdaGrad and AdaGrad-GT differences are small (0.2% BLEU absolute) but statistically significant on the 95% level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9930018782615662}, {"text": "AdaGrad", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9257542490959167}, {"text": "BLEU absolute", "start_pos": 137, "end_pos": 150, "type": "METRIC", "confidence": 0.9697284996509552}]}, {"text": "Altogether, RPROP improves over the baseline by 0.9 BLEU points, which is statistically significant at the 99% level.", "labels": [], "entities": [{"text": "RPROP", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.978023111820221}, {"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9995940327644348}]}, {"text": "In an additional experiment we verified that leave-one-out has a clear  impact on the results.", "labels": [], "entities": []}, {"text": "The BLEU difference between RPROP with and without leave-one-out is 0.6% absolute.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9997190833091736}, {"text": "RPROP", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9714657664299011}]}, {"text": "By adding lexical, triplet and reordering features, we get an additional gain and observe a total improvement of 1.2 BLEU points over the baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.99871826171875}]}, {"text": "921K discriminative phrase table features are active in our training data.", "labels": [], "entities": [{"text": "921K discriminative phrase table", "start_pos": 0, "end_pos": 32, "type": "DATASET", "confidence": 0.869277223944664}]}, {"text": "Due to the renormalization component, this results in a total of 6.08M features that are updated with GT using the same data.", "labels": [], "entities": []}, {"text": "Consequently, it is less time and space efficient than the other algorithms.", "labels": [], "entities": []}, {"text": "With our implementation, GT needed around 16 hours and 6.7G memory for 40 iterations, where RPROP, AdaGrad and SGD finished after less than 2.5 hours and required 2.1G memory.", "labels": [], "entities": []}, {"text": "For the BOLT task, we directly compare with the GT-trained system in (Setiawan and Zhou, 2013) using the same tune set for MERT and reporting results on the same test sets, see.", "labels": [], "entities": [{"text": "BOLT", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.850520670413971}]}, {"text": "With RPROP we achieve nearly twice the improvement reported by Setiawan on both web and MT06 using feature sets (a)-(c) . Our baseline on web is already much stronger and RPROP training yields +0.7 BLEU points, as opposed to +0.44 reported by Setiawan.", "labels": [], "entities": [{"text": "MT06", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.9494333267211914}, {"text": "BLEU", "start_pos": 198, "end_pos": 202, "type": "METRIC", "confidence": 0.9990277290344238}]}, {"text": "On MT06 our baseline system is slightly worse, but with the larger gain received by RPROP our final system outperforms the one reported by Se-  tiawan by 0.2 BLEU points.", "labels": [], "entities": [{"text": "MT06", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.9063164591789246}, {"text": "RPROP", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.48921719193458557}, {"text": "Se-  tiawan", "start_pos": 139, "end_pos": 150, "type": "DATASET", "confidence": 0.8355395197868347}, {"text": "BLEU", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.9990033507347107}]}, {"text": "We would like to stress that this is not a domain adaptation effect, as maximum expected BLEU training was performed on discussion forum (df) data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7091328650712967}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.998256504535675}]}, {"text": "On the df test set, on the other hand, we probably can observe domain adaptation via RPROP training.", "labels": [], "entities": [{"text": "df test set", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.7461109360059103}, {"text": "domain adaptation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7545621395111084}]}, {"text": "The improvement here is 0.7% BLEU absolute with a single reference, as opposed to four references on web and MT06.", "labels": [], "entities": [{"text": "BLEU absolute", "start_pos": 29, "end_pos": 42, "type": "METRIC", "confidence": 0.9279510080814362}, {"text": "MT06", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.9670701026916504}]}, {"text": "We also report results training the same feature sets with SGD and AdaGrad, confirming results we observed on IWSLT.", "labels": [], "entities": [{"text": "AdaGrad", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.898663341999054}, {"text": "IWSLT", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.9466792345046997}]}, {"text": "Here, SGD yields only minor improvements.", "labels": [], "entities": [{"text": "SGD", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.8112685680389404}]}, {"text": "AdaGrad performs better, but still 0.1 -0.4 BLEU points worse than RPROP.", "labels": [], "entities": [{"text": "AdaGrad", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9544335603713989}, {"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9969598054885864}, {"text": "RPROP", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.6377066373825073}]}, {"text": "Running GT is infeasible in our hierarchical phrase-based setup.", "labels": [], "entities": []}, {"text": "shows the results on the WMT task.", "labels": [], "entities": [{"text": "WMT task", "start_pos": 25, "end_pos": 33, "type": "TASK", "confidence": 0.5603931248188019}]}, {"text": "This is our largest setting, where max. exp.", "labels": [], "entities": []}, {"text": "BLEU training is performed on the full training data with more than 4M sentence pairs which, to the best of our knowledge, is unsurpassed in the literature.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.940205991268158}]}, {"text": "Altogether, training took more than one month, about 3/4 of which were for generating n-best lists by decoding the training data.", "labels": [], "entities": []}, {"text": "The triplet features did not finish in time, so we applied the feature sets (a), (b) and (d), 45M features in total.", "labels": [], "entities": []}, {"text": "With a renormalization step as in GT, this number would grow to 309M.", "labels": [], "entities": []}, {"text": "On newstest2013, our baseline already outperforms the best single system reported on matrix.statmt.org by 0.2 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9991924166679382}]}, {"text": "The discriminatively trained features yield an additional improvement of 0.6% BLEU absolute on this high-end system.", "labels": [], "entities": [{"text": "BLEU absolute", "start_pos": 78, "end_pos": 91, "type": "METRIC", "confidence": 0.8111876845359802}]}], "tableCaptions": [{"text": " Table 1: Statistics for the bilingual training data of the IWSLT 2013 German\u2192English, the DARPA BOLT  Chinese\u2192English and the WMT 2014 German\u2192English tasks.", "labels": [], "entities": [{"text": "IWSLT 2013 German\u2192English", "start_pos": 60, "end_pos": 85, "type": "DATASET", "confidence": 0.9204805612564086}, {"text": "DARPA", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.7802764177322388}, {"text": "BOLT", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.7944291234016418}, {"text": "WMT 2014 German\u2192English tasks", "start_pos": 127, "end_pos": 156, "type": "DATASET", "confidence": 0.8402333358923594}]}, {"text": " Table 3: Results for the BOLT Chinese\u2192English task  in BLEU [%] on the discussion forum test set (df), the  mixed web test set and NIST MT06. The baseline is our  BOLT evaluation system and contains a recurrent neural  LM. We compare with (Setiawan and Zhou, 2013) who  applied maximum expected BLEU training with growth  transformation (GT). Note that the number of features re- ported by Setiawan and Zhou (2013) is artificially blown  up due to renormalization.", "labels": [], "entities": [{"text": "BOLT Chinese\u2192English task", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7012255311012268}, {"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.929046094417572}, {"text": "discussion forum test set", "start_pos": 72, "end_pos": 97, "type": "DATASET", "confidence": 0.7826110869646072}, {"text": "mixed web test set", "start_pos": 109, "end_pos": 127, "type": "DATASET", "confidence": 0.8014937043190002}, {"text": "NIST MT06", "start_pos": 132, "end_pos": 141, "type": "DATASET", "confidence": 0.7988888621330261}]}, {"text": " Table 4: Results for the WMT German\u2192English task in  BLEU [%]. The baseline contains a recurrent neural LM.  We compare with the best single system that is reported  on matrix.statmt.org, which was submitted by the  Unversity of Edinburgh.", "labels": [], "entities": [{"text": "WMT German\u2192English task", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.8588964700698852}, {"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9972668886184692}, {"text": "Unversity of Edinburgh", "start_pos": 217, "end_pos": 239, "type": "DATASET", "confidence": 0.8586239616076151}]}]}