{"title": [{"text": "Shift-Reduce Constituency Parsing with Dynamic Programming and POS Tag Lattice", "labels": [], "entities": [{"text": "Shift-Reduce Constituency Parsing", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8400060335795084}]}], "abstractContent": [{"text": "We present the first dynamic programming (DP) algorithm for shift-reduce constituency parsing, which extends the DP idea of Huang and Sagae (2010) to context-free grammars.", "labels": [], "entities": [{"text": "shift-reduce constituency parsing", "start_pos": 60, "end_pos": 93, "type": "TASK", "confidence": 0.6493716835975647}]}, {"text": "To alleviate the propagation of errors from part-of-speech tagging, we also extend the parser to take a tag lattice instead of a fixed tag sequence.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.6798708140850067}]}, {"text": "Experiments on both English and Chinese treebanks show that our DP parser significantly improves parsing quality over non-DP baselines, and achieves the best accuracies among empirical linear-time parsers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 97, "end_pos": 104, "type": "TASK", "confidence": 0.9725556969642639}]}], "introductionContent": [{"text": "Incremental parsing has gained popularity in both dependency and constituency parsing ().", "labels": [], "entities": [{"text": "Incremental parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9056660830974579}, {"text": "constituency parsing", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.75912144780159}]}, {"text": "However, the greedy or beam search algorithms used in these parsers can only explore a tiny fraction of trees among exponentially many candidates.", "labels": [], "entities": []}, {"text": "To alleviate this problem, propose a dynamic programming (DP) algorithm, reducing the search space to a polynomial size by merging equivalent states.", "labels": [], "entities": []}, {"text": "This idea has been extended by and to other dependency parsing paradigms.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8571165800094604}]}, {"text": "In constituency parsing, however, DP has not yet been applied to incremental parsing, and the bigger search space in constituency parsing suggests a potentially even bigger advantage by DP.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8864847719669342}, {"text": "DP", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.6682872772216797}, {"text": "constituency parsing", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.7853355705738068}]}, {"text": "However, with unary rules and more-than-binary branchings, constituency parsing presents challenges not found in dependency parsing that must be addressed before applying DP.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.8884512484073639}, {"text": "dependency parsing", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7707958519458771}]}, {"text": "Thus, we first present an odd-even shift-reduce constituency parser which always finishes in same number of steps, eliminating the complicated asynchronicity issue in previous work (), and then develop dynamic programming on top of that.", "labels": [], "entities": []}, {"text": "Secondly, to alleviate the error propagation from POS tagging, we also extends the algorithm to take a tagging sausage lattice as input, which is a compromise between pipeline and joint approaches.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.6027564257383347}]}, {"text": "Our DP parser achieves state-of-the-art performances on both Chinese and English treebanks (at 90.8% on PTB and 83.9% on CTB, the latter being the highest in literature).", "labels": [], "entities": [{"text": "English treebanks", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.8352752327919006}, {"text": "PTB", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.9572696089744568}, {"text": "CTB", "start_pos": 121, "end_pos": 124, "type": "DATASET", "confidence": 0.9511003494262695}]}], "datasetContent": [{"text": "We evaluate our parsers on both Penn English Treebank (PTB) and Chinese Treebank (CTB).", "labels": [], "entities": [{"text": "Penn English Treebank (PTB)", "start_pos": 32, "end_pos": 59, "type": "DATASET", "confidence": 0.9597529967625936}, {"text": "Chinese Treebank (CTB)", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.9570169925689698}]}, {"text": "For PTB, we use sections 02-21 as the training, section 24 as the dev set, and section 23 as the test.", "labels": [], "entities": [{"text": "PTB", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.5573658347129822}]}, {"text": "For CTB, we use the version of 5.1, articles 001-270 and 440-1151 as the training data, articles 301-325 as the dev set, and articles 271-300 as the test set.", "labels": [], "entities": [{"text": "CTB", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8682546019554138}]}, {"text": "Besides training with gold POS tags, we add k-best automatic tagging results to the training set using a MaxEnt model with ten-way jackknifing).", "labels": [], "entities": []}, {"text": "And we automatically tag the dev and test sets with k-best tagging sequences us- ing the MaxEnt POS tagger (at 97.1% accuracy on English, and 94.5% on Chinese) trained on the training set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9950312376022339}]}, {"text": "We set k to 20 for English.", "labels": [], "entities": []}, {"text": "And we run two sets of experiments, 1-best vs. 20-best, for Chinese to address the tagging issue.", "labels": [], "entities": []}, {"text": "We train our parsers using \"max-violation perceptron\" ( (which has been shown to converge much faster than \"early-update\" of) with minibatch parallelization ( on the head-out binarized and unary-collapsed training set.", "labels": [], "entities": []}, {"text": "We finally debinarize the trees to recover the collapsed unary rules.", "labels": [], "entities": []}, {"text": "We evaluate parser performance with EVALB including labeled precision (LP), labeled recall (LR), and bracketing F1.", "labels": [], "entities": [{"text": "precision (LP)", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.9065050333738327}, {"text": "recall (LR)", "start_pos": 84, "end_pos": 95, "type": "METRIC", "confidence": 0.9513358920812607}, {"text": "F1", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.6571825742721558}]}, {"text": "We use abeam size of 32, and pick the optimal iteration number based on the performances on the dev set.", "labels": [], "entities": []}, {"text": "Our baseline is the shift-reduce parser without state recombination (henceforth \"non-DP\"), and our dynamic programming parser (henceforth \"DP\") is the extension of the baseline.", "labels": [], "entities": []}, {"text": "shows the learning curves on the PTB dev set.", "labels": [], "entities": [{"text": "PTB dev set", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9430054426193237}]}, {"text": "With a same beam width, DP parser achieves a better performance (89.8%, peaking at the 11th iteration) and converges faster than non-DP.", "labels": [], "entities": [{"text": "DP parser", "start_pos": 24, "end_pos": 33, "type": "TASK", "confidence": 0.6045465916395187}]}, {"text": "Picking the optimal iterations for DP and non-DP models, we test each with various beam size, and plot the F1 curves in.", "labels": [], "entities": [{"text": "F1", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9920048117637634}]}, {"text": "Again, DP is always better than non-DP, with 0.5% difference at beam of 64.", "labels": [], "entities": [{"text": "DP", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.9968656897544861}]}, {"text": "shows the final results on the PTB test set.", "labels": [], "entities": [{"text": "PTB test set", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.958080530166626}]}, {"text": "The last column shows the empirical time complexity.", "labels": [], "entities": []}, {"text": "Our baseline parser achieves a competitive score, which is higher than Berkeley even with a linear time complexity, and is comparable to.", "labels": [], "entities": []}, {"text": "Our DP parser improves the F1 score by 0.5 points over the non-DP, and achieves the best F1 score among empirical linear-time parsers.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9867000877857208}, {"text": "F1 score", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9838550984859467}]}], "tableCaptions": [{"text": " Table 1: All feature templates (43 templates based on 32 atomic features), taken from Zhu et al. (2013). s i .c, s i .w and  s i .t denote the syntactic label, the head word, and the head tag of s i . s i .lc.w means the head word of the left child of  s i . s i .u.w means the head word of the unary root s i . q i .w and q i .t denote the word and the tag of q i .", "labels": [], "entities": []}, {"text": " Table 2: Final Results on English (PTB) test set (sec23).   \u2020The empirical complexities for Charniak and Petrov are  O(n 2.5 ) and O(n 2.4 ), resp.,  \u2021but Carreras is exact O(n 4 ).", "labels": [], "entities": [{"text": "English (PTB) test set", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.799941728512446}, {"text": "O", "start_pos": 118, "end_pos": 119, "type": "METRIC", "confidence": 0.9891480803489685}, {"text": "O", "start_pos": 132, "end_pos": 133, "type": "METRIC", "confidence": 0.9699144959449768}]}, {"text": " Table 3: Results on Chinese (CTB) 5.1 test set.", "labels": [], "entities": [{"text": "Chinese (CTB) 5.1 test set", "start_pos": 21, "end_pos": 47, "type": "DATASET", "confidence": 0.922019498688834}]}]}