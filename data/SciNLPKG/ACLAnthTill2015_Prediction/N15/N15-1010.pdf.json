{"title": [{"text": "Not All Character N -grams Are Created Equal: A Study in Authorship Attribution", "labels": [], "entities": [{"text": "Authorship Attribution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.67989382147789}]}], "abstractContent": [{"text": "Character n-grams have been identified as the most successful feature in both single-domain and cross-domain Authorship Attribu-tion (AA), but the reasons for their discrimina-tive value were not fully understood.", "labels": [], "entities": [{"text": "Authorship Attribu-tion (AA)", "start_pos": 109, "end_pos": 137, "type": "TASK", "confidence": 0.5018004477024078}]}, {"text": "We identify subgroups of character n-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morpho-syntax, thematic content and style.", "labels": [], "entities": []}, {"text": "We evaluate the predictiveness of each of these groups in two AA settings: a single domain setting and a cross-domain setting where multiple topics are present.", "labels": [], "entities": []}, {"text": "We demonstrate that character n-grams that capture information about affixes and punctuation account for almost all of the power of character n-grams as features.", "labels": [], "entities": []}, {"text": "Our study contributes new insights into the use of n-grams for future AA work and other classification tasks.", "labels": [], "entities": [{"text": "AA work", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.9340838491916656}]}], "introductionContent": [{"text": "Authorship Attribution (AA) tackles the problem of determining who, among a set of authors, wrote the document at hand.", "labels": [], "entities": [{"text": "Authorship Attribution (AA)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8412056565284729}]}, {"text": "AA has relevant applications ranging from plagiarism detection to Forensic Linguistics, such as identifying authorship of threatening emails or malicious code.", "labels": [], "entities": [{"text": "AA", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9026846885681152}, {"text": "plagiarism detection", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7988543212413788}, {"text": "Forensic Linguistics", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.8434818089008331}, {"text": "identifying authorship of threatening emails", "start_pos": 96, "end_pos": 140, "type": "TASK", "confidence": 0.8486329793930054}]}, {"text": "Applied areas such as law and journalism can also benefit from authorship attribution, where identifying the true author of apiece of text (such as a ransom note) may help save lives or catch the offenders.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.687319740653038}, {"text": "identifying the true author of apiece of text (such as a ransom note)", "start_pos": 93, "end_pos": 162, "type": "TASK", "confidence": 0.6601770559946696}]}, {"text": "We know from state of the art research in AA that the length of the documents and the number of potential candidate authors have an important effect on the accuracy of AA approaches.", "labels": [], "entities": [{"text": "AA", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.9674807786941528}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9984378218650818}]}, {"text": "We can also point out the most common features that have been used successfully in AA work, including: bag-of-words (), stylistic features (;), and word and character level n-grams ().", "labels": [], "entities": [{"text": "AA work", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.9268584549427032}]}, {"text": "The utility of bag-of-words features is well understood: they effectively capture correlations between authors and topics ().", "labels": [], "entities": []}, {"text": "The discriminative value of these features is thus directly related to the level of content divergence among authors and among train and test sets.", "labels": [], "entities": []}, {"text": "The utility of stylistic features is also well understood: they model author preferences for the use of punctuation marks, emoticons, white spaces, and other traces of writing style.", "labels": [], "entities": []}, {"text": "Such preferences are less influenced by topic, and directly reflect some of the unique writing patterns of an author.", "labels": [], "entities": []}, {"text": "Character n-grams are the single most successful feature in authorship attribution (), but the reason for their success is not well understood.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.8808980584144592}]}, {"text": "One hypothesis is that character n-grams carry a little bit of everything: lexical content, syntactic content, and even style by means of punctuation and white spaces).", "labels": [], "entities": []}, {"text": "While this argument seems plausible, it falls short of a rigorous explanation.", "labels": [], "entities": []}, {"text": "In this paper, we investigate what in the make-up of these small units of text makes them so powerful.", "labels": [], "entities": []}, {"text": "Our goal is two-fold: on the one hand we want to have a principled understanding of character ngrams that will inform their use as features for AA and other tasks; on the other hand we want to make AA approaches more accessible to non-experts so that, for example, they could be acceptable pieces of evidence in criminal cases.", "labels": [], "entities": [{"text": "AA", "start_pos": 144, "end_pos": 146, "type": "TASK", "confidence": 0.9856223464012146}]}, {"text": "The research questions we aim to answer are: \u2022 Are all character n-grams equally important?", "labels": [], "entities": []}, {"text": "For example, are the prefix of 'there', the suffix of 'breathe' and the whole word 'the' all equivalent?", "labels": [], "entities": []}, {"text": "More generally, are character n-grams that capture morpho-syntactic information, thematic information and style information equally important?", "labels": [], "entities": []}, {"text": "\u2022 Are the character n-grams that are most important for single-domain settings also the most important for cross-domain settings?", "labels": [], "entities": []}, {"text": "Which character n-grams are more like bag-of-words features (which tend to track topics), and which are more like stylistic features (which tend to track authors)?", "labels": [], "entities": []}, {"text": "\u2022 Do different classifiers agree on the importance of the different types of character n-grams?", "labels": [], "entities": []}, {"text": "Are some character n-grams consistently the best regardless of the learning algorithm?", "labels": [], "entities": []}, {"text": "\u2022 Are some types of character n-grams irrelevant in AA tasks?", "labels": [], "entities": [{"text": "AA tasks", "start_pos": 52, "end_pos": 60, "type": "TASK", "confidence": 0.9369871020317078}]}, {"text": "Are there categories of character n-grams that we can exclude and get similar (or better) performance than using all n-grams?", "labels": [], "entities": []}, {"text": "If there are, are they the same for both singledomain and cross-domain AA settings?", "labels": [], "entities": []}, {"text": "Our study shows that using the default bag-ofwords representation of char n-grams results in collapsing sequences of characters that correspond to different linguistic aspects, and that this yields suboptimal prediction performance.", "labels": [], "entities": []}, {"text": "We further show that we can boost accuracy by loosing some categories of n-grams.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9992726445198059}]}, {"text": "Char n-grams closely related to thematic content can be completely removed without loss of accuracy, even in cases where the train and test sets have the same topics represented, a counter-intuitive argument.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9969761371612549}]}, {"text": "Given the widespread use of char n-grams in text classification tasks, our findings have significant implications for future work in related areas.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.8636552492777506}]}], "datasetContent": [{"text": "We consider two corpora, a single-domain corpus, where there is only one topic that all authors are writing about, and a multi-domain corpus, where there are multiple different topics.", "labels": [], "entities": []}, {"text": "The latter allows us to test the generalization of AA models, by testing them on a different topic from that used for training.", "labels": [], "entities": [{"text": "AA", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.7123755216598511}]}, {"text": "The first collection is the CCAT topic class, a subset of the Reuters Corpus Volume 1 (.", "labels": [], "entities": [{"text": "Reuters Corpus Volume 1", "start_pos": 62, "end_pos": 85, "type": "DATASET", "confidence": 0.9608863741159439}]}, {"text": "Although this collection was not gathered for the goal of doing authorship attribution studies, previous work has reported results for AA with 10 and 50 authors).", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.8082996010780334}, {"text": "AA", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.5702310800552368}]}, {"text": "We refer to these as CCAT 10 and CCAT 50, respectively.", "labels": [], "entities": []}, {"text": "Both CCAT 10 and CCAT 50 belong to CCAT category (about corporate/industrial news) and are balanced across authors, with 100 documents sampled for each author.", "labels": [], "entities": []}, {"text": "Manual inspection of the dataset revealed that some of the authors in this collection consistently used signatures at the end of documents.", "labels": [], "entities": []}, {"text": "Also, we noticed some writers use quotations a lot.", "labels": [], "entities": []}, {"text": "This dataset contains opinion articles on the topics: World, U.K., Society, and Politics.", "labels": [], "entities": []}, {"text": "Following prior work, to make the collection balanced across authors, we choose at most ten documents per author for each of the four topics.", "labels": [], "entities": []}, {"text": "We refer to this corpus as Guardian1.", "labels": [], "entities": []}, {"text": "We also consider a variation of this corpus that makes it more challenging but that more closely matches realistic scenarios of forensic investigation that deal with short texts such as tweets, SMS, and emails.", "labels": [], "entities": []}, {"text": "We chunk each of the documents by sentence boundaries into five new short documents.", "labels": [], "entities": []}, {"text": "We refer to this corpus as Guardian2.", "labels": [], "entities": []}, {"text": "shows some of the statistics of the CCAT and Guardian corpora and presents some of the top character n-grams for each category (taken from an author in the Guardian data, but the top ngrams look qualitatively similar for other authors).", "labels": [], "entities": [{"text": "CCAT", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.9475264549255371}, {"text": "Guardian corpora", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.8733876347541809}, {"text": "Guardian data", "start_pos": 156, "end_pos": 169, "type": "DATASET", "confidence": 0.9014372825622559}]}, {"text": "We performed various experiments using different categories of character n-grams.", "labels": [], "entities": []}, {"text": "We chose n=3 since our preliminary experiments found character 3-grams to be more effective than other higher level character n-grams.", "labels": [], "entities": []}, {"text": "For each category, we considered only those 3-grams that occur at least five times in the training documents.", "labels": [], "entities": []}, {"text": "The performance of different authorship attribu-  tion models was measured in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9986646175384521}]}, {"text": "In the single-domain CCAT experiments, accuracy was measured using the train/test partition of prior work.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9993141889572144}]}, {"text": "In the cross-domain Guardian experiments, accuracy was measured by considering all 12 possible pairings of the 4 topics, treating one topic as training data and the other as testing data, and averaging accuracy over these 12 scenarios.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9992569088935852}, {"text": "accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.9989597797393799}]}, {"text": "This ensured that in the crossdomain experiments, the topics of the training data were always different from that of the test data.", "labels": [], "entities": []}, {"text": "We trained support vector machine (SVM) classifiers using the Weka implementation) with default parameters.", "labels": [], "entities": []}, {"text": "We also ran some comparative experiments with the Weka implementation of naive Bayes classifiers and the Lib-SVM implementation of SVMs.", "labels": [], "entities": []}, {"text": "In the results below, when performance of a single classifier is presented, it is the result of Weka's SVM, which generally gave the best performance.", "labels": [], "entities": []}, {"text": "When performance of other classifiers are presented, the classifiers are explicitly indicated.", "labels": [], "entities": []}, {"text": "In this section, we present various results on authorship attribution tasks using both single as well as cross-domain datasets.", "labels": [], "entities": [{"text": "authorship attribution tasks", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.8861782948176066}]}, {"text": "We will explore character ngrams in depth and try to understand why they are so effective in discriminating authors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Some statistics about the datasets.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy of AA classifiers trained on each of the character n-gram categories. The top four accuracies for  each dataset are in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9945991039276123}]}, {"text": " Table 6: Spearman's rank correlation coefficient (\u03c1) for  each pair of classifiers on the single-domain (CCAT) and  cross-domain (Guardian) settings.", "labels": [], "entities": [{"text": "rank correlation coefficient (\u03c1)", "start_pos": 21, "end_pos": 53, "type": "METRIC", "confidence": 0.8904145260651907}]}, {"text": " Table 7: Results of excluding word n-grams, compared  to using all n-grams, either in the traditional approach  (untyped n-grams) or in the approach of this paper (typed  n-grams). Accuracy (Acc) and the number of features  (N in italics) are reported for each classifier. The best  accuracy for each dataset is in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9990035891532898}, {"text": "Acc)", "start_pos": 192, "end_pos": 196, "type": "METRIC", "confidence": 0.8840271532535553}, {"text": "accuracy", "start_pos": 284, "end_pos": 292, "type": "METRIC", "confidence": 0.999207079410553}]}]}