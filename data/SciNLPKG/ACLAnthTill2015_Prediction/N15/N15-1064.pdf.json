{"title": [{"text": "Jointly Modeling Inter-Slot Relations by Random Walk on Knowledge Graphs for Unsupervised Spoken Language Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "A key challenge of designing coherent semantic ontology for spoken language understanding is to consider inter-slot relations.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.6485839982827505}]}, {"text": "In practice , however, it is difficult for domain experts and professional annotators to define a coherent slot set, while considering various lexical , syntactic, and semantic dependencies.", "labels": [], "entities": []}, {"text": "In this paper, we exploit the typed syntactic dependency theory for unsupervised induction and filling of semantics slots in spoken dialogue systems.", "labels": [], "entities": []}, {"text": "More specifically, we build two knowledge graphs: a slot-based semantic graph, and a word-based lexical graph.", "labels": [], "entities": []}, {"text": "To jointly consider word-to-word, word-to-slot, and slot-to-slot relations, we use a random walk inference algorithm to combine the two knowledge graphs, guided by dependency grammars.", "labels": [], "entities": []}, {"text": "The experiments show that considering inter-slot relations is crucial for generating a more coherent and compete slot set, resulting in a better spoken language understanding model, while enhancing the inter-pretability of semantic slots.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 145, "end_pos": 174, "type": "TASK", "confidence": 0.7229693531990051}]}], "introductionContent": [{"text": "An important requirement for building a successful spoken dialogue system (SDS) is to define a coherent slot set and the corresponding slot-fillers for the spoken language understanding (SLU) component.", "labels": [], "entities": [{"text": "spoken dialogue system (SDS)", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.6545162151257197}, {"text": "spoken language understanding (SLU)", "start_pos": 156, "end_pos": 191, "type": "TASK", "confidence": 0.7967758079369863}]}, {"text": "Unfortunately, since the semantic slots are often mutually-related, it is non-trivial for domain experts and professional annotators to design a such slot set for semantic representation of SLU.", "labels": [], "entities": []}, {"text": "Considering a restaurant domain), \"restaurant\" is the target slot, and important adjective modifiers such as \"Asian\" (the restaurant type) and \"cheap\" (the price of the restaurant) should be included in the slot set, so that the semantic representation of SLU can be more coherent and complete.", "labels": [], "entities": []}, {"text": "In this case, it is challenging to design such a coherent and complete slot set manually, while considering various lexical, syntactic, and semantic dependencies.", "labels": [], "entities": []}, {"text": "Instead of considering slots independently, this paper takes a data-driven approach to model wordto-word relations via syntactic dependencies and further infer slot-to-slot relations.", "labels": [], "entities": []}, {"text": "To do this, we incorporate the typed dependency grammar theory) in a stateof-the-art frame-semantic driven unsupervised slot induction framework ).", "labels": [], "entities": []}, {"text": "In particular, we build two knowledge graphs: a slotbased semantic knowledge graph, and a word-based lexical knowledge graph.", "labels": [], "entities": []}, {"text": "Using typed dependency triples, we then study the stochastic relations between slots and words, using a mutually-reinforced random walk inference procedure to combine the two knowledge graphs.", "labels": [], "entities": []}, {"text": "In evaluations, we use the jointly learned inter-slot relations to induce a coherent slot set in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "Our contributions are three-fold: \u2022 We are among the first to consider unsupervised spoken language understanding combining semantic and lexical knowledge graphs; \u2022 We propose a novel typed syntactic dependency grammar driven random walk model for relation discovery; \u2022 Our experimental results suggest that jointly considering inter-slot relations helps obtain a more coherent and complete semantic slot set.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 248, "end_pos": 266, "type": "TASK", "confidence": 0.8853580951690674}]}], "datasetContent": [{"text": "We evaluate our approach in two ways.", "labels": [], "entities": []}, {"text": "First, we examine the slot induction accuracy by comparing the ranked list of induced slots with the reference slots created by system developers.", "labels": [], "entities": [{"text": "slot induction", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7967849969863892}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.935283362865448}]}, {"text": "Secondly, with the ranked list of induced slots and their associated semantic decoders, we can evaluate the SLU performance.", "labels": [], "entities": []}, {"text": "For the experiments, we evaluate both on ASR transcripts of the raw audio, and on the manual transcripts.", "labels": [], "entities": [{"text": "ASR", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.870173990726471}]}, {"text": "In this experiment, we used the Cambridge University SLU corpus, previously used on several other SLU tasks ().", "labels": [], "entities": [{"text": "Cambridge University SLU corpus", "start_pos": 32, "end_pos": 63, "type": "DATASET", "confidence": 0.9600711464881897}]}, {"text": "The domain of the corpus is about restaurant recommendation in Cambridge; subjects were asked to interact with multiple SDSs in an in-car setting.", "labels": [], "entities": [{"text": "restaurant recommendation in Cambridge", "start_pos": 34, "end_pos": 72, "type": "TASK", "confidence": 0.7157479524612427}]}, {"text": "The corpus contains a total number of 2,166 dialogues, including 15,453 utterances (10,571 for selftraining and 4,882 for testing).", "labels": [], "entities": []}, {"text": "The data is genderbalanced, with slightly more native than non-native speakers.", "labels": [], "entities": []}, {"text": "The vocabulary size is 1868.", "labels": [], "entities": []}, {"text": "An ASR system was used to transcribe the speech; the word error rate was reported as 37%.", "labels": [], "entities": [{"text": "ASR", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.7093944549560547}, {"text": "word error rate", "start_pos": 53, "end_pos": 68, "type": "METRIC", "confidence": 0.8244756460189819}]}, {"text": "There are 10 slots created by domain experts: addr, area, food, name, phone, postcode, price range, signature, task, and type.", "labels": [], "entities": []}, {"text": "For parameter setting, the damping factor for random walk \u03b1 is empirically set as 0.9 for all experiments.", "labels": [], "entities": []}, {"text": "For training the semantic decoders, we use SVM with a linear kernel to predict each semantic slot.", "labels": [], "entities": []}, {"text": "We use Stanford Parser to obtain the collapsed typed syntactic dependencies and set the dimensionality of embeddings d = 300 in all experiments.", "labels": [], "entities": []}, {"text": "To eliminate the influence of threshold selection when choosing induced slots, in the following metrics, we take the whole ranking list into account and evaluate the performance by the metrics that are independent of the selected threshold.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The performance of induced slots and corresponding SLU models (%)", "labels": [], "entities": []}, {"text": " Table 3: The top inter-slot relations learned from the  training set of ASR outputs.", "labels": [], "entities": [{"text": "ASR outputs", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.8561652600765228}]}]}