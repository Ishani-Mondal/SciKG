{"title": [{"text": "Aligning Sentences from Standard Wikipedia to Simple Wikipedia", "labels": [], "entities": [{"text": "Aligning Sentences from Standard Wikipedia", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7536504626274109}]}], "abstractContent": [{"text": "This work improves monolingual sentence alignment for text simplification, specifically for text in standard and simple Wikipedia.", "labels": [], "entities": [{"text": "monolingual sentence alignment", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.6361429989337921}, {"text": "text simplification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7434903085231781}]}, {"text": "We introduce a method that improves over past efforts by using a greedy (vs. ordered) search over the document and a word-level semantic similarity score based on Wiktionary (vs. WordNet) that also accounts for structural similarity through syntactic dependencies.", "labels": [], "entities": []}, {"text": "Experiments show improved performance on a hand-aligned set, with the largest gain coming from structural similarity.", "labels": [], "entities": []}, {"text": "Resulting datasets of manually and automatically aligned sentence pairs are made available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text simplification can improve accessibility of texts for both human readers and automatic text processing.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.793806403875351}, {"text": "text processing", "start_pos": 92, "end_pos": 107, "type": "TASK", "confidence": 0.6743035614490509}]}, {"text": "Although simplification could benefit from data-driven machine translation, paraphrasing, or grounded language acquisition techniques, e.g.), work has been limited because available parallel corpora are small or automatically generated are noisy.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7582699656486511}]}, {"text": "Wikipedia is potentially a good resource for text simplification, since it includes standard articles and their corresponding simple articles in English.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8792155385017395}, {"text": "text simplification", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7905562520027161}]}, {"text": "A challenge with automatic alignment is that standard and simple articles can be written independently so they are not strictly parallel, and have very different presentation ordering.", "labels": [], "entities": [{"text": "automatic alignment", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.6094549596309662}]}, {"text": "A few studies use editor comments attached to Wikipedia edit logs to extract pairs of simple and difficult words).", "labels": [], "entities": []}, {"text": "Other methods use text-based similarity techniques (, but assume sentences in standard and simple articles are ordered relatively.", "labels": [], "entities": []}, {"text": "In this paper, we align sentences in standard and simple Wikipedia using a greedy method that, for every simple sentence, finds the corresponding sentence (or sentence fragment) in standard Wikipedia.", "labels": [], "entities": []}, {"text": "Unlike other methods, we do not make any assumptions about the relative order of sentences in standard and simple Wikipedia articles.", "labels": [], "entities": []}, {"text": "We also constrain the many-to-one matches to cover sentence fragments.", "labels": [], "entities": []}, {"text": "In addition, our method takes advantage of a novel word-level semantic similarity measure that is built on top of Wiktionary (vs. WordNet) which incorporates structural similarity represented in syntactic dependencies.", "labels": [], "entities": []}, {"text": "The Wiktionary-based similarity measure has the advantage of greater word coverage than WordNet, while the use of syntactic dependencies provides a simple mechanism for approximating semantic roles.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.943473219871521}]}, {"text": "Here, we report the first manually annotated dataset for evaluating alignments for text simplification, develop and assess a series of alignment methods, and automatically generate a dataset of sentence pairs for standard and simple Wikipedia.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7777211368083954}]}, {"text": "Experiments show that our alignment method significantly outperforms previous methods on the hand-aligned Good Apple sauce or applesauce is a puree made of apples.", "labels": [], "entities": [{"text": "Good Apple sauce", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.9538059234619141}]}, {"text": "Applesauce (or applesauce) is a sauce that is made from stewed or mashed apples.", "labels": [], "entities": []}, {"text": "Good Partial Commercial versions of applesauce are really available in supermarkets It is easy to make at home, and it is also sold already made in supermarkets as a common food.", "labels": [], "entities": []}], "datasetContent": [{"text": "We develop datasets of aligned sentences in standard and simple Wikipedia.", "labels": [], "entities": []}, {"text": "Here, we describe the manually annotated dataset and leave the details of the automatically generated dataset to Section 5.2.", "labels": [], "entities": [{"text": "Section 5.2", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.9144945740699768}]}, {"text": "Manually Annotated: For every sentence in a standard Wikipedia article, we create an HTML survey that lists sentences in the corresponding simple article and allow the annotator to judge each sentence pair as a good, good partial, partial, or bad match (examples in): Good: The semantics of the simple and standard sentence completely match, possibly with small omissions (e.g., pronouns, dates, or numbers).", "labels": [], "entities": []}, {"text": "Good Partial: A sentence completely covers the other sentence, but contains an additional clause or phrase that has information which is not contained within the other sentence.", "labels": [], "entities": []}, {"text": "Partial: The sentences discuss unrelated concepts, but share a short related phrase that does not match considerably.", "labels": [], "entities": []}, {"text": "Bad: The sentences discuss unrelated concepts.", "labels": [], "entities": []}, {"text": "The annotators were native speaker, hourly paid, undergraduate students.", "labels": [], "entities": []}, {"text": "We randomly selected 46 article pairs from Wikipedia (downloaded in June 2012) that started with the character 'a'.", "labels": [], "entities": []}, {"text": "In total, 67,853 sentence pairs were annotated (277 good, 281 good partial, 117 partial, and 67,178 bad).", "labels": [], "entities": []}, {"text": "The kappa value for interannotator agreement is 0.68 (13% of articles were dual annotated).", "labels": [], "entities": []}, {"text": "Most disagreements between annotators are confusions between 'partial' and 'good partial' matches.", "labels": [], "entities": []}, {"text": "The manually annotated dataset is used as a test set for evaluating alignment methods as well as tuning parameters for generating automatically aligned pairs across standard and simple Wikipedia.", "labels": [], "entities": []}, {"text": "We test our method on all pairs of standard and simple sentences for each article in the hand-annotated data (no training data is used).", "labels": [], "entities": []}, {"text": "For our experiments, we preprocess the data by removing topic names, list markers, and non-English words.", "labels": [], "entities": []}, {"text": "In addition, the data was tokenized, lemmatized, and parsed using Stanford CoreNLP).", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.9534209668636322}]}], "tableCaptions": [{"text": " Table 2: Max F1, AUC for identifying good matches and  identifying good & good partial matches.", "labels": [], "entities": [{"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.5267912745475769}, {"text": "AUC", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9291221499443054}]}, {"text": " Table 3: Qualitative examples of the good and good partial matches identified by our method.", "labels": [], "entities": []}, {"text": " Table 4: Max F1, AUC for ablation study on word-level  and sequence-level similarity scores. Values with the +  superscript are significant with p<0.05.", "labels": [], "entities": [{"text": "Max F1", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.658564567565918}, {"text": "AUC", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.8599574565887451}, {"text": "sequence-level similarity scores", "start_pos": 60, "end_pos": 92, "type": "METRIC", "confidence": 0.8474077781041464}]}]}