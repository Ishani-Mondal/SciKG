{"title": [{"text": "Towards a Better Semantic Role Labeling of Complex Predicates", "labels": [], "entities": [{"text": "Semantic Role Labeling of Complex Predicates", "start_pos": 17, "end_pos": 61, "type": "TASK", "confidence": 0.7714733829100927}]}], "abstractContent": [{"text": "We propose away to automatically improve the annotation of verbal complex predicates in PropBank which until now has been treating language mostly in a compositional manner.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.9516085982322693}]}, {"text": "In order to minimize the manual re-annotation effort, we build on the recently introduced concept of aliasing complex predicates to existing PropBank rolesets which encompass the same meaning and argument structure.", "labels": [], "entities": []}, {"text": "We suggest to find aliases automatically by applying a multilingual distributional model that uses the translations of simple and complex predicates as features.", "labels": [], "entities": []}, {"text": "Furthermore, we setup an annotation effort to obtain a frequency balanced, realistic test set for this task.", "labels": [], "entities": []}, {"text": "Our method reaches an accuracy of 44% on this test set and 72% for the more frequent test items in a lenient evaluation, which is not far from the upper bounds from human annotation .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9995315074920654}]}], "introductionContent": [{"text": "Semantic Role Labeling (SRL) aims at determining 'who' did 'what' to 'whom' in sentences by identifying and associating predicates with their semantic arguments.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8476732273896536}]}, {"text": "This information is useful for many downstream applications, for example for question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.9553598463535309}]}, {"text": "The PropBank corpus (PB) () is one of the most widely used resources for training SRL systems.", "labels": [], "entities": [{"text": "PropBank corpus (PB)", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.9102253556251526}, {"text": "SRL", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.8317588567733765}]}, {"text": "It provides senses of (mostly verbal) predicates with their typical semantic arguments annotated in a corpus and accompanied by a lexical resource.", "labels": [], "entities": []}, {"text": "The sense of a predicate is referred to as a 'roleset' because it lists all required and possible semantic roles for the predicate used in a specific sense.", "labels": [], "entities": []}, {"text": "The 12K rolesets in PB describe mostly single word predicates, to a great part leaving aside multiword expressions (MWEs).", "labels": [], "entities": []}, {"text": "Complex predicates (CPs), 'predicates which are multi-headed: they are composed of more than one grammatical element', are most relevant in the context of SRL.", "labels": [], "entities": [{"text": "Complex predicates (CPs)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7196116983890534}, {"text": "SRL", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9782774448394775}]}, {"text": "Light verb constructions (LVCs), e.g. take care, and verb particle constructions (VPCs), e.g. watch out, are the most frequently occurring types of CPs.", "labels": [], "entities": []}, {"text": "As stated 'PB has previously treated language as if it were purely compositional, and has therefore lumped the majority of MWEs in with lexical verb usages'.", "labels": [], "entities": []}, {"text": "For example the predicates in the CPs take a hard line, take time and many others are all annotated with a sense of take, meaning acquire, come to have, chose, bring with you from somewhere.", "labels": [], "entities": []}, {"text": "This results in a loss of semantic information in the PB annotations.", "labels": [], "entities": []}, {"text": "This is especially critical because CPs area frequent phenomenon.", "labels": [], "entities": [{"text": "CPs", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.969772219657898}]}, {"text": "The Wiki50 corpus, which provides a full coverage MWE annotation, counts 814 occurrences of LVCs and VPCs in 4350 sentences.", "labels": [], "entities": [{"text": "Wiki50 corpus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9521033763885498}]}, {"text": "This makes for one CP in every fifth sentence.", "labels": [], "entities": [{"text": "CP", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9847698211669922}]}, {"text": "Recently, have introduced an approach to improve the handling of MWEs in PB while keeping annotation costs low.", "labels": [], "entities": [{"text": "handling of MWEs in PB", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.5247551620006561}]}, {"text": "The process is called aliasing.", "labels": [], "entities": []}, {"text": "Instead of creating new frames for CPs, human annotators map them to existing PB rolesets which encompass the same semantic and argument structure.", "labels": [], "entities": []}, {"text": "For example, the CP give (a) talk could be mapped to the alias lecture.01.", "labels": [], "entities": []}, {"text": "While this method significantly reduces the effort to create new rolesets, the time consuming manual mapping is still required.", "labels": [], "entities": []}, {"text": "To address this problem, our work extends this approach by proposing a method to find the aliases automatically.", "labels": [], "entities": []}, {"text": "One way to find the most suitable alias roleset fora given CP is to group predicates by their rolesets assigned by an automatic SRL system and compute the most similar roleset group by searching for (near-) synonymous predicates of the CP.", "labels": [], "entities": []}, {"text": "The roleset of the most similar roleset group is selected as alias for the CP.", "labels": [], "entities": []}, {"text": "Finding synonyms, both single-word and multiword, from corpora has been done successfully with the multilingual variant of the distributional hypothesis (Van der Plas and Tiedemann, 2006; Van der Plas et al., 2011).", "labels": [], "entities": []}, {"text": "The idea behind this approach is that words or MWEs that share many translations are probably synonymous.", "labels": [], "entities": []}, {"text": "We use the word alignments in a parallel corpus to find the translations of CPs and single predicates.", "labels": [], "entities": []}, {"text": "The predicates are automatically annotated with rolesets by an SRL system.", "labels": [], "entities": []}, {"text": "This allows us to compute the most suitable roleset fora given CP fully automatically.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: To the best of our knowledge, this work is the first to address the handling of CPs for SRL in an automatic way.", "labels": [], "entities": [{"text": "SRL", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.8271085619926453}]}, {"text": "We are thus able to scale up previous work that relies on manual intervention.", "labels": [], "entities": []}, {"text": "In addition, we setup an annotation effort to gather a frequency-balanced, data-driven evaluation set that is larger and more diverse than the annotated set provided by.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our system, we setup an annotation effort loosely following the guidelines provided by.", "labels": [], "entities": []}, {"text": "We selected 50 LVCs and 50 VPCs from the Wiki50 corpus (Vincze et al., 2011) divided equally over two frequency groups: Half of the expressions occur only once in the Wiki50 corpus (low-frequency subgroup) and the other half occur at least twice (high-frequency subgroup).", "labels": [], "entities": [{"text": "Wiki50 corpus", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9440259337425232}, {"text": "Wiki50 corpus", "start_pos": 167, "end_pos": 180, "type": "DATASET", "confidence": 0.9365867078304291}]}, {"text": "All occurrences of these 100 CP types in the corpus were selected to account for the polysemy of CPs.", "labels": [], "entities": []}, {"text": "Different instances of the same CP could get assigned to different aliases.", "labels": [], "entities": []}, {"text": "This resulted in a total of 197 annotated instances.", "labels": [], "entities": []}, {"text": "Four annotators were presented with the CP in their original sentence context and were asked to propose one or several PB aliases which encompass the same meaning and argument structure.", "labels": [], "entities": []}, {"text": "One annotator (A, one of the authors of this article) labeled the whole set of 100 expressions.", "labels": [], "entities": []}, {"text": "The three other annotators (B,C,D) each labeled one third of the expressions assigned randomly, so that every expression was annotated by two annotators.", "labels": [], "entities": []}, {"text": "First, they were asked to decide if there is already an appropriate PB roleset for the CP and then provide it.", "labels": [], "entities": []}, {"text": "The annotators were requested to divide these cases into semantically compositional CPs (e.g. obtain permission with the roleset obtain.01) and uncompositional CPs for which PB already provides a multi-word predicate (e.g. open.03 for open up).", "labels": [], "entities": []}, {"text": "For the remaining CPs, they were asked to suggest PB rolesets (aliases) that share the same semantics and argument structure as the CP.", "labels": [], "entities": []}, {"text": "The simple inter-annotator agreement 5 was 67% for annotator A%B, 51% for A&C and 44% for A&D.", "labels": [], "entities": [{"text": "A&C", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.83257524172465}, {"text": "A&D", "start_pos": 90, "end_pos": 93, "type": "DATASET", "confidence": 0.9067616860071818}]}, {"text": "These agreement figures are higher than the figures in, and actual agreement is probably even higher, because synonymous rolesets are regarded as disagreements.", "labels": [], "entities": []}, {"text": "Annotator A discussed the annotations with the other annotators and they were able to reach a consensus that resulted in a final agreed-upon test set.", "labels": [], "entities": []}, {"text": "shows the final decisions with respect to the complete set of 197 expressions.", "labels": [], "entities": []}, {"text": "In line with the results from who aliased 100 out of 138 uncompositional take MWEs, we were also able to alias most of the CPs in our annotation set.", "labels": [], "entities": []}, {"text": "The final Wiki50 set consists of 154 7 instances of", "labels": [], "entities": [{"text": "Wiki50 set", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.8581782579421997}]}], "tableCaptions": [{"text": " Table 1: Final decisions on the 197 annotated expressions", "labels": [], "entities": []}]}