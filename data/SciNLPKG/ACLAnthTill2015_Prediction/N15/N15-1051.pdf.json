{"title": [{"text": "Corpus-based discovery of semantic intensity scales", "labels": [], "entities": [{"text": "Corpus-based discovery of semantic intensity", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6164519309997558}]}], "abstractContent": [{"text": "Gradable terms such as brief, lengthy and extended illustrate varying degrees of a scale and can therefore participate in comparative constructs.", "labels": [], "entities": []}, {"text": "Knowing the set of words that can be compared on the same scale and the associated ordering between them (brief < lengthy < extended) is very useful fora variety of lexical semantic tasks.", "labels": [], "entities": []}, {"text": "Current techniques to derive such an ordering rely on WordNet to determine which words belong on the same scale and are limited to adjectives.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.974310040473938}]}, {"text": "Here we describe an extension to recent work: we investigate a fully automated pipeline to extract gradable terms from a corpus, group them into clusters reflecting the same scale and establish an ordering among them.", "labels": [], "entities": []}, {"text": "This methodology reduces the amount of required handcrafted knowledge, and can infer gradability of words independent of their part of speech.", "labels": [], "entities": []}, {"text": "Our approach infers an ordering for adjectives with comparable performance to previous work, but also for adverbs with an accuracy of 71%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9991821646690369}]}, {"text": "We find that the technique is useful for inferring such rankings among words across different domains, and present an example using biomedical text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Gradability) is a property of words that identifies different degrees of the quality the word denotes.", "labels": [], "entities": [{"text": "Gradability", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9442639946937561}]}, {"text": "For example, adjectives such as large, huge and gigantic present different degrees of size or volume.", "labels": [], "entities": []}, {"text": "Similarly, adverbs such as approximately, almost and roughly present different degrees of how accurate a measurement is.", "labels": [], "entities": []}, {"text": "Thus, one of the characteristics of gradable terms is that they participate in a scale and can be ordered along that scale: for example, good < great < excellent.", "labels": [], "entities": []}, {"text": "Another characteristic is that gradable terms can appear in comparative constructions, e.g., \"A is larger than B\".", "labels": [], "entities": []}, {"text": "Such comparative judgments area psychological process that precedes judgments of counting, e.g., \"A is twice as large as B\".", "labels": [], "entities": []}, {"text": "Modern NLP systems face the challenge of interpreting language as close to human perception as possible.", "labels": [], "entities": [{"text": "interpreting language", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.8887396454811096}]}, {"text": "Modeling gradable terms as well as their associated meaning and ordering is an important aspect of this challenge.", "labels": [], "entities": []}, {"text": "Such information can be very useful fora variety of inference tasks, such as sentiment analysis and textual inference ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.9698489010334015}]}, {"text": "However, current lexical resources, like WordNet, lack annotations capturing the gradability of words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9735013842582703}]}, {"text": "This weakens the notion of similarity: although words such as small and minuscule illustrate varying degrees of size, they are listed as synonyms in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 149, "end_pos": 156, "type": "DATASET", "confidence": 0.9635167717933655}]}, {"text": "Recently, there has been a lot of interest in exploring different approaches to derive an ordering among gradable adjectives based on their semantics.", "labels": [], "entities": []}, {"text": "de propose a novel Mixed Integer Linear Programming (MILP) based approach, publish a gold standard dataset and report the best performance on ordering scalar adjectives on this dataset.", "labels": [], "entities": []}, {"text": "However, these approaches are limited in two ways.", "labels": [], "entities": []}, {"text": "First, they depend on a manually created resource, such as WordNet or FrameNet (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9640859365463257}, {"text": "FrameNet", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.6993147730827332}]}, {"text": "Lexical patterns (e.g., 'not just x but y') are used both to extract words that belong to the same scale and to determine the direction of the ordering (e.g., in the above pattern, x is weaker than y).", "labels": [], "entities": []}, {"text": "However, this extraction process gives noisy results that require filtering using an electronic thesaurus.", "labels": [], "entities": []}, {"text": "The domain of application is thus restricted to words that exist in an electronic thesaurus.", "labels": [], "entities": []}, {"text": "Second, previous work is limited to the study of adjectives.", "labels": [], "entities": []}, {"text": "In this paper, we propose a fully automated pipeline that uses structural patterns to extract gradable terms from a corpus, cluster them into groups that reflect the same semantic scale of comparison, and finally rank them using de Melo and Bansal's MILP technique to establish an ordering among them.", "labels": [], "entities": []}, {"text": "We also explore how the technique fares on domain-specific (biomedical) text, deriving scales for domain-specific terms that might not exist in thesauri.", "labels": [], "entities": []}, {"text": "Our approach achieves a comparable performance to previous studies on scalar adjectives, and can be reliably extended to adverbs.", "labels": [], "entities": []}, {"text": "present the first work on automatically clustering adjectives that belong to the same scale, identifying scalar adjectives based on the intuition that similar nouns are modified by similar adjectives.", "labels": [], "entities": []}, {"text": "They use a hierarchical clustering algorithm on a newswire corpus for grouping similar adjectives, but do not provide ranking among a given cluster of related adjectives.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example comparison of automatically derived clusters against gold standard clusters from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.964821994304657}]}, {"text": " Table 2: AMT-based evaluations of cluster accuracy and pairwise ranking accuracy of systems that vary in the source  of clustering data, source of strength counts, and part of speech. For comparison, the approach used by de Melo and  Bansal (2013) achieves a pairwise ranking accuracy of 76.1% on the non-polysemous WordNet clusters.", "labels": [], "entities": [{"text": "AMT-based", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9202329516410828}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.8593592643737793}, {"text": "WordNet clusters", "start_pos": 317, "end_pos": 333, "type": "DATASET", "confidence": 0.9367510974407196}]}]}