{"title": [{"text": "Unsupervised Multi-Domain Adaptation with Feature Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Representation learning is the dominant technique for unsupervised domain adaptation, but existing approaches have two major weaknesses.", "labels": [], "entities": [{"text": "Representation learning", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9583600759506226}, {"text": "unsupervised domain adaptation", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.7674175103505453}]}, {"text": "First, they often require the specification of \"pivot features\" that generalize across domains, which are selected by task-specific heuristics.", "labels": [], "entities": []}, {"text": "We show that a novel but simple feature embedding approach provides better performance, by exploiting the feature template structure common in NLP problems.", "labels": [], "entities": []}, {"text": "Second, unsupervised domain adaptation is typically treated as a task of moving from a single source to a single target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7746033370494843}]}, {"text": "In reality, test data maybe diverse, relating to the training data in some ways but not others.", "labels": [], "entities": []}, {"text": "We propose an alternative formulation, in which each instance has a vector of domain attributes, can be used to learn distill the domain-invariant properties of each feature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Domain adaptation is crucial if natural language processing is to be successfully employed in highimpact application areas such as social media, patient medical records, and historical texts.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7866840660572052}]}, {"text": "Unsupervised domain adaptation is particularly appealing, since it requires no labeled data in the target domain.", "labels": [], "entities": [{"text": "Unsupervised domain adaptation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.660523533821106}]}, {"text": "Some of the most successful approaches to unsupervised domain adaptation are based on representation learning: transforming sparse high-dimensional surface features into dense vector representations,.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7561889290809631}]}, {"text": "Suppose we want to adapt from 19th Century narratives to 16th Century dissertations: can unlabeled data from other domains help?", "labels": [], "entities": []}, {"text": "which are often more robust to domain shift ().", "labels": [], "entities": []}, {"text": "However, these methods are computationally expensive to train, and often require special task-specific heuristics to select good \"pivot features.\"", "labels": [], "entities": []}, {"text": "A second, more subtle challenge for unsupervised domain adaptation is that it is normally framed as adapting from a single source domain to a single target domain.", "labels": [], "entities": [{"text": "unsupervised domain adaptation", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.7360750834147135}]}, {"text": "For example, we maybe given partof-speech labeled text from 19th Century narratives, and we hope to adapt the tagger to work on academic dissertations from the 16th Century.", "labels": [], "entities": []}, {"text": "This ignores text from the intervening centuries, as well as text that is related by genre, such as 16th Century narratives and 19th Century dissertations (see).", "labels": [], "entities": []}, {"text": "We address anew challenge of unsupervised multidomain adaptation, where the goal is to leverage this additional unlabeled data to improve performance in the target domain.", "labels": [], "entities": [{"text": "multidomain adaptation", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7921193242073059}]}], "datasetContent": [{"text": "We evaluate FEMA on part-of-speech (POS) tagging, in two settings: (1) adaptation of English POS tagging from news text to web text, as in the SANCL shared task; adaptation of Portuguese POS tagging across a graph of related domains over several centuries and genres, from the Tycho Brahe corpus (.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.6518967747688293}, {"text": "part-of-speech (POS) tagging", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.6514297485351562}, {"text": "POS tagging from news text to web text", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.7776705138385296}, {"text": "Tycho Brahe corpus", "start_pos": 277, "end_pos": 295, "type": "DATASET", "confidence": 0.8236262599627177}]}, {"text": "These evaluations are complementary: English POS tagging gives us the opportunity to evaluate feature embeddings in a well-studied and highimpact application; Portuguese POS tagging enables evaluation of multi-attribute domain adaptation, and demonstrates the capability of our approach in a morphologically-rich language, with a correspondingly large number of part-of-speech tags (383).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.5801148861646652}, {"text": "Portuguese POS tagging", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.5134323438008627}, {"text": "multi-attribute domain adaptation", "start_pos": 204, "end_pos": 237, "type": "TASK", "confidence": 0.6758547226587931}]}, {"text": "As more historical labeled data becomes available for English and other languages, we will be able to evaluate feature embeddings and related techniques there.", "labels": [], "entities": []}, {"text": "Recent work in domain adaptation for natural language processing has focused on the data from the shared task on Syntactic Analysis of Non-Canonical Language (SANCL;, which contains several web-related corpora (newsgroups, reviews, weblogs, answers, emails) as well as the WSJ portion of OntoNotes corpus).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7579348087310791}, {"text": "WSJ portion of OntoNotes corpus", "start_pos": 273, "end_pos": 304, "type": "DATASET", "confidence": 0.7576950490474701}]}, {"text": "Following, we use sections 02-21 of WSJ for training and section 22 for development, and use 100,000 unlabeled WSJ sentences from 1988 for learning representations.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.9405390024185181}]}, {"text": "On the web text side, each of the five target domains has an unlabeled training set of 100,000 sentences (except the ANSWERS domain, which has 27,274 unlabeled sentences), along with development and test sets of about 1000 labeled sentences each.", "labels": [], "entities": []}, {"text": "In the spirit of truly unsupervised domain adaptation, we do not use any target domain data for parameter tuning.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7737918496131897}]}, {"text": "Settings For FEMA, we consider only the singleembedding setting, learning a single feature embedding jointly across all domains.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.5174875259399414}]}, {"text": "We select 6918 pivot features for SCL, according to the method described above; the final dense representation is produced by performing a truncated singular value decomposition on the projection matrix that arises from the   Additional systems Aside from SCL and mDA, we compare against published results of FLORS (, which uses distributional features for domain adaptation.", "labels": [], "entities": [{"text": "FLORS", "start_pos": 309, "end_pos": 314, "type": "DATASET", "confidence": 0.5319043397903442}, {"text": "domain adaptation", "start_pos": 357, "end_pos": 374, "type": "TASK", "confidence": 0.7378941178321838}]}, {"text": "We also republish the baseline results of using the Stanford POS Tagger, a maximum entropy Markov model (MEMM) tagger.", "labels": [], "entities": [{"text": "Stanford POS Tagger", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.8166671196619669}]}, {"text": "Results As shown in   gensim.", "labels": [], "entities": []}, {"text": "4 This is slightly faster than SCL, although slower than mDA with structured dropout noise.", "labels": [], "entities": []}, {"text": "shows the average accuracy on the SANCL development set, versus the latent dimensions of different methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995805621147156}, {"text": "SANCL development set", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.7660367488861084}]}, {"text": "The latent dimension of SCL is modulated by the number of singular vectors; we consider sizes 10, 25, 50, 75, and 100.", "labels": [], "entities": [{"text": "SCL", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9288906455039978}]}, {"text": "In mDA, we consider pivot feature frequency thresholds 500, 400, 300, 250, and 200.", "labels": [], "entities": []}, {"text": "For FEMA, we consider embedding sizes 25, 50, 100, 150, and 200.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.5925756096839905}]}, {"text": "The resulting latent dimensionality multiplies these sizes by the number of non-binary templates  13.", "labels": [], "entities": []}, {"text": "FEMA dominates the other approaches across the complete range of latent dimensionalities.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5315108895301819}]}, {"text": "The best parameters for SCL are dimensionality K = 50 and rescale factor \u03b1 = 5.", "labels": [], "entities": [{"text": "SCL", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9829203486442566}, {"text": "dimensionality K", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.9068455398082733}, {"text": "rescale factor \u03b1", "start_pos": 58, "end_pos": 74, "type": "METRIC", "confidence": 0.9838640292485555}]}, {"text": "For both FEMA and WORD2VEC, the best embedding size is 100 and the best number of negative samples is 5.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.7419402599334717}, {"text": "WORD2VEC", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.8332566618919373}]}, {"text": "Next, we consider the problem of multi-attribute domain adaptation, using the Tycho Brahe corpus of historical Portuguese text (, which contains syntactic annotations of Portuguese texts in four genres over several centuries).", "labels": [], "entities": [{"text": "multi-attribute domain adaptation", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.6413166622320811}, {"text": "Tycho Brahe corpus of historical Portuguese text", "start_pos": 78, "end_pos": 126, "type": "DATASET", "confidence": 0.8948002457618713}]}, {"text": "We focus on temporal adaptation: training on the most modern data in the corpus, and testing on increasingly distant historical text.", "labels": [], "entities": [{"text": "temporal adaptation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7738309502601624}]}, {"text": "Settings For FEMA, we consider domain attributes for 50-year temporal epochs and genres; we also create an additional attribute merging all instances that are in neither the source nor target domain.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.5462965369224548}]}, {"text": "In SCL and mDA, 1823 pivot features pass the threshold.", "labels": [], "entities": [{"text": "mDA", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.8886656165122986}]}, {"text": "Optimizing on a source-domain development set, we find that the best parameters for SCL are dimensionality K = 25 and rescale factor \u03b1 = 5.", "labels": [], "entities": [{"text": "SCL", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9662315845489502}, {"text": "rescale factor \u03b1", "start_pos": 118, "end_pos": 134, "type": "METRIC", "confidence": 0.9774171511332194}]}, {"text": "The best embedding size and negative sample number are 50 and 15 for both FEMA and WORD2VEC.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8247005939483643}, {"text": "WORD2VEC", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8951467275619507}]}, {"text": "Results As shown in, FEMA outperforms competitive systems on all tasks.", "labels": [], "entities": [{"text": "FEMA", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.49854013323783875}]}, {"text": "The column \"single embedding\" reports results with a single feature embedding per feature, ignoring domain attributes; the column \"attribute embeddings\" shows that learning feature embeddings for domain attributes further improves performance, by 0.3-0.4% on average.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracy results for adaptation from WSJ to Web Text on SANCL dev set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9976964592933655}, {"text": "WSJ", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.7648672461509705}, {"text": "SANCL dev set", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.8480864564577738}]}, {"text": " Table 3: Accuracy results for adaptation from WSJ to Web Text on SANCL test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9977676868438721}, {"text": "WSJ", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.6724874973297119}, {"text": "SANCL test set", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.8518490791320801}]}, {"text": " Table 4: Accuracy results for adaptation in the Tycho Brahe corpus of historical Portuguese.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.99608314037323}, {"text": "Tycho Brahe corpus of historical Portuguese", "start_pos": 49, "end_pos": 92, "type": "DATASET", "confidence": 0.9275992314020792}]}, {"text": " Table 5: Label consistency of the Q-most similar words  in each embedding. FEMA-all is the concatenation of the  current, previous, and next-word FEMA embeddings.", "labels": [], "entities": [{"text": "consistency", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.625041127204895}, {"text": "FEMA-all", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.8954218029975891}]}]}