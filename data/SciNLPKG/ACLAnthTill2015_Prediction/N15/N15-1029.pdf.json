{"title": [{"text": "Disfluency Detection with a Semi-Markov Model and Prosodic Features", "labels": [], "entities": [{"text": "Disfluency Detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9116947948932648}]}], "abstractContent": [{"text": "We present a discriminative model for detecting disfluencies in spoken language transcripts.", "labels": [], "entities": [{"text": "detecting disfluencies in spoken language transcripts", "start_pos": 38, "end_pos": 91, "type": "TASK", "confidence": 0.8082363704840342}]}, {"text": "Structurally, our model is a semi-Markov conditional random field with features targeting characteristics unique to speech repairs.", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.704510286450386}]}, {"text": "This gives a significant performance improvement over standard chain-structured CRFs that have been employed in past work.", "labels": [], "entities": []}, {"text": "We then incorporate prosodic features over silences and relative word duration into our semi-CRF model, resulting in further performance gains; moreover, these features are not easily replaced by discrete prosodic indicators such as ToBI breaks.", "labels": [], "entities": []}, {"text": "Our final system , the semi-CRF with prosodic information, achieves an F-score of 85.4, which is 1.3 F 1 better than the best prior reported F-score on this dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9997757077217102}, {"text": "F-score", "start_pos": 141, "end_pos": 148, "type": "METRIC", "confidence": 0.9906820058822632}]}], "introductionContent": [{"text": "Spoken language is fundamentally different from written language in that it contains frequent disfluencies, or parts of an utterance that are corrected by the speaker.", "labels": [], "entities": []}, {"text": "Removing these disfluencies is desirable in order to clean the input for use in downstream NLP tasks.", "labels": [], "entities": []}, {"text": "However, automatically identifying disfluencies is challenging fora number of reasons.", "labels": [], "entities": [{"text": "automatically identifying disfluencies", "start_pos": 9, "end_pos": 47, "type": "TASK", "confidence": 0.7720595796902975}]}, {"text": "First, disfluencies area syntactic phenomenon, but defy standard context-free parsing models due to their parallel substructures), causing researchers to employ other approaches such as pipelines of sequence models (Qian and or incremental syntactic systems ().", "labels": [], "entities": []}, {"text": "Second, human processing of spoken language is complex and mixes acoustic and syntactic indicators (, so an automatic system must employ features targeting all levels of the perceptual stack to achieve high performance.", "labels": [], "entities": []}, {"text": "In spite of this, the primary thread of work in the NLP community has focused on identifying disfluencies based only on lexicosyntactic cues.", "labels": [], "entities": []}, {"text": "A separate line of work has therefore attempted to build systems that leverage prosody as well as lexical information (), though often with mixed success.", "labels": [], "entities": []}, {"text": "In this work, we present a model for disfluency detection that improves upon model structures used in past work and leverages additional prosodic information.", "labels": [], "entities": [{"text": "disfluency detection", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.861399918794632}]}, {"text": "Our model is a semi-Markov conditional random field that distinguishes disfluent chunks (to be deleted) from fluent chunks (everything else), as shown in.", "labels": [], "entities": []}, {"text": "By making chunk-level predictions, we can incorporate not only standard tokenlevel features but also features that can consider the entire reparandum and the start of the repair, enabling our model to easily capture parallelism between these two parts of the utterance.", "labels": [], "entities": []}, {"text": "1 This frame-work also enables novel prosodic features that compute pauses and word duration based on alignments to the speech signal itself, allowing the model to capture acoustic cues like pauses and hesitations that have proven useful for disfluency detection in earlier work (.", "labels": [], "entities": [{"text": "disfluency detection", "start_pos": 242, "end_pos": 262, "type": "TASK", "confidence": 0.8364333212375641}]}, {"text": "Such information has been exploited by NLP systems in the past via ToBI break indices, a mid-level prosodic abstraction that might be indicative of disfluencies.", "labels": [], "entities": []}, {"text": "These have been incorporated into syntactic parsers with some success), but we find that using features on predicted breaks is ineffective compared to directly using acoustic indicators.", "labels": [], "entities": []}, {"text": "Our implementation of a baseline CRF model already achieves results comparable to those of a highperformance system based on pipelined inference.", "labels": [], "entities": []}, {"text": "Our semi-CRF with span features improves on this, and adding prosodic indicators gives additional gains.", "labels": [], "entities": []}, {"text": "Our final system gets an F-score of 85.4, which is 1.3 F 1 better than the best prior reported F-score on this dataset).", "labels": [], "entities": [{"text": "F-score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9996931552886963}, {"text": "F-score", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.9863733053207397}]}], "datasetContent": [{"text": "Throughout this work, we make use of the Switchboard corpus using the train/test splits specified by and used in other work.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.8726516962051392}]}, {"text": "We use the provided transcripts and gold alignments between the text and the speech signal.", "labels": [], "entities": []}, {"text": "We follow the same preprocessing regimen as past work: we remove partial words, punctuation, and capitalization to make the input more realistic.", "labels": [], "entities": []}, {"text": "Finally, we use predicted POS tags from the Berkeley parser () trained on Switchboard.", "labels": [], "entities": [{"text": "Switchboard", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.9265450239181519}]}], "tableCaptions": [{"text": " Table 1: Disfluency results on the development set.  Adding span features on top of a CRF baseline im- proves performance, and including raw acoustic informa- tion gives further performance gains.", "labels": [], "entities": []}, {"text": " Table 2: Disfluency results with predicted ToBI fea- tures on the development set. We compare our baseline  semi-CRF system (Baseline) with systems that incorpo- rate prosody via predictions from the AuToBI system of  Rosenberg (2010) and from our CRF ToBI predictor, as  well as the full system using raw acoustic features.", "labels": [], "entities": [{"text": "AuToBI system of  Rosenberg (2010)", "start_pos": 201, "end_pos": 235, "type": "DATASET", "confidence": 0.9442188143730164}]}, {"text": " Table 3: Disfluency prediction results on the test set; our  base system outperforms that of", "labels": [], "entities": [{"text": "Disfluency prediction", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8909326195716858}]}]}