{"title": [{"text": "Type-Driven Incremental Semantic Parsing with Polymorphism *", "labels": [], "entities": [{"text": "Incremental Semantic Parsing", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.5680043200651804}]}], "abstractContent": [{"text": "Semantic parsing has made significant progress, but most current semantic parsers are extremely slow (CKY-based) and rather primitive in representation.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8167314827442169}]}, {"text": "We introduce three new techniques to tackle these problems.", "labels": [], "entities": []}, {"text": "First, we design the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.7109864950180054}]}, {"text": "Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction , which eliminates the need fora syntactic grammar such as CCG.", "labels": [], "entities": []}, {"text": "Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of sub-type polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing.", "labels": [], "entities": [{"text": "type-driven semantic parsing", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.6308184464772543}]}, {"text": "Our system learns very accurate parses in GEOQUERY, JOBS and ATIS domains.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9410696029663086}, {"text": "JOBS", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.7877684235572815}]}], "introductionContent": [{"text": "Most existing semantic parsing efforts employ a CKYstyle bottom-up parsing strategy to generate a meaning representation in simply typed lambda calculus) or its variants.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 14, "end_pos": 30, "type": "TASK", "confidence": 0.7262687236070633}, {"text": "CKYstyle bottom-up parsing", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.6602141261100769}]}, {"text": "Although these works led to fairly accurate semantic parsers, there are two major drawbacks: efficiency and expressiveness.", "labels": [], "entities": []}, {"text": "First, as many researches in syntactic parsing) have shown, compared to cubic-time CKY-style parsing, incremental parsing can achieve comparable accuracies while being linear-time, and orders of magnitude faster in practice.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7501572668552399}]}, {"text": "We therefore introduce the first incremental parsing algorithm for semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.8411123156547546}]}, {"text": "More interestingly, unlike syntactic parsing, our incremental semantic parsing algorithm, being strictly type-driven, directly employs type checking to automatically determine the direction of function application on-the-fly, thus reducing the search space and elimi- * We thank the reviewers for helpful suggestions.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7574060261249542}, {"text": "semantic parsing", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.7567355632781982}]}, {"text": "We are also grateful to Luke Zettelmoyer, Yoav Artzi, and Tom Kwiatkowski for providing data.", "labels": [], "entities": []}, {"text": "This research is supported by DARPA FA8750-13-2-0041 (DEFT), NSF IIS-1449278, and a Google Faculty Research Award.", "labels": [], "entities": [{"text": "DARPA FA8750-13-2-0041 (DEFT)", "start_pos": 30, "end_pos": 59, "type": "DATASET", "confidence": 0.5275918424129487}, {"text": "NSF IIS-1449278", "start_pos": 61, "end_pos": 76, "type": "DATASET", "confidence": 0.8585277497768402}]}, {"text": "nating the need fora syntactic grammar such as CCG to explicitly encode the direction of function application.", "labels": [], "entities": []}, {"text": "However, to fully exploit the power of type-driven incremental parsing, we need a more sophisticated type system than simply typed lambda calculus.", "labels": [], "entities": [{"text": "type-driven incremental parsing", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.5688750843207041}]}, {"text": "Compare the following two phrases: (1) the governor of New York (2) the mayor of New York If we know that governor is a function from state to person, then the first New York can only be of type state; similarly knowing mayor maps city to person disambiguates the second New York to be of type city.", "labels": [], "entities": []}, {"text": "This cannot be done using a simple type system with just entities and booleans.", "labels": [], "entities": []}, {"text": "Now let us consider a more complex question which will be our running example in this paper: (3) What is the capital of the largest state by area?", "labels": [], "entities": []}, {"text": "Since we know capital takes a state as input, we expect the largest state by area to return a state.", "labels": [], "entities": []}, {"text": "But does largest always return a state type?", "labels": [], "entities": []}, {"text": "Notice that it is polymorphic, for example, largest city by population, or largest lake by perimeter.", "labels": [], "entities": []}, {"text": "So there is no unique type for largest: its return type should depend on the type of its first argument (city, state, or lake).", "labels": [], "entities": []}, {"text": "This observation motivates us to introduce the powerful mechanism of parametric polymorphism from programming languages into natural language semantics for the first time.", "labels": [], "entities": []}, {"text": "For example, we can define the type of largest to be a template largest : where 'a is a type variable that can match any type (for formal details see \u00a73).", "labels": [], "entities": []}, {"text": "Just like in functional programming languages such as ML or Haskell, type variables can be bound to areal type (or a range of types) during function application, using the technique of type inference.", "labels": [], "entities": []}, {"text": "In the above example, when largest is applied to city, we know that type variable 'a is bound to type city (or its subtype), so largest would eventually return a city.", "labels": [], "entities": []}, {"text": "We make the following contributions: \u2022 We design the first linear-time incremental semantic parsing algorithm ( \u00a72), which is much more efficient than the existing semantic parsers that are cubictime and CKY-based.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.713509812951088}]}, {"text": "\u2022 In line with classical Montague theory, our parser is type-driven instead of syntax-driven as in CCG-based efforts) ( \u00a72.3).", "labels": [], "entities": []}, {"text": "\u2022 We introduce parametric polymorphism into natural language semantics ( \u00a73), along with proper treatment of subtype polymorphism, and implement Hindley-Milner style type inference (Pierce, 2005, Chap. 10) during parsing ( \u00a73.3).", "labels": [], "entities": []}, {"text": "1 \u2022 We adapt the latent-variable max-violation perceptron training from machine translation (, which is a perfect fit for semantic parsing due to its huge search space ( \u00a74).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7517065405845642}, {"text": "semantic parsing", "start_pos": 122, "end_pos": 138, "type": "TASK", "confidence": 0.7592822015285492}]}], "datasetContent": [{"text": "We implement our type-driven incremental semantic parser (TISP) using Python, and evaluate its performance on GEOQUERY, JOBS, and ATIS datasets.", "labels": [], "entities": [{"text": "type-driven incremental semantic parser (TISP)", "start_pos": 17, "end_pos": 63, "type": "TASK", "confidence": 0.6847787116255079}, {"text": "GEOQUERY", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9532253742218018}, {"text": "ATIS datasets", "start_pos": 130, "end_pos": 143, "type": "DATASET", "confidence": 0.7867794334888458}]}, {"text": "Our feature design is inspired by the very effective Word-Edge features in syntactic parsing) and MT (.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7500343918800354}, {"text": "MT", "start_pos": 98, "end_pos": 100, "type": "DATASET", "confidence": 0.6108878254890442}]}, {"text": "From each parsing state, we collect atomic features including the types and the leftmost and rightmost words of the span of the top 3 MR expressions on the stack, the top 3 words on the queue, the grounded predicate names and the ID of the MR template used in the shift action.", "labels": [], "entities": []}, {"text": "We use budget scheme similar to () to alleviate the overfitting problem caused by feature sparsity.", "labels": [], "entities": []}, {"text": "We get 84 combined feature templates in total.", "labels": [], "entities": []}, {"text": "Our final system contains 62 MR expression templates, of which 33 are triggered by POS tags, and 29 are triggered by specific phrases.", "labels": [], "entities": []}, {"text": "In the experiments, we use the same training, development, and testing data splits as and.", "labels": [], "entities": []}, {"text": "For evaluation, we follow to use precision and recall: Precision = # of correctly parsed questions # of successfully parsed questions , Recall = # of correctly parsed questions # of questions .  We first evaluate TISP on GEOQUERY dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.999488353729248}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9990529417991638}, {"text": "Precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9982074499130249}, {"text": "Recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9984425902366638}, {"text": "TISP", "start_pos": 213, "end_pos": 217, "type": "METRIC", "confidence": 0.8356417417526245}, {"text": "GEOQUERY dataset", "start_pos": 221, "end_pos": 237, "type": "DATASET", "confidence": 0.9809080362319946}]}, {"text": "In the training and evaluating time, we use a very small beam size of 16, which gives us very fast decoding.", "labels": [], "entities": []}, {"text": "In serial mode, our parser takes \u223c 83s to decode the 280 sentences (2,147 words) in the testing set, which means \u223c 0.3s per sentence, or \u223c 0.04s per word.", "labels": [], "entities": []}, {"text": "We compare the our accuracy performance with existing methods) in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.999113142490387}]}, {"text": "Given that all other methods use CKY-style parsing, our method is well balanced between accuracy and speed.", "labels": [], "entities": [{"text": "CKY-style parsing", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.5185833871364594}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9995947480201721}, {"text": "speed", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.9827824234962463}]}, {"text": "In addition, to unveil the helpfulness of our type system, we train a parser with only simple types.", "labels": [], "entities": []}, {"text": "In this setting, the predicates only have primitive types of location lo, integer i, and boolean t, while the constants still keep their types.", "labels": [], "entities": []}, {"text": "It still has the type system, but it is weaker than the polymorphic one.", "labels": [], "entities": []}, {"text": "Its accuracy is lower than the standard one, mostly caused by that the type system cannot help pruning the wrong applications like (population:au\u2192i mississippi:rv).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994791150093079}]}, {"text": "We also evaluate the performance of our parser on JOBS and ATIS datasets.", "labels": [], "entities": [{"text": "JOBS", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.9325786828994751}, {"text": "ATIS datasets", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.8254302740097046}]}, {"text": "shows the type hierarchy for JOBS.", "labels": [], "entities": [{"text": "JOBS", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.9390015602111816}]}, {"text": "We omit the type hierarchy for ATIS due to space constraint.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.8459141850471497}]}, {"text": "Note that ATIS contains more than 5,000 examples and is a lot larger than GEOQUERY and JOBS.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.8030412197113037}, {"text": "GEOQUERY", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.8964941501617432}, {"text": "JOBS", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.928287148475647}]}, {"text": "We show the results in.", "labels": [], "entities": []}, {"text": "In JOBS, we achieves very good recall, but the precision is not as good as Zettlemoyer and, which is actually because we parsed a lot more sentences.", "labels": [], "entities": [{"text": "JOBS", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.858803927898407}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9988002777099609}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.999634861946106}]}, {"text": "Also, TISP with simple types is still weaker than the one with subtyping and parametric polymorphisms.", "labels": [], "entities": []}, {"text": "For ATIS, our performance is very close to the state-of-the-art.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8257222175598145}]}], "tableCaptions": [{"text": " Table 2: Performances (precision, recall, and F1) of various  parsing algorithms on GEOQUERY, JOBS, and ATIS datasets.  TISP with simple types are marked \"st\".", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9993728995323181}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9978519678115845}, {"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9997994303703308}, {"text": "GEOQUERY", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.9762015342712402}, {"text": "ATIS datasets", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.7944185137748718}]}]}