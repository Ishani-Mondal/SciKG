{"title": [{"text": "Because Syntax Does Matter: Improving Predicate-Argument Structures Parsing with Syntactic Features", "labels": [], "entities": [{"text": "Improving Predicate-Argument Structures Parsing", "start_pos": 28, "end_pos": 75, "type": "TASK", "confidence": 0.7325215637683868}]}], "abstractContent": [{"text": "Parsing full-fledged predicate-argument structures in a deep syntax framework requires graphs to be predicted.", "labels": [], "entities": []}, {"text": "Using the DeepBank (Flickinger et al., 2012) and the Predicate-Argument Structure treebank (Miyao and Tsu-jii, 2005) as a test field, we show how transition-based parsers, extended to handle connected graphs, benefit from the use of topologically different syntactic features such as dependencies, tree fragments, spines or syntactic paths, bringing a much needed context to the parsing models, improving notably overlong distance dependencies and elided coordinate structures.", "labels": [], "entities": []}, {"text": "By confirming this positive impact on an accurate 2nd-order graph-based parser (Martins and Almeida, 2014), we establish anew state-of-the-art on these data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the majority of the state-of-the-art parsers that routinely reach ninety percent performance plateau in capturing tree structures, the question of what next crucially arises.", "labels": [], "entities": []}, {"text": "Indeed, it has long been thought that the bottleneck preventing the advent of accurate syntax-to-semantic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output.", "labels": [], "entities": []}, {"text": "The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (PTB, () which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures.", "labels": [], "entities": [{"text": "Wall Street journal section of the Penn treebank (PTB", "start_pos": 136, "end_pos": 189, "type": "DATASET", "confidence": 0.8783064782619476}]}, {"text": "This led to the emergence of surface syntax-based parsers) whose output cannot by themselves be used to extract full-fledged predicateargument structures.", "labels": [], "entities": []}, {"text": "For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for.", "labels": [], "entities": [{"text": "argument sharing in ellipsis coordination", "start_pos": 62, "end_pos": 103, "type": "TASK", "confidence": 0.7945304751396179}]}, {"text": "The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9869905114173889}]}, {"text": "For most of the previous decade, the term deep syntax was used for rich parsing models built upon enriched versions of a constituency treebank, either with added HPSG or LFG annotation or CCG (almost) full rewrites (.", "labels": [], "entities": []}, {"text": "Its use now spreads by misnomer to models that provide more abstract structures, capable of generalizing classical functional labels to more semantic (in a logical view) arguments, potentially capable of neutralizing diathesis distinctions and of providing accurate predicate-argument structures.", "labels": [], "entities": []}, {"text": "Although the building of syntax-to-semantic interface seems inextricably linked to an efficient parsing stage, inspirational works on semantic role labelling () and more recently on broad coverage semantic parsing () that provide stateof-the-art results without relying on surface syntax, lead us to question the usefulness of syntactic parses for predicate-argument structure parsing.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.6063435971736908}, {"text": "broad coverage semantic parsing", "start_pos": 182, "end_pos": 213, "type": "TASK", "confidence": 0.5991851165890694}, {"text": "predicate-argument structure parsing", "start_pos": 348, "end_pos": 384, "type": "TASK", "confidence": 0.7737558484077454}]}, {"text": "In this study, we investigate the impact of syntactic features on a transition-based graph parser by testing on two treebanks.", "labels": [], "entities": []}, {"text": "We take advantage of the recent release for the SemEval 2014 shared task on semantic dependency parsing, by of two semantic-based treebanks, derived from two HPSG resources, the DeepBank (DM, ) and the Enju's predicate argument structure), to investigate the impact of syntactic features on a transition-based graph parser.", "labels": [], "entities": [{"text": "SemEval 2014 shared task", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.810909777879715}, {"text": "semantic dependency parsing", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.6576455235481262}, {"text": "transition-based graph parser", "start_pos": 293, "end_pos": 322, "type": "TASK", "confidence": 0.6814484794934591}]}, {"text": "Our results show that surface syntactic features significantly improve the parsing of predicate-argument structures.", "labels": [], "entities": [{"text": "parsing of predicate-argument structures", "start_pos": 75, "end_pos": 115, "type": "TASK", "confidence": 0.8219402134418488}]}, {"text": "More specifically, we show that adding syntactic context improves the recognition of long distance dependencies and elliptical constructions.", "labels": [], "entities": []}, {"text": "We finally discuss the usefulness of our approach, when applied on a second-order model based on dual decomposition, showing that our use of syntactic features enhances this model accuracy and provides state-of-the-art performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9956250786781311}]}], "datasetContent": [{"text": "Experimental Setup Both DM and PAS treebanks consist of texts from the PTB and which were either automatically derived from the original annotations or annotated with a hand-crafted grammar (see above).", "labels": [], "entities": [{"text": "PTB", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.8703744411468506}]}, {"text": "We use them in their bi-lexical dependency format, aligned at the token level as provided by 1 . The following split is used: sections 00-19 for training, 20 for the dev.", "labels": [], "entities": []}, {"text": "set and 21 for test . All predicted parses are evaluated against the gold standard with labeled precision, recall and f-measure metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9878095388412476}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9974353909492493}]}, {"text": "All improvements from the baseline are significant with a p-value p < 0.05.", "labels": [], "entities": []}, {"text": "There was no significant difference of the same p value between our two best mod-els for each of the treebanks.", "labels": [], "entities": []}, {"text": "As expected from the rapid overview of our datasets exposed earlier in section 2, the use of each single feature alone increases the performance over the baseline by 0.5 points for the BN feature in DM to 1.44 for PATHS, and by 1.10 for the SPINES to 1.85 for the PATHS features in PAS.", "labels": [], "entities": []}, {"text": "Looking at the conjunction of two classes in the DM table, it seems that dependency-based features benefit from the extra context brought by constituents features, reaching an increase of 2.21 points for BKY+BN(HPOS).", "labels": [], "entities": [{"text": "BKY+BN(HPOS)", "start_pos": 204, "end_pos": 216, "type": "DATASET", "confidence": 0.7525133391221365}]}, {"text": "Interestingly, the maximum gain is brought by the addition of topologically different phrase-based features such as SPINES (+2.80, inherently vertical) or BKY (+2.76, often wider) to the previous best.", "labels": [], "entities": [{"text": "SPINES", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9621831178665161}, {"text": "BKY", "start_pos": 155, "end_pos": 158, "type": "METRIC", "confidence": 0.9955154061317444}]}, {"text": "Regarding PAS, similar trends can be observed, although the gains are more distributed.", "labels": [], "entities": [{"text": "PAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5697078704833984}]}, {"text": "As opposed to DM where the conjunction of more features led to inferior results, here using a four-features class provides the second best improvement (ALL(HPOS) = BKY+BN(HPOS)+SPINES+PATHS), +2.82) while removing the SPINES slightly increases the score (+2.92).", "labels": [], "entities": [{"text": "ALL", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.9852730631828308}, {"text": "BKY+BN(HPOS)+SPINES+PATHS)", "start_pos": 164, "end_pos": 190, "type": "METRIC", "confidence": 0.7568379402160644}]}, {"text": "In fact, adding too many features to the model slightly degrades our scores, at least with regard to DM which has a larger label set than PAS.", "labels": [], "entities": []}, {"text": "Results show that syntactic information improves our parser performances.", "labels": [], "entities": []}, {"text": "As each feature represents one unique piece of information, they benefit from being combined in order to provide more structural information.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: DM and PAS treebank properties", "labels": [], "entities": [{"text": "PAS treebank", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.8056430518627167}]}, {"text": " Table 2: Breakdown of Label Statistics.  Cell values in italics not counted in the DM total.", "labels": [], "entities": [{"text": "Breakdown of Label Statistics", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8168266117572784}]}, {"text": " Table 4: Syntactic features statistics (Counts).", "labels": [], "entities": []}, {"text": " Table 5: Best results and gains on DM corpus.", "labels": [], "entities": [{"text": "DM corpus", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.7872529029846191}]}, {"text": " Table 6: Best results and gains on PAS.", "labels": [], "entities": [{"text": "PAS", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.5507623553276062}]}, {"text": " Table 7: Number of LDDs edges (dev. set).", "labels": [], "entities": []}, {"text": " Table 8: Long-distance dependencies eval. (dev sets).", "labels": [], "entities": []}, {"text": " Table 9: Shared subjects coordinations eval. (dev  sets).", "labels": [], "entities": [{"text": "Shared subjects coordinations", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.5966775417327881}]}, {"text": " Table 10: Comparison with the State-of-the-Art.", "labels": [], "entities": []}, {"text": " Table 11: LF Results for T.PARSER (test set).  Baseline = arc-factored + siblings", "labels": [], "entities": [{"text": "Baseline", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.977102518081665}, {"text": "arc-factored", "start_pos": 59, "end_pos": 71, "type": "METRIC", "confidence": 0.983350932598114}]}]}