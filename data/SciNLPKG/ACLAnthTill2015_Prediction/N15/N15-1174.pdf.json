{"title": [{"text": "Learning to Interpret and Describe Abstract Scenes", "labels": [], "entities": [{"text": "Learning to Interpret and Describe Abstract Scenes", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.6800741979054042}]}], "abstractContent": [{"text": "Given a (static) scene, a human can effortlessly describe what is going on (who is doing what to whom, how, and why).", "labels": [], "entities": []}, {"text": "The process requires knowledge about the world, how it is perceived, and described.", "labels": [], "entities": []}, {"text": "In this paper we study the problem of interpreting and verbalizing visual information using abstract scenes created from collections of clip art images.", "labels": [], "entities": [{"text": "interpreting and verbalizing visual information", "start_pos": 38, "end_pos": 85, "type": "TASK", "confidence": 0.7896102666854858}]}, {"text": "We propose a model inspired by machine translation operating over a large parallel corpus of visual relations and linguistic descriptions.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7292389124631882}]}, {"text": "We demonstrate that this approach produces human-like scene descriptions which are both fluent and relevant, outperforming a number of competitive alternatives based on templates , sentence-based retrieval, and a multi-modal neural language model.", "labels": [], "entities": []}], "introductionContent": [{"text": "What is going on in the scene in?", "labels": [], "entities": []}, {"text": "Is the boy trying to feed the dog or play with it?", "labels": [], "entities": []}, {"text": "Why is the girl upset?", "labels": [], "entities": []}, {"text": "Is it because the dog is wearing her glasses?", "labels": [], "entities": []}, {"text": "Or perhaps she is just scared of the dog?", "labels": [], "entities": []}, {"text": "Scene interpretation is effortless for humans, almost everyone can summarize in a few words, without probably paying too much attention to the fact the girl is wearing a pink dress, the sun is yellow or that there is a plane in the sky.", "labels": [], "entities": []}, {"text": "Discovering what an image means and relaying it in words is of theoretical importance raising questions about language and its grounding in the perceptual world but also has practical applications.", "labels": [], "entities": []}, {"text": "Examples include sentence-based image search and tools that enhance the accessibility of the web for visually impaired (blind and partially sighted) individuals.", "labels": [], "entities": [{"text": "sentence-based image search", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.6145315070947012}]}, {"text": "Indeed, there has been a recent surge of interest in the development of models that automatically describe image content in natural lan-: Given an image, humans do not simply see an arrangement of objects, they understand how they relate to each other as well as their attributes and the activities they are involved in. guage (see references in Section 2).", "labels": [], "entities": []}, {"text": "Due to the complex nature of the problem, existing approaches resort to modeling simplifications, on the generation side (e.g., through the use of templates and sentencebased retrieval methods), or the image processing side (e.g., by avoiding object-detection), or both.", "labels": [], "entities": []}, {"text": "In this paper we study the problem of interpreting visual scenes and rendering their content using natural language.", "labels": [], "entities": [{"text": "interpreting visual scenes", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.8843923807144165}]}, {"text": "We approach this problem within the methodology of , who proposed the use of abstract scenes generated from clip art to model scene understanding (see).", "labels": [], "entities": [{"text": "scene understanding", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7767696380615234}]}, {"text": "The use of abstract scenes offers several advantages over real images.", "labels": [], "entities": []}, {"text": "Firstly, it allows us to study the scene description problem in isolation, without the noise introduced by automatic object and attribute detectors in real images.", "labels": [], "entities": []}, {"text": "Secondly, it is relatively easy to gather large amounts of data, allowing us to compare multiple models on an equal footing, study in more detail the problem of language grounding, and how to identify what is important in an image.", "labels": [], "entities": [{"text": "language grounding", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.7197863012552261}]}, {"text": "Thirdly, information learned from abstract scenes will lead to better understanding of the challenges and data requirements arising when using real images.", "labels": [], "entities": []}, {"text": "We propose a model inspired by machine trans-lation, where the task is to transform a source sentence E into its target translation F.", "labels": [], "entities": []}, {"text": "We argue that generating descriptions for scenes is quite similar, but with a twist: the translation process is very loose and selective; there will always be objects in a scene not worth mentioning, and words in a description that will have no visual counterpart.", "labels": [], "entities": []}, {"text": "Our key insight is to represent scenes via visual dependency relations) corresponding to sentential descriptions.", "labels": [], "entities": []}, {"text": "This allows us to create a large parallel corpus for training a statistical machine translation system, which we interface with a content selection component guiding the translation toward interesting or important scene content.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.6290962994098663}]}, {"text": "Advantageously, our model can be used in the reverse direction, i.e., to generate scenes, without additional engineering effort.", "labels": [], "entities": []}, {"text": "Our approach outperforms a number of competitive alternatives, when evaluated both automatically and by humans.", "labels": [], "entities": []}], "datasetContent": [{"text": "The abstract scenes dataset 1 was created with the intent to represent real-world scenes that depict a diverse set of subtle relations.", "labels": [], "entities": []}, {"text": "It contains 10,020 images of children playing outside and 60,396 descriptions (on average six per image).", "labels": [], "entities": []}, {"text": "The data was collected in three stages.", "labels": [], "entities": []}, {"text": "First, Amazon Mechanical Turk (AMT) workers were asked to created scenes fora collection of 80 pieces of clip art depicting a boy and a girl (in different poses and with different facial expressions), and several objects including trees, toys, hats, animals, and soon.", "labels": [], "entities": []}, {"text": "Next, anew set of subjects were asked to describe the scenes using a one or two sentence description, finally, semantically similar scenes were generated by asking multiple subjects to create scenes depicting the same writ-\"Jenny is upset because Mike isn't sharing the soccer ball.\", \"Mike is wearing sunglasses.\", \"Jenny is wearing a silly hat.\", \"Mike is kicking the soccer ball away from Jenny.\", \"Jenny is chasing Mike to get the ball.\", \"Jenny is wearing a silly hat.\" ten description.", "labels": [], "entities": []}, {"text": "By construction, the dataset encodes the objects in each scene, and their position.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Model comparison on scene description task us- ing automatic measures.", "labels": [], "entities": []}, {"text": " Table 5: Rankings (shown as proportions) and mean rat- ings given to systems by human participants.", "labels": [], "entities": [{"text": "mean rat- ings", "start_pos": 46, "end_pos": 60, "type": "METRIC", "confidence": 0.8229022175073624}]}, {"text": " Table 6: Proportion of SMT descriptions deemed accu- rate and relevant. System output evaluated for rank place- ments 1. . . 6.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9856786131858826}, {"text": "accu- rate", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9360129038492838}]}]}