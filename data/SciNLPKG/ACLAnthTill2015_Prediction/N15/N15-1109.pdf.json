{"title": [{"text": "Unsupervised Code-Switching for Multilingual Historical Document Transcription", "labels": [], "entities": [{"text": "Multilingual Historical Document Transcription", "start_pos": 32, "end_pos": 78, "type": "TASK", "confidence": 0.7082733139395714}]}], "abstractContent": [{"text": "Transcribing documents from the printing press era, a challenge in its own right, is more complicated when documents interleave multiple languages-a common feature of 16th century texts.", "labels": [], "entities": [{"text": "Transcribing documents", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.895762026309967}]}, {"text": "Additionally, many of these documents precede consistent ortho-graphic conventions, making the task even harder.", "labels": [], "entities": []}, {"text": "We extend the state-of-the-art historical OCR model of Berg-Kirkpatrick et al.", "labels": [], "entities": []}, {"text": "(2013) to handle word-level code-switching between multiple languages.", "labels": [], "entities": []}, {"text": "Further, we enable our system to handle spelling variability , including now-obsolete shorthand systems used by printers.", "labels": [], "entities": [{"text": "spelling variability", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.89192134141922}]}, {"text": "Our results show average relative character error reductions of 14% across a variety of historical texts.", "labels": [], "entities": [{"text": "relative character error reductions", "start_pos": 25, "end_pos": 60, "type": "METRIC", "confidence": 0.588789738714695}]}], "introductionContent": [{"text": "Transcribing documents printed on historical printing presses poses a number of challenges for OCR technology.", "labels": [], "entities": [{"text": "Transcribing documents printed on historical printing presses", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.8344265307698931}, {"text": "OCR", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.9644070267677307}]}, {"text": "presented an unsupervised system, called Ocular, that handles the types of noise that are characteristic of pre20th century documents and uses a fixed monolingual language model to guide learning.", "labels": [], "entities": []}, {"text": "While this approach is highly effective on English documents from the 18th and 19th centuries, problems arise when it is applied to older documents that feature code-switching between multiple languages and obsolete orthographic characteristics.", "labels": [], "entities": []}, {"text": "In this work, we address these issues by developing anew language model for Ocular.", "labels": [], "entities": []}, {"text": "First, to handle multilingual documents, we replace Ocular's simple n-gram language model with an unsupervised model of intrasentential code-switching that allows joint transcription and word-level language identification.", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 187, "end_pos": 221, "type": "TASK", "confidence": 0.6416248381137848}]}, {"text": "Second, to handle orthographic variation, we provide an interface that allows individuals familiar with relevant languages to guide the language model with targeted orthographic information.", "labels": [], "entities": []}, {"text": "As a result, our system handles inconsistent spelling, punctuation, and diacritic usage, as well as now-obsolete shorthand conventions used by printers.", "labels": [], "entities": []}, {"text": "We evaluate our model using documents from the Primeros Libros project, a digital archive of books printed in the Americas prior to 1601.", "labels": [], "entities": [{"text": "Primeros Libros project, a digital archive of books printed in the Americas prior to 1601", "start_pos": 47, "end_pos": 136, "type": "DATASET", "confidence": 0.8119686804711819}]}, {"text": "These texts, written in European and indigenous languages, often feature as many as three languages on a single page, with code-switching occurring on the chapter, sentence, and word level.", "labels": [], "entities": []}, {"text": "Orthographic variations are pervasive throughout, and are particularly difficult with indigenous languages, for which writing systems were still being developed.", "labels": [], "entities": []}, {"text": "Our results show improvements across a range of documents, yielding an average 14% relative character error reduction over the previous state-of-the-art, with reductions as high as 27% on particular texts.", "labels": [], "entities": [{"text": "relative character error reduction", "start_pos": 83, "end_pos": 117, "type": "METRIC", "confidence": 0.7254304364323616}]}], "datasetContent": [{"text": "We compare to Ocular, the state of the art for historical OCR.", "labels": [], "entities": [{"text": "Ocular", "start_pos": 14, "end_pos": 20, "type": "DATASET", "confidence": 0.7798241376876831}, {"text": "OCR", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.8252909779548645}]}, {"text": "Since Ocular only supports monolingual English OCR, we added support for alternative alphabets, including diacritics and ligatures, and trained a single mixed-language model on a combined Spanish/Latin/Nahuatl corpus.", "labels": [], "entities": [{"text": "Ocular", "start_pos": 6, "end_pos": 12, "type": "DATASET", "confidence": 0.8545354604721069}]}, {"text": "We evaluate our model on five different books from the Primeros Libros collection, representing a variety of printers, presses, typefaces, and authors.", "labels": [], "entities": [{"text": "Primeros Libros collection", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.8563597997029623}]}, {"text": "Each book features code-switching be-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experimental results for each book, and average across all books. Columns show Character Error  Rate (CER) or Word Error Rate (WER; excluding punctuation). The final column gives the average WER  including punctuation (w.p.). The Ocular row is the previous state-of-the-art: Berg-Kirkpatrick et al. (2013).  The second row uses our code-switching model, and the third additionally handles orthographic variability.", "labels": [], "entities": [{"text": "Character Error  Rate (CER)", "start_pos": 89, "end_pos": 116, "type": "METRIC", "confidence": 0.9367242157459259}, {"text": "Word Error Rate (WER", "start_pos": 120, "end_pos": 140, "type": "METRIC", "confidence": 0.9183146119117737}]}]}