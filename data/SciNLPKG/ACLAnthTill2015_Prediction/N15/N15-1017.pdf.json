{"title": [{"text": "Discriminative Unsupervised Alignment of Natural Language Instructions with Corresponding Video Segments", "labels": [], "entities": [{"text": "Discriminative Unsupervised Alignment of Natural Language Instructions with Corresponding Video Segments", "start_pos": 0, "end_pos": 104, "type": "TASK", "confidence": 0.7540082254193046}]}], "abstractContent": [{"text": "We address the problem of automatically aligning natural language sentences with corresponding video segments without any direct supervision.", "labels": [], "entities": []}, {"text": "Most existing algorithms for integrating language with videos rely on hand-aligned parallel data, where each natural language sentence is manually aligned with its corresponding image or video segment.", "labels": [], "entities": []}, {"text": "Recently , fully unsupervised alignment of text with video has been shown to be feasible using hierarchical generative models.", "labels": [], "entities": []}, {"text": "In contrast to the previous generative models, we propose three latent-variable discriminative models for the unsupervised alignment task.", "labels": [], "entities": []}, {"text": "The proposed discriminative models are capable of incorporating domain knowledge, by adding diverse and overlapping features.", "labels": [], "entities": []}, {"text": "The results show that discriminative models outperform the generative models in terms of alignment accuracy.", "labels": [], "entities": [{"text": "alignment", "start_pos": 89, "end_pos": 98, "type": "TASK", "confidence": 0.9054210186004639}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.911345362663269}]}], "introductionContent": [{"text": "Learning to integrate natural language descriptions with video events is attracting increasing attention in the natural language processing and computer vision communities.", "labels": [], "entities": []}, {"text": "The Grounded Language Learning task aims to map the meaning of natural language expressions to their corresponding referents in videos (e.g., objects, actions, and events) without any dictionary.", "labels": [], "entities": []}, {"text": "Most existing grounded language learning algorithms are either supervised or weakly-supervised.", "labels": [], "entities": []}, {"text": "During the training stage, they assume each video is pre-segmented to chunks of short duration, and each video segment is manually Label the bottle Add 500 mL of DI water to the labeled bottle", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Alignment accuracy (% of video chunks aligned to the correct protocol step) for both manual and automatic  tracking data. LHMM is the existing state-of-the-art generative model. For the variants of latent perceptron (LSP) and  latent structured SVM (LSSVM), \"C\" indicates constrained decoding, and \"H\" indicates hybrid update.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9324852824211121}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.7699321508407593}]}, {"text": " Table 2: An example of an alignment, obtained for a part of a manually tracked video. We notice several incorrect  parses, e.g., the verbs \"mix\" and \"zero\" were not detected correctly.", "labels": [], "entities": []}]}