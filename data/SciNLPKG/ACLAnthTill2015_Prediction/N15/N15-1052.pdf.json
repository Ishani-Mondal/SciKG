{"title": [{"text": "Dialogue focus tracking for zero pronoun resolution", "labels": [], "entities": [{"text": "Dialogue focus tracking", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7650172114372253}, {"text": "zero pronoun resolution", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.6947924693425497}]}], "abstractContent": [{"text": "We take a novel approach to zero pronoun resolution in Chinese: our model explicitly tracks the flow of focus in a discourse.", "labels": [], "entities": [{"text": "zero pronoun resolution", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.689461350440979}]}, {"text": "Our approach, which generalizes to deictic references, is not reliant on the presence of overt noun phrase antecedents to resolve to, and allows us to address the large percentage of \"non-anaphoric\" pronouns filtered out in other approaches.", "labels": [], "entities": []}, {"text": "We furthermore train our model using readily available parallel Chinese/English corpora, allowing for training without hand-annotated data.", "labels": [], "entities": []}, {"text": "Our results demonstrate improvements on two test sets, as well as the usefulness of linguistically motivated features.", "labels": [], "entities": []}], "introductionContent": [{"text": "\"Pro-drop\" languages like Chinese, Japanese and Turkish allow for dropping of pronouns when the referents of those pronouns can be inferred.", "labels": [], "entities": []}, {"text": "English is typically not pro-drop, but is unusual in that regard: two thirds of languages documented in WALS () can be categorized as prodrop.", "labels": [], "entities": []}, {"text": "In such languages, sentences are frequently characterized by \"zero pronouns\": gaps in the sentence which in English would hold an overt pronoun.", "labels": [], "entities": []}, {"text": "In some languages, verbal morphology or clitics elsewhere in the sentence are sufficient to resolve the ambiguity of dropped pronouns; in other languages, there is no overt marking at all in the sentence and the referent of the dropped pronoun must be resolved using pragmatic information.", "labels": [], "entities": []}, {"text": "Our work departs from mainstream work on zero pronoun resolution in that we focus primarily on the resolution of deictic zero pronouns.", "labels": [], "entities": [{"text": "zero pronoun resolution", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.6884879668553671}, {"text": "resolution of deictic zero pronouns", "start_pos": 99, "end_pos": 134, "type": "TASK", "confidence": 0.7574598073959351}]}, {"text": "Unlike an anaphoric zero pronoun (Section 2), whose reference must be specified by a noun phrase occurring previously in the text, a non-anaphoric zero pronoun refers to an entity that is salient from larger units of discourse (such as full sentences or passages) or from the extralinguistic environment (outside of the text altogether).", "labels": [], "entities": []}, {"text": "Although anaphoric zero pronoun resolution has been the focus of most past work (), 50% or fewer of zero pronouns in natural Chinese text are anaphoric (.", "labels": [], "entities": [{"text": "anaphoric zero pronoun resolution", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.5966410711407661}]}, {"text": "Our approach allows for generalization to non-anaphoric pronouns, focusing in particular on deictic non-anaphoric zero pronouns, which refer to salient entities in the environment (such as the speaker, hearer or pragmatically accessible referent) without requiring any introduction in the preceding text.", "labels": [], "entities": []}, {"text": "shows an example conversation in which zero pronouns are frequently used to refer to speaker or listener, and would be translated to English as \"I\" or \"you.\"", "labels": [], "entities": []}, {"text": "We propose a model for resolving deictic zero pronouns that draws inspiration from ideas in Centering Theory (: discourses tend to settle on a particular focus fora time, before switching.", "labels": [], "entities": []}, {"text": "Furthermore, we presume that when a switch happens, there is likely to bean overt cue of this.", "labels": [], "entities": []}, {"text": "For example, in, the initial focus on T is signaled with the overt second person pronoun in the first utterance; the switch of focus to S in the third utterance is also signaled by an overt \"you.\"", "labels": [], "entities": []}, {"text": "However, at that point, the focus remains on S for several utterances until \"The last round.", "labels": [], "entities": []}, {"text": "\" at which point it switches away from the speakers.", "labels": [], "entities": []}, {"text": "It is brought back to S in the last utterance, which can be inferred from the fact that S is the most recent focus that fits the required semantic constraints.", "labels": [], "entities": []}, {"text": "To account for these phenomena, we develop a novel sequential model for zero pronoun resolution that explicitly tracks the conversation focus in a dialogue (Section 3).", "labels": [], "entities": [{"text": "zero pronoun resolution", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.7162394324938456}]}, {"text": "We test, using data from Chinese SMS (\"texting\") dialogues, the hypothesis that our model can predict the identity of pronouns (at a granularity of the person attribute: first, second, or third person-with particular focus on first and second person) based on a variety of features of the utterance context, without reference to a particular antecedent.", "labels": [], "entities": []}, {"text": "In this way, we address a much higher percentage of the zero pronouns found in Chinese texts, and particularly in dialogue.", "labels": [], "entities": []}, {"text": "Our second contribution is to show that one can train a zero pronoun resolution system using supervision coming from English translations of the Chinese text (Section 2.2).", "labels": [], "entities": [{"text": "zero pronoun resolution", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7318758567174276}]}, {"text": "This obviates the need for expensive linguistic annotation of Chinese and allows us to use plentiful parallel data to train our model.", "labels": [], "entities": []}, {"text": "Our results confirm that even though this \"translation as annotation\" process is noisy, it is still possible to learn on large amounts of \"bronze standard\" data.", "labels": [], "entities": [{"text": "translation as annotation\"", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.886644035577774}, {"text": "bronze standard\" data", "start_pos": 139, "end_pos": 160, "type": "DATASET", "confidence": 0.8419322371482849}]}], "datasetContent": [{"text": "Our goal in our experiments is to answer the following questions: 1.", "labels": [], "entities": []}, {"text": "How well does the bronze-standard annotation capture the underlying truth?", "labels": [], "entities": []}, {"text": "2. Is our model able to leverage both dialogue structure and semantic content to accurately resolve pronouns?", "labels": [], "entities": []}, {"text": "(Section 4.3) 3.", "labels": [], "entities": []}, {"text": "How important are the different components in our model in making effective predictions?", "labels": [], "entities": []}, {"text": "(Section 4.4) In the following sections, we describe the experiments we perform aimed at answering these questions.", "labels": [], "entities": []}, {"text": "First, we describe the data we use for experimentation.", "labels": [], "entities": []}, {"text": "For training our focus-tracking model, we use Chinese-English parallel data from the SMS/chat domain available as part of training data used in the Machine Translation task under the DARPA BOLT project.", "labels": [], "entities": [{"text": "Machine Translation task", "start_pos": 148, "end_pos": 172, "type": "TASK", "confidence": 0.8727450768152872}, {"text": "DARPA BOLT project", "start_pos": 183, "end_pos": 201, "type": "DATASET", "confidence": 0.5799102584520975}]}, {"text": "The training data consisted of 117k sentences.", "labels": [], "entities": []}, {"text": "We test our model on heldout SMS/Chat data consisting of 1152 sentences (hand-annotated,  as described in Section 4.2), and on telephone conversation data from the OntoNotes corpus (), consisting of 5000 sentences.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 164, "end_pos": 180, "type": "DATASET", "confidence": 0.8975021243095398}]}, {"text": "Full data statistics are provided in.", "labels": [], "entities": []}, {"text": "We perform zero pronoun identification using the method of), which automatically recovers empty categories corresponding to dropped pronouns, integrating these empty categories into syntactic parses.", "labels": [], "entities": [{"text": "zero pronoun identification", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.7318861285845438}]}, {"text": "Syntactic parses were obtained with the Berkeley parser (.", "labels": [], "entities": []}, {"text": "These parses were then used to split the Chinese utterances into single-clause units, based on IP and CP clausal nodes.", "labels": [], "entities": []}, {"text": "These clauses were aligned with clauses in the English translation, which were used to determine the identity of the clausal subject, for extracting the 1v, 2v, . .", "labels": [], "entities": []}, {"text": "For our machine learning systems, we use Vowpal Wabbit () with default hyperparameter settings.", "labels": [], "entities": []}, {"text": "We train on 75% of the training data and retain 25% as development data on which to perform early stopping.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.844209611415863}]}, {"text": "We run 20 iterations by default and take the parameters with best development performance based on sequence labeling accuracy.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.4858611822128296}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.5994321703910828}]}], "tableCaptions": [{"text": " Table 2: Dataset statistics; numbers are for the Chi- nese side of the data. English has 25% more tokens and  roughly as many types.", "labels": [], "entities": []}, {"text": " Table 3: Bronze vs Gold labels", "labels": [], "entities": []}, {"text": " Table 5: Summary of results for different comparator  models against the gold standard labels from SMS data  (left) and OntoNotes (right).", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8239012360572815}, {"text": "SMS data", "start_pos": 100, "end_pos": 108, "type": "DATASET", "confidence": 0.8076547682285309}]}, {"text": " Table 4: Results across different pronoun categories for (top) subject continuation and (bottom) our full model.", "labels": [], "entities": [{"text": "subject continuation", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7363094091415405}]}, {"text": " Table 6:  Summary of results for feature ablation  against the gold standard labels from SMS data (left) and  OntoNotes (right).", "labels": [], "entities": [{"text": "SMS data", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.7818426787853241}]}, {"text": " Table 6. We see in this table that for the SMS  data, the Verb feature creates the greatest improve- ment over the Minimal Model, followed by Bag of", "labels": [], "entities": [{"text": "SMS  data", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.7392357587814331}]}]}