{"title": [{"text": "IDEST: Learning a Distributed Representation for Event Patterns", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes IDEST, anew method for learning paraphrases of event patterns.", "labels": [], "entities": []}, {"text": "It is based on anew neural network architecture that only relies on the weak supervision signal that comes from the news published on the same day and mention the same real-world entities.", "labels": [], "entities": []}, {"text": "It can generalize across extractions from different dates to produce a robust paraphrase model for event patterns that can also capture meaningful representations for rare patterns.", "labels": [], "entities": []}, {"text": "We compare it with two state-of-the-art systems and show that it can attain comparable quality when trained on a small dataset.", "labels": [], "entities": []}, {"text": "Its generalization capabilities also allow it to leverage much more data, leading to substantial quality improvements.", "labels": [], "entities": [{"text": "generalization", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9604730010032654}]}], "introductionContent": [{"text": "Most Open Information Extraction (Open-IE) systems ( extract textual relational patterns between entities automatically) and optionally organize them into paraphrase clusters.", "labels": [], "entities": [{"text": "Open Information Extraction (Open-IE)", "start_pos": 5, "end_pos": 42, "type": "TASK", "confidence": 0.7341388861338297}]}, {"text": "These pattern clusters have been found to be useful for Question Answering) and relation extraction), among other tasks.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8339783251285553}, {"text": "relation extraction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8668567836284637}]}, {"text": "A related Open-IE problem is that of automatically extracting and paraphrasing event patterns: those that describe changes in the state or attribute values of one or several entities.", "labels": [], "entities": []}, {"text": "An existing approach lo learn paraphrases of event patterns is to build on the following weak supervision signal: * Work performed during an internship at Google news articles that were published on the same day and mention the same entities should contain good paraphrase candidates.", "labels": [], "entities": []}, {"text": "Two state-of-the-art event paraphrasing systems that are based on this assumption are NEWSSPIKE and HEADY ().", "labels": [], "entities": [{"text": "NEWSSPIKE", "start_pos": 86, "end_pos": 95, "type": "DATASET", "confidence": 0.6499621868133545}]}, {"text": "These two systems have a lot in common, yet they have never been compared with each other.", "labels": [], "entities": []}, {"text": "They have specific weak and strong points, and there are many ways in which they are substantially different: \u2022 Scope of generalization.", "labels": [], "entities": []}, {"text": "In NEWSSPIKE the paraphrase clusters are learned separately for each publication day and entity set, and the system cannot generalize across events of the same type involving different entities occurring on the same or on different days.", "labels": [], "entities": [{"text": "NEWSSPIKE", "start_pos": 3, "end_pos": 12, "type": "DATASET", "confidence": 0.8990458846092224}]}, {"text": "For example, if the event verbs has married and wed appear in news about two entities A and B marrying, and has married and tied the knot with appear in news involving two different entities C and D, NEWSSPIKE is notable to infer that wed and tied the knot with are also paraphrases, unless a post-processing is done.", "labels": [], "entities": []}, {"text": "HEADY overcomes this limitation thanks to a global model that learns event representations across different days and sets of entities.", "labels": [], "entities": []}, {"text": "However, the global nature of the learning problem can incur into other drawbacks.", "labels": [], "entities": []}, {"text": "First, training a global model is more costly and more difficult to parallelize.", "labels": [], "entities": []}, {"text": "Second, relatively frequent patterns that erroneously co-occur with other patterns may have a negative impact on the final models, potentially resulting in noisier clusters.", "labels": [], "entities": []}, {"text": "Lastly, low-frequency patterns are likely to be discarded as noisy in the final model.", "labels": [], "entities": []}, {"text": "Overall, HEADY is better at capturing paraphrases from the head of the pattern distribution, and is likely to ignore most of the long tail where useful paraphrases can still be found.", "labels": [], "entities": []}, {"text": "We already mentioned that the two systems share a common underlying assumption, i.e., that good paraphrase candidates can be found by looking at news published on the same day and mentioning the same entities.", "labels": [], "entities": []}, {"text": "On top of this, NEWSSPIKE also assumes that better paraphrases are reported around spiky entities, verb tenses may not differ, there is one event mention per discourse, and others.", "labels": [], "entities": [{"text": "NEWSSPIKE", "start_pos": 16, "end_pos": 25, "type": "DATASET", "confidence": 0.5277612805366516}]}, {"text": "These restrictions are not enforced by HEADY, where the common assumption is indeed even relaxed across days and entity sets.", "labels": [], "entities": []}, {"text": "NEWSSPIKE requires handannotated data to train the parameters of a supervised model that combines the different heuristics, whereas HEADY does not need annotated data.", "labels": [], "entities": [{"text": "NEWSSPIKE", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.93907231092453}]}, {"text": "This paper describes IDEST, anew method for learning paraphrases of event patterns that is designed to combine the advantages of these two systems and compensate for their weaknesses.", "labels": [], "entities": []}, {"text": "It is based on anew neural-network architecture that, like HEADY, only relies on the weak supervision signal that comes from the news published on the same day, requiring no additional heuristics or training data.", "labels": [], "entities": [{"text": "HEADY", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.7993102669715881}]}, {"text": "Unlike NEWSSPIKE, it can generalize across different sets of extracted patterns, and each event pattern is mapped into a low-dimensional embedding space.", "labels": [], "entities": [{"text": "NEWSSPIKE", "start_pos": 7, "end_pos": 16, "type": "DATASET", "confidence": 0.8663915991783142}]}, {"text": "This allows us to define a neighborhood around a pattern to find the ones that are closer in meaning.", "labels": [], "entities": []}, {"text": "IDEST produces a robust global model that can also capture meaningful representations for rare patterns, thus overcoming one of HEADY's main limitations.", "labels": [], "entities": [{"text": "IDEST", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8711247444152832}]}, {"text": "Our evaluation of the potential trade-off between local and global paraphrase models shows that comparably good results to NEWSSPIKE can be attained without relying on supervised training.", "labels": [], "entities": [{"text": "NEWSSPIKE", "start_pos": 123, "end_pos": 132, "type": "DATASET", "confidence": 0.7613948583602905}]}, {"text": "At the same time, the ability of IDEST to produce a global model allows it to benefit from a much larger news corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "In previous work we can find three different pattern extraction methods from a sentence: \u2022 Heuristic-based, where a number of handwritten rules or regular expressions based on part-of-speech tags or dependency trees are used to select the most likely pattern from the source sentence).", "labels": [], "entities": [{"text": "pattern extraction", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7683587670326233}]}, {"text": "\u2022 Sentence compression, which takes as input the original sentence and the entities of interest and produces a shorter version of the sentence that still includes the entities ().", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 2, "end_pos": 22, "type": "TASK", "confidence": 0.8878907561302185}]}, {"text": "\u2022 Memory-based, that tries to find the shortest reduction of the sentence that still includes the entities, with the constraint that its lexicosyntactic structure has been seen previously as a full sentence in a high-quality corpus ().", "labels": [], "entities": []}, {"text": "It is important to note that the final purpose of the system may impact the decision of which extraction method to choose.", "labels": [], "entities": []}, {"text": "use the event models to generate headlines, and using the memory-based method resulted in more grammatical headlines at the cost of coverage.", "labels": [], "entities": []}, {"text": "If the purpose of the patterns is information extraction for knowledge base population, then the importance of having well-formed complete sentences as patterns becomes less obvious, and higher coverage methods become more attractive.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.7556104362010956}]}, {"text": "For these reasons, in this paper we focus on the first two approaches, which are very well-established and can produce high-coverage output.", "labels": [], "entities": []}, {"text": "More specifically, we use REVERB extractions and a statistical compression model trained on (sentence, compression) pairs implemented after.", "labels": [], "entities": [{"text": "REVERB extractions", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9131591618061066}]}, {"text": "This section opens with a quantitative look at the clusterings obtained with the different methods to understand their implications with respect to the distribution of event clusters and their internal diversity.", "labels": [], "entities": []}, {"text": "In 5.2, we will complement these figures with the results of a manual quality evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the manual evaluation, averaged over  all the clusters produced by each configuration listed. Ex- traction algorithms: ReV = REVERB; Comp = Com- pression; Data sets: NS = NewsSpike URLs; All = news  2008-2014. Quality metrics: Size: average cluster size;  Coh: cohesiveness; Rel: relatedness; Read: readability.  Statistical significance: a : better than HEADY; b : bet- ter than NEWSSPIKE; c : better than IDEST-ReV-NS; d :  better than IDEST-Comp-NS;  *  : better than all others; ! :  worse than all others (0.95 confidence intervals, bootstrap  resampling).", "labels": [], "entities": [{"text": "REVERB", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9925026893615723}]}]}