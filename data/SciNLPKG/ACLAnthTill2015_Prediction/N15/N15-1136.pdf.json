{"title": [{"text": "Clustering Sentences with Density Peaks for Multi-document Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.7854437232017517}]}], "abstractContent": [{"text": "Multi-document Summarization (MDS) is of great value to many real world applications.", "labels": [], "entities": [{"text": "Multi-document Summarization (MDS)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8691706180572509}]}, {"text": "Many scoring models are proposed to select appropriate sentences from documents to form the summary, in which the clustering-based methods are popular.", "labels": [], "entities": []}, {"text": "In this work, we propose a unified sentence scoring model which measures representativeness and diversity at the same time.", "labels": [], "entities": []}, {"text": "Experimental results on DUC04 demonstrate that our MDS method outper-forms the DUC04 best method and the existing clustering-based methods, and it yields close results compared to the state-of-the-art generic MDS methods.", "labels": [], "entities": [{"text": "DUC04", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.9435088634490967}, {"text": "DUC04", "start_pos": 79, "end_pos": 84, "type": "DATASET", "confidence": 0.9096288084983826}]}, {"text": "Advantages of the proposed MDS method are twofold: (1) The density peaks clustering algorithm is firstly adopted, which is effective and fast.", "labels": [], "entities": []}, {"text": "(2) No external resources such as Wordnet and Wikipedia or complex language parsing algorithms is used, making reproduction and deployment very easy in real environment.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9527893662452698}, {"text": "language parsing", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.751263439655304}]}], "introductionContent": [{"text": "Document summarization is the process of generating a generic or topic-focused summary by reducing documents in size while retaining the main characteristics of original documents().", "labels": [], "entities": [{"text": "Document summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8819378912448883}]}, {"text": "The summary maybe formed in a variety of different ways, which are generally categorized as abstractive and extractive.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of generic multidocument summarization (MDS).", "labels": [], "entities": [{"text": "generic multidocument summarization (MDS)", "start_pos": 41, "end_pos": 82, "type": "TASK", "confidence": 0.7794176091750463}]}, {"text": "An effective summarization method should properly consider the following three important issues: representativeness, diversity, conciseness.", "labels": [], "entities": [{"text": "summarization", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9715761542320251}]}, {"text": "Many scoring models are proposed to select appropriate sentences from documents to form the summary, in which the clustering-based methods are popular.", "labels": [], "entities": []}, {"text": "Some researchers address the sentence scoring task in an isolation manner( (i.e., clustering and ranking are two independent steps).", "labels": [], "entities": [{"text": "sentence scoring task", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7989850838979086}]}, {"text": "Others handle the sentence ranking task in a mutuality manner) (i.e., clustering improves ranking and vice versa).", "labels": [], "entities": [{"text": "sentence ranking task", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.7621679802735647}]}, {"text": "Two drawbacks of the existing clustering-based methods are worth noting.", "labels": [], "entities": []}, {"text": "First, extra algorithms are required to determine the number of clusters beforehand.", "labels": [], "entities": []}, {"text": "Second, models are required to rank or score sentences within and across the clusters after clustering.", "labels": [], "entities": []}, {"text": "Our proposed MDS method is inspired by the recent work on density peaks clustering (DPC) algorithm published on Science (.", "labels": [], "entities": [{"text": "density peaks clustering (DPC)", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.7817404667536417}]}, {"text": "The underlying assumption is that cluster centers are characterized by a higher density than their neighbors and by a relatively large distance from points with higher densities.", "labels": [], "entities": []}, {"text": "In this paper, we adapt the density peaks clustering algorithm() to simultaneously cluster sentences and rank them in the mutuality manner.", "labels": [], "entities": []}, {"text": "Thanks to the density peaks clustering algorithm, we do not need to set the number of clusters and do not need a post-processing module to reduce redundancy.", "labels": [], "entities": []}, {"text": "From the view of summarization task, DPC is superior to other clustering methods because it cannot only find the best cluster centers, but also do rank all data points, including cluster centers, within and across clusters at the same time.", "labels": [], "entities": [{"text": "summarization", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.9860683679580688}]}, {"text": "Experimental results on the DUC2004 demonstrate that our method outperforms the best method in DUC04 and yields close results compared to the state-of-the-art unsupervised MDS methods.", "labels": [], "entities": [{"text": "DUC2004", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9678835272789001}, {"text": "DUC04", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.9552456140518188}]}, {"text": "The major contributions of this work are twofold: Firstly, a unified sentence scoring model is proposed to consider representativeness, diversity and conciseness at the same time.", "labels": [], "entities": []}, {"text": "Secondly, the density peaks clustering algorithm is first applied in the MDS task.", "labels": [], "entities": [{"text": "MDS task", "start_pos": 73, "end_pos": 81, "type": "TASK", "confidence": 0.5701152384281158}]}, {"text": "We further revise the clustering algorithm to address the summary length constraint.", "labels": [], "entities": [{"text": "summary length constraint", "start_pos": 58, "end_pos": 83, "type": "METRIC", "confidence": 0.7182499965031942}]}], "datasetContent": [{"text": "Two experiments are reported in this paper: comparing the MDS methods and tuning the density threshold.", "labels": [], "entities": []}, {"text": "For both experiments, we use the DUC2004(task 2) 1 dataset, which is annotated manually for generic MDS.", "labels": [], "entities": [{"text": "DUC2004(task 2) 1 dataset", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.77765440089362}]}, {"text": "We adopted ROUGE) version 1.5.5 2 and take F-measure of ROUGE-1, ROUGE-2 and ROUGE-SU as our evaluation metrics.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9959225654602051}, {"text": "ROUGE-1", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.8102294206619263}]}, {"text": "In pre-processing, we use the Porter Stemmer 3 in sentence segmenting, stop-word removing and word stemming.", "labels": [], "entities": [{"text": "sentence segmenting", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7420507073402405}, {"text": "stop-word removing", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7693809568881989}, {"text": "word stemming", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.731407880783081}]}, {"text": "Note that our MDS method is purely unsupervised, and uses no training or development data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results of the MDS methods on  DUC04.  System  ROUGE-1 ROUGE-2 ROUGE-SU  DUC04Best  0.38224  0.09216  0.13233  Centroid  0.36728  0.07379  0.12511  ClusterHITS  0.36463  0.07632  - SNMF  - 0.08400  0.12660  RTC  0.37475  0.08973  - FGB  0.38724  0.08115  0.12957  AASum  0.41150  0.09340  0.13760  LexRank  0.37842  0.08572  0.13097  CSFO  0.38900  - - WCS  0.39872  0.09611  0.13532  DPSC  0.39075  0.09376  0.14000", "labels": [], "entities": [{"text": "FGB  0.38724  0.08115  0.12957  AASum  0.41150  0.09340  0.13760  LexRank  0.37842  0.08572  0.13097  CSFO  0.38900  - - WCS  0.39872  0.09611  0.13532  DPSC  0.39075  0.09376  0.14000", "start_pos": 255, "end_pos": 439, "type": "DATASET", "confidence": 0.7816718369722366}]}]}