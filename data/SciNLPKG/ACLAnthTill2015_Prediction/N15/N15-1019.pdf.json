{"title": [{"text": "Inferring latent attributes of Twitter users with label regularization", "labels": [], "entities": []}], "abstractContent": [{"text": "Inferring latent attributes of online users has many applications in public health, politics, and marketing.", "labels": [], "entities": []}, {"text": "Most existing approaches rely on supervised learning algorithms, which require manual data annotation and therefore are costly to develop and adapt overtime.", "labels": [], "entities": []}, {"text": "In this paper, we propose a lightly supervised approach based on label regularization to infer the age, ethnicity, and political orientation of Twitter users.", "labels": [], "entities": [{"text": "label regularization", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7057606875896454}]}, {"text": "Our approach learns from a heterogeneous collection of soft constraints derived from Census demographics, trends in baby names, and Twitter accounts that are em-blematic of class labels.", "labels": [], "entities": []}, {"text": "To counteract the im-precision of such constraints, we compare several constraint selection algorithms that optimize classification accuracy on a tuning set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.8399972319602966}]}, {"text": "We find that using no user-annotated data, our approach is within 2% of a fully supervised baseline for three of four tasks.", "labels": [], "entities": []}, {"text": "Using a small set of labeled data for tuning further improves accuracy on all tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9988706707954407}]}], "introductionContent": [{"text": "Data annotation is a key bottleneck in applying supervised machine learning to language processing problems.", "labels": [], "entities": [{"text": "Data annotation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7653436362743378}]}, {"text": "This is especially problematic in streaming settings such as social media, where models quickly become dated as new linguistic patterns emerge.", "labels": [], "entities": []}, {"text": "An attractive alternative is lightly supervised learning (; Jin and.", "labels": [], "entities": []}, {"text": "In this approach, classifiers are trained from a set of domain-specific soft constraints, rather than individually labeled instances.", "labels": [], "entities": []}, {"text": "For example, label regularization () uses prior knowledge of the expected label distribution to fit a model from large pools of unlabeled instances.", "labels": [], "entities": [{"text": "label regularization", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7847227454185486}]}, {"text": "Similarly, annotating features with their expected class frequency has proven to bean efficient way of bootstrapping from domain knowledge (.", "labels": [], "entities": []}, {"text": "In this paper we use lightly supervised learning to infer the age, ethnicity, and political orientation of Twitter users.", "labels": [], "entities": []}, {"text": "Lightly supervised learning provides a natural method for incorporating the rich, declarative constraints available in social media.", "labels": [], "entities": []}, {"text": "Our approach pairs unlabeled Twitter data with constraints from county demographics, trends in first names, and exemplar Twitter accounts strongly associated with a class label.", "labels": [], "entities": []}, {"text": "Prior applications of label regularization use a small number of highly-accurate constraints; for example, use a single constraint that is the true label proportions of an unlabeled dataset, and use cross-lingual constraints from aligned text.", "labels": [], "entities": [{"text": "label regularization", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.7427546083927155}]}, {"text": "In contrast, we use hundreds of constraints that are heterogeneous, overlapping, and noisy.", "labels": [], "entities": []}, {"text": "For example, we constrain the predicted attributes of users from a county to match those collected by the Census, despite the known non-representativeness of Twitter users).", "labels": [], "entities": []}, {"text": "Furthermore, users from that county who list first names in their profile have additional constraints imposed upon them, which may conflict with the county constraints.", "labels": [], "entities": []}, {"text": "To deal with such noisy constraints, we explore forward selection algorithms that choose from hundreds of soft constraints to optimize accuracy on a tuning set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9980736970901489}]}, {"text": "We find that this approach is competitive with a fully supervised approach, with the added advantage of being less reliant on labeled data and therefore easier to update overtime.", "labels": [], "entities": []}, {"text": "Our primary research questions and answers are as follows: RQ1.", "labels": [], "entities": [{"text": "RQ1", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.5827957987785339}]}, {"text": "What effect do noisy constraints have on label regularization?", "labels": [], "entities": [{"text": "label regularization", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7564231753349304}]}, {"text": "We find that simply using all constraints, ignoring noise and overlap, results in surprisingly high accuracy, within 2% of a fully-supervised approach on three of four tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9990566372871399}]}, {"text": "For age classification, the constraint noise appears to substantially degrade accuracy.", "labels": [], "entities": [{"text": "age classification", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.634512722492218}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9983556866645813}]}, {"text": "How can we select the most useful constraints?", "labels": [], "entities": []}, {"text": "Using a small tuning set, we find that our forward selection algorithms improve label regularization accuracy while using fewer than 10% of the available constraints.", "labels": [], "entities": [{"text": "label regularization", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.7395855188369751}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.905888020992279}]}, {"text": "Constraint selection improves age classification accuracy by nearly 18% (absolute).", "labels": [], "entities": [{"text": "age classification", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.6424272954463959}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9804478883743286}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy on the testing set. all-const does  no constraint selection; imp-greedy selects con- straints to maximize accuracy on the tuning set using  the Improved-greedy algorithm.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9947988986968994}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9956479668617249}]}, {"text": " Table 1.  For all-const, the follower constraints (fol) outper- form the county constraints (cnt) for all tasks, while  the name constraint (which only applies to age), falls  between the two. Including both cnt and fol im- proves accuracy on two of the four tasks. These  trends change somewhat for imp-greedy. The cnt  constraints are superior for two tasks, while fol are  superior for the other two. The nam constraints  again fall between the two. Unlike for all-const,", "labels": [], "entities": [{"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9987866282463074}]}]}