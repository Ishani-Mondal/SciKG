{"title": [{"text": "Multiview LSA: Representation Learning via Generalized CCA", "labels": [], "entities": [{"text": "Multiview LSA", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.495673269033432}, {"text": "Representation Learning", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.9307940602302551}]}], "abstractContent": [{"text": "Multiview LSA (MVLSA) is a generalization of Latent Semantic Analysis (LSA) that supports the fusion of arbitrary views of data and relies on Generalized Canonical Correlation Analysis (GCCA).", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA)", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.752767284711202}]}, {"text": "We present an algorithm for fast approximate computation of GCCA, which when coupled with methods for handling missing values, is general enough to approximate some recent algorithms for inducing vector representations of words.", "labels": [], "entities": [{"text": "GCCA", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.6720458269119263}]}, {"text": "Experiments across a comprehensive collection of test-sets show our approach to be competitive with the state of the art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Winograd wrote that: \"Two sentences are paraphrases if they produce the same representation in the internal formalism for meaning\".", "labels": [], "entities": []}, {"text": "This intuition is made soft in vector-space models, where we say that expressions in language are paraphrases if their representations are close under some distance measure.", "labels": [], "entities": []}, {"text": "One of the earliest linguistic vector space models was Latent Semantic Analysis (LSA).", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA)", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7675741116205851}]}, {"text": "LSA has been successfully used for Information Retrieval but it is limited in its reliance on a single matrix, or view, of term co-occurrences.", "labels": [], "entities": [{"text": "LSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7057555317878723}, {"text": "Information Retrieval", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.8118027746677399}]}, {"text": "Here we address the single-view limitation of LSA by demonstrating that the framework of Generalized Canonical Correlation Analysis (GCCA) can be used to perform Multiview LSA (MVLSA).", "labels": [], "entities": []}, {"text": "This approach allows for the use of an arbitrary number of views in the induction process, including embeddings induced using other algorithms.", "labels": [], "entities": []}, {"text": "We also present a fast approximate method for performing GCCA and approximately recover the objective of () while accounting for missing values.", "labels": [], "entities": [{"text": "GCCA", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.5452748537063599}]}, {"text": "Our experiments show that MVLSA is competitive with state of the art approached for inducing vector representations of words and phrases.", "labels": [], "entities": []}, {"text": "As a methodological aside, we discuss the (in-)significance of conclusions being drawn from comparisons done on small sized datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We wanted to answer the following questions through our experiments: (1) How do hyperparameters affect performance?", "labels": [], "entities": []}, {"text": "(2) What is the contribution of the multiple sources of data to performance?", "labels": [], "entities": []}, {"text": "(3) How does the performance of MVLSA compare with other methods?", "labels": [], "entities": []}, {"text": "For brevity we show tuning runs only on the larger datasets.", "labels": [], "entities": []}, {"text": "We also highlight the top performing configurations in bold using the small threshold values in column \u03c3 0.09 0.05 of.", "labels": [], "entities": []}, {"text": "Effect of Hyper-parameters f j : We modeled the preprocessing function f j as the composition of two functions, f j = n j \u2022 t j . n j represents nonlinear preprocessing that is usually employed with LSA.", "labels": [], "entities": []}, {"text": "We experimented by setting n j to be: identity; logarithm of count plus one; and the fourth root of the count.", "labels": [], "entities": []}, {"text": "t j represents the truncation of columns and can be interpreted as a type of regularization of the raw counts themselves through which we prune away the noisy contexts.", "labels": [], "entities": []}, {"text": "Decrease int j also reduces the influence of views that have a large number of context columns and emphasizes the sparser views.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: List of test datasets used. The columns headed \u03c3 r  p0 contain MRDS values. The rows for accuracy based test  sets contain \u03c3 p0 which does not depend on r. See  \u00a7 4.1 for details.", "labels": [], "entities": [{"text": "MRDS", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.8135559558868408}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9879776239395142}]}, {"text": " Table 3: Performance versus n j , the non linear process- ing of cooccurrence counts. t = 200K, m = 500, v =  16, k = 300. All the top configurations determined by  \u03c3 0.09  0.05 are in bold font.", "labels": [], "entities": []}, {"text": " Table 4: Performance versus the truncation threshold, t,  of raw cooccurrence counts. We used n j = Count", "labels": [], "entities": []}, {"text": " Table 5: Performance versus m, the number of left singu- lar vectors extracted from raw cooccurrence counts. We  set n j = Count", "labels": [], "entities": []}, {"text": " Table 6: Performance versus k, the final dimensionality  of the embeddings. We set m = 300 and other settings  were same as", "labels": [], "entities": []}, {"text": " Table 7: Performance versus minimum view support  threshold v, The other hyperparameters were n j =  Count", "labels": [], "entities": []}, {"text": " Table 8: Performance versus views removed from the multiview GCCA procedure. !Framenet means that the view  containing counts derived from Frame semantic dataset was removed. Other columns are named similarly. The other  hyperparameters were n j = Count", "labels": [], "entities": [{"text": "Frame semantic dataset", "start_pos": 140, "end_pos": 162, "type": "DATASET", "confidence": 0.9032033681869507}]}, {"text": " Table 9: Comparison of Multiview LSA against Glove and WSG(Word2Vec Skip Gram). Using \u03c3 0.9  0.05 as the threshold  we highlighted the top performing systems in bold font.  \u2020 marks significant increments in performance due to use of  multiple views in the Gain columns. The r s columns demonstrate that GCCA increased pearson correlation.", "labels": [], "entities": [{"text": "Word2Vec Skip Gram", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.9400842388470968}, {"text": "GCCA", "start_pos": 304, "end_pos": 308, "type": "METRIC", "confidence": 0.5232588648796082}, {"text": "pearson correlation", "start_pos": 319, "end_pos": 338, "type": "METRIC", "confidence": 0.8605987131595612}]}]}