{"title": [{"text": "Development of the Multilingual Semantic Annotation System", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper reports on our research to generate multilingual semantic lexical resources and develop multilingual semantic annotation software, which assigns each word in running text to a semantic category based on a lexical semantic classification scheme.", "labels": [], "entities": []}, {"text": "Such tools have an important role in developing intelligent multilingual NLP, text mining and ICT systems.", "labels": [], "entities": [{"text": "text mining", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.8053795099258423}]}, {"text": "In this work, we aim to extend an existing English semantic annotation tool to cover a range of languages, namely Italian, Chinese and Brazilian Portuguese, by boot-strapping new semantic lexical resources via automatically translating existing English semantic lexicons into these languages.", "labels": [], "entities": []}, {"text": "We used a set of bilingual dictionaries and word lists for this purpose.", "labels": [], "entities": []}, {"text": "In our experiment, with minor manual improvement of the automatically generated semantic lexicons, the prototype tools based on the new lexicons achieved an average lexical coverage of 79.86% and an average annotation precision of 71.42% (if only precise annotations are considered) or 84.64% (if partially correct annotations are included) on the three languages.", "labels": [], "entities": [{"text": "precision", "start_pos": 218, "end_pos": 227, "type": "METRIC", "confidence": 0.6582732200622559}]}, {"text": "Our experiment demonstrates that it is feasible to rapidly develop prototype semantic annotation tools for new languages by automatically boot-strapping new semantic lexicons based on existing ones.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we report on an experiment to develop prototype semantic annotation tools for Italian, Chinese and Brazilian Portuguese based on an existing English annotation tool.", "labels": [], "entities": []}, {"text": "Over the last twenty years, semantic lexical resources and semantic annotation tools, such as EuroWordNet) and USAS (), have played an important role in developing intelligent NLP and HLT systems.", "labels": [], "entities": [{"text": "EuroWordNet", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9840673208236694}, {"text": "USAS", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.8797940015792847}]}, {"text": "Various applications of semantic annotation systems and annotated corpus resources have been reported, including empirical language studies at the semantic level ( and studies in information technology among others.", "labels": [], "entities": []}, {"text": "While various semantic annotation tools are available for monolingual analysis, particularly for English, there are few such systems that can carryout semantic analysis of multiple languages with a unified semantic annotation scheme.", "labels": [], "entities": []}, {"text": "We aim to address this issue by extending an existing English semantic annotation tool () to cover a range of languages.", "labels": [], "entities": []}, {"text": "The USAS semantic annotation tool mentioned above adopts a lexical semantic classification scheme derived from Tom McArthur's Longman Lexicon of Contemporary English, which consists of 21 main discourse fields and 232 sub-fields, such as \"social actions, states and processes\" and \"emotion\" etc.", "labels": [], "entities": [{"text": "USAS", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8976280689239502}, {"text": "Longman Lexicon of Contemporary English", "start_pos": 126, "end_pos": 165, "type": "DATASET", "confidence": 0.9087469458580018}]}, {"text": "It also uses a set of auxiliary codes, such as m/f (male/female), +/-(positive/negative) etc.", "labels": [], "entities": []}, {"text": "For example, it tags \"happy\" and \"sad\" with \"E4.1+\" and \"E4.1-\" respectively, indicating positive and negative sentiment.", "labels": [], "entities": []}, {"text": "It also identifies many types of multi-word expressions, such as phrasal verbs, noun phrases, named entities and true non-compositional idioms, and annotates them with single semantic tags since this is highly significant for identifying contextual meaning.", "labels": [], "entities": []}, {"text": "Recent applications of the USAS tagger include analysis of literary language, the language of psychopaths) and scientific deception).", "labels": [], "entities": [{"text": "USAS tagger", "start_pos": 27, "end_pos": 38, "type": "DATASET", "confidence": 0.8938175737857819}, {"text": "analysis of literary language", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.8344904780387878}]}, {"text": "There would be obvious benefits if such a semantic tool could cover a wide range of languages.", "labels": [], "entities": []}, {"text": "Efforts have been made to port the existing semantic annotation system to other languages (Finnish and Russian) (), so a prototype software framework could be used.", "labels": [], "entities": []}, {"text": "However, manually developing semantic lexical resources for new languages from scratch is a time consuming task.", "labels": [], "entities": []}, {"text": "In this experiment, we examine the feasibility of rapidly bootstrapping semantic lexical resources for new languages by automatically translating existing English semantic lexicons using bilingual dictionaries.", "labels": [], "entities": []}, {"text": "We developed prototype semantic annotation tools for Italian, Chinese and Brazilian Portuguese based on automatically generated semantic lexicons.", "labels": [], "entities": []}, {"text": "Our evaluation of the tools shows that it is feasible to rapidly develop prototype semantic tools via the aforementioned automatic method, which can be improved and refined manually to achieve a high performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following the initial manual evaluation of the prototype semantic taggers described in section 3, we then carried out larger scale automatic evaluations using a set of sample corpora.", "labels": [], "entities": []}, {"text": "We conducted two complementary types of evaluations: lexical coverage and annotation precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.863268256187439}]}, {"text": "The lexical coverage is a particularly interesting metric for our evaluation, as we expect this is where an automatic approach can make significant contribution to the development of annotation systems.", "labels": [], "entities": []}, {"text": "On the other hand, high annotation precision normally entails manual improvement of the lexical resources or a period of training on manually tagged corpora.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.969962477684021}]}, {"text": "For the lexical coverage evaluation, three reference corpora were chosen: PAIS\u00c0 Italian corpus), LCMC Corpus (Lancaster Corpus of Mandarin Chinese) () and Lacio-Ref Portuguese corpus (.", "labels": [], "entities": [{"text": "PAIS\u00c0 Italian corpus", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.7737513979276022}, {"text": "LCMC Corpus (Lancaster Corpus of Mandarin Chinese)", "start_pos": 97, "end_pos": 147, "type": "DATASET", "confidence": 0.9502047830157809}]}, {"text": "Because PAIS\u00c0 and Lacio-Ref corpora are too large for our purpose, we extracted subsections of about 1.5 million Italian words and 1.7 million Portuguese words from them.", "labels": [], "entities": [{"text": "PAIS\u00c0", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.8946790099143982}]}, {"text": "For the evaluation, we annotated the corpus data using the annotation tools of the corresponding target languages, and examined what percentage of the words were assigned with semantic tags.", "labels": [], "entities": []}, {"text": "Punctuation marks were excluded in this evaluation process.", "labels": [], "entities": [{"text": "Punctuation", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9512200355529785}]}, {"text": "shows the statistics of the evaluation for each language.", "labels": [], "entities": []}, {"text": "As shown in the table, the annotation tools achieved an average lexical coverage of 79.86% over the three languages, with Italian having the highest coverage of 85.53% and Portuguese the lowest coverage of 73.40%.", "labels": [], "entities": []}, {"text": "Due to the different types of data in the three sample corpora, this result is not conclusive.", "labels": [], "entities": []}, {"text": "Homogeneous corpus data from all of the three languages will be needed to make more reliable comparison of the lexical coverage.", "labels": [], "entities": []}, {"text": "Considering that the tools were built based on only three bilingual lexical resources over a short period of time, such lexical coverage is encouraging.", "labels": [], "entities": []}, {"text": "This result also demonstrates that, if sufficiently large bilingual lexicons become available; our approach can potentially achieve high lexical coverage.", "labels": [], "entities": []}, {"text": "Next we conducted an evaluation of the precision of the prototype tools.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9989583492279053}]}, {"text": "We randomly selected sample texts for each language as follows.", "labels": [], "entities": []}, {"text": "Italian sample texts were selected from domains of press, contemporary literature and blogs; Chinese sample texts from press, reviews and fiction; Portuguese sample texts from press and fiction.", "labels": [], "entities": []}, {"text": "In the evaluation, we annotated the sample texts using the prototype annotation tools and manually checked the precision among the annotated words.", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9992944002151489}]}, {"text": "We used two metrics: correctly tagged and partially cor- rectly tagged.", "labels": [], "entities": []}, {"text": "With the current tools, a word can be assigned with multiple candidate semantic tags.", "labels": [], "entities": []}, {"text": "The first evaluation metric refers to the cases where the first candidate tag is correct, whereas the other metric refers to the cases where the other tags in the list are corrector closely related to the true word sense.", "labels": [], "entities": []}, {"text": "shows the statistics of the evaluation.", "labels": [], "entities": []}, {"text": "Lan  As shown in the table, the Portuguese tagger obtained the highest first-tag precision (82.58%), while the Italian tagger produced a precision (55.91%) significantly lower than others.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9110853672027588}, {"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.998146653175354}]}, {"text": "However, if we include the partially correct annotations, the precision scores become more consistent: 76.49%, 87.69% and 89.72% for the three languages respectively, with an average precision of 84.64%.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9995682835578918}, {"text": "precision", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9975479245185852}]}, {"text": "We also estimated recall based on the numbers of tokens of the sample texts and those tagged correctly/partially correctly, obtaining 55.39%, 67.71% and 69.46% for Italian, Chinese and Portuguese respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9991710186004639}]}, {"text": "Such a fairly close range of the precision and recall values indicates that our approach to developing prototype semantic annotation tools can be expected to achieve stable results across various languages, although we need largerscale evaluations to draw a conclusion.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9994418025016785}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9930589199066162}]}, {"text": "It is worth noting that, although the recall is still low, these taggers are starting to approach the precision of the English system at 91% (.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9997615218162537}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.999514102935791}]}, {"text": "Our further error analysis revealed that the main causes of the errors include the homonym translations (e.g. bank as riverbank vs. money bank), translation errors and missing of the translation words in the English semantic lexicons.", "labels": [], "entities": []}, {"text": "For example, the Chinese word \"\u7238\u7238\" (father) has a number of synonymous English translation equivalents in the bilingual lexicon: dad (with semantic tag S4m), baba, da, dada, daddy (S4m), father (S4m S9/S2m), papa (S4m).", "labels": [], "entities": []}, {"text": "It is also translated into presence (M6, A3+, S1.1.3+, S1.2, S9) by mistake.", "labels": [], "entities": [{"text": "presence", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9370585083961487}]}, {"text": "Among the correct English translations, baba, da, dada (transliteration) are not included in the English semantic lexicons.", "labels": [], "entities": []}, {"text": "Making things worse, dais a homonym which is classified as a discourse marker of exclamation (Z4) in English lexicons.", "labels": [], "entities": []}, {"text": "Our current automatic process collects all the semantic tags derived from the English translation counterparts found in the bilingual lexicon and assigns them to the Chinese word \"\u7238\u7238\", resulting in an erroneous entry as shown below: \u7238\u7238 noun M6 A3+ S1.1.3+ S1.2 S9 S4/B1 S4m S9/S2.2m Z4 In order to resolve such cases, we will need to consider contexts of each translation word pairs' usage via parallel or comparable corpora.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Sizes of current semantic lexicons.", "labels": [], "entities": []}, {"text": " Table 3: Lexical coverage of the semantic taggers.", "labels": [], "entities": [{"text": "semantic taggers", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.6812634021043777}]}, {"text": " Table 4: Evaluation of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9887154698371887}]}]}