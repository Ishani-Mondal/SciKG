{"title": [{"text": "Unsupervised Sparse Vector Densification for Short Text Similarity", "labels": [], "entities": [{"text": "Sparse Vector Densification", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.6612242162227631}, {"text": "Short Text Similarity", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.5882869958877563}]}], "abstractContent": [{"text": "Sparse representations of text such as bag-of-words models or extended explicit semantic analysis (ESA) representations are commonly used in many NLP applications.", "labels": [], "entities": [{"text": "extended explicit semantic analysis (ESA) representations", "start_pos": 62, "end_pos": 119, "type": "TASK", "confidence": 0.760487761348486}]}, {"text": "However, for short texts, the similarity between two such sparse vectors is not accurate due to the small term overlap.", "labels": [], "entities": []}, {"text": "While there have been multiple proposals for dense representations of words, measuring similarity between short texts (sen-tences, snippets, paragraphs) requires combining these token level similarities.", "labels": [], "entities": []}, {"text": "In this paper, we propose to combine ESA representations and word2vec representations as away to generate denser representations and, consequently , a better similarity measure between short texts.", "labels": [], "entities": []}, {"text": "We study three densification mechanisms that involve aligning sparse representation via many-to-many, many-to-one, and one-to-one mappings.", "labels": [], "entities": []}, {"text": "We then show the effectiveness of these mechanisms on measuring similarity between short texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bag-of-words model has been used for many applications as the state-of-the-art method for tasks such as document classifications and information retrieval.", "labels": [], "entities": [{"text": "document classifications", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7384828627109528}, {"text": "information retrieval", "start_pos": 133, "end_pos": 154, "type": "TASK", "confidence": 0.8117890655994415}]}, {"text": "It represents each text as a bag-of-words, and computes the similarity, e.g., cosine value, between two sparse vectors in the high-dimensional space.", "labels": [], "entities": []}, {"text": "When the contextual information is insufficient, e.g., due to the short length of the document, explicit semantic analysis (ESA) has been used as away to enrich the text representation ( ;).", "labels": [], "entities": [{"text": "explicit semantic analysis", "start_pos": 96, "end_pos": 122, "type": "TASK", "confidence": 0.613956997791926}]}, {"text": "Instead of using only the words in a document, ESA uses a bag-of-concepts retrieved from Wikipedia to represent the text.", "labels": [], "entities": [{"text": "ESA", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.7754351496696472}]}, {"text": "Then the similarity between two texts can be computed in this enriched concept space.", "labels": [], "entities": []}, {"text": "Both bag-of-words and bag-of-concepts models suffer from the sparsity problem.", "labels": [], "entities": []}, {"text": "Because both models use sparse vectors to represent text, when comparing two pieces of texts, the similarity can be zero even when the text snippets are highly related, but make use of different vocabulary.", "labels": [], "entities": []}, {"text": "We can expect that these two texts are related but the similarity value does not reflect that.", "labels": [], "entities": [{"text": "similarity", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.9739500880241394}]}, {"text": "ESA, despite augmenting the lexical space with relevant Wikipedia concepts, still suffers from the sparsity problem.", "labels": [], "entities": [{"text": "ESA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9721629023551941}]}, {"text": "We illustrate this problem with the following simple experiment, done by choosing a documents from the \"rec.autos\" group in the 20-newsgroups data set 1 . For both documents and the label description \"cars\" (here we follow the description shown in), we computed 500 concepts using ESA.", "labels": [], "entities": [{"text": "ESA", "start_pos": 281, "end_pos": 284, "type": "DATASET", "confidence": 0.9058125019073486}]}, {"text": "Then we identified the concepts that appear both in the document ESA representation and in the label ESA representation.", "labels": [], "entities": []}, {"text": "The average sizes of this intersection (number of overlapping concepts in the document and label representation) are shown in.", "labels": [], "entities": []}, {"text": "In addition to the original documents, we also split each document into 2, 4, 8, 16 equal length parts, computed the ESA representation of each, and then the intersection with the ESA representation of the label.", "labels": [], "entities": []}, {"text": "shows that the number of concepts shared by the label and the document representation decreases significantly, even if not as significantly as the drop in the document size.", "labels": [], "entities": []}, {"text": "For example, there are on average 8 concepts in the intersection of two vectors with 500 non-zero concepts when we split each document into 16 parts.", "labels": [], "entities": []}, {"text": "When there are fewer overlapping terms between two pieces of texts, it can cause mismatch or biased match and result in less accurate comparison.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use unsupervised approaches to improve the representation, along with a corresponding similarity approach between these representations.", "labels": [], "entities": []}, {"text": "First, we incorporate the popular word2vec () representations into ESA representation, and show that incorporating semantic relatedness between Wikipedia titles can indeed help the similarity measure between short texts.", "labels": [], "entities": []}, {"text": "Second, we propose and evaluate three mechanisms for comparing the resulting representations.", "labels": [], "entities": []}, {"text": "We verify the superiority of the proposed methods using three different NLP tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experiment on three data sets.", "labels": [], "entities": []}, {"text": "We use dataless classification () over 20-newsgroups data set to verify the correctness of our argument of short text problems, and use two short text data sets to evaluate document similarity measurement and event classification for sentences.", "labels": [], "entities": [{"text": "event classification", "start_pos": 209, "end_pos": 229, "type": "TASK", "confidence": 0.7300495356321335}]}], "tableCaptions": [{"text": " Table 1: Average sizes of the intersection between the  ESA concept representations of documents and label- s. Both documents and label are represented with 500  Wikipedia concepts. Documents are split into different  lengths.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of dataless classification using ESA and Dense-ESA with 500 dimensions.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9830368161201477}, {"text": "ESA", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.9398664832115173}]}, {"text": " Table 3: Spearman's correlation of document similarity  using ESA and Dense-ESA with 500 concepts.", "labels": [], "entities": []}]}