{"title": [{"text": "Lexical Event Ordering with an Edge-Factored Model", "labels": [], "entities": [{"text": "Lexical Event Ordering", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7779362996419271}]}], "abstractContent": [{"text": "Extensive lexical knowledge is necessary for temporal analysis and planning tasks.", "labels": [], "entities": [{"text": "temporal analysis", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7038016617298126}]}, {"text": "We address in this paper a lexical setting that allows for the straightforward incorporation of rich features and structural constraints.", "labels": [], "entities": []}, {"text": "We explore a lexical event ordering task, namely determining the likely temporal order of events based solely on the identity of their predicates and arguments.", "labels": [], "entities": [{"text": "lexical event ordering", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7022592226664225}]}, {"text": "We propose an \"edge-factored\" model for the task that decomposes over the edges of the event graph.", "labels": [], "entities": []}, {"text": "We learn it using the structured perceptron.", "labels": [], "entities": []}, {"text": "As lexical tasks require large amounts of text, we do not attempt manual annotation and instead use the textual order of events in a domain where this order is aligned with their temporal order, namely cooking recipes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Temporal relations between events are often implicit, and inferring them relies on lexical and world knowledge about the likely order of events.", "labels": [], "entities": []}, {"text": "For instance, to execute the instruction \"fry the onion,\" the hearer should probably obtain oil beforehand, even if not instructed so explicitly.", "labels": [], "entities": []}, {"text": "Lexical knowledge about the likely order of events is therefore necessary for any semantic task that requires temporal reasoning or planning, such as classifying temporal relations (;, inter alia), textual entailment () or temporal information extraction.", "labels": [], "entities": [{"text": "Lexical knowledge about the likely order of events", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7986707165837288}, {"text": "temporal information extraction", "start_pos": 223, "end_pos": 254, "type": "TASK", "confidence": 0.6227058867613474}]}, {"text": "Lexical temporal knowledge is further important for modeling grammatical phenomena such as tense and aspect.", "labels": [], "entities": [{"text": "Lexical temporal knowledge", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8455455501874288}]}, {"text": "In this paper we address the task of lexical event ordering, namely predicting the ordering of events based only on the identity of the words comprising their predicates and arguments.", "labels": [], "entities": [{"text": "lexical event ordering", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.6384620070457458}, {"text": "predicting the ordering of events", "start_pos": 68, "end_pos": 101, "type": "TASK", "confidence": 0.8553190588951111}]}, {"text": "Concretely, the task is to predict the order of an unordered set of predicate-argument structures.", "labels": [], "entities": []}, {"text": "Predicting the likely order of event types is a step towards more intricate planning and reasoning scenarios (see \u00a73), and is useful in itself for tasks such as conceptto-text generation (), or in validating the correctness of instruction sets.", "labels": [], "entities": [{"text": "conceptto-text generation", "start_pos": 161, "end_pos": 186, "type": "TASK", "confidence": 0.7855148911476135}]}, {"text": "A related idea can be found in modeling sentence coherence, inter alia), although here we focus on lexical relations between events, rather than coherence relations between complete sentences.", "labels": [], "entities": []}, {"text": "Compiling a resource of temporal tendencies between events can hardly be done manually, given the number and wealth of phenomena that have to be accounted for.", "labels": [], "entities": []}, {"text": "Temporally annotated corpora, often annotated according to TimeML principles, area useful resource for studying temporal relations.", "labels": [], "entities": []}, {"text": "However, due to incurred costs, annotated corpora are too small for most lexical tasks.", "labels": [], "entities": []}, {"text": "For instance, the TimeML annotated data used in the latest TempEval shared task contains only 100K words or so (.", "labels": [], "entities": [{"text": "TimeML annotated data", "start_pos": 18, "end_pos": 39, "type": "DATASET", "confidence": 0.862683892250061}, {"text": "TempEval shared task", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.5228312412897745}]}, {"text": "Previous work that does not rely on manually annotated data has had some success in discovering temporal lexical relations between predicates ().", "labels": [], "entities": []}, {"text": "However, despite their appeal, these methods have mostly fo-cused on inducing simple event types, consisting of single words (e.g., \"buy-own\") or fixed expressions, and are hard to extend to include rich features (e.g., order-based and pattern-based features).", "labels": [], "entities": []}, {"text": "Furthermore, measuring recall without annotated data is notoriously difficult, and evaluation is often precisionbased or extrinsic.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9899622201919556}, {"text": "precisionbased", "start_pos": 103, "end_pos": 117, "type": "METRIC", "confidence": 0.9823057055473328}]}, {"text": "We take a graph-based structured prediction approach to the task, motivated by the flexibility it allows in incorporating various feature sets and constraints.", "labels": [], "entities": []}, {"text": "We use an edge-factored model, which decomposes over the edges in the graph of events comprising the recipe ( \u00a74).", "labels": [], "entities": []}, {"text": "We estimate the model using the structured perceptron algorithm.", "labels": [], "entities": []}, {"text": "We compare the structured perceptron approach to an approximate greedy baseline and to a locally normalized model reminiscent of common approaches for order learning, obtaining superior results ( \u00a78).", "labels": [], "entities": []}, {"text": "The learning algorithm is of potential use in other ordering tasks such as machine translation reordering.", "labels": [], "entities": [{"text": "machine translation reordering", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.83208829164505}]}, {"text": "We focus on domains in which the order of events in the text is aligned with their temporal order.", "labels": [], "entities": []}, {"text": "By doing so we avoid the costly and error-prone manual annotation of temporal relations by using the textual order of recipes to approximate their temporal order.", "labels": [], "entities": []}, {"text": "Specifically, we address the cooking recipes domain, which we motivate in \u00a72.", "labels": [], "entities": []}, {"text": "In summary, the contribution of this paper is three-fold: (1) we explore the task of lexical event ordering and means for its evaluation; (2) we present an edge-factored model for the task, and show it can be used to predict the order of events well (77.7% according to standard measures for ordering evaluation); (3) we present a method for extracting events and create a dataset of ordered events using recipes extracted from the web.", "labels": [], "entities": [{"text": "lexical event ordering", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.7026789585749308}]}], "datasetContent": [{"text": "The data is extracted from a recipe repository found on the web.", "labels": [], "entities": []}, {"text": "The recipes are given as free text.", "labels": [], "entities": []}, {"text": "To extract event types we run the Stanford CoreNLP 4 pipeline of a tokenizer, POS tagger, a lexical constituency parser (the englishPCFG parsing model) and extract typed Stanford dependencies.", "labels": [], "entities": [{"text": "Stanford CoreNLP 4", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.8476014335950216}, {"text": "POS tagger", "start_pos": 78, "end_pos": 88, "type": "TASK", "confidence": 0.6161153763532639}]}, {"text": "As is common with web extractions, the recipes contain occasional spelling, grammatical and formatting errors.", "labels": [], "entities": []}, {"text": "The corpus consists of 139 files, 73484 recipes, 1.02M events (13.8 events per recipe on average) and 11.05M words.", "labels": [], "entities": []}, {"text": "We focus on verbal events and do not extract nominal and adjectival argument structures, which are not as well supported by current parsing technology.", "labels": [], "entities": []}, {"text": "Any verb is taken to define an event, aside from modal verbs, auxiliaries and secondary verbs.", "labels": [], "entities": []}, {"text": "A secondary verb (e.g., \"let,\" \"begin\") does not describe an action in its own right, but rather modifies an event introduced by another verb.", "labels": [], "entities": []}, {"text": "We identify these verbs heuristically using a list given in) and a few simple rules defined over parse trees.", "labels": [], "entities": []}, {"text": "E.g., from the sentence \"you should begin to chop the onion,\" we extract a single event with a predicate \"chop.\"", "labels": [], "entities": []}, {"text": "Arguments are taken to be the immediate dependents of the predicate that have an argument dependency type (such as director indirect objects) according to the extracted Stanford dependencies.", "labels": [], "entities": []}, {"text": "For prepositional phrases, we include the preposition as part of the argument.", "labels": [], "entities": []}, {"text": "Argument indices are determined by their order in the text.", "labels": [], "entities": []}, {"text": "The order of events is taken to be the order of their verbs in the text.", "labels": [], "entities": []}, {"text": "We focus on a subset of linkage relations, which are relevant for temporal relations.", "labels": [], "entities": []}, {"text": "We use explicit discourse connectives classifier to identify temporal discourse linkers, discarding all other discourse linkers.", "labels": [], "entities": []}, {"text": "Once a discourse linker has been detected, we heuristically extract its arguments (namely the pair of verbs it links) according to a deterministic extraction rule defined over the parse tree.", "labels": [], "entities": []}, {"text": "We find 28 distinct connectives in our training set, where the 5 most common linkers \"until,\" \"then,\" \"before,\" \"when\" and \"as\" cover over 95% of the instances.", "labels": [], "entities": []}, {"text": "We extract 36756 such linkages from the corpus, 0.5 linkages per recipe on average.", "labels": [], "entities": []}, {"text": "In order to confirm that temporal and textual order of recipes are generally in agreement, we manually examine the first 20 recipes in our development set.", "labels": [], "entities": []}, {"text": "One recipe was excluded as noise 6 , resulting in 19 recipes and 353 events.", "labels": [], "entities": []}, {"text": "We identify the sources of misalignment between the linear order and the temporal order of the events.", "labels": [], "entities": []}, {"text": "7 13 events (3.7%) did not have any clear temporal orderings.", "labels": [], "entities": []}, {"text": "These consisted of mostly negations and modalities (e.g., \"do not overbrown!\"), sub-section headings (e.g., \"Preparation\") or other general statements that do not constitute actions or states.", "labels": [], "entities": []}, {"text": "For the remaining 340 events, we compare their linear and the temporal orderings.", "labels": [], "entities": []}, {"text": "We estimate the frequency of sub-sequences that contradict the temporal order and confirm that they occur only infrequently.", "labels": [], "entities": []}, {"text": "We find that most disagreements fall into these two categories: (1) disjunctions between several events, only one of which will actually take place (e.g., \"roll Springerle pin over dough, or press mold into top\"); (2) a pair, or less commonly a triplet, of events are expressed in reverse order.", "labels": [], "entities": []}, {"text": "For instance, \"place on greased and floured cookie sheet,\" where greasing and flouring should occur before the placing action.", "labels": [], "entities": []}, {"text": "We note that assuming the alignment of the temporal and textual order of recipes does not suggest that the textual order is the only order of events that would yield the same outcome.", "labels": [], "entities": []}, {"text": "We compute the Kendall's Tau correlation, a standard measure for information ordering), between the temporal and linear orderings for each recipe.", "labels": [], "entities": [{"text": "Kendall's Tau correlation", "start_pos": 15, "end_pos": 40, "type": "METRIC", "confidence": 0.6514735817909241}, {"text": "information ordering", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7853401005268097}]}, {"text": "In cases of several events that happen simultaneously (including disjunctions), we take their ordinals to be equal.", "labels": [], "entities": []}, {"text": "For instance, for three events where the last two happen at the same time, we take their ordering to be) in our analysis.", "labels": [], "entities": []}, {"text": "We find that indeed temporal and textual orderings are in very high agreement, with 6 recipes of the 19 perfectly aligned.", "labels": [], "entities": []}, {"text": "The average Kendall's Tau between the temporal ordering and the linear one is 0.924.", "labels": [], "entities": [{"text": "Kendall's Tau", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.7057177225748698}]}, {"text": "We compute the accuracy of our algorithms by comparing the predicted order to the one in which the events are written.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9994983673095703}]}, {"text": "We first compute the number of exact matches, denoted with EXACT, namely the percentage of recipes in which the predicted and the textual orders are the same.", "labels": [], "entities": [{"text": "EXACT", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.9938083291053772}]}, {"text": "For a more detailed analysis of imperfect predictions, we compute the agreement between subsequences of the orderings.", "labels": [], "entities": []}, {"text": "We borrow the notion of a \"concordant pair\" from the definition of Kendall's Tau and generalize it to capture agreement of longer sub-sequences.", "labels": [], "entities": []}, {"text": "Two k-tuples of integers (x 1 , ..., x k ) and (y 1 , ..., y k ) are said to \"agree in order\" if for every 1 \u2264 i < j \u2264 k, xi < x jiff y i < y j . Given two orderings of the same recipe O 1 = (e \u03c4 (1) , ..., e \u03c4 (m) ) and O 2 = (e \u03c3(1) , ..., e \u03c3(m) ) (where \u03c4 and \u03c3 are permutations over [m] = {1, . .", "labels": [], "entities": []}, {"text": ", m}) and given a sequence of k monotonically increasing indices t = (i 1 , ..., i k ), t is said to be a \"concordant k-tuple\" of O 1 and O 2 if (\u03c4 (i 1 ), ..., \u03c4 (i k )) and (\u03c3(i 1 ), ..., \u03c3(i k )) agree in order, as defined above.", "labels": [], "entities": []}, {"text": "Denote the unordered recipes of the test data as , where R i = {e The k-wise (micro-averaged) accuracy of T with respect to \u03a3 is: Any k-tuples containing the start node s or the end node fare excluded, as their ordering is trivial.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.8366333246231079}]}, {"text": "Recipes of length less thank are discarded when computing acc k . A micro-averaged accuracy measure is used so as not to disproportionately weigh short recipes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.8060226440429688}]}, {"text": "However, in order to allow comparison to mean Kendall's Tau, commonly used in works on order learning, we further report a macroaveraged acc 2 by computing acc 2 for each recipe separately, and taking the average of resulting accuracy levels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 226, "end_pos": 234, "type": "METRIC", "confidence": 0.9985283613204956}]}, {"text": "Average Kendall's Tau can now be computed by 2acc 2 \u2212 1 for the macro-averaged acc 2 score.", "labels": [], "entities": [{"text": "Kendall's Tau", "start_pos": 8, "end_pos": 21, "type": "METRIC", "confidence": 0.5861346324284872}, {"text": "acc 2 score", "start_pos": 79, "end_pos": 90, "type": "METRIC", "confidence": 0.8938025037447611}]}, {"text": "We randomly partition the text into training, test and development sets, taking an 80-10-10 percent split.", "labels": [], "entities": []}, {"text": "We do not partition the individual files so as to avoid statistical artifacts introduced by recipe duplications or near-duplications.", "labels": [], "entities": []}, {"text": "The training, development and test sets contain 58038, 7667 and 7779 recipes respectively.", "labels": [], "entities": []}, {"text": "The total number of feature template instantiations in the training data is 8.94M.", "labels": [], "entities": []}, {"text": "We compare three learning algorithms.", "labels": [], "entities": []}, {"text": "GLOBAL-PRC is the structured perceptron algorithm that uses ILP inference.", "labels": [], "entities": []}, {"text": "GREEDY-PRC is a structured perceptron in which inference is done greedily.", "labels": [], "entities": [{"text": "GREEDY-PRC", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9151215553283691}]}, {"text": "GREEDY-LOGLIN is the locally normalized log-linear model with greedy inference.", "labels": [], "entities": [{"text": "GREEDY-LOGLIN", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.8746032118797302}]}, {"text": "RANDOM randomly (uniformly) selects a permutation of the recipe's events.", "labels": [], "entities": []}, {"text": "The structured perceptron algorithms, GLOBAL-PRC and GREEDY-PRC, are run with a learning rate of 0.1 for 3 iterations.", "labels": [], "entities": [{"text": "GLOBAL-PRC", "start_pos": 38, "end_pos": 48, "type": "DATASET", "confidence": 0.7022168636322021}, {"text": "GREEDY-PRC", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.5875887870788574}]}, {"text": "To avoid exceedingly long runs, we set a time limit in seconds \u03b2 on the running time of each ILP inference stage used in GLOBAL-PRC.", "labels": [], "entities": []}, {"text": "We consider two training scenarios: 4K, which trains on the first 4K recipes of the training set, and 58K, which trains on the full training data of 58K recipes.", "labels": [], "entities": []}, {"text": "In GLOBAL-PRC we set \u03b2 to be 30 seconds for the 4K  scenario, and 5 seconds in the 58K scenario.", "labels": [], "entities": [{"text": "GLOBAL-PRC", "start_pos": 3, "end_pos": 13, "type": "DATASET", "confidence": 0.761113166809082}]}, {"text": "The number of threads was limited to 3.", "labels": [], "entities": []}, {"text": "Where the time limit is reached before an optimal solution is found, the highest scoring Hamiltonian path found up to that point is returned by the ILP solver.", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 148, "end_pos": 158, "type": "TASK", "confidence": 0.6505336165428162}]}, {"text": "In the infrequent samples where no feasible solution is found during training, the sample is skipped over, while attest time, we perform greedy inference instead.", "labels": [], "entities": []}, {"text": "We define the following feature sets.", "labels": [], "entities": []}, {"text": "Fr includes only features of class Frequency, while Fr + Lex includes features from both the Frequency and Lexical categories.", "labels": [], "entities": []}, {"text": "Full includes all feature sets.", "labels": [], "entities": []}, {"text": "All above feature sets take C, the reference corpus for computing FREQUENCY features, to be the entire 58K training samples in both scenarios.", "labels": [], "entities": [{"text": "FREQUENCY", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.7378040552139282}]}, {"text": "In the 4K scenario, we also experiment with FrLim, which includes all features, but takes C to contain only the 4K samples of the training data.", "labels": [], "entities": [{"text": "FrLim", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.8640362024307251}]}, {"text": "We use the Gurobi package for ILP.", "labels": [], "entities": [{"text": "Gurobi package", "start_pos": 11, "end_pos": 25, "type": "DATASET", "confidence": 0.8473383486270905}]}, {"text": "8 Brown clusters are extracted from the 58K samples of the training data using Liang's implementation.", "labels": [], "entities": []}, {"text": "The convex log-likelihood function of GREEDY-LOGLIN is optimized using LBFGS.", "labels": [], "entities": [{"text": "GREEDY-LOGLIN", "start_pos": 38, "end_pos": 51, "type": "METRIC", "confidence": 0.8278611898422241}]}, {"text": "All features are selected and all parameters are tuned using the development set.", "labels": [], "entities": []}, {"text": "presents the results of the three major algorithms in the two main scenarios 58K and 4K.", "labels": [], "entities": []}, {"text": "We find that the structured perceptron algorithm, GLOBAL-PRC, obtains the best results in both cases and under all evaluation measures.", "labels": [], "entities": [{"text": "GLOBAL-PRC", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.5871418714523315}]}, {"text": "The importance of global optimization was also stressed in other works on event ordering.", "labels": [], "entities": [{"text": "global optimization", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.8088415861129761}, {"text": "event ordering", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.7210728228092194}]}, {"text": "In order to assess the contribution of the different components of the model of the best scoring model, GLOBAL-PRC, we compare the performance of the different feature sets and settings of \u03b2 on the development set in 4K.", "labels": [], "entities": [{"text": "GLOBAL-PRC", "start_pos": 104, "end_pos": 114, "type": "DATASET", "confidence": 0.8212392330169678}, {"text": "4K", "start_pos": 217, "end_pos": 219, "type": "DATASET", "confidence": 0.9242169260978699}]}, {"text": "Results reveal the strong impact of the Frequency feature set on the results.", "labels": [], "entities": [{"text": "Frequency feature set", "start_pos": 40, "end_pos": 61, "type": "DATASET", "confidence": 0.7047494649887085}]}, {"text": "Using this category set alone (Fr) yields slightly lower results than using the full feature set, while estimating the Frequency features on a small corpus (FrLim) lowers results dramatically.", "labels": [], "entities": []}, {"text": "Adding Lexical and Brown features yields a small improvement over using Frequency alone.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature templates used for computing \u03c6. The", "labels": [], "entities": [{"text": "computing \u03c6", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.5064303427934647}]}, {"text": " Table 2: Accuracy of the different models on the test data in", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985945820808411}]}, {"text": " Table 3: The performance of GLOBAL-PRC on the develop-", "labels": [], "entities": []}]}