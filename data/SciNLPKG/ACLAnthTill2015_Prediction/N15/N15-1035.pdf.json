{"title": [{"text": "Semi-Supervised Word Sense Disambiguation Using Word Embeddings in General and Specific Domains", "labels": [], "entities": [{"text": "Semi-Supervised Word Sense Disambiguation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6471323668956757}]}], "abstractContent": [{"text": "One of the weaknesses of current supervised word sense disambiguation (WSD) systems is that they only treat a word as a discrete entity.", "labels": [], "entities": [{"text": "supervised word sense disambiguation (WSD)", "start_pos": 33, "end_pos": 75, "type": "TASK", "confidence": 0.7868002610547202}]}, {"text": "However, a continuous-space representation of words (word embeddings) can provide valuable information and thus improve generalization accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.8988890647888184}]}, {"text": "Since word embed-dings are typically obtained from unlabeled data using unsupervised methods, this method can be seen as a semi-supervised word sense disambiguation approach.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 139, "end_pos": 164, "type": "TASK", "confidence": 0.67610631386439}]}, {"text": "This paper investigates two ways of incorporating word embed-dings in a word sense disambiguation setting and evaluates these two methods on some Sen-sEval/SemEval lexical sample and all-words tasks and also a domain-specific lexical sample task.", "labels": [], "entities": [{"text": "word sense disambiguation setting", "start_pos": 72, "end_pos": 105, "type": "TASK", "confidence": 0.7135232836008072}]}, {"text": "The obtained results show that such representations consistently improve the accuracy of the selected supervised WSD system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9990485310554504}, {"text": "WSD", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9151041507720947}]}, {"text": "Moreover, our experiments on a domain-specific dataset show that our supervised base-line system beats the best knowledge-based systems by a large margin.", "labels": [], "entities": []}], "introductionContent": [{"text": "Because of the ambiguity of natural language, many words can have different meanings in different contexts.", "labels": [], "entities": []}, {"text": "For example, the word \"bank\" has two different meanings in \"the bank of a river\" and \"a bank loan\".", "labels": [], "entities": []}, {"text": "While it seems simple for humans to identify the meaning of a word according to the context, word sense disambiguation (WSD)) is a difficult task for computers and thus requires sophisticated means to achieve its goal.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD))", "start_pos": 93, "end_pos": 125, "type": "TASK", "confidence": 0.7742293526728948}]}, {"text": "Part of this ambiguity maybe resolved by considering part-of-speech (POS) tags but the word senses are still highly ambiguous even for the same part-of-speech.", "labels": [], "entities": []}, {"text": "Machine translation is probably the most important application of word sense disambiguation.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7935867011547089}, {"text": "word sense disambiguation", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.7623733083407084}]}, {"text": "In machine translation, different senses of a word cause a great amount of ambiguity for automated translation and it negatively affects the results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.734775573015213}, {"text": "automated translation", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.7688672542572021}]}, {"text": "Hence, an accurate WSD system can benefit machine translation significantly and improve the results ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9576502442359924}, {"text": "machine translation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7160902619361877}]}, {"text": "Moreover, have shown that word sense disambiguation improves information retrieval by proposing a method to use word senses in a language modeling approach to information retrieval.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7018264631430308}, {"text": "information retrieval", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.7328482419252396}, {"text": "information retrieval", "start_pos": 159, "end_pos": 180, "type": "TASK", "confidence": 0.7718630135059357}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a literature review of related work, including a review of semi-supervised word sense disambiguation and distributed word representation called word embeddings.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.6374990046024323}]}, {"text": "The method and framework used in this paper are explained in Section 3.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the system in Section 4 and conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "All-words tasks do not provide any training samples and only include a test set (see).", "labels": [], "entities": []}, {"text": "In order to train our system for SE3 all-words task, we used the automatically labeled training samples used earlier for training models for DS05 (see section 4.1.1).", "labels": [], "entities": []}, {"text": "shows some statistics about our training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of lexical sample tasks", "labels": [], "entities": []}, {"text": " Table 3: The scores for each part-of-speech (POS) on  SE2 lexical sample tasks. The window size is shown in- side brackets.", "labels": [], "entities": [{"text": "SE2 lexical sample tasks", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.5091499537229538}]}, {"text": " Table 4: The scores for each part-of-speech (POS) on  SE3 lexical sample tasks. The window size is shown in- side brackets.", "labels": [], "entities": []}, {"text": " Table 5: Lexical sample task results. The values inside  brackets are the selected window sizes and statistically  significant (p < 0.05) improvements are marked with '*'.", "labels": [], "entities": []}, {"text": " Table 6: DS05 task results. The values inside brackets are the selected window sizes and statistically significant (p <  0.05) improvements over 'IMS + CC' are marked with '*'.", "labels": [], "entities": []}, {"text": " Table 8: SE3 all-words task results. The values inside  brackets are the selected window sizes and statistically  significant (p < 0.05) improvements over the IMS base- line are marked with '*'.", "labels": [], "entities": []}]}