{"title": [{"text": "Improving unsupervised vector-space thematic fit evaluation via role-filler prototype clustering", "labels": [], "entities": [{"text": "Improving unsupervised vector-space thematic fit evaluation", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8435473243395487}, {"text": "role-filler prototype clustering", "start_pos": 64, "end_pos": 96, "type": "TASK", "confidence": 0.6802142262458801}]}], "abstractContent": [{"text": "Most recent unsupervised methods in vector space semantics for assessing thematic fit (e.g. Erk, 2007; Baroni and Lenci, 2010; Sayeed and Demberg, 2014) create prototypical role-fillers without performing word sense disam-biguation.", "labels": [], "entities": []}, {"text": "This leads to a kind of sparsity problem: candidate role-fillers for different senses of the verb end up being measured by the same \"yardstick\", the single prototypical role-filler.", "labels": [], "entities": []}, {"text": "In this work, we use three different feature spaces to construct robust unsupervised models of distributional semantics.", "labels": [], "entities": []}, {"text": "We show that correlation with human judgements on thematic fit estimates can be improved consistently by clustering typical role-fillers and then calculating similarities of candidate role-fillers with these cluster centroids.", "labels": [], "entities": []}, {"text": "The suggested methods can be used in any vector space model that constructs a prototype vector from a non-trivial set of typical vectors.", "labels": [], "entities": []}], "introductionContent": [{"text": "Thematic fit estimations can be quite useful for many NLP applications and also for cognitive models of human language processing difficulty, since human processing difficulty is highly sensitive to semantic plausibilities.", "labels": [], "entities": [{"text": "Thematic fit estimations", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.596593846877416}]}, {"text": "For example, we expect that after the word mash, banana would be easier to process because it fits well as the patient, or direct object, of mash, but milk would be harder to process because it does not fit well.", "labels": [], "entities": []}, {"text": "A common method for estimating the thematic fit between a verb and a proposed role filler involves computing a centroid, or vector average, over the most typical role fillers for that verb, and then calculating the cosine similarity between this centroid and the proposed role filler (.", "labels": [], "entities": []}, {"text": "For instance, we use the cosine of the angle between the banana vector and a vector average of the 20 nouns that, according to training data, are most likely to be mashed as a score for how well banana fits as the patient of mash.", "labels": [], "entities": []}, {"text": "Hopefully, the banana vector will be closer to the centroid than milk, so banana will have a higher cosine similarity to the centroid, and thus a higher thematic fit score, than milk.", "labels": [], "entities": [{"text": "thematic fit score", "start_pos": 153, "end_pos": 171, "type": "METRIC", "confidence": 0.7088559865951538}]}, {"text": "This conceptualization assumes that the most typical fillers fora verb-role will all be variants of a single prototype, i.e. distributionally similar to each other.", "labels": [], "entities": []}, {"text": "However, such an assumption may not be true for ambiguous verbs.", "labels": [], "entities": []}, {"text": "A verb with many different senses may have typical fillers for each sense, which fit relatively equally well, but are distributionally very different from one another.", "labels": [], "entities": []}, {"text": "This means that the calculated prototypical filler will be a mixture of the arguments that are typical role fillers for the main senses of the verb.", "labels": [], "entities": []}, {"text": "For example, consider the verb serve, for which the 24 most typical prepositional arguments related via the preposition with fall into three different senses, as illustrated in.", "labels": [], "entities": []}, {"text": "Supposing that the centroid occupies apart of the vector space between two typical role fillers, but is relatively far from anyone of the typical role fillers from which it was composed, as in, none of the original typical role fillers will achieve high the- matic fit scores.", "labels": [], "entities": []}, {"text": "Also, verbs will be \"penalized\" for having many senses in that it will seem as though no role filler fits as well as they do with unambiguous verbs.", "labels": [], "entities": []}, {"text": "This may produce inconsistent judgements when comparing one verb that is highly polysemous with a second, more restrictive verb whose meaning overlaps with the most dominant meanings of the first verb.", "labels": [], "entities": []}, {"text": "For example, cut can be used in the sense of \"cutting costs,\" which carries with it restrictions on instruments, locations, and soon that somewhat overlap with eliminate as in \"eliminating costs.\"", "labels": [], "entities": []}, {"text": "Things that are plausible to be eliminated are also plausible to be cut.", "labels": [], "entities": []}, {"text": "But cut is also used in the sense of \"cutting a cake\" or \"cutting (editing) a film.\"", "labels": [], "entities": []}, {"text": "Without taking word sense into account, costs would be judged by the model as being less appropriate as a patient of cut than it should, and also its score for filling the patient role of eliminate would be infelicitously higher than its score for filling the patient role of cut.", "labels": [], "entities": []}, {"text": "One possible solution to this problem would be to do full word sense disambiguation on the resources from which these vector spaces are constructed.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.6574210723241171}]}, {"text": "Then, there would be separate entries in the space for each meaning.", "labels": [], "entities": []}, {"text": "This would however increase the overall size of the vector space by a significant factor and also cause an additional burden on corpus construction and annotation, even if automatic.", "labels": [], "entities": [{"text": "corpus construction", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.715461254119873}]}, {"text": "In this paper, we will approach the verb-role sense problem by clustering the most typical role-filler vectors and calculating the maximal cosine similarity fora candidate role filler with respect to each cluster prototype vector.", "labels": [], "entities": []}, {"text": "So, to estimate the thematic fit of salad as an item with which something is served, in the vector space represented by, we would use the cosine similarity with the nearest cluster centroid, the cluster 1 centroid.", "labels": [], "entities": []}, {"text": "For a thematic fit task, the correlation between calculated estimates and human judgements can be expected to improve.", "labels": [], "entities": []}, {"text": "In particular, good role fillers that are very different from one another and belong to different senses of a verb can all be assigned thematic fit scores as high as those of good role fillers of monosemous verbs.", "labels": [], "entities": [{"text": "role fillers", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.7551669478416443}]}, {"text": "We will evaluate our system using three distributional spaces: TypeDM (, which is based on a syntactic dependency parser, SDDM, which uses features obtained from the semantic role labeller SENNA, and SDDMX , a novel extension of SDDM . This way, we can draw conclusions about feature space-specific and feature space-general trends.", "labels": [], "entities": []}, {"text": "The effects of clustering and choice of distributional space will be evaluated against the Pad\u00f3 (2007) and datasets of human judgements on thematic fit of agent and patient roles, and the datasets of human judgements on thematic fit of instrument and location roles.", "labels": [], "entities": []}, {"text": "These different roles are conceptually interesting to compare, as instruments tend to be more strongly constrained by verbs than locations.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Centroid , OneBest, 2Clusters, and kClusters methods each determine their own prototype vector set fora verb-role, and then return the maximum cosine similarity value for each test role-filler.", "labels": [], "entities": []}, {"text": "Prototype sets are stored in a dictionary so they can be reused.", "labels": [], "entities": []}, {"text": "It is necessary to expand the sparse data structure of each vector in order to efficiently compute all of the necessary cosine similarities.", "labels": [], "entities": []}, {"text": "Finally, we calculate Spearman's \u03c1 values to measure the correlations between these sets of thematic fit scores and the four datasets of human judgements.", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 22, "end_pos": 34, "type": "METRIC", "confidence": 0.5483606159687042}]}, {"text": "For our main experiment, we always retrieve the top 20 highest-ranked role-fillers for the verb-role pair to compute the prototype set.", "labels": [], "entities": []}, {"text": "This allows our work to be more directly comparable with other implementations.", "labels": [], "entities": []}, {"text": "Also, choosing a value of n that maximizes \u03c1 would make this unsupervised system more supervised.", "labels": [], "entities": []}, {"text": "However, it is useful to know how the number of top role-fillers retrieved affects the correlation with human judgements, so as a follow-up experiment, we evaluate versions of the Centroid , OneBest, and kClusters methods, with the SDDMX and TypeDM models, retrieving from 10 to 50 top role-fillers, against the instruments dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Coverage (%) by dataset for each DM model.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9331782460212708}]}, {"text": " Table 3: Spearman's \u03c1 for each method on each dataset and on all datasets together, using the 20 highest ranked words  per verb-role.", "labels": [], "entities": [{"text": "\u03c1", "start_pos": 21, "end_pos": 22, "type": "METRIC", "confidence": 0.53336101770401}]}]}