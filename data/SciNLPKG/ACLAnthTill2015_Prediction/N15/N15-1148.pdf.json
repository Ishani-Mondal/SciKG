{"title": [{"text": "GPU-Friendly Local Regression for Voice Conversion", "labels": [], "entities": [{"text": "GPU-Friendly", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.892591118812561}, {"text": "Voice Conversion", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.6875498443841934}]}], "abstractContent": [{"text": "Voice conversion is the task of transforming a source speaker's voice so that it sounds like a target speaker's voice.", "labels": [], "entities": [{"text": "Voice conversion", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7349152565002441}]}, {"text": "We present a GPU-friendly local regression model for voice conversion that is capable of converting speech in real-time and achieves state-of-the-art accuracy on this task.", "labels": [], "entities": [{"text": "voice conversion", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.7743391692638397}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9990353584289551}]}, {"text": "Our model uses anew approximation for computing local regression coefficients that is explicitly designed to preserve memory locality.", "labels": [], "entities": []}, {"text": "As a result, our inference procedure is amenable to efficient implementation on the GPU.", "labels": [], "entities": [{"text": "GPU", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9694989323616028}]}, {"text": "Our approach is more than 10X faster than a highly optimized CPU-based implementation, and is able to convert speech 2.7X faster than real-time.", "labels": [], "entities": []}], "introductionContent": [{"text": "Voice conversion is the task of transforming an utterance from a source speaker's voice into a target speaker's voice.", "labels": [], "entities": [{"text": "Voice conversion", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7118759304285049}]}, {"text": "The primary setup in recent work has been to learn this transformation from a parallel corpus consisting of recordings of the same sequence of sentences read by both source and target speakers ().", "labels": [], "entities": []}, {"text": "The converted speech is evaluated by how well its spectral properties match those of the target voice.", "labels": [], "entities": []}, {"text": "While various models have been proposed (), the most accurate ones are non-parametric because the mapping between two voices' spectra can be highly non-linear ().", "labels": [], "entities": []}, {"text": "Unfortunately, while non-parametric methods are accurate, they are also slow -current non-parametric approaches to voice conversion are too compute-intensive for the real-time speed required by many voice conversion applications.", "labels": [], "entities": [{"text": "voice conversion", "start_pos": 115, "end_pos": 131, "type": "TASK", "confidence": 0.7396697551012039}, {"text": "voice conversion", "start_pos": 199, "end_pos": 215, "type": "TASK", "confidence": 0.7838262617588043}]}, {"text": "In this paper, we begin with the state-of-the-art local linear regression (LLR) model used by by for voice conversion, and present anew GPU-based inference approach that greatly accelerates it, to much faster than real-time.", "labels": [], "entities": [{"text": "voice conversion", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.761418342590332}]}, {"text": "LLR, in principle, requires each new model prediction to be a function of the entire set of training examples.", "labels": [], "entities": [{"text": "LLR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7821909189224243}]}, {"text": "In practice, LLR depends most strongly on nearby points, so a standard CPU implementation will skip distant points, with limited loss of accuracy.", "labels": [], "entities": [{"text": "LLR", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9731152653694153}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.996679425239563}]}, {"text": "A GPU cannot exploit sparsity in the same way (scan and skip) without suffering from memory bottlenecks, but even a GPU will be relatively slow if all training points are included in each computation.", "labels": [], "entities": []}, {"text": "Our primary algorithmic change is to make use of anew sparsity structure that allows the GPU to skip major sections of the training data while still using dense memory access patterns on the points it does process.", "labels": [], "entities": []}, {"text": "In experiments, this inference technique is more than 10X faster than a highly-optimized CPUbased implementation, operates almost three times faster than real-time, and is only slightly less accurate than the CPU-based method.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run a series of experiments to determine whether our GPU-based inference technique offers speedsups and at what cost to accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9979822635650635}]}, {"text": "Baselines We compare our LLR-based conversion system that performs inference on the GPU (using the GPU-friendly neighborhood function) with two different baseline systems.", "labels": [], "entities": [{"text": "LLR-based conversion", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.8014309406280518}]}, {"text": "The first baseline system also uses LLR, but performs inference on the CPU using the standard neighborhood function.", "labels": [], "entities": []}, {"text": "The second baseline is the GMM model of, which is known to be fast and is widely used in practice.", "labels": [], "entities": [{"text": "GMM", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.7843989133834839}]}, {"text": "The size, K, of both CPU and GPU neighborhoods was set on a development data to the smallest value that did not show degraded performance compared to exact local regression.", "labels": [], "entities": []}, {"text": "Implementation We implemented our GPUbased LLR technique using the CUDA API (, and the CUBLAS API which contains bindings for GPU BLAS routines.", "labels": [], "entities": []}, {"text": "We ran the system using an NVIDIA Tesla K40c GPU.", "labels": [], "entities": []}, {"text": "We built a multi-threaded implementation of CPU-based inference for local regression using calls to CPU BLAS routines, and ran this system on a 4.4GHz 4-core Intel CPU.", "labels": [], "entities": []}, {"text": "Data We train and test on a portion of the CMU Arctic database.", "labels": [], "entities": [{"text": "CMU Arctic database", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.9707236091295878}]}, {"text": "The training data consists of 70 sentences spoken by both a US female speaker and a Scottish male speaker.", "labels": [], "entities": []}, {"text": "The testing data consists of 20 sentences spoken by the same two speakers.", "labels": [], "entities": []}, {"text": "We give results for converting in both directions, from the female voice to the male voice, and from the male voice to the female voice.", "labels": [], "entities": []}, {"text": "Frame Alignment Since the source and target speakers speak at slightly different rates, our training data consist of different numbers of frames for each training sentence.", "labels": [], "entities": [{"text": "Frame Alignment", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7867950797080994}]}, {"text": "We use dynamic time warping to induce the frame alignment.", "labels": [], "entities": [{"text": "frame alignment", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.6628428399562836}]}, {"text": "Specifically, we find the minimum cost monotonic alignment from source frames into target frames where the cost of each alignment edge is the L2 distance between the corresponding vectors.", "labels": [], "entities": []}, {"text": "We use a distortion limit of 2, and a linear distortion cost.", "labels": [], "entities": [{"text": "distortion", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.9853803515434265}]}, {"text": "Analysis and Synthesis We use the CMU implementation of the STRAIGHT analysis and synthesis methods introduced by.", "labels": [], "entities": [{"text": "CMU", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.9023587107658386}, {"text": "STRAIGHT", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.6009405851364136}]}, {"text": "This is the same method used many state-of-the-art voice conversion systems, included our GMM baseline of.", "labels": [], "entities": [{"text": "GMM baseline", "start_pos": 90, "end_pos": 102, "type": "DATASET", "confidence": 0.9255299866199493}]}, {"text": "We transform the top 24 cepstral coefficients using our system, but process the power coefficient and fundamental frequency separately, using simple transformations for the latter two components.", "labels": [], "entities": []}, {"text": "Evaluation In order to evaluate the accuracy of our model we measure the cepstral distortion between the predicted ceptstral frames\u02c6yframes\u02c6 frames\u02c6y and the actual cepstral frames for the target voice y.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.99931800365448}]}, {"text": "The cepstral distortion is calculated as follows: distortion(\u02c6 y, y) \u221d \u02c6 y \u2212 y We using dynamic time warping to align the predicted frame sequence to the target frame sequence.", "labels": [], "entities": [{"text": "distortion", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9934681057929993}]}], "tableCaptions": [{"text": " Table 1: Voice conversion results for the GMM baseline system, CPU-based local linear regression baseline system, and the GPU- based local linear regression method. The cepstral distortion (CD), average inference time per sentence in seconds (Time), and  fraction of real-time (Frac. RT) are shown. Smaller cepstral distortion corresponds to more accurate transformations and fractions  of real-time that exceed one imply faster than real-time operation.", "labels": [], "entities": [{"text": "Voice conversion", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7066950649023056}, {"text": "GMM baseline", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.9194584786891937}, {"text": "cepstral distortion (CD)", "start_pos": 170, "end_pos": 194, "type": "METRIC", "confidence": 0.8229209184646606}, {"text": "average inference time per sentence in seconds (Time)", "start_pos": 196, "end_pos": 249, "type": "METRIC", "confidence": 0.8654471039772034}, {"text": "fraction of real-time (Frac. RT)", "start_pos": 256, "end_pos": 288, "type": "METRIC", "confidence": 0.6688750513962337}]}]}