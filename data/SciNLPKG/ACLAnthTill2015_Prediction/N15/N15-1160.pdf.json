{"title": [{"text": "Large-scale Native Language Identification with Cross-Corpus Evaluation", "labels": [], "entities": [{"text": "Large-scale Native Language Identification", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.6046923100948334}]}], "abstractContent": [{"text": "We present a large-scale Native Language Identification (NLI) experiment on new data, with a focus on cross-corpus evaluation to identify corpus-and genre-independent language transfer features.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.8207511603832245}]}, {"text": "We test anew corpus and show it is comparable to other NLI corpora and suitable for this task.", "labels": [], "entities": []}, {"text": "Cross-corpus evaluation on two large corpora achieves good accuracy and evidences the existence of reliable language transfer features, but lower performance also suggests that NLI models are not completely portable across corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9989778995513916}]}, {"text": "Finally , we present a briefcase study of features distinguishing Japanese learners' En-glish writing, demonstrating the presence of cross-corpus and cross-genre language transfer features that are highly applicable to SLA and ESL research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native Language Identification, the task of determining the native language (L1) of an author based on a second language (L2) text, has received much attention recently.", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.67867444952329}, {"text": "determining the native language (L1) of an author based on a second language (L2) text", "start_pos": 44, "end_pos": 130, "type": "TASK", "confidence": 0.6875864079124049}]}, {"text": "Much of this is motivated by Second Language Acquisition (SLA) as NLI, often accomplished via machine learning methods, can be used to study language transfer effects.", "labels": [], "entities": [{"text": "Second Language Acquisition (SLA)", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.7717241744200388}, {"text": "language transfer effects", "start_pos": 141, "end_pos": 166, "type": "TASK", "confidence": 0.7698801457881927}]}, {"text": "Most NLI research hitherto has focused on identifying linguistic phenomena that can capture transfer effects, with little effort towards interpreting discriminant features.", "labels": [], "entities": []}, {"text": "Some researchers have now shifted their focus to developing data-driven methods for the automatic extraction and ranking of linguistic features that distinguish specific L1s.", "labels": [], "entities": [{"text": "automatic extraction and ranking of linguistic features", "start_pos": 88, "end_pos": 143, "type": "TASK", "confidence": 0.7828014322689602}]}, {"text": "Such methods could be used not only to confirm existing SLA hypotheses, but also to create new ones.", "labels": [], "entities": []}, {"text": "This hypothesis formulation is an inherently difficult problem requiring copious amounts of data.", "labels": [], "entities": [{"text": "hypothesis formulation", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.7501004934310913}]}, {"text": "Contrary to this requirement, researchers have long noted the paucity of suitable corpora 1 for this task ().", "labels": [], "entities": []}, {"text": "This is one of the research issues addressed by this work.", "labels": [], "entities": []}, {"text": "Furthermore, deriving SLA hypotheses from a single corpus may not be entirely useful for SLA research.", "labels": [], "entities": [{"text": "SLA hypotheses", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.8311624526977539}, {"text": "SLA", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9822167158126831}]}, {"text": "Many variables like genre and topic are constant within a corpus, restricting the validity of such cross-validation studies to those dimensions.", "labels": [], "entities": []}, {"text": "An alternative, potentially more helpful approach, is to identify transfer features that reliably distinguish an L1 across multiple corpora of differing genres and domains.", "labels": [], "entities": []}, {"text": "A cross-corpus methodology maybe a more promising avenue to finding features that generalize to diverse text sources, but requires additional large corpora.", "labels": [], "entities": []}, {"text": "It is also a more realistic approach, and one we pursue in this work.", "labels": [], "entities": []}, {"text": "Accordingly, the aims of the present work are to: (1) test a large new corpus suitable for NLI, (2) perform within-corpus evaluation with a comparative analysis against equivalent corpora, (3) perform cross-corpus evaluation to determine the efficiency of corpus independent features and (4) analyze the features' utility for SLA & ESL research.", "labels": [], "entities": [{"text": "SLA & ESL research", "start_pos": 326, "end_pos": 344, "type": "TASK", "confidence": 0.8520732372999191}]}], "datasetContent": [{"text": "Our first experiment applies 10-fold cross-validation within the corpus to assess feature efficacy.", "labels": [], "entities": []}, {"text": "The results are shown in the first column of.", "labels": [], "entities": []}, {"text": "All features perform substantially higher than the 9% baseline.", "labels": [], "entities": []}, {"text": "POS trigrams are the best single feature (53%), suggesting there exist significant interclass syntactic differences.", "labels": [], "entities": []}, {"text": "Next, we also combined all features using a classifier ensemble, which has been shown to be helpful for NLI.", "labels": [], "entities": []}, {"text": "This yields the best accuracy of 65% against an upper-bound of 87% set by the oracle.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9995390176773071}]}, {"text": "We also compare these results to those from the TOEFL11 and Chinese Learner Corpus (CLC).", "labels": [], "entities": [{"text": "TOEFL11", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9301728010177612}, {"text": "Chinese Learner Corpus (CLC)", "start_pos": 60, "end_pos": 88, "type": "DATASET", "confidence": 0.9167933265368143}]}, {"text": "As shown in, we find that feature performance is nearly identical across corpora.", "labels": [], "entities": []}, {"text": "Consistent with the results in, this seems to suggest an invariant degree of transfer across different learners and L1-L2 pairs.", "labels": [], "entities": []}, {"text": "German is the most correctly classified L1, while the highest confusion is between Japanese-Korean, followed by Spanish-Portuguese and French-Italian.", "labels": [], "entities": [{"text": "confusion", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9845759868621826}]}, {"text": "This is not surprising given their syntactic similarity as well as being typologically related in case of the latter two.", "labels": [], "entities": []}, {"text": "Our second experiment tests the cross-corpus efficacy of the features by training on EFCAMDAT and testing on TOEFL11, and vice versa.", "labels": [], "entities": [{"text": "EFCAMDAT", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.6224585771560669}, {"text": "TOEFL11", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.6914069652557373}]}, {"text": "As the corpus texts are from different genres, this approach enables The 9 common classes discussed in \u00a73 are used.", "labels": [], "entities": []}, {"text": "us to test the cross-corpus and cross-genre generalizability of our features.", "labels": [], "entities": []}, {"text": "Results are shown in the second and third column of.", "labels": [], "entities": []}, {"text": "While lower than the cross-validation results which were on 11 classes vs 9 here, the results are far greater than the baseline.", "labels": [], "entities": []}, {"text": "The accuracy for training on EFCAMDAT and testing on TOEFL11 is higher (33.45%) than the other way around (28.42%), even though TOEFL11 is the larger corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997488856315613}, {"text": "EFCAMDAT", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.8961978554725647}, {"text": "TOEFL11", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.8640816807746887}, {"text": "TOEFL11", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.8862857818603516}]}, {"text": "This is possibly because EFCAMDAT has numerous genres while TOEFL11 does not.", "labels": [], "entities": [{"text": "EFCAMDAT", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.9305185675621033}, {"text": "TOEFL11", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9445967078208923}]}, {"text": "The cross-corpus oracle is also over 20% lower, despite an increase in the random baseline, showing some features are not portable across corpora.", "labels": [], "entities": []}, {"text": "Training on TOEFL11 yields a lower oracle.", "labels": [], "entities": [{"text": "TOEFL11", "start_pos": 12, "end_pos": 19, "type": "DATASET", "confidence": 0.841127872467041}]}], "tableCaptions": [{"text": " Table 2: Classification accuracy (%) for our within-and cross-corpus experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8654170036315918}]}]}