{"title": [{"text": "Socially-Informed Timeline Generation for Complex Events", "labels": [], "entities": []}], "abstractContent": [{"text": "Existing timeline generation systems for complex events consider only information from traditional media, ignoring the rich social context provided by user-generated content that reveals representative public interests or in-sightful opinions.", "labels": [], "entities": [{"text": "timeline generation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7887891232967377}]}, {"text": "We instead aim to generate socially-informed timelines that contain both news article summaries and selected user comments.", "labels": [], "entities": []}, {"text": "We present an optimization framework designed to balance topical cohesion between the article and comment summaries along with their informativeness and coverage of the event.", "labels": [], "entities": []}, {"text": "Automatic evaluations on real-world datasets that cover four complex events show that our system produces more informative timelines than state-of-the-art systems.", "labels": [], "entities": []}, {"text": "In human evaluation, the associated comment summaries are furthermore rated more insightful than editor's picks and comments ranked highly by users.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social media sites on the Internet provide increasingly more, and increasingly popular, means for people to voice their opinions on trending events.", "labels": [], "entities": []}, {"text": "Traditional news media -the New York Times and CNN, for example -now provide online mechanisms that allow and encourage readers to share reactions, opinions, and personal experiences relevant to a news story.", "labels": [], "entities": []}, {"text": "For complex emerging events, in particular, user comments can provide relevant, interesting and insightful information beyond the facts reported in the news.", "labels": [], "entities": []}, {"text": "But their large volume and tremendous variation in quality make it impossible * Comment A: The \"Crimean Parliament\", headed by an ethnic Russian separatist who was elected leader of parliament AFTER pro-Russian armed forces occupied the parliamentary chambers, has voted for Crimea to be annexed into Russia\u2026 * Comment B: Does the West and US have a policy at all?", "labels": [], "entities": []}, {"text": "The Obama administration has warned of \"increasingly harsh sanctions\", but it is unlikely that Europe will comply\u2026", "labels": [], "entities": []}], "datasetContent": [{"text": "We test importance scorers (Section 3) on single document sentence ranking and comment ranking.", "labels": [], "entities": [{"text": "single document sentence ranking", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.5992049872875214}]}, {"text": "For both tasks, we compare with two previous systems on joint ranking and summarization of news articles and tweets.", "labels": [], "entities": [{"text": "summarization of news articles and tweets", "start_pos": 74, "end_pos": 115, "type": "TASK", "confidence": 0.8844251831372579}]}, {"text": "employ supervised learning based on factor graphs to model content similarity between the two types of data.", "labels": [], "entities": []}, {"text": "We use the same features for this model.", "labels": [], "entities": []}, {"text": "summarize by including the complementary information between articles and tweets, which is estimated by an unsupervised topic model.", "labels": [], "entities": []}, {"text": "We also consider two state-of-the-art rankers: RankBoost ( and.", "labels": [], "entities": [{"text": "RankBoost", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.9180777668952942}]}, {"text": "Finally, we use a position baseline that ranks sentences based on their position in the article, and a rating baseline that ranks comments based on positive user ratings.", "labels": [], "entities": []}, {"text": "We evaluate using normalized discounted cumulative gain at top 3 returned results (NDCG@3).", "labels": [], "entities": [{"text": "NDCG", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.6307603120803833}]}, {"text": "Sentences are considered relevant if they have ROUGE-2 scores larger than 0.0 (computed against human abstracts), and comments are considered relevant if they are editor's picks.", "labels": [], "entities": [{"text": "ROUGE-2 scores", "start_pos": 47, "end_pos": 61, "type": "METRIC", "confidence": 0.9705197811126709}]}, {"text": "4 demonstrates that our joint learning model uniformly outperforms all the other comparisons for both ranking tasks.", "labels": [], "entities": []}, {"text": "In general, supervised learning based approaches (e.g. our method,, RankBoost, and LambdaMART) produce better results than unsupervised method (e.g. ). Figure 3: Evaluation of sentence and comment ranking on the four datasets by using normalized discounted cumulative gain at top 3 returned results (NDCG@3).", "labels": [], "entities": []}, {"text": "Our joint learning based approach uniformly outperforms all the other comparisons.", "labels": [], "entities": []}, {"text": "Here we evaluate on the utility of event threads for high-level information access guidance: can event threads allow users to easily locate and absorb information with a specific interest in mind?", "labels": [], "entities": [{"text": "information access guidance", "start_pos": 64, "end_pos": 91, "type": "TASK", "confidence": 0.6947529911994934}]}, {"text": "We first sample a 10-day timeline for each dataset from those produced by the THREAD+OPT WordVec variation of our system.", "labels": [], "entities": [{"text": "THREAD+OPT WordVec variation", "start_pos": 78, "end_pos": 106, "type": "DATASET", "confidence": 0.6324211776256561}]}, {"text": "We designed one question for each timeline.", "labels": [], "entities": []}, {"text": "Sample questions are: \"describe the activities for searching for the missing flight MH370\", and \"describe the attitude and action of Russian Government on Eastern Ukraine\".", "labels": [], "entities": [{"text": "MH370", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.7947073578834534}]}, {"text": "We recruited 10 undergraduate and graduate students who are native speakers of English.", "labels": [], "entities": []}, {"text": "Each student first read one question and its corresponding timeline for 5 minutes.", "labels": [], "entities": []}, {"text": "The timeline was then removed, and the student wrote down an answer for the question.", "labels": [], "entities": []}, {"text": "We asked each student to answer the question for each of four timelines (one for each event dataset).", "labels": [], "entities": []}, {"text": "Two timelines are displayed with threads, and two without threads.", "labels": [], "entities": []}, {"text": "We presented threads by adding a thread number in front of each sentence.", "labels": [], "entities": []}, {"text": "We then used Amazon Mechanical Turk to evaluate the informativeness of students' answers.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 13, "end_pos": 35, "type": "DATASET", "confidence": 0.9297885100046793}]}, {"text": "Turkers were asked to read all 10 answers for the same question, with five answers based on timelines with threads and five others based on timelines without threads.", "labels": [], "entities": []}, {"text": "After that, they rated each answer with an informativeness score on a 1-to-5 rating scale (1 as \"not relevant to the query\", and 5 as \"very informative\").", "labels": [], "entities": []}, {"text": "We also added two quality control questions.", "labels": [], "entities": []}, {"text": "shows that the average rating for answers written after reading timelines with threads is 3.29 (43% are rated \u2265 4), higher than the 2.58 for the timelines with no thread exhibited (30% are rated \u2265 4).", "labels": [], "entities": []}, {"text": "Answer Type Avg \u00b1 STD Rated 5 (%) Rated 4 (%) No Thread 2.58 \u00b1 1.20 7% 23% With Threads 3.29 \u00b1 1.28 17% 26%: Human evaluation on the informativeness of answers written after reading timelines with threads vs. with no thread.", "labels": [], "entities": [{"text": "Answer Type Avg \u00b1 STD Rated 5", "start_pos": 0, "end_pos": 29, "type": "METRIC", "confidence": 0.7056241418634143}]}, {"text": "Answers written with access to threads are rated higher (3.29) than the ones with no thread (2.58).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on the four event datasets.", "labels": [], "entities": []}, {"text": " Table 4: ROUGE-2 (R-2) and ROUGE-SU4 (R-SU4)", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9401580095291138}, {"text": "ROUGE-SU4", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.8747081756591797}]}, {"text": " Table 5: Human evaluation results on the comment por-", "labels": [], "entities": []}]}