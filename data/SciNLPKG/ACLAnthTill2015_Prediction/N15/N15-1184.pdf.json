{"title": [{"text": "Retrofitting Word Vectors to Semantic Lexicons", "labels": [], "entities": [{"text": "Retrofitting Word Vectors", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8905512690544128}]}], "abstractContent": [{"text": "Vector space word representations are learned from distributional information of words in large corpora.", "labels": [], "entities": [{"text": "Vector space word representations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7009328901767731}]}, {"text": "Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 142, "end_pos": 149, "type": "DATASET", "confidence": 0.9690441489219666}]}, {"text": "This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.", "labels": [], "entities": []}, {"text": "Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models.", "labels": [], "entities": []}, {"text": "Our refinement method outperforms prior techniques for incorporating semantic lexicons into word vector training algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven learning of word vectors that capture lexico-semantic information is a technique of central importance in NLP.", "labels": [], "entities": []}, {"text": "These word vectors can in turn be used for identifying semantically related word pairs) or as features in downstream text processing applications (.", "labels": [], "entities": []}, {"text": "A variety of approaches for constructing vector space embeddings of vocabularies are in use, notably including taking low rank approximations of cooccurrence statistics) and using internal representations from neural network models of word sequences.", "labels": [], "entities": []}, {"text": "Because of their value as lexical semantic representations, there has been much research on improving the quality of vectors.", "labels": [], "entities": []}, {"text": "Semantic lexicons, which provide type-level information about the semantics of words, typically by identifying synonymy, hypernymy, hyponymy, and paraphrase relations should be a valuable resource for improving the quality of word vectors that are trained solely on unlabeled corpora.", "labels": [], "entities": []}, {"text": "Examples of such resources include WordNet, FrameNet ( and the Paraphrase Database (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9562727212905884}]}, {"text": "Recent work has shown that by either changing the objective of the word vector training algorithm in neural language models () or by relation-specific augmentation of the cooccurence matrix in spectral word vector models to incorporate semantic knowledge (), the quality of word vectors can be improved.", "labels": [], "entities": []}, {"text": "However, these methods are limited to particular methods for constructing vectors.", "labels": [], "entities": []}, {"text": "The contribution of this paper is a graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call \"retrofitting.\"", "labels": [], "entities": []}, {"text": "In contrast to previous work, retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors ( \u00a72).", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7433106899261475}]}, {"text": "This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.", "labels": [], "entities": []}, {"text": "Intuitively, our method encourages the new vectors to be (i) similar to the vectors of related word types and (ii) similar to their purely distributional representations.", "labels": [], "entities": []}, {"text": "The retrofitting process is fast, taking about 5 seconds fora graph of 100,000 words and vector length 300, and its runtime is independent of the original word vector training model.", "labels": [], "entities": []}, {"text": "Experimentally, we show that our method works well with different state-of-the-art word vector models, using different kinds of semantic lexicons and gives substantial improvements on a variety of benchmarks, while beating the current state-of-theart approaches for incorporating semantic information in vector training and trivially extends to multiple languages.", "labels": [], "entities": []}, {"text": "We show that retrofitting gives consistent improvement in performance on evaluation benchmarks with different word vector lengths and show a qualitative visualization of the effect of retrofitting on word vector quality.", "labels": [], "entities": []}, {"text": "The retrofitting tool is available at: https://github.com/ mfaruqui/retrofitting.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the quality of our word vector representations on tasks that test how well they capture both semantic and syntactic aspects of the representations along with an extrinsic sentiment analysis task.", "labels": [], "entities": [{"text": "extrinsic sentiment analysis", "start_pos": 173, "end_pos": 201, "type": "TASK", "confidence": 0.6589202384154002}]}, {"text": "We evaluate our word representations on a variety of different benchmarks that have been widely used to measure word similarity.) between the rankings produced by our model against the human rankings.", "labels": [], "entities": []}, {"text": "given a, b, and c.", "labels": [], "entities": []}, {"text": "We use the vector offset method (), computing q = q a \u2212 q b + q c and returning the vector from Q which has the highest cosine similarity to q.", "labels": [], "entities": [{"text": "vector offset", "start_pos": 11, "end_pos": 24, "type": "TASK", "confidence": 0.6637539714574814}]}, {"text": "Synonym Selection (TOEFL).", "labels": [], "entities": [{"text": "Synonym Selection (TOEFL)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7926376700401306}]}, {"text": "The TOEFL synonym selection task is to select the semantically closest word to a target from a list of four candidates).", "labels": [], "entities": [{"text": "TOEFL synonym selection", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.8311889966328939}]}, {"text": "The dataset contains 80 such questions.", "labels": [], "entities": []}, {"text": "An example is \"rug \u2192 {sofa, ottoman, carpet, hallway}\", with carpet being the most synonym-like candidate to the target.", "labels": [], "entities": []}, {"text": "Sentiment Analysis (SA).", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8797558784484864}]}, {"text": "Socher et al. created a treebank containing sentences annotated with fine-grained sentiment labels on phrases and sentences from movie review excerpts.", "labels": [], "entities": []}, {"text": "The coarsegrained treebank of positive and negative classes has been split into training, development, and test datasets containing 6,920, 872, and 1,821 sentences, respectively.", "labels": [], "entities": []}, {"text": "We train an 2 -regularized logistic regression classifier on the average of the word vectors of a given sentence to predict the coarse-grained sentiment tag at the sentence level, and report the testset accuracy of the classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9959405660629272}]}, {"text": "We first show experiments measuring improvements from the retrofitting method ( \u00a76.1), followed by comparisons to using lexicons during MAP learning ( \u00a76.2) and other published methods ( \u00a76.3).", "labels": [], "entities": [{"text": "MAP learning", "start_pos": 136, "end_pos": 148, "type": "TASK", "confidence": 0.8235639035701752}]}, {"text": "We then test how well retrofitting generalizes to other languages ( \u00a76.4).", "labels": [], "entities": []}, {"text": "We tested our method on three additional languages: German, French, and Spanish.", "labels": [], "entities": []}, {"text": "We used the Universal WordNet (de, an automatically constructed multilingual lexical knowledge base based on WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.9553515911102295}]}, {"text": "12 It contains words connected via different lexical relations to other words both within and across languages.", "labels": [], "entities": []}, {"text": "We construct separate graphs for different languages (i.e., only linking words to other words in the same language) and apply retrofitting to each.", "labels": [], "entities": []}, {"text": "Since not many word similarity evaluation benchmarks are available for languages other than English, we tested our baseline and improved vectors on one benchmark per language.", "labels": [], "entities": []}, {"text": "We used RG-65), RG-65 () for German, French and Spanish, respectively.", "labels": [], "entities": []}, {"text": "We trained SG vectors for each language of length 300 on a corpus of 1 billion tokens, each extracted from Wikipedia, and evaluate them on word similarity on the benchmarks before and after retrofitting.", "labels": [], "entities": []}, {"text": "shows that we obtain high improvements which strongly indicates that our method generalizes across these languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Approximate size of the graphs obtained from  different lexicons.", "labels": [], "entities": [{"text": "Approximate size", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9477623999118805}]}, {"text": " Table 2: Absolute performance changes with retrofitting. Spearman's correlation (3 left columns) and accuracy (3  right columns) on different tasks. Higher scores are always better. Bold indicates greatest improvement for a vector  type.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9849087595939636}, {"text": "Spearman's correlation", "start_pos": 58, "end_pos": 80, "type": "METRIC", "confidence": 0.9369632601737976}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9994045495986938}]}, {"text": " Table 3: Absolute performance changes for including PPDB information while training LBL vectors. Spearman's  correlation (3 left columns) and accuracy (3 right columns) on different tasks. Bold indicates greatest improvement.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9823836088180542}, {"text": "Spearman's  correlation", "start_pos": 98, "end_pos": 121, "type": "METRIC", "confidence": 0.9211455583572388}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9993244409561157}]}, {"text": " Table 4: Comparison of retrofitting for semantic enrichment against Yu and Dredze (2014), Xu et al. (2014). Spear- man's correlation (3 left columns) and accuracy (3 right columns) on different tasks.", "labels": [], "entities": [{"text": "semantic enrichment", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7618102729320526}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9985798597335815}]}, {"text": " Table 5: Spearman's correlation for word similarity eval- uation using the using original and retrofitted SG vectors.", "labels": [], "entities": []}]}