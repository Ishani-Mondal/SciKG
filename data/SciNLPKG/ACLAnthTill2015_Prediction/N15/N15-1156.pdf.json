{"title": [{"text": "CASSA: A Context-Aware Synonym Simplification Algorithm", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew context-aware method for lexical simplification that uses two free language resources and real web frequencies.", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.742528110742569}]}, {"text": "We compare it with the state-of-the-art method for lexical simplification in Spanish and the established simplification baseline, that is, the most frequent synonym.", "labels": [], "entities": []}, {"text": "Our method improves upon the other methods in the detection of complex words, in meaning preservation, and in simplicity.", "labels": [], "entities": [{"text": "meaning preservation", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7949213683605194}, {"text": "simplicity", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.9637568593025208}]}, {"text": "Although we use Spanish, the method can be extended to other languages since it does not require alignment of parallel corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Simplified text is crucial for some populations to read effectively, especially for cognitively impaired people such as people with autism spectrum disorder (), aphasia), dyslexia (), Down syndrome (), or other intellectual disabilities.", "labels": [], "entities": []}, {"text": "In fact, the United Nations proposed a set of standard rules to leverage document accessibility for persons with disabilities.", "labels": [], "entities": []}, {"text": "Text simplification attempts to solve this problem automatically by reducing the complexity of the lexicon, syntax, or semantics while attempting to preserve its meaning and information content).", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8061708509922028}]}, {"text": "Among all the types of text simplification this paper focuses on lexical simplification.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7055033594369888}, {"text": "lexical simplification", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7103309035301208}]}, {"text": "Lexical simplification methods require language resources, such as simplified corpora or synonyms dictionaries.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8696805536746979}]}, {"text": "For languages with less resources than English, e.g. no Simple Wikipedia) or less representation in WordNet, such as Spanish, 1 the creation of lexical simplification methods is more challenging.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.9311192631721497}]}, {"text": "Our approach makes use of two free resources, Google Books Ngram Corpus and the Spanish OpenThesaurus, as well as real web frequencies to create a lexical simplification system.", "labels": [], "entities": [{"text": "Google Books Ngram Corpus", "start_pos": 46, "end_pos": 71, "type": "DATASET", "confidence": 0.8802808672189713}]}, {"text": "Our system improves upon the state of the art for lexical simplification in Spanish and the established simplification baseline, i.e., the most frequent synonym, in several aspects: complex word detection, meaning preservation, and simplicity.", "labels": [], "entities": [{"text": "word detection", "start_pos": 190, "end_pos": 204, "type": "TASK", "confidence": 0.697946161031723}, {"text": "meaning preservation", "start_pos": 206, "end_pos": 226, "type": "TASK", "confidence": 0.7355494499206543}, {"text": "simplicity", "start_pos": 232, "end_pos": 242, "type": "METRIC", "confidence": 0.9714870452880859}]}, {"text": "We also show the coverage of our technique in a collection of books in Spanish, as this is another relevant measure of a simplification algorithm.", "labels": [], "entities": [{"text": "coverage", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9693917036056519}]}, {"text": "The method is language independent and given that these resources are available in other languages, it could be easily extended to other languages with similar language resources.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents related work.", "labels": [], "entities": []}, {"text": "Then in Section 3 we present the simplification algorithm while in Sections 4 and 5 we present our experimental evaluation.", "labels": [], "entities": []}, {"text": "Finally, in Section 6 we discuss our results, extensions to other languages, and outline future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Main dataset: From a set of texts of scientific and literature genres (37,876 words), we randomly selected [LOW] and 20 complex words within the sentence they appear, together with their corresponding candidate for substitution generated by the Baseline, LexSiS, and ours (a valid sentence must had at least 2 different substitutions).", "labels": [], "entities": [{"text": "LOW", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9758749008178711}, {"text": "LexSiS", "start_pos": 255, "end_pos": 261, "type": "DATASET", "confidence": 0.9098394513130188}]}, {"text": "We had in total 120 simplification examples (composed by an original and a simplified sentence).", "labels": [], "entities": []}, {"text": "shows a set of substitutions along with the original sentence.", "labels": [], "entities": []}, {"text": "Similar studies had smaller or slightly larger evaluation data sets.", "labels": [], "entities": []}, {"text": "In, 200 simplification examples were rated by six annotators (three native, three non-native speakers of English), although only the native speakers annotations were used for the results because they yielded higher inter-annotator agreement.", "labels": [], "entities": []}, {"text": "used 130 examples that were judged by three annotators (native English speakers).", "labels": [], "entities": []}, {"text": "In, three annotators (native speakers of Spanish) rated 69 sentences each of the Spanish lexical simplification performed by LexSiS.", "labels": [], "entities": [{"text": "LexSiS", "start_pos": 125, "end_pos": 131, "type": "DATASET", "confidence": 0.9753875732421875}]}, {"text": "Complexity dataset: This dataset was created to evaluate the degree of complexity of the words selected by the algorithms.", "labels": [], "entities": []}, {"text": "Using the same texts as before we extracted 40 random complex words according to LexSiS and 40 according to our method (recall that those also are complex for the baseline).", "labels": [], "entities": [{"text": "LexSiS", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.9711167812347412}]}, {"text": "As not all possible contexts appear in Google Books Ngrams, we created a corpus made of 195 classic literature books from the 15th century to the 20th century of over 100Mb, to check the coverage of our The coverage of the Spanish Open Thesaurus in our corpus is 88.34%.", "labels": [], "entities": []}, {"text": "5 This is the maximum that any simplification algorithm that uses this resource can obtain.", "labels": [], "entities": []}, {"text": "In we present the coverage of the baseline and our method depending on the threshold k used to decide what a complex word is and hence a complex content, including the absolute percentages as well as the relative percentages with respect to the complex words or contexts.", "labels": [], "entities": []}, {"text": "For smaller k, the coverage of the baseline increases significantly being the maximum possible 84.43% when all words are considered complex (more than three times the default coverage).", "labels": [], "entities": [{"text": "coverage", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9700630903244019}]}, {"text": "On the other hand, our method does not increase much the coverage as that is limited by the context coverage reaching a maximum of 12.14%, only 27% more than the default case (k = 10).", "labels": [], "entities": [{"text": "coverage", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9906174540519714}]}, {"text": "This maximum, compared with the baseline is a bit more than 14% of the cases, implying that our method is equal to the baseline around 85% of the time.", "labels": [], "entities": []}, {"text": "Considering the maximum possible coverage of the baseline and assuming that all non covered sentences contain complex words (most probable case), the simplicity performance of the baseline drops to 53.1% while for ours would be 54.2% (that is, a 2.1% improvement).", "labels": [], "entities": [{"text": "simplicity", "start_pos": 150, "end_pos": 160, "type": "METRIC", "confidence": 0.9984496831893921}]}, {"text": "This should improve if any of the resources used grow.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average percentage scores in meaning preser- vation (Mean.), simplification (Simp.), and simplification  among the synonyms (SimpSyn.).", "labels": [], "entities": []}, {"text": " Table 2: Average percentage scores by frequency band.", "labels": [], "entities": [{"text": "Average percentage scores", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.9441078901290894}]}, {"text": " Table 3: Coverage of the baseline and our method.", "labels": [], "entities": []}]}