{"title": [{"text": "Unsupervised Induction of Semantic Roles within a Reconstruction-Error Minimization Framework", "labels": [], "entities": [{"text": "Unsupervised Induction of Semantic Roles within a Reconstruction-Error Minimization", "start_pos": 0, "end_pos": 83, "type": "TASK", "confidence": 0.6401183472739326}]}], "abstractContent": [{"text": "We introduce anew approach to unsupervised estimation of feature-rich semantic role labeling models.", "labels": [], "entities": [{"text": "feature-rich semantic role labeling", "start_pos": 57, "end_pos": 92, "type": "TASK", "confidence": 0.6148790493607521}]}, {"text": "Our model consists of two components: (1) an encoding component: a semantic role labeling model which predicts roles given a rich set of syntactic and lexical features; (2) a reconstruction component: a tensor factorization model which relies on roles to predict argument fillers.", "labels": [], "entities": []}, {"text": "When the components are estimated jointly to minimize errors in argument reconstruction, the induced roles largely correspond to roles defined in annotated resources.", "labels": [], "entities": [{"text": "argument reconstruction", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.7379772216081619}]}, {"text": "Our method performs on par with most accurate role induction methods on English and German, even though, unlike these previous approaches, we do not incorporate any prior linguistic knowledge about the languages.", "labels": [], "entities": [{"text": "role induction", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.8260936439037323}]}], "introductionContent": [{"text": "Shallow semantic representations, and semantic role labels in particular, have along history in linguistics.", "labels": [], "entities": []}, {"text": "More recently, with an emergence of large annotated resources such as PropBank () and FrameNet (), automatic semantic role labeling (SRL) has attracted a lot of attention (.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9463074803352356}, {"text": "automatic semantic role labeling (SRL)", "start_pos": 99, "end_pos": 137, "type": "TASK", "confidence": 0.7142867275646755}]}, {"text": "Semantic role representations encode the underlying predicate-argument structure of sentences, or, more specifically, for every predicate in a sentence they identify a set of arguments and associate each argument with an underlying semantic role, such as an agent (an initiator or doer of the action) or a patient (an affected entity).", "labels": [], "entities": []}, {"text": "Semantic roles have many potential applications in NLP and have been shown to benefit question answering, textual entailment (, machine translation (, and dialogue systems (), among others.", "labels": [], "entities": [{"text": "NLP", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9435057640075684}, {"text": "question answering", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.85202556848526}, {"text": "textual entailment", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7355695366859436}, {"text": "machine translation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7362305074930191}]}, {"text": "Most current statistical approaches to SRL are supervised, requiring large quantities of human annotated data to estimate model parameters.", "labels": [], "entities": [{"text": "SRL", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9949703812599182}]}, {"text": "However, such resources are expensive to create and only available fora small number of languages.", "labels": [], "entities": []}, {"text": "Moreover, when moved to anew domain (e.g., from news corpora to blogs or biomedical texts), the performance of these models tends to degrade substantially (.", "labels": [], "entities": []}, {"text": "The scarcity of annotated data has motivated the research into unsupervised learning of semantic representations).", "labels": [], "entities": []}, {"text": "The existing methods have a number of serious shortcomings.", "labels": [], "entities": []}, {"text": "First, they make very strong assumptions, for example, assuming that arguments are conditionally independent of each other given the predicate.", "labels": [], "entities": []}, {"text": "Second, unlike state-ofthe-art supervised parsers, they rely on a very simplistic set of features of a sentence.", "labels": [], "entities": []}, {"text": "These factors lead to models being insufficiently expressive to capture the syntax-semantics interface, inadequate 1 handling of language ambiguity and, overall, introduces a restrictive upper bound on their performance.", "labels": [], "entities": []}, {"text": "Moreover, these approaches are especially problematic for languages with freer word order than English, where richer features are necessary to account for interactions between surface realizations, syntax and semantics.", "labels": [], "entities": []}, {"text": "For example, the two most accurate previous models) both treat the role induction task as clustering of argument signatures: an argument signature encodes key syntactic properties of an argument realization and consists of a syntactic function of an argument along with additional information such as an argument position with respect to the predicate.", "labels": [], "entities": [{"text": "role induction", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.7184876501560211}]}, {"text": "Though it is possible to design signatures which mostly map to a single role, this set-up limits oracle performance even for English, and can be quite restrictive for languages with freer word order.", "labels": [], "entities": []}, {"text": "These shortcomings are inherent limitations of the modeling frameworks used in previous work (primarily generative modeling or agglomerative clustering), and cannot be addressed by simply incorporating more features or relaxing some of the modeling assumptions.", "labels": [], "entities": [{"text": "generative modeling", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.9434779584407806}]}, {"text": "In this work, we propose a method for effective unsupervised estimation of feature-rich models of semantic roles.", "labels": [], "entities": []}, {"text": "We demonstrate that reconstructionerror objectives, which have been shown to be effective primarily for training neural networks, are well suited for inducing feature-rich log-linear models of semantics.", "labels": [], "entities": []}, {"text": "Our model consists of two components: a log-linear feature-rich semantic role labeler and a tensor-factorization model which captures interaction between semantic roles and argument fillers.", "labels": [], "entities": []}, {"text": "When estimated jointly on unlabeled data, roles induced by the model mostly corresponds to roles defined in existing resources by annotators.", "labels": [], "entities": []}, {"text": "Our method rivals the most accurate semantic role induction methods on).", "labels": [], "entities": [{"text": "semantic role induction", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.6162905792395273}]}, {"text": "Importantly, no prior knowledge about the languages was incorporated in our feature-rich model, whereas the clustering counterparts relied on language-specific argument signatures.", "labels": [], "entities": []}, {"text": "These languages-specific priors were crucial for their success.", "labels": [], "entities": []}, {"text": "For example, using English-specific argument signatures for German with the Bayesian model of results in a drop of performance from clustering F1 of 80.9% to considerably lower 78.3% (our model yields 81.4%).", "labels": [], "entities": [{"text": "F1", "start_pos": 143, "end_pos": 145, "type": "METRIC", "confidence": 0.7576426267623901}]}, {"text": "This confirms the intuition that using richer features helps to capture the syntax-semantics interface in multilingual settings, reducing the need for languagespecific model engineering, as is highly desirable in unsupervised learning.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 begins with a definition of the semantic role labeling task and discusses some specifics of the unsupervised setting.", "labels": [], "entities": [{"text": "semantic role labeling task", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.7067669555544853}]}, {"text": "In Section 3, we describe our approach, starting with a general motivation and proceeding to technical details of the model (Section 3.3) and the learning procedure (Section 3.4).", "labels": [], "entities": []}, {"text": "Section 4 provides both evaluation and analysis.", "labels": [], "entities": []}, {"text": "Finally, additional related work is presented in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We considered English and German in our experiments.", "labels": [], "entities": []}, {"text": "For each language, we replicated experimental set-ups used in previous work.", "labels": [], "entities": []}, {"text": "For English, we followed Lang and Lapata and used the dependency version of PropBank () released for the CoNLL 2008 shared task ().", "labels": [], "entities": [{"text": "PropBank", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.8926418423652649}, {"text": "CoNLL 2008 shared task", "start_pos": 105, "end_pos": 127, "type": "DATASET", "confidence": 0.8412470370531082}]}, {"text": "The dataset is divided into three segments.", "labels": [], "entities": []}, {"text": "As in the previous work on unsupervised role labeling, we used the largest segment (the original CoNLL training set, sections 2-21) both for evaluation and learning.", "labels": [], "entities": [{"text": "role labeling", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.7117841243743896}, {"text": "CoNLL training set", "start_pos": 97, "end_pos": 115, "type": "DATASET", "confidence": 0.8666591048240662}]}, {"text": "This is permissible as unsupervised models do not use gold labels in training.", "labels": [], "entities": []}, {"text": "The two small segments (sections 22 and 23) were used for model development.", "labels": [], "entities": [{"text": "model development", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.9193120300769806}]}, {"text": "In our experiments, we relied on gold standard syntax and gold standard argument identification, as this set-up allows us to evaluate against much of the previous work.", "labels": [], "entities": [{"text": "gold standard argument identification", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.526629202067852}]}, {"text": "We refer the reader to for details of the experimental set-up.", "labels": [], "entities": []}, {"text": "There has not been much work on unsupervised induction of roles for languages other than English, perhaps primarily because of the above-mentioned model limitations.", "labels": [], "entities": []}, {"text": "For German, we replicate the set-up considered in.", "labels": [], "entities": []}, {"text": "They used the) of the SALSA corpus ().", "labels": [], "entities": [{"text": "SALSA corpus", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.7568405270576477}]}, {"text": "Instead of using syntactic parses provided in the CoNLL dataset, they re-parsed it with the MALT dependency parser ().", "labels": [], "entities": [{"text": "CoNLL dataset", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.972240686416626}]}, {"text": "Similarly, rather than relying on gold standard annotations for argument identification, they used a supervised classifier to predict argument positions.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.7892893850803375}]}, {"text": "Details of the preprocessing can be found in.", "labels": [], "entities": [{"text": "preprocessing", "start_pos": 15, "end_pos": 28, "type": "METRIC", "confidence": 0.965753436088562}]}, {"text": "As inmost previous work on unsupervised SRL, we evaluate our model using purity, collocation and their harmonic mean F1.", "labels": [], "entities": [{"text": "SRL", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9486689567565918}, {"text": "purity", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9870132803916931}, {"text": "F1", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.6765657663345337}]}, {"text": "Purity (PU) measures the average number of arguments with the same gold role label in each cluster, collocation (CO) measures to what extent a specific gold role is represented by a single cluster.", "labels": [], "entities": [{"text": "Purity (PU)", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9073439389467239}, {"text": "collocation (CO)", "start_pos": 100, "end_pos": 116, "type": "METRIC", "confidence": 0.6549666821956635}]}, {"text": "More formally: where if Ci is the set of arguments in the i-th induced cluster, G j is the set of arguments in the jth gold cluster, and N is the total number of arguments.", "labels": [], "entities": []}, {"text": "Similarly, for collocation: We compute the aggregate PU, CO, and F1 scores overall predicates in the same way as Lang and Lapata: we weight the scores for each predicate by the number of times its arguments occur and compute the weighted average.", "labels": [], "entities": [{"text": "F1", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9958699345588684}]}], "tableCaptions": [{"text": " Table 1: Results on English (PropBank / CoNLL 2008).", "labels": [], "entities": [{"text": "English (PropBank / CoNLL 2008)", "start_pos": 21, "end_pos": 52, "type": "DATASET", "confidence": 0.8980711613382611}]}, {"text": " Table 2: Results on German (SALSA / CoNLL 2009).", "labels": [], "entities": [{"text": "German (SALSA / CoNLL 2009)", "start_pos": 21, "end_pos": 48, "type": "DATASET", "confidence": 0.9114864724023002}]}]}