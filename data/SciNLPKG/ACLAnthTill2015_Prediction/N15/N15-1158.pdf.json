{"title": [{"text": "Sampling Techniques for Streaming Cross Document Coreference Resolution", "labels": [], "entities": [{"text": "Streaming Cross Document Coreference Resolution", "start_pos": 24, "end_pos": 71, "type": "TASK", "confidence": 0.7695032954216003}]}], "abstractContent": [{"text": "We present the first truly streaming cross document coreference resolution (CDC) system.", "labels": [], "entities": [{"text": "cross document coreference resolution (CDC)", "start_pos": 37, "end_pos": 80, "type": "TASK", "confidence": 0.794732119355883}]}, {"text": "Processing infinite streams of mentions forces us to use a constant amount of memory and so we maintain a representative, fixed sized sample at all times.", "labels": [], "entities": []}, {"text": "For the sample to be representative it should represent a large number of entities whilst taking into account both temporal recency and distant references.", "labels": [], "entities": []}, {"text": "We introduce new sampling techniques that take into account a notion of streaming discourse (cur-rent mentions depend on previous mentions).", "labels": [], "entities": []}, {"text": "Using the proposed sampling techniques we are able to get a CEAFe score within 5% of a non-streaming system while using only 30% of the memory.", "labels": [], "entities": [{"text": "CEAFe score", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9620318412780762}]}], "introductionContent": [{"text": "Cross document coreference resolution (CDC) -identifying mentions that refer to the same entity across documents -is a prerequisite when combining entity specific information from multiple documents.", "labels": [], "entities": [{"text": "Cross document coreference resolution (CDC)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7718837814671653}]}, {"text": "Typically large scale CDC involves applying a scalable clustering algorithm to all the mentions.", "labels": [], "entities": []}, {"text": "We consider streaming CDC, hence our system must conform to the streaming computational resource model.", "labels": [], "entities": []}, {"text": "Each mention is processed in bounded time and only a constant amount of memory is used.", "labels": [], "entities": []}, {"text": "Honoring these constraints ensures our system can be applied to infinite streams such as newswire or social media.", "labels": [], "entities": []}, {"text": "Storing all the mentions in memory is clearly infeasible, hence we need to either compress mentions or store a sample.", "labels": [], "entities": []}, {"text": "Compression is more computationally expensive as it involves merging/forgetting mention components (for example: components of a vector) whereas sampling decides to store or forget whole mentions.", "labels": [], "entities": []}, {"text": "We investigate sampling techniques due to their computational efficiency.", "labels": [], "entities": []}, {"text": "We explore which mentions should be stored while performing streaming CDC.", "labels": [], "entities": []}, {"text": "A sample should represent a diverse set of entities while taking into account both temporal recency and distant mentions.", "labels": [], "entities": []}, {"text": "We show that using a notion of streaming discourse, where what is currently being mentioned depends on what was previously mentioned significantly improves performance on anew CDC annotated Twitter corpus.", "labels": [], "entities": [{"text": "CDC annotated Twitter corpus", "start_pos": 176, "end_pos": 204, "type": "DATASET", "confidence": 0.9067647159099579}]}], "datasetContent": [{"text": "We collected 52 million English tweets from the 1% sample of all tweets sent over a 77 day period.", "labels": [], "entities": []}, {"text": "We performed named entity recognition using.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.6741237640380859}]}, {"text": "It is clearly infeasible for us to annotate all the mentions in the dataset.", "labels": [], "entities": []}, {"text": "Hence we annotated a sample of the entities.", "labels": [], "entities": []}, {"text": "As with most prior work we focused on person named entity mentions (of which there is approximately 6 million in the dataset).", "labels": [], "entities": []}, {"text": "To select the entities we first sampled two names based on how frequently they occur in the dataset: 'Roger' was chosen randomly from the low frequency names (between 1,000 and 10,000 occurrences) and 'Jessica' was chosen similarly from medium frequency names (10,000 to 100,0000 occurrences).", "labels": [], "entities": [{"text": "Roger", "start_pos": 102, "end_pos": 107, "type": "METRIC", "confidence": 0.9705600738525391}]}, {"text": "We first annotated all mentions of the names 'Roger' and 'Jessica' discarding entities mentioned once.", "labels": [], "entities": []}, {"text": "For the remaining entities we annotated all their mentions (not restricting to mentions that contained the words 'Roger' or 'Jessica').", "labels": [], "entities": []}, {"text": "This covers a diverse selection of people including: 'Roger Federer' (tennis player) and 'Jessie J' (the singer whose real name is 'Jessica Cornish') as well as less popular entities such as porn stars and journalists . Some statistics of the dataset are summarized in table 1.", "labels": [], "entities": []}, {"text": "We also plot the mention frequency (how often each entity was mentioned) distribution in figure 1 which shows a clear power law distribution similar to what reported on the New York Times annotated corpus.", "labels": [], "entities": [{"text": "New York Times annotated corpus", "start_pos": 173, "end_pos": 204, "type": "DATASET", "confidence": 0.6763489246368408}]}, {"text": "We show that recency and distant reference are important aspects by plotting the time since previous mention of the same entity (gap) for each mention in.", "labels": [], "entities": []}, {"text": "The gap is often less than 24 hours demonstrating the importance of recency.", "labels": [], "entities": []}, {"text": "There are also plenty of mentions with much larger gaps, demonstrating the need to be able to resolve distant references.", "labels": [], "entities": []}, {"text": "As we are processing a stream we use a rolling evaluation protocol.", "labels": [], "entities": []}, {"text": "Our corpus is split up into 11 constant sized temporally adjacent blocks each lasting approximately one week.", "labels": [], "entities": []}, {"text": "Parameters are set using a standard grid search on one block then we progress to the next block to evaluate.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.965773344039917}]}, {"text": "The first block is reserved for setting the linking threshold prior to our rolling evaluation.", "labels": [], "entities": []}, {"text": "We report the average over the remaining blocks.", "labels": [], "entities": []}, {"text": "For all sampling techniques that have a randomized component we report an average over 10 runs.", "labels": [], "entities": []}, {"text": "As the sample size will have a large effect on performance we evaluate using various sample sizes.", "labels": [], "entities": []}, {"text": "We base our sample size on the average amount of mentions per day (78,450) and evaluate our system with sample sizes of 0.25,0.5,1,2 times the average amount of mentions per day.", "labels": [], "entities": []}, {"text": "We evaluate using CEAFe (, it is the only coreference evaluation metric that can be trivially adapted to datasets with a sample of annotated entities.", "labels": [], "entities": [{"text": "CEAFe", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.5446543097496033}]}, {"text": "With no adaption it measures how well a small amount of entities align with a system output over a large amount.", "labels": [], "entities": []}, {"text": "To make the evaluation more representative we only use response clusters that contain an annotated mention.", "labels": [], "entities": []}, {"text": "This scales precision and maintains interpretability.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.99950110912323}, {"text": "interpretability", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.9332886338233948}]}, {"text": "We determine if observed differences are significant by using a Wilcoxon signed-rank test with a p value of 5% over the 9 testing points.", "labels": [], "entities": []}, {"text": "Results are shown in table 2.", "labels": [], "entities": []}, {"text": "\u2022 Window: This shows the performance that can be achieved by only considering recency.", "labels": [], "entities": []}, {"text": "\u2022 Uniform Reservoir Sampling (Uniform-R): This shows the performance achieved by using an uninformed technique to store a diverse set of older mentions.", "labels": [], "entities": [{"text": "Uniform Reservoir Sampling", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.562440941731135}]}, {"text": "\u2022 Biased Reservoir Sampling (Biased-R): Uninformed sampling of older mentions is not sufficient to significantly improve performance.", "labels": [], "entities": []}, {"text": "\u2022 Cache: By using an informed model of recency we keep mentions critical to resolving references currently being tweeted resulting in a significant performance improvement.", "labels": [], "entities": []}, {"text": "\u2022 Diversity: By using an informed technique to increase the amount of distinct entities represented in the sample we significantly improve performance.", "labels": [], "entities": []}, {"text": "\u2022 Diversity-Cache (D-C): By combining the new sampling techniques we significantly improve performance.", "labels": [], "entities": []}, {"text": "Once we have increased the amount of entities represented in the sample we are still able to benefit from an informed model of recency.", "labels": [], "entities": []}, {"text": "Using uninformed sampling techniques (reservoir sampling) does not result in a significant performance improvement over Window sampling, only informed sampling techniques show a significant improvement.", "labels": [], "entities": []}, {"text": "As the sample size increases the performance difference decreases.", "labels": [], "entities": []}, {"text": "With larger samples there is space to represent more entities and it is less likely to remove a useful mention at random.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Mention/entity counts and percentage of entities  that have a Wikipedia page.", "labels": [], "entities": []}, {"text": " Table 2: CEAFe performance for various sample sizes  and sampling techniques.  *  indicates significant improve- ment over Window sampling.  \u2020 indicates significant im- provement over Diversity sampling", "labels": [], "entities": [{"text": "CEAFe", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8696842193603516}, {"text": "improve- ment", "start_pos": 105, "end_pos": 118, "type": "METRIC", "confidence": 0.877411683400472}, {"text": "im- provement", "start_pos": 166, "end_pos": 179, "type": "METRIC", "confidence": 0.9151777823766073}]}]}