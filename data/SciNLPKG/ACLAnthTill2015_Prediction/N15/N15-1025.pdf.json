{"title": [{"text": "Spinning Straw into Gold: Using Free Text to Train Monolingual Alignment Models for Non-factoid Question Answering", "labels": [], "entities": [{"text": "Spinning Straw into Gold", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8488151580095291}, {"text": "Question Answering", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.6729560345411301}]}], "abstractContent": [{"text": "Monolingual alignment models have been shown to boost the performance of question answering systems by \"bridging the lexical chasm\" between questions and answers.", "labels": [], "entities": [{"text": "question answering", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7546846568584442}]}, {"text": "The main limitation of these approaches is that they require semistructured training data in the form of question-answer pairs, which is difficult to obtain in specialized domains or low-resource languages.", "labels": [], "entities": []}, {"text": "We propose two inexpensive methods for training alignment models solely using free text, by generating artificial question-answer pairs from discourse structures.", "labels": [], "entities": []}, {"text": "Our approach is driven by two representations of discourse: a shallow sequential representation, and a deep one based on Rhetorical Structure Theory.", "labels": [], "entities": []}, {"text": "We evaluate the proposed model on two corpora from different genres and domains: one from Yahoo!", "labels": [], "entities": []}, {"text": "Answers and one from the biology domain, and two types of non-factoid questions: manner and reason.", "labels": [], "entities": []}, {"text": "We show that these alignment models trained directly from discourse structures imposed on free text improve performance considerably over an information retrieval baseline and a neural network language model trained on the same data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Question Answering (QA) is a challenging task that draws upon many aspects of NLP.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9018643379211426}]}, {"text": "Unlike search or information retrieval, answers infrequently contain lexical overlap with the question (e.g. What should we eat for breakfast?", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.7046742290258408}]}, {"text": "-Zoe's Diner has good pancakes), and require QA models to draw upon more complex methods to bridge this \"lexical chasm\" ().", "labels": [], "entities": []}, {"text": "These methods range from robust shallow models based on lexical semantics, to deeper, explainably-correct, but much more brittle inference methods based on first order logic.", "labels": [], "entities": []}, {"text": "proposed that this \"lexical chasm\" might be partially bridged by repurposing statistical machine translation (SMT) models for QA.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.7878831525643667}]}, {"text": "Instead of translating text from one language to another, these monolingual alignment models learn to translate from question to answer 1 , learning common associations from question terms such as eat or breakfast to answer terms like kitchen, pancakes, or cereal.", "labels": [], "entities": []}, {"text": "While monolingual alignment models have enjoyed a good deal of recent success in QA (see related work), they have expensive training data requirements, requiring a large set of aligned indomain question-answer pairs for training.", "labels": [], "entities": []}, {"text": "For lowresource languages or specialized domains like science or biology, often the only option is to enlist a domain expert to generate gold QA pairs -a process that is both expensive and time consuming.", "labels": [], "entities": []}, {"text": "All of this means that only in rare cases are we accorded the luxury of having enough high-quality QA pairs to properly train an alignment model, and so these models are often underutilized or left struggling for resources.", "labels": [], "entities": []}, {"text": "Making use of recent advancements in discourse parsing), here we address this issue, and investigate whether alignment models for QA can be trained from artificial question-answer pairs generated from discourse structures imposed on free text.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7204411178827286}]}, {"text": "We evaluate our methods on two corpora, generating alignment models for an opendomain community QA task using Gigaword 2 , and fora biology-domain QA task using a biology textbook.", "labels": [], "entities": []}, {"text": "In practice, alignment for QA is often done from answer to question, as answers tend to be longer and provide more opportunity for association ().", "labels": [], "entities": [{"text": "QA", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9093783497810364}]}], "datasetContent": [{"text": "We tested our approach in two different domains, open-domain and cellular biology.", "labels": [], "entities": []}, {"text": "For consistency we use the same corpora as, which are described briefly here.", "labels": [], "entities": []}, {"text": "Jenson-Shannon Distance (JSD) Pairwise JSDs were found between the probability distribution of each content word in the question and those in the answer.", "labels": [], "entities": []}, {"text": "The mean, minimum, and maximum JSD values were used as features.", "labels": [], "entities": [{"text": "mean", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9826858043670654}, {"text": "JSD", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.45437437295913696}]}, {"text": "Additionally, composite vectors were formed which represented the entire question and the entire answer and the overall JSD between these two vectors was also included as a feature.", "labels": [], "entities": [{"text": "JSD", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.4738454222679138}]}, {"text": "See Fried et. al (In press) for additional details.", "labels": [], "entities": []}], "tableCaptions": []}