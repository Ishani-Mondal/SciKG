{"title": [{"text": "Multi-Task Word Alignment Triangulation for Low-Resource Languages", "labels": [], "entities": [{"text": "Multi-Task Word Alignment Triangulation", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7145198062062263}]}], "abstractContent": [{"text": "We present a multi-task learning approach that jointly trains three word alignment models over disjoint bitexts of three languages: source, target and pivot.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7371340394020081}]}, {"text": "Our approach builds upon model triangulation, following Wang et al., which approximates a source-target model by combining source-pivot and pivot-target models.", "labels": [], "entities": []}, {"text": "We develop a MAP-EM algorithm that uses triangulation as a prior, and show how to extend it to a multi-task setting.", "labels": [], "entities": []}, {"text": "On a low-resource Czech-English corpus, using French as the pivot, our multi-task learning approach more than doubles the gains in both F-and Bleu scores compared to the interpolation approach of Wang et al.", "labels": [], "entities": [{"text": "Czech-English corpus", "start_pos": 18, "end_pos": 38, "type": "DATASET", "confidence": 0.7621819078922272}, {"text": "F-and Bleu scores", "start_pos": 136, "end_pos": 153, "type": "METRIC", "confidence": 0.8769779801368713}]}, {"text": "Further experiments reveal that the choice of pivot language does not significantly affect performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word alignment () is a fundamental task in the machine translation (MT) pipeline.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7525913715362549}, {"text": "machine translation (MT) pipeline", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.8519930293162664}]}, {"text": "To train good word alignment models, we require access to a large parallel corpus.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7135960459709167}]}, {"text": "However, collection of parallel corpora has mostly focused on a small number of widely-spoken languages.", "labels": [], "entities": []}, {"text": "As such, resources for almost any other pair are either limited or non-existent.", "labels": [], "entities": []}, {"text": "To improve word alignment and MT in a lowresource setting, we design a multitask learning approach that utilizes parallel data of a third language, called the pivot language ( \u00a73).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.8122886419296265}, {"text": "MT", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9940702319145203}]}, {"text": "Specifically, we derive an efficient and easy-to-implement MAP-EM-like algorithm that jointly trains sourcetarget, source-pivot and pivot-target alignment models, each on its own bitext, such that each model benefits from observations made by the other two.", "labels": [], "entities": []}, {"text": "Our method subsumes the model interpolation approach of, who independently train these three models and then interpolate the source-target model with an approximate sourcetarget model, constructed by combining the sourcepivot and pivot-target models.", "labels": [], "entities": []}, {"text": "Pretending that Czech-English is low-resource, we conduct word alignment and MT experiments ( \u00a74).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7931152880191803}, {"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9716478586196899}]}, {"text": "With French as the pivot, our approach significantly outperforms the interpolation method of on both alignment F-and Bleu scores.", "labels": [], "entities": [{"text": "alignment F-and Bleu scores", "start_pos": 101, "end_pos": 128, "type": "METRIC", "confidence": 0.71466064453125}]}, {"text": "Somewhat surprisingly, we find that our approach is insensitive to the choice of pivot language.", "labels": [], "entities": []}, {"text": "focus on learning a word alignment model without a source-target corpus.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7432262897491455}]}, {"text": "To do so, they assume access to both source-pivot and pivot-target bitexts on which they independently train a source-pivot word alignment model \u0398 sp and a pivot-target model \u0398 pt . They then combine the two models by marginalizing over the pivot language, resulting in an approximate source-target model \u0398 st . This combination process is referred to as triangulation (see \u00a75).", "labels": [], "entities": []}], "datasetContent": [{"text": "Pretending that Czech-English is a low-resource pair, we conduct two experiments.", "labels": [], "entities": []}, {"text": "In the first, we set French as the pivot language and compare our fixedprior (Sec. \u00a73.1) and joint training (Sec.", "labels": [], "entities": [{"text": "fixedprior", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.860332190990448}]}, {"text": "\u00a73.2) approaches against the interpolation method of Wang et al. and a baseline HMM word alignment model (.", "labels": [], "entities": [{"text": "HMM word alignment", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.8116408387819926}]}, {"text": "In the second, we examine the effect of the pivot language identity on our joint training approach, varying the pivot language over French, German, Greek, Hungarian, Lithuanian and Slovak.", "labels": [], "entities": []}, {"text": "We trained word alignment models in both sourceto-target and target-to-source directions.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.7933526635169983}]}, {"text": "We used 5 iterations of IBM Model 1 followed by 5 iterations of HMM.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.9252409736315409}, {"text": "HMM", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.9075704216957092}]}, {"text": "We tuned hyperparameters to maximize alignment F-score of the hand-aligned development set.", "labels": [], "entities": [{"text": "alignment", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9495725035667419}, {"text": "F-score", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.5357016921043396}]}, {"text": "Both interpolation parameters \u03bb interp and \u03bb were tuned over the range.", "labels": [], "entities": []}, {"text": "For our methods, we fixed \u03b3 = 0.5, which we found effective during preliminary experiments.", "labels": [], "entities": []}, {"text": "Alignment F-scores using grow-diag-final-and (gdfa) symmetrization are reported in, column 2.", "labels": [], "entities": [{"text": "Alignment F-scores", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.6884710192680359}]}, {"text": "We conducted MT experiments using the Moses translation system (.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9922089576721191}, {"text": "Moses translation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.6054891049861908}]}, {"text": "We used a 5-gram LM trained on the Xinhua portion of English Gigaword (LDC2007T07).", "labels": [], "entities": [{"text": "Xinhua portion of English Gigaword", "start_pos": 35, "end_pos": 69, "type": "DATASET", "confidence": 0.7469457745552063}]}, {"text": "To tune the decoder, we used the WMT10 tune set.", "labels": [], "entities": [{"text": "WMT10 tune set", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9637036720911661}]}, {"text": "MT Bleu scores are reported in, columns 3-4.", "labels": [], "entities": [{"text": "MT Bleu scores", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.6933620174725851}]}, {"text": "Both our methods outperform the baseline and the interpolation approach.", "labels": [], "entities": []}, {"text": "In particular, the joint training approach more than doubles the gains obtained by the interpolation approach, on both F-and Bleu.", "labels": [], "entities": [{"text": "F-and Bleu", "start_pos": 119, "end_pos": 129, "type": "DATASET", "confidence": 0.8051497638225555}]}, {"text": "We also evaluated the Czech-French and FrenchEnglish alignments produced as a by-product of our joint method.", "labels": [], "entities": [{"text": "FrenchEnglish alignments", "start_pos": 39, "end_pos": 63, "type": "DATASET", "confidence": 0.8072299361228943}]}, {"text": "While our French-to-English MT experiments showed no improvement in Bleu, we saw a +0.6 (25.6 to 26.2) gain in Bleuon the Czech-toFrench translation task.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.873386025428772}, {"text": "Bleu", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.7102046012878418}, {"text": "Czech-toFrench translation task", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.6630123356978098}]}, {"text": "This shows that joint training may lead to some improvements even on highresource bitexts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Czech-English sentence and token statistics.", "labels": [], "entities": []}, {"text": " Table 2: F-and Bleu scores for Czech-English via  French. The joint training method outperforms all other  methods tested.", "labels": [], "entities": [{"text": "F-and Bleu scores", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8479475776354471}]}, {"text": " Table 3: Czech-English Bleu scores over pivot language  combinations. Key: fr=French, sk=Slovak, el=Greek.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.7593262195587158}]}]}