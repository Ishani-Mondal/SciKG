{"title": [{"text": "Learning Translation Models from Monolingual Continuous Representations", "labels": [], "entities": [{"text": "Learning Translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.677086740732193}]}], "abstractContent": [{"text": "Translation models often fail to generate good translations for infrequent words or phrases.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9452936053276062}]}, {"text": "Previous work attacked this problem by inducing new translation rules from monolin-gual data with a semi-supervised algorithm.", "labels": [], "entities": []}, {"text": "However, this approach does not scale very well since it is very computationally expensive to generate new translation rules for only a few thousand sentences.", "labels": [], "entities": []}, {"text": "We propose a much faster and simpler method that directly hallu-cinates translation rules for infrequent phrases based on phrases with similar continuous representations for which a translation is known.", "labels": [], "entities": []}, {"text": "To speedup the retrieval of similar phrases, we investigate approximated nearest neighbor search with redundant bit vectors which we find to be three times faster and significantly more accurate than locality sensitive hashing.", "labels": [], "entities": []}, {"text": "Our approach of learning new translation rules improves a phrase-based baseline by up to 1.6 BLEU on Arabic-English translation, it is three-orders of magnitudes faster than existing semi-supervised methods and 0.5 BLEU more accurate.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.998557984828949}, {"text": "BLEU", "start_pos": 215, "end_pos": 219, "type": "METRIC", "confidence": 0.9986718893051147}]}], "introductionContent": [{"text": "Statistical translation models () are trained with bilingual data and a simple solution to improve accuracy is to train on more data.", "labels": [], "entities": [{"text": "Statistical translation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7162193953990936}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9984550476074219}]}, {"text": "However, for many language pairs we only have a very limited amount of bilingual data and even when dealing with resource-rich languages, we still often perform poorly when dealing with rare words or phrases.", "labels": [], "entities": []}, {"text": "On the other hand, there is plenty of monolingual data and previous work has investigated its use in learning translation models; Saluja et *The entirety of this work was conducted while at Microsoft).", "labels": [], "entities": [{"text": "learning translation", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.6216774880886078}]}, {"text": "However, most methods rely on statistics that are computationally expensive.", "labels": [], "entities": []}, {"text": "As a concrete example, the graph propagation algorithm of relies on pair-wise mutual information statistics between any pair of phrases in the monolingual corpus that is very expensive to compute, even for moderately sized corpora.", "labels": [], "entities": [{"text": "graph propagation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7549668848514557}]}, {"text": "In this paper, we study the use of standard continuous representations for words to generate translation rules for infrequent phrases ( \u00a72).", "labels": [], "entities": []}, {"text": "We explore linear projections that map continuous representations of rare foreign phrases to English phrases.", "labels": [], "entities": []}, {"text": "In particular, we propose to learn many local projections that are specific to a given foreign phrase.", "labels": [], "entities": []}, {"text": "We find this to be much more accurate than a single globally learned mapping such as proposed by.", "labels": [], "entities": []}, {"text": "Our method relies on the fast retrieval of similar phrases in continuous space.", "labels": [], "entities": []}, {"text": "We explore both Locality Sensitive Hashing) as well as the lesser known Redundant Bit Vector method (RBV;) for fast k-nearest neighbor (k-NN) search.", "labels": [], "entities": [{"text": "Locality Sensitive Hashing", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.7810786763827006}, {"text": "Redundant Bit Vector method (RBV", "start_pos": 72, "end_pos": 104, "type": "METRIC", "confidence": 0.6772885868946711}]}, {"text": "RBV outperforms the popular LSH algorithm by a large margin, both in speed as well as accuracy ( \u00a74).", "labels": [], "entities": [{"text": "RBV", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6343887448310852}, {"text": "speed", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.9969521760940552}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.999472439289093}]}, {"text": "Our results show that the local linear projection method is not only three orders of magnitudes faster than the algorithm of but also by 0.5 BLEU more accurate.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9994199275970459}]}, {"text": "We achieve a 1.6 BLEU improvement in Arabic-English translation compared to a standard phrase-based baseline ( \u00a75).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9994707703590393}, {"text": "Arabic-English translation", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.6429862082004547}]}], "datasetContent": [{"text": "We first evaluate the speed and accuracy of the presented approximate k-NN query algorithms ( \u00a75.2).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9994305968284607}]}, {"text": "Next we experiment with the translation rule generation approaches ( \u00a75.3), and then we analyze the global and local projection methods ( \u00a75.4).", "labels": [], "entities": [{"text": "translation rule generation", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.9152669111887614}]}, {"text": "Following, we present most results on Arabic-English translation and then validate our findings on Urdu-English ( \u00a75.5), a low-resource setting.", "labels": [], "entities": [{"text": "Arabic-English translation", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.680630624294281}]}, {"text": "Lastly, we discuss some qualitative results ( \u00a75.6).", "labels": [], "entities": []}, {"text": "We test our approach on both Arabic-English and Urdu-English translation.", "labels": [], "entities": []}, {"text": "For Arabic-English our bilingual training data comprises of 685k sentence pairs.", "labels": [], "entities": []}, {"text": "The NIST MT08 and MT09 data sets serve as tuning and testing sets, respectively.", "labels": [], "entities": [{"text": "NIST", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9793776869773865}, {"text": "MT08", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.5978868007659912}, {"text": "MT09 data sets", "start_pos": 18, "end_pos": 32, "type": "DATASET", "confidence": 0.9696037371953329}]}, {"text": "Both are combinations of newswire and weblog articles, and each Arabic sentence has four reference translations.", "labels": [], "entities": []}, {"text": "For Urdu-English our bilingual training corpus contains 165k sentence pairs, and the tuning and testing sets are NIST MT08 and NIST MT09, respectively.", "labels": [], "entities": [{"text": "NIST MT08", "start_pos": 113, "end_pos": 122, "type": "DATASET", "confidence": 0.8502819240093231}, {"text": "NIST MT09", "start_pos": 127, "end_pos": 136, "type": "DATASET", "confidence": 0.888981968164444}]}, {"text": "shows some statistics for the monolingual data we use.", "labels": [], "entities": []}, {"text": "The majority of the data for Arabic and English is drawn from the AFP Gigaword corpus.", "labels": [], "entities": [{"text": "AFP Gigaword corpus", "start_pos": 66, "end_pos": 85, "type": "DATASET", "confidence": 0.9444878300031027}]}, {"text": "For Urdu most of the data is mined by a web crawler, mainly because there are not many official resources for this language.", "labels": [], "entities": []}, {"text": "We run standard tokenization and segmentation on the monolingual corpora.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.9606658220291138}]}, {"text": "After that we use the Word2Vec tool (  word embeddings for each language with the bagof-words model, where the number of dimensions is set to d = 300.", "labels": [], "entities": []}, {"text": "See for the number of word vectors learned for each language.", "labels": [], "entities": []}, {"text": "To obtain phrases in each language, we use a similar strategy as in.", "labels": [], "entities": []}, {"text": "For Arabic and Urdu, we collect all unigrams and bigrams from the tuning and testing sets.", "labels": [], "entities": []}, {"text": "This gives 0.66m phrases for Arabic and 0.2m phrases for Urdu.", "labels": [], "entities": []}, {"text": "For English, we collect unigrams and bigrams from the monolingual data instead.", "labels": [], "entities": []}, {"text": "However, the English monolingual corpus is much larger than the tuning and testing sets for Arabic and Urdu.", "labels": [], "entities": []}, {"text": "We therefore train a language model over the monolingual data, and collect the unigrams and bigrams from the ARPA file, filtering out all candidates that have a probability smaller than 10 \u22127 . Similar to, we use a baseline MT system to translate the Arabic or Urdu phrases and add their translations to the English phrase set.", "labels": [], "entities": [{"text": "ARPA file", "start_pos": 109, "end_pos": 118, "type": "DATASET", "confidence": 0.94918093085289}, {"text": "MT", "start_pos": 224, "end_pos": 226, "type": "TASK", "confidence": 0.9394564032554626}]}, {"text": "After this procedure we end up with 1.5m English phrases.", "labels": [], "entities": []}, {"text": "We use simple component-wise addition to generate phrase vectors from word vectors.", "labels": [], "entities": []}, {"text": "Some rare words do not receive a vector representation after running Word2Vec, and we simply remove phrases containing those words, resulting in a total of 0.65m phrases for Arabic, 0.18m phrases for Urdu, and 1.2m phrases for English.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.9631632566452026}]}, {"text": "We first evaluate the performances of different k-NN query approaches on English word vectors.", "labels": [], "entities": []}, {"text": "There are 2.9m word vectors ind = 300 dimensional space.", "labels": [], "entities": []}, {"text": "We randomly select 1,000 words, and query for each word the 200 nearest neighbors, k = 200, with either linear search, LSH, and RBV.", "labels": [], "entities": [{"text": "LSH", "start_pos": 119, "end_pos": 122, "type": "METRIC", "confidence": 0.9717857241630554}, {"text": "RBV", "start_pos": 128, "end_pos": 131, "type": "METRIC", "confidence": 0.9574169516563416}]}, {"text": "We measure the false negative ratio, i.e., the percentage of true neighbors missed by each query method, as well as time.", "labels": [], "entities": [{"text": "false negative ratio", "start_pos": 15, "end_pos": 35, "type": "METRIC", "confidence": 0.7899301250775655}]}, {"text": "For LSH and RBV, we tune the parameters for best performance (LSH: number of projected dimensions, number of layers, and width of: Arabic-English translation accuracy of structured label propagation with PMI (SLP) and with continuous representations (SLP w/ PMI), the global linear projection (GLP), our local linear projection (LLP) and with an added backoff scheme (LLP w/ backoff).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9889776110649109}, {"text": "structured label propagation", "start_pos": 170, "end_pos": 198, "type": "TASK", "confidence": 0.6743845740954081}]}, {"text": "For applicable methods, we list the running time to compute distributional representations as a separate term in the time column.", "labels": [], "entities": []}, {"text": "This is usually only required once per language which is why we report it separately.", "labels": [], "entities": []}, {"text": "the bin; RBV: hypercube width and number of bins for each dimension).", "labels": [], "entities": [{"text": "RBV", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9687014818191528}]}, {"text": "shows that RBV gives significantly better performance than LSH, both in terms of accuracy and speed.", "labels": [], "entities": [{"text": "RBV", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.8076969385147095}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9996116757392883}]}, {"text": "RBV reduces the false negative ratio by 1/3 compared to LSH and is 3.6 times faster.", "labels": [], "entities": [{"text": "RBV", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9586575031280518}, {"text": "false negative ratio", "start_pos": 16, "end_pos": 36, "type": "METRIC", "confidence": 0.9501034617424011}]}, {"text": "This is inline with who observed that the performance of LSH degrades in high dimensional space.", "labels": [], "entities": []}, {"text": "We therefore use RBV in the following experiments.", "labels": [], "entities": [{"text": "RBV", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.5861169099807739}]}, {"text": "Next, we evaluate the quality of the generated translation rules for Arabic-English translation using either SLP, the global linear projection (GLP), or the local linear projection (LLP).", "labels": [], "entities": []}, {"text": "Our baseline system is an in-house phrase-based system similar to Moses with a 4-gram language model.", "labels": [], "entities": []}, {"text": "The underlying log-linear model comprises of 13 features: two maximum likelihood translation probabilities, two lexicalized translation probabilities, five hierarchical reordering model features (), one language model, word penalty, phrase length, and distortion penalty), and is tuned with minimum error rate training (MERT;).", "labels": [], "entities": [{"text": "minimum error rate training (MERT", "start_pos": 291, "end_pos": 324, "type": "METRIC", "confidence": 0.8057721157868704}]}, {"text": "Translation quality is measured with BLEU ().", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9391373991966248}, {"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9990307092666626}]}, {"text": "For comparison, we reimplemented the graphbased method in.", "labels": [], "entities": []}, {"text": "This method calculates the pairwise mutual information (PMI) between phrases, and employs all the techniques mentioned in to speedup the computations.", "labels": [], "entities": []}, {"text": "Our reimplementation achieves similar performance to (with a negligible \u223c 0.06 drop in BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9992454051971436}]}, {"text": "We parallelized the algorithm on a cluster since a single core implementation would run for \u223c 10k hours.", "labels": [], "entities": []}, {"text": "Our continuous phrase based version of SLP is orders of magnitudes faster than the SLP variant of because it replaces the computationally expensive PMI calculation by an approximated k-NN query in distributional space.", "labels": [], "entities": []}, {"text": "Moreover, our variant of SLP even improves translation quality by 0.2-0.3 BLEU.", "labels": [], "entities": [{"text": "translation", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.8757290840148926}, {"text": "BLEU", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9984374642372131}]}, {"text": "Overall, our version of SLP improves the baseline by 2.0 BLEU on the tuning set and by 1.3 BLEU on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9995062351226807}, {"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9990978240966797}]}, {"text": "The linear projection based methods, GLP and LLP, are in turn again several times faster than SLP with continuous representations.", "labels": [], "entities": []}, {"text": "This is because they require significantly fewer k-NN queries.", "labels": [], "entities": []}, {"text": "For both GLP and LLP, we retrieve the 200 nearest neighbors of the projected point.", "labels": [], "entities": []}, {"text": "For LLP, the local projection is calculated based on the 500 nearest labeled neighbors of the infrequent source phrase.", "labels": [], "entities": [{"text": "LLP", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9443721771240234}]}, {"text": "LLP achieves slightly better accuracy on the test set than PMI-based SLP but at four times the speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.999345600605011}]}, {"text": "GLP is the fastest method but also the least accurate, improving the baseline only by about 0.6 BLEU.", "labels": [], "entities": [{"text": "GLP", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.870479941368103}, {"text": "baseline", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9531809091567993}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9979217648506165}]}, {"text": "We explore this result in more detail in the next section.", "labels": [], "entities": []}, {"text": "Overall, our local projection outperforms the global projection by 0.9 BLEU on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9994096755981445}]}, {"text": "For some infrequent source phrases, approximated k-NN query does not retrieve enough (\u2265 d) neighbors to learn a local linear projection.", "labels": [], "entities": []}, {"text": "For these phrases, we employ a backoff strategy that uses the translations of their neighbors as additional translation candidates.", "labels": [], "entities": []}, {"text": "This strategy provides helpful additional rules for LLP).", "labels": [], "entities": [{"text": "LLP", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9714348316192627}]}, {"text": "To learn why GLP does not generate high quality translation rules, we run an extra experiment to measure the projection quality of GLP.", "labels": [], "entities": []}, {"text": "We train a global linear projection on an increas-   ing amount of training data and measure its accuracy on two test sets).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9992770552635193}]}, {"text": "The first test set contains the 100 most frequent source phrases and their translations.", "labels": [], "entities": []}, {"text": "The second test set contains less frequent examples; we choose the 50,000 to 50,100 most frequent source phrases.", "labels": [], "entities": []}, {"text": "The training data uses the l most frequent source phrases and their translations which are not already contained in the first test.", "labels": [], "entities": []}, {"text": "The projection quality is measured by the ratio of how many times the correct translation is one of the 200-nearest neighbors of the projected point computed by GLP.", "labels": [], "entities": [{"text": "GLP", "start_pos": 161, "end_pos": 164, "type": "DATASET", "confidence": 0.8433213829994202}]}, {"text": "The results in clearly show that GLP can find the best translation for very frequent source phrases which is inline with previous work.", "labels": [], "entities": [{"text": "GLP", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.6431636810302734}]}, {"text": "However, the accuracy for infrequent phrases is poor.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9993135929107666}]}, {"text": "This explains why GLP helps relatively little in our translation experiments because our setup requires a method that can find good translations for infrequent source phrases.", "labels": [], "entities": []}, {"text": "Resources for Urdu are limited compared to Arabic ( \u00a75.1) which results in fewer word vectors and fewer source phrases.", "labels": [], "entities": []}, {"text": "This will also affect the quality of the word vectors in Urdu, since more training data usually results in better representations.", "labels": [], "entities": []}, {"text": "shows that the improvements of both SLP and LLP in Urdu-English are not as significant as for Arabic-English.", "labels": [], "entities": []}, {"text": "Our reimplementation of SLP is \u223c 1 BLEU better on the tuning set than the baseline, and \u223c 0.5 BLEU better on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9987646341323853}, {"text": "BLEU", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.9984139204025269}]}, {"text": "As ex-  pected, the translation quality improvement on small corpora is not as significant as on large corpora like Arabic, since the monolingual data in Urdu is much smaller than for Arabic (75m tokens vs. 5b tokens) which makes it more difficult to learn good representations.", "labels": [], "entities": []}, {"text": "In general, with continuous representations, SLP and LLP achieve similar performance to PMIbased SLP but the projection based methods are orders of magnitudes faster.", "labels": [], "entities": []}, {"text": "shows some examples of the translation rules produced by our system.", "labels": [], "entities": [{"text": "translation", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9617437720298767}]}, {"text": "The first five examples are for the Arabic-English system, while the last five are for the Urdu-English system.", "labels": [], "entities": []}, {"text": "All source phrases are unknown to the baseline system which usually results in sub-optimal translations.", "labels": [], "entities": []}, {"text": "Our system on the other hand, managed to generate translation rules for them.", "labels": [], "entities": []}, {"text": "The Arabic-English examples show mostly morphological variants of phrases which did not appear in the parallel data; this can be helpful for highly inflected languages since most of the inflectional variations are underrepresented in the parallel data.", "labels": [], "entities": []}, {"text": "The Urdu-English examples show mostly unknown phrases since there is much less parallel data than for Arabic.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Arabic-English translation accuracy of struc- tured label propagation with PMI (SLP) and with con- tinuous representations (SLP w/ PMI), the global linear  projection (GLP), our local linear projection (LLP) and  with an added backoff scheme (LLP w/ backoff). For ap- plicable methods, we list the running time to compute dis- tributional representations as a separate term in the time  column. This is usually only required once per language  which is why we report it separately.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9883700609207153}, {"text": "struc- tured label propagation", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.6392337560653687}]}, {"text": " Table 4: Quality of global linear projection measured by  the ratio that GLP can fetch the most possible translation  in the 200-nearest neighbors.", "labels": [], "entities": [{"text": "global linear projection", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.6600589752197266}, {"text": "GLP", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.8227564692497253}]}, {"text": " Table 5: Urdu-English translation accuracy (cf. Table 3).", "labels": [], "entities": [{"text": "Urdu-English translation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.5047080963850021}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.6420642137527466}]}]}