{"title": [{"text": "Discriminative Phrase Embedding for Paraphrase Identification", "labels": [], "entities": [{"text": "Discriminative Phrase Embedding", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6500863134860992}, {"text": "Paraphrase Identification", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.8735598623752594}]}], "abstractContent": [{"text": "This work, concerning paraphrase identification task, on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases.", "labels": [], "entities": [{"text": "paraphrase identification task", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.9265592296918234}]}, {"text": "On the other hand, it comes up with anew scheme TF-KLD-KNN to learn the discrimi-native weights of words and phrases specific to paraphrase task, so that a weighted sum of embeddings can represent sentences more effectively.", "labels": [], "entities": []}, {"text": "Based on these two innovations we get competitive state-of-the-art performance on paraphrase identification.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.8966064155101776}]}], "introductionContent": [{"text": "This work investigates representation learning via deep learning in paraphrase identification task, which aims to determine whether two sentences have the same meaning.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9276585280895233}, {"text": "paraphrase identification task", "start_pos": 68, "end_pos": 98, "type": "TASK", "confidence": 0.8173723419507345}]}, {"text": "One main innovation of deep learning is that it learns distributed word representations (also called \"word embeddings\") to deal with various Natural Language Processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "Our goal is to use and refine embeddings to get competitive performance.", "labels": [], "entities": []}, {"text": "We adopt a supervised classification approach to paraphrase identification like most top performing systems.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.9813393950462341}]}, {"text": "Our focus is representation learning of sentences.", "labels": [], "entities": [{"text": "representation learning of sentences", "start_pos": 13, "end_pos": 49, "type": "TASK", "confidence": 0.8644100725650787}]}, {"text": "Following prior work (e.g., Blacoe and Lapata (2012)), we compute the vector of a sentence as the sum of the vectors of its components.", "labels": [], "entities": []}, {"text": "But unlike prior work we use single words, continuous phrases and discontinuous phrases as the components, not just single words.", "labels": [], "entities": []}, {"text": "Our rationale is that many semantic units are formed by multiple words -e.g., the continuous phrase \"side effects\" and the discontinuous phrase \"pick . .", "labels": [], "entities": []}, {"text": "The better we can discover and represent such components, the better the compositional sentence vector should be.", "labels": [], "entities": []}, {"text": "We use the term unit to refer to single words, continuous phrases and discontinuous phrases.", "labels": [], "entities": []}, {"text": "show that not all words are equally important for paraphrase identification.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.9815074503421783}]}, {"text": "They propose TF-KLD, a discriminative weighting scheme to address this problem.", "labels": [], "entities": []}, {"text": "While they do not represent sentences as vectors composed of other vectors, TF-KLD is promising fora vector-based approach as well since the insight that units are of different importance still applies.", "labels": [], "entities": []}, {"text": "A shortcoming of TF-KLD is its failure to define weights for words that do not occur in the training set.", "labels": [], "entities": []}, {"text": "We propose TF-KLD-KNN, an extension of TF-KLD that computes the weight of an unknown unit as the average of the weights of its k nearest neighbors.", "labels": [], "entities": []}, {"text": "We determine nearest neighbors by cosine measure over embedding space.", "labels": [], "entities": []}, {"text": "We then represent a sentence as the sum of the vectors of its units, weighted by TF-KLD-KNN.", "labels": [], "entities": []}, {"text": "We use () as our baseline system.", "labels": [], "entities": []}, {"text": "They used simple features -eight different machine translation metrics -yet got good performance.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.6630621254444122}]}, {"text": "Based on above new sentence representations, we compute three kinds of features to describe a pair of sentences -cosine similarity, element-wise sum and absolute element-wise difference -and show that combining them with the features from gets state-of-the-art performance on the Microsoft Research Paraphrase (MSRP) corpus).", "labels": [], "entities": [{"text": "Microsoft Research Paraphrase (MSRP) corpus", "start_pos": 280, "end_pos": 323, "type": "DATASET", "confidence": 0.6844544581004551}]}, {"text": "In summary, our first contribution lies in embedding learning of continuous and discontinuous phrases.", "labels": [], "entities": []}, {"text": "Our second contribution is the weighting scheme TF-KLD-KNN.", "labels": [], "entities": [{"text": "TF-KLD-KNN", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.8341954946517944}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our method for learning embeddings of units.", "labels": [], "entities": []}, {"text": "Section 4 introduces a measure of unit discriminativity that can be used for differential weighting of units.", "labels": [], "entities": []}, {"text": "Section 5 presents experimental setup and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Cases overall and subset both suggest that phrase embeddings improve sentence representations.", "labels": [], "entities": []}, {"text": "The accuracy of WORD+PHRASE is lower on overall than on subset because WORD+PHRASE has no advantage over WORD for sentences without phrases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994968175888062}]}], "tableCaptions": [{"text": " Table 1: Results on overall and subset corpus. Significant  improvements over MT are marked with  *  (approximate  randomization test, Pad\u00f3 (2006), p < .05).", "labels": [], "entities": [{"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.8702864050865173}]}, {"text": " Table 2: Effects of different reweighting methods on  overall.", "labels": [], "entities": []}]}