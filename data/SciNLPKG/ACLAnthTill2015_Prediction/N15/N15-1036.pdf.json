{"title": [{"text": "Continuous Space Representations of Linguistic Typology and their Application to Phylogenetic Inference", "labels": [], "entities": [{"text": "Continuous Space Representations", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6276009976863861}, {"text": "Phylogenetic Inference", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7358366847038269}]}], "abstractContent": [{"text": "For phylogenetic inference, linguistic typol-ogy is a promising alternative to lexical evidence because it allows us to compare an arbitrary pair of languages.", "labels": [], "entities": [{"text": "phylogenetic inference", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8945907354354858}]}, {"text": "A challenging problem with typology-based phylogenetic inference is that the changes of typological features overtime are less intuitive than those of lexical features.", "labels": [], "entities": [{"text": "typology-based phylogenetic inference", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.6452504893143972}]}, {"text": "In this paper, we work on reconstructing typologically natural ancestors To do this, we leverage dependencies among typological features.", "labels": [], "entities": []}, {"text": "We first represent each language by continuous latent components that capture feature dependencies.", "labels": [], "entities": []}, {"text": "We then combine them with a typology evaluator that distinguishes typologically natural languages from other possible combinations of features.", "labels": [], "entities": []}, {"text": "We perform phylogenetic inference in the continuous space and use the evalua-tor to ensure the typological naturalness of inferred ancestors.", "labels": [], "entities": [{"text": "phylogenetic inference", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.9243552088737488}]}, {"text": "We show that the proposed method reconstructs known language families more accurately than baseline methods.", "labels": [], "entities": []}, {"text": "Lastly, assuming the monogenesis hypothesis, we attempt to reconstruct a common ancestor of the world's languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic typology is a cross-linguistic study that classifies the world's languages according to structural properties such as complexity of syllable structure and object-verb ordering.", "labels": [], "entities": []}, {"text": "The availability of a large typology database () makes it possible to take computational approaches to this area of study.", "labels": [], "entities": []}, {"text": "In this paper, we consider its application to phylogenetic inference.", "labels": [], "entities": [{"text": "phylogenetic inference", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.9714605510234833}]}, {"text": "We aim at reconstructing evolutionary trees that illustrate how modern languages have descended from common ancestors.", "labels": [], "entities": []}, {"text": "Typological features have two advantages over other linguistic traits.", "labels": [], "entities": [{"text": "Typological", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.8711202144622803}]}, {"text": "First, they allow us to compare an arbitrary pair of languages.", "labels": [], "entities": []}, {"text": "By contrast, historical linguistics has worked on regular sound changes (see) for computational models).", "labels": [], "entities": []}, {"text": "Glottochronology and computational phylogenetics make use of the presence and absence of lexical items.", "labels": [], "entities": []}, {"text": "All these approaches require that certain sets of cognates, or words with common etymological origins, are shared by the languages in question.", "labels": [], "entities": []}, {"text": "For this reason, it is hardly possible to use lexical evidence to search for external relations involving language isolates and tiny language families such as Ainu, Basque, and Japanese.", "labels": [], "entities": []}, {"text": "For these languages, typology can be seen as the last hope.", "labels": [], "entities": []}, {"text": "The second advantage is that typological features are potentially capable of tracing evolutionary history on the order of 10,000 years because they change far more slowly than lexical traits.", "labels": [], "entities": []}, {"text": "A glottochronological study indicates that even if Japanese is genetically related to Korean, they diverged from a common ancestor no earlier than 6,700 years ago.", "labels": [], "entities": []}, {"text": "Even the basic vocabulary vanishes so rapidly that after some 6,000 years, the retention rate becomes comparable to chance similarity.", "labels": [], "entities": [{"text": "retention rate", "start_pos": 79, "end_pos": 93, "type": "METRIC", "confidence": 0.9841568171977997}]}, {"text": "By contrast, the word order of Japanese, for example is astonishingly stable.", "labels": [], "entities": []}, {"text": "It remains intact from the earliest attested data.", "labels": [], "entities": []}, {"text": "Thus we argue that if we manage to develop a statistical model of typological: Typological comparison of the Munda and Mon-Khmer branches of the Austroasiatic languages.", "labels": [], "entities": [{"text": "Typological", "start_pos": 79, "end_pos": 90, "type": "METRIC", "confidence": 0.9734513759613037}]}, {"text": "An abridged version of of ().", "labels": [], "entities": []}, {"text": "changes with predictive power, we can understand a much deeper past.", "labels": [], "entities": []}, {"text": "A challenging problem with typology-based inference is that the changes of typological features overtime are less intuitive than those of lexical features.", "labels": [], "entities": []}, {"text": "Regular sound changes have been well known since the time of the Neogrammarians.", "labels": [], "entities": []}, {"text": "The binary representations of lexical items commonly used in computational phylogenetics correspond to their their presence and absence.", "labels": [], "entities": []}, {"text": "The alternations of each feature value can be straightforwardly interpreted as the birth and death of a lexical item.", "labels": [], "entities": []}, {"text": "By contrast, it is difficult to understand how a language switches from SOV to SVO.", "labels": [], "entities": []}, {"text": "Practically speaking, since each language is represented by a vector of categorical features, we can easily perform distance-based hierarchical clustering.", "labels": [], "entities": []}, {"text": "Still, the extent to which the resultant tree reflects evolutionary history is unclear.", "labels": [], "entities": []}, {"text": "proposed a generative model for hierarchical clustering, which straightforwardly explains evolutionary history.", "labels": [], "entities": []}, {"text": "However, features used in their experiments were binarized in a one-versus-rest manner (i.e., expanding a feature with K possible values into K binary features)) although the model itself had an ability to handle categorical values.", "labels": [], "entities": []}, {"text": "With the independence assumption of binary features, the model was likely to reconstruct ancestors with logically impossible states.", "labels": [], "entities": []}, {"text": "Typological studies have shown that dependencies among typological features are not limited to the categorical constraints.", "labels": [], "entities": []}, {"text": "For example, objectverb ordering is said to imply adjective-noun ordering.", "labels": [], "entities": [{"text": "objectverb ordering", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7730944156646729}]}, {"text": "A natural question arises as to what would happen to adjective-noun ordering if object-verb ordering were altered.", "labels": [], "entities": []}, {"text": "While dependencies among feature pairs were discussed in previous studies), dependencies among more than two features are yet to be exploited.", "labels": [], "entities": []}, {"text": "To gain a better insight into typological changes, we take Austroasiatic languages as an example.", "labels": [], "entities": []}, {"text": "Table 1 compares some typological features of the Munda and Mon-Khmer branches.", "labels": [], "entities": []}, {"text": "Although their genetic relationship was firmly established, they are almost opposite in structure.", "labels": [], "entities": []}, {"text": "Their common ancestor is considered to have been Mon-Khmer-like.", "labels": [], "entities": []}, {"text": "This indicates that the holistic changes have happened in the Munda branch ().", "labels": [], "entities": [{"text": "Munda branch", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.7554304897785187}]}, {"text": "To generalize from this example, we suggest the following hypotheses: 1.", "labels": [], "entities": []}, {"text": "The holistic polarization can be explained by latent components that control dependencies among observable features.", "labels": [], "entities": []}, {"text": "2. Typological changes can occur in away such that typologically unnatural intermediate states are avoided.", "labels": [], "entities": [{"text": "Typological", "start_pos": 3, "end_pos": 14, "type": "METRIC", "confidence": 0.99010169506073}]}, {"text": "To incorporate these hypotheses, we propose continuous space representations of linguistic typology.", "labels": [], "entities": []}, {"text": "Specifically, we use an autoencoder (see) fora review) to map each language into the latent space.", "labels": [], "entities": []}, {"text": "In analogy with principal component analysis (PCA), each element of the encoded vector is referred to as a component.", "labels": [], "entities": [{"text": "principal component analysis (PCA)", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.8175850113232931}]}, {"text": "We combine the autoencoder with a typology evaluator that distinguishes typologically natural languages from other possible combinations of features.", "labels": [], "entities": []}, {"text": "Armed with the typology evaluator, we perform phylogenetic inference in the continuous space.", "labels": [], "entities": [{"text": "phylogenetic inference", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.9559752345085144}]}, {"text": "The evaluator ensures that inferred ancestors are also typologically natural.", "labels": [], "entities": []}, {"text": "The inference procedure is guided by known language families so that each component's stability with respect to evolutionary history can be learned.", "labels": [], "entities": []}, {"text": "To evaluate the proposed method, we hide some trees to see how well they are reconstructed.", "labels": [], "entities": []}, {"text": "Lastly, we build a binary tree on top of known language families.", "labels": [], "entities": []}, {"text": "This experiment is based on a controversial assumption that the world's languages descend from one common ancestor.", "labels": [], "entities": []}, {"text": "Our goal here is not to address the validity of the monogenesis hypothesis.", "labels": [], "entities": []}, {"text": "Rather, we address the questions of how the common ancestor looked like if it existed and how modern languages have evolved from it.", "labels": [], "entities": []}], "datasetContent": [{"text": "To analyze the continuous space representations, we generated mixtures of two languages, which were potential candidates for their common ancestor.", "labels": [], "entities": []}, {"text": "The pair of languages A and B was mixed in two ways.", "labels": [], "entities": []}, {"text": "First, we replaced elements of A's categorical vector v A with v B , with the specified probability.", "labels": [], "entities": []}, {"text": "We repeated this procedure 1,000 times to obtain a mean and a standard deviation.", "labels": [], "entities": [{"text": "mean", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9574496746063232}]}, {"text": "Second, we applied linear interpolation of two vectors h A and h B and mapped the resultant vector to v \u2032 . In this experiment, d 0 = 539 and we set d 1 = 100 and d 2 = 10.", "labels": [], "entities": []}, {"text": "shows the case of the Austroasiatic languages.", "labels": [], "entities": []}, {"text": "In the original, categorical representations, the mixtures of two languages form a deep valley (i.e., typologically unnatural intermediate states).", "labels": [], "entities": []}, {"text": "By contrast, the continuous space representations allow a language to change into another without harming typological naturalness.", "labels": [], "entities": []}, {"text": "This indicates that in the continuous space, we can easily reconstruct typologically natural ancestors.", "labels": [], "entities": []}, {"text": "The major feature changes include \"postpositional\" to \"prepositional\" (0.46-0.47), \"strongly suffixing\" to \"little affixation\" (0.53-0.54) and \"SOV\" to \"SVO\" (0.60-0.61).", "labels": [], "entities": []}, {"text": "We present purity), subtree ( and outlier fraction scores (: Results of the reconstruction of known family trees.", "labels": [], "entities": [{"text": "purity", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9907804131507874}]}, {"text": "Macro-averages are followed by microaverages.", "labels": [], "entities": []}, {"text": "Only non-trivial family trees (trees with more than two children) were considered.", "labels": [], "entities": []}, {"text": "Purity and subtree scores compare inferred trees with gold-standard class labels.", "labels": [], "entities": []}, {"text": "In WALS, genera were treated as class labels because they were the only intermediate layer between families and leaves.", "labels": [], "entities": [{"text": "WALS", "start_pos": 3, "end_pos": 7, "type": "TASK", "confidence": 0.9622101783752441}]}, {"text": "By contrast, Ethnologue provided more complex trees and we were unable to assign one class label to each language.", "labels": [], "entities": []}, {"text": "For this reason, only outlier fraction scores are reported for Ethnologue.", "labels": [], "entities": [{"text": "Ethnologue", "start_pos": 63, "end_pos": 73, "type": "DATASET", "confidence": 0.8698248267173767}]}, {"text": "shows the scores for reconstructed family trees.", "labels": [], "entities": []}, {"text": "The proposed method outperformed the baselines in 5 out of 8 metrics.", "labels": [], "entities": []}, {"text": "Three methods performed almost equally for Ethnologue.", "labels": [], "entities": [{"text": "Ethnologue", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.6574796438217163}]}, {"text": "We suspect that typological features reflect long term trends in comparison to Ethnologue's fine-grained classification.", "labels": [], "entities": [{"text": "Ethnologue", "start_pos": 79, "end_pos": 89, "type": "DATASET", "confidence": 0.9063863158226013}]}, {"text": "For WALS, the proposed method was beaten by average-link agglomerative clustering only in the macro-average of subtree scores.", "labels": [], "entities": [{"text": "WALS", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.9686225056648254}]}, {"text": "One possible explanation is randomness of the proposed method.", "labels": [], "entities": []}, {"text": "Apparently, random sampling distributed errors more evenly than deterministic clustering.", "labels": [], "entities": []}, {"text": "It was penalized more often by subtree scores because they required that all leaves of an internal node belonged to the same class.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the reconstruction of known family trees. Macro-averages are followed by micro- averages.", "labels": [], "entities": []}, {"text": " Table 3: Some features of the world's ancestor with  sample frequencies.", "labels": [], "entities": []}]}