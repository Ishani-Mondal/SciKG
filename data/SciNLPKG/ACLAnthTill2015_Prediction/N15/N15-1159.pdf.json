{"title": [{"text": "On the Automatic Learning of Sentiment Lexicons", "labels": [], "entities": [{"text": "Automatic Learning of Sentiment Lexicons", "start_pos": 7, "end_pos": 47, "type": "TASK", "confidence": 0.7282815933227539}]}], "abstractContent": [{"text": "This paper describes a simple and princi-pled approach to automatically construct sentiment lexicons using distant supervision.", "labels": [], "entities": []}, {"text": "We induce the sentiment association scores for the lexicon items from a model trained on a weakly supervised corpora.", "labels": [], "entities": []}, {"text": "Our empirical findings show that features extracted from such a machine-learned lexicon outperform models using manual or other automatically constructed sentiment lexicons.", "labels": [], "entities": []}, {"text": "Finally, our system achieves the state-of-the-art in Twitter Sentiment Analysis tasks from Semeval-2013 and ranks 2nd best in Semeval-2014 according to the average rank.", "labels": [], "entities": [{"text": "Twitter Sentiment Analysis tasks", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.690832294523716}]}], "introductionContent": [{"text": "One of the early and rather successful models for sentiment analysis) relied on manually constructed lexicons that map words to their sentiment, e.g., positive, negative or neutral.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.9633490741252899}]}, {"text": "The document-level polarity is then assigned by performing some form of averaging, e.g., majority voting, of individual word polarities found in the document.", "labels": [], "entities": []}, {"text": "These systems show an acceptable level of accuracy, they are easy to build and are highly computationally efficient as the only operation required to assign a polarity label are the word lookups and averaging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9988197684288025}]}, {"text": "However, the information about word polarities in a document are best exploited when using machine learning models to train a sentiment classifier.", "labels": [], "entities": []}, {"text": "In fact, most successful sentiment classification systems rely on supervised learning.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.9633297622203827}]}, {"text": "Interestingly, a simple bag of words model using just unigrams and bigrams with an SVM has shown excellent results () performing on par or beating more complicated models, e.g., using neural networks.", "labels": [], "entities": []}, {"text": "Regarding Twitter sentiment analysis, the top performing system (  from Semeval-2013 Twittter Sentiment Analysis task ( follows this recipe by training an SVM on various surface form, sentiment and semantic features.", "labels": [], "entities": [{"text": "Twitter sentiment analysis", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7062139014403025}, {"text": "Semeval-2013 Twittter Sentiment Analysis", "start_pos": 72, "end_pos": 112, "type": "TASK", "confidence": 0.59676443785429}]}, {"text": "Perhaps, the most valuable finding is that sentiment lexicons appear to be the most useful source of features accounting for over 8 point gains in the F-measure on top of the standard feature sets.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9875518679618835}]}, {"text": "Sentiment lexicons are mappings from words to scores capturing the degree of the sentiment expressed by a given word.", "labels": [], "entities": []}, {"text": "While several manually constructed lexicons are made available, e.g., the MPQA (), the Bing and Liu () and NRC) lexicons, providing high quality word-sentiment associations compiled by humans, still their main drawback is low recall.", "labels": [], "entities": [{"text": "MPQA", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.955913245677948}, {"text": "NRC) lexicons", "start_pos": 107, "end_pos": 120, "type": "DATASET", "confidence": 0.8777515292167664}, {"text": "recall", "start_pos": 226, "end_pos": 232, "type": "METRIC", "confidence": 0.9961115717887878}]}, {"text": "For example, the largest NRC Emoticon lexicon contains only 14k items, whereas tweets with extremely sparse surface forms are known to form very large vocabularies.", "labels": [], "entities": [{"text": "NRC Emoticon lexicon", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.9034162163734436}]}, {"text": "Hence, using larger lexicons with better recall has the potential of learning more accurate models.", "labels": [], "entities": [{"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9984180927276611}]}, {"text": "Extracting such lexicons automatically is a challenging and interesting problem ().", "labels": [], "entities": [{"text": "Extracting such lexicons automatically", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8624187707901001}]}, {"text": "However, different from previous work our goal is not to extract human-interpretable lexicons but to use them as a source of features to improve the classifier accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9091931581497192}]}, {"text": "Following this idea, the authors in ( ) use features derived from the lexicons to build a state-of-the-art sentiment classifier for Twitter.", "labels": [], "entities": []}, {"text": "They construct automatic lexicons using noisy labels automatically inferred from emoticons and hashtags present in the tweets.", "labels": [], "entities": []}, {"text": "The wordsentiment association scores are estimated using pointwise mutual information (PMI) computed between a word and a tweet label.", "labels": [], "entities": []}, {"text": "While the idea to model statistical correlations between the words and tweet labels using PMI or any other metric is rather intuitive, we believe there is a more effective way to exploit noisy labels for estimating the word-sentiment association scores.", "labels": [], "entities": []}, {"text": "Our method relies on the idea of distant supervision).", "labels": [], "entities": []}, {"text": "We use a large distantly supervised Twitter corpus, which contains noisy opinion labels (positive or negative) to learn a supervised polarity classifier.", "labels": [], "entities": []}, {"text": "We encode tweets using words and multi-word expressions as features (which are also entries in our lexicon).", "labels": [], "entities": []}, {"text": "The weights from the learned model are then used to define which lexicon items to keep, i.e., items that constitute a good sentiment lexicon.", "labels": [], "entities": []}, {"text": "The scores for the lexicon items can be then directly used to encode new tweets or used to derive more advanced features.", "labels": [], "entities": []}, {"text": "Using machine learning to induce the scores for the lexicon items has an advantage of learning the scores that are directly optimized for the classification task, where lexicon items with higher discriminative power tend to receive higher weights.", "labels": [], "entities": []}, {"text": "To assess the effectiveness of our approach, we reimplemented the state-of-the-art system ranking 1st in Semeval-2013 Twitter Sentiment Analysis challenge and used it as our baseline.", "labels": [], "entities": [{"text": "Semeval-2013 Twitter Sentiment Analysis challenge", "start_pos": 105, "end_pos": 154, "type": "TASK", "confidence": 0.6375721514225006}]}, {"text": "We show that adding features from our machine-learned sentiment lexicon yields better results than any of the automatic PMI lexicons used in the baseline and all of them combined together.", "labels": [], "entities": []}, {"text": "Our system obtains new state-of-the-art results on the SemEval-2013 message level task with an F-score of 71.32 -a 2% of absolute improvement over the previous best system in SemEval-2013.", "labels": [], "entities": [{"text": "SemEval-2013 message level task", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.5650246888399124}, {"text": "F-score", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.9994126558303833}]}, {"text": "We also evaluate the utility of the ML lexicon on the five test sets from a recent Semeval-2014 task showing significant improvement over a strong baseline.", "labels": [], "entities": [{"text": "ML lexicon", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.8441996276378632}]}, {"text": "Finally, our system shows high accuracy among the 42 systems participating in the Semeval-2014 challenge ranking 2nd best according to the average rank across all test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9995013475418091}]}], "datasetContent": [{"text": "In the following experiments our goal is to assess the value of our distant supervision method to au- tomatically extract sentiment lexicons.", "labels": [], "entities": []}, {"text": "We compare its performance with other automatically constructed lexicons extracted from large Twitter corpora, e.g., auto lexicons built using the PMI approach from (Mohammad et al., 2013).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Semeval-2014. Numbers in parenthesis is the  absolute rank of a system on a given test set. Bold scores  compares using our ML lexicon on top of the NRC sys- tem. Results marked with  \u2020 are statistically significant at  p > 0.05 (via the paired t-test).", "labels": [], "entities": [{"text": "NRC sys- tem", "start_pos": 159, "end_pos": 171, "type": "DATASET", "confidence": 0.9380835592746735}]}]}