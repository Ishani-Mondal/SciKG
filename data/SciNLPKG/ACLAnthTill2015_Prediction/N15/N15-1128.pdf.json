{"title": [{"text": "Distributed Representations of Words to Guide Bootstrapped Entity Classifiers", "labels": [], "entities": []}], "abstractContent": [{"text": "Bootstrapped classifiers iteratively generalize from a few seed examples or prototypes to other examples of target labels.", "labels": [], "entities": []}, {"text": "However, sparseness of language and limited supervision make the task difficult.", "labels": [], "entities": []}, {"text": "We address this problem by using distributed vector representations of words to aid the generalization.", "labels": [], "entities": []}, {"text": "We use the word vectors to expand entity sets used for training classifiers in a bootstrapped pattern-based entity extraction system.", "labels": [], "entities": [{"text": "bootstrapped pattern-based entity extraction", "start_pos": 81, "end_pos": 125, "type": "TASK", "confidence": 0.6437789723277092}]}, {"text": "Our experiments show that the classifiers trained with the expanded sets perform better on entity extraction from four online forums, with 30% F 1 improvement on one forum.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7199482321739197}, {"text": "F 1", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9915700554847717}]}, {"text": "The results suggest that distributed representations can provide good directions for generalization in a bootstrapping system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bootstrapped or distantly-supervised learning is a form of semi-supervised learning, in which supervision is provided by seed examples.", "labels": [], "entities": []}, {"text": "Supervised machine learning systems, on the other hand, require hand-labeling sufficient data to train a model, which can be costly and time consuming.", "labels": [], "entities": []}, {"text": "Bootstrapped information extraction (IE) has become even more pertinent with the ever-growing amount of data coupled with the emergence of open IE systems) and shared tasks like TAC-KBP.", "labels": [], "entities": [{"text": "Bootstrapped information extraction (IE)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7718218763669332}]}, {"text": "Limited supervision provided in bootstrapped systems, though an attractive quality, is also one of 1 http://www.nist.gov/tac/2014/KBP its main challenges.", "labels": [], "entities": []}, {"text": "When seed sets are small, noisy, or do not cover the label space, the bootstrapped classifiers do not generalize well.", "labels": [], "entities": []}, {"text": "We use a major guiding inspiration of deep learning: we can learn a lot about syntactic and semantic similarities between words in an unsupervised fashion and capture this information in word vectors.", "labels": [], "entities": []}, {"text": "This distributed representation can inform an inductive bias to generalize in a bootstrapping system.", "labels": [], "entities": []}, {"text": "In this paper, we present a simple approach of using the distributed vector representations of words to expand training data for entity classifiers in a bootstrapped system (see Algorithm 1).", "labels": [], "entities": []}, {"text": "To improve the step of learning an entity classifier, we first learn vector representation of entities using the continuous bag of words model ().", "labels": [], "entities": []}, {"text": "We then use kNN to expand the training set of the classifier by adding unlabeled entities close to seed entities in the training set.", "labels": [], "entities": []}, {"text": "The key insight is to use the word vector similarity indirectly by enhancing training data for the entity classifier.", "labels": [], "entities": []}, {"text": "We do not directly label the unlabeled entities using the similarity between word vectors, which we show extracts many noisy entities.", "labels": [], "entities": []}, {"text": "We show that classifiers trained with expanded sets of entities perform better on extracting drug-and-treatment entities from four online health forums from MedHelp.", "labels": [], "entities": [{"text": "MedHelp", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.9155644178390503}]}], "datasetContent": [{"text": "We present results on the same experimental setup, dataset, and seed lists as used in.", "labels": [], "entities": []}, {"text": "The task is to extract drug-and-treatment (DT) entities in sentences from four forums on the MedHelp user health discussion website: 1.", "labels": [], "entities": [{"text": "MedHelp user health discussion website", "start_pos": 93, "end_pos": 131, "type": "DATASET", "confidence": 0.8660156846046447}]}, {"text": "Adult Type II Diabetes (called Diabetes), and 4.", "labels": [], "entities": []}, {"text": "Ear Nose & Throat (called ENT).", "labels": [], "entities": [{"text": "Ear Nose", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.7300890684127808}, {"text": "Throat", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.919016420841217}]}, {"text": "A DT entity is defined as a pharmaceutical drug, or any treatment or intervention mentioned that may help a symptom or a condition.", "labels": [], "entities": []}, {"text": "The output of all systems were judged by the authors, following the guidelines in).", "labels": [], "entities": []}, {"text": "We used Asthma as the development forum for parameter and threshold tuning.", "labels": [], "entities": [{"text": "parameter and threshold tuning", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6199745908379555}]}, {"text": "We used threshold \u03b8 as 0.4 and use k (number of nearest neighbors) as 2 when expanding the seed sets.", "labels": [], "entities": []}, {"text": "We evaluate systems by their precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9994352459907532}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9992954730987549}]}, {"text": "Precision is defined as the fraction of correct entities among the entities extracted.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9383701682090759}]}, {"text": "Similar to), we present the precision and recall curves for precision above 75% to compare systems when they extract entities with reasonably: Area under Precision-Recall curve for all the systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9994307160377502}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9966844916343689}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9985094666481018}, {"text": "Area", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.9694744944572449}]}, {"text": "Expanded is our system when word vectors are learned using the Wiki+Twit+MedHelp data and Expanded-M is when word vectors are learning using the MedHelp data.", "labels": [], "entities": [{"text": "Wiki+Twit+MedHelp data", "start_pos": 63, "end_pos": 85, "type": "DATASET", "confidence": 0.8705805043379465}, {"text": "MedHelp data", "start_pos": 145, "end_pos": 157, "type": "DATASET", "confidence": 0.9288600385189056}]}, {"text": "Recall is defined as the fraction of correct entities among the total unique correct entities pooled from all systems.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7795389294624329}]}, {"text": "We calculate the area under the precision-recall curves (AUC-PR) to compare the systems.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.9987952709197998}, {"text": "AUC-PR", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.819652795791626}]}, {"text": "We call our system Expanded in the experiments.", "labels": [], "entities": []}, {"text": "To compare the effects of word vectors learned using different types of datasets, we also study our system when the word vectors are learned using just the in-domain MedHelp data, called Expanded-M. We compare against two baselines: NotExpanded as explained in Section 3, and Average, in which we average the feature values, similar to Note that calculating lower precisions or true recall is very hard to compute.", "labels": [], "entities": [{"text": "MedHelp data", "start_pos": 166, "end_pos": 178, "type": "DATASET", "confidence": 0.8505072891712189}, {"text": "Average", "start_pos": 276, "end_pos": 283, "type": "METRIC", "confidence": 0.9927654266357422}, {"text": "precisions", "start_pos": 364, "end_pos": 374, "type": "METRIC", "confidence": 0.983649492263794}, {"text": "recall", "start_pos": 383, "end_pos": 389, "type": "METRIC", "confidence": 0.9201958179473877}]}, {"text": "Our dataset is unlabeled and manually labeling all entities is expensive.", "labels": [], "entities": []}, {"text": "Pooling is a common evaluation strategy in such situations (such as, TAC-KBP shared task).", "labels": [], "entities": []}, {"text": "shows AUC-PR of various systems and shows the precision-recall curves.", "labels": [], "entities": [{"text": "AUC-PR", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.8164817690849304}, {"text": "precision-recall", "start_pos": 46, "end_pos": 62, "type": "METRIC", "confidence": 0.997647225856781}]}, {"text": "Our systems Expanded and Expanded-M, which used similar entities for training, improved the scores for all four forums.", "labels": [], "entities": []}, {"text": "We believe the improvement for the Diabetes forum was much higher than other forums because the baseline's performance on the forum degraded quickly in later iterations (see the, and improving the classifier helped in adding more correct entities.", "labels": [], "entities": []}, {"text": "Additionally, Diabetes DT entities are more lifestyle-based and hence occur frequently in web text, making the word vectors trained using the Wiki+Twit+MedHelp dataset better suited.", "labels": [], "entities": [{"text": "Wiki+Twit+MedHelp dataset", "start_pos": 142, "end_pos": 167, "type": "DATASET", "confidence": 0.7323421140511831}]}], "tableCaptions": [{"text": " Table 1: Area under Precision-Recall curve for all the systems. Expanded is our system when word vectors  are learned using the Wiki+Twit+MedHelp data and Expanded-M is when word vectors are learning using  the MedHelp data.", "labels": [], "entities": [{"text": "Wiki+Twit+MedHelp data", "start_pos": 129, "end_pos": 151, "type": "DATASET", "confidence": 0.7999845246473948}, {"text": "MedHelp data", "start_pos": 212, "end_pos": 224, "type": "DATASET", "confidence": 0.9478139281272888}]}]}