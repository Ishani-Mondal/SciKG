{"title": [{"text": "Identification and Characterization of Newsworthy Verbs in World News", "labels": [], "entities": [{"text": "Identification and Characterization of Newsworthy Verbs in World News", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.5874030921194289}]}], "abstractContent": [{"text": "We present a data-driven technique for acquiring domain-level importance of verbs from the analysis of abstract/article pairs of world news articles.", "labels": [], "entities": []}, {"text": "We show that existing lexical resources capture some the semantic characteristics for important words in the domain.", "labels": [], "entities": []}, {"text": "We develop a novel characterization of the association between verbs and personal story narratives , which is descriptive of verbs avoided in summaries for this domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Summarization, either by people or machine, calls for the ability to identify important content.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9235717058181763}]}, {"text": "Computational approaches to identifying important content fall into the two extremes of a possible spectrum.", "labels": [], "entities": []}, {"text": "On one end, the types of important information fora given domain and topic are predefined as information extraction templates defined by experts, as in the earliest approaches to multidocument summarization) and the recently introduced guided summarization ().", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 179, "end_pos": 206, "type": "TASK", "confidence": 0.6110709011554718}]}, {"text": "On the other extreme, traditional systems work only with indicators of importance coming solely from the input to be summarized, or possibly also from the context of the input, i.e . analyzing the anchor text of links to a webpage, or comments on a blog post or citations to a scientific article.", "labels": [], "entities": []}, {"text": "Here we explore the feasibility of data-driven identification of important information in the world news domain.", "labels": [], "entities": [{"text": "data-driven identification of important information in the world news domain", "start_pos": 35, "end_pos": 111, "type": "TASK", "confidence": 0.7506718724966049}]}, {"text": "We specifically focus on the analysis of verbs, which is the first step of identifying event types of special interest.", "labels": [], "entities": [{"text": "analysis of verbs", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.8681251406669617}]}, {"text": "The goal is to collect evidence of verb importance globally, without regard to a particular input or its context.", "labels": [], "entities": []}, {"text": "Such ideas have been explored in the past as subcomponents of extractive summarizers () or as features derived from small datasets for sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 135, "end_pos": 155, "type": "TASK", "confidence": 0.7192862033843994}]}, {"text": "In contrast, in our work we rely on large corpora and exclusively focus on the task of acquiring input independent indicators of importance.", "labels": [], "entities": []}, {"text": "We also constrain our analysis to a single domain, which allows us to examine the semantic aspects of the verbs that may contribute to their perceived importance.", "labels": [], "entities": []}, {"text": "We leverage a dataset of human-written summaries of news articles to objectively ground the definition of word importance.", "labels": [], "entities": [{"text": "definition of word importance", "start_pos": 92, "end_pos": 121, "type": "TASK", "confidence": 0.6411553099751472}]}, {"text": "Summaries are intended to convey important information while omitting the less important pieces, so words that are important in a newsworthy sense will occur more frequently in summaries.", "labels": [], "entities": [{"text": "Summaries", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.964792788028717}]}, {"text": "The same data and intuition was used recently to develop a large corpus for determining entity salience).", "labels": [], "entities": []}, {"text": "We derive a list of over one thousand verbs that have statistically significant bias to appear in the summaries (important verbs) and verbs with higher rate of occurrence in the original articles (unimportant).", "labels": [], "entities": []}, {"text": "This resource of verbs and their domain-level importance maybe fruitfully exploited in models of summarization that do not use pre-defined templates but are richer than approaches that rely solely on analysis of the article text.", "labels": [], "entities": [{"text": "summarization", "start_pos": 97, "end_pos": 110, "type": "TASK", "confidence": 0.9757919311523438}]}, {"text": "We furthermore seek to characterize the properties of words that are biased to occur more often in either summaries or in articles.", "labels": [], "entities": []}, {"text": "We noticed that verbs that tended to be dis-preferred in the summaries related to personal narratives, in which people are described as private entities rather than public personas.", "labels": [], "entities": []}, {"text": "We applied the same measures that we used to analyze domain-level importance in world news to a collection of labeled personal and nonpersonal blog entries.", "labels": [], "entities": []}, {"text": "Characterizing verbs on the personal vs. nonpersonal dimension indeed turned out to beneficial for explaining domain-level importance of verbs in world news: personal narratives are not considered important in this domain and verbs that tended to get excluded from summaries also tended to appear more frequently in personal blog entries.", "labels": [], "entities": []}, {"text": "This characterization offered broad coverage of the article vocabulary and additional explanatory power compared to a characterization derived from General Inquirer categories.", "labels": [], "entities": []}, {"text": "The derived lexical resources may serve as shallow semantics fora range of language processing tasks such as summarization, news filtering and search.", "labels": [], "entities": [{"text": "summarization", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.9824196100234985}, {"text": "news filtering", "start_pos": 124, "end_pos": 138, "type": "TASK", "confidence": 0.7635804116725922}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Percentage of words in each class covered by  different GI tags. The first two example words come  from the summary-biased class and last two come from  the article-biased class.", "labels": [], "entities": []}, {"text": " Table 6: 10-fold cross-validation mean squared error of a  linear regression for increasingly biased vocabularies.", "labels": [], "entities": [{"text": "cross-validation mean squared error", "start_pos": 18, "end_pos": 53, "type": "METRIC", "confidence": 0.753314733505249}]}]}