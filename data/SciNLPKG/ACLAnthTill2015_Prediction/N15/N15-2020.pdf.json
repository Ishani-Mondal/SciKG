{"title": [{"text": "Recognizing Textual Entailment using Dependency Analysis and Machine Learning", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9048155943552653}, {"text": "Dependency Analysis", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.6883977949619293}]}], "abstractContent": [{"text": "This paper presents a machine learning system that uses dependency-based features and lexical features for recognizing textual entailment.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 107, "end_pos": 137, "type": "TASK", "confidence": 0.7713852127393087}]}, {"text": "The proposed system evaluates the feature values automatically.", "labels": [], "entities": []}, {"text": "The performance of the proposed system is evaluated by conducting experiments on RTE1, RTE2 and RTE3 da-tasets.", "labels": [], "entities": [{"text": "RTE1", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.8239103555679321}, {"text": "RTE2", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.8242109417915344}]}, {"text": "Further, a comparative study of the current system with other ML-based systems for RTE to check the performance of the proposed system is also presented.", "labels": [], "entities": [{"text": "RTE", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.6838929653167725}]}, {"text": "The dependency based heuristics and lexical features from the current system have resulted in significant improvement inaccuracy over existing state-of-art ML-based solutions for RTE.", "labels": [], "entities": [{"text": "RTE", "start_pos": 179, "end_pos": 182, "type": "TASK", "confidence": 0.8683794736862183}]}], "introductionContent": [{"text": "Recognizing textual entailment (RTE) has aroused lot of interest in natural language research community with recent Pascal RTE challenges.", "labels": [], "entities": [{"text": "Recognizing textual entailment (RTE)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7579771280288696}]}, {"text": "RTE provides a generic evaluation framework and is useful across various applications like questionanswering, information-extraction, machine translation etc.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.8293746411800385}]}, {"text": "Textual Entailment is a directional relation between text fragments () which holds true when the truth of one text fragment, referred to as 'hypothesis', follows from another, referred to as 'text'.", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7121939361095428}]}, {"text": "The task of recognizing textual entailment can bethought of as a classification problem to classify a given pair of sentences, text (T) and hypothesis (H), as true or false entailment as suggested by.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.7559658885002136}]}, {"text": "Machine Learning approaches to RTE challenges have used combination of features like syntactic, semantic or lexical features.", "labels": [], "entities": [{"text": "RTE challenges", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.9556127190589905}]}, {"text": "However, inmost of the cases, the features used for the purpose are either large in number which makes the evaluation time consuming or are not very intuitive which makes them difficult to comprehend.", "labels": [], "entities": []}, {"text": "In our work, we have attempted to address these two concerns.", "labels": [], "entities": []}, {"text": "Our approach uses a combination of dependency and lexical features to train Machine Learning (ML) classifiers.", "labels": [], "entities": []}, {"text": "We use only 8 features that are simple and intuitive.", "labels": [], "entities": []}, {"text": "The process of evaluating feature values is automated, thereby reducing any manual effort and intervention.", "labels": [], "entities": []}, {"text": "The system performance has been tested over RTE1, RTE2 and RTE3 datasets.", "labels": [], "entities": [{"text": "RTE1", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.8520771861076355}, {"text": "RTE2", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.8308850526809692}, {"text": "RTE3 datasets", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9444030523300171}]}, {"text": "Our system shows significant improvement inaccuracy over the state-of-the-art ML solutions to RTE challenges.", "labels": [], "entities": [{"text": "ML", "start_pos": 78, "end_pos": 80, "type": "TASK", "confidence": 0.9556513428688049}, {"text": "RTE", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.8422216773033142}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a brief of the earlier work of ML based approaches for RTE.", "labels": [], "entities": [{"text": "ML based", "start_pos": 47, "end_pos": 55, "type": "TASK", "confidence": 0.9084951281547546}, {"text": "RTE", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9680886268615723}]}, {"text": "Section 3 describes our solution approach for RTE, including details on the features used and the experimental setup.", "labels": [], "entities": [{"text": "RTE", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9649884700775146}]}, {"text": "We present the results and observations in Section 4, followed by conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system performance is evaluated by conducting experiments on RTE1, RTE2 and RTE3 datasets.", "labels": [], "entities": [{"text": "RTE1", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.9010562896728516}, {"text": "RTE2", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.7485050559043884}, {"text": "RTE3 datasets", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9123045802116394}]}, {"text": "The RTE1 dataset consists of 567 sentences pairs (T and H) in the development set and 800 sentence pairs in the test set.", "labels": [], "entities": [{"text": "RTE1 dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9386150538921356}]}, {"text": "These sets are further divided into seven subsets, namely: Information Retrieval (IR), Comparable Documents (CD), Question Answering (QA), Information Extraction (IE), Machine Translation (MT) and Paraphrase Acquisition (PP).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.79426509141922}, {"text": "Question Answering (QA)", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.8273057103157043}, {"text": "Information Extraction (IE)", "start_pos": 139, "end_pos": 166, "type": "TASK", "confidence": 0.7857340335845947}, {"text": "Machine Translation (MT)", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.8327754735946655}]}, {"text": "The RTE2 and RTE3 datasets contain 800 sentence pairs each in their development as well as test sets.", "labels": [], "entities": [{"text": "RTE2", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9444169402122498}, {"text": "RTE3 datasets", "start_pos": 13, "end_pos": 26, "type": "DATASET", "confidence": 0.91199791431427}]}, {"text": "Both the development and test sets of RTE2 and RTE3 are subdivided into four tasks, namely: IE, IR, QA and SUM (summarization).", "labels": [], "entities": [{"text": "RTE2", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.8176832795143127}, {"text": "RTE3", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.7096096277236938}, {"text": "IE", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9709163904190063}, {"text": "IR", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.8457080721855164}, {"text": "QA", "start_pos": 100, "end_pos": 102, "type": "METRIC", "confidence": 0.9440290331840515}, {"text": "SUM", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.8914055824279785}]}, {"text": "We have conducted experiments with different ML algorithms including Support Vector Machines (SVM), Na\u00efve Bayes and Decision Trees (DT) using Weka 3 tool.", "labels": [], "entities": [{"text": "ML", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9698215126991272}]}, {"text": "For each of the RTE datasets, respective training set has been used while experimenting with corresponding test-set.", "labels": [], "entities": [{"text": "RTE datasets", "start_pos": 16, "end_pos": 28, "type": "DATASET", "confidence": 0.8941057324409485}]}, {"text": "We have also performed task based analysis for RTE1 dataset.", "labels": [], "entities": [{"text": "RTE1 dataset", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.8883301019668579}]}, {"text": "Following section summarizes the observations of our experiments.).", "labels": [], "entities": []}, {"text": "In our case, DT turned out to be efficient and fast learners to identify relationship between the feature vectors and the expected entailment results.", "labels": [], "entities": []}, {"text": "For SVM, though it is not guaranteed which kernel performs better in a situation, RBF kernel is generally more flexible than the linear or polynomial kernels as it can model a high dimensional feature space with minimum error.", "labels": [], "entities": []}, {"text": "The observations with these algorithms are strengthened by the test-set results as presented in table 3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Structured Representation for S1", "labels": [], "entities": [{"text": "Structured Representation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8700777590274811}, {"text": "S1", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.8687047362327576}]}, {"text": " Table 2: Validation of system on development sets", "labels": [], "entities": []}, {"text": " Table 4: System Performance -Task label as Feature", "labels": [], "entities": []}, {"text": " Table 6: Comparison of accuracy of our system with  other systems", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9964759945869446}]}]}