{"title": [{"text": "Everyone Likes Shopping! Multi-class Product Categorization for e-Commerce", "labels": [], "entities": []}], "abstractContent": [{"text": "Online shopping caters the needs of millions of users on a daily basis.", "labels": [], "entities": []}, {"text": "To build an accurate system that can retrieve relevant products fora query like \"MB252 with travel bags\" one requires product and query categorization mechanisms, which classify the text as Home&Garden>Kitchen&Dining>Kitchen Appliances>Blenders.", "labels": [], "entities": [{"text": "MB252", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.9376235008239746}]}, {"text": "One of the biggest challenges in e-Commerce is that providers like Amazon, e-Bay, Google, Yahoo! and Walmart organize products into different product taxonomies making it hard and time-consuming for sellers to categorize goods for each shopping platform.", "labels": [], "entities": []}, {"text": "To address this challenge, we propose an automatic product categorization mechanism, which fora given product title assigns the correct product category from a taxonomy.", "labels": [], "entities": []}, {"text": "We conducted an empirical evaluation on 445, 408 product titles and used a rich product taxon-omy of 319 categories organized into 6 levels.", "labels": [], "entities": []}, {"text": "We compared performance against multiple algorithms and found that the best performing system reaches .88 f-score.", "labels": [], "entities": [{"text": "f-score", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.5711871385574341}]}], "introductionContent": [], "datasetContent": [{"text": "In this section, we describe the evaluation metric and the sets of experiments we have conducted.", "labels": [], "entities": []}, {"text": "To evaluate the performance of the product categorization algorithms, we calculate f-score on the test set.", "labels": [], "entities": []}, {"text": "The results are on exact match from top-to-leaf path of the gold and predicted categories.", "labels": [], "entities": []}, {"text": "The highest performance is achieved with the neural network embedding representation.", "labels": [], "entities": []}, {"text": "Between the two classifiers one-against-all consistently achieved the highest scores for all different feature sets.", "labels": [], "entities": []}, {"text": "We also studied various feature combinations, however embeddings reached the highest performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 shows the obtained results. For each fea- ture we report the performance of the two machine  learning algorithms one-against-all (OAA) and error  correcting tournament (ECT).", "labels": [], "entities": [{"text": "error  correcting tournament (ECT)", "start_pos": 148, "end_pos": 182, "type": "TASK", "confidence": 0.6365052759647369}]}]}