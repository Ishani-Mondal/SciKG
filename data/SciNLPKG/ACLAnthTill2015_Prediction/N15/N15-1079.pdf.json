{"title": [{"text": "Using External Resources and Joint Learning for Bigram Weighting in ILP-Based Multi-Document Summarization", "labels": [], "entities": [{"text": "Bigram Weighting", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.6416465640068054}, {"text": "ILP-Based Multi-Document Summarization", "start_pos": 68, "end_pos": 106, "type": "TASK", "confidence": 0.6069799860318502}]}], "abstractContent": [{"text": "Some state-of-the-art summarization systems use integer linear programming (ILP) based methods that aim to maximize the important concepts covered in the summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.9561724662780762}]}, {"text": "These concepts are often obtained by selecting bigrams from the documents.", "labels": [], "entities": []}, {"text": "In this paper, we improve such bigram based ILP summarization methods from different aspects.", "labels": [], "entities": [{"text": "ILP summarization", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.8065806329250336}]}, {"text": "First we use syntactic information to select more important bi-grams.", "labels": [], "entities": []}, {"text": "Second, to estimate the importance of the bigrams, in addition to the internal features based on the test documents (e.g., document frequency, bigram positions), we propose to extract features by leveraging multiple external resources (such as word embedding from additional corpus, Wikipedia, Dbpedia, Word-Net, SentiWordNet).", "labels": [], "entities": [{"text": "Word-Net", "start_pos": 303, "end_pos": 311, "type": "DATASET", "confidence": 0.8914889693260193}]}, {"text": "The bigram weights are then trained discriminatively in a joint learning model that predicts the bigram weights and selects the summary sentences in the ILP framework at the same time.", "labels": [], "entities": []}, {"text": "We demonstrate that our system consistently outperforms the prior ILP method on different TAC data sets, and performs competitively compared to other previously reported best results.", "labels": [], "entities": [{"text": "TAC data sets", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.88608185450236}]}, {"text": "We also conducted various analyses to show the contributions of different components.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extractive summarization is a sentence selection problem: identifying important summary sentences from one or multiple documents.", "labels": [], "entities": [{"text": "Extractive summarization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9006147384643555}, {"text": "sentence selection", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7159578800201416}]}, {"text": "Many methods have been developed for this problem, including supervised approaches that use a classifier to predict whether or not a sentence is in the summary, or unsupervised methods such as graph-based approaches to rank the sentences.", "labels": [], "entities": []}, {"text": "Recently global optimization methods such as integer linear programming (ILP) have been shown to be quite powerful for this task.", "labels": [], "entities": [{"text": "integer linear programming (ILP)", "start_pos": 45, "end_pos": 77, "type": "TASK", "confidence": 0.7194039722283682}]}, {"text": "For example, used ILP to achieve the best result in the TAC 09 summarization task.", "labels": [], "entities": [{"text": "TAC 09 summarization task", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.6040345653891563}]}, {"text": "The core idea of this summarization method is to select the summary sentences by maximizing the sum of the weights of the language concepts that appear in the summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.9701254963874817}]}, {"text": "Bigrams are often used as these language concepts because stated that the bigrams gave consistently better performance than unigrams or trigrams fora variety of ROUGE measures.", "labels": [], "entities": []}, {"text": "The association between the language concepts and sentences serves as the constraints.", "labels": [], "entities": []}, {"text": "This ILP method is formally represented as below (see () for more details): s j \u2208 {0, 1} \u2200j (6) c i and s j are binary variables that indicate the presence of a concept and a sentence respectively.", "labels": [], "entities": []}, {"text": "l j is the sentence length and L is maximum length of the generated summary.", "labels": [], "entities": []}, {"text": "w i is a concept's weight and Occ ij means the occurrence of concept i in sentence j.", "labels": [], "entities": [{"text": "Occ", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9941446185112}]}, {"text": "Inequalities (2)(3) associate the sentences and concepts.", "labels": [], "entities": []}, {"text": "They ensure that selecting a sentence leads to the selection of all the concepts it contains, and selecting a concept only happens when it is present in at least one of the selected sentences.", "labels": [], "entities": []}, {"text": "In such ILP-based summarization methods, how to determine the concepts and measure their weights is the key factor impacting the system performance.", "labels": [], "entities": [{"text": "ILP-based summarization", "start_pos": 8, "end_pos": 31, "type": "TASK", "confidence": 0.7234621942043304}]}, {"text": "Intuitively, if we can successfully identify the important key bigrams to use in the ILP system, or assign large weights to those important bigrams, the system generated summary sentences will contain as many important bigrams as possible.", "labels": [], "entities": []}, {"text": "The oracle experiment in ( showed that if they just use the bigrams extracted from human generated summaries as the input of the ILP system, much better ROUGE scores can be obtained than using the automatically selected bigrams.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 153, "end_pos": 158, "type": "METRIC", "confidence": 0.9907838106155396}]}, {"text": "In this paper, we adopt the ILP summarization framework, but make improvement from three aspects.", "labels": [], "entities": [{"text": "ILP summarization", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.8015864193439484}]}, {"text": "First, we use the part-of-speech tag and constituent parse information to identify important bigram candidates: bigrams from base NP (noun phrases) and bigrams containing verbs or adjectives.", "labels": [], "entities": []}, {"text": "This bigram selection method allows us to keep the important bigrams and filter useless ones.", "labels": [], "entities": []}, {"text": "Second, to estimate the bigrams' weights, in addition to using information from the test documents, such as document frequency, syntactic role in a sentence, etc., we utilize a variety of external resources, including a corpus of news articles with human generated summaries, Wiki documents, description of name entities from DBpedia, WordNet, and SentiWordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 335, "end_pos": 342, "type": "DATASET", "confidence": 0.9501384496688843}]}, {"text": "Discriminative features are computed based on these external resources with the goal to better represent the importance of a bigram and its semantic similarity with the given query.", "labels": [], "entities": []}, {"text": "Finally, we propose to use a joint bigram weighting and sentence selection process to train the feature weights.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.6861061751842499}]}, {"text": "Our experimental results on multiple TAC data sets show the competitiveness of our proposed methods.", "labels": [], "entities": [{"text": "TAC data sets", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.816379596789678}]}], "datasetContent": [{"text": "We evaluate our methods using several recent TAC data sets, from 2008 to 2011.", "labels": [], "entities": [{"text": "TAC data sets", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.886044998963674}]}, {"text": "The TAC summarization task is to generate at most 100 words summaries from 10 documents fora given topic query consisting of a title and more detailed description (this is unavailable in 2010 and 2011 data).", "labels": [], "entities": [{"text": "TAC summarization", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8369062840938568}]}, {"text": "When evaluating on one TAC data set, we use the data from the other three years as the training set.", "labels": [], "entities": [{"text": "TAC data set", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.8987639745076498}]}, {"text": "All the summaries are evaluated using ROUGE.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.968960165977478}]}, {"text": "In all of our experiments, we use Stanford CoreNLP toolkit to tokenize the sentences, extract name entities and POS tags.", "labels": [], "entities": [{"text": "Stanford CoreNLP toolkit", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.9238525231679281}]}, {"text": "Berkeley Parser () is used to get the constituent parse tree for every sentence.", "labels": [], "entities": []}, {"text": "An academic free solver 11 does all the ILP decoding.", "labels": [], "entities": [{"text": "academic free solver", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.47951876123746234}]}, {"text": "shows the ROUGE-2 results of our proposed joint system, the ICSI system (which uses document frequency threshold to select bigram concepts and uses df as weights), the best performing system in the NIST TAC evaluation, and the state of the art performance we could find.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8918129801750183}, {"text": "ICSI", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.5049694180488586}, {"text": "NIST TAC evaluation", "start_pos": 198, "end_pos": 217, "type": "DATASET", "confidence": 0.8905033270517985}]}, {"text": "The result of our proposed method is statistically significantly better than that of ICSI ILP (p < 0.05 based on paired ttest", "labels": [], "entities": [{"text": "ICSI ILP", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.7592419683933258}]}], "tableCaptions": [{"text": " Table 1: ROUGE-2 summarization results. \u2020 is from (Li  et al., 2013b),  \u2021 is from (Davis et al., 2012), and  *  is from  (Ng et al., 2012).", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.6334847807884216}]}, {"text": " Table 2: ROUGE-2 summarization results when using  different bigrams, both using document frequencies as  weights.", "labels": [], "entities": [{"text": "ROUGE-2 summarization", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.5798732936382294}]}, {"text": " Table 3: ROUGE-2 results using one feature type.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9265368580818176}]}, {"text": " Table 4: ROUGE-2 results using internal features com- bined with features from just one external resource.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.890268862247467}]}, {"text": " Table 5: ROUGE-2 results using features incrementally  combined.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9440271258354187}]}, {"text": " Table 6: ROUGE-2 results when leaving out each feature  type.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9802345633506775}]}]}