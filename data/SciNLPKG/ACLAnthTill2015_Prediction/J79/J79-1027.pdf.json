{"title": [{"text": "American Journal of Computational Linguistics A FORMAL PSYCHOLINGUISTIC MODEL O F Association for Computational Linguistics Xm CLAUSE-TOWCLAUSE L IN K IN G mm * a o a o * o + mo m . m --* ---* -- I . SOME PSYCHOLOGICAL CONSTRAINTS ON SENTENCE COMPREHENSION MODELS PSR r (THEX 1 BOYX) (By) ISRI (IIIEX~BOYX &HUMAN% & ~ADULTX m 0 * } ( 3 ~ ) ( 3 t~", "labels": [], "entities": [{"text": "CLAUSE-TOWCLAUSE L IN K IN G mm", "start_pos": 127, "end_pos": 158, "type": "METRIC", "confidence": 0.7798425299780709}, {"text": "THEX 1 BOYX", "start_pos": 271, "end_pos": 282, "type": "METRIC", "confidence": 0.7102960348129272}, {"text": "BOYX", "start_pos": 301, "end_pos": 305, "type": "METRIC", "confidence": 0.9506104588508606}]}], "abstractContent": [{"text": "This paper outlines a psychologically constrained theory of sentence comprehension The most prominent features of the theory are that: (1) syntactic structure is discarded clause by clause (where the traditional notion of clause is modified in certain re s p e ct s so as to conform to short term memory requirements); (2) the syntactic and semantic processor work in parallel.", "labels": [], "entities": [{"text": "sentence comprehension", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7074194550514221}]}, {"text": "The semantic analysis proceeds from the preliminary semantic representation (PSR) via the intermediate SR (ISR) to the final SR (FSR), making crucial use O X an encyclopedia which codes semantic knowledge.", "labels": [], "entities": [{"text": "FSR", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.7317059636116028}]}, {"text": "The three stages of the semantic analysis are discussed.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.9183914065361023}]}, {"text": "Concatenation Rules establish the PSR, Meaning Rules and Ency-clopedic Rules the ISR, and Semantic Linking Strategies the FSR.", "labels": [], "entities": [{"text": "FSR", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.6067093014717102}]}, {"text": "At every stage, the semantic representations are in terms of a modified pr ed i ca t e ca ~ cu l u s notation.", "labels": [], "entities": []}, {"text": "Syntax-free as well as syntax-sensitive Linking Strategies are presented for clause-internal linking.", "labels": [], "entities": []}, {"text": "Finally, syntax-free linking of constituent clauses of complex sentences is described.", "labels": [], "entities": [{"text": "syntax-free linking of constituent clauses of complex sentences", "start_pos": 9, "end_pos": 72, "type": "TASK", "confidence": 0.7983795814216137}]}, {"text": "TABLE OF CONTENTS I l SOW3 PSYCHOLOGICAL CONSTRAINTS ON SENTENCE COMPRXHENSTQN MODZLS a.", "labels": [], "entities": [{"text": "TABLE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9694924354553223}, {"text": "MODZLS", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.493889719247818}]}, {"text": ".. am om ma mo *.", "labels": [], "entities": []}, {"text": "am o e. o em a o a o am om 4 11.", "labels": [], "entities": []}, {"text": "TRADITIONAL LINGUISTIC APPROACHES rm mm. a am o am mm am em 11 LII l A THREE-STAGE THEOXY O F SENANTIC ANALYSIS ll la a. a l 13 IV AB I OD I F IE B PREDICATE CALCULUS NOTATION FOR SSdANTIC REPRESENTATIONS mm. m. ma e e o. am e o a o om.", "labels": [], "entities": [{"text": "TRADITIONAL LINGUISTIC APPROACHES rm mm. a am o am mm am em 11 LII l A THREE-STAGE THEOXY O F SENANTIC ANALYSIS", "start_pos": 0, "end_pos": 111, "type": "METRIC", "confidence": 0.7039476836269553}, {"text": "AB I OD I F IE B PREDICATE CALCULUS NOTATION FOR SSdANTIC REPRESENTATIONS", "start_pos": 131, "end_pos": 204, "type": "METRIC", "confidence": 0.7523833788358248}]}, {"text": ".. ma mm 15 Vm THE PSRB CONCATENATION R UL E S. o ~ m.", "labels": [], "entities": [{"text": "Vm", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.9390425682067871}, {"text": "THE PSRB CONCATENATION R UL E S. o", "start_pos": 15, "end_pos": 49, "type": "METRIC", "confidence": 0.8033134937286377}]}, {"text": "* * ea o a a em e *.", "labels": [], "entities": []}, {"text": "mm om m 1 7 VI.", "labels": [], "entities": []}, {"text": "THE ISR: SEMANTIC KNOWLEDGE R UL E S a o em ma a o a o em e * a o a 1 9 VTI THE-FSR t SEMANTIC LINKING STRATEGIES ll l 6 la ll la 3 2 2 VI I I e DIFFERENT MODES OF PROCESSING a a la la mo o la em or la l rn ma 30 I X o \"ALTERNATIVE LINKING STRATEGIES''.", "labels": [], "entities": [{"text": "SEMANTIC KNOWLEDGE R UL E", "start_pos": 9, "end_pos": 34, "type": "METRIC", "confidence": 0.6601003289222718}, {"text": "VTI THE-FSR", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.8115114271640778}]}, {"text": "a a o a a o a a a o ~ ma mm a In t hi s paper I consider t he question of how an a u to ma ti c sentence recognizer would have to look in order to be compatible wLth present psycholinguistic knowledge about speech co mp re h m h The basic premise is that psycholinguistic considerations are of potential interest to computational theories (s e e , e. g. , ~chank(1972)) Let me begin by summarizing some characteristics of speeck processing which we know either from experiments, or which are in t u it iv e l y clear.", "labels": [], "entities": []}, {"text": "First, there i s some evidence t ha t the clause i s a u n it of processing.", "labels": [], "entities": []}, {"text": "For instance, ~aplan(1972) showed that after a clause boundary is passed, the cons-bitaent words bf t he completed clause are relatively inaccesai'ble, as measured by w m d recognition la t en c y.", "labels": [], "entities": []}, {"text": "The e ff e ct was independent of the serial position of the word for which recognition time was tested.", "labels": [], "entities": []}, {"text": "Th i s suggests that sentences are processed clause by cl a u s e , w it ho n l y the semantic content regularly retained after the clause boundary is passed.", "labels": [], "entities": []}, {"text": "The surface words (and g fortiori the syntactic st r u ct u r e) of the clause would tend to be erased after each clause boundary.", "labels": [], "entities": []}, {"text": "1 *Thie paper i s based on chapter VII of my doctoral dissertation (~ e i mo l d (forthcoming)).", "labels": [], "entities": [{"text": "Thie", "start_pos": 3, "end_pos": 7, "type": "METRIC", "confidence": 0.9883715510368347}]}, {"text": "I wish to thank Thomas G. Bever , Jame-a Higginbotham, and D *Terence Langendoen f or he l pf u l suggestions.", "labels": [], "entities": [{"text": "Jame-a Higginbotham", "start_pos": 34, "end_pos": 53, "type": "DATASET", "confidence": 0.7625580132007599}]}, {"text": "l ~ he f or ti or i J refers to the fact that the syntactic st r u ct u re Another study supporting the clause as unit of proceasing is Abrams 6 ~ e v er (1 9 6 9).", "labels": [], "entities": []}, {"text": "These a u t ho r s found t ha tr ea ct i on time to sh or t bursts of noise \" cl i ck s \") superimposed on sentences was longer for clause-final clicks than for clause-initial ones.", "labels": [], "entities": []}, {"text": "This would point to the clause as unit of perception, under the assumption t ha t processing is more intensive towards the end of a p er c e ~ t u a l unit, and that reaction time toe x t er n a l stimuli is a valid ineicator oft he intensity of internal procesging. or a review of other studies in support of the clausal processing theory, the reader i s referred to Podor, Bever & ~arre%t(1974), where arguments a re a l so given f or the clause as a decision point across which ambiguitiis are ,normally at l ea st , not carried-.)", "labels": [], "entities": []}, {"text": "Secondly, it seems t ha t as we l i st en to speech, we simultaneously have access to both the syntactic and semantic propertiee of what we hear.", "labels": [], "entities": []}, {"text": "That is, there appears to be ~ a r a ll e l orocessing oft he syntax and the semantics of a clause.", "labels": [], "entities": []}, {"text": "One finding explained by this assumption i st ha t so-called \"irreversible\" passive sentences like (1) are perceptually no more complex t h n n their active counterparts (the air1 ~ i ck ed the rlower,in this ca s e).", "labels": [], "entities": []}, {"text": "By co n tr a st , 'reversiblew passives l i k e (2) take longer to verify visa -vis pi ct u re s than t he ~orre~pondin$ active sentences (~lobin(1.966)).", "labels": [], "entities": []}, {"text": "presumably contain8 surface wards a s terminal nodes.", "labels": [], "entities": []}, {"text": "Hence if the eyntax were regularly preserved the surface words should remain easily accessible, too.", "labels": [], "entities": []}, {"text": "(1) The fl ow e ~ was picked by t he g i r l.", "labels": [], "entities": []}, {"text": "(irreversible) (2) The boy was k i ck ed by the girl.", "labels": [], "entities": []}, {"text": "(r e v er s i bl e) It appears that t he syntactic complexity introduced by the passive construction i s somehow circumvented by a predominantly semantic method of analysis int he case of i&reversible passives m 2 W e thus get a picture of speech processing as in ~ i ~ ~ l.", "labels": [], "entities": []}, {"text": "3 yntactic p r-l $ syntactic structure of .S 1 input I ' [string S I semantic ~ r z ad semantic structure of s 1 Fig.1: Parallel Processing Model 2 ~ no t he r experimental study su parting t he Parallel.", "labels": [], "entities": []}, {"text": "Processing theory is larslen-lilson(l973 ! '. 3 ~ y view of the r o l e of syntax is re la t ed tot ha t expressed in ~chank(1972), w ho believes t ha t the function of syntax is \"\"as a pointer to semantic information rather than as a f i r st st e pt o aemantic analysis?'", "labels": [], "entities": []}, {"text": "(~ ~ 5 5 5) Similarly, winograd (1971) a ll ow s parallel operation of syntactic and semantic analysis.", "labels": [], "entities": [{"text": "syntactic and semantic analysis", "start_pos": 71, "end_pos": 102, "type": "TASK", "confidence": 0.6192301586270332}]}, {"text": "However, me syntactic and semantic processor in Winograd's systehr have f u ll power, in mi n c i pl e , to question each other about their respective success before proceeding with t he i r part pf t he analysis* This powerful device has been aeverely re st r i ct ed int he theory described here (for details, see Reimold (f or t h c oming)) The main reasons f or t hi e are t he greater re l i an c e , in my theory, on \"syntax-free\" semantic interpretation, and the generally sh or t er life-apan of syntactic structure (see t he d i s cu s s i on of \"peripheral clauses\" be lo w).", "labels": [], "entities": [{"text": "syntax-free\" semantic interpretation", "start_pos": 424, "end_pos": 460, "type": "TASK", "confidence": 0.6520915105938911}]}, {"text": "Woods (1973) also d i s cu s s e ea system w it h c er ta in facilities f or parallel processing, for instance, the \"Selnctlve Modifier Placement\" facility (s M P) ~ The function of SMP is to ~ e l s ct from the list of syn%actically adrnissibLe alternatives the one which is semantically most appropriate, and return only that alternative tot he parser before golng an *o analyze t he re st of t he sentence.", "labels": [], "entities": [{"text": "SMP", "start_pos": 182, "end_pos": 185, "type": "TASK", "confidence": 0.9670020341873169}]}, {"text": "The most important d if f er en c e between Woods' proposal and the one presented here is that his semantic processor on l y chooaes among ta ct tructQrsd alternatives (and, int ha t sense,% a fu%$%$tax-sensltve method), whereas my t he or y partdates rn gyntactfclm me n w h mo d if i er sand t he i r he ad s.", "labels": [], "entities": []}, {"text": "Let me return now to the pr in c i pl e of clause-by-clause processing, If we assume that \"imqediate processing\" takes place in short term memory, then we must automatically requkre that t he unit of processing mu st not exceed the known Limits of sh or t term memory.", "labels": [], "entities": []}, {"text": "Now since t ha t limit is generally taken to be about 5 wordsp t he clause-by-clause pr in c i pl e ca n no t be literally true.", "labels": [], "entities": []}, {"text": "(3) lists some \"clauses\" longer than 5 w or d s.", "labels": [], "entities": []}, {"text": "It seems tome, therefore, t ha t we have to revise the traditional concept of olause* (3) a) John and Bill and O t to st r o k ed and huaaed t he go at am the goose.", "labels": [], "entities": [{"text": "John and Bill", "start_pos": 93, "end_pos": 106, "type": "DATASET", "confidence": 0.8513744870821635}]}, {"text": "b) The man w it h the dog w it h the c ~ ll a r , w it ht he bell Laughed, c) John me this friends yelafzerdau morning around ten o'clock ih .a liCtle cafe near D L-U ~ U W ~ Y.", "labels": [], "entities": [{"text": "Y", "start_pos": 175, "end_pos": 176, "type": "METRIC", "confidence": 0.8516824245452881}]}, {"text": "Z propose to take the underlined phrases in (3) o u t of the sentence proper and process them as if they we re separate clauses.", "labels": [], "entities": []}, {"text": "That is, f draw a distinction between t he \"nucLearH clause and \"peripheralw clauses.", "labels": [], "entities": []}, {"text": "The non-underlined 'portions in (3) are nuclear clauses.", "labels": [], "entities": []}, {"text": "Peripheral clauses include: Prep-clauses (\" w it ht he co ll a r \") , Comparison-clauses (\"than the old co lo n e l w).", "labels": [], "entities": [{"text": "Prep-clauses", "start_pos": 28, "end_pos": 40, "type": "METRIC", "confidence": 0.9144273400306702}]}, {"text": "Post-clauses (\"yesterday, 'I \"around ten o t cl o ~ 'in a l it t l e ca f e \") , and Coordinate-clauses (\"and Bill,\" \"and hugged\") This treatment of c er ta in phrases as peripheral clauses seems pl a u s i bl e to o , if we consider t ha t \"adnominal\" Prep-phrases, f or instance, are semantically l i k er e la ti v e clauses, as shown in (4), and t ha t adverbs are pa r a ll e l to c er ta in \"adverbialU clauses, as indicated in (5).", "labels": [], "entities": []}, {"text": "(4) ~ q i r l { w it ha green hat who wore a green hat gr e e t ed John.", "labels": [], "entities": []}, {"text": "5) Jo h n ate t he cake C afterwards.", "labels": [], "entities": []}, {"text": "Z v l d en t l y , w it ha green ha tin (4) is re la t ed to who wore a meen hat, and t he adverb afterwards in (5) can be replaced by f i ll 1 adverbial clauses like after t he m 1 e s. t ~ l e ft.", "labels": [], "entities": []}, {"text": "We are presently testing the validity oft hi s notion of peripheral cl a u s e. e use snntence pairs l i k e (6a-b) I (6a) The officer threatened tog iv e t he woman * a +icket.b&e-internal p o s it i on of cl i ck \" * \") (6 b) The officer threatened to f in e t he woman * w it ho u t Ba license.", "labels": [], "entities": []}, {"text": "(c la v s e-f in a l position of cl i ck \" * \") Y O u r goal is to determine, mine a ' cl i ck d e t e ct i on pa r ad i en , whether or no t there is a \"clause boundary e ff e ct \" be f or e t he final peripheral clause witho7l-t a License in (6b) * No ti c e t ha t according to my hypothesis, t he re is a clause boundary after woman in (6b), but not in (6a).", "labels": [], "entities": []}, {"text": "It ha s been shown inn humber of st u d i e st ha t clause boundaries (b u t not p hr a ~ e boundaries, in general) have certain measurable behavioral e ff e ct n Crf.", "labels": [], "entities": []}, {"text": "t he review in Focbr, Bever L ~arrett(l974))t sot hi s should apply here to o , ff p er i p he r a l clauses are indeed p s y ch o lo g i ca ll y reab clauses 'Now, the last pr in c i pl e-I w an t to d i s ca s sis t ha tin understanding an utterance, people mage creative u s e oft he i r knowledge-about thew a r I d.", "labels": [], "entities": [{"text": "Focbr", "start_pos": 15, "end_pos": 20, "type": "DATASET", "confidence": 0.979417622089386}, {"text": "arrett", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9133174419403076}]}, {"text": "4 For in st an c e , if Io n l y hear you say* (7,) The cat just caught a-I can immediately guess t ha t t he last word was something like bi rd or DDUW SimlLar-ly, if yo u say: (8) Pu t t he freezer int he turkey.", "labels": [], "entities": []}, {"text": "I know t ha t your ea ll y meant \"put the turkey int he freezer,\" 4 This general point has been made, in one fortn pr another, by many authors.", "labels": [], "entities": []}, {"text": "For instance, Winograd~1971) notes that correct understanding of they in *The c it y councilmen refused to give the women a permit fora demonstration because 3;he-y. feared violezkmm and \"The ck k y coundlmen re f u s ed tog iv e the women a permit f or a denaonst6ation because they advocated revalution\" needs t he \"information and reasoning power to realize t ha t c it y councf lmen a re usually staunch advocates of la wand or d er , btlt a re hardly l i k e l y to be revolutionaries.\"(p~ll) Si mi la r l y , ~chank(19-72) envisages at he or y of natural language under-etanding whlch.\"has a conceptual base t ha t coneiate of a formal etructurew and \"can make predictfons on t he basis of this conceptual structurew(,556) The principal d if f er en c e s between these approaches and m f ne have to do w it h (1) t he of the stored semantic information (PLANNER and \"conceptual case networkn representations v s c predicate calculus representations) and (2) the proposed ~ cc em ~ ch an 5 s ~ tot hi a infobmation.", "labels": [], "entities": []}, {"text": "Schank's theory relies on l ex L ca l decornpoeLtion, while I uae the \"meaning postulates\" methodr Winograd opts fora broad procedural approach, representing \"knowledge in the form of praceuuree rather than tables of rules or lists of pattern~~\"(p.21) By contrast, my proposal remaine cl o s er to the traditional WdeclarativeH approach, as w i ll become cl ea r because J.", "labels": [], "entities": []}, {"text": "Know someznlng a D o u t turkeys and freezers.", "labels": [], "entities": []}, {"text": "No model excluding t he possibility af matching speech against stored knowledge of the world can explain such fa ct s.", "labels": [], "entities": []}, {"text": "In this connection, consider a l so t he sentences in (911 (9a) I ' m leaving the dbor open so I won't f or g e t to wina &=p (it= the clock-t he re was no previous mention of ac lo ck in the d i a lo g u e , butt he speaker was looking at a Grandfather cl o ck w it h open door) (9b) They published Wodehouse immediately he came over.", "labels": [], "entities": []}, {"text": "(= published books written by Wodehouse) (9 c) Italy was sitting in the f i r st row, and France int he second.", "labels": [], "entities": []}, {"text": "(= p e o ~ l e from It a l y and France) (9 d) We'd better put in 20 minutes.", "labels": [], "entities": []}, {"text": "(= money f or 20 minutes-speaking ab o u ta parking meter) (9 e) He's sitting bv hi s olate t ha t isn't t he re.", "labels": [], "entities": []}, {"text": "(= by where he wishes* hi s pl at e were, by his late in his wish-world-epeaking of a cat) These sentences can a11 be understood without difficultyr and t he way we understand them is by using our general semantic knowledge.", "labels": [], "entities": []}, {"text": "What t hi s means, then, i s that the comprehension model needs to incorporate an encyclopedia which somehow codes semantic knowledge.", "labels": [], "entities": []}, {"text": "In slm, to be compatible with the psychological model, the al~tomatic sentence recognizer should have the following properties 8 (1) it should be a clause-by-clause processo2, where my no ti on of \"-lause\" includes some things traditionally regarded as phrases; as soon as the in t er pr e ta ti on of a clause is completed, its syntactic structure is erased; (2) there should be parallel syntactic and semantic processing of each clause1 (3) the recognizer must make systematic use of an encyclopedia which codes knowledge about thew or l d * IIt TZADITIONAL LINGUISTIC APPROACHES Putting together the above observations, one can already see that current linguistic theories a re no t very he l pf u l for the eolution of our problem.", "labels": [], "entities": [{"text": "TZADITIONAL LINGUISTIC APPROACHES", "start_pos": 548, "end_pos": 581, "type": "METRIC", "confidence": 0.8199486335118612}]}, {"text": "Fnr inetance, linguistic theory would claim that sentence (10) hast he syntactic structwe in (11)~ which then undergoes various syntactic transformations until it is finally mapped onto it s appropriate semantics true ture.", "labels": [], "entities": []}, {"text": "The rrentence recognizers moat directly meetfng this d e s c r i pt i or a re robabl those developed by Stanley P e tr i ck (see P e tr i ck (~ 9 6 9 , 197)y).", "labels": [], "entities": [{"text": "rrentence recognizers", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6920166015625}]}, {"text": "Wlth some modlf icatione, however, t hi s deecription a l so f it s the theories preeerited in Winograd (1971) and Woode (1973).", "labels": [], "entities": []}, {"text": "Whkle these syetema are feature-manipulating rather than transformational, they nonetheless assume t ha t the lifespan of syntax extends over an entire sentence, and they make crucial use of integrated syntactic structures f or corn la x sentences or instan~e, winograd (1971) presents an f ntegrated syntactic structure for the sentence \" P i ck up anything green, at l ea st three oft he blocker and either a box or a sphere which is bigger than any brick on the table.", "labels": [], "entities": []}, {"text": "Recagnlzere ueing an inverse \"Geherative Se'lllantics\" grammar would a l do fa ll under t hi s deecriptioh.", "labels": [], "entities": []}, {"text": "(10) The man with the beard claimed f i er c e l y t ha the w a s innocent.", "labels": [], "entities": []}, {"text": "fiercely t ha t h~ ent But in the vLew I have just sketched, sentence (10) never has any integrated syntactic structure like (11).", "labels": [], "entities": [{"text": "vLew", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.9553136229515076}]}, {"text": "Instead, as shown in (121, the string with the beard, for in st an c e , i s processed as a separate cl a u s e , and as soon as. it s meaning has been extracted and added as q u a l if i er to t he preceding noun phrase the man, its syntactic structure is erased.", "labels": [], "entities": []}, {"text": "(12) 4 successive \"perceptual crrruses\" for sentence (1 0) r [ cl a i me d MVB] Lq ma< Similarly, t he \"Post+ Lause\" f i er c e l y and the entire complement clause t ha the was innocent must be linked to the main clause without referring to the syntactic struc~ure oft he latter, which is assumed to be erased as soon as the word claimed has been semantically integrate& This would seem to be a more economical procedure, because it minimizes the size of the syntactic b a ll a st t ha t has to be carried along.", "labels": [], "entities": []}, {"text": "C~mparsr for instance, t he s i z e of the chunk in (11) to the s i z e 0.4 the little chunks in (12).", "labels": [], "entities": []}, {"text": "Secondly, transformational grammar is ha rd l y compatible w it h the principle of parallel Processins of the eyntax and semantics of a @lausem The reason is t ha t accdrding to transformational grammar, the syntactic analysis precedes and determines the semaqtic analysis.", "labels": [], "entities": []}, {"text": "By contrast, Parallel Processing means that at least some of the semantic interpretation rules must be syntax-free.", "labels": [], "entities": []}, {"text": "111 a A THREE-STAGE THEORY OF SEMANTIC ANALYSIS Lez US reT;urn Lora moment to rlg.l.", "labels": [], "entities": [{"text": "THREE-STAGE", "start_pos": 8, "end_pos": 19, "type": "METRIC", "confidence": 0.8745937943458557}, {"text": "THEORY", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.7740775346755981}, {"text": "SEMANTIC ANALYSIS Lez US reT", "start_pos": 30, "end_pos": 58, "type": "METRIC", "confidence": 0.7643507122993469}, {"text": "Lora", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.8664369583129883}]}, {"text": "Th at rlgure contained a box la be ll ed gyn*actic pr ac e w , and another box la be ll ed semantic proceseoP.", "labels": [], "entities": []}, {"text": "As I have st at ed , t he s e components cannot be identified with the eyntactic and semantic components of current transformational grammar.", "labels": [], "entities": []}, {"text": "The syntactic processor w i ll not bed i s cu s s ed ind e ta i l here (see ~ e i mo l d ~ f or t h co mi n g) f or a fuller diacuesiori).", "labels": [], "entities": []}, {"text": "It is a predictive parser using d-ency * notation.", "labels": [], "entities": []}, {"text": "There are-no syptactic transformations at all, but the output is a simple surface tree for each clbause, with certain nodes marked by functional features like SuBJect, OBJ1, OBJ2, or MainVerB.", "labels": [], "entities": []}, {"text": "The trees m (-12) above are exarpples.", "labels": [], "entities": []}, {"text": "For the remainder, let me concentrate on t he semantic box.", "labels": [], "entities": []}, {"text": "I suggest t ha t there are three stapes in the semantic analysis.", "labels": [], "entities": []}, {"text": "as shown in FigS, namely a preliminary, intermediate, and f.inal semantic representatton (PSR, ISR, and FSR).", "labels": [], "entities": [{"text": "FigS", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.8993995785713196}, {"text": "FSR", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9929876923561096}]}, {"text": "Preliminary SR f-$ ~ ~ t er r n ed i at e w F in a l SR I c onc at enati on Meaning Rules & (Rules1 '-Encyclopedic Rules ' Fig.24 +Stage Model of Semantic Analysis The PSIi corresponds to a simple co m bl n at i p ~ ~ oft he l ex i ca l meaninsrs of the words.", "labels": [], "entities": [{"text": "Semantic Analysis", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.7798598110675812}]}, {"text": "Cl ea r l y , as we hear the words in a sentence, we immediately grasp their in d i 4 id u a l meaning, even though we ma y not be sure ye t how they f it to g e t he r.", "labels": [], "entities": []}, {"text": "Thi-s' then f st he preliminary SR.", "labels": [], "entities": [{"text": "Thi-s'", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.936150312423706}, {"text": "SR", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.7135478258132935}]}, {"text": "But we a l s ~ immediately have access to some of the immJ,ications oft he words and phrases.", "labels": [], "entities": []}, {"text": "For instance, if I hear \" ca t w I immediately also know wanlmal.w Adding such implications derives t he intermediate SR fr o m-the PSRe The final SR isl a k e the preliminary one, except t ha t t he appropriate semantic r o l e sh av e been assigned to all t he conetLtuents.", "labels": [], "entities": []}, {"text": "An example f or the three stages is given in (13).", "labels": [], "entities": []}, {"text": "(13) The boy laughed.", "labels": [], "entities": []}, {"text": "(simolif i ed to a (~ I b r BOYX) (E t t PAST t) C LAUGHxt 3) Before translatAmg the structures in (13) into English l e t me remark on the form of semantic representations.", "labels": [], "entities": [{"text": "BOYX", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9284249544143677}, {"text": "PAST t) C LAUGHxt 3", "start_pos": 41, "end_pos": 60, "type": "METRIC", "confidence": 0.8509717682997385}]}, {"text": "3 3 : A MODIFIED PREDICATE CALCULUS NOTATION $OR Sm A NT I C REPRESENTATIONS Bgch semantic representation consists of a number of mef iaeq-a n d a matrix, where t he prewf ix e s oorrespona roughly to the noun phrased of the sentence, and t he matrix tot he main predicate.", "labels": [], "entities": [{"text": "A MODIFIED PREDICATE CALCULUS NOTATION $OR Sm A NT I C REPRESENTATIONS Bgch", "start_pos": 6, "end_pos": 81, "type": "METRIC", "confidence": 0.7205072492361069}]}, {"text": "For easier reference, I have marked t hi s distinction in the t ex t by always enclosing t he matrix in square bracke%s * cf \".", "labels": [], "entities": []}, {"text": "6 For instance, in (13) there are three prefixes, and t he matrix i& LAUGHVYI.", "labels": [], "entities": [{"text": "LAUGHVYI", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9977667331695557}]}, {"text": "Each prefix consists of a quantifier (e.g., THE, g-which reade \"there is at l ea st onew-or ALL), f o ll ow ed by a variable g &,y,=,&,g-represented by lowercase l e t t er s 6 The lfnear notatLon used throughout here is an abbreviation defined over dependency stru~tures.", "labels": [], "entities": [{"text": "THE", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9852592945098877}]}, {"text": "Ford e ta i l s , see ~ e ~ mo l 4 (forthcoming), where definitions a re a l so given f or tranelating t he m structures into standard predicate ca l cu l u s. in the examples), and optionally followed by a backmounded proposition.", "labels": [], "entities": []}, {"text": "Backgrounded propositions are the expressions to the rl&t oft he colon w it hi n the prefixes.", "labels": [], "entities": []}, {"text": "For instance, the f i r st prefix in (13) contains t he quantifier THE, t he variable &@ and a backgrounded pl?oposition BO'lhc, and thee n ti re prefix is readt \"The entity x such mat x is &.boy.", "labels": [], "entities": [{"text": "THE", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9506568312644958}, {"text": "BO'lhc", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9426197409629822}]}, {"text": "#I We can now translate t he structures 111 (13) in to E n g l i sh.", "labels": [], "entities": []}, {"text": "The f i r st , Le e , t he preliminary S I i , sayst \"%e x such t ha t x. is a boy is invowed in somE vent suoh t ha t there is some y and sometime which is PAST, and.", "labels": [], "entities": [{"text": "PAST", "start_pos": 157, "end_pos": 161, "type": "METRIC", "confidence": 0.9958851933479309}]}, {"text": "y is laughing at time t.\"", "labels": [], "entities": []}, {"text": "Notice t ha t t hi s only asserts that the boy is somehow ,invo&%ed int hi s , but it does not specify j u st h.", "labels": [], "entities": []}, {"text": "B u tin order to describe what the l i gt en er ac t u a ll y understand$ when hearing %he bov la u d ed , we must of course s p e c if y which r o l e the boy plays int hi s event.", "labels": [], "entities": []}, {"text": "Now, looking at the final SH in (13).", "labels": [], "entities": []}, {"text": "it can be seen t ha tit i s l i k e t he PS3, except t ha tit a l so contains a r o l e p s s i me n t (or $ink, as I w i ll caL1 it), namely x=y:.", "labels": [], "entities": []}, {"text": "That is, 5, t he boy, playe t he role of y, who wast he one who d id t he laughing.", "labels": [], "entities": []}, {"text": "By executing t hi s equation x-Y, we can of course simplify the representation, which gives us t he last l in e in (13) The intermediate SR in (13), furthermore, isl i k e t he preliminary SR, but in addition contains certain i mp l i ca ti on s oft he words.", "labels": [], "entities": []}, {"text": "Thus we have: \"the x such t ha t x is a boy and (by implication) human and not ad u l t. e t c.", "labels": [], "entities": []}, {"text": "* And in the matrix of the fSR we get \"y laughs at time t and, by implication, y is hman and animate and alive-at-time-t.* In o t he r words, one cann.ot laugh u n l e s s one i s human and a l iv e Vs THE PSR J CONCUENATION RULES Let us return wain to Fig.2.", "labels": [], "entities": [{"text": "THE PSR J CONCUENATION", "start_pos": 202, "end_pos": 224, "type": "METRIC", "confidence": 0.6558372154831886}, {"text": "RULES", "start_pos": 225, "end_pos": 230, "type": "METRIC", "confidence": 0.5104541778564453}, {"text": "Fig.2", "start_pos": 253, "end_pos": 258, "type": "DATASET", "confidence": 0.983249306678772}]}, {"text": "It shows t hr e ed if f er en tb lo ck s of rules which are responsible for deriving t he three stages of the semantic analysis, namely, Concatenation Rules, Meaning Rules and Encyclopedic Rules (collectively ~ e f erred to as Semantic Knowledge ~ules), and finally Semantic Linking Strategies.", "labels": [], "entities": [{"text": "Semantic Linking Strategies", "start_pos": 266, "end_pos": 293, "type": "TASK", "confidence": 0.8129644791285197}]}, {"text": "They will occupy ue fn this order The Concatenation Rules take the semantic d e f in it i on of the most recent input word and add it to the cu r re n t preliminary semantic structure.", "labels": [], "entities": []}, {"text": "For instance, (14) lists t he semantic definitions (namely-for t he , b6v.and laughed) which are relevant fort he example in (13) ab o v e.", "labels": [], "entities": []}, {"text": "7~ have made the simplifying assumption t ha t there are lower-level components providing the s y n ta ct i c an& semantic components w it ha l ex i ca ll y analyzed input string* Th i s , of course, is almost certainly incorrect, and should be refined by making t he matching procaea pa rt l y top-downi(1n t he case oft he syntax t hi s has been done to a certain extent, since it i s. b a s ed on s predictive analyzer.", "labels": [], "entities": []}, {"text": "It ha s no t ye t been done fort he eemantioel but it seems t ha ti t can be bu it into the present s stem relative1 easj.1 .) See Nash-Webber 1974) f or f u rt he r PP t drscuseion.eepec a ll y h s d e s c r i pt i on of the SPEECHLIS system.", "labels": [], "entities": [{"text": "SPEECHLIS system", "start_pos": 226, "end_pos": 242, "type": "DATASET", "confidence": 0.7419929504394531}]}, {"text": "(14) (a) rt he DDI a (THSV~-) re-1 (b) ~ ~ OS T ~ fl I (E X) E BO Y X I (c) Elaurrhed MVB PAST], (~ ' y) (E tr PAST t) LL A U G ~ ~ ~ 1 Notice t ha teach oft he deftnitions consists again of a prefix and a matrix.", "labels": [], "entities": []}, {"text": "There are t w o Concatenation Rules, namely Jo in in g and Ba ~ km o u n d in q ~ They a re sta-t;ed in abbreviated form in (15) and (~ 6). and are i ll u st r at ed in (17).", "labels": [], "entities": []}, {"text": "(15) Joir.;_?gc Let (x) t M 1 l be the current preliminary SR, and (Y) t M 2 3 the semantic definition oft he la st input woPd (which may pot be art of an NP), where (x) and (Y) a re the prefixes , and ml ' J and tM23 t he matrixes Then form (K)(Y) [ MI & M 2 3 (16) Backeroundin~: Let {QTFV~ (x) (hll)) bet he partial 9 Rf or the cu r re n t NP.", "labels": [], "entities": []}, {"text": "Then j oi n t he semantic d e f in it i on (Y) [P121 oft he last in p ~ ~ t word (if it is pa rt of this NP) as in {PTR~:(x)(Y)(MI Rc M2) I (17) Joinin& and packarwndinq applied to (13-14): St a rt r (THEVI-) t-3 Backgrounding:", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}