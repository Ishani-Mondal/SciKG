{"title": [{"text": "Squibs and Discussions Measuring Word Alignment Quality for Statistical Machine Translation", "labels": [], "entities": [{"text": "Squibs and Discussions Measuring Word Alignment", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7687092423439026}, {"text": "Statistical Machine Translation", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.8310166796048483}]}], "abstractContent": [{"text": "Automatic word alignment plays a critical role in statistical machine translation.", "labels": [], "entities": [{"text": "Automatic word alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5826812485853831}, {"text": "statistical machine translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.7407814959685007}]}, {"text": "Unfortunately , the relationship between alignment quality and statistical machine translation performance has not been well understood.", "labels": [], "entities": [{"text": "alignment", "start_pos": 41, "end_pos": 50, "type": "TASK", "confidence": 0.9503580331802368}, {"text": "statistical machine translation", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.6289737820625305}]}, {"text": "In the recent literature, the alignment task has frequently been decoupled from the translation task and assumptions have been made about measuring alignment quality for machine translation which, it turns out, are not justified.", "labels": [], "entities": [{"text": "translation task", "start_pos": 84, "end_pos": 100, "type": "TASK", "confidence": 0.8904148638248444}, {"text": "machine translation", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7232018560171127}]}, {"text": "In particular, none of the tens of papers published over the last five years has shown that significant decreases in alignment error rate (AER) result in significant increases in translation performance.", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 117, "end_pos": 143, "type": "METRIC", "confidence": 0.9015153249104818}, {"text": "translation", "start_pos": 179, "end_pos": 190, "type": "TASK", "confidence": 0.9585081934928894}]}, {"text": "This paper explains this state of affairs and presents steps towards measuring alignment quality in away which is predictive of statistical machine translation performance.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 128, "end_pos": 159, "type": "TASK", "confidence": 0.6086977024873098}]}], "introductionContent": [{"text": "Automatic word alignment () is a vital component of all statistical machine translation (SMT) approaches.", "labels": [], "entities": [{"text": "Automatic word alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5940479338169098}, {"text": "statistical machine translation (SMT)", "start_pos": 56, "end_pos": 93, "type": "TASK", "confidence": 0.7715319891770681}]}, {"text": "There were a number of research papers presented from 2000 to 2005 at ACL, NAACL, HLT, COLING, WPT03, WPT05, and so forth, outlining techniques for attempting to increase word alignment quality.", "labels": [], "entities": [{"text": "ACL", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.9268209338188171}, {"text": "NAACL", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.9019232988357544}, {"text": "COLING", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.567572832107544}, {"text": "WPT03", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.9222120046615601}, {"text": "WPT05", "start_pos": 102, "end_pos": 107, "type": "DATASET", "confidence": 0.9173238277435303}, {"text": "word alignment quality", "start_pos": 171, "end_pos": 193, "type": "TASK", "confidence": 0.8588256438573202}]}, {"text": "Despite this high level of interest, none of these techniques has been shown to result in a large gain in translation performance as measured by BLEU () or any other metric.", "labels": [], "entities": [{"text": "translation", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.9562256336212158}, {"text": "BLEU", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.9971482157707214}]}, {"text": "We find this lack of correlation between previous word alignment quality metrics and BLEU counterintuitive, because we and other researchers have measured this correlation in the context of building SMT systems that have benefited from using the BLEU metric in improving performance in open evaluations such as the NIST evaluations.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.6729948371648788}, {"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.994942843914032}, {"text": "SMT", "start_pos": 199, "end_pos": 202, "type": "TASK", "confidence": 0.989012598991394}, {"text": "BLEU", "start_pos": 246, "end_pos": 250, "type": "METRIC", "confidence": 0.9538648724555969}, {"text": "NIST evaluations", "start_pos": 315, "end_pos": 331, "type": "DATASET", "confidence": 0.9238366484642029}]}, {"text": "We confirm experimentally that previous metrics do not predict BLEU well and develop a methodology for measuring alignment quality that is predictive of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9937291145324707}, {"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9788076877593994}]}, {"text": "We also show that alignment error rate (AER) is not correctly derived from F-Measure and is therefore unlikely to be useful as a metric.", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 18, "end_pos": 44, "type": "METRIC", "confidence": 0.9103310306866964}, {"text": "F-Measure", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9638513922691345}]}], "datasetContent": [], "tableCaptions": []}