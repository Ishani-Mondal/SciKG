{"title": [{"text": "Dependency-Based Construction of Semantic Space Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Traditionally, vector-based semantic space models use word co-occurrence counts from large corpora to represent lexical meaning.", "labels": [], "entities": []}, {"text": "In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account.", "labels": [], "entities": []}, {"text": "We introduce a formalization for this class of models, which allows linguistic knowledge to guide the construction process.", "labels": [], "entities": []}, {"text": "We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing: semantic priming, synonymy detection, and word sense disambiguation.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.7186728517214457}, {"text": "synonymy detection", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.7834015488624573}, {"text": "word sense disambiguation", "start_pos": 152, "end_pos": 177, "type": "TASK", "confidence": 0.7393134236335754}]}, {"text": "In all cases, our framework obtains results that are comparable or superior to the state of the art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Vector space models of word co-occurrence have proved a useful framework for representing lexical meaning in a variety of natural language processing (NLP) tasks, such as word sense discrimination) and ranking (), text segmentation, contextual spelling correction, automatic thesaurus extraction, and notably, information retrieval (Salton,.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 171, "end_pos": 196, "type": "TASK", "confidence": 0.6689433058102926}, {"text": "text segmentation", "start_pos": 214, "end_pos": 231, "type": "TASK", "confidence": 0.7811624109745026}, {"text": "contextual spelling correction", "start_pos": 233, "end_pos": 263, "type": "TASK", "confidence": 0.6312015652656555}, {"text": "automatic thesaurus extraction", "start_pos": 265, "end_pos": 295, "type": "TASK", "confidence": 0.6251348455746969}, {"text": "information retrieval", "start_pos": 310, "end_pos": 331, "type": "TASK", "confidence": 0.8573269546031952}]}, {"text": "These models have also been popular in cognitive science and figure prominently in several studies simulating human behavior.", "labels": [], "entities": []}, {"text": "Examples include similarity judgments, semantic priming (, and text comprehension.", "labels": [], "entities": [{"text": "similarity judgments", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7779287397861481}]}, {"text": "The popularity of vector-based models in both fields lies in their ability to represent word meaning simply by using distributional statistics.", "labels": [], "entities": []}, {"text": "The central assumption here is that the context surrounding a given word provides important information about its meaning).", "labels": [], "entities": []}, {"text": "The semantic properties of words are captured in a multi-dimensional space by vectors that are constructed from large bodies of text by observing the distributional patterns of co-occurrence with their neighboring words.", "labels": [], "entities": []}, {"text": "Co-occurrence information is typically collected in a frequency matrix, where each row corresponds to a unique word, commonly referred to as \"target word,\" and each column represents a given linguistic context.", "labels": [], "entities": []}, {"text": "The semantic similarity between any two words can then be quantified directly using a distance measure such as cosine or Euclidean distance.", "labels": [], "entities": []}, {"text": "Contexts are defined as a small number of words surrounding the target word ( or as entire paragraphs-even documents.", "labels": [], "entities": []}, {"text": "Latent Semantic Analysis (LSA; is an example of a document-based vector space model that is commonly used in information retrieval and cognitive science.", "labels": [], "entities": [{"text": "Latent Semantic Analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5865340431531271}, {"text": "information retrieval", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7634096741676331}]}, {"text": "Each target word t is represented by a k element vector of paragraphs p 1...k and the value of each vector element is a function of the number of times t occurs in pi . In contrast, the Hyperspace Analogue to Language model (HAL; creates a word-based semantic space: each target word t is represented by a k element vector, whose dimensions correspond to context words c 1...k . The value of each vector element is a function of the number of times each c i occurs within a window of size n before or after tin a large corpus.", "labels": [], "entities": []}, {"text": "In their simplest incarnation, semantic space models treat context as a set of unordered words, without even taking parts of speech into account (e.g., to drink and a drink are represented by a single vector).", "labels": [], "entities": []}, {"text": "In fact, with the exception of function words (e.g., the, down), which are often removed, it is often assumed that all context words within a certain distance from the target word are semantically relevant.", "labels": [], "entities": []}, {"text": "Because no linguistic knowledge is taken into account, the construction of semantic space models is straightforward and language-independent-all that is needed is a segmented corpus of written or spoken text.", "labels": [], "entities": []}, {"text": "However, the assumption that contextual information contributes indiscriminately to a word's meaning is clearly a simplification.", "labels": [], "entities": []}, {"text": "There is ample evidence demonstrating that syntactic relations across and within sentences are crucial for sentence and discourse processing and modulate cognitive behavior in sentence priming tasks.", "labels": [], "entities": [{"text": "sentence and discourse processing", "start_pos": 107, "end_pos": 140, "type": "TASK", "confidence": 0.6362966150045395}]}, {"text": "Furthermore, much research in lexical semantics hypothesizes that the behavior of words, particularly with respect to the expression and interpretation of their arguments, is to a large extent determined by their meaning.", "labels": [], "entities": []}, {"text": "It is therefore not surprising that there have been efforts to enrich vector-based models with morpho-syntactic information.", "labels": [], "entities": []}, {"text": "Extensions range from part of speech tagging) to shallow syntactic analysis and full-blown parsing).", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.710980623960495}, {"text": "shallow syntactic analysis", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.6367988884449005}]}, {"text": "In these semantic space models, contexts are defined over words bearing a syntactic relationship to the target words of interest.", "labels": [], "entities": []}, {"text": "This makes semantic spaces more flexible; different types of contexts can be selected; words do not have to co-occur within a small, fixed word window; and word order or argument structure differences can be naturally mirrored in the semantic space.", "labels": [], "entities": []}, {"text": "This article proposes a general framework for semantic space models which conceptualizes context in terms of syntactic relations.", "labels": [], "entities": []}, {"text": "We introduce an algorithm for constructing semantic space models from texts annotated with syntactic information (specifically dependency relations) and illustrate how different model classes can be derived from this linguistically rich representation.", "labels": [], "entities": []}, {"text": "Our guiding hypothesis is that syntactic structure in general and argument structure in particular is a close reflection of lexical meaning).", "labels": [], "entities": []}, {"text": "We thus model meaning by quantifying the degree to which words are attested in similar syntactic environments.", "labels": [], "entities": []}, {"text": "The expressive power of our framework stems from three novel parameters which guide model construction.", "labels": [], "entities": []}, {"text": "The first parameter determines which types of syntactic structures contribute towards the representation of lexical meaning.", "labels": [], "entities": [{"text": "representation of lexical meaning", "start_pos": 90, "end_pos": 123, "type": "TASK", "confidence": 0.7864598631858826}]}, {"text": "The second parameter allows us to weigh the relative importance of different syntactic relations.", "labels": [], "entities": []}, {"text": "Finally, the third parameter determines how the semantic space is actually represented, for instance as co-occurrences of words with other words, words with parts of speech, or words with argument relations (e.g., subject, object).", "labels": [], "entities": []}, {"text": "We evaluate our framework on tasks relevant for cognitive science and NLP.", "labels": [], "entities": []}, {"text": "We start by simulating semantic priming, a phenomenon that has received much attention in computational psycholinguistics and is typically modeled using word-based semantic spaces.", "labels": [], "entities": []}, {"text": "We next consider the problem of recognizing synonyms by selecting an appropriate synonym fora target word from a set of semantically related candidate words.", "labels": [], "entities": [{"text": "recognizing synonyms", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8319634199142456}]}, {"text": "Specifically, we evaluate the performance of our model on synonym questions from the Test of English as a Foreign Language (TOEFL).", "labels": [], "entities": []}, {"text": "These are routinely used as a testbed for assessing how well vector-based models capture lexical knowledge).", "labels": [], "entities": []}, {"text": "Our final experiment concentrates on unsupervised word sense disambiguation (WSD), thereby exploring the potential of the proposed framework for NLP applications requiring large scale semantic processing.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.7580220500628153}]}, {"text": "We automatically infer predominant senses in untagged text by incorporating our syntax-based semantic spaces into the modeling paradigm proposed by.", "labels": [], "entities": []}, {"text": "In all cases, we show that our framework consistently outperforms word-based models yielding results that are comparable or superior to state of the art.", "labels": [], "entities": []}, {"text": "Our contributions are threefold: a novel framework for semantic spaces that incorporates syntactic information in the form of dependency relations and generalizes previous syntax-based vector-based models; an application of this framework to a wide range of tasks relevant to cognitive modeling and NLP; and an empirical comparison of our dependency-based models against state-of-the-art word-based models.", "labels": [], "entities": []}, {"text": "In Section 2, we give a brief overview of existing word-based and syntax-based models.", "labels": [], "entities": []}, {"text": "In Section 3, we present our modeling framework and relate it to previous work.", "labels": [], "entities": []}, {"text": "Section 4 discusses the parameter settings for our experiments.", "labels": [], "entities": []}, {"text": "Section 5 details our priming experiment, Section 6 presents our study on the TOEFL synonymy task, and Section 7 describes our sense-ranking experiment.", "labels": [], "entities": [{"text": "TOEFL synonymy task", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.5898816287517548}]}, {"text": "Discussion of our results and future work concludes the article (Section 8).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the corpus and parser chosen for our experiments.", "labels": [], "entities": []}, {"text": "We also discuss our parameter and model choice procedure, and introduce the baseline wordbased model which we use for comparison with our approach.", "labels": [], "entities": []}, {"text": "Our experiments are then presented in Sections 5-7.", "labels": [], "entities": []}, {"text": "A large number of modeling studies in psycholinguistics have focused on simulating semantic priming phenomena).", "labels": [], "entities": []}, {"text": "The semantic priming paradigm provides a natural test bed for semantic space models, as it concentrates on the semantic similarity or dissimilarity between words, and it is precisely this type of lexical relation that vector-based models should capture.", "labels": [], "entities": []}, {"text": "If dependency-based models indeed represent more linguistic knowledge, they should be able to model semantic priming better than traditional word-based models.", "labels": [], "entities": []}, {"text": "In this experiment, we focus on Hodgson's (1991) single-word lexical priming study.", "labels": [], "entities": [{"text": "Hodgson's (1991) single-word lexical priming", "start_pos": 32, "end_pos": 76, "type": "TASK", "confidence": 0.5110835023224354}]}, {"text": "In single-word semantic priming, the transient presentation of a prime word like tiger directly facilitates pronunciation or lexical decision on a target word like lion: responses are usually faster and more accurate when the prime is semantically related to the target than when it is unrelated.", "labels": [], "entities": [{"text": "single-word semantic priming", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.7127514878908793}]}, {"text": "Hodgson set out to investigate which types of lexical relations induce priming.", "labels": [], "entities": []}, {"text": "He collected a set of 144 word pairs exemplifying six different lexical relations: (a) synonymy (words with the same meaning, e.g., value and worth); (b) superordination and subordination (one word is an instance of the kind expressed by the other word, e.g., pain and sensation); (c) category coordination (words which express two instances of a common superordinate concept, e.g., truck and train); (d) antonymy (words with opposite meaning, e.g., friend and enemy); (e) conceptual association (the first word subjects produce in free association given the other word, e.g., leash and dog); and (f) phrasal association (words which co-occur in phrases, e.g., private and property).", "labels": [], "entities": []}, {"text": "The pairs covered the most prevalent parts of speech (adjectives, verbs, and nouns); they were selected to be unambiguous examples of the relation type they instantiate and were matched for frequency.", "labels": [], "entities": [{"text": "frequency", "start_pos": 190, "end_pos": 199, "type": "METRIC", "confidence": 0.9671439528465271}]}, {"text": "Hogdson found equivalent priming effects (i.e., reduced reading times) for all six types of lexical relation, indicating that priming was not restricted to particular types of prime-target relation.", "labels": [], "entities": []}, {"text": "The priming effects reported in Hodgson (1991) have recently been modeled by, using an incremental vector-based model of contextual facilitation.", "labels": [], "entities": []}, {"text": "Their ICE model (short for Incremental Construction of Semantic Expectations) simulates the difference in effort between processing a target word preceded by a related prime and processing the same target preceded by an unrelated prime.", "labels": [], "entities": [{"text": "Incremental Construction of Semantic Expectations", "start_pos": 27, "end_pos": 76, "type": "TASK", "confidence": 0.8166000366210937}]}, {"text": "This is achieved by quantifying the ability of the distributional characteristics of the prime word to predict the distributional properties of the target.", "labels": [], "entities": []}, {"text": "The prime word is represented by a vector of probabilities which reflects the likely location in semantic space of the upcoming word.", "labels": [], "entities": []}, {"text": "When the target word is observed, the representation is updated using a Bayesian inference mechanism to reflect the newly arrived information.", "labels": [], "entities": []}, {"text": "McDonald and Brew use a traditional semantic space that takes only word co-occurrences into account and is defined over the 500 most frequent words of the spoken portion of the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 177, "end_pos": 180, "type": "DATASET", "confidence": 0.8749657273292542}]}, {"text": "They measure distance in semantic space using relative entropy (also known as Kullback-Leibler divergence) and successfully model the data by predicting that the distance should be lower for related prime-target pairs than for unrelated prime-target pairs.", "labels": [], "entities": []}, {"text": "The Test of English as a Foreign Language (TOEFL) is commonly used as a benchmark for comparing the merits of different similarity models.", "labels": [], "entities": []}, {"text": "The testis designed to assess non-native speakers' knowledge of English.", "labels": [], "entities": []}, {"text": "It consists of multiple-choice questions, each involving a target word embedded in a sentence and four potential synonyms.", "labels": [], "entities": []}, {"text": "The task is to identify the real synonym.", "labels": [], "entities": []}, {"text": "An example is shown below where crossroads is the real synonym for intersection.", "labels": [], "entities": []}, {"text": "You will find the office at the main intersection.", "labels": [], "entities": []}, {"text": "(a) place (b) crossroads (c) roundabout (d) building were the first to propose the TOEFL items as a test for lexical semantic similarity.", "labels": [], "entities": [{"text": "TOEFL items", "start_pos": 83, "end_pos": 94, "type": "DATASET", "confidence": 0.7042809426784515}]}, {"text": "Their LSA model achieved an accuracy of 64.4% on 80 items, a performance comparable to the average score attained by non-native speakers taking the test.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9992753863334656}]}, {"text": "uses Random Indexing, a method comparable to LSA, to represent the meaning of words and reports a 75.0% accuracy on the same TOEFL items.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9979692101478577}, {"text": "TOEFL items", "start_pos": 125, "end_pos": 136, "type": "DATASET", "confidence": 0.7778657078742981}]}, {"text": "It should be noted that both Landauer and Dumais and Sahlgren report results on seen data, that is, parameters are optimized on the entire data set until performance has peaked.", "labels": [], "entities": []}, {"text": "Rather than assuming that similar words tend to occur in similar contexts, Turney (2001) and propose models that capitalize on the collocational nature of semantically related words.", "labels": [], "entities": []}, {"text": "Two words are considered similar if they tend to occur near each other.", "labels": [], "entities": []}, {"text": "Turney uses pointwise mutual information (PMI) to measure the similarity between a target word and each of its candidate synonyms.", "labels": [], "entities": []}, {"text": "Co-occurrence frequencies are retrieved from the Web using an information retrieval (IR) engine: where P(w 1 , w2) is estimated by the number of hits (i.e., number of documents) returned by the IR engine (Turney used AltaVista) when submitting a query with the NEAR operator.", "labels": [], "entities": []}, {"text": "The PMI-IR model obtained an accuracy of 72.5% on the TOEFL data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9995898604393005}, {"text": "TOEFL data set", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.9594075679779053}]}, {"text": "proposes a modification to Equation: He dispenses with the NEAR operator by concentrating on word pairs that are strictly adjacent: Similarity LC\u2212IR (w 1 , w 2 ) = min(hits(w 1 , w 2 ), hits(w 2 , w 1 )) hits(w 1 )hits(w 2 ) Note that Equation (16) takes the minimum number of hits for the two possible orders w1, w 2 and w 2 , w 1 in an attempt to rule out the effects of collocations and part-of-speech ambiguities.", "labels": [], "entities": [{"text": "NEAR", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.6852709650993347}, {"text": "Similarity LC\u2212IR", "start_pos": 132, "end_pos": 148, "type": "METRIC", "confidence": 0.7715782672166824}]}, {"text": "The LC-IR (local-context information retrieval) model outperformed PMI-IR, achieving an accuracy of 81.3% on the TOEFL items.", "labels": [], "entities": [{"text": "local-context information retrieval)", "start_pos": 11, "end_pos": 47, "type": "TASK", "confidence": 0.689470686018467}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9992191791534424}, {"text": "TOEFL items", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.8900743424892426}]}, {"text": "The ability to identify the intended reading of a polysemous word (the word sense) in context is crucial for accomplishing many NLP tasks.", "labels": [], "entities": [{"text": "identify the intended reading of a polysemous word (the word sense) in context", "start_pos": 15, "end_pos": 93, "type": "TASK", "confidence": 0.7805205702781677}]}, {"text": "Examples include lexicon acquisition, discourse parsing, or metonymy resolution.", "labels": [], "entities": [{"text": "lexicon acquisition", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7412788569927216}, {"text": "discourse parsing", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.731656402349472}, {"text": "metonymy resolution", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7778534293174744}]}, {"text": "Applications such as question answering or machine translation could also benefit from large scale word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "question answering", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8957392871379852}, {"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.746144562959671}, {"text": "word sense disambiguation (WSD)", "start_pos": 99, "end_pos": 130, "type": "TASK", "confidence": 0.7713805635770162}]}, {"text": "Given the importance of WSD for basic NLP tasks and multilingual applications, a variety of approaches have been proposed for disambiguating word senses.", "labels": [], "entities": []}, {"text": "To date, most accurate WSD systems are supervised and rely on the availability of training data (see,, and the references therein).", "labels": [], "entities": [{"text": "WSD", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9739026427268982}]}, {"text": "Although supervised methods typically achieve better performance than their unsupervised alternatives, their applicability is limited to those words for which senselabeled data exists, and their accuracy is strongly correlated with the amount of labeled data available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9980302453041077}]}, {"text": "Furthermore, if the distribution of senses is skewed, as is often the case, the simple heuristic of choosing the most common or predominant sense in the training data (henceforth \"the first sense heuristic\") delivers results competitive with supervised approaches based on local context (.", "labels": [], "entities": []}, {"text": "Obtaining the first sense heuristic via annotation is obviously costly and time consuming.", "labels": [], "entities": []}, {"text": "More importantly, one would expect that a word's first sense varies across domains and text genres (the word court in legal documents will most likely mean \"tribunal\" rather than \"yard\").", "labels": [], "entities": []}, {"text": "Therefore, manual annotation must be redone for most new languages, domains, and sense inventories.", "labels": [], "entities": []}, {"text": "show that the annotation bottleneck can be avoided by inferring the first sense heuristic automatically from raw text.", "labels": [], "entities": []}, {"text": "They argue that, even though the first sense heuristic is not a WSD method in itself, it can be usefully combined with context-based disambiguation methods in order to alleviate the data requirements for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 204, "end_pos": 207, "type": "TASK", "confidence": 0.736911416053772}]}, {"text": "Their method builds on the observation that a word's distributionally similar neighbors often provide cues about its senses.", "labels": [], "entities": []}, {"text": "In their model, sense ranking is equivalent to quantifying the degree of similarity between each neighbor and each sense description of a polysemous word.", "labels": [], "entities": []}, {"text": "The sense most similar to the neighbors is the first sense.", "labels": [], "entities": []}, {"text": "approach crucially relies on the quality of the set of neighbors to acquire more or less accurate first senses.", "labels": [], "entities": []}, {"text": "In this experiment, we examine whether the dependency-based models discussed in this article can be used for the sense ranking task, thereby assessing their potential for practical NLP tasks.", "labels": [], "entities": [{"text": "sense ranking task", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7916330099105835}]}, {"text": "The aims of our experiment are twofold: (1) to investigate whether our dependency-based framework can be used to acquire distributionally similar words that differ in quality from those obtained with word-based models and (2) to observe their impact on WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 253, "end_pos": 256, "type": "TASK", "confidence": 0.8722312450408936}]}, {"text": "We first describe McCarthy et al.'s sense-ranking model, which forms the basis of our experiments, and then detail our methodology and results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Correlations (Pearson's r) between elicited similarity and dependency models using the cosine  distance, 2,000 basis elements, and the log-likelihood association function.", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.6678993304570516}]}, {"text": " Table 3  Correlations (Pearson's r) between elicited similarity and dependency models using Lin's  (1998a) similarity measure, 2,000 basis elements and the log-likelihood association function.", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.5853414336840311}]}, {"text": " Table 4  Mean distance values for Related and Unrelated prime-target pairs; Prime Effect size  (= Related \u2212 Unrelated) for the dependency model and ICE.", "labels": [], "entities": [{"text": "Mean distance", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9331161379814148}, {"text": "Prime Effect size", "start_pos": 77, "end_pos": 94, "type": "METRIC", "confidence": 0.8366809686024984}, {"text": "ICE", "start_pos": 149, "end_pos": 152, "type": "DATASET", "confidence": 0.474017858505249}]}, {"text": " Table 6  Results on sense ranking and WSD tasks, using 50 neighbors and the Jiang and Conrath (1995)  distance measure.", "labels": [], "entities": [{"text": "sense ranking", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.7511630654335022}, {"text": "WSD tasks", "start_pos": 39, "end_pos": 48, "type": "TASK", "confidence": 0.9135795831680298}]}, {"text": " Table 7  Sense ranking and WSD accuracy for the dependency-based model as word frequency and  average sense ambiguity are varied.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9043610692024231}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7791082859039307}]}]}