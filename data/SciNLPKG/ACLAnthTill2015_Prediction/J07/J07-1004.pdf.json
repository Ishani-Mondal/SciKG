{"title": [{"text": "Special Section on Restricted-Domain Question Answering Question Answering in Restricted Domains: An Overview", "labels": [], "entities": [{"text": "Question Answering Question Answering in Restricted Domains", "start_pos": 37, "end_pos": 96, "type": "TASK", "confidence": 0.8267243887696948}]}], "abstractContent": [{"text": "Automated question answering has been a topic of research and development since the earliest AI applications.", "labels": [], "entities": [{"text": "Automated question answering", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.781762937704722}]}, {"text": "Computing power has increased since the first such systems were developed, and the general methodology has changed from the use of hand-encoded knowledge bases about simple domains to the use of text collections as the main knowledge source over more complex domains.", "labels": [], "entities": []}, {"text": "Still, many research issues remain.", "labels": [], "entities": []}, {"text": "The focus of this article is on the use of restricted domains for automated question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.73287533223629}]}, {"text": "The article contains a historical perspective on question answering over restricted domains and an overview of the current methods and applications used in restricted domains.", "labels": [], "entities": [{"text": "question answering", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8571227490901947}]}, {"text": "A main characteristic of question answering in restricted domains is the integration of domain-specific information that is either developed for question answering or that has been developed for other purposes.", "labels": [], "entities": [{"text": "question answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.8882330358028412}, {"text": "question answering", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.848952442407608}]}, {"text": "We explore the main methods developed to leverage this domain-specific information.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has been an interest in representing knowledge and automatically processing it from the time of the first generation of computers.", "labels": [], "entities": []}, {"text": "This interest has increased from the end of the 1980s to become an urgent necessity.", "labels": [], "entities": []}, {"text": "Decisive factors in this increase of interest are an unprecedented growth in the amount of digital information available, an explosion of growth in the use of computers for communications, and the increasing number of users that have access to all this information.", "labels": [], "entities": []}, {"text": "These circumstances have fostered research into information systems that can facilitate the localization, retrieval, and manipulation of these enormous quantities of data.", "labels": [], "entities": []}, {"text": "Question Answering (QA) is one of these research fields.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9142445206642151}]}, {"text": "In this article, QA is defined as the task whereby an automated machine (such as a computer) answers arbitrary questions formulated in natural language.", "labels": [], "entities": []}, {"text": "QA systems are especially useful in situations in which a user needs to know a very specific piece of information and does not have the time-or just does not want-to read all the available documentation related to the search topic in order to solve the problem at hand.", "labels": [], "entities": []}, {"text": "Research in QA has been developed from two different scientific perspectives, artificial intelligence (AI) and information retrieval (IR).", "labels": [], "entities": [{"text": "QA", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.9487358927726746}, {"text": "information retrieval (IR)", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.8508048534393311}]}, {"text": "Work in QA since the early stages of AI has led to systems that respond to questions using the knowledge encoded in databases as an information source.", "labels": [], "entities": []}, {"text": "Obviously, these systems can only provide answers concerning the information previously encoded in the database.", "labels": [], "entities": []}, {"text": "The benefit of this approach is that having a conceptual model of the application domain represented in the database structure allows the use of advanced techniques such as theorem proving and deep reasoning in order to address complex information needs.", "labels": [], "entities": [{"text": "theorem proving", "start_pos": 173, "end_pos": 188, "type": "TASK", "confidence": 0.8835934400558472}]}, {"text": "Currently we are witnessing a surge of activity in the area from the perspective of IR, initiated by the Question Answering track of TREC 1 in 1999.", "labels": [], "entities": [{"text": "IR", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.8774056434631348}, {"text": "Question Answering", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7254523932933807}, {"text": "TREC 1 in 1999", "start_pos": 133, "end_pos": 147, "type": "DATASET", "confidence": 0.8023525923490524}]}, {"text": "Since then, increasingly powerful systems have participated in TREC and other evaluation fora such as CLEF 2 () and NTCIR 3).", "labels": [], "entities": [{"text": "TREC", "start_pos": 63, "end_pos": 67, "type": "TASK", "confidence": 0.5590777397155762}, {"text": "NTCIR", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.7159585356712341}]}, {"text": "From this perspective, question answering focuses on finding text excerpts that contain the answer within large collections of documents.", "labels": [], "entities": [{"text": "question answering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9200074970722198}]}, {"text": "The tasks set in these conferences have molded a specific kind of question answering that is easy to evaluate and that focuses on the use of fast and shallow methods that are generally independent of the application domain.", "labels": [], "entities": [{"text": "question answering", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8013311624526978}]}, {"text": "In other words, current research focuses on text-based, open-domain question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7068375945091248}]}, {"text": "Both trends have developed in parallel and represent the opposite ends of a spectrum connecting what we might label as structured knowledge-based and free textbased question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.6951715797185898}]}, {"text": "Whereas structured knowledge-based QA systems are well adapted to applications managing complex queries in a very structured information environment, the kind of research developed in TREC, CLEF, and NTCIR is probably better suited to broad-purpose generic applications dealing with simple factual questions such as World Wide Web-based question answering.", "labels": [], "entities": [{"text": "NTCIR", "start_pos": 200, "end_pos": 205, "type": "DATASET", "confidence": 0.8638039231300354}, {"text": "World Wide Web-based question answering", "start_pos": 316, "end_pos": 355, "type": "TASK", "confidence": 0.5685353338718414}]}, {"text": "However, both approaches have serious disadvantages when they attempt to tackle important real applications that handle complex questions by combining domainspecific information typically expressed in different sources (structured, semistructured, unstructured, etc.) using reasoning techniques.", "labels": [], "entities": []}, {"text": "Examples of such applications are: Interfaces to machine-readable technical manuals: Many software applications are very complex and they are accompanied by extensive documentation.", "labels": [], "entities": []}, {"text": "A QA system that finds specific answers to a user's question based on such documentation would be very useful.", "labels": [], "entities": []}, {"text": "Front-ends to knowledge sources: Many disciplines and areas of human activity have their own specific knowledge sources.", "labels": [], "entities": []}, {"text": "An example is the medical domain, which, as we shall see in this article, contains a wealth of technical information and resources that can be used fora QA system targeting this kind of information.", "labels": [], "entities": []}, {"text": "Help desk systems in large organizations: Help desk staff in large organizations need to quickly satisfy the customer's need for information.", "labels": [], "entities": []}, {"text": "Although many such requests for information will be found in FAQs available to the help desk staff, there will always be requests that are unique and that require staff to have access to fast methods to find the relevant information.", "labels": [], "entities": []}, {"text": "End systems tailored to such staff (who can be trained) are different from QA systems designed for the end user, but they still need to leverage the organization domain.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}