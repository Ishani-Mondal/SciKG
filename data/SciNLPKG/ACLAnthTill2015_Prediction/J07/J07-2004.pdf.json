{"title": [{"text": "Generating Referring Expressions: Making Referents Easy to Identify", "labels": [], "entities": [{"text": "Generating Referring Expressions", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8361420631408691}]}], "abstractContent": [{"text": "It is often desirable that referring expressions be chosen in such away that their referents are easy to identify.", "labels": [], "entities": []}, {"text": "This article focuses on referring expressions in hierarchically structured domains, exploring the hypothesis that referring expressions can be improved by including logically redundant information in them if this leads to a significant reduction in the amount of search that is needed to identify the referent.", "labels": [], "entities": []}, {"text": "Generation algorithms are presented that implement this idea by including logically redundant information into the generated expression, in certain well-circumscribed situations.", "labels": [], "entities": []}, {"text": "To test our hypotheses, and to assess the performance of our algorithms, two controlled experiments with human subjects were conducted.", "labels": [], "entities": []}, {"text": "The first experiment confirms that human judges have a preference for logically redundant expressions in the cases where our model predicts this to be the case.", "labels": [], "entities": []}, {"text": "The second experiment suggests that readers benefit from the kind of logical redundancy that our algorithms produce, as measured in terms of the effort needed to identify the referent of the expression.", "labels": [], "entities": []}], "introductionContent": [{"text": "Common sense suggests that speakers and writers who want to get their message across should make their utterances easy to understand.", "labels": [], "entities": []}, {"text": "Broadly speaking, this view is confirmed by empirical research).", "labels": [], "entities": []}, {"text": "The present article will examine its consequences for the generation of referring expressions (GRE).", "labels": [], "entities": [{"text": "generation of referring expressions (GRE)", "start_pos": 58, "end_pos": 99, "type": "TASK", "confidence": 0.6597623314176287}]}, {"text": "In doing this, we distinguish between two aspects of the \"understanding\" of a referring expression, which we shall denote by the terms interpretation and resolution.", "labels": [], "entities": [{"text": "interpretation and resolution", "start_pos": 135, "end_pos": 164, "type": "TASK", "confidence": 0.6793058117230734}]}, {"text": "We take interpretation to be the process whereby a hearer/reader determines the meaning or logical form of the referring expression; we take resolution to be the identification of the referent of the expression once its meaning has been determined.", "labels": [], "entities": []}, {"text": "It is resolution that will take center stage in our investigation.", "labels": [], "entities": []}, {"text": "Difficulty of resolution and interpretation do not always go hand in hand.", "labels": [], "entities": [{"text": "resolution", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.8983970284461975}, {"text": "interpretation", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.7826741933822632}]}, {"text": "Consider sentences (1a)-(1c), uttered somewhere in Brighton but not on Lewes Road.", "labels": [], "entities": [{"text": "Lewes Road", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.9764930307865143}]}, {"text": "The description in (1a) is longer (and might take more time to read and interpret) than (1b), but the additional material in (1a) makes resolution easier once interpretation is successfully completed.", "labels": [], "entities": []}, {"text": "The first two of these descriptions refer uniquely.", "labels": [], "entities": []}, {"text": "As for the third: Lewes Road is along street.", "labels": [], "entities": [{"text": "Lewes Road", "start_pos": 18, "end_pos": 28, "type": "DATASET", "confidence": 0.972561240196228}]}, {"text": "Supposing that other streets in Brighton do not have numbers above 900, then even (1c) is a unique description-but a pretty useless one, because it does not help you to find the house unless your knowledge of Brighton is exceptional.", "labels": [], "entities": [{"text": "even (1c)", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9571077227592468}]}, {"text": "We will explore how a natural-language-generation (NLG) program should make use of logically redundant properties so as to simplify resolution (i.e., the identification of the referent).", "labels": [], "entities": []}, {"text": "When we write about identifying or \"finding\" the referent of a referring expression, we mean this in the sense of determining which object is the intended referent.", "labels": [], "entities": []}, {"text": "This conceptual goal mayor may not require the hearer to make a physical effort, for example by turning the pages of a book, or more dramatically by walking and waiting for traffic lights.", "labels": [], "entities": []}, {"text": "The fact that referring expressions tend to contain logically redundant information has been observed in many empirical studies., for example, mentions the need for redundancy in situations of \"degraded communication\" (e.g., background noise); and even in normal situations, redundant nondiscriminating information can help the addressee identify the referent).", "labels": [], "entities": []}, {"text": "In Levelt's words, psycholinguistic experiments show thatisteners apparently create a 'gestalt' of the object for which they have to search.", "labels": [], "entities": []}, {"text": "It is harder to search for 'something red' than for 'a big red bird', even if the color would be sufficiently discriminating.", "labels": [], "entities": []}, {"text": "Information about the kind of object to be looked for (e.g., a bird) is especially helpful for constructing such a gestalt.", "labels": [], "entities": []}, {"text": "Although early GRE algorithms have often followed the Gricean maxim, \"be brief\", by minimizing the number of properties in a generated description, proposed an algorithm that allows certain redundancies, for example, by guaranteeing that each generated description expresses the ontological \"type\" of the referent, in the form of a noun, a move that addresses Levelt's claim to some extent.", "labels": [], "entities": []}, {"text": "In corpus-based studies, it has been shown that logically redundant properties tend to be included when their inclusion fulfils one of a number of pragmatic functions, such as to indicate that a property is of particular importance to the speaker (i.e., it constitutes one of her reasons for being interested in the referent) or to highlight the speaker's awareness that the referent has the property in question).", "labels": [], "entities": []}, {"text": "Implementations of such findings in NLG are not difficult to envisage.", "labels": [], "entities": []}, {"text": "The present article takes this reader-oriented perspective on the redundancy of referring expressions a step further, by asking how a generator can use logically redundant information to reduce the search space within which a reader has to \"find\" a referent; this will be specifically useful when referents need to be found in situations where the extensions of some of the properties are not known to the reader/hearer in advance (cf., fora related set of problems) and where some effort maybe needed to identify the referent.", "labels": [], "entities": []}, {"text": "By focusing on the information needs of the hearer/reader, our work, a further development of that also takes the results of into account, addresses an issue that lies close to the heart of NLG as a practical enterprise, whose purpose is, after all, to make information accessible to people.", "labels": [], "entities": []}, {"text": "These issues originally came to the fore while studying references to parts of documents () but their relevance extends to many other situations.", "labels": [], "entities": []}, {"text": "Our findings will also shed light on the egocentricity debate among psycholinguists about the extent to which speakers take hearer's knowledge into account when they speak.", "labels": [], "entities": []}, {"text": "Throughout the article, we shall focus on issues of Content Determination (as opposed to, for example Lexical Choice), and on the situations in which individuals are first mentioned (as opposed to ones in which linguistic context allows them to be shortened [e.g.,).", "labels": [], "entities": [{"text": "Content Determination", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.6895555704832077}, {"text": "Lexical Choice)", "start_pos": 102, "end_pos": 117, "type": "TASK", "confidence": 0.9296691219011942}]}], "datasetContent": [{"text": "In this section we start putting the intuition that LO and DE are better avoided to the test.", "labels": [], "entities": [{"text": "LO", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9946953654289246}, {"text": "DE", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9919752478599548}]}, {"text": "We report on a small experiment with human subjects, which involved a document structured in sections and subsections as an example of a hierarchically ordered domain.", "labels": [], "entities": []}, {"text": "We chose this domain because, unlike most other domains, it allows us to show subjects the domain itself (i.e., areal document), rather than, for example, a pictorial representation of it.", "labels": [], "entities": []}, {"text": "More specifically, we investigated the choice of so-called document-deictic references, such as the picture in part x of section y (Paraboni 2003), to check whether they avoid potential DE and LO situations by adding logically redundant properties (favoring ease of resolution) and, conversely, whether they choose shorter descriptions when there is no such risk (favoring ease of interpretation).", "labels": [], "entities": []}, {"text": "Forty-two students on a first-year Computing Science course participated in the experiment as part of a scheduled practical.", "labels": [], "entities": []}, {"text": "A within-subjects design was used.", "labels": [], "entities": []}, {"text": "All subjects were shown 20 on-line documents.", "labels": [], "entities": []}, {"text": "The order of the documents was randomized per subject, to control for order effects.", "labels": [], "entities": []}, {"text": "The document structure was always visible, and so was the content of the current document part.", "labels": [], "entities": []}, {"text": "A screenshot of an example document providing this level of information is shown in.", "labels": [], "entities": []}, {"text": "Each document was initially opened in Part B of either Section 2 or 3, where a task was given of the form \"Let's talk about.", "labels": [], "entities": []}, {"text": "Please click on [referring expression];\" for instance: Let's talk about elephants.", "labels": [], "entities": []}, {"text": "Please click on picture 5 in part A.", "labels": [], "entities": []}, {"text": "Subjects could navigate through the document by clicking on the names of the parts (e.g. Part A as visible under Section 3).", "labels": [], "entities": []}, {"text": "As soon as the subject had correctly clicked on the picture indicated, the next document was presented.", "labels": [], "entities": []}, {"text": "Subjects were reminded throughout the document about the task to be accomplished, and the location at which the task was given.", "labels": [], "entities": []}, {"text": "All navigation actions were recorded.", "labels": [], "entities": [{"text": "navigation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9675565361976624}]}, {"text": "At the start of the experiment, subjects were instructed to try to accomplish the task with a minimal number of navigation actions.", "labels": [], "entities": []}, {"text": "We assume that readers do not have complete knowledge of the domain.", "labels": [], "entities": []}, {"text": "So, they do not know which pictures are present in each part of each section.", "labels": [], "entities": []}, {"text": "If readers had complete knowledge, then a minimal description would suffice: For example, if readers knew that there is only one picture 5 in the document, located in part B of section 3, then the description picture 5 would probably be completely clear.", "labels": [], "entities": []}, {"text": "We do not, however, assume readers to be completely ignorant, either.", "labels": [], "entities": []}, {"text": "We assume that they have some knowledge of the domain, particularly of its hierarchical structure.", "labels": [], "entities": []}, {"text": "This brings us to the question of how much knowledge we should assume our readers to have.", "labels": [], "entities": []}, {"text": "In practice (unlike Section 3.1, where the hearer was pictured as blindfolded until the description is uttered) readers will always have some knowledge: If in Part B of Section 2, then they would know (by convention) that there will also be a Section 1, and a Part A in Section 2, and soon.", "labels": [], "entities": []}, {"text": "It is also likely that being in Part B of Section 2 and seeing pictures 1, 2, 3, readers will infer that sections can have parts, that parts can contain pictures, and that pictures are numbered (though not necessarily per part).", "labels": [], "entities": []}, {"text": "Because of these kinds of consideration, it seems appropriate to give our readers knowledge about the entire document structure (the 5 sections and their parts) and the content (i.e., the existing pictures) in the current document part (but crucially, no knowledge about pictures elsewhere in the document, which require navigation to be discovered).", "labels": [], "entities": []}, {"text": "A navigation structure like the one in provides this knowledge to the readers.", "labels": [], "entities": []}, {"text": "We want to test whether longer descriptions indeed help resolution, particularly in so-called problematic situations.", "labels": [], "entities": [{"text": "resolution", "start_pos": 56, "end_pos": 66, "type": "TASK", "confidence": 0.9792141914367676}]}, {"text": "shows the types of situation (potential DE, LO, and non-problematic), 12 reader and referent location, and descriptions used.", "labels": [], "entities": [{"text": "DE", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9200358390808105}, {"text": "LO", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.7804476022720337}]}, {"text": "This hypothesis is similar to hypotheses 1.1 and 1.2 of the previous experiment.", "labels": [], "entities": []}, {"text": "We will use the DE and LO situations in to test this hypothesis, comparing for each situation the number of navigation actions of the short, that is, minimally distinguishing (MD) and long (FI/SL) expressions.", "labels": [], "entities": [{"text": "DE", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9497648477554321}, {"text": "LO", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.7220982313156128}]}, {"text": "In the previous experiment, we had an additional hypothesis about nonproblematic situations, stating that MD descriptions would be preferred to long descriptions in non-problematic situations.", "labels": [], "entities": []}, {"text": "This is not a natural hypothesis in the new experiment, because it might not happen very often that a shorter description will lead to fewer navigation actions (pace Cremers 1996).", "labels": [], "entities": []}, {"text": "(Note that in the previous experiment we looked at the combination of interpretation and resolution, whereas we are now focusing on resolution only).", "labels": [], "entities": [{"text": "resolution", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9841782450675964}, {"text": "resolution", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.9737563133239746}]}, {"text": "Instead, we will look at gain: the number of navigation actions required fora short description minus the number of navigation actions required fora long description.", "labels": [], "entities": []}, {"text": "For situation s, short description sd of s, and long description ld of s, Gain(s, sd, ld) = the number of navigation actions required in s for description sd minus the number of navigation actions required in s for description ld.", "labels": [], "entities": [{"text": "Gain", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9995228052139282}]}, {"text": "This first experiment supported the hypothesis that subjects prefer references that include logically redundant information where there is a risk of DE/LO.", "labels": [], "entities": [{"text": "DE/LO", "start_pos": 149, "end_pos": 154, "type": "METRIC", "confidence": 0.9470317363739014}]}, {"text": "Arguably, it is precisely this kind of information that is needed for the construction of NLG algorithms.", "labels": [], "entities": []}, {"text": "Where logically redundant information does not make the referent easier to identify, the results of the experiment are less clear, with the subjects being divided between logically minimal and logically redundant descriptions.", "labels": [], "entities": []}, {"text": "In other words, while supporting the informal observations reported in Sections 2 and 3, the experiment does not point to a generic preference of one of the two GRE algorithms presented in Section 4.", "labels": [], "entities": []}, {"text": "Evidently, there are many factors that this experiment did not address, such as the \"distance\" between objects.", "labels": [], "entities": []}, {"text": "For example, if tables are enumerated throughout the document, is the brief, SL-type description easy enough to resolve?", "labels": [], "entities": []}, {"text": "It depends: If there are tables on virtually every page then resolution is easy, because the table numbers support browsing not unlike page numbers; if tables are sparse, however, then searching through the entire document may take unacceptably long, and a more redundant, FI-type description such as in Section 4.3 is likely to be preferred.", "labels": [], "entities": [{"text": "resolution", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.5250025987625122}]}, {"text": "The nature of the domain is bound to matter as well.", "labels": [], "entities": []}, {"text": "For example, in a large spatial domain in which navigation requires physical effort, short, SL-style descriptions are probably less acceptable than in a situation where the domain can be surveyed at a glance.", "labels": [], "entities": []}, {"text": "To exemplify the first type of situation, let us return briefly to Examples (1a)-(1c), assuming that a city is divided into areas, and an area into streets: If these are uttered somewhere in Brighton but not on Lewes Road then AS predicts that utterance (1c) leads to LO, because the hearer will start looking fora number 968 in the street where the description is uttered.", "labels": [], "entities": [{"text": "Lewes Road", "start_pos": 211, "end_pos": 221, "type": "DATASET", "confidence": 0.9400867819786072}, {"text": "AS", "start_pos": 227, "end_pos": 229, "type": "METRIC", "confidence": 0.8791394829750061}, {"text": "LO", "start_pos": 268, "end_pos": 270, "type": "METRIC", "confidence": 0.9940989017486572}]}, {"text": "Consequently, utterance (1c) is infelicitous anywhere except on Lewes Road.", "labels": [], "entities": [{"text": "Lewes Road", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.989233672618866}]}, {"text": "But how about Examples (1a) and (1b)?", "labels": [], "entities": []}, {"text": "Both descriptions avoid LO and DE, because Brighton has only one Lewes Road.", "labels": [], "entities": [{"text": "LO", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9984899759292603}, {"text": "DE", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9923067688941956}, {"text": "Lewes Road", "start_pos": 65, "end_pos": 75, "type": "DATASET", "confidence": 0.9710429906845093}]}, {"text": "Yet if the hearer does not know that Lewes Road is in Moulsecoomb, then the resolution of Example (1b) may involve more work than.", "labels": [], "entities": [{"text": "Lewes Road", "start_pos": 37, "end_pos": 47, "type": "DATASET", "confidence": 0.9673258662223816}, {"text": "Moulsecoomb", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.9290387630462646}, {"text": "Example", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.6755452752113342}]}, {"text": "This experiment attempted to find out what types of references are favored by human judges when their opinion about these references is asked.", "labels": [], "entities": []}, {"text": "Although this has the advantage that subjects were in a position to make trade-offs between the advantages and disadvantages of the different expressions (perhaps balancing ease of interpretation with ease of resolution), the method is limited in other respects.", "labels": [], "entities": []}, {"text": "One limitation arises from the fact that meta-linguistic judgments are sometimes thought to bean unreliable predictor of people's linguistic behavior (e.g., van Deemter 2004).", "labels": [], "entities": []}, {"text": "Perhaps more seriously, the experiment fails to tell us how difficult a given type of reference (for example, one of the DE type) would actually be fora reader, and whether the difficulty is a matter of interpretation or resolution.", "labels": [], "entities": [{"text": "interpretation or resolution", "start_pos": 203, "end_pos": 231, "type": "TASK", "confidence": 0.6832674741744995}]}, {"text": "For these reasons, we decided to perform another experiment.", "labels": [], "entities": []}, {"text": "In the previous experiment, we found that human authors often prefer logically redundant references, particularly when DE and LO can arise.", "labels": [], "entities": [{"text": "DE", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9889026284217834}, {"text": "LO", "start_pos": 126, "end_pos": 128, "type": "METRIC", "confidence": 0.8681421875953674}]}, {"text": "Ina follow-up experiment, we investigate the effect of logical redundancy on the performance of readers.", "labels": [], "entities": []}, {"text": "We are primarily interested in understanding the search process, so resolution rather than interpretation.", "labels": [], "entities": [{"text": "resolution", "start_pos": 68, "end_pos": 78, "type": "TASK", "confidence": 0.9363356828689575}]}, {"text": "It will become clear that the new experiment necessitates a more careful design and a more complex analysis than the previous one.", "labels": [], "entities": []}, {"text": "What does the second experiment teach us, over and above what we learned from the first one?", "labels": [], "entities": []}, {"text": "First of all, the experiment suggests an explanation of why it was that, in problematic situations, subjects (in the first experiment) preferred redundant descriptions: The new experiment suggests that the reason may lie in the fact that, in the potentially problematic situations, the addition of structural information reduces the effort involved in resolution.", "labels": [], "entities": []}, {"text": "This is, of course, exactly inline with the way in which DE and LO were introduced in Section 3, and with the assumptions about ease of resolution that were formulated in Paraboni and Van Deemter (2002a) and in the present Section 2.", "labels": [], "entities": [{"text": "DE", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.7491315603256226}, {"text": "LO", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9231308102607727}, {"text": "ease of resolution", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.6979695856571198}, {"text": "Paraboni and Van Deemter (2002a)", "start_pos": 171, "end_pos": 203, "type": "DATASET", "confidence": 0.7864020381655011}]}, {"text": "Do our experiments, taken together, tell us how much redundancy is optimal in any given situation?", "labels": [], "entities": []}, {"text": "In answering this question, let us first realize that pragmatic factors relating to the utterance situation are likely to affect how much redundancy is needed.", "labels": [], "entities": []}, {"text": "At one end of the spectrum, there maybe highly fault-critical settings, where flawless understanding is essential; at the other end, there maybe discourse settings where accurate understanding is not important, and where the speaker/writer is under time pressure.", "labels": [], "entities": []}, {"text": "Surely, redundant information must be more common in the former than in the latter.", "labels": [], "entities": []}, {"text": "No one algorithm can cater to all types of settings.", "labels": [], "entities": []}, {"text": "On the other hand, our data do suggest quite strongly that, at least in the situation in which our subjects found themselves, a law of diminishing returns is in operation.", "labels": [], "entities": []}, {"text": "To see this, let us first focus on the two non-problematic situations: Averaging numbers of clicks of all subjects overall relevant situations, short descriptions required a mere 1.53 clicks; by adding redundant information (unlike SL/FI), this number gets reduced to an average of 1.34 clicks (long(other), in situations 7 and 8).", "labels": [], "entities": []}, {"text": "This very slight gain (0.19 clicks) is not statistically significant (F 1,39 = .60, p = .44, \u03b7 2 p = .02) and is bought at the price of a description that is one and a half times longer, which makes it likely to take more time during interpretation.", "labels": [], "entities": [{"text": "F 1,39", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.980840653181076}]}, {"text": "As for the more interesting problematic situations, perhaps the best comparison is between situations 3 and 4 (where long(other) exists and is longer than long(FI/SL)).", "labels": [], "entities": [{"text": "FI/SL))", "start_pos": 160, "end_pos": 167, "type": "METRIC", "confidence": 0.9042097628116608}]}, {"text": "Here, short descriptions lead to a pretty dismal average of 4.05 clicks.", "labels": [], "entities": []}, {"text": "If we lengthen the descriptions as prescribed by FI/SL (long(FI/SL)) then this figure is lowered drastically to what looks like a pretty acceptable 1.77 clicks, which constitutes again of 2.28.", "labels": [], "entities": [{"text": "FI/SL", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.8762582937876383}, {"text": "FI/SL))", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.7211845964193344}]}, {"text": "By adding even more information (as in long(other)), the figure is lowered further, to 1.31 clicks.", "labels": [], "entities": []}, {"text": "Although this does represent again, it is not statistically significant (F 1,39 = 2.94, p = .095, \u03b7 2 p = .07), and besides it is so small (at 0.46 clicks) that it seems likely to be more than offset by the disadvantages for interpretation that are implied by the increased length of the description.", "labels": [], "entities": [{"text": "F 1,39", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9759567677974701}, {"text": "interpretation", "start_pos": 225, "end_pos": 239, "type": "TASK", "confidence": 0.9610103964805603}]}, {"text": "Needless to say, these effects can only become stronger if more complex documents are considered, and with descriptions that are even longer.", "labels": [], "entities": []}, {"text": "Really excessive redundancy might have detrimental effects on resolution as well as interpretation, because it confuses hearers.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 84, "end_pos": 98, "type": "TASK", "confidence": 0.9616737365722656}]}, {"text": "(A hearer might wonder, along Gricean lines, \"Why are they saying 'Picture 5 in Part A of Section 3, printed in black and white'.", "labels": [], "entities": []}, {"text": "Surely if they have to give so much information, they cannot simply mean Picture 5?\".)", "labels": [], "entities": []}, {"text": "Finally, we also explored the searching behavior of our subjects, focusing on the 12 documents in which incomplete descriptions were given.", "labels": [], "entities": []}, {"text": "Ancestral Search predicts that subjects will search the current section (where the question is asked) exhaustively, before moving onto another section.", "labels": [], "entities": []}, {"text": "shows subjects' compliance with Ancestral Search in their first navigation action.", "labels": [], "entities": []}, {"text": "(Eight of the 12 documents contained a description of the form Picture 5 in Part A, so for these it suffices to look at the first navigation action.)", "labels": [], "entities": []}, {"text": "Half the subjects complied almost perfectly, deviating in at most 2 of the 12 cases.", "labels": [], "entities": []}, {"text": "However, five subjects deviated almost completely (10 or more times).", "labels": [], "entities": []}, {"text": "Closer inspection showed that these latter subjects seemed to navigate randomly, not following any obvious pattern (e.g., top to bottom).", "labels": [], "entities": []}, {"text": "It may well be that these subjects did not take the experiment seriously.", "labels": [], "entities": []}, {"text": "Nevertheless, we still have more deviation from Ancestral Search than expected.", "labels": [], "entities": [{"text": "Ancestral Search", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.711509957909584}]}, {"text": "There are two possible explanations.", "labels": [], "entities": []}, {"text": "First, some subjects may have started using Ancestral Search, and then found that it was not effective when they encountered some documents in which the referent turned out to be in some far-away section, after which they changed to a more random strategy.", "labels": [], "entities": []}, {"text": "(Recall that our experiment deliberately included some unreasonably short descriptions.)", "labels": [], "entities": []}, {"text": "Our data seem to confirm this.", "labels": [], "entities": []}, {"text": "For instance, subject S11 started in compliance with Ancestral Search until encountering a document asking, in Section 2, to find a picture in Part C. The subject clicked as many as 6 times on Part C of Section 2, before finally finding the referent in Section 3.", "labels": [], "entities": []}, {"text": "He went onto deviate four times from Ancestral Search.", "labels": [], "entities": [{"text": "Ancestral Search", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7137740701436996}]}, {"text": "A second explanation for deviating from Ancestral Search is the kind of navigation that we allowed.", "labels": [], "entities": [{"text": "Ancestral Search", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.7352972328662872}]}, {"text": "Subjects could go directly from, say, Part C in Section 2, to part A in Section 3, without an extra navigation step to go into Section 3.", "labels": [], "entities": []}, {"text": "In fact, it may even be faster to navigate to another section than within the current one, depending on the position of the mouse pointer.", "labels": [], "entities": []}, {"text": "(This contrasts with the university domain, where one could not go directly from room 120 in Watts building to room 140 in Cockcroft building without first having to walk between the buildings.)", "labels": [], "entities": [{"text": "Cockcroft building", "start_pos": 123, "end_pos": 141, "type": "DATASET", "confidence": 0.9452846050262451}]}, {"text": "It should be noted that this problem maybe more pronounced after the first navigation action has been made.", "labels": [], "entities": [{"text": "navigation", "start_pos": 75, "end_pos": 85, "type": "TASK", "confidence": 0.9636133909225464}]}, {"text": "For instance, if one clicks on Part A in Section 2, then the mouse pointer is about as close to Part C in Section 1 as to Part C in Section 2.", "labels": [], "entities": []}, {"text": "To explore this idea, we looked at the four documents in which a description of the form picture 5 was given.", "labels": [], "entities": []}, {"text": "In 83 cases, subjects who complied with Ancestral Search for the first navigation action needed to perform a second action; in 77% of these cases, they also complied with Ancestral Search in the second action.", "labels": [], "entities": []}, {"text": "Now in as many as 68% of the cases in which they did not comply, they clicked on the closest link in an adjacent section (e.g., Part A of the next section after having first clicked on Part C).", "labels": [], "entities": []}, {"text": "This confirms our suspicion that the lack of effort required to deviate may have been a reason for deviation.", "labels": [], "entities": []}, {"text": "With hindsight, we should probably have made the distance between the relevant sections larger.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Situations of reference for Experiment 1.", "labels": [], "entities": []}, {"text": " Table 6  Table 6 in Part B Sec 3  10  NONE Part C Sec 2 Part A Sec 3  Table 5  Table 5 in Part A Sec 3  12  NONE Part A Sec 3 Part B Sec 2  Table 2  Table 2 in Part B Sec 2  18  NONE Part B Sec 3  Part A Sec 1  Table 1  Table 1 in Part A Sec 1", "labels": [], "entities": []}, {"text": " Table 2  Situations of reference for Experiment 2.", "labels": [], "entities": []}, {"text": " Table 3  Number of clicks used to complete the tasks.", "labels": [], "entities": []}, {"text": " Table 4  Gain as used for Hypothesis 2.2.", "labels": [], "entities": []}, {"text": " Table 5  Gain as used for Hypothesis 2.3.", "labels": [], "entities": []}]}