{"title": [], "abstractContent": [{"text": "This article describes a method for composing fluent and complex natural language questions , while avoiding the standard pitfalls of free text queries.", "labels": [], "entities": []}, {"text": "The method, based on Conceptual Authoring, is targeted at question-answering systems where reliability and transparency are critical, and where users cannot be expected to undergo extensive training in question composition.", "labels": [], "entities": [{"text": "reliability", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.9797655940055847}, {"text": "question composition", "start_pos": 202, "end_pos": 222, "type": "TASK", "confidence": 0.7212356328964233}]}, {"text": "This scenario is found inmost corporate domains, especially in applications that are risk-averse.", "labels": [], "entities": []}, {"text": "We present a proof-of-concept system we have developed: a question-answering interface to a large repository of medical histories in the area of cancer.", "labels": [], "entities": []}, {"text": "We show that the method allows users to successfully and reliably compose complex queries with minimal training.", "labels": [], "entities": []}], "introductionContent": [{"text": "Where early attempts to build natural language question-answering systems focused on accessing and presenting information held in (closed domain) databases (e.g.,, the advent of the World Wide Web has led to a shift towards (open domain) collections of texts.", "labels": [], "entities": []}, {"text": "However, despite significant advances in open domain question answering since the simple pattern-matching systems of the first TREC competition in 1999, current systems are still largely restricted to simple questions.", "labels": [], "entities": [{"text": "question answering", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7247461229562759}, {"text": "TREC competition in 1999", "start_pos": 127, "end_pos": 151, "type": "TASK", "confidence": 0.6544222831726074}]}, {"text": "They can, for example, successfully find answers to questions like Which is the highest peak in Africa? or Who first climbed Kilimanjaro?", "labels": [], "entities": []}, {"text": "but they cannot correctly answer more complex questions like: What is the median height of the top twelve highest peaks in Africa?", "labels": [], "entities": []}, {"text": "Which explorer who climbed Kilimanjaro but not Everest between 1960 and 1995 died in the last three years before the age of 55?", "labels": [], "entities": []}, {"text": "How many of the explorers who climbed Kilimanjaro but not Everest between 1960 and 1995 did so more than three times during that period?", "labels": [], "entities": []}, {"text": "There are many reasons why such queries are unlikely to be successful.", "labels": [], "entities": []}, {"text": "For example, although the first question is very simple to interpret, a correct answer is unlikely to be available (in a retrievable form) in any individual document in the target collection.", "labels": [], "entities": []}, {"text": "A question-answering system would thus have to first retrieve the heights of each of the top twelve highest peaks, probably from different documents, and apply some calculations to obtain their median height, and then generate a response that aggregates answers from multiple documents.", "labels": [], "entities": []}, {"text": "The answer to the second question, on the other hand, is very simple and likely to be found in a small number of documents, but the question itself is not trivial to interpret and would require (among other things) resolving the temporal information, correctly assuming that 55 refers to age at the time of death, and interpreting the negation but not as referring to the climbing of Everest only within the specified time span.", "labels": [], "entities": []}, {"text": "For the third question, the difficulty comes from a combination of complex question and complex answer.", "labels": [], "entities": []}, {"text": "Retrieving aggregated results from the World Wide Web also introduces issues of reliability because the sources may not all be trusted, and there is no guarantee that a different selection of sources would not yield a contrary result.", "labels": [], "entities": [{"text": "reliability", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9758678674697876}]}, {"text": "For many applications of question answering, the need for complex questions and trusted answers is paramount-for example, in the medical, legal, and financial domains, or indeed in any research area-and it is to this scenario that the work we present here applies.", "labels": [], "entities": [{"text": "question answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9193318784236908}]}, {"text": "Our goal is to develop a general and intuitive method by which users can pose complex queries to data repositories; we are particularly concerned with scenarios where the users are domain experts (i.e., clinicians, lawyers, financiers, etc.) rather than database experts, where reliability of the answer is critical, where the method of posing questions should be easy to learn, and where the questions themselves should be transparent (i.e., clear and unambiguous) to both user and system.", "labels": [], "entities": []}, {"text": "Current methods for querying databases typically make use of formal query languages such as SQL.", "labels": [], "entities": []}, {"text": "These languages are highly technical and require a great deal of training to achieve the level of proficiency required to pose the kinds of complex queries shown in the previous example.", "labels": [], "entities": []}, {"text": "Successful query composition requires the user to be proficient in the query language and have detailed knowledge of the structure of the database to which the queries are being addressed.", "labels": [], "entities": [{"text": "query composition", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8047431409358978}]}, {"text": "Users also need to be fluent in any formal codes employed to refer to entities in the domain (e.g., disease classifications, laws, bank codes).", "labels": [], "entities": [{"text": "disease classifications", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7795872390270233}]}, {"text": "For example, in the medical domain alone there area large number of clinical terminologies and classifications, used for different purposes: Some classifications, such as ICD-9, ICD-10, and OPCS-4, are employed in summarizing the incidence of diseases and operations on a national or worldwide level; others, such as CPT4 or ICD-9CM, manage the process of billing patients.", "labels": [], "entities": [{"text": "ICD-9", "start_pos": 171, "end_pos": 176, "type": "DATASET", "confidence": 0.860567033290863}, {"text": "ICD-10", "start_pos": 178, "end_pos": 184, "type": "DATASET", "confidence": 0.7507861256599426}, {"text": "OPCS-4", "start_pos": 190, "end_pos": 196, "type": "DATASET", "confidence": 0.796863317489624}, {"text": "summarizing the incidence of diseases and operations", "start_pos": 214, "end_pos": 266, "type": "TASK", "confidence": 0.8329904590334211}, {"text": "CPT4", "start_pos": 317, "end_pos": 321, "type": "DATASET", "confidence": 0.9300623536109924}, {"text": "ICD-9CM", "start_pos": 325, "end_pos": 332, "type": "DATASET", "confidence": 0.8832225203514099}]}, {"text": "Each covers a large number of terms and associated codes: SNOMED-CT alone, to name the most widely used medical terminology, currently contains some 365,000 individual concepts, and is being updated continuously (College of American Pathologists 2004).", "labels": [], "entities": []}, {"text": "Finally, because database languages are not transparent, mistakes in query formulation can be difficult to spot; so even where the system itself maybe highly reliable, there is a reasonable chance that-except for very highly experienced database programmers-the returned answer may not bean accurate response to the intended question.", "labels": [], "entities": [{"text": "query formulation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7208309173583984}]}, {"text": "A well-known alternative to formal database languages is available in visual query systems, which make use of graphical devices such as forms, diagrams, menus, and pointers to communicate the content of a database to the user.", "labels": [], "entities": []}, {"text": "They are also widely used in commercial applications, and research shows that they are much preferred over textual query languages like SQL, especially by casual and non-expert users.", "labels": [], "entities": []}, {"text": "However, visual interfaces are also problematic: empirical studies report high error rates by domain experts using visual object-oriented modeling tools, and a clear advantage of text over graphics for understanding nested conditional structures.", "labels": [], "entities": []}, {"text": "Natural language clearly provides a more intuitive means for users to pose their questions, but this is also highly problematic because queries expressed in free natural language are obviously very sensitive to errors of composition (e.g., misspellings, ungrammaticalities) or processing (at the lexical, syntactic, or semantic level).", "labels": [], "entities": []}], "datasetContent": [{"text": "The best evaluation of any question-answering system is one which looks at real users making information-seeking requests in real-life contexts.", "labels": [], "entities": []}, {"text": "Because the complete CLEF system is not yet ready for deployment, this is impractical at this stage.", "labels": [], "entities": []}, {"text": "However, we have been able to perform usability tests on the query interface in isolation from the full system, and this is what we report on here.", "labels": [], "entities": []}, {"text": "Our current study does not cover the Query to SQL Translation and the Answer Retrieval components, which are part of the server components side of the query interface.", "labels": [], "entities": [{"text": "Query to SQL Translation", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7358046174049377}, {"text": "Answer Retrieval", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.8596251010894775}]}, {"text": "This separation is not always possible in practice.", "labels": [], "entities": []}, {"text": "For example, we cannot at this stage test the full range of queries that can be constructed in the interface, because some are not yet supported by the back-end.", "labels": [], "entities": []}, {"text": "Similarly, we can only assess the time necessary for editing queries, not for retrieving answers, because this is almost entirely dependent on the communication procedure and on the speed of the SQL translator.", "labels": [], "entities": []}, {"text": "We have thus far conducted two formal experiments, to address the following questions: r Are users able to successfully compose complex queries using the system?", "labels": [], "entities": []}, {"text": "r Can the system be used with minimal training?", "labels": [], "entities": []}, {"text": "r Are the queries, as presented in the interface, easily understandable?", "labels": [], "entities": []}, {"text": "As mentioned earlier (Section 1), one of the main desiderata behind the design of our querying method is that it should be intuitive.", "labels": [], "entities": []}, {"text": "With respect to the system we have implemented for CLEF, what this means is that medics and bio-informaticians should be able to pose the kind of complex queries that they require, without the need for extensive training, or for knowledge of the structure or language of the underlying repository.", "labels": [], "entities": []}, {"text": "This experiment tests the extent to which our querying method fulfills these requirements.", "labels": [], "entities": []}, {"text": "Fifteen medics and bio-informaticians participated in the experiment.", "labels": [], "entities": []}, {"text": "All had previously been granted clearance to seethe information in the confidential repository of patient records.", "labels": [], "entities": []}, {"text": "All subjects were knowledgeable in the domain of cancer, and all but two had no knowledge of the representation language of the repository (SQL), or of how the data contained therein were structured; none had any prior experience with the query-formulation interface.", "labels": [], "entities": []}, {"text": "Each subject was given a short (5-10 minute) introduction to the interface, which included a demonstration of the construction of a fairly simple query.", "labels": [], "entities": []}, {"text": "Subjects were then given a set of four queries, which they were asked to compose using the interface.", "labels": [], "entities": []}, {"text": "To increase the difficulty of the task, the questions presented to the subjects avoided, where possible, the wording required by the user interface, so that users were obliged to think about the meaning rather than to aim for particular target phrases.", "labels": [], "entities": []}, {"text": "To avoid effects of practice, we varied randomly the order in which the questions in the set were presented to subjects.", "labels": [], "entities": []}, {"text": "Subjects were allowed as much time as they needed to compose each query.", "labels": [], "entities": []}, {"text": "For each subject, we measured the time taken to build each query, and recorded the number of operations used for constructing it.", "labels": [], "entities": []}, {"text": "The materials for the experiment consisted of the following set of four queries:  Interfaces to databases based on natural language interpretation inevitably suffer from the ambiguity and imprecision of the input texts, unless users can be trained in a controlled language.", "labels": [], "entities": [{"text": "Interfaces to databases based on natural language interpretation", "start_pos": 82, "end_pos": 146, "type": "TASK", "confidence": 0.5700569078326225}]}, {"text": "Our method of composing queries avoids this problem altogether: because the natural language feedback text is generated by the system rather than the user, there is no need for the system to choose among alternative interpretations.", "labels": [], "entities": []}, {"text": "Of course, this does not guarantee that the query text is equally transparent to the user: this will depend on the efficacy of our feedback text design-the point we wish to evaluate in the present experiment, which explores the extent to which composed queries, as presented in the feedback texts, can be clearly understood.", "labels": [], "entities": []}, {"text": "Fifteen subjects participated in the experiment.", "labels": [], "entities": []}, {"text": "Of these, ten had previously participated in Experiment 1; the new subjects had the same profile as those previously seen.", "labels": [], "entities": []}, {"text": "Subjects were given a paper-based questionnaire containing 24 trials, each showing a completed complex query as presented in the interface (i.e., as a 'feedback text').", "labels": [], "entities": []}, {"text": "Each query was associated with three alternative interpretations, presented as full natural language questions: only one of these represented the correct meaning; the other two represented plausible but incorrect meanings.", "labels": [], "entities": []}, {"text": "Subjects were given a forced-choice task to identify which of the three alternatives corresponded to the meaning of the given feedback text.", "labels": [], "entities": []}, {"text": "The queries were presented to all subjects in the same (random) order.", "labels": [], "entities": []}, {"text": "We devised five presentation sets, each containing a different ordering of the options for each query, and these were randomly assigned to subjects.", "labels": [], "entities": []}, {"text": "We suggested to subjects that a useful strategy might be to read the alternatives before looking at the associated feedback text.", "labels": [], "entities": []}, {"text": "There was no time limit.", "labels": [], "entities": [{"text": "time limit", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9774681627750397}]}, {"text": "The materials comprised four examples, each of six patterns of ambiguity: Type 1: Attachment of temporal expression.", "labels": [], "entities": []}, {"text": "Most events can have a temporal expression associated.", "labels": [], "entities": []}, {"text": "When there is more than one event that could be subsumed by a temporal expression, the text may become ambiguous.", "labels": [], "entities": []}, {"text": "For example: Relevant subjects: patients with a clinical diagnosis of breast cancer Treatment: patients who did not receive adjuvant chemotherapy in the past year r How many patients diagnosed with invasive ductal carcinoma did not undergo breast conservation surgery, did not undergo auxillary surgery, and received radiotherapy?", "labels": [], "entities": [{"text": "breast conservation", "start_pos": 240, "end_pos": 259, "type": "TASK", "confidence": 0.7276987284421921}]}, {"text": "Type 3: Scope of conjunctions plus attachment of temporal expression.", "labels": [], "entities": [{"text": "Scope of conjunctions", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.8534340659777323}]}, {"text": "This is an extension of the first two cases, where a temporal expression post-modifies an expression that is part of a conjunction of events.", "labels": [], "entities": []}, {"text": "For example: Relevant subjects: patients with a clinical diagnosis of malignant neoplasm, unspecified Treatment: patients who received radiotherapy and chemotherapy within 1 year of the diagnosis Tests:[ ] Outcome:absolute number of patients Options: r How many patients diagnosed with cancer had radiotherapy and chemotherapy both within 1 year of diagnosis?", "labels": [], "entities": [{"text": "Outcome", "start_pos": 206, "end_pos": 213, "type": "METRIC", "confidence": 0.9917470216751099}]}, {"text": "r How many patients diagnosed with cancer had radiotherapy within 1 year of diagnosis and also had chemotherapy at any time?", "labels": [], "entities": []}, {"text": "In the examples that follow, the correct interpretations are indicated with italics.", "labels": [], "entities": []}, {"text": "r How many patients diagnosed with cancer had radiotherapy and chemotherapy and received any kind of treatment within 1 year of diagnosis?", "labels": [], "entities": []}, {"text": "Type 4: Combination of various query components.", "labels": [], "entities": []}, {"text": "Events in a query can be linked to each other by various means, including temporal expressions, conjunctions, and disjunctions.", "labels": [], "entities": []}, {"text": "Complex combinations may render the feedback text ambiguous.", "labels": [], "entities": []}, {"text": "For example: Relevant subjects: patients with a clinical diagnosis of breast cancer and who had nausea within 1 year of the chemotherapy Treatment: patients who received [some surgical procedure] [at some point in time] and chemotherapy but no radiotherapy within 1 year of the diagnosis Tests:[ ] Outcome: percentage of patients who were alive after 5 years of the diagnosis Options: r What percentage of patients diagnosed with breast cancer who underwent a surgical procedure at anytime, received chemotherapy within 1 year of the diagnosis, had nausea within 1 year of the chemotherapy, and received no radiotherapy within 1 year of the diagnosis, survived more than 5 years after diagnosis?", "labels": [], "entities": [{"text": "Outcome", "start_pos": 298, "end_pos": 305, "type": "METRIC", "confidence": 0.9897456169128418}]}, {"text": "r What percentage of patients diagnosed with breast cancer who underwent a surgical procedure at anytime, received chemotherapy at anytime, had nausea at anytime after chemotherapy, and received no radiotherapy within 1 year of the diagnosis, survived more than 5 years after diagnosis?", "labels": [], "entities": []}, {"text": "r What percentage of patients diagnosed with breast cancer who underwent a surgical procedure at anytime, received chemotherapy within 1 year of the diagnosis, had nausea after chemotherapy but within 1 year of the diagnosis, and received no radiotherapy within 1 year of the diagnosis, survived more than 5 years after diagnosis?", "labels": [], "entities": []}, {"text": "Type 5: Complex queries, non-ambiguous components.", "labels": [], "entities": []}, {"text": "We introduced this category in order to test the readability of complex queries that do not necessarily contain ambiguous components.", "labels": [], "entities": []}, {"text": "Because most queries in the medical domain are likely to be very complex, can the sheer number of query components render the query ambiguous to the users?", "labels": [], "entities": []}, {"text": "For example: r How many patients with breast cancer, under the age of 50, had a surgical procedure within one year of the diagnosis and did not have chemotherapy within one year of the diagnosis?", "labels": [], "entities": []}, {"text": "r How many patients with breast cancer, below the age of 50, had a surgical procedure within one year of the diagnosis and had chemotherapy after one year of the diagnosis?", "labels": [], "entities": []}, {"text": "Type 6: Attachment/interpretation of outcome.", "labels": [], "entities": [{"text": "Attachment/interpretation of outcome", "start_pos": 8, "end_pos": 44, "type": "TASK", "confidence": 0.8385727047920227}]}, {"text": "The outcome section generally describes a condition holding between a reference and a target set of patients.", "labels": [], "entities": []}, {"text": "If the query contains multiple features describing the patient set, it maybe difficult to differentiate between features that contribute to the reference set and features that contribute to the target set.", "labels": [], "entities": []}, {"text": "For example: Relevant subjects: patients with a clinical diagnosis of breast cancer and who had anaemia after chemotherapy Treatment: patients who received chemotherapy Results.", "labels": [], "entities": []}, {"text": "If the presented feedback text is incomprehensible, the probability that subjects will select the correct interpretation will be 0.33 (i.e., they will get the right answer only a third of the time).", "labels": [], "entities": []}, {"text": "Our results show that subjects' precision is 0.84; that is, on average, they select the intended interpretation 84% of the time, rather than 33% as would be predicted if their selections were random.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9989328980445862}]}, {"text": "Statistical analysis of these results, using a one-sample t-test, shows this effect to be highly significant (mean = 0.8361, d = 0.5028, t = 16.76, p < .0001).", "labels": [], "entities": [{"text": "mean", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9725763201713562}]}, {"text": "The breakdown by type of ambiguity is shown in.", "labels": [], "entities": []}, {"text": "The true test of any system comes with its use in situ by the users for which it was designed.", "labels": [], "entities": []}, {"text": "Normally, this would be preceded by a bank of formal empirical studies under more controlled conditions.", "labels": [], "entities": []}, {"text": "For a question-answering system like the one we are addressing in this article (which is but a small part of a much larger system), a formal controlled evaluation would ideally cover a large number of exemplars of each type of query supported by the system, and a large number of subjects.", "labels": [], "entities": []}, {"text": "Given our constraints on the number of available subjects (and the concomitant effect this has on the possible design of any experiments), the evaluation reported here is necessarily more limited in scope.", "labels": [], "entities": []}, {"text": "This is not an unusual situation in system development, where evaluation must proceed by gradual refinement through the application of rigor, wherever possible, but also applying along the way intuition, commonsense, and past experience.", "labels": [], "entities": []}, {"text": "The evaluation we have presented here shows what can be done during the early phases of the development of a large and complex system whose components are in different stages of completion, and where access to representative users is limited.", "labels": [], "entities": []}, {"text": "Given these caveats, the picture that emerges from this study is nonetheless very encouraging.", "labels": [], "entities": []}, {"text": "Our results suggest that our target users (medical researchers) can quickly learn to construct queries of the type and complexity that they have identified as relevant.", "labels": [], "entities": []}, {"text": "Specifically: r They are able to use the Conceptual Authoring method successfully to compose complex queries, with no prior exposure to the method and with the benefit of only minimal training.", "labels": [], "entities": []}, {"text": "r They become quickly proficient with the system, achieving near perfect performance by their fourth attempt at query composition.", "labels": [], "entities": [{"text": "query composition", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.8430203497409821}]}, {"text": "The study also indicates that the feedback texts employed to construct queries of a high degree of structural complexity are not difficult to understand.", "labels": [], "entities": []}, {"text": "This is extremely important, as it means that users can be confident that they are obtaining an answer that pertains to the question that they think they are asking, as opposed to an answer to some other similar question.", "labels": [], "entities": []}, {"text": "Additionally, in a separate, informal study, we have found suggestive evidence that the Conceptual Authoring method of query composition maybe much more user-friendly than the traditional method of direct SQL editing, even for extremely skilled SQL coders with a high level of familiarity with the database and the domain).", "labels": [], "entities": [{"text": "query composition", "start_pos": 119, "end_pos": 136, "type": "TASK", "confidence": 0.7279163748025894}, {"text": "SQL editing", "start_pos": 205, "end_pos": 216, "type": "TASK", "confidence": 0.7496184408664703}]}, {"text": "Our tests showed that (an albeit small sample of) such experts, even in a situation that is heavily biased towards optimal performance of SQL codes, found it much easier to compose queries with the Conceptual Authoring interface than in SQL.", "labels": [], "entities": []}, {"text": "Not only did it take them more than three times longer, on average, to compose the query in SQL, but they were notable to produce the complete SQL in that time.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Interpretation of feedback texts.", "labels": [], "entities": []}]}