{"title": [{"text": "From Molecule to Metaphor: A Neural Theory of Language", "labels": [], "entities": []}], "abstractContent": [{"text": "Over the last decade or so, it has become increasingly clear to many cognitive scientists that research into human language (and cognition in general, for that matter) has largely neglected how language and thought are embedded in the body and the world.", "labels": [], "entities": []}, {"text": "As argued by, for instance, Clark (1997), cognition is fundamentally embodied, that is, it can only be studied in relation to human action, perception, thought, and experience.", "labels": [], "entities": []}, {"text": "As Feldman puts it: \"Human language and thought are crucially shaped by the properties of our bodies and the structure of our physical and social environment.", "labels": [], "entities": []}, {"text": "Language and thought are not best studied as formal mathematics and logic, but as adaptations that enable creatures like us to thrive in a wide range of situations\" (p. 7).", "labels": [], "entities": []}, {"text": "Although it may seem paradoxical to try formalizing this view in a computational theory of language comprehension, this is exactly what From Molecule to Metaphor does.", "labels": [], "entities": []}, {"text": "Starting from the assumption that human thought is neural computation, Feldman develops a computational theory that takes the embodied nature of language into account: the neural theory of language.", "labels": [], "entities": []}, {"text": "The book comprises 27 short chapters, distributed over nine parts.", "labels": [], "entities": []}, {"text": "Part I presents the basic ideas behind embodied language and cognition and explains how the embodiment of language is apparent in the brain: The neural circuits involved in a particular experience or action are, fora large part, the same circuits involved in processing language about this experience or action.", "labels": [], "entities": []}, {"text": "Part II discusses neural computation, starting from the molecules that take part in information processing by neurons.", "labels": [], "entities": []}, {"text": "This detailed exposition is followed by a description of neuronal networks in the human body, in particular in the brain.", "labels": [], "entities": []}, {"text": "The description of the neural theory of language begins in Part III, where it is explained how localist neural networks, often used as psycholinguistic models, can represent the meaning of concepts.", "labels": [], "entities": []}, {"text": "This is done by introducing triangle nodes into the network.", "labels": [], "entities": []}, {"text": "Each triangle node connects the nodes representing a concept, a role, and a filler-for example, \"pea,\" \"has-color,\" and \"green.\"", "labels": [], "entities": []}, {"text": "Such networks are trained by a process called recruitment learning, which is described only very informally.", "labels": [], "entities": [{"text": "recruitment learning", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.9538297355175018}]}, {"text": "This is certainly an interesting idea for combining propositional and connectionist models, but it does leave the reader with a number of questions.", "labels": [], "entities": []}, {"text": "For instance, how is the concept distinguished from the filler when they can be interchanged, as in \"cats, feed-on, mice\" versus \"mice, feed-on, cats.\"", "labels": [], "entities": []}, {"text": "And on a more philosophical note: Where does this leave embodiment?", "labels": [], "entities": []}, {"text": "The idea that there exists anode representing the concept \"pea,\" neurally distinct from its properties and from experiences with peas, seems to introduce abstract and arbitrary symbols.", "labels": [], "entities": []}, {"text": "These are quite alien to embodied theories of cognition, which generally assume modal and analogical perceptual symbols (Barsalou 1999) or even no symbols at all (Brooks 1991).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}