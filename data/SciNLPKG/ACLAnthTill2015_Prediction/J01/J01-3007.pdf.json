{"title": [{"text": "Book Reviews Advances in Probabilistic and Other Parsing Technologies Harry Bunt and Anton Nijholt (editors)", "labels": [], "entities": []}], "abstractContent": [{"text": "papers are already well-known and others should be.", "labels": [], "entities": []}, {"text": "The book could easily be used as the basis fora graduate-level advanced course on parsing.", "labels": [], "entities": []}, {"text": "The title is unwieldy, but appropriate: most but not all of the papers have a strong probabilistic flavor.", "labels": [], "entities": []}, {"text": "My favorite papers are Erik Hektoen on \"Probabilistic parse selection based on semantic co-occurrences,\" Jason Eisner on \"Bilexical grammars and their cubic-time parsing algorithms,\" and Chris Manning and Bob Carpenter on \"Probabilistic parsing using left corner language models.\"", "labels": [], "entities": [{"text": "Probabilistic parse selection", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.869636595249176}, {"text": "cubic-time parsing", "start_pos": 151, "end_pos": 169, "type": "TASK", "confidence": 0.6407797038555145}, {"text": "Probabilistic parsing", "start_pos": 223, "end_pos": 244, "type": "TASK", "confidence": 0.7865042686462402}]}, {"text": "I like these papers because they step back from the details of parsing technology and consider its wider significance.", "labels": [], "entities": [{"text": "parsing technology", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.9205217957496643}]}, {"text": "Manning and Carpenter offer both detail and overview.", "labels": [], "entities": [{"text": "detail", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9777895212173462}, {"text": "overview", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9469103813171387}]}, {"text": "They provide a series of probabilistic models that relax the context-freeness assumption of probabilistic context-free grammars, measure performance in the usual way, draw appropriate conclusions, then provide the kicker in the form of a brief section explaining \"Why parsing the Penn Treebank is easy.\"", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 280, "end_pos": 293, "type": "DATASET", "confidence": 0.9247078895568848}]}, {"text": "As Manning and Carpenter point out, in the particular case of the Penn Treebank, the currently accepted PARSEVAL metrics (Grishman, Macleod, and Sterling 1992) are actually quite easy to do well on, even if the system makes systematic errors on such things as prepositional-phrase attachment.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.992342621088028}, {"text": "PARSEVAL", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.8399020433425903}, {"text": "prepositional-phrase attachment", "start_pos": 260, "end_pos": 291, "type": "TASK", "confidence": 0.7463423311710358}]}, {"text": "If systems are to be deployed into situations where such deficiencies might matter, it might be necessary to find more appropriate evaluation methods.", "labels": [], "entities": []}, {"text": "This issue has subsequently been addressed by others (Carroll, Briscoe, and Sanfilippo 1998; Carroll, Minnen, and Briscoe 1999), who argue for more obviously task-related evaluation schemes involving predicate argument structure and/or dependency information.", "labels": [], "entities": []}, {"text": "Hektoen's contribution is in the same vein; it takes seriously the notion that parsing is often simply a device forgetting at an underlying semantics.", "labels": [], "entities": []}, {"text": "Under his scheme, parse selection relies on the ability to collect statistics over semantic forms.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.983568012714386}]}, {"text": "Following this path leads Hektoen into a careful exposition of a Bayesian-estimation approach to parse selection, which appears to be \"a sufficient response to the high degree of sparse-ness in the lexical co-occurrence data without the blurring associated with smoothing and clustering\" (p. 162).", "labels": [], "entities": [{"text": "parse selection", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.9568058848381042}]}, {"text": "Hektoen's approach appears to work well; of course, it does require a broad-coverage parser capable of generating semantic representations, which maybe an obstacle for many.", "labels": [], "entities": []}, {"text": "The exposition of the method is very clear and the comparison with previous approaches is enlightening.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}