{"title": [{"text": "Integrating Prosodic and Lexical Cues for Automatic Topic Segmentation", "labels": [], "entities": [{"text": "Topic Segmentation", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7061260938644409}]}], "abstractContent": [{"text": "We present a probabilistic model that uses both prosodic and lexical cues for the automatic seg-mentation of speech into topically coherent units.", "labels": [], "entities": []}, {"text": "We propose two methods for combining lexical and prosodic information using hidden Markov models and decision trees.", "labels": [], "entities": []}, {"text": "Lexical information is obtained from a speech recognizer, and prosodic features are extracted automatically from speech waveforms.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the Broadcast News corpus, using the DARPA-TDT evaluation metrics.", "labels": [], "entities": [{"text": "Broadcast News corpus", "start_pos": 32, "end_pos": 53, "type": "DATASET", "confidence": 0.938564658164978}]}, {"text": "Results show that the prosodic model alone is competitive with word-based segmentation methods.", "labels": [], "entities": []}, {"text": "Furthermore, we achieve a significant reduction in error by combining the prosodic and word-based knowledge sources.", "labels": [], "entities": [{"text": "error", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9899061322212219}]}], "introductionContent": [{"text": "Topic segmentation is the task of automatically dividing a stream of text or speech into topically homogeneous blocks.", "labels": [], "entities": [{"text": "Topic segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8089257776737213}, {"text": "dividing a stream of text or speech into topically homogeneous blocks", "start_pos": 48, "end_pos": 117, "type": "TASK", "confidence": 0.5143601189960133}]}, {"text": "That is, given a sequence of (written or spoken) words, the aim of topic segmentation is to find the boundaries where topics change.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.7447501122951508}]}, {"text": "gives an example of a topic change boundary from a broadcast news transcript.", "labels": [], "entities": []}, {"text": "Topic segmentation is an important task for various language understanding applications, such as information extraction and retrieval, and text summarization.", "labels": [], "entities": [{"text": "Topic segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8301681876182556}, {"text": "language understanding", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7245690524578094}, {"text": "information extraction and retrieval", "start_pos": 97, "end_pos": 133, "type": "TASK", "confidence": 0.8616941273212433}, {"text": "text summarization", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7905062139034271}]}, {"text": "In this paper, we present our work on automatic detection of topic boundaries from speech input using both prosodic and lexical information.", "labels": [], "entities": [{"text": "automatic detection of topic boundaries from speech input", "start_pos": 38, "end_pos": 95, "type": "TASK", "confidence": 0.8479477278888226}]}, {"text": "Other automatic topic segmentation systems have focused on written text and have depended mostly on lexical information.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7027561664581299}]}, {"text": "This is problematic when segmenting speech.", "labels": [], "entities": [{"text": "segmenting speech", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8917411267757416}]}, {"text": "First, relying on word identities can propagate automatic speech recognizer errors to the topic segmenter.", "labels": [], "entities": []}, {"text": "Second, speech lacks typographic cues, as shown in: there are no headers, paragraphs, sentence punctuation marks, or capitalized letters.", "labels": [], "entities": []}, {"text": "Speech itself, on the other hand, provides an additional, nonlexical knowledge source through its durational, intonational, and energy characteristics, i.e., its prosody.", "labels": [], "entities": []}, {"text": "Prosodic cues are known to be relevant to discourse structure in spontaneous speech (cf. Section 2.3) and can therefore be expected to play a role in indicating topic transitions.", "labels": [], "entities": [{"text": "indicating topic transitions", "start_pos": 150, "end_pos": 178, "type": "TASK", "confidence": 0.6765775680541992}]}, {"text": "Furthermore, prosodic cues, by their nature, are relatively unaffected byword identity, and should therefore improve the robustness of lexical topic segmentation methods based on automatic speech recognition.", "labels": [], "entities": []}, {"text": "tens of thousands of people are homeless in northern china tonight after a powerful earthquake hit an earthquake registering six point two on the richter scale at least forty seven people are dead few pictures available from the region but we do know temperatures there will be very cold tonight minus seven degrees <TOPIC_CHANGE> peace talks expected to resume on monday in belfast northern ireland former u. s. senator george mitchell is representing u. s. interests in the talks but it is another american center senator rather who was the focus of attention in northern ireland today here's a. b. c.'s richard gizbert the senator from america's best known irish catholic family is in northern ireland today to talk about peace and reconciliation a peace process does not mean asking unionists or nationalists to change or discard their identity or aspirations...", "labels": [], "entities": [{"text": "TOPIC", "start_pos": 317, "end_pos": 322, "type": "METRIC", "confidence": 0.8398715853691101}]}], "datasetContent": [{"text": "To evaluate our topic segmentation models, we carried out experiments in the TDT paradigm.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7278628051280975}]}, {"text": "We first describe our test data and the evaluation metrics used to compare model performance, then give the results we obtained with individual knowledge sources, followed by the results of the combined models.", "labels": [], "entities": []}, {"text": "We have adopted the evaluation paradigm used by the TDT2--Topic Detection and Tracking Phase 2 (Doddington 1998) program, allowing fair comparisons of various approaches both within this study and with respect to other recent work.", "labels": [], "entities": [{"text": "TDT2--Topic Detection and Tracking Phase", "start_pos": 52, "end_pos": 92, "type": "TASK", "confidence": 0.7712887270109994}, {"text": "Doddington 1998) program", "start_pos": 96, "end_pos": 120, "type": "DATASET", "confidence": 0.5972055494785309}]}, {"text": "Segmentation accuracy was measured using TDT evaluation software from NIST, which implements a variant of an evaluation metric suggested by.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.8086625337600708}, {"text": "NIST", "start_pos": 70, "end_pos": 74, "type": "DATASET", "confidence": 0.9376128315925598}]}, {"text": "The TDT segmentation metric is different from those used inmost previous topic segmentation work, and therefore merits some discussion.", "labels": [], "entities": [{"text": "TDT segmentation", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.8804250955581665}]}, {"text": "It is designed to work on data streams without any potential topic boundaries, such as paragraph or sentence boundaries, being given a priori.", "labels": [], "entities": []}, {"text": "It also gives proper partial credit to segmentation decisions that are close to actual boundaries; for example, placing a boundary one word from an actual boundary is considered a lesser error than if the hypothesized boundary is off by, say, 100 words.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.9641607403755188}]}, {"text": "The evaluation metric reflects the probability that two positions in the corpus probed at random and separated by a distance of k words are correctly classified as belonging to the same story or not.", "labels": [], "entities": []}, {"text": "If the two words belong to the same topic segment, but are erroneously claimed to be in different topic segments by the segmenter, then this will increase the system's false alarm probability.", "labels": [], "entities": [{"text": "false alarm probability", "start_pos": 168, "end_pos": 191, "type": "METRIC", "confidence": 0.7767161329587301}]}, {"text": "Conversely, if the two words are in different topic segments, but are erroneously marked to be in the same segment, this will contribute to the miss probability.", "labels": [], "entities": [{"text": "miss probability", "start_pos": 144, "end_pos": 160, "type": "METRIC", "confidence": 0.9739356637001038}]}, {"text": "The false alarm and miss rates are defined as averages overall possible probe positions with distance k.", "labels": [], "entities": [{"text": "false alarm and miss rates", "start_pos": 4, "end_pos": 30, "type": "METRIC", "confidence": 0.7613921523094177}]}, {"text": "Formally, miss and false alarm rates are computed as 5 where the CMis~ = 1 is the cost of amiss, CFalseAlarm : 1 is the cost of a false alarm, and Pseg = 0.3 is the a priori probability of a segment being within an interval of k words or A seconds on the TDT2 training corpus.", "labels": [], "entities": [{"text": "miss", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.967966616153717}, {"text": "CFalseAlarm", "start_pos": 97, "end_pos": 108, "type": "METRIC", "confidence": 0.8900039792060852}, {"text": "Pseg", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9976828098297119}, {"text": "TDT2 training corpus", "start_pos": 255, "end_pos": 275, "type": "DATASET", "confidence": 0.9211970369021097}]}], "tableCaptions": [{"text": " Table 1  Segmentation error rates for various chopping criteria, using true words of the larger  development data set.", "labels": [], "entities": []}, {"text": " Table 3  Segmentation error rates with the language model only (LM), the combined HMM using all  prosodic features (CM-HMM-all), the combined HMM using only pause duration and turn  features (CM-HMM-pause-turn), and using only pause duration, turn, and gender features  (CM-HMM-pause-turn-gender).", "labels": [], "entities": []}]}