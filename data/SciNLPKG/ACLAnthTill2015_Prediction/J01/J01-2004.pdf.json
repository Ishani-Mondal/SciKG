{"title": [{"text": "Probabilistic Top-Down Parsing and Language Modeling", "labels": [], "entities": [{"text": "Language Modeling", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.692020907998085}]}], "abstractContent": [{"text": "This paper describes the functioning of a broad-coverage probabilistic top-down parser, and its application to the problem of language modeling for speech recognition.", "labels": [], "entities": [{"text": "broad-coverage probabilistic top-down parser", "start_pos": 42, "end_pos": 86, "type": "TASK", "confidence": 0.5834459662437439}, {"text": "language modeling", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.7270838916301727}, {"text": "speech recognition", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.7866552472114563}]}, {"text": "The paper first introduces key notions in language modeling and probabilistic parsing, and briefly reviews some previous approaches to using syntactic structure for language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7571116089820862}, {"text": "language modeling", "start_pos": 165, "end_pos": 182, "type": "TASK", "confidence": 0.7206435203552246}]}, {"text": "A lexicalized probabilistic top-down parser is then presented, which performs very well, in terms of both the accuracy of returned parses and the efficiency with which they are found, relative to the best broad-coverage statistical parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9991036057472229}]}, {"text": "A new language model that utilizes probabilistic top-down parsing is then outlined, and empirical results show that it improves upon previous work in test corpus perplexity.", "labels": [], "entities": []}, {"text": "Interpolation with a trigram model yields an exceptional improvement relative to the improvement observed by other models, demonstrating the degree to which the information captured by our parsing model is orthogonal to that captured by a trigram model.", "labels": [], "entities": []}, {"text": "A small recognition experiment also demonstrates the utility of the model.", "labels": [], "entities": []}], "introductionContent": [{"text": "With certain exceptions, computational linguists have in the past generally formed a separate research community from speech recognition researchers, despite some obvious overlap of interest.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.7652978897094727}]}, {"text": "Perhaps one reason for this is that, until relatively recently, few methods have come out of the natural language processing community that were shown to improve upon the very simple language models still standardly in use in speech recognition systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 226, "end_pos": 244, "type": "TASK", "confidence": 0.7165453433990479}]}, {"text": "In the past few years, however, some improvements have been made over these language models through the use of statistical methods of natural language processing, and the development of innovative, linguistically well-motivated techniques for improving language models for speech recognition is generating more interest among computational linguists.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 273, "end_pos": 291, "type": "TASK", "confidence": 0.7324360311031342}]}, {"text": "While language models built around shallow local dependencies are still the standard in state-of-the-art speech recognition systems, there is reason to hope that better language models can and will be developed by computational linguists for this task.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.755134105682373}]}, {"text": "This paper will examine language modeling for speech recognition from a natural language processing point of view.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7265525758266449}, {"text": "speech recognition", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.774049699306488}]}, {"text": "Some of the recent literature investigating approaches that use syntactic structure in an attempt to capture long-distance dependencies for language modeling will be reviewed.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 140, "end_pos": 157, "type": "TASK", "confidence": 0.7112181037664413}]}, {"text": "A new language model, based on probabilistic top-down parsing, will be outlined and compared with the previous literature, and extensive empirical results will be presented which demonstrate its utility.", "labels": [], "entities": []}, {"text": "Two features of our top-down parsing approach will emerge as key to its success.", "labels": [], "entities": []}, {"text": "First, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.", "labels": [], "entities": []}, {"text": "A left-toright parser whose derivations are not rooted, i.e., with derivations that can consist of disconnected tree fragments, such as an LR or shift-reduce parser, cannot incrementally calculate the probability of each prefix string being generated by the probabilistic grammar, because their derivations include probability mass from unrooted structures.", "labels": [], "entities": []}, {"text": "Only at the point when their derivations become rooted (at the end of the string) can generative string probabilities be calculated from the grammar.", "labels": [], "entities": []}, {"text": "These parsers can calculate word probabilities based upon the parser state--as in--but such a distribution is not generative from the probabilistic grammar.", "labels": [], "entities": []}, {"text": "A parser that is not left to right, but which has rooted derivations, e.g., a headfirst parser, will be able to calculate generative joint probabilities for entire strings; however, it will not be able to calculate probabilities for each word conditioned on previously generated words, unless each derivation generates the words in the string in exactly the same order.", "labels": [], "entities": []}, {"text": "For example, suppose that there are two possible verbs that could be the head of a sentence.", "labels": [], "entities": []}, {"text": "For a head-first parser, some derivations will have the first verb as the head of the sentence, and the second verb will be generated after the first; hence the second verb's probability will be conditioned on the first verb.", "labels": [], "entities": []}, {"text": "Other derivations will have the second verb as the head of the sentence, and the first verb's probability will be conditioned on the second verb.", "labels": [], "entities": []}, {"text": "In such a scenario, there is noway to decompose the joint probability calculated from the set of derivations into the product of conditional probabilities using the chain rule.", "labels": [], "entities": []}, {"text": "Of course, the joint probability can be used as a language model, but it cannot be interpolated on a word-by-word basis with, say, a trigram model, which we will demonstrate is a useful thing to do.", "labels": [], "entities": []}, {"text": "Thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as Earley parsers) or left-corner parsers.", "labels": [], "entities": [{"text": "generative conditional word probabilities", "start_pos": 68, "end_pos": 109, "type": "TASK", "confidence": 0.8107143342494965}]}, {"text": "A second key feature of our approach is that top-down guidance improves the efficiency of the search as more and more conditioning events are extracted from the derivation for use in the probabilistic model.", "labels": [], "entities": []}, {"text": "Because the rooted partial derivation is fully connected, all of the conditioning information that might be extracted from the top-down left context has already been specified, and a conditional probability model built on this information will not impose any additional burden on the search.", "labels": [], "entities": []}, {"text": "In contrast, an Earley or left-corner parser will underspecify certain connections between constituents in the left context, and if some of the underspecified information is used in the conditional probability model,-it will have to become specified.", "labels": [], "entities": []}, {"text": "Of course, this can be done, but at the expense of search efficiency; the more that this is done, the less benefit there is from the underspecification.", "labels": [], "entities": []}, {"text": "A top-down parser will, in contrast, derive an efficiency benefit from precisely the information that is underspecified in these other approaches.", "labels": [], "entities": []}, {"text": "Thus, our top-down parser makes it very easy to condition the probabilistic grammar on an arbitrary number of values extracted from the rooted, fully specified derivation.", "labels": [], "entities": []}, {"text": "This has lead us to a formulation of the conditional probability model in terms of values returned from tree-walking functions that themselves are contextually sensitive.", "labels": [], "entities": []}, {"text": "The top-down guidance that is provided makes this approach quite efficient in practice.", "labels": [], "entities": []}, {"text": "The following section will provide some background in probabilistic context-free grammars and language modeling for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.7616714239120483}]}, {"text": "There will also be a brief review of previous work using syntactic information for language modeling, before we introduce our model in Section 4.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.7488899827003479}]}, {"text": "Three parse trees: (a) a complete parse tree; (b) a complete parse tree with an explicit stop symbol; and (c) a partial parse tree.", "labels": [], "entities": []}], "datasetContent": [{"text": "Perplexity is a standard measure within the speech recognition community for comparing language models.", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8782981634140015}, {"text": "speech recognition community", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.7891057928403219}]}, {"text": "In principle, if two models are tested on the same test corpus, the model that assigns the lower perplexity to the test corpus is the model closest to the true distribution of the language, and thus better as a prior model for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 227, "end_pos": 245, "type": "TASK", "confidence": 0.7657749950885773}]}, {"text": "Perplexity is the exponential of the cross entropy, which we will define next.", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9749199748039246}]}, {"text": "Given a random variable X with distribution p and a probability model q, the cross entropy, H(p, q) is defined as follows: xcX Let p be the true distribution of the language.", "labels": [], "entities": []}, {"text": "Then, under certain assumptions, given a large enough sample, the sample mean of the negative log probability of a model will converge to its cross entropy with the true model.", "labels": [], "entities": []}, {"text": "14 That is H(p,q) = -lira 1_ logq(w~) r/--+ Oo n where w~ is a string of the language L.", "labels": [], "entities": []}, {"text": "In practice, one takes a large sample of the language, and calculates the negative log probability of the sample, normalized by its size.", "labels": [], "entities": []}, {"text": "15 The lower the cross entropy (i.e., the higher the probability the model assigns to the sample), the better the model.", "labels": [], "entities": []}, {"text": "Usually this is reported in terms of perplexity, which we will do as well.", "labels": [], "entities": []}, {"text": "16 Some of the trials discussed below will report results in terms of word and/or sentence error rate, which are obtained when the language model is embedded in a speech recognition system.", "labels": [], "entities": [{"text": "sentence error rate", "start_pos": 82, "end_pos": 101, "type": "METRIC", "confidence": 0.631768137216568}]}, {"text": "Word error rate is the number of deletion, insertion, or substitution errors per 100 words.", "labels": [], "entities": [{"text": "Word error rate", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.6870360573132833}]}, {"text": "Sentence error rate is the number of sentences with one or more errors per 100 sentences.", "labels": [], "entities": [{"text": "Sentence error rate", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.7097181777159373}]}, {"text": "Statistical parsers are typically evaluated for accuracy at the constituent level, rather than simply whether or not the parse that the parser found is completely corrector not.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9989560842514038}]}, {"text": "A constituent for evaluation purposes consists of a label (e.g., NP) and a span (beginning and ending word positions).", "labels": [], "entities": []}, {"text": "For example, in, there is a VP that spans the words \"chased the ball\".", "labels": [], "entities": []}, {"text": "Evaluation is carried out on a hand-parsed test corpus, and the manual parses are treated as correct.", "labels": [], "entities": []}, {"text": "We will call the manual parse GOLD and the parse that the parser returns TEST.", "labels": [], "entities": [{"text": "GOLD", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.8942081928253174}, {"text": "TEST", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9911023378372192}]}, {"text": "Precision is the number of common constituents in GOLD and TEST divided by the number of constituents in TEST.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9919722080230713}, {"text": "GOLD", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.6792974472045898}, {"text": "TEST", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.42690300941467285}, {"text": "TEST", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.9365261197090149}]}, {"text": "Recall is the number of common constituents in GOLD and TEST divided by the number of constituents in GOLD.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9884334206581116}, {"text": "GOLD", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.7417217493057251}, {"text": "TEST", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9221235513687134}, {"text": "GOLD", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.934613049030304}]}, {"text": "Following standard practice, we will be reporting scores only for non-part-of-speech constituents, which are called labeled recall (LR) and labeled precision (LP).", "labels": [], "entities": [{"text": "recall (LR)", "start_pos": 124, "end_pos": 135, "type": "METRIC", "confidence": 0.9347254931926727}, {"text": "precision (LP)", "start_pos": 148, "end_pos": 162, "type": "METRIC", "confidence": 0.949100449681282}]}, {"text": "Sometimes in figures we will plot their average, and also what can be termed the parse error, which is one minus their average.", "labels": [], "entities": [{"text": "parse error", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9435289800167084}]}, {"text": "LR and LP are part of the standard set of PARSEVAL measures of parser quality (.", "labels": [], "entities": [{"text": "LP", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.9568697214126587}]}, {"text": "From this set of measures, we will also include the crossing bracket scores: average crossing brackets (CB), percentage of sentences with no crossing brackets (0 CB), and the percentage of sentences with two crossing brackets or fewer (< 2 CB).", "labels": [], "entities": [{"text": "average crossing brackets (CB)", "start_pos": 77, "end_pos": 107, "type": "METRIC", "confidence": 0.8866373896598816}]}, {"text": "In addition, we show the average number of rule expansions considered per word, that is, the number of rule expansions for which a probability was calculated (see Roark and Charniak), and the average number of analyses advanced to the next priority queue per word.", "labels": [], "entities": []}, {"text": "This is an incremental parser with a pruning strategy and no backtracking.", "labels": [], "entities": []}, {"text": "In such a model, it is possible to commit to a set of partial analyses at a particular point that cannot be completed given the rest of the input string (i.e., the parser can \"garden path\").", "labels": [], "entities": []}, {"text": "In such a case, the parser fails to return a complete parse.", "labels": [], "entities": []}, {"text": "In the event that no complete parse is found, the highest initially ranked parse on the last nonempty priority queue is returned.", "labels": [], "entities": []}, {"text": "All unattached words are then attached at the highest level in the tree.", "labels": [], "entities": []}, {"text": "In such away we predict no new constituents and all incomplete constituents are closed.", "labels": [], "entities": []}, {"text": "This structure is evaluated for precision and recall, which is entirely appropriate for these incomplete as well as complete parses.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994914531707764}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9992086291313171}]}, {"text": "If we fail to identify nodes later in the parse, recall will suffer, and if our early predictions were bad, both precision and recall will suffer.", "labels": [], "entities": [{"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9992699027061462}, {"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.999482274055481}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9985598921775818}]}, {"text": "Of course, the percentage of these failures are reported as well.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Results conditioning on various contextual events, Sections 23-24, modifications following  Chelba and Jelinek.", "labels": [], "entities": [{"text": "conditioning", "start_pos": 18, "end_pos": 30, "type": "METRIC", "confidence": 0.9024039506912231}]}]}