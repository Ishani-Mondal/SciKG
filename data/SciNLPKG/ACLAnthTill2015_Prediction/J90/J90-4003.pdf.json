{"title": [], "abstractContent": [{"text": "Discontinuous constituents-for example, a noun and its modifying adjective separated by words unrelated to them-arc common in variable-word-order languages; Figure I shows examples.", "labels": [], "entities": []}, {"text": "But phrase structure grammars, including ID/LP grammars, require each constituent to be a contiguous series of words.", "labels": [], "entities": [{"text": "phrase structure grammars", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7395164966583252}]}, {"text": "Insofar as standard parsing algorithms are based on phrase structure rules, they are inadequate for parsing such languagesJ The algorithm presented here, however, does not require constituents to be continuous, but merely prefers them so.", "labels": [], "entities": []}, {"text": "It can therefore parse languages in which conventional parsing techniques do notwork.", "labels": [], "entities": [{"text": "parse languages", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.9202448427677155}]}, {"text": "At the same time, because of its preference for nearby attachments, it prefers to make constituents continuous when more than one analysis is possible.", "labels": [], "entities": []}, {"text": "The new algorithm has been used successfully to parse Russian and Latin (Covington 1988, 1990).", "labels": [], "entities": [{"text": "parse Russian and Latin", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.8719511181116104}]}, {"text": "This algorithm uses dependency grammar.", "labels": [], "entities": []}, {"text": "That is, instead of breaking the sentence into phrases and subphrases, it establishes links between individual words.", "labels": [], "entities": []}, {"text": "Each link connects a word (the \"head\") with one of its \"dependents\" (an argument or modifier).", "labels": [], "entities": []}, {"text": "Figure 2 shows how this works.", "labels": [], "entities": []}, {"text": "The arrows point from head to dependent; ahead can have many dependents, but each dependent can have only one head.", "labels": [], "entities": []}, {"text": "Of course the same word can be the head in one link and the dependent in another.", "labels": [], "entities": []}, {"text": "2 Dependency grammar is equivalent to an X-bar theory with only one phrasal bar level (Figure 3)-the dependents of a word are the heads of its sisters.", "labels": [], "entities": [{"text": "Dependency grammar", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.8637688457965851}]}, {"text": "Thus dependency grammar captures the increasingly recognized importance of headship in syntax.", "labels": [], "entities": [{"text": "dependency grammar", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.8378078639507294}]}, {"text": "At the same time, the absence of phrasal nodes from the dependency representation streamlines the search process during parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 120, "end_pos": 127, "type": "TASK", "confidence": 0.965785026550293}]}, {"text": "The parser presupposes a grammar that specifies which words can depend on which.", "labels": [], "entities": []}, {"text": "In the prototype, the grammar consists of unification-based dependency rules (called D-rules) such as:", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}