{"title": [{"text": "A STATISTICAL APPROACH TO MACHINE TRANSLATION", "labels": [], "entities": [{"text": "A", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9262929558753967}, {"text": "STATISTICAL APPROACH", "start_pos": 2, "end_pos": 22, "type": "TASK", "confidence": 0.44691386818885803}, {"text": "TRANSLATION", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.8358692526817322}]}], "abstractContent": [{"text": "In this paper, we present a statistical approach to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8328574001789093}]}, {"text": "We describe the application of our approach to translation from French to English and give preliminary results.", "labels": [], "entities": [{"text": "translation from French to English", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.8820975542068481}]}], "introductionContent": [{"text": "The field of machine translation is almost as old as the modern digital computer.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.782933384180069}]}, {"text": "In 1949 Warren Weaver suggested that the problem be attacked with statistical methods and ideas from information theory, an area which he, Claude Shannon, and others were developing at the time.", "labels": [], "entities": [{"text": "information theory", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7962305843830109}]}, {"text": "Although researchers quickly abandoned this approach, advancing numerous theoretical objections, we believe that the true obstacles lay in the relative impotence of the available computers and the dearth of machinereadable text from which to gather the statistics vital to such an attack.", "labels": [], "entities": []}, {"text": "Today, computers are five orders of magnitude faster than they were in 1950 and have hundreds of millions of bytes of storage.", "labels": [], "entities": []}, {"text": "Large, machine-readable corpora are readily available.", "labels": [], "entities": []}, {"text": "Statistical methods have proven their value in automatic speech recognition () and have recently been applied to lexicography and to natural language processing).", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.6145490904649099}]}, {"text": "We feel that it is time to give them a chance in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.8003453612327576}]}, {"text": "The job of a translator is to render in one language the meaning expressed by a passage of text in another language.", "labels": [], "entities": []}, {"text": "This task is not always straightforward.", "labels": [], "entities": []}, {"text": "For example, the translation of a word may depend on words quite far from it.", "labels": [], "entities": [{"text": "translation of a word", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.8824437707662582}]}, {"text": "Some English translators of Proust's seven volume work Ala Recherche du Temps Perdu have striven to make the first word of the first volume the same as the last word of the last volume because the French original begins and ends with the same word).", "labels": [], "entities": [{"text": "English translators of Proust's seven volume work Ala Recherche du Temps Perdu", "start_pos": 5, "end_pos": 83, "type": "TASK", "confidence": 0.7784651334469135}]}, {"text": "Thus, in its most highly developed form, translation involves a careful study of the original text and may even encompass a detailed analysis of the author's life and circumstances.", "labels": [], "entities": [{"text": "translation", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.9827769994735718}]}, {"text": "We, of course, do not hope to reach these pinnacles of the translator's art.", "labels": [], "entities": []}, {"text": "In this paper, we consider only the translation of individual sentences.", "labels": [], "entities": [{"text": "translation of individual sentences", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.8569603711366653}]}, {"text": "Usually, there are many acceptable translations of a particular sentence, the choice among them being largely a matter of taste.", "labels": [], "entities": []}, {"text": "We take the view that every sentence in one language is a possible translation of any sentence in the other.", "labels": [], "entities": []}, {"text": "We assign to every pair of sentences (S, T) a probability, Pr(TIS), to be interpreted as the probability that a translator will produce T in the target language when presented with S in the source language.", "labels": [], "entities": [{"text": "Pr(TIS)", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9338822215795517}]}, {"text": "We expect Pr(TIS) to be very small for pairs like (Le matin je me brosse les dents lPresident Lincoln was a good lawyer) and relatively large for pairs like (Le president Lincoln btait un bon avocat l President Lincoln was a good lawyer).", "labels": [], "entities": [{"text": "Pr(TIS)", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8616587370634079}]}, {"text": "We view the problem of machine translation then as follows.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7876607179641724}]}, {"text": "Given a sentence T in the target language, we seek the sentence S from which the translator produced T.", "labels": [], "entities": []}, {"text": "We know that our chance of error is minimized by choosing that sentence S that is most probable given T.", "labels": [], "entities": [{"text": "error", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.7203493714332581}]}, {"text": "Thus, we wish to choose S so as to maximize Pr(SI T).", "labels": [], "entities": []}, {"text": "Using Bayes' theorem, we can write The denominator on the right of this equation does not depend on S, and so it suffices to choose the S that maximizes the product Pr(S)Pr(TIS).", "labels": [], "entities": []}, {"text": "Call the first factor in this product the language model probability of Sand the second factor the translation probability of T given S.", "labels": [], "entities": []}, {"text": "Although the interaction of these two factors can be quite profound, it may help the reader to think of the translation probability as suggesting words from the source language that might have produced the words that we observe in the target sentence and to think of the language model probability as suggesting an order in which to place these source words.", "labels": [], "entities": []}, {"text": "Thus, as illustrated in, a statistical translation system requires a method for computing language model probabilities, a method for computing translation probabilities, and, finally, a method for searching among possible source sentences S for the one that gives the greatest value for Pr(S)Pr( TIS).", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7282497882843018}]}, {"text": "In the remainder of this paper we describe a simple version of such a system that we have implemented.", "labels": [], "entities": []}, {"text": "In the Pz (S, T) of the pair (S, T) is the product of the probability Pr (S) computed by the language model and the conditional probability Pr (T I S) computed by the translation model.", "labels": [], "entities": []}, {"text": "The parameters of these models are estimated automatically f~om a large database of source-target sentence pairs using a statistical aigoritlim which optimizes, in an appropriate sense, the fit between the models and the data.", "labels": [], "entities": []}, {"text": "T ~ Decoder = argmaxPr(S IT ) = argmaxPr (S,T) s s A Decoder performs the actual translation.", "labels": [], "entities": []}, {"text": "Given a sentence T in the target language, the decoder chooses a viable translation by selecting that sentence in the source langnage for which the probability Pr (S [ T) is maximum.", "labels": [], "entities": []}, {"text": "next section we describe our language model for Pr(S), and in Section 3 we describe our translation model for Pr(T[S).", "labels": [], "entities": []}, {"text": "In Section 4 we describe our search procedure.", "labels": [], "entities": []}, {"text": "In Section 5 we explain how we estimate the parameters of our models from a large database of translated text.", "labels": [], "entities": []}, {"text": "In Section 6 we describe the results of two experiments we performed using these models.", "labels": [], "entities": []}, {"text": "Finally, in Section 7 we conclude with a discussion of some improvements that we intend to implement.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our first experiment, we test our ability to estimate parameters for the translation model.", "labels": [], "entities": []}, {"text": "We chose as our English vocabulary the 9,000 most common words in the English part of the Hansard data, and as our French vocabulary the 9,000 most common French words.", "labels": [], "entities": [{"text": "Hansard data", "start_pos": 90, "end_pos": 102, "type": "DATASET", "confidence": 0.9838944673538208}]}, {"text": "For the purposes of this experiment, we replaced all other words with either the unknown English word or the unknown Frenc.h word, as appropriate.", "labels": [], "entities": [{"text": "Frenc.h word", "start_pos": 117, "end_pos": 129, "type": "DATASET", "confidence": 0.8434835076332092}]}, {"text": "We applied the iterative algorithm discussed above in order to estimate some 81 millJion parameters from 40,000 pairs of sentences comprising a total of about 800,000 words in each language.", "labels": [], "entities": []}, {"text": "The algorithm requires an initial guess of the parameters.", "labels": [], "entities": []}, {"text": "We assumted that each of the 9,000 French words was equally probable as a translation of any of the 9,000 English words; we assumed that each of the fertilities from 0 to 25 was equally probable for each of the 9,000 English words; and finally, we assumed that each target position was equally probable given each source position and target length.", "labels": [], "entities": []}, {"text": "Thus, our initial choices contained very little information about either French or English.", "labels": [], "entities": []}, {"text": "Fi[gure 4 shows the translation and fertility probabilities we estimated for the English word the.", "labels": [], "entities": []}, {"text": "We see that, according to the model, the translates most frequently into the French articles le and la.", "labels": [], "entities": []}, {"text": "This is not surprising, of course, but we emphasize that it is determined completely automatically by the estimation process.", "labels": [], "entities": []}, {"text": "In some sense, this correspondence is inherent in the sentence pairs themselves.", "labels": [], "entities": []}, {"text": "shows these probabilities for the English word not.", "labels": [], "entities": []}, {"text": "As expected, the French word pas appears as a highly probable translation.", "labels": [], "entities": []}, {"text": "Also, the fertility probabilities indicate that not translates most often into two French words, a situation consistent with the fact that negative French sentences contain the auxiliary word ne in addition to a primary negative word such as pas or rien.", "labels": [], "entities": []}, {"text": ".004 Probabilities for \"the.\"", "labels": [], "entities": []}, {"text": "For both of these words, we could easily have discovered the same information from a dictionary.", "labels": [], "entities": []}, {"text": "In, we seethe trained parameters for the English word hear.", "labels": [], "entities": []}, {"text": "As we would expect, various forms of the French word entendre appear as possible translations, but the most probable translation is the French word bravo.", "labels": [], "entities": []}, {"text": "When we look at the fertilities here, we see that the probability is about equally divided between fertility 0 and fertility 1.", "labels": [], "entities": []}, {"text": "The reason for this is that the English speaking members of parliament express their approval by shouting Hear, hear/, while the French speaking ones say Bravo/The translation model has learned that usually two hears produce one bravo by having one of them produce the bravo and the other produce nothing.", "labels": [], "entities": [{"text": "translation", "start_pos": 164, "end_pos": 175, "type": "TASK", "confidence": 0.955267071723938}]}, {"text": "A given pair of sentences has many possible alignments, since each target word can be aligned with any source word.", "labels": [], "entities": []}, {"text": "A translation model will assign significant probability only to some of the possible alignments, and we can gain further insight about the model by examining the alignments that it considers most probable.", "labels": [], "entities": []}, {"text": "We show one such alignment in.", "labels": [], "entities": []}, {"text": "Observe that, quite reasonably, not is aligned with ne and pas, while implemented is aligned with the phrase mises en application.", "labels": [], "entities": []}, {"text": "We can also see here Probabilities for \"hear.\" a deficiency of the model since intuitively we feel that will and be act in concert to produce seront while the model aligns will with seront but aligns be with nothing.", "labels": [], "entities": []}, {"text": "In our second experiment, we used the statistical approach to translate from French to English.", "labels": [], "entities": [{"text": "translate from French to English", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.8487315773963928}]}, {"text": "To have a manageable task, we limited the English vocabulary to the 1,000 most frequently used words in the English part of the Hansard corpus.", "labels": [], "entities": [{"text": "Hansard corpus", "start_pos": 128, "end_pos": 142, "type": "DATASET", "confidence": 0.980717808008194}]}, {"text": "We chose the French vocabulary to be the 1,700 most frequently used French words in translations of sentences that were completely covered by the 1,000-word English vocabulary.", "labels": [], "entities": []}, {"text": "We estimated the 17 million parameters of the translation model from 117,000 pairs of sentences that were completely covered by both our French and English vocabularies.", "labels": [], "entities": []}, {"text": "We estimated the parameters of the bigram language model from 570,000 sentences from the English part of the Hansard data.", "labels": [], "entities": [{"text": "Hansard data", "start_pos": 109, "end_pos": 121, "type": "DATASET", "confidence": 0.9885152876377106}]}, {"text": "These sentences contain about 12 million words altogether and are not restricted to sentences completely covered by our vocabulary.", "labels": [], "entities": []}, {"text": "We used our search procedure to decode 73 new French sentences from elsewhere in the Hansard data.", "labels": [], "entities": [{"text": "Hansard data", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.9852909743785858}]}, {"text": "We assigned each of the resulting sentences a category according to the following criteria.", "labels": [], "entities": []}, {"text": "If the decoded sentence was exactly the same as the actual Hansard translation, we assigned the sentence to the exact category.", "labels": [], "entities": [{"text": "Hansard translation", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.8854577243328094}]}, {"text": "If it conveyed the same meaning as the Hansard translation but in slightly different words, we assigned it to the alternate category.", "labels": [], "entities": [{"text": "Hansard translation", "start_pos": 39, "end_pos": 58, "type": "DATASET", "confidence": 0.9420186579227448}]}, {"text": "If the decoded sentence was a legitimate translation of the French sentence but did not convey the same meaning as the Hansard translation, we assigned it to the different category.", "labels": [], "entities": [{"text": "Hansard translation", "start_pos": 119, "end_pos": 138, "type": "DATASET", "confidence": 0.9275804460048676}]}, {"text": "If it made sense as an English sentence but could not be interpreted as a translation of the French sentence, we assigned it to the wrong category.", "labels": [], "entities": []}, {"text": "Finally, if the decoded sentence was grammatically deficient, we assigned it to the ungrammatical category.", "labels": [], "entities": []}, {"text": "An example from each category is shown in, and our decoding results are summarized in.", "labels": [], "entities": []}, {"text": "Only 5% of the sentences fell into the exact category.", "labels": [], "entities": []}, {"text": "However, we feel that a decoded sentence that is in any of the first three categories (exact, alternate, or different) represents a reasonable translation.", "labels": [], "entities": []}, {"text": "By this criterion, the system performed successfully 48% of the time.", "labels": [], "entities": []}, {"text": "As an alternate measure of the system's performance, one of us corrected each of the sentences in the last three categories (different, wrong, and ungrammatical) to either the exact or the alternate category.", "labels": [], "entities": []}, {"text": "Counting one stroke for each letter that must be deleted and one stroke for each letter that must be inserted, 776 strokes were needed to repair all of the decoded sentences.", "labels": [], "entities": []}, {"text": "This compares with the 1,916 strokes required to generate all of the Hansard translations from scratch.", "labels": [], "entities": [{"text": "Hansard translations", "start_pos": 69, "end_pos": 89, "type": "DATASET", "confidence": 0.9337504208087921}]}, {"text": "Thus, to the extent that translation time can be equated with key strokes, the system reduces the work by about 60%.", "labels": [], "entities": [{"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.946307361125946}]}], "tableCaptions": []}