{"title": [{"text": "Discriminative Sentence Compression with Soft Syntactic Evidence", "labels": [], "entities": [{"text": "Discriminative Sentence Compression", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6733923455079397}]}], "abstractContent": [{"text": "We present a model for sentence compression that uses a discriminative large-margin learning framework coupled with a novel feature set defined on compressed bigrams as well as deep syntactic representations provided by auxiliary dependency and phrase-structure parsers.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7829212248325348}]}, {"text": "The parsers are trained out-of-domain and contain a significant amount of noise.", "labels": [], "entities": []}, {"text": "We argue that the discriminative nature of the learning algorithm allows the model to learn weights relative to any noise in the feature set to optimize compression accuracy directly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9306332468986511}]}, {"text": "This differs from current state-of-the-art models (Knight and Marcu, 2000) that treat noisy parse trees, for both compressed and uncompressed sentences, as gold standard when calculating model parameters.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ability to compress sentences grammatically with minimal information loss is an important problem in text summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.738470733165741}]}, {"text": "Most summarization systems are evaluated on the amount of relevant information retained as well as their compression rate.", "labels": [], "entities": [{"text": "summarization", "start_pos": 5, "end_pos": 18, "type": "TASK", "confidence": 0.9723169207572937}]}, {"text": "Thus, returning highly compressed, yet informative, sentences allows summarization systems to return larger sets of sentences and increase the overall amount of information extracted.", "labels": [], "entities": [{"text": "summarization", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.969231903553009}]}, {"text": "We focus on the particular instantiation of sentence compression when the goal is to produce the compressed version solely by removing words or phrases from the original, which is the most common setting in the literature).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.7221935242414474}]}, {"text": "In this framework, the goal is to find the shortest substring of the original sentence that conveys the most important aspects of the meaning.", "labels": [], "entities": []}, {"text": "We will work in a supervised learning setting and assume as input a training set T =(x t , y t ) |T | t=1 of original sentences x t and their compressions y t . We use the Ziff-Davis corpus, which is a set of 1087 pairs of sentence/compression pairs.", "labels": [], "entities": []}, {"text": "Furthermore, we use the same 32 testing examples from and the rest for training, except that we holdout 20 sentences for the purpose of development.", "labels": [], "entities": []}, {"text": "A handful of sentences occur twice but with different compressions.", "labels": [], "entities": []}, {"text": "We randomly select a single compression for each unique sentence in order to create an unambiguous training set.", "labels": [], "entities": []}, {"text": "Examples from this data set are given in.", "labels": [], "entities": []}, {"text": "Formally, sentence compression aims to shorten a sentence x = x 1 . .", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7396928369998932}]}, {"text": "x n into a substring y = y 1 . .", "labels": [], "entities": []}, {"text": "y m , where y i \u2208 {x 1 , . .", "labels": [], "entities": []}, {"text": "We define the function I(y i ) \u2208 {1, . .", "labels": [], "entities": []}, {"text": ", n} that maps wordy i in the compression to the index of the word in the original sentence.", "labels": [], "entities": []}, {"text": "Finally we include the constraint I(y i ) < I(y i+1 ), which forces each word in x to occur at most once in the compression y.", "labels": [], "entities": []}, {"text": "Compressions are evaluated on three criteria,", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the same experimental methodology as.", "labels": [], "entities": []}, {"text": "We provide every compression to four judges and ask them to evaluate each one for grammaticality and importance on a scale from 1 to 5.", "labels": [], "entities": []}, {"text": "For each of the 32 sentences in our test set we ask the judges to evaluate three systems: human annotated, the decision tree model of Knight and Marcu (2000) and our system.", "labels": [], "entities": []}, {"text": "The judges were told all three compressions were automatically generated and the order in which they were presented was randomly chosen for each sentence.", "labels": [], "entities": []}, {"text": "We compared our system to the decision tree model of Knight and Marcu instead of the noisy-channel model since both performed nearly as well in their evaluation, and the compression rate of the decision tree model is nearer to our system (around 57-58%).", "labels": [], "entities": []}, {"text": "The noisy-channel model typically returned longer compressions.", "labels": [], "entities": []}, {"text": "We present the average score overall judges as well as the standard deviation.", "labels": [], "entities": []}, {"text": "The evaluation for the decision tree system of Knight and Marcu is strikingly similar to the original evaluation in their work.", "labels": [], "entities": []}, {"text": "This provides strong evidence that the evaluation criteria in both cases were very similar.", "labels": [], "entities": []}, {"text": "shows that all models had similar com- pressions rates, with humans preferring to compress a little more aggressively.", "labels": [], "entities": [{"text": "com- pressions rates", "start_pos": 34, "end_pos": 54, "type": "METRIC", "confidence": 0.920565128326416}]}, {"text": "Not surprisingly, the human compressions are practically all grammatical.", "labels": [], "entities": [{"text": "human compressions", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7388596832752228}]}, {"text": "A quick scan of the evaluations shows that the few ungrammatical human compressions were for sentences that were not really grammatical in the first place.", "labels": [], "entities": []}, {"text": "Of greater interest is that the compressions of our system are typically more grammatical than the decision tree model of Knight and Marcu.", "labels": [], "entities": []}, {"text": "When looking at importance, we see that our system actually does the best -even better than humans.", "labels": [], "entities": []}, {"text": "The most likely reason for this is that our model returns longer sentences and is thus less likely to prune away important information.", "labels": [], "entities": []}, {"text": "For example, consider the sentence The chemical etching process used for glare protection is effective and will help if your office has the fluorescent-light overkill that's typical in offices The human compression was Glare protection is effective, whereas our model compressed the sentence to The chemical etching process used for glare protection is effective.", "labels": [], "entities": [{"text": "glare protection", "start_pos": 73, "end_pos": 89, "type": "TASK", "confidence": 0.9076055288314819}, {"text": "Glare protection", "start_pos": 219, "end_pos": 235, "type": "TASK", "confidence": 0.6160364001989365}, {"text": "glare protection", "start_pos": 333, "end_pos": 349, "type": "TASK", "confidence": 0.8855567276477814}]}, {"text": "A primary reason that our model does better than the decision tree model of Knight and Marcu is that on a handful of sentences, the decision tree compressions were a single word or noun-phrase.", "labels": [], "entities": [{"text": "decision tree compressions", "start_pos": 132, "end_pos": 158, "type": "TASK", "confidence": 0.6367077032725016}]}, {"text": "For such sentences the evaluators typically rated the compression a 1 for both grammaticality and importance.", "labels": [], "entities": []}, {"text": "In contrast, our model never failed in such drastic ways and always output something reasonable.", "labels": [], "entities": []}, {"text": "This is quantified in the standard deviation of the two systems.", "labels": [], "entities": []}, {"text": "Though these results are promising, more large scale experiments are required to really ascertain the significance of the performance increase.", "labels": [], "entities": []}, {"text": "Ideally we could sample multiple training/testing splits and use all sentences in the data set to evaluate the systems.", "labels": [], "entities": []}, {"text": "However, since these systems require human evaluation we did not have the time or the resources to conduct these experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4.1. The first shows", "labels": [], "entities": []}]}