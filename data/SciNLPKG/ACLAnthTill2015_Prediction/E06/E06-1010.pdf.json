{"title": [], "abstractContent": [{"text": "We investigate a series of graph-theoretic constraints on non-projective dependency parsing and their effect on expressivity, i.e. whether they allow naturally occurring syntactic constructions to be adequately represented, and efficiency, i.e. whether they reduce the search space for the parser.", "labels": [], "entities": []}, {"text": "In particular, we define anew measure for the degree of non-projectivity in an acyclic dependency graph obeying the single-head constraint.", "labels": [], "entities": []}, {"text": "The constraints are evaluated experimentally using data from the Prague Dependency Treebank and the Danish Dependency Treebank.", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.9800215363502502}, {"text": "Danish Dependency Treebank", "start_pos": 100, "end_pos": 126, "type": "DATASET", "confidence": 0.9554528792699178}]}, {"text": "The results indicate that, whereas complete linguistic coverage in principle requires unrestricted non-projective dependency graphs, limiting the degree of non-projectivity to at most 2 can reduce average running time from quadratic to linear, while excluding less than 0.5% of the dependency graphs found in the two treebanks.", "labels": [], "entities": []}, {"text": "This is a substantial improvement over the commonly used projective approximation (degree 0), which excludes 15-25% of the graphs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven approaches to syntactic parsing has until quite recently been limited to representations that do not capture non-local dependencies.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.8893486261367798}]}, {"text": "This is true regardless of whether representations are based on constituency, where such dependencies are traditionally represented by empty categories and coindexation to avoid explicitly discontinuous constituents, or on dependency, where it is more common to use a direct encoding of so-called nonprojective dependencies.", "labels": [], "entities": []}, {"text": "While this \"surface dependency approximation\" () maybe acceptable for certain applications of syntactic parsing, it is clearly not adequate as a basis for deep semantic interpretation, which explains the growing body of research devoted to different methods for correcting this approximation.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7496680021286011}, {"text": "deep semantic interpretation", "start_pos": 155, "end_pos": 183, "type": "TASK", "confidence": 0.6418783167997996}]}, {"text": "Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations () or in the categories used to label arcs in dependency representations.", "labels": [], "entities": []}, {"text": "By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures.", "labels": [], "entities": []}, {"text": "Notable exceptions are, where discontinuous phrase structure grammar parsing is explored, and, where nonprojective dependency structures are derived using spanning tree algorithms from graph theory.", "labels": [], "entities": [{"text": "phrase structure grammar parsing", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.7553807348012924}]}, {"text": "One question that arises if we want to pursue the structure-based approach is how to constrain the class of permissible structures.", "labels": [], "entities": []}, {"text": "On the one hand, we want to capture all the constructions that are found in natural languages, or at least to provide a much better approximation than before.", "labels": [], "entities": []}, {"text": "On the other hand, it must still be possible for the parser not only to search the space of permissible structures in an efficient way but also to learn to select the most appropriate structure fora given sentence with sufficient accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 230, "end_pos": 238, "type": "METRIC", "confidence": 0.9898279905319214}]}, {"text": "This is the usual tradeoff between expressivity and complexity, where a less restricted class of permissible structures can capture more complex constructions, but where the enlarged search space makes parsing harder with respect to both accuracy and efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 238, "end_pos": 246, "type": "METRIC", "confidence": 0.9977803826332092}]}, {"text": "Whereas extensions to context-free grammar have been studied quite extensively, there are very few corresponding results for dependency-based systems.", "labels": [], "entities": []}, {"text": "Since proved that his projective dependency grammar is weakly equivalent to context-free grammar, have shown that the recognition problem fora dependency grammar that can define arbitrary non-projective structures is NP complete, but there are no results for systems of intermediate complexity.", "labels": [], "entities": []}, {"text": "The pseudo-projective grammar proposed by can be parsed in polynomial time and captures non-local dependencies through a form of gap-threading, but the structures generated by the grammar are strictly projective.", "labels": [], "entities": []}, {"text": "Moreover, the study of formal grammars is only partially relevant for research on datadriven dependency parsing, where most systems are not grammar-based but rely on inductive inference from treebank data ().", "labels": [], "entities": [{"text": "datadriven dependency parsing", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.5980375111103058}]}, {"text": "For example, despite the results of, perform parsing with arbitrary non-projective dependency structures in O(n 2 ) time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9721776843070984}]}, {"text": "In this paper, we will therefore approach the problem from a slightly different angle.", "labels": [], "entities": []}, {"text": "Instead of investigating formal dependency grammars and their complexity, we will impose a series of graphtheoretic constraints on dependency structures and see how these constraints affect expressivity and parsing efficiency.", "labels": [], "entities": []}, {"text": "The approach is mainly experimental and we evaluate constraints using data from two dependency-based treebanks, the Prague Dependency Treebank () and the Danish Dependency Treebank ().", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 116, "end_pos": 142, "type": "DATASET", "confidence": 0.9603009621302286}, {"text": "Danish Dependency Treebank", "start_pos": 154, "end_pos": 180, "type": "DATASET", "confidence": 0.9539770483970642}]}, {"text": "Expressivity is investigated by examining how large a proportion of the structures found in the treebanks are parsable under different constraints, and efficiency is addressed by considering the number of potential dependency arcs that need to be processed when parsing these structures.", "labels": [], "entities": []}, {"text": "This is a relevant metric for data-driven approaches, where parsing time is often dominated by the computation of model predictions or scores for such arcs.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9779614210128784}]}, {"text": "The parsing experiments are performed with a variant of Covington's algorithm for dependency parsing), using the treebank as an oracle in order to establish an upper bound on accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.978158175945282}, {"text": "dependency parsing", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7969796657562256}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9960561990737915}]}, {"text": "However, the results are relevant fora larger class of algorithms that derive nonprojective dependency graphs by treating every possible word pair as a potential dependency arc.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2 we define dependency graphs, and in section 3 we formulate a number of constraints that can be used to define different classes of dependency graphs, ranging from unrestricted non-projective to strictly projective.", "labels": [], "entities": []}, {"text": "In section 4 we introduce the parsing algorithm used in the experiments, and in section 5 we describe the experimental setup.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9655444025993347}]}, {"text": "In section 6 we present the results of the experiments and discuss their implications for non-projective dependency parsing.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 90, "end_pos": 123, "type": "TASK", "confidence": 0.6409678955872854}]}, {"text": "We conclude in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments are based on data from two treebanks.", "labels": [], "entities": []}, {"text": "The Prague Dependency Treebank (PDT) contains 1.5M words of newspaper text, annotated in three layers) according to the theoretical framework of Functional Generative Description (.", "labels": [], "entities": [{"text": "Prague Dependency Treebank (PDT)", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.9318505128224691}, {"text": "Functional Generative Description", "start_pos": 145, "end_pos": 178, "type": "TASK", "confidence": 0.6601177155971527}]}, {"text": "Our experiments concern only the analytical layer and are based on the dedicated training section of the treebank.", "labels": [], "entities": []}, {"text": "The Danish Dependency Treebank (DDT) comprises 100K words of text selected from the Danish PAROLE corpus, with annotation of primary and secondary dependencies based on Discontinuous Grammar (.", "labels": [], "entities": [{"text": "Danish Dependency Treebank (DDT)", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.8943828741709391}, {"text": "Danish PAROLE corpus", "start_pos": 84, "end_pos": 104, "type": "DATASET", "confidence": 0.8001463810602824}]}, {"text": "Only primary dependencies are considered in the experiments, which are based on 80% of the data (again the standard training section).", "labels": [], "entities": []}, {"text": "The experiments are performed by parsing each sentence of the treebanks while using the gold standard dependency graph for that sentence as an oracle to resolve the nondeterministic choice in the LINK(i, j) operation as follows: where E g is the arc relation of the gold standard dependency graph G g and E is the arc relation of the graph G built by the parsing algorithm.", "labels": [], "entities": []}, {"text": "Conditions are varied by cumulatively adding constraints in the following order:: Proportion of dependency arcs and complete graphs correctly parsed under different constraints The purpose of the experiments is to study how different constraints influence expressivity and running time.", "labels": [], "entities": []}, {"text": "The first dimension is investigated by comparing the dependency graphs produced by the parser with the gold standard dependency graphs in the treebank.", "labels": [], "entities": []}, {"text": "This gives an indication of the extent to which naturally occurring structures can be parsed correctly under different constraints.", "labels": [], "entities": []}, {"text": "The results are reported both as the proportion of individual dependency arcs (per token) and as the proportion of complete dependency graphs (per sentence) recovered correctly by the parser.", "labels": [], "entities": []}, {"text": "In order to study the effects on running time, we examine how the number of active pairs varies as a function of sentence length.", "labels": [], "entities": []}, {"text": "Whereas the asymptotic worst-case complexity remains O(n 2 ) under all conditions, the average running time will decrease with the number of active pairs if the LINK(i, j) operation is more expensive than the call to PERMISSIBLE(i, j, C).", "labels": [], "entities": [{"text": "O", "start_pos": 53, "end_pos": 54, "type": "METRIC", "confidence": 0.9908201098442078}, {"text": "LINK", "start_pos": 161, "end_pos": 165, "type": "METRIC", "confidence": 0.9860411286354065}, {"text": "PERMISSIBLE", "start_pos": 217, "end_pos": 228, "type": "METRIC", "confidence": 0.9242991209030151}]}, {"text": "For data-driven dependency parsing, this is relevant not only for parsing efficiency, but also because it may improve training efficiency by reducing the number of pairs that need to be included in the training data.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.6604682505130768}, {"text": "parsing", "start_pos": 66, "end_pos": 73, "type": "TASK", "confidence": 0.9872337579727173}]}, {"text": "displays the proportion of dependencies (single arcs) and sentences (complete graphs) in the two treebanks that can be parsed exactly with Covington's algorithm under different constraints.", "labels": [], "entities": []}, {"text": "Starting at the bottom of the table, we see that the unrestricted algorithm (None) of course reproduces all the graphs exactly, but we also see that the constraints SINGLE-HEAD and ACYCLICITY do not put any real restrictions on expressivity with regard to the data at hand.", "labels": [], "entities": [{"text": "SINGLE-HEAD", "start_pos": 165, "end_pos": 176, "type": "METRIC", "confidence": 0.946224570274353}]}, {"text": "However, this is primarily a reflection of the design of the treebank annotation schemes, which in themselves require dependency graphs to obey these constraints.", "labels": [], "entities": []}, {"text": "If we go to the other end of the table, we see that PROJECTIVITY, on the other hand, has a very noticeable effect on the parser's ability to capture the structures found in the treebanks.", "labels": [], "entities": [{"text": "PROJECTIVITY", "start_pos": 52, "end_pos": 64, "type": "METRIC", "confidence": 0.9146561622619629}]}, {"text": "Almost 25% of the sentences in PDT, and more than 15% in DDT, are beyond its reach.", "labels": [], "entities": [{"text": "PDT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.6960363388061523}, {"text": "DDT", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.8284079432487488}]}, {"text": "At the level of individual dependencies, the effect is less conspicuous, but it is still the casein PDT that one dependency in twenty-five cannot be found by the parser even with a perfect oracle (one in fifty in DDT).", "labels": [], "entities": []}, {"text": "It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves).", "labels": [], "entities": []}, {"text": "This is due to error propagation, since some projective arcs are blocked from the parser's view because of missing non-projective arcs.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.679888516664505}]}], "tableCaptions": [{"text": " Table 2: Quadratic curve estimation for y = ax + bx 2 (y = number of active pairs, x = number of words)", "labels": [], "entities": [{"text": "Quadratic curve estimation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.5602020521958669}]}]}