{"title": [{"text": "Investigating a Generic Paraphrase-based Approach for Relation Extraction", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.9616546034812927}]}], "abstractContent": [{"text": "Unsupervised paraphrase acquisition has been an active research field in recent years, but its effective coverage and performance have rarely been evaluated.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7868312001228333}]}, {"text": "We propose a generic paraphrase-based approach for Relation Extraction (RE), aiming at a dual goal: obtaining an applicative evaluation scheme for paraphrase acquisition and obtaining a generic and largely unsupervised configuration for RE.", "labels": [], "entities": [{"text": "Relation Extraction (RE)", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.8545674800872802}, {"text": "paraphrase acquisition", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.812727302312851}]}, {"text": "We analyze the potential of our approach and evaluate an implemented prototype of it using an RE dataset.", "labels": [], "entities": [{"text": "RE dataset", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.7375231236219406}]}, {"text": "Our findings reveal a high potential for unsupervised paraphrase acquisition.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7836805880069733}]}, {"text": "We also identify the need for novel robust models for matching paraphrases in texts, which should address syntactic complexity and variability.", "labels": [], "entities": []}], "introductionContent": [{"text": "A crucial challenge for semantic NLP applications is recognizing the many different ways for expressing the same information.", "labels": [], "entities": []}, {"text": "This semantic variability phenomenon was addressed within specific applications, such as question answering, information extraction and information retrieval.", "labels": [], "entities": [{"text": "question answering", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.8965875804424286}, {"text": "information extraction", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.8563603162765503}, {"text": "information retrieval", "start_pos": 136, "end_pos": 157, "type": "TASK", "confidence": 0.8252987265586853}]}, {"text": "Recently, the problem was investigated within generic application-independent paradigms, such as paraphrasing and textual entailment.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.6982602477073669}]}, {"text": "Eventually, it would be most appealing to apply generic models for semantic variability to concrete applications.", "labels": [], "entities": []}, {"text": "This paper investigates the applicability of a generic \"paraphrase-based\" approach to the Relation Extraction (RE) task, using an available RE dataset of protein interactions.", "labels": [], "entities": [{"text": "Relation Extraction (RE) task", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.8172889848550161}]}, {"text": "RE is highly suitable for such investigation since its goal is to exactly identify all the different variations in which a target semantic relation can be expressed.", "labels": [], "entities": [{"text": "RE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.49982672929763794}]}, {"text": "Taking this route sets up a dual goal: (a) from the generic paraphrasing perspective -an objective evaluation of paraphrase acquisition performance on a concrete application dataset, as well as identifying the additional mechanisms needed to match paraphrases in texts; (b) from the RE perspectiveinvestigating the feasibility and performance of a generic paraphrase-based approach for RE.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.7764790952205658}, {"text": "RE", "start_pos": 386, "end_pos": 388, "type": "TASK", "confidence": 0.9770280122756958}]}, {"text": "Our configuration assumes a set of entailing templates (non-symmetric \"paraphrases\") for the target relation.", "labels": [], "entities": []}, {"text": "For example, for the target relation \"X interact with Y\" we would assume a set of entailing templates as in.", "labels": [], "entities": []}, {"text": "In addition, we require a syntactic matching module that identifies template instances in text.", "labels": [], "entities": []}, {"text": "First, we manually analyzed the proteininteraction dataset and identified all cases in which protein interaction is expressed by an entailing template.", "labels": [], "entities": []}, {"text": "This set a very high idealized upper bound for the recall of the paraphrase-based approach for this dataset.", "labels": [], "entities": [{"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9984637498855591}]}, {"text": "Yet, obtaining high coverage in practice would require effective paraphrase acquisition and lexical-syntactic template matching.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8109039664268494}, {"text": "lexical-syntactic template matching", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.6917555332183838}]}, {"text": "Next, we implemented a prototype that utilizes a state-of-the-art method for learning entailment relations from the web (), the Minipar dependency parser and a syntactic matching module.", "labels": [], "entities": []}, {"text": "As expected, the performance of the implemented system was much lower than the ideal upper bound, yet obtaining quite reasonable practical results given its unsupervised nature.", "labels": [], "entities": []}, {"text": "The contributions of our investigation follow the dual goal set above.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first comprehensive evaluation that measures directly the performance of unsupervised paraphrase acquisition relative to a standard application dataset.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.7814649641513824}]}, {"text": "It is also the first evaluation of a generic paraphrase-based approach for the standard RE setting.", "labels": [], "entities": [{"text": "RE setting", "start_pos": 88, "end_pos": 98, "type": "TASK", "confidence": 0.6782115995883942}]}, {"text": "Our findings are encouraging for both goals, particularly relative to their early maturity level, and reveal constructive evidence for the remaining room for improvement.", "labels": [], "entities": []}], "datasetContent": [{"text": "For development purposes, we randomly split the abstracts into a 60% development set (575 interactions) and a 40% test set (477 interactions).", "labels": [], "entities": []}, {"text": "In order to analyze the potential of our approach, two of the authors manually annotated the 575 interacting protein pairs in the development set.", "labels": [], "entities": []}, {"text": "For each pair the annotators annotated whether it can be identified using only template-based matching, assuming an ideal implementation of the configuration of Section 3.", "labels": [], "entities": []}, {"text": "If it can, the normalized form of the template connecting the two proteins was annotated as well.", "labels": [], "entities": []}, {"text": "The normalized template form is based on the active form of the verb, stripped of the syntactic phenomena listed in.", "labels": [], "entities": []}, {"text": "Additionally, the relevant syntactic phenomena from were annotated for each template instance.", "labels": [], "entities": []}, {"text": "A Kappa value of 0.85 (nearly perfect agreement) was measured for the agreement between the two annotators, regarding whether a protein pair can be identified using the template-based method.", "labels": [], "entities": [{"text": "agreement)", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9638216197490692}]}, {"text": "Additionally, the annotators agreed on 96% of the normalized templates that should be used for the matching.", "labels": [], "entities": []}, {"text": "Finally, the annotators agreed on at least 96% of the cases for each syntactic phenomenon except transparent heads, for which they agreed on 91% of the cases.", "labels": [], "entities": []}, {"text": "This high level of agreement indicates both that templatebased matching is a well defined task and that normalized template form and its syntactic variations are well defined notions.", "labels": [], "entities": [{"text": "templatebased matching", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7163035273551941}]}, {"text": "Several interesting statistics arise from the an-Sentence Annotation We have crystallized a complex between human FGF1 and a two-domain extracellular fragment of human FGFR2.", "labels": [], "entities": []}, {"text": "\u2022 template: 'complex between X and Y' \u2022 transparent head: 'fragment of X' CD30 and its counter-receptor CD30 ligand (CD30L) are members of the TNF-receptor / TNFalpha superfamily and function to regulate lymphocyte survival and differentiation.", "labels": [], "entities": []}, {"text": "\u2022 template: 'X's counter-receptor Y' \u2022 apposition \u2022 co-reference iCdi1, a human G1 and S phase protein phosphatase that associates with Cdk2.", "labels": [], "entities": []}, {"text": "\u2022 template: 'X associate with Y' \u2022 relative clause   Second, for 66% of the template-based pairs at least one syntactic phenomenon was annotated.", "labels": [], "entities": []}, {"text": "contains the occurrence percentage of each phenomenon in the development set.", "labels": [], "entities": []}, {"text": "These results show the need fora powerful syntactic matcher on top of high performance template acquisition, in order to correctly match a template in a sentence.", "labels": [], "entities": []}, {"text": "Third, 175 different normalized templates were identified.", "labels": [], "entities": []}, {"text": "For each template we counted its template instances, the number of times the template occurred, counting only occurrences that express an interaction of a protein pair.", "labels": [], "entities": []}, {"text": "In total, we counted 341 template instances for all 175 templates.", "labels": [], "entities": []}, {"text": "Interestingly, 50% of the template instances (184/341) are instances of the 21 most frequent templates.", "labels": [], "entities": []}, {"text": "This shows that, though protein interaction can be expressed in many ways, writers tend to choose from among just a few common expressions.", "labels": [], "entities": []}, {"text": "presents the most frequent templates.", "labels": [], "entities": []}, {"text": "presents the minimal number of templates required to obtain the range of different recall levels.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9942663311958313}]}, {"text": "Furthermore, we grouped template variants that are based on morphological derivations (e.g. 'X interact with Y' and 'X Y interaction') and found that 4 groups, 'X interact with Y', 'X bind to Y', 'X associate with Y' and 'X complex with Y', together with their morphological derivations, cover 45% of the template instances.", "labels": [], "entities": []}, {"text": "This shows the need to handle generic lexicalsyntactic phenomena, and particularly morphological based variations, separately from the acquisition of normalized lexical syntactic templates.", "labels": [], "entities": []}, {"text": "To conclude, this analysis indicates that the template-based approach provides very high coverage for this RE dataset, and a small number of normalized templates already provides significant recall.", "labels": [], "entities": [{"text": "RE dataset", "start_pos": 107, "end_pos": 117, "type": "DATASET", "confidence": 0.9039585888385773}, {"text": "recall", "start_pos": 191, "end_pos": 197, "type": "METRIC", "confidence": 0.997972309589386}]}, {"text": "However, it is important to (a) develop a model for morphological-based template variations (e.g. as encoded in), and (b) apply accurate parsing and develop syntactic matching models to recognize the rather complex variations of template instantiations in text.", "labels": [], "entities": []}, {"text": "Finally, we note that our particular figures are specific to this dataset and the biological abstracts domain.", "labels": [], "entities": []}, {"text": "However, the annotation and analysis methodologies are general and are suggested as highly effective tools for further research.", "labels": [], "entities": []}, {"text": "To acquire a set of entailing templates we first executed TEASE on the input template 'X subj \u2190 interact and(U ): The dependency parse graph of the sentence \"Prot1 detected and activated Prot2\". relation.", "labels": [], "entities": [{"text": "TEASE", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9938488602638245}]}, {"text": "TEASE learned 118 templates for this relation.", "labels": [], "entities": [{"text": "TEASE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8739407658576965}]}, {"text": "lists the top 18 learned templates that we considered as correct (out of the top 30 templates in TEASE output).", "labels": [], "entities": []}, {"text": "We then extracted interacting protein pair candidates by applying the syntactic matcher to the 119 templates (the 118 learned plus the input template).", "labels": [], "entities": []}, {"text": "Candidate pairs that do not consist of two proteins, as tagged in the input dataset, were filtered out (see Section 4.1; recall that our experiments were applied to the dataset of protein interactions, which isolates the RE task from the protein name recognition task).", "labels": [], "entities": [{"text": "RE task", "start_pos": 221, "end_pos": 228, "type": "TASK", "confidence": 0.8473307192325592}, {"text": "protein name recognition task", "start_pos": 238, "end_pos": 267, "type": "TASK", "confidence": 0.6811735928058624}]}, {"text": "Ina subsequent experiment we iteratively executed TEASE on the 5 top-ranked learned templates to acquire additional relevant templates.", "labels": [], "entities": [{"text": "TEASE", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9807939529418945}]}, {"text": "In total, we obtained 1233 templates that were likely to imply the original input relation.", "labels": [], "entities": []}, {"text": "The syntactic matcher was then reapplied to extract candidate interacting protein pairs using all 1233 templates.", "labels": [], "entities": []}, {"text": "We used the development set to tune a small set of 10 generic hand-crafted transformation rules that handle different syntactic variations.", "labels": [], "entities": []}, {"text": "To handle transparent head nouns, which is the only phenomenon that demonstrates domain dependence, we extracted a set of the 5 most frequent transparent head patterns in the development set, e.g. 'fragment of X'.", "labels": [], "entities": []}, {"text": "In order to compare (roughly) our performance with supervised methods applied to this dataset, as summarized in ( ), we adopted their recall and precision measurement.", "labels": [], "entities": [{"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9993680119514465}, {"text": "precision measurement", "start_pos": 145, "end_pos": 166, "type": "METRIC", "confidence": 0.9729310870170593}]}, {"text": "Their scheme counts over distinct protein pairs per abstract, which yields 283 interacting pairs in our test set and 418 in the development set.", "labels": [], "entities": []}, {"text": "recall precision F 1 input 0.18 0.62 0.28 input + iterative 0.29 0.42 0.34: System results on the test set.", "labels": [], "entities": [{"text": "recall precision F 1 input 0.18 0.62 0.28 input", "start_pos": 0, "end_pos": 47, "type": "METRIC", "confidence": 0.9271130561828613}]}, {"text": "presents our system results for the test set, corresponding to the first two experiments in.", "labels": [], "entities": []}, {"text": "The recall achieved by our current implementation is notably worse than the upper bound of the manual analysis because of two general setbacks of the current syntactic matcher: 1) parsing errors; 2) limited transformation rule coverage.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9992559552192688}]}, {"text": "First, the texts from the biology domain presented quite a challenge for the Minipar parser.", "labels": [], "entities": [{"text": "Minipar parser", "start_pos": 77, "end_pos": 91, "type": "DATASET", "confidence": 0.8620167970657349}]}, {"text": "For example, in the sentences containing the phrase 'X bind specifically to Y' the parser consistently attaches the PP 'to' to 'specifically' instead of to 'bind'.", "labels": [], "entities": []}, {"text": "Thus, the template 'X bind to Y' cannot be directly matched.", "labels": [], "entities": []}, {"text": "Second, we manually created a small number of transformation rules that handle various syntactic phenomena, since we aimed at generic domain independent rules.", "labels": [], "entities": []}, {"text": "The most difficult phenomenon to model with transformation rules is transparent heads.", "labels": [], "entities": []}, {"text": "For example, in \"the dimerization of Prot1 interacts with Prot2\", the transparent head 'dimerization of X' is domain dependent.", "labels": [], "entities": []}, {"text": "Transformation rules that handle such examples are difficult to acquire, unless a domain specific learning approach (either supervised or unsupervised) is used.", "labels": [], "entities": []}, {"text": "Finally, we did not handle co-reference resolution in the current implementation.  and  approached the protein interaction RE task using both handcrafted rules and several supervised Machine Learning techniques, which utilize about 180 manually annotated abstracts for training.", "labels": [], "entities": [{"text": "co-reference resolution", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7661458253860474}, {"text": "protein interaction RE task", "start_pos": 103, "end_pos": 130, "type": "TASK", "confidence": 0.5767894685268402}]}, {"text": "Our results are not directly comparable with theirs because they adopted 10-fold crossvalidation, while we had to divide the dataset into a development and a test set, but a rough comparison is possible.", "labels": [], "entities": []}, {"text": "For the same 30% recall, the rulebased method achieved precision of 62% and the best supervised learning algorithm achieved precision of 73%.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9989161491394043}, {"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9995266199111938}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9993477463722229}]}, {"text": "Comparing to these supervised and domain-specific rule-based approaches our system is noticeably weaker, yet provides useful results given that we supply very little domain specific information and acquire the paraphrasing templates in a fully unsupervised manner.", "labels": [], "entities": []}, {"text": "Still, the matching models need considerable additional research in order to achieve the potential performance suggested by TEASE.", "labels": [], "entities": [{"text": "TEASE", "start_pos": 124, "end_pos": 129, "type": "DATASET", "confidence": 0.7393997311592102}]}, {"text": "tionally, we manually assessed the coverage of the TEASE acquisition algorithm and found that 63% of the distinct pairs can be potentially recognized with the learned templates, assuming an ideal matcher, indicating a significant potential recall for completely unsupervised paraphrase acquisition.", "labels": [], "entities": [{"text": "TEASE acquisition", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7111887484788895}, {"text": "recall", "start_pos": 240, "end_pos": 246, "type": "METRIC", "confidence": 0.9948541522026062}, {"text": "paraphrase acquisition", "start_pos": 275, "end_pos": 297, "type": "TASK", "confidence": 0.753397673368454}]}, {"text": "Finally, we evaluated our current system performance and found it weaker than supervised RE methods, being far from fulfilling the potential indicated in our manual analyses due to insufficient syntactic matching.", "labels": [], "entities": [{"text": "RE", "start_pos": 89, "end_pos": 91, "type": "TASK", "confidence": 0.9588310718536377}]}, {"text": "But, even our current performance maybe considered useful given the very small amount of domain-specific information used by the system.", "labels": [], "entities": []}, {"text": "Most importantly, we believe that our analysis and evaluation methodologies for an RE dataset provide an excellent benchmark for unsupervised learning of paraphrases and entailment rules.", "labels": [], "entities": [{"text": "RE dataset", "start_pos": 83, "end_pos": 93, "type": "DATASET", "confidence": 0.910748153924942}]}, {"text": "In the long run, we plan to develop and improve our acquisition and matching algorithms, in order to realize the observed potential of the paraphrasebased approach.", "labels": [], "entities": [{"text": "acquisition and matching", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.6789629856745402}]}, {"text": "Notably, our findings point to the need to learn generic morphological and syntactic variations in template matching, an area which has rarely been addressed till now.", "labels": [], "entities": [{"text": "template matching", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7044835835695267}]}], "tableCaptions": [{"text": " Table 5: The number of most frequent templates  necessary to reach different recall levels within the  341 template instances.", "labels": [], "entities": [{"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9922418594360352}]}, {"text": " Table 6. TEASE first retrieves  from the Web sentences containing the input tem- plate. From these sentences it extracts variable in- stantiations, termed anchor-sets, which are identi- fied as being characteristic for the input template  based on statistical criteria (first column in Ta- ble 6). Characteristic anchor-sets are assumed to  uniquely identify a specific event or fact. Thus,  any template that appears with such an anchor-set  is assumed to have an entailment relationship with  the input template. Next, TEASE retrieves from  the Web a corpus S of sentences that contain the  characteristic anchor-sets (second column), hop- ing to find occurrences of these anchor-sets within  templates other than the original input template.  Finally, TEASE parses S and extracts templates  that are assumed to entail or be entailed by the  input template. Such templates are identified as", "labels": [], "entities": []}]}