{"title": [{"text": "Computing Consensus Translation from Multiple Machine Translation Systems Using Enhanced Hypotheses Alignment", "labels": [], "entities": [{"text": "Computing Consensus Translation from Multiple Machine Translation", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.6957225927284786}]}], "abstractContent": [{"text": "This paper describes a novel method for computing a consensus translation from the outputs of multiple machine translation (MT) systems.", "labels": [], "entities": [{"text": "consensus translation from the outputs of multiple machine translation (MT)", "start_pos": 52, "end_pos": 127, "type": "TASK", "confidence": 0.7548619459072748}]}, {"text": "The outputs are combined and a possibly new translation hypothesis can be generated.", "labels": [], "entities": []}, {"text": "Similarly to the well-established ROVER approach of (Fiscus, 1997) for combining speech recognition hypotheses, the consensus translation is computed by voting on a confusion network.", "labels": [], "entities": [{"text": "ROVER", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.9111620783805847}, {"text": "speech recognition hypotheses", "start_pos": 81, "end_pos": 110, "type": "TASK", "confidence": 0.7933166821797689}, {"text": "consensus translation", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.6565196961164474}]}, {"text": "To create the confusion network, we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering.", "labels": [], "entities": []}, {"text": "The context of a whole document of translations rather than a single sentence is taken into account to produce the alignment.", "labels": [], "entities": []}, {"text": "The proposed alignment and voting approach was evaluated on several machine translation tasks, including a large vocabulary task.", "labels": [], "entities": [{"text": "alignment and voting", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.652081569035848}, {"text": "machine translation tasks", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.7713478803634644}]}, {"text": "The method was also tested in the framework of multi-source and speech translation.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.6836787611246109}]}, {"text": "On all tasks and conditions, we achieved significant improvements in translation quality, increasing e. g. the BLEU score by as much as 15% relative.", "labels": [], "entities": [{"text": "translation", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.9526618719100952}, {"text": "BLEU score", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9815539121627808}]}], "introductionContent": [{"text": "In this work we describe a novel technique for computing a consensus translation from the outputs of multiple machine translation systems.", "labels": [], "entities": [{"text": "consensus translation from the outputs of multiple machine translation", "start_pos": 59, "end_pos": 129, "type": "TASK", "confidence": 0.6965351336532168}]}, {"text": "Combining outputs from different systems was shown to be quite successful in automatic speech recognition (ASR).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 77, "end_pos": 111, "type": "TASK", "confidence": 0.7732586661974589}]}, {"text": "Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems.", "labels": [], "entities": [{"text": "edit distance alignment", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.5710352261861166}, {"text": "ASR", "start_pos": 162, "end_pos": 165, "type": "TASK", "confidence": 0.949354887008667}]}, {"text": "Some research on multi-engine machine translation has also been performed in recent years.", "labels": [], "entities": [{"text": "multi-engine machine translation", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.6657666166623434}]}, {"text": "The most straightforward approaches simply select, for each sentence, one of the provided hypotheses.", "labels": [], "entities": []}, {"text": "The selection is made based on the scores of translation, language, and other models).", "labels": [], "entities": []}, {"text": "Other approaches combine lattices or N -best lists from several different MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9588239789009094}]}, {"text": "To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices.", "labels": [], "entities": []}, {"text": "However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7684168517589569}]}, {"text": "For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9846253395080566}]}, {"text": "() used the edit distance alignment extended to multiple sequences to construct a confusion network from several translation hypotheses.", "labels": [], "entities": []}, {"text": "This algorithm produces monotone alignments only (i. e. allows insertion, deletion, and substitution of words); it is notable to align translation hypotheses with significantly different word order.", "labels": [], "entities": []}, {"text": "(Jayaraman and) try to overcome this problem.", "labels": [], "entities": []}, {"text": "They introduce a method that allows non-monotone alignments of words in different translation hypotheses for the same sentence.", "labels": [], "entities": []}, {"text": "However, this approach uses many heuristics and is based on the alignment that is performed to calculate a specific MT error measure; the performance improvements are reported only in terms of this measure.", "labels": [], "entities": [{"text": "MT error measure", "start_pos": 116, "end_pos": 132, "type": "METRIC", "confidence": 0.7586685121059418}]}, {"text": "Here, we propose an alignment procedure that explicitly models reordering of words in the hypotheses.", "labels": [], "entities": []}, {"text": "In contrast to existing approaches, the context of the whole document rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment.", "labels": [], "entities": []}, {"text": "Based on the alignment, we construct a confusion network from the (possibly reordered) translation hypotheses, similarly to the approach of ().", "labels": [], "entities": []}, {"text": "Using global system probabilities and other statistical models, the voting procedure selects the best consensus hypothesis from the confusion network.", "labels": [], "entities": []}, {"text": "This consensus translation maybe different from the original translations.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we will describe the computation of consensus translations with our approach.", "labels": [], "entities": [{"text": "consensus translations", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7077775001525879}]}, {"text": "In particular, we will present details of the enhanced alignment and reordering procedure.", "labels": [], "entities": [{"text": "alignment", "start_pos": 55, "end_pos": 64, "type": "TASK", "confidence": 0.9186447262763977}]}, {"text": "A large set of experimental results on several machine translation tasks is presented in Section 3, which is followed by a summary.", "labels": [], "entities": [{"text": "machine translation tasks", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.8325196107228597}]}], "datasetContent": [{"text": "Well-established objective evaluation measures like the word error rate (WER), positionindependent word error rate (PER), and the BLEU score () were used to assess the translation quality.", "labels": [], "entities": [{"text": "word error rate (WER)", "start_pos": 56, "end_pos": 77, "type": "METRIC", "confidence": 0.871879369020462}, {"text": "positionindependent word error rate (PER)", "start_pos": 79, "end_pos": 120, "type": "METRIC", "confidence": 0.8894858360290527}, {"text": "BLEU score", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9860416650772095}]}, {"text": "All measures were computed with respect to multiple reference translations.", "labels": [], "entities": []}, {"text": "The evaluation (as well as the alignment training) was case-insensitive, without considering the punctuation marks.", "labels": [], "entities": [{"text": "alignment", "start_pos": 31, "end_pos": 40, "type": "TASK", "confidence": 0.8860414624214172}]}], "tableCaptions": [{"text": " Table 1: Corpus statistics of the test corpora.", "labels": [], "entities": []}, {"text": " Table 2: Improved translation results for the con- sensus translation computed from 5 translation  outputs on the Chinese-English IWSLT04 task.", "labels": [], "entities": [{"text": "Improved", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9841049313545227}, {"text": "IWSLT04 task", "start_pos": 131, "end_pos": 143, "type": "DATASET", "confidence": 0.7240018546581268}]}, {"text": " Table 3: Improved translation results for the con- sensus translation computed from 4 translation  outputs on the Spanish-English TC-STAR task.", "labels": [], "entities": [{"text": "Improved", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9713563323020935}]}, {"text": " Table 3. Compared to the  best performing single system, the consensus hy- pothesis reduces the WER from 41.0 to 39.1%.  This result is further improved by rescoring the  N -best lists derived from the confusion networks  (N =1000). For rescoring, a word penalty fea- ture, the IBM Model 1, and a 4-gram target lan- guage model were included. The linear interpola- tion weights of these models and the score from  the confusion network were optimized on a sep- arate development set with respect to word error  rate.", "labels": [], "entities": [{"text": "WER", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9933264255523682}, {"text": "IBM Model 1", "start_pos": 279, "end_pos": 290, "type": "DATASET", "confidence": 0.8825653990109762}]}, {"text": " Table 5: Multi-source translation: improvements  in translation quality when computing consen- sus translation using the output of two Chinese- English and two Japanese-English systems on the  IWSLT04 task.  BTEC Chinese-English WER PER BLEU  + Japanese-English  [%] [%]  [%]  worst single system  58.0 41.8 39.5  best single system  51.3 38.6 44.7  consensus of 4 systems 44.9 33.9 49.6", "labels": [], "entities": [{"text": "Multi-source translation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7857306599617004}, {"text": "IWSLT04", "start_pos": 194, "end_pos": 201, "type": "DATASET", "confidence": 0.8265170454978943}, {"text": "BTEC Chinese-English", "start_pos": 209, "end_pos": 229, "type": "DATASET", "confidence": 0.8380060791969299}, {"text": "WER", "start_pos": 230, "end_pos": 233, "type": "METRIC", "confidence": 0.8628372550010681}, {"text": "PER", "start_pos": 234, "end_pos": 237, "type": "METRIC", "confidence": 0.6582443714141846}, {"text": "BLEU", "start_pos": 238, "end_pos": 242, "type": "METRIC", "confidence": 0.5149536728858948}]}, {"text": " Table 6: Consensus-based combination vs. se- lection: potential for improvement (multi-source  translation, selection/combination of 4 translation  outputs).", "labels": [], "entities": []}, {"text": " Table 7: Improvements in translation quality on  the BTEC Italian-English task through comput- ing consensus translations from the output of two  speech translation systems with different types of  source language input.", "labels": [], "entities": [{"text": "BTEC Italian-English task", "start_pos": 54, "end_pos": 79, "type": "DATASET", "confidence": 0.6835136214892069}]}]}