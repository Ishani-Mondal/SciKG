{"title": [{"text": "A Machine Learning Approach to Extract Temporal Information from Texts in Swedish and Generate Animated 3D Scenes", "labels": [], "entities": []}], "abstractContent": [{"text": "Carsim is a program that automatically converts narratives into 3D scenes.", "labels": [], "entities": []}, {"text": "Carsim considers authentic texts describing road accidents, generally collected from web sites of Swedish newspapers or transcribed from handwritten accounts by victims of accidents.", "labels": [], "entities": []}, {"text": "One of the program's key features is that it animates the generated scene to visualize events.", "labels": [], "entities": []}, {"text": "To create a consistent animation, Carsim extracts the participants mentioned in a text and identifies what they do.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the extraction of temporal relations between actions.", "labels": [], "entities": []}, {"text": "We first describe how we detect time expressions and events.", "labels": [], "entities": []}, {"text": "We then present a machine learning technique to order the sequence of events identified in the narratives.", "labels": [], "entities": []}, {"text": "We finally report the results we obtained.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "As far as we know, there is no available timeannotated corpus in Swedish, which makes the evaluation more difficult.", "labels": [], "entities": []}, {"text": "As development and test sets, we collected approximately 300 reports of road accidents from various Swedish newspapers.", "labels": [], "entities": []}, {"text": "Each report is annotated with its publishing date.", "labels": [], "entities": []}, {"text": "Analyzing the reports is complex because of their variability in style and length.", "labels": [], "entities": []}, {"text": "Their size ranges from a couple of sentences to more than a page.", "labels": [], "entities": []}, {"text": "The amount of details is overwhelming in some reports, while in others most of the information is implicit.", "labels": [], "entities": []}, {"text": "The complexity of the accidents described ranges from simple accidents with only one vehicle to multiple collisions with several participating vehicles and complex movements.", "labels": [], "entities": []}, {"text": "We manually annotated a subset of our corpus consisting of 25 texts, 476 events and 1,162 temporal links.", "labels": [], "entities": []}, {"text": "We built the trees automatically from this set using the C4.5 program.", "labels": [], "entities": []}, {"text": "Our training set is relatively small and the number of features we use relatively large for the set size.", "labels": [], "entities": []}, {"text": "This can produce a training overfit.", "labels": [], "entities": []}, {"text": "However, C4.5, to some extent, makes provision for this and prunes the decision trees.", "labels": [], "entities": [{"text": "C4.5", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.9808032512664795}]}, {"text": "We evaluated three aspects of the temporal information extraction modules: the detection and interpretation of time expressions, the detection and interpretation of events, and the quality of the final ordering.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.6768386960029602}, {"text": "detection and interpretation of events", "start_pos": 133, "end_pos": 171, "type": "TASK", "confidence": 0.8021342754364014}]}, {"text": "We report here the detection of events and the final ordering.: Feature detection for 180 events.", "labels": [], "entities": [{"text": "Feature detection", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.698050245642662}]}, {"text": "We evaluated the final ordering with the method proposed by.", "labels": [], "entities": []}, {"text": "Their scheme is comprehensive and enables to compare the performance of different systems.", "labels": [], "entities": []}, {"text": "Description of the Evaluation Method.", "labels": [], "entities": []}, {"text": "Setzer and Gaizauskas carried out an inter-annotator agreement test for temporal relation markup.", "labels": [], "entities": []}, {"text": "When evaluating the final ordering of a text, they defined the set E of all the events in the text and the set T of all the time expressions.", "labels": [], "entities": []}, {"text": "They computed the set (E \u222a T ) \u00d7 (E \u222a T ) and they defined the sets S \ud97b\udf59 , I \ud97b\udf59 , and B \ud97b\udf59 as the transitive closures for the relations simultaneous, includes, and before, respectively.", "labels": [], "entities": []}, {"text": "If S \ud97b\udf59 k and S \ud97b\udf59 r represent the set S \ud97b\udf59 for the answer key (\"Gold Standard\") and system response, respectively, the measures of precision and recall for the simultaneous relation are: For an overall measure of recall and precision, Setzer and Gaizauskas proposed the following formulas: They used the classical definition of the Fmeasure: the harmonic means of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.9992000460624695}, {"text": "recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9976493716239929}, {"text": "recall", "start_pos": 211, "end_pos": 217, "type": "METRIC", "confidence": 0.9972055554389954}, {"text": "precision", "start_pos": 222, "end_pos": 231, "type": "METRIC", "confidence": 0.9971094727516174}, {"text": "Fmeasure", "start_pos": 330, "end_pos": 338, "type": "METRIC", "confidence": 0.8181182146072388}, {"text": "precision", "start_pos": 362, "end_pos": 371, "type": "METRIC", "confidence": 0.9966238737106323}, {"text": "recall", "start_pos": 376, "end_pos": 382, "type": "METRIC", "confidence": 0.9795435070991516}]}, {"text": "Note that the precision and recall are computed per text, not for all relations in the test set simultaneously.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9995914101600647}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9991470575332642}]}, {"text": "We evaluated the output of the Carsim system on 10 previously unseen texts against our Gold Standard.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.9669818580150604}]}, {"text": "As a baseline, we used a simple algorithm that assumes that all events occur in the order they are introduced in the narrative.", "labels": [], "entities": []}, {"text": "For comparison, we also did an inter-annotator evaluation on the same texts, where we compared the Gold Standard, annotated by one of us, with the annotation produced by another member in our group.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 99, "end_pos": 112, "type": "DATASET", "confidence": 0.981997162103653}]}, {"text": "As our system doesn't support comparisons of time expressions, we evaluated the relations contained in the set E \u00d7 E.", "labels": [], "entities": []}, {"text": "We only counted the reflexive simultaneous relation once per tuples (e x , e y ) and (e y , ex ) and we didn't count relations (e x , ex ).", "labels": [], "entities": []}, {"text": "shows our results averaged over the 10 texts.", "labels": [], "entities": []}, {"text": "As a reference, we also included Setzer and Gaizauskas' averaged results for interannotator agreement on temporal relations in six texts.", "labels": [], "entities": []}, {"text": "Their results are not directly comparable however as they did the evaluation over the set (E \u222a T ) \u00d7 (E \u222a T ) for English texts of another type.", "labels": [], "entities": []}, {"text": "The computation of ratios on the transitive closure makes Setzer and Gaizauskas' evaluation method extremely sensitive.", "labels": [], "entities": []}, {"text": "Missing a single link often results in a loss of scores of generated transitive links and thus has a massive impact on the final evaluation figures.", "labels": [], "entities": []}, {"text": "As an example, one of our texts contains six events whose order is e 4 < e 5 < e 6 < e 1 < e 2 < e 3 . The event module automatically detects the chains e 4 < e 5 < e 6 and e 1 < e 2 < e 3 correctly, but misses the link e 6 < e 1 . This gives a recall of 6/15 = 0.40.", "labels": [], "entities": [{"text": "recall", "start_pos": 245, "end_pos": 251, "type": "METRIC", "confidence": 0.9995844960212708}]}, {"text": "When considering evaluations performed using the method above, it is meaningful to have this in mind.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature detection for 180 events.", "labels": [], "entities": [{"text": "Feature detection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6977094858884811}]}, {"text": " Table 2: Evaluation results for final ordering averaged per text (with P , R, and F in %).", "labels": [], "entities": [{"text": "F", "start_pos": 83, "end_pos": 84, "type": "METRIC", "confidence": 0.9553309082984924}]}]}