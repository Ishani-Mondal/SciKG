{"title": [{"text": "Improved Lexical Alignment by Combining Multiple Reified Alignments", "labels": [], "entities": [{"text": "Improved Lexical Alignment", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8855149547259012}, {"text": "Combining Multiple Reified Alignments", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.6002722233533859}]}], "abstractContent": [{"text": "We describe a word alignment platform which ensures text pre-processing (to-kenization, POS-tagging, lemmatization, chunking, sentence alignment) as required by an accurate word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7589137256145477}, {"text": "sentence alignment", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.7316853851079941}]}, {"text": "The platform combines two different methods, producing distinct alignments.", "labels": [], "entities": []}, {"text": "The basic word aligners are described in some details and are individually evaluated.", "labels": [], "entities": []}, {"text": "The union of the individual alignments is subject to a filtering post-processing phase.", "labels": [], "entities": []}, {"text": "Two different filtering methods are also presented.", "labels": [], "entities": []}, {"text": "The evaluation shows that the combined word alignment contains 10.75% less errors than the best individual aligner.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is almost a truism that more decision makers, working together, are likely to find a better solution than when working alone.", "labels": [], "entities": []}, {"text": "discusses conditions under which different decisions (in his case classifications) maybe combined for obtaining a better result.", "labels": [], "entities": []}, {"text": "Essentially, a successful automatic combination method would require comparable performance for the decision makers and, additionally, that they should not make similar errors.", "labels": [], "entities": []}, {"text": "This idea has been exploited by various NLP researchers in language modelling, statistical POS tagging, parsing, etc.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.792037308216095}, {"text": "POS tagging", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.81892991065979}, {"text": "parsing", "start_pos": 104, "end_pos": 111, "type": "TASK", "confidence": 0.9328777194023132}]}, {"text": "We developed two quite different word aligners, driven by two distinct objectives: the first one was motivated by a project aiming at the development of an interlingually aligned set of wordnets while the other one was developed within an SMT ongoing project.", "labels": [], "entities": [{"text": "SMT", "start_pos": 239, "end_pos": 242, "type": "TASK", "confidence": 0.9048954844474792}]}, {"text": "The first one was used for validating, against a multilingual corpus, the interlingual synset equivalences and also for WSD experiments.", "labels": [], "entities": [{"text": "WSD", "start_pos": 120, "end_pos": 123, "type": "TASK", "confidence": 0.9168380498886108}]}, {"text": "Although, initially, it was concerned only with open class words recorded in a wordnet, turning it into an \"all words\" aligner was not a difficult task.", "labels": [], "entities": []}, {"text": "This word aligner, called YAWA is described in section 3.", "labels": [], "entities": [{"text": "YAWA", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.663451611995697}]}, {"text": "A quite different approach from the one used by YAWA, is implemented in our second word aligner, called MEBA, described in section 4.", "labels": [], "entities": [{"text": "YAWA", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.8405072093009949}, {"text": "MEBA", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.7085698843002319}]}, {"text": "It is a multiple parameter and multiple step algorithm using relevance thresholds specific to each parameter, but different from each step to the other.", "labels": [], "entities": []}, {"text": "The implementation of MEBA was strongly influenced by the notorious five IBM models described in ().", "labels": [], "entities": [{"text": "MEBA", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.6940426826477051}]}, {"text": "We used GIZA++ to estimate different parameters of the MEBA aligner.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.8719395995140076}, {"text": "MEBA", "start_pos": 55, "end_pos": 59, "type": "DATASET", "confidence": 0.8366259932518005}]}, {"text": "The alignments produced by MEBA were compared to the ones produced by YAWA and evaluated against the Gold Standard (GS) annotations used in the Word Alignment Shared Tasks (Romanian-English track) organized at HLT-NAACL2003 (.", "labels": [], "entities": [{"text": "Gold Standard (GS) annotations", "start_pos": 101, "end_pos": 131, "type": "METRIC", "confidence": 0.8607415556907654}, {"text": "Word Alignment Shared Tasks (Romanian-English track) organized at HLT-NAACL2003", "start_pos": 144, "end_pos": 223, "type": "TASK", "confidence": 0.7463344579393213}]}, {"text": "Given that the two aligners are based on quite different models and that their F-measures are comparable, it was quite a natural idea to combine their results and hope for an improved alignment.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.9705545902252197}]}, {"text": "Moreover, by analyzing the alignment errors done by each word aligner, we found that the number of common mistakes was small, so the premises fora successful combination were very good.", "labels": [], "entities": []}, {"text": "The Combined Word Aligner, COWAL-described in section 5, is a wrapper of the two aligners (YAWA and MEBA) merging the individual alignments and filtering the result.", "labels": [], "entities": []}, {"text": "At the Shared Task on Word Alignment organized by the ACL2005 Workshop on \"Building and Using Parallel Corpora: Data-driven Machine Translation and Beyond\"), we participated (on the Romanian-English track) with the two aligners and the combined one (COWAL).", "labels": [], "entities": [{"text": "Shared Task on Word Alignment", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.6506941616535187}, {"text": "Machine Translation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.6612653583288193}, {"text": "COWAL", "start_pos": 250, "end_pos": 255, "type": "METRIC", "confidence": 0.6448453068733215}]}, {"text": "Out of 37 competing systems, COWAL was rated the first, MEBA the 20 th and TREQ-AL (, the former version of YAWA, was rated the 21 st . The usefulness of the aligner combination was convincingly demonstrated.", "labels": [], "entities": [{"text": "COWAL", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.6025469303131104}, {"text": "MEBA", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.8386863470077515}, {"text": "TREQ-AL", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9957700371742249}]}, {"text": "Meanwhile, both the individual aligners and their combination were significantly improved.", "labels": [], "entities": []}, {"text": "COWAL is now embedded into a larger platform that incorporates several tools for bitexts preprocessing (briefly reviewed in section 2), a graphical interface that allows for comparing and editing different alignments, as well as a word sense disambiguation module.", "labels": [], "entities": [{"text": "COWAL", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.932319700717926}, {"text": "word sense disambiguation", "start_pos": 231, "end_pos": 256, "type": "TASK", "confidence": 0.6988211274147034}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: MEBA evaluation  The score of a candidate link (LS) between a  source token i and a target token j is computed  by a linear function of several features scores  (Tiedemann, 2003).", "labels": [], "entities": []}]}