{"title": [{"text": "An Approach to Summarizing Short Stories", "labels": [], "entities": [{"text": "Summarizing Short Stories", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.9606396754582723}]}], "abstractContent": [{"text": "This paper describes a system that produces extractive summaries of short works of literary fiction.", "labels": [], "entities": [{"text": "extractive summaries of short works of literary fiction", "start_pos": 44, "end_pos": 99, "type": "TASK", "confidence": 0.7371945157647133}]}, {"text": "The ultimate purpose of produced summaries is defined as helping a reader to determine whether she would be interested in reading a particular story.", "labels": [], "entities": []}, {"text": "To this end, the summary aims to provide a reader with an idea about the settings of a story (such as characters, time and place) without revealing the plot.", "labels": [], "entities": []}, {"text": "The approach presented here relies heavily on the notion of aspect.", "labels": [], "entities": []}, {"text": "Preliminary results show an improvement over two na\u00efve baselines: a lead baseline and a more sophisticated variant of it.", "labels": [], "entities": []}, {"text": "Although modest, the results suggest that using aspectual information maybe of help when summarizing fiction.", "labels": [], "entities": [{"text": "summarizing fiction", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.9399562776088715}]}, {"text": "A more thorough evaluation involving human judges is underway.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the course of recent years the scientific community working on the problem of automatic text summarization has been experiencing an upsurge.", "labels": [], "entities": [{"text": "automatic text summarization", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.668170303106308}]}, {"text": "A multitude of different techniques has been applied to this end, some of the more remarkable of them being, to name just a few.", "labels": [], "entities": []}, {"text": "These researchers worked on various text genres: scientific and popular scientific articles), texts in computational linguistics (), and medical texts ().", "labels": [], "entities": []}, {"text": "All these genres are examples of texts characterized by rigid structure, relative abundance of surface markers and straightforwardness.", "labels": [], "entities": []}, {"text": "Relatively few attempts have been made at summarizing less structured genres, some of them being dialogue and speech summarization).", "labels": [], "entities": [{"text": "summarizing less structured genres", "start_pos": 42, "end_pos": 76, "type": "TASK", "confidence": 0.8553087562322617}, {"text": "speech summarization", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.6805228441953659}]}, {"text": "The issue of summarizing fiction remains largely untouched, since a few very thorough earlier works.", "labels": [], "entities": [{"text": "summarizing fiction", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.9598219692707062}]}, {"text": "The work presented here seeks to fill in this gap.", "labels": [], "entities": []}, {"text": "The ultimate objective of the project is stated as follows: to produce indicative summaries of short works of fiction such that they be helpful to a potential reader in deciding whether she would be interested in reading a particular story or not.", "labels": [], "entities": []}, {"text": "To this end, revealing the plot was deemed unnecessary and even undesirable.", "labels": [], "entities": []}, {"text": "Instead, the current approach relies on the following assumption: when a reader is presented with an extracted summary outlining the general settings of a story (such as time, place and who it is about), she will have enough information to decide how interested she would be in reading a story.", "labels": [], "entities": []}, {"text": "For example, a fragment of such a summary, produced by an annotator for the story The Cost of Kindness by Jerome K. Jerome is presented in.", "labels": [], "entities": [{"text": "The Cost of Kindness by Jerome K. Jerome", "start_pos": 82, "end_pos": 122, "type": "TASK", "confidence": 0.7894065193831921}]}, {"text": "The plot, which is a tale of how one local family decides to bid a warm farewell to Rev.", "labels": [], "entities": []}, {"text": "Cracklethorpe and causes the vicar to change his mind and remain in town, is omitted.", "labels": [], "entities": [{"text": "Cracklethorpe", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.795906662940979}]}, {"text": "The data used in the experiments consisted of 23 short stories, all written in XIX -early XX century by main-stream authors such as Katherine Mansfield, Anton Chekhov, O.Henry, Guy de Maupassant and others (13 authors in total).", "labels": [], "entities": []}, {"text": "The genre can be vaguely termed social fiction with the exception of a few fairy-tales.", "labels": [], "entities": [{"text": "social fiction", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.714143693447113}]}, {"text": "Such vagueness as far as genre is concerned was deliberate, as the author wished to avoid producing a system relying on cues specific to a particular genre.", "labels": [], "entities": []}, {"text": "Average length of a story in the corpus is 3,333 tokens (approximately 4.5 letter-sized pages) and the target compression rate is 6%.", "labels": [], "entities": []}, {"text": "In order to separate the background of a story from events, this project relies heavily on the notion of aspect (the term is explained in Section 3.1).", "labels": [], "entities": []}, {"text": "Each clause of every sentence is described in terms of aspect-related features.", "labels": [], "entities": []}, {"text": "This representation is then used to select salient descriptive sentences and to leave out those which describe events.", "labels": [], "entities": []}, {"text": "The organization of the paper follows the overall architecture of the system.", "labels": [], "entities": []}, {"text": "Section 2 provides a generalized overview of the preprocessing stage of the project, during which pronominal and nominal anaphoric references (the term is explained in Section 2) were resolved and main characters were identified.", "labels": [], "entities": []}, {"text": "Section 3 briefly reviews the concept of aspect, gives an overview of the system and provides the linguistic motivation behind it.", "labels": [], "entities": []}, {"text": "Section 4 describes the classification procedures (machine learning and manual rule creation) used to distinguish between descriptive elements of a story and passages that describe events.", "labels": [], "entities": [{"text": "manual rule creation)", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.7785962224006653}]}, {"text": "Section 5 draws some conclusions and outlines possible directions in which this work may evolve.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data used in the experiments consisted of 23 stories split into a training set (14 stories) and a testing set (9 stories).", "labels": [], "entities": []}, {"text": "Each clause of every story was annotated by the author of this paper as summary-worthy or not.", "labels": [], "entities": []}, {"text": "Therefore, the classification process occurred at the clause-level.", "labels": [], "entities": [{"text": "classification", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9601386189460754}]}, {"text": "Yet, summary construction occurred at the sentencelevel, that is if one clause in a sentence was considered summary-worthy, the whole sentence was also considered summary-worthy.", "labels": [], "entities": [{"text": "summary construction", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.8096577823162079}]}, {"text": "Because of this, results are reported at two levels: clause and sentence.", "labels": [], "entities": []}, {"text": "The results at the clause-level are more appropriate to judge the accuracy of the classification process.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9990443587303162}, {"text": "classification process", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.8905260860919952}]}, {"text": "The results at the sentence level are better suited forgiving an idea about how close the produced summaries are to their annotated counterparts.", "labels": [], "entities": []}, {"text": "The training set contained 5,514 clauses and the testing set contained 4,196 clauses.", "labels": [], "entities": []}, {"text": "The target compression rate was set at 6% expressed in terms of sentences.", "labels": [], "entities": []}, {"text": "This rate was selected because it approximately corresponds to the average compression rate achieved by the annotator Before describing the experiments and discussing results, it is useful to define baselines.", "labels": [], "entities": []}, {"text": "The author of this paper is not familiar with any comparable summarization experiments and for this reason was unable to use existing work for comparison.", "labels": [], "entities": [{"text": "summarization", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.9779719114303589}]}, {"text": "Therefore, a baseline needed to be defined in different terms.", "labels": [], "entities": []}, {"text": "To this end, two na\u00efve baselines were computed.", "labels": [], "entities": []}, {"text": "Intuitively, when a person wishes to decide whether to read a certain book or not, he opens it and flips through several pages at the beginning.", "labels": [], "entities": []}, {"text": "Imitating this process, a simple lead baseline consisting of the first 6% of the sentences in a story was computed.", "labels": [], "entities": []}, {"text": "It is denoted LEAD in Tables 3 and 4.", "labels": [], "entities": [{"text": "LEAD", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9961917400360107}]}, {"text": "The second baseline is a slightly modified version of the lead baseline and it consists of the first 6% of the sentences that contain at least one mention of one of the important characters.", "labels": [], "entities": []}, {"text": "It is denoted LEAD CHAR in  The first classification procedure consisted of applying a set of manually designed rules to produce descriptive summaries.", "labels": [], "entities": [{"text": "LEAD CHAR", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.8947848975658417}]}, {"text": "The rules were designed using the same features that were used for machine learning and that are described in Section 3.3.", "labels": [], "entities": [{"text": "machine learning", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.7278228402137756}]}, {"text": "Two sets of rules were created: one for the fine-grained dataset and another for the coarsegrained dataset.", "labels": [], "entities": [{"text": "coarsegrained dataset", "start_pos": 85, "end_pos": 106, "type": "DATASET", "confidence": 0.6864625364542007}]}, {"text": "Due to space restrictions it is not possible to reproduce the rules in this paper.", "labels": [], "entities": []}, {"text": "Yet, several examples are given in.", "labels": [], "entities": []}, {"text": "(If a rule returns True, then a clause is considered to be summary-worthy.)", "labels": [], "entities": []}, {"text": "The results obtained using these rules are presented in.", "labels": [], "entities": []}, {"text": "They are discussed along with the results obtained using machine learning in Section 4.4.", "labels": [], "entities": []}, {"text": "As an alternative to rule construction, the author used C5.0 (Quilan, 1992) implementation of decision trees to select descriptive sentences.", "labels": [], "entities": [{"text": "rule construction", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7518331110477448}]}, {"text": "The algorithm was chosen mainly because of the readability of its output.", "labels": [], "entities": []}, {"text": "Both training and testing datasets exhibited a 1:18 class imbalance, which, given a small size of the datasets, needed to be compensated.", "labels": [], "entities": []}, {"text": "Undersampling (randomly removing instances of the majority class) was applied to both datasets in order to correct class imbalance.", "labels": [], "entities": []}, {"text": "This yielded altogether 4 different datasets (see).", "labels": [], "entities": []}, {"text": "For each dataset, the best model was selected using 10-fold cross-validation on the training set.", "labels": [], "entities": []}, {"text": "The model was then tested on the testing set and the results are reported in.", "labels": [], "entities": []}, {"text": "Rule 1 if a clause contains a character mention as subject or object and a temporal expression of type enactment (ever, never, always) return True Rule 2 if a clause contains a character mention as subject or object and a stative verb return True Rule 3 if a clause is in progressive tense return False", "labels": [], "entities": [{"text": "False", "start_pos": 297, "end_pos": 302, "type": "METRIC", "confidence": 0.970301628112793}]}], "tableCaptions": [{"text": " Table 1. After re- solving anaphoric expressions, characters that are  central to the story were selected based on nor- malized frequency counts.", "labels": [], "entities": []}, {"text": " Table 1. Results of anaphora resolution.  Type of  anaphora", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7458460032939911}]}, {"text": " Table 2. Description of the features in both datasets  Fine-grained dataset  Coarse-grained dataset  Type of features  Number of fea- tures", "labels": [], "entities": []}, {"text": " Table 3. Results obtained using rules (summary-worthy class)  Dataset  Level  Preci- sion,%", "labels": [], "entities": [{"text": "Dataset  Level  Preci-", "start_pos": 63, "end_pos": 85, "type": "METRIC", "confidence": 0.5910254120826721}]}]}