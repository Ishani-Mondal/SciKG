{"title": [{"text": "Data-driven Generation of Emphatic Facial Displays", "labels": [], "entities": [{"text": "Data-driven Generation of Emphatic Facial Displays", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.5441748450199763}]}], "abstractContent": [{"text": "We describe an implementation of data-driven selection of emphatic facial displays for an embodied conversational agent in a dialogue system.", "labels": [], "entities": []}, {"text": "A corpus of sentences in the domain of the target dialogue system was recorded, and the facial displays used by the speaker were annotated.", "labels": [], "entities": []}, {"text": "The data from those recordings was used in a range of models for generating facial displays, each model making use of a different amount of context or choosing displays differently within a context.", "labels": [], "entities": []}, {"text": "The models were evaluated in two ways: by cross-validation against the corpus, and by asking users to rate the output.", "labels": [], "entities": []}, {"text": "The predictions of the cross-validation study differed from the actual user ratings.", "labels": [], "entities": []}, {"text": "While the cross-validation gave the highest scores to models making a majority choice within a context, the user study showed a significant preference for models that produced more variation.", "labels": [], "entities": []}, {"text": "This preference was especially strong among the female subjects.", "labels": [], "entities": []}], "introductionContent": [{"text": "It has long been documented that there are characteristic facial displays that accompany the emphasised parts of spoken utterances.", "labels": [], "entities": []}, {"text": "For example, says that eyebrow raises \"appear to coincide with primary vocal stress, or more simply with a word that is spoken more loudly.\"", "labels": [], "entities": []}, {"text": "Correlations have also been found between prosodic features and events such as head nodding and the amplitude of mouth movements.", "labels": [], "entities": []}, {"text": "When performed an empirical, cross-linguistic evaluation of the influence of brow movements on the perception of prosodic stress, they found that subjects preferred eyebrow movements to be correlated with the most prominent word in an utterance and that eyebrow movements boosted the perceived prominence of the word they were associated with.", "labels": [], "entities": []}, {"text": "While many facial displays have been shown to co-occur with prosodic accents, the converse is not true: in normal embodied speech, many pitch accents and other prosodic events are unaccompanied by any facial display, and when displays are used, the selection varies widely.", "labels": [], "entities": []}, {"text": "demonstrated that \"envelope\" facial displays related to the process of conversation have a greater impact on successful interaction with an embodied conversational agent than do emotional displays.", "labels": [], "entities": []}, {"text": "However, no description of face motion is sufficiently detailed that it can be used as the basis for selecting emphatic facial displays for an agent.", "labels": [], "entities": []}, {"text": "This is therefore a task for which data-driven techniques are beneficial.", "labels": [], "entities": []}, {"text": "In this paper, we address the task of selecting emphatic facial displays for the talking head in the COMIC 1 multimodal dialogue system.", "labels": [], "entities": [{"text": "COMIC 1 multimodal dialogue", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.5722006112337112}]}, {"text": "In the basic COMIC process for generating multimodal output ( ), facial displays are selected using simple rules based only on the pitch accents specified by the text generation system.", "labels": [], "entities": []}, {"text": "In order to make a more sophisticated and naturalistic selection of facial displays, we recorded a single speaker reading a set of sentences drawn from the COMIC domain, and annotated the facial displays that he used and the contexts in which he used them.", "labels": [], "entities": [{"text": "COMIC domain", "start_pos": 156, "end_pos": 168, "type": "DATASET", "confidence": 0.850407063961029}]}, {"text": "We then created models based on the data from this corpus and used them to choose the facial displays for the COMIC talking head.", "labels": [], "entities": [{"text": "COMIC talking head", "start_pos": 110, "end_pos": 128, "type": "DATASET", "confidence": 0.7730218172073364}]}, {"text": "The rest of this paper is arranged as follows.", "labels": [], "entities": []}, {"text": "First, in Section 2, we describe previous approaches to selecting non-verbal behaviour for embodied conversational agents.", "labels": [], "entities": []}, {"text": "In Section 3, we then show how we collected and annotated a corpus of facial displays, and give some generalisations about the range of displays found in the corpus.", "labels": [], "entities": []}, {"text": "After that, in Section 4, we outline how we implemented a range of models for selecting behaviours for the COMIC agent using the corpus data, using varying amounts of context and different selection strategies within a context.", "labels": [], "entities": []}, {"text": "Next, we give the results of two evaluation studies comparing the quality of the output generated by the various models: a cross-validation study against the corpus (Section 5) and a direct user evaluation of the output (Section 6).", "labels": [], "entities": []}, {"text": "In Section 7, we discuss the results of these two evaluations.", "labels": [], "entities": []}, {"text": "Finally, in Section 8, we draw some conclusions from the current study and outline potential follow-up work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first compared the performance of the models using 10-fold cross-validation against the corpus.", "labels": [], "entities": []}, {"text": "For each fold, we built models using 90% of the sentences in the corpus, and then used those models to predict the facial displays for the sentences in the other 10% of the corpus.", "labels": [], "entities": []}, {"text": "We measured the recall and precision on a sentence by comparing the predicted facial displays for each segment to the actual displays used by the speaker and averaging those scores across the sentence.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9993863105773926}, {"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9922448992729187}]}, {"text": "We then used the recall and precision scores fora sentence to compute a sentence-level F score.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9993278980255127}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.972467303276062}, {"text": "sentence-level F score", "start_pos": 72, "end_pos": 94, "type": "METRIC", "confidence": 0.6851305365562439}]}, {"text": "Averaged across all of the cross-validation folds, the NM model had the highest recall score, while the FM model scored highest for precision and F score.", "labels": [], "entities": [{"text": "recall score", "start_pos": 80, "end_pos": 92, "type": "METRIC", "confidence": 0.986259251832962}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9996936321258545}, {"text": "F score", "start_pos": 146, "end_pos": 153, "type": "METRIC", "confidence": 0.9916629493236542}]}, {"text": "shows the average sentencelevel F score for all of the models.", "labels": [], "entities": [{"text": "sentencelevel F score", "start_pos": 18, "end_pos": 39, "type": "METRIC", "confidence": 0.6897908051808676}]}, {"text": "All but one of the differences shown are significant at the p < That the majority-choice models generally scored better on this measure than the weightedchoice models is not unexpected: a weightedchoice model is more likely to choose a lesscommon display, and if it chooses it in a context where the speaker did not, the score for that sentence is decreased.", "labels": [], "entities": []}, {"text": "It is also not surprising that, within a selection strategy, the models that take into account more of the context did better than those that useless of it; this is simply an indication that there are patterns in the corpus, and that all of the contextual information contributes to the selection of displays.", "labels": [], "entities": []}, {"text": "The majority-choice models performed better on the cross-validation study than the weightedchoice ones did; however, this does not does not mean that users will necessarily like their output in practice.", "labels": [], "entities": []}, {"text": "A large amount of the lateral motion and eyebrow movements occurs in the second-or third-largest class in a number of contexts, and is therefore less likely to be selected by a majoritychoice model.", "labels": [], "entities": []}, {"text": "If users like to see motion other than simple nodding, it might be that the schedules generated by the weighted-choice models are actually preferred.", "labels": [], "entities": []}, {"text": "To address this question, we performed a user evaluation.", "labels": [], "entities": []}, {"text": "Materials For this study, we generated 30 new sentences from the COMIC system.", "labels": [], "entities": [{"text": "COMIC system", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9004148840904236}]}, {"text": "The sentences were selected to ensure that they covered the full range of syntactic structures available to COMIC and that none of them was a duplicate of anything from the recording script.", "labels": [], "entities": []}, {"text": "We then generated a facial schedule for each sentence using each of the six models.", "labels": [], "entities": []}, {"text": "Note that, for some of the sentences, more than one model produced an identical sequence of facial displays, either because the majority choice in a broader context was the same as in a more narrow context, or because a weighted-choice model ended up selecting the majority option in every case.", "labels": [], "entities": []}, {"text": "All such identical schedules were retained in the set of materials; in Section 6.2, we discuss their impact on the results.", "labels": [], "entities": []}, {"text": "We then made videos of every schedule for every sentence, using the Festival speech synthesiser) and the RUTH talking head ).", "labels": [], "entities": [{"text": "Festival speech synthesiser", "start_pos": 68, "end_pos": 95, "type": "DATASET", "confidence": 0.8981545368830363}, {"text": "RUTH", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.7029857039451599}]}, {"text": "shows synthesised versions of the facial displays from.", "labels": [], "entities": []}, {"text": "Procedure 33 subjects took part in the experiment: 17 female subjects and 16 males.", "labels": [], "entities": []}, {"text": "They were primarily undergraduate students, between 20 and 24 years old, native speakers of English, with an intermediate amount of computer experience.", "labels": [], "entities": []}, {"text": "Each subject in the study was shown videos of all 30 sentences in an individually-chosen random order.", "labels": [], "entities": []}, {"text": "For each sentence, the subject saw two versions, each generated by a different model, and was asked to choose which version they liked better.", "labels": [], "entities": []}, {"text": "The displayed versions were counterbalanced so that every subject performed each pairwise comparison of models twice, once in each order.", "labels": [], "entities": []}, {"text": "The study was run over the web.", "labels": [], "entities": []}, {"text": "on that graph indicates the proportion of the time that model was chosen over any of the alternatives.", "labels": [], "entities": []}, {"text": "For example, in all of the trials where the FW model was one of the options, it was chosen over the alternative 55% of the time.", "labels": [], "entities": [{"text": "FW", "start_pos": 44, "end_pos": 46, "type": "DATASET", "confidence": 0.7709776163101196}]}, {"text": "Note that the values on that graph should not be directly compared against one another; instead, each should be individually compared with 0.5 (the dotted line) to determine whether it was chosen more or less frequently than chance.", "labels": [], "entities": []}, {"text": "A binomial test on these values indicates that both the FW and the NW models were chosen significantly above chance, while those generated by the SM and NM models were chosen significantly below chance (all p < 0.05).", "labels": [], "entities": [{"text": "FW", "start_pos": 56, "end_pos": 58, "type": "DATASET", "confidence": 0.8065630197525024}]}, {"text": "The choices on the FM and SW models were indistinguishable from chance.", "labels": [], "entities": []}, {"text": "If we examine the preferences within a context, we also see a preference for the weighted-choice models.", "labels": [], "entities": []}, {"text": "shows the preferences for selection strategy within each context.", "labels": [], "entities": []}, {"text": "For example, when choosing between schedules both generated by models using the full context (FM vs. FW ), subjects chose the one generated by the FW model 60% of the time.", "labels": [], "entities": []}, {"text": "The trend in both the full-context and no-context cases is in favour of the weightedchoice models, and the combined values overall such trials (the rightmost pair of bars in the show a significant preference for weighted choice over majority choice across all contexts (binomial test; p < 0.05).", "labels": [], "entities": []}, {"text": "Gender differences There was a large gender effect on the users' preferences: overall, the male subjects (n = 16) tended to choose the majority and weighted versions with almost equal probabilities, while the female subjects (n = 17) strongly preferred the weighted versions in any context, and chose the weighted versions significantly more often in head-to-head comparisons (p < 0.001).", "labels": [], "entities": []}, {"text": "In fact, all of the overall preference for weighted-choice models came from the responses of the female subjects.", "labels": [], "entities": []}, {"text": "The graphs in show the head-to-head preferences in all contexts for both groups of subjects.", "labels": [], "entities": []}], "tableCaptions": []}