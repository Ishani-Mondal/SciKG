{"title": [{"text": "A Clustering Approach for the Nearly Unsupervised Recognition of Nonliteral Language *", "labels": [], "entities": [{"text": "Nearly Unsupervised Recognition of Nonliteral Language", "start_pos": 30, "end_pos": 84, "type": "TASK", "confidence": 0.8189889987309774}]}], "abstractContent": [{"text": "In this paper we present TroFi (Trope Finder), a system for automatically classifying literal and nonliteral usages of verbs through nearly unsupervised word-sense disambiguation and clustering techniques.", "labels": [], "entities": [{"text": "TroFi", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.9583746194839478}, {"text": "classifying literal and nonliteral usages of verbs", "start_pos": 74, "end_pos": 124, "type": "TASK", "confidence": 0.7666483010564532}]}, {"text": "TroFi uses sentential context instead of selectional constraint violations or paths in semantic hierarchies.", "labels": [], "entities": [{"text": "TroFi", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8135089874267578}]}, {"text": "It also uses literal and nonliteral seed sets acquired and cleaned without human supervision in order to bootstrap learning.", "labels": [], "entities": []}, {"text": "We adapt a word-sense disambiguation algorithm to our task and augment it with multiple seed set learners, a voting schema, and additional features like SuperTags and extra-sentential context.", "labels": [], "entities": []}, {"text": "Detailed experiments on hand-annotated data show that our enhanced algorithm outperforms the base-line by 24.4%.", "labels": [], "entities": []}, {"text": "Using the TroFi algorithm , we also build the TroFi Example Base, an extensible resource of annotated literal/nonliteral examples which is freely available to the NLP research community.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we propose TroFi (Trope Finder), a nearly unsupervised clustering method for separating literal and nonliteral usages of verbs.", "labels": [], "entities": [{"text": "TroFi", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9497776627540588}, {"text": "separating literal and nonliteral usages of verbs", "start_pos": 92, "end_pos": 141, "type": "TASK", "confidence": 0.7904833044324603}]}, {"text": "For example, given the target verb \"pour\", we would expect TroFi to cluster the sentence \"Custom demands that cognac be poured from a freshly opened bottle\" as literal, and the sentence \"Salsa and rap music pour out of the windows\" as nonliteral, which, indeed, it does.", "labels": [], "entities": []}, {"text": "We call our method nearly unsupervised.", "labels": [], "entities": []}, {"text": "See Section 3.1 for why we use this terminology.", "labels": [], "entities": []}, {"text": "We reduce the problem of nonliteral language recognition to one of word-sense disambiguation by redefining literal and nonliteral as two different senses of the same word, and we adapt an existing similarity-based word-sense disambiguation method to the task of separating usages of verbs into literal and nonliteral clusters.", "labels": [], "entities": [{"text": "nonliteral language recognition", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6457297503948212}, {"text": "word-sense disambiguation", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.6891820132732391}, {"text": "separating usages of verbs into literal and nonliteral clusters", "start_pos": 262, "end_pos": 325, "type": "TASK", "confidence": 0.7752358118693033}]}, {"text": "This paper focuses on the algorithmic enhancements necessary to facilitate this transformation from word-sense disambiguation to nonliteral language recognition.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.7158929854631424}, {"text": "nonliteral language recognition", "start_pos": 129, "end_pos": 160, "type": "TASK", "confidence": 0.7616012891133627}]}, {"text": "The output of TroFi is an expandable example base of literal/nonliteral clusters which is freely available to the research community.", "labels": [], "entities": []}, {"text": "Many systems that use NLP methods -such as dialogue systems, paraphrasing and summarization, language generation, information extraction, machine translation, etc.", "labels": [], "entities": [{"text": "paraphrasing and summarization", "start_pos": 61, "end_pos": 91, "type": "TASK", "confidence": 0.5505443712075552}, {"text": "language generation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7515203952789307}, {"text": "information extraction", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.8135838210582733}, {"text": "machine translation", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.7866167426109314}]}, {"text": "-would benefit from being able to recognize nonliteral language.", "labels": [], "entities": []}, {"text": "Consider an example based on a similar example from an automated medical claims processing system.", "labels": [], "entities": []}, {"text": "We must determine that the sentence \"she hit the ceiling\" is meant literally before it can be marked up as an ACCIDENT claim.", "labels": [], "entities": [{"text": "ACCIDENT", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9223053455352783}]}, {"text": "Note that the typical use of \"hit the ceiling\" stored in a list of idioms cannot help us.", "labels": [], "entities": []}, {"text": "Only using the context, \"She broke her thumb while she was cheering for the Patriots and, in her excitement, she hit the ceiling,\" can we decide.", "labels": [], "entities": []}, {"text": "We further motivate the usefulness of the ability to recognize literal vs. nonliteral usages using an example from the Recognizing Textual Entailment (RTE-1) challenge of 2005.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE-1) challenge of 2005", "start_pos": 119, "end_pos": 175, "type": "TASK", "confidence": 0.7527297536532084}]}, {"text": "(This is just an example; we do not compute entailments.)", "labels": [], "entities": []}, {"text": "In the challenge data, Pair 1959 was: Kerry hit Bush hard on his conduct on the war in Iraq.", "labels": [], "entities": []}, {"text": "The objective was to report FALSE since the second statement in this case is not entailed from the first one.", "labels": [], "entities": [{"text": "FALSE", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.750350296497345}]}, {"text": "In order to do this, it is crucial to know that \"hit\" is being used nonliterally in the first sentence.", "labels": [], "entities": []}, {"text": "Ideally, we would like to look at TroFi as a first step towards an unsupervised, scalable, widely applicable approach to nonliteral language processing that works on real-world data from any domain in any language.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Target and Feedback Set Sizes.", "labels": [], "entities": []}]}