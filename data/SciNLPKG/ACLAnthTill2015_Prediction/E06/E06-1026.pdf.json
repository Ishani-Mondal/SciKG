{"title": [{"text": "Latent Variable Models for Semantic Orientations of Phrases", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose models for semantic orienta-tions of phrases as well as classification methods based on the models.", "labels": [], "entities": []}, {"text": "Although each phrase consists of multiple words, the semantic orientation of the phrase is not a mere sum of the orientations of the component words.", "labels": [], "entities": []}, {"text": "Some words can invert the orientation.", "labels": [], "entities": []}, {"text": "In order to capture the property of such phrases, we introduce latent variables into the models.", "labels": [], "entities": []}, {"text": "Through experiments , we show that the proposed latent variable models work well in the classification of semantic orientations of phrases and achieved nearly 82% classification accuracy .", "labels": [], "entities": [{"text": "classification of semantic orientations of phrases", "start_pos": 88, "end_pos": 138, "type": "TASK", "confidence": 0.8857400417327881}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9716928601264954}]}], "introductionContent": [{"text": "Technology for affect analysis of texts has recently gained attention in both academic and industrial areas.", "labels": [], "entities": [{"text": "affect analysis of texts", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.8598941266536713}]}, {"text": "It can be applied to, for example, a survey of new products or a questionnaire analysis.", "labels": [], "entities": []}, {"text": "Automatic sentiment analysis enables a fast and comprehensive investigation.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9292621314525604}]}, {"text": "The most fundamental step for sentiment analysis is to acquire the semantic orientations of words: desirable or undesirable (positive or negative).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9716291725635529}]}, {"text": "For example, the word \"beautiful\" is positive, while the word \"dirty\" is negative.", "labels": [], "entities": []}, {"text": "Many researchers have developed several methods for this purpose and obtained good results).", "labels": [], "entities": []}, {"text": "One of the next problems to be solved is to acquire semantic orientations of phrases, or multi-term expressions.", "labels": [], "entities": []}, {"text": "No computational model for semantically oriented phrases has been proposed so far although some researchers have used techniques developed for single words.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to propose computational models for phrases with semantic orientations as well as classification methods based on the models.", "labels": [], "entities": []}, {"text": "Indeed the semantic orientations of phrases depend on context just as the semantic orientations of words do, but we would like to obtain the most basic orientations of phrases.", "labels": [], "entities": []}, {"text": "We believe that we can use the obtained basic orientations of phrases for affect analysis of higher linguistic units such as sentences and documents.", "labels": [], "entities": [{"text": "affect analysis of higher linguistic units such as sentences and documents", "start_pos": 74, "end_pos": 148, "type": "TASK", "confidence": 0.7253281094811179}]}, {"text": "The semantic orientation of a phrase is not a mere sum of its component words.", "labels": [], "entities": []}, {"text": "Semantic orientations can emerge out of combinations of non-oriented words.", "labels": [], "entities": []}, {"text": "For example, \"light laptopcomputer\" is positively oriented although neither \"light\" nor \"laptop-computer\" has a positive orientation.", "labels": [], "entities": []}, {"text": "Besides, some words can invert the orientation of a neighboring word, such as \"low\" in \"low risk\", where the negative orientation of \"risk\" is inverted to a \"positive\" by the adjective \"low\".", "labels": [], "entities": []}, {"text": "This kind of non-compositional operation has to be incorporated into the model.", "labels": [], "entities": []}, {"text": "We focus on \"noun+adjective\" in this paper, since this type of phrase contains most of interesting properties of phrases, such as emergence or inversion of semantic orientations.", "labels": [], "entities": []}, {"text": "In order to capture the properties of semantic orientations of phrases, we introduce latent variables into the models, where one random variable corresponds to nouns and another random variable corresponds to adjectives.", "labels": [], "entities": []}, {"text": "The words that are similar in terms of semantic orientations, such as \"risk\" and \"mortality\" (i.e., the positive orientation emerges when they are \"low\"), make a cluster in these models.", "labels": [], "entities": [{"text": "mortality", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9222373366355896}]}, {"text": "Our method is language-independent in the sense that it uses only cooccurrence data of words and semantic orientations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We extracted pairs of a noun (subject) and an adjective (predicate), from Mainichi newspaper articles (1995) written in Japanese, and annotated the pairs with semantic orientation tags : positive, neutral or negative.", "labels": [], "entities": [{"text": "Mainichi newspaper articles (1995)", "start_pos": 74, "end_pos": 108, "type": "DATASET", "confidence": 0.9584686160087585}]}, {"text": "We thus obtained the labeled dataset consisting of 12066 pair instances (7416 different pairs).", "labels": [], "entities": []}, {"text": "The dataset contains 4459 negative instances, 4252 neutral instances, and 3355 positive instances.", "labels": [], "entities": []}, {"text": "The number of distinct nouns is 4770 and the number of distinct adjectives is 384.", "labels": [], "entities": []}, {"text": "To check the inter-annotator agreement between two annotators, we calculated \u03ba statistics, which was 0.640.", "labels": [], "entities": []}, {"text": "This value is allowable, but not quite high.", "labels": [], "entities": []}, {"text": "However, positive-negative disagreement is observed for only 0.7% of the data.", "labels": [], "entities": []}, {"text": "In other words, this statistics means that the task of extracting neutral examples, which has hardly been explored, is intrinsically difficult.", "labels": [], "entities": []}, {"text": "We employ 10-fold cross-validation to obtain the average value of the classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.8757498264312744}]}, {"text": "We split the dataset such that there is no overlapping pair (i.e., any pair in the training dataset does not appear in the test dataset).", "labels": [], "entities": []}, {"text": "If either of the two words in a pair in the test dataset does not appear in the training dataset, we excluded the pair from the test dataset since the problem of unknown words is not in the scope of this research.", "labels": [], "entities": []}, {"text": "Therefore, we evaluate the pairs that are not in the training dataset, but whose component words appear in the training dataset.", "labels": [], "entities": [{"text": "training dataset", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.6671717166900635}]}, {"text": "In addition to the original dataset, which we call the standard dataset, we prepared another dataset in order to examine the power of the latent variable model.", "labels": [], "entities": []}, {"text": "The new dataset, which we call the hard dataset, consists only of examples with 17 difficult adjectives such as \"high\", \"low\", \"large\", \"small\", \"heavy\", and \"light\".", "labels": [], "entities": []}, {"text": "The semantic orientations of pairs including these difficult words often shift depending on the noun they modify.", "labels": [], "entities": []}, {"text": "Thus, the hard dataset is a subset of the standard dataset.", "labels": [], "entities": []}, {"text": "The size of the hard dataset is 4787.", "labels": [], "entities": []}, {"text": "Please note that the hard dataset is used only as a test dataset.", "labels": [], "entities": []}, {"text": "For training, we always use the standard dataset in our experiments.", "labels": [], "entities": []}, {"text": "We performed experiments with all the values of \u03b2 in {0.1, 0.2, \u00b7 \u00b7 \u00b7 , 1.0} and with all the values of Min {10, 30, 50, 70, 100, 200, 300, 500}, and predicted the best values of the hyper-parameters with the held-out method in Section 3.4.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracies with predicted \u03b2 and M", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9988629817962646}]}]}