{"title": [{"text": "Phrase-Based Backoff Models for Machine Translation of Highly Inflected Languages", "labels": [], "entities": [{"text": "Machine Translation of Highly Inflected Languages", "start_pos": 32, "end_pos": 81, "type": "TASK", "confidence": 0.8514373054107031}]}], "abstractContent": [{"text": "We propose a backoff model for phrase-based machine translation that translates unseen word forms in foreign-language text by hierarchical morphological abstractions at the word and the phrase level.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 31, "end_pos": 63, "type": "TASK", "confidence": 0.6273606916268667}]}, {"text": "The model is evaluated on the Europarl corpus for German-English and Finnish-English translation and shows improvements over state-of-the-art phrase-based models.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9920486807823181}, {"text": "Finnish-English translation", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.6553137600421906}]}], "introductionContent": [{"text": "Current statistical machine translation (SMT) usually works well in cases where the domain is fixed, the training and test data match, and a large amount of training data is available.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.7845677783091863}]}, {"text": "Nevertheless, standard SMT models tend to perform much better on languages that are morphologically simple, whereas highly inflected languages with a large number of potential word forms are more problematic, particularly when training data is sparse.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.993510901927948}]}, {"text": "SMT attempts to find a sentenc\u00ea e in the desired output language given the corresponding sentence fin the source language, according t\u00f4 t\u00f4 e = argmax e P (f |e)P (e) Most state-of-the-art SMT adopt a phrase-based approach such that e is chunked into I phrases \u00af e 1 , ..., \u00af e I and the translation model is defined over mappings between phrases in e and inf . i.e. P ( \u00af f |\u00af e).", "labels": [], "entities": [{"text": "SMT", "start_pos": 188, "end_pos": 191, "type": "TASK", "confidence": 0.9772238731384277}]}, {"text": "Typically, phrases are extracted from a word-aligned training corpus.", "labels": [], "entities": []}, {"text": "Different inflected forms of the same lemma are treated as different words, and there is no provision for unseen forms, i.e. unknown words encountered in the test data are not translated at all but appear verbatim in the output.", "labels": [], "entities": []}, {"text": "Although the percentage of such unseen word forms maybe negligible when the training set is large and matches the test set well, it may rise drastically when training data is limited or from a different domain.", "labels": [], "entities": []}, {"text": "Many current and future applications of machine translation require the rapid porting of existing systems to new languages and domains without being able to collect appropriate training data; this problem can therefore be expected to become increasingly more important.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7934823930263519}]}, {"text": "Furthermore, untranslated words can be one of the main factors contributing to low user satisfaction in practical applications.", "labels": [], "entities": []}, {"text": "Several previous studies (see Section 2 below) have addressed issues of morphology in SMT, but most of these have focused on the problem of word alignment and vocabulary size reduction.", "labels": [], "entities": [{"text": "SMT", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9853237867355347}, {"text": "word alignment", "start_pos": 140, "end_pos": 154, "type": "TASK", "confidence": 0.77194744348526}, {"text": "vocabulary size reduction", "start_pos": 159, "end_pos": 184, "type": "TASK", "confidence": 0.6854182084401449}]}, {"text": "Principled ways of incorporating different levels of morphological abstraction into phrase-based models have mostly been ignored so far.", "labels": [], "entities": []}, {"text": "In this paper we propose a hierarchical backoff model for phrasebased translation that integrates several layers of morphological operations, such that more specific models are preferred over more general models.", "labels": [], "entities": [{"text": "phrasebased translation", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.8196877539157867}]}, {"text": "We experimentally evaluate the model on translation from two highly-inflected languages, German and Finnish, into English and present improvements over a state-of-the-art system.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows: The following section discusses related background work.", "labels": [], "entities": []}, {"text": "Section 4 describes the proposed model; Sections 5 and 6 provide details about the data and baseline system used in this study.", "labels": [], "entities": []}, {"text": "Section 7 provides experimental results and discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first investigated to what extent the OOV rate on the development data could be reduced by our backoff procedure.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9839394688606262}]}, {"text": "shows the percentage of words that are still untranslatable after backoff.", "labels": [], "entities": []}, {"text": "A comparison with shows that the backoff model reduces the OOV rate, with a larger reduction effect observed when the training set is smaller.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9869307279586792}]}, {"text": "We next performed translation with backoff systems trained on each data partition.", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9921324849128723}]}, {"text": "In each case, the combination weights for the indi-  vidual model scores were re-optimized.", "labels": [], "entities": []}, {"text": "shows the evaluation results on the dev set.", "labels": [], "entities": []}, {"text": "Since the BLEU score alone is often not a good indicator of successful translations of unknown words (the unigram or bigram precision maybe increased but may not have a strong effect on the overall BLEU score), position-independent word error rate (PER) rate was measured as well.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9750052392482758}, {"text": "translations of unknown words", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.8635421693325043}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.5316921472549438}, {"text": "BLEU score", "start_pos": 198, "end_pos": 208, "type": "METRIC", "confidence": 0.9753862917423248}, {"text": "position-independent word error rate (PER) rate", "start_pos": 211, "end_pos": 258, "type": "METRIC", "confidence": 0.8258545063436031}]}, {"text": "We see improvements in BLEU score and PERs in almost all cases.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9390644729137421}, {"text": "PERs", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.8582773804664612}]}, {"text": "Statistical significance was measured on PER using a difference of proportions significance test and on BLEU using a segment-level paired t-test.", "labels": [], "entities": [{"text": "significance", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.5322571992874146}, {"text": "PER", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.45448392629623413}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9904768466949463}]}, {"text": "PER improvements are significant almost all training conditions for both languages; BLEU improvements are significant in all conditions for Finnish and for the two smallest training sets for German.", "labels": [], "entities": [{"text": "PER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9821690917015076}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9988780617713928}]}, {"text": "The effect on the overall development set (consisting of both sentences with known words only and sentences with unknown words) is shown in.", "labels": [], "entities": []}, {"text": "As expected, the impact on overall performance is smaller, especially for larger training data sets, due to the relatively small percentage of OOV tokens (see).", "labels": [], "entities": []}, {"text": "The evaluation results for the test set are shown in Tables 6 (for the subset of sentences with OOVs) and 7 (for the entire test set), with similar conclusions.", "labels": [], "entities": []}, {"text": "The examples A and B in demonstrate higher-scoring translations produced by the backoff system as opposed to the baseline system.", "labels": [], "entities": []}, {"text": "An analysis of the backoff system output showed that in some cases (e.g. examples C and: BLEU (%) and position-independent word error rate (PER) on the subset of the development data containing unknown words (secondpass output).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9992914199829102}, {"text": "position-independent word error rate (PER)", "start_pos": 102, "end_pos": 144, "type": "METRIC", "confidence": 0.8373695867402213}]}, {"text": "Here and in the following tables, statistically significant differences to the baseline model are shown in boldface (p < 0.05).: BLEU (%) and position-independent word error rate (PER) for the test set (subset with OOV words).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.99969482421875}, {"text": "position-independent word error rate (PER)", "start_pos": 142, "end_pos": 184, "type": "METRIC", "confidence": 0.8343904444149562}]}], "tableCaptions": [{"text": " Table 1: Training set sizes and percentages of  OOV words (types/tokens) on the development  and test sets.", "labels": [], "entities": []}, {"text": " Table 2: Baseline system BLEU scores (%) on dev  and test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9970954656600952}]}, {"text": " Table 3: OOV rates (%) on the development  and test sets under the backoff model (word  types/tokens).", "labels": [], "entities": [{"text": "OOV", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9916559457778931}]}, {"text": " Table 4: BLEU (%) and position-independent  word error rate (PER) on the subset of the devel- opment data containing unknown words (second- pass output). Here and in the following tables,  statistically significant differences to the baseline  model are shown in boldface (p < 0.05).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9996815919876099}, {"text": "position-independent  word error rate (PER)", "start_pos": 23, "end_pos": 66, "type": "METRIC", "confidence": 0.8377881859030042}]}, {"text": " Table 5: BLEU (%) and position-independent  word error rate (PER) for the entire development  set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9996930360794067}, {"text": "position-independent  word error rate (PER)", "start_pos": 23, "end_pos": 66, "type": "METRIC", "confidence": 0.838846640927451}]}, {"text": " Table 6: BLEU (%) and position-independent  word error rate (PER) for the test set (subset with  OOV words).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9997376799583435}, {"text": "position-independent  word error rate (PER)", "start_pos": 23, "end_pos": 66, "type": "METRIC", "confidence": 0.8504832472120013}]}, {"text": " Table 7: BLEU (%) and position-independent  word error rate (PER) for the test set (entire test  set).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9997223019599915}, {"text": "position-independent  word error rate (PER)", "start_pos": 23, "end_pos": 66, "type": "METRIC", "confidence": 0.8687175767762321}]}]}