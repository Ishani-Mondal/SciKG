{"title": [{"text": "Large linguistically-processed Web corpora for multiple languages", "labels": [], "entities": []}], "abstractContent": [{"text": "The Web contains vast amounts of linguistic data.", "labels": [], "entities": []}, {"text": "One key issue for linguists and language technologists is how to access it.", "labels": [], "entities": []}, {"text": "Commercial search engines give highly compromised access.", "labels": [], "entities": []}, {"text": "An alternative is to crawl the Web ourselves, which also allows us to remove duplicates and near-duplicates, navigational material, and a range of other kinds of non-linguistic matter.", "labels": [], "entities": []}, {"text": "We can also tokenize, lemmatise and part-of-speech tag the corpus, and load the data into a corpus query tool which supports sophisticated linguistic queries.", "labels": [], "entities": []}, {"text": "We have now done this for German and Ital-ian, with corpus sizes of over 1 billion words in each case.", "labels": [], "entities": []}, {"text": "We provide Web access to the corpora in our query tool, the Sketch Engine.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Web contains vast amounts of linguistic data for many languages.", "labels": [], "entities": []}, {"text": "One key issue for linguists and language technologists is how to access it.", "labels": [], "entities": []}, {"text": "The drawbacks of using commercial search engines are presented in.", "labels": [], "entities": []}, {"text": "An alternative is to crawl the Web ourselves.", "labels": [], "entities": []}, {"text": "We have done this for two languages, German and Italian, and here we report on the pipeline of processes which give us reasonably well-behaved, 'clean' corpora for each language.", "labels": [], "entities": []}, {"text": "Another Web access option is Alexa (http://pages. alexa.com/company/index.html), who allow the user (for a modest fee) to access their cached Web directly.", "labels": [], "entities": [{"text": "Alexa", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9099138975143433}]}, {"text": "Using Alexa would mean one did not need to crawl; however in our experience, crawling, given free software like Heritrix, is not the bottleneck.", "labels": [], "entities": []}, {"text": "The point at which input is required is the filtering out of non-linguistic material.", "labels": [], "entities": []}, {"text": "We use the German corpus (which was developed first) as our example throughout.", "labels": [], "entities": [{"text": "German corpus", "start_pos": 11, "end_pos": 24, "type": "DATASET", "confidence": 0.8634480237960815}]}, {"text": "The procedure was carried on a server running RH Fedora Core 3 with 4 GB RAM, Dual Xeon 4.3 GHz CPUs and about 2.5 TB hard disk space.", "labels": [], "entities": [{"text": "RH Fedora Core 3", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.9063063263893127}]}, {"text": "We are making the tools we develop as part of the project freely available, 2 in the hope of stimulating public sharing of resources and know-how.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}