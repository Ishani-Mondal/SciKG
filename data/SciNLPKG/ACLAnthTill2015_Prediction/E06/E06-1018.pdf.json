{"title": [{"text": "Word Sense Induction: Triplet-Based Clustering and Automatic Evaluation", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6083288490772247}, {"text": "Automatic Evaluation", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.6743477880954742}]}], "abstractContent": [{"text": "In this paper a novel solution to automatic and unsupervised word sense induction (WSI) is introduced.", "labels": [], "entities": [{"text": "word sense induction (WSI)", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.8058628688255945}]}, {"text": "It represents an instantiation of the 'one sense per colloca-tion' observation (Gale et al., 1992).", "labels": [], "entities": []}, {"text": "Like most existing approaches it utilizes clustering of word co-occurrences.", "labels": [], "entities": []}, {"text": "This approach differs from other approaches to WSI in that it enhances the effect of the one sense per collocation observation by using triplets of words instead of pairs.", "labels": [], "entities": [{"text": "WSI", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9479875564575195}]}, {"text": "The combination with a two-step clustering process using sentence co-occurrences as features allows for accurate results.", "labels": [], "entities": []}, {"text": "Additionally , a novel and likewise automatic and unsupervised evaluation method inspired by Sch\u00fctze's (1992) idea of evaluation of word sense disambiguation algorithms is employed.", "labels": [], "entities": [{"text": "evaluation of word sense disambiguation algorithms", "start_pos": 118, "end_pos": 168, "type": "TASK", "confidence": 0.6520454635222753}]}, {"text": "Offering advantages like reproducability and independency of a given biased gold standard it also enables automatic parameter optimization of the WSI algorithm.", "labels": [], "entities": []}], "introductionContent": [{"text": "The aim of word sense induction 1 (WSI) is to find senses of a given target word automatically and if possible in an unsupervised manner.", "labels": [], "entities": [{"text": "word sense induction 1 (WSI)", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.7993805110454559}]}, {"text": "WSI is akin to word sense disambiguation (WSD) both in methods employed and in problems encountered, such as vagueness of sense distinctions.", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9204992055892944}, {"text": "word sense disambiguation (WSD)", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.8130604277054468}]}, {"text": "The input to a WSI algorithm is a target word to be disambiguated, e.g. space, and the output is a number of word sets representing the various senses, e.g. (3-dimensional, expanse, locate) and (office, building, square).", "labels": [], "entities": []}, {"text": "Such results can beat the very least used as empirically grounded suggestions for lexicographers or as input for WSD algorithms.", "labels": [], "entities": [{"text": "WSD algorithms", "start_pos": 113, "end_pos": 127, "type": "TASK", "confidence": 0.8992575407028198}]}, {"text": "Other possible uses include automatic thesaurus or ontology construction, machine translation or information retrieval.", "labels": [], "entities": [{"text": "automatic thesaurus or ontology construction", "start_pos": 28, "end_pos": 72, "type": "TASK", "confidence": 0.5971410512924195}, {"text": "machine translation", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7832558453083038}, {"text": "information retrieval", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.8065699636936188}]}, {"text": "But the usefulness of WSI in real-world applications has yet to be tested and proved.", "labels": [], "entities": [{"text": "WSI", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9502938985824585}]}], "datasetContent": [{"text": "Sch\u00fctze (1992) introduced a pseudoword-based evaluation method for WSD algorithms.", "labels": [], "entities": [{"text": "WSD algorithms", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.9287547469139099}]}, {"text": "The idea is to take two arbitrarily chosen words like banana and door and replace all occurrences of either word by the new pseudoword bananadoor.", "labels": [], "entities": []}, {"text": "Then WSD is applied to each sentence and the amount of correctly disambiguated sentences is measured.", "labels": [], "entities": [{"text": "WSD", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.9289132952690125}]}, {"text": "A disambiguation in this case is correct, if the sentence like I ate the banana is assigned to sense #1 (banana) instead of #2 (door).", "labels": [], "entities": []}, {"text": "In other words all sentences where one of the two words occurs are viewed as one set and the WSD algorithm is then supposed to sort them correctly apart.", "labels": [], "entities": []}, {"text": "This, in fact, is very similar to the WSI task, which is supposed to sort the set of words apart that co-occur with the target word and refer to its different meanings.", "labels": [], "entities": [{"text": "WSI task", "start_pos": 38, "end_pos": 46, "type": "TASK", "confidence": 0.9022291600704193}]}, {"text": "Thus, again it is possible to take two words, view their co-occurrences as one set and let the WSI algorithm sort them apart.", "labels": [], "entities": []}, {"text": "For example, the word banana might have cooccurrences such as apple, fruit, coconut, ... and the word door co-occurrences such as open, front, locked, ....", "labels": [], "entities": []}, {"text": "The WSI algorithm would therefore have to disambiguate the pseudoword bananadoor with the co-occurrences apple, open, fruit, front, locked, ....", "labels": [], "entities": []}, {"text": "In short, the method merges the co-occurrences of two words into one set of words.", "labels": [], "entities": []}, {"text": "Then, the WSI algorithm is applied to that set of co-occurrences and the evaluation measures the result by comparing it to the original co-occurrence sets.", "labels": [], "entities": []}, {"text": "In order to find out whether a given sense has been correctly identified by the WSI algorithm, its retrieval precision (rP ) -the similarity of the found sense with the original sense using the overlap measure -can be computed.", "labels": [], "entities": [{"text": "retrieval precision (rP )", "start_pos": 99, "end_pos": 124, "type": "METRIC", "confidence": 0.9670713424682618}, {"text": "overlap measure", "start_pos": 194, "end_pos": 209, "type": "METRIC", "confidence": 0.9574992060661316}]}, {"text": "In the present evaluations, the threshold of 0.6 was chosen, which means that at least 60% of words of the found sense must overlap with the original sense in order to be counted as a correctly found sense.", "labels": [], "entities": []}, {"text": "The average numbers of similarity are much higher, ranging between 85% and 95%.", "labels": [], "entities": [{"text": "similarity", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9972478747367859}]}, {"text": "It is further informative to measure retrieval recall (rR) -the amount of words that have been correctly retrieved into the correct sense.", "labels": [], "entities": [{"text": "retrieval recall (rR) -", "start_pos": 37, "end_pos": 60, "type": "METRIC", "confidence": 0.8741919895013174}]}, {"text": "If, e.g., two words are merged into a pseudoword and the meaning of each of these two words is represented by 200 co-occurring words, then it could happen that one of the senses has been correctly found by the WSI algorithm containing 110 words with an overlap similarity of 0.91.", "labels": [], "entities": []}, {"text": "That means that only 100 words representing the original sense were retrieved, resulting in a 50% retrieval recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.7560395002365112}]}, {"text": "This retrieval recall also has an upper bound for two reasons.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.927270770072937}]}, {"text": "The average overlap ratio of the cooccurrences of the word pairs used for the evaluation was 3.6%.", "labels": [], "entities": [{"text": "overlap ratio", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.9765510857105255}]}, {"text": "Another factor lowering the upper bound by an unknown amount is the fact that some of the words are ambiguous.", "labels": [], "entities": []}, {"text": "If the algorithm correctly finds different senses of one of the two original words, then only one of the found senses will be chosen to represent the original 'meaning' of the original word.", "labels": [], "entities": []}, {"text": "All words assigned to the other sense are lost to the other sense.", "labels": [], "entities": []}, {"text": "Using terms from information retrieval makes sense because this task can be reformulated as follows: Given a set of 400 words and one out of several word senses, try to retrieve all words belonging to that sense (retrieval recall) without retrieving any wrong ones (retrieval precision).", "labels": [], "entities": [{"text": "recall", "start_pos": 223, "end_pos": 229, "type": "METRIC", "confidence": 0.7473888993263245}, {"text": "precision", "start_pos": 276, "end_pos": 285, "type": "METRIC", "confidence": 0.8844273686408997}]}, {"text": "A sense is then defined as correctly found by the WSI algorithm, if its retrieval precision is above 60% and retrieval recall above 25%.", "labels": [], "entities": [{"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.6252336502075195}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.7499459385871887}]}, {"text": "The latter number implies that at least 50 words have to be retrieved correctly since the initial co-occurrence sets contained 200 words.", "labels": [], "entities": []}, {"text": "This also assumes that 50 words would be sufficient to characterize a sense if the WSI algorithm is not only used to evaluate itself.", "labels": [], "entities": []}, {"text": "The reason to set the minimum retrieval precision to any value above 50% is to avoid a too strong baseline, see below.", "labels": [], "entities": [{"text": "minimum retrieval precision", "start_pos": 22, "end_pos": 49, "type": "METRIC", "confidence": 0.5961421529452006}]}, {"text": "Using these prerequisites it is possible to define precision and recall (based on retrieval precision and retrieval recall) which will be used to measure the quality of the WSI algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9993391633033752}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9984032511711121}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.676496684551239}, {"text": "WSI algorithm", "start_pos": 173, "end_pos": 186, "type": "TASK", "confidence": 0.7553516924381256}]}, {"text": "Precision (P ) is defined as the number of times the original co-occurrence sets are properly restored divided by the number of different sets found.", "labels": [], "entities": [{"text": "Precision (P )", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9725731313228607}]}, {"text": "Precision has therefore an unknown upper bound below 100%, because any two words chosen could be ambiguous themselves.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.5418844223022461}]}, {"text": "Thus, if the algorithm finds three meanings of the pseudoword that might be because one of the two words was ambiguous and had two meanings, and hence precision will only be 66%, although the algorithm operated flawlessly.", "labels": [], "entities": [{"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9997335076332092}]}, {"text": "Recall (R) is defined as the number of senses found divided by the number of words merged to create the pseudoword.", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9568943232297897}]}, {"text": "For example, recall is 60% if five words are used to create the pseudoword, but only three senses were found correctly (according to retrieval precision and retrieval recall).", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9994452595710754}, {"text": "recall", "start_pos": 167, "end_pos": 173, "type": "METRIC", "confidence": 0.6030303239822388}]}, {"text": "There is at least one possible baseline for the four introduced measures.", "labels": [], "entities": []}, {"text": "One is an algorithm that does nothing, resulting in a single set of 400 co-occurrences of the pseudo-word.", "labels": [], "entities": []}, {"text": "This set has a retrieval Precision rP of 50% compared to either of the two original 'senses' because for any of the two senses only half of the 'retrieved' words match.", "labels": [], "entities": [{"text": "Precision rP", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.945455014705658}]}, {"text": "This is below the allowed 60% and thus does not count as a correctly found sense.", "labels": [], "entities": []}, {"text": "This means that also retrieval Recall rR, Recall R are both 0% and Precision P in such a case (nothing correctly retrieved, but also nothing wrong retrieved) is defined to be 100%.", "labels": [], "entities": [{"text": "Recall R", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.7910292446613312}, {"text": "Precision P", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.9877051115036011}]}, {"text": "As mentioned in the previous sections, there are several parameters that have a strong impact on the quality of a WSI algorithm.", "labels": [], "entities": [{"text": "WSI algorithm", "start_pos": 114, "end_pos": 127, "type": "TASK", "confidence": 0.9167527854442596}]}, {"text": "One interesting question is, whether the quality of disambiguation depends on the type of ambiguity: Would the WSI based on sentence co-occurrences (and hence on the bag-of-words model) produce better results for two syntactically different senses or for two senses differing by topic (as predicted by).", "labels": [], "entities": []}, {"text": "This can be simulated by choosing two words of different word classes to create the pseudoword, such as the (dominantly) noun committee and the (dominantly) verb accept.", "labels": [], "entities": []}, {"text": "Another interesting question concerns the influence of frequency of either the word itself or the sense to be found.", "labels": [], "entities": []}, {"text": "The latter, for example, can be simulated by choosing one high-frequent word and one low-frequent word, thus representing a well-represented vs. a poorly represented sense.", "labels": [], "entities": []}, {"text": "The aim of the evaluation is to test the described parameters and produce an overall average of precision and recall and at the same time make it completely reproducable by third parties.", "labels": [], "entities": [{"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9996026158332825}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9990235567092896}]}, {"text": "Therefore the raw BNC without baseform reduction (because lemmatization introduces additional ambiguity) or POS-tags was used and nine groups each containing five words were picked semi-randomly (avoiding extremely ambiguous words, with respect to WordNet, if possible): \u2022 high frequent nouns (N h ): picture, average, blood, committee, economy \u2022 medium frequent nouns (N m ): disintegration, substrate, emigration, thirst, saucepan \u2022 low frequent nouns (N l ): paratuberculosis, gravitation, pharmacology, papillomavirus, sceptre \u2022 high frequent verbs (V h ): avoid, accept, walk, agree, write \u2022 medium frequent verbs (V m ): rend, confine, uphold, evoke, varnish \u2022 low frequent verbs (V l ): immerse, disengage, memorize, typify, depute \u2022 high frequent adjectives (A h ): useful, deep, effective, considerable, traditional \u2022 medium frequent adjectives (A m ): ferocious, normative, phenomenal, vibrant, inactive \u2022 low frequent adjectives (A l ): astrological, crispy, unrepresented, homoclinic, bitchy These nine groups were used to design fours tests, each focussing on a different variable.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 248, "end_pos": 255, "type": "DATASET", "confidence": 0.9644564390182495}]}, {"text": "The high frequent nouns are around 9000 occurrences, medium frequent around 300 and low frequent around 50.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Influence of the syntactic class of the in- put word in Test 1. Showing precision P and re- call R, as well as average retrieval precision rP  and recall rR.", "labels": [], "entities": [{"text": "precision P", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.94181227684021}, {"text": "re- call R", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.8295303285121918}, {"text": "average retrieval precision rP", "start_pos": 121, "end_pos": 151, "type": "METRIC", "confidence": 0.656839519739151}, {"text": "recall rR", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9588724970817566}]}, {"text": " Table 3: Influence of frequency of the input word  in Test 3.", "labels": [], "entities": [{"text": "Influence", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9623607397079468}]}, {"text": " Table 4: Influence of different representation of  senses based on frequency of the two constituents  of the pseudoword in Test 4.", "labels": [], "entities": []}]}