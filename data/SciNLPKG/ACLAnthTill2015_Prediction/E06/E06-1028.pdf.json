{"title": [{"text": "A Figure of Merit for the Evaluation of Web-Corpus Randomness", "labels": [], "entities": [{"text": "Randomness", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.5384472608566284}]}], "abstractContent": [{"text": "In this paper, we present an automated, quantitative, knowledge-poor method to evaluate the randomness of a collection of documents (corpus), with respect to a number of biased partitions.", "labels": [], "entities": []}, {"text": "The method is based on the comparison of the word frequency distribution of the target corpus to word frequency distributions from corpora builtin deliberately biased ways.", "labels": [], "entities": []}, {"text": "We apply the method to the task of building a corpus via queries to Google.", "labels": [], "entities": []}, {"text": "Our results indicate that this approach can be used, reliably, to discriminate biased and unbi-ased document collections and to choose the most appropriate query terms.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Web is a very rich source of linguistic data, and in the last few years it has been used intensively by linguists and language technologists for many tasks.", "labels": [], "entities": []}, {"text": "Among other uses, the Web allows fast and inexpensive construction of \"general purpose\" corpora, i.e., corpora that are not meant to represent a specific sub-language, but a language as a whole.", "labels": [], "entities": []}, {"text": "There are several recent studies on the extent to which Web-derived corpora are comparable, in terms of variety of topics and styles, to traditional \"balanced\" corpora).", "labels": [], "entities": []}, {"text": "Our contribution, in this paper, is to present an automated, quantitative method to evaluate the \"variety\" or \"randomness\" (with respect to a number of non-random partitions) of a Web corpus.", "labels": [], "entities": []}, {"text": "The more random/less-biased towards specific partitions a corpus is, the more it should be suitable as a general purpose corpus.", "labels": [], "entities": []}, {"text": "We are not proposing a method to evaluate whether a sample of Web pages is a random sample of the Web, although this is a related issue).", "labels": [], "entities": []}, {"text": "Instead, we propose a method, based on simple distributional properties, to evaluate if a sample of Web pages in a certain language is reasonably varied in terms of the topics (and, perhaps, textual types) it contains.", "labels": [], "entities": []}, {"text": "This is independent from whether they are actually proportionally representing what is out thereon the Web or not.", "labels": [], "entities": []}, {"text": "For example, although computer-related technical language is probably much more common on the Web than, say, the language of literary criticism, one might prefer a biased retrieval method that fetches documents representing these and other sub-languages in comparable amounts, to an unbiased method that leads to a corpus composed mostly of computer jargon.", "labels": [], "entities": []}, {"text": "This is anew area of investigationwith traditional corpora, one knows a priori their composition.", "labels": [], "entities": []}, {"text": "As the Web plays an increasingly central role as data source in NLP, we believe that methods to efficiently characterize the nature of automatically retrieved data are becoming of central importance to the discipline.", "labels": [], "entities": [{"text": "characterize the nature of automatically retrieved data", "start_pos": 108, "end_pos": 163, "type": "TASK", "confidence": 0.7296490839549473}]}, {"text": "In the empirical evaluation of the method, we focus on general purpose corpora built issuing automated queries to a search engine and retrieving the corresponding pages, which has been shown to bean easy and effective way to build Web-based corpora (; Ueyama and).", "labels": [], "entities": []}, {"text": "It is natural to ask which kinds of query terms, henceforth seeds, are more appropriate to build a corpus comparable, in terms of variety, to traditional balanced corpora such as the British National Corpus, henceforth BNC.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 183, "end_pos": 206, "type": "DATASET", "confidence": 0.9252124230066935}, {"text": "BNC", "start_pos": 219, "end_pos": 222, "type": "DATASET", "confidence": 0.9240489602088928}]}, {"text": "We test our procedure to assess Web-corpus randomness on corpora built using seeds chosen following different strategies.", "labels": [], "entities": []}, {"text": "However, the method per se can also be used to assess the randomness of corpora builtin other ways; e.g., by crawling the Web.", "labels": [], "entities": []}, {"text": "Our method is based on the comparison of the word frequency distribution of the target corpus to word frequency distributions constructed using queries to a search engine for deliberately biased seeds.", "labels": [], "entities": []}, {"text": "As such, it is nearly resource-free, as it only requires lists of words belonging to specific domains that can be used as biased seeds.", "labels": [], "entities": []}, {"text": "In our experiments we used Google as the search engine of choice, but different search engines could be used as well, or other ways to obtain collections of biased documents, e.g., via a directory of precategorized Web-pages.", "labels": [], "entities": []}], "datasetContent": [{"text": "From each source list we randomly select 20 pairs of words without replacement.", "labels": [], "entities": []}, {"text": "Each pair is used as a query to Google, asking for pages in English only.", "labels": [], "entities": []}, {"text": "Pairs are used instead of single words to maximize our chances to find documents that contain running text).", "labels": [], "entities": []}, {"text": "For each query, we retrieve a maximum of 20 documents.", "labels": [], "entities": []}, {"text": "The whole procedure is repeated 20 times with all lists, so that we can compute the mean distances to fill the distance matrices.", "labels": [], "entities": []}, {"text": "Our unit of analysis is the corpus of all the non-duplicated documents retrieved with a set of 20 paired word queries.", "labels": [], "entities": []}, {"text": "The documents retrieved from the Web undergo post-processing, including filtering by minimum and maximum size, removal of HTML code and \"boilerplate\" (navigational information and similar) and heuristic filtering of documents that do not contain connected text.", "labels": [], "entities": []}, {"text": "A corpus can contain maximally 400 documents (20 queries times 20 documents retrieved per query), although typically the documents retrieved are less, because of duplicates, or because some query pairs are found in less than 20 documents.", "labels": [], "entities": []}, {"text": "summarizes the average size in terms of word types, tokens and number of documents of the resulting corpora.", "labels": [], "entities": []}, {"text": "Queries for the unbiased seeds tend to retrieve more documents except for the BNC.af set, which, as expected, found considerably less data than the other unbiased sets.", "labels": [], "entities": [{"text": "BNC.af set", "start_pos": 78, "end_pos": 88, "type": "DATASET", "confidence": 0.9625647664070129}]}, {"text": "Most of the differences are not statistically significant and, as the table shows, the difference in number of documents is often counterbalanced by the fact that specialized queries tend to retrieve longer documents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Average number of types, tokens and docu- ments of corpora constructed with Google queries (type  and token sizes in thousands).", "labels": [], "entities": []}, {"text": " Table 3. Mean scores based on \u03b4 with bootstrap standard error (B=10). In bold the lowest (best) score in each  column, always the unbiased category.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9945626854896545}, {"text": "bootstrap standard error", "start_pos": 38, "end_pos": 62, "type": "METRIC", "confidence": 0.8189663092295328}, {"text": "B", "start_pos": 64, "end_pos": 65, "type": "METRIC", "confidence": 0.5819754600524902}]}]}