{"title": [{"text": "An Algorithm for Pronominal Anaphora Resolution", "labels": [], "entities": [{"text": "Pronominal Anaphora", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.6610772460699081}]}], "abstractContent": [{"text": "This paper presents an algorithm for identifying the noun phrase antecedents of third person pronouns and lexical anaphors (reflexives and reciprocals).", "labels": [], "entities": []}, {"text": "The algorithm applies to the syntactic representations generated by McCord's Slot Grammar parser and relies on salience measures derived from syntactic structure and a simple dynamic model of attentional state.", "labels": [], "entities": []}, {"text": "Like the parser, the algorithm is implemented in Prolog.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9470981359481812}]}, {"text": "The authors have tested it extensively on computer manual texts and conducted a blind test on manual text containing 360 pronoun occurrences.", "labels": [], "entities": []}, {"text": "The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun occurrences.", "labels": [], "entities": []}, {"text": "The relative contributions of the algorithm's components to its overall success rate in this blind test are examined.", "labels": [], "entities": []}, {"text": "Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.", "labels": [], "entities": []}, {"text": "Interestingly, this enhancement only marginally improves the algorithm's performance (by 2%).", "labels": [], "entities": []}, {"text": "The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.794851690530777}]}, {"text": "In particular, the search procedure of Hobbs'algorithm was implemented in the Slot Grammar framework and applied to the sentences in the blind test set.", "labels": [], "entities": [{"text": "Slot Grammar framework", "start_pos": 78, "end_pos": 100, "type": "DATASET", "confidence": 0.5848894317944845}]}, {"text": "The authors\" algorithm achieves a higher rate of success (4%) than Hobbs' algorithm.", "labels": [], "entities": []}, {"text": "The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.751887708902359}]}], "introductionContent": [{"text": "We present an algorithm for identifying both intrasentential and intersentential antecedents of pronouns in text.", "labels": [], "entities": []}, {"text": "We refer to this algorithm as RAP (Resolution of Anaphora Procedure).", "labels": [], "entities": [{"text": "RAP", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.8626804351806641}]}, {"text": "RAP applies to the syntactic structures of) Slot Grammar parser, and like the parser, it is implemented in Prolog.", "labels": [], "entities": [{"text": "RAP", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7481356859207153}, {"text": "Slot Grammar parser", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.6468709111213684}, {"text": "Prolog", "start_pos": 107, "end_pos": 113, "type": "DATASET", "confidence": 0.9559969305992126}]}, {"text": "It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase (NP) of a pronoun from a list of candidates.", "labels": [], "entities": []}, {"text": "It does not employ semantic conditions (beyond those implicit in grammatical number and gender agreement) or real-world knowledge in evaluating candidate antecedents; nor does it model intentional or global discourse structure (as in.", "labels": [], "entities": []}, {"text": "In Section 2 we present RAP and discuss its main properties.", "labels": [], "entities": [{"text": "RAP", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.8822318315505981}]}, {"text": "We provide examples of its output for different sorts of cases in Section 3.", "labels": [], "entities": []}, {"text": "Most of these examples are taken from the computer manual texts on which we trained the algorithm.", "labels": [], "entities": []}, {"text": "We give the results of a blind test in Section 4, as well as an analysis of the relative contributions of the algorithm's components to the overall success rate.", "labels": [], "entities": []}, {"text": "In Section 5 we discuss a procedure developed by for using statistically measured lexical preference patterns to reevaluate RAP's salience rankings of antecedent candidates.", "labels": [], "entities": [{"text": "RAP", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.8395074605941772}]}, {"text": "We present the results of a comparative blind test of RAP and this procedure.", "labels": [], "entities": [{"text": "RAP", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.8822579979896545}]}, {"text": "Finally, in Section 6 we compare RAP to several other approaches to anaphora resolution that have been proposed in the computational literature.", "labels": [], "entities": [{"text": "RAP", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9833206534385681}, {"text": "anaphora resolution", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7992335259914398}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3  Results of blind test", "labels": [], "entities": []}, {"text": " Table 5  Results of blind test (Hobbs' algorithm)", "labels": [], "entities": []}]}