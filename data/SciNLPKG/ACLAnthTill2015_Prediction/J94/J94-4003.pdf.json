{"title": [{"text": "Word Sense Disambiguation Using a Second Language Monolingual Corpus", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7448442975680033}]}], "abstractContent": [{"text": "This paper presents anew approach for resolving lexical ambiguities in one language using statistical data from a monolingual corpus of another language.", "labels": [], "entities": [{"text": "resolving lexical ambiguities", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.8398787975311279}]}, {"text": "This approach exploits the differences between mappings of words to senses in different languages.", "labels": [], "entities": []}, {"text": "The paper concentrates on the problem of target word selection in machine translation, for which the approach is directly applicable.", "labels": [], "entities": [{"text": "target word selection", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.6570510268211365}, {"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.6762199699878693}]}, {"text": "The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon.", "labels": [], "entities": []}, {"text": "The preferred senses are then selected according to statistics on lexical relations in the target language.", "labels": [], "entities": []}, {"text": "The selection is based on a statistical model and on a constraint propagation algorithm, which simultaneously handles all ambiguities in the sentence.", "labels": [], "entities": []}, {"text": "The method was evaluated using three sets of Hebrew and German examples and was found to be very useful for disambiguation.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.973637580871582}]}, {"text": "The paper includes a detailed comparative analysis of statistical sense disambiguation methods.", "labels": [], "entities": [{"text": "statistical sense disambiguation", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.7310712138811747}]}], "introductionContent": [{"text": "The resolution of lexical ambiguities in nonrestricted text is one of the most difficult tasks of natural language processing.", "labels": [], "entities": [{"text": "resolution of lexical ambiguities in nonrestricted text", "start_pos": 4, "end_pos": 59, "type": "TASK", "confidence": 0.8933572939464024}, {"text": "natural language processing", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.6494832734266917}]}, {"text": "A related task in machine translation, on which we focus in this paper, is target word selection.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7962263524532318}, {"text": "target word selection", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.6622822086016337}]}, {"text": "This is the task of deciding which target language word is the most appropriate equivalent of a source language word in context.", "labels": [], "entities": []}, {"text": "In addition to the alternatives introduced by the different word senses of the source language word, the target language may specify additional alternatives that differ mainly in their usage.", "labels": [], "entities": []}, {"text": "Traditionally, several linguistic levels were used to deal with this problem: syntactic, semantic, and pragmatic.", "labels": [], "entities": []}, {"text": "Computationally, the syntactic methods are the most affordable, but are of no avail in the frequent situation when the different senses of the word show the same syntactic behavior, having the same part of speech and even the same subcategorization frame.", "labels": [], "entities": []}, {"text": "Substantial application of semantic or pragmatic knowledge about the word and its context requires compiling huge amounts of knowledge, the usefulness of which for practical applications in broad domains has not yet been proven (e.g.,.", "labels": [], "entities": [{"text": "Substantial application of semantic or pragmatic knowledge about the word and its context", "start_pos": 0, "end_pos": 89, "type": "TASK", "confidence": 0.7930063009262085}]}, {"text": "Moreover, such methods usually do not reflect word usages.", "labels": [], "entities": []}, {"text": "Statistical approaches, which were popular several decades ago, have recently reawakened and were found to be useful for computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.8665158450603485}]}, {"text": "Within this framework, a possible (though partial) alternative to using manually constructed knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora (e.g.,.", "labels": [], "entities": []}, {"text": "The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research.", "labels": [], "entities": []}, {"text": "More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment and pronoun references.", "labels": [], "entities": [{"text": "prepositional phrase attachment and pronoun references", "start_pos": 122, "end_pos": 176, "type": "TASK", "confidence": 0.7834137082099915}]}, {"text": "Clearly, statistics on lexical relations can also be useful for target word selection.", "labels": [], "entities": [{"text": "target word selection", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.6259637673695883}]}, {"text": "Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Ha-Aretz, September 1990 (transcripted to Latin letters): (1) Nose ze mana\" mi-shtei ha-mdinot mi-lahtom \"al hoze shalom.", "labels": [], "entities": [{"text": "foreign news section of the daily Ha-Aretz, September 1990", "start_pos": 62, "end_pos": 120, "type": "DATASET", "confidence": 0.7040162116289139}]}, {"text": "issue this prevented from-two the-countries from-signing on treaty peace This sentence would translate into English as This issue prevented the two countries from signing a peace treaty.", "labels": [], "entities": []}, {"text": "The verb lahtom has four senses: 'sign,' 'seal,' 'finish,' and 'close.'", "labels": [], "entities": []}, {"text": "The noun hoze means both 'contract' and 'treaty,' where the difference is mainly in usage rather than in the meaning (in Hebrew the word h.oze is used for both sub-senses).", "labels": [], "entities": []}, {"text": "One possible solution is to consult a Hebrew corpus tagged with word senses, from which we would probably learn that the sense 'sign' of lahtom appears more frequently with hoze as its object than all the other senses.", "labels": [], "entities": []}, {"text": "Thus we should prefer that sense.", "labels": [], "entities": []}, {"text": "However, the size of corpora required to identify lexical relations in abroad domain is very large, and therefore it is usually not feasible to have such corpora manually tagged with word senses) The problem of choosing between 'treaty' and 'contract' cannot be solved using only information on Hebrew, because Hebrew does not distinguish between them.", "labels": [], "entities": []}, {"text": "The solution suggested in this paper is to identify the lexical relations in corpora of the target language, instead of the source language.", "labels": [], "entities": []}, {"text": "We consider word combinations and count how often they appear in the same syntactic relation as in the ambiguous sentence.", "labels": [], "entities": []}, {"text": "For the above example, the noun compound 'peace treaty' appeared 49 times in our corpus (see Section 4.3 for details on our corpus), whereas the compound 'peace contract' did not appear at all; the verb-obj combination 'to sign a treaty' appeared 79 times, whereas none of the other three alternatives appeared more than twice.", "labels": [], "entities": []}, {"text": "Thus, we first prefer 'treaty' to 'contract' because of the noun compound 'peace treaty' and then proceed to prefer 'sign' since it appears most frequently having the object 'treaty.", "labels": [], "entities": []}, {"text": "The order of selection is determined by a constraint propagation algorithm.", "labels": [], "entities": []}, {"text": "In both cases, the correctly selected word is not the most frequent one: 'close' is more frequent in our corpus than 'sign' and 'contract' is more frequent than 'treaty.'", "labels": [], "entities": []}, {"text": "Also, by using a model of statistical confidence, the algorithm avoids a decision in cases in which no alternative is significantly better than the others.", "labels": [], "entities": []}, {"text": "Our approach can be analyzed from two different points of view.", "labels": [], "entities": []}, {"text": "From that of monolingual sense disambiguation, we exploit the fact that the mapping between words and word senses varies significantly among different languages.", "labels": [], "entities": [{"text": "monolingual sense disambiguation", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.6634293297926585}]}, {"text": "This enables US to map an ambiguous construct from one language to another, obtaining representations in which each sense corresponds to a distinct word.", "labels": [], "entities": []}, {"text": "Now it is possible to collect co-occurrence statistics automatically from a corpus of the other language, without requiring manual tagging of senses.", "labels": [], "entities": []}, {"text": "From the point of view of machine translation, we suggest that some ambiguity problems are easier to solve at the level of the target language than the source language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7951763570308685}]}, {"text": "The source language sentences are considered a noisy source for target language sentences, and our task is to devise a target language model that prefers the most reasonable translation.", "labels": [], "entities": []}, {"text": "Machine translation is thus viewed in part as a recognition problem, and the statistical model we use specifically for target word selection maybe compared with other language models in recognition tasks (e.g.,, for speech recognition).", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8292458653450012}, {"text": "speech recognition", "start_pos": 216, "end_pos": 234, "type": "TASK", "confidence": 0.805843323469162}]}, {"text": "To a limited extent, this view is shared with the statistical machine translation system of, which employs a target language n-gram model (see Section 8 fora comparison with this system).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.6265805761019388}]}, {"text": "In contrast to this view, previous approaches in machine translation typically resolve examples like (1) by stating various constraints in terms of the source language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7798400521278381}]}, {"text": "As explained above, such constraints cannot be acquired automatically and therefore are usually limited in their coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9314267635345459}]}, {"text": "The experiments we conducted clearly show that statistics on lexical relations are very useful for disambiguation.", "labels": [], "entities": []}, {"text": "Most notable is the result for the set of examples of Hebrew to English translation, which was picked randomly from foreign news sections in the Israeli press.", "labels": [], "entities": [{"text": "Hebrew to English translation", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.7168744206428528}]}, {"text": "For this set, the statistical model was applicable for 70% of the ambiguous words, and its selection was then correct for 91% of the cases.", "labels": [], "entities": []}, {"text": "We cite also the results of a later experiment that tested a weaker variant of our method on texts in the computer domain, achieving a precision of 85%.", "labels": [], "entities": [{"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9990869760513306}]}, {"text": "Both results significantly improve upon a naive method that uses only a priori word probabilities.", "labels": [], "entities": []}, {"text": "These results are comparable to recent reports in the literature (see Section 7).", "labels": [], "entities": []}, {"text": "It should be emphasized, though, that our results were achieved fora realistic simulation of abroad coverage machine translation system, on randomly selected examples.", "labels": [], "entities": [{"text": "abroad coverage machine translation", "start_pos": 93, "end_pos": 128, "type": "TASK", "confidence": 0.4989117458462715}]}, {"text": "We therefore believe that our figures reflect the expected performance of the algorithm in a practical implementation.", "labels": [], "entities": []}, {"text": "On the other hand, most other results relate to a small number of words and senses that were determined by the experimenters.", "labels": [], "entities": []}, {"text": "Section 2 of the paper describes the linguistic model we use, employing a syntactic parser and a bilingual lexicon.", "labels": [], "entities": []}, {"text": "Section 3 presents the statistical model, assuming a multinomial model fora single lexical relation and then using a constraint propagation algorithm to account simultaneously for all relations in the sentence.", "labels": [], "entities": []}, {"text": "Section 4 describes the experimental Setting.", "labels": [], "entities": [{"text": "Setting", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.945335865020752}]}, {"text": "Section 5 presents and analyzes the results of the experiment and cites additional results.", "labels": [], "entities": []}, {"text": "In Section 6 we analyze the limitations of the algorithm in different cases and suggest enhancements to improve it.", "labels": [], "entities": []}, {"text": "We also discuss the possibility of adopting the algorithm for monolingual applications.", "labels": [], "entities": []}, {"text": "Finally, in Section 7 we present a comparative analysis of statistical sense disambiguation methods and then conclude in Section 8. 2 A similar observation underlies the use of parallel bilingual corpora for sense disambiguation (.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.6937930881977081}, {"text": "sense disambiguation", "start_pos": 208, "end_pos": 228, "type": "TASK", "confidence": 0.7073084563016891}]}, {"text": "As we explain in Section 7, these corpora area form of a manually tagged corpus and are more difficult to obtain than monolingual corpora.", "labels": [], "entities": []}, {"text": "Erroneously, the preliminary publication of our method was cited several times as requiring a parallel bilingual corpus,", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the proposed disambiguation method, we implemented and tested the method on a random set of examples.", "labels": [], "entities": []}, {"text": "The examples consisted of a set of Hebrew paragraphs and a set of German paragraphs.", "labels": [], "entities": []}, {"text": "In both cases the target language was English.", "labels": [], "entities": []}, {"text": "The Hebrew examples consisted often paragraphs picked at random from foreign news sections of the Israeli press.", "labels": [], "entities": []}, {"text": "The paragraphs were selected from several news items and articles that appeared in several daily newspapers.", "labels": [], "entities": []}, {"text": "The target language corpus consisted of American newspaper articles, and the Hansard corpus of the proceedings of the Canadian Parliament.", "labels": [], "entities": [{"text": "Hansard corpus of the proceedings of the Canadian Parliament", "start_pos": 77, "end_pos": 137, "type": "DATASET", "confidence": 0.9336044523451064}]}, {"text": "The domain of foreign news articles was chosen to correspond to some of the topics that appear in the English corpus, s The German examples were chosen at random from the German press, without restricting the topic.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.7706785500049591}]}, {"text": "9 Since we did not have a translation system from Hebrew or German to English, we simulated the steps such a system would perform.", "labels": [], "entities": []}, {"text": "Hence, the results we report measure the performance of just the target word selection module and not the performance of a complete translation system.", "labels": [], "entities": []}, {"text": "The latter can be expected to be somewhat lower fora real system, depending on the performance of its other components.", "labels": [], "entities": []}, {"text": "Note, however, that since the disambiguation module is highly immune to noise, it might be more useful in areal system: in such a system some of the alternatives would be totally erroneous.", "labels": [], "entities": []}, {"text": "Since the corresponding syntactic tuples would typically not be found in the corpora, they would be eliminated by our module.", "labels": [], "entities": []}, {"text": "The experiment is described in detail in the following subsections.", "labels": [], "entities": []}, {"text": "It provides an example fora thorough evaluation that is carried out without having a complete system available.", "labels": [], "entities": []}, {"text": "We specifically describe the processing of the Hebrew data, which was performed by a professional translator, supervised by the authors.", "labels": [], "entities": []}, {"text": "The German examples were processed very similarly.", "labels": [], "entities": []}, {"text": "Two measurements, applicability and precision, are used to evaluate the performance of the algorithm.", "labels": [], "entities": [{"text": "applicability", "start_pos": 18, "end_pos": 31, "type": "METRIC", "confidence": 0.9778627157211304}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9994148015975952}]}, {"text": "The applicability (coverage) denotes the proportion of cases for which the model performed a selection, i.e., those cases for which the bound B~ passed the threshold.", "labels": [], "entities": [{"text": "applicability (coverage)", "start_pos": 4, "end_pos": 28, "type": "METRIC", "confidence": 0.7911747395992279}]}, {"text": "The precision denotes the proportion of cases for which the model performed a correct selection out of all the applicable cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.999030590057373}]}, {"text": "We compare the precision of our method, which we term TWS (for Target Word Selection), with that of the Word Frequencies procedure, which always selects the most frequent target word.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9995759129524231}, {"text": "TWS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.8499181270599365}]}, {"text": "In other words, the Word Frequencies method prefers the alternative that has the highest a priori probability of appearing in the target language corpus.", "labels": [], "entities": []}, {"text": "This naive \"straw-man\" is less sophisticated than other methods suggested in the literature, but it is useful as a common benchmark since it can be easily implemented.", "labels": [], "entities": []}, {"text": "The success rate of the Word Frequencies procedure can serve as a measure for the degree of lexical ambiguity in a given set of examples, and thus different methods can be partly compared by their degree of success relative to this procedure.", "labels": [], "entities": []}, {"text": "Out of the 103 ambiguous Hebrew words, for 33 the bound B~ did not pass the threshold, achieving an applicability of 68%.", "labels": [], "entities": [{"text": "B", "start_pos": 56, "end_pos": 57, "type": "METRIC", "confidence": 0.8771568536758423}, {"text": "applicability", "start_pos": 100, "end_pos": 113, "type": "METRIC", "confidence": 0.9954054355621338}]}, {"text": "The remaining 70 examples were distributed according to.", "labels": [], "entities": []}, {"text": "Thus the precision of the statistical model was 91% The number of Hebrew examples is large enough to permit a meaningful analysis of the statistical significance of the results.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9996349811553955}]}, {"text": "By computing confidence intervals for the distribution of proportions, we claim that with 95% confidence our method succeeds in at least 86% of the applicable examples.", "labels": [], "entities": []}, {"text": "This means that though the figure of 91% might be due to a lucky selection of the random examples, there is only a 5% chance that the real figure is less than 86% (for the given domain and corpus).", "labels": [], "entities": []}, {"text": "The confidence interval was computed as follows: p~f~_Zl_c~f~) f-~4 . 6 -70 1\"65V 7\u00b0-7-07\u00b0 -0\"86' where a = 0.05 and the variance is estimated by ]~(1 -f))/n.", "labels": [], "entities": []}, {"text": "With the same confidence, our method improves the Word Frequencies method by at least 18% (relative to the actual improvement of 28% in the given test set).", "labels": [], "entities": []}, {"text": "Let Pl be the proportion of cases for which our method succeeds and the Word Frequencies method fails (Pl = 22/70) and P2 be the proportion of cases for which the Word Frequencies method succeeds and ours fails (P2 = 2/70).", "labels": [], "entities": []}, {"text": "The confidence interval is for the difference of proportions in multinomial distribution and is computed as follows: Out of the 54 ambiguous German words, for 27 the bound B~ did not pass the threshold (applicability of 50%).", "labels": [], "entities": [{"text": "confidence interval", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.9577686786651611}, {"text": "applicability", "start_pos": 203, "end_pos": 216, "type": "METRIC", "confidence": 0.9717851877212524}]}, {"text": "The remaining 27 examples were distributed according to.", "labels": [], "entities": []}, {"text": "Thus, the precision of the statistical model was 78% (21/27), whereas Ana posteriori observation showed that in three of the six errors the selection of the model was actually acceptable, and the a priori judgment of the human translator was too restrictive.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9997336268424988}]}, {"text": "For example, in one of these cases the statistics selected the expression 'to begin the talks,' whereas the human translator regarded this expression as incorrect and selected 'to start the talks.'", "labels": [], "entities": []}, {"text": "If we consider these cases as correct, then there are only three selection errors, getting 96% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9991355538368225}]}, {"text": "relying just on Word Frequencies yields 56%.", "labels": [], "entities": [{"text": "Word Frequencies", "start_pos": 16, "end_pos": 32, "type": "DATASET", "confidence": 0.8503476083278656}]}, {"text": "Here our method corrected 6 errors of the Word Frequencies method, without causing any new errors.", "labels": [], "entities": []}, {"text": "We attribute the lower success rate for the German examples to the fact that they were not restricted to topics that are well represented in the corpus.", "labels": [], "entities": []}, {"text": "This poor correspondence between the training and testing texts is reflected also by the low precision of the Word Frequencies method.", "labels": [], "entities": [{"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9992935657501221}]}, {"text": "This means that the a priori probability of the target words, as estimated from the training corpora, provides a very poor prediction of the correct selection in the test examples.", "labels": [], "entities": []}, {"text": "Relative to the a priori probability, the precision of our method is still 22% higher.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9998058676719666}]}, {"text": "In most of the above-mentioned papers, experimental results are reported fora small set of up to 12 preselected words, usually with two or three senses per word.", "labels": [], "entities": []}, {"text": "In the current paper we have evaluated our method using a random set of example sentences, with no a priori selection of the words.", "labels": [], "entities": []}, {"text": "This standard evaluation method, which is commonly used for other natural language processing tasks, provides a direct prediction for the expected success rate of the method when employed in a practical application.", "labels": [], "entities": []}, {"text": "To compare results on different test data, it is useful to compare the precision of the disambiguation method with some a priori figure that reflects the degree of ambiguity in the text.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9992222785949707}]}, {"text": "Reporting the number of senses per example word corresponds to the expected success rate of random selection.", "labels": [], "entities": []}, {"text": "A more informative figure is the success rate of a naive method that always selects the most frequent sense (the Word Frequencies method in our evaluations).", "labels": [], "entities": []}, {"text": "The success rate of this naive method is higher than that of random selection and thus provides a tighter lower bound for the desired precision of a proposed disambiguation method.", "labels": [], "entities": [{"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9984157085418701}]}, {"text": "An important practical issue in evaluation is how to get the test examples, which should be tagged with the correct sense.", "labels": [], "entities": []}, {"text": "In most papers (including ours) the tagging of the test data was done by hand, which limits the size of the testing set.", "labels": [], "entities": []}, {"text": "Preparing one test set by hand may still be reasonable, though time consuming.", "labels": [], "entities": []}, {"text": "However, it is useful to have more than one set, such that results will be reported on anew, unseen, set, while another set is used for developing and tuning the system.", "labels": [], "entities": []}, {"text": "One useful source of tagged examples is an aligned bilingual corpus, which can be used for testing any sense disambiguation method, including methods that do not use bilingual material for training.", "labels": [], "entities": []}, {"text": "Gale proposes to use \"pseudo-words\" as another practical source of testing examples (Gale, Church, and Yarowsky 1992b) (equivalently, Schfitze uses \"artificial ambiguous words\").", "labels": [], "entities": []}, {"text": "Pseudo-words are constructed artificially as a union of several different words (say, wl, w2, and w3 define three \"senses\" of the pseudo-word x).", "labels": [], "entities": []}, {"text": "The disambiguation method is presented with texts in which all occurrences of wl,, and w3 are considered as occurrences of x and should then select the original word (sense) for each occurrence.", "labels": [], "entities": []}, {"text": "Though testing with this method does not provide results for real ambiguities that occur in the text, it can be very useful while develop-ing and tuning the method (Gale shows high correlation between the performance of his method on real sense ambiguities and pseudo-words).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Thus, the precision of the statistical model was 78% (21/27), whereas", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9998216032981873}]}, {"text": " Table 4  Comparison of TWS' and Word Frequencies methods for  the 173 applicable examples", "labels": [], "entities": []}, {"text": " Table 4. For the words that are covered by the TWS' method,  the Word Frequencies method has a precision of 71.1% (123/173), whereas the TWS'  method has a precision of 85.5%(148/173). As can be seen in the table, the TWS' method  is correct in almost all the cases it disagrees with the Word Frequencies method (28 out  of 31). The applicability and precision figures in this experiment are somewhat lower  than those achieved for the Hebrew set in our original evaluation of the TWS method", "labels": [], "entities": [{"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.993553876876831}, {"text": "precision", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9712342023849487}, {"text": "applicability", "start_pos": 334, "end_pos": 347, "type": "METRIC", "confidence": 0.9809985756874084}, {"text": "precision", "start_pos": 352, "end_pos": 361, "type": "METRIC", "confidence": 0.9963685274124146}]}]}