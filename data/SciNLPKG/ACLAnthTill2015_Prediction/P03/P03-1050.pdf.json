{"title": [{"text": "Unsupervised Learning of Arabic Stemming using a Parallel Corpus", "labels": [], "entities": [{"text": "Unsupervised Learning of Arabic Stemming", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6278516232967377}]}], "abstractContent": [{"text": "This paper presents an unsupervised learning approach to building a non-English (Arabic) stemmer.", "labels": [], "entities": []}, {"text": "The stemming model is based on statistical machine translation and it uses an English stemmer and a small (10K sentences) parallel corpus as its sole training resources.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6324199438095093}]}, {"text": "No parallel text is needed after the training phase.", "labels": [], "entities": []}, {"text": "Mono-lingual, unannotated text can be used to further improve the stemmer by allowing it to adapt to a desired domain or genre.", "labels": [], "entities": []}, {"text": "Examples and results will be given for Arabic , but the approach is applicable to any language that needs affix removal.", "labels": [], "entities": []}, {"text": "Our resource-frugal approach results in 87.5% agreement with a state of the art, proprietary Arabic stemmer built using rules, affix lists, and human annotated text, in addition to an unsupervised component.", "labels": [], "entities": []}, {"text": "Task-based evaluation using Arabic information retrieval indicates an improvement of 22-38% in average precision over unstemmed text, and 96% of the performance of the proprietary stem-mer above.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9579620361328125}]}], "introductionContent": [{"text": "Stemming is the process of normalizing word variations by removing prefixes and suffixes.", "labels": [], "entities": [{"text": "normalizing word variations", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.7933123111724854}]}, {"text": "From an \u2020 Work done while a summer intern at IBM TJ Watson Research Center information retrieval point of view, prefixes and suffixes add little or no additional meaning; inmost cases, both the efficiency and effectiveness of text processing applications such as information retrieval and machine translation are improved.", "labels": [], "entities": [{"text": "IBM TJ Watson Research Center information retrieval", "start_pos": 45, "end_pos": 96, "type": "TASK", "confidence": 0.6944474620478494}, {"text": "information retrieval", "start_pos": 263, "end_pos": 284, "type": "TASK", "confidence": 0.8167455792427063}, {"text": "machine translation", "start_pos": 289, "end_pos": 308, "type": "TASK", "confidence": 0.825387716293335}]}, {"text": "Building a rule-based stemmer fora new, arbitrary language is time consuming and requires experts with linguistic knowledge in that particular language.", "labels": [], "entities": []}, {"text": "Supervised learning also requires large quantities of labeled data in the target language, and quality declines when using completely unsupervised methods.", "labels": [], "entities": []}, {"text": "We would like to reach a compromise by using a few inexpensive and readily available resources in conjunction with unsupervised learning.", "labels": [], "entities": []}, {"text": "Our goal is to develop a stemmer generator that is relatively language independent (to the extent that the language accepts stemming) and is trainable using little, inexpensive data.", "labels": [], "entities": [{"text": "stemmer generator", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8896167278289795}]}, {"text": "This paper presents an unsupervised learning approach to non-English stemming.", "labels": [], "entities": [{"text": "non-English stemming", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7496152520179749}]}, {"text": "The stemming model is based on statistical machine translation and it uses an English stemmer and a small (10K sentences) parallel corpus as its sole training resources.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6324194471041361}]}, {"text": "A parallel corpus is a collection of sentence pairs with the same meaning but in different languages (i.e. United Nations proceedings, bilingual newspapers, the Bible).", "labels": [], "entities": []}, {"text": "shows an example that uses the Buckwalter transliteration).", "labels": [], "entities": [{"text": "Buckwalter transliteration", "start_pos": 31, "end_pos": 57, "type": "DATASET", "confidence": 0.9238161146640778}]}, {"text": "Usually, entire documents are translated by humans, and the sentence pairs are subsequently aligned by automatic means.", "labels": [], "entities": []}, {"text": "A small parallel corpus can be available when native speakers and translators are not, which makes building a stemmer out of such corpus a preferable direction.", "labels": [], "entities": []}], "datasetContent": [{"text": "Task Description: Given a set of Arabic documents and an Arabic query, find a list of documents relevant to the query, and rank them by probability of relevance.", "labels": [], "entities": []}, {"text": "We used the TREC 2002 documents (several years of AFP data), queries and relevance judgments.", "labels": [], "entities": [{"text": "TREC 2002 documents", "start_pos": 12, "end_pos": 31, "type": "DATASET", "confidence": 0.9445833365122477}, {"text": "AFP data", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9314911365509033}]}, {"text": "The 50 queries have a shorter, \"title\" component as wel as a longer \"description\".", "labels": [], "entities": []}, {"text": "We stemmed both the queries and the documents using UNSUP and GOLD respectively.", "labels": [], "entities": [{"text": "UNSUP", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.8934178948402405}, {"text": "GOLD", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.6772935390472412}]}, {"text": "For comparison purposes, we also left the documents and queries unstemmed.", "labels": [], "entities": []}, {"text": "The UNSUP stemmer was trained with 10K UN sentences in Step 1, and with one year's worth of monolingual AFP data in Step 2.", "labels": [], "entities": [{"text": "UNSUP stemmer", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7906951308250427}, {"text": "UN sentences", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.8246575891971588}]}, {"text": "Evaluation metric: The evaluation metric used below is mean average precision (the standard IR metric), which is the mean of average precision scores for each query.", "labels": [], "entities": [{"text": "mean average precision", "start_pos": 55, "end_pos": 77, "type": "METRIC", "confidence": 0.864944855372111}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.7366333603858948}]}, {"text": "The average precision of a single query is the mean of the precision scores after each relevant document retrieved.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9437351822853088}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9975982308387756}]}, {"text": "Note that average precision implicitly includes recall information.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.900235116481781}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9989615678787231}]}, {"text": "Precision is defined as the ratio of relevant documents to total documents retrieved up to that point in the ranking.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9934850335121155}]}], "tableCaptions": []}