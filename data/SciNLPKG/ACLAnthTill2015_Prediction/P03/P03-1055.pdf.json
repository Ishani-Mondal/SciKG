{"title": [{"text": "Deep Syntactic Processing by Combining Shallow Methods", "labels": [], "entities": [{"text": "Deep Syntactic Processing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6647945841153463}]}], "abstractContent": [{"text": "We present a novel approach for finding discontinuities that outperforms previously published results on this task.", "labels": [], "entities": []}, {"text": "Rather than using a deeper grammar formalism , our system combines a simple un-lexicalized PCFG parser with a shallow pre-processor.", "labels": [], "entities": []}, {"text": "This pre-processor, which we calla trace tagger, does surprisingly well on detecting where discontinuities can occur without using phase structure information.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we explore a novel approach for finding long-distance dependencies.", "labels": [], "entities": []}, {"text": "In particular, we detect such dependencies, or discontinuities, in a two-step process: (i) a conceptually simple shallow tagger looks for sites of discontinuties as a preprocessing step, before parsing; (ii) the parser then finds the dependent constituent (antecedent).", "labels": [], "entities": []}, {"text": "Clearly, information about long-distance relationships is vital for semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.9200003445148468}]}, {"text": "However, such constructions prove to be difficult for stochastic parsers) and they either avoid tackling the problem or only deal with a subset of the problematic cases.", "labels": [], "entities": []}, {"text": "proposes an algorithm that is able to find long-distance dependencies, as a postprocessing step, after parsing.", "labels": [], "entities": []}, {"text": "Although this algorithm fares well, it faces the problem that stochastic parsers not designed to capture non-local dependencies may get confused when parsing a sentence with discontinuities.", "labels": [], "entities": []}, {"text": "However, the approach presented here is not susceptible to this shortcoming as it finds discontinuties before parsing.", "labels": [], "entities": []}, {"text": "Overall, we present three primary contributions.", "labels": [], "entities": []}, {"text": "First, we extend the mechanism of adding gap variables for nodes dominating a site of discontinuity.", "labels": [], "entities": []}, {"text": "This approach allows even a context-free parser to reliably recover antecedents, given prior information about where discontinuities occur.", "labels": [], "entities": []}, {"text": "Second, we introduce a simple yet novel finite-state tagger that gives exactly this information to the parser.", "labels": [], "entities": []}, {"text": "Finally, we show that the combination of the finite-state mechanism, the parser, and our new method for antecedent recovery can competently analyze discontinuities.", "labels": [], "entities": [{"text": "antecedent recovery", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7236885726451874}]}, {"text": "The overall organization of the paper is as follows.", "labels": [], "entities": []}, {"text": "First, Section 2 sketches the material we use for the experiments in the paper.", "labels": [], "entities": []}, {"text": "In Section 3, we propose a modification to a simple PCFG parser that allows it to reliably find antecedents if it knows the sites of long-distance dependencies.", "labels": [], "entities": []}, {"text": "Then, in Section 4, we develop a finite-state system that gives the parser exactly that information with fairly high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9958240985870361}]}, {"text": "We combine the models in Section 5 to recover antecedents.", "labels": [], "entities": []}, {"text": "Section 6 discusses related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate on all sentences in the test section of the treebank.", "labels": [], "entities": []}, {"text": "As our interest lies in trace detection and antecedent recovery, we adopt the evaluation measures introduced by.", "labels": [], "entities": [{"text": "trace detection", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.8056230843067169}, {"text": "antecedent recovery", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7622814774513245}]}, {"text": "An EE is correctly detected if our model gives it the correct label as well as the correct position (the words before and after it).", "labels": [], "entities": []}, {"text": "When evaluating antecedent recovery, the EEs are regarded as four-tuples, consisting of the type of the EE, its location, the type of its antecedent and the location(s) (beginning and end) of the antecedent.", "labels": [], "entities": [{"text": "antecedent recovery", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7091087996959686}]}, {"text": "An antecedent is correctly recovered if all four values match the gold standard.", "labels": [], "entities": []}, {"text": "The precision, recall, and the combined F-score is presented for each experiment.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997817873954773}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9997355341911316}, {"text": "F-score", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.9991256594657898}]}, {"text": "Missed parses are ignored for evaluation purposes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: EE detection, antecedent recovery, parsing  times, and missed parses for the parser", "labels": [], "entities": [{"text": "EE detection", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.7976855933666229}, {"text": "parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9450114965438843}]}, {"text": " Table 5. The overall unlabeled F-score is  85 3%, whereas the labeled F-score is 79 1%, which  amounts to 97 9% word-level tagging accuracy.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9628642201423645}, {"text": "F-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.8097143769264221}, {"text": "word-level tagging", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.5916882753372192}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9133046269416809}]}, {"text": " Table 5: EE-detection results on Section 23 and com- parison with Johnson (2002) (where applicable).", "labels": [], "entities": [{"text": "EE-detection", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8572320342063904}, {"text": "Section 23", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.888358473777771}, {"text": "com- parison", "start_pos": 49, "end_pos": 61, "type": "METRIC", "confidence": 0.8264783223470052}]}, {"text": " Table 6: Antecedent recovery, parsing times, and  missed parses for the combined model", "labels": [], "entities": [{"text": "Antecedent recovery", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8424493670463562}, {"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9584120512008667}]}, {"text": " Table 7: Antecedent recovery results for the  combined NOINSERT model and comparison with  Johnson (2002).", "labels": [], "entities": [{"text": "Antecedent recovery", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8376522064208984}, {"text": "NOINSERT", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.5509934425354004}]}]}