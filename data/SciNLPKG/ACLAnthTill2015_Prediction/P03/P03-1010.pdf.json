{"title": [{"text": "Reliable Measures for Aligning Japanese-English News Articles and Sentences", "labels": [], "entities": [{"text": "Reliable Measures", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7024225890636444}, {"text": "Aligning Japanese-English News Articles and Sentences", "start_pos": 22, "end_pos": 75, "type": "TASK", "confidence": 0.8878137667973837}]}], "abstractContent": [{"text": "We have aligned Japanese and English news articles and sentences to make a large parallel corpus.", "labels": [], "entities": []}, {"text": "We first used a method based on cross-language information retrieval (CLIR) to align the Japanese and English articles and then used a method based on dynamic programming (DP) matching to align the Japanese and English sentences in these articles.", "labels": [], "entities": [{"text": "cross-language information retrieval (CLIR)", "start_pos": 32, "end_pos": 75, "type": "TASK", "confidence": 0.7029803196589152}]}, {"text": "However , the results included many incorrect alignments.", "labels": [], "entities": []}, {"text": "To remove these, we propose two measures (scores) that evaluate the validity of alignments.", "labels": [], "entities": []}, {"text": "The measure for article alignment uses similarities in sentences aligned by DP matching and that for sentence alignment uses similarities in articles aligned by CLIR.", "labels": [], "entities": [{"text": "article alignment", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8360573351383209}, {"text": "sentence alignment", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.750264436006546}]}, {"text": "They enhance each other to improve the accuracy of alignment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.999189555644989}, {"text": "alignment", "start_pos": 51, "end_pos": 60, "type": "TASK", "confidence": 0.9303745627403259}]}, {"text": "Using these measures, we have successfully constructed a large-scale article and sentence alignment corpus available to the public.", "labels": [], "entities": [{"text": "article and sentence alignment", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.6040458157658577}]}], "introductionContent": [{"text": "A large-scale Japanese-English parallel corpus is an invaluable resource in the study of natural language processing (NLP) such as machine translation and cross-language information retrieval (CLIR).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 89, "end_pos": 122, "type": "TASK", "confidence": 0.7723206182320913}, {"text": "machine translation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.7548809945583344}, {"text": "cross-language information retrieval (CLIR)", "start_pos": 155, "end_pos": 198, "type": "TASK", "confidence": 0.7486305584510168}]}, {"text": "It is also valuable for language education.", "labels": [], "entities": [{"text": "language education", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8355344235897064}]}, {"text": "However, no such corpus has been available to the public.", "labels": [], "entities": []}, {"text": "We recently have obtained a noisy parallel corpus of Japanese and English newspapers consisting of issues published over more than a decade and have tried to align their articles and sentences.", "labels": [], "entities": []}, {"text": "We first aligned the articles using a method based on CLIR () and then aligned the sentences in these articles by using a method based on dynamic programming (DP) matching (.", "labels": [], "entities": []}, {"text": "However, the results included many incorrect alignments due to noise in the corpus.", "labels": [], "entities": []}, {"text": "To remove these, we propose two measures (scores) that evaluate the validity of article and sentence alignments.", "labels": [], "entities": [{"text": "article and sentence alignments", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.5646370723843575}]}, {"text": "Using these, we can selectively extract valid alignments.", "labels": [], "entities": []}, {"text": "In this paper, we first discuss the basic statistics on the Japanese and English newspapers.", "labels": [], "entities": [{"text": "Japanese and English newspapers", "start_pos": 60, "end_pos": 91, "type": "DATASET", "confidence": 0.7282829284667969}]}, {"text": "We next explain methods and measures used for alignment.", "labels": [], "entities": [{"text": "alignment", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.978346586227417}]}, {"text": "We then evaluate the effectiveness of the proposed measures.", "labels": [], "entities": []}, {"text": "Finally, we show that our aligned corpus has attracted people both inside and outside the NLP community.", "labels": [], "entities": []}], "datasetContent": [{"text": "Here, we discuss the results of evaluating article and sentence alignments.", "labels": [], "entities": [{"text": "article and sentence alignments", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.5984631776809692}]}, {"text": "We first estimate the precision of article alignments by using randomly sampled alignments.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9987775683403015}]}, {"text": "Next, we sort them in descending order of BM25 and AVSIM to see whether these measures can be used to provide correct alignments with a high ranking.", "labels": [], "entities": [{"text": "BM25", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9782339930534363}, {"text": "AVSIM", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9974467754364014}]}, {"text": "Finally, we show that the absolute values of AVSIM correspond well with human judgment.", "labels": [], "entities": [{"text": "AVSIM", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.895367443561554}]}, {"text": "Sentence alignments in article alignments have many errors even if they have been obtained from correct article alignments due to free translation as discussed in Section 2.", "labels": [], "entities": [{"text": "article alignments", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7718714773654938}]}, {"text": "To extract only correct alignments, we sorted whole sentence alignments in whole article alignments in decreasing order of SntScore and selected only the higher ranked sentence alignments so that the selected alignments would be sufficiently precise to be useful as NLP resources.", "labels": [], "entities": []}, {"text": "The number of whole sentence alignments was about 1,300,000.", "labels": [], "entities": [{"text": "whole sentence alignments", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.6232732534408569}]}, {"text": "The most important category for sentence alignment is one-to-one.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7992981374263763}]}, {"text": "Thus, we want to discard as many errors in this category as possible.", "labels": [], "entities": []}, {"text": "In the first step, we classified whole oneto-one alignments into two classes: the first consisted of alignments whose Japanese and English sentences ended with periods, question marks, exclamation marks, or other readily identifiable characteristics.", "labels": [], "entities": []}, {"text": "We call this class \"one-to-one\".", "labels": [], "entities": []}, {"text": "The second class consisted of the one-to-one alignments not belonging to the first class.", "labels": [], "entities": []}, {"text": "The alignments in this class, together with the whole one-to-n alignments, are called \"one-to-many\".", "labels": [], "entities": []}, {"text": "One-to-one had about 640,000 alignments and one-to-many had about 660,000 alignments.", "labels": [], "entities": []}, {"text": "We first evaluated the precision of one-to-one alignments by sorting them in decreasing order of SntScore.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9988455772399902}]}, {"text": "We randomly extracted 100 samples from each of 10 blocks ranked at the top-300,000 alignments.", "labels": [], "entities": []}, {"text": "(A block had 30,000 alignments.)", "labels": [], "entities": []}, {"text": "We classified these 1000 samples into two classes: The first was \"match\" (A), the second was \"not match\" (D).", "labels": [], "entities": [{"text": "match", "start_pos": 66, "end_pos": 71, "type": "METRIC", "confidence": 0.9945871829986572}]}, {"text": "We judged a sample as \"A\" if the Japanese and English sentences of the sample shared a common event (approximately a clause).", "labels": [], "entities": []}, {"text": "\"D\" consisted of the samples not belonging to \"A\".", "labels": [], "entities": []}, {"text": "The results of evaluation are in  This table shows that the number of A's decreases rapidly as the rank increases.", "labels": [], "entities": []}, {"text": "This means that SntScore ranks appropriate one-to-one alignments highly.", "labels": [], "entities": [{"text": "SntScore", "start_pos": 16, "end_pos": 24, "type": "TASK", "confidence": 0.8488950133323669}]}, {"text": "The table indicates that the top-150,000 oneto-one alignments are sufficiently reliable.", "labels": [], "entities": []}, {"text": "The ratio of A's in these alignments was 0.982.", "labels": [], "entities": [{"text": "A", "start_pos": 13, "end_pos": 14, "type": "METRIC", "confidence": 0.995912492275238}]}, {"text": "We then evaluated precision for one-to-many alignments by sorting them in decreasing order of SntScore.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9994551539421082}]}, {"text": "We classified one-to-many into three categories: \"1-90000\", \"90001-180000\", and \"180001-270000\", each of which was covered by the range of SntScore of one-to-one that was presented in.", "labels": [], "entities": []}, {"text": "We randomly sampled 100 one-to-many alignments from these categories and judged them to be A or D (see).", "labels": [], "entities": []}, {"text": "indicates that the 38,090 alignments in the range from \"1-90000\" are sufficiently reliable.", "labels": [], "entities": []}, {"text": "show that we can extract valid alignments by sorting alignments according to SntScore and by selecting only higher ranked sentence alignments.", "labels": [], "entities": []}, {"text": "Overall, evaluations between the first and second check were consistent.", "labels": [], "entities": []}, {"text": "The notion of \"appropriate (correct) sentence alignment\" depends on applications.", "labels": [], "entities": [{"text": "appropriate (correct) sentence alignment", "start_pos": 15, "end_pos": 55, "type": "TASK", "confidence": 0.6969357679287592}]}, {"text": "Machine translation, for example, may require more precise (literal) alignment.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6831744909286499}]}, {"text": "To get literal alignments beyond a sharing of a common event, we will select a set of alignments from the top of the sorted alignments that satisfies the required literalness.", "labels": [], "entities": []}, {"text": "This is because, in general, higher ranked alignments are more literal translations, because those alignments tend to have many one-to-one corresponding words and to be contained in highly similar article alignments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Ratio of article alignments", "labels": [], "entities": [{"text": "Ratio", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9685399532318115}, {"text": "article alignments", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.6607896089553833}]}, {"text": " Table 3: Statistics on AVSIM (1996-2001)", "labels": [], "entities": [{"text": "AVSIM", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.5254883170127869}]}, {"text": " Table 4: Statistics on AVSIM", "labels": [], "entities": [{"text": "AVSIM", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.47382792830467224}]}, {"text": " Table  5. It shows that the number of alignments estimated  to be A or B was 46738 (= 31495 + 15243). We  regard about 47,000 article alignments to be suffi- ciently large to be useful as a resource for NLP such  as bilingual lexicon acquisition and for language ed- ucation.", "labels": [], "entities": [{"text": "bilingual lexicon acquisition", "start_pos": 217, "end_pos": 246, "type": "TASK", "confidence": 0.6489885846773783}]}, {"text": " Table 5: Number of articles per evaluation", "labels": [], "entities": []}, {"text": " Table 6: One-to-one: Rank vs. judgment", "labels": [], "entities": []}, {"text": " Table  6. We randomly sampled 100 one-to-many align- ments from these categories and judged them to be A  or D (see", "labels": [], "entities": []}, {"text": " Table 7: One-to-many: Rank vs. judgment", "labels": [], "entities": []}]}