{"title": [{"text": "Parsing with generative models of predicate-argument structure", "labels": [], "entities": []}], "abstractContent": [{"text": "The model used by the CCG parser of Hockenmaier and Steedman (2002b) would fail to capture the correct bilexical dependencies in a language with freer word order, such as Dutch.", "labels": [], "entities": []}, {"text": "This paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of Clark et al.", "labels": [], "entities": []}, {"text": "(2002), and defines a generative model for CCG derivations that captures these dependencies, including bounded and unbounded long-range dependencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "State-of-the-art statistical parsers for Penn Treebank-style phrase-structure grammars,), but also for Categorial), include models of bilexical dependencies defined in terms of local trees.", "labels": [], "entities": [{"text": "Penn Treebank-style phrase-structure grammars", "start_pos": 41, "end_pos": 86, "type": "DATASET", "confidence": 0.9469840079545975}]}, {"text": "However, this paper demonstrates that such models would be inadequate for languages with freer word order.", "labels": [], "entities": []}, {"text": "We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see ).", "labels": [], "entities": []}, {"text": "We argue that this problem can be avoided if instead the bilexical dependencies in the predicate-argument structure are captured, and propose a generative model for these dependencies.", "labels": [], "entities": []}, {"text": "The focus of this paper is on models for Combinatory Categorial Grammar).", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.6960647702217102}]}, {"text": "Due to CCG's transparent syntax-semantics interface, the parser has direct and immediate access to the predicate-argument structure, which includes not only local, but also long-range dependencies arising through coordination, extraction and control.", "labels": [], "entities": []}, {"text": "These dependencies can be captured by our model in a sound manner, and our experimental results for English demonstrate that their inclusion improves parsing performance.", "labels": [], "entities": []}, {"text": "However, since the predicate-argument structure itself depends only to a degree on the grammar formalism, it is likely that parsers that are based on other grammar formalisms could equally benefit from such a model.", "labels": [], "entities": []}, {"text": "The conditional model used by the CCG parser of also captures dependencies in the predicate-argument structure; however, their model is inconsistent.", "labels": [], "entities": []}, {"text": "First, we review the dependency model proposed by.", "labels": [], "entities": []}, {"text": "We then use the example of Dutch ditransitives to demonstrate its inadequacy for languages with a freer word order.", "labels": [], "entities": []}, {"text": "This leads us to define anew generative model of CCG derivations, which captures word-word dependencies in the underlying predicate-argument structure.", "labels": [], "entities": []}, {"text": "We show how this model can capture long-range dependencies, and deal with the presence of multiple dependencies that arise through the presence of long-range dependencies.", "labels": [], "entities": []}, {"text": "In our current implementation, the probabilities of derivations are computed during parsing, and we discuss the difficulties of integrating the model into a probabilistic chart parsing regime.", "labels": [], "entities": [{"text": "parsing", "start_pos": 84, "end_pos": 91, "type": "TASK", "confidence": 0.9733768105506897}]}, {"text": "Since there is no CCG treebank for other languages available, experimental results are presented for English, using CCGbank), a translation of the Penn Treebank to CCG.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 147, "end_pos": 160, "type": "DATASET", "confidence": 0.9937272071838379}]}, {"text": "These results demonstrate that this model benefits greatly from the inclusion of long-range dependencies.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use sections 02-21 of CCGbank for training, section 00 for development, and section 23 for testing.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.9800889492034912}]}, {"text": "The input is POS-tagged using the tagger of.", "labels": [], "entities": []}, {"text": "However, since parsing with the new model is less efficient, only sentences \ud97b\udf59 40 tokens only are used to test the model.", "labels": [], "entities": []}, {"text": "A frequency cutoff of \ud97b\udf59 20 was used to determine rare words in the training data, which are replaced with their POS-tags.", "labels": [], "entities": []}, {"text": "Unknown words in the test data are also replaced by their POS-tags.", "labels": [], "entities": [{"text": "POS-tags", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.7848373055458069}]}, {"text": "The models are evaluated according to their Parseval scores and to the recovery of dependencies in the predicateargument structure.", "labels": [], "entities": [{"text": "Parseval", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8336663842201233}]}, {"text": "In order to determine the impact of capturing different kinds of long-range dependencies, four different models were investigated: The baseline model is like the LexCat model of (2002b), since the structural probabilities of our model are like those of that model.", "labels": [], "entities": [{"text": "LexCat", "start_pos": 162, "end_pos": 168, "type": "DATASET", "confidence": 0.9673945307731628}]}, {"text": "Local only takes local dependencies into account.", "labels": [], "entities": []}, {"text": "LeftArgs only takes long-range dependencies that are projected through left arguments (\u00d2\ud97b\udf59) into account.", "labels": [], "entities": []}, {"text": "This includes for instance longrange dependencies projected by subjects, subject and object control verbs, subject extraction and leftnode raising.", "labels": [], "entities": [{"text": "subject extraction", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.7461528778076172}, {"text": "leftnode raising", "start_pos": 130, "end_pos": 146, "type": "TASK", "confidence": 0.7248045355081558}]}, {"text": "All takes all long-range dependencies into account, in particular it extends LeftArgs by capturing also the unbounded dependencies arising through right-node-raising and object extraction.", "labels": [], "entities": [{"text": "object extraction", "start_pos": 170, "end_pos": 187, "type": "TASK", "confidence": 0.7336454540491104}]}, {"text": "Local, LeftArgs and All are all tested with the aggressive beam strategy described above.", "labels": [], "entities": []}, {"text": "In all cases, the CCG derivation includes all longrange dependencies.", "labels": [], "entities": []}, {"text": "However, with the models that exclude certain kinds of dependencies, it is possible that a word is conditioned on no dependencies.", "labels": [], "entities": []}, {"text": "In these cases, the word is generated with \u00c8 \u00b4\u00db\ud97b\udf59\ud97b\udf59\u00b5. gives the performance of all four models on section 23 in terms of the accuracy of lexical categories, Parseval scores, and in terms of the recovery of word-word dependencies in the predicateargument structure.", "labels": [], "entities": [{"text": "\u00c8 \u00b4\u00db\ud97b\udf59\ud97b\udf59\u00b5.", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.78049336373806}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9992129802703857}, {"text": "Parseval scores", "start_pos": 155, "end_pos": 170, "type": "METRIC", "confidence": 0.9614041447639465}]}, {"text": "Here, results are further broken up into the recovery of local, all long-range, bounded long-range and unbounded long-range dependencies.", "labels": [], "entities": []}, {"text": "LexCat does not capture any word-word dependencies.", "labels": [], "entities": [{"text": "LexCat", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9716923236846924}]}, {"text": "Its performance on the recovery of predicate-argument structure can be improved by 3% by capturing only local word-word dependencies (Local).", "labels": [], "entities": []}, {"text": "This excludes certain kinds of dependencies that were captured by the SD model.", "labels": [], "entities": []}, {"text": "For instance, the dependency between the head of a noun phrase and the head of a reduced relative clause (the shares bought by John) is captured by the SD model, since shares and bought are both heads of the local trees that are combined to form the complex noun phrase.", "labels": [], "entities": []}, {"text": "However, in the SD model the probability of this dependency can only be estimated from occurrences of the same construction, since dependency relations are defined in terms of local trees and not in terms of the underlying predicate-argument struc- ture.", "labels": [], "entities": []}, {"text": "By including long-range dependencies on left arguments (such as subjects) (LeftArgs), a further improvement of 0.7% on the recovery of predicateargument structure is obtained.", "labels": [], "entities": []}, {"text": "This model captures the dependency between shares and bought.", "labels": [], "entities": []}, {"text": "In contrast to the SD model, it can use all instances of shares as the subject of a passive verb in the training data to estimate this probability.", "labels": [], "entities": []}, {"text": "Therefore, even if shares and bought do not co-occur in this particular construction in the training data, the event that is modelled by our dependency model might not be unseen, since it could have occurred in another syntactic context.", "labels": [], "entities": []}, {"text": "Our results indicate that in order to perform well on long-range dependencies, they have to be included in the model, since Local, the model that captures only local dependencies performs worse on long-range dependencies than LexCat, the model that captures no word-word dependencies.", "labels": [], "entities": [{"text": "LexCat", "start_pos": 226, "end_pos": 232, "type": "DATASET", "confidence": 0.9410620331764221}]}, {"text": "However, with more than 5% difference on labelled precision and recall on long-range dependencies, the model which captures long-range dependencies on left arguments performs significantly better on recovering long-range dependencies than Local.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.6892619132995605}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9988104104995728}]}, {"text": "The greatest difference in performance between the models which do capture long-range dependencies and the models which do not is on long-range dependencies.", "labels": [], "entities": []}, {"text": "This indicates that, at least in the kind of model considered here, it is very important to model not just local, but also long-range dependencies.", "labels": [], "entities": []}, {"text": "It is not clear why All, the model that includes all dependencies, performs slightly worse than the model which includes only long-range dependencies on subjects.", "labels": [], "entities": [{"text": "All", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9668967723846436}]}, {"text": "On the Wall Street Journal task, the overall performance of this model is lower than that of the SD model of.", "labels": [], "entities": [{"text": "Wall Street Journal task", "start_pos": 7, "end_pos": 31, "type": "DATASET", "confidence": 0.964756116271019}]}, {"text": "In that model, words are generated at the maximal projection of constituents; therefore, the structural probabilities can also be conditioned on words, which improves the scores by about 2%.", "labels": [], "entities": []}, {"text": "It is also very likely that the performance of the new models is harmed by the very aggressive beam search.", "labels": [], "entities": [{"text": "beam search", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.8477528095245361}]}], "tableCaptions": [{"text": " Table 1: Evaluation (sec. 23, \ud97b\udf59 40 words).", "labels": [], "entities": []}]}