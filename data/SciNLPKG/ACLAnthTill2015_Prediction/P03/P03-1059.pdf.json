{"title": [{"text": "Learning the Countability of English Nouns from Corpus Data", "labels": [], "entities": [{"text": "Learning the Countability of English Nouns from Corpus", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.7727788239717484}]}], "abstractContent": [{"text": "This paper describes a method for learning the countability preferences of English nouns from raw text corpora.", "labels": [], "entities": []}, {"text": "The method maps the corpus-attested lexico-syntactic properties of each noun onto a feature vector, and uses a suite of memory-based classifiers to predict membership in 4 countability classes.", "labels": [], "entities": []}, {"text": "We were able to assign countability to English nouns with a precision of 94.6%.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9986793398857117}]}], "introductionContent": [{"text": "This paper is concerned with the task of knowledgerich lexical acquisition from unannotated corpora, focusing on the case of countability in English.", "labels": [], "entities": [{"text": "knowledgerich lexical acquisition from unannotated corpora", "start_pos": 41, "end_pos": 99, "type": "TASK", "confidence": 0.8436317841211954}]}, {"text": "Knowledge-rich lexical acquisition takes unstructured text and extracts out linguistically-precise categorisations of word and expression types.", "labels": [], "entities": [{"text": "Knowledge-rich lexical acquisition", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6693101723988851}]}, {"text": "By combining this with a grammar, we can build broad-coverage deep-processing tools with a minimum of human effort.", "labels": [], "entities": []}, {"text": "This research is close in spirit to the work of Light (1996) on classifying the semantics of derivational affixes, and on learning verb aspect.", "labels": [], "entities": [{"text": "classifying the semantics of derivational affixes", "start_pos": 64, "end_pos": 113, "type": "TASK", "confidence": 0.7968989710013071}, {"text": "learning verb aspect", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.7247862815856934}]}, {"text": "In English, nouns heading noun phrases are typically either countable or uncountable (also called count and mass).", "labels": [], "entities": [{"text": "count", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.9932823181152344}]}, {"text": "Countable nouns can be modified by denumerators, prototypically numbers, and have a morphologically marked plural form: one dog, two dogs.", "labels": [], "entities": []}, {"text": "Uncountable nouns cannot be modified by denumerators, but can be modified by unspecific quantifiers such as much, and do not show any number distinction (prototypically being singular): *one equipment, some equipment, *two equipments.", "labels": [], "entities": []}, {"text": "Many nouns can be used in countable or uncountable environments, with differences in interpretation.", "labels": [], "entities": []}, {"text": "We call the lexical property that determines which uses a noun can have the noun's countability preference.", "labels": [], "entities": []}, {"text": "Knowledge of countability preferences is important both for the analysis and generation of English.", "labels": [], "entities": [{"text": "generation of English", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.805417557557424}]}, {"text": "In analysis, it helps to constrain the interpretations of parses.", "labels": [], "entities": []}, {"text": "In generation, the countability preference determines whether a noun can become plural, and the range of possible determiners.", "labels": [], "entities": []}, {"text": "Knowledge of countability is particularly important in machine translation, because the closest translation equivalent may have different countability from the source noun.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8024719953536987}]}, {"text": "Many languages, such as Chinese and Japanese, do not mark countability, which means that the choice of countability will be largely the responsibility of the generation component).", "labels": [], "entities": []}, {"text": "In addition, knowledge of countability obtained from examples of use is an important resource for dictionary construction.", "labels": [], "entities": [{"text": "dictionary construction", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.8629109859466553}]}, {"text": "In this paper, we learn the countability preferences of English nouns from unannotated corpora.", "labels": [], "entities": []}, {"text": "We first annotate them automatically, and then train classifiers using a set of gold standard data, taken from COMLEX () and the transfer dictionaries used by the machine translation system ALT-J/E (.", "labels": [], "entities": [{"text": "COMLEX", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.9566164612770081}]}, {"text": "The classifiers and their training are described in more detail in.", "labels": [], "entities": []}, {"text": "These are then run over the corpus to extract nouns as members of four classes -countable: dog; uncountable: furniture; bipartite: [pair of] scissors and plural only: clothes.", "labels": [], "entities": []}, {"text": "We first discuss countability in more detail ( \u00a7 2).", "labels": [], "entities": []}, {"text": "Then we present the lexical resources used in our experiment ( \u00a7 3).", "labels": [], "entities": []}, {"text": "Next, we describe the learning process ( \u00a7 4).", "labels": [], "entities": []}, {"text": "We then present our results and evaluation ( \u00a7 5).", "labels": [], "entities": []}, {"text": "Finally, we discuss the theoretical and practical implications ( \u00a7 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation is broken down into two components.", "labels": [], "entities": []}, {"text": "First, we determine the optimal classifier configuration for each countability class byway of stratified cross-validation over the gold-standard data.", "labels": [], "entities": []}, {"text": "We then run each classifier in optimised configuration over the remaining target nouns for which we have feature vectors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Details of the gold-standard data", "labels": [], "entities": [{"text": "gold-standard data", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.8618947863578796}]}]}