{"title": [{"text": "Coreference Resolution Using Competition Learning Approach", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9463750123977661}]}], "abstractContent": [{"text": "In this paper we propose a competition learning approach to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.9694335758686066}]}, {"text": "Traditionally, supervised machine learning approaches adopt the single-candidate model.", "labels": [], "entities": []}, {"text": "Nevertheless the preference relationship between the antecedent candidates cannot be determined accurately in this model.", "labels": [], "entities": []}, {"text": "By contrast, our approach adopts a twin-candidate learning model.", "labels": [], "entities": []}, {"text": "Such a model can present the competition criterion for antecedent candidates reliably, and ensure that the most preferred candidate is selected.", "labels": [], "entities": []}, {"text": "Furthermore , our approach applies a candidate filter to reduce the computational cost and data noises during training and resolution.", "labels": [], "entities": []}, {"text": "The experimental results on MUC-6 and MUC-7 data set show that our approach can outperform those based on the single-candidate model.", "labels": [], "entities": [{"text": "MUC-6", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.9342371821403503}, {"text": "MUC-7 data set", "start_pos": 38, "end_pos": 52, "type": "DATASET", "confidence": 0.9706257780392965}]}], "introductionContent": [{"text": "Coreference resolution is the process of linking together multiple expressions of a given entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9250927269458771}]}, {"text": "The key to solve this problem is to determine the antecedent for each referring expression in a document.", "labels": [], "entities": []}, {"text": "In coreference resolution, it is common that two or more candidates compete to be the antecedent of an anaphor.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.9694294333457947}]}, {"text": "Whether a candidate is coreferential to an anaphor is often determined by the competition among all the candidates.", "labels": [], "entities": []}, {"text": "So far, various algorithms have been proposed to determine the preference relationship between two candidates.", "labels": [], "entities": []}, {"text": "Mitkov's knowledge-poor pronoun resolution method, for example, uses the scores from a set of antecedent indicators to rank the candidates.", "labels": [], "entities": [{"text": "knowledge-poor pronoun resolution", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.5936446785926819}]}, {"text": "And centering algorithms (, sort the antecedent candidates based on the ranking of the forward-looking or backwardlooking centers.", "labels": [], "entities": []}, {"text": "In recent years, supervised machine learning approaches have been widely used in coreference resolution, and have achieved significant success.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.9793258309364319}]}, {"text": "Normally, these approaches adopt a single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with a confidence value.", "labels": [], "entities": []}, {"text": "The confidence values are generally used as the competition criterion for the antecedent candidates.", "labels": [], "entities": []}, {"text": "For example, the \"Best-First\" selection algorithms) link the anaphor to the candidate with the maximal confidence value (above 0.5).", "labels": [], "entities": []}, {"text": "One problem of the single-candidate model, however, is that it only takes into account the relationships between an anaphor and one individual candidate at a time, and overlooks the preference relationship between candidates.", "labels": [], "entities": []}, {"text": "Consequently, the confidence values cannot accurately represent the true competition criterion for the candidates.", "labels": [], "entities": []}, {"text": "In this paper, we present a competition learning approach to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9646876752376556}]}, {"text": "Motivated by the research work by, our approach adopts a twin-candidate model to directly learn the competition criterion for the antecedent candidates.", "labels": [], "entities": []}, {"text": "In such a model, a classifier is trained based on the instances formed by an anaphor and a pair of its antecedent candidates.", "labels": [], "entities": []}, {"text": "The classifier is then used to determine the preference between any two candidates of an anaphor encountered in anew document.", "labels": [], "entities": []}, {"text": "The candidate that wins the most comparisons is selected as the antecedent.", "labels": [], "entities": []}, {"text": "In order to reduce the computational cost and data noises, our approach also employs a candidate filter to eliminate the invalid or irrelevant candidates.", "labels": [], "entities": []}, {"text": "The layout of this paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes the single-candidate model and analyzes its limitation.", "labels": [], "entities": []}, {"text": "Section 3 proposes in details the twin-candidate model and Section 4 presents our coreference resolution approach based on this model.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.9243084490299225}]}, {"text": "Section 5 reports and discusses the experimental results.", "labels": [], "entities": []}, {"text": "Section 6 describes related research work.", "labels": [], "entities": []}, {"text": "Finally, conclusion is given in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our coreference resolution approach is evaluated on the standard MUC-6 (1995) and MUC-7 (1998) data set.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9533780515193939}, {"text": "MUC-6", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.8996400237083435}, {"text": "MUC-7 (1998) data set", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.8500489294528961}]}, {"text": "For MUC-6, 30 \"dry-run\" documents annotated with coreference information could be used as training data.", "labels": [], "entities": [{"text": "MUC-6", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.7255005836486816}]}, {"text": "There are also 30 annotated training documents from MUC-7.", "labels": [], "entities": [{"text": "MUC-7", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.8635463118553162}]}, {"text": "For testing, we utilize the 30 standard test documents from MUC-6 and the 20 standard test documents from MUC-7.", "labels": [], "entities": [{"text": "MUC-6", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.9557293057441711}, {"text": "MUC-7", "start_pos": 106, "end_pos": 111, "type": "DATASET", "confidence": 0.9696568250656128}]}], "tableCaptions": [{"text": " Table 2: Results for the pronoun resolution", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7649032175540924}]}, {"text": " Table 3: Results for the non-pronoun resolution", "labels": [], "entities": [{"text": "non-pronoun resolution", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7663999795913696}]}, {"text": " Table 4: Results for the coreference resolution", "labels": [], "entities": [{"text": "coreference", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.9797887206077576}]}]}