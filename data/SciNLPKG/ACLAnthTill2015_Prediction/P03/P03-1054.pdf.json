{"title": [], "abstractContent": [{"text": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which breakdown false independence assumptions latent in a vanilla treebank grammar.", "labels": [], "entities": []}, {"text": "Indeed, its performance of 86.36% (LP/LR F 1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art.", "labels": [], "entities": [{"text": "LP/LR F 1)", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.7394807289044062}]}, {"text": "This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexical-ized PCFG is much more compact, easier to repli-cate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity , and easier to optimize.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9973326921463013}]}, {"text": "In the early 1990s, as probabilistic methods swept NLP, parsing work revived the investigation of prob-abilistic context-free grammars (PCFGs) (Booth and Thomson, 1973; Baker, 1979).", "labels": [], "entities": []}, {"text": "However, early results on the utility of PCFGs for parse disambigua-tion and language modeling were somewhat disappointing.", "labels": [], "entities": [{"text": "parse disambigua-tion", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.901963859796524}, {"text": "language modeling", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.761480301618576}]}, {"text": "A conviction arose that lexicalized PCFGs (where head words annotate phrasal nodes) were the key tool for high performance PCFG parsing.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 123, "end_pos": 135, "type": "TASK", "confidence": 0.8530103862285614}]}, {"text": "This approach was congruent with the great success of word n-gram models in speech recognition, and drew strength from a broader interest in lexicalized grammars, as well as demonstrations that lexical dependencies were a key tool for resolving ambiguities such as PP attachments (Ford et al., 1982; Hindle and Rooth, 1993).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7362698316574097}]}, {"text": "In the following decade, great success in terms of parse disambiguation and even language modeling was achieved by various lexicalized PCFG models (Magerman, 1995; Charniak, 1997; Collins, 1999; Charniak, 2000; Charniak, 2001).", "labels": [], "entities": [{"text": "parse disambiguation", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.8691060245037079}, {"text": "language modeling", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7504121959209442}, {"text": "Magerman, 1995; Charniak, 1997; Collins, 1999; Charniak, 2000; Charniak, 2001", "start_pos": 148, "end_pos": 225, "type": "TASK", "confidence": 0.6527785141217081}]}, {"text": "However, several results have brought into question how large a role lexicalization plays in such parsers.", "labels": [], "entities": []}, {"text": "Johnson (1998) showed that the performance of an unlexicalized PCFG over the Penn tree-bank could be improved enormously simply by annotating each node by its parent category.", "labels": [], "entities": [{"text": "Penn tree-bank", "start_pos": 77, "end_pos": 91, "type": "DATASET", "confidence": 0.9867764413356781}]}, {"text": "The Penn treebank covering PCFG is a poor tool for parsing because the context-freedom assumptions it embodies are far too strong, and weakening them in this way makes the model much better.", "labels": [], "entities": [{"text": "Penn treebank covering PCFG", "start_pos": 4, "end_pos": 31, "type": "DATASET", "confidence": 0.9400865435600281}, {"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9847554564476013}]}, {"text": "More recently, Gildea (2001) discusses how taking the bilexical probabilities out of a good current lexicalized PCFG parser hurts performance hardly at all: by at most 0.5% for test text from the same domain as the training data, and not at all for test text from a different domain.", "labels": [], "entities": []}, {"text": "1 But it is precisely these bilexical dependencies that backed the intuition that lexicalized PCFGs should be very successful, for example in Hindle and Rooth's demonstration from PP attachment.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 180, "end_pos": 193, "type": "TASK", "confidence": 0.7956641912460327}]}, {"text": "We take this as a reflection of the fundamental sparseness of the lexical dependency information available in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 114, "end_pos": 127, "type": "DATASET", "confidence": 0.9961004257202148}]}, {"text": "As a speech person would say, one million words of training data just isn't enough.", "labels": [], "entities": []}, {"text": "Even for topics central to the treebank's Wall Street Journal text, such as stocks, many very plausible dependencies occur only once, for example stocks stabilized , while many others occur not at all, for example stocks skyrocketed.", "labels": [], "entities": [{"text": "Wall Street Journal text", "start_pos": 42, "end_pos": 66, "type": "DATASET", "confidence": 0.9225722849369049}]}, {"text": "2 The best-performing lexicalized PCFGs have increasingly made use of subcategorization 3 of the 1 There are minor differences, but all the current best-known lexicalized PCFGs employ both monolexical statistics, which describe the phrasal categories of arguments and adjuncts that appear around ahead lexical item, and bilexical statistics, or dependencies , which describe the likelihood of ahead word taking as a dependent a phrase headed by a certain other word.", "labels": [], "entities": []}, {"text": "2 This observation motivates various class-or similarity-based approaches to combating sparseness, and this remains a promising avenue of work, but success in this area has proven somewhat elusive, and, at any rate, current lexicalized PCFGs do simply use exact word matches if available, and interpolate with syntactic category-based estimates when they are not.", "labels": [], "entities": []}, {"text": "3 In this paper we use the term subcategorization in the original general sense of Chomsky (1965), for where a syntactic cat", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "To facilitate comparison with previous work, we trained our models on sections 2-21 of the WSJ section of the Penn treebank.", "labels": [], "entities": [{"text": "WSJ section of the Penn treebank", "start_pos": 91, "end_pos": 123, "type": "DATASET", "confidence": 0.9216727515061697}]}, {"text": "We used the first 20 files (393 sentences) of section 22 as a development set (devset).", "labels": [], "entities": []}, {"text": "This set is small enough that there is noticeable variance in individual results, but it allowed rapid search for good features via continually reparsing the devset in a partially manual hill-climb.", "labels": [], "entities": []}, {"text": "All of section 23 was used as a test set for the final model.", "labels": [], "entities": []}, {"text": "For each model, input trees were annotated or transformed in someway, as in.", "labels": [], "entities": []}, {"text": "Given a set of transformed trees, we viewed the local trees as grammar rewrite rules in the standard way, and used (unsmoothed) maximum-likelihood estimates for rule probabilities.", "labels": [], "entities": []}, {"text": "To parse the grammar, we used a simple array-based Java implementation of a generalized CKY parser, which, for our final best model, was able to exhaustively parse all sentences in section 23 in 1GB of memory, taking approximately 3 sec for average length sentences.", "labels": [], "entities": []}, {"text": "6 The tagging probabilities were smoothed to accommodate unknown words.", "labels": [], "entities": []}, {"text": "The quantity P(tag|wor d) was estimated as follows: words were split into one of several categories wor dclass, based on capitalization, suffix, digit, and other character features.", "labels": [], "entities": []}, {"text": "For each of these categories, we took the maximum-likelihood estimate of P(tag|wor dclass).", "labels": [], "entities": []}, {"text": "This distribution was used as a prior against which observed taggings, if any, were taken, giving P(tag|wor d) = [c(tag, wor d) + \u03ba P(tag|wor dclass)]/[c(wor d)+\u03ba].", "labels": [], "entities": []}, {"text": "This was then inverted to give P(wor d|tag).", "labels": [], "entities": [{"text": "P", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.9656174778938293}]}, {"text": "The quality of this tagging model impacts all numbers; for example the raw treebank grammar's devset F 1 is 72.62 with it and 72.09 without it.", "labels": [], "entities": []}, {"text": "The parser is available for download as open source at: http://nlp.stanford.edu/downloads/lex-parser.shtml", "labels": [], "entities": []}], "tableCaptions": []}