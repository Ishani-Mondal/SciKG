{"title": [{"text": "Probabilistic Parsing for German using Sister-Head Dependencies", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a probabilistic parsing model for German trained on the Negra tree-bank.", "labels": [], "entities": [{"text": "Negra tree-bank", "start_pos": 67, "end_pos": 82, "type": "DATASET", "confidence": 0.9813461899757385}]}, {"text": "We observe that existing lexicalized parsing models using head-head dependencies , while successful for English, fail to outperform an unlexicalized baseline model for German.", "labels": [], "entities": []}, {"text": "Learning curves show that this effect is not due to lack of training data.", "labels": [], "entities": []}, {"text": "We propose an alternative model that uses sister-head dependencies instead of head-head dependencies.", "labels": [], "entities": []}, {"text": "This model out-performs the baseline, achieving a labeled precision and recall of up to 74%.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.8341148495674133}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9996002316474915}]}, {"text": "This indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as Negra.", "labels": [], "entities": [{"text": "Negra", "start_pos": 114, "end_pos": 119, "type": "DATASET", "confidence": 0.9126960039138794}]}], "introductionContent": [{"text": "Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g.,.", "labels": [], "entities": [{"text": "Treebank-based probabilistic parsing", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5098380049069723}, {"text": "parsing", "start_pos": 118, "end_pos": 125, "type": "TASK", "confidence": 0.9665324687957764}, {"text": "accuracy", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.946750283241272}]}, {"text": "However, most of the existing models have been developed for English and trained on the Penn Treebank (, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 88, "end_pos": 101, "type": "DATASET", "confidence": 0.9948730766773224}, {"text": "Penn Treebank markup", "start_pos": 230, "end_pos": 250, "type": "DATASET", "confidence": 0.9839926958084106}]}, {"text": "The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (), a syntactically annotated corpus for German.", "labels": [], "entities": []}, {"text": "German has a number of syntactic properties that set it apart from English, and the Negra annotation scheme differs in important respects from the Penn Treebank markup.", "labels": [], "entities": [{"text": "Penn Treebank markup", "start_pos": 147, "end_pos": 167, "type": "DATASET", "confidence": 0.9845297932624817}]}, {"text": "While Negra has been used to build probabilistic chunkers, the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge).", "labels": [], "entities": []}, {"text": "Lexicalization can increase parsing performance dramatically for English, and the lexicalized model proposed by has been successfully applied to) and Chinese).", "labels": [], "entities": []}, {"text": "However, the resulting performance is significantly lower than the performance of the same model for English (see Table 1).", "labels": [], "entities": []}, {"text": "Neither nor compare the lexicalized model to an unlexicalized baseline model, leaving open the possibility that lexicalization is useful for English, but not for other languages.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews the syntactic properties of German, focusing on its semi-flexible wordorder.", "labels": [], "entities": []}, {"text": "Section 3 describes two standard lexicalized models, as well as an unlexicalized baseline model.", "labels": [], "entities": []}, {"text": "Section 4 presents a series of experiments that compare the parsing performance of these three models (and several variants) on Negra.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9704804420471191}, {"text": "Negra", "start_pos": 128, "end_pos": 133, "type": "DATASET", "confidence": 0.9606720805168152}]}, {"text": "The results show that both lexicalized models fail to outperform the unlexicalized baseline.", "labels": [], "entities": []}, {"text": "This is at odds with what has been reported for English.", "labels": [], "entities": []}, {"text": "Learning curves show that the poor performance of the lexicalized models is not due to lack of training data.", "labels": [], "entities": []}, {"text": "Section 5 presents an error analysis for lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra.", "labels": [], "entities": [{"text": "Negra", "start_pos": 169, "end_pos": 174, "type": "DATASET", "confidence": 0.9326630234718323}]}, {"text": "We propose an alternative model that uses sister-head dependencies instead.", "labels": [], "entities": []}, {"text": "This model outperforms the two original lexicalized models, as well as the unlexicalized baseline.", "labels": [], "entities": []}, {"text": "Based on this result and on the review of the previous literature (Section 6), we argue (Section 7) that sister-head models are more appropriate for treebanks with very flat structures (such as Negra), typically used to annotate languages with semifree wordorder (such as German).", "labels": [], "entities": []}], "datasetContent": [{"text": "This experiment was designed to compare the performance of the three models introduced in the last section.", "labels": [], "entities": []}, {"text": "Our main hypothesis was that the lexicalized models will outperform the unlexicalized baseline model.", "labels": [], "entities": []}, {"text": "Another prediction was that adding Negra-specific information to the models will increase parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 90, "end_pos": 97, "type": "TASK", "confidence": 0.9724217653274536}]}, {"text": "We therefore tested a model variant that included grammatical function labels, i.e., the set of categories was augmented by the function tags specified in Negra (see Section 2.2).", "labels": [], "entities": []}, {"text": "Adding grammatical functions is away of dealing with the wordorder facts of German (see Section 2.1) in the face of Negra's very flat annotation scheme.", "labels": [], "entities": []}, {"text": "For instance, subject and object NPs have different wordorder preferences (subjects tend to be preverbal, while objects tend to be postverbal), a fact that is captured if subjects have the label NP-SB, while objects are labeled NP-OA (accusative object), NP-DA (dative object), etc.", "labels": [], "entities": []}, {"text": "Also the fact that verb order differs between subordinate and main clauses is captured by the function labels: the former are labeled S, while the latter are labeled S-OC (object clause), S-RC (relative clause), etc.", "labels": [], "entities": []}, {"text": "Another idiosyncrasy of the Negra annotation is that conjoined categories have separate labels (S and CS, NP and CNP, etc.), and that PPs do not contain an NP node.", "labels": [], "entities": []}, {"text": "We tested a variant of the model that takes this into account.", "labels": [], "entities": []}, {"text": "As we saw in the last section, lack of training data is not a plausible explanation for the sub-baseline performance of the lexicalized models.", "labels": [], "entities": []}, {"text": "In this experiment, we therefore investigate an alternative hypothesis, viz., that the lexicalized models do not cope  The reason for this problem is that neben is the head of the constituent in (6), and the Collins model uses a crude distance measure together with head-head dependencies to decide if additional constituents should be added to the PP.", "labels": [], "entities": []}, {"text": "The distance measure is inadequate for finding PPs with high precision.", "labels": [], "entities": [{"text": "distance measure", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.969738245010376}, {"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9882012009620667}]}, {"text": "The chunking problem is more widespread than PPs.", "labels": [], "entities": [{"text": "chunking", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9801861047744751}]}, {"text": "The error analysis shows that other constituents, including Ss and VPs, also have the wrong boundary.", "labels": [], "entities": []}, {"text": "This problem is compounded by the fact that the rules in Negra are substantially flatter than the rules in the Penn Treebank, for which the Collins model was developed.", "labels": [], "entities": [{"text": "Negra", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.9411669373512268}, {"text": "Penn Treebank", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.9937212765216827}, {"text": "Collins model", "start_pos": 140, "end_pos": 153, "type": "DATASET", "confidence": 0.9533719718456268}]}, {"text": "compares the average number of daughters in both corpora.", "labels": [], "entities": []}, {"text": "The flatness of PPs is easy to reduce.", "labels": [], "entities": []}, {"text": "As detailed in Section 2.2, PPs lack an intermediate NP projection, which can be inserted straightforwardly using the following rule: In the present experiment, we investigated if parsing performance improves if we test and train on aversion of Negra on which the transformation in, but instead substitutes Pr (and, by analogy, Pl ) by: Here the head H is substituted by the sister R i\u22121 (and L i\u22121 ).", "labels": [], "entities": [{"text": "parsing", "start_pos": 180, "end_pos": 187, "type": "TASK", "confidence": 0.9772258996963501}, {"text": "Negra", "start_pos": 245, "end_pos": 250, "type": "DATASET", "confidence": 0.8971065282821655}]}, {"text": "In the literature, the version of Pr in is said to capture head-head relationships.", "labels": [], "entities": []}, {"text": "We will refer to the alternative model in as capturing sister-head relationships.", "labels": [], "entities": []}, {"text": "Using sister-head relationships is away of counteracting the flatness of the grammar productions; it implicitly adds binary branching to the grammar.", "labels": [], "entities": []}, {"text": "Our proposal is to extend the use of sister-head relationship from non-recursive NPs (as proposed by Collins) to all categories.", "labels": [], "entities": []}, {"text": "shows the linguistic features of the resulting model compared to the models of,.", "labels": [], "entities": []}, {"text": "The C&R model effectively includes category information about all previous sisters, as it uses contextfree rules.", "labels": [], "entities": []}, {"text": "The Collins (1997) model does not use context-free rules, but generates the next category using zeroth order Markov chains (see Section 3.3), hence no information about the previous sisters is included.", "labels": [], "entities": []}, {"text": "model extends this to higher order Markov chains (first to third order), and therefore includes category information about previous sisters.The current model differs from all these proposals: it does not use any information about the head sister, but instead includes the category, headword, and head tag of the previous sister, effectively treating it as the head.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for the Collins (1997) model for  various languages (dependency precision for Czech)", "labels": [], "entities": []}, {"text": " Table 2: Results for Experiment 1: comparison of lexicalized and unlexicalized models (GF: grammatical  functions; pool: parameter pooling for NPs/PPs and conjoined categories)", "labels": [], "entities": []}, {"text": " Table 3: Average number of daughters for the gram- matical categories in the Penn Treebank and Negra", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 78, "end_pos": 91, "type": "DATASET", "confidence": 0.9929156303405762}, {"text": "Negra", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.5779799818992615}]}, {"text": " Table 5: Results for Experiment 2: performance for models using split phrases and sister-head dependencies", "labels": [], "entities": []}, {"text": " Table 6: Change in performance when reverting to  head-head statistics for individual categories", "labels": [], "entities": []}]}