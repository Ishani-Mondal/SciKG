{"title": [{"text": "A Comparative Study on Reordering Constraints in Statistical Machine Translation", "labels": [], "entities": [{"text": "Reordering Constraints in Statistical Machine Translation", "start_pos": 23, "end_pos": 80, "type": "TASK", "confidence": 0.7772280623515447}]}], "abstractContent": [{"text": "In statistical machine translation, the generation of a translation hypothesis is com-putationally expensive.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6488014658292135}]}, {"text": "If arbitrary word-reorderings are permitted, the search problem is NP-hard.", "labels": [], "entities": []}, {"text": "On the other hand, if we restrict the possible word-reorderings in an appropriate way, we obtain a polynomial-time search algorithm.", "labels": [], "entities": []}, {"text": "In this paper, we compare two different reordering constraints, namely the ITG constraints and the IBM constraints.", "labels": [], "entities": [{"text": "ITG constraints", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.8965264856815338}, {"text": "IBM constraints", "start_pos": 99, "end_pos": 114, "type": "DATASET", "confidence": 0.872588187456131}]}, {"text": "This comparison includes a theoretical discussion on the permitted number of re-orderings for each of these constraints.", "labels": [], "entities": []}, {"text": "We show a connection between the ITG constraints and the since 1870 known Schr\u00f6der numbers.", "labels": [], "entities": []}, {"text": "We evaluate these constraints on two tasks: the Verbmobil task and the Cana-dian Hansards task.", "labels": [], "entities": [{"text": "Cana-dian Hansards task", "start_pos": 71, "end_pos": 94, "type": "DATASET", "confidence": 0.8644395271937052}]}, {"text": "The evaluation consists of two parts: First, we check how many of the Viterbi alignments of the training corpus satisfy each of these constraints.", "labels": [], "entities": []}, {"text": "Second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.", "labels": [], "entities": []}, {"text": "The experiments will show that the base-line ITG constraints are not sufficient on the Canadian Hansards task.", "labels": [], "entities": [{"text": "Canadian Hansards task", "start_pos": 87, "end_pos": 109, "type": "DATASET", "confidence": 0.8973800539970398}]}, {"text": "Therefore , we present an extension to the ITG constraints.", "labels": [], "entities": []}, {"text": "These extended ITG constraints increase the alignment coverage from about 87% to 96%.", "labels": [], "entities": [{"text": "ITG", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.8897426128387451}, {"text": "alignment", "start_pos": 44, "end_pos": 53, "type": "TASK", "confidence": 0.9367727637290955}, {"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.653098464012146}]}], "introductionContent": [{"text": "In statistical machine translation, we are given a source language ('French') sentence f J 1 = f 1 . .", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6925295988718668}]}, {"text": "f J , which is to be translated into a target language ('English') sentence e I 1 = e 1 . .", "labels": [], "entities": []}, {"text": "e I . Among all possible target language sentences, we will choose the sentence with the highest probability: = argmax e I 1 {P r(e I 1 ) \u00b7 P r(f J 1 |e I 1 )} (2) The decomposition into two knowledge sources in Eq.", "labels": [], "entities": [{"text": "argmax e I 1", "start_pos": 112, "end_pos": 124, "type": "METRIC", "confidence": 0.942857563495636}]}, {"text": "2 is the so-called source-channel approach to statistical machine translation (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.704432209332784}]}, {"text": "It allows an independent modeling of target language model P r(e I 1 ) and translation model P r(f J 1 |e I 1 ).", "labels": [], "entities": []}, {"text": "The target language model describes the well-formedness of the target language sentence.", "labels": [], "entities": []}, {"text": "The translation model links the source language sentence to the target language sentence.", "labels": [], "entities": []}, {"text": "It can be further decomposed into alignment and lexicon model.", "labels": [], "entities": []}, {"text": "The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.", "labels": [], "entities": []}, {"text": "We have to maximize overall possible target language sentences.", "labels": [], "entities": []}, {"text": "In this paper, we will focus on the alignment problem, i.e. the mapping between source sentence positions and target sentence positions.", "labels": [], "entities": []}, {"text": "As the word order in source and target language may differ, the search algorithm has to allow certain word-reorderings.", "labels": [], "entities": []}, {"text": "If arbitrary word-reorderings are allowed, the search problem is NP-hard).", "labels": [], "entities": []}, {"text": "Therefore, we have to restrict the possible reorderings in someway to make the search problem feasible.", "labels": [], "entities": []}, {"text": "Here, we will discuss two such constraints in detail.", "labels": [], "entities": []}, {"text": "The first constraints are based on inversion transduction grammars (ITG).", "labels": [], "entities": []}, {"text": "In the following, we will call these the ITG constraints.", "labels": [], "entities": []}, {"text": "The second constraints are the IBM constraints ().", "labels": [], "entities": [{"text": "IBM", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.634041965007782}]}, {"text": "In the next section, we will describe these constraints from a theoretical point of view.", "labels": [], "entities": []}, {"text": "Then, we will describe the resulting search algorithm and its extension for word graph generation.", "labels": [], "entities": [{"text": "word graph generation", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.6876425544420878}]}, {"text": "Afterwards, we will analyze the Viterbi alignments produced during the training of the alignment models.", "labels": [], "entities": []}, {"text": "Then, we will compare the translation results when restricting the search to either of these constraints.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will investigate for each of the constraints the coverage of the training corpus alignment.", "labels": [], "entities": []}, {"text": "For this purpose, we compute the Viterbi alignment of IBM Model 5 with GIZA++ ).", "labels": [], "entities": [{"text": "IBM Model 5", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.9497133096059164}]}, {"text": "This alignment is produced without any restrictions on word-reorderings.", "labels": [], "entities": []}, {"text": "Then, we check for every sentence if the alignment satisfies each of the constraints.", "labels": [], "entities": []}, {"text": "The ratio of the number of satisfied alignments and the total number of sentences is referred to as coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9912704229354858}]}, {"text": "4 shows the results for the Verbmobil task and for the Canadian Hansards task.", "labels": [], "entities": [{"text": "Verbmobil task", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.6273266971111298}, {"text": "Canadian Hansards task", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.8860470056533813}]}, {"text": "It contains the results for both translation directions German-English (S\u2192T) and English-German (T\u2192S) for the Verbmobil task and French-English (S\u2192T) and English-French (T\u2192S) for the Canadian Hansards task, respectively.", "labels": [], "entities": [{"text": "Canadian Hansards task", "start_pos": 183, "end_pos": 205, "type": "DATASET", "confidence": 0.8539084394772848}]}, {"text": "For the Verbmobil task, the baseline ITG constraints and the IBM constraints result in a similar coverage.", "labels": [], "entities": []}, {"text": "It is about 91% for the German-English translation direction and about 88% for the EnglishGerman translation direction.", "labels": [], "entities": [{"text": "EnglishGerman translation direction", "start_pos": 83, "end_pos": 118, "type": "DATASET", "confidence": 0.8291002114613851}]}, {"text": "A significantly higher   In our experiments, we use the following error criteria: \u2022 WER (word error rate): The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the target sentence.", "labels": [], "entities": [{"text": "WER", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9944463968276978}, {"text": "word error rate)", "start_pos": 89, "end_pos": 105, "type": "METRIC", "confidence": 0.8272147178649902}, {"text": "WER", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9957345128059387}]}, {"text": "\u2022 PER (position-independent word error rate): A shortcoming of the WER is the fact that it requires a perfect word order.", "labels": [], "entities": [{"text": "PER", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.9973008036613464}, {"text": "position-independent word error rate)", "start_pos": 7, "end_pos": 44, "type": "METRIC", "confidence": 0.7216750323772431}, {"text": "WER", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.7765474915504456}]}, {"text": "The PER compares the words in the two sentences ignoring the word order.", "labels": [], "entities": [{"text": "PER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9520605206489563}]}, {"text": "\u2022 mWER (multi-reference word error rate): For each test sentence, not only a single reference translation is used, as for the WER, but a whole set of reference translations.", "labels": [], "entities": [{"text": "multi-reference word error rate)", "start_pos": 8, "end_pos": 40, "type": "METRIC", "confidence": 0.6828696072101593}, {"text": "WER", "start_pos": 126, "end_pos": 129, "type": "DATASET", "confidence": 0.45960330963134766}]}, {"text": "For each translation hypothesis, the WER to the most similar sentence is calculated ().", "labels": [], "entities": [{"text": "WER", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9984593391418457}]}, {"text": "\u2022 BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9862821996212006}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.998875081539154}]}, {"text": "BLEU measures accuracy, i.e. large BLEU scores are better.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9884402751922607}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9994174242019653}, {"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9987710118293762}]}, {"text": "\u2022 SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary.", "labels": [], "entities": [{"text": "SSER (subjective sentence error rate)", "start_pos": 2, "end_pos": 39, "type": "METRIC", "confidence": 0.7168883723872048}]}, {"text": "Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Ratio of the number of permitted reorderings with the ITG constraints S n\u22121 and the IBM constraints  r n for different sentence lengths n.", "labels": [], "entities": [{"text": "Ratio", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9656413197517395}, {"text": "ITG", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.9105526208877563}]}, {"text": " Table 2: Statistics of training and test corpus for  the Verbmobil task (PP=perplexity, SL=sentence  length).", "labels": [], "entities": [{"text": "SL=sentence  length", "start_pos": 89, "end_pos": 108, "type": "METRIC", "confidence": 0.7584767192602158}]}, {"text": " Table 3: Statistics of training and test corpus  for the Canadian Hansards task (PP=perplexity,  SL=sentence length).  French English  Train Sentences  1.5M  Words  24M  22M  Vocabulary 100 269 78 332  Singletons  40 199 31 319  average SL  16.6  15.1  Test  Sentences  5432  Words  97 646 88 773  Trigram PP  - 179.8  average SL  18.0  16.3", "labels": [], "entities": [{"text": "Canadian Hansards task", "start_pos": 58, "end_pos": 80, "type": "DATASET", "confidence": 0.8654812375704447}, {"text": "French English  Train Sentences  1.5M  Words  24M  22M  Vocabulary 100", "start_pos": 120, "end_pos": 190, "type": "DATASET", "confidence": 0.8896350622177124}, {"text": "Trigram PP  - 179.8  average SL  18.0  16.3", "start_pos": 299, "end_pos": 342, "type": "METRIC", "confidence": 0.7572773583233356}]}, {"text": " Table 4: Coverage on the training corpus for align- ment constraints for the Verbmobil task (VM) and  for the Canadian Hansards task (CH).  coverage [%]  task  constraint  S\u2192T T\u2192S  VM IBM  91.0  88.1  ITG baseline  91.6  87.0  extended  96.5  96.9  CH IBM  87.1  86.7  ITG baseline  81.3  73.6  extended  96.1  95.6", "labels": [], "entities": [{"text": "Canadian Hansards task (CH)", "start_pos": 111, "end_pos": 138, "type": "DATASET", "confidence": 0.8955963551998138}, {"text": "coverage", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9837893843650818}, {"text": "IBM  91.0  88.1  ITG baseline  91.6  87.0  extended  96.5  96.9  CH IBM  87.1  86.7  ITG baseline  81.3  73.6  extended  96.1  95.6", "start_pos": 185, "end_pos": 316, "type": "DATASET", "confidence": 0.618007386014575}]}, {"text": " Table 5: Translation results on the Verbmobil task.  type  automatic  human  System WER [%] PER [%] mWER [%] BLEU [%] SSER [%]  IBM  46.2  33.3  40.0  42.5  40.8  ITG  45.6  33.9  40.0  37.1  42.0", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9682300686836243}, {"text": "WER", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.8474546074867249}, {"text": "PER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9521934390068054}, {"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9078066945075989}, {"text": "IBM  46.2  33.3  40.0  42.5  40.8  ITG  45.6  33.9  40.0  37.1  42.0", "start_pos": 129, "end_pos": 197, "type": "DATASET", "confidence": 0.8689698874950409}]}, {"text": " Table 6: Verbmobil: translation examples.  source ja, ich w\u00fcrde den Flug um viertel nach sieben vorschlagen.  reference yes, I would suggest the flight at a quarter past seven.", "labels": [], "entities": []}]}