{"title": [{"text": "Parametric Models of Linguistic Count Data", "labels": [], "entities": [{"text": "Parametric Models of Linguistic Count", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.5751522243022918}]}], "abstractContent": [{"text": "It is well known that occurrence counts of words in documents are often mod-eled poorly by standard distributions like the binomial or Poisson.", "labels": [], "entities": []}, {"text": "Observed counts vary more than simple models predict, prompting the use of overdispersed models like Gamma-Poisson or Beta-binomial mixtures as robust alternatives.", "labels": [], "entities": [{"text": "Observed counts", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9316290020942688}]}, {"text": "Another deficiency of standard models is due to the fact that most words never occur in a given document, resulting in large amounts of zero counts.", "labels": [], "entities": []}, {"text": "We propose using zero-inflated models for dealing with this, and evaluate competing models on a Naive Bayes text classification task.", "labels": [], "entities": [{"text": "Naive Bayes text classification task", "start_pos": 96, "end_pos": 132, "type": "TASK", "confidence": 0.76497802734375}]}, {"text": "Simple zero-inflated models can account for practically relevant variation, and can be easier to work with than overdispersed models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic count data often violate the simplistic assumptions of standard probability models like the binomial or Poisson distribution.", "labels": [], "entities": []}, {"text": "In particular, the inadequacy of the Poisson distribution for modeling word (token) frequency is well known, and robust alternatives have been proposed.", "labels": [], "entities": []}, {"text": "In the case of the Poisson, a commonly used robust alternative is the negative binomial distribution, which has the ability to capture extra-Poisson variation in the data, in other words, it is overdispersed compared with the Poisson.", "labels": [], "entities": []}, {"text": "When a small set of parameters controls all properties of the distribution it is important to have enough parameters to model the relevant aspects of one's data.", "labels": [], "entities": []}, {"text": "Simple models like the Poisson or binomial do not have enough parameters for many realistic applications, and we suspect that the same might be true of loglinear models.", "labels": [], "entities": []}, {"text": "When applying robust models like the negative binomial to linguistic count data like word occurrences in documents, it is natural to ask to what extent the extra-Poisson variation has been captured by the model.", "labels": [], "entities": []}, {"text": "Answering that question is our main goal, and we begin by reviewing some of the classic results of.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Ob- serve the huge number of passages with zero oc- currences of his, which is ten times the number of  passages with exactly one occurrence. Also notice  how the negative binomial distribution fitted using  the Method of Maximum Likelihood (MLE model,  first line in", "labels": [], "entities": [{"text": "Ob", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9722492098808289}]}, {"text": " Table 1: Occurrence counts of his in Hamilton and  Madison passages.", "labels": [], "entities": [{"text": "Occurrence counts", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.959968626499176}, {"text": "Hamilton and  Madison passages", "start_pos": 38, "end_pos": 68, "type": "DATASET", "confidence": 0.9236070066690445}]}, {"text": " Table 3. As we can see, the classifi- cation results under the zero-inflated binomial and  beta-binomial models are never significantly differ-", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of the four models on the News- group data set for different vocabulary sizes.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9949017763137817}, {"text": "News- group data set", "start_pos": 45, "end_pos": 65, "type": "DATASET", "confidence": 0.9655680060386658}]}, {"text": " Table 3: Pairwise McNemar test results. A in- dicates a significant difference of the classification  results when comparing a pair of of models.", "labels": [], "entities": [{"text": "A", "start_pos": 41, "end_pos": 42, "type": "METRIC", "confidence": 0.9757039546966553}]}]}