{"title": [{"text": "An Expert Lexicon Approach to Identifying English Phrasal Verbs", "labels": [], "entities": [{"text": "Identifying English Phrasal Verbs", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.8521130234003067}]}], "abstractContent": [{"text": "Phrasal Verbs are an important feature of the English language.", "labels": [], "entities": []}, {"text": "Properly identifying them provides the basis for an English parser to decode the related structures.", "labels": [], "entities": []}, {"text": "Phrasal verbs have been a challenge to Natural Language Processing (NLP) because they sit at the borderline between lexicon and syntax.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.702003280321757}]}, {"text": "Traditional NLP frameworks that separate the lexicon module from the parser make it difficult to handle this problem properly.", "labels": [], "entities": []}, {"text": "This paper presents a finite state approach that integrates a phrasal verb expert lexicon between shallow parsing and deep parsing to handle morpho-syntactic interaction.", "labels": [], "entities": []}, {"text": "With precision/recall combined performance benchmarked consistently at 95.8%-97.5%, the Phrasal Verb identification problem has basically been solved with the presented method.", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.999275267124176}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9876865744590759}, {"text": "Phrasal Verb identification", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.6774190962314606}]}], "introductionContent": [{"text": "Any natural language processing (NLP) system needs to address the issue of handling multiword expressions, including Phrasal Verbs (PV).", "labels": [], "entities": []}, {"text": "This paper presents a proven approach to identifying English PVs based on pattern matching using a formalism called Expert Lexicon.", "labels": [], "entities": []}, {"text": "Phrasal Verbs are an important feature of the English language since they form about one third of the English verb vocabulary.", "labels": [], "entities": [{"text": "Phrasal Verbs", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.4823344945907593}]}, {"text": "1 Properly recognizing PVs is an important condition for English parsing.", "labels": [], "entities": [{"text": "English parsing", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.7186574935913086}]}, {"text": "Like single-word verbs, each PV has its own lexical features including subcategorization features that determine its structural patterns, e.g., look for has syntactic subcategorization and semantic features similar to those of search; carry\u2026on shares lexical features with continue.", "labels": [], "entities": []}, {"text": "Such lexical features can be represented in the PV lexicon in the same way as those for single-word verbs, but a parser can only use them when the PV is identified.", "labels": [], "entities": []}, {"text": "Problems like PVs are regarded as 'a pain in the neck for NLP'.", "labels": [], "entities": []}, {"text": "A proper solution to this problem requires tighter interaction between syntax and lexicon than traditionally available.", "labels": [], "entities": []}, {"text": "Simple lexical lookup leads to severe degradation in both precision and recall, as our benchmarks show (Section 4).", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9992309808731079}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9985355138778687}]}, {"text": "The recall problem is mainly due to separable PVs such as turn\u2026off which allow for syntactic units to be inserted inside the PV compound, e.g., turn it off, turn the radio off.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.997582197189331}]}, {"text": "The precision problem is caused by the ambiguous function of the particle.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9975070357322693}]}, {"text": "For example, a simple lexical lookup will mistag looked for as a phrasal verb in sentences such as He looked for quite awhile but saw nothing.", "labels": [], "entities": []}, {"text": "In short, the traditional NLP framework that separates the lexicon module from a parser makes it difficult to handle this problem properly.", "labels": [], "entities": []}, {"text": "This paper presents an expert lexicon approach that integrates the lexical module with contextual checking based on shallow parsing results.", "labels": [], "entities": []}, {"text": "Extensive blind benchmarking shows that this approach is very effective for identifying phrasal verbs, resulting in the precision/recall combined F-score of about 96%.", "labels": [], "entities": [{"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9996048808097839}, {"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9499741196632385}, {"text": "F-score", "start_pos": 146, "end_pos": 153, "type": "METRIC", "confidence": 0.9838353395462036}]}, {"text": "The remaining text is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the problem and defines the task.", "labels": [], "entities": []}, {"text": "Section 3 presents the Expert Lexicon formalism and illustrates the use of this formalism in solving this problem.", "labels": [], "entities": []}, {"text": "Section 4 shows the benchmarking and analysis, followed by conclusions in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2. The F-score is a combined measure  of precision and recall, reflecting the overall  performance of a system.", "labels": [], "entities": [{"text": "F-score", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9975641965866089}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9994764924049377}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9990277290344238}]}, {"text": " Table 1. Running Text Benchmarking 1", "labels": [], "entities": []}, {"text": " Table 2. Sampling Corpus Benchmarking", "labels": [], "entities": [{"text": "Sampling Corpus Benchmarking", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8579206466674805}]}, {"text": " Table 3. Running Text Benchmarking 2", "labels": [], "entities": []}]}