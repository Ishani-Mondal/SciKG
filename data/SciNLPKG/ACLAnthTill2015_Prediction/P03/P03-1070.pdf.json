{"title": [{"text": "Towards a Model of Face-to-Face Grounding", "labels": [], "entities": [{"text": "Face-to-Face Grounding", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.6907868385314941}]}], "abstractContent": [{"text": "We investigate the verbal and nonverbal means for grounding, and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction.", "labels": [], "entities": []}, {"text": "We analyzed eye gaze, head nods and attentional focus in the context of a direction giving task.", "labels": [], "entities": []}, {"text": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded, and the overall pattern reflected a monitoring of lack of negative feedback.", "labels": [], "entities": []}, {"text": "Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.", "labels": [], "entities": []}], "introductionContent": [{"text": "An essential part of conversation is to ensure that the other participants share an understanding of what has been said, and what is meant.", "labels": [], "entities": []}, {"text": "The process of ensuring that understanding -adding what has been said to the common ground -is called grounding.", "labels": [], "entities": []}, {"text": "In face-to-face interaction, nonverbal signals as well as verbal participate in the grounding process, to indicate that an utterance is grounded, or that further work is needed to ground.", "labels": [], "entities": []}, {"text": "shows an example of human face-to-face conversation.", "labels": [], "entities": []}, {"text": "Even though no verbal feedback is provided, the speaker (S) continues to add to the directions.", "labels": [], "entities": []}, {"text": "Intriguingly, the listener gives no explicit nonverbal feedback -no nods or gaze towards S.", "labels": [], "entities": []}, {"text": "S, however, is clearly monitoring the listener's behavior, as we see by the fact that S looks at her twice (continuous lines above the words).", "labels": [], "entities": []}, {"text": "In fact, our analyses show that maintaining focus of attention on the task (dash-dot lines underneath the words) is the listener's public signal of understanding S's utterance sufficiently for the task at hand.", "labels": [], "entities": []}, {"text": "Because S is manifestly attending to this signal, the signal allows the two jointly to recognize S's contribution as grounded.", "labels": [], "entities": []}, {"text": "This paper provides empirical support for an essential role for nonverbal behaviors in grounding, motivating an architecture for an embodied conversational agent that can establish common ground using eye gaze, head nods, and attentional focus.", "labels": [], "entities": []}, {"text": "Although grounding has received significant attention in the literature, previous work has not addressed the following questions: (1) what predictive factors account for how people use nonverbal signals to ground information, (2) how can a model of the face-to-face grounding process be used to adapt dialogue management to face-to-face conversation with an embodied conversational agent.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 301, "end_pos": 320, "type": "TASK", "confidence": 0.7268249094486237}]}, {"text": "This paper addresses these issues, with the goal of contributing to the literature on discourse phenomena, and of building more advanced conversational humanoids that can engage inhuman conversational protocols.", "labels": [], "entities": []}, {"text": "In the next section, we discuss relevant previous work, report results from our own empirical study and, based on our analysis of conversational data, propose a model of grounding using both verbal and nonverbal information, and present our implementation of that model into an embodied conversational agent.", "labels": [], "entities": []}, {"text": "As a preliminary evaluation, we compare a user interacting with the embodied conversational agent with and without grounding.", "labels": [], "entities": []}], "datasetContent": [{"text": "Based on previous direction-giving tasks, students from two different universities gave directions to campus locations to one another.", "labels": [], "entities": []}, {"text": "Each pair had a conversation in a (1) Face-to-face condition (F2F): where two subjects sat with a map drawn by the direction-giver sitting between them, and in a (2) Shared Reference condition (SR): where an L-shaped screen between the subjects let them share a map drawn by the direction-giver, but not to seethe other's face or body.", "labels": [], "entities": [{"text": "F2F)", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.926544189453125}, {"text": "Shared Reference condition (SR)", "start_pos": 166, "end_pos": 197, "type": "METRIC", "confidence": 0.6758202761411667}]}, {"text": "Interactions between the subjects were videorecorded from four different angles, and combined by a video mixer into synchronized video clips.", "labels": [], "entities": []}, {"text": "Although we have shown an empirical basis for our implementation, it is important to ensure both that human users interact with MACK as we expect, and that their interaction is more effective than without nonverbal grounding.", "labels": [], "entities": []}, {"text": "The issue of effectiveness merits a full-scale study and thus we have chosen to concentrate hereon whether MACK elicits the same behaviors from users as does interaction with other humans.", "labels": [], "entities": [{"text": "MACK elicits", "start_pos": 107, "end_pos": 119, "type": "TASK", "confidence": 0.8935902416706085}]}, {"text": "Two subjects were therefore assigned to one of the following two conditions, both of which were run as Wizard of Oz (that is, \"speech recognition\" was carried out by an experimenter): (a) MACK-with-grounding: MACK recognized user's nonverbal signals for grounding, and displayed his nonverbal signals as a speaker.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.764296144247055}]}, {"text": "(b) MACK-without-grounding: MACK paid no attention to the user's nonverbal behavior, and did not display nonverbal signals as a speaker.", "labels": [], "entities": []}, {"text": "He gave the directions in one single turn.", "labels": [], "entities": []}, {"text": "Subjects were instructed to ask for directions to two places, and were told that they would have to lead the experimenters to those locations to test their comprehension.", "labels": [], "entities": []}, {"text": "We analyzed the second direction-giving interaction, after subjects became accustomed to the system.", "labels": [], "entities": []}, {"text": "Results: In neither condition, did users return verbal feedback during MACK's direction giving.", "labels": [], "entities": [{"text": "MACK's direction giving", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.6489353477954865}]}, {"text": "As shown in, in MACK-with-grounding 7 nonverbal status transitions were observed during his direction giving, which consisted of 5 Assertion UUs, one of them an elaboration.", "labels": [], "entities": []}, {"text": "The transition patterns between MACK and the user when MACK used nonverbal grounding are strikingly similar to those in our empirical study of humanto-human communication.", "labels": [], "entities": []}, {"text": "There were three transitions to gM/gM (both look at the map), which is a normal status in map task conversation, and two transitions to gP/gM (MACK looks at the user, and the user looks at the map), which is the most frequent transition in Assertion as reported in Section 3.", "labels": [], "entities": [{"text": "Assertion", "start_pos": 240, "end_pos": 249, "type": "TASK", "confidence": 0.9487727880477905}]}, {"text": "Moreover, in MACK's third UU, the user began looking at MACK at the middle of the UU and kept looking at him after the UU ended.", "labels": [], "entities": [{"text": "MACK's third UU", "start_pos": 13, "end_pos": 28, "type": "DATASET", "confidence": 0.5231280997395515}]}, {"text": "This behavior successfully elicited MACK's elaboration in the next UU.", "labels": [], "entities": [{"text": "MACK's elaboration", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6929095486799876}, {"text": "UU", "start_pos": 67, "end_pos": 69, "type": "DATASET", "confidence": 0.9659808874130249}]}, {"text": "On the other hand, in the MACK-withoutgrounding condition, the user never looked at MACK, and nodded only once, early on.", "labels": [], "entities": []}, {"text": "As shown in, only three transitions were observed (shift to gMgM at the beginning of the interaction, shift to gMgMwN, then back to gMgM).", "labels": [], "entities": []}, {"text": "While a larger scale evaluation with quantitative data is one of the most important issues for future work, the results of this preliminary study strongly support our model, and show MACK's potential for interacting with a human user using human-human conversational protocols.", "labels": [], "entities": []}], "tableCaptions": []}