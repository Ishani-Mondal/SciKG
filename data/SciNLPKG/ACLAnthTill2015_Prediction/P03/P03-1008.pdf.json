{"title": [{"text": "Syntactic Features and Word Similarity for Supervised Metonymy Resolution", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a supervised machine learning algorithm for metonymy resolution, which exploits the similarity between examples of conventional metonymy.", "labels": [], "entities": [{"text": "metonymy resolution", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.9515156447887421}]}, {"text": "We show that syntactic head-modifier relations area high precision feature for metonymy recognition but suffer from data sparse-ness.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.993553876876831}, {"text": "metonymy recognition", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.8851495683193207}]}, {"text": "We partially overcome this problem by integrating a thesaurus and introducing simpler grammatical features, thereby preserving precision and increasing recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9988136291503906}, {"text": "recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9946198463439941}]}, {"text": "Our algorithm generalises over two levels of contextual similarity.", "labels": [], "entities": []}, {"text": "Resulting inferences exceed the complexity of inferences undertaken in word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.6491634746392568}]}, {"text": "We also compare automatic and manual methods for syntactic feature extraction.", "labels": [], "entities": [{"text": "syntactic feature extraction", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.7290777564048767}]}], "introductionContent": [{"text": "Metonymy is a figure of speech, in which one expression is used to refer to the standard referent of a related one (.", "labels": [], "entities": []}, {"text": "In (1), 1 \"seat 19\" refers to the person occupying seat 19.", "labels": [], "entities": []}, {"text": "(1) Ask seat 19 whether he wants to swap The importance of resolving metonymies has been shown fora variety of NLP tasks, e.g., machine translation, question answering and anaphora resolution).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8009591400623322}, {"text": "question answering", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.8615843057632446}, {"text": "anaphora resolution", "start_pos": 172, "end_pos": 191, "type": "TASK", "confidence": 0.7044703364372253}]}, {"text": "(1) was actually uttered by a flight attendant on a plane.", "labels": [], "entities": []}, {"text": "In order to recognise and interpret the metonymy in (1), a large amount of knowledge and contextual inference is necessary (e.g. seats cannot be questioned, people occupy seats, people can be questioned).", "labels": [], "entities": []}, {"text": "Metonymic readings are also potentially open-ended, so that developing a machine learning algorithm based on previous examples does not seem feasible.", "labels": [], "entities": []}, {"text": "However, it has long been recognised that many metonymic readings are actually quite regular.", "labels": [], "entities": []}, {"text": "In (2), \"Pakistan\", the name of a location, refers to one of its national sports teams.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of readings in our corpus", "labels": [], "entities": [{"text": "Distribution of readings", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.846319834391276}]}, {"text": " Table 4: Example thesaurus entries", "labels": [], "entities": []}, {"text": " Table 5: Results summary for manual annotation.  For relax I and combination we report best results  (50 thesaurus iterations).", "labels": [], "entities": [{"text": "combination", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.972939670085907}]}, {"text": " Table 6: Results summary for the different algo- rithms using RASP. For relax I and combination  we report best results (50 thesaurus iterations).", "labels": [], "entities": [{"text": "combination", "start_pos": 85, "end_pos": 96, "type": "METRIC", "confidence": 0.9511568546295166}]}]}