{"title": [{"text": "Improved Source-Channel Models for Chinese Word Segmentation 1", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.5707915524641672}]}], "abstractContent": [{"text": "This paper presents a Chinese word segmen-tation system that uses improved source-channel models of Chinese sentence generation.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 100, "end_pos": 127, "type": "TASK", "confidence": 0.6715062061945597}]}, {"text": "Chinese words are defined as one of the following four types: lexicon words, morphologically derived words, factoids, and named entities.", "labels": [], "entities": []}, {"text": "Our system provides a unified approach to the four fundamental features of word-level Chinese language processing: (1) word segmentation, (2) morphological analysis , (3) factoid detection, and (4) named entity recognition.", "labels": [], "entities": [{"text": "word-level Chinese language processing", "start_pos": 75, "end_pos": 113, "type": "TASK", "confidence": 0.5771991237998009}, {"text": "word segmentation", "start_pos": 119, "end_pos": 136, "type": "TASK", "confidence": 0.750643253326416}, {"text": "factoid detection", "start_pos": 171, "end_pos": 188, "type": "TASK", "confidence": 0.8962029814720154}, {"text": "named entity recognition", "start_pos": 198, "end_pos": 222, "type": "TASK", "confidence": 0.6590517262617747}]}, {"text": "The performance of the system is evaluated on a manually annotated test set, and is also compared with several state-of-the-art systems, taking into account the fact that the definition of Chinese words often varies from system to system.", "labels": [], "entities": []}, {"text": "1 Introduction Chinese word segmentation is the initial step of many Chinese language processing tasks, and has attracted a lot of attention in the research community.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6463321050008138}, {"text": "Chinese language processing tasks", "start_pos": 69, "end_pos": 102, "type": "TASK", "confidence": 0.6903428882360458}]}, {"text": "It is a challenging problem due to the fact that there is no standard definition of Chinese words.", "labels": [], "entities": []}, {"text": "In this paper, we define Chinese words as one of the following four types: entries in a lexicon, morphologically derived words, factoids, and named entities.", "labels": [], "entities": []}, {"text": "We then present a Chinese word segmen-tation system which provides a solution to the four fundamental problems of word-level Chinese language processing: word segmentation, morphological analysis, factoid detection, and named entity recognition (NER).", "labels": [], "entities": [{"text": "word-level Chinese language processing", "start_pos": 114, "end_pos": 152, "type": "TASK", "confidence": 0.5844332352280617}, {"text": "word segmentation", "start_pos": 154, "end_pos": 171, "type": "TASK", "confidence": 0.7261300086975098}, {"text": "morphological analysis", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.7480096220970154}, {"text": "factoid detection", "start_pos": 197, "end_pos": 214, "type": "TASK", "confidence": 0.9050816893577576}, {"text": "named entity recognition (NER)", "start_pos": 220, "end_pos": 250, "type": "TASK", "confidence": 0.7625870207945505}]}, {"text": "There are no word boundaries in written Chinese text.", "labels": [], "entities": []}, {"text": "Therefore, unlike English, it may not be desirable to separate the solution to word segmenta-tion from the solutions to the other three problems.", "labels": [], "entities": []}, {"text": "Ideally, we would like to propose a unified approach to all the four problems.", "labels": [], "entities": []}, {"text": "The unified approach we used in our system is based on the improved source-channel models of Chinese sentence generation, with two components: a source model and a set of channel models.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.6339350342750549}]}, {"text": "The source model is used to estimate the generative probability of a word sequence, in which each word belongs to one word type.", "labels": [], "entities": []}, {"text": "For each word type, a channel model is used to estimate the generative probability of a character string given the word type.", "labels": [], "entities": []}, {"text": "So there are multiple channel models.", "labels": [], "entities": []}, {"text": "We shall show in this paper that our models provide a statistical framework to corporate a wide variety linguistic knowledge and statistical models in a unified way.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our system using an annotated test set.", "labels": [], "entities": []}, {"text": "We also compare our system with several state-of-the-art systems, taking into account the fact that the definition of Chinese words often varies from system to system.", "labels": [], "entities": []}, {"text": "In the rest of this paper: Section 2 discusses previous work.", "labels": [], "entities": []}, {"text": "Section 3 gives the detailed definition of Chinese words.", "labels": [], "entities": []}, {"text": "Sections 4 to 6 describe in detail the improved source-channel models.", "labels": [], "entities": []}, {"text": "Section 8 describes the evaluation results.", "labels": [], "entities": []}, {"text": "Section 9 presents our conclusion.", "labels": [], "entities": []}, {"text": "2 Previous Work Many methods of Chinese word segmentation have been proposed: reviews include (Wu and Tseng, 1993; Sproat and Shih, 2001).", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.624943862358729}]}, {"text": "These methods can be roughly classified into dictionary-based methods and statistical-based methods, while many state-of-the-art systems use hybrid approaches.", "labels": [], "entities": []}, {"text": "In dictionary-based methods (e.g. Cheng et al., 1999), given an input character string, only words that are stored in the dictionary can be identified.", "labels": [], "entities": []}, {"text": "The performance of these methods thus depends to", "labels": [], "entities": []}], "introductionContent": [{"text": "Chinese word segmentation is the initial step of many Chinese language processing tasks, and has attracted a lot of attention in the research community.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5792801380157471}, {"text": "Chinese language processing tasks", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.6960888579487801}]}, {"text": "It is a challenging problem due to the fact that there is no standard definition of Chinese words.", "labels": [], "entities": []}, {"text": "In this paper, we define Chinese words as one of the following four types: entries in a lexicon, morphologically derived words, factoids, and named entities.", "labels": [], "entities": []}, {"text": "We then present a Chinese word segmentation system which provides a solution to the four fundamental problems of word-level Chinese language processing: word segmentation, morphological analysis, factoid detection, and named entity recognition (NER).", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.6622623999913534}, {"text": "word-level Chinese language processing", "start_pos": 113, "end_pos": 151, "type": "TASK", "confidence": 0.5936955362558365}, {"text": "word segmentation", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.7283093929290771}, {"text": "morphological analysis", "start_pos": 172, "end_pos": 194, "type": "TASK", "confidence": 0.7427541315555573}, {"text": "factoid detection", "start_pos": 196, "end_pos": 213, "type": "TASK", "confidence": 0.9020295143127441}, {"text": "named entity recognition (NER)", "start_pos": 219, "end_pos": 249, "type": "TASK", "confidence": 0.7720746994018555}]}, {"text": "There are no word boundaries in written Chinese text.", "labels": [], "entities": []}, {"text": "Therefore, unlike English, it may not be desirable to separate the solution to word segmentation from the solutions to the other three problems.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7113850563764572}]}, {"text": "Ideally, we would like to propose a unified approach to all the four problems.", "labels": [], "entities": []}, {"text": "The unified approach we used in our system is based on the improved source-channel models of Chinese sentence generation, with two components: a source model and a set of channel models.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.6339350342750549}]}, {"text": "The source model is used to estimate the generative probability of a word sequence, in which each word belongs to one word type.", "labels": [], "entities": []}, {"text": "For each word type, a channel model is used to estimate the generative probability of a character string given the word type.", "labels": [], "entities": []}, {"text": "So there are multiple channel models.", "labels": [], "entities": []}, {"text": "We shall show in this paper that our models provide a statistical framework to corporate a wide variety linguistic knowledge and statistical models in a unified way.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our system using an annotated test set.", "labels": [], "entities": []}, {"text": "We also compare our system with several state-of-the-art systems, taking into account the fact that the definition of Chinese words often varies from system to system.", "labels": [], "entities": []}, {"text": "In the rest of this paper: Section 2 discusses previous work.", "labels": [], "entities": []}, {"text": "Section 3 gives the detailed definition of Chinese words.", "labels": [], "entities": []}, {"text": "Sections 4 to 6 describe in detail the improved source-channel models.", "labels": [], "entities": []}, {"text": "Section 8 describes the evaluation results.", "labels": [], "entities": []}, {"text": "Section 9 presents our conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "To conduct a reliable evaluation, a manually annotated test set was developed.", "labels": [], "entities": []}, {"text": "As described earlier, it is more useful to define words depending on how the words are used in real applications.", "labels": [], "entities": []}, {"text": "In our system, a lexicon (containing 98,668 lexicon words and 59,285 morphologically derived words) has been constructed for several applications, such as Asian language input and web search.", "labels": [], "entities": []}, {"text": "Therefore, we annotate the text corpus based on the lexicon.", "labels": [], "entities": []}, {"text": "That is, we segment each sentence as much as possible into words that are stored in our lexicon, and tag only the new words, which otherwise would be segmented into strings of one -character words.", "labels": [], "entities": []}, {"text": "When there are multiple segmentations fora sentence, we keep only one that contains the least number of words.", "labels": [], "entities": []}, {"text": "The annotated test set contains in total 247,039 tokens (including 205,162 lexicon/morph-lexicon words, 4,347 PNs, 5,311 LNs, 3,850 ONs, and 6,630 factoids, etc.)", "labels": [], "entities": []}, {"text": "Our system is measured through multiple precision-recall (P/R) pairs, and F-measures (F \u03b2=1 , which is defined as 2PR/(P+R)) for each word class.", "labels": [], "entities": [{"text": "precision-recall (P/R)", "start_pos": 40, "end_pos": 62, "type": "METRIC", "confidence": 0.8516409198443095}, {"text": "F-measures", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9797705411911011}, {"text": "F \u03b2", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.8679310083389282}]}, {"text": "Since the annotated test set is based on a particular lexicon, some of the evaluation measures are meaningless when we compare our system to other systems that use different lexicons.", "labels": [], "entities": []}, {"text": "So in comparison with different systems, we consider only the precision-recall of NER and the number of OAS errors (i.e. crossing brackets) because these measures are lexicon independent and there is always a single unambiguous answer.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 62, "end_pos": 78, "type": "METRIC", "confidence": 0.9989615678787231}, {"text": "NER", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.621303379535675}, {"text": "OAS errors", "start_pos": 104, "end_pos": 114, "type": "METRIC", "confidence": 0.9288859963417053}]}, {"text": "The training corpus for context model contains approximately 80 million Chinese characters from various domains of text such as newspapers, novels, magazines etc.", "labels": [], "entities": []}, {"text": "The training corpora for class models are described in Section 5.", "labels": [], "entities": []}], "tableCaptions": []}