{"title": [{"text": "A Syllable Based Word Recognition Model for Korean Noun Extraction", "labels": [], "entities": [{"text": "Syllable Based Word Recognition", "start_pos": 2, "end_pos": 33, "type": "TASK", "confidence": 0.6874998062849045}, {"text": "Korean Noun Extraction", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7699226339658102}]}], "abstractContent": [{"text": "Noun extraction is very important for many NLP applications such as information retrieval, automatic text classification, and information extraction.", "labels": [], "entities": [{"text": "Noun extraction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8258675634860992}, {"text": "information retrieval", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.8370401561260223}, {"text": "automatic text classification", "start_pos": 91, "end_pos": 120, "type": "TASK", "confidence": 0.6083778540293375}, {"text": "information extraction", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.9164452254772186}]}, {"text": "Most of the previous Korean noun extraction systems use a morphological analyzer or a Part-of-Speech (POS) tagger.", "labels": [], "entities": [{"text": "Korean noun extraction", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.5639788806438446}]}, {"text": "Therefore, they require much of the linguistic knowledge such as morpheme dictionaries and rules (e.g. morphosyntactic rules and morphological rules).", "labels": [], "entities": []}, {"text": "This paper proposes anew noun extraction method that uses the syllable based word recognition model.", "labels": [], "entities": [{"text": "noun extraction", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8839813768863678}, {"text": "syllable based word recognition", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6894706785678864}]}, {"text": "It finds the most probable syllable-tag sequence of the input sentence by using automatically acquired statistical information from the POS tagged corpus and extracts nouns by detecting word boundaries.", "labels": [], "entities": [{"text": "POS tagged corpus", "start_pos": 136, "end_pos": 153, "type": "DATASET", "confidence": 0.7522201538085938}]}, {"text": "Furthermore, it does not require any labor for constructing and maintaining linguistic knowledge.", "labels": [], "entities": []}, {"text": "We have performed various experiments with a wide range of variables influencing the performance.", "labels": [], "entities": []}, {"text": "The experimental results show that without morphological analysis or POS tagging, the proposed method achieves comparable performance with the previous methods.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.7418063879013062}]}], "introductionContent": [{"text": "Noun extraction is a process to find every noun in a document ().", "labels": [], "entities": [{"text": "Noun extraction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8002866804599762}]}, {"text": "In Korean, Nouns are used as the most important terms (features) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.7895345091819763}, {"text": "text summarization", "start_pos": 167, "end_pos": 185, "type": "TASK", "confidence": 0.7216225862503052}, {"text": "information extraction", "start_pos": 187, "end_pos": 209, "type": "TASK", "confidence": 0.8284994959831238}]}, {"text": "Korean is a highly agglutinative language and nouns are included in Eojeols.", "labels": [], "entities": [{"text": "Eojeols", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9200681447982788}]}, {"text": "An Eojeol is a surface level form consisting of more than one combined morpheme.", "labels": [], "entities": []}, {"text": "Therefore, morphological analysis or POS tagging is required to extract Korean nouns.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.6953772902488708}, {"text": "POS tagging", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.7291813790798187}]}, {"text": "The previous Korean noun extraction methods are classified into two categories: morphological analysis based method) and POS tagging based method).", "labels": [], "entities": [{"text": "noun extraction", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.6518469899892807}, {"text": "POS tagging", "start_pos": 121, "end_pos": 132, "type": "TASK", "confidence": 0.6868151426315308}]}, {"text": "The morphological analysis based method tries to generate all possible interpretations fora given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries.", "labels": [], "entities": [{"text": "Eojeol", "start_pos": 98, "end_pos": 104, "type": "DATASET", "confidence": 0.9614443778991699}]}, {"text": "It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 89, "end_pos": 103, "type": "METRIC", "confidence": 0.9807063937187195}]}, {"text": "Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (), they cannot completely resolve the ambiguity.", "labels": [], "entities": []}, {"text": "The POS tagging based method chooses the most probable analysis among the results produced by the morphological analyzer.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6879216730594635}]}, {"text": "Due to the resolution of the ambiguities, it can obtain relatively accurate results.", "labels": [], "entities": []}, {"text": "But it also suffers from errors not only produced by a POS tagger but also triggered by the preceding morphological analyzer.", "labels": [], "entities": []}, {"text": "Furthermore, both methods have serious deficien- cies in that they require considerable manual labor to construct and maintain linguistic knowledge and suffer from the unknown word problem.", "labels": [], "entities": []}, {"text": "If a morphological analyzer fails to recognize an unknown noun in an unknown Eojeol, the POS tagger would never extract the unknown noun.", "labels": [], "entities": []}, {"text": "Although the morphological analyzer properly recognizes the unknown noun, it would not be extracted due to the sparse data problem.", "labels": [], "entities": []}, {"text": "This paper proposes anew noun extraction method that uses a syllable based word recognition model.", "labels": [], "entities": [{"text": "noun extraction", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8879215717315674}]}, {"text": "The proposed method does not require labor for constructing and maintaining linguistic knowledge and it can also alleviate the unknown word problem or the sparse data problem.", "labels": [], "entities": []}, {"text": "It finds the most probable syllable-tag sequence of the input sentence by using statistical information and extracts nouns by detecting the word boundaries.", "labels": [], "entities": []}, {"text": "The statistical information is automatically acquired from a POS annotated corpus and the word boundary can be detected by using an additional tag to represent the boundary of a word.", "labels": [], "entities": [{"text": "POS annotated corpus", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.7521796822547913}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, the notion of word is defined.", "labels": [], "entities": []}, {"text": "Section 3 presents the syllable based word recognition model.", "labels": [], "entities": [{"text": "syllable based word recognition", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.5704325810074806}]}, {"text": "Section 4 describes the method of constructing the training data from existing POS tagged corpora.", "labels": [], "entities": []}, {"text": "Section 5 discusses experimental results.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divided the test data into ten parts.", "labels": [], "entities": []}, {"text": "The performances of the model are measured by averaging over Figure 3: Changes of F-measure according to the size of training data the ten test sets in the 10-fold cross-validation experiment.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9969767332077026}]}, {"text": "shows experimental results according to each representation scheme and tagset.", "labels": [], "entities": []}, {"text": "In the first column, each number denotes the tagset used.", "labels": [], "entities": []}, {"text": "When it comes to the issue of frequency, the cases of considering frequency are better for precision but worse for recall, and better for F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9995456337928772}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9994584918022156}, {"text": "F-measure", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9881682991981506}]}, {"text": "The representation schemes using single syllable information (e.g. \"BIS\", \"IES\") are better than other representation schemes (e.g. \"BI\", \"IE\").", "labels": [], "entities": [{"text": "BIS", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9441367983818054}]}, {"text": "Contrary to our expectation, the results of Tagset 2 consistently outperform other tagsets.", "labels": [], "entities": []}, {"text": "The results of Tagset 1 are not as good as other tagsets because of the lack of the syntactic context.", "labels": [], "entities": []}, {"text": "Nevertheless, the results reflect the usefulness of the syllable based processing.", "labels": [], "entities": []}, {"text": "The changes of the F-measure according to the tagsets and the representation schemes reflecting frequency are shown in.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9721716046333313}]}, {"text": "To show the influence of the difference between the training data and the test data, we have performed the experiments on the Sejong corpus as a training data and the entire ETRI corpus as a test data.", "labels": [], "entities": [{"text": "Sejong corpus", "start_pos": 126, "end_pos": 139, "type": "DATASET", "confidence": 0.9621853232383728}, {"text": "ETRI corpus", "start_pos": 174, "end_pos": 185, "type": "DATASET", "confidence": 0.9760564267635345}]}, {"text": "shows the experimental results on all of the three training data.", "labels": [], "entities": []}, {"text": "Although more training data are used in this experiment, the results of shows better outcomes.", "labels": [], "entities": []}, {"text": "Like other POS tagging models, this indicates that our model is dependent on the text domain.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.7666228711605072}]}, {"text": "Results reported by are presented in.", "labels": [], "entities": []}, {"text": "The experiments were performed on the same condition as that of our experiments.", "labels": [], "entities": []}, {"text": "NE2001, which is a system designed only to extract nouns, improves efficiency of the general morphological analyzer by using positive and negative information about occurrences of nouns.", "labels": [], "entities": [{"text": "NE2001", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9704421758651733}, {"text": "general morphological analyzer", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.6311674614747366}]}, {"text": "KOMA () is a general-purpose morphological analyzer.) is a POS tagger, which takes the result of KOMA as input.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 59, "end_pos": 69, "type": "TASK", "confidence": 0.670367568731308}]}, {"text": "According to, HanTag, which is a POS tagger, is an optimal tool in performing noun extraction in terms of the precision and the F-measure.", "labels": [], "entities": [{"text": "HanTag", "start_pos": 14, "end_pos": 20, "type": "DATASET", "confidence": 0.9113460779190063}, {"text": "POS tagger", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.6553360670804977}, {"text": "noun extraction", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.8929267227649689}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.999523401260376}, {"text": "F-measure", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.993850588798523}]}, {"text": "Although the best performance of our proposed model (BIS-2) is worse than HanTag, it is better than NE2001 and KOMA.", "labels": [], "entities": [{"text": "BIS-2", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.6406612396240234}, {"text": "HanTag", "start_pos": 74, "end_pos": 80, "type": "DATASET", "confidence": 0.9495987296104431}, {"text": "NE2001", "start_pos": 100, "end_pos": 106, "type": "DATASET", "confidence": 0.9450119137763977}, {"text": "KOMA", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.9044542908668518}]}], "tableCaptions": [{"text": " Table 3: Experimental results of the ten-fold cross validation  without considering frequency  with considering frequency  Precision Recall F-measure Precision Recall F-measure  BI-1  72.37  83.61  77.58  74.61  82.47  78.34  BI-2  85.99  92.30  89.03  88.96  90.42  89.69  BI-3  84.85  91.20  87.90  87.56  89.55  88.54  BIS-1  78.50  83.53  80.93  80.36  83.99  82.13  BIS-2  88.15  92.34  90.19  90.65  91.58  91.11  BIS-3  86.92  91.07  88.94  89.27  90.62  89.94  IE-1  73.21  81.38  77.07  75.11  81.04  77.96  IE-2  85.12  91.54  88.21  88.37  90.34  89.34  IE-3  83.28  89.70  86.37  86.54  88.80  87.65  IES-1  78.07  82.69  80.31  79.54  83.08  81.27  IES-2  87.30  92.18  89.67  90.05  91.48  90.76  IES-3  85.80  90.79  88.22  88.46  90.47  89.45", "labels": [], "entities": [{"text": "cross validation", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.6135370880365372}, {"text": "F-measure Precision Recall F-measure  BI-1", "start_pos": 141, "end_pos": 183, "type": "METRIC", "confidence": 0.4947469413280487}, {"text": "BIS-1", "start_pos": 323, "end_pos": 328, "type": "METRIC", "confidence": 0.933849573135376}, {"text": "BIS-2", "start_pos": 372, "end_pos": 377, "type": "METRIC", "confidence": 0.9207215905189514}, {"text": "BIS-3  86.92  91.07  88.94  89.27  90.62  89.94  IE-1  73.21  81.38  77.07  75.11  81.04  77.96  IE-2  85.12  91.54  88.21  88.37  90.34  89.34  IE-3  83.28  89.70  86.37  86.54  88.80  87.65  IES-1  78.07  82.69  80.31  79.54  83.08  81.27  IES-2  87.30  92.18  89.67  90.05  91.48  90.76  IES-3  85.80  90.79  88.22  88.46  90.47  89.45", "start_pos": 421, "end_pos": 759, "type": "TASK", "confidence": 0.6864252826389001}]}, {"text": " Table 4: Experimental results of Sejong corpus (from 1999 to 2001)  without considering frequency  with considering frequency  Precision Recall F-measure Precision Recall F-measure  BI-1  71.91  83.92  77.45  73.57  82.95  77.98  BI-2  85.38  89.96  87.61  87.19  88.26  87.72  BI-3  83.36  89.17  86.17  85.12  87.39  86.24  BIS-1  76.77  82.60  79.58  78.40  83.16  80.71  BIS-2  87.66  90.41  89.01  88.75  89.75  89.25  BIS-3  86.02  88.89  87.43  87.10  88.41  87.75  IE-1  70.82  79.97  75.12  72.67  79.64  75.99  IE-2  84.18  89.23  86.63  85.99  87.83  86.90  IE-3  82.01  87.67  84.74  83.79  86.57  85.16  IES-1  76.19  81.84  78.91  77.31  82.32  79.74  IES-2  86.41  89.33  87.85  87.66  88.75  88.20  IES-3  84.45  88.28  86.33  85.89  87.96  86.91", "labels": [], "entities": [{"text": "Sejong corpus", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.7414791733026505}, {"text": "F-measure Precision Recall F-measure  BI-1  71.91  83.92  77.45  73.57  82.95  77.98  BI-2", "start_pos": 145, "end_pos": 235, "type": "METRIC", "confidence": 0.6277224123477936}, {"text": "BIS-1", "start_pos": 327, "end_pos": 332, "type": "METRIC", "confidence": 0.9568933248519897}, {"text": "BIS-3", "start_pos": 425, "end_pos": 430, "type": "METRIC", "confidence": 0.911227285861969}]}, {"text": " Table 5: Performances of other systems  without considering frequency  with considering frequency  Precision Recall F-measure Precision Recall F-measure  NE2001  84.08  91.34  87.56  87.02  89.86  88.42  KOMA  60.10  93.12  73.06  58.07  93.67  71.70  HanTag  90.54  88.68  89.60  91.77  88.58  90.15", "labels": [], "entities": [{"text": "NE2001  84.08  91.34  87.56  87.02  89.86  88.42  KOMA  60.10  93.12  73.06  58.07  93.67  71.70  HanTag  90.54  88.68  89.60  91.77  88.58  90.15", "start_pos": 155, "end_pos": 301, "type": "DATASET", "confidence": 0.9000049602417719}]}]}