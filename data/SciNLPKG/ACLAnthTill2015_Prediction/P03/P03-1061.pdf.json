{"title": [{"text": "Morphological Analysis of a Large Spontaneous Speech Corpus in Japanese", "labels": [], "entities": [{"text": "Morphological Analysis of a Large Spontaneous Speech Corpus", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8033869788050652}]}], "abstractContent": [{"text": "This paper describes two methods for detecting word segments and their morphological information in a Japanese spontaneous speech corpus, and describes how to tag a large spontaneous speech corpus accurately by using the two methods.", "labels": [], "entities": [{"text": "detecting word segments and their morphological information", "start_pos": 37, "end_pos": 96, "type": "TASK", "confidence": 0.8293852039745876}]}, {"text": "The first method is used to detect any type of word segments.", "labels": [], "entities": []}, {"text": "The second method is used when there are several definitions for word segments and their POS categories, and when one type of word segments includes another type of word segments.", "labels": [], "entities": []}, {"text": "In this paper, we show that by using semi-automatic analysis we achieve a precision of better than 99% for detecting and tagging short words and 97% for long words; the two types of words that comprise the corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9993784427642822}, {"text": "detecting and tagging short words", "start_pos": 107, "end_pos": 140, "type": "TASK", "confidence": 0.7766040623188019}]}, {"text": "We also show that better accuracy is achieved by using both methods than by using only the first.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9993113279342651}]}], "introductionContent": [{"text": "The \"Spontaneous Speech: Corpus and Processing Technology\" project is sponsoring the construction of a large spontaneous Japanese speech corpus, Corpus of Spontaneous Japanese (CSJ) ().", "labels": [], "entities": []}, {"text": "The CSJ is a collection of monologues and dialogues, the majority being monologues such as academic presentations and simulated public speeches.", "labels": [], "entities": []}, {"text": "Simulated public speeches are short speeches presented specifically for the corpus by paid non-professional speakers.", "labels": [], "entities": []}, {"text": "The CSJ includes transcriptions of the speeches as well as audio recordings of them.", "labels": [], "entities": []}, {"text": "One of the goals of the project is to detect two types of word segments and corresponding morphological information in the transcriptions.", "labels": [], "entities": []}, {"text": "The two types of word segments were defined by the members of The National Institute for Japanese Language and are called short word and long word.", "labels": [], "entities": []}, {"text": "The term short word approximates a dictionary item found in an ordinary Japanese dictionary, and long word represents various compounds.", "labels": [], "entities": []}, {"text": "The length and part-of-speech (POS) of each are different, and every short word is included in along word, which is shorter than a Japanese phrasal unit, a bunsetsu.", "labels": [], "entities": [{"text": "part-of-speech (POS)", "start_pos": 15, "end_pos": 35, "type": "METRIC", "confidence": 0.8364241272211075}]}, {"text": "If all of the short words in the CSJ were detected, the number of the words would be approximately seven million.", "labels": [], "entities": []}, {"text": "That would be the largest spontaneous speech corpus in the world.", "labels": [], "entities": []}, {"text": "So far, approximately one tenth of the words have been manually detected, and morphological information such as POS category and inflection type have been assigned to them.", "labels": [], "entities": []}, {"text": "Human annotators tagged every morpheme in the one tenth of the CSJ that has been tagged, and other annotators checked them.", "labels": [], "entities": []}, {"text": "The human annotators discussed their disagreements and resolved them.", "labels": [], "entities": []}, {"text": "The accuracies of the manual tagging of short and long words in the one tenth of the CSJ were greater than 99.8% and 97%, respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.997870683670044}, {"text": "CSJ", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.5043473243713379}]}, {"text": "The accuracies were evaluated by random sampling.", "labels": [], "entities": []}, {"text": "As it took over two years to tag one tenth of the CSJ accurately, tagging the remainder with morphological information would take about twenty years.", "labels": [], "entities": []}, {"text": "Therefore, the remaining nine tenths of the CSJ must be tagged automatically or semi-automatically.", "labels": [], "entities": [{"text": "CSJ", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.9087591767311096}]}, {"text": "In this paper, we describe methods for detecting the two types of word segments and corresponding morphological information.", "labels": [], "entities": []}, {"text": "We also describe how to tag a large spontaneous speech corpus accurately.", "labels": [], "entities": []}, {"text": "Henceforth, we call the two types of word segments short word and long word respectively, or merely morphemes.", "labels": [], "entities": []}, {"text": "We use the term morphological analysis for the process of segmenting a given sentence into a row of morphemes and assigning to each morpheme grammatical attributes such as a POS category.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we used 744,204 short words and 618,538 long words for training, and 63,037 short words and 51,796 long words for testing.", "labels": [], "entities": []}, {"text": "Those words were extracted from one tenth of the CSJ that already had been manually tagged.", "labels": [], "entities": [{"text": "CSJ", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.8125821948051453}]}, {"text": "The training corpus consisted of 319 speeches and the test corpus consisted of 19 speeches.", "labels": [], "entities": []}, {"text": "Transcription consisted of basic form and pronunciation, as shown in.", "labels": [], "entities": []}, {"text": "Speech sounds were faithfully transcribed as pronunciation, and also represented as basic forms by using kanji and hiragana characters.", "labels": [], "entities": []}, {"text": "Lines beginning with numerical digits are time stamps and represent the time it took to produce the lines between that timestamp and the next timestamp.", "labels": [], "entities": []}, {"text": "Each line other than time stamps represents a bunsetsu.", "labels": [], "entities": []}, {"text": "In our experiments, we used only the basic forms.", "labels": [], "entities": []}, {"text": "Basic forms were tagged with several types of labels such as fillers, as shown in.", "labels": [], "entities": []}, {"text": "Strings tagged with those labels were handled according to rules as shown in the rightmost columns in.", "labels": [], "entities": []}, {"text": "Since there are no boundaries between sentences in the corpus, we selected the places in the CSJ that: Example of transformation rules. are automatically detected as pauses of 500 ms or longer and then designated them as sentence boundaries.", "labels": [], "entities": []}, {"text": "In addition to these, we also used utterance boundaries as sentence boundaries.", "labels": [], "entities": []}, {"text": "These are automatically detected at places where short pauses (shorter than 200 ms but longer than 50 ms) follow the typical sentence-ending forms of predicates such as verbs, adjectives, and copula.", "labels": [], "entities": []}, {"text": "Results of the morphological analysis obtained by using morpheme models are shown in and 4.", "labels": [], "entities": []}, {"text": "In these tables, OOV indicates Out-of-Vocabulary rates.", "labels": [], "entities": [{"text": "OOV", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9961791038513184}, {"text": "Out-of-Vocabulary", "start_pos": 31, "end_pos": 48, "type": "METRIC", "confidence": 0.9811151623725891}]}, {"text": "Shown in, OOV was calculated as the proportion of words not found in a dictionary to all words in the test corpus.", "labels": [], "entities": [{"text": "OOV", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.997916042804718}]}, {"text": "In, OOV was calculated as the proportion of word and POS category pairs that were not found in a dictionary to all pairs in the test corpus.", "labels": [], "entities": [{"text": "OOV", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9983066320419312}]}, {"text": "Recall is the percentage of morphemes in the test corpus for which the segmentation and major POS category were identified correctly.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9923498034477234}]}, {"text": "Precision is the percentage of all morphemes identified by the system that were identified correctly.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9916141033172607}]}, {"text": "The F-measure is defined by the following equation.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9706239700317383}]}, {"text": "show that accuracies would improve significantly if no words were unknown.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9962252378463745}]}, {"text": "This indicates that all morphemes of the CSJ could be analyzed accurately if there were no unknown words.", "labels": [], "entities": []}, {"text": "The improvements that we can expect by detecting unknown words and putting them into dictionaries are about 1.5 in F-measure for detecting word segments of short words and 2.5 for long words.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9995386600494385}]}, {"text": "For detecting the word segments and their POS categories, for short words we expect an improvement of about 2 in F-measure and for long words 3.", "labels": [], "entities": [{"text": "POS", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9216198921203613}, {"text": "F-measure", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.996638298034668}]}, {"text": "Next, we discuss accuracies obtained when unknown words existed.", "labels": [], "entities": []}, {"text": "The OOV for long words was 4% higher than that for short words.", "labels": [], "entities": [{"text": "OOV", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9992190599441528}]}, {"text": "In general, the higher the OOV is, the more difficult detecting word segments and their POS categories is.", "labels": [], "entities": [{"text": "OOV", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9518333077430725}]}, {"text": "However, the difference between accuracies for short and long words was about 1% in recall and 2% in precision, which is not significant when we consider that the difference between OOVs for short and long words was 4%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9892126321792603}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9988670349121094}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9995647072792053}]}, {"text": "This result indicates that our morpheme models could detect both known and unknown words accurately, especially long words.", "labels": [], "entities": []}, {"text": "Therefore, we investigated the recall of unknown words in the test corpus, and found that 55.7% (928/1,667) of short word segments and 74.1% (2,660/3,590) of long word segments were detected correctly.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9603602886199951}]}, {"text": "In addition, regarding unknown words, we also found that 47.5% (791/1,667) of short word segments plus their POS categories and 67.3% (2,415/3,590) of long word segments plus their POS categories were detected correctly.", "labels": [], "entities": []}, {"text": "The recall of unknown words was about 20% higher for long words than for short words.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9993796348571777}]}, {"text": "We believe that this result mainly depended on the difference between short words and long words in terms of the definitions of compound words.", "labels": [], "entities": []}, {"text": "A compound word is defined as one word when it is based on the definition of long words; however it is defined as two or more words when it is based on the definition of short words.", "labels": [], "entities": []}, {"text": "Furthermore, based on the definition of short words, a division of compound words depends on its context.", "labels": [], "entities": []}, {"text": "More information is needed to precisely detect short words than is required for long words.", "labels": [], "entities": []}, {"text": "Next, we extracted words that were detected by the morpheme model but were not found in a dictionary, and investigated the percentage of unknown words that were completely or partially matched to the extracted words by their context.", "labels": [], "entities": []}, {"text": "This percentage was 77.6% (1,293/1,667) for short words, and 80.6% (2,892/3,590) for long words.", "labels": [], "entities": []}, {"text": "Most of the remaining unknown words that could not be detected by this method are compound words.", "labels": [], "entities": []}, {"text": "We expect that these compounds can be detected during the manual examination of those words for which the morpheme model estimated a low probability, as will be shown later.", "labels": [], "entities": []}, {"text": "The recall of unknown words was lower than that of known words, and the accuracy of automatic morphological analysis was lower than that of manual morphological analysis.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9985702037811279}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9996637105941772}]}, {"text": "As previously stated, to improve the accuracy of the whole corpus we take a semi-automatic approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9985004663467407}]}, {"text": "We assume that the smaller the probability is for an output morpheme estimated by a model, the more likely the output morpheme is wrong, and we examine output morphemes in ascending order of their probabilities.", "labels": [], "entities": []}, {"text": "We investigated how much the accuracy of the whole corpus would increase.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.999114453792572}]}, {"text": "shows the relationship between the percentage of output morphemes whose probabilities exceed a threshold and their Output Rates (%) \"short_without_UKW\" \"long_without_UKW\" \"short_with_UKW\" \"long_with_UKW\" Figure 5: Partial analysis. precision.", "labels": [], "entities": [{"text": "Output Rates", "start_pos": 115, "end_pos": 127, "type": "METRIC", "confidence": 0.985800176858902}, {"text": "UKW", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.95960533618927}, {"text": "precision", "start_pos": 232, "end_pos": 241, "type": "METRIC", "confidence": 0.9988141059875488}]}, {"text": "In this figure, \"short without UKW\", \"long without UKW\ud97b\udf59\", \"short with UKW\", and \"long with UKW\" represent the precision for short words detected assuming there were no unknown words, precision for long words detected assuming there were no unknown words, precision of short words including unknown words, and precision of long words including unknown words, respectively.", "labels": [], "entities": [{"text": "UKW", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.9300399422645569}, {"text": "UKW", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.9305450916290283}, {"text": "UKW", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.9055508375167847}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9986974596977234}, {"text": "precision", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9985336065292358}, {"text": "precision", "start_pos": 255, "end_pos": 264, "type": "METRIC", "confidence": 0.9978151321411133}, {"text": "precision", "start_pos": 309, "end_pos": 318, "type": "METRIC", "confidence": 0.9987382292747498}]}, {"text": "When the output rate in the horizontal axis increases, the number of low-probability morphemes increases.", "labels": [], "entities": []}, {"text": "In all graphs, precisions monotonously decrease as output rates increase.", "labels": [], "entities": [{"text": "precisions", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9991711378097534}]}, {"text": "This means that tagging errors can be revised effectively when morphemes are examined in ascending order of their probabilities.", "labels": [], "entities": []}, {"text": "Next, we investigated the relationship between the percentage of morphemes examined manually and the precision obtained after detected errors were revised.", "labels": [], "entities": [{"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.999567449092865}]}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "Precision represents the precision of word segmentation and POS tagging.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9815989136695862}, {"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9991620779037476}, {"text": "word segmentation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.72627954185009}, {"text": "POS tagging", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.8192788064479828}]}, {"text": "If unknown words were detected and put into a dictionary by the method described in the fourth paragraph of this section, the graph line for short words would be drawn between the graph lines \"short without UKW\" and \"short with UKW\", and the graph line for long words would be drawn between the graph lines \"long without UKW\" and \"long with UKW\".", "labels": [], "entities": [{"text": "UKW", "start_pos": 228, "end_pos": 231, "type": "DATASET", "confidence": 0.9495477676391602}, {"text": "UKW", "start_pos": 341, "end_pos": 344, "type": "DATASET", "confidence": 0.962047278881073}]}, {"text": "Based on test results, we can expect better than 99% precision for short words and better than 97% precision for long words in the whole corpus when we examine 10% of output mor-  phemes in ascending order of their probabilities.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9982183575630188}, {"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9971200227737427}]}, {"text": "Finally, we investigated the relationship between percentage of morphemes examined manually and the error rate for all of the examined morphemes.", "labels": [], "entities": [{"text": "error rate", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9800433814525604}]}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "We found that about 50% of examined morphemes would be found as errors at the beginning of the examination and about 20% of examined morphemes would be found as errors when examination of 10% of the whole corpus was completed.", "labels": [], "entities": []}, {"text": "When unknown words were detected and put into a dictionary, the error rate decreased; even so, over 10% of examined morphemes would be found as errors.", "labels": [], "entities": [{"text": "error rate", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.992102861404419}]}, {"text": "Results of the morphological analysis of long words obtained by using a chunking model are shown in and 6.", "labels": [], "entities": []}, {"text": "The first and second lines  show the respective accuracies obtained when OOVs were 5.81% and 6.93%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9987205266952515}, {"text": "OOVs", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.7399494647979736}]}, {"text": "The third lines show the accuracies obtained when we assumed that the OOV for short words was 0% and there were no errors in detecting short word segments and their POS categories.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9834344387054443}, {"text": "OOV", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9988306164741516}]}, {"text": "The fourth line in shows the accuracy obtained when a chunking model without transformation rules was used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9996029734611511}]}, {"text": "The accuracy obtained by using the chunking model was one point higher in F-measure than that obtained by using the morpheme model, and it was very close to the accuracy achieved for short words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992706179618835}, {"text": "F-measure", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.995215654373169}, {"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9964362382888794}]}, {"text": "This result indicates that errors newly produced by applying a chunking model to the results obtained for short words were slight, or errors in the results obtained for short words were amended by applying the chunking model.", "labels": [], "entities": []}, {"text": "This result also shows that we can achieve good accuracy for long words by applying a chunking model even if we do not detect unknown long words and do not put them into a dictionary.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9979057312011719}]}, {"text": "If we could improve the accuracy for short words, the accuracy for long words would be improved also.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9989544153213501}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9992030262947083}]}, {"text": "The third lines in show that the accuracy would improve to over 98 points in F-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9997854828834534}, {"text": "F-measure", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9758729934692383}]}, {"text": "The fourth line in transformation rules significantly contributed to improving the accuracy.", "labels": [], "entities": [{"text": "transformation", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9691699743270874}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.998410701751709}]}, {"text": "Considering the results obtained in this section and in Section 4.2.1, we are now detecting short and long word segments and their POS categories in the whole corpus by using the following steps: 1.", "labels": [], "entities": []}, {"text": "Automatically detect and manually examine unknown words for short words.", "labels": [], "entities": []}, {"text": "2. Improve the accuracy for short words in the whole corpus by manually examining short words in ascending order of their probabilities estimated by a morpheme model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9983330368995667}]}, {"text": "3. Apply a chunking model to the short words to detect long word segments and their POS categories.", "labels": [], "entities": []}, {"text": "As future work, we are planning to use an active learning method such as that proposed by) to more effectively improve the accuracy of the whole corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9976795315742493}]}], "tableCaptions": [{"text": " Table 3: Accuracies of word segmentation.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9221243858337402}, {"text": "word segmentation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7045523375272751}]}, {"text": " Table 4: Accuracies of word segmentation and POS  tagging.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9417469501495361}, {"text": "word segmentation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7569386959075928}, {"text": "POS  tagging", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.8624607026576996}]}, {"text": " Table 5: Accuracies of long word segmentation.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9619602560997009}, {"text": "long word segmentation", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.671212246020635}]}, {"text": " Table 6: Accuracies of long word segmentation and  POS tagging.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9644294381141663}, {"text": "long word segmentation", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.6533156136671702}, {"text": "POS tagging", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.8526727557182312}]}]}