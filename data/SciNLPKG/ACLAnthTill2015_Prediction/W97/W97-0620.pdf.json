{"title": [{"text": "Dialogue Strategies for Improving the Usability of Telephone Human-Machine Communication", "labels": [], "entities": [{"text": "Telephone Human-Machine Communication", "start_pos": 51, "end_pos": 88, "type": "TASK", "confidence": 0.6339835027853647}]}], "abstractContent": [{"text": "Interactions with spoken language systems may present breakdowns that are due to errors in the acoustic decoding of user utterances.", "labels": [], "entities": []}, {"text": "Some of these errors have important consequences in reducing the naturalness of human-machine dialogues.", "labels": [], "entities": []}, {"text": "In this paper we identify some typologies of recognition errors that cannot be recovered during the syntactico-semantic analysis, but that maybe effectively approached at the dialogue level.", "labels": [], "entities": []}, {"text": "We will describe how non-understanding and the effects of misrecog-nition are dealt with by Dialogos, a real-time spoken dialogue system that allows users to access a database of railway information by telephone.", "labels": [], "entities": []}, {"text": "We will discuss the importance of supporting confirmation turns, and clarification and correction sub-dialogues.", "labels": [], "entities": [{"text": "confirmation turns", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.9425118863582611}]}, {"text": "We will show the positive effects of robust dialogue management and dialogue state dependent language modeling, by taking into account both the recognition and understanding performance, and the success rate of dialogue transactions.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7958588898181915}, {"text": "dialogue state dependent language modeling", "start_pos": 68, "end_pos": 110, "type": "TASK", "confidence": 0.7034708261489868}]}], "introductionContent": [{"text": "During the last few years the recognition of spontaneous speech in telephone applications \"has greatly improved; nevertheless spoken dialogue between computers and inexperienced users still presents some problematic issues that reduce the user satisfaction in interacting with spoken language systems.", "labels": [], "entities": []}, {"text": "The occurrence of errors in the acoustic decoding of users' utterance is the potential cause of miscommunication in oral interaction with spoken language systems.", "labels": [], "entities": []}, {"text": "Some of these errors have important consequences in reducing the naturalness of humanmachine dialogues.", "labels": [], "entities": []}, {"text": "Sometimes a robust approach in parsing and the use of language models during recognition are not sufficient to avoid recognition breakdowns.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9706281423568726}]}, {"text": "The recognition performance has a direct impact on the requirements that the dialogue modules of spoken language systems have to meet.", "labels": [], "entities": []}, {"text": "In order to increase the usability of the applications, dialogue management modules have to deal with partial or total breakdowns of the lower levels of analysis by preventing and detecting miscommunication sources.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8439258635044098}]}, {"text": "In this paper we identify some typologies of recognition errors that cannot be recovered during the syntactico-semantic analysis, but that maybe effectively approached at the dialogue level.", "labels": [], "entities": []}, {"text": "Our analysis and the methodologies we describe have been tested in a task-oriented telephone application, but we deem that some considerations may also be useful for other display-less human-machine communication applications.", "labels": [], "entities": []}, {"text": "We will describe how nonunderstanding and the effects of misrecognition are dealt within Dialogos, a real-time spoken language system that allows/users to access a database of railway information by using the telephone.", "labels": [], "entities": []}, {"text": "A detailed description of the different modules of Dialogos maybe found in (.", "labels": [], "entities": []}, {"text": "In this paper we will discuss the importance of supporting confirmation turns, and clarification and correction subdialogues.", "labels": [], "entities": [{"text": "confirmation turns", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.9225993454456329}]}, {"text": "The dialogue module of Dialogos makes an extensive use of context knowledge: contextual information is used not only for validating or rejecting semantic interpretations, but it is also sent to the lower levels of input analysis for helping the recognizer.", "labels": [], "entities": []}, {"text": "We will show that the positive effects of robust dialogue management and dialogue state dependent language modeling maybe evaluated by taking into account both the recognition and understanding performance, and the success rate of dialogue transactions.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7657539248466492}, {"text": "dialogue state dependent language modeling", "start_pos": 73, "end_pos": 115, "type": "TASK", "confidence": 0.6839583873748779}]}, {"text": "From our experience we may conclude that if we provide robust behaviour in our dialogue systems, speech is a viable interface even with relatively low word accuracy rates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.8452145457267761}]}, {"text": "Nevertheless we believe that some important issues are still unexplored, and one of these is related to the weight that recognition errors have with respect to the degree of co-operativeness of the users.", "labels": [], "entities": []}, {"text": "These open issues and some experimental data that emphasize their I14 urgency will be discussed in the section on experimental data.", "labels": [], "entities": [{"text": "I14 urgency", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.5549525022506714}]}], "datasetContent": [{"text": "The Dialogos corpus consists of 1,404 dialogues, including 13,123 utterances.", "labels": [], "entities": [{"text": "Dialogos corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.6952621936798096}]}, {"text": "All the calls were performed over the public telephone network and in different environments (house, office, street, and car).", "labels": [], "entities": []}, {"text": "The WA and SU results on the global utterance corpus were: 61% for WA and 76% for SU.", "labels": [], "entities": [{"text": "WA", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.6335508823394775}, {"text": "global utterance corpus", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.7188450892766317}, {"text": "WA", "start_pos": 67, "end_pos": 69, "type": "DATASET", "confidence": 0.7825704216957092}]}, {"text": "These results were greatly influenced by the quality of the telephone acoustic signal, and by the noise environment.", "labels": [], "entities": []}, {"text": "Moreover, several city names contained in the dictionary of the system could be easily confused.", "labels": [], "entities": []}, {"text": "The overall system performance was measured with the Transaction Success (TS) metric, i.e. the measure of the success of the system in providing users with the information they require).", "labels": [], "entities": [{"text": "Transaction Success (TS) metric", "start_pos": 53, "end_pos": 84, "type": "METRIC", "confidence": 0.7145685056845347}]}, {"text": "The TS rate was 70% on the 1,404 dialogues.", "labels": [], "entities": [{"text": "TS rate", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9679982960224152}]}, {"text": "By excluding from the corpus a set of dialogues that failed for users' errors, we obtained a TS result of 84%.", "labels": [], "entities": [{"text": "TS", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.9989714622497559}]}, {"text": "The average successful dialogue duration is about 2 minutes: inmost of the dialogues all the parameters were acquired and confirmed during the first minute of user-system interaction.", "labels": [], "entities": []}, {"text": "It is an open issue if a spoken dialogue system has to generate a clarification subdialogue when faced with ambiguity or unclear input.", "labels": [], "entities": []}, {"text": "For example, the system described in) was designed on the basis of the principle that it was better to assume an interpretation and, of course, to be able to understand corrections when they arise.", "labels": [], "entities": []}, {"text": "On the contrary, Dialogos was designed to enter clarification subdialogues when faced with input that cannot receive a single coherent interpretation in the dialogue context.", "labels": [], "entities": []}, {"text": "Actually, we think that in general the strategy implemented by) maybe more effective for the naturalness of the dialogue, however we believe that the effectiveness of that choice greatly depends on the ability of the users to grasp inconsistencies in the system feed-back.", "labels": [], "entities": []}, {"text": "In the Dialogos corpus we observed that while subjects were usually able to correct errors in confirmation turns that concern a single information, or two semantically related information (such departure and arrival); on the contrary, some errors were not corrected when the feedback was offered together with a system initiative, or when the system asked to confirm information that had not strong relationships.", "labels": [], "entities": [{"text": "Dialogos corpus", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.7024277597665787}]}, {"text": "The dialogue shown in is atypical example.", "labels": [], "entities": []}, {"text": "The acoustic decoding of \"Allora\" (a word that is used in Italian for taking turn) was erroneous: it was substituted with \"All'una\" (at one o'clock).", "labels": [], "entities": []}, {"text": "This was interpreted as a departure hour.", "labels": [], "entities": []}, {"text": "A conjunct confirmation of departure hour and arrival city was asked and the user confirmed both of them.", "labels": [], "entities": []}, {"text": "In next section we will elaborate more on users' error.: Example of erroneous confirmation For the sake of the present discussion, this example shows us that users are not always able to correct errors: on the contrary, we have seen above that the percentage of users' errors is high.", "labels": [], "entities": []}, {"text": "In order to evaluate the effectiveness of the different approaches to face ambiguity we should experiment the different strategies on the same domain, or at least with the same interaction modality (phone or microphone).", "labels": [], "entities": []}, {"text": "However, we have obtained some data that may give some insights on the issue.", "labels": [], "entities": []}, {"text": "In the Dialogos corpus we have calculated the number of turns necessary for acquiring departure and arrival cities in the successful dialogues.", "labels": [], "entities": [{"text": "Dialogos corpus", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.7055251449346542}]}, {"text": "While 64% of the users were able to give them in two turns (that is without experiencing recognition errors), the remaining 36% took from three to eight turns, i.e. these users' spent in correction from three to eight turns.", "labels": [], "entities": []}, {"text": "Since the percentage of users that was notable to detect recognition errors is around 16%, we may hypothesize that apart of the subjects that experienced clarification subdialogues would have failed to give the correct values of the task parameters.", "labels": [], "entities": []}, {"text": "Moreover, if we consider the cost of clarifications and repairs in terms of time, that is not awfully high: giving departure and arrival in less than three turns (that is, without clarifications or repair) takes from 20 to 29 seconds, while the entering of repair subdialogues increased this time of an average of 25 seconds on the total average time of the dialogues.", "labels": [], "entities": []}], "tableCaptions": []}