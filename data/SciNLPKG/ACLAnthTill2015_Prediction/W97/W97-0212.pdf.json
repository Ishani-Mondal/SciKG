{"title": [{"text": "Sense Tagging in Action Combining Different Tests with Additive Weightings", "labels": [], "entities": [{"text": "Sense Tagging in Action Combining", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.773609209060669}]}], "abstractContent": [{"text": "This paper describes a working sense tagger, which attempts to automatically link each word in a text corpus to its corresponding sense in a machine-readable dictionary.", "labels": [], "entities": [{"text": "working sense tagger", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.6250046988328298}]}, {"text": "It uses information automatically extracted from the MRD to find matches between the dictionary and the Corpus sentences, and combines different types of information by simple additive scores with manually set weightings.", "labels": [], "entities": [{"text": "MRD", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.6540266275405884}]}], "introductionContent": [{"text": "This paper describes a working sense tagger, which attempts to automatically link each word in a text corpus to its corresponding sub-sense in the Cambridge International Dictionary of English (CIDE).", "labels": [], "entities": [{"text": "working sense tagger", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.6288037697474161}, {"text": "Cambridge International Dictionary of English (CIDE)", "start_pos": 147, "end_pos": 199, "type": "DATASET", "confidence": 0.8378293700516224}]}, {"text": "Much research elsewhere has gone into the generation of probabilities from corpora and the extraction of textual information from printed dictionaries.", "labels": [], "entities": [{"text": "extraction of textual information from printed dictionaries", "start_pos": 91, "end_pos": 150, "type": "TASK", "confidence": 0.7893239344869342}]}, {"text": "Our research has had the distinct advantage of being done alongside a large lexicographic team, who have been developing further the database used for the creation of CIDE.", "labels": [], "entities": [{"text": "CIDE", "start_pos": 167, "end_pos": 171, "type": "DATASET", "confidence": 0.860337495803833}]}, {"text": "It has thus been possible to have very useful computational data expertly coded by hand.", "labels": [], "entities": []}, {"text": "We have been able to concentrate on defining the specification of this lexical resource, encoding it and then making use of it, rather than on trying to extractor refine the desired information automatically from existing corpora or printed dictionaries.", "labels": [], "entities": []}], "datasetContent": [{"text": "These results clearly need to be improved dramatically before automatic sense tagging can prove practically useful.", "labels": [], "entities": [{"text": "automatic sense tagging", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.586990604797999}]}, {"text": "Nonetheless, these results, especially at subsense level, compare favourably with other research in the area.", "labels": [], "entities": []}, {"text": "have found only 57% agreement when comparing the same texts tagged according to the same dictionary senses by different (human!) research groups.", "labels": [], "entities": [{"text": "agreement", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9893877506256104}]}, {"text": "Cowie, Guthrie and Guthrie (1992) have reported 72% correct assignment at the LDOCE homograph level (and a much lower level for individual sense assignment).", "labels": [], "entities": [{"text": "correct assignment", "start_pos": 52, "end_pos": 70, "type": "METRIC", "confidence": 0.8043177127838135}]}, {"text": "Wilks, comment that 62% accuracy can be achieved at this level just by assigning the first (therefore most frequent) homograph in LDOCE.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9993225336074829}]}, {"text": "Furthermore, propose a method which should apparently achieve 92% accuracy to that same level just by using grammatical tags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9774466156959534}]}, {"text": "It must be noted however that the LDOCE homograph level is far more rough-grained than the CIDE guideword level, let alone the sub-sense level, and that Wilks and Stevenson's approach on its own would, by its very nature, not transfer down to more fine-grained distinctions.", "labels": [], "entities": []}, {"text": "Other research, such as Yarowsky's into accent restoration in, which reports accuracy levels of 90%-99%, is again at a more rough-grained level, in this case that of distinguished unaccented and accented word forms.", "labels": [], "entities": [{"text": "accent restoration", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7291914075613022}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9986993074417114}]}, {"text": "While the sense tagging results are fairly encouraging, the part of speech tagging results arc at present relatively poor.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7959985435009003}, {"text": "speech tagging", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7541615962982178}]}, {"text": "It thus secrns sensible, especially noting Wilks and Stevenson's analysis mentioned above, to first run a sentence through a traditional part of speech tagger before trying to disambiguate the senses.", "labels": [], "entities": []}, {"text": "In thcory, we would expect information such as subject domain and collocations to help part of speech tagging to be more accurate, however slightly, but we have not yet bccn able to demonstrate this in practice.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.7048012465238571}]}], "tableCaptions": []}