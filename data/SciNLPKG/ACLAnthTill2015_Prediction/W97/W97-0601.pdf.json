{"title": [{"text": "Evaluating Interactive Dialogue Systems: Extending Component Evaluation to Integrated System Evaluation", "labels": [], "entities": [{"text": "Extending Component Evaluation", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.8940088947614034}, {"text": "Integrated System Evaluation", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.6627252598603567}]}], "abstractContent": [{"text": "This paper discusses the range of ways in which spoken dialogue system components have been evaluated and discusses approaches to evaluation that attempt to integrate component evaluation into an overall view of system performance.", "labels": [], "entities": []}, {"text": "We will argue that the PARADISE (PARAdigm for Dialogue System Evaluation) framework has several advantages over other proposals.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9209828972816467}]}], "introductionContent": [], "datasetContent": [{"text": "At the top level, this model posits that performance can be correlated with a meaningful external criterion such as usability, and thus that the overall goal of a spoken dialogue agent is to maximize an objective related to usability.", "labels": [], "entities": []}, {"text": "User satisfaction ratings) are the most widely used external indicator of the usability of a dialogue agent.", "labels": [], "entities": []}, {"text": "The model further posits that two types of factors are potential relevant contributors to user satisfaction, namely task success and dialogue costs.", "labels": [], "entities": []}, {"text": "PARADISE uses linear regression to quantify the relative contribution of the success and cost factors to user satisfaction.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6355069875717163}]}, {"text": "The task success measure builds on previous measures of transaction success and task completion), but makes use of the Kappa coefficient to operationalize task success.", "labels": [], "entities": []}, {"text": "The cost factors consist of two types.", "labels": [], "entities": []}, {"text": "The efficiency measures arise from the list of objective performance measures used in previous work as described above.", "labels": [], "entities": []}, {"text": "Qualitative measures try to capture aspects of the quality of the dialog.", "labels": [], "entities": []}, {"text": "These are based on both objective and subjective measures used in previous work, such as the frequency of diagnostic or error messages, inappropriate utterance ratios, or the proportion of repair utterances.", "labels": [], "entities": []}, {"text": "The remainder of this section explains the measures (ovals in) used to operationalize the set of objectives, and the methodology for estimating a quantitative performance function that reflects the objective structure.", "labels": [], "entities": []}, {"text": "Section 2.1 describes PARADISE's task representation, which is needed to calculate the task-based success measure described in Section 2.2.", "labels": [], "entities": []}, {"text": "Section 2.3 describes the cost measures considered in PARADISE, which reflect both the efficiency and the naturalness of an agent's dialogue behaviors.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.5683476328849792}]}, {"text": "Section 2.4 describes the use of linear regression and user satisfaction to estimate the relative contribution of the success and cost measures in a single performance function.", "labels": [], "entities": []}, {"text": "Finally, Section 2.5 summarizes the method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Confusion matrix, Agent A", "labels": [], "entities": []}, {"text": " Table 4: Hypothetical performance data from users of  Agents A and B", "labels": [], "entities": []}]}