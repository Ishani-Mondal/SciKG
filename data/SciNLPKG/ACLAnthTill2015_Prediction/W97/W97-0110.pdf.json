{"title": [{"text": "Corpus Based Statistical Generalization Tree in Rule Optimization *", "labels": [], "entities": [{"text": "Statistical Generalization", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.689130961894989}, {"text": "Rule Optimization", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.8376877009868622}]}], "abstractContent": [{"text": "A corpus-based statistical Generalization Tree model is described to achieve rule opthnization for the information extraction task.", "labels": [], "entities": [{"text": "information extraction task", "start_pos": 103, "end_pos": 130, "type": "TASK", "confidence": 0.8486601909001669}]}, {"text": "First, the user creates specific rules for the target information from the sample articles through a training interface.", "labels": [], "entities": []}, {"text": "Second, WordNet is applied to generalize noun entities in the specific rules.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 8, "end_pos": 15, "type": "DATASET", "confidence": 0.9158301949501038}]}, {"text": "The degree of generalization is adjusted to fit the user's needs by use of the statistical Generalization Tree model FinaUy, the optimally generalized rules are applied to scan new information.", "labels": [], "entities": [{"text": "FinaUy", "start_pos": 117, "end_pos": 123, "type": "DATASET", "confidence": 0.7872753143310547}]}, {"text": "The results of experiments demonstrate the applicability of our Generalization Tree method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Research on corpus-based natural language learning and processing is rapidly accelerating following the introduction of large on-line corpora, faster computers, and cheap storage devices.", "labels": [], "entities": [{"text": "corpus-based natural language learning and processing", "start_pos": 12, "end_pos": 65, "type": "TASK", "confidence": 0.6875462134679159}]}, {"text": "Recent work involves novel ways to employ annotated corpus in part of speech tagging) and the application of mutual information statistics on the corpora to uncover lexical information.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.7132977545261383}]}, {"text": "The goal of the research is the construction of robust and portable natural language processing systems.", "labels": [], "entities": []}, {"text": "The wide range of topics available on the Internet calls for an easily adaptable information extraction system for different domains.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7429284453392029}]}, {"text": "Adapting an extraction systeem to anew domain is a tedious process.", "labels": [], "entities": [{"text": "Adapting an extraction systeem", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8212204277515411}]}, {"text": "In the traditional customization process, the given corpus must be studied carefully in order to get all the possible ways to express target information.", "labels": [], "entities": []}, {"text": "Many research groups are implementing the efficient customization of information extraction systems, such as BBN, NYU (Grishman 1995), SRI (Appelt, Hobbs, et al 1995), SRA (Krupka 1995), MITRE, and UMass (Fisher, Soderland, et al 1995).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.7696186900138855}, {"text": "BBN", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.9464651942253113}, {"text": "NYU", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.9187145233154297}, {"text": "MITRE", "start_pos": 187, "end_pos": 192, "type": "DATASET", "confidence": 0.8854694366455078}]}, {"text": "\"This work has been supported by a Fellowship from IBM Corporation.", "labels": [], "entities": []}, {"text": "We employ a rule optimization approach and implement it in our tradable information extraction system.", "labels": [], "entities": [{"text": "rule optimization", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7760098278522491}, {"text": "information extraction", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7108235508203506}]}, {"text": "The system allows the user to train on a small amount of data in the domain and creates the specific rules.", "labels": [], "entities": []}, {"text": "Then it automatically extracts a generalization from the tr~iui~g corpus and makes the rule general for the new information, depending on the user's needs.", "labels": [], "entities": []}, {"text": "In this way, rule generali~.ation makes the customization fora new domain easier.", "labels": [], "entities": []}, {"text": "This paper specifically describes the automated rule optimiT.ation method and the usage of WordNet . A Generalization Tree (GT) model based on the tr~inlng corpus and WordNet is presented, as well as how the GT model is used by our system to automatically learn and control the degree of generalization according to the user's needs.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9564577341079712}]}], "datasetContent": [{"text": "In this section we present and discuss results from an experiment.", "labels": [], "entities": []}, {"text": "The experimental domain is triangle.jobs USENET newsgroup.", "labels": [], "entities": [{"text": "USENET newsgroup", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.8105826377868652}]}, {"text": "We trained our system on 24 articles for the extraction of six facts of interests as follows: Company Name.", "labels": [], "entities": []}, {"text": "Examples: IBM, Metro Information Services, DCR Inc.", "labels": [], "entities": []}, {"text": "Examples: programmer, financial analyst, software engineer.", "labels": [], "entities": []}, {"text": "Example: 5 years experience in Oracle.", "labels": [], "entities": []}, {"text": "Examples: Winston-Salem, North Carolina.", "labels": [], "entities": []}, {"text": "Examples: company matching funds~ comprehensive health plan.", "labels": [], "entities": []}, {"text": "Examples: Fax is 919-660-6519, e-mail address.", "labels": [], "entities": []}, {"text": "The testing set contained 162 articles from the same domain as the system was trained on.", "labels": [], "entities": []}, {"text": "Out of 162 articles, 21 articles were unrelated to the domain due to the misplacement made by the person who posted them.", "labels": [], "entities": []}, {"text": "Those unrelated articles were about jobs, which is the number of articles containing each fact out of the total number of articles.", "labels": [], "entities": []}, {"text": "The distribution of number of facts presented in each article is shown in.", "labels": [], "entities": []}, {"text": "The mean number of facts in each article from the tra;nlng set is 4.39, the standard deviation is 1.2; the mean number of facts in each article from the testing set is 4.35, the standard deviation is 1.", "labels": [], "entities": [{"text": "standard", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9787963628768921}, {"text": "standard", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.977015495300293}]}, {"text": "Although these statistics are not strong enough to indicate the training set is absolutely the good trMn;ng corpora for this information extraction task, it suggests that as far as the facts of interest are concerned, the training set is a reasonable set to be trained and learned.", "labels": [], "entities": [{"text": "information extraction task", "start_pos": 125, "end_pos": 152, "type": "TASK", "confidence": 0.8514348069826762}]}, {"text": "The evaluation process consisted of the following steps: fn'st, each unseen article was studied to see if there was any fact of interest presented; second, the semantic transitions produced by the system were examined to see if they correctly extracted the fact of interest.", "labels": [], "entities": []}, {"text": "Precision is the number of transitions correctly extracting facts of interest out of the total number of transitions produced by the system; recall is the number of facts which have been correctly extracted out of the total number of facts of interest.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9907311797142029}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9994648098945618}]}, {"text": "The overall performance of recall and precision is defined by the Fomeasurement (Chinchor 1992), which is (~2 + 1.0) \u2022 P * R ~.P+R where P is precision, R is recall, 13 = 1 ff precision and recall are equally important.", "labels": [], "entities": [{"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9982176423072815}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9989604949951172}, {"text": "Fomeasurement", "start_pos": 66, "end_pos": 79, "type": "METRIC", "confidence": 0.9881513118743896}, {"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9963365793228149}, {"text": "recall", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.9942264556884766}, {"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9975520968437195}, {"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.999293327331543}]}, {"text": "First, we tested on single fact extraction, which was position~title fact.", "labels": [], "entities": [{"text": "single fact extraction", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.5900162855784098}]}, {"text": "The purpose of this experiment is to test whether the different 8 values will lead to the expected recall, and precision statistics.", "labels": [], "entities": [{"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9925077557563782}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9996102452278137}]}, {"text": "From the result out of 141 related testing articles, the recall, precision, F-measurement curves are shown in.", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9996052384376526}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9986339211463928}, {"text": "F-measurement", "start_pos": 76, "end_pos": 89, "type": "METRIC", "confidence": 0.9981642365455627}]}, {"text": "Recall is 51.6% when 8 = 1.0, which is lower than 75% at # = 0, however, precision is the highest at 84.7% when 0 = 1.0.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9956594109535217}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9997172951698303}]}, {"text": "The F-measurement achieves its highest value at 64.1% when 0 = 1.0.", "labels": [], "entities": [{"text": "F-measurement", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.998112678527832}]}, {"text": "The interesting question rising here is can we use GT rule optimization method to achieve the information retrieval, in this particular case, to identify those unrelated articles.", "labels": [], "entities": [{"text": "GT rule optimization", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.5999948879082998}]}, {"text": "Certaln]y, we would hope that optlrn;zed rules won't produce any trauqitions from the unrelated articles.", "labels": [], "entities": []}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "The precision of unrelated articles is the number of articles without any transitions created out of total 21 articles.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9985646605491638}]}, {"text": "We can see that, when 0 = 0.8, 1.0, precision is 95.7%.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9997782111167908}]}, {"text": "Only one article out of 21 articles is mis-identified.", "labels": [], "entities": []}, {"text": "But when 0 = 0, 0.2, the precision rate is very low, only 28.6% and 38.1%.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 25, "end_pos": 39, "type": "METRIC", "confidence": 0.9792779386043549}]}, {"text": "If we use the traditional way of keyword matching to do this information retrieval, the precision won't achieve as high as 95.7% since a few resume and job wanted postings will succeed the keyword matching and be mls-identitled as related articles.", "labels": [], "entities": [{"text": "keyword matching", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7208320647478104}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9991937279701233}, {"text": "keyword matching", "start_pos": 189, "end_pos": 205, "type": "TASK", "confidence": 0.716327354311943}]}], "tableCaptions": [{"text": " Table 1: Sample Database for Objects Activating {entity}", "labels": [], "entities": [{"text": "Objects Activating", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7508478462696075}]}, {"text": " Table 3: Percentage of Facts in Training and Testing", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9747985005378723}]}]}