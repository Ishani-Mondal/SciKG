{"title": [{"text": "A Natural Language Correction Model for Continuous Speech Recognition 1", "labels": [], "entities": [{"text": "Continuous Speech Recognition", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.6676225463549296}]}], "abstractContent": [{"text": "We have developed a method of improving and controlling the accuracy of automated continuous speech recognition through linguistic postprocessing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9983752965927124}, {"text": "continuous speech recognition", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.6002157032489777}]}, {"text": "In this approach, an output from a speech recognitio n system is passed to a trainable Correction Box module which attempts to locate and repair any transcription errors.", "labels": [], "entities": []}, {"text": "The Correction Box consists of a text alignment program, a correction rule generator, and a series of rule application and verification steps.", "labels": [], "entities": [{"text": "text alignment", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7565643489360809}]}, {"text": "In the training phase, the correction rules are learned by aligning the recognized speech samples with their original, fully correct versions, on sentence by sentence basis.", "labels": [], "entities": []}, {"text": "Misaligned sections give rise to candidate context free correlation rules, e.g., from ~ frontal ; there were made ~ the remainder, etc.", "labels": [], "entities": []}, {"text": "Validation against a text corpus leads to context-sensitive correction rules, such as from view ~ frontal view.", "labels": [], "entities": []}, {"text": "The system is applied to medical dictation in the area of clinical radiology.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we describe a method of improving the accuracy of automated speech recognition through text-based linguistic post-processing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9982253909111023}, {"text": "speech recognition", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.6725731939077377}]}, {"text": "The basic assumption of our approach is that a majority of transcription errors can be attributed to either some inherent limitations of the language model employed by a speech recognition system, or else to the specific speech patterns of a speaker or a group of speakers.", "labels": [], "entities": []}, {"text": "Many advanced speech recognition systems use trainable language models that can be optimized fora particular speaker (speaker-adaptable, or speaker-independent) as well as fora specific sublanguge usage (e.g., radiology).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7424445152282715}]}, {"text": "This optimization is necessary to achieve a respectable level of recognition accuracy, however, it may not guarantee consistently high-accuracy performance due to the limited capabilities of the underlying language model, usually a 2-or 3-gram HMMs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9409704804420471}]}, {"text": "Our method is to take a reasonably accurate transcription (perhaps 70-90% word accuracy) and automatically develop a correction filter that would assure I.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.8441708087921143}]}, {"text": "This research is based upon work supported in part under a cooperative agreement between the National Institute of Standards and Technology Advanced Technology Program (under the HITECC contract, number 70NANB5Hl195) and the Healthcare Open Systems and Trials, Inc. consortium.", "labels": [], "entities": [{"text": "HITECC contract, number 70NANB5Hl195", "start_pos": 179, "end_pos": 215, "type": "DATASET", "confidence": 0.7745427370071412}]}, {"text": "consistently the highest possible performance.", "labels": [], "entities": []}, {"text": "Unlike other approaches (e.g.,) that attempt to choose from among alternative transcriptions based on syntactic and/or lexieal well-formedness, our method is to actually identify and correct transcription errors in the SRS output.", "labels": [], "entities": []}, {"text": "We would like to stress that while the experiments described in this paper are relatively modest and preliminary, the system we designed is robust and fully automatic: there is no human intervention involved.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental data was obtained from the University of Maryland Medical Center in Baltimore, which is one of the clinical sites used in this project.", "labels": [], "entities": []}, {"text": "The validated transcriptions have been extracted from the hospital database by the hospital personnel, and then sanitized to remove any patient information such as names, addresses, etc.", "labels": [], "entities": []}, {"text": "At the time this report is written, we collected nearly 7000 transcribed dictations, all in the area of chest X-ray.", "labels": [], "entities": []}, {"text": "Chest X-ray is the most prevalent form of radiology, and we decided to start with this sub-area because of its the largest potential practical significance.", "labels": [], "entities": [{"text": "Chest X-ray", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7790394425392151}]}, {"text": "The sanitized reports were subsequently re-dictated through the automated speech recognition system in order to obtain parallel samples of automated transcription.", "labels": [], "entities": []}, {"text": "The redictation was done over a period of several months by a final-year radiology resident at Albany Medical Center, a native North American English speaker.", "labels": [], "entities": [{"text": "redictation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9640840291976929}]}, {"text": "At the time this paper is prepared, some 1000 reports have been redictated.", "labels": [], "entities": []}, {"text": "Clinical tests of the system equipped with the C-Box that are starting in early 1997 will provide additional speakers.", "labels": [], "entities": []}, {"text": "Generally, we observed significant word error rates in automated speech recognition, in some cases as high as 38%, with the average of 14.3%.", "labels": [], "entities": [{"text": "automated speech recognition", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6219609677791595}]}, {"text": "This is substantially higher than the advertised 5% error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9499771595001221}]}, {"text": "Before starting re-dictation, the speaker underwent a few hours training session, learning how to use the system, and having his voice patterns incorporated into the language model (the system we use is speaker adaptable).", "labels": [], "entities": []}, {"text": "The above numbers therefore represent an optimal performance of the system for this speaker, although there are some hard-to-measure mitigating considerations.", "labels": [], "entities": []}, {"text": "For example, the radiology reports used in these experiments were read by an AMC resident, who while obviously familiar with the subject matter, also pointed out some fine vocabulary and style differences between AMC and UMMC Baltimore, where the reports were produced.", "labels": [], "entities": [{"text": "AMC resident", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.9070825576782227}]}, {"text": "This could potentially have an impact at SRS performance.", "labels": [], "entities": [{"text": "SRS", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9890138506889343}]}, {"text": "It should be noted that atypical chest X-ray dictation report is quite short, from a few lines to a few paragraphs, and is dictated quite rapidly in anywhere from 15 seconds to a few minutes.", "labels": [], "entities": [{"text": "chest X-ray dictation", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.5811864733695984}]}, {"text": "Preliminary experiments with context-free rules have already shown interesting results: we noticed that the average word error rate decreased from 14.3% to 11.3% (a 21% reduction) on a test sample after running it through a C-Box equipped with only a few CF rules.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 116, "end_pos": 131, "type": "METRIC", "confidence": 0.6934569478034973}]}, {"text": "This C-Box was trained on 800 reports (0.3 MByte) and tested on 200 reports (92 KBytes).", "labels": [], "entities": []}, {"text": "Below is a sample radiology report, its automated transcription version, and the effect of a partial correction.", "labels": [], "entities": []}, {"text": "Note that only context-free rules are used; a context-sensitive correction indication colon ~ indication : would fix the problem in the first line.", "labels": [], "entities": []}, {"text": "Correction rules used: and trachea to ~ endotracheal tube, size factor ~ satisfactory, is and ~ has been.", "labels": [], "entities": []}], "tableCaptions": []}