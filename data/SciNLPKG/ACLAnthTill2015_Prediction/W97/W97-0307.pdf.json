{"title": [], "abstractContent": [{"text": "This paper addresses issues in automated treebank construction.", "labels": [], "entities": [{"text": "automated treebank construction", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.5799138446648916}]}, {"text": "We show how standard part-of-speech tagging techniques extend to the more general problem of structural annotation, especially for determining grammatical functions and syntactic categories.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7153241485357285}]}, {"text": "Annotation is viewed as an interactive process where manual and automatic processing alternate.", "labels": [], "entities": []}, {"text": "Efficiency and accuracy results are presented.", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9904952049255371}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9992953538894653}]}, {"text": "We also discuss further automation steps.", "labels": [], "entities": []}], "introductionContent": [{"text": "The aim of the work reported here is to construct a corpus of German annotated with syntactic structures (treebank).", "labels": [], "entities": []}, {"text": "The required size of the treebank and granularity of encoded information make it necessary.", "labels": [], "entities": []}, {"text": "to ensure high annotation efficiency and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9982800483703613}]}, {"text": "Annotation automation has thus become one of the central issues of the project.", "labels": [], "entities": [{"text": "Annotation automation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8968984484672546}]}, {"text": "In this section, we discuss the relation between automatic and manual annotation.", "labels": [], "entities": []}, {"text": "Section 2 focuses on the annotation format employed in our treebank.", "labels": [], "entities": []}, {"text": "The annotation software is presented in section 3.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 deal with automatic assignment of grammatical functions and phrasal categories.", "labels": [], "entities": [{"text": "automatic assignment of grammatical functions", "start_pos": 27, "end_pos": 72, "type": "TASK", "confidence": 0.7411168038845062}]}, {"text": "Experiments on automating the annotation are presented in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "To investigate the possibility of automating annotation, experiments were performed with the cleaned part of the treebank 6 (approx. 1,200 sentences, 24,000 words).", "labels": [], "entities": []}, {"text": "The first run of experiments was carried out to test tagging of grammatical functions, the second run to test tagging of phrase categories.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Levels of reliability and the percentage ca- ses where the tagger assigned a correct grammati- cal function (or would have assigned if a decision is  forced).", "labels": [], "entities": [{"text": "reliability", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9928869605064392}]}, {"text": " Table 2: Tagging accuracy for assigning grammatical  functions depending on the category of the mother  node. For each category, the first row shows the per- centage of branches that occur within this category  and the overall accuracy, the following rows show the  relative percentage and accuracy for different levels  of reliability.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9675440788269043}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9814307689666748}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9992276430130005}, {"text": "accuracy", "start_pos": 291, "end_pos": 299, "type": "METRIC", "confidence": 0.9993379712104797}]}, {"text": " Table 3: The 10 most frequent errors in assigning  grammatical functions. The table shows a mother  and a daughter node category, the frequency of this  particular combination (sum over 10 test runs), the  grammatical function assigned manually (and its fre- quency) and the grammatical function assigned by  the tagger (and its frequency).", "labels": [], "entities": [{"text": "fre- quency", "start_pos": 255, "end_pos": 266, "type": "METRIC", "confidence": 0.9202747146288554}]}, {"text": " Table 4: Levels of reliability and the percentage of  cases in which the tagger assigned a correct phrase  category (or would have assigned if a decision is  forced).", "labels": [], "entities": [{"text": "reliability", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9366574883460999}]}, {"text": " Table 5: Tagging accuracy for assigning phrase cate- gories, depending on the manually assigned category.  For each category, the first row shows the percentage  of phrases belongi:lg to a specific category (accor- ding to manual ~,zsignment) and the percentage of  correct assignments. The following rows show the  relative percentage and accuracy for different levels  of reliability.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9853378534317017}, {"text": "accuracy", "start_pos": 341, "end_pos": 349, "type": "METRIC", "confidence": 0.9993021488189697}]}, {"text": " Table 6: The 10 most frequent errors in assigning  phrase categories (summed over reliability levels).  The table shows the phrase category assigned manu- ally (and its frequency) and the category erroneously  assigned by the tagger (and its frequency).", "labels": [], "entities": []}]}