{"title": [{"text": "Clustering Co-occurrence Graph based on Transitivity", "labels": [], "entities": []}], "abstractContent": [{"text": "Word co-occurrences form a graph, regarding words as nodes and co-occurrence relations as branches.", "labels": [], "entities": []}, {"text": "Thus, a co-occurrence graph can be constructed by co-occurrence relations in a corpus.", "labels": [], "entities": []}, {"text": "This paper discusses a clustering method of the co-occurrence graph, the decomposition of the graph, from a graph-theoretical viewpoint.", "labels": [], "entities": []}, {"text": "Since one of the applications for the clustering results is the ambiguity resolution, each output cluster is expected to have no ambiguity and be specialized in a single topic.", "labels": [], "entities": []}, {"text": "We observed that a graph has no ambiguity if its branches representing co-occurrence relations are transitive.", "labels": [], "entities": []}, {"text": "An algorithm to extract such graphs are proposed and its uniqueness of the output is discussed.", "labels": [], "entities": []}, {"text": "The effectiveness of our method is examined by an experiment using co-occurrence graph obtained from a 30M bytes corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "Clustering is the operation to group words by some criterion.", "labels": [], "entities": []}, {"text": "Thesauri and synonym dictionaries are some of its manual examples.", "labels": [], "entities": []}, {"text": "Automatic outputs can be used not only to revise them, but also to aid ambiguity resolution, an essential problem in natural language processing.", "labels": [], "entities": [{"text": "ambiguity resolution", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.7539708018302917}]}, {"text": "For instance, the me~ing of an ambiguous word can be decided by e.xamln'i~g the duster it belongs to.", "labels": [], "entities": []}, {"text": "Furthermore, clusters grouped according to topics have many application areas such as automatic document classification.", "labels": [], "entities": [{"text": "automatic document classification", "start_pos": 86, "end_pos": 119, "type": "TASK", "confidence": 0.600067526102066}]}, {"text": "The input in this paper is the word co-occurrence graph obta~ued from corpus.", "labels": [], "entities": []}, {"text": "The output is its subgraphs with the condition that each subgraph is specialized in a topic.", "labels": [], "entities": []}, {"text": "Many automatic clustering methods have been already proposed.", "labels": [], "entities": []}, {"text": "Most of them are based on the statistical similarity between two words.", "labels": [], "entities": []}, {"text": "Our approach is different; it is graph theoretical.", "labels": [], "entities": []}, {"text": "We tried to find out the special structure in linguistic graph.", "labels": [], "entities": []}, {"text": "Having a huge co-occurrence graph obtained from a corpus, we first tried to decompose it to analyze its graph structure using graph theoretical tools, such as maximum strongly connected components, or biconnected components.", "labels": [], "entities": []}, {"text": "Although both tools decompose a graph into tightly connected subgraphs, these trials resulted in vain.", "labels": [], "entities": []}, {"text": "The question arose; what must betaken into account to decompose the cooccurrence graph.", "labels": [], "entities": []}, {"text": "7 The answer is the ambiguity.", "labels": [], "entities": []}, {"text": "Furthermore, we reached to the conclusion that the ambiguity can be explained in terms of intransitivity.", "labels": [], "entities": []}, {"text": "This feature is developed into an algorithm for clustering.", "labels": [], "entities": [{"text": "clustering", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.9580976963043213}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The following chapter describes the relationship between the transitivity in the graph and the ambiguity resolution.", "labels": [], "entities": []}, {"text": "Chapter 3 shows the relationships between clustering and transitivity.", "labels": [], "entities": []}, {"text": "Chapter 4 proposes and discusses an algorithm for clustering.", "labels": [], "entities": []}, {"text": "Related work is resumed in Chapter 5.", "labels": [], "entities": []}, {"text": "Our method is examined in Chapter 6 by some experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "In Appendix, 39 clusters are shown their contents sorted by size.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 3, "end_pos": 11, "type": "METRIC", "confidence": 0.5719461441040039}]}, {"text": "Words judged inappropriate in each cluster are attached ~t'-Words tmdecidable being suitable in their clusters are put \"~\".", "labels": [], "entities": []}, {"text": "All 39 clusters are attached four items as follows: \u2022 Subjectively judged topic \u2022 Cluster size (CS): number of words in a cluster \u2022 Error rate (ER): rate of inappropriate words (attached \"t') \u2022 Uncertainty rate (UR): rate of uncertain words (attached \"~\" and \"~\") The average of the above items were CS=20, ER=10.3%, UP,.= 14.7%; hence, the ambiguity was removed from clusters up to 85% on average.", "labels": [], "entities": [{"text": "Cluster size (CS)", "start_pos": 82, "end_pos": 99, "type": "METRIC", "confidence": 0.7722647666931153}, {"text": "Error rate (ER)", "start_pos": 132, "end_pos": 147, "type": "METRIC", "confidence": 0.9736047983169556}, {"text": "Uncertainty rate (UR)", "start_pos": 194, "end_pos": 215, "type": "METRIC", "confidence": 0.8976085424423218}, {"text": "ER", "start_pos": 307, "end_pos": 309, "type": "METRIC", "confidence": 0.9947705864906311}, {"text": "UP", "start_pos": 317, "end_pos": 319, "type": "METRIC", "confidence": 0.9974284768104553}]}, {"text": "The number of the cluster whose topic was inestimable is only 1.", "labels": [], "entities": []}, {"text": "The estimation of topic becomes clltTicult with two factors, CS and UR.", "labels": [], "entities": [{"text": "estimation", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.8880617022514343}, {"text": "UR", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.9805348515510559}]}, {"text": "When CS is too small, even when UR is 0.0, the cluster itself lacks in information.", "labels": [], "entities": [{"text": "UR", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.8947551846504211}]}, {"text": "When UR is high, it is natural that the topic becomes inestimable.", "labels": [], "entities": [{"text": "UR", "start_pos": 5, "end_pos": 7, "type": "METRIC", "confidence": 0.9945322275161743}]}, {"text": "The number of words belonging to more than two clusters amounts to 57.", "labels": [], "entities": []}], "tableCaptions": []}