{"title": [], "abstractContent": [{"text": "In foundational works of generative phonology it is claimed that subjects can reliably discriminate between possible but non-occurring words and words that could not be English.", "labels": [], "entities": [{"text": "generative phonology", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.9457050263881683}]}, {"text": "In this paper we examine the use of a pr0babilistic phonological parser for words to model experimentally-obtained judgements of the acceptability of a set of nonsense words.", "labels": [], "entities": []}, {"text": "We compared various methods oft scoring the goodness of the parse as a predictor of acceptability.", "labels": [], "entities": []}, {"text": "We found that the probability of the worst part is not the best score of acceptability, indicating that classical generative phonology and Optimality Theory miss an important fact, as these app[oaches do not recognise a mechanism by which the frequency of well-formed parts may ameliorate the unacceptability of low-frequency parts.", "labels": [], "entities": []}, {"text": "We argue that probabilistic generative grammars are demonstrably a more psychologically realistic model of phonological competence than standard generative phonology or Optimality Theory.", "labels": [], "entities": [{"text": "generative grammars", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8880451321601868}]}], "introductionContent": [{"text": "In standard models of phonology, the phonological representation of a word is understood to be a hierarchical structure in which the phonological material (features and/or phonemes) is organized into syllables, which are in turn organized into feet, prosodic Words and intonation phrases.", "labels": [], "entities": []}, {"text": "The existence of ~uch structure is supported by a confluence of evidence from phonotactic constraints, patterns of allophony, and results of psycholinguisti~ experiments.", "labels": [], "entities": []}, {"text": "In this paper, we i . .", "labels": [], "entities": []}, {"text": "present a probabdlstlc phonological parser for words, based on a context free grammar.", "labels": [], "entities": []}, {"text": "Unlike classical probabilistic context-free grammars, it attaches probabilities to entire root-to-frontier :paths instead of to individual rules.", "labels": [], "entities": []}, {"text": "This approach makes it possible to exploit regularities in the horizontal, or time-wise, location of frequency effects.", "labels": [], "entities": []}, {"text": "The grammar is applied to model phonological productivity as revealed in acceptability ratings of nonsense words.", "labels": [], "entities": []}, {"text": "Specifically, we examine the issue of whether acceptability is related to expected frequency as computed over the whole word (with deviations in different locations having a cumulative effect), or whether the judgments of acceptability are dominated by the local extreme values.", "labels": [], "entities": []}, {"text": "We find that an experimentally obtained measure of subjective phonotactic \"badness\" correlates with three probabilistic measures: word probability, log word probability, and frequency of the lowest frequency (i.e. \"worst\") constituent.", "labels": [], "entities": []}, {"text": "The hierarchical structures of phonology obviously lend themselves to being formalized using standard types of grammars.", "labels": [], "entities": []}, {"text": "Formalization makes it possible to rigorously relate generation and parsing.", "labels": [], "entities": []}, {"text": "It allows us to test particular linguistic theories of prosody by evaluating their predictions overlarge data sets.", "labels": [], "entities": []}, {"text": "Previous work which has established these points includes,.", "labels": [], "entities": []}, {"text": "Prosodic structure in some respects presents a simpler problem than syntactic strficture, because the inventory of different node types is small and the grammar lacks recursion.", "labels": [], "entities": [{"text": "Prosodic structure", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.839004248380661}]}, {"text": "In terms of weak generative capacity, the grammar can obviously be treated as finite state.", "labels": [], "entities": []}, {"text": "The linguistically transparent prosodic grammar presented in this paper was developed for the purpose of modeling phonological productivity.", "labels": [], "entities": []}, {"text": "The grammar is trained on an existing dictionary, and it is applied to model judgments of well-formedness obtained fora study of the psychological reality of phonotactic constraints.", "labels": [], "entities": []}, {"text": "For the study, nonsense words were constructed which either respected or violated known phonotactic constraints, and subjects indicated by pressing one of two buttons whether or not the nonsense word could be a possible English word.", "labels": [], "entities": []}, {"text": "The total number of \"votes\" against each word, from 6 subjects on 2 runs yields a scale of 0 (good) to 12 (bad).", "labels": [], "entities": []}, {"text": "For example, the nonsense word /smlofit/ contains an extremely anomalous onset cluster, and it received 10 votes against.", "labels": [], "entities": []}, {"text": "In contrast, the nonsense word/'taehn/did not violate any known phonotactic constraints, and it received only 2 votes against.", "labels": [], "entities": []}, {"text": "We undertake to model productivity because it is a standard diagnostic for the psychological reality of abstractions.", "labels": [], "entities": []}, {"text": "Modeling in detail the perceived well-formedness of neologisms provides us with an opportunity to assess how prosodic structure figures in the cognitive system.", "labels": [], "entities": []}, {"text": "Although earlier work has established a connection between lexical statistics and acceptability, no general architecture for manipulating lexical statistics in a structure-sensitive fashion has yet been developed.", "labels": [], "entities": []}, {"text": "The connection between lexical statistics and acceptability is demonstrated by a rather substantial literature on lexical neighborhoods, where the \"lexical neighborhood\" of an existing or nonsense forms is defined by the set of words which differ in a single phoneme (according to the definition of).", "labels": [], "entities": []}, {"text": "Studies by Luce and colleagues demonstrate that the lexical neighborhood density of a word has a strong effect on word perception, which maybe attributed to the number of active competitors fora word at each point in the speech signal.", "labels": [], "entities": [{"text": "word perception", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.7618334293365479}]}, {"text": "Studies relating lexical neighborhoods to acceptability include, who asked subjects to rate forms which violated an equal number of morpheme structure conditions, but which differed in their distance from actual words.", "labels": [], "entities": []}, {"text": "The difference in ratings showed that the acceptability of a word was correlated with its distance from actual words, as proposed by, not with the number of MSC violations.", "labels": [], "entities": []}, {"text": "A smaller literature considers structural factors through intensive study of particular configurations.", "labels": [], "entities": []}, {"text": "Ina study of medial triconsonantal clusters, such as /lfr/ in \"palfrey\", Pierrehumbert showed that the independent probabilities of the coda and the following onset was the single biggest factor in predicting which complex clusters exist.", "labels": [], "entities": []}, {"text": "Almost all of the 40 existing different triconsonantal clusters are among the 200 most probable if the complete cross-product of (frequency-tagged) onsets and codas is computed.", "labels": [], "entities": []}, {"text": "Since the complete cross-product yields more than 8000 different candidate medial clusters, this is a very powerful factor.", "labels": [], "entities": []}, {"text": "Results of an experiment described in that paper showed that subjects have an implicit awareness of the statistical underrepresentation of consonant sequences and reveal this awareness in judgments of wellformedness.", "labels": [], "entities": []}, {"text": "These two groups of papers leave many unanswered questions.", "labels": [], "entities": []}, {"text": "provides no suggestions about how effects over the whole word maybe combined.", "labels": [], "entities": []}, {"text": "If Pierrehumbert's claim is extrapolated without elaboration, it entails that longer words should almost always be worse than shorter ones.", "labels": [], "entities": []}, {"text": "Longer words, having more parts, would have more factors in their computed likelihoods, with each factor less than one (since the probability of any given choice is always less than one).", "labels": [], "entities": []}, {"text": "Hence the longer the word, the more probable that its likelihood would beat a very 10w value.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.967307984828949}]}, {"text": "This difficulty is a classic problem for stochastic parsing, and it leads to suggestions about normalizing the scores.", "labels": [], "entities": [{"text": "stochastic parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.635728508234024}]}, {"text": "But a scoring system which completely normalized for length (e.g. by considering mean log probabilities) would provide noway of capturing the effect that Pierrehumbert reports, since the mean log probabilities of the nonexistent complex clusters would be no worse than the log probabilities of their component parts.", "labels": [], "entities": []}, {"text": "The lexical neighborhood literature also avoids the question of integration over the word, by virtue of threshholding on a single distance (obviously, a crude expedient adopted during a first pass at the problem).", "labels": [], "entities": []}, {"text": "The question of how structure figures in the perceived relatedness of words has also not been taken up in the lexical neighborhood literature.", "labels": [], "entities": []}, {"text": "The phoneme-wise calculation maybe reasonably well-behaved if computed over monosyllables, but it is too crude a measure if the situation is considered in its full generality.", "labels": [], "entities": []}, {"text": "For example, a single phoneme substitution which had a drastic effect on the syllable structure must surely yield a less cognitively related form than one which does not.", "labels": [], "entities": []}, {"text": "In order to advance our understanding of these issues, we have developed a probabilistic parser which handles the interactions amongst the following factors: 1) the phonemic content of the onset and of the rhyme; 2) the location with respect to the word edge; 3) the stress pattern within the word.", "labels": [], "entities": []}, {"text": "These factors cover a substantial fragment of English phonotactics.", "labels": [], "entities": []}, {"text": "We then parse a set of neologisms and compare various methods of scoring the goodness of the parse as a predictor of acceptability: 1) The overall acceptability of a form is the likelihood of the best parse.", "labels": [], "entities": []}, {"text": "However, because long words contain more constituents than short words, their likelihood is lower, as 5o more multiplilcations are involved.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9896535277366638}]}, {"text": "In order to offset this , multiplicative effect, we also considered the following score: 2) The overall acceptability c~f a form is the log likelihood of the best parse.", "labels": [], "entities": []}, {"text": "3) The overall acceptability of the form is dominated by the worst component (the single lowest probability onset or rhyme).", "labels": [], "entities": [{"text": "rhyme", "start_pos": 117, "end_pos": 122, "type": "METRIC", "confidence": 0.5271226167678833}]}, {"text": "This alternative is loosely inspired by the phonological literature, from classical generative phonology to Optimality Theory, in which the badness of a form depends on fits most egregious phonotactic constraint violation.", "labels": [], "entities": []}, {"text": "4) We also examined the idea that the overall acceptability of a form is dominated by the best constituent, in recognition of the experimental result that nonsense words such as \"mrupation\" are often not regarded by subjects as being particularly bad, since despite containing a very un-English onset, the remainder of the word, :including its morphological and prosodic structgres, are well-formed.", "labels": [], "entities": []}, {"text": "We find that of these four proposals for scoring phonotactic well-formedness, 1), 2) and 3) yield statistically significant correlations with experimentally i obtained judgements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}