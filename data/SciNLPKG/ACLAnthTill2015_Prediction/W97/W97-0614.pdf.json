{"title": [{"text": "Grammatical analysis in the OVIS spoken-dialogue system", "labels": [], "entities": [{"text": "Grammatical analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8784081637859344}, {"text": "OVIS", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.8758645057678223}]}], "abstractContent": [{"text": "We argue that grammatical processing is a viable alternative to concept spotting for processing spoken input in a practical dialogue system.", "labels": [], "entities": [{"text": "grammatical processing", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7500561475753784}, {"text": "concept spotting", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.8077735304832458}]}, {"text": "We discuss the structure of the grammar, the properties of the parser, and a method for achieving robustness.", "labels": [], "entities": []}, {"text": "We discuss test results suggesting that grammatical processing allows fast and accurate processing of spoken input.", "labels": [], "entities": [{"text": "grammatical processing", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.781198650598526}]}], "introductionContent": [{"text": "The NWO Priority Programme Language and Speech Technology is a research programme aiming at the development of spoken language information systems.", "labels": [], "entities": [{"text": "NWO Priority Programme Language", "start_pos": 4, "end_pos": 35, "type": "DATASET", "confidence": 0.9000147134065628}]}, {"text": "Its immediate goal is to develop a demonstrator of a public transport information system, which operates over ordinary telephone lines.", "labels": [], "entities": []}, {"text": "This demonstrator is called OVIS, Openbaar Vervoer Informatie Systeem (Public Transport Information Systern).", "labels": [], "entities": [{"text": "OVIS", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.7551411390304565}, {"text": "Openbaar Vervoer Informatie Systeem (Public Transport Information Systern)", "start_pos": 34, "end_pos": 108, "type": "TASK", "confidence": 0.6267269581556321}]}, {"text": "The language of the system is Dutch.", "labels": [], "entities": []}, {"text": "At present, a prototype is in operation, which is aversion of a German system developed by Philips Dialogue Systems in Aachen (, adapted to Dutch.", "labels": [], "entities": []}, {"text": "This German system processes spoken input using \"concept spotting\", which means that the smallest information-carrying units in the input are extracted, such as names of train stations and expressions of time, and these are translated more or less individually into updates of the internal database representing the dialogue state.", "labels": [], "entities": [{"text": "concept spotting", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7777123153209686}]}, {"text": "The words between the concepts thus perceived are ignored.", "labels": [], "entities": []}, {"text": "The use of concept spotting is common in spokenlanguage information systems.", "labels": [], "entities": [{"text": "concept spotting", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7785945534706116}]}, {"text": "Arguments in favour of this kind of shallow parsing is that it is relatively easy to develop the NLP component, since larger sentence constructs do not have to betaken into account, and that the robustness of the parser is enhanced, since sources of ungrammaticality occurring between concepts are skipped and therefore do not hinder the translation of the utterance to updates.", "labels": [], "entities": []}, {"text": "The prototype presently under construction departs from the use of concept spotting.", "labels": [], "entities": [{"text": "concept spotting", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.8225382268428802}]}, {"text": "The grammar for OVIS describes grarnrnat'ical user utterances, i.e. whole sentences are described.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.7391685843467712}]}, {"text": "Yet, as part of this it also describes phrases such as expressions of time and prepositional phrases involving e.g. train stations, in other words, the former concepts.", "labels": [], "entities": []}, {"text": "By an appropriate parsing algorithm one thus combines the robustness that can be achieved using concept spotting with the flexibility of a sophisticated language model.", "labels": [], "entities": [{"text": "concept spotting", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.7654106318950653}]}, {"text": "The main objective of this paper is to show that our grammatical approach is feasible in terms of accuracy and computational resources, and thus is a viable alternative to pure concept spotting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9982179999351501}, {"text": "concept spotting", "start_pos": 177, "end_pos": 193, "type": "TASK", "confidence": 0.7801357209682465}]}, {"text": "Although the added benefit of grammatical analysis over concept spotting is not clear for our relatively simple application, the grammatical approach may become essential as soon as the application is extended in such away that mor~ complicated grammatical constructions need to be recognized.", "labels": [], "entities": [{"text": "concept spotting", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7826693058013916}]}, {"text": "In that case, simple concept spotting may not be able to correctly process all constructions, whereas the capabilities of the grammatical approach extend much further.", "labels": [], "entities": [{"text": "concept spotting", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.8388544917106628}]}, {"text": "Whereas some (e.g. () argue that grammatical analysis may improve recognition accuracy, our current experiments have as yet not been able to reveal a clear advantage in this respect.", "labels": [], "entities": [{"text": "grammatical analysis", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7559386789798737}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.8763021230697632}]}, {"text": "As the basis for our implementation we have chosen definite-clause grammars (DCGs), a flexible formalism which is related to various kinds of common linguistics description, and which allows application of various parsing algorithms.", "labels": [], "entities": []}, {"text": "DCGs can be translated directly into Prolog, for which interpreters and compilers exist that are fast enough to handle real-time processing of spoken input.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.9083992838859558}]}, {"text": "The grammar for OVIS is in turn written in away to allow an easy translation to pure DCGs.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.8302688598632812}]}, {"text": "1 The structure of this paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the grammar for OVIS, and in Section 3 we describe the output of the NLP module.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.8227830529212952}]}, {"text": "The robust parsing algorithm is described in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 reports test results, showing that grammatical analysis allows fast and accurate processing of spoken input.", "labels": [], "entities": [{"text": "grammatical analysis", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7475788295269012}]}], "datasetContent": [{"text": "This section evaluates the NLP component with respect to efficiency and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9983674883842468}]}], "tableCaptions": [{"text": " Table 1: This table lists the number of transitions,  the number of words of the actual utterances, the  average number of transitions per word, and the av- erage number of words per utterances.", "labels": [], "entities": [{"text": "av- erage number", "start_pos": 154, "end_pos": 170, "type": "METRIC", "confidence": 0.7568964511156082}]}, {"text": " Table 3: Word accuracy and sentence accuracy based on acoustic score only (Acoustic); using the best  possible path through the word-graph, based on acoustic scores only (Possible); a combination of acoustic  score and bigram score (Acoustic + Bigram), as reported by the current version of the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9016942977905273}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.7159301042556763}]}]}