{"title": [], "abstractContent": [{"text": "We propose a general approach for performing event coreference and for constructing complex event representations, such as those required for information extraction tasks.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7144881337881088}, {"text": "information extraction tasks", "start_pos": 142, "end_pos": 170, "type": "TASK", "confidence": 0.8095812400182089}]}, {"text": "Our approach is based on a representation which allows a tight coupling between world or conceptual modelling and discourse modelling.", "labels": [], "entities": []}, {"text": "The representation and the coreference mechanism are fully implemented within the LaSIE information extraction system where the mechanism is used for both object (noun phrase) and event coreference resolution.", "labels": [], "entities": [{"text": "LaSIE information extraction", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.8089030782381693}, {"text": "event coreference resolution", "start_pos": 180, "end_pos": 208, "type": "TASK", "confidence": 0.6324109037717184}]}, {"text": "Indirect evaluation of the approach shows small, but significant benefit, for information extraction tasks.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.8827066421508789}]}], "introductionContent": [{"text": "Much recent work on anaphora has concentrated on coreference between objects referred to by noun phrases or pronouns (see, e.g.,).", "labels": [], "entities": [{"text": "coreference between objects referred to by noun phrases or pronouns", "start_pos": 49, "end_pos": 116, "type": "TASK", "confidence": 0.8853021025657654}]}, {"text": "But coreference involving events, expressed via verbs or nominalised verb forms, is also common, and can play an important role in practical applications of natural language processing (NLP) systems.", "labels": [], "entities": []}, {"text": "One application area of increasing interest is information extraction (IE) (see, e.g.,).", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.9146779417991638}]}, {"text": "Information extraction systems attempt to fill predefined template structures with information extracted from short natural language texts, such as newswire articles.", "labels": [], "entities": [{"text": "Information extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8135974109172821}]}, {"text": "The prototypical IE tasks are those specified in the Message Understanding Conference (MUC) evaluations.", "labels": [], "entities": [{"text": "IE", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9835220575332642}, {"text": "Message Understanding Conference (MUC) evaluations", "start_pos": 53, "end_pos": 103, "type": "TASK", "confidence": 0.7780915924480983}]}, {"text": "In these exercises the main template filling task centres around a 'scenario' which is defined in terms of a key event type and various roles pertaining to it.", "labels": [], "entities": [{"text": "template filling", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7451735734939575}]}, {"text": "Examples of scenarios used in previous MUCs include joint venture announcements, microprocessor product announcements, terrorist attacks, labour negotiations, and management succession events.", "labels": [], "entities": [{"text": "MUCs", "start_pos": 39, "end_pos": 43, "type": "TASK", "confidence": 0.9149917960166931}]}, {"text": "In order not to spuriously overgenerate event instances and to properly acquire all available role information, it is crucial that multiple references to the same event be correctly identified and merged.", "labels": [], "entities": []}, {"text": "While these concerns are of central importance to IE systems, they are clearly of significance for any NLP system, and more broadly for any computational model of natural language.", "labels": [], "entities": [{"text": "IE", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9801821708679199}]}, {"text": "A few concrete examples will make the issues clearer 1.", "labels": [], "entities": []}, {"text": "A management succession event (as used in MUC-6) may involve the two separate events of a corporate position being vacated by one person and then filled by another.", "labels": [], "entities": [{"text": "management succession event", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.8821433782577515}, {"text": "MUC-6)", "start_pos": 42, "end_pos": 48, "type": "TASK", "confidence": 0.803319901227951}]}, {"text": "For an event to be considered reportable for the IE task, the post, the company and at least one person (either incoming or outgoing) must all be identifiable in the text.", "labels": [], "entities": [{"text": "IE task", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.9333324432373047}]}, {"text": "The first thing to note here is that while management succession events are sometimes reported as single, simple events, as in  Both of these pairs of sentences refer to a single management succession event (though the second sentence in 2 also identifies a further one).", "labels": [], "entities": [{"text": "management succession events", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.8437650601069132}]}, {"text": "Such event/sub-event relations are similar to the familiar part-whole or related-object anaphora exemplified in sentences such as The airplane crashed a~ter the wings/ell off or When John entered the kitchen the stove was on.", "labels": [], "entities": []}, {"text": "The second thing to note is the variety of surface forms used to refer to events.", "labels": [], "entities": []}, {"text": "Events are referred to by verb phrases in main clauses (1 above), and in relative clauses (second sentence in 2) or subordinate clauses.", "labels": [], "entities": []}, {"text": "They maybe referred to through nominalised forms (resignation in 3 above) or through infinitival forms in control sentences (second sentence in 3).", "labels": [], "entities": []}, {"text": "When there are multiple references to the same event, antecedent and anaphor appear to be able to adopt all combinations of these forms 2.", "labels": [], "entities": []}, {"text": "This paper discusses an approach to handling event coreference as implemented in the LaSIE information extraction system ().", "labels": [], "entities": [{"text": "handling event coreference", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6149113774299622}, {"text": "LaSIE information extraction", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.831015944480896}]}, {"text": "Within this system, event coreference is handled as a natural extension to object coreference, outlined here and described in detail in.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.6885995864868164}]}, {"text": "Both mechanisms are handled within a general approach to discourse and world modelling.", "labels": [], "entities": [{"text": "world modelling", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.7031198143959045}]}, {"text": "In the next section we give a brief overview of the LaSIE system.", "labels": [], "entities": [{"text": "LaSIE system", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8557886481285095}]}, {"text": "Section 3 describes in more detail the approach to world and discourse modelling within LaSIE and Section 4 details our coreference procedure.", "labels": [], "entities": [{"text": "world and discourse modelling", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.6202034056186676}, {"text": "LaSIE", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.8879396319389343}]}, {"text": "In Section 5 we discuss a particular example in detail and show how our approach enables us to correctly corefer multiple event references.", "labels": [], "entities": []}, {"text": "Section 6 presents results of an approach to evaluating the the approach and Section 7 concludes the paper with some general discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have not been able to carryout direct evaluation of our approach to event coreference.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.7515567243099213}]}, {"text": "To do so would require manually annotating coreferential events in a corpus of significant size, and we have not had the resources to do so.", "labels": [], "entities": []}, {"text": "However, we have attempted to gain some indirect measure of the successfulness of the approach by toggling event coreference on and off and observing the effect on the ability of the system to fill MUC-6 management succession templates correctly.", "labels": [], "entities": [{"text": "MUC-6 management succession templates", "start_pos": 198, "end_pos": 235, "type": "TASK", "confidence": 0.5894406735897064}]}, {"text": "The hypothesis here is that effective event coreference will lead to higher scores in the template filling task for at least two reasons.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7067299336194992}, {"text": "template filling task", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.7692937354246775}]}, {"text": "First, role players in events (which become slot fillers in the scored templates, e.g. persons and organisations) should become available due to event coreference.", "labels": [], "entities": []}, {"text": "Second, spurious succession events should be eliminated due to proper event coreference.", "labels": [], "entities": []}, {"text": "The MUC-6 management succession scenario task involved filling an object-oriented template consisting of five objects, each with associated slots (twenty slots in total).", "labels": [], "entities": [{"text": "MUC-6 management succession scenario task", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.8104792594909668}]}, {"text": "The top level object was a template object and contained one or more succession_event objects which in turn contained an organization object and one or more in_and_out objects, themselves containing organization and person objects (a precise definition of the template and the task can be found in DARPA).", "labels": [], "entities": [{"text": "DARPA", "start_pos": 298, "end_pos": 303, "type": "DATASET", "confidence": 0.8866066336631775}]}, {"text": "shows the gross results of running the system against the 100 articles in the MUC-6 scenario task test corpus.", "labels": [], "entities": [{"text": "MUC-6 scenario task test corpus", "start_pos": 78, "end_pos": 109, "type": "DATASET", "confidence": 0.9014599680900574}]}, {"text": "Our system is easily reconfigured to run with or without attempting event coreference.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.6695420891046524}]}, {"text": "The two rows in the table show the effects without and with event coreference.", "labels": [], "entities": []}, {"text": "The 'Overall' column show the effects on the overall scenario template filling task, i.e., on recall and precision scores for all objects and slots in the templates.", "labels": [], "entities": [{"text": "scenario template filling task", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.7279678732156754}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9992157220840454}, {"text": "precision scores", "start_pos": 105, "end_pos": 121, "type": "METRIC", "confidence": 0.9734289646148682}]}, {"text": "The 'Succession Events' column shows the effect just for the succession_event objects in the templates, and is therefore a more direct measure of template filling performance where we might expect event coreference to have an effect.", "labels": [], "entities": [{"text": "template filling", "start_pos": 146, "end_pos": 162, "type": "TASK", "confidence": 0.7061630487442017}, {"text": "event coreference", "start_pos": 197, "end_pos": 214, "type": "TASK", "confidence": 0.6800348609685898}]}, {"text": "As can be seen from the table, the effect overall is not particularly significant.", "labels": [], "entities": []}, {"text": "However, the effect on succession events alone is more substantial, with precision going up five percentage points and recall dropping only one, when event coreference is switched on.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.999484658241272}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9989728927612305}]}, {"text": "Closer examination revealed that the event coreference mechanism successfully avoided the proposal of 11 spurious succession events in the evaluation corpus, which included 196 possible events.", "labels": [], "entities": []}, {"text": "We stress that this is a crude measure of our event coreference algorithm -really just an indication of its utility in the information extraction task.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7837174832820892}, {"text": "information extraction task", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.883452296257019}]}, {"text": "However, even as such, it shows that the algorithm is performing correctly, on balance, and that event coreference is worth addressing in an IE system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Upper Ontology.for the management succession task", "labels": [], "entities": [{"text": "management succession", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.9180408418178558}]}]}