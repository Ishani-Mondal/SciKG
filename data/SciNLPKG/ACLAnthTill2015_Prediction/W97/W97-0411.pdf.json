{"title": [{"text": "Translation Methodology in the Spoken Language Translator: An Evaluation Telia Research AB Handelshcjskolen i Kc~benhavn Spoken Language Processing Institut for Datalingvistik S-13680 Haninge Dalgas Have 15 Sweden DK-2000 Frederiksberg Denmark", "labels": [], "entities": [{"text": "Translation Methodology in the Spoken Language Translator", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.6894349157810211}, {"text": "Telia Research AB Handelshcjskolen i Kc~benhavn Spoken Language Processing Institut for Datalingvistik S-13680 Haninge Dalgas Have 15 Sweden DK-2000 Frederiksberg Denmark", "start_pos": 73, "end_pos": 243, "type": "DATASET", "confidence": 0.6104755220205887}]}], "abstractContent": [{"text": "In this paper we describe how the translation methodology adopted for the Spoken Language Translator (SLT) addresses the characteristics of the speech translation task in a context where it is essential to achieve easy customization to new languages and new domains.", "labels": [], "entities": [{"text": "Spoken Language Translator (SLT)", "start_pos": 74, "end_pos": 106, "type": "TASK", "confidence": 0.8376781145731608}, {"text": "speech translation task", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.8097280263900757}]}, {"text": "We then discuss the issues that arise in any attempt to evaluate a speech translator, and present the results of such an evaluation carried out on SLT for several language pairs.", "labels": [], "entities": []}, {"text": "1 The nature of the speech translation task Speech translation is in many respects a particularly difficult version of the translation task.", "labels": [], "entities": [{"text": "speech translation task Speech translation", "start_pos": 20, "end_pos": 62, "type": "TASK", "confidence": 0.8641616821289062}, {"text": "translation task", "start_pos": 123, "end_pos": 139, "type": "TASK", "confidence": 0.8914037644863129}]}, {"text": "High quality output is essential: the speech produced must sound natural if it is to be easily compre-hensible.", "labels": [], "entities": []}, {"text": "The quality of the translation itself must also be high, in spite of the fact that, by the nature of the problem, no post-editing is possible.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9729552268981934}]}, {"text": "Things are equally difficult on the input side: pre-editing, too, is difficult or impossible, yet ill-formed input and recognition errors are both likely to be quite common.", "labels": [], "entities": []}, {"text": "Thus robust analysis and translation are also required.", "labels": [], "entities": [{"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.9738799929618835}]}, {"text": "Furthermore, any attempted solutions to these problems must be capable of operating at a speed close enough to real time that users are not faced with unacceptable delays.", "labels": [], "entities": []}, {"text": "Together, these factors mean that speech translation is currently only practical for limited domains , typically involving a vocabulary of a few thousand words.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7659603953361511}]}, {"text": "Because of this, it is desirable that a speech translator should be easily portable to new domains.", "labels": [], "entities": [{"text": "speech translator", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7336764335632324}]}, {"text": "Portability to new languages , involving the acquisition of both monolin-gual and cross-linguistic information, should also be as straightforward as possible.", "labels": [], "entities": []}, {"text": "These ends can be achieved by using general-purpose components for both speech and language processing and training them on domain-specific speech and text corpora.", "labels": [], "entities": []}, {"text": "The training should be automated whenever possible, and where human intervention is required, the process should be deskilled to the level where, ideally, it can be carried out by people who are familiar with the domain but are not experts in the systems themselves.", "labels": [], "entities": []}, {"text": "These points will be discussed in the context of the Spoken Language Translator (SLT) (Rayner, Alshawi eta/, 1993; Agn~s et al., 1994; Rayner and Carter, 1997), a customizable speech translator built as a pipelined sequence of general-purpose components.", "labels": [], "entities": [{"text": "Spoken Language Translator (SLT)", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.7742098818222681}]}, {"text": "These components are: aversion of the Decipher (TM) speech recognizer (Murveit eta/, 1993) for the source language; a copy of the Core Language Engine (CLE) (Al-shawi (ed), 1992) for the source language; another copy of the CLE for the target language; and a target language text-to-speech synthesizer.", "labels": [], "entities": [{"text": "Decipher (TM) speech recognizer", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.5528215318918228}]}, {"text": "The current SLT system carries out multilingual speech translation in near real time in the ATIS domain (Hemphill et al., 1990) for several language pairs.", "labels": [], "entities": [{"text": "SLT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9519246220588684}, {"text": "multilingual speech translation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.679993212223053}, {"text": "ATIS domain (Hemphill et al., 1990)", "start_pos": 92, "end_pos": 127, "type": "DATASET", "confidence": 0.8626632889111837}]}, {"text": "Good demonstration versions exist for the four pairs English ~ Swedish, English French, Swedish ~ English and Swedish Danish.", "labels": [], "entities": []}, {"text": "Preliminary versions exist for five more pairs: Swedish ~ French, French-~ English, En-glish ~ Danish, French-d.", "labels": [], "entities": []}, {"text": "Spanish and English-~ Spanish.", "labels": [], "entities": []}, {"text": "We describe the methodology used to build the SLT system itself, particularly in the areas of cus-tomization (Section 2), robustness (Section 3), and multilinguality (Section 4).", "labels": [], "entities": [{"text": "SLT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9783912301063538}]}, {"text": "For further details on the topics of customization and multilin-73 guality, see (Rayner, Bretan et al, 1996; Rayner, Carter et al, 1997); and on robustness, see (Rayner and Carter, 1997).", "labels": [], "entities": []}, {"text": "We then discuss the evaluation of speech translation systems.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.753703773021698}]}, {"text": "This is an area that deserves more attention than it has received to date; indeed, it is not obvious how best to perform such an evaluation so as to measure meaningfully the performance both of the overall system and of each of its components.", "labels": [], "entities": []}, {"text": "In Sections 5 and 6 of this paper, we therefore consider the characteristics an evaluation should have, and describe one we have carried out, discussing the extent to which it meets the desired criteria.", "labels": [], "entities": []}, {"text": "2 Customization to languages and domains In the Core Language Engine, the language processing component of the Spoken Language Translator system, we address the requirement of porta-bility by maintaining a clear separation between (I) the system code; (2) linguistic rules, including lexicon entries, to generate possible analyses and translations non-deterministically; and (3) statistical information, to choose between these possibilities.", "labels": [], "entities": []}, {"text": "The practical advantage of this architecture is that most of the work involved in porting the system to anew domain is concerned with the parts of the system that can be modified by non-experts: the central activities are addition of new lexicon entries, and supervised training to derive the statistical preference information.", "labels": [], "entities": []}, {"text": "Porting to new languages is a more complex task, but still only involves modifications to a relatively small subset of the whole system.", "labels": [], "entities": [{"text": "Porting to new languages", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8567207902669907}]}, {"text": "In more detail: (I) The system code is completely general-purpose and does not need any changes for new domains or, other than in exceptional cases, I for new languages.", "labels": [], "entities": []}, {"text": "(2) The more complex of the linguistic rules fora given language are the grammar, the function word lexicon, and the macros defining common content word behaviours (count noun, transitive verb, etc).", "labels": [], "entities": []}, {"text": "These are defined using explicit feature-value equations which must be written by a skilled grammarian.", "labels": [], "entities": []}, {"text": "For a given language pair,", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In speech-to-text mode, evaluation of the system's performance on a given utterance proceeds as follows.", "labels": [], "entities": []}, {"text": "The judge is first shown a text version of the correct source utterance (what the user actually said), followed by the selected recognition hypothesis (what the system thought the user said).", "labels": [], "entities": []}, {"text": "The judge is then asked to decide whether the recognition hypothesis is acceptable.", "labels": [], "entities": []}, {"text": "Judges are told to assume that they have the option of aborting translation if recognition is of insufficient quality; judging a recognition hypothesis as unacceptable corresponds to pushing the 'abort' button.", "labels": [], "entities": []}, {"text": "When the judge has determined the acceptability of the recognition hypothesis, the text version of the translation is presented.", "labels": [], "entities": []}, {"text": "(Note that it is not presented earlier, as this might bias the decision about recognition acceptability.)", "labels": [], "entities": [{"text": "recognition acceptability", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.9037610292434692}]}, {"text": "The judge is now asked to classify the quality of the translation along a seven-point scale; the points on the scale have been chosen to reflect the distinctions judges most frequently have been observed to make in practice.", "labels": [], "entities": []}, {"text": "When selecting the appropriate category, judges are instructed only to take into account the actual spoken source utterance and the translation produced, and ignore the recognition hypothesis.", "labels": [], "entities": []}, {"text": "The possible judgement categories are the following; the headings are those used in Tables 1 and 2 below.", "labels": [], "entities": []}, {"text": "Fully acceptable, except that style is not completely natural.", "labels": [], "entities": []}, {"text": "This is most commonly due to over-literal translation.", "labels": [], "entities": []}, {"text": "One or two minor syntactic or word-choice errors, otherwise acceptable.", "labels": [], "entities": []}, {"text": "Typical examples are bad choices of determiners or prepositions.", "labels": [], "entities": []}, {"text": "At least one major or several minor syntactic or word-choice errors, but the sense of the utterance is preserved.", "labels": [], "entities": []}, {"text": "The most common example is an error in word-order produced when the system is forced to backup to the robust translation method.", "labels": [], "entities": []}, {"text": "At least half of the utterance has been acceptably translated, and the rest is nonsense.", "labels": [], "entities": []}, {"text": "A typical example is when most of the utterance has been correctly recognized and translated, but there is a short 'false start' at the beginning which has resulted in a word or two of junk at the start of the translation.", "labels": [], "entities": []}, {"text": "The translation makes no sense.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9571704268455505}]}, {"text": "The most common reason is gross misrecognition, but translation problems can sometimes be the cause as well.", "labels": [], "entities": [{"text": "translation", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.9657309055328369}]}, {"text": "The translation makes some sense, but fails to convey the sense of the source utterance.", "labels": [], "entities": []}, {"text": "The most common reason is again a serious recognition error.", "labels": [], "entities": []}, {"text": "Results are presented by simply counting the number of translations in a run which fall into each category.", "labels": [], "entities": []}, {"text": "By taking account of the \"unacceptable hypothesis\" judgements, it is possible to evaluate the performance of the system either in a fully automatic mode, or in a mode where the source-language user has the option of aborting misrecognized utterances.", "labels": [], "entities": []}, {"text": "Our intuitive impression, based on many evaluation runs in several different language-pairs, is that the \"fine-grained\" style of speech-totext evaluation described in the preceding section gives a much more informative picture of the system's performance than the simple acceptable/unacceptable dichotomy.", "labels": [], "entities": []}, {"text": "However, it raises an obvious question: how important, in objective terms, are the distinctions drawn by the finegrained scale?", "labels": [], "entities": []}, {"text": "The preliminary work we now goon to describe attempts to provide an empirically justifiable answer, in terms of the relationship between translation quality and comprehensibility of output speech.", "labels": [], "entities": []}, {"text": "Our goal, in other words, is to measure objectively the ability of subjects to understand the content of speech output.", "labels": [], "entities": []}, {"text": "This must be the key criterion for evaluating a candidate translation: if apparent deficiencies in syntax or word-choice fail to affect subject's ability to understand content, then it is hard to say that they represent real loss of quality.", "labels": [], "entities": []}, {"text": "The programme sketched above is difficult or, arguably, impossible to implement in a general setting.", "labels": [], "entities": []}, {"text": "Ina limited domain, however, it appears quite feasible to construct a domain-specific form-based questionnaire designed to test a subject's understanding of a given utterance.", "labels": [], "entities": []}, {"text": "In the SLT system's current domain of air travel planning (ATIS), a simple form containing about 20 questions extracts enough content from most utterances that it can be used as a reliable measure of a subject's understanding.", "labels": [], "entities": [{"text": "SLT", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9830535054206848}, {"text": "air travel planning (ATIS)", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.7811421304941177}]}, {"text": "The assumption is that a normal domain utterance can be regarded as a database query involving a limited number of possible categories: in the ATIS domain, these are concepts like flight origin and destination, departure and arrival times, choice of airline, and soon.", "labels": [], "entities": []}, {"text": "A detailed description of the evaluation method follows.", "labels": [], "entities": []}, {"text": "The judging interface is structured as a hypertext document that can be accessed through a. web-browser.", "labels": [], "entities": []}, {"text": "Each utterance is represented by one web page.", "labels": [], "entities": []}, {"text": "On entering the page fora given utterance, the judge first clicks a button that plays an audio file, and then fills in an HTML form describing what they heard.", "labels": [], "entities": []}, {"text": "Judges are allowed to start by writing down as much as they can of the utterance, so as to keep it clear ir; their memory as they fill in the form.", "labels": [], "entities": []}, {"text": "The form is divided into four major sections.", "labels": [], "entities": []}, {"text": "The first deals with the linguistic form of the enquiry, for example, whether it is a command (imperative), a yes/no-question or a wh-question.", "labels": [], "entities": []}, {"text": "In the second section the judge is asked to write down the principal '!object\" of the utterance.", "labels": [], "entities": []}, {"text": "For example, in the utterance \"Show flights from Boston to Atlanta\", the principal object would be \"flights\".", "labels": [], "entities": []}, {"text": "The third section lists some 15 constraints on the object explicitly mentioned in the enquiry, like \"...one-way from New York to Boston on Sunday\".", "labels": [], "entities": []}, {"text": "Initial testing proved that these three sections covered the form and content of most enquiries within the domain, but to account for unforeseen material the judge is also presented with a \"miscellaneous\" category.", "labels": [], "entities": []}, {"text": "Depending on the character of the options, form entries are either multiple-choice or free-text.", "labels": [], "entities": []}, {"text": "All form entries maybe negated (\"No stopovers\") and disjunctive enquiries are indicated by dint of indexing (\"Delta on Thursday or American on Friday\").", "labels": [], "entities": []}, {"text": "When the page is exited, the contents of the completed form are stored for further use.", "labels": [], "entities": []}, {"text": "Each translated utterance is judged in three versions, by different judges.", "labels": [], "entities": []}, {"text": "The first two versions are the source and target speech files; the third time, the form is filled in from the tezt version of the source utterance.", "labels": [], "entities": []}, {"text": "(The judging tool allows a mode in which the text version is displayed instead of an audio file being played.)", "labels": [], "entities": []}, {"text": "The intention is that the source text version of the utterance should act as a baseline with which the source and target speech versions can respectively be compared.", "labels": [], "entities": []}, {"text": "Comparison is carried out by a fourth judge.", "labels": [], "entities": []}, {"text": "Here, the contents of the form entries for two versions of the utterance are compared.", "labels": [], "entities": []}, {"text": "The judge has to decide whether the contents of each field in the form are compatible between the two versions.", "labels": [], "entities": []}, {"text": "When the forms for two versions of an utterance have been filled in and compared, the results can be examined for comprehensibility in terms of the standard notions of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9992132186889648}, {"text": "recall", "start_pos": 182, "end_pos": 188, "type": "METRIC", "confidence": 0.995315432548523}]}, {"text": "We say that the recall of version 2 of the utterance with respect to version I is the proportion of the fields filled in version 1 that are filled in compatibly in version 2.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9993508458137512}]}, {"text": "Conversely, the precision is the proportion of the fields filled in in version 2 that are filled in compatibly in version i.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.999237060546875}]}, {"text": "The recall and precision scores together define a two-element vector which we will call the comprehensibility of version 2 with respect to version i.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9992352724075317}, {"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9970523118972778}]}, {"text": "We can now define C,o~,ce to be the comprehensibility of the source speech with respect to the source text, and Ct~,get to be the comprehensibility of the target speech with respect to the source text.", "labels": [], "entities": []}, {"text": "Finally, we define the quality of the translation to be I -(C,~,ce -Cta,get), where Cm~rce -Cta~get in a natural way can be interpreted as the extent to which comprehensibility has degraded as a result of the translation process.", "labels": [], "entities": []}, {"text": "At the end of the following section, we describe an experiment in which we use this measure to evaluate the quality of translation in the English --~ French version of SLT.", "labels": [], "entities": []}, {"text": "We begin by presenting the results of tests run in speech-to-text mode on versions of the SLT system developed for six different language-pairs: English Swedish, English ~ French, Swedish --+ English, Swedish ~ French, Swedish -+ Danish, and English ~ Danish.", "labels": [], "entities": []}, {"text": "Before going any further, it must be stressed that the various versions of the system differ in important ways; some languagepairs are intrinsically much easier than others, and some versions of the system have received far more effort than others.", "labels": [], "entities": []}, {"text": "In terms of diffculty, Swedish --~ Danish is clearly the easiest language-pair, and Swedish French is clearly the hardest.", "labels": [], "entities": []}, {"text": "English ~ French is easier than Swedish ~ French, but substantially more diffcult than any of the others.", "labels": [], "entities": []}, {"text": "English --~ Swedish, Swedish ~ English and English --~ Danish are all of comparable difficulty.", "labels": [], "entities": []}, {"text": "We present approximate figures for the amounts of effort devoted to each language pair in conjunction with the other results.", "labels": [], "entities": []}, {"text": "We evaluated performance on each languagepair in the manner described in Section 5.1 above, taking as input two sets of 200 recorded speech utterances each (one for English and one for Swedish) which had not previously been used for system development.", "labels": [], "entities": []}, {"text": "Judging was done by subjects who had not participated in system development, were native speakers of the target language, and were fluent in the source language.", "labels": [], "entities": []}, {"text": "Results are presented both fora fully automatic version of the system, and fora version with a simulated 'abort' button.", "labels": [], "entities": []}, {"text": "Finally, we turn to a preliminary experiment which used the speech-to-speech evaluation methodology from Section 5.2 above.", "labels": [], "entities": []}, {"text": "A set of 200 previously unseen English utterances were translated by the system into French speech, using the same kind of subjects as in the previous experiments.", "labels": [], "entities": []}, {"text": "Source-language and target-language speech was synthesized using commercially available, state-of-the-art synthesizers (TrueTalk from Entropies and CNETVOX from ELAN Informatique, respectively).", "labels": [], "entities": []}, {"text": "The subjects were only allowed to hear each utterance once.", "labels": [], "entities": []}, {"text": "The results were evaluated in the manner described, to produce figures for comprehensibility of source and target speech respectively.", "labels": [], "entities": []}, {"text": "The figures are presented in; we expect to be able to present a more detailed discussion of their ~ignificance by the time of the workshop.", "labels": [], "entities": []}, {"text": "In summary, we have improved the standard evaluation method for speech translation by developing a feasible alternative with a more finegrained taxonomy of acceptability.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7756573855876923}]}, {"text": "In order to make the task of evaluation more realistic, we have also created a method in which instead of textual translations it is the spoken form that is judged.", "labels": [], "entities": []}, {"text": "This method is currently in embryonic form, but the pilot experiment described here leads us to think that the method shows promise for further development.", "labels": [], "entities": []}, {"text": "An interesting future task would be to investigate the significance of various kinds of written-language translation errors in terms of reducing comprehensibility of the spoken output.", "labels": [], "entities": []}, {"text": "This would amount to systematically comparing Cta,#et with results obtained in speech-to-text evaluations, divided up according to error categories such as those in our taxonomy.", "labels": [], "entities": []}, {"text": "46.0% 14.0% 12.0% 72.0% 7.0% 6.5% 13.5% 7.5%", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Translation results for six language pairs on 200 unseen utterances, ignoring utterances judged  as recognition failures.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9719895124435425}]}]}