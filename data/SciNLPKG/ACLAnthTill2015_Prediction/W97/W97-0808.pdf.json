{"title": [{"text": "Word Sense Disambiguation for Acquisition of Selectional Preferences", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6116995712121328}, {"text": "Selectional Preferences", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.7228293120861053}]}], "abstractContent": [{"text": "The selectional preferences of verbal predicates are an important component of lexical information useful fora number of NLP tasks including disambiglia-tion of word senses.", "labels": [], "entities": []}, {"text": "Approaches to selectional preference acquisition without word sense disambigua-tion are reported to be prone to errors arising from erroneous word senses.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 14, "end_pos": 48, "type": "TASK", "confidence": 0.7246760328610738}]}, {"text": "Large scale automatic semantic tagging of texts in sufficient quantity for preference acquisition has received little attention as most research in word sense disambiguation has concentrated on quality word sense disambiguation of a handful of target words.", "labels": [], "entities": [{"text": "automatic semantic tagging of texts", "start_pos": 12, "end_pos": 47, "type": "TASK", "confidence": 0.7505165696144104}, {"text": "preference acquisition", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7332605272531509}, {"text": "word sense disambiguation", "start_pos": 148, "end_pos": 173, "type": "TASK", "confidence": 0.7348861296971639}, {"text": "word sense disambiguation", "start_pos": 202, "end_pos": 227, "type": "TASK", "confidence": 0.6801618734995524}]}, {"text": "The work described here concentrates on adapting semantic tagging methods that do not require a massive overhead of manual semantic tagging and that strike a reasonable compromise between accuracy and cost so that large amounts of text can be tagged relatively quickly.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7062169909477234}, {"text": "semantic tagging", "start_pos": 123, "end_pos": 139, "type": "TASK", "confidence": 0.7394830584526062}, {"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9980625510215759}]}, {"text": "The results of some of these adaptations are described here along with a comparison of the selec-tional preferences acquired with and without one of these methods.", "labels": [], "entities": []}, {"text": "Results of a bootstrapping approach are also outlined in which the preferences obtained are used for coarse grained sense disambiguation and then the partially disambiguated data is fed back into the preference acquisition system.", "labels": [], "entities": []}, {"text": "1 1This work was supported by CEC Telematics Applications Programme project LE1-2111 \"SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering\".", "labels": [], "entities": [{"text": "CEC Telematics Applications Programme project LE1-2111", "start_pos": 30, "end_pos": 84, "type": "DATASET", "confidence": 0.9065262178579966}, {"text": "Knowledge extraction", "start_pos": 115, "end_pos": 135, "type": "TASK", "confidence": 0.722231537103653}]}], "introductionContent": [{"text": "The automatic acquisition of lexical information is widely seen as away of overcoming the bottleneck of producing NLP applications.", "labels": [], "entities": [{"text": "automatic acquisition of lexical information", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.7263746201992035}]}, {"text": "The selectional preferences that predicates have for their arguments provide useful information that can help with resolution of both lexical and structural ambiguity and anaphora as well as being important for identifying the underlying semantic roles in argument slots.", "labels": [], "entities": []}, {"text": "The work reported here concentrates on acquisition for verbal predicates since verbs are of such obvious importance for the lexicon.", "labels": [], "entities": []}, {"text": "However it could also be applied to any other type of predication.", "labels": [], "entities": []}, {"text": "The main contribution of this work is that it uses shallow parses produced by a fully automatic parser and that some word sense disambiguation (WSD) is performed on the heads collected from these parses.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.6890686353047689}]}, {"text": "Most current research on selectional preference acquisition has used the Penn Treebank parses) These are obtained semi-automatically with a deterministic parser and manual correction.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.8296966950098673}, {"text": "Penn Treebank parses", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.9449147979418436}]}, {"text": "Additionally the other approaches do not perform any WSD on the input data and most report a major source of error arising from the contribution of erroneous senses sometimes giving incorrect preferences and at other times a noticeable effect of over-generalisation (.", "labels": [], "entities": [{"text": "WSD", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.890816867351532}]}, {"text": "The relationship between selectional preference acquisition and WSD is a circular one.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.7559677958488464}, {"text": "WSD", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8418290615081787}]}, {"text": "One potential use of selectional preferences is WSD yet their acquisition appears to require disarabiguated data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8796563744544983}]}, {"text": "There are ways of breaking this circle.", "labels": [], "entities": []}, {"text": "This pa-per describes work comparing the preferences acquired with and without semantic tagging of the input data.", "labels": [], "entities": []}, {"text": "The cost of word sense disambiguation is kept low enough to permit tagging of a sufficient quantity of data.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7744601368904114}]}, {"text": "An iterative approach is also outlined whereby the preferences so acquired are used to disambiguate the argument heads which are then fed back into the preference acquisition system.", "labels": [], "entities": []}, {"text": "It is hoped that with enough data erroneous senses can be filtered out as noise.", "labels": [], "entities": []}, {"text": "However tagged data should produce more appropriate selectional restrictions provided the tagging is sufficiently accurate.", "labels": [], "entities": []}, {"text": "Tagging should be particularly useful in cases where the data is scarce.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9582232236862183}]}], "datasetContent": [{"text": "This experiment followed the approach of using the first sense regardless of context.", "labels": [], "entities": []}, {"text": "Wilks and Stevenson did this in order to disambiguate LDOCE homographs.", "labels": [], "entities": []}, {"text": "Distinguishing between WordNet senses is a much harder problem and so performance was not expected to be as good.", "labels": [], "entities": [{"text": "Distinguishing between WordNet senses", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6781143695116043}]}, {"text": "The only frequency information available for WordNet senses, assuming large scale manual tagging is out of the question, is the portion of the Brown corpus that has been semantically tagged with WordNet senses for the SemCor project.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 143, "end_pos": 155, "type": "DATASET", "confidence": 0.9239264726638794}]}, {"text": "Criteria were used alongside this frequency data specifying when to use the first sense and when to leave the ambiguity untouched.", "labels": [], "entities": []}, {"text": "Two criteria were used initially: 1.", "labels": [], "entities": []}, {"text": "Fi~EQ -a threshold on the frequency of the first sense . RATIO -a threshold ratio between the frequencies of the first sense and next most frequent sense.", "labels": [], "entities": [{"text": "Fi~EQ", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8372156023979187}, {"text": "RATIO", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9819305539131165}]}, {"text": "At first FREQ was set at 5 and RATIO at 2.", "labels": [], "entities": [{"text": "FREQ", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9989417195320129}, {"text": "RATIO", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9928256273269653}]}, {"text": "The method was then evaluated against the manually tagged sample of the Brown corpus (200,000 words of text) from which the frequency data was obtained and two small manually tagged samples from the LOB corpus (sample size of nouns 179) and the Wall Street Journal corpus (size 191 nouns).", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.9781423509120941}, {"text": "LOB corpus", "start_pos": 199, "end_pos": 209, "type": "DATASET", "confidence": 0.8982113897800446}, {"text": "Wall Street Journal corpus", "start_pos": 245, "end_pos": 271, "type": "DATASET", "confidence": 0.9733491688966751}]}, {"text": "The results are shown in table 1.", "labels": [], "entities": []}, {"text": "As expected the performance was superior when scored against the same data from which the frequency estimates had been taken.", "labels": [], "entities": []}, {"text": "Further experimentation was performed using the LOB sample and varying FREQ and RATIO.", "labels": [], "entities": [{"text": "LOB sample", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.8193803131580353}, {"text": "FREQ", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.999466598033905}, {"text": "RATIO", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9869591593742371}]}, {"text": "Additionally a third constraint was added (D).", "labels": [], "entities": [{"text": "constraint", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9592052698135376}, {"text": "D)", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9666213095188141}]}, {"text": "In this nouns identified on the SemCor project as being difficult for humans to tag were ignored.", "labels": [], "entities": []}, {"text": "The results are shown in table 2.", "labels": [], "entities": []}, {"text": "Although the resuits indicate this is rather a limited method of disambiguating it was hoped that it would improve the  selectional preference acquisition process whilst also avoiding a heavy cost in terms of human time (for manual tagging) or computer time (for unsupervised training).", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 120, "end_pos": 154, "type": "TASK", "confidence": 0.8420248031616211}]}, {"text": "For the selectional preference acquisition experiments 4 and 6 described below it was decided to use the criteria FREQ 3, RATIO 2 and D (ignore difficult nouns).", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 8, "end_pos": 42, "type": "TASK", "confidence": 0.8035021225611368}, {"text": "FREQ", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.99299156665802}, {"text": "RATIO 2", "start_pos": 122, "end_pos": 129, "type": "METRIC", "confidence": 0.9395132064819336}, {"text": "D", "start_pos": 134, "end_pos": 135, "type": "METRIC", "confidence": 0.7547325491905212}]}, {"text": "Yarowksy's unsupervised algorithm (1995) was also investigated using WordNet to generate the initial seed collocations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9595462679862976}]}, {"text": "This has the advantage that it does not rely on a quantity of handtagged data however the time taken for training remains an issue.", "labels": [], "entities": []}, {"text": "Without optimisation the algorithm took 15 minutes of elapsed time for 710 citations of the word \"plant\".", "labels": [], "entities": []}, {"text": "Accuracy was reasonable considering a) the quantity of data used (a corpus of 90 million words compared with Yarowsky's 460 million) and b) the simplifications made, imparticular the use of only one type of collocation.", "labels": [], "entities": []}, {"text": "3 On initial experimentation it was evident that predominant senses quickly became favoured.", "labels": [], "entities": []}, {"text": "For this reason the measure to order the decision list 3The only collocation used was within a window of 10 words either side of the target.", "labels": [], "entities": []}, {"text": "Recall is 71% and precision is 72% when using the loglikelihood to order the decision list with a stopping condition that the tagged portion exceeds 95% of the target data.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9963022470474243}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9998072981834412}]}, {"text": "The ratio of association scores compensates for the relative frequencies of the senses and on stopping the recall is 76% and precision is 78% Unfortunately evaluation on the target word \"plant\" was rather optimistic when contrasted with an evMuation on randomly selected targets involving finer word sense distinctions.", "labels": [], "entities": [{"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9993147850036621}, {"text": "precision", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9997183680534363}]}, {"text": "Ina experiment 390 mid-frequency nouns were trained and the algorithm used to disambiguate the same nouns appearing in the SemCor files of the Brown corpus.", "labels": [], "entities": [{"text": "SemCor files of the Brown corpus", "start_pos": 123, "end_pos": 155, "type": "DATASET", "confidence": 0.9022350907325745}]}, {"text": "This produced only 29% for both recall and precision which was only just better than chance.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9996247291564941}, {"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9994383454322815}]}, {"text": "An important source of error seems to have been the poor quality of the automatically derived seeds.", "labels": [], "entities": []}, {"text": "On account of the training time that would be required Yarowsky's unsupervised algorithm was abandoned for the purpose of tagging the argument heads.", "labels": [], "entities": []}, {"text": "The Wilks and Stevenson style strategy was chosen instead because it requires storage of one parameter only and is exceptionally easy to apply.", "labels": [], "entities": []}, {"text": "A major disadvantage for this approach is that lower rank senses do not feature in the data at all.", "labels": [], "entities": []}, {"text": "It is hoped that this will not matter where we are collecting information from many heads in a particular slot because any mistagging will be outweighed by correct taggings overall.", "labels": [], "entities": []}, {"text": "However this approach would be unhelpful where we want to distinguish behaviour for different word senses.", "labels": [], "entities": []}, {"text": "A potential use of Yarowky's algorithm might be verb sense distinction.", "labels": [], "entities": [{"text": "verb sense distinction", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7444138526916504}]}, {"text": "The experiments outlined in the next section have been conducted using verb form rather than sense.", "labels": [], "entities": []}, {"text": "If verbs sense distinction were to be performed it would be important to obtain the preferences for the different senses and would not be appropriate to lump the preferences together under the predominant sense.", "labels": [], "entities": [{"text": "verbs sense distinction", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.6717038750648499}]}, {"text": "It is hoped that with some alteration to the automatic seed derivation and allowance fora coarser grained distinction this would be viable.", "labels": [], "entities": []}, {"text": "a threshold of 0.1 was adhered to as this not only avoided noise but also reduced the search space.", "labels": [], "entities": []}, {"text": "The input data was produced by the system described in) and comprised 2 million words of parsed text with argument heads and subcategorisation frames identified.", "labels": [], "entities": []}, {"text": "Only argument heads consisting of common nouns, days of the week and months and personal pronouns with the exception of \"it\" were used.", "labels": [], "entities": []}, {"text": "The personal pronouns were all tagged with the \"SOMEONE\" class which is unambiguous in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9677473306655884}]}, {"text": "Selectional preferences were acquired fora handful of verbs using either subject or object position.", "labels": [], "entities": []}, {"text": "In experiment 3 class frequencies were calculated in much the same way as in Li and Abe's original experiments, dividing frequencies for each noun between the set of classes in which they featured as synonyms.", "labels": [], "entities": []}, {"text": "In experiment 4 the nouns in the target slots were disambiguated using the approach outlined in experiment 1.", "labels": [], "entities": []}, {"text": "Where frequency data was not available for the target word the word was simply treated as ambiguous and class frequencies were calculated as in experiment 3.", "labels": [], "entities": []}, {"text": "Since ATCMs have only been obtained for the subject and object slot and for 10 target verbs no formal evaluation has been performed as yet.", "labels": [], "entities": [{"text": "ATCMs", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.913781464099884}]}, {"text": "Instead the ATCMs were examined and some observations are given below along with diagrams showing some of the models obtained.", "labels": [], "entities": [{"text": "ATCMs", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.7420520186424255}]}, {"text": "For clarity only some of the nodes have been shown and classes are labelled with some of the synonyms belonging to that class in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.9681481719017029}]}, {"text": "In order to obtain the ATCMs \"tree cut models\" (TCMs) for the target slot, irrespective of verb are obtained.", "labels": [], "entities": []}, {"text": "A TCM is similar to an ATCM except that the scores associated with each class on the cut are probabilities and should sum to 1.", "labels": [], "entities": []}, {"text": "The TCMs obtained fora given slot with and without WSD were similar.", "labels": [], "entities": [{"text": "WSD", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.7029598951339722}]}, {"text": "In contrast ATCMs are produced with a small data set specific to the target verb.", "labels": [], "entities": []}, {"text": "The verbs in our target set having between 32 ('clean') and 2176 ('make') instances.", "labels": [], "entities": []}, {"text": "Because of this the noise from erroneous senses is not as easily filtered and WSD does seem to make a difference although this depends on the verb and the degree of polysemy of the most common arguments.", "labels": [], "entities": [{"text": "WSD", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.69040447473526}]}, {"text": "\"Eat\" is a verb which selects strongly for its ob-.", "labels": [], "entities": []}, {"text": "The ATCMs are similar but WSD gives slightly stronger scores to the appropriate nodes.", "labels": [], "entities": [{"text": "ATCMs", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.562050461769104}, {"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.4974074065685272}]}, {"text": "Additionally the NATURAL OBJECT class changes from a slight preference in the ATCM without WSD to a score below 1 (indicating no evidence fora preference) with WSD.", "labels": [], "entities": [{"text": "NATURAL OBJECT class", "start_pos": 17, "end_pos": 37, "type": "METRIC", "confidence": 0.7012515266736349}, {"text": "ATCM", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.4635763168334961}, {"text": "WSD", "start_pos": 160, "end_pos": 163, "type": "DATASET", "confidence": 0.7579576969146729}]}, {"text": "WSD appears to slightly improve the preferences acquired but the difference is small.", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.32247552275657654}]}, {"text": "The reasons are that there is a predominant sense of \"eat\" which selects strongly for its direct object and many of the heads in the data were monosemous (e.g. food, sandwich and pretzel).", "labels": [], "entities": []}, {"text": "In contrast \"establish\" only has 79 instances and without any WSD the ATCM consists of the root node with a score of 1.8.", "labels": [], "entities": [{"text": "ATCM", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.8518776893615723}]}, {"text": "This shows that without WSD the variety of erroneous senses causes gross over-generalisation when compared to the cut with WSD as pictured in.", "labels": [], "entities": [{"text": "WSD", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.7827842235565186}]}, {"text": "There are cases where the WSD is faulty and many heads are not covered by the criteria outlined in experiment 1.", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.7824745774269104}]}, {"text": "The head \"right\" for example contributes to a higher association score at the LOCATION node though its correct sense really falls under the ABSTRACTION node.", "labels": [], "entities": [{"text": "association score", "start_pos": 53, "end_pos": 70, "type": "METRIC", "confidence": 0.9573327302932739}, {"text": "ABSTRACTION node", "start_pos": 140, "end_pos": 156, "type": "DATASET", "confidence": 0.6471642404794693}]}, {"text": "However even with these inadequacies the cut with WSD appears to provide a reasonable set of preferences as opposed to the cut at the root node which is uninformative.", "labels": [], "entities": [{"text": "WSD", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.7526552677154541}]}, {"text": "There was no distinction of verb senses for the preferences acquired and the data and ATCM for \"serve\" highlights this.", "labels": [], "entities": [{"text": "ATCM", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9892963767051697}]}, {"text": "\"Serve\" has a number of senses including the sense of \"meet the needs of\" or \"set food on the table\" or \"undergo a due period'.", "labels": [], "entities": [{"text": "Serve\"", "start_pos": 1, "end_pos": 7, "type": "TASK", "confidence": 0.9434483647346497}]}, {"text": "The heads indirect object position could on the whole be identified as belonging to one or other of these senses.", "labels": [], "entities": []}, {"text": "The ATCM with WSD is illustrated in The GROUP, RELATION and MENTAL OBJECT nodes relate to the first sense, the SUB-STANCE to the second and the third sense to the STATE and RELATION nodes.", "labels": [], "entities": [{"text": "GROUP", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9934638142585754}, {"text": "RELATION", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9540565609931946}, {"text": "MENTAL OBJECT", "start_pos": 60, "end_pos": 73, "type": "METRIC", "confidence": 0.7759602963924408}]}, {"text": "The ATCM without WSD was again an uninformative cut at the root.", "labels": [], "entities": [{"text": "ATCM", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.7698367834091187}]}, {"text": "Ideally preferences should be acquired respective to verb sense otherwise the preferences for the different predicates will be confused.", "labels": [], "entities": []}, {"text": "Although formal evaluation has as yet to be performed the models examined so far with the crude WSD seem to improve on those without.", "labels": [], "entities": [{"text": "WSD", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.7135104537010193}]}, {"text": "This is especially so in cases of sparse data.", "labels": [], "entities": []}, {"text": "Some errors were due to the parser.", "labels": [], "entities": [{"text": "errors", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9598327279090881}]}, {"text": "For example time adverbials such as \"the night before\" were mistaken as direct objects when the parser failed to identify the passive as in :-\"...", "labels": [], "entities": []}, {"text": "presented a lamb, killed the night before\".", "labels": [], "entities": []}, {"text": "Errors also arose because collocations such as \"post office\" were not recognised~as such.", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9224692583084106}]}, {"text": "Despite these errors the advantages Of using automatic parsing are significant in terms of the quantity of data thereby made available and portability to new domains.", "labels": [], "entities": [{"text": "parsing", "start_pos": 55, "end_pos": 62, "type": "TASK", "confidence": 0.8162118196487427}]}, {"text": "In experiment 5 cuts obtained in experiment 3, without any initial WSD, are used to disambiguate the heads before these are then fed back in.", "labels": [], "entities": [{"text": "WSD", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.606151819229126}]}, {"text": "In contrast experiment 6 uses the cuts obtained with Wilks and Stevenson style WSD from experiment 4 to disambiguate the heads.", "labels": [], "entities": []}, {"text": "In both cases the cuts are only used to disambiguate the heads appearing with the target verb and the full data sample required for the prior distribution TCM is left as in experiments 3 and 4.", "labels": [], "entities": [{"text": "TCM", "start_pos": 155, "end_pos": 158, "type": "METRIC", "confidence": 0.8326543569564819}]}, {"text": "Where the verb selects strongly for its arguments, for example \"eat\", the cuts obtained in experiments 5 and 6 were similar to those achieved with initial Wilks and Stevenson WSD, for example both have the effect of taking the class NATURAL OBJECT below 1 (i.e. removing the weak indication of a preference).", "labels": [], "entities": [{"text": "NATURAL", "start_pos": 233, "end_pos": 240, "type": "METRIC", "confidence": 0.8384772539138794}, {"text": "OBJECT", "start_pos": 241, "end_pos": 247, "type": "METRIC", "confidence": 0.5190197825431824}]}, {"text": "In contrast where the quantity of data is sparse and the verb selects less strongly the cut obtained from fully ambiguous data (experiment 5) is unhelpful for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 159, "end_pos": 162, "type": "TASK", "confidence": 0.8096567988395691}]}, {"text": "However if the Wilks and Stevenson style disambiguation is performed on the initial data the cuts in experiment 6 show great improvement on those from experiment 4.", "labels": [], "entities": []}, {"text": "For example the ATCM in experiment 6 for \"establish\" showed no preferences for the LOCATION and POSSESSION nodes where preferences in experiment 4 had arisen because of erroneous word senses.", "labels": [], "entities": [{"text": "ATCM", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.8502341508865356}]}], "tableCaptions": [{"text": " Table 1: Threshold 5 ratio 2", "labels": [], "entities": [{"text": "Threshold", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9876652956008911}]}, {"text": " Table 2: Variation of thresholds on the LOB data", "labels": [], "entities": [{"text": "Variation of thresholds", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.7949612339337667}, {"text": "LOB data", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.7835122644901276}]}]}