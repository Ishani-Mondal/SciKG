{"title": [{"text": "A. Linear Observed Time Statistical Parser Based on Maximum Entropy Models", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a statistical parser for natural language that obtains a parsing accuracy-roughly 87% precision and 86% recall-which surpasses the best previously published results on the Wall St. Journal domain.", "labels": [], "entities": [{"text": "accuracy-roughly", "start_pos": 85, "end_pos": 101, "type": "METRIC", "confidence": 0.9097707867622375}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.7115204334259033}, {"text": "recall-which", "start_pos": 124, "end_pos": 136, "type": "METRIC", "confidence": 0.9963498115539551}, {"text": "Wall St. Journal domain", "start_pos": 192, "end_pos": 215, "type": "DATASET", "confidence": 0.9898193627595901}]}, {"text": "The parser itself requires very little human intervention, since the information it uses to make parsing decisions is specified in a concise and simple manner, and is combined in a fully automatic way under the maximum entropy framework.", "labels": [], "entities": []}, {"text": "The observed running time of the parser on a test sentence is linear with respect to the sentence length.", "labels": [], "entities": []}, {"text": "Furthermore, the parser returns several scored parses fora sentence, and this paper shows that a scheme to pick the best parse from the 20 highest scoring parses could yield a dramatically higher accuracy of 93% precision and recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 196, "end_pos": 204, "type": "METRIC", "confidence": 0.9988493919372559}, {"text": "precision", "start_pos": 212, "end_pos": 221, "type": "METRIC", "confidence": 0.9994780421257019}, {"text": "recall", "start_pos": 226, "end_pos": 232, "type": "METRIC", "confidence": 0.9984228610992432}]}], "introductionContent": [{"text": "This paper presents a statistical parser for natural language that finds one or more scored syntactic parse trees fora given input sentence.", "labels": [], "entities": []}, {"text": "The parsing accuracy--roughly 87% precision and 86% recall--surpasses the best previously published results on the Wall St. Journal domain.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9642394185066223}, {"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9703050255775452}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9984361529350281}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9986649751663208}, {"text": "Wall St. Journal domain", "start_pos": 115, "end_pos": 138, "type": "DATASET", "confidence": 0.9917407184839249}]}, {"text": "The parser consists of the following three conceptually distinct parts: 1.", "labels": [], "entities": []}, {"text": "h set of procedures that use certain actions to incrementally construct parse trees.", "labels": [], "entities": []}, {"text": "2. A set of maximum entropy models that compute probabilities of the above actions, and effectively \"score\" parse trees.", "labels": [], "entities": []}, {"text": "* The author acknowledges the support of AI:tPA grant N66001-94C-6043.", "labels": [], "entities": [{"text": "tPA grant N66001-94C-6043", "start_pos": 44, "end_pos": 69, "type": "DATASET", "confidence": 0.8057297865549723}]}, {"text": "3. A search heuristic which attempts to find the highest scoring parse tree fora given input sentence.", "labels": [], "entities": []}, {"text": "The maximum entropy models used here are similar inform to those in).", "labels": [], "entities": []}, {"text": "The models compute the probabilities of actions based on certain syntactic characteristics, or features, of the current context.", "labels": [], "entities": []}, {"text": "The features used here are defined in a concise and simple manner, and their relative importance is determined automatically by applying a training procedure on a corpus of syntactically annotated sentences, such as the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 220, "end_pos": 233, "type": "DATASET", "confidence": 0.9940379858016968}]}, {"text": "Although creating the annotated corpus requires much linguistic expertise, creating the feature set for the parser itself requires very little linguistic effort.", "labels": [], "entities": []}, {"text": "Also, the search heuristic is very simple, and its observed running time on a test sentence is linear with respect to the sentence length.", "labels": [], "entities": []}, {"text": "Furthermore, the search heuristic returns several scored parses for -a sentence, and this paper shows that a scheme to pick the best parse from the 20 highest scoring parses could yield a dramatically higher accuracy of 93% precision and recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9985349178314209}, {"text": "precision", "start_pos": 224, "end_pos": 233, "type": "METRIC", "confidence": 0.9994263648986816}, {"text": "recall", "start_pos": 238, "end_pos": 244, "type": "METRIC", "confidence": 0.9981346130371094}]}, {"text": "Sections 2, 3, and 4 describe the tree-building procedures, the maximum entropy models, and the search heuristic, respectively.", "labels": [], "entities": []}, {"text": "Section 5 describes experiments with the Penn Treebank and section 6 compares this paper with previously published works.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9930912852287292}]}], "datasetContent": [{"text": "The maximum entropy parser was trained on sections 2 through 21 (roughly 40000 sentences) of the Penn Treebank Wall St. Journal corpus, release 2, and tested on section 23 (2416 sentences) for comparison with other work.", "labels": [], "entities": [{"text": "Penn Treebank Wall St. Journal corpus", "start_pos": 97, "end_pos": 134, "type": "DATASET", "confidence": 0.9726588129997253}]}, {"text": "All trees were stripped of their semantic tags (e.g., -LOC, -BNF, etc.), coreference information(e.g., *-1), and quotation marks (\" and ' ' ) for both training and testing.", "labels": [], "entities": [{"text": "BNF", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9075440764427185}]}, {"text": "The PAR-SEVAL (Black and others, 1991) measures compare a proposed parse P with the corresponding correct treebank parse T as follows: # correct constituents in P Recall = # constituents in T # correct constituents in P Precision = # constituents in PA constituent in P is \"correct\" if there exists a constituent in T of the same label that spans the same words.", "labels": [], "entities": [{"text": "Recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9599394202232361}]}, {"text": "shows results using the PARSEVAL measures, as well as results using the slightly more forgiving measures of and).", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.94623863697052}]}, {"text": "shows that the maximum entropy parser performs better than the parsers presented in and) ~, which have the best previously published parsing accuracies on the Wall St. Journal domain.", "labels": [], "entities": [{"text": "Wall St. Journal domain", "start_pos": 159, "end_pos": 182, "type": "DATASET", "confidence": 0.9913573265075684}]}, {"text": "It is often advantageous to produce the top N parses instead of just the top 1, since additional information can be used in a secondary model that reorders the top N and hopefully improves the quality of the top ranked parse.", "labels": [], "entities": []}, {"text": "Suppose there exists a \"perfect\" reranking scheme that, for each sentence, magically picks the best parse from the top N parses produced by the maximum entropy parser, where the best parse has the highest average precision and recall when compared to the treebank parse.", "labels": [], "entities": [{"text": "precision", "start_pos": 213, "end_pos": 222, "type": "METRIC", "confidence": 0.9897240400314331}, {"text": "recall", "start_pos": 227, "end_pos": 233, "type": "METRIC", "confidence": 0.9995966553688049}]}, {"text": "The performance of this \"perfect\" scheme is then an upper bound on the performance of any reranking scheme that might be used to reorder the top N parses.", "labels": [], "entities": []}, {"text": "shows that the \"perfect\" scheme would achieve roughly 93% precision and recall, which is a dramatic increase over the top 1 accuracy of 87% precision and 86% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9996911287307739}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9996786117553711}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9884495735168457}, {"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9981756210327148}, {"text": "recall", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.9971900582313538}]}, {"text": "shows that the \"Exact Match\", which counts the percentage of times 2Results for SPATTER on section 23 are reported in  the proposed parse P is identical (excluding POS tags) to the treebank parse T, rises substantially to about 53% from 30% when the \"perfect\" scheme is applied.", "labels": [], "entities": [{"text": "Exact Match\"", "start_pos": 16, "end_pos": 28, "type": "METRIC", "confidence": 0.9851170778274536}]}, {"text": "For this reason, research into reranking schemes appears to be a promising step towards the goal of improving parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.9824554920196533}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9270422458648682}]}], "tableCaptions": []}