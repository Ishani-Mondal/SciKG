{"title": [{"text": "Factors in anaphora resolution: they are not the only things that matter. A case study based on two different approaches", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8157888650894165}]}], "abstractContent": [{"text": "The paper discusses the significance of factors in anaphora resolution and on the basis of a comparative study argues that what matters is not only a good set of reliable factors but also the strategy for their application.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.9411011338233948}]}, {"text": "The objective of the study was to find out how well the same set of factors worked within two different computational strategies.", "labels": [], "entities": []}, {"text": "To this end, we tuned two anaphora resolution approaches to use the same core set of factors.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7260028719902039}]}, {"text": "The first approach uses constraints to discount implausible candidates and then consults preferences to rank order the most likely candidate.", "labels": [], "entities": []}, {"text": "The second employs only preferences and does not discard any candidate but assumes initially that the candidate examined is the antecedent; on the basis of uncertainty reasoning formula this hypothesis is either rejected or accepted.", "labels": [], "entities": []}, {"text": "The last section of the paper addresses some related unresolved issues which need further research.", "labels": [], "entities": []}, {"text": "I. Approaches and factors in anaphora resolution Approaches to anaphora resolution usually rely on a set of \"anaphora resolution factors\".", "labels": [], "entities": [{"text": "Approaches", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.9860250353813171}, {"text": "anaphora resolution", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7021716386079788}, {"text": "anaphora resolution", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.6770892590284348}]}, {"text": "Factors used frequently in the resolution process include gender and number agreement, c-command constraints, semantic consistency, syntactic parallelism, semantic parallelism, salience, proximity etc.", "labels": [], "entities": [{"text": "resolution process", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9116165339946747}]}, {"text": "These factors can be \"eliminating\" i.e. discounting certain noun phrases from the set of possible candidates (such as gender and number constraints, c-command constraints, semantic consistency) or \"preferential\", giving more preference to certain candidates and less to others (such as parallelism, salience).", "labels": [], "entities": []}, {"text": "Computational linguistics literature uses diverse terminology for these-for example E.", "labels": [], "entities": []}, {"text": "Rich and S. LuperFoy ([Rich & LuperFoy 88]) refer to the \"eliminating\" factors as \"constraints\", and to the preferential ones as \"proposers\", whereas Carbonell and Brown ([Carbonell & Brown 88] use the terms \"constraints\" and \"preferences\".", "labels": [], "entities": []}, {"text": "Other authors argue that all factors should be regarded as preferential, giving higher preference to more restrictive factors and lower-to less \"absolute\" ones, calling them simply \"factors\" ([PreuB et al.", "labels": [], "entities": []}, {"text": "94]), \"attributes\" ([P6rez 94]) or \"symptoms\" ([Mitkov 95]).", "labels": [], "entities": []}, {"text": "The impact of different factors and/or their coordination have already been described in the literature (e.g. [Carter 90], [Dagan et al. 91]).", "labels": [], "entities": [{"text": "Carter 90]", "start_pos": 111, "end_pos": 121, "type": "DATASET", "confidence": 0.9214801788330078}]}, {"text": "In his work David Carter argues that a flexible control structure based on numerical scores assigned to preferences allows greater cooperation between factors as opposed to a more limited depth-first architecture.", "labels": [], "entities": []}, {"text": "His discussion is grounded in comparisons between two different implemented systems -SPAR ([Carter 87]) and the SRI Core Language Engine ([Alshawi 90]).", "labels": [], "entities": [{"text": "SPAR ([Carter 87])", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.8545015931129456}, {"text": "SRI Core Language Engine ([Alshawi 90])", "start_pos": 112, "end_pos": 151, "type": "DATASET", "confidence": 0.8882460296154022}]}, {"text": "I. Dagan, J. Just-eson, Sh.", "labels": [], "entities": []}, {"text": "Lappin, H. Leass and A. Ribak ([Dagan et al. 91] attempt to determine the relative importance of distinct informational factors by comparing a syntactically-based salience algorithm for pronominal anaphora resolution (RAP) ([Lappin & Leass 94]) with a procedure for reevaluating the decisions of the algorithm on the basis of statistically modelled lexical semantic/pragmatic preferences ([Dagan 92]).", "labels": [], "entities": [{"text": "pronominal anaphora resolution (RAP", "start_pos": 186, "end_pos": 221, "type": "TASK", "confidence": 0.7018491208553315}]}, {"text": "Their results suggest that syntactically measured salience preferences are dominant in anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7506579756736755}]}, {"text": "While a number of approaches use a similar set of factors, the \"computational strategies\" for the application of these factors may differ (by \"computational strategy\" we mean here the way antecedents are computed, tracked down, i.e. the algorithm, formula for assigning antecedents and not computational issues related to programming languages, complexity etc.).", "labels": [], "entities": []}, {"text": "Some approaches incorporate a traditional model which discounts unlikely candidates until a minimal set of plausible candidates is obtained (then make use of center or focus, for instance), whereas others compute the most likely candidate on the basis of statistical or AI techniques/models.", "labels": [], "entities": []}, {"text": "This observation led us to term the approaches to anaphora resolution \"traditional knowledge-based\" and \"alternative\" 14", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The evaluation was conducted on the basis of a manually annotated test corpus from the sublanguage of Computer Science.", "labels": [], "entities": []}, {"text": "We selected 133 paragraphs containing the anaphor \"it\" (altogether 512 occurrences of \"it\") and tested both approaches tuned to activate only the core set of factors described.", "labels": [], "entities": []}, {"text": "Our preliminary results showed a success rate of 83% for the IR as opposed to 82% for the URA with CFthreshol d 0.7.", "labels": [], "entities": [{"text": "IR", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.4289824664592743}, {"text": "URA", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.7682331800460815}, {"text": "CFthreshol d 0.7", "start_pos": 99, "end_pos": 115, "type": "METRIC", "confidence": 0.897334893544515}]}, {"text": "Out of the 17% uncorrectly solved anaphors by the IR, 5% were solved correctly by the URA.", "labels": [], "entities": [{"text": "IR", "start_pos": 50, "end_pos": 52, "type": "DATASET", "confidence": 0.697830319404602}, {"text": "URA", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.8856610655784607}]}, {"text": "Out of the 18% uncorrectly solved anaphors by the URA, 4% were solved correctly by the IR.", "labels": [], "entities": [{"text": "URA", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.8850665092468262}, {"text": "IR", "start_pos": 87, "end_pos": 89, "type": "DATASET", "confidence": 0.770494282245636}]}, {"text": "With a higher threshold of 0.8, however, the URA went down to a level of accuracy of 71%.", "labels": [], "entities": [{"text": "URA", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9400282502174377}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9997032284736633}]}, {"text": "The lower success rates (as compared to) are due to the fact that both approaches are restricted to the \"core set of factors\" and thus cannot draw on others which they would normally have at their disposal (e.g. ccommand constraints were not included in the experimental core set).", "labels": [], "entities": []}, {"text": "In particular, when the number of symptoms is reduced, the URA cannot benefit from all its sources of evidence and thus high thresholds cannot realistically be reached.", "labels": [], "entities": [{"text": "URA", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.7860743999481201}]}], "tableCaptions": []}