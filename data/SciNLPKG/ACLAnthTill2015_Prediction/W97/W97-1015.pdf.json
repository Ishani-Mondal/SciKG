{"title": [{"text": "A Comparative Study of the Application of Different Learning Techniques to Natural Language Interfaces", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present first results from a comparative study.", "labels": [], "entities": []}, {"text": "Its aim is to test the feasibility of different inductive learning techniques to perform the automatic acquisition of linguistic knowledge within a natural language database interface.", "labels": [], "entities": []}, {"text": "In our interface architecture the machine learning module replaces an elaborate semantic analysis component.", "labels": [], "entities": []}, {"text": "The learning module learns the correct mapping of a user's input to the corresponding database command based on a collection of past input data.", "labels": [], "entities": []}, {"text": "We use an existing interface to a production planning and control system as evaluation and compare the results achieved by different instance-based and model-based learning algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the main obstacles to the efficient use of natural language interfaces is the often required high amount of manual knowledge engineering (see) fora recent survey).", "labels": [], "entities": []}, {"text": "This time-consuming and tedious process is often referred to as \"knowledge acquisition bottleneck\".", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.8381692469120026}]}, {"text": "It may require extensive efforts by experts highly experienced in linguistics as well as in the domain and the task (.", "labels": [], "entities": []}, {"text": "Therefore, natural language interfaces represent a domain that is very well suited for the application of machine learning algorithms to automate the acquisition process of linguistic knowledge.", "labels": [], "entities": []}, {"text": "So far, inductive learning has already been applied successfully to a large variety of natural Janguage tasks.", "labels": [], "entities": []}, {"text": "This includes basic linguistic problems such as morphological analysis (van den, parsing, word sense disambiguation, and anaphora resolution (.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7451981604099274}, {"text": "word sense disambiguation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.6611969868342081}, {"text": "anaphora resolution", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.7097778022289276}]}, {"text": "Besides this, there also exists some research on applications, e.g. machine translation (), text categorization (, or information extraction (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8252619504928589}, {"text": "text categorization", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8355922698974609}, {"text": "information extraction", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.8471950888633728}]}, {"text": "The learning task in natural language interfaces is to select the correct command class based on semantic features extracted from the user input.", "labels": [], "entities": []}, {"text": "Therefore, it can be modeled as classification problem, i.e. the machine learning algorithms construct a theory from the training data that is used for classifying unseen test data.", "labels": [], "entities": []}, {"text": "So far, we consider only supervised learning so that each training case has to be labeled with the correct class.", "labels": [], "entities": []}, {"text": "We apply different existing instance-based and model-based algorithms to this problem and compare the achieved results.", "labels": [], "entities": []}, {"text": "In addition, we have also developed several new algorithms, which we present briefly in this paper.", "labels": [], "entities": []}, {"text": "We have implemented all algorithms by means of the deductive objectoriented database system ROCK ~ ROLL.", "labels": [], "entities": [{"text": "ROLL", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9414120316505432}]}, {"text": "It solves the problem of updates in deductive databases in that it separates the declarative logic query language ROLL from the imperative data manipulation language ROCK within the context of a common object-oriented data model.", "labels": [], "entities": []}, {"text": "Besides this, ROCK ~ ROLL makes a clean distinction between type declarations, which describe the structural characteristics of a set of instance objects and the methods that can be applied to them, and class definitions, which specify the implementation of the methods associated with a type.", "labels": [], "entities": [{"text": "ROLL", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.8868388533592224}]}, {"text": "The use of the available powerful logic and objectoriented programming language enables an efficient implementation of the different approaches to machine learning.", "labels": [], "entities": []}, {"text": "It also gives us a convenient integrated tool that assists in applying the machine learning algorithms to the data collection stored in the same database.", "labels": [], "entities": []}], "datasetContent": [{"text": "As case study for investigating the feasibility of the implemented machine learning algorithms, we use a multilinguM natura ! language interface to a production planning and control system (PPC).", "labels": [], "entities": []}, {"text": "The PPC performs the mean-term scheduling of products and resources involved in the manufacturing processes, i.e. material, machines, and labor.", "labels": [], "entities": []}, {"text": "The resulting master production schedule forms the basis of the coordination of related business services such as engineering, manufacturing, and finance.", "labels": [], "entities": []}, {"text": "The modeled enterprise makes precision tools by using job order production and serial manufacture as basic strategies.", "labels": [], "entities": []}, {"text": "The efficient realization of the high demands of the application exceeds the power of relational database technology.", "labels": [], "entities": []}, {"text": "Therefore, it represents an excellent choice for deriving full advantage of the extended functionality of deductive object-oriented database systems, i Furthermore, the sophisticated functionality justifies the effective use of a natural language interface.", "labels": [], "entities": []}, {"text": "During previous research we developed a German natural language interface based on 1000 input sentences that had been collected from users by means of questionnaires.", "labels": [], "entities": []}, {"text": "The input sentences were then mapped to 100 command classes (10 for each class).", "labels": [], "entities": []}, {"text": "The mapping was performed by elaborate semantic analysis; for the development of the underlying rule base we spent several man-months.", "labels": [], "entities": []}, {"text": "Therefore, we were eager to see if we could replace this extensive effort by a machine learning component that learns the same linguistic knowledge automatically.", "labels": [], "entities": []}, {"text": "For this purpose we divided the 1000 sentences into 900 training cases and 100 test cases.", "labels": [], "entities": []}, {"text": "In addition, we collected 100 Japanese and 100 English test sentences to check whether the learned knowledge really operates at a semantic level independent from language-specific phenomena.", "labels": [], "entities": []}, {"text": "As result of the encoding of the training set (see Sect.", "labels": [], "entities": []}, {"text": "2), we obtained the large number of 316 features, 289 for the DFL and 27 for the UVL.", "labels": [], "entities": [{"text": "DFL", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8830966949462891}, {"text": "UVL", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.9214024543762207}]}, {"text": "For the evaluation of the different machine learning algorithms we used as performance measures the success rate, i.e. the proportion of correctly classified test cases, and the top-3 rate.", "labels": [], "entities": []}, {"text": "The latter indicates the proportion of cases where the correct classification is among the first three predicted classes.", "labels": [], "entities": []}, {"text": "For the case of model-based approaches we had to produce additional candidates for classes.", "labels": [], "entities": []}, {"text": "This was achieved by applying approximate methods that allow one incorrect edge along the traversal of decision trees or one divergent literal for the test of rules (see Sect. 3).", "labels": [], "entities": []}, {"text": "Our first experiment was the comparison of the four instance-based algorithms IB1, IBi-IG, BIN-CAT, and BIN-PRO.", "labels": [], "entities": [{"text": "BIN-CAT", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.9650928378105164}, {"text": "BIN-PRO", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.8289913535118103}]}, {"text": "As can be seen from the results in, BIN-CAT clearly outperforms IB1 and IBi-IG.", "labels": [], "entities": [{"text": "BIN-CAT", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9975038170814514}, {"text": "IB1", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.5706197023391724}]}, {"text": "Concerning the method BIN-PRO, which uses prototypes of classes, we achieved results at the same quality level as for BIN-CAT.", "labels": [], "entities": [{"text": "BIN-PRO", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.5083563327789307}, {"text": "BIN-CAT", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.7629626989364624}]}, {"text": "This is remarkable if one considers the much more condensed representation of the learned knowledge.", "labels": [], "entities": []}, {"text": "The comparison between the results for the individual languages shows that there is no advantage for the German test sentences.", "labels": [], "entities": [{"text": "German test sentences", "start_pos": 105, "end_pos": 126, "type": "DATASET", "confidence": 0.8686012625694275}]}, {"text": "On the contrary, the test results for German are inferior to that for English or Japanese.", "labels": [], "entities": []}, {"text": "This maybe partly due to a greater deviation of the German expressions and phrases used in the test set from the ones used in the training set.", "labels": [], "entities": []}, {"text": "Besides this, the restriction of extracted features during encoding the test set to those learned from the training set certainly performs an important filtering function.", "labels": [], "entities": []}, {"text": "It removes languagespecific syntactic particles that do not contribute to the meaning Of the input.", "labels": [], "entities": []}, {"text": "This is especially true for the case of Japanese sentences, which possess a  completely different syntactic structure in comparison with English or German including many particles with no equivalent words in the other two languages.", "labels": [], "entities": []}, {"text": "The second part of the evaluation was the comparison of the four algorithms for building decision trees: IGTree, BS-tree, C4.5, and BD-tree.", "labels": [], "entities": [{"text": "IGTree", "start_pos": 105, "end_pos": 111, "type": "DATASET", "confidence": 0.647206723690033}, {"text": "BD-tree", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.7037600874900818}]}, {"text": "Besides this, we also included the SE-tree constructed by a hybrid approach (see Sect. 3).", "labels": [], "entities": []}, {"text": "The test results in indicate that the trees with dynamic splitting are superior to those with static splitting and that C4.5, BD-tree, and SE-tree produce results of similar quality.", "labels": [], "entities": [{"text": "BD-tree", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.8399829268455505}]}, {"text": "compares the number of nodes, leaves, and levels for the individual trees.", "labels": [], "entities": []}, {"text": "The two trees with dynamic splitting are much more compact than those with static splitting, with C4.5 clearly outperforming BD-tree.", "labels": [], "entities": []}, {"text": "Finally, the hybrid SE-tree is much flatter than C4.5 but possesses a larger number of nodes and leaves.", "labels": [], "entities": []}, {"text": "As last part of our comparative study we tested the rule-based techniques FOIL, BIN-rules, and the hybrid approach C4.5-RULES.", "labels": [], "entities": [{"text": "FOIL", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9804394841194153}, {"text": "BIN-rules", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9970830082893372}]}, {"text": "As shows, FOIL produces the most compact representation of learned knowledge, followed by C4.5-RULES and BIN-rules.", "labels": [], "entities": [{"text": "FOIL", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.704879105091095}, {"text": "BIN-rules", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9908549785614014}]}, {"text": "However, according to  An advantage of rule-based learning in comparison with other methods is that the learned knowledge can be easily presented to the user in a clear and understandable form.", "labels": [], "entities": []}, {"text": "The derived rules allow a transparent knowledge representation that one can use for explaining decisions of the system to the user.", "labels": [], "entities": []}, {"text": "gives some examples of rule sets learned by BIN-rules for several command classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test results for instance-based learning", "labels": [], "entities": []}, {"text": " Table 2: Test results for decision trees", "labels": [], "entities": []}, {"text": " Table 3: Characteristics for decision trees", "labels": [], "entities": []}, {"text": " Table 5: Test results for rule-based learning", "labels": [], "entities": []}]}