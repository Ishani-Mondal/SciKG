{"title": [{"text": "What makes a word: Learning base units in Japanese for speech recognition", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7233908474445343}]}], "abstractContent": [{"text": "We describe an automatic process for learning word units in Japanese.", "labels": [], "entities": []}, {"text": "Since the Japanese orthography has no spaces delimiting words, the first step in building a Japanese speech recognition system is to define the units that will be recognized.", "labels": [], "entities": [{"text": "Japanese speech recognition", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.5992719133694967}]}, {"text": "Our method applies a compound-finding algorithm, previously used to find word sequences in English, to learning syllable sequences in Japanese.", "labels": [], "entities": []}, {"text": "We report that we were able not only to extract meaningful units, eliminating the need for possibly inconsistent manual segmentation, but also to decrease perplexity using this automatic procedure, which relies on a statistical, not syntactic, measure of relevance.", "labels": [], "entities": []}, {"text": "Our algorithm also uncovers the kinds of environments that help the recognizer predict phonological alternations, which are often hidden by morphologically-motivated tok-enization.", "labels": [], "entities": []}], "introductionContent": [{"text": "What defines a word when there are no spaces in a written language?", "labels": [], "entities": []}, {"text": "Words, as they are known in English and other western languages, are the basic units of recognition inmost CSR systems, but when a language is written as a string of characters with no white space, how does one go about specifying the fundamental units that must be recognized?", "labels": [], "entities": []}, {"text": "Mapping onto English-style words is one solution, but an artificial one, and may hide natural characteristics of Japanese that can be important in recognition.", "labels": [], "entities": [{"text": "Mapping onto English-style words", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8878905922174454}]}, {"text": "Recognizing phonemes, or short phoneme clusters, is another option, but recognition accuracy can improve when we have longer phoneme strings to work with; acoustic confusability decreases and along word is a more useful predictor of subsequent words than a single syllable.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9679363965988159}]}, {"text": "Automatic segmenting tools eliminate an often inconsistent manual segmentation step, but are generally based on morphological analysis, which can produce units smaller than are desirable for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 191, "end_pos": 209, "type": "TASK", "confidence": 0.7385136485099792}]}, {"text": "Certainly, there exist words as can be looked up in a dictionary, but when a language is as heavily inflected as Japanese is, that only solves part of the problem.", "labels": [], "entities": []}, {"text": "In this paper we describe an automatic process for learning base units in Japanese and discuss its usefulness for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.88111412525177}]}], "datasetContent": [{"text": "Since the phrase-finding algorithm described in 3.2 is designed to maximize bigram perplexity, the evaluations described here measure this criterion.", "labels": [], "entities": []}], "tableCaptions": []}