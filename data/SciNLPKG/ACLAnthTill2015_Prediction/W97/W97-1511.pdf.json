{"title": [{"text": "Exploiting Contextual Information in Hypothesis Selection for Grammar Refinement", "labels": [], "entities": [{"text": "Grammar Refinement", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7588283121585846}]}], "abstractContent": [{"text": "In this paper, we propose anew framework of grammar development and some techniques for exploiting contextual information in a process of grammar refinement.", "labels": [], "entities": [{"text": "grammar development", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7155893594026566}, {"text": "grammar refinement", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7333846092224121}]}, {"text": "The proposed framework involves two processes, partial grammar acquisition and grammar refinement.", "labels": [], "entities": [{"text": "partial grammar acquisition", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.6087571680545807}, {"text": "grammar refinement", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7327721416950226}]}, {"text": "In the former process, a rough grammar is constructed from a bracketed corpus.", "labels": [], "entities": []}, {"text": "The grammar is later refined by the latter process where a combination of rule-based and corpus-based approaches is applied.", "labels": [], "entities": []}, {"text": "Since there maybe more than one rules introduced as alternative hypotheses to recover the analysis of sentences which cannot be parsed by the current grammar, we propose a method to give priority to these hypotheses based on local contextual information.", "labels": [], "entities": []}, {"text": "By experiments , our hypothesis selection is evaluated and its effectiveness is shown.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the essential tasks to realize an efficient natural language processing system is to construct a broad-coverage and high-accurate grammar.", "labels": [], "entities": []}, {"text": "In most of the currently working systems, such grammars have been derived manually by linguists or lexicographers.", "labels": [], "entities": []}, {"text": "Unfortunately, this task requires time-consuming skilled effort and, inmost cases, the obtained grammars may not be completely satisfactory and frequently fail to cover many unseen sentences.", "labels": [], "entities": []}, {"text": "Toward these problems, there were several attempts developed for automatically learning grammars based on rule-based approach(, corpus-based approach or hybrid approach).", "labels": [], "entities": []}, {"text": "Unlike previous works, we have introduced anew framework for grammar development, which is a combination of rule-based and corpus-based approaches where contextual information can be exploited.", "labels": [], "entities": [{"text": "grammar development", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8057995140552521}]}, {"text": "In this framework, a whole grammar is not acquired from scratch or an initial grammar does not need to be assumed).", "labels": [], "entities": []}, {"text": "Instead, a rough but effective grammar is learned, in the first place, from a large corpus based on a corpus-based method and then later refined by the way of the combination of rulebased and corpus-based methods.", "labels": [], "entities": []}, {"text": "We call the former step of the framework partial grammar acquisition and the latter grammar refinement.", "labels": [], "entities": []}, {"text": "For the partial grammar acquisition, in our previous works, we have proposed a mechanism to acquire a partial grammar automatically from a bracketed corpus based on local contextual information and have shown the effectiveness of the derived grammar(Theeramunkong and Okumura, 1997).", "labels": [], "entities": [{"text": "partial grammar acquisition", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.6832396984100342}]}, {"text": "Through some preliminary experiments, we found out that it seems difficult to learn grammar rules which are seldom used in the corpus.", "labels": [], "entities": []}, {"text": "This causes by the fact that rarely used rules occupy too few events for us to catch their properties.", "labels": [], "entities": []}, {"text": "Therefore in the first step, only grammar rules with relatively high occurrence are first learned.", "labels": [], "entities": [{"text": "occurrence", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9877625703811646}]}, {"text": "In this paper, we focus on the second step, grammar refinement, where some new rules can be added to the current grammar in order to accept unparsable sentences.", "labels": [], "entities": [{"text": "grammar refinement", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7035370320081711}]}, {"text": "This task is achieved by two components: (1) the rule-based component, which detects incompleteness of the current grammar and generates a set of hypotheses of new rules and (2) the corpus-based component, which selects plausible hypotheses based on local contextual information.", "labels": [], "entities": []}, {"text": "In addition, this paper also describes a stochastic parsing model which finds the most likely parse of a sentence and then evaluates the hypothesis selection based on the plausible parse.", "labels": [], "entities": [{"text": "stochastic parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.722838968038559}]}, {"text": "In the rest, we give an explanation of our framework and then describe the grammar refinement process and hypothesis selection based on local contextual information.", "labels": [], "entities": []}, {"text": "Next, a stochastic parsing model which exploits contextual information is described.", "labels": [], "entities": []}, {"text": "Finally, the effectiveness of our approach is shown through some experiments investigating the correctness of selected hypotheses and parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 134, "end_pos": 141, "type": "TASK", "confidence": 0.9730726480484009}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9244051575660706}]}], "datasetContent": [{"text": "Some evaluation experiments and their results are described.", "labels": [], "entities": []}, {"text": "For the experiments, we use texts from the EDR corpus, where bracketings are given.", "labels": [], "entities": [{"text": "EDR corpus", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.9634487926959991}]}, {"text": "The subject is 48,100 sentences including around 510,000 words.", "labels": [], "entities": []}, {"text": "shows some example sentences in the EDR corpus (((ART,\" a\" )((ADJ ,\" large\" )(NOUN ,\"festival\" ))) ((VT,\"held\")(ADV,\"biennially\"))) ((AOV,\"again\")((PRON,\"he\")((VT,\"says\") ((P RON,\" he\")((A DV,\" completely\") ((VT,\"forgot\")((PaEe,\"about\") his\" )(NOUN,\" homework\" ))))))))): Some example sentences in the EDR corpus The initial grammar is acquired from the same corpus using divergence shown in section 2.1.", "labels": [], "entities": [{"text": "EDR corpus", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.8236699998378754}, {"text": "AOV", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9461283087730408}, {"text": "EDR corpus", "start_pos": 302, "end_pos": 312, "type": "DATASET", "confidence": 0.764671266078949}]}, {"text": "The number of rules is 272, the maximum length of rules is 4, and the numbers of terminal and nonterminal categories are 18 and 55 respectively.", "labels": [], "entities": []}, {"text": "A part of the initial grammar is enumerated in.", "labels": [], "entities": []}, {"text": "In the grammar, llnl is expected to be noun phrase with an article, lln2 is expected to be noun phrase without an article, and iln3 is expected to be verb phrase.", "labels": [], "entities": []}, {"text": "Moreover, among 48,100 sentences, 5,083 sentences cannot be parsed by the grammar.", "labels": [], "entities": []}, {"text": "We use these sentences for evaluating our hypothesis selection approach.", "labels": [], "entities": [{"text": "hypothesis selection", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7679035067558289}]}, {"text": "From 5,083 unparsable sentences, the hypothesis generator can produce some hypotheses for 4,730 sentences (93.1%).", "labels": [], "entities": []}, {"text": "After comparing them with the parses in the EDR corpus, the hypothesis sets of 3,127 sentences (61.5 %) include correct hypotheses.", "labels": [], "entities": [{"text": "EDR corpus", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.9610641598701477}]}, {"text": "Then we consider the sentences for which some correct hypotheses can be generated (i.e., 3,127 sentences) and evaluate our scoring function in selecting the most plausible hypothesis.", "labels": [], "entities": []}, {"text": "For each sentence, we rank the generated hypotheses by their preference score according to our scoring function.", "labels": [], "entities": []}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "From the table, even though only 12.3 % of the whole generated hypotheses are correct, our hypothesis selection can choose the correct hypothesis for 41.6 % of the whole sentences when the most plausible hypothesis is selected for each sentence.", "labels": [], "entities": []}, {"text": "Moreover, 29.8 % of correct hypotheses are ordered at the ranks of 2-5, 24.3 % at the ranks of 6-10 and just only 6.2 % at the ranks of more than 50.", "labels": [], "entities": []}, {"text": "This indicates that the hypothesis selection is influential for placing the correct hypotheses at the higher ranks.", "labels": [], "entities": []}, {"text": "However, when we consider the top 10 hypotheses, we found out that the accuracy is (1362+3368+3134)/(3217+11288+12846)= 28.8 %.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9995881915092468}]}, {"text": "This indicates that there area lot of hypotheses generated fora sentence.", "labels": [], "entities": []}, {"text": "This suggests us to consider the correct hypothesis for each sentence instead of all hypotheses.", "labels": [], "entities": []}, {"text": "In this section, we consider the accuracy of our hypothesis selection for each sentence.: Sentence Level Evaluation can getup to 2,623 (81.5%) accuracy when the top 10 of the ordered hypotheses are considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.999366819858551}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9985899329185486}]}, {"text": "The result shows that our hypothesis selection is effective enough to place the correct hypothesis at the higher ranks.", "labels": [], "entities": []}, {"text": "Another experiment is also done for evaluating the parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9791530966758728}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9069792032241821}]}, {"text": "The parsing model we consider here is one described in section 5.", "labels": [], "entities": []}, {"text": "The chart parser outputs the best parse of the sentence.", "labels": [], "entities": []}, {"text": "This parse is formed by using grammar rules and a single rule hypothesis.", "labels": [], "entities": []}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "In this evaluation, the PARSEVAL measures as defined in  From this result, we found out that the parser can succeed 57.3 % recall and 65.2 % precision for the short sentences (3-9 words).", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9958204030990601}, {"text": "recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9994244575500488}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9994378685951233}]}, {"text": "In this case, the averaged crossings are 1.87 per sentence and the number of sentences with less than 2 crossings is 69.2 % of the comparisons.", "labels": [], "entities": []}, {"text": "For long sentences not so much advantage is obtained.", "labels": [], "entities": []}, {"text": "However, our parser can achieve 51.4 % recall and 56.3 % precision for all unparsable sentences.", "labels": [], "entities": [{"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9994602799415588}, {"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9991483688354492}]}], "tableCaptions": [{"text": " Table 1: Hypothesis Level Evaluation", "labels": [], "entities": [{"text": "Hypothesis Level Evaluation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.759511391321818}]}]}