{"title": [{"text": "Getting Serious about Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.6604773998260498}]}], "abstractContent": [{"text": "Recent advances in large-scale, broad coverage part-of-speech tagging and syntactic parsing have been achieved in no small part due to the availability of large amounts of online, human-annotated corpora.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.6803120523691177}, {"text": "syntactic parsing", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7824094593524933}]}, {"text": "In this paper, I argue that a large, human sense-tagged corpus is also critical as well as necessary to achieve broad coverage, high accuracy word sense disambiguation, where the sense distinction is at the level of a good desk-top dictionary such as WORD-NET.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9820975661277771}, {"text": "word sense disambiguation", "start_pos": 142, "end_pos": 167, "type": "TASK", "confidence": 0.5643721620241801}]}, {"text": "Using the sense-tagged corpus of 192,800 word occurrences reported in (Ng and Lee, 1996), I examine the effect of the number of training examples on the accuracy of an exemplar-based classifier versus the base-line, most-frequent-sense classi-tier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9985275268554688}]}, {"text": "I also estimate the amount of human sense-tagged corpus and the manual annotation effort needed to build a large-scale, broad coverage word sense disambig-uation program which can significantly out-perform the most-frequent-sense classifier.", "labels": [], "entities": []}, {"text": "Finally, I suggest that intelligent example selection techniques may significantly reduce the amount of sense-tagged corpus needed and offer this research problem as a fruitful area for word sense disambiguation research.", "labels": [], "entities": [{"text": "word sense disambiguation research", "start_pos": 186, "end_pos": 220, "type": "TASK", "confidence": 0.8239375799894333}]}], "introductionContent": [{"text": "Much recent research in the field of natural language processing (NLP) has focused on an empirical, corpus-based approach.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.8253872295220693}]}, {"text": "The high accuracy achieved by a corpus-based approach to part-of-speech tagging and noun phrase parsing, as demonstrated by, has inspired similar approaches to other problems in natural language processing, including syntactic parsing and word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9989468455314636}, {"text": "part-of-speech tagging", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7298641800880432}, {"text": "noun phrase parsing", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.6679073969523112}, {"text": "syntactic parsing", "start_pos": 217, "end_pos": 234, "type": "TASK", "confidence": 0.7232215702533722}, {"text": "word sense disambiguation (WSD)", "start_pos": 239, "end_pos": 270, "type": "TASK", "confidence": 0.7656138837337494}]}, {"text": "The availability of large quantities of part-ofspeech tagged and syntactically parsed sentences like the Penn Treebank corpus has contributed greatly to the development of robust, broad coverage partof-speech taggers and syntactic parsers.", "labels": [], "entities": [{"text": "Penn Treebank corpus", "start_pos": 105, "end_pos": 125, "type": "DATASET", "confidence": 0.9935878912607828}]}, {"text": "The Penn Treebank corpus contains a sufficient number of partof-speech tagged and syntactically parsed sentences to serve as adequate training material for building broad coverage part-of-speech taggers and parsers.", "labels": [], "entities": [{"text": "Penn Treebank corpus", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.9943058093388876}, {"text": "partof-speech tagged and syntactically parsed sentences", "start_pos": 57, "end_pos": 112, "type": "TASK", "confidence": 0.7343959907690684}]}, {"text": "Unfortunately, an analogous sense-tagged corpus large enough to achieve broad coverage, high accuracy word sense disambiguation is not available at present.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9649640321731567}, {"text": "word sense disambiguation", "start_pos": 102, "end_pos": 127, "type": "TASK", "confidence": 0.5796613494555155}]}, {"text": "In this paper, I argue that, given the current state-of-the-art capability of automated machine learning algorithms, a supervised learning approach using a large sense-tagged corpus is a viable way to build a robust, wide coverage, and high accuracy WSD program.", "labels": [], "entities": [{"text": "WSD", "start_pos": 250, "end_pos": 253, "type": "TASK", "confidence": 0.9232210516929626}]}, {"text": "In this view, a large sense-tagged corpus is critical as well as necessary to achieve broad coverage, high accuracy WSD.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9724048376083374}, {"text": "WSD", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.3919528126716614}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, I briefly discuss the utility of WSD in practical NLP tasks like information retrieval and machine translation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9397596120834351}, {"text": "information retrieval", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.8057747483253479}, {"text": "machine translation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.8096942901611328}]}, {"text": "I also address some objections to WSD research.", "labels": [], "entities": [{"text": "WSD research", "start_pos": 34, "end_pos": 46, "type": "TASK", "confidence": 0.9413815140724182}]}, {"text": "In Section 3, I examine the size of the training corpus on the accuracy of WSD, using a corpus of 192,800 occurrences of 191 words hand tagged with WORDNET senses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9993797540664673}, {"text": "WSD", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.8016024827957153}]}, {"text": "In Section 4, I estimate the amount of human sense-tagged corpus and the manual annotation effort needed to build abroad coverage, high accuracy WSD program.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9476594924926758}, {"text": "WSD", "start_pos": 145, "end_pos": 148, "type": "TASK", "confidence": 0.3540787994861603}]}, {"text": "Finally, in Section 5, I suggest that intelligent example selection techniques may significantly reduce the amount of sense-tagged corpus needed and offer this research problem as a fruitful area for WSD research.", "labels": [], "entities": [{"text": "WSD research", "start_pos": 200, "end_pos": 212, "type": "TASK", "confidence": 0.9433511197566986}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation of LEXAS", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9701508283615112}]}, {"text": " Table 2: Number of polysemous words in each part  of speech making up the top 80%, ..., 99% of word  occurrences in the Brown corpus.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 121, "end_pos": 133, "type": "DATASET", "confidence": 0.9521346688270569}]}, {"text": " Table 3: Number of polysemous words in each part  of speech making up the top 80%, ..., 99% of word  occurrences in the Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 121, "end_pos": 147, "type": "DATASET", "confidence": 0.9691199660301208}]}, {"text": " Table 4: Average number of senses per polysemous word in the Brown corpus for the top 80%, ..., top 99%,  and the bottom 20%, ..., bottom 1% of word occurrences.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.9558181166648865}]}, {"text": " Table 5: Average number of senses per polysemous word in the Wall Street Journal corpus for the top 80%,  ..., top 99%, and the bottom 20%, ..., bottom 1% of word occurrences.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 62, "end_pos": 88, "type": "DATASET", "confidence": 0.9731829017400742}]}]}