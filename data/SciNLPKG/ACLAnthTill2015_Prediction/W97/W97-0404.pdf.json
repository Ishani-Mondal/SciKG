{"title": [{"text": "Correct parts extraction from speech recognition results using semantic distance calculation, and its application to speech translation", "labels": [], "entities": [{"text": "Correct parts extraction from speech recognition", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6379469037055969}, {"text": "semantic distance calculation", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.7127172748247782}, {"text": "speech translation", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.7234019339084625}]}], "abstractContent": [{"text": "This paper proposes a method for extracting the correct parts from speech recognition results by using an example-based approach for parsing those results that include several recognition errors.", "labels": [], "entities": [{"text": "extracting the correct parts from speech recognition", "start_pos": 33, "end_pos": 85, "type": "TASK", "confidence": 0.6091427888189044}]}, {"text": "Correct parts are extracted using two factors: (1) the semantic distance between the input expression and example expression, and (2) the structure selected by the shortest semantic distance.", "labels": [], "entities": []}, {"text": "We examined the correct parts extraction rate and the effectiveness of the method in improving the speech understanding rate and the speech translation rate.", "labels": [], "entities": [{"text": "parts extraction", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.6955636888742447}, {"text": "speech understanding", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.6931929886341095}, {"text": "speech translation", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.721137747168541}]}, {"text": "The examination results showed that the proposed method is able to efficiently extract the correct parts from speech recognition results.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.674985870718956}]}, {"text": "About ninety-six percent of the extracted parts are correct.", "labels": [], "entities": []}, {"text": "The results also showed that the proposed method is effective in understanding misrecognition speech sentences and in improving speech translation results.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.7517404854297638}]}, {"text": "The misunderstanding rate for erroneous sentences is reduced about haiti Sixty-nine percent of speech translation results are improved for misrecognized sentences.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7224259376525879}]}], "introductionContent": [{"text": "In continuous speech recognition, N-grams have been widely used as effective linguistic constraints for spontaneous speech.", "labels": [], "entities": [{"text": "continuous speech recognition", "start_pos": 3, "end_pos": 32, "type": "TASK", "confidence": 0.6697004735469818}]}, {"text": "To reduce the search effort, N of a high-order can be quite powerful; but making the large corpus necessary to calculate a reliable high-order N is unrealistic.", "labels": [], "entities": []}, {"text": "For a realistic linguistic constraint, almost all speech recognition systems use a low-order N-gram, like a bi-gram or tri-gram, which can be constrainted only to the local parts.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.744529664516449}]}, {"text": "However this is one of the reasons why many misrecognized sentences using N-grams are strange on long parts spanning over N words.", "labels": [], "entities": []}, {"text": "During *Now working at Toyo Information Systems Co., Ltd the recognition process, several candidates have to be pruned if the beam width is too small, and the pruning cannot but use only those local parts already recognized.", "labels": [], "entities": [{"text": "Toyo Information Systems Co.", "start_pos": 23, "end_pos": 51, "type": "DATASET", "confidence": 0.8841970860958099}]}, {"text": "Even if we could get a large enough corpus to train a high-order N-gram, it would be impossible to determine the best recognition candidate in consideration of the whole sentence.", "labels": [], "entities": []}, {"text": "To put a speech dialogue system or a speech translation system into practical use, it is necessary to develop a mechanism that can parse the misrecognized results using global linguistic constraints.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.723209947347641}]}, {"text": "Several methods have already been proposed to parse ill-formed sentences or phrases using global linguistic constraints based on a contextfree-grammar (CFG) framework, and their effectiveness against some misrecognized speech sentences have been confirmed.", "labels": [], "entities": [{"text": "parse ill-formed sentences or phrases", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.8605982661247253}]}, {"text": "Also these parsings are used for translation ( see for example the use of the GLR parser in Janus ).", "labels": [], "entities": [{"text": "translation", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.981198787689209}]}, {"text": "In these studies, even if the parsing was unsuccessful for erroneous parts, the parsing could be continued by deleting or recovering the erroneous parts.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9606028199195862}]}, {"text": "The parsing was done on the assumption that every input sentence is well-formed after all erroneous parts are recovered.", "labels": [], "entities": []}, {"text": "In reality, however spontaneous speech contains a lot of ill-formed sentences and it is difficult to analyze every spontaneous sentence by the CFG framework.", "labels": [], "entities": [{"text": "CFG framework", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.9589307010173798}]}, {"text": "Concerning the CFG framework, syntactic rules written by subtrees are proposed.", "labels": [], "entities": [{"text": "CFG framework", "start_pos": 15, "end_pos": 28, "type": "DATASET", "confidence": 0.8956242501735687}]}, {"text": "Even if a whole sentence cannot be analyzed by CFG, the sentence can be expressed by combining several subtrees.", "labels": [], "entities": [{"text": "CFG", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.9178839921951294}]}, {"text": "The subtrees are effective in parsing spontaneous speech parts.", "labels": [], "entities": [{"text": "parsing spontaneous speech parts", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.910181850194931}]}, {"text": "Still, because the subtrees can deal only with local parts like in Ngram modeling basically, parsing is not sufficient for parsing misrecognized sentences.", "labels": [], "entities": [{"text": "parsing misrecognized sentences", "start_pos": 123, "end_pos": 154, "type": "TASK", "confidence": 0.8938874006271362}]}, {"text": "Furthermore, the subtrees are not sufficient in extracting suitable meaningful candidate structures, because that these linguistic constraints are based on the grammatical constraint without semantics.", "labels": [], "entities": []}, {"text": "To parse misrecognized sentences of spontaneous speech, we propose a correct parts extraction (CPE) method that uses global linguistic and semantic c0nstraints by an example-based approach.", "labels": [], "entities": [{"text": "parse misrecognized sentences of spontaneous speech", "start_pos": 3, "end_pos": 54, "type": "TASK", "confidence": 0.8655679523944855}]}, {"text": "In the next section, we describe the CPE method.", "labels": [], "entities": [{"text": "CPE", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.6342134475708008}]}, {"text": "In the following section, we show evaluation results of CPE applied to Japanese-toEnglish speech translation experiments.", "labels": [], "entities": [{"text": "CPE", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.480991005897522}, {"text": "Japanese-toEnglish speech translation", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.5349906881650289}]}, {"text": "For effective and robust spoken-language translation, a speech translation system called Transfer Driven Machine Translation (TDMT) which carries out analysis and translation in an examplebased framework has been proposed.", "labels": [], "entities": [{"text": "spoken-language translation", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.7886688113212585}, {"text": "speech translation", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7520265281200409}, {"text": "Transfer Driven Machine Translation (TDMT)", "start_pos": 89, "end_pos": 131, "type": "TASK", "confidence": 0.7589132274900164}]}, {"text": "TDMT which refers to as Example-Based Machine translation(EBMT) does not require a full analysis and instead defines patterns on sentences/phrases expressed by \"variables\" and \"constituent boundaries\".", "labels": [], "entities": [{"text": "Example-Based Machine translation(EBMT)", "start_pos": 24, "end_pos": 63, "type": "TASK", "confidence": 0.7579198181629181}]}, {"text": "These patterns are classified into several classes, for example a complex sentence pattern class, an embedded clause pattern class, and phrase class.", "labels": [], "entities": []}, {"text": "A long-distance dependency structure can be handled by complex sentence patterns.", "labels": [], "entities": []}, {"text": "The process employs a fast nearest-matching method to find the closest translation example by measuring the semantic conceptual distance of a given linguistic expression from a set of equivalents in the example corpus.", "labels": [], "entities": []}, {"text": "In general, the EBMT method is particularly effective when the structure of an input expression is short or well-defined and its bounds have been recognized.", "labels": [], "entities": []}, {"text": "When applying it in translation of longer utterances, the input must first be chunked to determine potential patterns by analyzing it into phrases after adding part-ofspeech tags.", "labels": [], "entities": [{"text": "translation of longer utterances", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.8188802748918533}]}, {"text": "In TDMT, translation is performed by means of stored translation examples which are represented by \"constituent boundary patterns\".", "labels": [], "entities": []}, {"text": "These are built using limited word-tag information, derived from morphological analysis, in the following sequence: (a) insertion of constituent boundary markers, (b) derivation of possible structures by pattern matching, and (c) structural disambiguation using similarity calculation.", "labels": [], "entities": []}, {"text": "If the process of the similarity calculations for candidate phrase patterns were executed topdown ~: breadth-first, then the calculation cost would be too expensive and the decision on the best phrase would have to be postponed.", "labels": [], "entities": [{"text": "breadth-first", "start_pos": 101, "end_pos": 114, "type": "METRIC", "confidence": 0.9982800483703613}]}, {"text": "The translation cost are reduced in TDMT and phrases or partial sentences are analyzed because that the current TDMT uses instead on incremental method to determine the best structure locally in a bottom-up & best-only way to constrain the number of competing structures.", "labels": [], "entities": []}, {"text": "This means that even TDMT fails fora whole sentence analysis, substructures partially analyzed can begotten.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated CPE using the speech translation system shown in.", "labels": [], "entities": [{"text": "CPE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8445438146591187}, {"text": "speech translation", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.704261913895607}]}, {"text": "CPE has already been integrated into TDMT as explained in the previous section.", "labels": [], "entities": [{"text": "CPE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8953558802604675}, {"text": "TDMT", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.7010544538497925}]}, {"text": "At first, the obtained recognition results were analyzed and then partial structures and their semantic distances were output.", "labels": [], "entities": []}, {"text": "Next, the correct parts were extracted and only the extracted parts were translated into target sentences.", "labels": [], "entities": []}, {"text": "We evaluated the following three things: (1) the recall and precision rates of the extracted parts , (2) the effectiveness of the method in understanding misrecognized results, and (3) the effectiveness of the method in improving the translation rate.", "labels": [], "entities": [{"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.999482274055481}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9973058700561523}, {"text": "translation", "start_pos": 234, "end_pos": 245, "type": "TASK", "confidence": 0.9693971276283264}]}, {"text": "For the evaluations, we used 70 erroneous results output by a speech recognition experiment using the ATR spoken language database on travel arrangement.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7069616466760635}, {"text": "ATR spoken language database", "start_pos": 102, "end_pos": 130, "type": "DATASET", "confidence": 0.8807696253061295}]}], "tableCaptions": [{"text": " Table 1: The effect of CPE toward understanding misrecognition results", "labels": [], "entities": []}, {"text": " Table 2: The effect of CPE toward translating misrecognition results", "labels": [], "entities": [{"text": "translating misrecognition", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.8911496698856354}]}]}