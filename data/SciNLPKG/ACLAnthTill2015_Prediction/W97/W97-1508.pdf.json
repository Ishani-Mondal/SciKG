{"title": [{"text": "Lexical Resource Reconciliation in the Xerox Linguistic Environment", "labels": [], "entities": [{"text": "Lexical Resource Reconciliation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8165117899576823}, {"text": "Xerox Linguistic Environment", "start_pos": 39, "end_pos": 67, "type": "DATASET", "confidence": 0.7772417664527893}]}], "abstractContent": [{"text": "This paper motivates and describes those", "labels": [], "entities": []}], "introductionContent": [{"text": "The LISP-based LFG Grammar Writers Workbench (GWB)) has long served both as a testbed for the development of parsing algorithms and as a self-contained environment for work in syntactic theory.", "labels": [], "entities": [{"text": "LISP-based LFG Grammar Writers Workbench (GWB))", "start_pos": 4, "end_pos": 51, "type": "DATASET", "confidence": 0.8184870183467865}, {"text": "parsing algorithms", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.9103344976902008}, {"text": "syntactic theory", "start_pos": 176, "end_pos": 192, "type": "TASK", "confidence": 0.7606021463871002}]}, {"text": "The C/Unix-based Xerox Linguistic Environment (XLE) further develops the GWB parsing algorithms, extends them to generation, and adapts the environment to a different set of requirements.", "labels": [], "entities": [{"text": "GWB parsing", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.686641663312912}]}, {"text": "This paper motivates and describes the morphological and lexical adaptations of XLE.", "labels": [], "entities": []}, {"text": "They evolved concurrently with PARGRAM, a multi-site XLF_~ based broad-coverage grammar writing effort aimed at creating parallel grammars for English, French, and German (see Butt et. al., forthcoming).", "labels": [], "entities": [{"text": "broad-coverage grammar writing", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.5976461271444956}]}, {"text": "The XLE adaptations help to reconcile separately constructed linguistic resources with the needs of the core grammars.", "labels": [], "entities": []}, {"text": "The paper is divided into three major sections.", "labels": [], "entities": []}, {"text": "The next section sets the stage by providing a short overview of the overall environmental features of the original LFG GWB and its provisions for morphological and lexicon processing.", "labels": [], "entities": [{"text": "LFG GWB", "start_pos": 116, "end_pos": 123, "type": "DATASET", "confidence": 0.9390782415866852}, {"text": "morphological and lexicon processing", "start_pos": 147, "end_pos": 183, "type": "TASK", "confidence": 0.6721377745270729}]}, {"text": "The two following sections describe the XLE extensions in those areas.", "labels": [], "entities": []}, {"text": "The GWB Data Base GWB provides a computational environment tailored especially for defining and testing grammars in the LFG formalism.", "labels": [], "entities": [{"text": "GWB Data Base GWB", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9334347099065781}]}, {"text": "Comprehensive editing facilities internal to the environment are used to construct and modify a database of grammar elements of various types: morphologicalrules, lexical entries, syntactic rules, and \"templates\" allowing named abbreviations for combinations of constraints.", "labels": [], "entities": []}, {"text": "(See Kaplan and for descriptions of the LFG formalism.)", "labels": [], "entities": []}, {"text": "Separate \"configuration\" specifications indicate how to select and assemble collections of these elements to makeup a complete grammar, and alternative configurations make it easy to experiment with different linguistic analyses.", "labels": [], "entities": []}, {"text": "This paper focuses on the lexical mapping process, that is, the overall process of translating between the characters in an input string and the initial edges of the parse-chart.", "labels": [], "entities": []}, {"text": "We divide this process into the typical stages of tokenization, morphological analysis, and LFG lexicon lookup.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.9722697138786316}, {"text": "morphological analysis", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.665466383099556}]}, {"text": "In GWB tokenizing is accomplished with a finite-state transducer compiled from a few simple rules according to the methods described by.", "labels": [], "entities": [{"text": "GWB tokenizing", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.5329363197088242}]}, {"text": "It tokenizes the input string by inserting explicit token boundary symbols at appropriate character positions.", "labels": [], "entities": []}, {"text": "This process can produce multiple outputs because of uncertainties in the interpretation of punctuation such as spaces and periods.", "labels": [], "entities": []}, {"text": "For example, \"I like Jan.\" results in two alternatives (\"I@like@Jan@.@\" and \"I@like@Jan.@.@\") because the period in \"Jan.\" could optionally mark an abbreviation as well as a sentence end.", "labels": [], "entities": []}, {"text": "Morphological analysis is also implemented as a finite-state transducer again compiled from a set of rules.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9365788400173187}]}, {"text": "These rules are limited to describing only simple suffixing and inflectional morphology.", "labels": [], "entities": []}, {"text": "The morphological transducer is arranged to apply to individual tokens produced by the tokenizer, not to strings of tokens.", "labels": [], "entities": []}, {"text": "The result of applying the morphological rules to a token is a stem and one or more inflectional tags, each of which is the heading for an entry in the LFG lexicon.", "labels": [], "entities": [{"text": "LFG lexicon", "start_pos": 152, "end_pos": 163, "type": "DATASET", "confidence": 0.9042612314224243}]}, {"text": "Morphological ambiguity can lead to alternative analyses fora single token, so this stage can add further possibilities to the alternatives coming from the tokenizer.", "labels": [], "entities": []}, {"text": "The token \"cooks\" can be analyzed as \"cook +NPL\" or \"cook +V3SG\", for instance.", "labels": [], "entities": []}, {"text": "In the final phase of GWB lexical mapping, these stem-tag sequences are looked up in the LFG lexicon to discover the syntactic category (N, V, etc.) and constraints (e.g. (1\" NUM)=PL) to be placed on a single edge in the initial parse chart.", "labels": [], "entities": [{"text": "GWB lexical mapping", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6160198350747427}]}, {"text": "The category of that edge is determined by the particular combination of stems and tags, and the corresponding edge constraints are formed by conjoining the constraints found in the stem/tag lexical entries.", "labels": [], "entities": []}, {"text": "Because of the ambiguities in tokenization, morphological analysis and also lexical lookup, the initial chart is a network rather than a simple sequence.", "labels": [], "entities": []}, {"text": "The grammar writer enters morphological rules, syntactic rules, and lexical entries into a database.", "labels": [], "entities": []}, {"text": "These are grouped by type into named collections.", "labels": [], "entities": []}, {"text": "The collections may overlap in content in that different syntactic rule collections may contain alternative expansions fora particular category and different lexical collections may contain alternative definitions fora particular headword.", "labels": [], "entities": []}, {"text": "A configuration contains an ordered list of collection names to indicate which alternatives to include in the active grammar.", "labels": [], "entities": []}, {"text": "This arrangement provides considerable support for experimentation.", "labels": [], "entities": []}, {"text": "The grammar writer can investigate alternative hypotheses by switching among configurations with different inclusion lists.", "labels": [], "entities": []}, {"text": "Also, the inclusion list order is significant, with collections mentioned later in the list having higher precedence than ones mentioned earlier.", "labels": [], "entities": []}, {"text": "If a rule for the same syntactic category appears m more than one included rule collection, or an entry for the same headword appears in more than one included lexical collection, the instance from the collection of highest precedence is the one included in the grammar.", "labels": [], "entities": []}, {"text": "Thus the grammar writer can tentatively replace a few rules or lexical entries by placing some very small collections containing the replacements later in the configuration list.", "labels": [], "entities": []}, {"text": "We constructed XLE around the same databaseplus-configuration model but adapted it to operate in the C/Unix world and to meet an additional set of user requirements.", "labels": [], "entities": []}, {"text": "GWB is implemented in a residential Lisp system where rules and definitions on text files are \"loaded\" into a memory-based database and then selected and manipulated.", "labels": [], "entities": [{"text": "GWB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8308898210525513}]}, {"text": "In C/Unix we treat the files themselves as the analog of the GWB database.", "labels": [], "entities": [{"text": "GWB database", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.9210022985935211}]}, {"text": "Thus, the XLE user executes either a \"create-parser\" or \"create-generator\" command to select a file containing one or more configurations and to select one of those configurations to specify the current grammar.", "labels": [], "entities": []}, {"text": "The selected configuration, in turn, names a list of files comprising the database, and identifies the elements in those files to be used in the grammar.", "labels": [], "entities": []}, {"text": "This arrangement still supports alternative versions of lexical entries and rules, but the purpose is not just to permit easy and rapid exploration of these alternatives.", "labels": [], "entities": []}, {"text": "The XLE database facilities also enable linguistic specifications from different sources and with different degrees of quality to be combined together in an orderly and coherent way.", "labels": [], "entities": []}, {"text": "For XLE the goal is to produce efficient, robust, and broad coverage processors for parsing and generation, and this requires that we make use of large-scale, independently developed morphological analyzers and lexicons.", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.8157204190889994}]}, {"text": "Such comprehensive, well-engineered components exist for many languages, and can relieve the grammar developer of much of the effort and expense of accounting again for those aspects of language processing. are, at present, primarily aimed at relatively undemanding commercial applications such as information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 298, "end_pos": 319, "type": "TASK", "confidence": 0.8673475384712219}]}, {"text": "As such, they may have mistakes or gaps that have gone unnoticed because they have no effect on the target applications.", "labels": [], "entities": []}, {"text": "For example, function words are generally ignored in IR, so mistakes in those words might go undetected; but those words are crucial in syntactic processing.", "labels": [], "entities": [{"text": "IR", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9538033604621887}]}, {"text": "And even correct analyses generally deviate in some respects from the characterizations desired by the grammar writer.", "labels": [], "entities": []}, {"text": "These mistakes, gaps, and mismatches are often not easy to correct at the source.", "labels": [], "entities": []}, {"text": "It may not be practical to refer problems back to the supplier as they are uncovered, because of inherent time lags, economic feasibility, or other factors.", "labels": [], "entities": []}, {"text": "But the grammar writer may not have the tools, permissions, or skills, to modify the source specifications directly.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}