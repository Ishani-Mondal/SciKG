{"title": [{"text": "Analysis of Unknown Lexical Items using Morphological and Syntactic Information with the TIMIT Corpus", "labels": [], "entities": [{"text": "Analysis of Unknown Lexical Items", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7773550510406494}, {"text": "TIMIT Corpus", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.9147475957870483}]}], "abstractContent": [{"text": "The importance of dealing with unknown words in Natural Language Processing (NLP) is growing as NLP systems are used in more and more applications.", "labels": [], "entities": [{"text": "dealing with unknown words in Natural Language Processing (NLP)", "start_pos": 18, "end_pos": 81, "type": "TASK", "confidence": 0.6888810179450295}]}, {"text": "One aid in predicting the lexical class of words that do not appear in the lexicon (referred to as unknown words) is the use of syntactic parsing rules.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.70771723985672}]}, {"text": "The distinction between closed-class and open-class words together with morphological recognition appears to be pivotal in increasing the ability of the system to predict the lexical categories of unknown words.", "labels": [], "entities": [{"text": "predict the lexical categories of unknown words", "start_pos": 163, "end_pos": 210, "type": "TASK", "confidence": 0.6721264379365104}]}, {"text": "An experiment is performed to investigate the ability of a parser to parse unknown words using morphology and syntactic parsing rules without human intervention.", "labels": [], "entities": []}, {"text": "This experiment shows that the performance of the parser is enhanced greatly when morphological recognition is used in conjunction with syntactic rules to parse sentences containing unknown words from the TIMIT corpus.", "labels": [], "entities": [{"text": "morphological recognition", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.7542766630649567}, {"text": "TIMIT corpus", "start_pos": 205, "end_pos": 217, "type": "DATASET", "confidence": 0.698678731918335}]}], "introductionContent": [{"text": "One of the problems facing natural language parsing (NLP) systems is the appearance of unknown words; words that appear in sentences, but are not contained within the lexicon for the system.", "labels": [], "entities": [{"text": "natural language parsing (NLP)", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.8300437132517496}]}, {"text": "This problem is one that will only get worse as NLP systems are used for more on-line computer applications.", "labels": [], "entities": []}, {"text": "New words are continually added to the language, and people will often use words that a parsing system may not expect.", "labels": [], "entities": []}, {"text": "This paper will empirically investigate how well a dictionary of closed-class words, syntactic parsing rules, and a morphological recognizer can parse sentences containing unknown words in natural language processing tasks.", "labels": [], "entities": []}, {"text": "Syntactic knowledge can be used to aid in the analysis of unknown words--sentence structure can be a strong clue as to the possible part of speech of an unknown word.", "labels": [], "entities": []}, {"text": "The distinction between closed-class and open-class words should help to refine the possibilities for an unknown word and enhance the information provided by the syntactic knowledge.", "labels": [], "entities": []}, {"text": "Morphological recognition can also be helpful in predicting possible parts of speech for many unknown words.", "labels": [], "entities": [{"text": "Morphological recognition", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.903424084186554}, {"text": "predicting possible parts of speech", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.8226897239685058}]}, {"text": "We expect that these three knowledge sources will greatly improve our parser's ability to process and cope with words that are not in the system lexicon.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parsing system used in this experiment is based on a Tomita style parser.", "labels": [], "entities": []}, {"text": "It is an LR-type parser, using a shift-reduce algorithm with packed parse forests.", "labels": [], "entities": []}, {"text": "It is implemented in Common Lisp.", "labels": [], "entities": []}, {"text": "The test corpus is a set of 356 sentences from the Timit corpus, a corpus of sentences that has no underlying semantic theme.", "labels": [], "entities": [{"text": "Timit corpus", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.7122302502393723}]}, {"text": "It was originally designed as a corpus for training phoneme recognition for speech processing.", "labels": [], "entities": [{"text": "training phoneme recognition", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.6214209695657095}, {"text": "speech processing", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.7612128853797913}]}, {"text": "This corpus was specifically chosen for our tests because it has no theme, and would thus offer a wider range of sentence types.", "labels": [], "entities": []}, {"text": "The rule set was designed first to properly parse the test corpus, and second to be as general as possible.", "labels": [], "entities": []}, {"text": "It is hoped that these rules could deal with a wide variety of English sentences, though they have not been tested on other corpora.", "labels": [], "entities": []}, {"text": "The issue of the size of the grammar is not addressed in this experiment.", "labels": [], "entities": []}, {"text": "Also, the possible failure of the parser clue to insufficient rule coverage is not considered.", "labels": [], "entities": []}, {"text": "There are many applications that use grammars that do not cover an extensive range of English sentences, and these applications would benefit from our mechanisms for dealing with unknown words.", "labels": [], "entities": []}, {"text": "There are four separate files that constitute the lexicon for this parser and corpus: \u2022 nouns -contains all irregular noun plurals.", "labels": [], "entities": []}, {"text": "\u2022 verbs -contains all forms of all irregular verbs.", "labels": [], "entities": []}, {"text": "\u2022 closed -contains all other closed-class words.", "labels": [], "entities": []}, {"text": "\u2022 dict -actually a set of files, named dictl to dictl0.", "labels": [], "entities": []}, {"text": "Dictl0 contains all the words from the corpus that are not contained in the other three files and are thus all open-class words.", "labels": [], "entities": []}, {"text": "Dict9 contains 90% of the words from dictl0, dict8 contains 80%, and soon down to dictl, which contains 10% of these words.", "labels": [], "entities": []}, {"text": "All these files were created randomly and \u2022 independently using the words in dictl0.", "labels": [], "entities": []}, {"text": "These percentages are based on a word count, not on a definition count--many words have more than one definition.", "labels": [], "entities": []}, {"text": "For example, acts is one word, but it has two definitions--as a noun and a verb.", "labels": [], "entities": []}, {"text": "For our experiment, we perform two data runs.", "labels": [], "entities": []}, {"text": "The first run uses a variation Tomita's method; it assigns all possible open-class parts of speech (noun, verb, adjective, adverb, and modifier) to unknown words.", "labels": [], "entities": []}, {"text": "This data run is called the baseline run.", "labels": [], "entities": []}, {"text": "The second run assigns parts of speech using the post-mortem approach described in Section 3.4.", "labels": [], "entities": []}, {"text": "This data run is called the experimental run.", "labels": [], "entities": []}, {"text": "For each test run, the sentences in the corpus are parsed by the system eleven times.", "labels": [], "entities": []}, {"text": "Each time through the corpus, all the dosed-class words are loaded into the lexicon.", "labels": [], "entities": []}, {"text": "In each separate run, a different open-class dictionary is used.", "labels": [], "entities": []}, {"text": "For the first run, the full dictionary found in dictl0 is used.", "labels": [], "entities": []}, {"text": "This run is used as a control, since all words in the corpus are defined in the lexicon.", "labels": [], "entities": []}, {"text": "For each successive run, the next dictionary is used, from dict9 down to dictl.", "labels": [], "entities": []}, {"text": "Finally, the eleventh run is done without loading any extra dictionary files--only the three dosed-class files are used.", "labels": [], "entities": []}, {"text": "After all of the parse trees have been generated, each run is compared to the control run, and three numbers are calculated for each sentence in each run--the number of matches~ deletions, and insertions.", "labels": [], "entities": []}, {"text": "A match occurs when the sentence has generated a parse that occurs within the control parse forest for that sentence.", "labels": [], "entities": []}, {"text": "A deletion occurs when the sentence has failed to produce a parse that occurs in the: control parse forest for that sentence.", "labels": [], "entities": []}, {"text": "An insertion occurs when the sentence produces a parse that does not occur in the control parse forest for that sentence.", "labels": [], "entities": []}, {"text": "For example, assume sentence ~16 produces parses A, B, C, and D in the first, or control, run.", "labels": [], "entities": []}, {"text": "Ina later runt sentence ~16 produces parses A, C, E, F, and G.", "labels": [], "entities": []}, {"text": "Then, for sentence #16, we have two matches (A and C), two deletions (B and D), and three insertions (E, F, and G).", "labels": [], "entities": []}, {"text": "By using these measurements, we can determine the precision and recall of the parsing system when parsing sentences with unknown words.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9995848536491394}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9978007674217224}, {"text": "parsing sentences with unknown words", "start_pos": 98, "end_pos": 134, "type": "TASK", "confidence": 0.8642685770988464}]}, {"text": "The issue of disambiguation is not explicitly dealt within this experiment.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9675200581550598}]}, {"text": "We wish to see how well the morphological recognizer can replicate the performance of a parser with a full dictionary.", "labels": [], "entities": []}, {"text": "This is demonstrated in our use of the match, insertion, and deletion numbers above.", "labels": [], "entities": [{"text": "match", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.997052788734436}, {"text": "insertion", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9323181509971619}]}, {"text": "The number of matches is important, since ideally we want the recognizer to return all possible parses that occur when the full dictionary is used.", "labels": [], "entities": []}, {"text": "The issue of which of these parses is the correct one would require that we utilize semantic, pragmatic, and contextual information to select the correct parse, a topic beyond the scope of our experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Deletion and Insertion Data", "labels": [], "entities": []}]}