{"title": [], "abstractContent": [{"text": "Few attention has been paid to terminology extraction for what concerns the possibilities it offers to corpus linguistics and lexical acquisition.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.9645254909992218}, {"text": "corpus linguistics", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.7540294826030731}, {"text": "lexical acquisition", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7234645038843155}]}, {"text": "The problem of detecting terms in textual corpora has been approached in a complex framework.", "labels": [], "entities": []}, {"text": "Terminology is seen as the acquisition of domain specific knowledge (i.e. semantic features, selectional restrictions) for complex terms and /or unknown words.", "labels": [], "entities": [{"text": "Terminology", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9626380801200867}]}, {"text": "This has useful implications on more complex text processing tasks (e.g. information extraction).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.8057603538036346}]}, {"text": "An hybrid symbolic and probabilistic approach to terminology extraction has been defined.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.9704598486423492}]}, {"text": "The proposed inductive method puts a specific attention to the linguistic description of what terms are as well as to the statistical characterization of terms as complex units of information typical of domain sub-. languages.", "labels": [], "entities": []}, {"text": "Experimental evidence of the proposed method are discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Nowadays corpus processing techniques are widely adopted to approach the well-known lexical bottleneck problems in language engineering.", "labels": [], "entities": [{"text": "corpus processing", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7709839046001434}]}, {"text": "Lexical acquisition methods rely on collocational analysis (pure statistics), robust parsing (syntax-driven acquisition) or semantic annotations as they are found in large thesaura or on-line dictionaries.", "labels": [], "entities": [{"text": "Lexical acquisition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.869097888469696}]}, {"text": "The lexical information that trigger induction varies from simple word/tokens to syntactically annotated or semantically typed collocations (e.g. powerful vs. strong tea), syntactic disambiguation rules (e.g. (,) or sense disalnbiguation rules are usually derived.", "labels": [], "entities": []}, {"text": "Such information is lexical as it, encodes constraints (of different types) at the word level, to be thus inherited by morphologic variants of a given lemma.", "labels": [], "entities": []}, {"text": "This strongly lexicalized knowledge, as it is extracted from corpus data, requires lexical entries to be known in advance in some morphologic database.", "labels": [], "entities": []}, {"text": "POS taggers or temmatizers are generally used to suitably map tokens to lemmas.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.6890484094619751}]}, {"text": "It should be noted that lemmas in a corpus depends on the underlying sublanguage and their nature and shape is not as general as it is usually encoded in a morphologic dictionary.", "labels": [], "entities": []}, {"text": "As an example, let studio (i.e. study as a noun) bean entry in an italian morphologic dictionary.", "labels": [], "entities": []}, {"text": "Typical information in such a database is the following: studio pos=noun gen=mas aura=sing Tlle only legal morphologic variant of ,studio is studi (studies, with nura=plur).", "labels": [], "entities": [{"text": "Tlle", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9314969778060913}]}, {"text": "Tile environmental corpus, called ENEA, is a collection of short scientific abstracts or newspaper articles dealing with pollution.", "labels": [], "entities": [{"text": "Tile environmental corpus", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.6549487312634786}]}, {"text": "they select specific and independent senses of the related term: studi di base refers to the abstract notion of study as an on-going reasearch, while studi di fattibilita' is not a reaseareh but a specific engineering task ; the related nominal compounds show independent lexical properties.", "labels": [], "entities": []}, {"text": "For example, all the examples are potential object of verbs like carryout, do ....", "labels": [], "entities": []}, {"text": "but only feasibility studies or studies on the environmental impact can be modelled by some techniques or policies.", "labels": [], "entities": []}, {"text": "Furthermore, studies on the environmental impact have specific social and political implications that are no longer valid for the general notion of study.", "labels": [], "entities": []}, {"text": "In the same environmental corpus the typical short contexts of the lemma attivit6 (activity) include notions like: attivitti umana (human activity), attivit6 entropica (hentropic activity), attivit6 di costruzione (building activity).", "labels": [], "entities": []}, {"text": "These very common instances show that lexical acquisition for attivit6 or studio cannot be fully accomplished without discriminating the lexieal properties of such pure collocations from those related to their complex nominals.", "labels": [], "entities": []}, {"text": "The results of lexical acquisition should thus be different for entries like attivittl and attivitd entropica.", "labels": [], "entities": []}, {"text": "The underlying hypothesis is that complex concepts related to a lemma do not support all the generalizations related to the source lemma.", "labels": [], "entities": []}, {"text": "In fact, whenever a concepts is built it acquires an autonomous role within a language so it behaves in an almost independent fashion.", "labels": [], "entities": []}, {"text": "In order to capture the essential differences we need to select the proper set of terms in a given sublanguages, formalize them into independent lexicalizations and carryout a separate lexical acquisition for each of them.", "labels": [], "entities": []}, {"text": "A further aspects that is worth to be mentioned is that terms are generally understood as single lexical units during syntactic recognition.", "labels": [], "entities": [{"text": "syntactic recognition", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.7459133863449097}]}, {"text": "They are sentence fragments already parsed.", "labels": [], "entities": []}, {"text": "Robust methods widely empl3yed in computational linguistics are thus sensible to a precise recognition of terms, as much of the ambiguity embedded within the term structures simply disappear after ercognition has been accomplished.", "labels": [], "entities": []}, {"text": "although inherently ambiguous (l 'inizio della costruzione and trasportavano da spiaggia are sentence readings that also obey to selectional constraints (e.g. to transport/bring from a place)) can be correctly parsed when the two terms are employed before syntactic analysis is triggered.", "labels": [], "entities": []}, {"text": "Applying syntactic driven lexical acquisition (e.g. ( or (Basili et a1.,1996)) after corpus specific term recognition and extraction highly improve the precision and complexity of the parsing activity.", "labels": [], "entities": [{"text": "corpus specific term recognition and extraction", "start_pos": 85, "end_pos": 132, "type": "TASK", "confidence": 0.6725490887959799}, {"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9984707236289978}, {"text": "parsing activity", "start_pos": 184, "end_pos": 200, "type": "TASK", "confidence": 0.894091933965683}]}, {"text": "Experimental evidence will be discussed in later sections.", "labels": [], "entities": []}, {"text": "In synthesis corpus driven terminology definition and recognition has positive implications on LA: * Terms rather than words are the atomic units of information on which LA applies: more selective induction thus results in a more precise acquisition \u2022 Terminologic variants of a given term are hints for domain specific word sense disambiguation \u2022 Terms are sentence fragments that have been already parsed: the lower ambiguity resulting from term recognition has a beneficial effect on the later syntagmatic analysis of the corpus 2 Terminology and Lexical Acquisition.", "labels": [], "entities": [{"text": "terminology definition and recognition", "start_pos": 27, "end_pos": 65, "type": "TASK", "confidence": 0.6218005046248436}, {"text": "domain specific word sense disambiguation", "start_pos": 304, "end_pos": 345, "type": "TASK", "confidence": 0.6620030879974366}, {"text": "term recognition", "start_pos": 443, "end_pos": 459, "type": "TASK", "confidence": 0.7269163429737091}]}, {"text": "In this framework, a term is more than a token or word (to be searched for) as it stands in a more subtle relation with apiece of information in a specific knowledge domain.", "labels": [], "entities": []}, {"text": "It is a concept, as it requires a larger number of constraints on the information to be searched for in texts.", "labels": [], "entities": []}, {"text": "Furthermore a term conveys a well assessed (usually complex) meaning as long as a user community agrees on its content.", "labels": [], "entities": []}, {"text": "As long as we are interested in automatic terminology derivation, we can look at terms as surface canonical forms of (possibly structured) expressions indicating those contents.", "labels": [], "entities": []}, {"text": "A term is thus characterized by a general commitment about it and this has some effects on its usage.", "labels": [], "entities": []}, {"text": "Distributional properties of complex terms (nominals) differ significantly on those of their basic elements.", "labels": [], "entities": []}, {"text": "Deviance from usual distributional behavior of single components can be used both as marker of non compositionality and specific hints of domain relevance.", "labels": [], "entities": []}, {"text": "The detection of complex terms assumes a crucial role in improving robust parsing and POS tagging for lexical acquisition, thus supporting a more precise induction of lexical properties (e.g. PP disambiguation rules).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.7262645959854126}, {"text": "lexical acquisition", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7314657270908356}]}, {"text": "This specific view extends and generalizes the classical notion of terminology as used in Information Science.", "labels": [], "entities": [{"text": "Information Science", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7918885052204132}]}, {"text": "Most of the domain specific terms we are interested to are nouns or noun phrases that generally denote concepts in a knowledge domain.", "labels": [], "entities": []}, {"text": "In order to approach the problem of terminological induction we thus need: 1.", "labels": [], "entities": [{"text": "terminological induction", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7014050632715225}]}, {"text": "to extract surface forms that are possible candidates as concept markers; 2.", "labels": [], "entities": []}, {"text": "to decide which of those candidates are actually concepts within a given knowledge domain, identified by the set of analyzed texts.", "labels": [], "entities": []}, {"text": "Linguistic principles characterize classes of surface forms as potential terms (step 1).", "labels": [], "entities": []}, {"text": "Note that the notion of terminological legal expression here is not equivalent to that of legal noun phrases.", "labels": [], "entities": []}, {"text": "Concepts are lexicalized in surface forms via a set of operations that imply semantic specifications.", "labels": [], "entities": []}, {"text": "The way syntax operates such specification maybe very complex and independent on the notion of grammatical well formedness.", "labels": [], "entities": []}, {"text": "The decision in step (2) is again sensible to a principled way a language expresses concept specifications but needs also to be specific to the given knowledge domain, i.e. to the underlying sublanguage.", "labels": [], "entities": []}, {"text": "Given the body of texts, the selective extraction should be sensitive to the different observed information.", "labels": [], "entities": []}, {"text": "In this phase statistics is crucial to control the relevance of linguistically plausible forms of all the guessed terms.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of this experiment was to test the ability of the method to capture relevant concepts in the sublanguage.", "labels": [], "entities": []}, {"text": "We run this test on the environmental domain (ENEA corpus).", "labels": [], "entities": [{"text": "ENEA corpus)", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.9462731083234152}]}, {"text": "The reference term dictionary was manually compiled by a team of three domain experts, culturally heterogeneous.", "labels": [], "entities": []}, {"text": "We got a complete list of terms (simple nouns as well as complex nominals) to be used as a test-set (RT).", "labels": [], "entities": []}, {"text": "The reference document set was a collection of 106 documents.", "labels": [], "entities": [{"text": "reference document set", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7614668607711792}]}, {"text": "The experts compiled a set of 482 terms organized in 155 sections (i.e. relevant head nouns).", "labels": [], "entities": []}, {"text": "Each section thus includes 3.12 terms.", "labels": [], "entities": []}, {"text": "For sake of completeness we selected two large hand-coded thesaura for the environment: the CNR dictionary  (CNR,1995)(that includes 9613 terms) and the AIB dictionary.", "labels": [], "entities": [{"text": "CNR dictionary  (CNR,1995)(", "start_pos": 92, "end_pos": 119, "type": "DATASET", "confidence": 0.9494239926338196}, {"text": "AIB dictionary", "start_pos": 153, "end_pos": 167, "type": "DATASET", "confidence": 0.9155819714069366}]}, {"text": "Both these dictionaries as well as the automatically generated dictionary TD have been compared with the reference RT.", "labels": [], "entities": []}, {"text": "The comparison has been carried out throughout the different aligned sections.", "labels": [], "entities": []}, {"text": "The alignment of the section related to the head smaltimento is reported in (\"X\" means the presence of the term in the corresponding dictionary, while \".\" denotes its absence): Any dictionary D can thus be evaluated by measuring precision~ i.e. precision = RTterrnsoDterrn8 Dterrns and recall, i.e. recall = RTterrnsf'lDterrns  Consulting a terminologic dictionary before activating a shallow syntactic analyzer is helpful to solve several morphological and syntactic ambiguities.", "labels": [], "entities": [{"text": "precision", "start_pos": 229, "end_pos": 238, "type": "METRIC", "confidence": 0.9984416365623474}, {"text": "precision", "start_pos": 245, "end_pos": 254, "type": "METRIC", "confidence": 0.9980124235153198}, {"text": "recall", "start_pos": 286, "end_pos": 292, "type": "METRIC", "confidence": 0.9965219497680664}, {"text": "recall", "start_pos": 299, "end_pos": 305, "type": "METRIC", "confidence": 0.9946158528327942}]}, {"text": "For exa~nple, given the sentence 6 As each sentence reading cannot assign more than a single referent to each PP, we can partition the set of esl into several collision sets (i.e. sets of esi that cannot belong to the same sentence reading according to ().", "labels": [], "entities": []}, {"text": "The sample sentence gives rise to the following collision sets: When terminology is available many complex nominals are retained as single tokens and several ambiguity disappear.", "labels": [], "entities": []}, {"text": "In the Sole24Ore corpus our method produced both the terms guardia di finanza and aeroporto di Fium, icino so that the final list of esl reduces to N-P-N ufficiale della gua.rdia-di-finanz& N_V ufl~ciMe visit6 N_V guardia-di-finanza visit6 V_N visit6 aeroporto_di_fiumicino and no ambiguous (i.e. not singleton) collision set remains.", "labels": [], "entities": [{"text": "Sole24Ore corpus", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8941783905029297}]}, {"text": "We have two positive effects on the parsing activity.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9848935008049011}]}, {"text": "The first is data compression.", "labels": [], "entities": [{"text": "data compression", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.8151780068874359}]}, {"text": "In fact the overgeneration typically due to the shallow grammatical approach is significantly limited.", "labels": [], "entities": []}, {"text": "In our example the early 7 elementary syntactic groups obtained in absence of terminology reduced to 4 with an overall data compression of ((7-4)/7) 42.8%.", "labels": [], "entities": []}, {"text": "An extended experimentation has been carried out on a subset of 500 sentences of the corpus.", "labels": [], "entities": []}, {"text": "The use of terminology reduces the number of elementary syntactic links from 500 to 403 with a corresponding 20% of overall data compression.", "labels": [], "entities": []}, {"text": "Furthermore, the detection of a term carried out over single tokens that are morphologically ambiguous improves also the morphological recognition.", "labels": [], "entities": [{"text": "morphological recognition", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.6830454170703888}]}, {"text": "In fact the detection of a chain of tokens that are part of the same term implies a specific choice on the grammatical category of each token, thus augmenting the selectivity of POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 178, "end_pos": 189, "type": "TASK", "confidence": 0.8270967304706573}]}, {"text": "Over the same subset of the corpus we measured a decrement of 4% in the number of morphological derivations produced with terminology against the recognition carried out in absence of any terminological knowledge.", "labels": [], "entities": []}, {"text": "A second positive aspect of having an available where separate columns express the scores for the different runs: a simple parser (SP), and a terminology driven parser (TP).", "labels": [], "entities": []}, {"text": "As a result the simple parser obtains several complex nominals but only as syntactic structures so that it fails in detecting higher order syntactic links (i.e. syntactic relations between complex nominals and other sentence segments).", "labels": [], "entities": []}, {"text": "In these cases we penalized also the recall of the SP method, so that the difference between the two methods relies not only in amount of persisting ambiguity (i.e. precision), but also in coverage (better captured by recall).", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.998916745185852}, {"text": "precision", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.9981445074081421}, {"text": "coverage", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9838565587997437}, {"text": "recall", "start_pos": 218, "end_pos": 224, "type": "METRIC", "confidence": 0.9882098436355591}]}], "tableCaptions": [{"text": " Table 1: Distribution of indexes headed by attivit5", "labels": [], "entities": []}, {"text": " Table 2: Smaltimento in different dictionaries  RT  CNR AIB TD  smaltimento dei fanghi  _  X  smaltimento dei rifiuti  X  X  X  smaltimento delle scorie  X", "labels": [], "entities": [{"text": "RT  CNR AIB TD", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.8131921142339706}]}, {"text": " Table 3: Global Performance of different dictionaries  Dictionary  CNRD  AIB  TD  # of Relevant Terms  41  45  331  # of Terms  880  180  472  Recall  8,87%  9,74%  71,56%  Precision  4,66% 23,94% 70,13%", "labels": [], "entities": [{"text": "CNRD  AIB  TD", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.8654501438140869}, {"text": "Recall", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.6938759088516235}]}, {"text": " Table 4: Performance evaluation of terminology driven  parsing", "labels": [], "entities": [{"text": "terminology driven  parsing", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6534439921379089}]}]}