{"title": [{"text": "A Lightweight Terminology Verification Service for External Machine Translation Engines", "labels": [], "entities": [{"text": "External Machine Translation Engines", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.7177124992012978}]}], "abstractContent": [{"text": "We propose a demonstration of a domain-specific terminology checking service which works on top of any generic black-box MT, and only requires access to a bilingual terminology resource in the domain.", "labels": [], "entities": [{"text": "terminology checking", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.811133474111557}, {"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.9281352758407593}]}, {"text": "In cases where an incorrect translation of a source term was proposed by the generic MT service, our service locates the wrong translation of the term in the target and suggests a terminologically correct translation for this term.", "labels": [], "entities": [{"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.8850515484809875}]}], "introductionContent": [{"text": "Today there exist generic MT services fora large number of language pairs, which allow relatively easily to make your domain-specific portal multilingual, and allow access to its documents fora broad international public.", "labels": [], "entities": [{"text": "MT", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9736312031745911}]}, {"text": "However, applying a generic MT service to domain-specific texts often leads to wrong results, especially relative to the translation of domain-specific terminology.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9734914302825928}]}, {"text": "illustrates an example of a terminology inconsistent translation provided by a generic MT system.", "labels": [], "entities": [{"text": "terminology inconsistent translation", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.5844479699929556}, {"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.9339613318443298}]}, {"text": "English Source: Farmers tend to implement abroad non-focused weed-control strategy, on the basis of broad spectrum products and mixtures of different products.", "labels": [], "entities": []}, {"text": "Bing 1 : Los agricultores tienden a aplicar una estrategia amplia para control de malezas no centrado, sobre la base de productos de amplio espectro y las mezclas de diferentes productos.: Example of the translation produced by a generic MT model fora domain-specific document.", "labels": [], "entities": []}, {"text": "Source term : weed-control, official Spanish term translation: control de malas hierbas.", "labels": [], "entities": []}, {"text": "The importance of domain-specific terminology for Machine Translation has been mentioned in several previous works).", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8560263812541962}]}, {"text": "However, most of these works handle the case where the terminology is tightly integrated into the translation process.", "labels": [], "entities": []}, {"text": "This requires both a good expertise in SMT and a large amount of both in-domain and generic parallel texts, which is often difficult, especially for low-resourced languages like Turkish or Estonian.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9916285276412964}]}, {"text": "Here, we are targeting the situation where the content provider is not willing to train a dedicated translation system, for some reason such as lack of technical skills or lack of necessary resources (parallel data or computational resources), but has at his disposal a multilingual in-domain terminology which could be helpful for improving the generic translation provided by an external translation service.", "labels": [], "entities": []}, {"text": "We propose a demonstration of a multilingual terminology verification/correction service, which detects the wrongly translated terms and suggests a better translation of these terms.", "labels": [], "entities": [{"text": "multilingual terminology verification/correction", "start_pos": 32, "end_pos": 80, "type": "TASK", "confidence": 0.7059385716915131}]}, {"text": "This service can be seen as an aid for machine translation post-editing focused on in-domain terminology and as a tool for supporting the workflow of practicing translators.", "labels": [], "entities": [{"text": "machine translation post-editing", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.8430909117062887}]}], "datasetContent": [{"text": "In order to evaluate the quality of locating the wrong term translation, we applied the terminology verification service to an SMT model trained with Moses () on the Europarl ( corpus.", "labels": [], "entities": [{"text": "locating the wrong term translation", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.6667068541049957}, {"text": "SMT", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.9623641967773438}, {"text": "Europarl ( corpus", "start_pos": 166, "end_pos": 183, "type": "DATASET", "confidence": 0.9737788637479147}]}, {"text": "This SMT model was used for translating a test set in the Agricultural domain from Spanish into English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9840138554573059}]}, {"text": "In these settings we have access to the internal sub-phrase alignment provided by Moses, thus we know the exact location of the wrong term translation, which allows us to evaluate how good our locating technique is.", "labels": [], "entities": []}, {"text": "The test set consists of 100 abstracts in Spanish from a bibliographical database of scientific publications in the Agriculture domain.", "labels": [], "entities": []}, {"text": "These abstracts were translated into English with our translation model, and we then applied terminology verification and terminology correction procedures to these translations.", "labels": [], "entities": [{"text": "terminology correction", "start_pos": 122, "end_pos": 144, "type": "TASK", "confidence": 0.7638086080551147}]}, {"text": "When applying terminology verification we detected in total 171 terms in Spanish, 71 of them being correctly translated into English (consistent with terminology), and 100 being wrongly translated (not consistent with terminology).", "labels": [], "entities": []}, {"text": "We then attempted to locate these wrongly translated terms in the system translation MT (s).", "labels": [], "entities": []}, {"text": "Matching the out-of-context term translation with initial translation allowed to find a match for 82 wrongly translated terms (out of 100); Matching 1 left/right word extended term translation (M T (w i\u22121 T s w j+1 )) allowed to find a match for 16 more terms (out of 18 left).", "labels": [], "entities": []}, {"text": "Using the internal word alignments provided by Moses, we also evaluated how precisely the borders of the wrongly translated term were recovered by our term location procedure.", "labels": [], "entities": []}, {"text": "This precision is measured as follows: \u2022 The target tokens identified by our procedure (as described in 3) are: g T = t 1 , . .", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9974368214607239}]}, {"text": ", t j ; \u2022 We then identify the reference target tokens corresponding to the translation of the term T s using the Moses word alignment : r T = {r t 1 , . .", "labels": [], "entities": []}, {"text": "We define term location precision p asp = . The precision of term location with out-of-context term translation is of 0.92; the precision of term location with context-extended term translation is 0.91.", "labels": [], "entities": [{"text": "term location precision p", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.5932095646858215}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9990736246109009}, {"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9880181550979614}]}, {"text": "Overall, our approach allows to match 98% of the wrongly translated terms, with an overall location precision of 0.91.", "labels": [], "entities": [{"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.5745810270309448}]}, {"text": "Although these numbers may vary for other language pairs and other MT systems, this performance is encouraging.", "labels": [], "entities": [{"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9712337255477905}]}], "tableCaptions": []}