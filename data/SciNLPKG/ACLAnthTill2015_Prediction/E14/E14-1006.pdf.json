{"title": [{"text": "A Hierarchical Bayesian Model for Unsupervised Induction of Script Knowledge", "labels": [], "entities": [{"text": "Unsupervised Induction of Script Knowledge", "start_pos": 34, "end_pos": 76, "type": "TASK", "confidence": 0.8023263454437256}]}], "abstractContent": [{"text": "Scripts representing commonsense knowledge about stereotyped sequences of events have been shown to be a valuable resource for NLP applications.", "labels": [], "entities": []}, {"text": "We present a hierarchical Bayesian model for unsupervised learning of script knowledge from crowdsourced descriptions of human activities.", "labels": [], "entities": []}, {"text": "Events and constraints on event ordering are induced jointly in one unified framework.", "labels": [], "entities": []}, {"text": "We use a statistical model over permutations which captures event ordering constraints in a more flexible way than previous approaches.", "labels": [], "entities": []}, {"text": "In order to alleviate the sparsity problem caused by using relatively small datasets, we incorporate in our hierarchical model an informed prior on word distributions.", "labels": [], "entities": []}, {"text": "The resulting model substantially outperforms a state-of-the-art method on the event ordering task.", "labels": [], "entities": [{"text": "event ordering task", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7839586138725281}]}], "introductionContent": [{"text": "A script is a \"predetermined, stereotyped sequence of actions that define a well-known situation\".", "labels": [], "entities": []}, {"text": "While humans acquire such common-sense knowledge over their lifetime, it constitutes a bottleneck for many NLP systems.", "labels": [], "entities": []}, {"text": "Effective question answering and summarization are impossible without a form of story understanding, which in turn has been shown to benefit from access to databases of script knowledge.", "labels": [], "entities": [{"text": "question answering", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7917464971542358}, {"text": "summarization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9861300587654114}, {"text": "story understanding", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7118518799543381}]}, {"text": "Knowledge about the typical ordering of events can further help assessing document coherence and generating coherent text.", "labels": [], "entities": []}, {"text": "Here, we present a general method for acquiring data bases of script knowledge.", "labels": [], "entities": []}, {"text": "Our work maybe regarded as complementary to existing work on learning script knowledge from natural text), as not all types of scripts are elaborated in natural text -being left implicit because of assumed readers' world knowledge.", "labels": [], "entities": []}, {"text": "Our model, operating on data obtained in a cheap way by crowdsourcing, is applicable to any kind of script and can fill this gap.", "labels": [], "entities": []}, {"text": "We follow work in inducing script knowledge from explicit instantiations of scripts, socalled event sequence descriptions (ESDs).", "labels": [], "entities": []}, {"text": "Our data consists of sets of ESDs, each set describing a well-known situation we will call scenario (e.g., \"washing laundry\").", "labels": [], "entities": []}, {"text": "An ESD consists of a sequence of events, each describing an action defining part of the scenario (e.g., \"place the laundry in the washing machine\").", "labels": [], "entities": []}, {"text": "We refer to descriptions of the same event across ESDs as event types.", "labels": [], "entities": []}, {"text": "We refer to entities involved in a scenario as participants (e.g., a \"washing machine\" or a \"detergent\"), and to sets of participant descriptions describing the same entity as participant types.", "labels": [], "entities": []}, {"text": "For each type of scenario, our model clusters descriptions which refer to the same type of event, and infers constraints on the temporal order in which the events types occur in a particular scenario.", "labels": [], "entities": []}, {"text": "Common characteristics of ESDs such as event optionality and varying degrees of temporal flexibility of event types make this task nontrivial.", "labels": [], "entities": []}, {"text": "We propose a model which, in contrast to previous approaches, explicitly targets these characteristics.", "labels": [], "entities": []}, {"text": "We develop a Bayesian formulation of the script learning problem, and present a generative model for joint learning of event types and ordering constraints, arguing that the temporal position of an event in an ESD provides a strong cue for its type, and vice versa.", "labels": [], "entities": [{"text": "script learning problem", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.8797683914502462}]}, {"text": "Our model is unsupervised in that no event-or participant labels are required for training.", "labels": [], "entities": []}, {"text": "We model constraints on the order of event types using a statistical model over permutations, the Generalized Mallows Model).", "labels": [], "entities": []}, {"text": "With the GMM we can flexibly model apparent characteristics of scripts, such as event type-specific temporal flexibility.", "labels": [], "entities": []}, {"text": "Assuming that types of participants provide a strong cue for the type of event they are observed in, we use participant types as a latent variable in our model.", "labels": [], "entities": []}, {"text": "Finally, by modeling event type occurrence using Binomial distributions, we can model event optionality, a characteristic of scripts that previous approaches did not capture.", "labels": [], "entities": []}, {"text": "We evaluate our model on a data set of ESDs collected via web experiments from non-expert annotators by and compare our model against their approach.", "labels": [], "entities": []}, {"text": "Our model achieves an absolute average improvement of 7% over the model of Regneri et al. on the task of event ordering.", "labels": [], "entities": [{"text": "event ordering", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.751658171415329}]}, {"text": "For our unsupervised Bayesian model the limited size of this training set constitutes an additional challenge.", "labels": [], "entities": []}, {"text": "In order to alleviate this problem, we use an informed prior on the word distributions.", "labels": [], "entities": []}, {"text": "Instead of using Dirichlet priors which do not encode a-priori correlations between words, we incorporate a logistic normal distribution with the covariance matrix derived from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 177, "end_pos": 184, "type": "DATASET", "confidence": 0.9762536883354187}]}, {"text": "While we will show that prior knowledge as defined above enables the application of our model to small data sets, we emphasize that the model is generally widely applicable for two reasons.", "labels": [], "entities": []}, {"text": "First, the data, collected using crowdsourcing, is comparatively easy and cheap to extend.", "labels": [], "entities": []}, {"text": "Secondly, our model is domain independent and can be applied to scenario descriptions from any domain without any modification.", "labels": [], "entities": []}, {"text": "Note that parameters were tuned on held-out scenarios, and no scenario-specific tuning was performed.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our evaluation, we evaluate the quality of the event clusters induced by the model and the extent to which the clusters capture the global event ordering underlying the script, as well as the benefit of the GMM and the informed prior knowledge.", "labels": [], "entities": [{"text": "GMM", "start_pos": 210, "end_pos": 213, "type": "DATASET", "confidence": 0.7969642281532288}]}, {"text": "We start by describing data and evaluation metrics.: Test scenarios used in experiments (left), the size of the corresponding corpus (middle), and the average length of an ESD in events (right).", "labels": [], "entities": []}, {"text": "We follow R10 in evaluating induced event types and orderings in a binary classification setting.", "labels": [], "entities": []}, {"text": "R10 collected a gold standard by classifying pairs of event descriptions w.r.t. whether or not they are paraphrases.", "labels": [], "entities": [{"text": "R10", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9160952568054199}]}, {"text": "Our model classifies two event descriptions as equivalent whenever z e 1 = z e 2 . Equivalently, R10 classify ordered pairs of event descriptions as to whether they are presented in their natural order.", "labels": [], "entities": []}, {"text": "Assuming the identity ordering as canonical ordering in the Generalized Mallows Model, event types tending to occur earlier in the script should be assigned lower cluster IDs than event types occurring later.", "labels": [], "entities": []}, {"text": "Thus, whenever z e 1 < z e 2 , our the model predicts that two event descriptions occur in their natural order.", "labels": [], "entities": []}, {"text": "We evaluate the output of our model against the described gold standard, using Precision, Recall and F1 as evaluation metrics, so that our results are directly comparable to R10.", "labels": [], "entities": [{"text": "Precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.998916745185852}, {"text": "Recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9754449129104614}, {"text": "F1", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9961321353912354}, {"text": "R10", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.7791114449501038}]}, {"text": "We tune our parameters on a development set of 5 scenarios which are not used in testing.", "labels": [], "entities": []}, {"text": "presents the results of our two evaluation tasks.", "labels": [], "entities": []}, {"text": "While on the event paraphrase task the R10 system performs slightly better, our model outperforms the R10 system on the event ordering task by a substantial margin of 7 points average F-score.", "labels": [], "entities": [{"text": "R10", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9310199618339539}, {"text": "event ordering task", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.8028465509414673}, {"text": "F-score", "start_pos": 184, "end_pos": 191, "type": "METRIC", "confidence": 0.9970410466194153}]}, {"text": "While both systems perform similarly on the task of event type induction, we induce a joint model for both objectives.", "labels": [], "entities": [{"text": "event type induction", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.6400884091854095}]}, {"text": "The results show that, despite the limited amount of data, and the more complex learning objective, our model succeeds in inducing event types and ordering constraints.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test scenarios used in experiments (left),  the size of the corresponding corpus (middle), and  the average length of an ESD in events (right).", "labels": [], "entities": []}, {"text": " Table 2: Comparison of model variants: For each  scenario: The full model (top), a version without  the GMM (-GMM), and a version with a uniform  Dirichlet prior over language models (-COVAR).", "labels": [], "entities": []}, {"text": " Table 3: Results of our model for the event paraphrase task (left) and event type ordering task (right).", "labels": [], "entities": [{"text": "event type ordering task", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.6543484702706337}]}]}