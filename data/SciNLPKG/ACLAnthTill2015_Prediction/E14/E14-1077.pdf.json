{"title": [{"text": "A Summariser based on Human Memory Limitations and Lexical Competition", "labels": [], "entities": [{"text": "Human Memory Limitations", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.5901214679082235}]}], "abstractContent": [{"text": "Kintsch and van Dijk proposed a model of human comprehension and summarisa-tion which is based on the idea of processing propositions on a sentence-by-sentence basis, detecting argument overlap , and creating a summary on the basis of the best connected propositions.", "labels": [], "entities": []}, {"text": "We present an implementation of that model, which gets around the problem of identifying concepts in text by applying coref-erence resolution, named entity detection, and semantic similarity detection, implemented as a two-step competition.", "labels": [], "entities": [{"text": "coref-erence resolution", "start_pos": 118, "end_pos": 141, "type": "TASK", "confidence": 0.7008508145809174}, {"text": "named entity detection", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.5944617986679077}, {"text": "semantic similarity detection", "start_pos": 171, "end_pos": 200, "type": "TASK", "confidence": 0.7135360836982727}]}, {"text": "We evaluate the resulting summariser against two commonly used extractive summaris-ers using ROUGE, with encouraging results .", "labels": [], "entities": [{"text": "summariser", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.9554459452629089}, {"text": "ROUGE", "start_pos": 93, "end_pos": 98, "type": "METRIC", "confidence": 0.9943310022354126}]}], "introductionContent": [{"text": "Kintsch and van (henceforth KvD) present a model of human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics.", "labels": [], "entities": [{"text": "memory retention", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.6694046258926392}]}, {"text": "It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later.", "labels": [], "entities": []}, {"text": "It has been very influential, particularly in the 1980 and 1990s in educational and cognitive) psychology, and is still today used as a theoretical model of reading and comprehension).", "labels": [], "entities": []}, {"text": "It has also been used for improving education, particularly for the production of better instructional text), and for teaching humans how to read for deep comprehension) and to summarise).", "labels": [], "entities": [{"text": "summarise", "start_pos": 177, "end_pos": 186, "type": "TASK", "confidence": 0.9869242310523987}]}, {"text": "In the summarisation community, the model has been commended for its elegant and explanatory \"deep\" treatment of the summarisation process), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge-and inference-based aspects the model relies on.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.9806157946586609}, {"text": "summarisation process", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.905718058347702}]}, {"text": "We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the construction of the coherence tree as a double competition (firstly of concept partners for word forms, secondly of attachment sites for propositions).", "labels": [], "entities": []}, {"text": "In the KvD model, a text (e.g.) is converted into propositions (see) which have one functor and one or more arguments.", "labels": [], "entities": []}, {"text": "The functor can betaken either from a fixed list of grammatical relations (e.g. or an open class-set of so-called concepts, (e.g. BLOODY; TEACH).", "labels": [], "entities": []}, {"text": "Arguments can be concepts or proposition numbers.", "labels": [], "entities": []}, {"text": "Proposition numbers express embedded semantic structures (e.g. #9 in).", "labels": [], "entities": []}, {"text": "assumed that this tranformation is performed manually; they were able to train humans to do so consistently.", "labels": [], "entities": []}, {"text": "A series of violent, bloody encounters between police and Black Panther members punctuated the early summer days of 1969.", "labels": [], "entities": []}, {"text": "Soon after, a group of black students I teach at California State College, Los Angeles, who were members of the Panther Party, began to complain of continuous harassment bylaw enforcement officers..: Propositions for.", "labels": [], "entities": []}, {"text": "The KvD algorithm is manually simulated in their work, but is described in a mechanistic manner that should in principle lend itself to implementation, once propositions are created.", "labels": [], "entities": []}, {"text": "Propositions form a tree where a proposition is attached to another proposition with which they share at least one argument; attachment higher in the tree is preferred.", "labels": [], "entities": []}, {"text": "The tree is built incrementally; blocks of propositions, each of which roughly corresponding to one sentence, are processed in cycles.", "labels": [], "entities": []}, {"text": "After each cycle, a process of \"forgetting\" is simulated by copying only the most salient propositions to the short-term memory (STM).", "labels": [], "entities": []}, {"text": "This selection is performed by the so-called leading edge strategy (LES), which prefers propositions that are attached more recently and those attached at higher positions.", "labels": [], "entities": []}, {"text": "This algorithms mirrors van model of textual coherence.", "labels": [], "entities": []}, {"text": "When choosing an attachment site for proposition, arguments which are currently in STM are preferred.", "labels": [], "entities": []}, {"text": "A resource-consuming search in long-term memory (LTM) is only triggered if a proposition cannot be attached in STM; in that case a bridging proposition is reintroduced into the tree.", "labels": [], "entities": []}, {"text": "The KvD model can be used to explain human recall of stories, and can also to create a summary of a text.", "labels": [], "entities": []}, {"text": "The most natural way fora human to summarise from scratch is to replace propositions with so-called macropropositions, and the KvD model prefers this style of summary creation.", "labels": [], "entities": []}, {"text": "An example for macroproposition is a statement that generalises over other propositions.", "labels": [], "entities": []}, {"text": "This results in a more abstract version of the text.", "labels": [], "entities": []}, {"text": "However if for any reason it is not possible to create macropropositions (for instance due to lack of deep knowledge representation), a summary can also be created in a simpler way based only on the propositions contained in the text.", "labels": [], "entities": []}, {"text": "In that case, the selection criterion is the number of cycles a proposition has remained in STM.", "labels": [], "entities": []}, {"text": "There are three main stumbling blocks in the way of an implementation of the KvD model: 1.", "labels": [], "entities": []}, {"text": "The automatic creation of propositions from text, and of summary text from summary propositions; 2.", "labels": [], "entities": []}, {"text": "The automatic creation of concepts from words (including coreference resolution); 3.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.9345284998416901}]}, {"text": "The creation of macropropositions, which would require sophisticated knowledge representation and reasoning.", "labels": [], "entities": []}, {"text": "We present a fully automatic version of the KvD model based on the following assumptions: 1.", "labels": [], "entities": []}, {"text": "Current parser technology allows us to reconstruct the compositional semantics of the text well enough to make the KvD model operational, both in terms of creating propositions from text, and in terms of creating reasonably understandable output text from propositions (even if not fully grammatical).", "labels": [], "entities": []}, {"text": "2. We model the lexical variation of how a concept is expressed in a text probabilistically by semantic similarity and coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.8924258649349213}]}, {"text": "This creates a competition between plausible expressions for argument overlap.", "labels": [], "entities": []}, {"text": "3. Our core algorithm is modelled as two competitions: (a) the competition between concept matches as mentioned in the point above; and (b) the competition between possible positions in a tree where a proposition could attach.", "labels": [], "entities": []}, {"text": "4. We also observed that KvD's method of choosing the tree root in the first processing cycle, and to never change it afterwards unless texts are truly incoherent (resorting to multiple trees), is too limiting, in particular in combination with their LES.", "labels": [], "entities": []}, {"text": "Texts can have topic changes and still be perfectly co-herent, particularly if they are longer and less linearly structured than the examples used by KvD.", "labels": [], "entities": [{"text": "KvD", "start_pos": 150, "end_pos": 153, "type": "DATASET", "confidence": 0.9187796711921692}]}, {"text": "We therefore experiment with more flexible root choice strategies.", "labels": [], "entities": []}, {"text": "We have nothing to say on the third and biggest obstacle, the creation of macropropositions.", "labels": [], "entities": []}, {"text": "Nevertheless, the experiments presented here test whether our hypotheses 1 -4 are strong enough to provide our summariser with useful information concerning the discourse structure of the texts.", "labels": [], "entities": []}, {"text": "We test this by comparing its performance to that of two current state-of-the-art summarisers, which instead rely on the sole use of lexical information.", "labels": [], "entities": []}, {"text": "A psychologically-motivated summariser such as ours should be evaluated by comparison to abstractive, i.e., reformulated human summaries, rather than by comparison to extractive summaries.", "labels": [], "entities": [{"text": "summariser", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.9511757493019104}]}, {"text": "We do so using ROUGE, an evaluation framework that supports such comparisons ().", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.8864296078681946}]}, {"text": "The structure of the paper is as follows.", "labels": [], "entities": []}, {"text": "In the next section, we will detail our implementation of the KvD model, with particular emphasis on the creation of propositions, probabilistic concepts, proposition attachment, and root choice.", "labels": [], "entities": [{"text": "proposition attachment", "start_pos": 155, "end_pos": 177, "type": "TASK", "confidence": 0.7386221438646317}]}, {"text": "In Section 4, we will present experiments comparing our summariser against two research extractive summarisers, MEAD and LexRank.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 112, "end_pos": 116, "type": "DATASET", "confidence": 0.7726736068725586}, {"text": "LexRank", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.964576780796051}]}, {"text": "We also test how our inventions including similarity-based concept matching and root choice strategy contribute to performance.", "labels": [], "entities": [{"text": "similarity-based concept matching", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.5693134566148123}]}, {"text": "We compare to related work in Section 3, and draw our conclusions in Section 5.", "labels": [], "entities": []}, {"text": "At the end of each cycle, important propositions (IPs) are selected by the Selector, stored in STM, and thus retained for the next cycle, where they are available for new incoming propositions to attach to.", "labels": [], "entities": []}, {"text": "The selector is a full implementation of KvD's LES, which also updates the recency of propositions reinstantiated from the LTM.", "labels": [], "entities": [{"text": "KvD's LES", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.8857495188713074}]}, {"text": "1 Less important propositions leave the cycle and go into the LTM, which is conceptually a secondary repository of propositions to provide the \"missing links\" when no coherence between the STM and the incoming propositions can be established.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now perform two experiments.", "labels": [], "entities": []}, {"text": "The first tests the contribution of our concept matcher and root change strategy on a small document set we have collected, and compares against two research summarisers.", "labels": [], "entities": []}, {"text": "In the second experiment, we test the performance of our summariser on a much larger and standard dataset.", "labels": [], "entities": []}, {"text": "We will use the intrinsic evaluation strategy of comparison to a gold standard.", "labels": [], "entities": []}, {"text": "Human judgements would be the most credible, but as a cheap alternative, we use ROUGE-L, which has been shown to correlate well to human judgements.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9968240261077881}]}, {"text": "For each sentence, ROUGE-L treats it as a sequence of words, and finds the longest common subsequences (LCSs) with any sentence in a gold standard summary.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.7965145707130432}]}, {"text": "The score is defined as the Fmeasure of the precision and recall of the LCSs.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9993494153022766}, {"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9995847344398499}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9982263445854187}]}, {"text": "The next question is how the gold standard summaries used in ROUGE are defined.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 61, "end_pos": 66, "type": "TASK", "confidence": 0.5420862436294556}]}, {"text": "Because our summariser is deep and has a fine granularity, it should be compared against human-written summaries on a variety of texts.", "labels": [], "entities": [{"text": "summariser", "start_pos": 12, "end_pos": 22, "type": "TASK", "confidence": 0.9508866667747498}]}, {"text": "For the first experiment, we have collected from volunteers 8 human abstractive summaries for each of the 4 short scientific articles or stories we found in (average length: 120 words), and 4 for each of 2 longer political news texts (average length: 523 words).", "labels": [], "entities": []}, {"text": "The volunteers were instructed to condense the text to 1/3 of its length for the short texts, and to 100 words for the longer ones.", "labels": [], "entities": []}, {"text": "They were also instructed not to paraphrase, but to use the words in the text as much as possible.", "labels": [], "entities": []}, {"text": "This was because no summariser in this experiment has a paraphrasing ability.", "labels": [], "entities": []}, {"text": "Nevertheless, not all subjects followed this instruction strictly.", "labels": [], "entities": []}, {"text": "For the second experiment, we use the DUC 2002 dataset).", "labels": [], "entities": [{"text": "DUC 2002 dataset", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.9813864628473917}]}, {"text": "There are 827 texts from news media, of a variety of topics and lengths, among which our script is able to extract titles and contents of 822 documents.", "labels": [], "entities": []}, {"text": "We use the provided single document abstractive summaries, which are of 100 words in length each, as gold standard summaries.", "labels": [], "entities": []}, {"text": "A few of the documents are selected in multiple clusters and therefore have multiple summaries; all of them are used in evaluation.", "labels": [], "entities": []}, {"text": "We compare our summariser against a baseline constructed with the first n words from the original text, where n is the summary length as defined above, and two summarisers: MEAD () is a research summariser which uses a centroid-based paradigm and is known to perform generally well over a range of texts.) uses lexically derived similarities in its similarity graph of sentences, sharing the same idea of sentence similarity with MEAD.", "labels": [], "entities": []}, {"text": "Note that both summarisers are extractive.", "labels": [], "entities": []}, {"text": "We illustrate what our summaries look like in, where we asked the summariser to give us summaries as close to 20 and 50 word summaries as possible, with showing the underlying propositions.", "labels": [], "entities": []}, {"text": "In contrast, MEAD can only extract sentences as-is (thus not as flexible in length), and does not have meaning blocks like our propositions.", "labels": [], "entities": []}, {"text": "Encounters between police and Black Panther members.", "labels": [], "entities": []}, {"text": "Students to complain of harassment.", "labels": [], "entities": []}, {"text": "Automobiles Panther Party signs glued to bumpers.", "labels": [], "entities": []}, {"text": "Bloody encounters between police and Black Panther members punctuated the summer days of 1969.", "labels": [], "entities": []}, {"text": "Students to complain of continuous harassment bylaw enforcement officers.", "labels": [], "entities": []}, {"text": "They receiving many traffic citations.", "labels": [], "entities": []}, {"text": "Automobiles with Panther Party signs glued to their bumpers.", "labels": [], "entities": []}, {"text": "Ito determine whether we were hearing the voice of paranoia or reality.: Summary propositions for the first summary above.", "labels": [], "entities": []}, {"text": "We create summaries for all three summarisers following this procedure: We provide sentencesplit texts and their headlines (not needed by LexRank), and run the summarisers in such away as to produce a summary of the same length as stipulated for the standard summaries.", "labels": [], "entities": [{"text": "LexRank", "start_pos": 138, "end_pos": 145, "type": "DATASET", "confidence": 0.9664773941040039}]}, {"text": "Our summariser controls word count precisely; we require MEAD to produce summaries close to the length (allowing variations), and for LexRank we allow it to go beyond the limit by less than one sentence and then discard the exceeding part in the sentence with the lowest salience.", "labels": [], "entities": [{"text": "summariser", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9572318196296692}, {"text": "MEAD", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9296835660934448}, {"text": "LexRank", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.9455777406692505}]}, {"text": "The results of Experiment 1 are summarised in Table 4.", "labels": [], "entities": []}, {"text": "As is well-known from similar experiments, it is hard beating the first n baseline due to the fact that journalistic style (in the long texts) already puts a summary of each text first.", "labels": [], "entities": []}, {"text": "It is slightly surprising that this effect also holds for the short texts (literary style).", "labels": [], "entities": []}, {"text": "It is of note that our KvD summariser beats both MEAD and LexRank on this dataset, which is shelved away during development, with statistical significance on the long texts: the 95%-confidence interval of ours is 0.403 -0.432, and that of MEAD is 0.", "labels": [], "entities": [{"text": "KvD summariser", "start_pos": 23, "end_pos": 37, "type": "DATASET", "confidence": 0.7956388592720032}, {"text": "MEAD", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.913124680519104}, {"text": "LexRank", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9579180479049683}, {"text": "MEAD", "start_pos": 239, "end_pos": 243, "type": "DATASET", "confidence": 0.83845055103302}]}, {"text": "We test whether concept matching is beneficial by switching off similarity derived from distributional semantics, or switching off all \"word information\" which includes distributional semantics, lemmatisation, and coreference detection, i.e. to consider matching only for the same word.", "labels": [], "entities": [{"text": "concept matching", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7473608255386353}, {"text": "coreference detection", "start_pos": 214, "end_pos": 235, "type": "TASK", "confidence": 0.9144139587879181}]}, {"text": "Performance deteriorates when concept matching is switched off, substantially if all word information is off.", "labels": [], "entities": [{"text": "concept matching", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.7299675047397614}]}, {"text": "This confirms our hypothesis that one of the cornerstones of KvD, concept matching, can beat least partially simulated using today's distributional semantics methods.", "labels": [], "entities": [{"text": "concept matching", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.7150605171918869}]}, {"text": "As for root change, turning it off seems to hurt performance on the longer texts, but not soon the shorter ones, which matches our speculation that root change is useful for longer texts, which have some focus shifts.", "labels": [], "entities": []}, {"text": "The result of Experiment 2 is shown in.", "labels": [], "entities": []}, {"text": "This experiment on a large dataset demonstrates that our summariser performs in the ballpark of typical results of extractive summarisers, although it is still statistically a little worse than the state-ofthe-art MEAD (whose F-measure 95%-confidence interval is 0.349 -0.367).", "labels": [], "entities": [{"text": "summariser", "start_pos": 57, "end_pos": 67, "type": "TASK", "confidence": 0.9628807306289673}, {"text": "MEAD", "start_pos": 214, "end_pos": 218, "type": "METRIC", "confidence": 0.9649619460105896}, {"text": "F-measure 95%-confidence interval", "start_pos": 226, "end_pos": 259, "type": "METRIC", "confidence": 0.946502435207367}]}, {"text": "Our summariser is good at precision because many summaries produced have not used up the 100-word limit, making the average summary length smaller than that of MEAD's.", "labels": [], "entities": [{"text": "summariser", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9354112148284912}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9987666606903076}, {"text": "MEAD's", "start_pos": 160, "end_pos": 166, "type": "DATASET", "confidence": 0.8819208443164825}]}, {"text": "This indicates that our summariser might be good at very short summaries, or we could improve the memory selection to allow fora more diversified important proposition set.", "labels": [], "entities": [{"text": "summariser", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.9564090967178345}]}, {"text": "Considering this, and the fact that we have many parameters not tuned for the task, and we have not utilised the structural / positional features (whose importance is shown in the first-n baseline), the result is still encouraging.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: ROUGE-L F-measures for Experiment 1.", "labels": [], "entities": [{"text": "ROUGE-L F-measures", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.8578327298164368}]}, {"text": " Table 5: ROUGE-L scores for Experiment 2.", "labels": [], "entities": [{"text": "ROUGE-L scores", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9613062143325806}]}]}