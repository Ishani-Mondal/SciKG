{"title": [{"text": "Acquiring a Dictionary of Emotion-Provoking Events", "labels": [], "entities": [{"text": "Acquiring a Dictionary of Emotion-Provoking", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7801087975502015}]}], "abstractContent": [{"text": "This paper is concerned with the discovery and aggregation of events that provoke a particular emotion in the person who experiences them, or emotion-provoking events.", "labels": [], "entities": []}, {"text": "We first describe the creation of a small manually-constructed dictionary of events through a survey of 30 subjects.", "labels": [], "entities": []}, {"text": "Next, we describe first attempts at automatically acquiring and aggregating these events from web data, with a baseline from previous work and some simple extensions using seed expansion and clustering.", "labels": [], "entities": []}, {"text": "Finally , we propose several evaluation measures for evaluating the automatically acquired events, and perform an evaluation of the effectiveness of automatic event extraction .", "labels": [], "entities": [{"text": "event extraction", "start_pos": 159, "end_pos": 175, "type": "TASK", "confidence": 0.7191055864095688}]}], "introductionContent": [{"text": "\"You look happy today, did something good happen?\"", "labels": [], "entities": []}, {"text": "This is a natural question inhuman dialogue, and most humans could think of a variety of answers, such as \"I met my friends\" or \"I passed a test.\"", "labels": [], "entities": []}, {"text": "In this work, we concern ourselves with creating resources that answer this very question, or more formally \"given a particular emotion, what are the most prevalent events (or situations, contexts) that provoke it?\"", "labels": [], "entities": []}, {"text": "1 Information about these emotion-provoking events is potentially useful for emotion recognition (recognizing emotion based on events mentioned in a dialogue), response generation (providing an answer to emotion-related questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population).", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7287129759788513}, {"text": "response generation", "start_pos": 160, "end_pos": 179, "type": "TASK", "confidence": 0.8660597801208496}, {"text": "answering social-science related questions", "start_pos": 236, "end_pos": 278, "type": "TASK", "confidence": 0.8606480360031128}]}, {"text": "While there is very little previous research on this subject, one previous work of note by focused on emotion-provoking events purely from the viewpoint of emotion recognition.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7320348024368286}]}, {"text": "They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors emotion classifier for dialog systems and found that the classifier significantly outperforms baseline methods.", "labels": [], "entities": []}, {"text": "This method provides both an inspiration and a baseline for our work, but still lacks in that it makes no attempt to measure the quality of the extracted events, aggregate similar events, or rank events by prevalence, all essential factors when attempting to use extracted events for applications other than simple emotion recognition.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 315, "end_pos": 334, "type": "TASK", "confidence": 0.717415452003479}]}, {"text": "In this paper, we describe work on creating prevalence-ranked dictionaries of emotionprovoking events through both manual labor and automatic information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.7328419089317322}]}, {"text": "To create a manual dictionary of events, we perform a survey asking 30 participants to describe events that caused them to feel a particular emotion, and manually cleaned and aggregated the results into a ranked list.", "labels": [], "entities": []}, {"text": "Next, we propose several methods for extracting events automatically from large data from the Web, which will allow us to increase the coverage over the smaller manually created dictionary.", "labels": [], "entities": []}, {"text": "We start with's patterns as a baseline, and examine methods for improving precision and coverage through the use of seed expansion and clustering.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9969176054000854}]}, {"text": "Finally, we discuss evaluation measures for the proposed task, and perform an evaluation of the automatically extracted emotion-provoking events.", "labels": [], "entities": []}, {"text": "The acquired events will be provided publicly upon acceptance of the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Work on information extraction typically uses accuracy and recall of the extracted information as an evaluation measure.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.819789320230484}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.998784601688385}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9971330165863037}]}, {"text": "However, in this work, we found that it is difficult to assign a clear-cut distinction between whether an event provokes a particular emotion or not.", "labels": [], "entities": []}, {"text": "In addition, recall is difficult to measure, as there are essentially infinitely many events.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9985333681106567}]}, {"text": "Thus, in this section, we propose two new evaluation measures to measure the precision and recall of the events that we recovered in this task.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9993245601654053}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9972856044769287}]}, {"text": "To evaluate the precision of the events extracted by our method, we focus on the fact that an event might provoke multiple emotions, but usually these emotions can be ranked in prominence or appropriateness.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9977134466171265}]}, {"text": "This is, in away, similar to the case of information retrieval, where there maybe many search results, but some are more appropriate than others.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.779763400554657}]}, {"text": "Based on this observation, we follow the information retrieval literature) in adapting mean reciprocal rank (MRR) as an evaluation measure of the accuracy of our extraction.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 87, "end_pos": 113, "type": "METRIC", "confidence": 0.9161650836467743}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9980192184448242}]}, {"text": "In our case, one event can have multiple emotions, so for each event that the system outputs, we ask an annotator to assign emotions in descending order of prominence or appropriateness, and assess MRR with respect to these ranked emotions.", "labels": [], "entities": [{"text": "MRR", "start_pos": 198, "end_pos": 201, "type": "METRIC", "confidence": 0.980701744556427}]}, {"text": "We also measure recall with respect to the manually created dictionary described in Section 2, which gives us an idea of what percent of common emotions we were able to recover.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9994348883628845}]}, {"text": "It should be noted that in order to measure recall, it is necessary to take a matching between the events output by the system and the events in the previously described list.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9972375631332397}]}, {"text": "While it would be ideal to do this automatically, this is difficult due to small lexical variations between the system output and the list.", "labels": [], "entities": []}, {"text": "Thus, for the current work we perform manual matching between the system hypotheses and the references, and hope to examine other ways of matching in future work.", "labels": [], "entities": []}, {"text": "In this section, we describe an experimental evaluation of the accuracy of automatic extraction of emotion-provoking events.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9983803033828735}, {"text": "automatic extraction of emotion-provoking events", "start_pos": 75, "end_pos": 123, "type": "TASK", "confidence": 0.7708614110946655}]}, {"text": "We use Twitter 3 as a source of data, as it is it provides a massive amount of information, and also because users tend to write about what they are doing as well as their thoughts, feelings and emotions.", "labels": [], "entities": []}, {"text": "We use a data set that contains more than 30M English tweets posted during the course of six weeks in June and July of 2012.", "labels": [], "entities": []}, {"text": "To remove noise, we perform a variety of preprocessing, removing emoticons and tags, normalizing using the scripts provided by Han and Baldwin (2011), and.", "labels": [], "entities": []}, {"text": "CoreNLP 4 was used to get the information about part-of-speech, syntactic parses, and lemmas.", "labels": [], "entities": []}, {"text": "We prepared four systems for comparison.", "labels": [], "entities": []}, {"text": "As a baseline, we use a method that only uses the original seed pattern mentioned in Section 3 to acquire emotion-provoking events.", "labels": [], "entities": []}, {"text": "We also evaluate expansions to this method with clustering, with pattern expansion, and with both.", "labels": [], "entities": []}, {"text": "We set a 10 iteration limit on the Espresso algorithm and after each iteration, we add the 20  The results are found in.", "labels": [], "entities": []}, {"text": "From these results we can see that clustering the events causes a significant gain on both MRR and recall, regardless of whether we use Espresso or not.", "labels": [], "entities": [{"text": "MRR", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.7639420032501221}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9993140697479248}]}, {"text": "Looking at the results for Espresso, we see that it allows for small boost in recall when used on its own, due to the fact that the additional patterns help recover more instances of each event, making the estimate of frequency counts more robust.", "labels": [], "entities": [{"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9990645051002502}]}, {"text": "However, Espresso is more effective when used in combination with clustering, showing that both methods are capturing different varieties of information, both of which are useful for the task.", "labels": [], "entities": []}, {"text": "In the end, the combination of pattern expansion and clustering achieves an MRR of 71.7% and recall of 15.4%.", "labels": [], "entities": [{"text": "pattern expansion", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7976770401000977}, {"text": "MRR", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.998936116695404}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9997923970222473}]}, {"text": "While the MRR could be deemed satisfactory, the recall is still relatively low.", "labels": [], "entities": [{"text": "MRR", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.4307677745819092}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9996719360351562}]}, {"text": "One reason for this is that due to the labor-intensive manual evaluation, it is not realistic to check many more than the top 20 extracted events for each emotion, making automatic evaluation metrics the top on the agenda for future work.", "labels": [], "entities": []}, {"text": "We exclude disgust, as the seed only matched 26 times over entire corpus, not enough fora reasonable evaluation.", "labels": [], "entities": []}, {"text": "However, even without considering this, we found that the events extracted from Twitter were somewhat biased towards common, everyday events, or events regarding love and dating.", "labels": [], "entities": []}, {"text": "On the other hand, our annotators produced a wide variety of events including both everyday events, and events that do not happen everyday, but leave a particularly strong impression when encountered.", "labels": [], "entities": []}, {"text": "This can be seen particularly in the accuracy and recall results by emotion for the best system shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9994159936904907}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9989608526229858}]}, {"text": "We can see that for some emotions we achieved recall approaching 25%, but for surprise we didn't manage to extract any of the emotions created by the annotators at all, instead extracting more mundane events such as \"surprised I'm not fat yet\" or \"surprised my mom hasn't called me yet.\"", "labels": [], "entities": [{"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9995456337928772}]}, {"text": "Covering the rare, but important events is an interesting challenge for expansions to this work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Average MRR and recall by emotion for  the Espresso + clustering method.", "labels": [], "entities": [{"text": "MRR", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.8013498783111572}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.999107301235199}]}]}