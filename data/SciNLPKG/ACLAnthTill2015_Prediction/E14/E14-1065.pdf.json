{"title": [{"text": "Augmenting Translation Models with Simulated Acoustic Confusions for Improved Spoken Language Translation", "labels": [], "entities": [{"text": "Augmenting Translation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9466993808746338}, {"text": "Spoken Language Translation", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.6265575885772705}]}], "abstractContent": [{"text": "We propose a novel technique for adapting text-based statistical machine translation to deal with input from automatic speech recognition in spoken language translation tasks.", "labels": [], "entities": [{"text": "text-based statistical machine translation", "start_pos": 42, "end_pos": 84, "type": "TASK", "confidence": 0.6633855104446411}, {"text": "automatic speech recognition in spoken language translation tasks", "start_pos": 109, "end_pos": 174, "type": "TASK", "confidence": 0.7077541165053844}]}, {"text": "We simulate likely misrecognition errors using only a source language pronunciation dictionary and language model (i.e., without an acoustic model), and use these to augment the phrase table of a standard MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 205, "end_pos": 207, "type": "TASK", "confidence": 0.9625758528709412}]}, {"text": "The augmented system can thus recover from recognition errors during decoding using synthesized phrases.", "labels": [], "entities": []}, {"text": "Using the outputs of five different English ASR systems as input, we find consistent and significant improvements in translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.9539033770561218}]}, {"text": "Our proposed technique can also be used in conjunction with lattices as ASR output, leading to further improvements.", "labels": [], "entities": [{"text": "ASR", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.909598171710968}]}], "introductionContent": [{"text": "Spoken language translation (SLT) systems generally consist of two components: (i) an automatic speech recognition (ASR) system that transcribes source language utterances and (ii) a machine translation (MT) system that translates the transcriptions into the target language.", "labels": [], "entities": [{"text": "Spoken language translation (SLT)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.9035807152589163}, {"text": "automatic speech recognition (ASR)", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.7799816926320394}, {"text": "machine translation (MT)", "start_pos": 183, "end_pos": 207, "type": "TASK", "confidence": 0.837751817703247}]}, {"text": "These two components are usually developed independently and then combined and integrated.", "labels": [], "entities": []}, {"text": "While this architecture is attractive since it relies only on components that are independently useful, such systems face several challenges.", "labels": [], "entities": []}, {"text": "First, spoken language tends to be quite different from the highly edited parallel texts that are available to train translation systems.", "labels": [], "entities": []}, {"text": "For example, disfluencies, such as repeated words or phrases, restarts, and revisions of content, are frequent in spontaneous speech, 1 while these are usually absent in written texts.", "labels": [], "entities": []}, {"text": "In addition, ASR outputs typically lack explicit segmentation into sentences, as well as reliable casing and punctuation information, which are crucial for MT and other text-based language processing applications (.", "labels": [], "entities": [{"text": "ASR outputs", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9225834906101227}, {"text": "MT", "start_pos": 156, "end_pos": 158, "type": "TASK", "confidence": 0.9819552302360535}]}, {"text": "Second, ASR systems are imperfect and make recognition errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9901099801063538}]}, {"text": "Even high quality systems make recognition errors, especially in acoustically similar words with similar language model scores, for example morphological substitutions like confusing bare stem and past tense forms, and in high-frequency short words (function words) which often lack both disambiguating context and are subject to reduced pronunciations (.", "labels": [], "entities": []}, {"text": "One would expect that training an MT system on ASR outputs (rather than the usual writtenstyle texts) would improve matters.", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9780805706977844}, {"text": "ASR outputs", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.8953582942485809}]}, {"text": "Unfortunately, there are few corpora of speech paired with text translations into a second language that could be used for this purpose.", "labels": [], "entities": []}, {"text": "This has been an incentive to various MT adaptation approaches and development of speech-input MT systems.", "labels": [], "entities": [{"text": "MT adaptation", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.9901418685913086}, {"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.902978777885437}]}, {"text": "MT adaptation has been done via input text pre-processing, by transformation of spoken language (ASR output) into written language (MT input) (; via decoding ASR nbest lists), or confusion networks (, or lattices (; via additional translation features capturing acoustic information (); and with methods that follow a paradigm of unified decoding (.", "labels": [], "entities": [{"text": "MT adaptation", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9903349578380585}]}, {"text": "In line with the previous research, we too adapt a standard MT system to a speech-input MT, but by altering the translation model itself so it is better able to deal with ASR output).", "labels": [], "entities": [{"text": "MT", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.9613763689994812}]}, {"text": "We address speech translation in a resourcedeficient scenario, specifically, adapting MT systems to SLT when ASR is unavailable.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7230780869722366}, {"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9518333077430725}]}, {"text": "We augment a discriminative set that translation models rescore with synthetic translation options.", "labels": [], "entities": []}, {"text": "These automatically generated translation rules (henceforth synthetic phrases) are noisy variants of observed translation rules with simulated plausible speech recognition errors ( \u00a72).", "labels": [], "entities": []}, {"text": "To simulate ASR errors we generate acoustically and distributionally similar phrases to a source (English) phrase with a phonologically-motivated algorithm ( \u00a74).", "labels": [], "entities": [{"text": "ASR errors", "start_pos": 12, "end_pos": 22, "type": "TASK", "confidence": 0.8793553709983826}]}, {"text": "Likely phonetic substitutions are learned with an unsupervised algorithm that produces clusters of similar phones ( \u00a73).", "labels": [], "entities": []}, {"text": "We show that MT systems augmented with synthetic phrases increase the coverage of input sequences that can be translated, and yield significant improvement in the quality of translated speech ( \u00a76).", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9879751801490784}]}, {"text": "This work makes several contributions.", "labels": [], "entities": []}, {"text": "Primary is our framework to adapt MT to SLT by populating translation models with synthetic phrases.", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9884045124053955}, {"text": "SLT", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.781821072101593}]}, {"text": "Second, we propose a novel method to generate acoustic confusions that are likely to be encountered in ASR transcription hypotheses.", "labels": [], "entities": [{"text": "ASR transcription hypotheses", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.9396032094955444}]}, {"text": "Third, we devise simple and effective phone clustering algorithm.", "labels": [], "entities": [{"text": "phone clustering", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7039659470319748}]}, {"text": "All aforementioned algorithms work in a low-resource scenario, without recourse to audio data, speech transcripts, or ASR outputs: our method to predict likely recognition errors uses phonological rather than acoustic information and does not depend on a specific ASR system.", "labels": [], "entities": [{"text": "ASR outputs", "start_pos": 118, "end_pos": 129, "type": "TASK", "confidence": 0.8959460854530334}]}, {"text": "Since our source language is English, we operate on a phone level and employ a pronunciation dictionary and a language model, but the algorithm can in principle be applied without pronunciation dictionary for languages with a phonemic orthography.", "labels": [], "entities": []}], "datasetContent": [{"text": "To establish the effectiveness and robustness of our approach, we conducted two sets of experiments-expASR and expMultilingual-with transcribed and In this set of experiments we compare baseline systems performance to a performance of systems augmented with synthetic phrases on (1) reference transcriptions, (2) 1-best hypotheses from all released ASR systems, and (3) a set of ASR lattices produced by).", "labels": [], "entities": []}, {"text": "8 Experiments with individual systems are aimed to validate that MT augmented with synthetic phrases can better translate ASR outputs with recognition errors and sequences that were not observed in the MT training data.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9798619747161865}, {"text": "ASR outputs", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.8583860993385315}, {"text": "MT training", "start_pos": 202, "end_pos": 213, "type": "TASK", "confidence": 0.8745522499084473}]}, {"text": "Consistency in performance across different ASRs is expected if our approach to generate plausible misrecognition variants is universal, rather than biased to a specific system.", "labels": [], "entities": [{"text": "ASRs", "start_pos": 44, "end_pos": 48, "type": "TASK", "confidence": 0.9680642485618591}]}, {"text": "Comparison of 1-best system with synthetic phrases to lattice decoding setup without synthetic phrases should demonstrate whether nbest plausible misrecognition variants that we generate assemble multiple paths through a lattice.", "labels": [], "entities": []}, {"text": "The purpose of expMultilingual is to show that translation improvement is consistent across different target languages.", "labels": [], "entities": [{"text": "translation improvement", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.9442876279354095}]}, {"text": "This multilingual experiment is interesting because typologically different languages pose different challenges to translation (degree and locality of reordering, morphological richness, etc.).", "labels": [], "entities": [{"text": "translation", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.9729761481285095}]}, {"text": "By showing that we improve results across languages (even with the same underlying ASR system), we show that our technique is robust to the different demands that languages place on the translation model.", "labels": [], "entities": []}, {"text": "We could not find any publicly available multilingual data sets of the translated speech, 9 therefore we constructed anew test set.", "labels": [], "entities": []}, {"text": "We use our in-house speech recognizer and evaluate on locally crawled and pre-processed TED audio and text data.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7217645645141602}]}, {"text": "We build SLT systems for five target languages: French, German, Russian, Hebrew, and Hindi.", "labels": [], "entities": [{"text": "SLT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.985842764377594}]}, {"text": "Consequently, our test systems are diverse typologically and trained on corpora of different sizes.", "labels": [], "entities": []}, {"text": "We sample a test set of seven talks, representing approximately two hours of English speech, for which we have translations to all five languages; 10 talks are listed in.", "labels": [], "entities": []}, {"text": "Due to segmentation differences in the released TED (text) corpora and then several automatic preprocessing stages, numbers of sentences for the same talks are not identical across languages.", "labels": [], "entities": []}, {"text": "Therefore, we select English-French system as an oracle (this is the largest dataset), and first align it with the ASR output.", "labels": [], "entities": []}, {"text": "Then, we filter out test sets for non-French MT systems, to retain only sentence pairs that are included in the English-French test set.", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9800841808319092}]}, {"text": "Thus, our test sets for non-French MT systems are smaller, and source-side sentences in the English-French MT is a superset of source-side sentences in all five languages.", "labels": [], "entities": [{"text": "MT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9687497019767761}]}, {"text": "Training, tuning, and test corpora sizes are listed in.", "labels": [], "entities": []}, {"text": "Same training and development sets were used in both expASR and expMultilingual experiments.", "labels": [], "entities": [{"text": "expASR", "start_pos": 53, "end_pos": 59, "type": "DATASET", "confidence": 0.7844492197036743}]}], "tableCaptions": [{"text": " Table 2. Same  training and development sets were used in both  expASR and expMultilingual experiments.", "labels": [], "entities": []}, {"text": " Table 2: Number of sentences in training, dev and  expMultilingual test corpora.", "labels": [], "entities": []}, {"text": " Table 1: Test set of TED talks.", "labels": [], "entities": []}, {"text": " Table 3: Sizes of phrase tables from the baseline  systems, and phrase tables with synthetic phrases.", "labels": [], "entities": []}, {"text": " Table 4: Phrasal coverage of recognition errors  that our technique is able to predict. These are  raw counts of 1-gram and 2-gram types that are  OOVs in the baseline system and are recovered  by our method when we augment the system with  plausible misrecognitions. Percentages in paren- theses show OOV rate reduction due to recovered  n-grams.", "labels": [], "entities": [{"text": "Phrasal coverage", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.753334641456604}, {"text": "OOV rate reduction", "start_pos": 303, "end_pos": 321, "type": "METRIC", "confidence": 0.9729284445444742}]}, {"text": " Table 5: Comparison of the baseline translation  systems with the systems augmented with syn- thetic phrases. We measure EN-FR MT perfor- mance on the tst2011 test set: reference tran- scripts and ASR outputs on from five systems  and their ROVER combination. Improvements in  translation of all ASR outputs are statistically sig- nificant. This confirms the claim that incorporat- ing simulated ASR errors via synthetic phrases ef- fectively adapts MT to SLT scenario.", "labels": [], "entities": [{"text": "MT", "start_pos": 128, "end_pos": 130, "type": "TASK", "confidence": 0.86055988073349}, {"text": "tst2011 test set", "start_pos": 152, "end_pos": 168, "type": "DATASET", "confidence": 0.8628193934758505}, {"text": "MT", "start_pos": 451, "end_pos": 453, "type": "TASK", "confidence": 0.9692888855934143}]}, {"text": " Table 6: Comparison of the baseline EN-FR trans- lation systems with the systems augmented with  synthetic phrases, in 1-best and lattice decoding  setups. 1-best synthetic system significantly out- performs baseline lattice decoding setup. Addi- tional improvement in lattice decoding with syn- thetic phrases suggests that lattice decoding and  phrase table adaptation are two complementary  strategies.", "labels": [], "entities": [{"text": "phrase table adaptation", "start_pos": 348, "end_pos": 371, "type": "TASK", "confidence": 0.6312762498855591}]}, {"text": " Table 7: Comparison of the baseline translation  systems with the systems augmented with syn- thetic phrases. We measure MT performance on  the reference transcripts and ASR outputs. Con- sistent improvements are observed in four out of  five languages.", "labels": [], "entities": [{"text": "MT", "start_pos": 122, "end_pos": 124, "type": "TASK", "confidence": 0.9449528455734253}]}]}