{"title": [{"text": "Map Translation Using Geo-tagged Social Media", "labels": [], "entities": [{"text": "Map Translation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.816002607345581}]}], "abstractContent": [{"text": "This paper discusses the problem of map translation, of servicing spatial entities in multiple languages.", "labels": [], "entities": [{"text": "map translation", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.73848095536232}]}, {"text": "Existing work on entity translation harvests translation evidence from text resources, not considering spatial locality in translation.", "labels": [], "entities": [{"text": "entity translation", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7556336522102356}]}, {"text": "In contrast , we mine geo-tagged sources for multilingual tags to improve recall, and consider spatial properties of tags for translation to improve precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.998170018196106}, {"text": "precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.995877742767334}]}, {"text": "Our approach empirically improves accuracy from 0.562 to 0.746 using Taiwanese spatial entities.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9993020296096802}]}], "introductionContent": [{"text": "A map is becoming an essential online service for mobile devices, providing a current location and generating directions to spatial entities (SEs).", "labels": [], "entities": []}, {"text": "Although major map services aim to support a map in more than 100 local languages, their current support is often biased either to English or local maps.", "labels": [], "entities": []}, {"text": "For example, contrasts richly populated Taiwanese entities (in the local language) whereas only some of those entities are translated in English version.", "labels": [], "entities": []}, {"text": "Our goal is to translate richly populated SEs into another language, in the finer granularity such as restaurants.", "labels": [], "entities": []}, {"text": "A baseline approach would be adopting existing work on entity transliteration work, which uses phonetic similarity, such as translating 'Barack Obama' into '\u8d1d \u62c9 \u514b\u00b7\u5965 \u5df4 \u9a6c'.", "labels": [], "entities": []}, {"text": "Another approach is using automatically-harvested or manually-built translation resources, such as multilingual Gazetteer (or, SE dictionary 1 ).", "labels": [], "entities": []}, {"text": "However, these resources are often limited to well-known or large SEs, which leads to translation with near-perfect precision but low recall.", "labels": [], "entities": [{"text": "translation", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.9709209203720093}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9937605261802673}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9974506497383118}]}, {"text": "Moreover, blindly applying existing entity translation methods to SE translation leads to extremely low accuracy.", "labels": [], "entities": [{"text": "entity translation", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7678966522216797}, {"text": "SE translation", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.9500671029090881}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.997385561466217}]}, {"text": "For example, an SE '\u5341 \u5206 \u8eca \u7ad9' should be translated into 'Shifen station', where '\u5341 \u5206' is transliterated to, whereas '\u8eca \u7ad9' is semantically translated based on its meaning 'station'.", "labels": [], "entities": []}, {"text": "However, due to this complex nature often observed in SE translation, an off-the-shelf translation service (e.g., Google Translate) returns 'very station' 2 as an output.", "labels": [], "entities": [{"text": "SE translation", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.931942492723465}]}, {"text": "In addition, SE names are frequently abbreviated so that we cannot infer the meanings to semantically translate them.", "labels": [], "entities": [{"text": "SE names", "start_pos": 13, "end_pos": 21, "type": "TASK", "confidence": 0.9033588767051697}]}, {"text": "For instance, 'United Nations' is often abbreviated into 'UN' and its translation is also often abbreviated.", "labels": [], "entities": [{"text": "United Nations'", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.7966105341911316}]}, {"text": "As a result, the abbreviation in the two languages, (UN, \u8054\u5408\u56fd), shares neither phonetic nor semantic similarity.", "labels": [], "entities": []}, {"text": "To overcome these limitations, we propose to extract and leverage properties of SEs from asocial media, namely Flickr.", "labels": [], "entities": [{"text": "Flickr", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.9372417330741882}]}, {"text": "Especially, we exploit co-occurrence of names in two different languages.", "labels": [], "entities": []}, {"text": "For example, '\u53f0\u5317' co-occurs with its English translation 'Taipei' as tags on the same photo.", "labels": [], "entities": []}, {"text": "This is strong evidence that they are translations of each other.", "labels": [], "entities": []}, {"text": "In addition to co-occurrence, we leverage spatial properties of SEs.", "labels": [], "entities": []}, {"text": "For example, among tags that frequently co-occur with '\u53f0\u5317', such as 'Taipei' and 'Canon', 'Taipei' is: Overview of symbols more likely to be its correct translation because the spatial distributions of the two tags are similarly skewed in the same area.", "labels": [], "entities": []}, {"text": "Our approach significantly improves the F1-score (0.562 to 0.746), compared to an off-the-shelf translators.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9997127652168274}]}], "datasetContent": [{"text": "Photo Data and Ground Truth: We crawled 227,669 photos taken in Taipei from Flickr, which also provided GPS coordinates of photos.", "labels": [], "entities": [{"text": "Flickr", "start_pos": 76, "end_pos": 82, "type": "DATASET", "confidence": 0.5186110138893127}]}, {"text": "We took a set D of 148,141 photos containing both Chinese and English tags and manually labelled 200 gold standard Chinese-English SE pairs whose names appeared together in at least one photo in D.", "labels": [], "entities": []}, {"text": "Administrative Hierarchy: An administrative hierarchy was obtained from Taiwan Geographical Names Information System 4 . Baselines: We chose baselines available for many languages except for the gazetteer and excluded methods that used specific textual corpora.", "labels": [], "entities": [{"text": "Taiwan Geographical Names Information System 4", "start_pos": 72, "end_pos": 118, "type": "DATASET", "confidence": 0.8576451043287913}]}, {"text": "\u2022 Phonetic Similarity (PH) ( \u2022 Off-the-  Comparison to Baselines: The proposed approach (SB + PN) with or without the administrative hierarchy provided higher Rand F1 than did the baseline methods).", "labels": [], "entities": [{"text": "Rand F1", "start_pos": 159, "end_pos": 166, "type": "METRIC", "confidence": 0.9309984743595123}]}, {"text": "The baseline methods showed generally low P, R, and F1.", "labels": [], "entities": [{"text": "P", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9947509169578552}, {"text": "R", "start_pos": 45, "end_pos": 46, "type": "METRIC", "confidence": 0.9711933732032776}, {"text": "F1", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9994526505470276}]}, {"text": "Especially, the gazetteer produced high precision, but poor recall because it could not translate lesser-known SEs such as '\u5154\u5b50\u9910\u5ef3 (To House)' and '\u5178\u83ef\u65d7\u8266\u9928 (Denwell Restaurant)'.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9989965558052063}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9993994235992432}, {"text": "Denwell Restaurant)'", "start_pos": 153, "end_pos": 173, "type": "DATASET", "confidence": 0.9112931489944458}]}, {"text": "Effect of SB and PN: We experimented on the effect of the combinations of the features (Table 6).", "labels": [], "entities": []}, {"text": "Using all the features FB+SB+PN with hierarchy, which translated the upper level of the hierarchy with FB and the lower level with SB, showed the best effectiveness.", "labels": [], "entities": [{"text": "FB", "start_pos": 103, "end_pos": 105, "type": "METRIC", "confidence": 0.5206195116043091}]}, {"text": "Simple FB gave both low precision and very low recall regardless of whether we used the hierarchy.", "labels": [], "entities": [{"text": "FB", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.6888684630393982}, {"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9992169141769409}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9995074272155762}]}, {"text": "Replacing FB with SB yielded both higher F1 and higher MRR.", "labels": [], "entities": [{"text": "FB", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.8393670916557312}, {"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9996451139450073}, {"text": "MRR", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9960417747497559}]}, {"text": "PN increased F1, especially greatly when it was used with SB or the hierarchy because PN filtered out different types of noises, non-SEs.", "labels": [], "entities": [{"text": "F1", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9996918439865112}]}, {"text": "Applying PN, we classified 361 non-SEs and 6 SEs as noises in total.", "labels": [], "entities": []}, {"text": "Despite some misclassifications, it (b) With given hierarchy: Effect of FB, SB, PN, and the hierarchy improved the overall accuracy by ignoring highly ranked non-SEs such as 'dog' and 'food'.", "labels": [], "entities": [{"text": "FB", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.992326021194458}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9991474151611328}]}], "tableCaptions": [{"text": " Table 5: P, R, and F1 of baselines", "labels": [], "entities": [{"text": "F1", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.9981093406677246}]}, {"text": " Table 6: Effect of FB, SB, PN, and the hierarchy", "labels": [], "entities": [{"text": "FB", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.9532791972160339}]}]}