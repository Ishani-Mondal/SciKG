{"title": [{"text": "Improving the Lexical Function Composition Model with Pathwise Optimized Elastic-Net Regression", "labels": [], "entities": [{"text": "Lexical Function Composition", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.7680636048316956}]}], "abstractContent": [{"text": "In this paper, we show that the lexical function model for composition of dis-tributional semantic vectors can be improved by adopting a more advanced regression technique.", "labels": [], "entities": []}, {"text": "We use the pathwise coordinate-descent optimized elastic-net regression method to estimate the composition parameters, and compare the resulting model with several recent alternative approaches in the task of composing simple intransitive sentences, adjective-noun phrases and determiner phrases.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate that the lexical function model estimated by elastic-net regression achieves better performance, and it provides good qualitative interpretabil-ity through sparsity constraints on model parameters.", "labels": [], "entities": []}], "introductionContent": [{"text": "Vector-based distributional semantic models of word meaning have gained increased attention in recent years (.", "labels": [], "entities": []}, {"text": "Different from formal semantics, distributional semantics represents word meanings as vectors in a highdimensional semantic space, where the dimensions are given by co-occurring contextual features.", "labels": [], "entities": []}, {"text": "The intuition behind these models lies in the fact that words which are similar in meaning often occur in similar contexts, e.g., moon and star might both occur with sky, night and bright.", "labels": [], "entities": []}, {"text": "This leads to convenient ways to measure similarity between different words using geometric methods (e.g., the cosine of the angle between two vectors that summarize their contextual distribution).", "labels": [], "entities": []}, {"text": "Distributional semantic models have been successfully applied to many tasks in linguistics and cognitive science).", "labels": [], "entities": []}, {"text": "However, most of these tasks only deal with isolated words, and there is a strong need to construct representations for longer linguistic structures such as phrases and sentences.", "labels": [], "entities": []}, {"text": "In order to achieve this goal, the principle of compositionality of linguistic structures, which states that complex linguistic structures can be formed through composition of simple elements, is applied to distributional vectors.", "labels": [], "entities": []}, {"text": "Therefore, in recent years, the problem of composition within distributional models has caught many researchers' attention.", "labels": [], "entities": []}, {"text": "A number of compositional frameworks have been proposed and tested.", "labels": [], "entities": []}, {"text": "propose a set of simple component-wise operations, such as multiplication and addition.", "labels": [], "entities": []}, {"text": "Later, and proposed more elaborate methods, in which composition is modeled as matrix-vector multiplication operations.", "labels": [], "entities": []}, {"text": "Particularly new to their approach is the proposal to estimate model parameters by minimizing the distance of the composed vectors to corpus-observed phrase vectors.", "labels": [], "entities": []}, {"text": "For example, consider the case of Adjective-Noun composition and model it as matrix-vector multiplication: adjective matrices are parameters to be estimated and nouns are cooccurrence vectors.", "labels": [], "entities": [{"text": "Adjective-Noun composition", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.8610740303993225}]}, {"text": "The model parameter estimation procedure becomes a multiple response multivariate regression problem.", "labels": [], "entities": [{"text": "model parameter estimation", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6179983119169871}]}, {"text": "This method, that, following  and others, we term the lexical function composition model, can also be generalized to more complex structures such as 3rd order tensors for modeling transitive verbs ( Au, Av \u2208 R m\u00d7m: Composition functions of inputs (u, v). neighbor words or phrases) simultaneously.", "labels": [], "entities": []}, {"text": "They use recursive neural networks to learn and construct the entire model and show that it reaches state-of-the-art performance in various evaluation experiments.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the simpler, linear lexical function model proposed by (see also) and show that its performance can be further improved through more advanced regression techniques.", "labels": [], "entities": []}, {"text": "We use the recently introduced elasticnet regularized linear regression method, which is solved by the pathwise coordinate descent optimization algorithm along a regularization parameter path.", "labels": [], "entities": [{"text": "pathwise coordinate descent optimization", "start_pos": 103, "end_pos": 143, "type": "TASK", "confidence": 0.6776707619428635}]}, {"text": "This new regression method can rapidly generate a sequence of solutions along the regularization path.", "labels": [], "entities": []}, {"text": "Performing cross-validation on this parameter path should yield a much more accurate model for prediction.", "labels": [], "entities": [{"text": "prediction", "start_pos": 95, "end_pos": 105, "type": "TASK", "confidence": 0.9606119394302368}]}, {"text": "Besides better prediction accuracy, the elastic-net method also brings interpretability to the composition procedure through sparsity constraints on the model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9265862703323364}]}, {"text": "The rest of this paper is organized as follows: In Section 2, we give details on the above-mentioned composition models, which will be used for comparison in our experiments.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the pathwise optimized elastic-net regression algorithm.", "labels": [], "entities": []}, {"text": "Experimental evaluation on three composition tasks is provided in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5 we conclude and suggest directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate on the three data sets described below, that were also used by , our most direct point of comparison.", "labels": [], "entities": []}, {"text": "Intransitive sentences The first dataset, introduced by, focuses on the composition of intransitive verbs and their noun subjects.", "labels": [], "entities": []}, {"text": "It contains a total of 120 sentence pairs together with human similarity judgments on a 7-point scale.", "labels": [], "entities": []}, {"text": "For example, value slumps/value declines is scored 7, skin glows/skin burns is scored 1.", "labels": [], "entities": []}, {"text": "On average, each pair is rated by 30 participants.", "labels": [], "entities": []}, {"text": "Rather than evaluating against mean scores, we use each rating as a separate data point, as done by Mitchell and Lapata.", "labels": [], "entities": []}, {"text": "We report Spearman correlations between human-assigned scores and cosines of model-generated vector pairs.", "labels": [], "entities": []}, {"text": "Adjective-noun phrases Turney (2012) introduced a dataset including both noun-noun compounds and adjective-noun phrases (ANs).", "labels": [], "entities": []}, {"text": "We focus on the latter, and we frame the task as in . The dataset contains 620 ANs, each paired with a single-noun paraphrase.", "labels": [], "entities": []}, {"text": "Examples include: upper side/upside, false belief/fallacy and electric refrigerator/fridge.", "labels": [], "entities": []}, {"text": "We evaluate a model by computing the cosine of all 20K nouns in our semantic space with the target AN, and looking at the rank of the correct paraphrase in this list.", "labels": [], "entities": []}, {"text": "The lower the rank, the better the model.", "labels": [], "entities": []}, {"text": "We report median rank across the test items.", "labels": [], "entities": [{"text": "median rank", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9466489255428314}]}, {"text": "Determiner phrases The third dataset, introduced in, focuses on a class of determiner words.", "labels": [], "entities": []}, {"text": "It is a multiplechoice test where target nouns (e.g., omniscience) must be matched with the most closely related determiner(-noun) phrases (DPs) (e.g., all knowledge).", "labels": [], "entities": []}, {"text": "There are 173 target nouns in total, each paired with one correct DP response, as well as 5 foils, namely the determiner (all) and noun (knowledge) from the correct response and three more DPs, two of which contain the same noun as the correct phrase (much knowledge, some knowledge), the third the same determiner (all preliminaries).", "labels": [], "entities": []}, {"text": "Other examples of targets/related-phrases are quatrain/four lines and apathy/no emotion.", "labels": [], "entities": []}, {"text": "The models compute cosines between target noun and responses and are scored based on their accuracy at ranking the correct phrase first.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9984297156333923}]}, {"text": "The experimental results are shown in Tables 2, 3, 4 and    the fact that they might negatively affect the semantic vector space.", "labels": [], "entities": []}, {"text": "A reasonable way out of this problem would be to save the mean and standard deviation parameters used for data standardization and use them to project the composed phrase vector outputs back to the original vector space.", "labels": [], "entities": []}, {"text": "On the other hand, EnetLex obtained a stable good performance in SVD space, with the best results achieved with dimensions between 200 and 300.", "labels": [], "entities": []}, {"text": "A set of Tukey's Honestly Significant Tests show that EnetLex significantly outperforms the other models across SVD settings for determiner phrases and intransitive sentences.", "labels": [], "entities": []}, {"text": "The difference is not significant for most comparisons in the adjective phrases task.", "labels": [], "entities": []}, {"text": "For the simpler models for which it was computationally feasible, we repeated the experiments without dimensionality reduction.", "labels": [], "entities": []}, {"text": "The results obtained with (unweighted) Add and Mult using fullspace representations are reported in  results confirm that dimensionality reduction is not only a computational necessity when working with more complex models, but it is actually improving the quality of the underlying semantic space.", "labels": [], "entities": []}, {"text": "Another benefit that elastic-net has brought to us is the sparsity in coefficient matrices.", "labels": [], "entities": []}, {"text": "Sparsity here means that many entries in the coefficient matrix are shrunk to 0.", "labels": [], "entities": [{"text": "Sparsity", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9762029647827148}]}, {"text": "For the above three experiments, the mean adjective, verb and determiner models' sparsity ratios are 0.66, 0.55 and 0.18 respectively.", "labels": [], "entities": []}, {"text": "Sparsity can greatly reduce the space needed to store the lexical function model, especially when we want to use higher orders of representation.", "labels": [], "entities": []}, {"text": "Moreover, sparsity in the model is helpful to interpret the concept a specific functor word is conveying.", "labels": [], "entities": []}, {"text": "For example, we show how to analyze the coefficient matrices for functor content words (verbs and adjectives).", "labels": [], "entities": []}, {"text": "The verb burst and adjective poisonous, when estimated in the space projected to 100 dimensions with NMF, have percentages of sparsity 47% and 39% respectively, which means 47% of the entries in the burst matrix and 39% of the entries in the poisonous matrix are zeros.", "labels": [], "entities": []}, {"text": "Most of the (hopefully) irrelevant dimensions were discarded during model training.", "labels": [], "entities": []}, {"text": "For visualization, we list the 6 most significant columns and rows from verb burst and adjective poisonous in.", "labels": [], "entities": []}, {"text": "Each reduced NMF dimension is represented by the 3 largest originalcontext entries in the corresponding row of the NMF basis matrix.", "labels": [], "entities": []}, {"text": "The top columns and rows are selected by ordering sums of row entries and sums of column entries (the 10 most common features across trained matrices are omitted).", "labels": [], "entities": []}, {"text": "In the matrix-vector multiplication scenario, a larger column contributes more to all the features of the composed output phrase vector, while one large row corresponds to a large composition output feature.", "labels": [], "entities": []}, {"text": "From these tables, we can see that the selected top columns and rows are mostly semantically relevant to the corresponding functor words (burst and poisonous, in the displayed examples).", "labels": [], "entities": []}, {"text": "Avery interesting aspect of these experiments is the role of the intercept in our regression model.", "labels": [], "entities": [{"text": "intercept", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.979759156703949}]}, {"text": "The path-wise optimization algorithm starts with a lambda value (\u03bb max ), which sets all the coefficients exactly to 0, and at that time the intercept is just the expected mean value of the training phrase vectors, which in turn is of course quite similar to the co-occurrence vector of the corresponding functor word (by averaging the poisonous N context distributions, we obtain a vector that approximates the poisonous distribution).", "labels": [], "entities": []}, {"text": "And, although the intercept also changes with different lambda values, it still highly correlates with the co-occurrence vectors of the functor words in vector space.", "labels": [], "entities": [{"text": "intercept", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9490892887115479}]}, {"text": "For adjectives and verbs, we compared the initial model's (\u03bb max ) intercept and the minimum cross-validation error model intercept with corpus-extracted vectors for the corresponding words.", "labels": [], "entities": [{"text": "initial model's (\u03bb max ) intercept", "start_pos": 42, "end_pos": 76, "type": "METRIC", "confidence": 0.771886795759201}, {"text": "cross-validation error model intercept", "start_pos": 93, "end_pos": 131, "type": "METRIC", "confidence": 0.7647380232810974}]}, {"text": "That is, we used the word cooccurrence vector fora verb or an adjective extracted from the corpus and projected onto the reduced feature space (e.g., NMF, 100 dimensions), then computed cosine similarity between this word meaning representation and its corresponding EnetLex matrix initial and minimumerror intercepts, respectively.", "labels": [], "entities": [{"text": "NMF", "start_pos": 150, "end_pos": 153, "type": "DATASET", "confidence": 0.8282467126846313}, {"text": "minimumerror intercepts", "start_pos": 294, "end_pos": 317, "type": "METRIC", "confidence": 0.9025987982749939}]}, {"text": "Most of the similarities are still quite high after estimation: The mean cosine values for adjectives are 0.82 for the initial intercept and 0.72 for the minimum-error one.", "labels": [], "entities": []}, {"text": "For verbs, the corresponding values are 0.75 and 0.69, respectively.", "labels": [], "entities": []}, {"text": "Apparently, the sparsity constraint helps the intercept retaining information from training phrases.", "labels": [], "entities": [{"text": "intercept retaining information from training phrases", "start_pos": 46, "end_pos": 99, "type": "TASK", "confidence": 0.7512621482213339}]}, {"text": "Qualitatively, often the intercept encodes the representation of the original: Interpretability for verbs and adjectives (exemplified by burst and poisonous).", "labels": [], "entities": [{"text": "intercept", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9751580357551575}]}, {"text": "For example, if we check the intercept for poisonous, the cosine between the original vector space representation (from corpus) and the minimum-error solution intercept (from training phrases) is at 0.7.", "labels": [], "entities": []}, {"text": "The NMF dimensions corresponding with the largest intercept entries are rather intuitive for poisonous: \u27e8ventilation, fluid, bacterium\u27e9, \u27e8racist, racism, outrage\u27e9, \u27e8reptile, mammal, predator\u27e9, \u27e8flowering, shrub, perennial\u27e9, \u27e8sceptical, accusation, credibility\u27e9, \u27e8infectious, infect, infected\u27e9.", "labels": [], "entities": []}, {"text": "The mathematical reason for the above facts lies in the updating rule of the elastic-net's intercept: Sparsity in the regression coefficients ( \u02c6 \u03b2 j ) encourages intercept \u03b2 0 to stay as close to the mean value of response \u00af y as possible.", "labels": [], "entities": [{"text": "Sparsity", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9950271248817444}]}, {"text": "So the elasticnet lexical function composition model is de facto also capturing the inherent meaning of the functor word, learning it from the training word-phrase pairs.", "labels": [], "entities": [{"text": "elasticnet lexical function composition", "start_pos": 7, "end_pos": 46, "type": "TASK", "confidence": 0.5432013124227524}]}, {"text": "In future research, we would like to test if these lexical meaning representations are as good or even better than standard co-occurrence vectors for single-word similarity tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Best performance comparison for intran- sitive verb sentence composition.", "labels": [], "entities": [{"text": "intran- sitive verb sentence composition", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.6815464993317922}]}, {"text": " Table 3: Best performance comparison for adjec- tive noun composition (lower ranks mean better  performance).", "labels": [], "entities": [{"text": "adjec- tive noun composition", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6880846619606018}]}, {"text": " Table 4: Best performance comparison for deter- miner phrase composition.", "labels": [], "entities": [{"text": "deter- miner phrase composition", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7067992568016053}]}, {"text": " Table 5: Performance of Add and Mult models  without dimensionality reduction.", "labels": [], "entities": []}]}