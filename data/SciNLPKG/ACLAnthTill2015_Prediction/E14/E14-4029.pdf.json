{"title": [{"text": "Integrating an Unsupervised Transliteration Model into Statistical Machine Translation", "labels": [], "entities": [{"text": "Integrating", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9695690870285034}, {"text": "Statistical Machine Translation", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.6774817605813345}]}], "abstractContent": [{"text": "We investigate three methods for integrating an unsupervised transliteration model into an end-to-end SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9663256406784058}]}, {"text": "We induce a transliteration model from parallel data and use it to translate OOV words.", "labels": [], "entities": []}, {"text": "Our approach is fully unsupervised and language independent.", "labels": [], "entities": []}, {"text": "In the methods to integrate transliterations, we observed improvements from 0.23-0.75 (\u2206 0.41) BLEU points across 7 language pairs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9990019202232361}]}, {"text": "We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "All machine translation (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8511570751667022}]}, {"text": "OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration.", "labels": [], "entities": []}, {"text": "Much work has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality.", "labels": [], "entities": [{"text": "transliterating named entities and OOVs", "start_pos": 27, "end_pos": 66, "type": "TASK", "confidence": 0.861599326133728}, {"text": "MT", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.9951459765434265}]}, {"text": "Transliteration has also shown to be useful for translating closely related language pairs (, and for disambiguation.", "labels": [], "entities": [{"text": "translating closely related language pairs", "start_pos": 48, "end_pos": 90, "type": "TASK", "confidence": 0.8674932718276978}]}, {"text": "However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (.", "labels": [], "entities": [{"text": "MT toolkits", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.8172301352024078}]}, {"text": "One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliteration system, is not readily available for many language pairs.", "labels": [], "entities": []}, {"text": "Even if such a training data is available, mechanisms to integrate transliterated words into MT pipelines are unavailable in these toolkits.", "labels": [], "entities": [{"text": "MT pipelines", "start_pos": 93, "end_pos": 105, "type": "TASK", "confidence": 0.9099257588386536}]}, {"text": "Generally, a supervised transliteration system is trained separately outside of an MT pipeline, and a na\u00a8\u0131vena\u00a8\u0131ve approach, to replace OOV words with their 1-best transliterations in the post/pre-processing step of decoding is commonly used.", "labels": [], "entities": [{"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.892909049987793}]}, {"text": "In this work i) we use an unsupervised model based on Expectation Maximization (EM) to induce transliteration corpus from word aligned parallel data, which is then used to train a transliteration model, ii) we investigate three different methods for integrating transliteration during decoding, that we implemented within the Moses toolkit.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our work is the foremost attempt to integrate unsupervised transliteration model into SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.9867934584617615}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the unsupervised transliteration mining system, which automatically mines transliteration pairs from the same word-aligned parallel corpus as used for training the MT system.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7802481055259705}, {"text": "MT", "start_pos": 184, "end_pos": 186, "type": "TASK", "confidence": 0.9699914455413818}]}, {"text": "Section 3 describes the transliteration model that is trained using the automatically extracted pairs.", "labels": [], "entities": []}, {"text": "Section 4 presents three methods for incorporating transliteration into the MT pipeline, namely: i) replacing OOVs with the 1-best transliteration in a postdecoding step, ii) selecting the best transliteration from the list of n-best transliterations using transliteration and language model features in a post-decoding step, iii) providing a transliteration phrase-table to the decoder on the fly where it can consider all features to select the best transliteration of OOV words.", "labels": [], "entities": [{"text": "MT pipeline", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.906049519777298}]}, {"text": "Our integrations achieved an average improvement of 0.41 BLEU points over a competitive baseline across 7 language pairs (Arabic, Bengali, Farsi, Hindi, Russian, Telugu and Urdu-intoEnglish).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9973375201225281}]}, {"text": "An additional experiment showed that our system provides better rule coverage as opposed to another built from gold standard transliteration corpus and produces better translations.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data: We experimented with 7 language pairs, namely: Arabic, Bengali, Farsi, Hindi, Russian, Telugu and Urdu-into-English.", "labels": [], "entities": []}, {"text": "For Arabic and Farsi, we used the TED talks data () made available for IWSLT-13, and we used the dev2010 set for tuning and the test2011 and test2012 sets for evaluation.", "labels": [], "entities": [{"text": "TED talks data", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.8672651251157125}, {"text": "IWSLT-13", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.8899498581886292}]}, {"text": "For Indian languages we used the Indic multi-parallel corpus), and we used the dev and test sets provided with the parallel corpus.", "labels": [], "entities": []}, {"text": "For Russian, we used WMT-13 data (, and we used half of the news-test2012 for tuning and other half for testing.", "labels": [], "entities": [{"text": "WMT-13 data", "start_pos": 21, "end_pos": 32, "type": "DATASET", "confidence": 0.9211957156658173}]}, {"text": "We also evaluated on the newstest2013 set.", "labels": [], "entities": [{"text": "newstest2013 set", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9748606383800507}]}, {"text": "For all, we trained the language model using the monolingual WMT-13 data.", "labels": [], "entities": [{"text": "WMT-13 data", "start_pos": 61, "end_pos": 72, "type": "DATASET", "confidence": 0.9337052702903748}]}, {"text": "See   can be translated to \"Border\" and also transliterated to name \"Seema\".", "labels": [], "entities": []}, {"text": "Identifying such candidates that can be translated or transliterated is a challenge.", "labels": [], "entities": [{"text": "Identifying", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9643517136573792}]}, {"text": "Machine learning techniques) and named entity recognizers ( have been used for this purpose.", "labels": [], "entities": [{"text": "named entity recognizers", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6181879738966624}]}, {"text": "Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available.", "labels": [], "entities": []}, {"text": "Arabic and Urdu are segmented using MADA) and UWS ( ized reordering, sparse lexical and domain features (), a distortion limit of 6, 100-best translation options, MBR decoding (), Cube Pruning (, and the no-reordering-overpunctuation heuristic.", "labels": [], "entities": [{"text": "UWS", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.7183837294578552}]}, {"text": "We tuned with the k-best batch MIRA (Cherry and Foster, 2012).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9766237139701843}, {"text": "Cherry and Foster, 2012)", "start_pos": 37, "end_pos": 61, "type": "DATASET", "confidence": 0.7127351512511572}]}, {"text": "5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus.", "labels": [], "entities": []}, {"text": "We only used word pairs with 1-to-1 alignments.", "labels": [], "entities": []}, {"text": "Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs where source or target is composed from less than 3 characters, and words containing foreign characters that do not belong to this scripts.", "labels": [], "entities": []}, {"text": "We ran the miner with 10 iterations of EM.", "labels": [], "entities": [{"text": "EM", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.5989680886268616}]}, {"text": "The number of transliteration pairs (types) extracted for each language pair is shown in (Train tr ).", "labels": [], "entities": []}, {"text": "Transliteration System: Before evaluating our integrations into the SMT system, we performed an intrinsic evaluation of the transliteration system that we built from the mined pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9755027890205383}]}, {"text": "We formed test data for Arabic-English (1799 pairs), HindiEnglish (2394 pairs) and Russian-English (1859 pairs) by concatenating the seed data and gold standard transliteration pairs both provided for the Shared Task on Transliteration mining (.", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 220, "end_pos": 242, "type": "TASK", "confidence": 0.7798742353916168}]}, {"text": "shows precision and recall of the mined transliteration system (MTS).", "labels": [], "entities": [{"text": "precision", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.9993129968643188}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9995253086090088}]}], "tableCaptions": [{"text": " Table 1: No. of sentences in Training Data and  Mined Transliteration Corpus (Types) (Train tr )", "labels": [], "entities": [{"text": "Training Data and  Mined Transliteration Corpus", "start_pos": 30, "end_pos": 77, "type": "DATASET", "confidence": 0.7079002360502878}]}, {"text": " Table 3: End-to-End MT Evaluation -B 0 =  Baseline, M 1 = Method 1 , M 2 = Method 2 , M 3 =  Method 3 , BLEU gains shown for each method", "labels": [], "entities": [{"text": "End-to-End", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.951126754283905}, {"text": "MT Evaluation -B 0", "start_pos": 21, "end_pos": 39, "type": "METRIC", "confidence": 0.8192757964134216}, {"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9994416832923889}]}, {"text": " Table 4: Comparing Gold Standard Transliteration  (GST) and Mined Transliteration Systems", "labels": [], "entities": [{"text": "Comparing Gold Standard Transliteration  (GST)", "start_pos": 10, "end_pos": 56, "type": "TASK", "confidence": 0.7321309617587498}]}]}