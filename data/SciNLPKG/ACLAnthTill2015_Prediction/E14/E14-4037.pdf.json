{"title": [{"text": "Analysis and Prediction of Unalignable Words in Parallel Text", "labels": [], "entities": []}], "abstractContent": [{"text": "Professional human translators usually do not employ the concept of word alignments , producing translations 'sense-for-sense' instead of 'word-for-word'.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7219633907079697}]}, {"text": "This suggests that unalignable words maybe prevalent in the parallel text used for machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.8306784987449646}]}, {"text": "We analyze this phenomenon in-depth for Chinese-English translation.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.6029952317476273}]}, {"text": "We further propose a simple and effective method to improve automatic word alignment by pre-removing unalignable words, and show improvements on hierarchical MT systems in both translation directions.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.6796550303697586}, {"text": "MT", "start_pos": 158, "end_pos": 160, "type": "TASK", "confidence": 0.9474100470542908}]}, {"text": "1 Motivation It is generally acknowledged that absolute equivalence between two languages is impossible, since concept lexicalization varies across languages.", "labels": [], "entities": []}, {"text": "Major translation theories thus argue that texts should be translated 'sense-for-sense' instead of 'word-for-word' (Nida, 1964).", "labels": [], "entities": [{"text": "Nida, 1964)", "start_pos": 116, "end_pos": 127, "type": "TASK", "confidence": 0.8386309146881104}]}, {"text": "This suggests that unalignable words maybe an issue for the parallel text used to train current statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.7699031233787537}]}, {"text": "Although existing automatic word alignment methods have some mechanism to handle the lack of exact word-for-word alignment (e.g. null probabilities, fertility in the IBM models (Brown et al., 1993)), they maybe too coarse-grained to model the 'sense-for-sense' translations created by professional human translators.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.7078617662191391}]}, {"text": "For example, the Chinese term 'tai-yang' literally means 'sun', yet the concept it represents is equivalent to the English term 'the sun'.", "labels": [], "entities": []}, {"text": "Since the concept of a definite article is not incorporated in the morphology of 'tai yang', the added 'the' is not aligned to any Chinese word.", "labels": [], "entities": []}, {"text": "Yet in another context like 'the man', 'the' can be the translation of the Chinese demonstrative pronoun 'na', literally means 'that'.", "labels": [], "entities": []}, {"text": "A potential misunderstanding is that unalignable words are simply function words; but from the above example, we see that whether a word is alignable depends very much on the concept and the linguistic context.", "labels": [], "entities": []}, {"text": "As the quantity and quality of professionally-created parallel text increase, we believe there is a need to examine the question of unalignable words in-depth.", "labels": [], "entities": []}, {"text": "Our goal is to gain a better understanding of what makes a fluent human translation and use this insight to build better word aligners and MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 139, "end_pos": 141, "type": "TASK", "confidence": 0.9899994730949402}]}, {"text": "Our contributions are twofold: 1) We analyze 13000 sentences of manually word-aligned Chinese-English parallel text, quantifying the characteristics of unalignable words.", "labels": [], "entities": []}, {"text": "2) We propose a simple and effective way to improve automatic word alignment, based on predicting unalignable words and temporarily removing them during the alignment training procedure.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.6898414939641953}]}], "introductionContent": [], "datasetContent": [{"text": "In our experiments, we first show that removing manually-annotated unaligned words in ORACLE data leads to improvements in MT of both translation directions.", "labels": [], "entities": [{"text": "ORACLE data", "start_pos": 86, "end_pos": 97, "type": "DATASET", "confidence": 0.7044194936752319}, {"text": "MT", "start_pos": 123, "end_pos": 125, "type": "TASK", "confidence": 0.9628700613975525}]}, {"text": "Next, we show how a classifier trained on ORACLE data can be used to improve MT in another large-scale un-annotated dataset.", "labels": [], "entities": [{"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9941580295562744}]}, {"text": "We first performed an ORACLE experiment using gold standard unaligned word labels.", "labels": [], "entities": []}, {"text": "Following the training pipeline in Section 3, we removed gold unalignable words before running GIZA++ and restore them afterwards.", "labels": [], "entities": []}, {"text": "90% of the data is used for alignment and MT training, while 10% of the data is reserved for testing.", "labels": [], "entities": [{"text": "alignment", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.9840356707572937}, {"text": "MT training", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.9597305953502655}]}, {"text": "The upper half of list the alignment precision, recall and F1 of the resulting alignments, and quality of the final MT outputs.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.8785313367843628}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9995594620704651}, {"text": "F1", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9873665571212769}, {"text": "MT", "start_pos": 116, "end_pos": 118, "type": "TASK", "confidence": 0.9801382422447205}]}, {"text": "Baseline is the standard MT training pipeline without removal of unaligned words.", "labels": [], "entities": [{"text": "MT training", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.8905133306980133}]}, {"text": "Our Proposed approach performs better in alignment, phrasebased (PBMT) and hierarchical (Hiero) systems.", "labels": [], "entities": []}, {"text": "The results, evaluated by BLEU, METEOR and TER, support our hypothesis that removing gold unalignable words helps improve word alignment and the resulting SMT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9983177185058594}, {"text": "METEOR", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9528842568397522}, {"text": "TER", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9946802258491516}, {"text": "word alignment", "start_pos": 122, "end_pos": 136, "type": "TASK", "confidence": 0.7450613677501678}, {"text": "SMT", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9920828342437744}]}, {"text": "We next performed a more realistic experiment: the classifier trained on ORACLE data is used to automatically label a large data, which is then used to train a MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 160, "end_pos": 162, "type": "TASK", "confidence": 0.9735704064369202}]}, {"text": "This REAL data consists of parallel text from the NIST OpenMT2008.", "labels": [], "entities": [{"text": "REAL data", "start_pos": 5, "end_pos": 14, "type": "DATASET", "confidence": 0.744731068611145}, {"text": "NIST OpenMT2008", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.8378548622131348}]}, {"text": "MT experiments are performed in both directions.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9758139252662659}]}, {"text": "The lower half of shows the performance of the resulting MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9726607799530029}]}, {"text": "We observe that our proposed approach is still able to improve over the baseline.", "labels": [], "entities": []}, {"text": "In particular, Hiero achieved statistical significant improvements in BLEU and METEOR.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9965558052062988}, {"text": "METEOR", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.6047807931900024}]}, {"text": "Comparing to the results of PBMT, this suggests our method maybe most effective in improving systems where rule extraction is sen- We use the standard MT08 test sets; the training data includes (34M English words and 1.1M sentences).", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 107, "end_pos": 122, "type": "TASK", "confidence": 0.8410894572734833}, {"text": "MT08 test sets", "start_pos": 151, "end_pos": 165, "type": "DATASET", "confidence": 0.9654313921928406}]}, {"text": "Since we do not have access to all OpenMT data, e.g. FBIS, our results may not be directly comparable to other systems in the evaluation.", "labels": [], "entities": [{"text": "OpenMT data", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9182421863079071}]}, {"text": "Interestingly, PBMT did better than Hiero in this setup.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.7518361806869507}, {"text": "Hiero", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8986857533454895}]}], "tableCaptions": [{"text": " Table 1: Number of core and unalignable words in  hand aligned ORACLE corpus", "labels": [], "entities": []}, {"text": " Table 2: Count of unalignable words by types", "labels": [], "entities": []}, {"text": " Table 3: Top 5 POS categories of Chinese and En- glish unalignable words", "labels": [], "entities": []}, {"text": " Table 4: MT results of ORACLE and REAL ex- periments. Highest score per metric is bolded.  { + / \u2212 } indicates statistically significant improve- ment/degradation, p < 0.05. (P: precision; R: re- call; B: BLEU; M: METEOR; T:TER)", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9492396116256714}, {"text": "ORACLE", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9835599660873413}, {"text": "statistically significant improve- ment/degradation", "start_pos": 112, "end_pos": 163, "type": "METRIC", "confidence": 0.7909562928336007}, {"text": "precision", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.9779415130615234}, {"text": "BLEU", "start_pos": 206, "end_pos": 210, "type": "METRIC", "confidence": 0.8797953724861145}, {"text": "METEOR", "start_pos": 215, "end_pos": 221, "type": "METRIC", "confidence": 0.8640103340148926}, {"text": "T", "start_pos": 223, "end_pos": 224, "type": "METRIC", "confidence": 0.7862383127212524}, {"text": "TER", "start_pos": 225, "end_pos": 228, "type": "METRIC", "confidence": 0.6555962562561035}]}]}