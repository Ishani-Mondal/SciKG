{"title": [{"text": "Automatic Food Categorization from Large Unlabeled Corpora and Its Impact on Relation Extraction", "labels": [], "entities": [{"text": "Automatic Food Categorization from Large Unlabeled Corpora", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.7324822545051575}, {"text": "Relation Extraction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7427435219287872}]}], "abstractContent": [{"text": "We present a weakly-supervised induction method to assign semantic information to food items.", "labels": [], "entities": []}, {"text": "We consider two tasks of categorizations being food-type classification and the distinction of whether a food item is composite or not.", "labels": [], "entities": [{"text": "food-type classification", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7102319300174713}]}, {"text": "The cate-gorizations are induced by a graph-based algorithm applied on a large unlabeled domain-specific corpus.", "labels": [], "entities": []}, {"text": "We show that the usage of a domain-specific corpus is vital.", "labels": [], "entities": []}, {"text": "We do not only outperform a manually designed open-domain ontology but also prove the usefulness of these categoriza-tions in relation extraction, outperforming state-of-the-art features that include syntactic information and Brown clustering.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.8659855723381042}]}], "introductionContent": [{"text": "In view of the large interest in food in many parts of the population and the ever increasing amount of new dishes/food items, there is a need of automatic knowledge acquisition.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 156, "end_pos": 177, "type": "TASK", "confidence": 0.6885061413049698}]}, {"text": "We approach this task with the help of natural language processing.", "labels": [], "entities": []}, {"text": "We investigate different methods to assign categories to food items.", "labels": [], "entities": []}, {"text": "We focus on two categorizations, being a classification of food items to categories of the Food Guide Pyramid (U.S. Department of) and a categorization of whether a food item is composite or not.", "labels": [], "entities": [{"text": "Food Guide Pyramid (U.S. Department of)", "start_pos": 91, "end_pos": 130, "type": "DATASET", "confidence": 0.8826689720153809}]}, {"text": "We present a semi-supervised graph-based approach to induce these food categorizations from an unlabeled domain-specific text corpus crawled from the Web.", "labels": [], "entities": []}, {"text": "The method only requires minimal manual guidance for the initialization of the algorithm with seed terms.", "labels": [], "entities": []}, {"text": "It depends, however, on an automatically constructed high-quality similarity graph.", "labels": [], "entities": []}, {"text": "For that we choose a pattern-based representation that outperforms a distributionalbased representation.", "labels": [], "entities": []}, {"text": "For initialization, we examine some manually compiled seed words and a very few simple surface patterns to automatically induce such expressions.", "labels": [], "entities": [{"text": "initialization", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9621137380599976}]}, {"text": "As a hard baseline, we compare the effectiveness of using a generalpurpose ontology for the same types of categorizations.", "labels": [], "entities": []}, {"text": "Apart from an intrinsic evaluation, we also examine the categories in relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.880383312702179}]}, {"text": "The contributions of this paper area method requiring minimal supervision fora comprehensive classification of food items and a proof of concept that the knowledge that can thus be gained is beneficial for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 206, "end_pos": 225, "type": "TASK", "confidence": 0.9234291911125183}]}, {"text": "Even though we focus on a specific domain, the induction method can be easily translated to other domains.", "labels": [], "entities": []}, {"text": "In particular, other life-style domains, such as fashion, cosmetics or home & gardening, show parallels since comparable textual web data are available and similar relation types (e.g. that two items fit together or can be substituted by each other) exist.", "labels": [], "entities": []}, {"text": "Our experiments are carried out on German data but our findings should carryover to other languages since the issues we address are (mostly) language universal.", "labels": [], "entities": []}, {"text": "For general accessibility, all examples are given as English translations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We report precision, recall and F-score and accuracy.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986050724983215}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9998032450675964}, {"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9989336133003235}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9995647072792053}]}, {"text": "For precision, recall and F-score, we list the macro-averaged score.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996366500854492}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9995772242546082}, {"text": "F-score", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9991593360900879}]}, {"text": "compares different classifiers and configurations for the prediction of food types (against the gold standard from).", "labels": [], "entities": [{"text": "prediction of food types", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.8319216519594193}]}, {"text": "Apart from the previously described baselines, we consider n manually selected prototypes (n-PROTO) and the top n food items produced by Hearst-patterns (PATTopn) as seeds for graph-based optimization.", "labels": [], "entities": []}, {"text": "The table shows that the semi-supervised graph-based approach with these seeds outperforms the baselines UNSUP and HEUR.", "labels": [], "entities": [{"text": "UNSUP", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.7077637910842896}, {"text": "HEUR", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.8170551657676697}]}, {"text": "Only as few as 5 prototypical seeds (per category) are required to obtain performance that is even better than using plain GermaNet.", "labels": [], "entities": []}, {"text": "The table also shows that post-processing (with our suffix-heuristics) consistently improves performance.", "labels": [], "entities": []}, {"text": "Manually choosing prototypes is more effective than instantiating seeds via Hearst-patterns.", "labels": [], "entities": []}, {"text": "The quality of the output of Hearst-patterns degrades from top 10 onwards.", "labels": [], "entities": []}, {"text": "However, considering that PAT-Topn does not include any manual intervention, it already produces decent results.", "labels": [], "entities": [{"text": "PAT-Topn", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.6699863076210022}]}, {"text": "Finally, even GermaNet can be effectively used as seeds.", "labels": [], "entities": []}, {"text": "heterogeneous classes which is why more seeds are required for initialization.", "labels": [], "entities": []}, {"text": "This means that we cannot look for prototypes.", "labels": [], "entities": []}, {"text": "For simplicity, we resorted to randomly sample seeds from our gold standard (RAND-n).", "labels": [], "entities": [{"text": "RAND-n", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.938024640083313}]}, {"text": "For HEUR, we could not find a small and intuitive set of suffixes that are shared by many atomic food types, therefore we considered all food types from our vocabulary whose suffix did not match atypical dish suffix as atomic.", "labels": [], "entities": [{"text": "HEUR", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.5819202661514282}]}, {"text": "As this leaves no unspecified food items in our vocabulary, we cannot use the output of HEUR as seeds for graph-based optimization.", "labels": [], "entities": [{"text": "HEUR", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.6531336307525635}]}, {"text": "In contrast to the previous experiment, HEUR is a more robust baseline.", "labels": [], "entities": [{"text": "HEUR", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9696872234344482}]}, {"text": "But again, post-processing mostly improves performance, and patterns are not as good as manual (random) seeds yet the former are notably better than HEUR w.r.t.", "labels": [], "entities": [{"text": "HEUR w.r.t", "start_pos": 149, "end_pos": 159, "type": "DATASET", "confidence": 0.6928303986787796}]}, {"text": "Unlike in the food-type classification, graph-based optimization applied on GermaNet does not result in some improvement.", "labels": [], "entities": [{"text": "GermaNet", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.8819293975830078}]}, {"text": "We assume that the precision of plain GermaNet with 81.3% is too low.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9994890689849854}]}, {"text": "Since GermaNet cannot effectively be used as seeds for the graph-based optimization and postprocessing has already a strong positive effect, we may wonder how effective the actual graph-based optimization is for this classification task.", "labels": [], "entities": []}, {"text": "After all, significantly more seeds are required for this classification task than for the previous task, so we need to show that it is not the mere seeds (+post-processing) that are required fora reasonable categorization.", "labels": [], "entities": []}, {"text": "examines two key configurations with and without graph-based optimization.", "labels": [], "entities": []}, {"text": "It shows that also for this classification task, graph-based optimization produces a categorization superior to the mere seeds.", "labels": [], "entities": []}, {"text": "Moreover, the suffix-based post-processing is complementary to the improvement by the graph-based optimization.", "labels": [], "entities": []}, {"text": "compares for each food type 5 manually selected prototypical seeds (i.e. 5-PROTO) and the 5 food items most frequently been observed with patt hearst.", "labels": [], "entities": [{"text": "patt hearst", "start_pos": 138, "end_pos": 149, "type": "DATASET", "confidence": 0.7525035738945007}]}, {"text": "While the manually chosen seeds represent the spectrum of food items within each particular class (e.g. for STARCH, some type of pasta, rice and potato was chosen), it is not possible to enforce such diversity with the automatically extracted seeds.", "labels": [], "entities": [{"text": "STARCH", "start_pos": 108, "end_pos": 114, "type": "DATASET", "confidence": 0.6203281283378601}]}, {"text": "However, most food items are correct.", "labels": [], "entities": []}, {"text": "displays the 10 most highly ranked dishes and atomic food items extracted with patt dish and patt atom.", "labels": [], "entities": []}, {"text": "Unlike the previous task, we obtain more heterogeneous seeds within the same class.", "labels": [], "entities": []}, {"text": "We now examine whether automatic food categorization can be harnessed for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8891442716121674}]}, {"text": "The task is to detect instances of the relation types SuitsTo, SubstitutedBy and IngredientOf introduced Wiegand et al.", "labels": [], "entities": []}, {"text": "(2012b) (repeated in Table 12) and motivated in.", "labels": [], "entities": []}, {"text": "These relation types are highly relevant for customer advice/product recommendation.", "labels": [], "entities": [{"text": "customer advice/product recommendation", "start_pos": 45, "end_pos": 83, "type": "TASK", "confidence": 0.5972726285457611}]}, {"text": "In particular, SuitsTo and SubstitutedBy are fairly domainindependent relation types.", "labels": [], "entities": []}, {"text": "Customers want to know which items can be used together (SuitsTo), be it two food items that can be used as a meal or two fashion items that can be worn together.", "labels": [], "entities": [{"text": "SuitsTo)", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9606560468673706}]}, {"text": "Substitutes are also relevant for situations in which item A is out of stock but item B can be offered as an alternative.", "labels": [], "entities": []}, {"text": "Therefore, insights from this work should carryover to other domains.", "labels": [], "entities": []}, {"text": "We randomly extracted 1500 sentences from our text corpus ( \u00a72.1) in which (at least) two food items co-occur.", "labels": [], "entities": []}, {"text": "Each food pair mention was manually assigned one label.", "labels": [], "entities": []}, {"text": "In addition to the three relation types from above, we introduce the label Other for cases in which either another relation between the target food items is expressed or the co-occurrence is co-incidental.", "labels": [], "entities": []}, {"text": "On a subset of 200 sentences, we measured a substantial interannotation agreement of Cohen's \u03ba = 0.67.", "labels": [], "entities": []}, {"text": "We train a supervised classifier and incorporate the knowledge induced from our domain-specific corpus as features.", "labels": [], "entities": []}, {"text": "We chose Support Vector Machines with 5-fold cross-validation using SVM lightmulti-class.", "labels": [], "entities": []}, {"text": "displays all features that we examine for supervised classification.", "labels": [], "entities": [{"text": "supervised classification", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.6314810216426849}]}, {"text": "Most features are widely used throughout different NLP tasks.", "labels": [], "entities": []}, {"text": "One special feature brown takes into consideration the output of Brown clustering) which like our graph-based optimization produces a corpus-driven categorization of words.", "labels": [], "entities": []}, {"text": "Similar to UNSUP, this method is unsupervised but it considers the entire vocabulary of our text corpus rather than only food items.", "labels": [], "entities": [{"text": "UNSUP", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.8260269165039062}]}, {"text": "Therefore, this information can be considered as a generalization of all contextual words.", "labels": [], "entities": []}, {"text": "Such type of information has been shown to be useful for named-entity recognition and relation extraction.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.7879296243190765}, {"text": "relation extraction", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8587514758110046}]}, {"text": "For syntactic parsing, Stanford Parser (Rafferty and Manning, 2008) was used.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8524653315544128}, {"text": "Stanford Parser (Rafferty and Manning, 2008)", "start_pos": 23, "end_pos": 67, "type": "DATASET", "confidence": 0.8190892040729523}]}, {"text": "For Brown clustering, the SRILM-toolkit) was used.", "labels": [], "entities": [{"text": "Brown clustering", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.603200688958168}, {"text": "SRILM-toolkit", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.5876805782318115}]}, {"text": "Following, we induced 1000 clusters (from our domain-specific corpus \u00a72.1).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The different food types (gold standard).", "labels": [], "entities": []}, {"text": " Table 5: Comparison of different food-type classi- fiers (graph indicates graph-based optimization).", "labels": [], "entities": []}, {"text": " Table 6: Comparison of different classifiers dis- tinguishing between dishes and atomic food items  (graph indicates graph-based optimization).", "labels": [], "entities": []}, {"text": " Table 7: Impact of graph-based optimization  (graph) for the detection of dishes.", "labels": [], "entities": []}, {"text": " Table 8: Comparison of different seed initializations for the food type categorization task (underlined  food items represent erroneously extracted food items).", "labels": [], "entities": []}, {"text": " Table 9: Illustration of seed initialization for the  distinction between dishes and atomic food items.", "labels": [], "entities": [{"text": "seed initialization", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.6614128947257996}]}, {"text": " Table 10: Impact of the similarity representation.", "labels": [], "entities": []}, {"text": " Table 11: Comparison of Wikipedia and domain- specific corpus as a source for the similarity graph.", "labels": [], "entities": []}, {"text": " Table 12: The different relation types and their respective frequency on our dataset.", "labels": [], "entities": []}, {"text": " Table 13: Description of the feature set.", "labels": [], "entities": []}]}