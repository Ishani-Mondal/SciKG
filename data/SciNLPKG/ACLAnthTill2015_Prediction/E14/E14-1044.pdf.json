{"title": [{"text": "A Knowledge-based Representation for Cross-Language Document Retrieval and Categorization", "labels": [], "entities": [{"text": "Cross-Language Document Retrieval and Categorization", "start_pos": 37, "end_pos": 89, "type": "TASK", "confidence": 0.8299025535583496}]}], "abstractContent": [{"text": "Current approaches to cross-language document retrieval and categorization are based on discriminative methods which represent documents in a low-dimensional vector space.", "labels": [], "entities": [{"text": "cross-language document retrieval", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.6805099546909332}]}, {"text": "In this paper we propose a shift from the supervised to the knowledge-based paradigm and provide a document similarity measure which draws on BabelNet, a large multilingual knowledge resource.", "labels": [], "entities": []}, {"text": "Our experiments show state-of-the-art results in cross-lingual document retrieval and categorization.", "labels": [], "entities": [{"text": "cross-lingual document retrieval", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.6204622785250345}]}], "introductionContent": [{"text": "The huge amount of text that is available online is becoming ever increasingly multilingual, providing an additional wealth of useful information.", "labels": [], "entities": []}, {"text": "Most of this information, however, is not easily accessible to the majority of users because of language barriers which hamper the cross-lingual search and retrieval of knowledge.", "labels": [], "entities": []}, {"text": "Today's search engines would benefit greatly from effective techniques for the cross-lingual retrieval of valuable information that can satisfy a user's needs by not only providing and translating () relevant results into different languages, but also by reranking the results in a language of interest on the basis of the importance of search results in other languages.", "labels": [], "entities": [{"text": "cross-lingual retrieval of valuable information", "start_pos": 79, "end_pos": 126, "type": "TASK", "confidence": 0.8208502292633056}]}, {"text": "Vector-based models are typically used in the literature for representing documents both in monolingual and cross-lingual settings.", "labels": [], "entities": []}, {"text": "However, because of the large size of the vocabulary, having each term as a component of the vector makes the document representation very sparse.", "labels": [], "entities": []}, {"text": "To address this issue several approaches to dimensionality reduction have been proposed, such as Principal Component Analysis, Latent Semantic Indexing, Latent Dirichlet Allocation (LDA) ( and variants thereof, which project these vectors into a lower-dimensional vector space.", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.6952702105045319}, {"text": "Principal Component Analysis", "start_pos": 97, "end_pos": 125, "type": "TASK", "confidence": 0.632833868265152}, {"text": "Latent Dirichlet Allocation (LDA", "start_pos": 153, "end_pos": 185, "type": "METRIC", "confidence": 0.8151375412940979}]}, {"text": "In order to enable multilinguality, the vectors of comparable documents written in different languages are concatenated, making up the document matrix which is then reduced using linear projection).", "labels": [], "entities": []}, {"text": "However, to do so, comparable documents are needed as training.", "labels": [], "entities": []}, {"text": "Additionally, the lower dimensional representations are not of easy interpretation.", "labels": [], "entities": []}, {"text": "The availability of wide-coverage lexical knowledge resources extracted automatically from Wikipedia, such as DBPedia (),) and BabelNet (, has considerably boosted research in several areas, especially where multilinguality is a concern ().", "labels": [], "entities": [{"text": "DBPedia", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.9476748108863831}]}, {"text": "Among these latter are cross-language plagiarism detection, multilingual semantic relatedness ( and semantic alignment.", "labels": [], "entities": [{"text": "cross-language plagiarism detection", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.7986541589101156}, {"text": "semantic alignment", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.750720888376236}]}, {"text": "One main advantage of knowledge-based methods is that they provide a human-readable, semantically interconnected, representation of the textual item at hand (be it a sentence or a document).", "labels": [], "entities": []}, {"text": "Following this trend, in this paper we provide a knowledge-based representation of documents which goes beyond the lexical surface of text, while at the same time avoiding the need for training in a cross-language setting.", "labels": [], "entities": []}, {"text": "To achieve this we leverage a multilingual semantic network, i.e., BabelNet, to obtain language-independent representations, which contain concepts together with semantic relations between them, and also include semantic knowledge which is just implied by the input text.", "labels": [], "entities": []}, {"text": "The integration of our multilingual graph model with a vector representation enables us to obtain state-of-the-art results in comparable document retrieval and cross-language text categorization.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we compare our knowledgebased document similarity measure, KBSim, against state-of-the-art models on two different tasks: comparable document retrieval and crosslingual text categorization.", "labels": [], "entities": [{"text": "crosslingual text categorization", "start_pos": 172, "end_pos": 204, "type": "TASK", "confidence": 0.6475854714711508}]}], "tableCaptions": [{"text": " Table 1: Test results for comparable document re- trieval in Wikipedia. S2Net, OPCA, CosSim E ,  CCA and CL-LSI are from (Yih et al., 2011).", "labels": [], "entities": [{"text": "document re- trieval", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.6635726988315582}, {"text": "OPCA", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.8791795372962952}]}, {"text": " Table 2: Test results for cross-language text cat- egorization. Full MT, OPCA, CCA, CL-LSI and  CosSim E are from (Platt et al., 2010).", "labels": [], "entities": [{"text": "CosSim E", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.8961460888385773}]}, {"text": " Table 3: KBSim accuracy in a multilingual setup.", "labels": [], "entities": [{"text": "KBSim", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.548498272895813}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9863173365592957}]}]}