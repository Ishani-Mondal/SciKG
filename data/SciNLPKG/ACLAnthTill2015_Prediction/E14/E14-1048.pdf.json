{"title": [{"text": "Learning Dictionaries for Named Entity Recognition using Minimal Supervision", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.8092188040415446}]}], "abstractContent": [{"text": "This paper describes an approach for automatic construction of dictionaries for Named Entity Recognition (NER) using large amounts of unlabeled data and a few seed examples.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.806831439336141}]}, {"text": "We use Canonical Correlation Analysis (CCA) to obtain lower dimensional embeddings (representations) for candidate phrases and classify these phrases using a small number of labeled examples.", "labels": [], "entities": []}, {"text": "Our method achieves 16.5% and 11.3% F-1 score improvement over co-training on disease and virus NER respectively.", "labels": [], "entities": [{"text": "F-1 score", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.97449991106987}, {"text": "virus NER", "start_pos": 90, "end_pos": 99, "type": "TASK", "confidence": 0.39531219005584717}]}, {"text": "We also show that by adding candidate phrase embeddings as features in a sequence tagger gives better performance compared to using word embed-dings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several works (e.g.,) have shown that injecting dictionary matches as features in a sequence tagger results in significant gains in NER performance.", "labels": [], "entities": [{"text": "NER", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.9562566876411438}]}, {"text": "However, building these dictionaries requires a huge amount of human effort and it is often difficult to get good coverage for many named entity types.", "labels": [], "entities": []}, {"text": "The problem is more severe when we consider named entity types such as gene, virus and disease, because of the large (and growing) number of names in use, the fact that the names are heavily abbreviated and multiple names are used to refer to the same entity (.", "labels": [], "entities": []}, {"text": "Also, these dictionaries can only be built by domain experts, making the process very expensive.", "labels": [], "entities": []}, {"text": "This paper describes an approach for automatic construction of dictionaries for NER using large amounts of unlabeled data and a small number of seed examples.", "labels": [], "entities": [{"text": "NER", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.8945143818855286}]}, {"text": "Our approach consists of two steps.", "labels": [], "entities": []}, {"text": "First, we collect a high recall, low precision list of candidate phrases from the large unlabeled data collection for every named entity type using simple rules.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9985727071762085}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.919418215751648}]}, {"text": "In the second step, we construct an accurate dictionary of named entities by removing the noisy candidates from the list obtained in the first step.", "labels": [], "entities": []}, {"text": "This is done by learning a classifier using the lower dimensional, real-valued CCA embeddings of the candidate phrases as features and training it using a small number of labeled examples.", "labels": [], "entities": []}, {"text": "The classifier we use is a binary SVM which predicts whether a candidate phrase is a named entity or not.", "labels": [], "entities": []}, {"text": "We compare our method to a widely used semisupervised algorithm based on co-training).", "labels": [], "entities": []}, {"text": "The dictionaries are first evaluated on virus and disease (Dogan and Lu, 2012) NER by using them directly in dictionary based taggers.", "labels": [], "entities": [{"text": "NER", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.900377094745636}]}, {"text": "We also give results comparing the dictionaries produced by the two semi-supervised approaches with dictionaries that are compiled manually.", "labels": [], "entities": []}, {"text": "The effectiveness of the dictionaries are also measured by injecting dictionary matches as features in a Conditional Random Field (CRF) based tagger.", "labels": [], "entities": []}, {"text": "The results indicate that our approach with minimal supervision produces dictionaries that are comparable to dictionaries compiled manually.", "labels": [], "entities": []}, {"text": "Finally, we also compare the quality of the candidate phrase embeddings with word embeddings) by adding them as features in a CRF based sequence tagger.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we give experimental results on virus and disease NER.", "labels": [], "entities": [{"text": "virus and disease NER", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.5214944556355476}]}], "tableCaptions": [{"text": " Table 1: Precision, recall, F-1 scores of dictionary-based taggers", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9930317401885986}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9978986978530884}, {"text": "F-1", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9909229874610901}]}]}