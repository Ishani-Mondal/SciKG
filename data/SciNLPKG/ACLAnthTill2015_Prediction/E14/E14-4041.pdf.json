{"title": [{"text": "Finding middle ground? Multi-objective Natural Language Generation from time-series data", "labels": [], "entities": [{"text": "Multi-objective Natural Language Generation", "start_pos": 23, "end_pos": 66, "type": "TASK", "confidence": 0.5649077072739601}]}], "abstractContent": [{"text": "A Natural Language Generation (NLG) system is able to generate text from non-linguistic data, ideally personalising the content to a user's specific needs.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 2, "end_pos": 35, "type": "TASK", "confidence": 0.8078791697820028}]}, {"text": "In some cases, however, there are multiple stake-holders with their own individual goals, needs and preferences.", "labels": [], "entities": []}, {"text": "In this paper, we explore the feasibility of combining the preferences of two different user groups, lecturers and students, when generating summaries in the context of student feedback generation.", "labels": [], "entities": [{"text": "student feedback generation", "start_pos": 169, "end_pos": 196, "type": "TASK", "confidence": 0.6678064366181692}]}, {"text": "The preferences of each user group are modelled as a multivariate optimisation function, therefore the task of generation is seen as a multi-objective (MO) optimisation task, where the two functions are combined into one.", "labels": [], "entities": []}, {"text": "This initial study shows that treating the preferences of each user group equally smooths the weights of the MO function, in away that preferred content of the user groups is not presented in the generated summary.", "labels": [], "entities": [{"text": "MO", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.5210922956466675}]}], "introductionContent": [{"text": "Summarisation of time-series data refers to the task of automatically generating summaries from attributes whose values changeover time.", "labels": [], "entities": [{"text": "Summarisation of time-series", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.881127933661143}]}, {"text": "Content selection is the task of choosing what to say, i.e. what information to be included in a report).", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7322860956192017}]}, {"text": "Here, we consider the task of automatically generating feedback summaries for students describing their performance during the lab of a computer science module over the semester.", "labels": [], "entities": []}, {"text": "This work is motivated by the fact that different user groups have different preferences of the content that should be conveyed in a summary, as shown by.", "labels": [], "entities": []}, {"text": "Various factors can influence students' learning, such as difficulty of the material (, workload (), attendance in lectures etc.", "labels": [], "entities": []}, {"text": "These factors changeover time and can be interdependent.", "labels": [], "entities": []}, {"text": "The different stakeholders (i.e. lecturers and students) have different perceptions regarding what constitutes good feedback.", "labels": [], "entities": []}, {"text": "Therefore, when generating feedback, we should take into account all preferences in order to be able to produce feedback summaries that are acceptable by both user groups.", "labels": [], "entities": []}, {"text": "Stakeholders often have conflicting goals, needs and preferences, for example managers with employees or doctors with patients and relatives.", "labels": [], "entities": []}, {"text": "In our data, for instance, lecturers tend to comment on the hours that a student studied, whereas the students disprefer this content.", "labels": [], "entities": []}, {"text": "Generating the same summary for both groups allows for meaningful further discussion with common ground.", "labels": [], "entities": []}, {"text": "Previous work on NLG systems that address more than one user group use different versions of a system for each different user group ( or make use of User Models).", "labels": [], "entities": []}, {"text": "Here, we explore a method that adapts to both expert preferences and users simultaneously (i.e. lecturer and students preferences), by applying Multi-Objective optimisation (MOO).", "labels": [], "entities": []}, {"text": "MOO can be applied to situations where optimal decisions are sought in the presence of trade-offs between conflicting objectives (.", "labels": [], "entities": [{"text": "MOO", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8784660696983337}]}, {"text": "We explore whether balancing the preferences of two user groups can result in an adaptive system that is acceptable by all users.", "labels": [], "entities": []}, {"text": "At the same time, the programming effort is reduced as only one system needs to be developed.", "labels": [], "entities": []}, {"text": "Moreover, by pooling all available data together, there is less need for an extensive data collection.", "labels": [], "entities": []}, {"text": "In the next section, we present three systems: one tuned for lecturers, one for students, and one that attempts to find middle ground.", "labels": [], "entities": []}, {"text": "In Section 3, we describe an evaluation of these three systems and in Section 4 we discuss the results.", "labels": [], "entities": []}, {"text": "Finally, in 210 Section 5, directions for future work are discussed.", "labels": [], "entities": [{"text": "210 Section 5", "start_pos": 12, "end_pos": 25, "type": "DATASET", "confidence": 0.8497218092282613}]}], "datasetContent": [{"text": "The output of the above-mentioned three systems were evaluated both in simulation and with real users.", "labels": [], "entities": []}, {"text": "Example summaries of all systems are presented in.", "labels": [], "entities": []}, {"text": "26 summaries were produced by each system.", "labels": [], "entities": []}, {"text": "The output of each system was evaluated with the three reward functions.", "labels": [], "entities": []}, {"text": "As expected, all systems score highly when evaluated with the reward function for which they were trained, with the second highest reward scored from the MO function.", "labels": [], "entities": [{"text": "MO", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.5885521173477173}]}, {"text": "illustrates this with the MO Policy clearly between the other two policies.", "labels": [], "entities": [{"text": "MO", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.7370209693908691}]}, {"text": "Moreover, the MO function reduces the variability between summaries as is also reflected in the standard deviation given in.", "labels": [], "entities": [{"text": "MO", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9761362075805664}]}, {"text": "We used BLEU (4-grams) () to measure the similarities between the feedback summaries generated by the three systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9990038275718689}]}, {"text": "BLEU score is between 0-1 with values closer to 1 indicating texts are more similar.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9725503921508789}]}, {"text": "Our results demonstrate that the summaries generated by the three systems are quite different (BLEU score between 0.33 and 0.36).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9992179870605469}]}, {"text": "This shows that the framework presented here is capable of producing quite different summaries based on the various reward functions.", "labels": [], "entities": []}, {"text": "The goal of the evaluation is to determine whether the end-user can pickup on the above-mentioned differences in the feedback and rank them according to their preferences.", "labels": [], "entities": []}, {"text": "The output of the three systems was ranked by 19 lecturers and 48 firstyear Computer Science students.", "labels": [], "entities": []}, {"text": "Time-series data of three students were presented on graphs to each participant.", "labels": [], "entities": []}, {"text": "They were also shown 3 feedback summaries and they were asked to rank them in terms of preference.", "labels": [], "entities": []}, {"text": "As we can see from, the two user groups significantly preferred the output of the system which was trained for their preferences (MannWhitney U test, p < 0.05).", "labels": [], "entities": [{"text": "MannWhitney U test", "start_pos": 130, "end_pos": 148, "type": "DATASET", "confidence": 0.7798210779825846}]}, {"text": "Interestingly, lecturers found both the outputs produced by the Lectureradapted system and the Student-adapted system significantly preferable (p < 0.05) to the output produced by the MO system.", "labels": [], "entities": []}, {"text": "In contrast, students significantly preferred the output generated by the Student-adapted system over the other two.", "labels": [], "entities": []}, {"text": "Finally, both user groups rated the MO system 3rd, but there is not a significant difference between the student ratings for the MO system and the Lecturer-adapted system.", "labels": [], "entities": [{"text": "MO system", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.7005554735660553}]}], "tableCaptions": [{"text": " Table 1: Top left: example of the time-series raw data for feedback generation. Bottom left: example of  described trends. Right box: a target summary generated by an expert (bold signifies the chosen content).", "labels": [], "entities": [{"text": "feedback generation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7221464365720749}]}]}