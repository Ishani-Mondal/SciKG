{"title": [{"text": "Undirected Machine Translation with Discriminative Reinforcement Learning", "labels": [], "entities": [{"text": "Undirected Machine Translation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.583715409040451}]}], "abstractContent": [{"text": "We present a novel Undirected Machine Translation model of Hierarchical MT that is not constrained to the standard bottom-up inference order.", "labels": [], "entities": [{"text": "Undirected Machine Translation", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.6024074951807658}, {"text": "Hierarchical MT", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.5865250527858734}]}, {"text": "Removing the ordering constraint makes it possible to condition on top-down structure and surrounding context.", "labels": [], "entities": []}, {"text": "This allows the introduction of anew class of contextual features that are not constrained to condition only on the bottom-up context.", "labels": [], "entities": []}, {"text": "The model builds translation-derivations efficiently in a greedy fashion.", "labels": [], "entities": []}, {"text": "It is trained to learn to choose jointly the best action and the best inference order.", "labels": [], "entities": []}, {"text": "Experiments show that the decoding time is halved and forest-rescoring is 6 times faster, while reaching accuracy not significantly different from state of the art.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9994605183601379}]}], "introductionContent": [{"text": "Machine Translation (MT) can be addressed as a structured prediction task ().", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8889725804328918}]}, {"text": "MT's goal is to learn a mapping function, f , from an input sentence, x, into y = (t, h), where t is the sentence translated into the target language, and h is the hidden correspondence structure ).", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9388553500175476}]}, {"text": "In Hierarchical MT (HMT)) the hidden correspondence structure is the synchronous-tree composed by instantiations of synchronous rules from the input grammar, G. Statistical models usually define f as: f (x) = arg max y\u2208Y Score(x, y), where Score(x, y) is a function whose parameters can be learned with a specialized learning algorithm.", "labels": [], "entities": [{"text": "Hierarchical MT (HMT))", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7505058526992798}]}, {"text": "In MT applications, it is not possible to enumerate ally \u2208 Y.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9778532385826111}]}, {"text": "HMT decoding applies pruning (e.g. Cube Pruning), but even then HMT has higher complexity than Phrase Based MT (PbMT) ().", "labels": [], "entities": []}, {"text": "On the other hand, HMT improves over PbMT by introducing the possibility of exploiting a more sophisticated reordering model not bounded by a window size, and producing translations with higher syntacticsemantic quality.", "labels": [], "entities": []}, {"text": "In this paper, we present the Undirected Machine Translation (UMT) framework, which retains the advantages of HMT and allows the use of a greedy decoder whose complexity is lower than standard quadratic beamsearch PbMT.", "labels": [], "entities": [{"text": "Undirected Machine Translation (UMT)", "start_pos": 30, "end_pos": 66, "type": "TASK", "confidence": 0.7622574716806412}]}, {"text": "UMT's fast decoding is made possible through even stronger pruning: the decoder chooses a single action at each step, never retracts that action, and prunes all incompatible alternatives to that action.", "labels": [], "entities": [{"text": "UMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8636574149131775}]}, {"text": "If this extreme level of pruning was applied to the CKY-like beam-decoding used in standard HMT, translation quality would be severely degraded.", "labels": [], "entities": [{"text": "translation", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9403102397918701}]}, {"text": "This is because the bottom-up inference order imposed by CKY-like beam-decoding means that all pruning decisions must be based on a bottom-up approximation of contextual features, which leads to search errors that affect the quality of reordering and lexical-choice (.", "labels": [], "entities": []}, {"text": "UMT solves this problem by removing the bottom-up inference order constraint, allowing many different inference orders for the same tree structure, and learning the inference order where the decoder can be the most confident in its pruning decisions.", "labels": [], "entities": [{"text": "UMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.793144702911377}]}, {"text": "Removing the bottom-up inference order constraint makes it possible to condition on top-down structure and surrounding context.", "labels": [], "entities": []}, {"text": "This undirected approach allows us to integrate contextual features such as the Language Model (LM) in a more flex-ible way.", "labels": [], "entities": []}, {"text": "It also allows us to introduce anew class of undirected features.", "labels": [], "entities": []}, {"text": "In particular, we introduce the Context-Free Factor (CFF) features.", "labels": [], "entities": []}, {"text": "CFF features compute exactly and efficiently abound on the context-free cost of a partial derivation's missing branches, thereby estimating the future cost of partial derivations.", "labels": [], "entities": [{"text": "CFF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9185671806335449}]}, {"text": "The new class of undirected features is fundamental for the success of a greedy approach to HMT, because the additional nonbottom-up context is sometimes crucial to have the necessary information to make greedy decisions.", "labels": [], "entities": [{"text": "HMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9352282285690308}]}, {"text": "Because UMT prunes all but the single chosen action at each step, both choosing a good inference order and choosing a correct action reduce to a single choice of what action to take next.", "labels": [], "entities": []}, {"text": "To learn this decoding policy, we propose a novel Discriminative Reinforcement Learning (DRL) framework.", "labels": [], "entities": []}, {"text": "DRL is used to train models that construct incrementally structured output using a local discriminative function, with the goal of optimizing a global loss function.", "labels": [], "entities": [{"text": "DRL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8241837620735168}]}, {"text": "We apply DRL to learn the UMT scoring function's parameters, using the BLEU score as the global loss function.", "labels": [], "entities": [{"text": "DRL", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.609139084815979}, {"text": "UMT scoring", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.47545790672302246}, {"text": "BLEU score", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9616607427597046}]}, {"text": "DRL learns a weight vector fora linear classifier that discriminates between decisions based on which one leads to a complete translation-derivation with a better BLEU score.", "labels": [], "entities": [{"text": "DRL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9034160375595093}, {"text": "BLEU", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.9992840886116028}]}, {"text": "Promotions/demotions of translations are performed by applying a Perceptron-style update on the sequence of decisions that produced the translation, thereby training local decisions to optimize the global BLEU score of the final translation, while keeping the efficiency and simplicity of the Perceptron Algorithm.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 205, "end_pos": 215, "type": "METRIC", "confidence": 0.9714696705341339}, {"text": "simplicity", "start_pos": 275, "end_pos": 285, "type": "METRIC", "confidence": 0.9921765923500061}]}, {"text": "Our experiments show that UMT with DRL reduces decoding time by over half, and the time to rescore translations with the Language Model by 6 times, while reaching accuracy non-significantly different from the state of the art.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9989199638366699}]}], "datasetContent": [{"text": "We implement our model on top of Cdec (. Cdec provides a standard implementation of the HMT decoder and MERT training) that we use as baseline.", "labels": [], "entities": []}, {"text": "We experiment on the NIST Chinese-English parallel corpus.", "labels": [], "entities": [{"text": "NIST Chinese-English parallel corpus", "start_pos": 21, "end_pos": 57, "type": "DATASET", "confidence": 0.9354300796985626}]}, {"text": "The training corpus contains 239k sentence pairs with 6.9M Chinese words and 8.9M English words.", "labels": [], "entities": []}, {"text": "The test set contains 919 sentence pairs.", "labels": [], "entities": []}, {"text": "The hierarchical translation grammar was extracted using the Joshua toolkit () implementation of the suffix array rule extractor algorithm.", "labels": [], "entities": [{"text": "suffix array rule extractor", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.623589500784874}]}, {"text": "reports the decoding time measures.", "labels": [], "entities": []}, {"text": "HMT with beam1 is the fastest possible configuration for HMT, but it is 71.59% slower than UMT.", "labels": [], "entities": [{"text": "HMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.908948540687561}]}, {"text": "This is because HMT b1 constructs O(n 2 ) subtrees, many of which end up not being used in the final result, whereas UMT only constructs the rule instantiations that are required.", "labels": [], "entities": [{"text": "UMT", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.8043358325958252}]}, {"text": "HMT with beam30 is the fastest configuration that reaches state of the art accuracy, but increases the average time per sentence by an additional 131.36% when compared with UMT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9990816116333008}]}, {"text": "The rescoring time is   the average time spent on the forest rescoring step, which is the only step where the decoders actually differ.", "labels": [], "entities": []}, {"text": "This is the step that involves the integration of the Language Model and other contextual features.", "labels": [], "entities": []}, {"text": "For HMT b30, rescoring takes two thirds of the total decoding time.", "labels": [], "entities": [{"text": "HMT b30", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.7070646286010742}]}, {"text": "Thus rescoring is the most time consuming step in the pipeline.", "labels": [], "entities": [{"text": "rescoring", "start_pos": 5, "end_pos": 14, "type": "TASK", "confidence": 0.9612369537353516}]}, {"text": "The rescoring time comparison shows even bigger gains for UMT.", "labels": [], "entities": [{"text": "UMT", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.8204049468040466}]}, {"text": "HMT b30 is almost 6 times slower than UMT.", "labels": [], "entities": [{"text": "HMT b30", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8594065010547638}]}, {"text": "reports the training time measures.", "labels": [], "entities": []}, {"text": "These results show HMT b30 training is more than 4 times slower than UMT training with DRL.", "labels": [], "entities": [{"text": "HMT b30", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.5669484436511993}]}, {"text": "Comparing with, we notice that the relative gain on average training time is higher than the gain measured at decoding time.", "labels": [], "entities": []}, {"text": "This is because MERT has an higher complexity than DRL.", "labels": [], "entities": []}, {"text": "Both of the training algorithms requires 10 training epochs to reach convergence.", "labels": [], "entities": []}, {"text": "As expected, accuracy degrades the more aggressively the search space is pruned.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.999320387840271}]}, {"text": "UMT trained with DRL loses 2.0 BLEU points compared to HMT b30.", "labels": [], "entities": [{"text": "UMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8947337865829468}, {"text": "DRL", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.7939835786819458}, {"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9996175765991211}, {"text": "HMT b30", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.7693119943141937}]}, {"text": "This corresponds to a relative-loss of 6.33%.", "labels": [], "entities": [{"text": "relative-loss", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9852690100669861}]}, {"text": "Although not inconsequential, this variation is not considered big (e.g. at the WMT-11 Machine Translation shared task).", "labels": [], "entities": [{"text": "WMT-11 Machine Translation shared task", "start_pos": 80, "end_pos": 118, "type": "TASK", "confidence": 0.8031704187393188}]}, {"text": "To measure the significance of the variation, we compute the sign test and measure the one-tail p-value for the presented models in comparison to HMT b30.", "labels": [], "entities": [{"text": "HMT b30", "start_pos": 146, "end_pos": 153, "type": "DATASET", "confidence": 0.8835693299770355}]}, {"text": "From the values reported in the fourth column, we can observe that the BLEU score variations would not normally be considered significant.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9796816408634186}]}, {"text": "For example, at WMT-11 two systems were considered equivalent if p > 0.1, as in these cases.", "labels": [], "entities": [{"text": "WMT-11", "start_pos": 16, "end_pos": 22, "type": "DATASET", "confidence": 0.8527907729148865}]}, {"text": "The accuracy cannot be compared in terms of search score since the models we are comparing are trained with distinct algorithms and thus the search scores are not comparable.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994686245918274}]}, {"text": "To test the impact of the CFF features, we trained and tested UMT with DRL with and without these features.", "labels": [], "entities": []}, {"text": "This resulted in an accuracy decrease of 2.3 BLEU points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9997679591178894}, {"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9995455145835876}]}, {"text": "Thus these features are important for the success of the greedy approach.", "labels": [], "entities": []}, {"text": "They provide an estimate of the score of the missing branches, thus helping to avoid some actions that have a good local score but lead to final translations with low global score.", "labels": [], "entities": []}, {"text": "To validate the results, additional experiments were executed on the French to Italian portion of the Europarl corpus v6.", "labels": [], "entities": [{"text": "French to Italian portion of the Europarl corpus v6", "start_pos": 69, "end_pos": 120, "type": "DATASET", "confidence": 0.7368617786301507}]}, {"text": "This portion contains 190k pairs of sentences.", "labels": [], "entities": []}, {"text": "The first 186k sentences were used to extract the grammar and train the two models.", "labels": [], "entities": []}, {"text": "The final tests were performed on the remaining 4k sentence pairs.", "labels": [], "entities": []}, {"text": "With this corpus we measured a similar speed gain.", "labels": [], "entities": [{"text": "speed gain", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.954569399356842}]}, {"text": "HMT b30 is 2.3 times slower at decoding compared to UMT, and 6.1 times slower at rescoring, while UMT loses 1.1 BLEU points inaccuracy.", "labels": [], "entities": [{"text": "HMT b30", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8644270598888397}, {"text": "BLEU points inaccuracy", "start_pos": 112, "end_pos": 134, "type": "METRIC", "confidence": 0.9436051249504089}]}, {"text": "But again the accuracy differences are not considered significant.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996719360351562}]}, {"text": "We measured a p-value of 0.25, which is not significant at the 0.1 level.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Decoding speed comparison.", "labels": [], "entities": []}, {"text": " Table 2: Training speed comparison.", "labels": [], "entities": []}]}