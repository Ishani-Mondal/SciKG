{"title": [{"text": "Automatic Selection of Reference Pages in Wikipedia for Improving Targeted Entities Disambiguation", "labels": [], "entities": [{"text": "Improving Targeted Entities Disambiguation", "start_pos": 56, "end_pos": 98, "type": "TASK", "confidence": 0.8777617812156677}]}], "abstractContent": [{"text": "In Targeted Entity Disambiguation setting, we take (i) a set of entity names which belong to the same domain (target entities), (ii) candidate mentions of the given entities which are texts that contain the target entities as input, and then determine which ones are true mentions of \"target entity\".", "labels": [], "entities": [{"text": "Targeted Entity Disambiguation setting", "start_pos": 3, "end_pos": 41, "type": "TASK", "confidence": 0.707929402589798}]}, {"text": "For example, given the names of IT companies, including Apple, we determine Apple in a mention denotes an IT company or not.", "labels": [], "entities": [{"text": "Apple", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.8091241121292114}]}, {"text": "Prior work proposed a graph based model.", "labels": [], "entities": []}, {"text": "This model ranks all candidate mentions based on scores which denote the degree of relevancy to target entities.", "labels": [], "entities": []}, {"text": "Furthermore, this graph based model could utilize reference pages of target entities.", "labels": [], "entities": []}, {"text": "However, human annotators must select reference pages in advance.", "labels": [], "entities": []}, {"text": "We propose an automatic method that can select reference pages.", "labels": [], "entities": []}, {"text": "We formalize the selection problem of reference pages as an Integer Linear Programming problem.", "labels": [], "entities": []}, {"text": "We show that our model works as well as the prior work that manually selected reference pages.", "labels": [], "entities": []}], "introductionContent": [{"text": "The enterprise is typically interested in customer's opinions.", "labels": [], "entities": []}, {"text": "One of the methods to analyze customer's opinions is to collect mentions which contain product names.", "labels": [], "entities": []}, {"text": "We would get a noisy mention collection if we use a simple method which extracts mentions that contain product names, since the product names maybe used as other meanings.", "labels": [], "entities": []}, {"text": "proposed anew task which they referred to as Targeted Entity Disambiguation (TED).", "labels": [], "entities": [{"text": "Targeted Entity Disambiguation (TED)", "start_pos": 45, "end_pos": 81, "type": "TASK", "confidence": 0.7687260607878367}]}, {"text": "In this problem setting, we take (i) a set of entity names which belong to the same domain (target entities), (ii) candidate mentions of the given entities which are texts that contain the target entity entities as input, and then determine which ones are true mentions for the target entities.", "labels": [], "entities": []}, {"text": "TED is different from traditional Word Sense Disambiguation or Entity Linking.", "labels": [], "entities": [{"text": "TED", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6793650388717651}, {"text": "Word Sense Disambiguation or Entity Linking", "start_pos": 34, "end_pos": 77, "type": "TASK", "confidence": 0.6019128610690435}]}, {"text": "Word Sense Disambiguation can be viewed as a classification task in which word senses are the classes) and Entity Linking is the task of linking name in Web text with entities in Wikipedia ().", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.735068658987681}, {"text": "Entity Linking", "start_pos": 107, "end_pos": 121, "type": "TASK", "confidence": 0.6958744078874588}]}, {"text": "The uniqueness of this problem is that the entities are all in the same domain (referred to as the target domain) and not necessarily included in a knowledge base such as DBpedia, Freebase or YAGO.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 171, "end_pos": 178, "type": "DATASET", "confidence": 0.9392370581626892}]}, {"text": "realized TED with a graph based model.", "labels": [], "entities": []}, {"text": "In their graph based method, a target entity in a mention is regarded as anode, and the weight of an edge is determined according to context similarity, and a prior score of node that is determined according to the unique number of target entities in the mention.", "labels": [], "entities": []}, {"text": "This graph is called as a mention graph.", "labels": [], "entities": []}, {"text": "Using mention graph, the authority of each mention is calculated with MentionRank which is a variant of PageRank (.", "labels": [], "entities": [{"text": "MentionRank", "start_pos": 70, "end_pos": 81, "type": "DATASET", "confidence": 0.7950453758239746}]}, {"text": "This authority denotes a score of how likely this node is in the target domain.", "labels": [], "entities": []}, {"text": "In addition, MentionRank could integrate external knowledge such as Wikipedia.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.9304682016372681}]}, {"text": "For each target entity, a reference page is added as a virtual node to the graph.", "labels": [], "entities": []}, {"text": "Since reference pages can be regarded as true mentions, the prior scores of virtual nodes are higher than other mentions.", "labels": [], "entities": []}, {"text": "This extended method can propagate the score of the virtual node of each entity to candidate mentions which are likely true.", "labels": [], "entities": []}, {"text": "Although the use of reference pages works well, human annotators must select these reference pages.", "labels": [], "entities": []}, {"text": "In Word Sense Disambiguation and Entity Linking, there are some collective approaches.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.743860681851705}, {"text": "Entity Linking", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7441392540931702}]}, {"text": "In this paper, we apply this technique to the selection problem of reference pages for TED.", "labels": [], "entities": []}, {"text": "To select refer-ence pages, we collect candidate reference pages of target entities from Wikipedia in advance.", "labels": [], "entities": []}, {"text": "If the name of a target entity has a disambiguation page in Wikipedia, we have two or more candidate reference pages.", "labels": [], "entities": []}, {"text": "Then we formalize the problem of reference page selection as an Integer Linear Programming problem.", "labels": [], "entities": [{"text": "reference page selection", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.749787449836731}]}, {"text": "Our model is going to maximize the summation of similarities between selected pages under some constraints.", "labels": [], "entities": []}, {"text": "Thus, coherent pages are selected as reference pages.", "labels": [], "entities": []}, {"text": "Our method does not require any knowledge except for names of target entities.", "labels": [], "entities": []}, {"text": "We give only target entities as input to select reference pages.", "labels": [], "entities": []}, {"text": "Our method shows competitive accuracy of the prior method with manually selected reference pages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9992565512657166}]}], "datasetContent": [{"text": "We used weblogs written in Japanese for experiments.", "labels": [], "entities": []}, {"text": "Following the previous work, we created two datasets: Car and Magazine.", "labels": [], "entities": [{"text": "Magazine", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.7245745062828064}]}, {"text": "A summary of each dataset is shown in.", "labels": [], "entities": []}, {"text": "\u2022 Car: Target entities include car names such as Prius and Harrier.", "labels": [], "entities": [{"text": "Harrier", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9414185881614685}]}, {"text": "\u2022 Magazine: Target entities include magazine names such as MORE and LEE.", "labels": [], "entities": [{"text": "Magazine", "start_pos": 2, "end_pos": 10, "type": "DATASET", "confidence": 0.7008160948753357}, {"text": "MORE", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.7812892198562622}, {"text": "LEE", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9024937152862549}]}, {"text": "We randomly selected 5, 10 or 15 entities from each target entities for 10 times and conducted experiment for each dataset with parameter \u03bb = 0.15.", "labels": [], "entities": []}, {"text": "We conducted significance test using Wilcoxon signed-rank test.", "labels": [], "entities": [{"text": "significance", "start_pos": 13, "end_pos": 25, "type": "METRIC", "confidence": 0.9775407910346985}]}, {"text": "lists the experimental results on these datasets.", "labels": [], "entities": []}, {"text": "In Table 2, MentionRank+manVN denotes MentionRank with virtual nodes that are selected manually (.", "labels": [], "entities": []}, {"text": "MentionRank+randomVN denotes MentionRank with virtual nodes that are selected randomly from candidate reference pages in Wikipedia.", "labels": [], "entities": []}, {"text": "Proposed method denotes the MentionRank with virtual nodes that are selected automatically using ILP.", "labels": [], "entities": [{"text": "MentionRank", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9269508719444275}]}, {"text": "Values with \u2020in indicate that there are significant differences between mean average precision of proposed method and the others.", "labels": [], "entities": [{"text": "mean average precision", "start_pos": 72, "end_pos": 94, "type": "METRIC", "confidence": 0.8282221555709839}]}, {"text": "Five results of proposed methods are better than those of MentionRank, there are significant differences on two results.", "labels": [], "entities": [{"text": "MentionRank", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.9446459412574768}]}, {"text": "Furthermore, all the results of proposed method is better than those of MentionRank+randomVN and there are significant differences on three results.", "labels": [], "entities": [{"text": "MentionRank+randomVN", "start_pos": 72, "end_pos": 92, "type": "DATASET", "confidence": 0.8149859110514323}]}, {"text": "Four results of proposed method is worse than those of MentionRank+manVN, however there is a significant difference on only one of those results.", "labels": [], "entities": [{"text": "MentionRank+manVN", "start_pos": 55, "end_pos": 72, "type": "DATASET", "confidence": 0.804027775923411}]}, {"text": "From these results, we can see that use of reference pages automatically selected by our method improves mean average precision.", "labels": [], "entities": [{"text": "mean average", "start_pos": 105, "end_pos": 117, "type": "METRIC", "confidence": 0.8023530840873718}, {"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.6286113858222961}]}, {"text": "In Magazine, several entities are not ambiguous and we could get true reference pages easily.", "labels": [], "entities": [{"text": "Magazine", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.9778077602386475}]}, {"text": "Therefore, we think proposed method did not show any significant differences compared with MentionRank+randomVN.", "labels": [], "entities": [{"text": "MentionRank", "start_pos": 91, "end_pos": 102, "type": "DATASET", "confidence": 0.8891832232475281}]}, {"text": "Also, in Car, several entities are not ambiguous but these reference pages belong to domains other than Car domain.", "labels": [], "entities": []}, {"text": "As a result, we think that some results are worse than MentionRank.", "labels": [], "entities": [{"text": "MentionRank", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9752123355865479}]}, {"text": "For example, entity \"86\" which is a kind of car have only one reference page that belongs to number domain.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Datasets: n is # of entities, k is # of can- didate mentions, #cand is average # of candidate  reference pages for each entity and %Positive is %  of true mentions in all candidate mentions", "labels": [], "entities": []}, {"text": " Table 2: Mean average precision for each dataset", "labels": [], "entities": [{"text": "Mean average precision", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.9206802447636923}]}]}