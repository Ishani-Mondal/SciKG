{"title": [{"text": "Using Minimal Recursion Semantics for Entailment Recognition", "labels": [], "entities": [{"text": "Entailment Recognition", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.833817183971405}]}], "abstractContent": [{"text": "This paper describes work on using Minimal Recursion Semantics (MRS) representations for the task of recognising tex-tual entailment.", "labels": [], "entities": [{"text": "Minimal Recursion Semantics (MRS)", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7021558980147043}]}, {"text": "I use entailment data from a SemEval-2010 shared task to develop and evaluate an entailment recognition heuristic.", "labels": [], "entities": [{"text": "entailment recognition heuristic", "start_pos": 81, "end_pos": 113, "type": "TASK", "confidence": 0.7630156675974528}]}, {"text": "I compare my results to the shared task winner, and discuss differences in approaches.", "labels": [], "entities": []}, {"text": "Finally, I run my system with multiple MRS representations per sentence, and show that this improves the recognition results for positive entail-ment sentence pairs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the first shared task on Recognising Textual Entailment (RTE) () was organised in 2005, much research has been done on how one can detect entailment between natural language sentences.", "labels": [], "entities": [{"text": "Recognising Textual Entailment (RTE)", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.8223075171311697}]}, {"text": "A range of methods within statistical, rule based, and logical approaches have been applied.", "labels": [], "entities": []}, {"text": "The methods have exploited knowledge on lexical relations, syntactic and semantic knowledge, and logical representations.", "labels": [], "entities": []}, {"text": "In this paper, I examine the benefits and possible disadvantages of using rich semantic representations as the basis for entailment recognition.", "labels": [], "entities": [{"text": "entailment recognition", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.9330470561981201}]}, {"text": "More specifically, I use Minimal Recursion Semantics (MRS) () representations as output by the English Resource Grammar (ERG).", "labels": [], "entities": []}, {"text": "I want to investigate how logical-form semantics compares to syntactic analysis on the task of determining the entailment relationship between two sentences.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.765119880437851}]}, {"text": "To my knowledge, MRS representations have so far not been extensively used for this task.", "labels": [], "entities": [{"text": "MRS representations", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9386075437068939}]}, {"text": "To this end, I revisit a SemEval shared task from 2010 that used entailment recognition as a means to evaluate parser output.", "labels": [], "entities": [{"text": "SemEval shared task", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.8352142175038656}, {"text": "entailment recognition", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.721033364534378}]}, {"text": "The shared task data were constructed so as to require only syntactic analysis to decide entailment fora sentence pair.", "labels": [], "entities": []}, {"text": "The MRSs should perform well on such data, as they abstract over irrelevant syntactic variation, as for example use of active vs. passive voice, or meaning-preserving variation in constituent order, and thus normalise at a highly suitable level of \"who did what to whom\".", "labels": [], "entities": [{"text": "MRSs", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.7692240476608276}]}, {"text": "The core idea of my approach is graph alignment over MRS representations, where successful alignment of MRS nodes is treated as an indicator of entailment.", "labels": [], "entities": [{"text": "graph alignment", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7121438980102539}, {"text": "MRS representations", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9005131125450134}]}, {"text": "This work is part of an ongoing dissertation project, where the larger goal is to look more closely at correspondences between logical and textual entailment, and the use of semantic representations in entailment recognition.", "labels": [], "entities": [{"text": "entailment recognition", "start_pos": 202, "end_pos": 224, "type": "TASK", "confidence": 0.8261917233467102}]}, {"text": "Besides using MRS, one novel aspect of this work is an investigation of using n-best lists of parser outputs in deciding on entailment relations.", "labels": [], "entities": [{"text": "MRS", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8360649347305298}]}, {"text": "In principle, the top-ranked (i.e., most probable) parser output should correspond to the intended reading, but in practise this may not always be the case.", "labels": [], "entities": []}, {"text": "To increase robustness in our approach to imperfect parse ranking, I generalise the system to operate over n-best lists of MRSs.", "labels": [], "entities": [{"text": "parse ranking", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.8728141784667969}]}, {"text": "This setup yields greatly improved system performance and advances the state of the art on this task, i.e., makes my system retroactively the top performer in this specific competition.", "labels": [], "entities": []}, {"text": "The rest of this paper is organised as follows: in section 2, I describe the task of recognising textual entailment.", "labels": [], "entities": [{"text": "recognising textual entailment", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.8344294826189677}]}, {"text": "I also briefly describe MRS representations, and mention previous work on RTE using MRS.", "labels": [], "entities": [{"text": "MRS representations", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9511854648590088}]}, {"text": "In section 3, I analyse the shared task data, and implement an entailment decision component which takes as input MRS representations from the ERG.", "labels": [], "entities": []}, {"text": "I then analyse the errors that the component makes.", "labels": [], "entities": []}, {"text": "Finally, I compare my results to the actual winner of the 2010 shared task.", "labels": [], "entities": []}, {"text": "In section 4, I generalise my approach to 10-best lists of MRSs.", "labels": [], "entities": [{"text": "MRSs", "start_pos": 59, "end_pos": 63, "type": "TASK", "confidence": 0.9189176559448242}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The results for 1-best MRSs for the PETE  development data.", "labels": [], "entities": [{"text": "MRSs", "start_pos": 33, "end_pos": 37, "type": "TASK", "confidence": 0.8987815976142883}, {"text": "PETE  development data", "start_pos": 46, "end_pos": 68, "type": "DATASET", "confidence": 0.8620243469874064}]}, {"text": " Table 2: The results for 1-best MRSs for the PETE  test data.", "labels": [], "entities": [{"text": "MRSs", "start_pos": 33, "end_pos": 37, "type": "TASK", "confidence": 0.6466765999794006}, {"text": "PETE  test data", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.9120980302492777}]}, {"text": " Table 3: The two top systems from the PETE  shared task", "labels": [], "entities": [{"text": "PETE", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.846686840057373}]}]}