{"title": [{"text": "How to Produce Unseen Teddy Bears: Improved Morphological Processing of Compounds in SMT", "labels": [], "entities": [{"text": "Produce Unseen Teddy Bears", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.7975703477859497}, {"text": "Improved Morphological Processing of Compounds", "start_pos": 35, "end_pos": 81, "type": "TASK", "confidence": 0.7292226672172546}, {"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.5133992433547974}]}], "abstractContent": [{"text": "Compounding in morphologically rich languages is a highly productive process which often causes SMT approaches to fail because of unseen words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9923477172851562}]}, {"text": "We present an approach for translation into a compounding language that splits compounds into simple words for training and, due to an underspecified representation, allows for free merging of simple words into compounds after translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9771122336387634}]}, {"text": "In contrast to previous approaches, we use features projected from the source language to predict compound mergings.", "labels": [], "entities": []}, {"text": "We integrate our approach into end-to-end SMT and show that many compounds matching the reference translation are produced which did not appear in the training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.967391312122345}]}, {"text": "Additional manual evaluations support the usefulness of generalizing compound formation in SMT.", "labels": [], "entities": [{"text": "generalizing compound formation", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.8184532324473063}, {"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9833123087882996}]}], "introductionContent": [{"text": "Productive processes like compounding or inflection are problematic for traditional phrase-based statistical machine translation (SMT) approaches, because words can only be translated as they have occurred in the parallel training data.", "labels": [], "entities": [{"text": "compounding", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.9551199078559875}, {"text": "phrase-based statistical machine translation (SMT)", "start_pos": 84, "end_pos": 134, "type": "TASK", "confidence": 0.7429390932832446}]}, {"text": "As parallel training data is limited, it is desirable to extract as much information from it as possible.", "labels": [], "entities": []}, {"text": "We present an approach for compound processing in SMT, translating from English to German, that splits compounds prior to training (in order to access the individual words which together form the compound) and recombines them after translation.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8105047345161438}, {"text": "SMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9381066560745239}]}, {"text": "While compound splitting is a well-studied task, compound merging has not received as much attention in the past.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.8569633960723877}, {"text": "compound merging", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.8612096011638641}]}, {"text": "We start from, who used sequence models to predict compound merging and who, in addition, generalise over German inflection.", "labels": [], "entities": [{"text": "compound merging", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.6920787394046783}]}, {"text": "Our new contributions are: (i) We project features from the source language to support compound merging predictions.", "labels": [], "entities": [{"text": "compound merging predictions", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.760069211324056}]}, {"text": "As the source language input is fluent, these features are more reliable than features derived from target language SMT output.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 116, "end_pos": 126, "type": "TASK", "confidence": 0.8812577128410339}]}, {"text": "(ii) We reduce compound parts to an underspecified representation which allows for maximal generalisation.", "labels": [], "entities": []}, {"text": "(iii) We present a detailed manual evaluation methodology which shows that we obtain improved compound translations.", "labels": [], "entities": []}, {"text": "We evaluated compound processing both on held-out split data and in end-to-end SMT.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8772529661655426}, {"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9765557646751404}]}, {"text": "We show that using source language features increases the accuracy of compound generation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9991956353187561}, {"text": "compound generation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8040770292282104}]}, {"text": "Moreover, we find more correct compounds than the baselines, and a considerable number of these compounds are unseen in the training data.", "labels": [], "entities": []}, {"text": "This is largely due to the underspecified representation we are using.", "labels": [], "entities": []}, {"text": "Finally, we show that our approach improves upon the previous work.", "labels": [], "entities": []}, {"text": "We discuss compound processing in SMT in Section 2, and summarise related work in Section 3.", "labels": [], "entities": [{"text": "compound processing", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.850721925497055}, {"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9591970443725586}]}, {"text": "In Section 4 we present our method for splitting compounds and reducing the component words to an underspecified representation.", "labels": [], "entities": []}, {"text": "The merging to obtain German compounds is the subject of Section 5.", "labels": [], "entities": []}, {"text": "We evaluate the accuracy of compound prediction on held-out data in Section 6 and in end-to-end SMT experiments in Section 7.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9992583394050598}, {"text": "compound prediction", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8123847842216492}, {"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9859574437141418}]}, {"text": "We conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "This evaluation focuses on how compounds in the the reference text have been translated.", "labels": [], "entities": []}, {"text": "We: In another evaluation, we investigated the 519 compounds that our system produced but which did not match the reference: 367 were correct translations of the English, 1.", "labels": [], "entities": []}, {"text": "manually identify compounds in German reference text (1,105 found) 2.", "labels": [], "entities": []}, {"text": "manually perform word alignment of these compounds to the English source text 3.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.7094804495573044}]}, {"text": "project these English counterparts of compounds in the reference text to the decoded text using the \"-print-alignment-info\" flag 4.", "labels": [], "entities": []}, {"text": "manually annotate the resulting tuples, using the categories given in The results are given in the two rightmost columns of: besides a higher number of reference matches (cf. row 1a), STR overall produces more compounds than the UNSPLIT baseline, cf. rows 2a, 3a and 4a.", "labels": [], "entities": [{"text": "STR", "start_pos": 184, "end_pos": 187, "type": "TASK", "confidence": 0.5189455151557922}, {"text": "UNSPLIT baseline", "start_pos": 229, "end_pos": 245, "type": "DATASET", "confidence": 0.7771597802639008}]}, {"text": "Indirectly, this can also be seen from the low numbers of STR in category 2b), where the UNSPLIT baseline produces much more (101 vs. 54) translations that lexically match the reference without being a compound.", "labels": [], "entities": [{"text": "UNSPLIT baseline", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.8268621563911438}]}, {"text": "While the 171 compounds of STR of category 3a) show that our system produces many compounds that are correct translations of the English, even though not matching the reference (and thus not credited by BLEU), the compounds of categories 2a) and 4a) contain examples where we either fail to reproduce the correct compound or over-generate compounds.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.9654759168624878}]}, {"text": "We give some examples in: for \"teddy bear\", the correct German word \"Teddyb\u00e4ren\" is 87 contained erroneous lexemes and 65 were over-mergings.", "labels": [], "entities": []}, {"text": "missing in the parallel training data and instead of \"B\u00e4r\" (\"bear\"), the baseline selected \"tragen\" (\"to bear\").", "labels": [], "entities": [{"text": "B\u00e4r", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9742181897163391}]}, {"text": "Extracting all words containing the substring \"b\u00e4r\" (\"bear\") from the original parallel training data and from its underspecified split version demonstrates that our approach is able to access all occurrences of the word.", "labels": [], "entities": []}, {"text": "This leads to higher frequency counts and thus enhances the probabilities for correct translations.", "labels": [], "entities": []}, {"text": "We can generalise over 18 different word types containing \"bear\" (e.g. \"polar bears\", \"brown bears\", \"bear skin\", \"bear fur\") to obtain only 2: occurrences in raw training data:, B\u00e4ren \"b\u00e4r\" occurring in underspecified split data: B\u00e4r<+NN><Masc><Sg> B\u00e4r<+NN><Masc><Pl> \"Emissionsverringerung\" (cf.) is atypical example of group 3a): a correctly translated compound that does not lexically match the reference, but which is semantically very similar to the reference.", "labels": [], "entities": []}, {"text": "The same applies for \"Bu\u00dfgeld\", a synonym of \"Geldstrafe\", for which the UN-SPLIT baseline selected \"sch\u00f6nen\" (\"fine, nice\") instead.", "labels": [], "entities": [{"text": "Bu\u00dfgeld", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.8644229769706726}, {"text": "UN-SPLIT baseline", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.827292799949646}]}, {"text": "Consider also the wrong compound productions, e.g. \"Tischtennis\" is combined with the verb \"spielen\" (\"to play\") into \"Spieltischtennis\".", "labels": [], "entities": []}, {"text": "In contrast, \"Kreditmarkt\" dropped the middle part \"Karte\" (\"card\"), and in the case of \"Temporotation\", the head and modifier of the compound are switched.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Compound production accuracies of CRF models on held-out data: SC: re-implementation of Stymne", "labels": [], "entities": [{"text": "Stymne", "start_pos": 98, "end_pos": 104, "type": "DATASET", "confidence": 0.8505372405052185}]}, {"text": " Table 4: SMT results. Tuning scores (mert.log) are on merged but uninflected data (except RAW).", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.989469051361084}, {"text": "Tuning", "start_pos": 23, "end_pos": 29, "type": "TASK", "confidence": 0.915179967880249}]}, {"text": " Table 5: Groups for detailed manual compound evaluation and results for UNSPLIT and STR.", "labels": [], "entities": [{"text": "UNSPLIT", "start_pos": 73, "end_pos": 80, "type": "DATASET", "confidence": 0.8112620711326599}, {"text": "STR", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.6146703362464905}]}, {"text": " Table 7: Human perception of translation quality.", "labels": [], "entities": [{"text": "Human perception of translation quality", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.5472556531429291}]}]}