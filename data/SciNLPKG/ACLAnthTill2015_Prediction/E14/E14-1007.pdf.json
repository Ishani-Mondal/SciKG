{"title": [{"text": "Inducing Example-based Semantic Frames from a Massive Amount of Verb Uses", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an unsupervised method for inducing semantic frames from verb uses in giga-word corpora.", "labels": [], "entities": []}, {"text": "Our semantic frames are verb-specific example-based frames that are distinguished according to their senses.", "labels": [], "entities": []}, {"text": "We use the Chinese Restaurant Process to automatically induce these frames from a massive amount of verb instances.", "labels": [], "entities": []}, {"text": "In our experiments, we acquire broad-coverage semantic frames from two giga-word corpora, the larger comprising 20 billion words.", "labels": [], "entities": []}, {"text": "Our experimental results indicate the effectiveness of our approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic frames are indispensable knowledge for semantic analysis or text understanding.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.773995041847229}, {"text": "text understanding", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7497605979442596}]}, {"text": "In the last decade, semantic frames, such as FrameNet () and), have been manually elaborated.", "labels": [], "entities": []}, {"text": "These resources are effectively exploited in many natural language processing (NLP) tasks, including not only semantic parsing but also machine translation), information extraction (), question answering (), paraphrase acquisition ( and recognition of textual entailment).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.7558470368385315}, {"text": "machine translation", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.6949542909860611}, {"text": "information extraction", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.8344389200210571}, {"text": "question answering", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.8827812075614929}, {"text": "paraphrase acquisition", "start_pos": 208, "end_pos": 230, "type": "TASK", "confidence": 0.957099199295044}, {"text": "recognition of textual entailment", "start_pos": 237, "end_pos": 270, "type": "TASK", "confidence": 0.886403352022171}]}, {"text": "There have been many attempts to automatically acquire frame knowledge from raw corpora with the goal of either adding frequency information to an existing resource or of inducing similar frames for other languages.", "labels": [], "entities": []}, {"text": "Most of these approaches, however, focus on syntactic frames, i.e., subcategorization frames (e.g.,).", "labels": [], "entities": []}, {"text": "Since subcategorization frames represent argument patterns of verbs and are purely syntactic, expressions that have the same subcategorization frame can have different meanings (e.g., metaphors).", "labels": [], "entities": []}, {"text": "Semantics-oriented NLP applications based on frames, such as paraphrase acquisition and machine translation, require consistency in the meaning of each frame, and thus these subcategorization frames are not suitable for these semantic tasks.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.8799523413181305}, {"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7733587920665741}]}, {"text": "Recently, there have been a few studies on automatically acquiring semantic frames.", "labels": [], "entities": []}, {"text": "Materna induced semantic frames (called LDA-Frames) from triples of (subject, verb, object) in the British National Corpus (BNC) based on Latent Dirichlet Allocation (LDA) and the Dirichlet Process.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 99, "end_pos": 128, "type": "DATASET", "confidence": 0.9716911613941193}]}, {"text": "LDAFrames capture limited linguistic phenomena of these triples, and are defined across verbs based on probabilistic topic distributions.", "labels": [], "entities": []}, {"text": "This paper presents a method for automatically building verb-specific semantic frames from a large raw corpus.", "labels": [], "entities": []}, {"text": "Our semantic frames are verbspecific like PropBank and semantically distinguished.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9541385769844055}]}, {"text": "A frame has several syntactic case slots, each of which consists of words that are eligible to fill the slot.", "labels": [], "entities": []}, {"text": "For example, let us show three semantic frames of the verb \"observe\": 1 observe: Frequencies, which are not shown in the above examples, are attached to each semantic frame, case slot and word, and can be effectively exploited for the applications of these semantic frames.", "labels": [], "entities": [{"text": "Frequencies", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9523723721504211}]}, {"text": "The frequencies of words in each case slot become good sources of selectional preferences.", "labels": [], "entities": []}, {"text": "Our novel contributions are summarized as follows: \u2022 induction of semantic frames based on the Chinese Restaurant Process from only automatic parses of a web-scale corpus, \u2022 exploitation of the assumption of one sense per collocation to make the computation feasible, \u2022 providing broad-coverage knowledge for selectional preferences, and \u2022 evaluating induced semantic frames by using an existing annotated corpus with verb classes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use two kinds of large-scale corpora: a web corpus and the English Gigaword corpus.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 62, "end_pos": 85, "type": "DATASET", "confidence": 0.7725367148717245}]}, {"text": "To prepare a web corpus, we first crawled the web.", "labels": [], "entities": []}, {"text": "We extracted sentences from each web page that seems to be written in English based on the encoding information.", "labels": [], "entities": []}, {"text": "Then, we selected sentences that consist of at most 40 words, and removed duplicated sentences.", "labels": [], "entities": []}, {"text": "From this process, we obtained a corpus of one billion sentences, totaling approximately 20 billion words.", "labels": [], "entities": []}, {"text": "We focused on verbs whose frequency was more than 1,000.", "labels": [], "entities": []}, {"text": "There were 19,649 verbs, including phrasal verbs, and separating passive and active constructions.", "labels": [], "entities": []}, {"text": "We extracted 2,032,774,982 predicate-argument structures.", "labels": [], "entities": []}, {"text": "We also used the English Gigaword corpus (LDC2011T07; English Gigaword Fifth Edition) to induce semantic frames.", "labels": [], "entities": [{"text": "English Gigaword corpus (LDC2011T07; English Gigaword Fifth Edition)", "start_pos": 17, "end_pos": 85, "type": "DATASET", "confidence": 0.892611259763891}]}, {"text": "This corpus consists of approximately 180 million sentences, which totaling four billion words.", "labels": [], "entities": []}, {"text": "There were 7,356 verbs after applying the same frequency threshold as the web corpus.", "labels": [], "entities": []}, {"text": "We extracted 423,778,278 predicateargument structures from this corpus.", "labels": [], "entities": []}, {"text": "We set the hyper-parameters \u03b1 in (1) and \u03b2 in (3) to 1.0.", "labels": [], "entities": []}, {"text": "The frame assignments for all the components were initialized randomly.", "labels": [], "entities": []}, {"text": "We took 100 samples for each initial frame and selected the frame assignment that has the highest probability.", "labels": [], "entities": []}, {"text": "These parameters were determined according to a preliminary experiment to manually examine the quality of resulting frames.", "labels": [], "entities": []}, {"text": "We executed the per-verb clustering tasks on a PC cluster.", "labels": [], "entities": []}, {"text": "It finished within a few hours for most verbs, but it took a couple of days for very frequent verbs, such as \"get\" and \"say.\"", "labels": [], "entities": []}, {"text": "The clustering produced an average number of semantic frames per verb of 15.2 for the web corpus and 18.5 for the Gigaword corpus.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 114, "end_pos": 129, "type": "DATASET", "confidence": 0.9152621924877167}]}, {"text": "Examples of induced semantic frames from the web corpus are shown in: Examples of resulting frames for the verb \"observe\" and \"accept\" induced from the web corpus.", "labels": [], "entities": []}, {"text": "The number following an instance word represents its frequency.", "labels": [], "entities": []}, {"text": "We evaluate precision and coverage of induced semantic frames.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9994719624519348}]}, {"text": "To measure the precision of induced semantic frames, we adopt the purity metric, which is usually used to evaluate clustering results.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9968202114105225}, {"text": "purity metric", "start_pos": 66, "end_pos": 79, "type": "METRIC", "confidence": 0.9491320252418518}]}, {"text": "However, the problem is that it is impossible to assign gold-standard classes to the huge number of instances.", "labels": [], "entities": []}, {"text": "To automatically measure the purity of the induced semantic frames, we make use of the SemLink corpus (, in which VerbNet classes) and PropBank/FrameNet frames are assigned to each instance.", "labels": [], "entities": [{"text": "SemLink corpus", "start_pos": 87, "end_pos": 101, "type": "DATASET", "confidence": 0.7564142048358917}]}, {"text": "We make a test set that contains 157 polysemous verbs that occur 10 or more times in the SemLink corpus (sections 02-21 of the Wall Street Journal).", "labels": [], "entities": [{"text": "SemLink corpus", "start_pos": 89, "end_pos": 103, "type": "DATASET", "confidence": 0.8477279543876648}, {"text": "Wall Street Journal", "start_pos": 127, "end_pos": 146, "type": "DATASET", "confidence": 0.8499038219451904}]}, {"text": "We first add these instances to the instances from a raw corpus and apply clustering to these merged instances.", "labels": [], "entities": []}, {"text": "Then, we compare the induced semantic frames of the SemLink instances with their gold-standard classes.", "labels": [], "entities": []}, {"text": "We adopt VerbNet classes and PropBank frames as gold-standard classes.", "labels": [], "entities": []}, {"text": "For each group of verb-specific semantic frames, we measure the purity of the frames as the percentage of SemLink instances belonging to the majority gold class in their respective cluster.", "labels": [], "entities": []}, {"text": "Let   N denote the total number of SemLink instances of the target verb, G j the set of instances belonging to the j-th gold class and F i the set of instances belonging to the i-th frame.", "labels": [], "entities": []}, {"text": "The purity (PU) can then be written as follows: For example, a frame of the verb \"observe\" contains 11 SemLink instances, and eight out of them belong to the class SAY-37.7, which is the majority class among these 11 instances.", "labels": [], "entities": [{"text": "purity (PU)", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9355192929506302}]}, {"text": "PU is calculated by summing up such counts overall the frames of this verb.", "labels": [], "entities": [{"text": "PU", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.989409327507019}]}, {"text": "Usually, inverse purity or collocation is used to measure the recall of normal clustering tasks.", "labels": [], "entities": [{"text": "inverse purity", "start_pos": 9, "end_pos": 23, "type": "METRIC", "confidence": 0.9314491748809814}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9977633953094482}]}, {"text": "However, these recall measures do not fit our task.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9990956783294678}]}, {"text": "This is because it is not areal error to have similar separate frames.", "labels": [], "entities": []}, {"text": "Instead, we want to avoid having so many frames that we cannot provide broadcoverage selectional preferences due to sparsity.", "labels": [], "entities": []}, {"text": "To judge this aspect, we measure coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9959457516670227}]}, {"text": "The coverage (CO) measures to what extent predicate-argument structures of the target verb in a test set are included in one of frames of the verb.", "labels": [], "entities": [{"text": "coverage (CO)", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9625835865736008}]}, {"text": "We use the predicate-argument structures of the above 157 verbs from the SemLink corpus, which are the same ones used in the evaluation of PU.", "labels": [], "entities": [{"text": "SemLink corpus", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.7948163449764252}, {"text": "PU", "start_pos": 139, "end_pos": 141, "type": "DATASET", "confidence": 0.6250302195549011}]}, {"text": "We judge a predicate-argument structure as correct if all of its argument words (of the target slot described in Section 3.1) are included in the corresponding slot of a frame.", "labels": [], "entities": []}, {"text": "If the clustering gets better, the value of CO will get higher, because merging instances by clustering alleviates data sparsity.", "labels": [], "entities": [{"text": "CO", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9987924098968506}]}, {"text": "These per-verb scores are aggregated into an overall score by averaging overall verbs.", "labels": [], "entities": []}, {"text": "We use two ways of averaging: a macro average and a micro average.", "labels": [], "entities": []}, {"text": "The macro average is a simple average of scores for individual verbs.", "labels": [], "entities": []}, {"text": "The micro average is obtained by weighting the scores for individual verbs proportional to the number of instances for that verb.", "labels": [], "entities": [{"text": "micro average", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9340802133083344}]}, {"text": "Finally, we use the harmonic mean (F 1 ) of purity and coverage as a single measure of clustering quality.", "labels": [], "entities": [{"text": "harmonic mean (F 1 )", "start_pos": 20, "end_pos": 40, "type": "METRIC", "confidence": 0.8364721238613129}, {"text": "purity", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9282302260398865}, {"text": "coverage", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9918628931045532}]}, {"text": "For comparison, we adopt the following two baseline methods: One frame a frame into which all the instances fora verb are merged Initial frames the initial frames without clustering (described in Section 3.2) list evaluation results for semantic frames induced from the web corpus and the Gigaword corpus, respectively.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 289, "end_pos": 304, "type": "DATASET", "confidence": 0.9001002609729767}]}, {"text": "Note that CO does not consider gold-standard classes, and thus the values of CO are the same for the VerbNet and PropBank evaluations.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9229859113693237}]}, {"text": "The induced frames outperformed the two baseline methods in terms of F 1 inmost cases.", "labels": [], "entities": [{"text": "F 1", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.972891092300415}]}, {"text": "While the coverage of the web frames was higher than that of the Gigaword frames, as expected, the purity of the web frames was slightly lower than that of the Gigaword frames.", "labels": [], "entities": [{"text": "Gigaword frames", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.924017608165741}, {"text": "purity", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9959685802459717}, {"text": "Gigaword frames", "start_pos": 160, "end_pos": 175, "type": "DATASET", "confidence": 0.9174155592918396}]}, {"text": "This degradation might be caused by the noise in the web corpus.", "labels": [], "entities": []}, {"text": "The purity of the initial frames was around 98%-99%, which means that there were few cases that the one-sense-per-collocation assumption was violated.", "labels": [], "entities": [{"text": "purity", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9915665984153748}]}, {"text": "Modi et al. reported a purity of 77.9% for the assignment of FrameNet frames to the FrameNet corpus.", "labels": [], "entities": [{"text": "FrameNet corpus", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.9249752461910248}]}, {"text": "We also conducted the above purity evaluation against FrameNet frames for 140 verbs.", "labels": [], "entities": [{"text": "FrameNet frames", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8981166481971741}]}, {"text": "We obtained a macro average of 92.9% and a micro average of 89.2% for the web frames, and a macro average of 93.2% and a micro average of 89.8% for the Gigaword frames.", "labels": [], "entities": [{"text": "Gigaword frames", "start_pos": 152, "end_pos": 167, "type": "DATASET", "confidence": 0.9346543252468109}]}, {"text": "It is difficult to directly compare these results with, but our frame assignments seem to have higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9986128807067871}]}, {"text": "Corpus Pattern Analysis (CPA) is a technique for linking word usage to prototypical syntagmatic patterns.", "labels": [], "entities": [{"text": "Corpus Pattern Analysis (CPA)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8189243127902349}]}, {"text": "The resource was built manually by investigating examples in the BNC, and the set of corpus examples used to induce each pattern is given.", "labels": [], "entities": [{"text": "BNC", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9365865588188171}]}, {"text": "For example, the following three patterns describe the usage of the verb \"accommodate.\"", "labels": [], "entities": []}, {"text": "[Human 1] accommodate [Building] accommodate [Human] accommodate to In this paper, we use CPA to evaluate the quality of the automatically induced frames.", "labels": [], "entities": []}, {"text": "By comparing the induced frames to CPA patterns, we can evaluate the correctness and relevance of this approach from a human point of view.", "labels": [], "entities": [{"text": "correctness", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.9559162855148315}]}, {"text": "To do that, we associate semantic features to the set of words in each slot in the frames, using SUMO: CPA Evaluation.", "labels": [], "entities": []}, {"text": "Using SUMO, we map this frame to the following: nsubj: dobj:, which corresponds to pattern 3 for \"accomplish\" in CPA.", "labels": [], "entities": []}, {"text": "We also associate SUMO attributes to the CPA patterns with more than 10 examples (716 verbs).", "labels": [], "entities": []}, {"text": "There are many patterns of SUMO attributes for any CPA frame or induced frame, since each filler word in a particular slot can have more than one SUMO attribute.", "labels": [], "entities": []}, {"text": "We filter out the non-discriminative SUMO attributes following the technique described in.", "labels": [], "entities": []}, {"text": "Using this, we obtain SUMO attributes for both CPA clusters and induced frames, and we can use the standard entropy-based measures to evaluate the match between the two types of patterns: E -entropy, RC -recovery rate, and P -purity (): where m j is the number of induced frames corresponding to topic j, m ij is the number of induced frames in cluster j and annotated with the CPA pattern i, m is the total number of induced frames, L is the number of CPA patterns, and K is the number of induced frames.", "labels": [], "entities": [{"text": "RC -recovery rate", "start_pos": 200, "end_pos": 217, "type": "METRIC", "confidence": 0.8874998986721039}, {"text": "P -purity", "start_pos": 223, "end_pos": 232, "type": "METRIC", "confidence": 0.9109254479408264}]}, {"text": "We also consider a K-means clustering process, with K set as 2 or 3 depending on the number of SUMO-attributed patterns.", "labels": [], "entities": []}, {"text": "The K-means evaluation is carried out considering only the centroid of the cluster, which corresponds to the prototypical induced semantic frame with SUMO attributes.", "labels": [], "entities": []}, {"text": "We compute E, RC and P using formulae (5) -(7) for each verb and then compute the macro average, considering all the frames and only the Kmeans centroids, respectively.", "labels": [], "entities": []}, {"text": "The results for the induced web frames are displayed in.", "labels": [], "entities": []}, {"text": "The evaluation method presented here overcomes some of the drawbacks of the previous approaches.", "labels": [], "entities": []}, {"text": "First, we did not limit the evaluation to the most frequent patterns.", "labels": [], "entities": []}, {"text": "Second, the mapping was carried out automatically and not by hand.", "labels": [], "entities": [{"text": "mapping", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.9854215383529663}]}, {"text": "The results above compare favorably with the previous approaches, especially considering that no filtering procedures were applied to the induced frames.", "labels": [], "entities": []}, {"text": "We anticipate that the results based on the prototypical induced frames with SUMO attributes would be competitive.", "labels": [], "entities": []}, {"text": "Our post-analysis revealed that the entropy can be lowered further if an automatic filtering based on frequencies is applied.", "labels": [], "entities": []}, {"text": "We also investigated the quality of selectional preferences within the induced semantic frames.", "labels": [], "entities": []}, {"text": "The only publicly available test data for selectional preferences, to our knowledge, is from Chambers and Jurafsky.", "labels": [], "entities": []}, {"text": "This data consists of quadruples (verb, relation, word, confounder) and does not contain their context.", "labels": [], "entities": []}, {"text": "A typical way for using our semantic frames is to select an appropriate frame for an input sentence and judge the eligibility of the word uses against the selected frame.", "labels": [], "entities": []}, {"text": "However, due to the lack of context for the above data, it is difficult to select a corresponding semantic frame fora test quadruple and thus the induced semantic frames cannot be naturally applied to this data.", "labels": [], "entities": []}, {"text": "To investigate the potential for selectional preferences of the semantic frames, we approximately match a quadruple with each of the semantic frames of the verb and select the frame that has the highest probability as follows: where w is the word or confounder, v is the verb, rel is the relation and f i is a semantic frame.", "labels": [], "entities": []}, {"text": "By comparing the probabilities of the word and the confounder, we select either of them according to the higher probability.", "labels": [], "entities": []}, {"text": "For tie breaking in the case that no frames are found for the verb or both the word and confounder are not found in the case slot, we randomly select either of them in the same way as.", "labels": [], "entities": [{"text": "tie breaking", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.7567342519760132}]}, {"text": "We use the \"neighbor frequency\" set, which is the most difficult among the three sets included in the data.", "labels": [], "entities": []}, {"text": "It contains 6,767 quadruples and the relations consist of three classes: subject, object and preposition, which has no distinction of actual prepositions.", "labels": [], "entities": []}, {"text": "To link these relations with our case slots, we manually aligned the subject with the nsubj (nominal subject) slot, the object with the dobj (direct object) slot and the preposition with prep * (all the prepositions) slots.", "labels": [], "entities": []}, {"text": "For the preposition relation, we choose the highest probability among all the preposition slots in a frame.", "labels": [], "entities": []}, {"text": "To match the generalized \u27e8name\u27e9 with the word in a quadruple, we change the word to \u27e8name\u27e9 if it is capitalized and not a capitalized personal pronoun.", "labels": [], "entities": []}, {"text": "Our semantic frames from the Gigaword corpus achieved an accuracy of 81.7% 8 and those from the web corpus achieved an accuracy of 80.2%.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.9306990802288055}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9994519352912903}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9991581439971924}]}, {"text": "This slight deterioration seems to come from the noise in the web corpus.", "labels": [], "entities": []}, {"text": "The best performance in Chambers and Jurafsky is 81.7% on this \"neighbor frequency\" set, which was achieved by conditional probabilities with the Erk (2007)'s smoothing method calculated from the English Gigaword corpus.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 196, "end_pos": 219, "type": "DATASET", "confidence": 0.9000222086906433}]}, {"text": "Our approach for selectional preferences does not use smoothing like, but it achieved equivalent performance to the previous work.", "labels": [], "entities": []}, {"text": "If we applied our semantic frames to a verb instance with its context, a more precise judgment of selectional preferences would be possible with appropriate frame selection.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Evaluation results of semantic frames from the web corpus against VerbNet classes and Prop- Bank frames. \"Mac\" means a macro average and \"Mic\" means a micro average.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results of semantic frames from the Gigaword corpus against VerbNet classes and  PropBank frames. \"Mac\" means a macro average and \"Mic\" means a micro average.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.8485352694988251}]}]}