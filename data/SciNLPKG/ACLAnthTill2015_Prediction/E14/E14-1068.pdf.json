{"title": [{"text": "Discovering Implicit Discourse Relations Through Brown Cluster Pair Representation and Coreference Patterns", "labels": [], "entities": [{"text": "Discovering Implicit Discourse Relations", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7903588563203812}]}], "abstractContent": [{"text": "Sentences form coherent relations in a discourse without discourse connectives more frequently than with connectives.", "labels": [], "entities": []}, {"text": "Senses of these implicit discourse relations that hold between a sentence pair, however, are challenging to infer.", "labels": [], "entities": []}, {"text": "Here, we employ Brown cluster pairs to represent discourse relation and incorporate coreference patterns to identify senses of implicit discourse relations in naturally occurring text.", "labels": [], "entities": []}, {"text": "Our system improves the baseline performance by as much as 25%.", "labels": [], "entities": []}, {"text": "Feature analyses suggest that Brown cluster pairs and coreference patterns can reveal many key linguistic characteristics of each type of discourse relation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentences must be pieced together logically in a discourse to form coherent text.", "labels": [], "entities": []}, {"text": "Many discourse relations in the text are signaled explicitly through a closed set of discourse connectives.", "labels": [], "entities": []}, {"text": "Simply disambiguating the meaning of discourse connectives can determine whether adjacent clauses are temporally or causally related.", "labels": [], "entities": []}, {"text": "Discourse relations and their senses, however, can also be inferred by the reader even without discourse connectives.", "labels": [], "entities": []}, {"text": "These implicit discourse relations in fact outnumber explicit discourse relations in naturally occurring text.", "labels": [], "entities": []}, {"text": "Inferring types or senses of implicit discourse relations remains a key challenge in automatic discourse analysis.", "labels": [], "entities": [{"text": "automatic discourse analysis", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.6809748411178589}]}, {"text": "A discourse parser requires many subcomponents which form along pipeline.", "labels": [], "entities": []}, {"text": "The implicit discourse relation discovery has been shown to be the main performance bottleneck of an end-to-end parser (.", "labels": [], "entities": [{"text": "implicit discourse relation discovery", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.5705735087394714}]}, {"text": "It is also central to many applications such as automatic summarization and question-answering systems.", "labels": [], "entities": [{"text": "summarization", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.6460888981819153}]}, {"text": "Existing systems, which make heavy use of word pairs, suffer from data sparsity problem as a word pair in the training data may not appear in the test data.", "labels": [], "entities": []}, {"text": "A better representation of two adjacent sentences beyond word pairs could have a significant impact on predicting the sense of the discourse relation that holds between them.", "labels": [], "entities": []}, {"text": "Data-driven theory-independent word classification such as Brown clustering should be able to provide a more compact word representation.", "labels": [], "entities": [{"text": "Data-driven theory-independent word classification", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.5518538728356361}]}, {"text": "Brown clustering algorithm induces a hierarchy of words in a large unannotated corpus based on word co-occurrences within the window.", "labels": [], "entities": []}, {"text": "The induced hierarchy might give rise to features that we would otherwise miss.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use the cartesian product of Brown cluster assignment of the sentence pair as an alternative abstract word representation for building an implicit discourse relation classifier.", "labels": [], "entities": []}, {"text": "Through word-level semantic commonalities revealed by Brown clusters and entity-level relations revealed by coreference resolution, we might be able to paint a more complete picture of the discourse relation in question.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.9126876890659332}]}, {"text": "Coreference resolution unveils the patterns of entity realization within the discourse, which might provide clues for the types of the discourse relations.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8741297125816345}]}, {"text": "The information about certain entities or mentions in one sentence should be carried over to the next sentence to form a coherent relation.", "labels": [], "entities": []}, {"text": "It is possible that coreference chains and semantically-related predicates in the local context might show some patterns that characterize types of discourse relations.", "labels": [], "entities": []}, {"text": "We hypothesize that coreferential rates and coreference patterns created by Brown clusters should help characterize different types of discourse relations.", "labels": [], "entities": []}, {"text": "Here, we introduce two novel sets of features for implicit discourse relation classification.", "labels": [], "entities": [{"text": "implicit discourse relation classification", "start_pos": 50, "end_pos": 92, "type": "TASK", "confidence": 0.6206304505467415}]}, {"text": "We also study coreferential patterns in different types of discourse relations in addition to using them to boost the performance of our classifier.", "labels": [], "entities": []}, {"text": "These two sets of features along with previously used features outperform the baseline systems by approximately 5% absolute across all categories and reveal many important characteristics of implicit discourse relations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We followed the setup of the previous studies fora fair comparison with the two baseline systems by and.", "labels": [], "entities": []}, {"text": "The task is formulated as four separate one-against-all binary classification problems: one for each top level sense of implicit discourse relations.", "labels": [], "entities": []}, {"text": "In addition, we add one more classification task with which to test the system.", "labels": [], "entities": []}, {"text": "We merge ENTREL with EXPANSION relations to follow the setup used by the two baseline systems.", "labels": [], "entities": [{"text": "ENTREL", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.996810257434845}]}, {"text": "An argument pair is annotated with ENTREL in PDTB if an entity-based coherence and no other type of relation can be identified between the two arguments in the pair.", "labels": [], "entities": [{"text": "ENTREL", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9972584247589111}, {"text": "PDTB", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.9367482662200928}]}, {"text": "In this study, we assume that the gold standard argument pairs are provided for each relation.", "labels": [], "entities": []}, {"text": "Most argument pairs for implicit discourse relations area pair of adjacent sentences or adjacent clauses separated by a semicolon and should be easily extracted.", "labels": [], "entities": []}, {"text": "The PDTB corpus is split into a training set, development set, and test set the same way as in the baseline systems.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8934948444366455}]}, {"text": "Sections 2 to 20 are used to train classifiers.", "labels": [], "entities": []}, {"text": "Sections 0-1 are used for developing feature sets and tuning models.", "labels": [], "entities": []}, {"text": "Section 21-22 are used for testing the systems.", "labels": [], "entities": []}, {"text": "The statistical models in the following experiments are from MALLET implementation) and libSVM ().", "labels": [], "entities": [{"text": "MALLET implementation", "start_pos": 61, "end_pos": 82, "type": "DATASET", "confidence": 0.718193382024765}]}, {"text": "For all five binary classification tasks, we try Balanced Winnow, Maximum Entropy, Naive Bayes, and Support Vector Machine.", "labels": [], "entities": []}, {"text": "The parameters and the hyperparameters of each classifier are set to their default values.", "labels": [], "entities": []}, {"text": "The code for our model along with the data matrices is available at github.com/attapol/ brown_coref_implicit.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Our classifier outperform the previous systems across all four tasks without the use of gold- standard parses and coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.8765594959259033}]}, {"text": " Table 3: Ablation study: The four most impact- ful feature classes and their relative percentage  changes are shown. Brown cluster pair features  are the most impactful across all relation types.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.988885760307312}]}]}