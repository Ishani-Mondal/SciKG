{"title": [{"text": "Distributional Lexical Entailment by Topic Coherence", "labels": [], "entities": [{"text": "Distributional Lexical Entailment", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.9254840413729349}]}], "abstractContent": [{"text": "Automatic detection of lexical entailment, or hypernym detection, is an important NLP task.", "labels": [], "entities": [{"text": "Automatic detection of lexical entailment", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7772631466388702}, {"text": "hypernym detection", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.68623848259449}]}, {"text": "Recent hypernym detection measures have been based on the Distri-butional Inclusion Hypothesis (DIH).", "labels": [], "entities": [{"text": "hypernym detection", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.8364509344100952}]}, {"text": "This paper assumes that the DIH sometimes fails, and investigates other ways of quantifying the relationship between the co-occurrence contexts of two terms.", "labels": [], "entities": []}, {"text": "We consider the top features in a context vector as a topic, and introduce anew entailment detection measure based on Topic Coherence (TC).", "labels": [], "entities": []}, {"text": "Our measure successfully detects hypernyms, and a TC-based family of measures contributes to multi-way relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.7227142751216888}]}], "introductionContent": [{"text": "Automatically detecting lexical entailment -for example, that lion entails animal or guitar entails instrument, also known as hypernym detectionis an important linguistic task in its own right, and is also a prerequisite for recognizing entailments between longer text segments such as phrases or sentences.", "labels": [], "entities": [{"text": "Automatically detecting lexical entailment", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7950146570801735}, {"text": "hypernym detectionis", "start_pos": 126, "end_pos": 146, "type": "TASK", "confidence": 0.6867539435625076}, {"text": "recognizing entailments between longer text segments such as phrases or sentences", "start_pos": 225, "end_pos": 306, "type": "TASK", "confidence": 0.8278669389811429}]}, {"text": "Several recent techniques for hypernym detection have made use of distributional semantics ().", "labels": [], "entities": [{"text": "hypernym detection", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9020164906978607}]}, {"text": "These techniques are based on the Distributional Inclusion Hypothesis, hereafter DIH, which proposes that if term A entails term B (B is a hypernym of A), then the contexts in which A occurs area subset of those in which B occurs.", "labels": [], "entities": []}, {"text": "For example, all the contexts (co-occurrences) of lion -which might include zoo, hunt, wild, food, etc.", "labels": [], "entities": []}, {"text": "-are also contexts of animal.", "labels": [], "entities": []}, {"text": "Existing measures look at the amount of overlap between the co-occurrences of A and B, in order to judge whether B is a hypernym of A.", "labels": [], "entities": []}, {"text": "The motivation for the present paper is the wellknown fact that the DIH is not fully correct.", "labels": [], "entities": [{"text": "DIH", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.9251552224159241}]}, {"text": "There are many reasons why a hyponym might occur in contexts where its hypernym does not.", "labels": [], "entities": []}, {"text": "Some contexts are collocational, e.g. lion king.", "labels": [], "entities": []}, {"text": "Other contexts are highly specific, e.g. mane applies uniquely to lions, horses, and zebras; it would be unusual to see text about animals with manes.", "labels": [], "entities": []}, {"text": "The need to be informative is also relevant: lion cub will occur much more frequently than animal cub, since animal is of the wrong level of generality to pair with cub.", "labels": [], "entities": []}, {"text": "Moreover, the more general a hypernym becomes -up to the level of WordNet root elements, such as entity -its predominant sense ceases to correspond to the sense intended in hyponymhypernym chains.", "labels": [], "entities": []}, {"text": "Thus we never hear about going to visit an entity at the zoo.", "labels": [], "entities": []}, {"text": "This paper starts from the assumption that the DIH sometimes fails, and investigates not the amount of containment of A's features in B's features, but rather the nature of the non-contained features.", "labels": [], "entities": [{"text": "DIH", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.5910694003105164}]}, {"text": "We consider the top features of a distributional vector as a topic, and use recent measures for automatically measuring Topic Coherence () to evaluate how the topics change under various conditions.", "labels": [], "entities": []}, {"text": "Using a notion of vector negation, we investigate whether the distributional topic of e.g. lion becomes more or less coherent when we subtract the contexts of animal.", "labels": [], "entities": []}, {"text": "We introduce anew measure, Ratio of Change in Topic Coherence (RCTC), for detecting lexical entailment.", "labels": [], "entities": [{"text": "Ratio of Change in Topic Coherence (RCTC)", "start_pos": 27, "end_pos": 68, "type": "METRIC", "confidence": 0.8183245791329278}, {"text": "detecting lexical entailment", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.8885690768559774}]}, {"text": "The measure detects hypernyms with reasonable accuracy, and a family of Topic Coherence measures is used to perform a multi-way classification of tuples by relation class.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9984169006347656}]}, {"text": "Finally, we investigate how the level of generality of a hypernym affects entailment measures.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used a subset of the BLESS dataset () as defined by.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 24, "end_pos": 37, "type": "DATASET", "confidence": 0.9511010944843292}]}, {"text": "The entire dataset consists of 200 concrete nouns in 17 broad noun classes (e.g. clothing, amphibian/reptile, vegetable, container), participating in a variety of relations.", "labels": [], "entities": []}, {"text": "The subset contains the relation classes hypernym (HYPER), coordinate (COORD, i.e. co-hyponym), meronym (MERO, i.e. part-of), and random-noun (RAND-N, an unrelated noun).", "labels": [], "entities": [{"text": "COORD", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.5671955943107605}, {"text": "MERO", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.7070947289466858}]}, {"text": "It consists of 14,547 tuples in total.", "labels": [], "entities": []}, {"text": "gives an example of each relation class, along with the total number of tuples per class in the development data.", "labels": [], "entities": []}, {"text": "Since there was no pre-defined developmenttest split for the BLESS subset, we randomly selected half of the data for development.", "labels": [], "entities": [{"text": "BLESS", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.8894723057746887}]}, {"text": "For each of the 17 broad noun classes, we randomly chose half of the target nouns, and included all their HY-PER, COORD, MERO, and RAND-N tuples.", "labels": [], "entities": [{"text": "HY-PER", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9729588627815247}, {"text": "COORD", "start_pos": 114, "end_pos": 119, "type": "METRIC", "confidence": 0.925319492816925}, {"text": "MERO", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9684233665466309}, {"text": "RAND-N", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.7905775308609009}]}, {"text": "This resulted in a development set consisting of 96 target nouns and 7,053 tuples; and a test set consisting of 104 nouns and 7,494 tuples.", "labels": [], "entities": []}, {"text": "We first look at the effect of N (topic size) and negation type on RCTC on the development data).", "labels": [], "entities": [{"text": "RCTC", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.8712539076805115}]}, {"text": "It is clear that RCTC distinguishes relation types using Strict but not Widdows negation.", "labels": [], "entities": [{"text": "RCTC", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.7392640709877014}]}, {"text": "We believe this is because, as the \"harsher\" version of negation, it allows less-related features to rise to the top of the topic and reveal greater differences in topic coherence.", "labels": [], "entities": []}, {"text": "N=10 was the only  value that ranked hypernyms the highest; we use N=10 for the remaining experiments.", "labels": [], "entities": []}, {"text": "We then proceed to hypernym identification on the full dataset).", "labels": [], "entities": [{"text": "hypernym identification", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.7269612848758698}]}, {"text": "All measures we tested assigned the highest average value to hypernyms (in bold) compared to the other relations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Average Topic Coherence measures on the development set, using N=10, Strict negation.", "labels": [], "entities": []}, {"text": " Table 3: Average similarity and generality mea- sures on the dev. set, using N=10, Strict negation.", "labels": [], "entities": [{"text": "similarity", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.539076566696167}, {"text": "mea- sures", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.8654803236325582}]}, {"text": " Table 5: RCTC with varying N and neg type.", "labels": [], "entities": [{"text": "RCTC", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.9369984865188599}]}, {"text": " Table 6: Hypernym identification on full dataset:  average value by relation.", "labels": [], "entities": [{"text": "Hypernym identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8348856270313263}]}, {"text": " Table 7: Ranking results. Bold indicates best result for hypernyms by evaluation measure.", "labels": [], "entities": []}, {"text": " Table 9: Classification results on development  data using 10-fold cross-validation.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9439794421195984}]}, {"text": " Table 10: Classification results on test data using  development data as training.", "labels": [], "entities": [{"text": "Classification", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.9610906839370728}]}, {"text": " Table 11: Average value by depth D of hypernym.", "labels": [], "entities": []}]}