{"title": [{"text": "Type-Supervised Domain Adaptation for Joint Segmentation and POS-Tagging", "labels": [], "entities": [{"text": "Joint Segmentation", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7964066863059998}, {"text": "POS-Tagging", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.44695767760276794}]}], "abstractContent": [{"text": "We report an empirical investigation on type-supervised domain adaptation for joint Chinese word segmentation and POS-tagging, making use of domain-specific tag dictionaries and only un-labeled target domain data to improve target-domain accuracies, given a set of annotated source domain sentences.", "labels": [], "entities": [{"text": "type-supervised domain adaptation", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.627057413260142}, {"text": "joint Chinese word segmentation", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.6278768256306648}]}, {"text": "Previous work on POS-tagging of other languages showed that type-supervision can be a competitive alternative to token-supervision, while semi-supervised techniques such as label propagation are important to the effectiveness of type-supervision.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 173, "end_pos": 190, "type": "TASK", "confidence": 0.7415560334920883}]}, {"text": "We report similar findings using a novel approach for joint Chinese segmentation and POS-tagging, under a cross-domain setting.", "labels": [], "entities": [{"text": "joint Chinese segmentation", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.4355693757534027}]}, {"text": "With the help of un-labeled sentences and a lexicon of 3,000 words, we obtain 33% error reduction in target-domain tagging.", "labels": [], "entities": [{"text": "error", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.97539222240448}]}, {"text": "In addition, combined type-and token-supervision can lead to improved cost-effectiveness.", "labels": [], "entities": []}], "introductionContent": [{"text": "With accuracies of over 97%, POS-tagging of WSJ can be treated as a solved problem).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 5, "end_pos": 15, "type": "METRIC", "confidence": 0.9923568964004517}, {"text": "WSJ", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.7574465870857239}]}, {"text": "However, performance is still well below satisfactory for many other languages and domains.", "labels": [], "entities": []}, {"text": "There has been a line of research on using a tag-dictionary for POS-tagging).", "labels": [], "entities": []}, {"text": "The idea is compelling: on the one hand, a list of lexicons is often available for special domains, such as bio-informatics; on the other hand, compiling a * Corresponding author.", "labels": [], "entities": []}, {"text": "lexicon of word-tag pairs appears to be less timeconsuming than annotating full sentences.", "labels": [], "entities": []}, {"text": "However, success in type-supervised POStagging turns out to depend on several subtle factors.", "labels": [], "entities": []}, {"text": "For example, recent research has found that the quality of the tag-dictionary is crucial to the success of such methods ().", "labels": [], "entities": []}, {"text": "found that the accuracies can drop from 96% to 77% when a hand-crafted tag dictionary is replaced with a raw tag dictionary gleaned from data, without any human intervention.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9986302852630615}]}, {"text": "These facts indicate that careful considerations need to be given for effective typesupervision.", "labels": [], "entities": []}, {"text": "In addition, significant manual work might be required to ensure the quality of lexicons.", "labels": [], "entities": []}, {"text": "To compare type-and token-supervised tagging,  performed a set of experiments by conducting each type of annotation for two hours.", "labels": [], "entities": [{"text": "type-and token-supervised tagging", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.5324691534042358}]}, {"text": "They showed that for lowresource languages, a tag-dictionary can be reasonably effective if label propagation and model minimizations) are applied to expand and filter the lexicons.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.705636277794838}]}, {"text": "Similar findings were reported in . Do the above findings carryover to the Chinese language?", "labels": [], "entities": []}, {"text": "In this paper, we perform an empirical study on the effects of tag-dictionaries for domain adaptation of Chinese POS-tagging.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.6955026537179947}]}, {"text": "We aim to answer the following research questions: (a) Is domain adaptation feasible with only a target-domain lexicon?", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7662251889705658}]}, {"text": "(b) Can we further improve type-supervised domain adaptation using unlabeled target-domain sentences?", "labels": [], "entities": [{"text": "type-supervised domain adaptation", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.644012987613678}]}, {"text": "(c) Is crafting a tag dictionary for domain adaptation more effective than manually annotating target domain sentences, given similar efforts?", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7623108625411987}]}, {"text": "Our investigations are performed under two Chinese-specific settings.", "labels": [], "entities": []}, {"text": "First, unlike lowresource languages, large amounts of annotation are available for Chinese.", "labels": [], "entities": []}, {"text": "For example, the Chinese Treebank (CTB) () contains over 50,000 manually tagged news sentences.", "labels": [], "entities": [{"text": "Chinese Treebank (CTB)", "start_pos": 17, "end_pos": 39, "type": "DATASET", "confidence": 0.9693975567817688}]}, {"text": "Hence rather than studying purely type-supervised POS-tagging, we make use of CTB as the source domain, and study domain adaptation to the Internet literature.", "labels": [], "entities": [{"text": "CTB", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.9043509364128113}, {"text": "domain adaptation", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7307189702987671}]}, {"text": "Second, one uniqueness of Chinese POStagging, in contrast to the POS-tagging of alphabetical languages, is that word segmentation can be performed jointly to avoid error propagation ().", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.7093827724456787}]}, {"text": "We adopt this approach fora strong baseline.", "labels": [], "entities": []}, {"text": "Previous studies showed that unsupervised domain adaptation can give moderate improvements (.", "labels": [], "entities": []}, {"text": "We show that accuracies can be much more significantly improved by using targetdomain knowledge in the form of lexicons.", "labels": [], "entities": []}, {"text": "Both token-supervised and type-supervised domain adaptation rely on a set of source-domain annotations; while the former makes additional use of a small set of target annotations, the latter leverages a target-domain lexicon.", "labels": [], "entities": [{"text": "type-supervised domain adaptation", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.6709428131580353}]}, {"text": "We take a feature-based method, analogous to that of Daume III, which tunes domain-dependent versions of features using domain-specific data.", "labels": [], "entities": [{"text": "Daume III", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.9309959411621094}]}, {"text": "Our method tunes a set of lexicon-based features, so that domain-dependent models are derived from inserting domain-specific lexicons.", "labels": [], "entities": []}, {"text": "The conceptually simple method worked highly effectively on a test set of 1,394 sentences from the Internet novel \"Zhuxian\".", "labels": [], "entities": [{"text": "test set of 1,394 sentences from the Internet novel \"Zhuxian\"", "start_pos": 62, "end_pos": 123, "type": "DATASET", "confidence": 0.7895605365435282}]}, {"text": "Combined with the use of unlabeled data, a tag lexicon of 3,000 words gave a 33% error reduction when compared with a strong baseline system trained using CTB data.", "labels": [], "entities": [{"text": "error", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.9874268770217896}, {"text": "CTB data", "start_pos": 155, "end_pos": 163, "type": "DATASET", "confidence": 0.9068075120449066}]}, {"text": "We observe that joint use of type-and token-supervised domain adaptation is more costeffective than pure type-or token-supervision.", "labels": [], "entities": [{"text": "type-and token-supervised domain adaptation", "start_pos": 29, "end_pos": 72, "type": "TASK", "confidence": 0.5686939209699631}]}, {"text": "With 10 hours of annotation, the best error reduction reaches 47%, with F-score increasing from 80.81% to 89.84%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 38, "end_pos": 53, "type": "METRIC", "confidence": 0.9636720418930054}, {"text": "F-score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9997155070304871}]}], "datasetContent": [{"text": "In this section, we study type-supervised domain adaptation by conducting a series of experiments on the development data, addressing the following questions.", "labels": [], "entities": [{"text": "type-supervised domain adaptation", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.6090601086616516}]}, {"text": "First, what is the influence of tagdictionaries through lexicon-based features?", "labels": [], "entities": []}, {"text": "Second, what is the effect of type-supervised domain adaptation in contrast to token-supervised domain adaptation under the same annotation cost?", "labels": [], "entities": []}, {"text": "Third, what is the interaction between tag-dictionary and self-training?", "labels": [], "entities": []}, {"text": "Finally, what is the combined effect of type-and token-supervised domain adaptation?", "labels": [], "entities": [{"text": "type-and token-supervised domain adaptation", "start_pos": 40, "end_pos": 83, "type": "TASK", "confidence": 0.572900801897049}]}], "tableCaptions": [{"text": " Table 2: Example sentences from CTB and ZX to illustrate the differences between news and novel.", "labels": [], "entities": [{"text": "CTB", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.961243212223053}]}, {"text": " Table 4: Development test results, where Cost denotes the cost of type-or token-annotation measured  by person hours, ER denotes the error reductions of overall performances brought by self-training, T  denotes type-annotation and S denotes token-annotation.", "labels": [], "entities": [{"text": "Cost", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9964231848716736}, {"text": "ER", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9730513095855713}]}, {"text": " Table 5: Final results on test set within ten per- son hours' annotation, where ER denotes the over- all error reductions compared with the baseline  model, Time denotes the cost of type-or token- annotation measured by person hours, T denotes  type-annotation and S denotes token-annotation.", "labels": [], "entities": [{"text": "ER", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9949514865875244}, {"text": "over- all error reductions", "start_pos": 96, "end_pos": 122, "type": "METRIC", "confidence": 0.658303564786911}]}]}