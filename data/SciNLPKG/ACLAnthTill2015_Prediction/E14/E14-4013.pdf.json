{"title": [], "abstractContent": [{"text": "We train and evaluate two models for Ro-manian stress prediction: a baseline model which employs the consonant-vowel structure of the words and a cascaded model with averaged perceptron training consisting of two sequential models-one for predicting syllable boundaries and another one for predicting stress placement.", "labels": [], "entities": [{"text": "Ro-manian stress prediction", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.8346548676490784}, {"text": "predicting stress placement", "start_pos": 290, "end_pos": 317, "type": "TASK", "confidence": 0.8960403601328532}]}, {"text": "We show in this paper that Romanian stress is predictable, though not deterministic, by using data-driven machine learning techniques .", "labels": [], "entities": []}], "introductionContent": [{"text": "Romanian is a highly inflected language with a rich morphology.", "labels": [], "entities": []}, {"text": "As dictionaries usually fail to cover the pronunciation aspects for all word forms in languages with such a rich and irregular morphology (), we believe that a data-driven approach is very suitable for syllabication and stress prediction for Romanian words.", "labels": [], "entities": [{"text": "stress prediction", "start_pos": 220, "end_pos": 237, "type": "TASK", "confidence": 0.7277793288230896}]}, {"text": "Moreover, such a system proves extremely useful for inferring syllabication and stress placement for out-of-vocabulary words, for instance neologisms or words which recently entered the language.", "labels": [], "entities": []}, {"text": "Even if they are closely related, Romanian stress and syllabication were unevenly studied in the computational linguistic literature, i.e., the Romanian syllable received much more attention than the Romanian stress (.", "labels": [], "entities": []}, {"text": "One possible explanation for the fact that Romanian syllabication was more intensively studied than Romanian stress is the immediate application of syllabication to text editors which need reliable hyphenation.", "labels": [], "entities": []}, {"text": "Another explanation could be that most linguists (most recently) insisted that Romanian stress is not predictable, thus discouraging attempts to investigate any systematic patterns.", "labels": [], "entities": []}, {"text": "Romanian is indeed a challenging case study, because of the obvious complexities of the data with respect to stress assignment.", "labels": [], "entities": [{"text": "stress assignment", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.6972508579492569}]}, {"text": "At first sight, no obvious patterns emerge for learning stress placement, other than as part of individual lexical items.", "labels": [], "entities": [{"text": "learning stress placement", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.6942852735519409}]}, {"text": "The first author who challenges this view is, who argues in favor of the predictability of the Romanian stress system.", "labels": [], "entities": []}, {"text": "She states that stress placement strongly depends on the morphology of the language, more precisely on the distribution of the lexical items based on their part of speech.", "labels": [], "entities": [{"text": "stress placement", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7049240469932556}]}, {"text": "Thus, considering this type of information, lexical items can be clustered in a limited number of regular subpatterns and the unpredictability of stress placement is significantly reduced.", "labels": [], "entities": []}, {"text": "A rule-based method for lexical stress prediction on Romanian was introduced by. address lexical stress prediction as a sequence tagging problem, which proves to bean accurate approach for this task.", "labels": [], "entities": [{"text": "lexical stress prediction", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.6209239065647125}, {"text": "lexical stress prediction", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.7145048975944519}, {"text": "sequence tagging", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.6657836139202118}]}, {"text": "The effectiveness of using conditional random fields for orthographic syllabication is investigated by, who employ them for determining syllable boundaries and show that they outperform previous methods.", "labels": [], "entities": []}, {"text": "use a discriminative tagger for automatic orthographic syllabication and present several approaches for assigning labels, including the language-independent Numbered NB tag scheme, which labels each letter with a value equal to the distance between the letter and the last syllable boundary.", "labels": [], "entities": []}, {"text": "According to, syllable structure and stress pattern are very useful in text-to-speech synthesis, as they provide valuable knowledge regarding the pronunciation modeling.", "labels": [], "entities": [{"text": "text-to-speech synthesis", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.7297981083393097}, {"text": "pronunciation modeling", "start_pos": 146, "end_pos": 168, "type": "TASK", "confidence": 0.7550551891326904}]}, {"text": "Besides converting the letters to the corresponding phonemes, information about syllable boundaries and stress placement is also needed for the correct synthesizing of a word in grapheme-to-phoneme conversion.", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion", "start_pos": 178, "end_pos": 208, "type": "TASK", "confidence": 0.7658761143684387}]}, {"text": "In this paper, we rely on the assumption that the stress system of Romanian is predictable.", "labels": [], "entities": []}, {"text": "We propose a system for automatic prediction of stress placement and we investigate its performance by accounting for several fine-grained characteristics of Romanian words: part of speech, number of syllables and consecutive vowels.", "labels": [], "entities": [{"text": "automatic prediction of stress placement", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.7416774988174438}]}, {"text": "We investigate the consonant-vowel structure of the words (C/V structure) and we detect a high number of stress patterns.", "labels": [], "entities": []}, {"text": "This calls for the need of machine learning techniques, in order to automatically learn such a wide range of variational patterns.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present the main results drawn from our research on Romanian stress assignment.", "labels": [], "entities": [{"text": "Romanian stress assignment", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.6905464927355448}]}, {"text": "We train and evaluate a cascaded model consisting of two sequential models trained separately, the output of the first being used as input to the second.", "labels": [], "entities": []}, {"text": "We split the dataset in two subsets: train set (on which we perform cross-validation to select optimal parameters for our model) and test set (with unseen words, on which we evaluate the performance of our system).", "labels": [], "entities": []}, {"text": "We use the same train/test sets for the two sequential models, but they are trained independently.", "labels": [], "entities": []}, {"text": "The output of the first model (used for predicting syllabication) is used for determining feature values for the second one (used for predicting stress placement) for the test set.", "labels": [], "entities": [{"text": "predicting stress placement", "start_pos": 134, "end_pos": 161, "type": "TASK", "confidence": 0.8082987864812216}]}, {"text": "The second model is trained using gold syllabication (provided in the dataset) and we report results on the test set in both versions: using gold syllabication to determine feature values For example, for CCV-CVC structure (1,390 occurrences in our dataset) there are 2 associated stress patterns: CCV-CVC (1,017 occurrences) and CCV-CVC (373 occurrences).", "labels": [], "entities": []}, {"text": "Words with 6 syllables cover the highest number of distinct C/V structures.", "labels": [], "entities": []}, {"text": "There are 31 C/V structures (ranging from 4 to 7 syllables) reaching the maximum number of distinct associated stress patterns (6). and using predicted syllabication to determine feature values.", "labels": [], "entities": []}, {"text": "The results with gold syllabication are reported only for providing an upper bound for learning and for comparison.", "labels": [], "entities": []}, {"text": "We use averaged perceptron training) from CRFsuite (.", "labels": [], "entities": []}, {"text": "For the stress prediction model we optimize hyperparameters using grid search to maximize the 3-fold cross-validation F 1 score of class 1, which marks the stressed vowels.", "labels": [], "entities": [{"text": "stress prediction", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7193139493465424}, {"text": "cross-validation F 1 score", "start_pos": 101, "end_pos": 127, "type": "METRIC", "confidence": 0.8167236149311066}]}, {"text": "We searched over {2, 3, 4} for W and over {1, 5, 10, 25, 50} for the maximum number of iterations.", "labels": [], "entities": []}, {"text": "The values which optimize the system are 4 for W and 50 for the maximum number of iterations.", "labels": [], "entities": []}, {"text": "We investigate, during grid search, whether employing C/V markers and binary positional indicators improve our system's performance.", "labels": [], "entities": []}, {"text": "It turns out that inmost cases they do.", "labels": [], "entities": []}, {"text": "For the syllabication model, the optimal hyperparameters are 4 for the window radius and 50 for the maximum number of iterations.", "labels": [], "entities": []}, {"text": "We evaluate the cross-validation F 1 score of class 0, which marks the position of a hyphen.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9500739177068075}]}, {"text": "The system obtains 0.995 instance accuracy for predicting syllable boundaries.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9485612511634827}, {"text": "predicting syllable boundaries", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.8948760231335958}]}, {"text": "We use a \"majority class\" type of baseline which employs the C/V structures described in Section 3 and assigns, fora word in the test set, the stress pattern which is most common in the training set for the C/V structure of the word, or places the stress randomly on a vowel if the C/V structure is not found in the training set 2 . The performance of both models on RoSyllabiDict dataset is reported in.", "labels": [], "entities": [{"text": "RoSyllabiDict dataset", "start_pos": 367, "end_pos": 388, "type": "DATASET", "confidence": 0.8949020802974701}]}, {"text": "We report word-level accuracy, that is, we account for words for which the stress pattern was correctly assigned.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9583739638328552}]}, {"text": "As expected, the cascaded model performs significantly better than the baseline.", "labels": [], "entities": []}, {"text": "Model Accuracy Baseline 0.637 Cascaded model 0.975 Cascaded model (predicted) 0.973: Accuracy for stress prediction Further, we perform an in-depth analysis of the sequential model's performance by accounting for several fine-grained characteristics of the words in RoSyllabiDict.", "labels": [], "entities": [{"text": "Accuracy Baseline 0.637 Cascaded model 0.975 Cascaded model", "start_pos": 6, "end_pos": 65, "type": "METRIC", "confidence": 0.9086248427629471}, {"text": "Accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9968975782394409}, {"text": "stress prediction", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7049091905355453}]}, {"text": "We divide words in categories based on the following criteria: \u2022 part of speech: verbs, nouns, adjectives \u2022 number of syllables: 2-8, 9+ \u2022 number of consecutive vowels: with at least 2 consecutive vowels, without consecutive vowels: Accuracy for cascaded model with gold (G) and predicted (P) syllabication We train and test the cascaded model independently for each subcategory in the same manner as we did for the entire dataset.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.9987861514091492}]}, {"text": "We decided to use cross-validation for parameter selection instead of splitting the data in train/dev/test subsets in order to have consistency across all models, because some of these word categories do not comprise enough words for splitting in three subsets (words with more than 8 syllables, for example, have only 1,468 instances).", "labels": [], "entities": [{"text": "parameter selection", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7291086614131927}]}, {"text": "The evaluation of the system's performance and the number of words in each category are presented in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Stress placement for RoSyllabiDict", "labels": [], "entities": [{"text": "RoSyllabiDict", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.5670019388198853}]}, {"text": " Table 3: Accuracy for cascaded model with  gold (G) and predicted (P) syllabication", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.999014139175415}]}]}