{"title": [{"text": "Bayesian Word Alignment for Massively Parallel Texts", "labels": [], "entities": [{"text": "Bayesian Word Alignment", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5199974278608958}]}], "abstractContent": [{"text": "There has been a great amount of work done in the field of bitext alignment, but the problem of aligning words in massively parallel texts with hundreds or thousands of languages is largely unexplored.", "labels": [], "entities": [{"text": "bitext alignment", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.6779952645301819}]}, {"text": "While the basic task is similar, there are also important differences in purpose, method and evaluation between the problems.", "labels": [], "entities": []}, {"text": "In this work, I present a non-parametric Bayesian model that can be used for simultaneous word alignment in massively parallel corpora.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.6724970936775208}]}, {"text": "This method is evaluated on a corpus containing 1144 translations of the New Testament.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bitext word alignment is the problem of finding links between words given pairs of translated sentences).", "labels": [], "entities": [{"text": "Bitext word alignment", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6149216592311859}]}, {"text": "Initially, this was motivated by Statistical Machine Translation (SMT) applications), but wordaligned texts have also been used to transfer linguistic annotation between languages (, for Word Sense Disambiguation (WSD) () and lexicon extraction (.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.8214293221632639}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 187, "end_pos": 218, "type": "TASK", "confidence": 0.7509762495756149}, {"text": "lexicon extraction", "start_pos": 226, "end_pos": 244, "type": "TASK", "confidence": 0.8341955542564392}]}, {"text": "Massively parallel texts, in the sense used by, are essentially the same as bitexts, only with hundreds or thousands of languages rather than just two.", "labels": [], "entities": []}, {"text": "Parallel corpora used in SMT, for instance the Europarl Corpus (), tend to contain few (up to tens of) languages, but many (up to billions of) words in each language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9901866912841797}, {"text": "Europarl Corpus", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.9934360086917877}]}, {"text": "Massively parallel corpora, on the other hand, contain many (hundreds of) languages, but usually fewer (less than a million) words in each language.", "labels": [], "entities": []}, {"text": "Additionally, aligned massively parallel corpora have different applications than traditional parallel corpora with pairwise alignments.", "labels": [], "entities": []}, {"text": "Whereas the latter tend to be used for the various NLP tasks mentioned above, massively parallel corpora have mostly been used for investigations in linguistic typology.", "labels": [], "entities": []}, {"text": "There has been surprisingly few studies on multilingual word alignment.", "labels": [], "entities": [{"text": "multilingual word alignment", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6547916630903879}]}, {"text": "treat alignment as a clustering problem, where the words in each sentence are clustered according to some measure of co-occurrence.", "labels": [], "entities": []}, {"text": "They provide no evaluation, but alignment methods based on co-occurrence statistics have been found to have lower accuracy than even very simple generative models, so this might not be a promising direction as far as accuracy is concerned.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9968830347061157}, {"text": "accuracy", "start_pos": 217, "end_pos": 225, "type": "METRIC", "confidence": 0.99648118019104}]}, {"text": "A related line of research is due to, who learn sets of multilingual translation equivalent phrases.", "labels": [], "entities": []}, {"text": "Although later work () uses phrase pairs extracted with this method for (bitext) word alignment, their method solves a somewhat different problem from what is considered here.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.6789209544658661}]}, {"text": "Some authors have studied how multilingual parallel corpora can be used to improve bitext alignment.", "labels": [], "entities": [{"text": "bitext alignment", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.6412423998117447}]}, {"text": "use (bitext) alignments to addditional languages as features in bitext alignment, while interpolate alignments through multiple bridge languages to produce a bitext alignment for another language pair.", "labels": [], "entities": []}, {"text": "Since the goal of this research is not multilingual alignment, it will not be considered further here.", "labels": [], "entities": [{"text": "multilingual alignment", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.6954919099807739}]}], "datasetContent": [{"text": "The most basic question about the present model is whether sampling the common representation is helpful, compared to simply choosing a language and aligning all other languages to that one.", "labels": [], "entities": []}, {"text": "In order to test this, I initialize the model as described in section 3.3 and sample alignments (but not the common representation) for 200 iterations with \u03bb linearly increasing from 0 to 2, followed by two iterations with \u03bb \u2192 \u221e.", "labels": [], "entities": []}, {"text": "This gives a strong baseline, from which one can start learning the joint model.", "labels": [], "entities": []}, {"text": "Previous authors have tended to avoid multilingual evaluation altogether.", "labels": [], "entities": []}, {"text": "do not evaluate their method, while only use bilingual evaluation.", "labels": [], "entities": []}, {"text": "use the fact that some translations of the Bible have been annotated with Strong's Numbers, which map most word tokens to the lemma of its translation equivalent in the original language, to perform bilingual evaluation of Bible corpus alignments.", "labels": [], "entities": []}, {"text": "Strong's Numbers can be used in a different way to evaluate the type of multilingual alignment produced by the method in this work.", "labels": [], "entities": []}, {"text": "Both the Strong's Numbers and the common representation can be interpreted as clusterings of the word tokens in each language.", "labels": [], "entities": []}, {"text": "Ideally one would want these two clusterings to be identical, as they would be if the original language had been perfectly constructed.", "labels": [], "entities": []}, {"text": "Standard clustering evaluation measures can be used for this task, and in this work I use normalized mutual information (also reinvented as V-measure by).", "labels": [], "entities": []}, {"text": "The evaluation is limited to words which are assigned exactly one Strong's Number, in an attempt to avoid some of the problems with scope discussed by . Note that even a perfect alignment from one language to itself does not achieve the maximum score using this mea- In the Bible corpus used here, nine translations in seven languages contain Strong's Numbers annotations: English and Indonesian (two translations each), as well as German, French, Dutch, Portuguese and Russian (one translation each).", "labels": [], "entities": []}, {"text": "shows alignment quality during training in a model initialized using a translation in Mandarin, which is not related to any of the languages in the evaluation sample and was chosen to avoid initialization bias.", "labels": [], "entities": []}, {"text": "After an initial drop when noise is introduced during the Gibbs sampling process, alignment quality quickly increases as the common representation moves towards the versions in the evaluation sample.", "labels": [], "entities": []}, {"text": "The final two iterations (with \u03bb \u2192 \u221e) remove the sampling noise and the model rapidly converges to a local maximum, resulting in a sharp increase in alignment quality at the end.", "labels": [], "entities": []}, {"text": "Further iterations only result in minor improvements.", "labels": [], "entities": []}, {"text": "contains the baseline and joint model results for models initialized with either English or Mandarin versions.", "labels": [], "entities": []}, {"text": "The joint model outperforms the baseline in all cases except when the initialization language is the same as the evaluation language (the two English translations in the left column), which is expected since it is easy to align a text to itself or to a very similar version.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Normalized mutual information with re- spect to Strong's Numbers, using alignment only  (A) or joint alignment + common representation  learning (A+J), for models initialized using En- glish or Mandarin.", "labels": [], "entities": []}]}