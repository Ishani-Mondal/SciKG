{"title": [{"text": "Enhancing Authorship Attribution By Utilizing Syntax Tree Profiles", "labels": [], "entities": [{"text": "Enhancing Authorship Attribution", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7896413803100586}]}], "abstractContent": [{"text": "The aim of modern authorship attribution approaches is to analyze known authors and to assign authorships to previously unseen and unlabeled text documents based on various features.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7312657237052917}]}, {"text": "In this paper we present a novel feature to enhance current attribution methods by analyzing the grammar of authors.", "labels": [], "entities": []}, {"text": "To extract the feature , a syntax tree of each sentence of a document is calculated, which is then split up into length-independent patterns using pq-grams.", "labels": [], "entities": []}, {"text": "The mostly used pq-grams are then used to compose sample profiles of authors that are compared with the profile of the unlabeled document by utilizing various distance metrics and similarity scores.", "labels": [], "entities": []}, {"text": "An evaluation using three different and independent data sets reveals promising results and indicate that the grammar of authors is a significant feature to enhance modern authorship attribution methods .", "labels": [], "entities": []}], "introductionContent": [{"text": "The increasing amount of documents available from sources like publicly available literary databases often raises the question of verifying disputed authorships or assigning authors to unlabeled text fragments.", "labels": [], "entities": []}, {"text": "The original problem was initiated already in the midst of the twentieth century by Mosteller and Wallace, who tried to find the correct authorships of The Federalist Papers, nonetheless authorship attribution is still a major research topic.", "labels": [], "entities": [{"text": "The Federalist Papers", "start_pos": 152, "end_pos": 173, "type": "DATASET", "confidence": 0.6166563828786215}, {"text": "authorship attribution", "start_pos": 187, "end_pos": 209, "type": "TASK", "confidence": 0.6815261095762253}]}, {"text": "Especially with latest events in politics and academia, the verification of authorships becomes increasingly important and is used frequently in areas like juridical applications (Forensic Linguistics) or cybercrime detection).", "labels": [], "entities": [{"text": "cybercrime detection", "start_pos": 205, "end_pos": 225, "type": "TASK", "confidence": 0.7566788494586945}]}, {"text": "Similarily to works in the field of plagiarism detection (e.g.) which aim to find text fragments not written but claimed to be written by an author, the problem of traditional authorship attribution is defined as follows: Given several authors with text samples for each of them, the question is to label an unknown document with the correct author.", "labels": [], "entities": [{"text": "plagiarism detection", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.8166031241416931}, {"text": "traditional authorship attribution", "start_pos": 164, "end_pos": 198, "type": "TASK", "confidence": 0.6809574166933695}]}, {"text": "In contrast to this socalled closed-class problem, an even harder task is addressed in the open-class problem, where additionally a \"none-of-them\"-answer is allowed).", "labels": [], "entities": []}, {"text": "In this paper we present a novel feature for the traditional, closed-class authorship attribution task, following the assumption that different authors have different writing styles in terms of the grammar structure that is used mostly unconsciously.", "labels": [], "entities": [{"text": "authorship attribution task", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.75322026014328}]}, {"text": "Due to the fact that an author has many different choices of how to formulate a sentence using the existing grammar rules of a natural language, the assumption is that the way of constructing sentences is significantly different for individual authors.", "labels": [], "entities": []}, {"text": "For example, the famous Shakespeare quote \"To be, or not to be: that is the question.\"", "labels": [], "entities": []}, {"text": "(S1) could also be formulated as \"The question is whether to be or not to be.\"", "labels": [], "entities": []}, {"text": "(S2) or even \"The question is whether to be or not.\"", "labels": [], "entities": []}, {"text": "(S3) which is semantically equivalent but differs significantly according to the syntax (see).", "labels": [], "entities": []}, {"text": "The main idea of this approach is to quantify those differences by calculating grammar profiles for each candidate author as well as for the unlabeled document, and to assign one of the candidates as the author of the unseen document by comparing the profiles.", "labels": [], "entities": []}, {"text": "To quantify the differences between profiles multiple metrics have been implemented and evaluated.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 sketches the main idea of the algorithm which incorporates the distance metrics explained in detail in Section 3.", "labels": [], "entities": []}, {"text": "An extensive evaluation us- ing three different test sets is shown in Section 4, while finally Section 5 and Section 6 summarize related work and discuss future work, respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "The approach described in this paper has been extensively evaluated using three different English data sets, whereby all sets are completely unrelated and of different types: (1.)", "labels": [], "entities": []}, {"text": "CC04: the training set used for the Ad-hoc-Authorship Attribution The algorithm names are only used as a reference for this paper, but were not originally proposed like that Competition workshop held in 2004 4 -type: novels, authors: 4, documents: 8, samples per author: 1; (2.)", "labels": [], "entities": [{"text": "CC04", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9105998873710632}, {"text": "Ad-hoc-Authorship Attribution", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.7611857056617737}]}, {"text": "FED: the (undisputed) federalist papers written by Hamilton, Madison and Jay in the 18th century -type: political essays, authors: 3, documents: 61, samples per author: 3; (3.)", "labels": [], "entities": [{"text": "FED", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8494434952735901}]}, {"text": "PAN12: from the state-of-the-art corpus, especially created for the use in authorship identification for the PAN 2012 workshop 5, all closed-classed problems have been chosen -type: misc, authors: 3-16, documents: 6-16, samples per author: 2.", "labels": [], "entities": [{"text": "PAN12", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9630093574523926}, {"text": "authorship identification", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.730851024389267}, {"text": "PAN 2012 workshop 5", "start_pos": 109, "end_pos": 128, "type": "DATASET", "confidence": 0.568573921918869}]}, {"text": "For the evaluation, each of the sets has been used to optimize parameters while the remaining sets have been used for testing.", "labels": [], "entities": []}, {"text": "Besides examining the discussed metrics and values for p and q (e.g. by choosing p = 1 and q = 0 the pq-grams of a grammar profile are equal to pure POS tags), two additional optimization variables have been integrated for the similarity metric Sentence-SPI: \u2022 topPQGramCount t c : by assigning a value to this parameter, only the corresponding amount of mostly used pq-grams of a grammar profile are used.", "labels": [], "entities": []}, {"text": "\u2022 topPQGramOffset to : based on the idea that all authors might have a frequently used and common set of syntax rules that are predefined by a specific language, this parameter allows to ignore the given amount of mostly used pq-grams.", "labels": [], "entities": []}, {"text": "For example if to = 3 in Table 1, the first pq-gram to be used would be The evaluation results are depicted in.", "labels": [], "entities": []}, {"text": "It shows the rate of correct author attributions based on the grammar feature presented in this paper.", "labels": [], "entities": []}, {"text": "Generally, the algorithm worked best using the Sentence-SPI score, which led to a rate of 72% by using the PAN12 data set for optimization.", "labels": [], "entities": [{"text": "PAN12 data set", "start_pos": 107, "end_pos": 121, "type": "DATASET", "confidence": 0.9457045396169027}]}, {"text": "The optimal configuration uses p = 3 and q = 2, which is the same configuration that was used in to produce the best results.", "labels": [], "entities": []}, {"text": "The highest scores are gained by using a limit of top pq-grams (t c \u223c 65) and by ignoring the first three pq-grams (t o = 3), which indicates that it is sufficient to limit the number of syntax structures metric p and that there exists a certain number (3) of general grammar rules for English which are used by all authors.", "labels": [], "entities": []}, {"text": "I.e. those rules cannot by used to infer information about individual authors (e.g. every sentence starts with [S-...]).", "labels": [], "entities": []}, {"text": "All other metrics led to worse results, which may also be a result of the fact that only the Sentence-SPI metric makes use of the additional parameters t c and to . Future work should also investigate on integrating these parameters also in other metrics.", "labels": [], "entities": []}, {"text": "Moreover, results are better using the PAN12 data set for optimization, which maybe because this set is the most hetergeneous one: The Federalist Papers contain only political essays written sometime ago, and the CC04 set only uses literary texts written by four authors.", "labels": [], "entities": [{"text": "PAN12 data set", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.9565845330556234}, {"text": "Federalist Papers", "start_pos": 135, "end_pos": 152, "type": "DATASET", "confidence": 0.7660049200057983}, {"text": "CC04 set", "start_pos": 213, "end_pos": 221, "type": "DATASET", "confidence": 0.8962644934654236}]}], "tableCaptions": []}