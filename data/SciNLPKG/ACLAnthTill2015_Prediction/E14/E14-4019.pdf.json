{"title": [], "abstractContent": [{"text": "We present the first application of Native Language Identification (NLI) to non-English data.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.825718512137731}]}, {"text": "Motivated by theories of language transfer, NLI is the task of identifying a writer's native language (L1) based on their writings in a second language (the L2).", "labels": [], "entities": [{"text": "language transfer", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.774953305721283}]}, {"text": "An NLI system was applied to Chinese learner texts using topic-independent syntactic models to assess their accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9899084568023682}]}, {"text": "We find that models using part-of-speech tags, context-free grammar production rules and function words are highly effective, achieving a maximum accuracy of 71%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9994820952415466}]}, {"text": "Interestingly, we also find that when applied to equivalent English data, the model performance is almost identical.", "labels": [], "entities": []}, {"text": "This finding suggests a systematic pattern of cross-linguistic transfer may exist, where the degree of transfer is independent of the L1 and L2.", "labels": [], "entities": [{"text": "cross-linguistic transfer", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.7011108696460724}]}], "introductionContent": [{"text": "Native Language Identification (NLI) is the task of identifying an author's native language (L1) based on their writings in a second language (the L2).", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7754465937614441}]}, {"text": "NLI works by identifying language use patterns that are common to groups of speakers that share the same native language.", "labels": [], "entities": []}, {"text": "This process is underpinned by the presupposition that an author's L1 will dispose them towards particular language production patterns in their L2, as influenced by their mother tongue.", "labels": [], "entities": []}, {"text": "This relates to Cross-Linguistic Influence (CLI), a key topic in the field of Second Language Acquisition (SLA) that analyzes transfer effects from the L1 on later learned languages.", "labels": [], "entities": [{"text": "Cross-Linguistic Influence (CLI)", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.6400819659233093}, {"text": "Second Language Acquisition (SLA)", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.8099444210529327}]}, {"text": "While NLI has applications in security, most research has a strong linguistic motivation relating to language teaching and learning.", "labels": [], "entities": []}, {"text": "Rising numbers of language learners have led to an increasing need for language learning resources, which has in turn fuelled much of the language acquisition research of the past decade.", "labels": [], "entities": []}, {"text": "In this context, by identifying L1-specific language usage and error patterns, NLI can be used to better understand SLA and develop teaching methods, instructions and learner feedback that is specific to their mother tongue.", "labels": [], "entities": []}, {"text": "However, all of the NLI research to date has focused exclusively on English L2 data.", "labels": [], "entities": [{"text": "English L2 data", "start_pos": 68, "end_pos": 83, "type": "DATASET", "confidence": 0.8050078550974528}]}, {"text": "To this end there is a need to apply NLI to other languages, not only to gauge their applicability but also to aid in teaching research for other emerging languages.", "labels": [], "entities": []}, {"text": "Interest in learning Chinese is rapidly growing, leading to increased research in Teaching Chinese as a Second Language (TCSL) and the development of related resources such as learner corpora.", "labels": [], "entities": [{"text": "Teaching Chinese as a Second Language (TCSL)", "start_pos": 82, "end_pos": 126, "type": "TASK", "confidence": 0.6430928640895419}]}, {"text": "The application of these tools and scientific methods like NLI can greatly assist researchers in creating effective teaching practices and is an area of active research.", "labels": [], "entities": []}, {"text": "The aim of this research is to evaluate the crosslanguage applicability of NLI techniques by applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents.", "labels": [], "entities": []}, {"text": "To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique.", "labels": [], "entities": []}], "datasetContent": [{"text": "We also follow the supervised classification approach described in \u00a72.", "labels": [], "entities": [{"text": "supervised classification", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.6552565097808838}]}, {"text": "We devise and run experiments using several models that capture different types of linguistic information.", "labels": [], "entities": []}, {"text": "For each model, features are extracted from the texts and a classifier is trained to predict the L1 labels using the features.", "labels": [], "entities": []}, {"text": "As our data is not topic-balanced, we avoid using topic-dependent lexical features such as character or word n-grams.", "labels": [], "entities": []}, {"text": "Each experiment is run with two feature representations: binary (presence/absence of a feature) and normalized frequencies, where feature values are normalized to text length using the l2-norm.", "labels": [], "entities": []}, {"text": "The same evaluation metrics and standards used in the NLI2013 Shared Task are used: we report classification accuracy under 10-fold cross-validation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.8963470458984375}]}, {"text": "We also use the same number of classes as the shared task to facilitate comparative analyses.", "labels": [], "entities": [{"text": "comparative analyses", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.9392953813076019}]}], "tableCaptions": [{"text": " Table 2: Chinese Native Language Identification  accuracy (%) for all of our models.", "labels": [], "entities": [{"text": "Chinese Native Language Identification", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.7083046287298203}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.8480595946311951}]}]}