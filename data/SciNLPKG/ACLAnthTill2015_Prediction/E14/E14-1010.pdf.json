{"title": [{"text": "Simple, Robust and (almost) Unsupervised Generation of Polarity Lexicons for Multiple Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a simple, robust and (almost) unsupervised dictionary-based method, qwn-ppv (Q-WordNet as Person-alized PageRanking Vector) to automatically generate polarity lexicons.", "labels": [], "entities": []}, {"text": "We show that qwn-ppv outperforms other automatically generated lexicons for the four ex-trinsic evaluations presented here.", "labels": [], "entities": []}, {"text": "It also shows very competitive and robust results with respect to manually annotated ones.", "labels": [], "entities": []}, {"text": "Results suggest that no single lexicon is best for every task and dataset and that the intrinsic evaluation of polarity lexicons is not a good performance indicator on a Sentiment Analysis task.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 170, "end_pos": 193, "type": "TASK", "confidence": 0.9370712439219157}]}, {"text": "The qwn-ppv method allows to easily create quality polarity lexicons whenever no domain-based annotated corpora are available fora given language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Opinion Mining and Sentiment Analysis are important for determining opinions about commercial products, on companies reputation management, brand monitoring, or to track attitudes by mining social media, etc.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6708375662565231}, {"text": "Sentiment Analysis", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8750618696212769}]}, {"text": "Given the explosion of information produced and shared via the Internet, it is not possible to keep up with the constant flow of new information by manual methods.", "labels": [], "entities": []}, {"text": "Sentiment Analysis often relies on the availability of words and phrases annotated according to the positive or negative connotations they convey.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9682934582233429}]}, {"text": "'Beautiful', 'wonderful', and 'amazing' are examples of positive words whereas 'bad', 'awful', and 'poor' are examples of negatives.", "labels": [], "entities": []}, {"text": "The creation of lists of sentiment words has generally been performed by means of manual-, dictionary-and corpus-based methods.", "labels": [], "entities": []}, {"text": "Manually collecting such lists of polarity annotated words is labor intensive and time consuming, and is thus usually combined with automated approaches as the final check to correct mistakes.", "labels": [], "entities": []}, {"text": "However, there are well known lexicons which have been fully ( or at least partially manually created (.", "labels": [], "entities": []}, {"text": "Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet) that contain synonyms and antonyms for each word.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9614406228065491}]}, {"text": "A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (.", "labels": [], "entities": []}, {"text": "Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to anew one using a domain-specific corpus).", "labels": [], "entities": []}, {"text": "One particular issue arising from corpus methods is that fora given domain the same word can be positive in one context but negative in another.", "labels": [], "entities": []}, {"text": "This is also a problem shared by manual and dictionary-based methods, and that is why qwn-ppv also produces synset-based lexicons for approaches on Sentiment Analysis at sense level.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.9481370449066162}]}, {"text": "This paper presents a simple, robust and (almost) unsupervised dictionary-based method, QWordNet-PPV (QWordNet by Personalized PageRank Vector) to automatically generate polarity lexicons based on propagating some automatically created seeds using a Personalized PageRank algorithm) over a LKB projected into a graph.", "labels": [], "entities": []}, {"text": "We see qwn-ppv as an effective methodology to easily create polarity lexicons for any language for which a WordNet is available.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.9343069791793823}]}, {"text": "This paper empirically shows that: (i) qwn-ppv outperforms other automatically generated lexicons (e.g. SentiWordNet 3.0, MSOL) on the 4 extrinsic evaluations presented here; it also displays competitive and robust results also with respect to manually annotated lexicons; (ii) no single polarity lexicon is fit for every Sentiment Analysis task; depending on the text data and the task itself, one lexicon will perform better than others; (iii) if required, qwn-ppv efficently generates many lexicons on demand, depending on the task on which they will be used; (iv) intrinsic evaluation is not appropriate to judge whether a polarity lexicon is fit fora given Sentiment Analysis (SA) task because good correlation with respect to a gold-standard does not correspond with correlation with respect to a SA task; (v) it is easily applicable to create qwn-ppv(s) for other languages, and we demonstrate it hereby creating many polarity lexicons not only for English but also for Spanish; (vi) the method works at both word and sense levels and it only requires the availability of a LKB or dictionary; finally, (vii) a dictionarybased method like qwn-ppv allows to easily create quality polarity lexicons whenever no domainbased annotated reviews are available fora given language.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 322, "end_pos": 345, "type": "TASK", "confidence": 0.8754366437594095}]}, {"text": "After all, there usually is available a dictionary fora given language; for example, the Open Multilingual WordNet site lists WordNets for up to 57 languages.", "labels": [], "entities": []}, {"text": "Although there has been previous work using graph methods for obtaining lexicons via propagation, the qwn-ppv method to combine the seed generation and the Personalized PageRank propagation is novel.", "labels": [], "entities": []}, {"text": "Furthermore, it is considerable simpler and obtains better and easier to reproduce results than previous automatic approaches ().", "labels": [], "entities": []}, {"text": "Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes.", "labels": [], "entities": []}, {"text": "Section 3 describes the qwn-ppv method to automatically generate lexicons.", "labels": [], "entities": []}, {"text": "The resulting lexical resources are evaluated in section 4.", "labels": [], "entities": []}, {"text": "We finish with some concluding remarks and future work in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Previous approaches have provided intrinsic evaluation () using manually annotated resources such as the General Inquirer (  in general be evaluated extrinsically.", "labels": [], "entities": [{"text": "General Inquirer", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.9338606595993042}]}, {"text": "After all, any polarity lexicon is as good as the results obtained by using it fora particular Sentiment Analysis task.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.9424663980801901}]}, {"text": "Our goal is to evaluate the polarity lexicons simplifying the evaluation parameters to avoid as many external influences as possible on the results.", "labels": [], "entities": []}, {"text": "We compare our work with most of the lexicons reviewed in section 2, both at synset and word level, both manually and automatically generated: General Inquirer (GI), Opinion Finder (OF), Liu, Taboada et al.'s (SO-CAL), Agerri and Garc\u00eda-Serrano (2010) (QWN), Mohammad et al's, (MSOL(ASL-GI)) and SentiWordNet 3.0 (SWN).", "labels": [], "entities": []}, {"text": "The results presented in section 4.2 show that extrinsic evaluation is more meaningful to determine the adequacy of a polarity lexicon fora specific Sentiment Analysis task.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 149, "end_pos": 172, "type": "TASK", "confidence": 0.9538095196088155}]}, {"text": "Three different corpora were used: and MPQA ( for English, and HOpinion 2 in Spanish.", "labels": [], "entities": [{"text": "MPQA", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.8189612627029419}]}, {"text": "In addition, we divided the corpus into two subsets (75% development and 25% test) for applying our ratio system for the phrase polarity task too.", "labels": [], "entities": [{"text": "phrase polarity task", "start_pos": 121, "end_pos": 141, "type": "TASK", "confidence": 0.7973305781682333}]}, {"text": "Note that the development set is only used to setup the polarity classification task, and that the generation of qwn-ppv lexicons is unsupervised.", "labels": [], "entities": [{"text": "polarity classification task", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.8457172513008118}]}, {"text": "For Spanish we tried to reproduce the English settings with Bespalov's corpus.", "labels": [], "entities": []}, {"text": "Thus, both development and test sets were created from the HOpinion corpus.", "labels": [], "entities": [{"text": "HOpinion corpus", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.971728652715683}]}, {"text": "As it contains a much higher proportion of positive reviews, we created also subsets which contain a balanced number of positive and negative reviews to allow fora more meaningful comparison than that of table 6.", "labels": [], "entities": []}, {"text": "We report results of 4 extrinsic evaluations or tasks, three of them based on a simple ratio average system, inspired by, and another one based on.", "labels": [], "entities": []}, {"text": "We first implemented a simple average ratio classifier which computes the average ratio of the polarity words found in document d: where, for each polarity, pol(w) is 1 if w is included in the polarity lexicon and 0 otherwise.", "labels": [], "entities": []}, {"text": "Documents that reach a certain threshold are classified as positive, and otherwise as negative.", "labels": [], "entities": []}, {"text": "To setup an evaluation enviroment as fair as possible for every lexicon, the threshold is optimised by maximising accuracy over the development data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.998696506023407}]}, {"text": "Second, we implemented a phrase polarity task identification as described by.", "labels": [], "entities": [{"text": "phrase polarity task identification", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.8249302208423615}]}, {"text": "Their method consists of: (i) if any of the words in the target phrase is contained in the negative lexicon, then the polarity is negative; (ii) if none of the words are negative, and at least one word is in the positive lexicon, then is positive; (iii) the rest are not tagged.", "labels": [], "entities": []}, {"text": "We chose this very simple polarity estimators because our aim was to minimize the role other.", "labels": [], "entities": []}, {"text": "Having word sense annotated datasets gives us the opportunity to evaluate the lexicons both at word and sense levels.", "labels": [], "entities": []}, {"text": "For the evaluation of those lexicons that are synset-based, such as qwn-ppv and SentiWordNet 3.0, we convert them from senses to words by taking every word or variant contained in each of their senses.", "labels": [], "entities": []}, {"text": "Moreover, if a lemma appears as a variant in several synsets the most frequent polarity is assigned to that lemma.", "labels": [], "entities": []}, {"text": "With respect to lexicons at word level, we take the most frequent sense according to WordNet 3.0 for each of their positive and negative words.", "labels": [], "entities": []}, {"text": "Note that the latter conversion, for synset based evaluation, is mostly done to show that the evaluation at synset level is harder independently of the quality of the lexicon evaluated.", "labels": [], "entities": []}, {"text": "To facilitate intrinsic comparison with previous approaches, we evaluate our automatically generated lexicons against GI.", "labels": [], "entities": []}, {"text": "For each qwn-ppv lexicon shown in previous extrinsic evaluations, we compute the intersection between the lexicon and GI, and evaluate the words in that intersection.", "labels": [], "entities": []}, {"text": "shows results for the best-performing QWN-PPV lexicons (both using AG and TL seeds) in the extrinsic evaluations at word level of tables 1 (first two rows), 2 (rows 3 and 4) and 4 (rows 5 and 6: Accuracy QWN-PPV lexicons and SWN with respect to the GI lexicon.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9794297218322754}]}], "tableCaptions": [{"text": " Table 1: Evaluation of lexicons at document level using Bespalov's Corpus.", "labels": [], "entities": [{"text": "Bespalov's Corpus", "start_pos": 57, "end_pos": 74, "type": "DATASET", "confidence": 0.6549447973569235}]}, {"text": " Table 2: Evaluation of lexicons using averaged ratio on the MPQA 1.2 test Corpus.", "labels": [], "entities": [{"text": "MPQA 1.2 test Corpus", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.9337005764245987}]}, {"text": " Table 4: Evaluation of lexicons at phrase level using Mohammad et al.'s (2009) method on MPQA  1.2 total Corpus.", "labels": [], "entities": [{"text": "MPQA  1.2 total Corpus", "start_pos": 90, "end_pos": 112, "type": "DATASET", "confidence": 0.8671468496322632}]}, {"text": " Table 5: Evaluation of Spanish lexicons using the  full HOpinion corpus at synset level.", "labels": [], "entities": [{"text": "HOpinion corpus", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9265359044075012}]}, {"text": " Table 6: Evaluation of Spanish lexicons using the  full HOpinion corpus at word level.", "labels": [], "entities": [{"text": "HOpinion corpus", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9112817347049713}]}, {"text": " Table 7: Accuracy QWN-PPV lexicons and SWN  with respect to the GI lexicon.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9975186586380005}, {"text": "SWN", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9824061393737793}, {"text": "GI lexicon", "start_pos": 65, "end_pos": 75, "type": "DATASET", "confidence": 0.8486425578594208}]}]}