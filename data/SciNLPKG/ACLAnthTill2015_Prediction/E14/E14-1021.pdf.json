{"title": [{"text": "PARADIGM: Paraphrase Diagnostics through Grammar Matching", "labels": [], "entities": [{"text": "PARADIGM", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7337580323219299}, {"text": "Paraphrase Diagnostics", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9372820258140564}, {"text": "Grammar Matching", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.6939604133367538}]}], "abstractContent": [{"text": "Paraphrase evaluation is typically done either manually or through indirect, task-based evaluation.", "labels": [], "entities": [{"text": "Paraphrase evaluation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9522412121295929}]}, {"text": "We introduce an intrinsic evaluation PARADIGM which measures the goodness of paraphrase collections that are represented using synchronous grammars.", "labels": [], "entities": [{"text": "PARADIGM", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9759438037872314}]}, {"text": "We formulate two measures that evaluate these paraphrase grammars using gold standard sentential paraphrases drawn from a monolingual parallel corpus.", "labels": [], "entities": []}, {"text": "The first measure calculates how often a paraphrase grammar is able to synchronously parse the sentence pairs in the corpus.", "labels": [], "entities": []}, {"text": "The second measure enumerates paraphrase rules from the monolingual parallel corpus and calculates the overlap between this reference paraphrase collection and the paraphrase resource being evaluated.", "labels": [], "entities": []}, {"text": "We demonstrate the use of these evaluation metrics on paraphrase collections derived from three different data types: multiple translations of classic French novels, comparable sentence pairs drawn from different newspapers , and bilingual parallel corpora.", "labels": [], "entities": []}, {"text": "We show that PARADIGM correlates with human judgments more strongly than BLEU on a task-based evaluation of paraphrase quality.", "labels": [], "entities": [{"text": "PARADIGM", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9741567373275757}, {"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9986617565155029}]}], "introductionContent": [{"text": "Paraphrases are useful in a wide range of natural language processing applications.", "labels": [], "entities": []}, {"text": "A variety of data-driven approaches have been proposed to generate paraphrase resources (see  fora survey of these methods).", "labels": [], "entities": []}, {"text": "Few objective metrics have been established to evaluate these resources.", "labels": [], "entities": []}, {"text": "Instead, paraphrases are typically evaluated using subjective manual evaluation or through task-based evaluations.", "labels": [], "entities": []}, {"text": "Different researchers have used different criteria for manual evaluations.", "labels": [], "entities": []}, {"text": "For example, evaluated their paraphrases by asking judges whether paraphrases were \"approximately conceptually equivalent.\" asked judges whether their paraphrases were \"roughly interchangeable given the genre.\" replaced phrases with paraphrases in a number of sentences and asked judges whether the substitutions \"preserved meaning and remained grammatical.\"", "labels": [], "entities": []}, {"text": "The results of these subjective evaluations are not easily reusable.", "labels": [], "entities": []}, {"text": "Other researchers have evaluated their paraphrases through task-based evaluations.", "labels": [], "entities": []}, {"text": "measured their potential impact on question-answering.", "labels": [], "entities": []}, {"text": "evaluate their applicability in the text-to-text generation task of sentence compression.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7197957038879395}, {"text": "sentence compression", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.7091548293828964}]}, {"text": "use them to perform sentence compression and simplification and to compute sentence similarity.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.768394947052002}, {"text": "compute sentence similarity", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.6619156201680502}]}, {"text": "Several researchers have demonstrated that paraphrases can improve machine translation evaluation (c.f.,, and).", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.8681490222613016}]}, {"text": "We introduce an automatic evaluation metric called PARADIGM, PARAphrase DIagnostics through Grammar Matching.", "labels": [], "entities": [{"text": "PARADIGM", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9357374310493469}, {"text": "PARAphrase", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9323577284812927}, {"text": "Grammar Matching", "start_pos": 92, "end_pos": 108, "type": "TASK", "confidence": 0.6788678169250488}]}, {"text": "This metric evaluates paraphrase collections that are represented using synchronous grammars.", "labels": [], "entities": []}, {"text": "Synchronous treeadjoining grammars (STAGs), synchronous tree substitution grammars (STSGs), and synchronous context free grammars (SCFGs) are popular formalisms for representing paraphrase rules).", "labels": [], "entities": []}, {"text": "We present two measures that evaluate these paraphrase grammars using gold standard sentential paraphrases drawn from a monolingual parallel corpus, which have been previously proposed as a good resource for paraphrase evaluation . The first of our two proposed metrics calculates how often a paraphrase grammar is able to synchronously parse the sentence pairs in a test set.", "labels": [], "entities": [{"text": "paraphrase evaluation", "start_pos": 208, "end_pos": 229, "type": "TASK", "confidence": 0.8801316320896149}]}, {"text": "The second measure enumerates paraphrase rules from a monolingual parallel corpus and calculates the overlap between this reference paraphrase collection, and the paraphrase resource being evaluated.", "labels": [], "entities": []}], "datasetContent": [{"text": "We calculated our two metrics for each of the grammars listed in.", "labels": [], "entities": []}, {"text": "To perform synchronous parsing, we used the Joshua decoder (, which includes an implementation of Dyer's two-pass parsing algorithm.", "labels": [], "entities": []}, {"text": "After splitting the LDC data into 10 equal pieces, we trained paraphrase models on nine-tenths of the data and parsed the other tenth.", "labels": [], "entities": [{"text": "LDC data", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.8066301941871643}]}, {"text": "Grammars trained from other sources (the MSR corpus, French literature domain, and PPDB) were also evaluated on the held-out tenth of LDC data.", "labels": [], "entities": [{"text": "MSR corpus", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.9574416875839233}, {"text": "French literature domain", "start_pos": 53, "end_pos": 77, "type": "DATASET", "confidence": 0.8509887258211771}, {"text": "PPDB", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.926297664642334}, {"text": "LDC data", "start_pos": 134, "end_pos": 142, "type": "DATASET", "confidence": 0.8690690696239471}]}, {"text": "Note that the LDC data contains 4 independent translations of each foreign sentence, giving 6 possible (unordered) paraphrase pairs.", "labels": [], "entities": [{"text": "LDC data", "start_pos": 14, "end_pos": 22, "type": "DATASET", "confidence": 0.8683305978775024}]}, {"text": "We evaluated coverage in two ways (corresponding to the two columns in): first, considering all possible sentence pairs from the test data, how many were able to be parsed?", "labels": [], "entities": [{"text": "coverage", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9525808691978455}]}, {"text": "Secondly, if we consider all the English sentences that correspond to one foreign sentence, how many foreign sentences had at least one pair of English translations that could be parsed synchronously?", "labels": [], "entities": []}, {"text": "For grammar overlap, we perform both strict and non-strict calculations (see Section 4.2) against a syntactic grammar derived from handaligned ParaMetric data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Amount of English-English parallel data.  LDC data has 4 parallel translations per sentence.  Literature data is from Barzilay and McKeown  (2001). MSR data is from Quirk et al. (2004)  and Dolan et al. (2004). ParaMertic data is from  Callison-Burch et al. (2008).", "labels": [], "entities": [{"text": "LDC data", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.7671915292739868}]}, {"text": " Table 2: Size of various paraphrase grammars.", "labels": [], "entities": []}, {"text": " Table 3: Size of strict overlap (number of rules and  % of the gold standard) of each grammar with a  syntactic grammar derived from ParaMetric. freq.  \u2265 2 means we first removed all rules that ap- peared only once from the ParaMetric grammar.  The number in parentheses shows the percentage  of ParaMetric rules that are present in the overlap.", "labels": [], "entities": [{"text": "ParaMetric.", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.6964675188064575}, {"text": "freq", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.4479636251926422}]}, {"text": " Table 4: Size of non-strict overlap of each gram- mar with the syntactic grammar derived from  ParaMetric. The number in parentheses shows the  percentage of ParaMetric rules that are present in  the overlap.", "labels": [], "entities": []}, {"text": " Table 5: Number of paraphrases of each type  in each grammar's strict overlap with the syntac- tic ParaMetric grammar. Numbers in parentheses  show the percentage of ParaMetric rules of each  type.", "labels": [], "entities": []}, {"text": " Table 6: Parse coverage on held-out LDC data.  The all column considers every possible sentential  paraphrase in the test set. The any column consid- ers a sentence parsed if any of its paraphrases was  able to parsed.", "labels": [], "entities": [{"text": "Parse coverage", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.6714632213115692}, {"text": "LDC data", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.7538221180438995}]}]}