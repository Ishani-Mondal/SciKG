{"title": [{"text": "Jane: Open Source Machine Translation System Combination", "labels": [], "entities": [{"text": "Open Source Machine Translation System Combination", "start_pos": 6, "end_pos": 56, "type": "TASK", "confidence": 0.6396343310674032}]}], "abstractContent": [{"text": "Different machine translation engines can be remarkably dissimilar not only with respect to their technical paradigm, but also with respect to the translation output they yield.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.695641353726387}]}, {"text": "System combination is a method for combining the output of multiple machine translation engines in order to take benefit of the strengths of each of the individual engines.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.704465240240097}]}, {"text": "In this work we introduce a novel system combination implementation which is integrated into Jane, RWTH's open source statistical machine translation toolkit.", "labels": [], "entities": [{"text": "Jane, RWTH", "start_pos": 93, "end_pos": 103, "type": "DATASET", "confidence": 0.7903109192848206}, {"text": "statistical machine translation", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.7098151644070944}]}, {"text": "On the most recent Workshop on Statistical Machine Translation system combination shared task, we achieve improvements of up to 0.7 points in BLEU over the best system combination hypotheses which were submitted for the official evaluation.", "labels": [], "entities": [{"text": "Statistical Machine Translation system combination shared task", "start_pos": 31, "end_pos": 93, "type": "TASK", "confidence": 0.8320078509194511}, {"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9979907274246216}]}, {"text": "Moreover, we enhance our system combination pipeline with additional n-gram language models and lexical translation models.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present a novel machine translation system combination framework which has been implemented and released as part of the most recent version of the Jane toolkit.", "labels": [], "entities": [{"text": "machine translation system combination", "start_pos": 19, "end_pos": 57, "type": "TASK", "confidence": 0.8216582834720612}, {"text": "Jane toolkit", "start_pos": 150, "end_pos": 162, "type": "DATASET", "confidence": 0.9787004292011261}]}, {"text": "Our system combination framework has already been applied successfully for joining the outputs of different individual machine translation engines from several project partners within large-scale projects like Quaero (Peitz and others, 2013), EU-BRIDGE (, and DARPA BOLT.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.6963018774986267}, {"text": "EU-BRIDGE", "start_pos": 243, "end_pos": 252, "type": "DATASET", "confidence": 0.9032444953918457}, {"text": "DARPA", "start_pos": 260, "end_pos": 265, "type": "DATASET", "confidence": 0.6957638263702393}, {"text": "BOLT", "start_pos": 266, "end_pos": 270, "type": "METRIC", "confidence": 0.691281795501709}]}, {"text": "The combined translation is typically of better quality than any of the individual hypotheses.", "labels": [], "entities": []}, {"text": "The source code of our framework has now been released to the public.", "labels": [], "entities": []}, {"text": "We focus on system combination via confusion network decoding.", "labels": [], "entities": []}, {"text": "This basically means that we align all input hypotheses from individual machine translation (MT) engines together and extract a combination as anew output.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.825592303276062}]}, {"text": "For our baseline algorithm we only need the first best translation from each of the different MT engines, without any additional information.", "labels": [], "entities": [{"text": "MT", "start_pos": 94, "end_pos": 96, "type": "TASK", "confidence": 0.9408451318740845}]}, {"text": "Supplementary to the baseline models integrated into our framework, we optionally allow for utilization of n-gram language models and IBM-1 lexicon models (, both trained on additional training corpora that might beat hand.", "labels": [], "entities": []}, {"text": "We evaluate the Jane system combination framework on the latest official Workshop on Statistical Machine Translation (WMT) system combination shared task).", "labels": [], "entities": [{"text": "Statistical Machine Translation (WMT) system combination shared task", "start_pos": 85, "end_pos": 153, "type": "TASK", "confidence": 0.8105746120214462}]}, {"text": "Many state-of-the-art MT system combination toolkits have been evaluated on this task, which allows us to directly compare the results obtained with our novel Jane system combination framework with the best known results obtained with other toolkits.", "labels": [], "entities": [{"text": "MT system combination", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.9005575378735861}]}, {"text": "The paper is structured as follows: We commence with giving a brief outline of some related work (Section 2).", "labels": [], "entities": []}, {"text": "In Section 3 we describe the techniques which are implemented in the Jane MT system combination framework.", "labels": [], "entities": [{"text": "Jane MT system combination framework", "start_pos": 69, "end_pos": 105, "type": "DATASET", "confidence": 0.9311077952384949}]}, {"text": "The experimental results are presented and analyzed in Section 4.", "labels": [], "entities": []}, {"text": "We conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments are conducted on the latest official WMT system combination shared task.", "labels": [], "entities": [{"text": "WMT system combination shared task", "start_pos": 53, "end_pos": 87, "type": "DATASET", "confidence": 0.8499111294746399}]}, {"text": "We exclusively employ resources which were permitted for the constrained track of the task in all our setups.", "labels": [], "entities": []}, {"text": "The big LM was trained on News Commentary and Europarl data.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9815859496593475}]}, {"text": "As tuning set we used newssyscombtune2011, as test set we used newssyscombtest2011.", "labels": [], "entities": []}, {"text": "Feature weights have been optimized with MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.4613907039165497}]}, {"text": "contains the empirical results (truecase).", "labels": [], "entities": []}, {"text": "For all four language pairs we achieve improvements over the best 2011 evaluation system combination submission either in BLEU or TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.9878035187721252}, {"text": "TER", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.6625580787658691}]}, {"text": "We get the highest improvement of 0.7 points in BLEU for es\u2192en when adding both the big LM and IBM-1 features.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9979963898658752}]}, {"text": "Adding the big LM over the baseline enhances the translation quality for all four language pairs.", "labels": [], "entities": []}, {"text": "Adding IBM-1 lexicon models on top of the big LM is of marginal or no benefit for most language pairs, but at least provides slight improvements for es\u2192en.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results on the WMT system combination tasks (newssyscombtest2011).", "labels": [], "entities": [{"text": "WMT system combination tasks", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.680252805352211}]}]}