{"title": [{"text": "Weighted Krippendorff's alpha is a more reliable metrics for multi- coders ordinal annotations: experimental studies on emotion, opinion and coreference annotation", "labels": [], "entities": [{"text": "coreference annotation", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.9393260478973389}]}], "abstractContent": [{"text": "The question of data reliability is of first importance to assess the quality of manually annotated corpora.", "labels": [], "entities": []}, {"text": "Although Cohen ' s \u03ba is the prevailing reliability measure used in NLP, alternative statistics have been proposed.", "labels": [], "entities": []}, {"text": "This paper presents an experimental study with four measures (Cohen's \u03ba, Scott's \u03c0, binary and weighted Krippendorff ' s \u03b1) on three tasks: emotion, opinion and coreference annotation.", "labels": [], "entities": [{"text": "coreference annotation", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.9509202837944031}]}, {"text": "The reported studies investigate the factors of influence (annotator bias, category prevalence, number of coders, number of categories) that should affect reliability estimation.", "labels": [], "entities": []}, {"text": "Results show that the use of a weighted measure restricts this influence on ordinal annotations.", "labels": [], "entities": []}, {"text": "They suggest that weighted \u03b1 is the most reliable metrics for such an annotation scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "We have conducted experiments on three different annotation tasks in order to guarantee an appreciable generality of our findings.", "labels": [], "entities": []}, {"text": "The first two experiments correspond to an ordinal annotation.", "labels": [], "entities": []}, {"text": "They concern the affective dimension of language (emotion and opinion annotation).", "labels": [], "entities": []}, {"text": "They have been conducted with na\u00efve coders to preserve the spontaneity of judgment which is searched for in affective computing.", "labels": [], "entities": []}, {"text": "The third experiment concerns coreference annotation.", "labels": [], "entities": [{"text": "coreference annotation", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.969506025314331}]}, {"text": "It is a nominal annotation that has been designed to be used as a comparison with the previous ordinal annotations tasks.", "labels": [], "entities": []}, {"text": "The corresponding annotated corpora are available (TestAccord database) on the french Parole_Publique 1 corpus repository under a CC-BY-SA Creative Commons licence.", "labels": [], "entities": [{"text": "french Parole_Publique 1 corpus repository", "start_pos": 79, "end_pos": 121, "type": "DATASET", "confidence": 0.9266462751797268}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2. Reliability measures: emotion and opinion  random annotation as well as coreference annotation", "labels": [], "entities": [{"text": "coreference annotation", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.869536966085434}]}, {"text": " Table 3. Reliability measures with 3 and 5 annotation  classes: opinion contextual annotation (film reviews).", "labels": [], "entities": []}, {"text": " Table 4. Distribution of the coding categories", "labels": [], "entities": [{"text": "Distribution", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9603884220123291}]}, {"text": " Table 5. Relative standard deviation of measures on  any independent sets of coders", "labels": [], "entities": [{"text": "Relative standard deviation", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.9349161783854166}]}]}