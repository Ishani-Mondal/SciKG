{"title": [{"text": "Finding Terms in Corpora for Many Languages with the Sketch Engine", "labels": [], "entities": [{"text": "Finding Terms in Corpora for Many Languages", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8461901545524597}]}], "abstractContent": [], "introductionContent": [], "datasetContent": [{"text": "We have undertaken a first evaluation using the GENIA corpus (, in which all terms have been manually identified.", "labels": [], "entities": [{"text": "GENIA corpus", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.9636921286582947}]}, {"text": "First, a plain-text version of GENIA was extracted and loaded into the system.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.7793021202087402}]}, {"text": "Keyword and term extraction was performed to obtain the top 2000 keywords and top 1000 multi-word terms.", "labels": [], "entities": [{"text": "Keyword and term extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7153615951538086}]}, {"text": "Terms manually annotated in GENIA as well as terms extracted by our tool were normalized before comparison (lower case, spaces and hyphens removed) and then GENIA terms were looked up in the extraction results.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.9256897568702698}]}, {"text": "61 of the top 100 GE-NIA terms were found by the system.", "labels": [], "entities": []}, {"text": "The terms not found were not English words: most were acronyms, e.g. EGR1, STAT-6.", "labels": [], "entities": [{"text": "EGR1", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.9058517217636108}, {"text": "STAT-6", "start_pos": 75, "end_pos": 81, "type": "DATASET", "confidence": 0.6757169961929321}]}, {"text": "Concerning the domain corpus size: Although the extraction method works well even with very small corpora (e.g. the sample environmental corpus in 1 consists of 100,000 words), larger corpora should be employed to cover more terms.", "labels": [], "entities": []}, {"text": "An early version of this extraction tool was used to help lexicographers compile environment protection related terminology.", "labels": [], "entities": []}, {"text": "A 50 million words corpus was sufficient in that case.", "labels": [], "entities": []}, {"text": "() report 30 million words is enough.", "labels": [], "entities": []}], "tableCaptions": []}