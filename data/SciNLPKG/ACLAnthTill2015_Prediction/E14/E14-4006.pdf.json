{"title": [{"text": "Projecting the Knowledge Graph to Syntactic Parsing", "labels": [], "entities": [{"text": "Syntactic Parsing", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7427008152008057}]}], "abstractContent": [{"text": "We present a syntactic parser training paradigm that learns from large scale Knowledge Bases.", "labels": [], "entities": []}, {"text": "By utilizing the Knowledge Base context only during training, the resulting parser has no inference-time dependency on the Knowledge Base, thus not decreasing the speed during prediction.", "labels": [], "entities": []}, {"text": "Knowledge Base information is injected into the model using an extension to the Augmented-loss training framework.", "labels": [], "entities": []}, {"text": "We present empirical results that show this approach achieves a significant gain inaccuracy for syntactic categories such as coordination and apposi-tion.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural Language Processing systems require large amounts of world knowledge to achieve state-of-the-art performance.", "labels": [], "entities": []}, {"text": "Leveraging Knowledge Bases (KB) provides allows us to inject human curated world-knowledge into our systems.", "labels": [], "entities": []}, {"text": "As these KBs have increased in size, we are now able to leverage this information to improve upon the state-of-the-art.", "labels": [], "entities": []}, {"text": "Large scale KB have been developed rapidly in recent years, adding large numbers of entities and relations between the entities.", "labels": [], "entities": []}, {"text": "Such entities can be of any kind: an object, a person, a place, a company, a book, etc.", "labels": [], "entities": []}, {"text": "Entities and relations are stored in association with relevant data that describes the particular entity or relation; for example, the name of a book, it's author, other books by the same author, etc..", "labels": [], "entities": []}, {"text": "Large scale KB annotation efforts have focused on the collection of both current and historical entities, but are biased towards the contemporary entities.", "labels": [], "entities": [{"text": "KB annotation", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.9244544208049774}]}, {"text": "Of the many publicly available KBs, we focus this study on the use of Freebase 1 : a large collaborative Knowledge Base composed and updated by a member community.", "labels": [], "entities": []}, {"text": "Currently it contains roughly 40 million entities and 1.1 billion relations.", "labels": [], "entities": []}, {"text": "The aim of the presented work is to use the information provided by the KB to improve the accuracy of the statistical dependency parsing task ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9987820982933044}, {"text": "statistical dependency parsing task", "start_pos": 106, "end_pos": 141, "type": "TASK", "confidence": 0.7505229860544205}]}, {"text": "In particular we focus on the recognition of relations such as coordination and apposition.", "labels": [], "entities": []}, {"text": "This choice is motivated by the fact that the KB stores information about real-world entities while many of the errors associated with coordination and apposition is the lack of knowledge of these real-world entities.", "labels": [], "entities": []}, {"text": "We begin by defining the task (section 2).", "labels": [], "entities": []}, {"text": "Following, we present the modified augmented-loss training framework (section 3).", "labels": [], "entities": []}, {"text": "In section 4, we define how the Knowledge Base data is integrated into the training process.", "labels": [], "entities": [{"text": "Knowledge Base data", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.7615606983502706}]}, {"text": "Finally, we discuss the empirical results (section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "The primary training corpus is composed of manually annotated sentences with syntactic tress which are converted to dependency format using the Stanford converter v1.6 (de).", "labels": [], "entities": []}, {"text": "We run experiments using 10k sentences or 70k sentences from this corpus.", "labels": [], "entities": []}, {"text": "The test set contains 16k manually syntactically annotated sentences crawled from the web.", "labels": [], "entities": []}, {"text": "The test and train sets are from different domains.", "labels": [], "entities": []}, {"text": "This setting may degrade the parser accuracy in labelling out-of-domain entities, as we discussed in section 2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9825882911682129}]}, {"text": "Thus, we use web text as secondary training set to be used for the Augmented-loss loss sample training.", "labels": [], "entities": []}, {"text": "Web text is available in any quantity, and we do not need to provide gold-standard parses in order to integrate it in the Augmented-loss sample training.", "labels": [], "entities": []}, {"text": "The classifier is trained on 10k sentences extracted from news text which has been automatically parsed.", "labels": [], "entities": []}, {"text": "We chose to train the classifier on news data as the quality of the automatic parses is much higher than on general web text.", "labels": [], "entities": []}, {"text": "We do this despite the fact that we will apply the classifier to a different domain (the web text).", "labels": [], "entities": []}, {"text": "As dependency parser, we use an implementation of the transition-based dependency parsing framework with the arc-eager transition strategy.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.7862467467784882}, {"text": "transition-based dependency parsing", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.657687912384669}]}, {"text": "The part of Augmented-loss training based on the standard loss function, applies the perceptron algorithm as in () with abeam size of 16.", "labels": [], "entities": []}, {"text": "The baseline is the same model but trained only the primary training corpus without Augmented-loss.", "labels": [], "entities": []}, {"text": "reports the results of the accuracy comparison.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9996722936630249}]}, {"text": "It reports the metrics for Labeled Attachment Score (LAS) and Unlabeled Attachment Score (UAS) to measure the overall accuracy.", "labels": [], "entities": [{"text": "Labeled Attachment Score (LAS)", "start_pos": 27, "end_pos": 57, "type": "METRIC", "confidence": 0.7910809814929962}, {"text": "Unlabeled Attachment Score (UAS)", "start_pos": 62, "end_pos": 94, "type": "METRIC", "confidence": 0.8634728093942007}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9981715679168701}]}, {"text": "The syntactic classes that are affected the most are apposition (appos) and conjunction (conj).", "labels": [], "entities": []}, {"text": "On the development set we measured that the percentage of arcs connecting 2 entities that are labeled as conjunction is 36.11%.", "labels": [], "entities": []}, {"text": "While those that are labelled as apposition is 25.06%.", "labels": [], "entities": [{"text": "apposition", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9528705477714539}]}, {"text": "Each of the other 40 labels cover a small portion of the remaining 38.83%.", "labels": [], "entities": []}, {"text": "Training the models with the full primary training corpus (70k sentences), shows a significant gain for the Augmented-loss model.", "labels": [], "entities": []}, {"text": "Apposition F1 gains 1.28, while conjunction gains 0.75.", "labels": [], "entities": [{"text": "Apposition", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9917368292808533}, {"text": "F1", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.557852029800415}, {"text": "conjunction", "start_pos": 32, "end_pos": 43, "type": "METRIC", "confidence": 0.9876322746276855}]}, {"text": "The LAS gain is mainly due to the gain of the two mentioned classes.", "labels": [], "entities": [{"text": "LAS gain", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9654090702533722}]}, {"text": "It is surprising to measure a similar gain also for the unlabeled accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.995863676071167}]}, {"text": "Since the classifier can correct the label of an arc but never change the structure of the parse.", "labels": [], "entities": []}, {"text": "This implies that just by penalizing a labeling action, the model learns to construct better parse structures.", "labels": [], "entities": []}, {"text": "Training the model with 10k sentences shows a significantly bigger gain on all the measures.", "labels": [], "entities": []}, {"text": "This results shows that, in cases where the set of labeled data is small, this approach can be applied to integrate in unlimited amount of unlabeled data to boost the learning.", "labels": [], "entities": []}], "tableCaptions": []}