{"title": [{"text": "Multi-class Animacy Classification with Semantic Features", "labels": [], "entities": [{"text": "Animacy Classification", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7658915817737579}]}], "abstractContent": [{"text": "Animacy is the semantic property of nouns denoting whether an entity can act, or is perceived as acting, of its own will.", "labels": [], "entities": [{"text": "Animacy is the semantic property of nouns denoting whether an entity can act, or is perceived as acting, of its own will", "start_pos": 0, "end_pos": 120, "type": "Description", "confidence": 0.7374264585475127}]}, {"text": "This property is marked grammatically in various languages, albeit rarely in English.", "labels": [], "entities": []}, {"text": "It has recently been highlighted as a relevant property for NLP applications such as parsing and anaphora resolution.", "labels": [], "entities": [{"text": "parsing", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.976659893989563}, {"text": "anaphora resolution", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.6842476427555084}]}, {"text": "In order for animacy to be used in conjunction with other semantic features for such applications , appropriate data is necessary.", "labels": [], "entities": []}, {"text": "However , the few corpora which do contain animacy annotation, rarely contain much other semantic information.", "labels": [], "entities": []}, {"text": "The addition of such an annotation layer to a corpus already containing deep semantic annotation should therefore be of particular interest.", "labels": [], "entities": []}, {"text": "The work presented in this paper contains three main contributions.", "labels": [], "entities": []}, {"text": "Firstly, we improve upon the state of the art in multi-class animacy classification.", "labels": [], "entities": [{"text": "multi-class animacy classification", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.7336547573407491}]}, {"text": "Secondly, we use this classifier to contribute to the annotation of an openly available corpus containing deep semantic annotation.", "labels": [], "entities": []}, {"text": "Finally, we provide source code, as well as trained models and scripts needed to reproduce the results presented in this paper, or aid in annotation of other texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Animacy is the semantic property of nouns denoting whether, or to what extent, the referent of that noun is alive, human-like or even cognitively sophisticated.", "labels": [], "entities": []}, {"text": "Several ways of characterising the animacy of such referents have been proposed in the literature, the most basic distinction being between animate and inanimate entities.", "labels": [], "entities": []}, {"text": "In such a binary scheme, examples of animate nouns might include author and dog, while examples of inanimate nouns might include table and rock.", "labels": [], "entities": []}, {"text": "More elaborate schemes tend to represent a hierarchy or continuum typically ranging from HU-MAN \u2192 NON-HUMAN \u2192 INANIMATE (cf.), with other categories in between.", "labels": [], "entities": [{"text": "INANIMATE", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9358523488044739}]}, {"text": "In various languages, animacy affects linguistic phenomena such as case marking and argument realization.", "labels": [], "entities": [{"text": "case marking", "start_pos": 67, "end_pos": 79, "type": "TASK", "confidence": 0.727878138422966}, {"text": "argument realization", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.71702441573143}]}, {"text": "Furthermore, hierarchical restrictions are often imposed by animacy, e.g. with subjects tending to be higher in an animacy hierarchy than objects (.", "labels": [], "entities": []}, {"text": "Even though animacy is rarely overtly marked in English, it still influences the choice of certain grammatical structures, such as the choice of relative pronouns (e.g. who vs. which).", "labels": [], "entities": []}, {"text": "The aims of this work are as follows: (i) to improve upon the state of the art in multi-class animacy classification by comparing and evaluating different classifiers and features for this task, (ii) to investigate whether a corpus of spoken language containing animacy annotation can be used as a basis to annotate animacy in a corpus of written language, (iii) to use the resulting classifier as part of the toolchain used to annotate a corpus containing deep semantic annotation.", "labels": [], "entities": [{"text": "multi-class animacy classification", "start_pos": 82, "end_pos": 116, "type": "TASK", "confidence": 0.7042207717895508}]}, {"text": "The remainder of this paper is organized as follows: In Section 2 we go through the relevance of animacy for Natural Language Processing (NLP) and describe some corpora which contain animacy annotation.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 109, "end_pos": 142, "type": "TASK", "confidence": 0.7112821340560913}]}, {"text": "Previous attempts and approaches to animacy classification are portrayed in Section 3.", "labels": [], "entities": [{"text": "animacy classification", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.9111941158771515}]}, {"text": "Section 4 contains an overview of the data used in this study, as well as details regarding the manual annotation of animacy carried out as part of this work.", "labels": [], "entities": []}, {"text": "The methods employed and the results obtained are presented in Sections 5 and 6.", "labels": [], "entities": []}, {"text": "The discussion is given in Section 7.", "labels": [], "entities": []}, {"text": "Finally, Section 8 contains conclusions and some suggestions for future work in multi-class animacy classification.", "labels": [], "entities": [{"text": "multi-class animacy classification", "start_pos": 80, "end_pos": 114, "type": "TASK", "confidence": 0.8134465217590332}]}], "datasetContent": [{"text": "We employ 10-fold cross validation for the evaluations on the Switchboard corpus.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.936840832233429}]}, {"text": "All NPs were automatically extracted from the pre-processed corpus, put into random order and divided into ten equally-sized folds.", "labels": [], "entities": []}, {"text": "In each of the ten cross validation iterations, one of these folds was left out and used for evaluation.", "labels": [], "entities": [{"text": "cross validation iterations", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.7193397680918375}]}, {"text": "For the sake of conciseness, averaged results overall classes are given in the comparisons of Section 6.1.1 and Section 6.1.2, whereas detailed results are only given for the best performing classifier.", "labels": [], "entities": [{"text": "Section 6.1.1", "start_pos": 94, "end_pos": 107, "type": "DATASET", "confidence": 0.9153480231761932}, {"text": "Section 6.1.2", "start_pos": 112, "end_pos": 125, "type": "DATASET", "confidence": 0.9411522746086121}]}, {"text": "Note that the training data from Wordrobe is not used for the evaluations on the Switchboard corpus, as this would prohibit fair evaluation with previous work.", "labels": [], "entities": [{"text": "Wordrobe", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.8593841791152954}, {"text": "Switchboard corpus", "start_pos": 81, "end_pos": 99, "type": "DATASET", "confidence": 0.9065966308116913}]}, {"text": "We first ran experiments to evaluate which of the classifiers performed the best on this task.", "labels": [], "entities": []}, {"text": "shows the average accuracy for each classifier, using 10-fold cross validation on the Switchboard corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994999170303345}, {"text": "Switchboard corpus", "start_pos": 86, "end_pos": 104, "type": "DATASET", "confidence": 0.9417780339717865}]}, {"text": "contains the per-class results from the cross validation performed with the best performing classifier, namely the Logistic Regression classifier.", "labels": [], "entities": []}, {"text": "The remaining evaluations in this paper are all carried outwith this classifier.", "labels": [], "entities": []}, {"text": "Average accuracy over the 10 folds was 85.8%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9970760345458984}]}, {"text": "This is well above the baseline of always picking the most common class (HUM), which results in an accuracy of 45.3%.", "labels": [], "entities": [{"text": "HUM)", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9240988492965698}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.999599277973175}]}, {"text": "More interestingly, this is somewhat higher than the best results for this dataset reported in the literature (84.9% without cross validation (Bowman and Chopra, 2012)).", "labels": [], "entities": []}, {"text": "Using the best performing classifier, we ran experiments to evaluate how different features affect the results.", "labels": [], "entities": []}, {"text": "These experiments were also performed using 10-fold cross validation on the Switchboard corpus.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.9668457806110382}]}, {"text": "shows scores from using only one feature in addition to the lemma and PoS of the head of the NP to be classified.", "labels": [], "entities": [{"text": "PoS", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9900471568107605}]}, {"text": "Although none of the features in isolation add much to the performance of the classifier, some marginal gains can be observed.", "labels": [], "entities": []}, {"text": "Since one of the purposes of the development of this classifier was to include it in the tools used in the tagging of the GMB, we also present the first results in the literature for the animacy annotation of this corpus.", "labels": [], "entities": [{"text": "tagging of the GMB", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.6936173290014267}, {"text": "animacy annotation", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.7447217404842377}]}, {"text": "Due to the limited size of the portion of this corpus for which animacy tags have been manually corrected, no cross-validation was performed.", "labels": [], "entities": []}, {"text": "However, due to the high differences in the training data from the Switchboard corpus, and the evaluation data in the GMB, the results could be seen as a lower bound for this classifier on this data set.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.8738146126270294}, {"text": "GMB", "start_pos": 118, "end_pos": 121, "type": "DATASET", "confidence": 0.9749466776847839}]}, {"text": "contains the results from this evaluation.", "labels": [], "entities": []}, {"text": "The accuracy on this dataset was 79.4%, which can be compared to a most frequent class baseline of 37.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999808132648468}]}], "tableCaptions": [{"text": " Table 2: Annotation statistics for p00 of the GMB", "labels": [], "entities": [{"text": "GMB", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.5571354031562805}]}, {"text": " Table 4: Results from 10-fold cross validation on the Switchboard corpus and evaluation on the GMB.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 55, "end_pos": 73, "type": "DATASET", "confidence": 0.9098656475543976}, {"text": "GMB", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.9759035110473633}]}, {"text": " Table 6: Main results from all conditions. B&C  (2012) refers to Bowman & Chopra (2012).", "labels": [], "entities": [{"text": "B&C  (2012)", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.7772710124651591}, {"text": "Bowman & Chopra (2012)", "start_pos": 66, "end_pos": 88, "type": "DATASET", "confidence": 0.8994661172231039}]}]}