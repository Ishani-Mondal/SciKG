{"title": [{"text": "Dependency Tree Abstraction for Long-Distance Reordering in Statistical Machine Translation", "labels": [], "entities": [{"text": "Abstraction", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.977141797542572}, {"text": "Long-Distance Reordering", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6197278797626495}, {"text": "Statistical Machine Translation", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.7376509110132853}]}], "abstractContent": [{"text": "Word reordering is a crucial technique in statistical machine translation in which syntactic information plays an important role.", "labels": [], "entities": [{"text": "Word reordering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7324110716581345}, {"text": "statistical machine translation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7105103433132172}]}, {"text": "Synchronous context-free grammar has typically been used for this purpose with various modifications for adding flexibilities to its synchronized tree generation.", "labels": [], "entities": []}, {"text": "We permit further flexibilities in the synchronous context-free grammar in order to translate between languages with drastically different word order.", "labels": [], "entities": []}, {"text": "Our method pre-processes a parallel corpus by abstracting source-side dependency trees, and performs long-distance reordering on top of an off-the-shelf phrase-based system.", "labels": [], "entities": []}, {"text": "Experimental results show that our method significantly outperforms previous phrase-based and syntax-based models for translation between English and Japanese.", "labels": [], "entities": [{"text": "translation between English and Japanese", "start_pos": 118, "end_pos": 158, "type": "TASK", "confidence": 0.8694417476654053}]}], "introductionContent": [{"text": "Since the inception of statistical machine translation (SMT), long-distance word reordering has been a notable challenge, particularly when translating between languages with drastically different word orders, such as subject-verb-object (SVO) and subject-object-verb (SOV) languages like English and Japanese, respectively.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.7942325721184412}, {"text": "word reordering", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7338874042034149}]}, {"text": "Phrase-based models () have been strong in local translation and reordering.", "labels": [], "entities": [{"text": "local translation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.5874707847833633}]}, {"text": "However, phrase-based models cannot effectively conduct long-distance reordering because they are based purely on statistics of syntax-independent phrases.", "labels": [], "entities": []}, {"text": "As a complementary approach to phrase-based models, some researchers have incorporated syntactic information into an SMT framework (; ) using synchronous context-free grammar (SCFG) (Aho and when the fluid pressure cylinder 31 is used, fluid is gradually applied..", "labels": [], "entities": [{"text": "SMT", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9824946522712708}]}, {"text": "The original SCFG assumes that the syntactic trees of the source and target languages can be derived synchronously.", "labels": [], "entities": []}, {"text": "However, this assumption is too strict for handling parallel sentences that are often comparable rather than parallel.", "labels": [], "entities": []}, {"text": "For alleviating this assumption, some researchers have added flexibilities in synchronized tree generation.", "labels": [], "entities": []}, {"text": "In addition, in the SMT framework, there is an approach that alleviates the assumption by only generating the source-side syntactic tree and projecting it to the target-side sentence).", "labels": [], "entities": [{"text": "SMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9873249530792236}]}, {"text": "In practice, these existing methods are not flexible enough to handle parallel sentence pairs, especially those of SVO and SOV languages.", "labels": [], "entities": []}, {"text": "Therefore, we permit further flexibility in SCFG aiming to effectively conduct long-distance reordering.", "labels": [], "entities": []}, {"text": "We design our method as a pre-processing procedure so that we can use a well-developed phrasebased system without adding heavy computational complexity to the system.", "labels": [], "entities": []}, {"text": "Specifically, we propose an abstraction tree that is a shallow and nested representation, i.e., abstraction of the dependency tree as depicts.", "labels": [], "entities": []}, {"text": "Our method pre-processes a parallel corpus by generating source-side abstraction trees and projecting the trees onto the targetside sentences.", "labels": [], "entities": []}, {"text": "It then decomposes the corpus by collecting corresponding node pairs as anew corpus, and finally trains the phrase-based model.", "labels": [], "entities": []}, {"text": "In this manner, the source-side grammar is determined on the fly for each sentence based on a de-pendency parse of the source sentence.", "labels": [], "entities": []}, {"text": "The target side of each production in the grammar is determined by running the phrase-based decoder.", "labels": [], "entities": []}, {"text": "We empirically show effectiveness of our method for English-to-Japanese and Japanese-toEnglish translations by comparing it to phrasebased and syntax-based models.", "labels": [], "entities": []}, {"text": "Experimental results show that our method significantly outperforms the previous methods with respect to the BLEU () metric.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9974926710128784}]}], "datasetContent": [{"text": "We evaluate our method in English-to-Japanese (EJ) and Japanese-to-English (JE) translation tasks, since long-distance reordering is a serious problem in this language pair.", "labels": [], "entities": [{"text": "Japanese-to-English (JE) translation tasks", "start_pos": 55, "end_pos": 97, "type": "TASK", "confidence": 0.6664690723021826}]}, {"text": "We use NTCIR-7 PATMT (), a publicly available standard evaluation dataset, for EJ and JE machine translation.", "labels": [], "entities": [{"text": "NTCIR-7", "start_pos": 7, "end_pos": 14, "type": "DATASET", "confidence": 0.8813292384147644}, {"text": "PATMT", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.6663811206817627}, {"text": "JE machine translation", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.705082893371582}]}, {"text": "The dataset is constructed using English and Japanese patents and consists of 1.8 million parallel sentence pairs for training, 915 sentence pairs for development, and 1, 381 sentence pairs for testing.", "labels": [], "entities": []}, {"text": "The development and test sets have one reference per sentence.", "labels": [], "entities": []}, {"text": "This dataset is bidirectional and can be used for both EJ and JE translation evaluation.", "labels": [], "entities": [{"text": "JE translation evaluation", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.8829968969027201}]}], "tableCaptions": [{"text": " Table 1: Test-set BLEU scores. The symbol  *  *  represents", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9913334250450134}]}, {"text": " Table 2: Effect of threshold \u03b3", "labels": [], "entities": []}, {"text": " Table 3: Error distribution in 100 samples of EJ translation", "labels": [], "entities": [{"text": "Error distribution", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9732730090618134}]}]}