{"title": [{"text": "Bilingual Sentiment Consistency for Statistical Machine Translation", "labels": [], "entities": [{"text": "Bilingual Sentiment Consistency", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8502983450889587}, {"text": "Statistical Machine Translation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.8708284099896749}]}], "abstractContent": [{"text": "In this paper, we explore bilingual sentiment knowledge for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "bilingual sentiment knowledge", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.7605645259221395}, {"text": "statistical machine translation (SMT)", "start_pos": 60, "end_pos": 97, "type": "TASK", "confidence": 0.8100520124038061}]}, {"text": "We propose to explicitly model the consistency of sentiment between the source and target side with a lexicon-based approach.", "labels": [], "entities": []}, {"text": "The experiments show that the proposed model significantly improves Chinese-to-English NIST translation over a competitive baseline.", "labels": [], "entities": [{"text": "NIST translation", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.7787118554115295}]}], "introductionContent": [{"text": "The expression of sentiment is an interesting and integral part of human languages.", "labels": [], "entities": []}, {"text": "In written text sentiment is conveyed by senses and in speech also via prosody.", "labels": [], "entities": []}, {"text": "Sentiment is associated with both evaluative (positive or negative) and potency (degree of sentiment) -involving two of the three major semantic differential categories identified by.", "labels": [], "entities": []}, {"text": "Automatically analyzing the sentiment of monolingual text has attracted a large bulk of research, which includes, but is not limited to, the early exploration of.", "labels": [], "entities": []}, {"text": "Since then, research has involved a variety of approaches and been conducted on various type of data, e.g., product reviews, news, blogs, and the more recent social media text.", "labels": [], "entities": []}, {"text": "As sentiment has been an important concern in monolingual settings, better translation of such information between languages could be of interest to help better cross language barriers, particularly for sentiment-abundant data.", "labels": [], "entities": []}, {"text": "Even when we randomly sampled a subset of sentence pairs from the NIST Open MT 1 training data, we found that about 48.2% pairs contain at least one sentiment word on both sides, and 22.4% pairs contain at least one 1 http://www.nist.gov/speech/tests/mt intensifier word on both sides, which suggests a non-trivial percent of sentences may potentially involve sentiment in some degree  One expects that sentiment has been implicitly captured in SMT through the statistics learned from parallel corpus, e.g., the phrase tables in a phrase-based system.", "labels": [], "entities": [{"text": "NIST Open MT 1 training data", "start_pos": 66, "end_pos": 94, "type": "DATASET", "confidence": 0.8157233198483785}, {"text": "SMT", "start_pos": 445, "end_pos": 448, "type": "TASK", "confidence": 0.989698588848114}]}, {"text": "In this paper, we are interested in explicitly modeling sentiment knowledge for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.9759531021118164}]}, {"text": "We propose a lexicon-based approach that examines the consistency of bilingual subjectivity, sentiment polarity, intensity, and negation.", "labels": [], "entities": []}, {"text": "The experiments show that the proposed approach improves the NIST Chinese-to-English translation over a strong baseline.", "labels": [], "entities": [{"text": "NIST Chinese-to-English translation", "start_pos": 61, "end_pos": 96, "type": "TASK", "confidence": 0.7240915099779764}]}, {"text": "In general, we hope this line of work will help achieve better MT quality, especially for data with more abundant sentiment, such as social media text.", "labels": [], "entities": [{"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9956859350204468}]}, {"text": "The granularities of text have spanned from words and phrases to passages and documents.", "labels": [], "entities": []}, {"text": "Sentiment analysis has been approached mainly as an unsupervised or supervised problem, although the middle ground, semi-supervised approaches, exists.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9581884145736694}]}, {"text": "In this paper, we take a lexiconbased, unsupervised approach to considering sentiment consistency for translation, although the translation system itself is supervised.", "labels": [], "entities": [{"text": "translation", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.9763017296791077}]}, {"text": "The advantages of such an approach have been discussed in ().", "labels": [], "entities": []}, {"text": "Briefly, it is good at capturing the basic sentiment expressions common to different domains, and certainly it requires no bilingual sentiment-annotated data for our study.", "labels": [], "entities": []}, {"text": "It suits our purpose hereof exploring the basic role of sentiment for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.9580845832824707}]}, {"text": "Also, such a method has been reported to achieve a good cross-domain performance) comparable with that of other state-of-the-art models.", "labels": [], "entities": []}, {"text": "Translation for sentiment analysis Avery interesting line of research has leveraged labeled data in a resource-rich language (e.g., English) to help sentiment analysis in a resource-poorer language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.9703962504863739}, {"text": "sentiment analysis", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.9326985478401184}]}, {"text": "This includes the idea of constructing sentiment lexicons automatically by using a translation dictionary (, as well as the idea of utilizing parallel corpora or automatically translated documents to incorporate sentiment-labeled data from different languages).", "labels": [], "entities": []}, {"text": "Our concern here is different -instead of utilizing translation for sentiment analysis; we are interested in the SMT quality itself, by modeling bilingual sentiment in translation.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8815270960330963}, {"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9952646493911743}]}, {"text": "As mentioned above, while we expect that statistics learned from parallel corpora have implicitly captured sentiment in some degree, we are curious if better modeling is possible.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were carried outwith an in-house phrase-based system similar to Moses (.", "labels": [], "entities": []}, {"text": "Each corpus was word-aligned using IBM model 2, HMM, and IBM model 4, and the phrase table was the union of phrase pairs extracted from these separate alignments, with a length limit of 7.", "labels": [], "entities": [{"text": "IBM model 4", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.8933401902516683}]}, {"text": "The translation model was smoothed in both directions with Kneser-Ney smoothing).", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9618000984191895}]}, {"text": "We use the hierarchical lexicalized reordering model (, with a distortion limit of 7.", "labels": [], "entities": []}, {"text": "Other features include lexical weighting in both directions, word count, a distance-based RM, a 4-gram LM trained on the target side of the parallel data, and a 6-gram English Gigaword LM.", "labels": [], "entities": []}, {"text": "The system was tuned with batch lattice MIRA (Cherry and Foster, 2012).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9954332113265991}]}, {"text": "We conducted experiments on NIST Chinese-toEnglish translation task.", "labels": [], "entities": [{"text": "NIST Chinese-toEnglish translation task", "start_pos": 28, "end_pos": 67, "type": "TASK", "confidence": 0.7829996198415756}]}, {"text": "The training data are from NIST Open MT 2012.", "labels": [], "entities": [{"text": "NIST Open MT 2012", "start_pos": 27, "end_pos": 44, "type": "DATASET", "confidence": 0.9149503409862518}]}, {"text": "All allowed bilingual corpora were used to train the translation model and reordering models.", "labels": [], "entities": []}, {"text": "There are about 283M target word tokens.", "labels": [], "entities": []}, {"text": "The development (dev) set comprised mainly data from the NIST 2005 test set, and also some balanced-genre web-text from NIST training data.", "labels": [], "entities": [{"text": "NIST 2005 test set", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.9814659655094147}, {"text": "NIST training data", "start_pos": 120, "end_pos": 138, "type": "DATASET", "confidence": 0.9115941325823466}]}, {"text": "Evaluation was performed on NIST 2006 and 2008, which have 1,664 and 1,357 sentences, 39.7K and 33.7K source words respectively.", "labels": [], "entities": [{"text": "NIST 2006", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.9685397744178772}]}, {"text": "Four references were provided for all dev and test sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Percentages of sentence pairs that contain sen- timent words on both sides or intensifiers 3 on both sides.", "labels": [], "entities": []}, {"text": " Table 4: BLEU(%) scores on two original test sets for  different feature combinations. The sign * and ** indi- cate statistically significant gains over the baseline at  the p < 0.05 and p < 0.01 level, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994445443153381}]}, {"text": " Table 5: BLEU(%) scores on three sub test sets with  different sentiment ratios.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.99951171875}]}, {"text": " Table 6: BLEU(%) scores on two original test sets on  sentence-level sentiment features.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994404911994934}, {"text": "sentence-level sentiment", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.6776333451271057}]}]}