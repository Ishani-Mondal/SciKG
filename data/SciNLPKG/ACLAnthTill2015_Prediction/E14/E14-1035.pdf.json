{"title": [{"text": "Dynamic Topic Adaptation for Phrase-based MT", "labels": [], "entities": [{"text": "Dynamic Topic Adaptation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6632275581359863}, {"text": "MT", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.625342845916748}]}], "abstractContent": [{"text": "Translating text from diverse sources poses a challenge to current machine translation systems which are rarely adapted to structure beyond corpus level.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7693945467472076}]}, {"text": "We explore topic adaptation on a diverse data set and present anew bilingual variant of Latent Dirichlet Allocation to compute topic-adapted, probabilistic phrase translation features.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7898111343383789}, {"text": "phrase translation", "start_pos": 156, "end_pos": 174, "type": "TASK", "confidence": 0.7423394620418549}]}, {"text": "We dynamically infer document-specific translation probabilities for test sets of unknown origin, thereby capturing the effects of document context on phrase translations.", "labels": [], "entities": [{"text": "phrase translations", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.7169880867004395}]}, {"text": "We show gains of up to 1.26 BLEU over the base-line and 1.04 over a domain adaptation benchmark.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9988614320755005}]}, {"text": "We further provide an analysis of the domain-specific data and show additive gains of our model in combination with other types of topic-adapted features.", "labels": [], "entities": []}], "introductionContent": [{"text": "In statistical machine translation (SMT), there has been a lot of interest in trying to incorporate information about the provenance of training examples in order to improve translations for specific target domains.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8293677071730295}]}, {"text": "A popular approach are mixture models where each component contains data from a specific genre or domain.", "labels": [], "entities": []}, {"text": "Mixture models can be trained for crossdomain adaption when the target domain is known or for dynamic adaptation when the target domain is inferred from the source text under translation.", "labels": [], "entities": [{"text": "crossdomain adaption", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.8304124474525452}, {"text": "dynamic adaptation", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7482283711433411}]}, {"text": "More recent domain adaptation methods employ corpus or instance weights to promote relevant training examples ( or do more radical data selection based on language model perplexity.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7656231820583344}]}, {"text": "In this work, we are interested in the dynamic adaptation case, which is challenging because we cannot tune our model towards any specific domain.", "labels": [], "entities": []}, {"text": "In previous literature, domains have often been loosely defined in terms of corpora, for example, news texts would be defined as belonging to the news domain, ignoring the specific content of news documents.", "labels": [], "entities": []}, {"text": "It is often assumed that the data within a domain is homogeneous in terms of style and vocabulary, though that is not always true in practice.", "labels": [], "entities": []}, {"text": "The term topic on the other hand can describe the thematic content of a document (e.g. politics, economy, medicine) or a latent cluster in a topic model.", "labels": [], "entities": []}, {"text": "Topic modelling for machine translation aims to find a match between thematic context and topic clusters.", "labels": [], "entities": [{"text": "Topic modelling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7906988561153412}, {"text": "machine translation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7853342890739441}]}, {"text": "We view topic adaptation as fine-grained domain adaptation with the implicit assumption that there can be multiple distributions over translations within the same data set.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.788233608007431}]}, {"text": "If these distributions overlap, then we expect topic adaptation to help separate them and yield better translations than an unadapted system.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7573696374893188}]}, {"text": "Topics can be of varying granularity and are therefore a flexible means to structure data that is not uniform enough to be modelled in its entirety.", "labels": [], "entities": []}, {"text": "In recent years there have been several attempts to integrating topical information into SMT either by learning better word alignments (), by adapting translation features cross-domain (, or by dynamically adapting lexical weights) or adding sparse topic features).", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9859064817428589}, {"text": "word alignments", "start_pos": 119, "end_pos": 134, "type": "TASK", "confidence": 0.6945520043373108}]}, {"text": "We take anew approach to topic adaptation by estimating probabilistic phrase translation features in a completely Bayesian fashion.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.8600651323795319}, {"text": "estimating probabilistic phrase translation", "start_pos": 45, "end_pos": 88, "type": "TASK", "confidence": 0.6726839244365692}]}, {"text": "The motivation is that automatically identifying topics in the training data can help to select the appropriate translation of a source phrase in the context of a document.", "labels": [], "entities": []}, {"text": "By adapting a system to automatically induced topics we do not have to trust data from a given domain to be uniform.", "labels": [], "entities": []}, {"text": "We also overcome the problem of defining the level of granularity for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7125916928052902}]}, {"text": "With more and more training data automatically extracted from the web and little knowledge about its content, we believe this is an important area to focus on.", "labels": [], "entities": []}, {"text": "Translation of web sites is already a popular application for MT systems and could be helped by dynamic model adaptation.", "labels": [], "entities": [{"text": "Translation of web sites", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.894763857126236}, {"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9899985194206238}]}, {"text": "We present results on a mixed data set of the TED corpus, parts of the Commoncrawl corpus which contains crawled web data and parts of the News Commentary corpus which contains documents about politics and economics.", "labels": [], "entities": [{"text": "TED corpus", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.9079135656356812}, {"text": "Commoncrawl corpus", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.9849079847335815}, {"text": "News Commentary corpus", "start_pos": 139, "end_pos": 161, "type": "DATASET", "confidence": 0.8283699949582418}]}, {"text": "We believe that the broad range of this data set makes it a suitable testbed for topic adaptation.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.908424437046051}]}, {"text": "We focus on translation model adaptation to learn how words and phrases translate in a given document-context without knowing the origin of the document.", "labels": [], "entities": [{"text": "translation model adaptation", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.9231938322385153}]}, {"text": "By learning translations over latent topics and combining several topic-adapted features we achieve improvements of more than 1 BLEU point.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9992637038230896}]}], "datasetContent": [{"text": "Our experiments were carried out on a mixed data set, containing the TED corpus (), parts of the News Commentary corpus (NC) and parts of the Commoncrawl corpus (CC) from the WMT13 shared task (Bojar et al., 2013) as described in.", "labels": [], "entities": [{"text": "TED corpus", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.9001412987709045}, {"text": "News Commentary corpus (NC)", "start_pos": 97, "end_pos": 124, "type": "DATASET", "confidence": 0.857751468817393}, {"text": "Commoncrawl corpus (CC)", "start_pos": 142, "end_pos": 165, "type": "DATASET", "confidence": 0.9358636975288391}, {"text": "WMT13 shared task", "start_pos": 175, "end_pos": 192, "type": "DATASET", "confidence": 0.7167419592539469}]}, {"text": "We were guided by two constraints in chosing our data set.", "labels": [], "entities": []}, {"text": "1) the data has document boundaries and the content of each document is assumed to be topically related, 2) there is some degree of topical variation within each data set.", "labels": [], "entities": []}, {"text": "In order to compare to domain adaptation approaches, we chose a setup with data from different corpora.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7264860719442368}]}, {"text": "We want to abstract away from adaptation effects that concern tuning of length penalties and language models, so we use a mixed tuning set containing data from all three domains and train one language model on the concatenation of (equally sized) target sides of the training data.", "labels": [], "entities": []}, {"text": "Word alignments are trained on the concatenation of all training data and fixed for all models.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6927888691425323}]}, {"text": "Our baseline (ALL) is a phrase-based FrenchEnglish system trained on the concatenation of all parallel data.", "labels": [], "entities": [{"text": "FrenchEnglish", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.90767502784729}]}, {"text": "It was built with the Moses toolkit () using the 14 standard core features including a 5gram language model.", "labels": [], "entities": []}, {"text": "Translation quality is evaluated on a large test set, using the average feature weights of three optimisation runs with PRO ( shows BLEU scores of the baseline system as well as the performance of three in-domain models (IN) tuned under the same conditions.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9537941217422485}, {"text": "PRO", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.9876459240913391}, {"text": "BLEU", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9992005228996277}]}, {"text": "For the IN models, every portion of the test set is decoded with a domain-specific model.", "labels": [], "entities": []}, {"text": "Results on the test set are broken down by domain but also reported for the entire test set (mixed).", "labels": [], "entities": []}, {"text": "For Ted and NC, the in-domain models perform better than ALL, while for CC the all-domain model improves quite significantly over IN.", "labels": [], "entities": [{"text": "IN", "start_pos": 130, "end_pos": 132, "type": "METRIC", "confidence": 0.9375951886177063}]}], "tableCaptions": [{"text": " Table 1: Number of sentence pairs and documents  (in brackets) in the French-English data sets. The  training data has 2.7M English words per domain.", "labels": [], "entities": [{"text": "French-English data sets", "start_pos": 71, "end_pos": 95, "type": "DATASET", "confidence": 0.8724470734596252}]}, {"text": " Table 2: BLEU of in-domain and baseline models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989689588546753}]}, {"text": " Table 3: Average JSD of IN vs. ALL models.  Rank1-diff: % PT entries where preferred transla- tion changes.", "labels": [], "entities": [{"text": "PT entries", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.972156435251236}]}, {"text": " Table 5: BLEU scores of pLDA features (50 top- ics), separately and combined.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986578226089478}]}, {"text": " Table 6: BLEU scores of baseline and topic- adapted systems (pLDA) with all 4 features and  largest improvements over baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9984803795814514}]}, {"text": " Table 7: Comparison of best pLDA system with  two domain-aware benchmark systems.", "labels": [], "entities": []}, {"text": " Table 8: Combination of all models with addi- tional LM adaptation (pLDA: 50 topics).", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.7046851813793182}]}, {"text": " Table 7. Both FILLUP and LIN-TM improve over  the ALL model on the mixed test set, by 0.26 and  0.38 BLEU respectively. The largest improvement  is on TED while on the CC domain, FILLUP de- creases in performance and LIN-TM yields no im- provement either. This shows that relying on in- domain distributions for adaptation to a noisy and  diverse domain like CC is problematic. The pLDA  model yields the largest improvement over the  domain-adapted systems on the CC test set, with  in increase of 1.04 BLEU over FILLUP and 0.79  over LIN-TM. The improvements on the other two  domains are smaller but consistent.", "labels": [], "entities": [{"text": "FILLUP", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.6246639490127563}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9969411492347717}, {"text": "TED", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.9771518111228943}, {"text": "FILLUP de- creases", "start_pos": 180, "end_pos": 198, "type": "METRIC", "confidence": 0.866529181599617}, {"text": "CC test set", "start_pos": 466, "end_pos": 477, "type": "DATASET", "confidence": 0.7964333693186442}, {"text": "BLEU", "start_pos": 505, "end_pos": 509, "type": "METRIC", "confidence": 0.9946704506874084}, {"text": "FILLUP", "start_pos": 515, "end_pos": 521, "type": "METRIC", "confidence": 0.9065999388694763}]}, {"text": " Table 9: Average entropy of translation distribu- tions and test set perplexity of the adapted model.", "labels": [], "entities": []}]}