{"title": [{"text": "Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality", "labels": [], "entities": [{"text": "Machine Reading Tea Leaves", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7064747661352158}]}], "abstractContent": [{"text": "Topic models based on latent Dirichlet allocation and related methods are used in a range of user-focused tasks including document navigation and trend analysis, but evaluation of the intrinsic quality of the topic model and topics remains an open research area.", "labels": [], "entities": [{"text": "document navigation", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7691005766391754}, {"text": "trend analysis", "start_pos": 146, "end_pos": 160, "type": "TASK", "confidence": 0.7237206250429153}]}, {"text": "In this work, we explore the two tasks of automatic evaluation of single topics and automatic evaluation of whole topic models, and provide recommendations on the best strategy for performing the two tasks, in addition to providing an open-source toolkit for topic and topic model evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic modelling based on Latent Dirichlet Allocation (LDA:) and related methods is increasingly being used in user-focused tasks, in contexts such as the evaluation of scientific impact, trend analysis () and document search ().", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA:)", "start_pos": 25, "end_pos": 59, "type": "METRIC", "confidence": 0.8305131296316782}, {"text": "trend analysis", "start_pos": 187, "end_pos": 201, "type": "TASK", "confidence": 0.7003244906663895}, {"text": "document search", "start_pos": 209, "end_pos": 224, "type": "TASK", "confidence": 0.7336930632591248}]}, {"text": "The LDA model is based on the assumption that document collections have latent topics, in the form of a multinomial distribution of words, which is typically presented to users via its top-N highestprobability words.", "labels": [], "entities": []}, {"text": "In NLP, topic models are generally used as a means of preprocessing a document collection, and the topics and per-document topic allocations are fed into downstream applications such as document summarisation, novel word sense detection methods () and machine translation (.", "labels": [], "entities": [{"text": "document summarisation", "start_pos": 186, "end_pos": 208, "type": "TASK", "confidence": 0.6675821840763092}, {"text": "word sense detection", "start_pos": 216, "end_pos": 236, "type": "TASK", "confidence": 0.6588533123334249}, {"text": "machine translation", "start_pos": 252, "end_pos": 271, "type": "TASK", "confidence": 0.7966981530189514}]}, {"text": "In fields such as the digital humanities, on the other hand, human users interact directly with the output of topic models.", "labels": [], "entities": []}, {"text": "It is this context of topic modelling for direct human consumption that we target in this paper.", "labels": [], "entities": []}, {"text": "The topics produced by topic models have a varying degree of human-interpretability.", "labels": [], "entities": []}, {"text": "To illustrate this, we present two topics automatically learnt from a collection of news articles: 1.", "labels": [], "entities": []}, {"text": "farmers, farm, food, rice, agriculture 2.", "labels": [], "entities": []}, {"text": "stories, undated, receive, scheduled, clients The first topic is clearly related to agriculture.", "labels": [], "entities": []}, {"text": "The subject of the second topic, however, is less clear, and may confuse users if presented to them as part of a larger topic model.", "labels": [], "entities": []}, {"text": "Measuring the human-interpretability of topics and the overall topic model is the core topic of this paper.", "labels": [], "entities": []}, {"text": "Various methodologies have been proposed for measuring the semantic interpretability of topics.", "labels": [], "entities": [{"text": "semantic interpretability of topics", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.7895628660917282}]}, {"text": "In, the authors proposed an indirect approach based on word intrusion, where \"intruder words\" are randomly injected into topics and human users are asked to identify the intruder words.", "labels": [], "entities": []}, {"text": "The word intrusion task builds on the assumption that the intruder words are more identifiable in coherent topics than in incoherent topics, and thus the interpretability of a topic can be estimated by measuring how readily the intruder words can be manually identified by annotators.", "labels": [], "entities": []}, {"text": "Since its inception, the method of has been used variously as a means of assessing topic models ().", "labels": [], "entities": []}, {"text": "Despite its wide acceptance, the method relies on manual annotation and has never been automated.", "labels": [], "entities": []}, {"text": "This is one of the primary contributions of this work: the demonstration that we can automate the method of at near-human levels of accuracy, as a result of which we can perform automatic evaluation of the human-interpretability of topics, as well as topic models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9973320960998535}]}, {"text": "There has been prior work to directly estimate the human-interpretability of topics through automatic means.", "labels": [], "entities": []}, {"text": "For example,  introduced the notion of topic \"coherence\", and proposed an automatic method for estimating topic coherence based on pairwise pointwise mutual information (PMI) between the topic words.", "labels": [], "entities": []}, {"text": "similarly introduced a methodology for computing coherence, replacing PMI with log conditional probability.", "labels": [], "entities": []}, {"text": "incorporated the WordNet hierarchy to capture the relevance of topics, and in, the authors proposed the use of distributional similarity for computing the pairwise association of the topic words.", "labels": [], "entities": []}, {"text": "One application of these methods has been to remove incoherent topics before generating labels for topics (.", "labels": [], "entities": []}, {"text": "Ultimately, all these methodologies, and also the word intrusion approach, attempt to assess the same quality: the human-interpretability of topics.", "labels": [], "entities": []}, {"text": "The relationship between these methodologies, however, is poorly understood, and there is no consensus on what is the best approach for computing the semantic interpretability of topic models.", "labels": [], "entities": [{"text": "computing the semantic interpretability of topic models", "start_pos": 136, "end_pos": 191, "type": "TASK", "confidence": 0.7349495036261422}]}, {"text": "This is a second contribution of this paper: we perform a systematic empirical comparison of the different methods and find appreciable differences between them.", "labels": [], "entities": []}, {"text": "We further goon to propose an improved formulation of  based on normalised PMI.", "labels": [], "entities": []}, {"text": "Finally, we release a toolkit which implements the topic interpretability measures described in this paper.", "labels": [], "entities": [{"text": "topic interpretability", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.6281821876764297}]}, {"text": "challenged the conventional wisdom that held-out likelihood -often computed as the perplexity of test data or unseen documents -is the only way to evaluate topic models.", "labels": [], "entities": []}, {"text": "To measure the human-interpretability of topics, the authors proposed a word intrusion task and conducted experiments using three topic models: Latent Dirichlet Allocation (LDA:), Probabilistic Latent Semantic Indexing (PLSI: Hofmann (1999)) and the Correlated Topic Model (CTM:).", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA:)", "start_pos": 144, "end_pos": 178, "type": "METRIC", "confidence": 0.8618234495321909}]}, {"text": "Contrary to expectation, they found that perplexity correlates negatively with topic interpretability.", "labels": [], "entities": [{"text": "topic interpretability", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.6560689210891724}]}], "datasetContent": [{"text": "As one of the primary foci of this paper is the automation of the intruder word task of, our primary dataset is that used in the original paper by, which provides topics and human annotations fora range of 531 domains and topic model types.", "labels": [], "entities": []}, {"text": "In the dataset, two text collections were used: (1) 10,000 articles from English Wikipedia (WIKI); and (2) 8,447 articles from the New York Times dating from 1987 to 2007 (NEWS).", "labels": [], "entities": [{"text": "English Wikipedia (WIKI)", "start_pos": 73, "end_pos": 97, "type": "DATASET", "confidence": 0.8908110737800599}]}, {"text": "For each document collection, topics were generated by three topic modelling methods: LDA, PLSI and CTM (see Section 2).", "labels": [], "entities": []}, {"text": "For each topic model, three settings of T (the number of topics) were used: T = 50, T = 100 and T = 150.", "labels": [], "entities": [{"text": "T", "start_pos": 40, "end_pos": 41, "type": "METRIC", "confidence": 0.9710889458656311}]}, {"text": "In total, there were 9 topic models (3 models \u00d7 3 T ) and 900 topics (3 models \u00d7 (50 + 100 + 150)) for each dataset.", "labels": [], "entities": []}, {"text": "For some of topic interpretability estimation methods, we require a reference corpus to sample lexical probabilities.", "labels": [], "entities": [{"text": "topic interpretability estimation", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.6792897880077362}]}, {"text": "We use two reference corpora: (1) NEWS-FULL, which contains 1.2 million New York Times articles from 1994 to 2004 (from the English Gigaword); and (2) WIKI-FULL, which contains 3.3 million English Wikipedia articles (retrieved November 28th 2009).", "labels": [], "entities": [{"text": "NEWS-FULL", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.8783082365989685}]}, {"text": "The rationale for choosing the New York Times and English Wikipedia as the reference corpora is to ensure domain consistency with the word intrusion dataset; the full collections are used to more robustly estimate lexical probabilities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pearson correlation of WI-Human and WI-Auto-PMI/WI-Auto-NPMI at the model level.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.893022209405899}]}, {"text": " Table 2: Pearson correlation of OC-Human and the automated methods -OC-Auto-PMI, OC-Auto- NPMI, OC-Auto-LCP and OC-Auto-DS -at the model level.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8181316256523132}]}, {"text": " Table 3: Word intrusion vs. observed coherence: Pearson correlation coefficient at the model level.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 49, "end_pos": 68, "type": "METRIC", "confidence": 0.9506996273994446}]}, {"text": " Table 4: Pearson correlation coefficient of WI-Human and WI-Auto-PMI/WI-Auto-NPMI at the topic  level.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.9298514723777771}]}, {"text": " Table 5: Pearson correlation of OC-Human and the automated methods at the topic level.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8020822405815125}]}, {"text": " Table 6: Word intrusion vs. observed coherence: pearson correlation results at the topic level.", "labels": [], "entities": []}, {"text": " Table 7. WIKI-FULL  is used as the reference corpus for computing the", "labels": [], "entities": [{"text": "WIKI-FULL", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.823984682559967}]}, {"text": " Table 7: A list of WIKI topics to illustrate the impact of NPMI.", "labels": [], "entities": [{"text": "NPMI", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.7852122187614441}]}, {"text": " Table 8: A list of WIKI topics to illustrate the difference between observed coherence and word intrusion.  Boxes denote human chosen intruder words, and boldface denotes true intruder words.", "labels": [], "entities": []}]}