{"title": [{"text": "MILAB at SemEval-2019 Task 3: Multi-View Turn-by-Turn Model for Context-Aware Sentiment Analysis", "labels": [], "entities": [{"text": "Context-Aware Sentiment Analysis", "start_pos": 64, "end_pos": 96, "type": "TASK", "confidence": 0.6873019138971964}]}], "abstractContent": [{"text": "This paper describes our system for SemEval-2019 Task 3: EmoContext, which aims to predict the emotion of the third utterance considering two preceding utterances in a dialogue.", "labels": [], "entities": [{"text": "SemEval-2019 Task 3", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8937483231226603}]}, {"text": "To address this challenge of predicting the emotion considering its context, we propose a Multi-View Turn-by-Turn (MVTT) model.", "labels": [], "entities": []}, {"text": "Firstly, MVTT model generates vectors from each utterance using two encoders: word-level Bi-GRU encoder (WLE) and character-level CNN encoder (CLE).", "labels": [], "entities": []}, {"text": "Then, MVTT grasps contextual information by combining the vectors and predict the emotion with the contex-tual information.", "labels": [], "entities": []}, {"text": "We conduct experiments on the effect of vector encoding and vector combination.", "labels": [], "entities": [{"text": "vector encoding", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7906118333339691}, {"text": "vector combination", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7804322242736816}]}, {"text": "Our final MVTT model achieved 0.7634 microaveraged F1 score.", "labels": [], "entities": [{"text": "MVTT", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.7647113800048828}, {"text": "F1 score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9026803970336914}]}], "introductionContent": [{"text": "Sentiment analysis is a task of identifying emotional information from text materials and has been studied by various research fields since it can be applied to many applications such as public survey and market analysis.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9377121925354004}, {"text": "market analysis", "start_pos": 205, "end_pos": 220, "type": "TASK", "confidence": 0.7436771094799042}]}, {"text": "However, most studies in sentiment analysis have only focused on a single sentence) or a single document.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9768550395965576}]}, {"text": "It is still hard to predict the emotion of a sentence with extra contextual information because the emotion can be understood differently depending on its context.) provides a dataset of dialogues which consist of three utterances between two users).", "labels": [], "entities": []}, {"text": "Participants are required to predict the emotion of the third utterance among 'Happy', 'Sad', 'Angry', and 'Others', considering its context of two preceding utterances.", "labels": [], "entities": []}, {"text": "In this paper, we propose a Multi-View Turnby-Turn (MVTT) model which encodes each utterance separately and combines the encoded vec- tors to get the contextual information.", "labels": [], "entities": []}, {"text": "MVTT model first generates vectors from each utterance with two encoders: word-level Bi-GRU encoder (WLE) and character-level CNN encoder (CLE).", "labels": [], "entities": [{"text": "MVTT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7121493816375732}]}, {"text": "The two-encoder strategy makes MVTT model more robust to the noisy texts which have a lot of typos and abbreviations.", "labels": [], "entities": []}, {"text": "Then, MVTT extracts contextual information by combining the vectors and makes a prediction.", "labels": [], "entities": [{"text": "MVTT extracts contextual information", "start_pos": 6, "end_pos": 42, "type": "TASK", "confidence": 0.7220451086759567}]}, {"text": "We compare the MVTT model with some variants focusing on utterance vector encoding and utterance vector combination methods with microaveraged F1 score (F1) which is the main evaluation metric.", "labels": [], "entities": [{"text": "utterance vector encoding", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.7831899921099345}, {"text": "utterance vector combination", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.6553275982538859}, {"text": "microaveraged F1 score (F1)", "start_pos": 129, "end_pos": 156, "type": "METRIC", "confidence": 0.85516557097435}]}, {"text": "This paper is organized as follows: Section 2 describes MVTT model architecture in detail.", "labels": [], "entities": [{"text": "MVTT model architecture", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7453283270200094}]}, {"text": "Section 3 describes dataset and various methods that we use to reflect the dataset's characteristics to our training.", "labels": [], "entities": []}, {"text": "Section 4 compares our results of MVTT model and other variants, and Section 5 outlines our conclusions.", "labels": [], "entities": [{"text": "MVTT model", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.806671530008316}]}], "datasetContent": [{"text": "SemEval-2019 Task 3: EmoContext provided dialogue dataset consisting of three utterances written by two users and each sample is labeled among 'Happy', 'Sad', 'Angry' and 'Others'.", "labels": [], "entities": []}, {"text": "In this section, we describe the dataset and some implementation details.", "labels": [], "entities": []}, {"text": "The provided dialogue dataset is split into training, validation and test sets.", "labels": [], "entities": []}, {"text": "shows the label distribution of each data split.", "labels": [], "entities": []}, {"text": "As indicates, there are large differences in class label distributions among data splits and it is important to consider the differences in configuring our system.: The statistics for the number of labels of each split.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The statistics for the number of labels of each  split.", "labels": [], "entities": []}, {"text": " Table 2: Performance comparison among WLE, CLE  and MVTT.", "labels": [], "entities": [{"text": "WLE", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.6094240546226501}, {"text": "MVTT", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.8191553354263306}]}, {"text": " Table 3: The effect of vector combination on perfor- mance.", "labels": [], "entities": []}]}