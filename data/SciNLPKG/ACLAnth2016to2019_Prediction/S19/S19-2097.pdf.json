{"title": [{"text": "Amrita School of Engineering -CSE at SemEval-2019 Task 6: Manipulating Attention with Temporal Convolutional Neural Network for Offense Identification and Classification", "labels": [], "entities": [{"text": "Offense Identification and Classification", "start_pos": 128, "end_pos": 169, "type": "TASK", "confidence": 0.8011761978268623}]}], "abstractContent": [{"text": "With the proliferation and ubiquity of smart gadgets and smart devices, across the world, data generated by them has been growing at exponential rates, in particular social media platforms like Facebook, Twitter and Insta-gram have been generating voluminous data on a daily basis.", "labels": [], "entities": []}, {"text": "According to Twitter's usage statistics, about 500 million tweets are generated each day.", "labels": [], "entities": []}, {"text": "While the tweets reflect the users' opinions on several events across the world, there are tweets which are offensive in nature that need to be tagged under the hateful conduct policy of Twitter.", "labels": [], "entities": []}, {"text": "Offensive tweets have to be identified, captured and processed further, fora variety of reasons, which include i) identifying offensive tweets in order to prevent violent/abusive behaviour in Twitter (or any social media for that matter), ii) creating and maintaining a history of offensive tweets for individual users (would be helpful in creating meta-data for user profile), iii) inferring the sentiment of the users on particular event/issue/topic.", "labels": [], "entities": []}, {"text": "We (CodaLab Team/User Name: murali sr) have employed neural network models which manipulate attention with Temporal Convolutional Neural Network for the three shared sub-tasks i) ATT-TCN (ATTention based Temporal Convolutional Neural Network) employed for shared sub-task A that yielded a best macro-F1 score of 0.46, ii) SAE-ATT-TCN(Self Attentive Embedding-ATTention based Temporal Convolutional Neural Network) employed for shared sub-task B and sub-task C that yielded best macro-F1 score of 0.61 and 0.51 respectively.", "labels": [], "entities": []}, {"text": "Among the two variants ATT-TCN and SAE-ATT-TCN, the latter performed better.", "labels": [], "entities": [{"text": "ATT-TCN", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.5415424108505249}, {"text": "SAE-ATT-TCN", "start_pos": 35, "end_pos": 46, "type": "METRIC", "confidence": 0.4779016077518463}]}], "introductionContent": [{"text": "In the prevailing digital era, Deep Learning has penetrated almost all industry verticals and afforded several researchers an effective tool, in handling voluminous data and deriving meaningful inferences.", "labels": [], "entities": []}, {"text": "Initially, ( invented Convolutional Neural Network (CNN) model for extraction of local features, which later proved to be the standard choice for Computer Vision tasks.) the introduced LSTM (Long Short Term Memory) architecture, which went onto become the standard choice for Natural Language Processing (sequence) tasks due to the implicit ordering of the sequence data in words and sentences.", "labels": [], "entities": []}, {"text": "Then several architectures, combining LSTM with CNN were introduced that went onto become successful for NLP tasks as well.", "labels": [], "entities": []}, {"text": "Deep Learning techniques have leaped forward through multiple NLP tasks such as Modeling, Classification, Translation, Summarization, etc., and have proved to be better compared to traditional techniques.", "labels": [], "entities": [{"text": "Modeling, Classification, Translation, Summarization", "start_pos": 80, "end_pos": 132, "type": "TASK", "confidence": 0.6659907741206033}]}, {"text": "Ever since social media has become ubiquitous there have been individuals who take gratuitous advantage of the anonymous nature of social media platforms, and engage themselves in rude and offensive communications.", "labels": [], "entities": []}, {"text": "Such behaviour that prohibit free flow of communication and violate acceptable usage policy has necessitated to identify and capture the offensive posts, comments, etc., in order to prevent the dissemination of abusive behaviour in social media.", "labels": [], "entities": []}, {"text": "() focused on this aspect and organized a classification task with a particular focus on Twitter posts; unlike predictions of positive or negative sentiments, this task has three shared sub-tasks, intended to identify and capture the offense target as an entity.", "labels": [], "entities": []}, {"text": "The task includes three shared sub-tasks that include: i) Sub-Task A: Offensive language identification, ii) Sub-Task B: Offense type categorization and iii) Sub-Task C: Offense target identification.", "labels": [], "entities": [{"text": "Offensive language identification", "start_pos": 70, "end_pos": 103, "type": "TASK", "confidence": 0.7155538896719614}, {"text": "Offense type categorization", "start_pos": 121, "end_pos": 148, "type": "TASK", "confidence": 0.6240602433681488}, {"text": "Offense target identification", "start_pos": 170, "end_pos": 199, "type": "TASK", "confidence": 0.6723453203837076}]}, {"text": "i) Sub-Task A: Offensive language identification in which posts are categorized into Offensive or Not Offensive.", "labels": [], "entities": [{"text": "Offensive language identification", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.7435526251792908}]}, {"text": "Recently () empirically concluded that the association between sequence modeling and recurrent neural networks should be reconsidered and established that convolutional networks are ought to be considered for sequence modeling tasks.", "labels": [], "entities": [{"text": "sequence modeling", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7880860567092896}, {"text": "sequence modeling tasks", "start_pos": 209, "end_pos": 232, "type": "TASK", "confidence": 0.7801646788914999}]}, {"text": "The TCN model can be extended followed by introduction of Attention to the output of Embedding layer and TCN layer ii) Sub-Task B: Offense type categorization in which the Offense type is categorized into either targeted or untargeted.", "labels": [], "entities": []}, {"text": "The objective here is to understand sentence structure by emulating the relationship between words.", "labels": [], "entities": []}, {"text": "The sequence of words is crucial to capture the essence of sentence unlike the practice of mere focus on constituent parts of a sentence in the previous model.", "labels": [], "entities": []}, {"text": "Based on (, minor modifications are injected into the previous model employed in sub-task A, and introduced self-attention for embedding further to aggregate the relationship between words in a sentence and stacked attention layer, at the output of each dilated convolution blocks.", "labels": [], "entities": []}, {"text": "iii) Sub-Task C: Identification of target offense in which the who, the offense is aimed at is identified and categorized into Individual, Group or Other.", "labels": [], "entities": []}, {"text": "The same model used in the previous sub-task B is employed for this sub-task as well.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Hyper-parameters for each Sub-Task A, B and  C respectively. Parameters are in numbers. *x10 2", "labels": [], "entities": []}, {"text": " Table 2: Cross-Validation Results for Sub-Tasks A, 1 B  and 2 C respectively.", "labels": [], "entities": []}, {"text": " Table 3: CodaLab Test Results for Sub-Task A.", "labels": [], "entities": []}, {"text": " Table 4: CodaLab Test Results for Sub-Task B.", "labels": [], "entities": []}, {"text": " Table 5: CodaLab Test Results for Sub-Task C.", "labels": [], "entities": []}, {"text": " Table 6: Sub-Task A, Confusion Matrix for Base ATT- TCN at threshold 0.45", "labels": [], "entities": [{"text": "Base ATT- TCN", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.7639506980776787}]}, {"text": " Table 7: Sub-Task B, Confusion Matrix for SAE-ATT- TCN at threshold 0.70", "labels": [], "entities": [{"text": "SAE-ATT- TCN", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.4526737133661906}]}, {"text": " Table 8: Sub-Task C, Confusion Matrix for SAE-ATT- TCN at threshold 0.55", "labels": [], "entities": [{"text": "SAE-ATT- TCN", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.45220594604810077}]}]}