{"title": [{"text": "The Titans at SemEval-2019 Task 6: Offensive Language Identification, Categorization and Target Identification", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.857032984495163}, {"text": "Offensive Language Identification", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7398106455802917}, {"text": "Target Identification", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.6792546659708023}]}], "abstractContent": [{"text": "This system paper is a description of the system submitted to \"SemEval-2019 Task 6\", where we had to detect offensive language in Twitter.", "labels": [], "entities": [{"text": "SemEval-2019 Task 6\"", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.5502214431762695}]}, {"text": "There were two specific target audiences , immigrants and women.", "labels": [], "entities": []}, {"text": "The language of the tweets was English.", "labels": [], "entities": []}, {"text": "We were required to first detect whether a tweet contains offensive content, and then we had to find out whether the tweet was targeted against some individual , group or other entity.", "labels": [], "entities": []}, {"text": "Finally we were required to classify the targeted audience.", "labels": [], "entities": []}], "introductionContent": [{"text": "Offensive language is pervasive in social media.", "labels": [], "entities": []}, {"text": "Individuals frequently take advantage of the perceived anonymity of computer-mediated communication, using this to engage in behavior that many of them would not consider in real life.", "labels": [], "entities": []}, {"text": "Online communities, social media platforms, and technology companies have been investing heavily in ways to cope with offensive language to prevent abusive behavior in social media.", "labels": [], "entities": []}, {"text": "One of the most effective strategies for tackling this problem is to use computational methods to identify offense in user-generated content (e.g. posts, comments, microblogs, etc.).", "labels": [], "entities": [{"text": "identify offense in user-generated content (e.g. posts, comments, microblogs", "start_pos": 98, "end_pos": 174, "type": "TASK", "confidence": 0.6764216671387354}]}, {"text": "This topic has attracted significant attention in recent years of various Natural Language analysts.", "labels": [], "entities": []}, {"text": "The SemEval 2019 task 6 (Zampieri et al., 2019b) was a classification task where we were required to classify a tweet, as hate speech or otherwise.", "labels": [], "entities": [{"text": "SemEval 2019 task", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8442119359970093}]}, {"text": "However, there were some additional challenges presented, which involved automatic categorization of offense target types and the specific detection of the target audience, namely, women or immigrants.", "labels": [], "entities": []}, {"text": "The task was divided into three parts.", "labels": [], "entities": []}, {"text": "In the first subtask our system categorized the instances into OFF and NOT.", "labels": [], "entities": [{"text": "OFF", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9817805886268616}, {"text": "NOT", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9645115733146667}]}, {"text": "In the second subtask our system categorized instances into TIN and UNT while in the third subtask systems should categorize instances into IND, GRP, and OTH.", "labels": [], "entities": [{"text": "UNT", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.6154386401176453}]}, {"text": "To solve the task in hand we built a bidirectional LSTM based neural network for prediction of the classes present in the provided dataset.", "labels": [], "entities": []}, {"text": "The paper has been organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes a brief survey on the relevant work done in this field.", "labels": [], "entities": []}, {"text": "Section 3 describes the data, on which, the task was performed.", "labels": [], "entities": []}, {"text": "The methodology followed is described in Section 4.", "labels": [], "entities": []}, {"text": "This is followed by the results and concluding remarks in Section 5 and 6 respectively.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Meaning of the labels used in the dataset", "labels": [], "entities": [{"text": "Meaning", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9950994849205017}]}, {"text": " Table 2: Distribution of the labels in the dataset", "labels": [], "entities": []}, {"text": " Table 3: Sub-task A, garain CodaLab 528038 (Bi- Directional LSTM)", "labels": [], "entities": []}, {"text": " Table 4: Sub-task B, garain CodaLab 533103 (Bi- Directional LSTM threshold = 0.40)  * -class weights not used", "labels": [], "entities": [{"text": "Bi- Directional LSTM threshold", "start_pos": 45, "end_pos": 75, "type": "METRIC", "confidence": 0.9226008772850036}]}, {"text": " Table 5: Sub-task C, garain CodaLab 535813 (Bi- Directional LSTM)", "labels": [], "entities": []}]}