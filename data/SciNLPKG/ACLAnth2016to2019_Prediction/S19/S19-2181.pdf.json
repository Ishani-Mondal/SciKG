{"title": [{"text": "Team Peter-Parker at SemEval-2019 Task 4: BERT-Based Method in Hyperpartisan News Detection", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.8408206105232239}, {"text": "BERT-Based", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9978868365287781}, {"text": "Hyperpartisan News Detection", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.6381572782993317}]}], "abstractContent": [{"text": "This paper describes the team peter-parker's participation in Hyperpartisan News Detection task (SemEval-2019 Task 4), which requires to classify whether a given news article is bias or not.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection task", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.7283037751913071}]}, {"text": "We decided to use JAVA to do the article parser and the BERT model to do the bias analysis and prediction.", "labels": [], "entities": [{"text": "JAVA", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.8557386994361877}, {"text": "article parser", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7223551571369171}, {"text": "BERT", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9943023920059204}]}, {"text": "Furthermore, we will show experiment results with analysis.", "labels": [], "entities": []}], "introductionContent": [{"text": "As the Hyperpartisan News Detection is getting more and more popular in NLP area in recent years, our team decided to focus on such kind of topic and choose task 4 in 2019 SemEval competition, which requires to decide whether a given news article is showing an unreasoning or blind allegiance to some specific groups or persons(.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.6281100114186605}]}, {"text": "For the task, it also requires the competitor's model to classify the news article in one of the two classes, bias or not.", "labels": [], "entities": []}, {"text": "In previous SemEval competition, the classification tasks were mostly regarded as sentiment analysis on Twitter, news or scientific paper and soon.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.8524541258811951}]}, {"text": "For SemEval 2019, the task focus on bias detection, which gives great help for people in daily life to acquire the news and articles in a more objective way.", "labels": [], "entities": [{"text": "bias detection", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.7383298128843307}]}, {"text": "So far, the machine learning approaches to do the bias detection were mostly using the) or the Word Vectors, which can get the accuracy for more than 70%.", "labels": [], "entities": [{"text": "bias detection", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.8262502253055573}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9993399977684021}]}, {"text": "To reach a greater performance, we decided to adopt a state-of-the-art language model, BERT, which set new records on many NLP tasks recently, into our political bias task analysis.", "labels": [], "entities": [{"text": "BERT", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9982933402061462}, {"text": "political bias task analysis", "start_pos": 152, "end_pos": 180, "type": "TASK", "confidence": 0.7026884481310844}]}, {"text": "For dealing with the given large dataset, JAVA was used as a parser tool to help us make those training articles more readable.", "labels": [], "entities": [{"text": "JAVA", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.6059190034866333}]}], "datasetContent": [{"text": "A good training data cannot be made without data cleaning.", "labels": [], "entities": []}, {"text": "There were 600,000 training data (by publisher) and 150,000 validation data (by publisher) and 645 training data (by article).", "labels": [], "entities": []}, {"text": "For such a huge dataset, we first split data into 75 separated files, each contained 10,000 news articles so that they were easy to be opened by text editors.", "labels": [], "entities": []}, {"text": "After doing this, we used JAVA to do data parsing and cleaning and BERT model to do bias analysis and prediction.", "labels": [], "entities": [{"text": "JAVA", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.7875007390975952}, {"text": "data parsing", "start_pos": 37, "end_pos": 49, "type": "TASK", "confidence": 0.7047087252140045}, {"text": "BERT", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9957969188690186}]}, {"text": "In the articles, some of the characters are escaped as HTML such as that \" & \" became &amp.", "labels": [], "entities": []}, {"text": "It was really easy to unescape them with Java, which involved only one line of method invocation: StringEscapeUtils.unescapeHtml4().", "labels": [], "entities": []}, {"text": "There were some unknown Unicode characters in the articles, so it is good to be removed.", "labels": [], "entities": []}, {"text": "Unfortunately, when applying some regular expressions to the articles to remove those characters, some of the articles in other languages would begone, for example, Chinese, since it was hard to find all the occurring unknown characters in all news articles and we had to use a simple method which was blindly removing all the words, not in the range of \\x00 to \\x7F in Unicode.", "labels": [], "entities": []}, {"text": "So, all the unknown characters could not be removed in order for retaining meaningful words in other languages.", "labels": [], "entities": []}, {"text": "Another problem was that most of the articles contained too many urls and a number of html tags because these articles are parsed from the internet.", "labels": [], "entities": []}, {"text": "These might affect the performance and accuracy, so we used a set of regular expressions to catch and remove all the urls and html tags in different forms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9989641904830933}]}, {"text": "Finally, another regular expression was applied to remove the duplicate punctuation such as a line of only periods to divide the articles.", "labels": [], "entities": []}], "tableCaptions": []}