{"title": [{"text": "INF-HatEval at SemEval-2019 Task 5: Convolutional Neural Networks for Hate Speech Detection Against Women and Immigrants on Twitter", "labels": [], "entities": [{"text": "INF-HatEval", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9293159246444702}, {"text": "Hate Speech Detection", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.7930664618810018}]}], "abstractContent": [{"text": "In this paper, we describe our approach to detect hate speech against women and immigrants on Twitter in a multilingual context, En-glish and Spanish.", "labels": [], "entities": []}, {"text": "This challenge was proposed by the SemEval-2019 Task 5, where participants should develop models for hate speech detection, a two-class classification where systems have to predict whether a tweet in En-glish or in Spanish with a given target (women or immigrants) is hateful or not hateful (Task A), and whether the hate speech is directed at a specific person or a group of individuals (Task B).", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7833234369754791}, {"text": "hate speech detection", "start_pos": 101, "end_pos": 122, "type": "TASK", "confidence": 0.740919808546702}]}, {"text": "For this, we implemented a Convolutio-nal Neural Networks (CNN) using pre-trained word embeddings (GloVe and FastText) with 300 dimensions.", "labels": [], "entities": []}, {"text": "Our proposed model obtained in Task A 0.488 and 0.696 F1-score for English and Spanish, respectively.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9924732446670532}]}, {"text": "For Task B, the CNN obtained 0.297 and 0.430 EMR for English and Spanish, respectively.", "labels": [], "entities": [{"text": "CNN", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.9224607348442078}, {"text": "EMR", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9934322834014893}]}], "introductionContent": [{"text": "With the growth of users in social networks, there was also an increase in the odious activities that permeate these communicative structures.", "labels": [], "entities": []}, {"text": "According to, hate speech can be defined as any communication that deprecates a person or a group based on some characteristics such as race, color, ethnicity, gender, nationality, religion or other features.", "labels": [], "entities": []}, {"text": "And the main motive that encourages users to spread hate on social networks is anonymity, so users can spread hate words to a particular target.", "labels": [], "entities": []}, {"text": "For this reason, the hatred propagated can generate irreversible consequences, where young people who approach with cyberbullying and homophobia, mainly, commit suicide.", "labels": [], "entities": []}, {"text": "Nowadays, social networks like Twitter 1 , Fa-1 https://twitter.com/ cebook 2 and YouTube 3 are pressured to develop tools to fight the proliferation of hate in their networks.", "labels": [], "entities": [{"text": "Fa-1", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.9114786982536316}]}, {"text": "A good example of this is the German government that threatened to fine social networks by up to 50 million euros if they did not fight the spread of hate.", "labels": [], "entities": []}, {"text": "However, while there is plenty of available content on social networks, the task of detecting hate speech remains difficult, largely because of the use of different sets of data for work, lack of benchmarking, and efficient approaches.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.8449850678443909}]}, {"text": "Waseem, for example, bring a study focused on the detection of racism and sexism, whereas and Sanchez and Kumar 2011) conducted a survey on detecting bullying.", "labels": [], "entities": []}, {"text": "For the detection of homophobia, misogyny and xenophobia, the number of papers is still limited, one can cite a recent paper (, where the authors sought to identify hate speech against immigrants.", "labels": [], "entities": []}, {"text": "However, it is important that new research is publicized, because only in this way will it be possible to fight against hate in social networks.", "labels": [], "entities": []}, {"text": "Introducing a brief definition of hate speech and the importance of combating it, SemEval-2019 proposed a task in which it challenges participants to develop systems for detecting hate speech against women and immigrants on Twitter from a multilingual perspective , for English and Spanish.", "labels": [], "entities": []}, {"text": "The task was articulated around two related subtasks for each one of the languages involved: a basic task about hate speech, and another where refined hate content resources will be investigated to understand how existing approaches can handle the identification of especially dangerous forms of hatred, that is, those in which incitement is directed against an individual rather than against a group of people, and where aggressive behavior of the perpetrator can be identified as a prominent feature of the expression of hatred.", "labels": [], "entities": [{"text": "identification of especially dangerous forms of hatred, that is, those in which incitement is directed against an individual rather than against a group of people", "start_pos": 248, "end_pos": 410, "type": "Description", "confidence": 0.7833147954057764}]}, {"text": "In order to reach this goal, this work proposed to develop a Convolutional Neural Network with the use of word embeddings.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: previous work on hate-speech identification is discussed in Section 2.", "labels": [], "entities": [{"text": "hate-speech identification", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.8287005424499512}]}, {"text": "Section 3 presents details about the task, data sets and evaluation methods.", "labels": [], "entities": []}, {"text": "Section 4 describes the methodology for categorizing hate speech based on deep learning, while experiments and results are reported in Section 5.", "labels": [], "entities": [{"text": "categorizing hate speech", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.8444938460985819}]}, {"text": "Finally, Section 6 summarises the discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data for the task consists of 9000 tweets in English for training, 1000 for develop and 2805 for test.", "labels": [], "entities": []}, {"text": "For Spanish, 4469 tweets for training, 500 for develop and 415 for test.", "labels": [], "entities": []}, {"text": "The data were structured in 5 columns: id, text, Hate Speech (HS), Target Range (TR) and.", "labels": [], "entities": [{"text": "Target Range (TR)", "start_pos": 67, "end_pos": 84, "type": "METRIC", "confidence": 0.9563716292381287}]}, {"text": "See an example in the: Example of hate speech.", "labels": [], "entities": []}, {"text": "Some examples are also taken from the data.", "labels": [], "entities": []}, {"text": "For the results evaluation of both tasks A and B, different metrics were used in order to allow more refined conclusions.", "labels": [], "entities": []}, {"text": "Task A. The systems will be evaluated according to the following metrics: accuracy, precision, recall and F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.999605119228363}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.998759388923645}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9993360638618469}, {"text": "F1-score", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9992874264717102}]}, {"text": "The equations below show how the calculations are done.", "labels": [], "entities": []}, {"text": "In the case of this task, the scores will be classified by F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9983339905738831}]}, {"text": "For better understanding, we will show the following definitions: \u2022 True positive (TP): means a correct classification as odious.", "labels": [], "entities": [{"text": "True positive (TP)", "start_pos": 68, "end_pos": 86, "type": "METRIC", "confidence": 0.8510015964508056}]}, {"text": "For example, the royal class is hateful and the model ranks as hateful.", "labels": [], "entities": []}, {"text": "\u2022 True negative (TN): means a correct classification as not hateful.", "labels": [], "entities": [{"text": "True negative (TN)", "start_pos": 2, "end_pos": 20, "type": "METRIC", "confidence": 0.9517118215560914}]}, {"text": "For example, the royal class is not hateful and the model ranked as not hateful.", "labels": [], "entities": []}, {"text": "\u2022 False positive (FP): means a wrong classification as odious.", "labels": [], "entities": [{"text": "False positive (FP)", "start_pos": 2, "end_pos": 21, "type": "METRIC", "confidence": 0.959449577331543}]}, {"text": "For example, the royal class is not hateful and the model rated it as hateful.", "labels": [], "entities": []}, {"text": "\u2022 False negative (FN): means a wrong classification not hateful.", "labels": [], "entities": [{"text": "False negative (FN)", "start_pos": 2, "end_pos": 21, "type": "METRIC", "confidence": 0.964652419090271}]}, {"text": "For example, the royal class is hateful and the model ranked as not hateful.", "labels": [], "entities": []}, {"text": "Task B. In this task, the evaluation metrics are two: partial match and exact match.", "labels": [], "entities": [{"text": "exact match", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.9680534303188324}]}, {"text": "The strategy for the partial match is to evaluate the Hate Speech, Target Range and Agressiveness classes independently of each other using the metrics defined above.", "labels": [], "entities": [{"text": "Target Range", "start_pos": 67, "end_pos": 79, "type": "METRIC", "confidence": 0.8441181182861328}, {"text": "Agressiveness", "start_pos": 84, "end_pos": 97, "type": "METRIC", "confidence": 0.6360445618629456}]}, {"text": "However, each system will include all measures and a summary of the performance in terms of macro-average F1-score, calculated according to the Equation 5.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9395418167114258}, {"text": "Equation", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9737947583198547}]}, {"text": "The exact match considers the predicted classes together, thus computing the Exact Match Ratio ().", "labels": [], "entities": [{"text": "Exact Match Ratio", "start_pos": 77, "end_pos": 94, "type": "METRIC", "confidence": 0.9173326094945272}]}, {"text": "Given the set of data consisting of n multi-label samples (Xi, Yi), where Xi denotes the i-th instance and Yi corresponds to the labels to be predicted (HS, TR and AG), the Exact Match Ratio (EMR) is calculated according to Equation 6.", "labels": [], "entities": [{"text": "AG", "start_pos": 164, "end_pos": 166, "type": "METRIC", "confidence": 0.9400506615638733}, {"text": "Exact Match Ratio (EMR)", "start_pos": 173, "end_pos": 196, "type": "METRIC", "confidence": 0.8019319027662277}]}, {"text": "where Zi denotes the set of labels predicted for the i-th instance and I is the indicator function.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example of hate speech. Some examples are  also taken from the data.", "labels": [], "entities": []}, {"text": " Table 2: Results obtained related to Task A.", "labels": [], "entities": []}, {"text": " Table 2. This re- sult also suggests that the combination of CNN  and GloVe provides better results for this task.", "labels": [], "entities": [{"text": "CNN", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8699502348899841}]}, {"text": " Table 3: Confusion matrix concerning task A.", "labels": [], "entities": []}, {"text": " Table 4: Results obtained related to Task B.", "labels": [], "entities": []}]}