{"title": [{"text": "Lijunyi at SemEval-2019 Task 9: An attention-based LSTM model and ensemble of different models for suggestion mining from online reviews and forums", "labels": [], "entities": [{"text": "suggestion mining", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7305878400802612}]}], "abstractContent": [{"text": "In this paper, we describe a suggestion mining system that participated in SemEval 2019 Task 9, SubTask A-Suggestion Mining from Online Reviews and Forums.", "labels": [], "entities": [{"text": "SemEval 2019 Task 9", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8503564894199371}, {"text": "SubTask A-Suggestion Mining", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.7204143007596334}]}, {"text": "Given some suggestions from online reviews and forums that can be classified into suggestion and non-suggestion classes.", "labels": [], "entities": []}, {"text": "In this task, we combine the attention mechanism with the LSTM model , which is the final system we submitted.", "labels": [], "entities": []}, {"text": "The final submission achieves 14th place in Task 9, SubTask A with the accuracy of 0.6776.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9995936751365662}]}, {"text": "After the challenge, we train a series of neural network models such as convolutional neural net-work(CNN), TextCNN, long short-term mem-ory(LSTM) and C-LSTM.", "labels": [], "entities": []}, {"text": "Finally, we make an ensemble on the predictions of these models and get a better result.", "labels": [], "entities": []}], "introductionContent": [{"text": "Suggestion mining can be defined as the extraction of suggestions from unstructured text, where the term \"suggestions\" refers to the expressions of tips, advice, recommendations etc(.", "labels": [], "entities": [{"text": "Suggestion mining", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9757880866527557}]}, {"text": "These suggestions largely express positive and negative sentiments towards a given entity, but also tend to contain suggestions for improving the entity.", "labels": [], "entities": []}, {"text": "Suggestion mining remains a relatively young area compared to Sentiment Analysis, especially in the context of recent advancements in neural network based approaches for learning feature representations.", "labels": [], "entities": [{"text": "Suggestion mining", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9800597429275513}, {"text": "Sentiment Analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9337559640407562}]}, {"text": "In this task, suggestion mining that classified sentences into suggestion and non-suggestion classes was defined by the organizer.", "labels": [], "entities": [{"text": "suggestion mining", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7848459482192993}]}, {"text": "In this paper, we mainly use an attention-based LSTM model for this task.", "labels": [], "entities": []}, {"text": "The word-embedding used for all models in this task is Word2Vec.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.9696251153945923}]}, {"text": "Then, the word vectors are fed into the long short-term memory (LSTM) layer.", "labels": [], "entities": []}, {"text": "Finally, an attention mechanis-) is added into the neural networks, and the prediction results are output via the softmax activation.", "labels": [], "entities": []}, {"text": "What's more, we try a number of other models (such as the, the C-LSTM() and the attention-based Bi-LSTM( ) for comparative experiments.", "labels": [], "entities": []}, {"text": "Furthermore we combine all of the above models to get results by soft voting.", "labels": [], "entities": []}, {"text": "The rest of our paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 3 describes data preparation.", "labels": [], "entities": [{"text": "data preparation", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7976648509502411}]}, {"text": "Experiments and evaluation are described in Section 4.", "labels": [], "entities": []}, {"text": "The conclusions are drawn in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "After data pre-processing, we start the main part of the experiment.", "labels": [], "entities": []}, {"text": "The preprocessed data is feed into our prepared model for experimentation.", "labels": [], "entities": []}, {"text": "At the same time, we do experiments on different models to compare the test results.", "labels": [], "entities": []}, {"text": "In the experiments, we also find that the same model will get different results under different parameter adjustments.", "labels": [], "entities": []}, {"text": "For example, we use the C-LSTM model for experiments, and our experimental results range from 0.67 to 0.78 with different parameters in the trial data.", "labels": [], "entities": []}, {"text": "Therefore, reasonable adjustment of parameters during the experiment is also a factor in obtaining a good experimental result.", "labels": [], "entities": []}, {"text": "We run each individual model 5 times and use the average as the final result of this model.", "labels": [], "entities": []}, {"text": "In all of models, dropout parameters are changed from 0.2 to 0.6, What's more, in the LSTM model, we also select the recurrent dropout () that are set between 0.2 and 0.45.", "labels": [], "entities": []}, {"text": "And we set epoch = 10 and batch size = 64.", "labels": [], "entities": []}, {"text": "In this task, we mainly select 6 models and ensemble all of these models.", "labels": [], "entities": []}, {"text": "In the table 3 we post the F1-score and recall of the model.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9994779229164124}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9997374415397644}]}], "tableCaptions": [{"text": " Table 2: Recall and F1-score for each models on task  test data", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.997395396232605}, {"text": "F1-score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9996281862258911}]}]}