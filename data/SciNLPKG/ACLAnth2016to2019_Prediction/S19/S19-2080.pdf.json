{"title": [{"text": "MITRE at SemEval-2019 Task 5: Transfer Learning for Multilingual Hate Speech Detection", "labels": [], "entities": [{"text": "Multilingual Hate Speech Detection", "start_pos": 52, "end_pos": 86, "type": "TASK", "confidence": 0.5570813789963722}]}], "abstractContent": [{"text": "This paper describes MITRE's participation in SemEval-2019 Task 5, HatEval: Multilingual detection of hate speech against immigrants and women in Twitter.", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.8743537664413452}, {"text": "Multilingual detection of hate speech", "start_pos": 76, "end_pos": 113, "type": "TASK", "confidence": 0.837430763244629}]}, {"text": "The techniques explored range from simple bag-of-ngrams classifiers to neural architectures with varied attention mechanisms.", "labels": [], "entities": []}, {"text": "We describe several styles of transfer learning from auxiliary tasks, including a novel method for adapting pre-trained BERT models to Twitter data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.7960452437400818}]}, {"text": "Logistic regression ties the systems together into an ensemble submitted for evaluation.", "labels": [], "entities": []}, {"text": "The resulting system was used to produce predictions for all four HatEval subtasks, achieving the best mean rank of all teams that participated in all four conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "The popularity of social media allows anyone to post their thoughts and opinions for all to see.", "labels": [], "entities": []}, {"text": "While the vast majority of these communications are benign, there are those who express hateful or threatening messages online.", "labels": [], "entities": []}, {"text": "The identification of hate speech on platforms like Twitter is of particular interest for law enforcement and to social media companies who wish to remove accounts with offending content from their sites.", "labels": [], "entities": [{"text": "identification of hate speech", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8712173700332642}]}, {"text": "Automating the identification of hate speech will allow platforms to flag and remove content much more quickly and effectively.", "labels": [], "entities": [{"text": "identification of hate speech", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.869851216673851}]}, {"text": "In this effort we explored neural transfer learning techniques, including word embeddings and fine-tuning of models trained with diverse auxiliary tasks.", "labels": [], "entities": [{"text": "neural transfer learning", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.7735365827878317}]}, {"text": "We built and compared models employing soft attention over sequences and multiheaded self-attention.", "labels": [], "entities": []}, {"text": "We also present a novel task to aid in performing additional pre-training of BERT ( for domain adaptation to Twitter data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9969210624694824}, {"text": "domain adaptation", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7267322242259979}]}], "datasetContent": [{"text": "HatEval was a shared task organized within).", "labels": [], "entities": []}, {"text": "The primary task was detection of hate speech in Twitter, specifically against immigrants and women.", "labels": [], "entities": [{"text": "detection of hate speech in Twitter", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.8684958318869272}]}, {"text": "This multilingual shared task was organized into two sub-tasks, each presented in both English and Spanish, fora total of four sub-task evaluations.", "labels": [], "entities": []}, {"text": "Task A The first sub-task was simply to identify tweets containing hate speech against immigrants or women.", "labels": [], "entities": []}, {"text": "The official metric used for this binary classification task was macro-averaged F1 score, in which the F1 scores are calculated for both the positive hate speech and negative not hate speech classes and then those two scores are averaged.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9778343737125397}, {"text": "F1", "start_pos": 103, "end_pos": 105, "type": "METRIC", "confidence": 0.9961763620376587}]}, {"text": "Task B The second sub-task involved the detection of two specific aspects of hate speech: whether it is targeted at an individual vs. a group of people, and whether it expresses aggression on the part of the author.", "labels": [], "entities": []}, {"text": "In this annotation scheme, there is a dependency between these two categories and the hate speech label used in Task A, as tweets could only be labeled as positive for targeting or aggression if they were positive for hate speech.", "labels": [], "entities": []}, {"text": "The official metric used for Task B was Exact Match Ratio (EMR), which is the proportion of tweets that are labeled correctly for all categories (hate speech, targeting, and aggression).", "labels": [], "entities": [{"text": "Exact Match Ratio (EMR)", "start_pos": 40, "end_pos": 63, "type": "METRIC", "confidence": 0.9552272260189056}]}, {"text": "Another way to think of this is as a five-class classification problem where the classes are (H=0, T=0, A=0), (H=1, T=0, A=0), (H=1, T=0, A=1), (H=1, T=1, A=0), (H=1, T=1, A=1).", "labels": [], "entities": []}, {"text": "EMR on predicting the three classes separately is equivalent to accuracy on this five-class classification.", "labels": [], "entities": [{"text": "EMR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9464321732521057}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9996566772460938}]}, {"text": "The English datasets consisted of 9000 tweets for train, 1000 for dev, and 3000 for test.", "labels": [], "entities": [{"text": "English datasets", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8875825107097626}]}, {"text": "The Spanish datasets were half the size of the English, with 4500 tweets for train, 500 for dev, and 1500 for test.", "labels": [], "entities": [{"text": "Spanish datasets", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8265626430511475}]}, {"text": "Cursory examination revealed drastic differences between the training and test sets, particularly in English.", "labels": [], "entities": []}, {"text": "The pejorative term bitch appeared in 12% of the training tweets vs. 48% of the test tweets.", "labels": [], "entities": []}, {"text": "The hashtags #BuildThatWall or #BuildTheWall appeared at rates of 6% and 23% in train and test, respectively.", "labels": [], "entities": [{"text": "BuildThatWall", "start_pos": 14, "end_pos": 27, "type": "METRIC", "confidence": 0.805924117565155}]}, {"text": "Likewise, #MAGA was in over 12% of the test set tweets but in under 3% of the training set messages.", "labels": [], "entities": [{"text": "MAGA", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9697914719581604}]}, {"text": "Thus the English test set appears to be dominated by a handful of heavily represented phenomena.", "labels": [], "entities": [{"text": "English test set", "start_pos": 9, "end_pos": 25, "type": "DATASET", "confidence": 0.9073679447174072}]}, {"text": "Different annotation strategies appear to have been used on the training and test sets as well.", "labels": [], "entities": []}, {"text": "While tweets mentioning #BuildThatWall or #BuildTheWall were annotated as hate speech 98% of the time in the training set, this number is 35% on the test set.", "labels": [], "entities": []}, {"text": "Similarly, tweets containing bitch were labeled as hate speech 78% of the time in the training set vs. 43% of the time in the test set.", "labels": [], "entities": []}, {"text": "The use of hashtags differs markedly between languages.", "labels": [], "entities": []}, {"text": "Hashtags are much more frequent in the English training data than the Spanish training data, with English tweets 2.6 times more likely to contain at least one tag, and with tags occurring in English at 4.1 times the rate in Spanish.", "labels": [], "entities": [{"text": "English training data", "start_pos": 39, "end_pos": 60, "type": "DATASET", "confidence": 0.6330174803733826}]}, {"text": "In the English training data, the most frequent ten hashtags were 23% of the overall total and tended towards American political topics.", "labels": [], "entities": []}, {"text": "In Spanish, the top ten tags account for only 8% of the total, exhibiting a much longer and sparser tail.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Scores achieved with pre-training schemes.  Due to time constraints, the name-based training was  only done on Spanish models.", "labels": [], "entities": []}, {"text": " Table 2: Top LR word and character features.", "labels": [], "entities": []}]}