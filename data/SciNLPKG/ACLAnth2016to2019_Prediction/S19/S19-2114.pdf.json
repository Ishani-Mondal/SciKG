{"title": [{"text": "INGEOTEC at SemEval-2019 Task 5 and Task 6: A Genetic Programming Approach for Text Classification", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8108452260494232}]}], "abstractContent": [{"text": "This paper describes our participation in HatEval and OffensEval challenges for En-glish and Spanish languages.", "labels": [], "entities": []}, {"text": "We used several approaches, B4MSA, FastText, and EvoMSA.", "labels": [], "entities": []}, {"text": "Best results were achieved with EvoMSA, which is a multilingual and domain-independent architecture that combines the prediction from different knowledge sources to solve text classification problems.", "labels": [], "entities": [{"text": "text classification", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.722067192196846}]}], "introductionContent": [{"text": "Social media platforms, like Twitter and Facebook, are spaces where people interact with others and express themselves; while these platforms encourage free speech, other issues could emerge such as the usage of offensive language that could mock or insult individuals or groups of people.", "labels": [], "entities": []}, {"text": "Thus, detecting offenses and misbehavior expressed in text form is interesting to measure the people's feelings and warn them about possible attacks on others such as abusive language, hate speech, cyberbullying, trolling, among others (.", "labels": [], "entities": [{"text": "detecting offenses and misbehavior expressed in text form", "start_pos": 6, "end_pos": 63, "type": "TASK", "confidence": 0.8282542154192924}]}, {"text": "In order to tackle these text classifications problems, SemEval-2019 proposed two tasks: multilingual detection of hate speech against immigrants and women in Twitter HatEval, task 5 (, and identification and categorization of offensive language in social media OffensEval, task 6 (.", "labels": [], "entities": [{"text": "text classifications", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7087640166282654}, {"text": "multilingual detection of hate speech against immigrants and women in Twitter HatEval", "start_pos": 89, "end_pos": 174, "type": "TASK", "confidence": 0.7792112082242966}, {"text": "identification and categorization of offensive language in social media OffensEval", "start_pos": 190, "end_pos": 272, "type": "TASK", "confidence": 0.7956232011318207}]}, {"text": "In this paper, we present the results from our participating in these two tasks.", "labels": [], "entities": []}, {"text": "The HatEval challenge consists in detecting hate speech for two targets, immigrants and women, in Twitter for Spanish and English languages.", "labels": [], "entities": []}, {"text": "There are two subtasks, subtask A is a binary classification where systems have to predict whether a tweet with a given target (immigrants or women) is hateful or not hateful; subtask B is about aggressive behavior and target classification, systems are asked to classify hateful tweets as aggressive or not aggressive, and identify the target harassed (individual or group).", "labels": [], "entities": []}, {"text": "On the other hand, OffensEval challenge consists in determining if a given message has offensive content.", "labels": [], "entities": []}, {"text": "It is divided into three subtasks.", "labels": [], "entities": []}, {"text": "Subtask A is dedicated to identifying the offensive language, i.e., determine if a message is offensive or not offensive.", "labels": [], "entities": []}, {"text": "Subtask B is about categorizing offense types; that is, a tweet containing an insult or threat to someone, or a tweet containing nontargeted profanity and swearing.", "labels": [], "entities": []}, {"text": "Finally, subtask C focus on identifying the target, i.e., whether the offensive post is about an individual, a group, or others.", "labels": [], "entities": []}, {"text": "Both HatEval and OffensEval are related tasks to abusive language,) describe tasks on this theme; authors focus their analysis on two primary factors that could guide the modeling of systems: i) language is directed towards a specific individual, entity, or generalized group; ii) the abusive content maybe explicit or implicit.", "labels": [], "entities": []}, {"text": "For instance,) present a collection of works on hate speech detection highlighting the features commonly used such as surface-level features.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7560365994771322}]}, {"text": "For instance, authors use bag of words (n-grams) and character-level n-grams to attenuate the spelling variation issue on informal text, frequency of URL mentions, punctuation, token lengths, capitalization, among others; word generalization such as topic identification (LDA) and word embeddings (; outcomes from sentiment analysis classifiers (for example, samples predicted as negative polarity) as auxiliary evidence of hate for multi-step approaches; usage of lexical resources containing specific negative words (slurs, insults, etc.); linguistic aspects such as parts of speech and syntactic information; knowledge information such as ontologies and taxonomies (ConcepNet, WordNet, etc.).", "labels": [], "entities": [{"text": "topic identification (LDA)", "start_pos": 250, "end_pos": 276, "type": "TASK", "confidence": 0.8181438326835633}]}, {"text": "For both tasks, we use the same approach for final runs.", "labels": [], "entities": []}, {"text": "Our approach takes into account several features mentioned above.", "labels": [], "entities": []}, {"text": "For example, the effects of character-level n-grams are broadly studied for related tasks in ().", "labels": [], "entities": []}, {"text": "In particular, text modeling is a crucial factor in our approach; therefore we used the approach presented in () that selects the best configuration on the datasets concerned.", "labels": [], "entities": [{"text": "text modeling", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.8208491504192352}]}, {"text": "We also use external knowledge to the given training set to support the classification task; in this sense, our approach named EvoMSA ( \u00a72.1) is a stacking system based on genetic programming, and particularly on the use of semantic genetic operators, that focus on sentiment analysis, and, in general, on text classification.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 266, "end_pos": 284, "type": "TASK", "confidence": 0.9114336371421814}, {"text": "text classification", "start_pos": 306, "end_pos": 325, "type": "TASK", "confidence": 0.7911297976970673}]}], "datasetContent": [{"text": "As we mentioned, to determine the best configuration of parameters for text modeling, B4MSA integrates a hyper-parameter optimization phase that ensures the performance of the classifier based on the training data.", "labels": [], "entities": [{"text": "text modeling", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.7738551795482635}]}, {"text": "The text modeling parameters for B4MSA were set for all process as we show in for English and Spanish languages.", "labels": [], "entities": [{"text": "B4MSA", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.7644987106323242}]}, {"text": "A text transformation feature could be binary (yes/no) or ternary (group/delete/none) option.", "labels": [], "entities": [{"text": "text transformation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7334895581007004}]}, {"text": "Tokenizers denote how texts must be split after applying the process of each text transformation to texts.", "labels": [], "entities": []}, {"text": "Tokenizers generate text chunks in a range of lengths, all tokens generated are part of the text representation.", "labels": [], "entities": []}, {"text": "B4MSA allows selecting tokenizers based on n-words, q\u2212grams, and skip-grams, in any combination.", "labels": [], "entities": [{"text": "B4MSA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9109190702438354}]}, {"text": "We call n-words to the popular word ngrams; in particular, we allow to use any combination of unigrams, bigrams, and trigrams.", "labels": [], "entities": []}, {"text": "Also, the configuration space allows selecting any combination of character, q-grams, for q = 1 to 9.", "labels": [], "entities": []}, {"text": "Finally, we allow skip-grams such as (3, 1) and (2, 2), three words separated by one word (gap), and two words separated by two gaps.", "labels": [], "entities": []}, {"text": "We use two baselines B4MSA and the FastText's classifier () for both contests.", "labels": [], "entities": [{"text": "B4MSA", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.96028733253479}]}, {"text": "FastText represents sentences with a weighted bag of words, and each word is represented as a bag of character n-gram to create text vectors based on word embeddings.", "labels": [], "entities": []}, {"text": "Our custom FastText searches automatically the best parameters, e.g., for OffensEval with parameters such as window size = 9, learning rate = 0.01, epochs = 10, size of word vectors = 10, minimum and maximum length of character n-grams, 2 and 5, respectively; and some other preprocessing steps such as group numbers and reduce duplicated characters.", "labels": [], "entities": []}, {"text": "SemEval contests provide datasets to train systems for each task.", "labels": [], "entities": []}, {"text": "tion of the HatEval dataset.", "labels": [], "entities": [{"text": "HatEval dataset", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.9719291627407074}]}, {"text": "Hate class (HATE) defines tweets that convey hate against immigrants or women; its complement correspond to these messages not having hate content (NO-H), aggressive (AGGR) and no aggressive (NO-A), and target harassed (TARG) as individual and group.", "labels": [], "entities": [{"text": "target harassed (TARG)", "start_pos": 203, "end_pos": 225, "type": "METRIC", "confidence": 0.597164660692215}]}, {"text": "shows the OffensEval data distribution.", "labels": [], "entities": [{"text": "OffensEval data distribution", "start_pos": 10, "end_pos": 38, "type": "DATASET", "confidence": 0.9475054939587911}]}, {"text": "In Task A, class OFF defines tweets that have offenses or insults; while class NOT describes tweets with no offensive content.", "labels": [], "entities": [{"text": "OFF", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9832589626312256}, {"text": "NOT", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9409732222557068}]}, {"text": "Messages with labeled as TIN contain an insult or threat to an entity; UNT defines the opposite.", "labels": [], "entities": [{"text": "UNT", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.7572873830795288}]}, {"text": "Group (GRP), individual (IND), and others (OTH) classes contain the target of the offensive messages.", "labels": [], "entities": []}, {"text": "The OffensEval collection is described in detail in", "labels": [], "entities": [{"text": "OffensEval collection", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9664064347743988}]}], "tableCaptions": [{"text": " Table 2: Statistics of HatEval datasets.", "labels": [], "entities": [{"text": "HatEval datasets", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.9270663857460022}]}, {"text": " Table 3: Statistics of OffensEval datasets for English lan-", "labels": [], "entities": [{"text": "OffensEval datasets", "start_pos": 24, "end_pos": 43, "type": "DATASET", "confidence": 0.8988219201564789}, {"text": "English lan-", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.822715699672699}]}, {"text": " Table 4: Results of HateEval: Task A", "labels": [], "entities": [{"text": "HateEval", "start_pos": 21, "end_pos": 29, "type": "TASK", "confidence": 0.4566296935081482}]}, {"text": " Table 5: Results of HateEval: Task B", "labels": [], "entities": [{"text": "HateEval", "start_pos": 21, "end_pos": 29, "type": "TASK", "confidence": 0.594199538230896}]}]}