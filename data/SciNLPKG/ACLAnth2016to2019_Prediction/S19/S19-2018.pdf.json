{"title": [], "abstractContent": [{"text": "We present our system for semantic frame induction that showed the best performance in Subtask B.1 and finished as the runner-up in Subtask A of the SemEval 2019 Task 2 on un-supervised semantic frame induction (Qasem-iZadeh et al., 2019).", "labels": [], "entities": [{"text": "semantic frame induction", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.7104787429173788}, {"text": "SemEval 2019 Task 2 on un-supervised semantic frame induction", "start_pos": 149, "end_pos": 210, "type": "TASK", "confidence": 0.7346805002954271}]}, {"text": "Our approach separates this task into two independent steps: verb clustering using word and their context embed-dings and role labeling by combining these embeddings with syntactical features.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.7361292839050293}, {"text": "role labeling", "start_pos": 122, "end_pos": 135, "type": "TASK", "confidence": 0.7774141132831573}]}, {"text": "A simple combination of these steps shows very competitive results and can be extended to process other datasets and languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have seen a lot of interest in computational models of frame semantics, with the availability of annotated sources like PropBank () and FrameNet ().", "labels": [], "entities": []}, {"text": "Unfortunately, such annotated resources are very scarce due to their language and domain specificity.", "labels": [], "entities": []}, {"text": "Consequently, there has been work that investigated methods for unsupervised frame acquisition and parsing.", "labels": [], "entities": [{"text": "frame acquisition", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.6995322555303574}]}, {"text": "Researchers have used different approaches to induce frames, including clustering verb-specific arguments as per their roles (, subject-verb-object triples ( , syntactic dependency representation using dependency formats like CoNLL (, and latent-variable PCFG models ().", "labels": [], "entities": []}, {"text": "The SemEval 2019 task of semantic frame and role induction consists of three subtasks: (A) learning the frame type of the highlighted verb from the context in which it has been used; (B.1) clustering the highlighted arguments of the verb into specific roles as per the frame type of that verb, e.g., Buyer, Goods, etc.; (B.2) clustering the arguments into generic roles as per VerbNet classes (, without considering the frame type of the verb, i.e., Agent, Theme, etc.", "labels": [], "entities": [{"text": "semantic frame and role induction", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.5858625411987305}]}, {"text": "Our approach to frame induction is similar to the word sense induction approach by , which uses tf-idf-weighted context word embeddings fora shared task on word sense induction by . In this unsupervised task, our approach for clustering mainly consists of exploring the effectiveness of already available pre-trained models.", "labels": [], "entities": [{"text": "frame induction", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7907969653606415}, {"text": "word sense induction", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7012320955594381}]}, {"text": "1 Main contributions of this paper are: 1.", "labels": [], "entities": []}, {"text": "a method that uses contextualized distributional word representations (embeddings) for grouping verbs to frame type clusters (Subtask A); 2.", "labels": [], "entities": []}, {"text": "a method that combines word and context embeddings for clustering arguments of verbs to frame slots (Subtasks B.1 and B.2).", "labels": [], "entities": []}, {"text": "The key difference of our approach with respect to prior work by  and is that we have only used pre-trained embeddings to disambiguate the verb senses and then combined these embeddings with additional features for semantic labeling of the verb roles.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The methodology and the results for each subtask are discussed in Sections 2, 3 and 4 respectively, followed by the conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Our results on Subtask A: Grouping Verbs to  Frame Type Clusters. Purity F 1 -score is denoted as Pu  F 1 , B-Cubed F 1 -score is denoted as B 3 F 1 . denotes  our final submission (# 536426), denotes our post- competition result, denotes a baseline, and de- notes the submission of the winning team.", "labels": [], "entities": [{"text": "Purity F 1 -score", "start_pos": 76, "end_pos": 93, "type": "METRIC", "confidence": 0.9121545314788818}, {"text": "B-Cubed F 1 -score", "start_pos": 118, "end_pos": 136, "type": "METRIC", "confidence": 0.7989456295967102}]}, {"text": " Table 2: Our results on Subtask B.1: Clustering Ar- guments of Verbs to Frame-Specific Slots. Purity F 1 - score is denoted as Pu F 1 , B-Cubed F 1 -score is denoted  as B 3 F 1 . denotes our final submission (# 535483),  denotes a supervised Logistic Regression submission  that does not comply to the task rules, denotes our  post-competition result, denotes a baseline, and  denotes the submission of the winning team.", "labels": [], "entities": [{"text": "Ar- guments", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.8923609654108683}, {"text": "Purity F 1 - score", "start_pos": 95, "end_pos": 113, "type": "METRIC", "confidence": 0.878958547115326}, {"text": "B-Cubed F 1 -score", "start_pos": 137, "end_pos": 155, "type": "METRIC", "confidence": 0.7576959490776062}]}, {"text": " Table 3: Our results on Subtask B.2: Clustering Ar- guments of Verbs to Generic Roles. Purity F 1 -score  is denoted as Pu F 1 , B-Cubed F 1 -score is denoted as  B 3 F 1 . denotes our final submission (# 535480),  denotes a supervised Logistic Regression submission  that does not comply to the task rules, denotes our  post-competition result, denotes a baseline, and  denotes the submission of the winning team.", "labels": [], "entities": [{"text": "Purity F 1 -score", "start_pos": 88, "end_pos": 105, "type": "METRIC", "confidence": 0.8433056950569153}, {"text": "B-Cubed F 1 -score", "start_pos": 130, "end_pos": 148, "type": "METRIC", "confidence": 0.7600702166557312}]}]}