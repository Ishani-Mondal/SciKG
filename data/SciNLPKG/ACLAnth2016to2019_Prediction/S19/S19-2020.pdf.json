{"title": [{"text": "BrainEE at SemEval-2019 Task 3: Ensembling Linear Classifiers for Emotion Prediction", "labels": [], "entities": [{"text": "BrainEE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.715816080570221}, {"text": "Emotion Prediction", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8097496926784515}]}], "abstractContent": [{"text": "We present a homogeneous ensemble of linear perceptrons trained for emotion classification as part of the SemEval-2019 shared-task 3.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.7561762630939484}]}, {"text": "The model uses a matrix of probabilities to weight the activations of the base-classifiers and makes a final prediction using the sum rule.", "labels": [], "entities": []}, {"text": "The base-classifiers are multi-class perceptrons utilizing character and word n-grams, part-of-speech tags and sentiment polarity scores.", "labels": [], "entities": []}, {"text": "The results of our experiments indicate that the ensemble outperforms the base-classifiers, but only marginally.", "labels": [], "entities": []}, {"text": "In the best scenario our model attains an F-Micro score 1 of 0.672, whereas the base-classifiers attained scores ranging from 0.636 to 0.666.", "labels": [], "entities": [{"text": "F-Micro score 1", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.9622106353441874}]}], "introductionContent": [{"text": "Our task is to detect emotions in multi-turn chat messages (see examples in table 1).", "labels": [], "entities": []}, {"text": "The four emotion categories the model has choose from are happy, sad, angry and others.", "labels": [], "entities": []}, {"text": "A major caveat of the task is the imbalance of class distribution in the dataset, as described in 4.1.", "labels": [], "entities": []}, {"text": "The dataset, as well as the task itself are described in detail in (.", "labels": [], "entities": []}, {"text": "We choose to deploy ensemble of linear classifiers for this task, rather than a single model fora number of reasons.", "labels": [], "entities": []}, {"text": "Firstly, given the inherent ambiguity of emotions we expect that ensembles are better suited for any emotion prediction task.", "labels": [], "entities": [{"text": "emotion prediction task", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.8041098515192667}]}, {"text": "Secondly, it has been shown that ensembles are more immune to overfitting in similar tasks ().", "labels": [], "entities": []}, {"text": "And finally, a single model trained on a large number of feature sets, tend to perform significantly worse than an ensemble where each model is trained on a different subset (or combinations) of feature types.", "labels": [], "entities": []}, {"text": "For this purpose, we deploy BrainT, a multiclass perceptron model utilizing word n-grams and POS-tags, built and trained for implicit emotion detection in Tweets ().", "labels": [], "entities": [{"text": "implicit emotion detection", "start_pos": 125, "end_pos": 151, "type": "TASK", "confidence": 0.6859379808108012}]}, {"text": "In the current scenario, we extend the feature sets of BrainT with character n-grams and Sentiment polarity scores.", "labels": [], "entities": [{"text": "BrainT", "start_pos": 55, "end_pos": 61, "type": "DATASET", "confidence": 0.8933207392692566}]}, {"text": "We combine n = 11 and n = 5 classifiers into an ensemble model where a final prediction is made based on the activations.", "labels": [], "entities": []}, {"text": "Our model also calculates a matrix of probabilities used to weigh the input activations.", "labels": [], "entities": []}, {"text": "Each element in the matrix is the probability of a given node making correct prediction fora given emotion class.", "labels": [], "entities": []}, {"text": "In the initial experiments the nodes are trained on the full train data.", "labels": [], "entities": []}, {"text": "In the second group of experiments, nodes are assigned a random subsets of the train data separately.", "labels": [], "entities": []}, {"text": "We hope that this will promote diversity in the base-classifiers and boost the performance of the ensemble.", "labels": [], "entities": []}, {"text": "The results of our experiments indicate that in both cases the ensemble outperforms the baseclassifiers, however only slightly.", "labels": [], "entities": []}, {"text": "In the following sections we describe the architecture of the model, the actual results on the SemEval shared-task.", "labels": [], "entities": []}, {"text": "Finally we suggest ways to maximize the effectiveness of ensemble models as ideas for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset we use is provided by the SemEval2019 shared-task 3 and is described in detail by   is a significant difference between the class distributions in the train and test datasets as can be seen in tables 2 and 3 imposing an additional challenge for the classification task.", "labels": [], "entities": []}, {"text": "The evaluation metric of the shared task is a custom F-micro measure which takes only into account the three emotion classes (happy, angry, sad) and disregards the overrepresented class others.", "labels": [], "entities": []}, {"text": "We assign each node 2 to 4 feature types.", "labels": [], "entities": []}, {"text": "In the preparatory stage of the experiments we train nodes with different combinations of the feature The library is free-software and is available online: https://github.com/kevincobain2000/ sentiment_classifier   types and select the 11 highest ranking nodes.", "labels": [], "entities": []}, {"text": "Table 6 lists these nodes.", "labels": [], "entities": []}, {"text": "To overcome overrepresantation of the class others we apply a lower learning rate for this class.", "labels": [], "entities": []}, {"text": "We furthermore apply a higher learning rate for false negatives than false positives, since in the preparatory experiments all nodes showed a significantly lower Recall than Precision.", "labels": [], "entities": [{"text": "Recall", "start_pos": 162, "end_pos": 168, "type": "METRIC", "confidence": 0.9991320967674255}]}, {"text": "Finally, we test the ensemble model in two experimental setups: uniform learning and distributed learning.", "labels": [], "entities": []}, {"text": "In the first scenario, the entire train data is used to train the 11 nodes.", "labels": [], "entities": []}, {"text": "Either all 11 node activations are passed to the ensemble or only those of the 5 highest performing nodes.", "labels": [], "entities": []}, {"text": "In the second scenario, each node is assigned and trained on a random 50% subset of the train data.", "labels": [], "entities": []}, {"text": "For all our experiments we choose the number of epochs to be 60.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Class distribution in the train dataset.", "labels": [], "entities": []}, {"text": " Table 3: Class distribution in the test dataset.", "labels": [], "entities": []}, {"text": " Table 4: The feature types utilized by the base- classifiers.", "labels": [], "entities": []}, {"text": " Table 6: Results for Exp 1 with 11 nodes and uniform  training.", "labels": [], "entities": []}, {"text": " Table 7: Results for Exp 2 with 11 nodes and dis- tributed training.", "labels": [], "entities": []}]}