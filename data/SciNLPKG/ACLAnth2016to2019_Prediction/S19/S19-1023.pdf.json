{"title": [{"text": "Word Embeddings (Also) Encode Human Personality Stereotypes", "labels": [], "entities": [{"text": "Encode Human Personality Stereotypes", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.7212448567152023}]}], "abstractContent": [{"text": "Word representations trained on text reproduce human implicit bias related to gender, race and age.", "labels": [], "entities": []}, {"text": "Methods have been developed to remove such bias.", "labels": [], "entities": []}, {"text": "Here, we present results that show that human stereotypes exist even for much more nuanced judgments such as personality , fora variety of person identities beyond the typically legally protected attributes and that these are similarly captured in word representations.", "labels": [], "entities": []}, {"text": "Specifically, we collected human judgments about a person's Big Five personality traits formed solely from information about the occupation, nationality or a common noun description of a hypothetical person.", "labels": [], "entities": []}, {"text": "Analysis of the data reveals a large number of statistically significant stereotypes in people.", "labels": [], "entities": []}, {"text": "We then demonstrate the bias captured in lexical representations is statistically significantly correlated with the documented human bias.", "labels": [], "entities": []}, {"text": "Our results, showing bias fora large set of person descriptors for such nuanced traits put in doubt the feasibility of broadly and fairly applying debiasing methods and call for the development of new methods for auditing language technology systems and resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Implicit association tests probe biases individuals may harbor, by measuring the reaction times of people when asked to sort word stimuli with clearly positive/negative valance and words associated with racial groups or less morally relevant categories such as insects/flowers and musical instruments/weapons ().", "labels": [], "entities": []}, {"text": "Recent work has revealed that word representations trained on large text corpora reproduce human bias in preference to flowers and musical instruments, but also disturbingly on gender, race and age-related bias.", "labels": [], "entities": []}, {"text": "These findings pose a dilemma.", "labels": [], "entities": []}, {"text": "Having systems learn that flowers/musical instruments are pleasant and insects/weapons unpleasant appears to be useful commonsense knowledge that systems can leverage to better interact with people . Having racist, sexist and ageist systems however is highly undesirable, as these are integrated in broader technologies like machine translation, which can reinforce the stereotype 2 . Stereotypes are highly problematic because even simply evoking them can trigger change in behavior.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 325, "end_pos": 344, "type": "TASK", "confidence": 0.7552342712879181}]}, {"text": "Guided by these compelling arguments, many researchers have started looking for ways to debias word representations and language technologies.", "labels": [], "entities": []}, {"text": "In response to the examples in the supplementary materials in, that Google Translate translates 'doctor' as male and 'nurse' as female, Google has indeed rolled out anew version of their systems for certain language pairs, in which both translation versions are displayed . Similarly, earlier work has zeroed in on the gender bias in word representation and has proposed methods for debiasing, which take in a set of words to be debiased as an argument to the algorithm).", "labels": [], "entities": [{"text": "word representation", "start_pos": 334, "end_pos": 353, "type": "TASK", "confidence": 0.7400393784046173}]}, {"text": "Work further developing this line of analysis and debiasing has appeared in recent computational linguistics venues (.", "labels": [], "entities": []}, {"text": "This line of work is in stark contrast with earlier work in the field, which treated human stereotypes encoded in text as commonsense knowledge that could be helpful in automating tasks such as named entity tagging and coreference resolution (.", "labels": [], "entities": [{"text": "named entity tagging", "start_pos": 194, "end_pos": 214, "type": "TASK", "confidence": 0.6130096813042959}, {"text": "coreference resolution", "start_pos": 219, "end_pos": 241, "type": "TASK", "confidence": 0.9734950661659241}]}, {"text": "In this complex context, we set out to study how broad stereotypes are, both in terms of groups they may affect and the subtlety of distinction involved in the stereotype.", "labels": [], "entities": []}, {"text": "For this purpose, we turn to personality stereotypes evoked by a single descriptor of a person, such as nationality, profession and arbitrary words describing people.", "labels": [], "entities": []}, {"text": "We verify that people hold stereotypes about personality and that the human stereotypes can be recovered fairly accurately from word representations.", "labels": [], "entities": []}, {"text": "Given the wide variety of descriptors to which stereotypes apply, we argue that an approach different from classic debiasing approaches for dealing with the problem ought to be established.", "labels": [], "entities": []}, {"text": "We discuss some of these thoughts and considerations in the concluding section of this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Percentage of professions and nationalities with statistically significant human bias towards specific per- sonality traits i.e mean different from zero at 95% confidence using Wilcoxon signed rank test.", "labels": [], "entities": []}, {"text": " Table 2: Column 1 is percentage of professions or nationalities with n out of 5 statistically significant personality  traits i.e mean different from zero at 95% confidence using Wilcoxon signed rank test. Column 2 is percentage  of professions or nationalities with n out of 5 statistically significant personality traits and absolute value of mean  greater than equal to 1 indicating high bias.", "labels": [], "entities": [{"text": "Wilcoxon signed rank test", "start_pos": 180, "end_pos": 205, "type": "DATASET", "confidence": 0.6335088610649109}]}, {"text": " Table 4: Spearman correlation between human bias and predicted personality on the leave- one-out predictions for the training set, and on generic noun descriptions for the test set.", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8599340617656708}]}, {"text": " Table 5: Predicted scores on new descriptions.", "labels": [], "entities": [{"text": "Predicted scores", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.949460357427597}]}]}