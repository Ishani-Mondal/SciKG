{"title": [{"text": "MoonGrad at SemEval-2019 Task 3: Ensemble BiRNNs for Contextual Emotion Detection in Dialogues", "labels": [], "entities": [{"text": "Contextual Emotion Detection in Dialogues", "start_pos": 53, "end_pos": 94, "type": "TASK", "confidence": 0.7351870477199555}]}], "abstractContent": [{"text": "When reading \"I don't want to talk to you any more\", we might interpret this as either an angry or a sad emotion in the absence of context.", "labels": [], "entities": []}, {"text": "Often, the utterances are shorter, and given a short utterance like \"Me too!\", it is difficult to interpret the emotion without context.", "labels": [], "entities": []}, {"text": "The lack of prosodic or visual information makes it a challenging problem to detect such emotions only with text.", "labels": [], "entities": []}, {"text": "However, using contex-tual information in the dialogue is gaining importance to provide a context-aware recognition of linguistic features such as emotion, dialogue act, sentiment etc.", "labels": [], "entities": []}, {"text": "The SemEval 2019 Task 3 EmoContext competition provides a dataset of three-turn dialogues labeled with the three emotion classes, i.e. Happy, Sad and Angry , and in addition with Others as none of the aforementioned emotion classes.", "labels": [], "entities": [{"text": "SemEval 2019 Task 3 EmoContext competition", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.8075666725635529}]}, {"text": "We develop an ensemble of the recurrent neural model with character-and word-level features as an input to solve this problem.", "labels": [], "entities": []}, {"text": "The system performs quite well, achieving a microaveraged F1 score (F1) of 0.7212 for the three emotion classes.", "labels": [], "entities": [{"text": "F1 score (F1)", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.9057281136512756}]}], "introductionContent": [{"text": "Humans might interpret text wrongly when reading sentences in the absence of context, so machines might too.", "labels": [], "entities": []}, {"text": "When reading the following utterance, Why don't you ever text me?", "labels": [], "entities": []}, {"text": "it is hard to interpret the emotion where it can be either a sad or an angry emotion ().", "labels": [], "entities": []}, {"text": "The problem becomes even harder when there are ambiguous utterances, for example, the following utterance: Me too!", "labels": [], "entities": []}, {"text": "one cannot really interpret the emotion behind such an utterance in the absence of context.", "labels": [], "entities": []}, {"text": "See where the utterance \"Me too!\" is used in many emotional contexts such as sad, angry, and happy and also in the class \"others\" where none of aforementioned emotions is present.", "labels": [], "entities": []}, {"text": "Analyzing the emotion or sentiment of text provides the opinion cues expressed by the user.", "labels": [], "entities": [{"text": "Analyzing the emotion or sentiment of text", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7147367596626282}]}, {"text": "Such cues could assist computers to make better decisions to help users () or to prevent potentially dangerous situations.", "labels": [], "entities": []}, {"text": "Character-level deep neural networks have recently showed outstanding results on text understanding tasks such as machine translation and text classification (.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8195005357265472}, {"text": "machine translation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.8272386193275452}, {"text": "text classification", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.79783496260643}]}, {"text": "Usually, the utterances are short and contain mis-spelt words, emoticons, and hashtags, especially in the textual conversation.", "labels": [], "entities": []}, {"text": "Hence, using character-level language representations can theoretically capture the notion of such texts.", "labels": [], "entities": []}, {"text": "On the other hand, the EmoContext dataset is collected from the social media, and so the character language model used in our experiments is also trained on such a corpus (.", "labels": [], "entities": [{"text": "EmoContext dataset", "start_pos": 23, "end_pos": 41, "type": "DATASET", "confidence": 0.9608350992202759}]}, {"text": "We propose a system that encapsulates character-and word-level features and is modelled with recurrent and convolution neural networks (.", "labels": [], "entities": []}, {"text": "We used our recently developed models for the context-based dialogue act recognition (", "labels": [], "entities": [{"text": "context-based dialogue act recognition", "start_pos": 46, "end_pos": 84, "type": "TASK", "confidence": 0.6205902844667435}]}], "datasetContent": [{"text": "The final submitted result to the challenge is shown in.", "labels": [], "entities": []}, {"text": "The metric used for the challenge is the microaveraged F1 score (F1) for the three emotion classes, i.e. Happy, Sad and Angry.", "labels": [], "entities": [{"text": "F1 score (F1)", "start_pos": 55, "end_pos": 68, "type": "METRIC", "confidence": 0.9077677249908447}]}, {"text": "Our model performance was able compete quite well with the participating teams in the challenge.", "labels": [], "entities": []}, {"text": "The main goal to present these experiments is to explore the features used for contextual emotion detection.", "labels": [], "entities": [{"text": "contextual emotion detection", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.662596732378006}]}, {"text": "For the comparison of different language features (character and word), we consider calculating the accuracy overall four classes, in addition to F1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9996223449707031}, {"text": "F1", "start_pos": 146, "end_pos": 148, "type": "METRIC", "confidence": 0.9956529140472412}]}, {"text": "The experimental setup developed and each network is tested individually and in an ensemble way.", "labels": [], "entities": []}, {"text": "The results are reported in.", "labels": [], "entities": []}, {"text": "When the models train individually, the output of the model being trained is directly connected to the FCL as shown in dotted line in.", "labels": [], "entities": [{"text": "FCL", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.6916766166687012}]}, {"text": "From the results, it is clear that the average vec-  tor Char-LM AV Model outperforms the four individual networks.", "labels": [], "entities": [{"text": "vec-  tor Char-LM AV Model", "start_pos": 47, "end_pos": 73, "type": "METRIC", "confidence": 0.8553160031636556}]}, {"text": "As this model performs well, we also train a single FCL to seethe effect of the absence of context.", "labels": [], "entities": []}, {"text": "The ensemble models, Char-LM Models (Net1 and Net2) and Word Embs Models (Net3 and Net4) show a clearer pickup on accuracy than individuals.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9988530874252319}]}, {"text": "The final ensemble model clearly improves the overall performance.", "labels": [], "entities": []}, {"text": "However, we also ensemble the output predictions of all the networks trained individually, and average them at the end.", "labels": [], "entities": []}, {"text": "Such ensembling is also effective for the overall improvement in the performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples from training dataset, where turn3 is mostly the same while contextual emotion is different.", "labels": [], "entities": []}, {"text": " Table 2: EmoContext Data Distribution; first row rep- resents the total number of conversations in dataset.", "labels": [], "entities": [{"text": "EmoContext Data Distribution", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7460787693659464}, {"text": "first row rep- resents", "start_pos": 40, "end_pos": 62, "type": "METRIC", "confidence": 0.6904513835906982}]}, {"text": " Table 4: Results comparing our experimental setups.", "labels": [], "entities": []}]}