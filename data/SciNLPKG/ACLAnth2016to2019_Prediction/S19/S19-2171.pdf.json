{"title": [{"text": "Steve Martin at SemEval-2019 Task 4: Ensemble Learning Model for Detecting Hyperpartisan News", "labels": [], "entities": [{"text": "Detecting Hyperpartisan News", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.8542871077855428}]}], "abstractContent": [{"text": "This paper describes our submission to task 4 in SemEval 2019, i.e., hyperpartisan news detection.", "labels": [], "entities": [{"text": "SemEval 2019", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.8922023177146912}, {"text": "hyperpartisan news detection", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.7163718144098917}]}, {"text": "Our model aims at detecting hy-perpartisan news by incorporating the style-based features and the content-based features.", "labels": [], "entities": []}, {"text": "We extract abroad number of feature sets and use as our learning algorithms the GBDT and the n-gram CNN model.", "labels": [], "entities": [{"text": "GBDT", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.9603607654571533}]}, {"text": "Finally, we apply the weighted average for effective learning between the two models.", "labels": [], "entities": []}, {"text": "Our model achieves an accuracy of 0.745 on the test set in subtask A.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.999582827091217}]}], "introductionContent": [{"text": "The proliferation of misleading information in the media has made it challenging to identify trustworthy news sources, thus increasing the need for fake news detection tools able to provide insight into the reliability of news contents.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.7358913421630859}]}, {"text": "Since the spread of fake news is causing irreversible results, near-real-time fake news detection is crucial.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.729119618733724}]}, {"text": "However, knowledge-based and contextbased approaches to fake news detection can only be applied after publication; they may not be fast enough.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.719623843828837}]}, {"text": "As a practical alternative, style-based approaches try to detect fake news by capturing the manipulators in the writing style of news content.", "labels": [], "entities": []}, {"text": "This approach captures style signals that can indicate a decreased objectivity of news content and thus the potential to mislead consumers, such as hyperpartisan style.", "labels": [], "entities": []}, {"text": "Hyperpartisan style represents extreme behavior in favor of a particular political party, which often correlates with a strong motivation to create fake news.", "labels": [], "entities": []}, {"text": "Linguistic-based features can be applied to detect hyperpartisan articles (.", "labels": [], "entities": []}, {"text": "Deep network models, such as convolution neural networks (CNN), applied to classify fake news detection.", "labels": [], "entities": [{"text": "classify fake news detection", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.8607820272445679}]}, {"text": "In this paper, we employ the stylometrybased approach and N-gram CNN model for detecting hyperpartisan news.", "labels": [], "entities": [{"text": "detecting hyperpartisan news", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.8750648101170858}]}], "datasetContent": [{"text": "The statistics of the datasets provided by) are shown: Hyperpartisan news detection model.", "labels": [], "entities": [{"text": "news detection", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.6541246026754379}]}, {"text": "We conduct several experiments on each feature set to explore predictive separately.", "labels": [], "entities": []}, {"text": "In these experiments, we use the GDBC (i.e., XGBoost) for the above feature set.", "labels": [], "entities": []}, {"text": "For comparison with the Ngram model, we used the Char-level CNN model ().", "labels": [], "entities": []}, {"text": "The objective function was minimized through stochastic gradient descent over shuffled mini-batches with Adam().", "labels": [], "entities": []}, {"text": "The performance is evaluated using 5-fold cross validation with accuracy and F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9997305274009705}, {"text": "F-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9982252717018127}]}, {"text": "lists the experimental results for each feature set on the training dataset.", "labels": [], "entities": []}, {"text": "The prediction model through the incorporation of the entire feature showed higher accuracy than the prediction model for the individual feature.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9991574287414551}]}, {"text": "Our submission results to the subtask A on TIRA )-the web service platform to facilitate software submissions into virtual machine-achieve an accuracy of 0.745 (precision:  0.853, recall: 0.592, F1: 0.6999).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9994781613349915}, {"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.999077558517456}, {"text": "recall", "start_pos": 180, "end_pos": 186, "type": "METRIC", "confidence": 0.9994274377822876}, {"text": "F1", "start_pos": 195, "end_pos": 197, "type": "METRIC", "confidence": 0.9996417760848999}]}, {"text": "We ranked the 14th for subtask A in terms of accuracy.", "labels": [], "entities": [{"text": "A", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.8877626657485962}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9995094537734985}]}, {"text": "The prediction results of the test data are lower than the results of the training set, especially gains huge gap between precision and recall score.", "labels": [], "entities": [{"text": "precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.9996480941772461}, {"text": "recall score", "start_pos": 136, "end_pos": 148, "type": "METRIC", "confidence": 0.9840598702430725}]}], "tableCaptions": [{"text": " Table 1: Statistics of features.", "labels": [], "entities": []}, {"text": " Table 4: Experimental results on the subtask A dataset.", "labels": [], "entities": [{"text": "subtask A dataset", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.6818235715230306}]}]}