{"title": [{"text": "DUTH at SemEval-2019 Task 8: Part-Of-Speech Features for Question Classification", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7778958380222321}, {"text": "Question Classification", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7387136220932007}]}], "abstractContent": [{"text": "This report describes the methods employed by the Democritus University of Thrace (DUTH) team for participating in SemEval-2019 Task 8: Fact Checking in Community Question Answering Forums.", "labels": [], "entities": [{"text": "Democritus University of Thrace (DUTH) team", "start_pos": 50, "end_pos": 93, "type": "DATASET", "confidence": 0.6472258977591991}, {"text": "SemEval-2019 Task 8", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.9159011443456014}, {"text": "Fact Checking in Community Question Answering Forums", "start_pos": 136, "end_pos": 188, "type": "TASK", "confidence": 0.9213789275714329}]}, {"text": "Our team dealt only with Subtask A: Question Classification.", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7012382596731186}]}, {"text": "Our approach was based on shallow natural language processing (NLP) pre-processing techniques to reduce noise in data, feature selection methods, and supervised machine learning algorithms such as NearestCen-troid, Perceptron, and LinearSVC.", "labels": [], "entities": []}, {"text": "To determine the essential features, we were aided by exploratory data analysis and visualizations.", "labels": [], "entities": []}, {"text": "In order to improve classification accuracy, we developed a customized list of stopwords, retaining some opinion-and fact-denoting common function words which would have been removed by standard stoplisting.", "labels": [], "entities": [{"text": "classification", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.9533267617225647}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.8714661002159119}]}, {"text": "Furthermore, we examined the usefulness of part-of-speech (POS) categories for the task; by trying to remove nouns and adjectives, we found some evidence that verbs area valuable POS category for the opinion-oriented question class.", "labels": [], "entities": []}], "introductionContent": [{"text": "The significance of Community Question Answering (CQA) forums has risen in the past years.", "labels": [], "entities": [{"text": "Community Question Answering (CQA) forums", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.7635189933436257}]}, {"text": "Such forums represent a modern need for information that comes with the abundance of online sources and the needs of millions of people for answers.", "labels": [], "entities": []}, {"text": "Popular forums like StackOverflow, Yahoo!", "labels": [], "entities": []}, {"text": "Answers, and Answers.com provide platforms for general or specific questions in a wide range of topics by users' and also a communitybased model for user interaction.", "labels": [], "entities": []}, {"text": "The large numbers of questions and answers located in these forums generate many opportunities for information retrieval and data mining applications, such as query-intent detection, opinion mining, fake news classification, etc.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.7107097953557968}, {"text": "query-intent detection", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.7183886468410492}, {"text": "opinion mining", "start_pos": 183, "end_pos": 197, "type": "TASK", "confidence": 0.7865011990070343}, {"text": "fake news classification", "start_pos": 199, "end_pos": 223, "type": "TASK", "confidence": 0.6795781751473745}]}, {"text": "(. More advanced applications do not only aim at analyzing opinions but-by categorizing the feelings of the Q&As-they maybe able to detect inappropriate content such as hate speech and act accordingly (.", "labels": [], "entities": []}, {"text": "The SemEval Task 8, Fact Checking in Community Forums, aims to determine whether the answers that are provided fora question in a forum are true or false.", "labels": [], "entities": [{"text": "SemEval Task 8", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8713568250338236}, {"text": "Fact Checking in Community Forums", "start_pos": 20, "end_pos": 53, "type": "TASK", "confidence": 0.8804599523544312}]}, {"text": "While answers to factoriented questions can be deemed true or false, opinion-oriented and socializing questions evoke answers for which a true/false categorization does not make much sense.", "labels": [], "entities": []}, {"text": "As a result, determining the question type is a necessary first step.", "labels": [], "entities": []}, {"text": "Consequently, the subtask A of SemEval Task 8 has the goal of classifying questions in three categories: opinion, factual, or socializing.", "labels": [], "entities": [{"text": "SemEval Task 8", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.8863290548324585}]}, {"text": "The rest of this report is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews some previous studies for CQA classification.", "labels": [], "entities": [{"text": "CQA classification", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7339372932910919}]}, {"text": "Section 3 describes our system, while Section 4 presents experiments and results.", "labels": [], "entities": []}, {"text": "Conclusions are summarized in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The organizers provided the dataset in an XML format.", "labels": [], "entities": []}, {"text": "The given training set consisted of 1,118 questions for Subtask A that were selected from the Qatar Living forum.", "labels": [], "entities": [{"text": "Subtask A", "start_pos": 56, "end_pos": 65, "type": "TASK", "confidence": 0.8836163282394409}, {"text": "Qatar Living forum", "start_pos": 94, "end_pos": 112, "type": "DATASET", "confidence": 0.9728615482648214}]}, {"text": "We used Python's Element Tree library to parse and isolate specific content from the XML.", "labels": [], "entities": []}, {"text": "The interesting tags to select were RelQBody (the question) and RELQ FACT LABEL (labeled question by organizers).", "labels": [], "entities": [{"text": "RelQBody", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.5752022862434387}, {"text": "RELQ FACT LABEL", "start_pos": 64, "end_pos": 79, "type": "METRIC", "confidence": 0.8893582224845886}]}, {"text": "Before pre-processing, an exploratory data analysis gives us the opportunity to better understand the dataset.", "labels": [], "entities": []}, {"text": "Because we will develop a multipurpose model that classifies not only the opinion but fact and socializing questions, it is helpful to understand in depth the character of the questions.", "labels": [], "entities": []}, {"text": "A way to understand the contents of the forum is to examine where almost 50% of the questions are opinion oriented.", "labels": [], "entities": []}, {"text": "Also, presents the most common words in opinion questions.: Question types in the dataset: Most common words in opinion questions  This section summarizes our experiments in the context of SemEval 2019 Task 8 Subtask A. Beyond our officially submitted runs, we present 1 https://spacy.io 2 https://www.nltk.org/ some additional experiments that although they did not perform very well, there seems to be a promising room for improvement in the future.", "labels": [], "entities": [{"text": "SemEval 2019 Task 8 Subtask", "start_pos": 189, "end_pos": 216, "type": "TASK", "confidence": 0.8270583868026733}]}], "tableCaptions": [{"text": " Table 1: Question types in the dataset", "labels": [], "entities": []}, {"text": " Table 2: Test results with LinearSVC", "labels": [], "entities": [{"text": "LinearSVC", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.5081115365028381}]}, {"text": " Table 3: Test results with NearestCentroid", "labels": [], "entities": [{"text": "NearestCentroid", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.3378860354423523}]}, {"text": " Table 4: Test results with Perceptron", "labels": [], "entities": []}, {"text": " Table 5: Test results without Nouns", "labels": [], "entities": []}, {"text": " Table 6: Test results without Adjectives", "labels": [], "entities": [{"text": "Adjectives", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.6490747332572937}]}]}