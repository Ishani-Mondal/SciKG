{"title": [{"text": "Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. In HLT/EMNLP", "labels": [], "entities": [{"text": "Sproat. 2005.", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.961556077003479}, {"text": "text-based emotion prediction", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.6545678873856863}, {"text": "HLT/", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.7880953252315521}, {"text": "EMNLP", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.8080777525901794}]}], "abstractContent": [{"text": "This paper describes our approach to solve Se-meval task 3: EmoContext; where, given a tex-tual dialogue, i.e., a user utterance along with two turns of context, we have to classify the emotion associated with the utterance as one of the following emotion classes: Happy, Sad, Angry or Others.", "labels": [], "entities": []}, {"text": "To solve this problem, we experiment with different deep learning models ranging from simple LSTM to relatively more complex attention with Bi-LSTM model.", "labels": [], "entities": []}, {"text": "We also experiment with word embeddings such as ConceptNet along with word embeddings generated from bi-directional LSTM taking input characters.", "labels": [], "entities": []}, {"text": "We fine tune different parameters and hyper-parameters associated with each of our model and report the micro precision , micro recall and micro F1-score for each model.", "labels": [], "entities": [{"text": "micro precision", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.7330493927001953}, {"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.8302009701728821}, {"text": "F1-score", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.6714208126068115}]}, {"text": "We identify the Bi-LSTM model, along with the input word embedding taken as the concatenation of the embeddings generated from the bidirectional character LSTM and ConceptNet embedding, as the best performing model with a highest micro-F1 score over the test set as 0.7261.", "labels": [], "entities": []}, {"text": "References Muhammad Abdul-Mageed and Lyle H. Ungar.", "labels": [], "entities": []}, {"text": "2017. Emonet: Fine-grained emotion detection with gated recurrent neural networks.", "labels": [], "entities": [{"text": "Fine-grained emotion detection", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.6021677354971567}]}, {"text": "Acoustic profiles in vocal emotion expression.", "labels": [], "entities": [{"text": "vocal emotion expression", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.6747025648752848}]}, {"text": "Journal of personality and social psychology, 70 3:614-36.", "labels": [], "entities": []}, {"text": "Christos Baziotis, Nikos Pelekis, and Christos Doulk-eridis.", "labels": [], "entities": []}, {"text": "2017. Datastories at semeval-2017 task 4: Deep lstm with attention for message-level and topic-based sentiment analysis.", "labels": [], "entities": [{"text": "topic-based sentiment analysis", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.6340618232885996}]}], "introductionContent": [{"text": "In recent years, with the increase in the popularity of social media platforms, a significant amount of unstructured social media content (posts, tweets, messages etc.) has become available to the research community.", "labels": [], "entities": []}, {"text": "People use social media as a platform to share their opinions, emotions, thoughts etc.", "labels": [], "entities": []}, {"text": "This information has a huge potential to serve as a commercial catalyst to the business of companies and organizations, e.g., knowing the opinion of people about a product or a service could help the company to do betterment of their product or service according to the desire of the online consumers.", "labels": [], "entities": []}, {"text": "In similar lines, emotions from the peoples' comments/opinion can help us to model the future popularity of the product or the service.", "labels": [], "entities": []}, {"text": "Further, knowing public emotions about different events can help political parties to set their agenda for elections.", "labels": [], "entities": []}, {"text": "Thus mining of opinions and emotions has a lot of practical relevance.", "labels": [], "entities": [{"text": "mining of opinions and emotions", "start_pos": 5, "end_pos": 36, "type": "TASK", "confidence": 0.833812141418457}]}, {"text": "Even prior to the social media era, emotion detection had achieved significant attention of psychologists and linguistics.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.8420363068580627}]}, {"text": "An elaborate discussion of emotion as a research topic is presented in the next section.", "labels": [], "entities": []}, {"text": "In this paper, we describe our system and the models, with which, we achieved significant performance improvement over the SemEval baseline for task 3.", "labels": [], "entities": []}, {"text": "The task is described in (, where, given a textual dialogue, i.e., a user utterance along with two turns of context, we have to classify the emotion associated with the utterance into one of the following emotion classes: Happy, Sad, Angry or Others.", "labels": [], "entities": []}, {"text": "To solve this problem, we experiment with different deep learning models ranging from simple LSTMs to more complex attention based Bi-LSTM models.", "labels": [], "entities": []}, {"text": "We also experiment with different word embeddings such as ConceptNet along with word embeddings generated from bi-directional character LSTMs.", "labels": [], "entities": []}, {"text": "Our best model gives a micro F1 of 0.7261 on the test set released by the organizers.", "labels": [], "entities": [{"text": "F1", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.8274863958358765}]}], "datasetContent": [{"text": "The dataset consists of three parts, (i) training data, (ii) development data (dev set), and (iii) test data.", "labels": [], "entities": []}, {"text": "The training dataset consists of 30k conversations, where each conversation contains three turns of user utterances.", "labels": [], "entities": []}, {"text": "The dev set and the test set contains 2754 and 5508 conversations respectively.", "labels": [], "entities": []}, {"text": "These have been collected and annotated by the organisers.", "labels": [], "entities": [{"text": "organisers", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.8282835483551025}]}, {"text": "All of the conversations are classified into four classes, 'angry', 'sad', 'happy' and 'others'.", "labels": [], "entities": []}, {"text": "Training data consists of about 5k samples each from 'angry', 'sad', 'happy' class, and 15k samples from 'others' class, whereas, both dev and test sets have a real-life distribution, which is about 4% each of 'angry', 'sad', 'happy' class and the rest is 'others' class.", "labels": [], "entities": []}], "tableCaptions": []}