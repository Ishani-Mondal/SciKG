{"title": [], "abstractContent": [{"text": "Existing Machine Learning techniques yield close to human performance on text-based classification tasks.", "labels": [], "entities": [{"text": "text-based classification tasks", "start_pos": 73, "end_pos": 104, "type": "TASK", "confidence": 0.7469539244969686}]}, {"text": "However, the presence of multi-modal noise in chat data such as emoti-cons, slang, spelling mistakes, code-mixed data, etc.", "labels": [], "entities": []}, {"text": "makes existing deep-learning solutions perform poorly.", "labels": [], "entities": []}, {"text": "The inability of deep-learning systems to robustly capture these covariates puts a capon their performance.", "labels": [], "entities": []}, {"text": "We propose NELEC : Neural and Lexical Combiner, a system which elegantly combines textual and deep-learning based methods for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 126, "end_pos": 150, "type": "TASK", "confidence": 0.9388602375984192}]}, {"text": "We evaluate our system as part of the third task of 'Contextual Emotion Detection in Text' as part of SemEval-2019 (Chatterjee et al., 2019b).", "labels": [], "entities": [{"text": "Contextual Emotion Detection in Text'", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.7960247099399567}]}, {"text": "Our system performs significantly better than the baseline, as well as our deep-learning model benchmarks.", "labels": [], "entities": []}, {"text": "It achieved a micro-averaged F 1 score of 0.7765, ranking 3 rd on the test-set leader-board.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9658754467964172}]}, {"text": "Our code is available at https://github.com/ iamgroot42/nelec", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis of textual data: Twitter data (, movie reviews (, and product reviews (, is perhaps the most extensively explored problem, with a plethora of research to tackle it.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8670945465564728}]}, {"text": "Novel systems utilise deep learning architectures to achieve near-human performance on clean, well-formatted data.", "labels": [], "entities": []}, {"text": "However, sentiment classification of chat data is significantly challenging.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.9599288403987885}]}, {"text": "The presence of spelling errors, slang, emoticons, code-mixing, style of writing and abbreviations makes it significantly harder for existing deep-learning models to work on such data.", "labels": [], "entities": []}, {"text": "* Equal contribution, order determined by coin toss Literature dealing with this problem comprises a wide range of approaches: from hand-crafted features to end-to-end deep-learning methods.", "labels": [], "entities": []}, {"text": "Some rule-learning based methods use keywordbased analysis) and part-ofspeech tagging).", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.6855083256959915}]}, {"text": "These procedures require extensive human-involvement for identifying keywords and designing rules and are thus not scalable.", "labels": [], "entities": []}, {"text": "Non-neural machine-learning methods utilize feature extraction algorithms like n-grams and TfIdf vectors, coupled with classification algorithms like Naive Bayes (), Decision Trees (), SVM).", "labels": [], "entities": []}, {"text": "These approaches perform significantly better than rule-based approaches but fail to capture context well, since they ignore the order of words in text sequences.", "labels": [], "entities": []}], "datasetContent": [{"text": "To ascertain the novelty of our system, we report both class-wise and micro-averaged F 1 scores on the test set.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9724469780921936}]}, {"text": "We also compare our performance with the benchmarks provided by the contest organizers ().", "labels": [], "entities": []}, {"text": "As mentioned in Section 3.2, data preprocessing on deep-learning models leads to significant performance gains, while leading to a drop in performance when using NELEC.", "labels": [], "entities": []}, {"text": "NELEC outperforms both the baseline and our deep model by a considerable margin).", "labels": [], "entities": [{"text": "NELEC", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.5190138816833496}]}], "tableCaptions": [{"text": " Table 1: Some statistics for the given training, develop- ment and test sets.", "labels": [], "entities": []}, {"text": " Table 2: Class-wise and micro-averaged F 1 scores for  NELEC, our deep-learning model and existing base- line.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9399397174517313}, {"text": "NELEC", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.769279956817627}]}, {"text": " Table 3: Micro-averaged F 1 scores when all features apart from these (per row) are dropped. F 1 gain here refers  to the gain when using the feature mentioned, as opposed to dropping it.", "labels": [], "entities": [{"text": "Micro-averaged F 1 scores", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8137862235307693}, {"text": "F 1 gain", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9722559849421183}]}]}