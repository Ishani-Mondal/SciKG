{"title": [{"text": "NIT Agartala NLP Team at SemEval-2019 Task 6: An Ensemble Approach to Identifying and Categorizing Offensive Language in Twitter Social Media Corpora", "labels": [], "entities": [{"text": "NIT Agartala NLP Team at SemEval-2019 Task 6", "start_pos": 0, "end_pos": 44, "type": "DATASET", "confidence": 0.745313748717308}, {"text": "Identifying and Categorizing Offensive Language in Twitter Social Media Corpora", "start_pos": 70, "end_pos": 149, "type": "TASK", "confidence": 0.7066585749387742}]}], "abstractContent": [{"text": "The paper describes the systems submitted to OffensEval (SemEval 2019, Task 6) on 'Identifying and Categorizing Offensive Language in Social Media' by the 'NIT Agartala NLP Team'.", "labels": [], "entities": [{"text": "OffensEval (SemEval 2019, Task 6)", "start_pos": 45, "end_pos": 78, "type": "DATASET", "confidence": 0.7950155958533287}, {"text": "Identifying and Categorizing Offensive Language in Social Media", "start_pos": 83, "end_pos": 146, "type": "TASK", "confidence": 0.7944375723600388}, {"text": "NIT Agartala NLP Team", "start_pos": 156, "end_pos": 177, "type": "DATASET", "confidence": 0.9043579995632172}]}, {"text": "A Twitter annotated dataset of 13,240 English tweets was provided by the task organizers to train the individual models, with the best results obtained using an ensemble model composed of six different classifiers.", "labels": [], "entities": []}, {"text": "The ensemble model produced macro-averaged F 1-scores of 0.7434, 0.7078 and 0.4853 on Subtasks A, B, and C, respectively.", "labels": [], "entities": [{"text": "F 1-scores", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9354787766933441}]}, {"text": "The paper highlights the overall low predictive nature of various linguistic features and surface level count features, as well as the limitations of a traditional machine learning approach when compared to a Deep Learning counterpart.", "labels": [], "entities": []}], "introductionContent": [{"text": "Offensive language has been the scourge of the internet since the rise of social media.", "labels": [], "entities": []}, {"text": "Social media provides a platform for everyone and anyone to voice their opinion.", "labels": [], "entities": []}, {"text": "This has empowered people to make their voices heard and to speak out on global issues.", "labels": [], "entities": []}, {"text": "The downside to this, however, is the misuse of such platforms to attack an individual or a minority group, and to spread hateful opinions.", "labels": [], "entities": []}, {"text": "Pairing this with the perceived anonymity the internet provides, there has been a massive upswing in the use of social media for cyberbullying and hate speech, with technology giants coming under increased pressure to address the issue.", "labels": [], "entities": []}, {"text": "Most of what we maybe interested in detecting can be broadly labelled as hate speech, cyberbullying or abusive use of swearing.", "labels": [], "entities": []}, {"text": "The union of these three subsets form what can be identified as 'Offensive Language on Social Media'.", "labels": [], "entities": []}, {"text": "However, what we consider offensive is often a grey area, as is evident by the low inter-annotator agreement rates when labelling data for offensive language (.", "labels": [], "entities": []}, {"text": "Detecting offensive language has proven to be difficult, due to the broad spectrum in which language can be used to convey an insult.", "labels": [], "entities": [{"text": "Detecting offensive language", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9168555537859598}]}, {"text": "The nature of the abuse can be implicit -drawing from sarcasm and humour rather than offensive terms -as well as explicit, by making extensive use of traditional offensive terms and profanity.", "labels": [], "entities": []}, {"text": "It does not help that the reverse is also entertained, with profanity often being used to imply informality in speech or for emphasis.", "labels": [], "entities": []}, {"text": "Coincidentally, these are also the reasons why lexical detection methods have been unfruitful in classifying text as offensive or non-offensive.", "labels": [], "entities": [{"text": "lexical detection", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7612484097480774}]}, {"text": "The OffensEval 2019 shared task () is one of several endeavours to further the state-of-the-art in addressing the offensive language problem.", "labels": [], "entities": []}, {"text": "The paper describes the insights obtained when tackling the shared task using an ensemble of traditional machine learning classification models and a Long Short-Term Memory (LSTM) deep learning model.", "labels": [], "entities": []}, {"text": "Section 2 first discusses other related approaches to detecting hate speech and offensive language.", "labels": [], "entities": []}, {"text": "Then Section 3 describes the dataset and Section 4 the ideas and methodology behind our approach.", "labels": [], "entities": []}, {"text": "Section 5 reports the results obtained, while Section 6 discusses those results with a particular eye towards the errors committed by the models.", "labels": [], "entities": []}, {"text": "Finally, Section 7 sums up the key results and points to ways the work can be extended.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Ablation analysis on subtask A, with the training set.", "labels": [], "entities": [{"text": "Ablation analysis", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.821032851934433}]}, {"text": " Table 2: Test set results (macro-F 1 and accuracy) for all subtasks, with class baselines (\"All X\").", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9982459545135498}]}]}