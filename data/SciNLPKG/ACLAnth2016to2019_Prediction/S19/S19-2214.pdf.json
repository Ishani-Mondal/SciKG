{"title": [{"text": "NL-FIIT at SemEval-2019 Task 9: Neural Model Ensemble for Suggestion Mining", "labels": [], "entities": [{"text": "SemEval-2019 Task 9", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.5251955489317576}, {"text": "Suggestion", "start_pos": 58, "end_pos": 68, "type": "TASK", "confidence": 0.9775958061218262}]}], "abstractContent": [{"text": "In this paper, we present neural model architecture submitted to the SemEval-2019 Task 9 competition: \"Suggestion Mining from Online Reviews and Forums\".", "labels": [], "entities": [{"text": "SemEval-2019 Task 9 competition", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.6725969910621643}, {"text": "Suggestion Mining from Online Reviews and Forums", "start_pos": 103, "end_pos": 151, "type": "TASK", "confidence": 0.8924000092915126}]}, {"text": "We participated in both subtasks for domain specific and also cross-domain suggestion mining.", "labels": [], "entities": [{"text": "cross-domain suggestion mining", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.7570748726526896}]}, {"text": "We proposed a recurrent neural network architecture that employs Bi-LSTM layers and also self-attention mechanism.", "labels": [], "entities": []}, {"text": "Our architecture tries to encode words via word representations using ELMo and ensembles multiple models to achieve better results.", "labels": [], "entities": []}, {"text": "We performed experiments with different setups of our proposed model involving weighting of prediction classes for loss function.", "labels": [], "entities": []}, {"text": "Our best model achieved in official test evaluation score of 0.6816 for subtask A and 0.6850 for subtask B.", "labels": [], "entities": []}, {"text": "In official results, we achieved 12th and 10th place in subtasks A and B, respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "Review-based portals and online forums contain plethora of user-generated text.", "labels": [], "entities": []}, {"text": "We can consider customer reviews and inputs from online forums as an important source of novel information.", "labels": [], "entities": []}, {"text": "These texts often contain many different opinions, which are the subject of research in area of opinion mining.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.7334628999233246}]}, {"text": "On the other hand, there can be also different types of information within these texts, such as suggestions.", "labels": [], "entities": []}, {"text": "Unlike opinions, suggestions can appear in different parts of text and also appear more sparsely.", "labels": [], "entities": []}, {"text": "Suggestion mining, as defined in this task, can be realized as standard text classification.", "labels": [], "entities": [{"text": "Suggestion mining", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9734898209571838}, {"text": "text classification", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7582976818084717}]}, {"text": "We perform classification to two classes, which are suggestion and non-suggestion.", "labels": [], "entities": []}, {"text": "As presented by organizers, suggestion mining has different challenges (): \u2022 Class imbalance -suggestions appear very sparsely in reviews and forums and most of the samples are negatively sampled, \u2022 Figurative expressions -expression can be often found in social networks but it is not always inform of suggestion, \u2022 Context dependency -some sentences can be viewed as a suggestion, if it appears in specific domain or surrounded by specific sentences, \u2022 Long and complex sentences -suggestions can be expressed as only small part of original sentence, which can be much longer.", "labels": [], "entities": [{"text": "suggestion mining", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7411357164382935}]}, {"text": "Unlike opinions, suggestions can be more likely extracted also by pattern matching.", "labels": [], "entities": []}, {"text": "We can extract suggestions by different heuristic features and keywords, such as suggest, recommend, advise (.", "labels": [], "entities": []}, {"text": "Some works deal with domain terminology, thesaurus, linguistic parser and extraction rules.", "labels": [], "entities": []}, {"text": "Linguistic rules were also used for identification and extraction in sentiment expression.", "labels": [], "entities": [{"text": "identification and extraction in sentiment expression", "start_pos": 36, "end_pos": 89, "type": "TASK", "confidence": 0.6976088980833689}]}, {"text": "We believe that different extracted information from customer reviews and online forums can offer a valuable input for both customers and owners of products or forums and this information can be also a subject for automatic opinion summarization.", "labels": [], "entities": [{"text": "opinion summarization", "start_pos": 224, "end_pos": 245, "type": "TASK", "confidence": 0.6042424887418747}]}, {"text": "In this paper, we present a neural network architecture consisting of different types of layers, such as embedding, recurrent, transformer or selfattention layer.", "labels": [], "entities": []}, {"text": "We continued in our previous work on multi-level pre-processing ( ).", "labels": [], "entities": []}, {"text": "We performed experiments with different word representations, such as ELMo, BERT or GloVe.", "labels": [], "entities": [{"text": "BERT", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9950460195541382}]}, {"text": "We report results of our experiments along with error analysis of our models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we briefly summarize basic information about used dataset.", "labels": [], "entities": []}, {"text": "Later, we describe different setups of our model.", "labels": [], "entities": []}, {"text": "Each team could submit in total 4 submission as an official results.", "labels": [], "entities": []}, {"text": "For evaluation, binary F1 measure (F1 score over positive labels) was taken as an official results of submission.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9393579661846161}, {"text": "F1 score", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9662697911262512}]}, {"text": "The dataset for suggestion mining task consists of feedback posts on Universal Windows Platform available on uservoice.com.", "labels": [], "entities": [{"text": "suggestion mining task", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.8548328479131063}, {"text": "Universal Windows Platform", "start_pos": 69, "end_pos": 95, "type": "DATASET", "confidence": 0.9397364060084025}]}, {"text": "The dataset contains only labels for two categories: the text is suggestion or it is not.", "labels": [], "entities": []}, {"text": "The train dataset contains approximately 9 thousands of text samples.", "labels": [], "entities": []}, {"text": "For validation, there were available approximately 600 samples for subtask A and 800 samples for subtask B.", "labels": [], "entities": [{"text": "validation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9780817627906799}]}, {"text": "The size of test datasets were approximately 800 and 1000 samples for subtask A and B, respectively.", "labels": [], "entities": []}, {"text": "More detailed information can be found in the main paper of the task (Negi et al., 2019).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Official submission results in different measures", "labels": [], "entities": []}, {"text": " Table 2: Results of unsubmitted models in different  measures for subtask A", "labels": [], "entities": []}, {"text": " Table 3: Results of unsubmitted models in different  measures for subtask B", "labels": [], "entities": []}, {"text": " Table 4: Error analysis for submissions", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9742961525917053}, {"text": "submissions", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.7619702816009521}]}, {"text": " Table 5: Results of unsubmitted models in different  measures for subtask A", "labels": [], "entities": []}, {"text": " Table 6. We suppose that  further experiment would be needed with combi- nation of class re-balancing for loss and also fix- ing pre-trained weights. Since our language model  was trained with GloVe embeddings, we had to use  GloVe also in training for this task. Models 2 and  3 show results with change of class weight for loss  function to prefer positive labels", "labels": [], "entities": []}, {"text": " Table 6: Results of unsubmitted models in different  measures for subtask B", "labels": [], "entities": []}]}