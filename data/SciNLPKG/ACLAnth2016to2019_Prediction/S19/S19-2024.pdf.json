{"title": [{"text": "CLARK at SemEval-2019 Task 3: Exploring the Role of Context to Identify Emotion in a Short Conversation", "labels": [], "entities": [{"text": "CLARK", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7451792359352112}]}], "abstractContent": [{"text": "With text lacking valuable information available in other modalities, context may provide useful information to better detect emotions.", "labels": [], "entities": []}, {"text": "In this paper, we do a systematic exploration of the role of context in recognizing emotion in a conversation.", "labels": [], "entities": []}, {"text": "We use a Na\u00a8\u0131veNa\u00a8\u0131ve Bayes model to show that inferring the mood of the conversation before classifying individual utterances leads to better performance.", "labels": [], "entities": []}, {"text": "Additionally , we find that using context while training the model significantly decreases performance.", "labels": [], "entities": []}, {"text": "Our approach has the additional benefit that its performance rivals a baseline LSTM model while requiring fewer resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognizing affect (emotional content) in text has been an ongoing research challenge for roughly 20 years.", "labels": [], "entities": [{"text": "Recognizing affect (emotional content) in text", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8906527459621429}]}, {"text": "While earlier work focused on larger bodies of text, like movie reviews for sentiment analysis) or classifying mood in blog posts (), more recent work has looked at small bodies of text, particularly text from social media.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.9429600536823273}, {"text": "classifying mood in blog posts", "start_pos": 99, "end_pos": 129, "type": "TASK", "confidence": 0.8006810188293457}]}, {"text": "With smaller bodies of text inherently having less information, current efforts are investigating how context may supplement the information.", "labels": [], "entities": []}, {"text": "However, it is not yet clear how best to incorporate context.", "labels": [], "entities": []}, {"text": "To this end, we explore how mood and emotion from previous messages maybe used to better recognize emotions.", "labels": [], "entities": []}, {"text": "Mood and emotion are generally regarded as two types of affect.", "labels": [], "entities": []}, {"text": "Emotions are reactions and have a limited duration (;).", "labels": [], "entities": []}, {"text": "While emotions are dynamic and constantly changing, mood reflects a more persistent affect that can influence cognitive processes, including how people recognize emotions (.", "labels": [], "entities": []}, {"text": "For this work, we view mood as the affect present in the whole conversation and emotion as what is expressed in a given turn.", "labels": [], "entities": []}, {"text": "Our goal is to take a short, online conversation (see) and categorize the last utterance as happy, sad, angry, or others.", "labels": [], "entities": []}, {"text": "In this paper, we present our model Conversational Lexical Affect Recognition Kit (CLARK), which is the result of a systematic exploration into how context maybe used during the training and classification phases of a model to improve emotion recognition.", "labels": [], "entities": [{"text": "Conversational Lexical Affect Recognition", "start_pos": 36, "end_pos": 77, "type": "TASK", "confidence": 0.6059975847601891}, {"text": "emotion recognition", "start_pos": 235, "end_pos": 254, "type": "TASK", "confidence": 0.7281914353370667}]}, {"text": "To assess context we infer the mood of the conversation and the emotions of previous utterances.", "labels": [], "entities": []}, {"text": "Although context would seem to be useful, providing additional information, we find that is only beneficial during classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.9685025215148926}]}, {"text": "Conversely, including context while training the model leads to significantly degraded performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results from varying parameter classification  method and training on the whole conversation.", "labels": [], "entities": []}, {"text": " Table 2: Results from varying parameter classification  method and training on only T3.", "labels": [], "entities": []}]}