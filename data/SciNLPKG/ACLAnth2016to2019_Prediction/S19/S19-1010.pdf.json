{"title": [{"text": "Are We Consistently Biased? Multidimensional Analysis of Biases in Distributional Word Vectors", "labels": [], "entities": [{"text": "Multidimensional Analysis of Biases", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.8103433549404144}]}], "abstractContent": [{"text": "Word embeddings have recently been shown to reflect many of the pronounced societal biases (e.g., gender bias or racial bias).", "labels": [], "entities": []}, {"text": "Existing studies are, however, limited in scope and do not investigate the consistency of biases across relevant dimensions like embedding models, types of texts, and different languages.", "labels": [], "entities": []}, {"text": "In this work, we present a systematic study of biases encoded in distributional word vector spaces: we analyze how consistent the bias effects are across languages, corpora, and embedding models.", "labels": [], "entities": []}, {"text": "Furthermore, we analyze the cross-lingual biases encoded in bilingual embedding spaces, indicative of the effects of bias transfer encompassed in cross-lingual transfer of NLP models.", "labels": [], "entities": []}, {"text": "Our study yields some unexpected findings, e.g., that biases can be emphasized or downplayed by different embedding models or that user-generated content maybe less biased than encyclopedic text.", "labels": [], "entities": []}, {"text": "We hope our work cat-alyzes bias research in NLP and informs the development of bias reduction techniques.", "labels": [], "entities": [{"text": "bias reduction", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.752159833908081}]}], "introductionContent": [{"text": "Recent work demonstrated that word embeddings induced from large text collections encode many human biases (e.g.,.", "labels": [], "entities": []}, {"text": "This finding is not particularly surprising given that (1) we are likely project our biases in the text that we produce and (2) these biases in text are bound to be encoded in word vectors due to the distributional nature of the word embedding models (.", "labels": [], "entities": []}, {"text": "For illustration, consider the famous analogy-based gender bias example from: \"Man is to computer programmer as woman is to homemaker\".", "labels": [], "entities": []}, {"text": "This bias will be reflected in the text (i.e., the word man will co-occur more often with words like programmer or engineer, whereas woman will more often appear next to homemaker or nurse), and will, in turn, be captured byword embeddings built from such biased texts.", "labels": [], "entities": []}, {"text": "While biases encoded in word embeddings can be a useful data source for diachronic analyses of societal biases (e.g.,, they may cause ethical problems for many downstream applications and NLP models.", "labels": [], "entities": []}, {"text": "In order to measure the extent to which various societal biases are captured byword embeddings, proposed the Word Embedding Association Test (WEAT).", "labels": [], "entities": [{"text": "Word Embedding Association Test (WEAT)", "start_pos": 109, "end_pos": 147, "type": "DATASET", "confidence": 0.6519939814295087}]}, {"text": "WEAT measures semantic similarity, computed through word embeddings, between two sets of target words (e.g., insects vs. flowers) and two sets of attribute words (e.g., pleasant vs. unpleasant words).", "labels": [], "entities": []}, {"text": "While they test a number of biases, the analysis is limited in scope to English as the only language, GloVe) as the embedding model, and Common Crawl as the type of text.", "labels": [], "entities": []}, {"text": "Following the same methodology, extend the analysis to three more languages (German, Dutch, Spanish), but test only for gender bias.", "labels": [], "entities": []}, {"text": "In this work, we present the most comprehensive study of biases captured by distributional word vector to date.", "labels": [], "entities": []}, {"text": "We create XWEAT, a collection of multilingual and cross-lingual versions of the WEAT dataset, by translating WEAT to six other languages and offer a comparative analysis of biases over seven diverse languages.", "labels": [], "entities": [{"text": "WEAT dataset", "start_pos": 80, "end_pos": 92, "type": "DATASET", "confidence": 0.9089127480983734}]}, {"text": "Furthermore, we measure the consistency of WEAT biases across different embedding models and types of corpora.", "labels": [], "entities": [{"text": "consistency", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9929711222648621}, {"text": "WEAT biases", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.8480390012264252}]}, {"text": "What is more, given the recent surge of models for inducing cross-lingual embedding spaces (, inter alia) and their ubiquitous application in cross-lingual transfer of NLP models for downstream tasks, we investigate cross-lingual biases encoded in cross-lingual embedding spaces and compare them to bias effects present of corresponding monolingual embeddings.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.753576934337616}]}, {"text": "Our analysis yields some interesting findings: biases do depend on the embedding model and, quite surprisingly, they seem to be less pronounced in embeddings trained on social media texts.", "labels": [], "entities": []}, {"text": "Furthermore, we find that the effects (i.e., amount) of bias in cross-lingual embedding spaces can roughly be predicted from the bias effects of the corresponding monolingual embedding spaces.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: WEAT bias effects (EN FASTTEXT embed- dings trained on Wikipedia) for cosine similarity and  Euclidean distance. Asterisks indicate bias effects that  are insignificant at \u03b1 < 0.05.", "labels": [], "entities": [{"text": "WEAT bias", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6630315184593201}, {"text": "EN FASTTEXT embed- dings", "start_pos": 29, "end_pos": 53, "type": "METRIC", "confidence": 0.8413574695587158}]}, {"text": " Table 3: WEAT bias effects for spaces induced (on EN  Wikipedia) with different embedding models: CBOW,  GLOVE, FASTTEXT, and DICT2VEC methods. Aster- isks indicate bias effects that are insignificant at \u03b1 <  0.05.", "labels": [], "entities": [{"text": "WEAT", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.7358289957046509}, {"text": "EN  Wikipedia", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9705865383148193}, {"text": "GLOVE", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.8995423913002014}, {"text": "FASTTEXT", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.7995477318763733}]}, {"text": " Table 4: WEAT bias effects for GLOVE embeddings  trained on different corpora: Wikipedia (WIKI), Com- mon Crawl (CC), and corpus of tweets (TWEETS). As- terisks indicate bias effects that are insignificant at  \u03b1 < 0.05.", "labels": [], "entities": [{"text": "Wikipedia (WIKI)", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.8452979326248169}]}, {"text": " Table 5: XWEAT effects across languages (FASTTEXT  embeddings trained on Wikipedias). Avg all : average  of effects over all tests; Avg sig : average over the sub- set of tests yielding significant biases for all languages.  Asterisks indicate bias effects that are insignificant at  \u03b1 < 0.05.", "labels": [], "entities": [{"text": "Avg all", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9622347354888916}]}, {"text": " Table 6: XWEAT bias effects (aggregated over all six  tests) for cross-lingual word embedding spaces. Rows:  targets language; columns: attributes language. Aster- isks indicate the inclusion of bias effects sizes in the  aggregation that were insignificant at \u03b1 < 0.05.", "labels": [], "entities": []}, {"text": " Table 7: XWEAT T1 effect sizes for cross-lingual em- bedding spaces. Rows denote the target set language,  column the attribute set language.", "labels": [], "entities": [{"text": "XWEAT T1 effect sizes", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.6400597393512726}]}, {"text": " Table 8: XWEAT T2 effect sizes for cross-lingual em- bedding spaces. Rows denote the target set language,  column the attribute set language.", "labels": [], "entities": []}, {"text": " Table 9: XWEAT T6 effect sizes for cross-lingual em- bedding spaces. Rows denote the target set language,  column the attribute set language.", "labels": [], "entities": []}, {"text": " Table 10: XWEAT T7 effect sizes for cross-lingual em- bedding spaces. Rows denote the target set language,  column the attribute set language.", "labels": [], "entities": []}, {"text": " Table 11: XWEAT T8 effect sizes for cross-lingual em- bedding spaces. Rows denote the target set language,  column the attribute set language.", "labels": [], "entities": []}, {"text": " Table 12: XWEAT T9 effect sizes for cross-lingual em- bedding spaces. Rows denote the target set language,  column the attribute set language.", "labels": [], "entities": []}]}