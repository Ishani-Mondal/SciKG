{"title": [{"text": "KSU at SemEval-2019 Task 3: Hybrid Features for Emotion Recognition in Textual Conversation", "labels": [], "entities": [{"text": "KSU at SemEval-2019 Task", "start_pos": 0, "end_pos": 24, "type": "DATASET", "confidence": 0.8134667426347733}, {"text": "Emotion Recognition in Textual Conversation", "start_pos": 48, "end_pos": 91, "type": "TASK", "confidence": 0.6677832841873169}]}], "abstractContent": [{"text": "In this paper, we present the model submitted to the SemEval-2019 Task 3 competition: con-textual emotion detection in text \"EmoCon-text\".", "labels": [], "entities": [{"text": "SemEval-2019 Task 3 competition", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.7240407764911652}, {"text": "con-textual emotion detection", "start_pos": 86, "end_pos": 115, "type": "TASK", "confidence": 0.6441313425699869}]}, {"text": "We propose a model that hybridizes automatically extracted features and human engineered features to capture the representation of a textual conversation from different perspectives.", "labels": [], "entities": []}, {"text": "The proposed model utilizes a fast gated-recurrent-unit backed by CuDNN (CuDNNGRU), and a convolutional neural network (CNN) to automatically extract features.", "labels": [], "entities": []}, {"text": "The human engineered features take the term frequency-inverse document frequency (TF-IDF) of semantic meaning and mood tags extracted from SinticNet.", "labels": [], "entities": [{"text": "frequency-inverse document frequency (TF-IDF)", "start_pos": 44, "end_pos": 89, "type": "METRIC", "confidence": 0.7865122258663177}]}, {"text": "For the classification , a dense neural network (DNN) is used with a sigmoid activation function.", "labels": [], "entities": [{"text": "classification", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.9703234434127808}]}, {"text": "The model achieved a micro-F1 score of 0.6717 on the test dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Emotion recognition in text refers to the task of automatically assigning an emotion to a text selected from a set of predefined emotion labels.", "labels": [], "entities": [{"text": "Emotion recognition in text refers to the task of automatically assigning an emotion to a text selected from a set of predefined emotion labels", "start_pos": 0, "end_pos": 143, "type": "Description", "confidence": 0.7407914524277052}]}, {"text": "The) provides a textual dialogue and asks to classify the emotion as one of the emotion labels: happy, sad, and angry or others.", "labels": [], "entities": []}, {"text": "Previous research shows that emotion recognition has been performed on different types of text, including fairy tales  In this paper, we present an emotion recognition model that hybridizes human engineered features and automatically extracted features.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7519659101963043}, {"text": "emotion recognition", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.7516256868839264}]}, {"text": "For the human engineered features, we opted for calculating the term frequency-inverse document frequency (TF-IDF) of semantic meaning and mood tags retrieved from SenticNet.", "labels": [], "entities": [{"text": "frequency-inverse document frequency (TF-IDF)", "start_pos": 69, "end_pos": 114, "type": "METRIC", "confidence": 0.7890667219956716}]}, {"text": "For the automatically extracted features, we explored two deep neural networks, a fast gated-recurrent-unit backed by CuDNN (CuDNNGRU) and convolutional neural networks (CNN).", "labels": [], "entities": []}, {"text": "The classification is performed by a dense neural network (DNN).", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the task corpus.", "labels": [], "entities": []}, {"text": "Section 3 presents the proposed emotion recognition model.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7880224585533142}]}, {"text": "Section 4 presents the experimental results, and the main conclusions and future work are presented in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The code was implemented in Python.", "labels": [], "entities": []}, {"text": "We used the following libraries: NLTK 6 , scikit-learn 9 , and Keras 7 deep learning library run on a GPU, with the TensorFlow 10 backend.", "labels": [], "entities": []}, {"text": "We found the best hyper-parameters by evaluating on the development dataset.", "labels": [], "entities": []}, {"text": "We trained with a batch size of 32, for two epochs with Adam optimization and 0.0005 as a learning rate.", "labels": [], "entities": []}, {"text": "show the performance results obtained on the development dataset when only the automatically extracted features, and the human engineered features were used, respectively.", "labels": [], "entities": []}, {"text": "They show that automatically extracted features clearly lead to the best microaverage performance results (Precision=0.5398, Recall=0.7962, F1=0.6434) in comparison to those obtained with the human engineered features only (Precision=0.3858, Recall=0.6403, F1=0.4815).", "labels": [], "entities": [{"text": "Precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9907969236373901}, {"text": "Recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9982668161392212}, {"text": "F1", "start_pos": 140, "end_pos": 142, "type": "METRIC", "confidence": 0.9970405697822571}, {"text": "Recall", "start_pos": 242, "end_pos": 248, "type": "METRIC", "confidence": 0.9935764670372009}, {"text": "F1", "start_pos": 257, "end_pos": 259, "type": "METRIC", "confidence": 0.9981973767280579}]}, {"text": "presents the microaverage results obtained with the proposed model on the development dataset when both kinds of features were used altogether.", "labels": [], "entities": []}, {"text": "The model achieved its best precision and F1 results (precision=0.6014, F1=0.6852) and the same recall obtained with only the automatically extracted features (Recall=0.7962).", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9995170831680298}, {"text": "F1", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9998562335968018}, {"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9991826415061951}, {"text": "F1", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.9991170763969421}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9990277290344238}, {"text": "Recall", "start_pos": 160, "end_pos": 166, "type": "METRIC", "confidence": 0.9965037107467651}]}, {"text": "These performance results demonstrate the effectiveness of the proposed model.", "labels": [], "entities": []}, {"text": "It scored above the baseline () on the test dataset.", "labels": [], "entities": []}, {"text": "presents the microaverage results obtained (Precision=0.6098, Recall=0.7476, F1=0.6717).", "labels": [], "entities": [{"text": "Precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9994940757751465}, {"text": "Recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9995236396789551}, {"text": "F1", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9990261793136597}]}], "tableCaptions": [{"text": " Table 1: Performance results on the development  dataset using the automatically extracted features only.", "labels": [], "entities": []}, {"text": " Table 2: Performance results on the development  dataset using the human engineered features only.", "labels": [], "entities": []}, {"text": " Table 3: Performance results on the development  dataset using both automatically extracted features and  human engineered features.", "labels": [], "entities": []}, {"text": " Table 4: Performance results on the test dataset using  both automatically extracted features and human engi- neered features.", "labels": [], "entities": []}]}