{"title": [{"text": "ABARUAH at SemEval-2019 Task 5 : Bi-directional LSTM for Hate Speech Detection", "labels": [], "entities": [{"text": "ABARUAH", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9276784062385559}, {"text": "SemEval-2019 Task", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8413216769695282}, {"text": "Hate Speech Detection", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.8597408135732015}]}], "abstractContent": [{"text": "In this paper, we present the results obtained using bi-directional long short-term memory (BiLSTM) with and without attention and Logistic Regression (LR) models for SemEval-2019 Task 5 titled \"HatEval: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter\".", "labels": [], "entities": [{"text": "Logistic Regression (LR)", "start_pos": 131, "end_pos": 155, "type": "METRIC", "confidence": 0.8282960772514343}, {"text": "SemEval-2019 Task 5", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.895687202612559}, {"text": "Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter", "start_pos": 204, "end_pos": 281, "type": "TASK", "confidence": 0.804683270779523}]}, {"text": "This paper presents the results obtained for Subtask A for English language.", "labels": [], "entities": [{"text": "Subtask A", "start_pos": 45, "end_pos": 54, "type": "TASK", "confidence": 0.810602217912674}]}, {"text": "The results of the BiLSTM and LR models are compared for two different types of preprocessing.", "labels": [], "entities": []}, {"text": "One with no stemming performed and no stopwords removed.", "labels": [], "entities": []}, {"text": "The other with stemming performed and stopwords removed.", "labels": [], "entities": []}, {"text": "The BiLSTM model without attention performed the best for the first test, while the LR model with character n-grams performed the best for the second test.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.8704163432121277}]}, {"text": "The BiLSTM model obtained an F1 score of 0.51 on the test set and obtained an official ranking of 8/71.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.6449026465415955}, {"text": "F1 score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9839844703674316}]}], "introductionContent": [{"text": "has defined hate speech as \"language that is used to express hatred towards a targeted group or is intended to be derogatory, to humiliate, or to insult the members of the group.\",, and have used the term hate speech to indicate tweets having racist or sexist comments.", "labels": [], "entities": []}, {"text": "Social media is becoming a convenient medium to spread hate speech.", "labels": [], "entities": [{"text": "spread hate speech", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7435853282610575}]}, {"text": "Hate speech spread through social media has fueled riots in Myanmar 1 , Sri Lanka 2 , Charlottesville (USA) , and many other parts of the world.", "labels": [], "entities": []}, {"text": "Thus, it is becoming increasingly important to detect and remove hate messages from the web.", "labels": [], "entities": []}, {"text": "It is not possible to manually moderate the vast amount of text exchanged on the web.", "labels": [], "entities": []}, {"text": "Developing automated systems to recognize hate speech is becoming crucially important.", "labels": [], "entities": [{"text": "recognize hate speech", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7563709219296774}]}, {"text": "However, detecting hate speech in a text is more than just checking for the presence of hate words.", "labels": [], "entities": [{"text": "detecting hate speech in a text", "start_pos": 9, "end_pos": 40, "type": "TASK", "confidence": 0.8770408431688944}]}, {"text": "Lexicon based approaches have not been very effective in hate speech detection (.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.8608771959940592}]}, {"text": "As part of the 13th workshop on semantic evaluation, shared task 5 defines two subtasks with regard to detection of hate speech against immigrants and women in Twitter (.", "labels": [], "entities": [{"text": "semantic evaluation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8804179131984711}]}, {"text": "This task was conducted for tweets in English and Spanish language.", "labels": [], "entities": []}, {"text": "In Subtask A, it is required to determine if a tweet, with a given target, is hateful or not.", "labels": [], "entities": []}, {"text": "In Subtask B, it is required to determine if a given hateful tweet is aggressive or not and whether it targets an individual or a group.", "labels": [], "entities": []}, {"text": "studied the performance of different features such as character n-grams, word n-grams, word2vec, character2vec, etc.", "labels": [], "entities": []}, {"text": "A regression model was used in their study.", "labels": [], "entities": []}, {"text": "made a similar study to compare the performance of different features in detecting hate speech.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.857324500878652}]}, {"text": "used paragraph embeddings for detecting hate speech.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8044217030207316}]}, {"text": "worked on detecting insults in Wikipedia comments.", "labels": [], "entities": [{"text": "detecting insults in Wikipedia comments", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.8931936144828796}]}, {"text": "worked on detecting hate speech when hate words are not explicitly used in the text.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8961188793182373}]}, {"text": "used ensemble method and combined 16 different base classifiers to detect hate speech.", "labels": [], "entities": []}, {"text": "used character-based Recurrent Neural Network (RNN) to study the use of out-ofvocabulary words in hate speech.", "labels": [], "entities": []}, {"text": "used BiLSTMs with attention mechanism to detect hate speech.", "labels": [], "entities": []}, {"text": "used Convolutional Neural Network (CNN) and RNN with attention mechanism to moderate user comments.", "labels": [], "entities": []}, {"text": "compared the performance of several deep learning techniques, LR and Support Vector Machine (SVM) models in detecting hate speech.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.849803626537323}]}, {"text": "below shows the proportion of positive and negative instances of hate speech in the train, development and test data sets.", "labels": [], "entities": []}, {"text": "As can be seen, 42% of the instances in each of the data set are hate speech.", "labels": [], "entities": []}, {"text": "The data collected in  had only 0.6% hateful tweets.", "labels": [], "entities": []}, {"text": "found that only 5.9% of the online comments contained hate speech.", "labels": [], "entities": []}, {"text": "The data sets used for this task, however, are quite balanced.", "labels": [], "entities": []}, {"text": "The models used in our study were trained and validated using the train and development sets provided as part of this task.", "labels": [], "entities": []}, {"text": "No other external data sets were used for training or validating.", "labels": [], "entities": []}, {"text": "However, pre-trained GloVe 4 word vectors trained using 2 billion tweets were used as features for the two BiLSTM models.", "labels": [], "entities": []}, {"text": "The 200-dimensional word vectors were used in our experiments.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Hyperparameters for the BiLSTM model", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.8066064119338989}]}, {"text": " Table 4: Results of our models on Dev set of Task 5- Subtask A (No stemming + No Stopwords removed)", "labels": [], "entities": [{"text": "Dev set", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.8591229319572449}]}, {"text": " Table 5: Results of our models on Dev set of Task 5- Subtask A (Stemming + Stopwords removed)", "labels": [], "entities": []}, {"text": " Table 6: Official results for Task 5-Subtask A", "labels": [], "entities": []}]}