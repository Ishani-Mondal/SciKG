{"title": [{"text": "The Sally Smedley Hyperpartisan News Detector at SemEval-2019 Task 4: Learning Classifiers with Feature Combinations and Ensembling", "labels": [], "entities": [{"text": "Hyperpartisan News Detector", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.623389720916748}]}], "abstractContent": [{"text": "This paper describes our system submitted to the formal run of SemEval-2019 Task 4: Hy-perpartisan news detection.", "labels": [], "entities": [{"text": "SemEval-2019 Task 4", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.827400267124176}, {"text": "Hy-perpartisan news detection", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.7357234557469686}]}, {"text": "Our system is based on a linear classifier using several features , i.e., 1) embedding features based on the pre-trained BERT embeddings, 2) article length features, and 3) embedding features of informative phrases extracted from the by-publisher dataset.", "labels": [], "entities": [{"text": "BERT", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.6244796514511108}]}, {"text": "Our system achieved 80.9% accuracy on the test set for the formal run and got the 3rd place out of 42 teams.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9992002844810486}]}], "introductionContent": [{"text": "Hyperpartisan news detection () is a binary classification task, in which given a news article text, systems have to decide whether or not it follows a hyperpartisan argumentation, i.e., \"whether it exhibits blind, prejudiced, or unreasoning allegiance to one party, faction, cause, or person\".", "labels": [], "entities": [{"text": "Hyperpartisan news detection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6981570521990458}]}, {"text": "As resources for building such a system, the by-publisher and by-article datasets are provided by the organizer.", "labels": [], "entities": []}, {"text": "The by-publisher dataset is a collection of news articles labeled with the overall bias of the publisher as provided by BuzzFeed journalists or MediaBiasFactCheck.com.", "labels": [], "entities": []}, {"text": "The by-article dataset is a collection labeled through crowdsourcing on an article basis.", "labels": [], "entities": []}, {"text": "This data contains only the articles whose labels are agreed by all the crowd-workers.", "labels": [], "entities": []}, {"text": "The performance measure is accuracy on a balanced set of articles.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9992997646331787}]}, {"text": "Our system is based on a linear classifier using several types of features mainly consisting of 1) embedding features based on the pretrained BERT embeddings) and 2) article length features and 3) embedding features of informative phrases extracted from by-publisher dataset.", "labels": [], "entities": [{"text": "BERT", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.7282851934432983}]}, {"text": "Our system achieved 80.9% accuracy on the test set for the formal run and got 3rd place out of 42 teams in the formal run.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9991142153739929}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy of hyperpartisan classification for  each operation on BERT vectors.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9922590851783752}, {"text": "BERT", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.7701836824417114}]}, {"text": " Table 2: Accuracy of hyperpartisan classification for  each method to create N -gram set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9772985577583313}]}, {"text": " Table 3: Result of ablation.", "labels": [], "entities": [{"text": "ablation", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9417704939842224}]}]}