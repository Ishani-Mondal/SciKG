{"title": [{"text": "UHH-LT at SemEval-2019 Task 6: Supervised vs. Unsupervised Transfer Learning for Offensive Language Detection", "labels": [], "entities": [{"text": "UHH-LT at SemEval-2019 Task 6", "start_pos": 0, "end_pos": 29, "type": "DATASET", "confidence": 0.864022719860077}, {"text": "Offensive Language Detection", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.6813067495822906}]}], "abstractContent": [{"text": "We present a neural network based approach of transfer learning for offensive language detection.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.9123409688472748}, {"text": "offensive language detection", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.6272496581077576}]}, {"text": "For our system, we compare two types of knowledge transfer: supervised and unsu-pervised pre-training.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7852554619312286}]}, {"text": "Supervised pre-training of our bidirectional GRU-3-CNN architecture is performed as multi-task learning of parallel training of five different tasks.", "labels": [], "entities": []}, {"text": "The selected tasks are supervised classification problems from public NLP resources with some overlap to offensive language such as sentiment detection, emoji classification, and aggressive language classification.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.9569098353385925}, {"text": "emoji classification", "start_pos": 153, "end_pos": 173, "type": "TASK", "confidence": 0.8333448469638824}, {"text": "aggressive language classification", "start_pos": 179, "end_pos": 213, "type": "TASK", "confidence": 0.6253425975640615}]}, {"text": "Unsupervised transfer learning is performed with a thematic clustering of 40M unlabeled tweets via LDA.", "labels": [], "entities": [{"text": "Unsupervised transfer learning", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.68221116065979}]}, {"text": "Based on this dataset, pre-training is performed by predicting the main topic of a tweet.", "labels": [], "entities": []}, {"text": "Results indicate that unsupervised transfer from large datasets performs slightly better than supervised training on small 'near target category' datasets.", "labels": [], "entities": []}, {"text": "In the SemEval Task, our system ranks 14 out of 103 participants.", "labels": [], "entities": [{"text": "SemEval Task", "start_pos": 7, "end_pos": 19, "type": "TASK", "confidence": 0.9081615209579468}]}], "introductionContent": [{"text": "The automatic detection of hate speech, cyberbullying, abusive, aggressive or offensive language has become a vital field of research in natural language processing (NLP) during recent years.", "labels": [], "entities": [{"text": "automatic detection of hate speech", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.7775454044342041}, {"text": "natural language processing (NLP)", "start_pos": 137, "end_pos": 170, "type": "TASK", "confidence": 0.8085838556289673}]}, {"text": "Especially in social media, the tone of conversations escalates in a disturbing way that often threatens a free, democratic and argumentative discourse of users.", "labels": [], "entities": []}, {"text": "Concerning the tremendous amount of digital texts posted on platforms such as Twitter, Facebook or in comments sections of online newspapers, automatic approaches to offensive language detection are of high relevancy for moderation and filtering of content as well as for studying the phenomenon of offensive language use in social media at large scale.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 166, "end_pos": 194, "type": "TASK", "confidence": 0.8059380849202474}]}, {"text": "To take account of this development, a shared task on \"offensive language detection\" was conducted at the SemEval 2019 workshop.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6401191651821136}, {"text": "SemEval 2019 workshop", "start_pos": 106, "end_pos": 127, "type": "TASK", "confidence": 0.7495197057723999}]}, {"text": "This paper describes our approach to the shared task 6 (OffensEval) as organized and described in detail by.", "labels": [], "entities": []}, {"text": "The task contains three hierarchically ordered sub-tasks: Task A requires a classification of tweets into either offensive (OFF) or not offensive (NOT), Task B subdivides all offensive tweets into either targeted insults (TIN) or generally offensive expressions not targeted to any specific entity (UNT), and Task C finally asks to assign one out of three specific target labels to all targeted insults: groups (GRP, e.g. ethnic groups), individuals (IND, e.g. a politician or a specific Twitter user), or other (OTH, e.g. the media industry).", "labels": [], "entities": []}, {"text": "The dataset consisting of 14,100 examples (13,240 in the training set, 860 in the test set) was annotated via crowdsourcing (.", "labels": [], "entities": []}, {"text": "Each tweet was labeled by at least two annotators who must reach an agreement of at least 66% for including the tweet in the dataset.", "labels": [], "entities": []}, {"text": "The dataset is characterized by a high imbalance of label distributions, especially for Tasks B and C.", "labels": [], "entities": []}, {"text": "There are several challenges for automatic offensive language detection that render simple dictionary-based approaches unusable.", "labels": [], "entities": [{"text": "automatic offensive language detection", "start_pos": 33, "end_pos": 71, "type": "TASK", "confidence": 0.582718662917614}]}, {"text": "First, label distribution in the dataset is highly skewed for all sub-tasks.", "labels": [], "entities": []}, {"text": "Although offensive language is a growing problem for social media communication, it still accounts for only a small fraction of all content posted.", "labels": [], "entities": []}, {"text": "Second, language characteristics in social media pose a severe challenge to standard NLP tools.", "labels": [], "entities": []}, {"text": "Misspellings, slang vocabulary, emoticons and emojis, as well as ungrammatical punctuation must betaken into account fora successful solution.", "labels": [], "entities": []}, {"text": "Third, offensive language is highly context-dependent.", "labels": [], "entities": []}, {"text": "For instance, swear words are often used to mark overly positive emotion (\"This is fucking great!!!\"), and actually neutral and descriptive sentences can be conceived as derogatory if they refer to a specific individual (\"@Barack-Obama he is a Muslim\").", "labels": [], "entities": []}, {"text": "Our approach to the OffensEval shared task is based on two main contributions: First, we introduce a BiGRU-3CNN neural network architecture in combination with pre-trained sub-word embeddings that are able to handle social media language robustly.", "labels": [], "entities": []}, {"text": "Second, we investigate two types of knowledge transfer: supervised and unsupervised pre-training.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.839873731136322}]}, {"text": "Supervised pre-training of our neural network architecture is performed as multitask learning of parallel training of five different NLP tasks with some overlap to offensive language detection.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 164, "end_pos": 192, "type": "TASK", "confidence": 0.6461230715115865}]}, {"text": "Unsupervised transfer learning is performed with a thematic clustering of a large dataset of unlabeled tweets via LDA.", "labels": [], "entities": [{"text": "Unsupervised transfer learning", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6763655841350555}]}, {"text": "After shortly referencing related work (Section 2), we introduce both approaches in detail in Section 3 and present the results in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Model selection (cross-validation, macro-F1)", "labels": [], "entities": [{"text": "Model selection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7446863651275635}]}, {"text": " Table 2: Official test set performance results", "labels": [], "entities": []}]}