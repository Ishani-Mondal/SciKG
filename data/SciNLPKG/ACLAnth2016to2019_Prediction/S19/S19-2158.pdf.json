{"title": [{"text": "Linguistic Features for Hyperpartisan News Detection", "labels": [], "entities": [{"text": "Hyperpartisan News Detection", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.7164480288823446}]}], "abstractContent": [{"text": "This paper summarizes our contribution to the Hyperpartisan News Detection task in Se-mEval 2019.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection task", "start_pos": 46, "end_pos": 79, "type": "TASK", "confidence": 0.7946882098913193}]}, {"text": "We experiment with two different approaches: 1) an SVM classifier based on word vector averages and hand-crafted linguistic features, and 2) a BiLSTM-based neu-ral text classifier trained on a filtered training set.", "labels": [], "entities": []}, {"text": "Surprisingly, despite their different nature, both approaches achieve an accuracy of 0.74.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9995906949043274}]}, {"text": "The main focus of this paper is to further analyze the remarkable fact that a simple feature-based approach can perform on par with modern neural classifiers.", "labels": [], "entities": []}, {"text": "We also highlight the effectiveness of our filtering strategy for training the neural network on a large but noisy training set.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the era of misinformation, the challenge of differentiating reality from frames, facts from opinions, is becoming increasingly important.", "labels": [], "entities": []}, {"text": "Concepts such as Fake News, Fact Checking or PostTruth Era, generally unknown a few years ago (, started to play an important part in media, academic papers and even in Natural Language Processing (NLP) tasks.", "labels": [], "entities": [{"text": "Fake News", "start_pos": 17, "end_pos": 26, "type": "TASK", "confidence": 0.6780226230621338}, {"text": "Fact Checking", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.7283562272787094}]}, {"text": "Nowadays, strongly opinionated news stories can offer biased information, as is the case with hyperpartisan articles.", "labels": [], "entities": []}, {"text": "A text is considered hyperpartisan when it is highly polarized towards an extreme position.", "labels": [], "entities": []}, {"text": "analyzed hyperpartisanism in relation to fake news, to discover that a very similar writing style could be associated both with right-wing and left-wing polarized stories.", "labels": [], "entities": []}, {"text": "This shared style of biased articles was different from that of mainstream articles.", "labels": [], "entities": []}, {"text": "Task 4 in SemEval 2019 () consisted in a classification challenge where news articles had to be sorted out as hyperpartisan or nonhyperpartisan.", "labels": [], "entities": [{"text": "SemEval 2019", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.8721503913402557}]}, {"text": "Our approach addressed this challenge via two different models, which included 1) an SVM classifier based on word embeddings averages and handcrafted linguistic features and 2) a recurrent BiLSTM neural network classifier trained on filtered data.", "labels": [], "entities": []}, {"text": "The reason and process for filtering data will be explained in section 3.2.", "labels": [], "entities": []}, {"text": "Word embeddings have remained central to the state-of-the-art approaches in NLP since the introduction of) and GloVe () models.", "labels": [], "entities": []}, {"text": "In addition to modelling word meaning, embeddings can also be applied to longer units of significance, such as phrases, sentences, paragraphs or entire documents ().", "labels": [], "entities": []}, {"text": "However, although such vector representations often enable the best results in a variety of NLP challenges, some tasks still benefit from linguistically inspired approaches.", "labels": [], "entities": []}, {"text": "In fact, recent work has proved how linguistic features and stylometry could improve the performance of deep learning techniques.", "labels": [], "entities": []}, {"text": "The already mentioned work in Hyperpartisan and Fake News detection applied stylometry based on linguistic features to identify strongly biased articles.", "labels": [], "entities": [{"text": "Fake News detection", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.6047889888286591}]}, {"text": "Bag of words, stop words, part of speech and readability scores are some of the features analyzed by the authors.", "labels": [], "entities": []}, {"text": "They also focus on quotes, measuring their length and counting their appearances in a text.", "labels": [], "entities": []}, {"text": "Rhetorical questions or the appearance of personal pronouns, among many others linguistic features, also helped to classify suspicious vs trusted news posts on Twitter ().", "labels": [], "entities": [{"text": "classify suspicious vs trusted news posts", "start_pos": 115, "end_pos": 156, "type": "TASK", "confidence": 0.7947015166282654}]}, {"text": "The number of adverbs or swear words has also been used for fact checking purposes (.", "labels": [], "entities": [{"text": "fact checking", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.8160260319709778}]}, {"text": "Inspired by these previous works and their results, these linguistic features are some of the ones we apply in our first model.", "labels": [], "entities": []}, {"text": "The second model is based on word embeddings as input fora neural network.", "labels": [], "entities": []}, {"text": "Specifically, we used a Convolutional Neural Network (CNN) combined with a Bidirectional Long-Short Term Memory (BiLSTM) network.", "labels": [], "entities": []}, {"text": "The main novelty of this approach lies in the preprocessing step which filters the training data.", "labels": [], "entities": []}, {"text": "This strategy is used because the bulk of the training data only provides a weak supervision signal, which we found too noisy to use directly.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Linguistic features extracted from 645 articles  dataset.", "labels": [], "entities": []}, {"text": " Table 2: Ablation results for the first model in terms of  accuracy.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9977731108665466}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9994644522666931}]}]}