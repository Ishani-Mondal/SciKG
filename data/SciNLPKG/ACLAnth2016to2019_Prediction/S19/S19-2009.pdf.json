{"title": [{"text": "Fermi at SemEval-2019 Task 5: Using Sentence Embeddings to identify Hate Speech against Immigrants and Women on Twitter", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes our system (Fermi) for Task 5 of SemEval-2019: HatEval: Multilingual Detection of Hate Speech Against Immigrants and Women on Twitter.", "labels": [], "entities": [{"text": "Multilingual Detection of Hate Speech Against Immigrants and Women on Twitter", "start_pos": 77, "end_pos": 154, "type": "TASK", "confidence": 0.8357644297859885}]}, {"text": "We participated in the subtask A for English and ranked first in the evaluation on the test set.", "labels": [], "entities": []}, {"text": "We evaluate the quality of multiple sentence embeddings and explore multiple training models to evaluate the performance of simple yet effective embedding-ML combination algorithms.", "labels": [], "entities": []}, {"text": "Our team-Fermi's model achieved an accuracy of 65.00% for English language in task A.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9995895028114319}]}, {"text": "Our models, which use pretrained Universal En-coder sentence embeddings for transforming the input and SVM (with RBF kernel) for classification , scored first position (among 68) in the leaderboard on the test set for Subtask A in English language.", "labels": [], "entities": []}, {"text": "In this paper we provide a detailed description of the approach, as well as the results obtained in the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Microblogging platforms like Twitter provide channels to exchange ideas using short messages called tweets.", "labels": [], "entities": []}, {"text": "While such a platform can be used for constructive ideas, a small group of people can propagate their notions including hatred against an individual, or a group or a race to the entire world in a few seconds.", "labels": [], "entities": []}, {"text": "This necessitates the need to come up with computational methods to identify hate speech in user generated content.", "labels": [], "entities": [{"text": "identify hate speech in user generated content", "start_pos": 68, "end_pos": 114, "type": "TASK", "confidence": 0.6529714465141296}]}, {"text": "Using computational methods to identify offense, aggression and hate speech in user generated content has been gaining attention in the recent years as evidenced in ( and workshops such as Abusive Language Workshop (ALW)", "labels": [], "entities": [{"text": "identify offense, aggression and hate speech in user generated content", "start_pos": 31, "end_pos": 101, "type": "TASK", "confidence": 0.6558096977797422}, {"text": "Abusive Language Workshop (ALW)", "start_pos": 189, "end_pos": 220, "type": "TASK", "confidence": 0.62067844470342}]}], "datasetContent": [{"text": "The data collection methods used to compile the dataset used in HatEval is described in ().", "labels": [], "entities": []}, {"text": "We did not use any external datasets to augment the data for training our models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dev Set Accuracy and Macro-F1 scores(in percentage) for Sub-Task A-English.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9283615350723267}]}]}