{"title": [{"text": "YNU NLP at SemEval-2019 Task 5: Attention and Capsule Ensemble for Identifying Hate Speech", "labels": [], "entities": [{"text": "YNU NLP at SemEval-2019 Task 5", "start_pos": 0, "end_pos": 30, "type": "DATASET", "confidence": 0.7583176990350088}, {"text": "Identifying Hate Speech", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.9115906357765198}]}], "abstractContent": [{"text": "This paper describes the system submitted to SemEval 2019 Task 5: Multilingual detection of hate speech against immigrants and women in Twitter (hatEval).", "labels": [], "entities": [{"text": "SemEval 2019 Task", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.9051831761995951}, {"text": "Multilingual detection of hate speech", "start_pos": 66, "end_pos": 103, "type": "TASK", "confidence": 0.8694141983985901}]}, {"text": "Its main purpose is to conduct hate speech detection on Twitter, which mainly includes two specific different targets, immigrants and women.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.7147033413251241}]}, {"text": "We participate in both subtask A and subtask B for En-glish.", "labels": [], "entities": []}, {"text": "In order to address this task, we devel-ope an ensemble of an attention-LSTM model based on HAN and a BiGRU-capsule model.", "labels": [], "entities": []}, {"text": "Both models use fastText pre-trained embed-dings, and we use this model in both subtasks.", "labels": [], "entities": []}, {"text": "In comparison to other participating teams, our system is ranked 16th in the Subtask A for En-glish, and 12th in the Subtask B for English.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, the popularity of social networking and microblogging sites has increased, attracting more and more users.", "labels": [], "entities": []}, {"text": "With this huge user base, social media will continue to release a large number of user-generated content.", "labels": [], "entities": []}, {"text": "As the use of social media has grown, other undesirable phenomena and behaviors have emerged.", "labels": [], "entities": []}, {"text": "Social media users often abuse this freedom to spread abuse or hateful posts or comments.", "labels": [], "entities": []}, {"text": "In many cases, these usergenerated content is inherently offensive or proactive, and users may have to deal with threats such as cyber attacks or cyberbullying, as well as other undesirable phenomena.", "labels": [], "entities": []}, {"text": "So the problem of detecting and possibly limiting the spread of hate speech is becoming more and more important.", "labels": [], "entities": []}, {"text": "In order to solve the problem of abuse of language in social media platforms, some related research has been published, such as cyberbullying (, hate speech) and abusive language * Corresponding author), most methods are based on surveillance methods (.", "labels": [], "entities": []}, {"text": "There are also some (racial discrimination) bias towards specific goals.", "labels": [], "entities": []}, {"text": "In (, the authors proposed a series of criteria based on critical race theory to identify racism and gender discrimination, they use n-gram models for research; Tulkens et al. studied racism detection in Dutch social media.", "labels": [], "entities": [{"text": "racism detection in Dutch social media", "start_pos": 184, "end_pos": 222, "type": "TASK", "confidence": 0.7821710705757141}]}, {"text": "A recent discussion of the challenge of identifying hate speech was proposed by).", "labels": [], "entities": [{"text": "identifying hate speech", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.8878099918365479}]}, {"text": "The results show that it is difficult to distinguish between open and covert attacks in social media.", "labels": [], "entities": []}, {"text": "SemEval 2019 Task 5 is proposed to identify hate speech about immigrants and women in Twitter for English or Spanish, and classify hate speech and judge whether the target is an individual or a group (.", "labels": [], "entities": [{"text": "classify hate speech", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.8318660060564677}]}, {"text": "Hate speech is often defined as any communication that attacks an individual or group through certain characteristics (such as gender, nationality, religion, or other characteristics) in social media platforms.", "labels": [], "entities": [{"text": "Hate speech is often defined as any communication that attacks an individual or group through certain characteristics (such as gender, nationality, religion, or other characteristics) in social media platforms", "start_pos": 0, "end_pos": 209, "type": "Description", "confidence": 0.8478392196052215}]}, {"text": "This task gives us some text data from Twitter, we need to classify the content through computational analysis.", "labels": [], "entities": []}, {"text": "The task has two subtasks, in which Subtask A is Hate speech detection for immigrants and women: It's a binary classification task, the system must judge whether a tweet with a specific goal (female or immigrant) in English or Spanish is hate speech; Subtask B is Aggressive behavior and target classification: This subtask is to classify the identified hate speech based on Subtask A, to judge whether it is aggressive or non-aggressive, and then to identify the target being harassed as an individual or group.", "labels": [], "entities": [{"text": "Hate speech detection", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7173229257265726}]}, {"text": "In this paper, we developped a system stacked two different neural network models: an attentionbased model with LSTMs and an Capsule-based model with BiGRUs.", "labels": [], "entities": []}, {"text": "We make some changes to Hierarchical Attention Network to make it more suitable for this task, the detailed description of the Attention-LSTM model is provided in Section 2.2.", "labels": [], "entities": []}, {"text": "Next, we build a BiGRU-Capsule model using the latest \"Capsule\" model proposed by, the detailed description is provided in Section 2.3.", "labels": [], "entities": []}, {"text": "In Section 2.4, we describe the use of stacking as ensemble.", "labels": [], "entities": []}, {"text": "In Section 3.1, some details about data preprocessing for this task are described.", "labels": [], "entities": []}, {"text": "In Section 3.2 and Section 3.3, the hyperparameter setting and result analysis used in the whole experiment are introduced in detail.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 is the result  of different word vectors as embedding.", "labels": [], "entities": []}, {"text": " Table 2: The results of using BiGRU, LSTM, Bi- LSTM with the attention mechanism for development  data set in Subtask A.", "labels": [], "entities": [{"text": "BiGRU", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.8673388957977295}, {"text": "Bi- LSTM", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8499884009361267}]}, {"text": " Table 3: The result of different model for development  data set in Subtask A.", "labels": [], "entities": []}, {"text": " Table 5: The results of our test data set and the top  three results of the official rankings in Subtask B.", "labels": [], "entities": []}]}