{"title": [{"text": "Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets Hyperpartisan News Detection", "labels": [], "entities": [{"text": "Hyperpartisan News Detection", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.568175345659256}]}], "abstractContent": [{"text": "We describe our submission to SemEval-2019 Task 4 on Hyperpartisan News Detection.", "labels": [], "entities": [{"text": "SemEval-2019 Task 4", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.811058779557546}, {"text": "Hyperpartisan News Detection", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.6639201442400614}]}, {"text": "We rely on a variety of engineered features originally used to detect propaganda.", "labels": [], "entities": []}, {"text": "This is based on the assumption that biased messages are propagandistic and promote a particular political cause or viewpoint.", "labels": [], "entities": []}, {"text": "In particular, we trained a logistic regression model with features ranging from simple bag of words to vocabulary richness and text readability.", "labels": [], "entities": []}, {"text": "Our system achieved 72.9% accuracy on the manually annotated testset, and 60.8% on the test data that was obtained with distant supervision.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995056390762329}]}, {"text": "Additional experiments showed that significant performance gains can be achieved with better feature pre-processing.", "labels": [], "entities": []}], "introductionContent": [{"text": "The rise of social media has enabled people to easily share information with a large audience without regulations or quality control.", "labels": [], "entities": []}, {"text": "This has allowed malicious users to spread disinformation and misinformation (a.k.a. \"fake news\") at an unprecedented rate.", "labels": [], "entities": []}, {"text": "Fake news is typically characterized as being hyperpartisan (one-sided), emotional and riddled with lies ().", "labels": [], "entities": [{"text": "Fake news", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9401485919952393}]}, {"text": "The SemEval-2019 Task 4 on Hyperpartisan News Detection () focused on the challenge of automatically identifying whether a text is hyperpartisan or not.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.5709756314754486}]}, {"text": "While hyperpartisanship is defined as \"exhibiting one or more of blind, prejudiced, or unreasoning allegiance to one party, faction, cause, or person\", we model this task as a binary document classification problem.", "labels": [], "entities": [{"text": "binary document classification", "start_pos": 176, "end_pos": 206, "type": "TASK", "confidence": 0.7115688323974609}]}, {"text": "Scholars have argued that all biased messages can be considered propagandistic, regardless of whether the bias was intentional or not, p.", "labels": [], "entities": []}, {"text": "Thus, we approached the task departing from an existing model for propaganda identification . Our hypothesis is that propaganda is inherent in hyperpartisanship and that the two problems are two sides of the same coin, and thus solving one of them would help solve the other.", "labels": [], "entities": [{"text": "propaganda identification", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.7494169175624847}]}, {"text": "Our system consists of a logistic regression model that is trained with a variety of engineered features that range from word and character TF.IDF n-grams and lexicon-based features to more sophisticated features that represent different aspects of the article's text such vocabulary richness and language complexity.", "labels": [], "entities": []}, {"text": "Our official submission achieved an accuracy of 72.9% (while the winning system achieved 82.2%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9997218251228333}]}, {"text": "This was achieved using word and character n-grams.", "labels": [], "entities": []}, {"text": "Moreover, post-submission experiments have shown that further performance improvements can be achieved by carefully preprocessing the engineered features.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained our models on the Hyperpartisan News Dataset from SemEval-2019 Task 4 (), which is split by the task organizers into (i) Labeled by-Publisher, with 750K articles labeled via distant supervision, i.e., using labels for their publisher.", "labels": [], "entities": [{"text": "Hyperpartisan News Dataset from SemEval-2019 Task 4", "start_pos": 29, "end_pos": 80, "type": "DATASET", "confidence": 0.86244079044887}]}, {"text": "The labels are evenly distributed between \"hyperpartisan\" and \"not-hyperpartisan.\"", "labels": [], "entities": []}, {"text": "This set is further split into 600K articles for training and 150K for validation.", "labels": [], "entities": []}, {"text": "(ii) Labeled by-Article: This set contains 645 articles labeled using crowd-sourcing (37% are hyperpartisan and 63% are not).", "labels": [], "entities": []}, {"text": "Only articles with a consensus among the annotators were included.", "labels": [], "entities": []}, {"text": "We trained a logistic regression (LR) model with a Stochastic Average Gradient solver () due to the large size of the dataset.", "labels": [], "entities": [{"text": "Stochastic Average Gradient solver", "start_pos": 51, "end_pos": 85, "type": "METRIC", "confidence": 0.6584812849760056}]}, {"text": "In order to reduce overfitting, we used L 2 regularization (with C = 1 as the regularization parameter).", "labels": [], "entities": []}, {"text": "Moreover, feature normalization was needed since the different features represent different aspects of the text, and thus have very different scales.", "labels": [], "entities": [{"text": "feature normalization", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6757447123527527}]}, {"text": "We tried to normalize each feature set by subtracting the mean and then scaling it to unit variance.", "labels": [], "entities": []}, {"text": "However, we found that multiplying the features by constant scaling factors resulted in better performance.", "labels": [], "entities": []}, {"text": "The scaling factor for each family of features was a hyperparameter that we tuned on the validation dataset.", "labels": [], "entities": []}, {"text": "We trained the classifier using the 600K training examples annotated by-Publisher, then we used the remaining 150K examples for evaluation.", "labels": [], "entities": []}, {"text": "We fine-tuned the hyperparameters on the 645 byArticle examples.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An incremental analysis showing the performance of different feature combinations, evaluated on the  validation datasets labeled by article and by publisher.", "labels": [], "entities": []}]}