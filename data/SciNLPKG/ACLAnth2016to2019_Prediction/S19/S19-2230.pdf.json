{"title": [{"text": "UNH at SemEval-2019 Task 12: Toponym Resolution in Scientific Papers", "labels": [], "entities": [{"text": "UNH at SemEval-2019 Task 12", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8410094857215882}, {"text": "Toponym Resolution", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.901187002658844}]}], "abstractContent": [{"text": "The SemEval-2019 Task 12 is toponym resolution in scientific papers.", "labels": [], "entities": [{"text": "SemEval-2019 Task 12", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8013101021448771}, {"text": "toponym resolution", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.8247540295124054}]}, {"text": "We focus on Subtask 1: Toponym Detection which is the identification of spans of text for place names mentioned in a document.", "labels": [], "entities": [{"text": "Subtask 1: Toponym Detection", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6485314190387725}, {"text": "identification of spans of text for place names mentioned in a document", "start_pos": 54, "end_pos": 125, "type": "TASK", "confidence": 0.8534624924262365}]}, {"text": "We propose two methods: 1) sliding window convolutional neu-ral network using ELMo embeddings (CNN-ELMo), and 2) sliding window multi-Layer perceptron using ELMo embeddings (MLP-ELMo).", "labels": [], "entities": []}, {"text": "We also submit a bi-directional LSTM with Conditional Random Fields (bi-LSTM) as a strong baseline given its state-of-art performance in Named Entity Recognition (NER) task.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) task", "start_pos": 137, "end_pos": 172, "type": "TASK", "confidence": 0.8093585627419608}]}, {"text": "Our best performing model is CNN-ELMo with a F1 of 0.844 which was below bi-LSTM F1 of 0.862 when evaluated on overlap macro detection.", "labels": [], "entities": [{"text": "CNN-ELMo", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.8403856158256531}, {"text": "F1", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9991727471351624}, {"text": "bi-LSTM F1", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.6239466667175293}, {"text": "overlap macro detection", "start_pos": 111, "end_pos": 134, "type": "TASK", "confidence": 0.6114099125067393}]}, {"text": "Eight teams participated in this subtask with a total of 21 submissions .", "labels": [], "entities": []}], "introductionContent": [{"text": "Toponyms are textual spans of text identifying geospatial locations.", "labels": [], "entities": []}, {"text": "This can range from the canonical name of populated places, such as \"London\" to director indirect mentions of geographic entities.", "labels": [], "entities": [{"text": "London", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.9392219185829163}]}, {"text": "The parsing of geographic locations from unstructured text is considered an open challenge due to domain diversity, place name ambiguity, metonymic language and often limited leveraging of context ().", "labels": [], "entities": [{"text": "parsing of geographic locations from unstructured text", "start_pos": 4, "end_pos": 58, "type": "TASK", "confidence": 0.8609870757375445}]}, {"text": "Many scientific publications contain toponyms which can be challenging to extract automatically.", "labels": [], "entities": []}, {"text": "Specifically, names of institutions and viruses often contain geographic references which may confuse the extractor.", "labels": [], "entities": []}, {"text": "Often, the extractor needs to handle noisy text parsed from PDF versions of scientific articles which can introduce artifacts.", "labels": [], "entities": []}, {"text": "In Task 12, a toponym is defined to include proper names and geographic entities but to exclude indirect mentions of places and metonyms.", "labels": [], "entities": []}, {"text": "Additional discussion of the motivation and task description is available at the task website.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Gold Standard Corpus Statistics", "labels": [], "entities": [{"text": "Gold Standard Corpus Statistics", "start_pos": 10, "end_pos": 41, "type": "DATASET", "confidence": 0.9664505869150162}]}]}