{"title": [{"text": "Nikolov-Radivchev at SemEval-2019 Task 6: Offensive Tweet Classification with BERT and Ensembles", "labels": [], "entities": [{"text": "Offensive Tweet Classification", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.7935391863187155}, {"text": "BERT", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9344429969787598}]}], "abstractContent": [{"text": "This paper examines different approaches and models towards offensive tweet classification which were used as apart of the OffensE-val 2019 competition.", "labels": [], "entities": [{"text": "offensive tweet classification", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.6844188968340555}, {"text": "OffensE-val 2019 competition", "start_pos": 123, "end_pos": 151, "type": "DATASET", "confidence": 0.892805834611257}]}, {"text": "It reviews Tweet pre-processing, techniques for overcoming unbalanced class distribution in the provided test data, and comparison of multiple attempted machine learning models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The purpose of this paper is to explore different approaches towards classifying tweets based on whether they are offensive or not, whether offensive tweets are targeted, and identifying the target group of offensive tweets either an individual, a group, or other.", "labels": [], "entities": []}, {"text": "Those are the terms of the OffensEval 2019 competition in which we participated.", "labels": [], "entities": [{"text": "OffensEval 2019 competition", "start_pos": 27, "end_pos": 54, "type": "DATASET", "confidence": 0.7036800980567932}]}, {"text": "Each of the described activities constituted a separate subtask from the competition.", "labels": [], "entities": []}, {"text": "A maximum of three submissions were allowed per subtask which required careful preliminary analysis of the model results during the training phase.", "labels": [], "entities": []}, {"text": "A training set of over 13,000 tweets, containing labels for all three subtasks.", "labels": [], "entities": []}, {"text": "Each of the subtasks was scored using macro F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9450143575668335}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on the validation set for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 2: Results on the test set for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 3: Results on the validation set for Sub-task B.", "labels": [], "entities": []}, {"text": " Table 4: Results on the test set for Sub-task B.", "labels": [], "entities": []}, {"text": " Table 5: Results on the validation set for Sub-task C.", "labels": [], "entities": []}, {"text": " Table 6: Results on the test set for Sub-task C.", "labels": [], "entities": []}]}