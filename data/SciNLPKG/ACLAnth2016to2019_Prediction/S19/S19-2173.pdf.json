{"title": [{"text": "Team Fernando-Pessa at SemEval-2019 Task 4: Back to Basics in Hyperpartisan News Detection", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8412308990955353}, {"text": "Hyperpartisan News Detection", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.6165207823117574}]}], "abstractContent": [{"text": "This paper describes our submission 1 to the SemEval 2019 Hyperpartisan News Detection task.", "labels": [], "entities": [{"text": "SemEval 2019 Hyperpartisan News Detection task", "start_pos": 45, "end_pos": 91, "type": "TASK", "confidence": 0.8858306010564169}]}, {"text": "Our system aims fora linguistics-based document classification from a minimal set of interpretable features, while maintaining good performance.", "labels": [], "entities": [{"text": "linguistics-based document classification", "start_pos": 21, "end_pos": 62, "type": "TASK", "confidence": 0.6570588946342468}]}, {"text": "To this goal, we follow a feature-based approach and perform several experiments with different machine learning classifiers.", "labels": [], "entities": []}, {"text": "On the main task, our model achieved an accuracy of 71.7%, which was improved after the task's end to 72.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.999789297580719}]}, {"text": "We also participate in the meta-learning sub-task, for classifying documents with the binary classifications of all submitted systems as input, achieving an accuracy of 89.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9993560910224915}]}], "introductionContent": [{"text": "Hyperpartisan news detection consists in identifying news that exhibit extreme bias towards a single side.", "labels": [], "entities": [{"text": "Hyperpartisan news detection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7698111534118652}]}, {"text": "The shift, in news consumption behavior, from traditional outlets to social media platforms has been accompanied by a surge of fake and/or hyperpartisan news articles in recent years (, raising concerns in both researchers and the general public.", "labels": [], "entities": []}, {"text": "As ideologically aligned humans prefer to believe in ideologically aligned news, these tend to be shared more often and, thus, spread at a fast and unchecked pace.", "labels": [], "entities": []}, {"text": "Moreover, there is a large intersection of 'fake' and 'hyperpartisan' news, as 97% of fake news articles in BuzzFeed's Facebook fact-check dataset are also hyperpartisan (.", "labels": [], "entities": []}, {"text": "However, the detection/classification and consequent regulation of online content must be done https://github.com/AndreFCruz/ semeval2019-hyperpartisan-news with careful consideration, as any automatic system risks unintended censorship.", "labels": [], "entities": [{"text": "detection/classification", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7973037759462992}, {"text": "AndreFCruz", "start_pos": 114, "end_pos": 124, "type": "DATASET", "confidence": 0.9277375936508179}]}, {"text": "As such, we aim fora linguistically-guided model from a set of interpretable features, together with classifiers that facilitate inspection of what the model has learned, such as Random Forests, Support Vector Machines ( and Gradient Boosted Trees.", "labels": [], "entities": []}, {"text": "Neural network models are left out for their typically less self-explanatory nature.", "labels": [], "entities": []}, {"text": "The) challenged participants to build a system for hyperpartisan news detection.", "labels": [], "entities": [{"text": "hyperpartisan news detection", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.63944011926651}]}, {"text": "The provided dataset consists of 645 manually annotated articles (byarticle dataset), as well as 750,000 articles automatically annotated publisher-wise (by-publisher dataset, split 80% for training and 20% for validation).", "labels": [], "entities": []}, {"text": "Systems are ranked by accuracy on a set of unpublished test articles (from the by-article dataset), which has no publishers in common with the provided train dataset, preventing accuracy gains by profiling publishers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9986621141433716}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9969690442085266}]}, {"text": "All experiments on this paper are performed on the gold-standard (byarticle) corpus, as this was the official dataset.", "labels": [], "entities": [{"text": "gold-standard (byarticle) corpus", "start_pos": 51, "end_pos": 83, "type": "DATASET", "confidence": 0.5828810572624207}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes our pre-processing, feature selection, and the system's architecture.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.6773829013109207}]}, {"text": "Section 3 analyzes our model's performance, evaluates each feature importance, and goes in-depth on some classification examples.", "labels": [], "entities": []}, {"text": "Finally, Section 5 draws conclusions and sketches future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Models performance: values in the top rows result from 10-fold cross-validation on the by-article-training  set, and values in the bottom rows report evaluation on the official test set through TIRA (Potthast", "labels": [], "entities": [{"text": "TIRA", "start_pos": 204, "end_pos": 208, "type": "DATASET", "confidence": 0.6834518313407898}, {"text": "Potthast", "start_pos": 210, "end_pos": 218, "type": "DATASET", "confidence": 0.6289086937904358}]}, {"text": " Table 2: Average values for articles predicted (Pred.)  hyperpartisan (H) or mainstream (M), and for their  ground-truth (Gold), for top-10 features by impurity  decrease.", "labels": [], "entities": [{"text": "Pred.", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.8636796474456787}, {"text": "ground-truth (Gold)", "start_pos": 109, "end_pos": 128, "type": "METRIC", "confidence": 0.744184285402298}]}]}