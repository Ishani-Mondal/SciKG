{"title": [{"text": "LT3 at SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (hatEval)", "labels": [], "entities": [{"text": "Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter", "start_pos": 28, "end_pos": 105, "type": "TASK", "confidence": 0.8582622083750638}, {"text": "hatEval)", "start_pos": 107, "end_pos": 115, "type": "DATASET", "confidence": 0.9556425511837006}]}], "abstractContent": [{"text": "This paper describes our contribution to the SemEval-2019 Task 5 on the detection of hate speech against immigrants and women in Twitter (hatEval).", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.8731637895107269}]}, {"text": "We considered a supervised classification-based approach to detect hate speech in English tweets, which combines a variety of standard lexical and syntactic features with specific features for capturing offensive language.", "labels": [], "entities": []}, {"text": "Our experimental results show good classification performance on the training data, but a considerable drop in recall on the held-out test set.", "labels": [], "entities": [{"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9997344613075256}]}], "introductionContent": [{"text": "The exponential growth of social media such as Twitter, Facebook, Youtube and community forums has created a variety of novel ways for all of us to communicate with each other, but this opportunity to freely communicate online has unfortunately also given a forum to people who want to denigrate others because of their race, colour, gender, sexual orientation, religion, etc.", "labels": [], "entities": [{"text": "Youtube", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9536890387535095}]}, {"text": "While there has been an increasing interest in automatic hate speech detection in social media, the problem is far from solved, partly due to the low consensus on what exactly constitutes hate speech, how it relates to offensive language and bullying and thus the low reliability of hate speech annotations (.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.6261692146460215}, {"text": "reliability", "start_pos": 268, "end_pos": 279, "type": "METRIC", "confidence": 0.9830202460289001}]}, {"text": "for example observe that their classifications of hate speech tend to reflect their own subjective biases: while racist and homophobic insults are considered hateful, they tend to see sexist language as merely offensive.", "labels": [], "entities": []}, {"text": "When we consider the different approaches that address hate speech, we can observe that -apart from simple methodologies that rely on lookup in a dictionary of hateful terms) -most methods cast the problem as a supervised classification task either using a more standard machine learning approach or deep learning methods (.", "labels": [], "entities": []}, {"text": "This was also the approach we took for our hate speech detection system.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.8718025286992391}]}, {"text": "We participated for both subtasks proposed for English for Task 5 (Basile et al., 2019), being TASK A, which was defined as a binary classification task where systems have to predict whether a tweet with a given target (women or immigrants) is hateful or not hateful, and TASK B, where systems are asked first to classify hateful tweets as aggressive or not aggressive, and second to identify the target harassed as individual or generic (i.e. single human or group).", "labels": [], "entities": [{"text": "TASK A", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9653361439704895}, {"text": "TASK B", "start_pos": 272, "end_pos": 278, "type": "METRIC", "confidence": 0.8911518752574921}]}], "datasetContent": [{"text": "As mentioned in Section 2, we built three different classifiers to tackle the various subtasks: (1) determine whether a tweet is hateful or not, (2) for tweets classified as hateful, determine whether the target is individual or generic and (3) for tweets classified as hateful, determine whether the tweet is aggressive or not.", "labels": [], "entities": []}, {"text": "As the classification algorithm we used LIBSVM (Chang and Lin, 2011) with linear kernel.", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.7514132261276245}]}, {"text": "For each classification task, we performed a grid search to find the optimal cost parameter using 5-fold cross-validation (CV) on the training data.", "labels": [], "entities": [{"text": "cross-validation (CV)", "start_pos": 105, "end_pos": 126, "type": "METRIC", "confidence": 0.7562212646007538}]}, {"text": "The resulting hyperparameter (c = 0, 03125) was applied in four different experimental setups: LIBSVM with RBF kernel not normalized, RBF kernel normalized, linear kernel not normalized and linear kernel normalized.", "labels": [], "entities": []}, {"text": "These experiments revealed the setup with the linear kernel using normalized data as the best performing system.", "labels": [], "entities": []}, {"text": "presents the 5-fold CV results for this system on the training set.", "labels": [], "entities": []}, {"text": "The experimental results on the training data show good detection results of hate speech (F-score of 71.7% on the positive class), very good results for the classification of the target as being generic or individual (average F-score of 87.5%) and lower classification performance for the classification of aggressive tweets (average F-score of 66.2%).", "labels": [], "entities": [{"text": "F-score", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9979952573776245}, {"text": "F-score", "start_pos": 226, "end_pos": 233, "type": "METRIC", "confidence": 0.9820512533187866}, {"text": "F-score", "start_pos": 334, "end_pos": 341, "type": "METRIC", "confidence": 0.989626407623291}]}, {"text": "lists the results of our optimized linear kernel system for Task 1, whereas shows the results for all three subtasks.", "labels": [], "entities": []}, {"text": "As is clear from the results for task 1, our system undergenerates, resulting in a recall of only 6.8%, as opposed to 74.3% on the training data.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9994274377822876}]}], "tableCaptions": [{"text": " Table 1: Cross-validation results on the training data with the linear kernel with optimised hyperparameter settings.", "labels": [], "entities": []}, {"text": " Table 2: Final results task 1 of best system (optimized  linear kernel with normalization).", "labels": [], "entities": []}, {"text": " Table 3: Final results of best system (optimized linear  kernel with normalization).", "labels": [], "entities": []}]}