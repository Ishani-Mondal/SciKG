{"title": [{"text": "MIDAS at SemEval-2019 Task 6: Identifying Offensive Posts and Targeted Offense from Twitter", "labels": [], "entities": [{"text": "Identifying Offensive Posts and Targeted Offense from Twitter", "start_pos": 30, "end_pos": 91, "type": "TASK", "confidence": 0.8260970339179039}]}], "abstractContent": [{"text": "In this paper, we present our approach and the system description for Sub-task A and Sub Task B of SemEval 2019 Task 6: Identifying and Categorizing Offensive Language in Social Media.", "labels": [], "entities": [{"text": "SemEval 2019 Task 6", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.9070013910531998}, {"text": "Identifying and Categorizing Offensive Language in Social Media", "start_pos": 120, "end_pos": 183, "type": "TASK", "confidence": 0.7140448093414307}]}, {"text": "Sub-task A involves identifying if a given tweet is offensive or not, and Sub Task B involves detecting if an offensive tweet is targeted towards someone (group or an individual).", "labels": [], "entities": []}, {"text": "Our models for Sub-task A is based on an ensemble of Convolutional Neu-ral Network, Bidirectional LSTM with attention , and Bidirectional LSTM + Bidirectional GRU, whereas for Sub-task B, we rely on a set of heuristics derived from the training data and manual observation.", "labels": [], "entities": []}, {"text": "We provide a detailed analysis of the results obtained using the trained models.", "labels": [], "entities": []}, {"text": "Our team ranked 5th out of 103 participants in Sub-task A, achieving a macro F1 score of 0.807, and ranked 8th out of 75 participants in Sub Task B achieving a macro F1 of 0.695.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.8875619471073151}, {"text": "F1", "start_pos": 166, "end_pos": 168, "type": "METRIC", "confidence": 0.7166817784309387}]}], "introductionContent": [{"text": "The unrestricted use of offensive language in social media is disgraceful fora progressive society as it promotes the spread of abuse, violence, hatred, and leads to other activities like trolling.", "labels": [], "entities": []}, {"text": "Offensive text can be broadly classified as abusive and hate speech on the basis of the context and target of the offense.", "labels": [], "entities": []}, {"text": "Hate speech is an act of offending, insulting or threatening a person or a group of similar people on the basis of religion, race, caste, sexual orientation, gender or belongingness to a specific stereotyped community (.", "labels": [], "entities": [{"text": "Hate speech is an act of offending, insulting or threatening a person or a group of similar people on the basis of religion, race, caste, sexual orientation, gender or belongingness to a specific stereotyped community", "start_pos": 0, "end_pos": 217, "type": "Description", "confidence": 0.870397511124611}]}, {"text": "Abusive speech categorically differs from hate speech because of its casual motive to hurt using general slurs composed of demeaning words.", "labels": [], "entities": [{"text": "Abusive speech", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8882912397384644}]}, {"text": "Both of them are the popular categories of offensive content, widespread in different social media channels.", "labels": [], "entities": []}, {"text": "With the democratization of the web, the usage of offensive language in online platforms is a clear indication of misuse of our right to 'Freedom of Speech'.", "labels": [], "entities": []}, {"text": "While censorship of free moving online content curtails the freedom of speech, but unregulated opprobrious tweets discourage free discussions in the virtual world making the problem of identifying and filtering out offensive content from social media an important problem to be solved for creating a better society, both in and out of the Internet.", "labels": [], "entities": []}, {"text": "Detecting offensive content from social media is a hard research problem due to variations in the way people express themselves in a linguistically diverse social setting of the web.", "labels": [], "entities": [{"text": "Detecting offensive content from social media", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.9091537197430929}]}, {"text": "A major challenge in monitoring online content produced on social media websites like Twitter, Facebook and Reddit is the humongous volume of data being generated at a fast pace from varying demographic, cultural, linguistic and religious communities.", "labels": [], "entities": []}, {"text": "Apart from the problem of information overload, social media websites pose challenges for automated information mining tools and techniques due to their brevity, noisiness, idiosyncratic language, unusual structure and ambiguous representation of discourse.", "labels": [], "entities": []}, {"text": "Information extraction tasks using state-of-the-art natural language processing techniques, often give poor results when applied in such settings ().", "labels": [], "entities": [{"text": "Information extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8794805407524109}]}, {"text": "Abundance of link farms, unwanted promotional posts, and nepotistic relationships between content creates additional challenges.", "labels": [], "entities": []}, {"text": "Due to the lack of explicit links between content shared in these platforms it is also difficult to implement and get useful results from ranking algorithms popularly used for web pages).", "labels": [], "entities": []}, {"text": "Interests from both academia and industry has led to the organization of related workshops such as TA-COS 1 , Abusive Language Online 2 , and TRAC 3 , along with shared tasks such as GermEval () and TRAC ( ).", "labels": [], "entities": [{"text": "Abusive Language Online", "start_pos": 110, "end_pos": 133, "type": "TASK", "confidence": 0.8237019181251526}, {"text": "TRAC", "start_pos": 199, "end_pos": 203, "type": "METRIC", "confidence": 0.6627593040466309}]}, {"text": "The task 6 of) is one such recent effort containing short posts from tweets collected from the Twitter platform and annotated by human annotators with the objective of identifying expressions of offensive language, categorization of offensive language and identifying the target against whom the offensive language is being used, leading to three sub tasks (A, B and C).", "labels": [], "entities": []}, {"text": "We only participate in two of them for which we define the problems.", "labels": [], "entities": []}, {"text": "Problem Definition Sub-task A -Given a labeled dataset D of tweets, the objective of the task is to learn a classification/prediction function that can predict a label l fora given tweet t, where l \u2208 {OF F, N OT }, OFF -denoting a tweet being offensive, and NOT -denoting a tweet being not offensive.", "labels": [], "entities": [{"text": "OFF", "start_pos": 215, "end_pos": 218, "type": "METRIC", "confidence": 0.9973710775375366}, {"text": "NOT", "start_pos": 258, "end_pos": 261, "type": "METRIC", "confidence": 0.964804470539093}]}, {"text": "Problem Definition Sub Task B -Given a labeled dataset D of tweets, the objective of the task is to learn a classification/prediction function that can predict a label l fora given tweet t, where l \u2208 {T IN, UN T }, TIN -denoting an offensive tweet targeted towards a group or an individual, and UNT -denoting a tweet that does not contain a targeted offense although it might use offensive language.", "labels": [], "entities": [{"text": "UNT", "start_pos": 295, "end_pos": 298, "type": "METRIC", "confidence": 0.8456571102142334}]}, {"text": "Towards this objective we make the following contributions in this work: \u2022 Train deep learning models of different architectures -Convolutional Neural Networks, Bidirectional LSTM with attention and Bidirectional LSTM + Bidirectional GRU, and report their results on the provided dataset.", "labels": [], "entities": []}, {"text": "Our best model which ranked 5th in Sub-task A, is an ensemble of all the three deep learning architectures.", "labels": [], "entities": []}, {"text": "\u2022 We perform an analysis of the dataset, point out certain discrepancies in annotation and show how undersampling directed by error analysis could be sometimes useful for increasing the performance of the trained models.", "labels": [], "entities": []}], "datasetContent": [{"text": "\u2022 @user @user @user @user @user @user @user what a stupid incompetent devious and toxic pm ! may haven't you forgotten 17.4 million voters ? betray us at your peril ! you are eroding faith in democracy + destroying tory party ! you should go url.", "labels": [], "entities": []}, {"text": "(Original Label: NOT) \u2022 angelina is so funny at rhe wrong times imngonna shoot this bitch uppdoals.", "labels": [], "entities": [{"text": "NOT", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.5591776967048645}]}, {"text": "(Original Label: NOT) \u2022 @user @user so and accusation by a libtarded trump hating liberal activist against a trump appointee doesnt make u wonder if the accusation was politically motivated in the slightest ? no ? this is why conservatives think u are all stupid . because u are . This increased the performances of our trained models and could be considered as a heuristic based undersampling of the provided dataset.", "labels": [], "entities": []}, {"text": "We train different deep learning models for the Sub-task A and rely on heuristics learnt from the training data for Sub-task B.", "labels": [], "entities": []}, {"text": "In this section we explain the steps taken for pre-processing data and training the predictive models and give a short description of the heuristics that we came up with after analyzing the data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 2: Results for Sub-task B.", "labels": [], "entities": []}]}