{"title": [{"text": "Exploration of Noise Strategies in Semi-supervised Named Entity Classification", "labels": [], "entities": [{"text": "Semi-supervised Named Entity Classification", "start_pos": 35, "end_pos": 78, "type": "TASK", "confidence": 0.6244779899716377}]}], "abstractContent": [{"text": "Noise is inherent in real world datasets and modeling noise is critical during training as it is effective in regularization.", "labels": [], "entities": []}, {"text": "Recently, novel semi-supervised deep learning techniques have demonstrated tremendous potential when learning with very limited labeled training data in image processing tasks.", "labels": [], "entities": []}, {"text": "A critical aspect of these semi-supervised learning techniques is augmenting the input or the network with noise to be able to learn robust models.", "labels": [], "entities": []}, {"text": "While modeling noise is relatively straightforward in continuous domains such as image classification, it is not immediately apparent how noise can be modeled in discrete domains such as language.", "labels": [], "entities": [{"text": "image classification", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7288864850997925}]}, {"text": "Our work aims to address this gap by exploring different noise strategies for the semi-supervised named entity classification task, including statistical methods such as adding Gaussian noise to input embeddings, and linguistically-inspired ones such as dropping words and replacing words with their synonyms.", "labels": [], "entities": [{"text": "named entity classification task", "start_pos": 98, "end_pos": 130, "type": "TASK", "confidence": 0.7816406488418579}]}, {"text": "We compare their performance on two benchmark datasets (OntoNotes and CoNLL) for named entity classification.", "labels": [], "entities": [{"text": "named entity classification", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6698580781618754}]}, {"text": "Our results indicate that noise strategies that are linguistically informed perform at least as well as statistical approaches, while being simpler and requiring minimal tuning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modeling noise is a fundamental aspect of machine learning systems.", "labels": [], "entities": [{"text": "Modeling noise", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8803441524505615}]}, {"text": "The real world where these systems are deployed are certainly exposed to noisy data.", "labels": [], "entities": []}, {"text": "Furthermore, noise is used as an effective regularizer during the training of neural networks (e.g., dropout).", "labels": [], "entities": []}, {"text": "Correct prediction in the presence of noisy input demonstrates robustness of learning systems.", "labels": [], "entities": []}, {"text": "A simple analogy to illustrate this is, during image classification, the addition of limited random * * work done during AN's post-doc at Univ. of Arizona Gaussian noise to an image can be barely perceived by our visual system and does not drastically change the label a human assigns to an image.", "labels": [], "entities": [{"text": "image classification", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7654264271259308}, {"text": "AN's post-doc", "start_pos": 121, "end_pos": 134, "type": "TASK", "confidence": 0.7999354203542074}]}, {"text": "With the emphasis on compliance and recent advances in adversarial techniques, modeling noise has assumed renewed importance ().", "labels": [], "entities": [{"text": "modeling noise", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.9004023671150208}]}, {"text": "Noise is an important factor in recent state-ofthe-art semi-supervised learning systems for image classification.", "labels": [], "entities": [{"text": "image classification", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7737922370433807}]}, {"text": "In image processing modeling random noise is relatively straightforward as it is a continuous domain.", "labels": [], "entities": [{"text": "image processing modeling random noise", "start_pos": 3, "end_pos": 41, "type": "TASK", "confidence": 0.9007415890693664}]}, {"text": "For instance, adding a small amount random Gaussian jitter can be considered as noisy input.", "labels": [], "entities": []}, {"text": "So are other image transformations such as translation, rotation, removing color and soon.", "labels": [], "entities": []}, {"text": "However, a discrete domain such as language is not easily amenable to noise augmentation.", "labels": [], "entities": []}, {"text": "While one can certainly add random Gaussian noise to embeddings of words (continuous vector representation such as word2vec rather than one-hot encoding), the intuition behind such perturbation is not apparent.", "labels": [], "entities": []}, {"text": "Algorithms which require explicit modeling of noise require careful thinking in the language domain and is challenging.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, previous work in the area of modeling noise in natural language processing (NLP) applications has been limited.", "labels": [], "entities": [{"text": "modeling noise in natural language processing (NLP)", "start_pos": 59, "end_pos": 110, "type": "TASK", "confidence": 0.7813109954198202}]}, {"text": "acknowledge the difficulty of modeling noise for language and incorporate a simple word dropout in their experiments.", "labels": [], "entities": []}, {"text": "So does the work by.", "labels": [], "entities": []}, {"text": "Nagesh and Surdeanu (2018b) add a standard Gaussian perturbation with a fixed variance to the pretrained word vectors to simulate noise. is perhaps one of the most comprehensive works that explore various noise strategies with a different end goal in mind.", "labels": [], "entities": []}, {"text": "Their work: Mean Teacher framework for the named entity classification task (left).", "labels": [], "entities": [{"text": "named entity classification task", "start_pos": 43, "end_pos": 75, "type": "TASK", "confidence": 0.7408595234155655}]}, {"text": "E wi are words in the entity mention, W i are words in the context with entity mention replaced by <E> token.", "labels": [], "entities": []}, {"text": "cost = (classification cost) + \u03bb(consistency cost).", "labels": [], "entities": [{"text": "consistency", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9614763259887695}]}, {"text": "Unlabeled examples have only consistency cost.", "labels": [], "entities": [{"text": "consistency", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9824434518814087}]}, {"text": "Backprop only through student model, teacher model parameters are averaged.", "labels": [], "entities": []}, {"text": "The architecture of the student or teacher model (right).", "labels": [], "entities": []}, {"text": "Noise can be added to parts in boldface.", "labels": [], "entities": []}, {"text": "predictions = softmax(output layer) explores the degree of robustness of various neural network approaches to different types of noise on a machine translation task.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.7752244273821512}]}, {"text": "In this paper, we discuss several noise strategies for the semi-supervised named entity classification task.", "labels": [], "entities": [{"text": "semi-supervised named entity classification task", "start_pos": 59, "end_pos": 107, "type": "TASK", "confidence": 0.711526894569397}]}, {"text": "Some of these, such as word-dropout and synonym-replace, are linguistic and are discrete in nature while others such as Gaussian perturbation to word embeddings are statistical.", "labels": [], "entities": []}, {"text": "We show that linguistic noise, while being simple, perform as well as statistical noise.", "labels": [], "entities": []}, {"text": "A combination of linguistic and network dropout provides the best performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Task and datasets: The task investigated in this work is named entity classification (NEC), defined as identifying the correct type of an entity mention in a given context, e.g., classifying \"Bill Clinton\" in the sentence \"Former President Bill Clinton expects to attend the inauguration tomorrow.\" as a person name.", "labels": [], "entities": [{"text": "entity classification (NEC)", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.8502839803695679}, {"text": "classifying \"Bill Clinton\" in the sentence \"Former President Bill Clinton expects to attend the inauguration tomorrow.\"", "start_pos": 179, "end_pos": 298, "type": "TASK", "confidence": 0.7057605966925621}]}, {"text": "We define the context as the complete sentence in which the entity mention appears.", "labels": [], "entities": []}, {"text": "We use standard benchmark datasets, namely, CoNLL-2003 shared task dataset and.", "labels": [], "entities": [{"text": "CoNLL-2003 shared task dataset", "start_pos": 44, "end_pos": 74, "type": "DATASET", "confidence": 0.845993161201477}]}, {"text": "Our setting is semisupervised NEC, so we randomly select a very small percentage of the training dataset (40 datapoints i.e. 0.18% of CoNLL and 440 datapoints i.e. 0.56% of Ontonotes as labeled data, and artificially remove the labels of the remaining datapoints to simulate the semi-supervised setting.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.8839597105979919}]}, {"text": "Our task is to predict the correct labels of the unlabeled datapoints.", "labels": [], "entities": []}, {"text": "CoNLL had 4 label categories while Ontonotes has 11.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9747205972671509}, {"text": "Ontonotes", "start_pos": 35, "end_pos": 44, "type": "DATASET", "confidence": 0.9557092785835266}]}, {"text": "We measure the accuracy as the percentage of the datapoints which have   been predicted with the correct labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9997076392173767}]}, {"text": "Experimental settings: We use the entity boundaries for all datapoints during training but only use labels fora small portion of the data as indicated above.", "labels": [], "entities": []}, {"text": "We demonstrate an input to our model in the bottom-right of.", "labels": [], "entities": []}, {"text": "To reduce computational overhead, we filtered out entity mentions which were greater than length 5 from the Ontonotes dataset (4 respectively for CoNLL), and contexts which were greater than length 59 or smaller than length 5 (40 and 3 respectively for CoNLL).", "labels": [], "entities": [{"text": "Ontonotes dataset", "start_pos": 108, "end_pos": 125, "type": "DATASET", "confidence": 0.9693579375743866}]}, {"text": "Following Nagesh and Surdeanu (2018a), we intialized the pre-trained word-embeddings from Levy and Goldberg (2014) (300d).", "labels": [], "entities": []}, {"text": "We ran a 100d bi-directional LSTM on both the entity and context representations, concatenated their outputs and fed them to a 300d multi-layer perceptron with ReLU activations.", "labels": [], "entities": []}, {"text": "For network dropout we used p = 0.2.", "labels": [], "entities": []}, {"text": "This is similar to dropout regularization used in deep neural networks but since the dropout layer drops neurons randomly in teacher and student, this acts as noise.", "labels": [], "entities": [{"text": "dropout regularization", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.667442575097084}]}, {"text": "An important note is that the results are the accuracy of classification over 21,373 and 78,492 datapoints in CoNLL and Ontonotes respectively, using only a tiny sliver of the labels in these datasets as supervision.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9996063113212585}, {"text": "CoNLL", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.9112517237663269}, {"text": "Ontonotes", "start_pos": 120, "end_pos": 129, "type": "DATASET", "confidence": 0.7375709414482117}]}, {"text": "Increasing the number of labeled examples as supervision has the expected effect of improvement in performance.", "labels": [], "entities": []}, {"text": "However it is often difficult to obtain sufficient number of examples in the real world.", "labels": [], "entities": []}, {"text": "The datapoints for supervision are chosen randomly having equal representation in all classes.", "labels": [], "entities": []}, {"text": "The analysis of amount of supervision and its effect on accuracy is reported in Nagesh and Surdeanu (2018a).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9989773035049438}]}, {"text": "We report the average (along with their variance) of 5 randomized runs in each noise setting.", "labels": [], "entities": []}, {"text": "Our baseline is the no noise setting, where the input to the student and teacher models are not augmented by noise.", "labels": [], "entities": []}, {"text": "From, we observe that adding noise is necessary for good performance, as we see that the various noise strategies consistently improve performance over the baseline on both the datasets.", "labels": [], "entities": []}, {"text": "Network noise is a crucial factor for good per-formance.", "labels": [], "entities": []}, {"text": "Input noise which are linguistically motivated, such as word-dropout and synonymreplace perform as well as the statistical noise.", "labels": [], "entities": []}, {"text": "More specifically, word-dropout of 3 words and synonym-replace of 3 words, are the highest performing non-network noise strategies on CoNLL and Ontonotes respectively.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.9494947791099548}, {"text": "Ontonotes", "start_pos": 144, "end_pos": 153, "type": "DATASET", "confidence": 0.9349871873855591}]}, {"text": "Synonym-replace is an interesting strategy as we believe it makes the input more interpretable.", "labels": [], "entities": []}, {"text": "In the sense that, the word embedding of a synonym word is closer to the actual word in the vector space.", "labels": [], "entities": []}, {"text": "As opposed to gaussian embedding noise, which is a random delta noise added to the embedding to perturb it and we are not sure of its orientation in the high dimensional space.", "labels": [], "entities": []}, {"text": "Adding Gaussian noise to all words results in performance poorer than or close to baseline.", "labels": [], "entities": []}, {"text": "1 Furthermore, Gaussian noise requires fine-tuning over the value of stdev and the number of words on which these should be applied which makes this computationally expensive approach).", "labels": [], "entities": []}, {"text": "The performance on *-*-idf runs suggest that random word selection is as good or better.", "labels": [], "entities": []}, {"text": "This is ideal, since it is simpler and independent of the data distribution.", "labels": [], "entities": []}, {"text": "Finally, network noise in combination with linguistic input noise provides the best possible performance, as seen in.", "labels": [], "entities": []}, {"text": "One possible explanation for this could be that ensembling two high performance systems is akin to combining two good signals achieving better overall results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Tuning Gaussian noise -#words & stdev", "labels": [], "entities": [{"text": "Tuning Gaussian noise", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8305651545524597}]}]}