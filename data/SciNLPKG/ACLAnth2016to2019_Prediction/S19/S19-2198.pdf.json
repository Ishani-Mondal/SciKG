{"title": [{"text": "BLCU NLP at SemEval-2019 Task 8: A Contextual Knowledge-enhanced GPT Model for Fact Checking", "labels": [], "entities": [{"text": "BLCU NLP at SemEval-2019 Task 8", "start_pos": 0, "end_pos": 31, "type": "DATASET", "confidence": 0.777839461962382}, {"text": "Fact Checking", "start_pos": 79, "end_pos": 92, "type": "TASK", "confidence": 0.9155572950839996}]}], "abstractContent": [{"text": "Since the resources of Community Question Answering are abundant and information sharing becomes universal, it will be increasingly difficult to find factual information for ques-tioners in massive messages.", "labels": [], "entities": [{"text": "Community Question Answering", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6271731356779734}]}, {"text": "SemEval 2019 task 8 is focusing on these issues.", "labels": [], "entities": [{"text": "SemEval 2019 task 8", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.5327966958284378}]}, {"text": "We participate in the task and use Generative Pre-trained Transformer (OpenAI GPT) as our system.", "labels": [], "entities": []}, {"text": "Our innovations are data extension, feature extraction, and input transformation.", "labels": [], "entities": [{"text": "data extension", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.8532966077327728}, {"text": "feature extraction", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8035102486610413}, {"text": "input transformation", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.7329712212085724}]}, {"text": "For contextual knowledge enhancement, we extend the training set of subtask A, use several features to improve the results of our system and adapt the input formats to be more suitable for this task.", "labels": [], "entities": [{"text": "contextual knowledge enhancement", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7305113871892294}]}, {"text": "We demonstrate the effectiveness of our approaches, which achieves 81.95% of subtask A and 61.08% of subtask B inaccuracy on the SemEval 2019 task 8.", "labels": [], "entities": [{"text": "SemEval 2019 task", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.7835843960444132}]}], "introductionContent": [{"text": "With the development of Community Question Answering (cQA) forums, massive information is being shared.", "labels": [], "entities": [{"text": "Community Question Answering (cQA) forums", "start_pos": 24, "end_pos": 65, "type": "TASK", "confidence": 0.7691474088600704}]}, {"text": "However, not all information is factual, which makes finding an appropriate answer to satisfy the information needs of questioners more difficult.", "labels": [], "entities": []}, {"text": "Previous work which concentrated on these problems () reranked the questions based on their relevance with the original question.", "labels": [], "entities": []}, {"text": "\u02c7 treated the similarity ranking task as a binary classification problem.", "labels": [], "entities": [{"text": "similarity ranking task", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.8014010389645895}]}, {"text": "We study these issues in) by using the contextual Knowledge-enhanced GPT, which use Transformer ( as model architecture.", "labels": [], "entities": [{"text": "GPT", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.6128542423248291}]}, {"text": "The contextual knowledge enhancement includes data extension, feature extraction, and input transformation.", "labels": [], "entities": [{"text": "data extension", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.8151768147945404}, {"text": "feature extraction", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7202125191688538}, {"text": "input transformation", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.7572919428348541}]}, {"text": "The task includes two subtasks and they are both three classification problems.", "labels": [], "entities": []}, {"text": "In subtask A, we need to find out whether a question seeks a factual answer, an opinion or just want to socialize with others.", "labels": [], "entities": []}, {"text": "We classify the answers for questions that look for factual information in subtask A into three classes in subtask B: true, false or nonfactual.", "labels": [], "entities": []}, {"text": "In this paper, we study both subtasks and use a similar system to solve them.", "labels": [], "entities": []}, {"text": "Several challenges exist when doing this task.", "labels": [], "entities": []}, {"text": "The size of datasets for both subtasks is small.", "labels": [], "entities": []}, {"text": "The data contains a number of complex long text, which makes extracting key information more difficult.", "labels": [], "entities": []}, {"text": "The input format of GPT changes with different objectives of tasks, so it requires some modifications to fit specific tasks.", "labels": [], "entities": []}, {"text": "We apply three points to solve these problems.", "labels": [], "entities": []}, {"text": "We extend the training set of subtask A from two other datasets: DailyDialog ( and SQuAD2.0 (.", "labels": [], "entities": [{"text": "DailyDialog", "start_pos": 65, "end_pos": 76, "type": "DATASET", "confidence": 0.8984243869781494}]}, {"text": "We use two methods to guarantee the quality of expanded datasets.", "labels": [], "entities": []}, {"text": "Firstly we use the Levenshtein Distance to screen similar data, and then we use the prediction of the model to further screen the results of the previous step. and used various features.", "labels": [], "entities": []}, {"text": "used keywords to solve the previous similar problem.", "labels": [], "entities": []}, {"text": "We follow their work in feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8712388277053833}]}, {"text": "Working on subtask A, we also use characteristic words as features to improve the system.", "labels": [], "entities": []}, {"text": "Input transformation for classification task is Start + T ext + Extract, including randomly initialized start and end tokens.", "labels": [], "entities": [{"text": "classification task", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.9084972441196442}]}, {"text": "We concatenate the text and features token sequences with a delimiter token.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 contains a description of our system.", "labels": [], "entities": []}, {"text": "The experiments and analysis of the results are introduced in section 3.", "labels": [], "entities": []}, {"text": "We describe the conclusions in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present the experiments we conduct on our system and make a detailed analysis.", "labels": [], "entities": []}, {"text": "We compare the performance between GPT and other models in subtask B.", "labels": [], "entities": [{"text": "GPT", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.670916736125946}]}, {"text": "Follow, we use the default model configuration for our model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Class distribution of subtask A", "labels": [], "entities": []}, {"text": " Table 2: Development result of subtask A. Acc means  accuracy. Above means that a new change is added to  the system which mentioned in previous row.", "labels": [], "entities": [{"text": "A", "start_pos": 40, "end_pos": 41, "type": "METRIC", "confidence": 0.9333465695381165}, {"text": "Acc", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9990058541297913}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9995130300521851}]}, {"text": " Table 3: Development result of subtask B. Acc means  accuracy.", "labels": [], "entities": [{"text": "Acc", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9982141256332397}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9990025162696838}]}, {"text": " Table 4: Official submissions results on the test set for  our system and the organizers's baselines. The metric  is accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9995854496955872}]}]}