{"title": [{"text": "Target Based Speech Act Classification in Political Campaign Text", "labels": [], "entities": [{"text": "Target Based Speech Act Classification", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5702276170253754}]}], "abstractContent": [{"text": "We study pragmatics in political campaign text, through analysis of speech acts and the target of each utterance.", "labels": [], "entities": []}, {"text": "We propose anew annotation schema incorporating domain-specific speech acts, such as commissive-action, and present a novel annotated corpus of media releases and speech transcripts from the 2016 Australian election cycle.", "labels": [], "entities": []}, {"text": "We show how speech acts and target referents can be mod-eled as sequential classification, and evaluate several techniques, exploiting contextualized word representations, semi-supervised learning , task dependencies and speaker meta-data.", "labels": [], "entities": [{"text": "sequential classification", "start_pos": 64, "end_pos": 89, "type": "TASK", "confidence": 0.7518244683742523}]}], "introductionContent": [{"text": "Election campaign text is a core artifact in political analysis.", "labels": [], "entities": [{"text": "political analysis", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7601425349712372}]}, {"text": "Campaign communication can influence a party's reputation, credibility, and competence, which are primary factors in voter decision making).", "labels": [], "entities": [{"text": "competence", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9623274207115173}]}, {"text": "Also, modeling the discourse is key to measuring the role of party in constructive democracy -to engage in constructive discussion with other parties in a democracy (.", "labels": [], "entities": []}, {"text": "Speech act theory can be used to study such pragmatics in political campaign text.", "labels": [], "entities": [{"text": "Speech act theory", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6767520507176717}]}, {"text": "Traditional speech act classes have been studied to analyze how people engage with elected members, and how elected members engage in discussions (, with a particular focus on pledges.", "labels": [], "entities": []}, {"text": "Also, election manifestos have been analyzed for prospective and retrospective messages.", "labels": [], "entities": []}, {"text": "In this work, we combine traditional speech acts with those proposed by political scientists to study political discourse, such as specific pledges, which can also help to verify the pledges' fulfilment after an election ().", "labels": [], "entities": []}, {"text": "In addition to speech acts, it is important to identify the target of each utterance -that is, the political party referred to in the text -in order to determine the discourse structure.", "labels": [], "entities": []}, {"text": "Here, we study the effect of jointly modeling the speech act and target referent of each utterance, in order to exploit the task dependencies.", "labels": [], "entities": []}, {"text": "That is, this paper is an application of discourse analysis to the pragmaticsrich domain of political science, to determine the intent of every utterance made by politicians, and in part, automatically extract pledges at varying levels of specificity from campaign speeches and press releases.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7657671570777893}]}, {"text": "We assume that each utterance is associated with a unique speech act (similar to) and target party, 1 meaning that a sentence with multiple speech acts and/or targets must be segmented into component utterances.", "labels": [], "entities": []}, {"text": "Take the following example, from the Labor Party: (1) Labor will contribute $43 million towards the Roe Highway project and we call on the WA Government to contribute funds to get the project underway.", "labels": [], "entities": [{"text": "Roe Highway", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.6871877014636993}]}, {"text": "The example is made up of two utterances (with and without an underline), belonging to speech act types commissive-action-specific and directive, referring to different parties (LABOR and LIB-ERAL), resp.", "labels": [], "entities": [{"text": "LABOR", "start_pos": 178, "end_pos": 183, "type": "METRIC", "confidence": 0.6634085178375244}]}, {"text": "In our initial experiments, we perform target based speech act classification (i.e. joint speech act classification and determination of the target of the utterance) over gold-standard utterance data (Section 6), but return to perform automatic utterance segmentation along with target based speech act classification (Section 7).", "labels": [], "entities": [{"text": "target based speech act classification", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.7036080479621887}, {"text": "joint speech act classification", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.6849101781845093}, {"text": "utterance segmentation", "start_pos": 245, "end_pos": 267, "type": "TASK", "confidence": 0.7036309391260147}, {"text": "target based speech act classification", "start_pos": 279, "end_pos": 317, "type": "TASK", "confidence": 0.7833984613418579}]}, {"text": "While speech act classification has been applied to a wide range of domains, its application to polit-ical text is relatively new.", "labels": [], "entities": [{"text": "speech act classification", "start_pos": 6, "end_pos": 31, "type": "TASK", "confidence": 0.772850493590037}]}, {"text": "Most speech act analyses in the political domain have relied exclusively on manual annotation, and no labeled data has been made available for training classifiers.", "labels": [], "entities": []}, {"text": "As it is expensive to obtain large-scale annotations, in addition to developing a novel annotated dataset, we also experiment with a semi-supervised approach by utilizing unlabeled text, which is easy to obtain.", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: (1) we introduce the novel task of target based speech act classification to the analysis of political discourse; (2) we develop and release a dataset (can be found here https://github.com/ shivashankarrs/Speech-Acts) based on political speeches and press releases, from the two major parties -Labor and Liberal -in the 2016 Australian federal election cycle; and (3) we propose a semi-supervised learning approach to the problem by augmenting the training data with indomain unlabeled text.", "labels": [], "entities": [{"text": "target based speech act classification", "start_pos": 83, "end_pos": 121, "type": "TASK", "confidence": 0.7737192153930664}]}], "datasetContent": [{"text": "We collected media releases and speeches from the two major Australia political parties -Labor and Liberal -from the 2016 Australian federal election campaign.", "labels": [], "entities": []}, {"text": "A statistical breakdown of the dataset is given in.", "labels": [], "entities": []}, {"text": "We compute agreement over 15 documents, annotated by two independent annotators, with disagreements resolved by a third annotator.", "labels": [], "entities": []}, {"text": "The remaining documents are annotated by the two main annotators without redundancy.", "labels": [], "entities": []}, {"text": "Agreement between the two annotators for utterance segmentation based on exact boundary match using Krippendorff's alpha (\u03b1)) is 0.84.", "labels": [], "entities": [{"text": "utterance segmentation", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.8749811053276062}]}, {"text": "Agreement statistics for the classification tasks) are given in  We compare the models presented in Section 5 with the following baseline approaches: \u2022 Support Vector Machine (\"SVM BoW \") with with unigram term-frequency representation.", "labels": [], "entities": []}, {"text": "\u2022 Multi-layer perceptron (\"MLP BoW \") with unigram term-frequency representation.: Target party class-wise F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9775774776935577}]}], "tableCaptions": [{"text": " Table 3: Speech act agreement statistics", "labels": [], "entities": [{"text": "Speech act agreement", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8470710118611654}]}, {"text": " Table 4: Target party agreement statistics", "labels": [], "entities": []}, {"text": " Table 5: Classification results showing average performance based on 10 runs. * indicates results significantly  better than the indicated approaches (based on ID in the table) according to a paired t-test (p < 0.05). Boldface  shows the overall best results and results insignificantly different from the best. Meta naive is not applicable for  speech act classification. Note that all approaches use gold-standard segmentation for evaluation.", "labels": [], "entities": [{"text": "speech act classification", "start_pos": 347, "end_pos": 372, "type": "TASK", "confidence": 0.7812717159589132}]}, {"text": " Table 6: Speech act class-wise F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9742006659507751}]}, {"text": " Table 7: Target party class-wise F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9634239375591278}]}]}