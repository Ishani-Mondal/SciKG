{"title": [{"text": "STUFIIT at SemEval-2019 Task 5: Multilingual Hate Speech Detection on Twitter with MUSE and ELMo Embeddings", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8428443372249603}, {"text": "Multilingual Hate Speech Detection", "start_pos": 32, "end_pos": 66, "type": "TASK", "confidence": 0.7303522378206253}]}], "abstractContent": [{"text": "We evaluate the viability of multilingual learning for the task of hate speech detection.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.8286211291948954}]}, {"text": "We also experiment with adversarial learning as a means of creating a multilingual model.", "labels": [], "entities": []}, {"text": "Ultimately our multilingual models have had worse results than their monolignual counterparts.", "labels": [], "entities": []}, {"text": "We find that the choice of word representations (word embeddings) is very crucial for deep learning as a simple switch between MUSE and ELMo embeddings has shown a 3-4% increase inaccuracy.", "labels": [], "entities": []}, {"text": "This also shows the importance of context when dealing with on-line content.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Internet has been surging in popularity as well as general availability.", "labels": [], "entities": []}, {"text": "This has considerably increased the amount of user generated content present online.", "labels": [], "entities": []}, {"text": "This has, however, brought up a few issues.", "labels": [], "entities": []}, {"text": "One of the issues is hate speech detection, as manual detection has been made nearly impossible by the quantity of data.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.9030250509579977}, {"text": "manual detection", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.761674553155899}]}, {"text": "The only real solution is automated hate speech detection.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.8531832297643026}]}, {"text": "Our task is detection of hate speech towards immigrants and women on Twitter (Task A).", "labels": [], "entities": [{"text": "detection of hate speech", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.8791226148605347}]}, {"text": "Hate speech can be defined as \"Any communication that disparages a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics.\"", "labels": [], "entities": [{"text": "Any communication that disparages a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other", "start_pos": 31, "end_pos": 212, "type": "Description", "confidence": 0.8421108556144378}]}, {"text": "() This proves to be a very broad definition, because utterances can be offensive, yet not hateful (.", "labels": [], "entities": []}, {"text": "Even manual labeling of hate speech related data is notoriously difficult as hate speech is very subjective in nature (.", "labels": [], "entities": [{"text": "labeling of hate speech related", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.7332175016403198}]}, {"text": "The provided dataset consists of collected messages from Twitter in English or Spanish language.", "labels": [], "entities": []}, {"text": "Hate speech datasets are very prone to class imbalances (.", "labels": [], "entities": []}, {"text": "The provided dataset does not suffer from this problem.", "labels": [], "entities": []}, {"text": "The English data contains 10,000 messages with 42.1% of the messages labeled as hate speech.", "labels": [], "entities": [{"text": "English data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7940761148929596}]}, {"text": "The Spanish data contains 4969 messages and similarly to the English part, 41.5% were labeled as hate speech.", "labels": [], "entities": [{"text": "Spanish data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8470432162284851}]}, {"text": "This gives us a dataset with 14969 messages of which 6270 are categorized as hatespeech.", "labels": [], "entities": [{"text": "hatespeech", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.9813944101333618}]}, {"text": "We have not used any additional sources of training data for our models.", "labels": [], "entities": []}, {"text": "More information about the data can be found in the Task definition (.", "labels": [], "entities": []}, {"text": "Most research dealing with hate speech has been done in English due to labelled dataset availability.", "labels": [], "entities": []}, {"text": "However, this issue is not unique to English-based content.", "labels": [], "entities": []}, {"text": "In our work, we explore multilingual approaches, as we recognize data imbalance between languages as one of major challenges of NLP.", "labels": [], "entities": []}, {"text": "Multilingual approaches could help remedy this problem, as one could transfer knowledge from a data-rich language (English) to a datapoor language (Spanish).", "labels": [], "entities": []}], "datasetContent": [{"text": "We show detailed results in both English and Spanish.", "labels": [], "entities": []}, {"text": "We use a subscript of mono or multi to differentiate between learning methods and muse or elmo to differentiate between architectures in the table.", "labels": [], "entities": []}, {"text": "The table was completed by computing the mean of 5 runs of each model on the validation part of the datasets.", "labels": [], "entities": []}, {"text": "The validation set consisted of 10% available data.", "labels": [], "entities": []}, {"text": "Multilingual models were trained with concatenated English and Spanish datasets.", "labels": [], "entities": []}, {"text": "None of the multilingual models were able to  outperform the baseline monolingual LSTM based model with ELMo.", "labels": [], "entities": [{"text": "ELMo", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.7297801971435547}]}, {"text": "Not even in a multilingual setting of averaging results between languages.", "labels": [], "entities": []}, {"text": "Multilingual MUSE has not shown any significant increase in performance compared to monolingually trained MUSE.", "labels": [], "entities": []}, {"text": "The results show how potent ELMo embeddings are.", "labels": [], "entities": []}, {"text": "Online content can often be offensive and vulgar, while still being non-hateful.", "labels": [], "entities": []}, {"text": "This is often enough fora model to classify an utterance as hate speech (.", "labels": [], "entities": []}, {"text": "In these situations, ELMo has an advantage, as the representations are built entirely in the context of a sentence as a whole.", "labels": [], "entities": []}, {"text": "The adversarial models achieved the worst performance.", "labels": [], "entities": []}, {"text": "On first glance, judging by accuracy, the models seem to perform on a very average level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9994383454322815}]}, {"text": "After further analysis, we can see that their performance was very poor and inconsistent, e.g.the LSTM based model achieved only 0.123 recall on spanish dataset.", "labels": [], "entities": [{"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9935345649719238}]}, {"text": "The model labeled only a few messages as hate speech and even those not very successfully.", "labels": [], "entities": []}, {"text": "The relatively high accuracy was a result of data distribution, as 55.6% of the data was non-hate speech.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.999442994594574}]}, {"text": "We can also see that only in this category the CNN based models outperformed LSTM based models.", "labels": [], "entities": []}, {"text": "This implies that for adversarial learning to work, one has to use a very robust feature extractor.", "labels": [], "entities": []}, {"text": "It is also the only time that the performance on English was higher than on Spanish.", "labels": [], "entities": []}, {"text": "This is the result of data scarcity, as the extractor had a hard time creating truly multilingual representations.", "labels": [], "entities": []}, {"text": "This could also be seen during training as the discriminator hovered around 90% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9981117248535156}]}, {"text": "For our task submission, we have used the monolingual LSTM model based on ELMo, which we considered as our baseline model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on English dataset (Task A)", "labels": [], "entities": [{"text": "English dataset", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.893242359161377}]}, {"text": " Table 2: Results on Spanish dataset (Task A)", "labels": [], "entities": [{"text": "Spanish dataset", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.9207226634025574}]}, {"text": " Table 3: Results on test dataset", "labels": [], "entities": []}]}