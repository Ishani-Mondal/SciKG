{"title": [{"text": "Second-order contexts from lexical substitutes for few-shot learning of word representations", "labels": [], "entities": []}], "abstractContent": [{"text": "There is a growing awareness of the need to handle rare and unseen words in word representation modelling.", "labels": [], "entities": [{"text": "word representation modelling", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.8020732998847961}]}, {"text": "In this paper, we focus on few-shot learning of emerging concepts that fully exploits only a few available contexts.", "labels": [], "entities": []}, {"text": "We introduce a substitute-based context representation technique that can be applied on an existing word embedding space.", "labels": [], "entities": []}, {"text": "Previous context-based approaches to modelling unseen words only consider bag-of-word first-order contexts, whereas our method aggregates contexts as second-order substitutes that are produced by a sequence-aware sentence completion model.", "labels": [], "entities": []}, {"text": "We experimented with three tasks that aim to test the modelling of emerging concepts.", "labels": [], "entities": []}, {"text": "We found that these tasks show different emphasis on first and second order contexts, and our substitute-based method achieved superior performance on naturally-occurring contexts from corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "As language vocabulary follows the zipfian distribution, we expect to encounter a large number of rare and unseen words no matter how large the training corpus is.", "labels": [], "entities": []}, {"text": "The effective handling of such words is thus crucial for Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 57, "end_pos": 90, "type": "TASK", "confidence": 0.7665992677211761}]}, {"text": "Attempts to learn rare and unseen word representations can be categorized into the following three approaches: (1) constructing target word embeddings from the subword components,.", "labels": [], "entities": []}, {"text": "leveraging definitions or relational structures from external resources such as Wordnet (, and (3) modelling the target word from few available contexts.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9779986143112183}]}, {"text": "Our paper falls into the last approach.", "labels": [], "entities": []}, {"text": "We demonstrate improvements in performance by employing an alternative context representation, second-order lexical substitutes, as opposed to the traditional bag of word context representations.", "labels": [], "entities": []}, {"text": "In line with previous research in this area, we evaluate our methodology on three tasks that measure the quality of the induced unseen word representation from contexts ().", "labels": [], "entities": []}, {"text": "Our results reveal that the three tasks involve different types of contexts which put different emphasis on first or second order contexts.", "labels": [], "entities": []}, {"text": "Our second-order substitute-based method achieves the best performance for modelling rare words in natural contexts from corpora.", "labels": [], "entities": []}, {"text": "In the tasks in which both first order and second order contexts are important, the ensemble of these two types of contexts yields superior performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Nonce is introduced in Herbelot and Baroni (2017) as a task that challenges the models to reconstruct target word embeddings from single wikipedia definitions.", "labels": [], "entities": []}, {"text": "The quality of the representations is evaluated by measuring how close they are to the original word embeddings trained from the whole Wikipedia corpora.", "labels": [], "entities": []}, {"text": "Following Herbelot and Baroni (2017), we report in the Nonce columns of Table 1 the mean reciprocal rank (MRR) and median rank (Med. Rank) of the gold-vector (trained from the whole Wikipedia) in the ranked list of nearest neighbours from the induced representation in the 300 test cases.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 84, "end_pos": 110, "type": "METRIC", "confidence": 0.8605590065320333}, {"text": "median rank (Med. Rank)", "start_pos": 115, "end_pos": 138, "type": "METRIC", "confidence": 0.8289577861626943}]}, {"text": "We see strong performance from first-order context representation especially the a la carte method.", "labels": [], "entities": []}, {"text": "Manual observations show that definitions are designed to be maximally informative with many synonyms, hypernyms or words semantically related to the target word in the context, and the first-order context models can easily exploit this information.", "labels": [], "entities": []}, {"text": "Also, the sequential context around the target word in a definition may not reflect the context in which a target word will be typically used in a corpus.", "labels": [], "entities": []}, {"text": "The good performance of first-order context models is therefore to be expected.", "labels": [], "entities": []}, {"text": "Furthermore, the Nonce task tests how well the model reconstructs the original embedding but does not probe into the semantic properties or relations captured in the induced word representations.", "labels": [], "entities": []}, {"text": "Ala carte is thus especially suitable for this task as it has been explicitly trained to match the original embedding.", "labels": [], "entities": []}, {"text": "However, we demonstrate in the following experiments that the superior performance from a la carte may not always be transferred to other tasks.", "labels": [], "entities": []}, {"text": "In the Chimera dataset,   (For example, buffalo and elephant).", "labels": [], "entities": [{"text": "Chimera dataset", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.8184836804866791}]}, {"text": "Each novel concept is accompanied by 2, 4 or 6 natural contexts that originally belong to the related nouns.", "labels": [], "entities": []}, {"text": "The model needs to induce representation for these novel concepts from the contexts.", "labels": [], "entities": []}, {"text": "The quality of the representations is evaluated by similarity judgment with probe words.", "labels": [], "entities": []}, {"text": "Following Herbelot and Baroni (2017) and, we report in the Chimera columns of the average Spearman Rank coefficients against human annotations for 110 test cases in each sentence condition . We observe that the additive ISF model turns out to be the strongest of the first-order context models, outperforming all the other previouslyreported results.", "labels": [], "entities": []}, {"text": "We see immediate improvement when we represent the context as substitutes in the 6 sentence condition.", "labels": [], "entities": []}, {"text": "We see further improvement when combining both additive ISF (first order) and substitutes (second order contexts), which yields the best performance in 2 sentence and 6 sentence conditions.", "labels": [], "entities": []}, {"text": "The positive effect of the ensemble method from combining first-order and second-order contexts shows that the two different contexts capture complementary information in this task.", "labels": [], "entities": []}, {"text": "This is especially due to the fact that the contexts were controlled for informativeness so as to have different degrees of overlap with feature norms.", "labels": [], "entities": []}, {"text": "Therefore at least some, but not all, contexts will have a high bag-of-word overlap with features that are semantically related to the concepts (.", "labels": [], "entities": []}, {"text": "These contexts will easily benefit from first-order contexts alone.", "labels": [], "entities": []}, {"text": "However, for the other contexts where there is few or even no overlap with feature norms in the context words, it is the contextual sequence, and thus second-order context, that will give the maximum information about the target word.", "labels": [], "entities": []}, {"text": "We show such an example with the nearest neighbours of the representations induced by our substitutes model and additive ISF in.", "labels": [], "entities": []}, {"text": "We can see that while the additive ISF representation is easily affected by unrelated words in the sentence, the substitutes approach clearly has at least identified that the target word is likely to be a kind of animal.", "labels": [], "entities": []}, {"text": "The Contextual Rare Words dataset (CRW) was introduced by.", "labels": [], "entities": [{"text": "Contextual Rare Words dataset (CRW)", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.737698631627219}]}, {"text": "It consists of a subset of 562 word pairs from the original Rare Word (RW) Dataset ().", "labels": [], "entities": [{"text": "Rare Word (RW) Dataset", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.8564944962660471}]}, {"text": "For each pair, the second word is the rare word and is accompanied by 255 contexts.", "labels": [], "entities": []}, {"text": "We follow the experiment setup in and use their pre-trained vectors on the subcorpus that does not contain any of the rare words from the dataset.", "labels": [], "entities": []}, {"text": "This subcorpus is also used to train the context2vec model that generates substitutes.", "labels": [], "entities": []}, {"text": "As in, we randomly choose 2, 4, 6..128 number of contexts as separate conditions for 100 trials, and use these contexts to predict the rare word representations.", "labels": [], "entities": []}, {"text": "Cosine similarity is computed between the rare word representation from the given rare word contexts in the trial (2,4..128) and the embedding of the other word in the pair from the pre-trained vectors.", "labels": [], "entities": [{"text": "Cosine similarity", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.918158620595932}]}, {"text": "The cosinesimilarity of each pair is compared against similarity judgments from human annotations.", "labels": [], "entities": []}, {"text": "The average Spearman Rank coefficients against human annotations across the trials are reported in.", "labels": [], "entities": [{"text": "Spearman Rank", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.720861554145813}]}, {"text": "Standard deviations are reported in Appendix B. We see dramatic improvement from the substitutes method overall the other methods including the previous state-of-the-art a la carte in this datasets which come from corpora-based natural contexts of rare words.", "labels": [], "entities": []}, {"text": "The result here suggests that, in natural contexts, the sequence information rather than bag of words plays a more important role in predicting a target word's meaning.", "labels": [], "entities": [{"text": "predicting a target word's meaning", "start_pos": 133, "end_pos": 167, "type": "TASK", "confidence": 0.8241954247156779}]}, {"text": "We also notice that applying second order information on word2vec space consistently outperforms Context2vec alone which generates the second order substitutes.", "labels": [], "entities": []}, {"text": "We suspect that this is because the context representation induced by context2vec is more syntactically-oriented whereas the tasks in our study mainly test semantic relations.", "labels": [], "entities": []}, {"text": "We confirm this assumption by following to test the target word embeddings produced by context2vec on the MEN dataset ().", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.9573478400707245}]}, {"text": "We find that context2vec (Spearman \u03c1 = 0.65) correlates less with human's semantic relatedness judgment than word2vec (Spearman \u03c1 = 0.75) on this dataset.", "labels": [], "entities": []}, {"text": "Isolating the second order information from Context2vec and applying it on the word2vec space as an external constraint effectively preserves the semantic relations present in word2vec and at the same time provides a paradigmatic view which finds a both syntactically and semantically appropriate position for the rare word.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison with baselines and the previously-reported state-of-the-art results on the Chimera and Nonce  datasets. The Chimera dataset is evaluated with Spearman Rank coefficients. The top half of the table contains  first-order context methods and the bottom half has methods using second-order context or ensemble methods  using first and second order.", "labels": [], "entities": [{"text": "Nonce  datasets", "start_pos": 108, "end_pos": 123, "type": "DATASET", "confidence": 0.7304185032844543}, {"text": "Chimera dataset", "start_pos": 129, "end_pos": 144, "type": "DATASET", "confidence": 0.7603351771831512}]}]}