{"title": [{"text": "Scalable Cross-Lingual Transfer of Neural Sentence Embeddings", "labels": [], "entities": [{"text": "Scalable Cross-Lingual Transfer of Neural Sentence Embeddings", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.7092770082609994}]}], "abstractContent": [{"text": "We develop and investigate several cross-lingual alignment approaches for neural sentence embedding models, such as the supervised inference classifier, InferSent, and sequential encoder-decoder models.", "labels": [], "entities": []}, {"text": "We evaluate three alignment frameworks applied to these models: joint modeling, representation transfer learning, and sentence mapping, using parallel text to guide the alignment.", "labels": [], "entities": [{"text": "representation transfer learning", "start_pos": 80, "end_pos": 112, "type": "TASK", "confidence": 0.84023384253184}, {"text": "sentence mapping", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.7685378193855286}]}, {"text": "Our results support representation transfer as a scal-able approach for modular cross-lingual alignment of neural sentence embeddings, where we observe better performance compared to joint models in intrinsic and extrinsic evaluations , particularly with smaller sets of parallel data.", "labels": [], "entities": [{"text": "representation transfer", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.8380725979804993}, {"text": "modular cross-lingual alignment of neural sentence embeddings", "start_pos": 72, "end_pos": 133, "type": "TASK", "confidence": 0.7305440987859454}]}], "introductionContent": [{"text": "Probabilistic sentence representation models generally fall into two categories: bottom-up compositional models, where sentence embeddings are composed from word embeddings via a linear function like averaging, and top-down compositional models that are trained with a sentencelevel objective, typically within a neural architecture.", "labels": [], "entities": []}, {"text": "Sequential data like sentences can be modeled using recurrent, recursive, or convolutional networks, which can implicitly learn intermediate sentence representations suitable for each learning task.", "labels": [], "entities": []}, {"text": "Depending on the training objective, these intermediate representations sometimes encode enough semantic and syntactic features to be suitable as general-purpose sentence embeddings.", "labels": [], "entities": []}, {"text": "For examples, it was shown in that a model trained to maximize inference classification accuracy can yield generic representations that perform well across a wide set of extrinsic classification benchmarks.", "labels": [], "entities": [{"text": "inference classification", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.6518208682537079}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.6957422494888306}]}, {"text": "Other training objectives, like denoising auto-encoders or neural sequence to sequence models (), can also yield general-purpose representations with different characteristics.", "labels": [], "entities": []}, {"text": "While bottomup models can achieve superior performance in tasks that are independent of syntax, such as topic categorization, neural models often yield representations that encode syntactic and positional features, which results in superior performance in tasks that rely on sentence structure . General-purpose sentence embeddings can be used as features in various classification tasks, or to directly assess the similarity of a pair of sentences using the cosine measure.", "labels": [], "entities": [{"text": "topic categorization", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.7237005680799484}]}, {"text": "It is often desired to generalize word and sentence embeddings across several languages to facilitate cross-lingual transfer learning () and mining of parallel sentences ).", "labels": [], "entities": [{"text": "cross-lingual transfer learning", "start_pos": 102, "end_pos": 133, "type": "TASK", "confidence": 0.7950021624565125}]}, {"text": "For word embeddings, cross-lingual learning can be achieved in various ways (), such as learning directly with a cross-lingual objective or post-hoc alignment of monolingual word embeddings using dictionaries, parallel corpora (, or even with no bilingual supervision ().", "labels": [], "entities": [{"text": "word embeddings", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7024732381105423}]}, {"text": "For bottom-up composition like vector averaging, word-level alignment is sufficient to yield cross-lingual sentence embeddings.", "labels": [], "entities": [{"text": "vector averaging", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7179121673107147}, {"text": "word-level alignment", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7312126457691193}]}, {"text": "For top-down sentence embeddings, the efforts in cross-lingual learning are more limited.", "labels": [], "entities": []}, {"text": "Typically, a multi-faceted cross-lingual learning objective is used to align the sentence models while training them, as in.", "labels": [], "entities": []}, {"text": "Cross-lingual sentence embeddings can also be learned via a neural machine translation framework trained jointly for multiple languages.", "labels": [], "entities": []}, {"text": "While they indeed yield cross-lingual embeddings, the joint training models in existing literature pose some practical limitations: simultaneous training requires massive computational re-sources, particularly for sequential models like the bi-directional LSTM networks typically used to encode sentences.", "labels": [], "entities": []}, {"text": "In addition, the joint framework does not allow post-hoc or modular training, where new languages can be added and aligned to existing pre-trained encoders.", "labels": [], "entities": []}, {"text": "More recently, proposed an approach for crosslingual sentence embeddings by aligning encoders of new languages to a pre-trained English encoder using parallel corpora.", "labels": [], "entities": [{"text": "crosslingual sentence embeddings", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.7830318212509155}]}, {"text": "Such approach promises to be more suitable for modular training of general sentence encoders, although so far it has only been evaluated in natural language inference classification.", "labels": [], "entities": [{"text": "natural language inference classification", "start_pos": 140, "end_pos": 181, "type": "TASK", "confidence": 0.6457868441939354}]}, {"text": "In this paper, we develop and evaluate three alignment frameworks: joint modeling, representation transfer learning, and sentence mapping, applied on two modern general-purpose sentence embedding models: the inference-based encoder, InferSent (, and the sequential denoising auto-encoder, SDAE (.", "labels": [], "entities": [{"text": "representation transfer learning", "start_pos": 83, "end_pos": 115, "type": "TASK", "confidence": 0.8343110283215841}, {"text": "sentence mapping", "start_pos": 121, "end_pos": 137, "type": "TASK", "confidence": 0.7797344326972961}]}, {"text": "For most approaches, we rely on parallel sentences as sentence-level dictionaries for cross-lingual supervision.", "labels": [], "entities": []}, {"text": "We report the performance on sentence translation retrieval and crosslingual document classification.", "labels": [], "entities": [{"text": "sentence translation retrieval", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.8366477886835734}, {"text": "crosslingual document classification", "start_pos": 64, "end_pos": 100, "type": "TASK", "confidence": 0.6992993752161661}]}, {"text": "Our results support representation transfer as a scalable approach for modular cross-lingual alignment that works well across different neural models and evaluation benchmarks.", "labels": [], "entities": [{"text": "representation transfer", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.8288838863372803}, {"text": "cross-lingual alignment", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.6894510239362717}]}], "datasetContent": [{"text": "Ina well-aligned cross-lingual vector space, sentences should be clustered with their translations across various languages.", "labels": [], "entities": []}, {"text": "As discussed in this can be measured with sentence translation retrieval: the accuracy of retrieving the correct translation for each source sentence from the target side of a test parallel corpus.", "labels": [], "entities": [{"text": "sentence translation retrieval", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.8169195552666982}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9990981817245483}]}, {"text": "This is done using nearest neighbor search with the cosine as a similarity measure.", "labels": [], "entities": []}, {"text": "While not exactly an intrinsic evaluation metric, this scheme is the closest measure of alignment quality at the sentence level across all features in the vector space.", "labels": [], "entities": []}, {"text": "We used bottom-up embeddings composed using weighted averaging with smooth inverse frequency (, which has been shown to work well as monolingual sentence embeddings compared to other bottom-up approaches.", "labels": [], "entities": []}, {"text": "We use skipgram with subword information ( , i.e. FastText, for the word embeddings, which are also used as input to the neural models.", "labels": [], "entities": []}, {"text": "We applied static dictionary alignment using the approach and dictionaries in, in addition to sentence mapping using the parallel corpora.", "labels": [], "entities": [{"text": "static dictionary alignment", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6156657437483469}, {"text": "sentence mapping", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.7279184609651566}]}, {"text": "We trained the monolingual FastText word embeddings and SDAE models using the 1 Billion Word benchmark () for English, and WMT'12 News Crawl data for.", "labels": [], "entities": [{"text": "WMT'12 News Crawl data", "start_pos": 123, "end_pos": 145, "type": "DATASET", "confidence": 0.9326189905405045}]}, {"text": "We used WMT'12 Common Crawl data for cross-lingual alignment, and WMT'12 test sets for evaluations.", "labels": [], "entities": [{"text": "WMT'12 Common Crawl data", "start_pos": 8, "end_pos": 32, "type": "DATASET", "confidence": 0.9091611057519913}, {"text": "cross-lingual alignment", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.8072127401828766}, {"text": "WMT'12 test sets", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.9741455515225729}]}, {"text": "We used the augmented SNLI data described in ( and their translations for training the mono-lingual and joint InferSent models.", "labels": [], "entities": []}, {"text": "For all datasets and languages, the only preprocessing performed was tokenization.", "labels": [], "entities": []}, {"text": "One of our evaluation objective is to assess the minimal bilingual data requirements for each framework, so we split the training parallel corpora into subsets of increasing size from 1,000 to 1 million sentences, where we double the size in each step.", "labels": [], "entities": []}, {"text": "We report sentence translation retrieval accuracies in all language directions, using en for English, es for Spanish, and de for German 3 .  In this section, we compare the overall performance of different types of models on sentence translation retrieval.", "labels": [], "entities": [{"text": "sentence translation retrieval", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8309812943140665}, {"text": "sentence translation retrieval", "start_pos": 225, "end_pos": 255, "type": "TASK", "confidence": 0.8447527289390564}]}, {"text": "We plotted the average crosslingual accuracy (averaged overall language directions) by the best performing variant of each model in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.8655931949615479}]}, {"text": "With small amounts of parallel text, around 5K sentences, the best performance was achieved using InferSent transfer model.", "labels": [], "entities": []}, {"text": "The model continued to yield the highest performance until it was exceeded by the joint SDAE/NMT model at 500K sentences.", "labels": [], "entities": [{"text": "SDAE/NMT model", "start_pos": 88, "end_pos": 102, "type": "DATASET", "confidence": 0.7598258554935455}]}, {"text": "The representation transfer models for SDAE exceeded the FastText model at around 20K sentences, and achieved comparable performance to InferSent sentence mapping.", "labels": [], "entities": [{"text": "SDAE", "start_pos": 39, "end_pos": 43, "type": "TASK", "confidence": 0.9366047978401184}, {"text": "InferSent sentence mapping", "start_pos": 136, "end_pos": 162, "type": "TASK", "confidence": 0.5382518966992696}]}, {"text": "Relying on a single measure is never sufficient to probe all characteristics of a vector space.", "labels": [], "entities": []}, {"text": "Extrinsic evaluation can be another useful tool to measure the effectiveness of various cross-lingual models, although extrinsic tasks typically measure specific and narrow aspects of semantics.", "labels": [], "entities": [{"text": "Extrinsic evaluation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7713049054145813}]}, {"text": "Nevertheless, we can still gain some insights about certain characteristics of these models and their applicability.", "labels": [], "entities": []}, {"text": "One of the most widely used tasks for cross-lingual evaluation is the Cross-Lingual Document Classification benchmark (CLDC), where a model is trained in one language and tested on another (.", "labels": [], "entities": [{"text": "cross-lingual evaluation", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.7051292955875397}, {"text": "Cross-Lingual Document Classification benchmark (CLDC)", "start_pos": 70, "end_pos": 124, "type": "TASK", "confidence": 0.676563275711877}]}, {"text": "We report the average classification accuracies in CLDC across all language directions (a total of six directions) using the datasets in; the multi-layer perceptron was used as a classifier trained for each source language, then tested in the remaining two.", "labels": [], "entities": []}, {"text": "The highest accuracy was achieved using FastText vectors, followed by InferSent transfer and sentence mapping models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9993566870689392}, {"text": "sentence mapping", "start_pos": 93, "end_pos": 109, "type": "TASK", "confidence": 0.6899674385786057}]}, {"text": "With large enough parallel corpora, the performance of SDAE/NMT exceeded the transfer model, but with smaller data, SDAE transfer model achieved consistently higher performance.", "labels": [], "entities": []}, {"text": "These results are consistent with the trend of these models in mono-lingual topic categorization , where word averaging achieved consistently higher performance than all neural models.", "labels": [], "entities": [{"text": "mono-lingual topic categorization", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.6334313750267029}, {"text": "word averaging", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.7610752880573273}]}, {"text": "This indicates that crosslingual models share the same semantic characteristics as their underlying mono-lingual counterparts.", "labels": [], "entities": []}, {"text": "We should underscore that CLDC is a rather coarse categorization task where documents are classified into four categories.", "labels": [], "entities": []}, {"text": "Note also that the FastText model achieved relatively high performance even when it was aligned with only 1K parallel sentences, a condition in which sentence translation retrieval accuracy was less that 40%.", "labels": [], "entities": [{"text": "sentence translation retrieval", "start_pos": 150, "end_pos": 180, "type": "TASK", "confidence": 0.798591415087382}, {"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9005254507064819}]}, {"text": "This poor correlation with sentence translation retrieval accuracies indicates that neither evaluation framework is reliable on its own.", "labels": [], "entities": [{"text": "sentence translation retrieval", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.7909544308980306}]}, {"text": "Our intuition is that sentence translation retrieval is a more com-  prehensive measure since all features in the vector space weigh equally in calculating the cosine similarity; on the other hand, a supervised classifier weighs features according to their correlations with the target classes.", "labels": [], "entities": [{"text": "sentence translation retrieval", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.8261989156405131}]}], "tableCaptions": []}