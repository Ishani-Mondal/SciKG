{"title": [{"text": "Atalaya at SemEval 2019 Task 5: Robust Embeddings for Tweet Classification", "labels": [], "entities": [{"text": "SemEval 2019 Task", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8826736211776733}, {"text": "Tweet Classification", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.8228042125701904}]}], "abstractContent": [{"text": "In this article, we describe our participation in HatEval, a shared task aimed at the detection of hate speech against immigrants and women.", "labels": [], "entities": [{"text": "detection of hate speech", "start_pos": 86, "end_pos": 110, "type": "TASK", "confidence": 0.7813837975263596}]}, {"text": "We focused on Spanish sub-tasks, building from our previous experiences on sentiment analysis in this language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.9382978081703186}]}, {"text": "We trained linear classifiers and Recurrent Neural Networks, using classic features, such as bag-of-words, bag-of-characters, and word embed-dings, and also with recent techniques such as contextualized word representations.", "labels": [], "entities": []}, {"text": "In particular , we trained robust task-oriented subword-aware embeddings and computed tweet representations using a weighted-averaging strategy.", "labels": [], "entities": []}, {"text": "In the final evaluation, our systems showed competitive results for both Spanish subtasks ES-A and ES-B, achieving the first and fourth places respectively.", "labels": [], "entities": [{"text": "Spanish subtasks ES-A", "start_pos": 73, "end_pos": 94, "type": "DATASET", "confidence": 0.5443731347719828}]}], "introductionContent": [{"text": "Hate speech against women, immigrants, and many other groups is a pervasive phenomenon on the Internet.", "labels": [], "entities": []}, {"text": "On the early days of the World Wide Web, many academics adventured that prejudices and hatred would be removed in this space by the dissolution of identities.", "labels": [], "entities": []}, {"text": "Twenty years after this hypothesis, we can say that it has not been the case.", "labels": [], "entities": []}, {"text": "The prevalence of racism in the \"World White Web\" has been studied in a number of works) and so has been the misogyny in the virtual world.", "labels": [], "entities": [{"text": "World White Web\"", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.7368632107973099}]}, {"text": "Racist and sexist discourse area constant in social media, but peaks are documented after \"trigger\" events, such as murders with religious or political reasons ().", "labels": [], "entities": []}, {"text": "Most social media companies are concerned about this issue and take actions against it; nonetheless, most of the efforts still need human intervention, making this task very expensive.", "labels": [], "entities": []}, {"text": "Therefore, reducing human intervention is vital in order to have effective tools to avoid the escalation of hate speech.", "labels": [], "entities": []}, {"text": "HatEval () is a SemEval-2019 shared task aimed at the detection of hate speech towards immigrants and women in tweets.", "labels": [], "entities": [{"text": "SemEval-2019 shared task", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.8045546809832255}]}, {"text": "It comprises two subtasks, with datasets in English (EN) and Spanish (ES) for both of them, giving a total of four subtasks.", "labels": [], "entities": []}, {"text": "Subtask A is the binary classification of tweets into hateful or not hateful (HS).", "labels": [], "entities": []}, {"text": "Subtask B is a triple binary classification task where, in addition to HS, tweets are classified into aggressive or not aggressive (AG), and targets of hate speech are classified into single humans or groups of persons (TR).", "labels": [], "entities": []}, {"text": "In this article, we present our participation in HatEval as team Atalaya.", "labels": [], "entities": []}, {"text": "We focused our efforts on subtask A for Spanish (ES-A) but also worked at subtask B in Spanish (ES-B) and subtask A in English (EN-A).", "labels": [], "entities": []}, {"text": "Our systems are based on our participation in the polarity classification task of Spanish tweets TASS 2018 (Sentiment Analysis at SEPLN).", "labels": [], "entities": [{"text": "polarity classification task of Spanish tweets TASS 2018", "start_pos": 50, "end_pos": 106, "type": "TASK", "confidence": 0.7481854669749737}]}, {"text": "To represent tweets, we experimented with a mixed approach of bag-of-words, bag-ofcharacters and tweet embeddings, which were calculated from word vectors using different averaging schemes.", "labels": [], "entities": []}, {"text": "We used fastText () to get subword-aware representations specifically trained for sentiment analysis tasks.", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.9409115513165792}]}, {"text": "These word representations are robust to noise since they can be computed for unseen words by using subword embeddings.", "labels": [], "entities": []}, {"text": "Moreover, we trained them using a database of 90M tweets from various Spanish-speaking countries, giving wide domainspecific vocabulary coverage.", "labels": [], "entities": []}, {"text": "We achieved additional robustness by doing preprocessing using several text-normalization and noise-reduction techniques.", "labels": [], "entities": []}, {"text": "Also, we experimented with ELMo (Peters et al., 2018), a deep contextualized word representation that has drawn a lot of attention in the last months.", "labels": [], "entities": []}, {"text": "Unlike fastText, ELMo returns context-dependent embeddings from a multi-layer bidirectional-LSTM language model.", "labels": [], "entities": []}, {"text": "These representations improved the state-of-the-art of several NLP tasks.", "labels": [], "entities": []}, {"text": "For the neural approach, we used bidirectional LSTMs to combine the word embeddings.", "labels": [], "entities": []}, {"text": "We also did experiments that mix sequential models with complementary representations such as bagof-words.", "labels": [], "entities": []}, {"text": "The rest of the paper is as follows.", "labels": [], "entities": []}, {"text": "Next Section presents the primary tools we used to build our systems.", "labels": [], "entities": []}, {"text": "Section 3 presents the configuration and development of both linear and neural models.", "labels": [], "entities": []}, {"text": "Section 4 briefly shows our results in the competition, and Section 5 concludes the work with some observations about our experience.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Experiments with logistic regressions (LRs)  and SVMs on the Spanish development set. Models  are described in Section 3.1. The best result is in bold.", "labels": [], "entities": [{"text": "Spanish development set", "start_pos": 71, "end_pos": 94, "type": "DATASET", "confidence": 0.9452990690867106}]}, {"text": " Table 2: Our evaluation results for subtask A on the development and test sets for Spanish and English. F1 (avg)  is the average on positive and negative classes.", "labels": [], "entities": [{"text": "F1 (avg)", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.8800432831048965}]}]}