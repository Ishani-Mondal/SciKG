{"title": [], "abstractContent": [{"text": "This paper describes our system for SemEval 2019 RumorEval: Determining rumor veracity and support for rumors (SemEval 2019 Task 7).", "labels": [], "entities": [{"text": "SemEval 2019 RumorEval", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.844690223534902}, {"text": "SemEval 2019 Task 7", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.551173135638237}]}, {"text": "This track has two tasks: Task A is to determine a user's stance towards the source rumor, and Task B is to detect the veracity of the rumor: true, false or unverified.", "labels": [], "entities": []}, {"text": "For stance classification, a neural network model with language features is utilized.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.9745733439922333}]}, {"text": "For rumor verification, our approach exploits information from different dimensions: rumor content, source credibility, user credibility, user stance, event propagation path, etc.", "labels": [], "entities": [{"text": "rumor verification", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8601920008659363}]}, {"text": "We use an ensemble approach in both tasks, which includes neural network models as well as the traditional classification algorithms.", "labels": [], "entities": []}, {"text": "Our system is ranked 1 st place in the rumor verification task by both the macro F1 measure and the RMSE measure.", "labels": [], "entities": [{"text": "rumor verification task", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.8767634828885397}, {"text": "F1 measure", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.8678384125232697}, {"text": "RMSE", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.7842326164245605}]}], "introductionContent": [{"text": "Social media platforms, such as Twitter, Reddit and Facebook, do not always poses authentic information.", "labels": [], "entities": []}, {"text": "Rumors sometimes may spread quickly over these platforms).", "labels": [], "entities": []}, {"text": "A rumor maybe defined as a statement whose truth value is unverified or deliberately false).", "labels": [], "entities": []}, {"text": "Rumors usually spread fear or even euphoria, and they may confuse people and cause them to make wrong decisions.", "labels": [], "entities": []}, {"text": "Therefore, rumor detection has gained great interest recently.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.9671725928783417}]}, {"text": "In this paper, we describe the approaches we used in SemEval 2019 RumourEval: Determining rumor veracity and support for rumors.", "labels": [], "entities": [{"text": "SemEval 2019 RumourEval", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.7400348981221517}]}, {"text": "This task has two subtasks: Task A -user stance classification and Task B -rumor verification.", "labels": [], "entities": [{"text": "user stance classification", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6543985307216644}]}, {"text": "Stance classification is to determine the attitude of the author of a post message towards a target (.", "labels": [], "entities": [{"text": "Stance classification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9352856874465942}]}, {"text": "In task A, we focus on stance classification of messages towards the truthfulness of rumors in Twitter or Reddit conversations.", "labels": [], "entities": [{"text": "stance classification of messages", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.8411315232515335}]}, {"text": "Each conversation is defined by a source post that initiates the conversation, and a set of replies to it, which form a conversation thread.", "labels": [], "entities": []}, {"text": "The goal is to classify each post into one of the four categories: supporting, denying, querying or commenting (SDQC).", "labels": [], "entities": []}, {"text": "For this task, we use an ensemble approach, which combines the prediction results from both the traditional learning models, such as SVM, and a neural network model, using the language features extracted from the message text.", "labels": [], "entities": []}, {"text": "Task B predicts the veracity of a rumor: true, false, or unverified (i.e., its veracity cannot be verified based on the given information).", "labels": [], "entities": []}, {"text": "Each rumor consists of a source post that makes a claim, and a set of replies, directly or indirectly towards the source post.", "labels": [], "entities": []}, {"text": "We also employed an ensemble approach on this task, which uses multiple models together to do the veracity prediction.", "labels": [], "entities": [{"text": "veracity prediction", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7237884700298309}]}, {"text": "For more details about these two tasks, please check the task description paper from the task organizers ().", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Rumer verification result", "labels": [], "entities": [{"text": "Rumer verification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8545723557472229}]}]}