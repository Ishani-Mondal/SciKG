{"title": [{"text": "UBC-NLP at SemEval-2019 Task 4: Hyperpartisan News Detection With Attention-Based Bi-LSTMs", "labels": [], "entities": [{"text": "UBC-NLP", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8838300704956055}, {"text": "Hyperpartisan News Detection", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.6992379824320475}]}], "abstractContent": [{"text": "We present our deep learning models submitted to the SemEval-2019 Task 4 competition focused at Hyperpartisan News Detection.", "labels": [], "entities": [{"text": "SemEval-2019 Task 4 competition", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.837787538766861}, {"text": "Hyperpartisan News Detection", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.6849511663118998}]}, {"text": "We acquire best results with a Bi-LSTM network equipped with a self-attention mechanism.", "labels": [], "entities": []}, {"text": "Among 33 participating teams, our submitted system ranks top 7 (65.3% accuracy) on the labels-by-publisher sub-task and top 24 out of 44 teams (68.3% accuracy) on the labels-by-article sub-task (65.3% accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.998023271560669}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9884831309318542}, {"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9940569400787354}]}, {"text": "We also report a model that scores higher than the 8th ranking system (78.5% accuracy) on the labels-by-article sub-task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9943326711654663}]}], "introductionContent": [{"text": "Spread of fake news (e.g.,;) (or 'low-quality' information (), among other terms) can have destructive economic impacts, result in dangerous real world consequences, or possibly undermine the very democratic bases of modern societies (.", "labels": [], "entities": []}, {"text": "Several approaches have been employed for detecting fake stories online, including detecting the sources that are highly polarized (or hyperpartisan)] (.", "labels": [], "entities": [{"text": "detecting fake stories online", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.8196107745170593}]}, {"text": "Detecting whether a source is extremely biased for or against a given party can bean effective step toward identifying fake news.", "labels": [], "entities": [{"text": "Detecting", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9707430601119995}, {"text": "identifying fake news", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.833982785542806}]}, {"text": "Most research on news orientation prediction employed machine learning methods based on feature engineering.", "labels": [], "entities": [{"text": "news orientation prediction", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.8792513012886047}]}, {"text": "For example, use features such as text n-grams, part-ofspeech tags, hashtags, etc. with an SVM classifier to tackle political tendency identification in twitter.", "labels": [], "entities": [{"text": "political tendency identification", "start_pos": 116, "end_pos": 149, "type": "TASK", "confidence": 0.6767364939053854}]}, {"text": "investigate the writing style of hyperpartisan and mainstream news using a random forest classifier (.", "labels": [], "entities": []}, {"text": "Further, Preot\u00b8iucPreot\u00b8iuc- use a linear regression algorithm to categorize Twitter users into a fine-grained political group.", "labels": [], "entities": []}, {"text": "The authors were able to show a relationship between language use and political orientation.", "labels": [], "entities": []}, {"text": "Nevertheless, previous works have not considered the utility of deep learning methods for hyperpartisanship detection.", "labels": [], "entities": [{"text": "hyperpartisanship detection", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.8333339989185333}]}, {"text": "Our goal is to bridge this gap by investigating the extent to which deep learning can fare on the task.", "labels": [], "entities": []}, {"text": "More precisely, we employ several neural network architectures for hyperpartisans news detection, including long short-term memory networks (LSTM), convolutional neural networks (CNN), bi-directional long short term memory networks (Bi-LSTM), convolutional LSTM (CLSTM), recurrent convolutional neural network (RCNN), and attentionbased LSTMs and Bi-LSTMs.", "labels": [], "entities": [{"text": "hyperpartisans news detection", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.6321061849594116}]}, {"text": "We make the following contributions: (1) we investigate the utility of several deep learning models for classifying hyperpartisan news, (2) we test model performance under a range of training set conditions to identify the impact of training data size on the task, and (3) we probe our models with an attention mechanism coupled with a simple visualization method to discover meaningful contributions of various lexical features to the learning task.", "labels": [], "entities": [{"text": "classifying hyperpartisan news", "start_pos": 104, "end_pos": 134, "type": "TASK", "confidence": 0.8284307718276978}]}, {"text": "The rest of the paper is organized as follows: data are described in Section 2, Section 3 describes our methods, followed by experiments in Section 4.", "labels": [], "entities": []}, {"text": "Next, we explain the results in detail and our submission to SemEval-2019 Task4 in Section 4.", "labels": [], "entities": []}, {"text": "We present attention-based visualizations in Section 5, and conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run two main sets of experiments, which we will refer to as EXP-A and EXP-B.", "labels": [], "entities": []}, {"text": "For EXP-A, we train on the labels-by-publisher (Part 1) train set, tune on dev, and test on test.", "labels": [], "entities": []}, {"text": "All related results are reported in shows, our best macro F 1 as well as accuracy is acquired with Bi-LSTM with attention (Bi-LSTM+ATTN).", "labels": [], "entities": [{"text": "macro F 1", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.6898641983668009}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9995471835136414}, {"text": "Bi-LSTM", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9355691075325012}, {"text": "ATTN", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.83785480260849}]}, {"text": "For EXP-B, we use Part 1 and Part 2 datasets in tandem, where we train on each train set independently and (1) test on its test data, but also (2) test on the other set's test data.", "labels": [], "entities": [{"text": "EXP-B", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.7398999929428101}]}, {"text": "We also (3) fine-tune the models pre-trained on the bigger dataset (Part 1) on the smaller dataset (Part 2), to test the transferrability of knowledge from these bigger models.", "labels": [], "entities": []}, {"text": "Related results (only inaccuracy, for space) are in.", "labels": [], "entities": []}, {"text": "Again, the best accuracy is obtained with Bi-LSTM with attention.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9993851184844971}, {"text": "Bi-LSTM", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.9608615040779114}]}, {"text": "SemEval-2019 Task 4 Submissions: We submitted our Bi-LSMT+Attention model from EXP A to the labels-by-publisher leaderboard in TIRA ( , and it ranked top 7 out of the 33 teams, scoring at accuracy=0.6525 on the competition test set.", "labels": [], "entities": [{"text": "TIRA", "start_pos": 127, "end_pos": 131, "type": "DATASET", "confidence": 0.8013979196548462}, {"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9986997842788696}]}, {"text": "From EXP-B, we submitted our model based on Bi-LSMT+Attention that was trained on Part 2 train exclusively dataset (by-ATC in) to the labels-by-article leaderboard.", "labels": [], "entities": [{"text": "EXP-B", "start_pos": 5, "end_pos": 10, "type": "DATASET", "confidence": 0.9478272795677185}]}, {"text": "It ranked top 24th out of 44 teams (accuracy=0.6831).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.999763548374176}]}, {"text": "Post-competition, we submitted our EXP-B model that is pre-trained on the by-publisher data and fine-tuned on the by-article data (by-PSH+by-ATC in) to the labelsby-article leaderboard.", "labels": [], "entities": []}, {"text": "It ranked top 8th, with 78.50% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9974460601806641}]}, {"text": "This might be due to the ability of this specific model to transfer knowledge from the big (by-publisher) training set to the smaller (by-article) data (i.e., better generalization).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of labels over our data splits.", "labels": [], "entities": [{"text": "Distribution of labels", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8587526679039001}]}, {"text": " Table 2: Our best Hyper-parameters.", "labels": [], "entities": []}, {"text": " Table 3: Performance of Predicting Hyperpartisan News (EXP-A).", "labels": [], "entities": [{"text": "Performance of Predicting Hyperpartisan News (EXP-A)", "start_pos": 10, "end_pos": 62, "type": "TASK", "confidence": 0.5189001001417637}]}, {"text": " Table 4: Results with Part 1 and Part 2 datasets  (EXP-B). Last column \"by-PSH +by-ATC\" is the  setting of our models pre-trained on Part 1 and  fine-tuned on Part 2. +A= added attention.", "labels": [], "entities": [{"text": "Part 2 datasets", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.5949228902657827}, {"text": "A", "start_pos": 169, "end_pos": 170, "type": "METRIC", "confidence": 0.9727410078048706}, {"text": "attention", "start_pos": 178, "end_pos": 187, "type": "METRIC", "confidence": 0.5902729034423828}]}]}