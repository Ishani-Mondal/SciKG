{"title": [{"text": "T \u00a8 upa at SemEval-2019 Task 1: (Almost) feature-free Semantic Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "Our submission for Task 1 'Cross-lingual Semantic Parsing with UCCA' at SemEval-2018 is a feed-forward neural network that builds upon an existing state-of-the-art transition-based directed acyclic graph parser.", "labels": [], "entities": [{"text": "Cross-lingual Semantic Parsing", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.65994726618131}]}, {"text": "We replace most of its features by deep contextu-alized word embeddings and introduce an approximation to represent non-terminal nodes in the graph as an aggregation of their terminal children.", "labels": [], "entities": []}, {"text": "We further demonstrate how augmenting data using the baseline systems provides a consistent advantage in all open submission tracks.", "labels": [], "entities": []}, {"text": "We submitted results to all open tracks (English, in-and out-of-domain, German in-domain and French in-domain, low-resource).", "labels": [], "entities": []}, {"text": "Our system achieves competitive performance in all settings besides the French, where we did not augment the data.", "labels": [], "entities": [{"text": "French", "start_pos": 72, "end_pos": 78, "type": "DATASET", "confidence": 0.950988233089447}]}, {"text": "Post-evaluation experiments showed that data augmentation is especially crucial in this setting .", "labels": [], "entities": [{"text": "data augmentation", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7382393181324005}]}], "introductionContent": [{"text": "Semantic Parsing is the task of assigning an utterance a structured representation of its meaning.", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8048848807811737}]}, {"text": "The goal is to assign similar structures to utterances with similar meanings, regardless of their syntactic realizations.", "labels": [], "entities": []}, {"text": "In Syntactic Parsing, for instance, the sentence 'John saw Paul.'", "labels": [], "entities": [{"text": "Syntactic Parsing", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.8915079832077026}]}, {"text": "will have a different structure than 'Paul was seen by John'.", "labels": [], "entities": []}, {"text": "Semantic Parsing, in contrast, aims to solely encode the fact that John saw Paul.", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8221322894096375}]}, {"text": "Deriving a semantic representation of an utterance has various applications.", "labels": [], "entities": [{"text": "Deriving a semantic representation of an utterance", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.760430565902165}]}, {"text": "It can serve as a starting point for the evaluation of machine translation systems, as the structure of the semantic representation should be similar across languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7199297398328781}]}, {"text": "use human annotated scores of individual UCCA semantic units in their HUME metric to provide a fine-grained analysis of translation quality and improve scalability to longer sentences by approximating human judgement semiautomatically from the annotated scores of each unit.", "labels": [], "entities": []}, {"text": "Explicit semantic representations could also provide the structured information necessary to alleviate recent issues in Natural Language Inference (NLI) where showed that state-of-the-art NLI systems fail to recognize that e.g. 'Alice believes Mary is lying.'", "labels": [], "entities": [{"text": "Natural Language Inference (NLI)", "start_pos": 120, "end_pos": 152, "type": "TASK", "confidence": 0.75067072113355}]}, {"text": "does not entail 'Alice believes Mary.'.", "labels": [], "entities": []}, {"text": "Using precise semantic representations of the sentences a theorem could be built on which various logical inferences can be performed with a theorem prover such as in.", "labels": [], "entities": []}, {"text": "Universal Conceptual Cognitive Annotation (UCCA)) is a semantic grammar formalism where natural language expressions are analyzed as deep directed acyclic graph (DAG) structures, deep meaning the graphs feature non-terminal nodes.", "labels": [], "entities": [{"text": "Universal Conceptual Cognitive Annotation (UCCA))", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7485443098204476}]}, {"text": "Due to it's coarse-grained representation using cognitively motivated categories it is both domain and language independent and quickly learned even by annotators without a linguistic background.", "labels": [], "entities": []}, {"text": "The goal of the SemEval-2018 Task 1 'Crosslingual Semantic Parsing with UCCA' was to develop a parser producing UCCA-DAG structures trained on articles from Wikipedia in English and passages from the book \"Twenty Thousand Leagues Under the Sea\" in French and German.", "labels": [], "entities": [{"text": "SemEval-2018 Task 1", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.8746091723442078}, {"text": "Crosslingual Semantic Parsing with UCCA", "start_pos": 37, "end_pos": 76, "type": "TASK", "confidence": 0.6486637771129609}]}, {"text": "The parsers were evaluated on the DAG-F1 metric on in-domain passages in English, French and German as well as out-of-domain passages in English in both an open and a closed track).", "labels": [], "entities": [{"text": "DAG-F1", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.6803672313690186}]}, {"text": "Since we made extensive use of external resources we participated only in the open track of all settings.", "labels": [], "entities": []}, {"text": "For our participation, we build upon the transition-based DAG parser.", "labels": [], "entities": []}, {"text": "Our adaptation reuses the transition system and oracle.", "labels": [], "entities": []}, {"text": "We extend Tupa with respect to its representations of non-terminal nodes in away that they are an aggregation of all their terminal nodes.", "labels": [], "entities": [{"text": "Tupa", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.9216121435165405}]}, {"text": "While Tupa uses a Recurrent Neural Network, our system is a simple feed-forward network that uses a small set of features and ELMo contextualized embeddings () made available by.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will describe the findings of our post-evaluation experiments.", "labels": [], "entities": []}, {"text": "We evaluated the effect of silver data and provide results for French with silver data.", "labels": [], "entities": []}, {"text": "We further performed experiments on non-terminal representations and investigated the effect of model size.", "labels": [], "entities": []}, {"text": "Since this only covers a fraction of our experiments and describing them all would be out of scope, we  provide the full results alongside their hyperparameters at https://twuebi.github.io/ publications/ucca_post_eval.pdf.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: DAG-F1, primary F1 and remote F1 scores  with the DAG-F1 score of the baseline on the test sets  in the open tracks.", "labels": [], "entities": [{"text": "F1", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.8950904607772827}, {"text": "DAG-F1 score", "start_pos": 60, "end_pos": 72, "type": "METRIC", "confidence": 0.8355819284915924}]}, {"text": " Table 2: DAG F1 scores on the English development  set after training with gold and gold+silver data. Silver  data provides a boost for all combinations.", "labels": [], "entities": [{"text": "DAG", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9264981746673584}, {"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.7611640691757202}, {"text": "English development  set", "start_pos": 31, "end_pos": 55, "type": "DATASET", "confidence": 0.9095980525016785}]}, {"text": " Table 3: DAG F1 Scores on the French test set with  and without silver data. Here in the low-resource set- ting, the effect of additional data is the largest. Without  silver data, the parser did not predict any remote edges  correctly.", "labels": [], "entities": [{"text": "DAG F1 Scores", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.7867820262908936}, {"text": "French test set", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.9895267287890116}]}, {"text": " Table 4: Effect of discrete and aggregated non-terminal  representations on the DAG F1 score on the English de- velopment set. The aggregated representation provides  a clear advantage over the discrete one.", "labels": [], "entities": [{"text": "DAG F1 score", "start_pos": 81, "end_pos": 93, "type": "METRIC", "confidence": 0.7013645768165588}]}]}