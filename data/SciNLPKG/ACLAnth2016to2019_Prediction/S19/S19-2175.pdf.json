{"title": [{"text": "Team Howard Beale at SemEval-2019 Task 4: Hyperpartisan News Detection with BERT", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.862474650144577}, {"text": "Hyperpartisan News Detection", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6991115013758341}, {"text": "BERT", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9309529066085815}]}], "abstractContent": [{"text": "This paper describes our system for SemEval-2019 Task 4: Hyperpartisan News Detection (Kiesel et al., 2019).", "labels": [], "entities": [{"text": "SemEval-2019 Task 4", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.9002721309661865}, {"text": "Hyperpartisan News Detection", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.6022768318653107}]}, {"text": "We use pretrained BERT (Devlin et al., 2018) architecture and investigate the effect of different fine tuning regimes on the final classification task.", "labels": [], "entities": [{"text": "BERT", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9503273367881775}]}, {"text": "We show that additional pretraining on news domain improves the performance on the Hyperpartisan News Detection task.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection task", "start_pos": 83, "end_pos": 116, "type": "TASK", "confidence": 0.7127246856689453}]}, {"text": "Our system 1 ranked 8th out of 42 teams with 78.3% accuracy on the held-out test dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9994439482688904}]}], "introductionContent": [{"text": "With the rapid spread of the Internet and nextgeneration media development, people started to follow news through the Internet by abandoning de facto sources such as television and radio.", "labels": [], "entities": []}, {"text": "Recent studies reveal that 43% of Americans report often getting news online.", "labels": [], "entities": []}, {"text": "In parallel with that, there also has been a massive improvement in the NLP research in news domain to keep the content true, fair and unbiased.", "labels": [], "entities": []}, {"text": "SemEval-2019 Task 4: Hyperpartisan News Detection, is yet another attempt under this objective.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.757453441619873}]}, {"text": "Hyperpartisan is defined as being extremely biased in favor of apolitical party ( and the aim of the shared task is to detect hyperpartisan argumentation in news text.", "labels": [], "entities": []}, {"text": "Though it is an important task by itself, hyperpartisan argument detection is also considered as a very first step (or even replacement) of fake news detection, because it has been shown by) that there is a high positive correlation between having a hyperpartisan argumentation and being fake for news items.", "labels": [], "entities": [{"text": "hyperpartisan argument detection", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.6707088251908621}, {"text": "fake news detection", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7316083510716757}]}, {"text": "In this shared task, we seek to model this problem as a text classification task.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.8445191383361816}]}, {"text": "In general, the * equal contribution 1 https://github.com/ozanarkancan/hyperpartisan task aims to label the text in the question with one or more classes or categories.", "labels": [], "entities": []}, {"text": "The main question of text classification is how to mathematically represent the words/tokens such that they retain their original meaning in the context they appear.", "labels": [], "entities": [{"text": "text classification", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7139342725276947}]}, {"text": "This question has been tried to be answered in many different ways so far.", "labels": [], "entities": []}, {"text": "In earlier work, people mainly used the \"bag of words\" approach in algorithms such as Naive Bayes, Decision Tree, and SVM.", "labels": [], "entities": []}, {"text": "Then, () advanced the field further by introducing word embeddings, capturing a somewhat meaningful representation of words.", "labels": [], "entities": []}, {"text": "However, recent studies ( showed that contextual word embeddings perform quite better than traditional word embeddings in many different NLP tasks as a result of their superior capacity of meaning representation.", "labels": [], "entities": [{"text": "meaning representation", "start_pos": 189, "end_pos": 211, "type": "TASK", "confidence": 0.7242769300937653}]}, {"text": "Among those, BERT attracts researchers most because of (i) its transformer based architecture enabling faster training and (ii) state of the art results in many different tasks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9064849615097046}]}, {"text": "Though it is quite new, BERT has been tried in many different domains than the one proposed in.", "labels": [], "entities": [{"text": "BERT", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9955564141273499}]}, {"text": "However, almost all of these studies have two things in common: they don't start training BERT from scratch and the target domain contains very limited data (.", "labels": [], "entities": [{"text": "BERT", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9456846714019775}]}, {"text": "In this study, on the other hand, we address (1) the performance of BERT by comparing its domain specific pre-trained and fine-tuned performances, and (2) in the setting where the target domain has extensively more data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9053351283073425}]}, {"text": "In the following sections, we first summarize the BERT architecture, then give details of shared task data set, and then describe experimental setups we used to train BERT model.", "labels": [], "entities": [{"text": "BERT", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.5296695828437805}]}, {"text": "In the results section, we compare the performance of BERT under different settings and share our submission results for the shared task.", "labels": [], "entities": [{"text": "BERT", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9685155749320984}]}], "datasetContent": [{"text": "In this section, we first introduce data provided by the shared task and the data preprocessing step.", "labels": [], "entities": []}, {"text": "Then, we give the details of our experiments and results with BERT under pretraining and finetuning settings.", "labels": [], "entities": [{"text": "BERT", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9764862656593323}]}], "tableCaptions": [{"text": " Table 1: Classification results on our portal-wise data  splits with fine-tuned BERT.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9358493089675903}, {"text": "BERT", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9980648159980774}]}, {"text": " Table 3: Comparison of fine-tuning only and pretrain- ing + fine-tuning models.", "labels": [], "entities": [{"text": "pretrain- ing", "start_pos": 45, "end_pos": 58, "type": "METRIC", "confidence": 0.9520180026690165}]}, {"text": " Table 4: Shared task results.", "labels": [], "entities": []}]}