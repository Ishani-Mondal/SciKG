{"title": [{"text": "L 2 F/INESC-ID at SemEval-2019 Task 2: Unsupervised Lexical Semantic Frame Induction using Contextualized Word Representations", "labels": [], "entities": [{"text": "INESC-ID", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.7964869141578674}, {"text": "Unsupervised Lexical Semantic Frame Induction", "start_pos": 39, "end_pos": 84, "type": "TASK", "confidence": 0.5138396561145783}]}], "abstractContent": [{"text": "Building large datasets annotated with semantic information, such as FrameNet, is an expensive process.", "labels": [], "entities": []}, {"text": "Consequently, such resources are unavailable for many languages and specific domains.", "labels": [], "entities": []}, {"text": "This problem can be alleviated by using unsupervised approaches to induce the frames evoked by a collection of documents.", "labels": [], "entities": []}, {"text": "That is the objective of the second task of SemEval 2019, which comprises three sub-tasks: clustering of verbs that evoke the same frame and clustering of arguments into both frame-specific slots and semantic roles.", "labels": [], "entities": [{"text": "SemEval 2019", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.8167473077774048}]}, {"text": "We approach all the subtasks by applying a graph clustering algorithm on contextualized embedding representations of the verbs and arguments.", "labels": [], "entities": []}, {"text": "Using such representations is appropriate in the context of this task, since they provide cues for word-sense disambiguation.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 99, "end_pos": 124, "type": "TASK", "confidence": 0.719863697886467}]}, {"text": "Thus, they can be used to identify different frames evoked by the same words.", "labels": [], "entities": []}, {"text": "Using this approach we were able to outperform all of the baselines reported for the task on the test set in terms of Purity F 1 , as well as in terms of BCubed F 1 inmost cases.", "labels": [], "entities": [{"text": "Purity F 1", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.966907262802124}, {"text": "BCubed F 1", "start_pos": 154, "end_pos": 164, "type": "METRIC", "confidence": 0.9060298005739847}]}], "introductionContent": [{"text": "The Frame Semantics theory of language states that one cannot understand the meaning of a word without knowing the context surrounding it.", "labels": [], "entities": []}, {"text": "That is, a word may evoke different semantic frames depending on its context.", "labels": [], "entities": []}, {"text": "Considering this relation, sets of frame definitions and annotated datasets that map text into the semantic frames it evokes are important resources for multiple Natural Language Processing (NLP) tasks).", "labels": [], "entities": []}, {"text": "The most prominent of such resources is the FrameNet (, which provides a set of more than 1,200 generic semantic frames, as well as over 200,000 annotated sentences in English.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.8425079584121704}]}, {"text": "However, this kind of resource is expensive and time-consuming to build, since both the definition of the frames and the annotation of sentences require expertise in the underlying knowledge.", "labels": [], "entities": []}, {"text": "Furthermore, it is difficult to decide both the granularity and the domains to consider while defining the frames.", "labels": [], "entities": []}, {"text": "Consequently, such resources only exist fora reduced amount of languages and even English lacks domain-specific resources in multiple domains.", "labels": [], "entities": []}, {"text": "The problem of building semantic frame resources can be alleviated by using unsupervised approaches to induce the frames evoked by a collection of documents.", "labels": [], "entities": []}, {"text": "The second task of SemEval 2019 aims at comparing unsupervised frame induction systems for building semantic frame resources for verbs and their arguments.", "labels": [], "entities": []}, {"text": "It is split into three subtasks.", "labels": [], "entities": []}, {"text": "The first, Task A, focuses on clustering instances of verbs according to the semantic frame they evoke while the others focus on clustering the arguments of those verbs, both according to the frame-specific slots they fill, on Task B.1, and their semantic role, on In this paper, we address the three subtasks by following an approach that takes advantage of the recent developments on the generation of contextualized word representations (.", "labels": [], "entities": []}, {"text": "Such representations are able to disambiguate different word senses by varying the position of a word in the embedding space according to its context.", "labels": [], "entities": []}, {"text": "This ability is important in the context of semantic frame induction, since different wordsenses typically evoke different frames.", "labels": [], "entities": [{"text": "semantic frame induction", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.728697657585144}]}, {"text": "To identify words that evoke the same frame or have the same role, our approach consists of clustering their representations by applying the Chinese Whispers algorithm) to a similarity-based graph.", "labels": [], "entities": []}, {"text": "This way, we do not need to define the number of clusters and there is no bias towards the generation of clusters of similar size.", "labels": [], "entities": []}, {"text": "In the remainder of the paper, we start by providing an overview of previous studies related to the task, in Section 2.", "labels": [], "entities": []}, {"text": "Then, in Section 3, we describe our approach and explain how it differs from previous approaches.", "labels": [], "entities": []}, {"text": "Section 4 describes our experimental setup.", "labels": [], "entities": []}, {"text": "The results of our experiments are presented and discussed in Section 5.", "labels": [], "entities": []}, {"text": "Finally, Section 6 summarizes the conclusions of our work and provides pointers for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe our experimental setup in terms of data, implementation details, and evaluation metrics and baselines.", "labels": [], "entities": []}, {"text": "In our experiments, we used the dataset provided by the task organization, built with sentences from the Penn Treebank 3.0 (, and annotated with FrameNet frames (Task A), frame elements or slots (Task B.1) and generic semantic roles (Task B.2).", "labels": [], "entities": [{"text": "Penn Treebank 3.0", "start_pos": 105, "end_pos": 122, "type": "DATASET", "confidence": 0.9900515476862589}]}, {"text": "The development set consists of 600 verb-argument instances, 588 sentences and 1,211 arguments.", "labels": [], "entities": []}, {"text": "The (blind) test set comprises 4,620 verb-argument instances, 3,346 sentences, 9,466 arguments labeled for semantic role and 9,510 arguments labeled for frame slot.", "labels": [], "entities": []}, {"text": "Additionally, morphosyntactic information is provided in the CoNLL-U format ().", "labels": [], "entities": [{"text": "CoNLL-U format", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.905179351568222}]}, {"text": "We report our results using the metrics defined for the task: number of clusters (#C), purity, inversepurity, and their harmonic mean (Purity F 1 ), as proposed by, and BCubed (B 3 ) precision, recall, and F 1 , as proposed by.", "labels": [], "entities": [{"text": "purity", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9946692585945129}, {"text": "inversepurity", "start_pos": 95, "end_pos": 108, "type": "METRIC", "confidence": 0.9908697009086609}, {"text": "Purity F 1 )", "start_pos": 135, "end_pos": 147, "type": "METRIC", "confidence": 0.9688042104244232}, {"text": "BCubed (B 3 )", "start_pos": 169, "end_pos": 182, "type": "METRIC", "confidence": 0.6644141614437103}, {"text": "precision", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.5293715596199036}, {"text": "recall", "start_pos": 194, "end_pos": 200, "type": "METRIC", "confidence": 0.9988321661949158}, {"text": "F 1", "start_pos": 206, "end_pos": 209, "type": "METRIC", "confidence": 0.9948005676269531}]}], "tableCaptions": [{"text": " Table 1: Results obtained on the development set. The baselines are identified with BL.", "labels": [], "entities": [{"text": "BL", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9970388412475586}]}, {"text": " Table 2: Results obtained on the test set. The baselines are identified with BL.", "labels": [], "entities": [{"text": "BL", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9977267384529114}]}]}