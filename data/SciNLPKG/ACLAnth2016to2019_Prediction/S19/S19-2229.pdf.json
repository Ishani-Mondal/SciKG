{"title": [{"text": "THU NGN at SemEval-2019 Task 12: Toponym Detection and Disambiguation on Scientific Papers", "labels": [], "entities": [{"text": "THU NGN", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.5683585107326508}, {"text": "Toponym Detection and Disambiguation", "start_pos": 33, "end_pos": 69, "type": "TASK", "confidence": 0.7960955575108528}]}], "abstractContent": [{"text": "Toponym resolution is an important and challenging task in the neural language processing field, and has wide applications such as emergency response and social media geographical event analysis.", "labels": [], "entities": [{"text": "Toponym resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9129045009613037}, {"text": "emergency response", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.7974869310855865}, {"text": "social media geographical event analysis", "start_pos": 154, "end_pos": 194, "type": "TASK", "confidence": 0.5570336639881134}]}, {"text": "Toponym resolution can be roughly divided into two independent steps, i.e., toponym detection and toponym disam-biguation.", "labels": [], "entities": [{"text": "Toponym resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9054121375083923}, {"text": "toponym detection", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.8037051558494568}]}, {"text": "In order to facilitate the study on toponym resolution, the SemEval 2019 task 12 is proposed, which contains three subtasks, i.e., toponym detection, toponym disambigua-tion and toponym resolution.", "labels": [], "entities": [{"text": "toponym resolution", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8205558657646179}, {"text": "SemEval 2019 task 12", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.8021767437458038}, {"text": "toponym detection", "start_pos": 131, "end_pos": 148, "type": "TASK", "confidence": 0.7961255311965942}, {"text": "toponym resolution", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.7585977911949158}]}, {"text": "In this paper, we introduce our system that participated in the SemEval 2019 task 12.", "labels": [], "entities": [{"text": "SemEval 2019 task 12", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.8818211853504181}]}, {"text": "For toponym detection , in our approach we use TagLM as the basic model, and explore the use of various features in this task, such as word embeddings extracted from pre-trained language models, POS tags and lexical features extracted from dictionaries.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8586357533931732}]}, {"text": "For toponym disambiguation, we propose a heuristics rule-based method using toponym frequency and population.", "labels": [], "entities": [{"text": "toponym disambiguation", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7984596490859985}]}, {"text": "Our systems achieved 83.03% strict macro F1, 74.50 strict micro F1, 85.92 overlap macro F1 and 78.47 overlap micro F1 in toponym detection subtask.", "labels": [], "entities": [{"text": "strict macro F1", "start_pos": 28, "end_pos": 43, "type": "METRIC", "confidence": 0.7003200848897299}, {"text": "strict micro F1", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.6686812937259674}, {"text": "overlap macro F1", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.9227115909258524}, {"text": "overlap micro F1", "start_pos": 101, "end_pos": 117, "type": "METRIC", "confidence": 0.8765823841094971}, {"text": "toponym detection", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.6577617824077606}]}], "introductionContent": [{"text": "Toponym resolution is an important task in the natural language processing field and has many applications such as emergency response and social media geographical event analysis(.", "labels": [], "entities": [{"text": "Toponym resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.897016853094101}, {"text": "emergency response and social media geographical event analysis", "start_pos": 115, "end_pos": 178, "type": "TASK", "confidence": 0.6370106600224972}]}, {"text": "Toponym resolution is usually modelled as a two-step task.", "labels": [], "entities": [{"text": "Toponym resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9276812374591827}]}, {"text": "The first step is toponym detection, which is atypical named entity recognition (NER) task.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.8622311353683472}, {"text": "named entity recognition (NER) task", "start_pos": 55, "end_pos": 90, "type": "TASK", "confidence": 0.8094011885779244}]}, {"text": "The second step is toponym disambiguation, which aims to map locations to its coordinates in the real world.", "labels": [], "entities": [{"text": "toponym disambiguation", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.7452793419361115}]}, {"text": "NER is a widely explored task and most NER methods can be applied to toponym detection.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.8141552209854126}]}, {"text": "For example, used n-grams, history predictions as the input features of conditional random fields (CRF) for toponym detection.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7913358211517334}]}, {"text": "Usually the performance of these methods heavily relies on the quality of hand-crafted features.", "labels": [], "entities": []}, {"text": "However, manually selected features maybe sub-optimal.", "labels": [], "entities": []}, {"text": "Also, these methods cannot effectively exploit contextual information due to the dependency on bag-of-word features.", "labels": [], "entities": []}, {"text": "In recent years, many neural network based methods have been proposed for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9809932708740234}]}, {"text": "For example, proposed a CNN-LSTM-CRF model for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9226309657096863}]}, {"text": "They use CNN layer to learn character features of each word, LSTM layer to learn the contextual word representations and CRF layer to predict the label jointly.", "labels": [], "entities": []}, {"text": "They split a single LSTM into multiple equally-size ones with a penalty to promote diversity.", "labels": [], "entities": []}, {"text": "However, these methods cannot utilize external knowledge to recognize entities, which is usually important to toponym detection.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.8715218305587769}]}, {"text": "Usually, linguistic knowledge such as part-of-speech and dictionary knowledge maybe useful for toponym detection, and they are easy to obtain.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.9265299439430237}]}, {"text": "Therefore, in this paper, we aim to incorporate these external knowledge sources to enhance our neural model for toponym detection.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.8838271200656891}]}, {"text": "Similarly, there are many works on toponym disambiguation.", "labels": [], "entities": [{"text": "toponym disambiguation", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7509670257568359}]}, {"text": "Most of them are rule-based methods.", "labels": [], "entities": []}, {"text": "They use some heuristics to rank the candidates and choose the highest one(.", "labels": [], "entities": []}, {"text": "For example, used the geographical level(e.g. country, province and city), the Levenshtein Distance and the population of potential candidates to rank the candidate toponym and choose the highest one.", "labels": [], "entities": [{"text": "Levenshtein Distance", "start_pos": 79, "end_pos": 99, "type": "DATASET", "confidence": 0.6183554232120514}]}, {"text": "However, the result of toponym disambiguation relied on corpus domain and the rule should be reconsidered when applied to different corpus.", "labels": [], "entities": []}, {"text": "For the toponym detection task, we use TagLM() as the basic model.", "labels": [], "entities": [{"text": "toponym detection task", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.8756392598152161}]}, {"text": "In our model, we first learn word representations from original characters, then learn contextual word representations by a stacked Bi-LSTM network, and finally use a CRF layer to jointly decode the label sequence.", "labels": [], "entities": []}, {"text": "To enrich the representations of words, we incorporate various features such as pre-trained word embeddings, POS tags and lexicon features.", "labels": [], "entities": []}, {"text": "For the toponym disambiguation task, we design a rule-based heuristics method by using toponym frequency and population to rank candidate toponyms.", "labels": [], "entities": [{"text": "toponym disambiguation task", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.8075921734174093}]}, {"text": "Our systems achieved 83.03% strict macro F1 in the toponym detection task, 67.21% in the toponym disambiguation task and 61.31% strict macro F1 in toponym resolution.", "labels": [], "entities": [{"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.5659277439117432}, {"text": "toponym detection task", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.8203844229380289}, {"text": "toponym disambiguation task", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.7642772893110911}, {"text": "strict macro F1", "start_pos": 128, "end_pos": 143, "type": "METRIC", "confidence": 0.5570707817872366}, {"text": "toponym resolution", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.6957384049892426}]}], "datasetContent": [{"text": "We conduct experiments on science reports provided the SemEval-2019 task 12.", "labels": [], "entities": [{"text": "SemEval-2019 task 12", "start_pos": 55, "end_pos": 75, "type": "DATASET", "confidence": 0.5933352808157603}]}, {"text": "The data set is composed of 72 full-text journal articles in open access.", "labels": [], "entities": []}, {"text": "There are four different metrics to evaluate the prediction performance, i.e., strict macro F1, strict micro F1, overlap macro F1 and overlap micro F1.", "labels": [], "entities": [{"text": "strict macro F1", "start_pos": 79, "end_pos": 94, "type": "METRIC", "confidence": 0.5362473924954733}, {"text": "strict micro F1", "start_pos": 96, "end_pos": 111, "type": "METRIC", "confidence": 0.5525067150592804}, {"text": "overlap macro F1", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.9123748739560446}, {"text": "overlap micro F1", "start_pos": 134, "end_pos": 150, "type": "METRIC", "confidence": 0.8821974396705627}]}, {"text": "In the toponym detection task, we used NLTK 1 for sentence segmentation, word tokenization and POS tagging.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.877500593662262}, {"text": "sentence segmentation", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7542929947376251}, {"text": "word tokenization", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7485342621803284}, {"text": "POS tagging", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.8265848755836487}]}, {"text": "We used ELMo(Reimers and Gurevych, 2017) and BERT( model to generate 1024-dimensional contextualized word embeddings.", "labels": [], "entities": [{"text": "ELMo", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.8347981572151184}, {"text": "BERT", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9968871474266052}]}, {"text": "We used GeoNames 2 to construct lexical feature.", "labels": [], "entities": []}, {"text": "The BIO tagging scheme) was used in the toponym detection task.", "labels": [], "entities": [{"text": "BIO tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.703311413526535}, {"text": "toponym detection task", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.9013881087303162}]}, {"text": "In the toponym disambiguation task, we use GeoNames database to retrieve candidate toponyms.", "labels": [], "entities": [{"text": "toponym disambiguation", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.7633942663669586}, {"text": "GeoNames database", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.9414281845092773}]}, {"text": "In our approach, the three word embedding vectors we used (Glove(), word2vec(, fasttext() were all 300-dimensional.", "labels": [], "entities": [{"text": "Glove", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.8620495200157166}]}, {"text": "The dimension of the character embedding was set to 100.", "labels": [], "entities": []}, {"text": "The character CNN had 100 filters, and their window size was set to 3.", "labels": [], "entities": [{"text": "CNN", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.8479685187339783}]}, {"text": "The sizes of the 3-layer FFNN were respectively set to 256, 256, and 128.", "labels": [], "entities": [{"text": "FFNN", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.6135863065719604}]}, {"text": "We set the dimension of POS tag embeddings to 128.", "labels": [], "entities": []}, {"text": "The Bi-GRU layer for POS tag representation learning was 64-dimensional.", "labels": [], "entities": [{"text": "POS tag representation learning", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.8923904150724411}]}, {"text": "The two Bi-LSTM layers for capturing long-distance and short-distance information were 128-dimensional and 64-dimensional.", "labels": [], "entities": []}, {"text": "To mitigate overfitting, we added 20% dropout to each layer.", "labels": [], "entities": []}, {"text": "We used Adam as the optimizer for model training.", "labels": [], "entities": [{"text": "model training", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.7982382774353027}]}, {"text": "In our approach, we used transductive learning techniques to further improve the performance of our approach.", "labels": [], "entities": []}, {"text": "We first trained our model on the train set, and then applied our model to the test set to generate pseudo labeled data.", "labels": [], "entities": []}, {"text": "Finally, we jointly trained our model on the combination of the training and test sets.", "labels": [], "entities": []}, {"text": "In addition, we use model ensemble strategy to reduce the uncertainty of our model(.", "labels": [], "entities": []}, {"text": "We trained our model for 10 times independently and the final predictions are made by voting.", "labels": [], "entities": []}, {"text": "In this section, we compare our approach with several baseline methods to evaluate the performance of our approach.", "labels": [], "entities": []}, {"text": "The baseline methods are listed as follows.", "labels": [], "entities": []}, {"text": "Baseline: a baseline system provided by  only capture local information, instead, LSTM can utilize global information.", "labels": [], "entities": []}, {"text": "This indicates that capturing global contextual information have the potential to improve the performance of toponym detection.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.805732935667038}]}, {"text": "Second, the baseline method outperforms LSTM-CRF and CNN-CRF.", "labels": [], "entities": [{"text": "CNN-CRF", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9093825221061707}]}, {"text": "This may because LSTM-CRF and CNN-CRF did not use characterlevel features, which shows the effect of characterlevel information on the performance of toponym detection.", "labels": [], "entities": [{"text": "CNN-CRF", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9360277056694031}, {"text": "toponym detection", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.7301270812749863}]}, {"text": "In addition, the performances of CNN-CRF and LSTM-CRF are very poor.", "labels": [], "entities": [{"text": "CNN-CRF", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9665907621383667}, {"text": "LSTM-CRF", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.6706278324127197}]}, {"text": "This may because these two models only use word embedding to enhance the model's semantic information.", "labels": [], "entities": []}, {"text": "And this word embedding is not trained on science reports dataset, which may make these two methods lack of semantic information.", "labels": [], "entities": []}, {"text": "Third, our approach outperformed all these baseline methods.", "labels": [], "entities": []}, {"text": "This is because our approach use pre-trained word embeddings and language model to enhance the semantic information of model, use character-level word representations to capture character patterns of toponym names, and features, i.e., lexicon features and POStag features, to add extract information.", "labels": [], "entities": []}, {"text": "This result validates the effectiveness of our model.", "labels": [], "entities": []}, {"text": "The results for toponym disambiguation are listed in.", "labels": [], "entities": [{"text": "toponym disambiguation", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.8543519973754883}]}, {"text": "Baseline method selected toponym with highest population among candidate toponyms.", "labels": [], "entities": []}, {"text": "The performance of our method is similar to baseline method.", "labels": [], "entities": []}, {"text": "This maybe because high frequency toponyms are often with large population.: Influence of different features on the performance of our model.", "labels": [], "entities": []}, {"text": "WE, CE, POS, LEX respectively denote toponym detector using word embedding, character encoder, POS tag representations and lexicon representations as input.", "labels": [], "entities": [{"text": "WE", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.6990748047828674}, {"text": "LEX", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9897934198379517}]}], "tableCaptions": [{"text": " Table 1: Performance of different toponym detection  methods. SMA, SMI, OMA, and OMI respectively de- note the strict macro F1, strict micro F1, overlap macro  F1 and overlap micro F1.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7770112156867981}, {"text": "overlap macro  F1", "start_pos": 146, "end_pos": 163, "type": "METRIC", "confidence": 0.909827450911204}, {"text": "overlap micro F1", "start_pos": 168, "end_pos": 184, "type": "METRIC", "confidence": 0.8876164158185323}]}, {"text": " Table 2: Performance evaluation of toponym disam- biguation.", "labels": [], "entities": []}, {"text": " Table 3: Influence of different features on the perfor- mance of our model. WE, CE, POS, LEX respectively  denote toponym detector using word embedding, char- acter encoder, POS tag representations and lexicon rep- resentations as input.", "labels": [], "entities": [{"text": "WE", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.6672309041023254}, {"text": "CE", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.7590017914772034}, {"text": "LEX", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.960643470287323}]}]}