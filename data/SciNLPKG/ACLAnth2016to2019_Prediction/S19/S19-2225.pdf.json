{"title": [{"text": "Zoho at SemEval-2019 Task 9: Semi-supervised Domain Adaptation using Tri-training for Suggestion Mining", "labels": [], "entities": [{"text": "SemEval-2019 Task 9", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.8077812790870667}, {"text": "Semi-supervised Domain Adaptation", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.5769782265027364}, {"text": "Suggestion", "start_pos": 86, "end_pos": 96, "type": "TASK", "confidence": 0.9723021984100342}]}], "abstractContent": [{"text": "This paper describes our submission for the SemEval-2019 Suggestion Mining task.", "labels": [], "entities": [{"text": "SemEval-2019 Suggestion Mining task", "start_pos": 44, "end_pos": 79, "type": "TASK", "confidence": 0.8772169798612595}]}, {"text": "A simple Convolutional Neural Network (CNN) classifier with contextual word representations from a pre-trained language model is used for sentence classification.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.8071505725383759}]}, {"text": "The model is trained using tri-training, a semi-supervised bootstrapping mechanism for labelling unseen data.", "labels": [], "entities": []}, {"text": "Tri-training proved to bean effective technique to accommodate domain shift for cross-domain suggestion mining (Subtask B) where there is no hand labelled training data.", "labels": [], "entities": [{"text": "cross-domain suggestion mining", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.6444736619790395}]}, {"text": "For in-domain evaluation (Subtask A), we use the same technique to augment the training set.", "labels": [], "entities": []}, {"text": "Our system ranks thirteenth in Subtask A with an F 1-score of 68.07 and third in Subtask B with an F 1-score of 81.94.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9926761090755463}, {"text": "F 1-score", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9918465316295624}]}], "introductionContent": [{"text": "Task 9 of) focuses on mining sentences that contain suggestions in online discussions and reviews.", "labels": [], "entities": []}, {"text": "Suggestion Mining is modelled as a sentence classification task with two Subtasks: \u2022 Subtask A evaluates the classifier performance on a technical domain specific setting.", "labels": [], "entities": [{"text": "Suggestion Mining", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9792620539665222}, {"text": "sentence classification task", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.7879450718561808}]}, {"text": "\u2022 Subtask B evaluates the domain adaptability of a model by doing cross-domain suggestion classification on hotel reviews.", "labels": [], "entities": [{"text": "cross-domain suggestion classification", "start_pos": 66, "end_pos": 104, "type": "TASK", "confidence": 0.6157982150713602}]}, {"text": "We approached this task as an opportunity to test the effectiveness of transfer learning and semisupervised learning techniques.", "labels": [], "entities": []}, {"text": "In Subtask A, the high class imbalance and relatively smaller size of the training data made it an ideal setup for evaluating the efficacy of recent transfer learning techniques.", "labels": [], "entities": []}, {"text": "Using pre-trained language models for contextual word representations has been shown to improve many Natural Language Processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "This transfer learning technique is also an effective method when less labelled data is available as shown in.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.9028257131576538}]}, {"text": "In this work, we use the BERT model) for obtaining contextual representations.", "labels": [], "entities": [{"text": "BERT", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9964733719825745}]}, {"text": "This results in enhanced scores even for simple baseline classifiers.", "labels": [], "entities": []}, {"text": "Subtask B requires the system to not use manually labelled data and hence it lends itself to a classic semi-supervised learning scenario.", "labels": [], "entities": []}, {"text": "Many methods have been proposed for domain adaptation for NLP).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7328911572694778}]}, {"text": "We use a label bootstrapping technique called tri-training () with which unlabelled samples are labelled iteratively with increasing confidence at each training iteration(explained in Section 2.4).", "labels": [], "entities": []}, {"text": "shows the effectiveness of tri-training for baseline deep neural models in text classification under domain shift.", "labels": [], "entities": [{"text": "text classification", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8367921113967896}]}, {"text": "They also propose a multi-task approach for tri-training, however we only adapt the classic tri-training procedure presented for suggestion mining task.", "labels": [], "entities": [{"text": "suggestion mining task", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.7920785148938497}]}, {"text": "Detailed explanation of the submitted system and experiments are elicited in the following sections.", "labels": [], "entities": []}, {"text": "Section 2 describes the components of the system.", "labels": [], "entities": []}, {"text": "Following this, Section 3 details the experiments, results and ablation studies that were performed.", "labels": [], "entities": [{"text": "ablation", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9636496901512146}]}], "datasetContent": [{"text": "This section details the various experiments that were performed using the above components for our submissions.", "labels": [], "entities": []}, {"text": "Suggestions (%)  The original training data has a class imbalance with only 23% of the sentences labelled as suggestions.", "labels": [], "entities": [{"text": "Suggestions", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9854147434234619}]}, {"text": "We tried to balance the labels by naive upsampling, ie., adding duplicates of sentences that are labelled as suggestions.", "labels": [], "entities": []}, {"text": "This allowed us to have a balanced training dataset for our experiments.", "labels": [], "entities": []}, {"text": "This resulted in consistent gains over the original dataset during the trial evaluation phase.", "labels": [], "entities": []}, {"text": "However during the final submission, in Subtask A we found that the model's performance in the test set did not correlate well with that of the validation set as shown in.", "labels": [], "entities": []}, {"text": "This could be because the percentage of positive labels in the test set is only 10% while the validation set has 50%.", "labels": [], "entities": []}, {"text": "Experiments without upsampling gives better performance in test set even though there is a decrease in the validation score.", "labels": [], "entities": []}, {"text": "For Subtask B however, upsampling has actually increased the model performance.", "labels": [], "entities": []}, {"text": "On hindsight, this could be because of similar distribution of class labels in both validation and test sets.", "labels": [], "entities": []}, {"text": "The submitted models received an F 1 -score of 68.07 in Subtask A and 81.03 in Subtask B.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.992607980966568}]}], "tableCaptions": [{"text": " Table 1: Performance metrics of different models on validation and test sets of both subtasks. Confidence intervals  for the metrics are reported for five runs using different random seeds on t-distribution with 95% confidence.  Upsampling is used in the training dataset unless otherwise specified. Single model from experiments with * was  used for the final submission.", "labels": [], "entities": [{"text": "Confidence intervals", "start_pos": 96, "end_pos": 116, "type": "METRIC", "confidence": 0.9765589833259583}]}]}