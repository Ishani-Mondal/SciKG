{"title": [{"text": "WUT at SemEval-2019 Task 9: Domain-Adversarial Neural Networks for Domain Adaptation in Suggestion Mining", "labels": [], "entities": [{"text": "WUT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7391725182533264}, {"text": "SemEval-2019 Task 9", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.5846544504165649}, {"text": "Domain Adaptation in Suggestion Mining", "start_pos": 67, "end_pos": 105, "type": "TASK", "confidence": 0.795714795589447}]}], "abstractContent": [{"text": "We present a system for cross-domain suggestion mining, prepared for the SemEval-2019 Task 9: Suggestion Mining from Online Reviews and Forums (Subtask B).", "labels": [], "entities": [{"text": "cross-domain suggestion mining", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6950500309467316}, {"text": "SemEval-2019 Task 9", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.6136442025502523}, {"text": "Suggestion Mining from Online Reviews and Forums", "start_pos": 94, "end_pos": 142, "type": "TASK", "confidence": 0.9121067694255284}]}, {"text": "Our submitted solution for this text classification problem explores the idea of treating different sugges-tions' sources as one of the settings of Transfer Learning-Domain Adaptation.", "labels": [], "entities": [{"text": "text classification", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7144962102174759}, {"text": "Transfer Learning-Domain Adaptation", "start_pos": 148, "end_pos": 183, "type": "TASK", "confidence": 0.8925503889719645}]}, {"text": "Our experiments show that without any labeled target domain examples during training time, we are capable of proposing a system, reaching up to 0.778 in terms of F 1 score on test dataset, based on Target Preserving Domain-Adversarial Neural Networks.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 162, "end_pos": 171, "type": "METRIC", "confidence": 0.9885402917861938}]}], "introductionContent": [{"text": "Suggestion mining is an emerging task in a natural language processing (NLP) field.", "labels": [], "entities": [{"text": "Suggestion mining", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9839726686477661}]}, {"text": "Definition of suggestion mining task differs in NLP's community.", "labels": [], "entities": [{"text": "suggestion mining task", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.8052868247032166}]}, {"text": "Close areas of study like opinion mining or sentiment analysis get a lot of attention not only from academic, but also industrial researchers.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.8789687156677246}, {"text": "sentiment analysis", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.951181560754776}]}, {"text": "From a linguistic point of view, while these areas treat neutral polarity of a statement as an absence of opinion, suggestion does not have to be connected with positive or negative emotion and can be treated as complementary information.", "labels": [], "entities": []}, {"text": "Lack of sensitivity to statement's sentiment and various suggestions' realization strategies) make suggestion mining task interesting and challenging from a NLP's standpoint.", "labels": [], "entities": [{"text": "suggestion mining task", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.7834555904070536}]}, {"text": "In this work, we present a system for crossdomain suggestion mining, ranked in the 7 th place in SemEval-2019 Task 9 Subtask B. The training data for this task was collected from feedback posts on Universal Windows Platform.", "labels": [], "entities": [{"text": "crossdomain suggestion mining", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.7272806763648987}, {"text": "SemEval-2019 Task 9 Subtask", "start_pos": 97, "end_pos": 124, "type": "TASK", "confidence": 0.6039861440658569}, {"text": "Universal Windows Platform", "start_pos": 197, "end_pos": 223, "type": "DATASET", "confidence": 0.9465025862058004}]}, {"text": "On the other hand, the test dataset comes from the different domain of hotel reviews from the TripAdvisor website (.", "labels": [], "entities": []}, {"text": "In this work we will refer to those datasets' domain as source domain and target domain accordingly.", "labels": [], "entities": []}, {"text": "For suggestion mining task in this context, we employ ensemble of Domain-Adversarial Neural Networks (DANN) where we use Structured Self-Attentive Sentence Embedding () as a feature extractor.", "labels": [], "entities": [{"text": "suggestion mining task", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8065432707468668}]}, {"text": "Moreover, to achieve better adaptation towards target domain, we follow the approach of for the part-of-speech tagging and extend DANN with a Target Preserving component in a form of words decoder for target domain sentences.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.752391517162323}]}, {"text": "We train all of the parts of the described system using modified domain adversarial training procedure than the one proposed in ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Training dataset for Subtask B was built using only sentences from source domain.", "labels": [], "entities": [{"text": "Subtask B", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.8637845516204834}]}, {"text": "In order to train DANN we take advantage of an additional set of unlabeled sentences from the same domain as a test dataset.", "labels": [], "entities": []}, {"text": "We use a subset of data from another corpora () consisting of hotel's reviews.", "labels": [], "entities": []}, {"text": "The selection of the subset is as follows, first we take benefit of a \"weak\" classifier in the form of the baseline, rules-based system provided by the organizers, to predict a class in the mentioned corpora.", "labels": [], "entities": []}, {"text": "After that we choose the subset with the same distribution of classes (2085 suggestions and 6415 no suggestions) and remove too short statements to obtain a histogram of sentences' lengths close to the rest of datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F 1 score on target domain validation and test datasets.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9789179166158041}]}]}