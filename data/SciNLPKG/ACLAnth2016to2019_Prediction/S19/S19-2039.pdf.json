{"title": [{"text": "IIT Gandhinagar at SemEval-2019 Task 3: Contextual Emotion Detection Using Deep Learning", "labels": [], "entities": [{"text": "IIT Gandhinagar", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7569576501846313}, {"text": "Contextual Emotion Detection", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.742084781328837}]}], "abstractContent": [{"text": "Recent advancements in Internet and Mobile infrastructure have resulted in the development of faster and efficient platforms of communication.", "labels": [], "entities": []}, {"text": "These platforms include speech, facial and text-based conversational mediums.", "labels": [], "entities": []}, {"text": "Majority of these are text-based messaging platforms.", "labels": [], "entities": []}, {"text": "Development of Chatbots that automatically understand latent emotions in the tex-tual message is a challenging task.", "labels": [], "entities": []}, {"text": "In this paper , we present an automatic emotion detection system that aims to detect the emotion of a person textually conversing with a chatbot.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7287431955337524}]}, {"text": "We explore deep learning techniques such as CNN and LSTM based neural networks and outper-formed the baseline score by 14%.", "labels": [], "entities": []}, {"text": "The trained model and code are kept in public domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent times, text has become a preferred mode of communication over phone/video calling or face-to-face communication.", "labels": [], "entities": []}, {"text": "New challenges and opportunities accompany this change.", "labels": [], "entities": []}, {"text": "Identifying sentiment from text has become a sought after research topic.", "labels": [], "entities": [{"text": "Identifying sentiment from text", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9335995465517044}]}, {"text": "Applications include detecting depression ( or teaching empathy to chatbots.", "labels": [], "entities": [{"text": "detecting depression", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.8763954639434814}]}, {"text": "These applications leverage NLP for extracting sentiments from text.", "labels": [], "entities": [{"text": "extracting sentiments from text", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.8838944584131241}]}, {"text": "On this line, SemEval Task 3: EmoContext () challenges participants to identify Contextual Emotions in Text.", "labels": [], "entities": []}, {"text": "Challenges: The challenges with extracting sentiments from text are not only limited to the use of slang, sarcasm or multiple languages in a sentence.", "labels": [], "entities": []}, {"text": "There is also a challenge which is presented by the use of non-standard acronyms specific to individuals and others which are present in the task's dataset 2.", "labels": [], "entities": []}, {"text": "* Equal Contribution Existing work: For sentiment analysis, most of the previous year's submissions focused on neural networks (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.9814658761024475}]}, {"text": "Teams experimented with Recurrent Neural Network (RNN) as well as Convolutional Neural Network (CNN) based models (.", "labels": [], "entities": []}, {"text": "However, some top ranking teams also used () classic machine learning models.", "labels": [], "entities": []}, {"text": "Aiming for the best system, we started with classical machine learning algorithms like Support Vector Machine (SVM) and Logistic Regression (LR).", "labels": [], "entities": []}, {"text": "Based on the findings from them we moved to complex models using Long ShortTerm Memory (LSTM), and finally, we experimented with CNN in search for the right system.", "labels": [], "entities": []}, {"text": "Our contribution: In this paper, we present models to extract emotions from text.", "labels": [], "entities": []}, {"text": "All our models are trained using only the dataset provided by EmoContext organizers.", "labels": [], "entities": []}, {"text": "The evaluation metric set by the organizers is micro F1 score (referred as score in rest of the paper) on three {Happy, Sad, Angry} out of the four labels.", "labels": [], "entities": [{"text": "micro F1 score", "start_pos": 47, "end_pos": 61, "type": "METRIC", "confidence": 0.815291166305542}]}, {"text": "We experimented by using simpler models like SVM, and Logistic regression but the score on dev set was below 0.45.", "labels": [], "entities": []}, {"text": "We then worked with a CNN model and two LSTM based models where we were able to beat the baseline and achieve a maximum score of 0.667 on test set.", "labels": [], "entities": []}, {"text": "Outline: Section 2 describes the dataset and preprocessing steps.", "labels": [], "entities": []}, {"text": "Section 3 presents model description and system information.", "labels": [], "entities": [{"text": "model description", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.6931803524494171}]}, {"text": "In the next section (Section 4), we discuss experimental results and comparisons against state-of-the-art baselines.", "labels": [], "entities": []}, {"text": "Towards the end, Section 5 and Section 6 conclude this work with current limitations and proposal for future extension.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the dataset provided by Task 3 in SE-MEVAL 2019.", "labels": [], "entities": []}, {"text": "This task is titled as 'EmoContext: Contextual Emotion Detection in Text'.", "labels": [], "entities": [{"text": "EmoContext: Contextual Emotion Detection in Text", "start_pos": 24, "end_pos": 72, "type": "TASK", "confidence": 0.6721899253981454}]}, {"text": "The dataset consists of textual dialogues i.e. a user utterance along with two turns of context.", "labels": [], "entities": []}, {"text": "Each dialogue is labelled into several emotion classes: Happy, Sad, Angry or Others.", "labels": [], "entities": []}, {"text": "Preprocessing: We leverage two pretrained word embedding: (i)) and (ii) sentiment specific word embedding (SSWE) ().", "labels": [], "entities": []}, {"text": "However, several classes of words are not present in these embeddings.", "labels": [], "entities": []}, {"text": "We list these classes below: \u2022 Emojis: , , etc.", "labels": [], "entities": []}, {"text": "\u2022 Elongated words: Wowwww, noooo, etc.", "labels": [], "entities": []}, {"text": "\u2022 Misspelled words: ofcorse, activ, doin, etc.", "labels": [], "entities": [{"text": "Misspelled", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.8400634527206421}, {"text": "doin", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9077880382537842}]}, {"text": "\u2022 Non-English words: Chalo, kyun, etc.", "labels": [], "entities": []}, {"text": "We follow a standard preprocessing pipeline to address the above limitations.", "labels": [], "entities": []}, {"text": "describes the dataset preprocessing pipeline.", "labels": [], "entities": []}, {"text": "By using the dataset preprocessing pipeline, we reduced the number of words not found in GloVe embedding from 4154 to 813 and in SSWE from 3188 to 1089.", "labels": [], "entities": [{"text": "SSWE", "start_pos": 129, "end_pos": 133, "type": "DATASET", "confidence": 0.8993700742721558}]}, {"text": "\u2020 NLTK Library ( \u2021 For spellcheck we the used the following PyPI package -pypi.org/project/pyspellchecker/.", "labels": [], "entities": [{"text": "NLTK Library", "start_pos": 2, "end_pos": 14, "type": "DATASET", "confidence": 0.8441173136234283}]}, {"text": "We experiment with several classification systems.", "labels": [], "entities": []}, {"text": "In the following subsections we first explain the classical ML based models followed by Deep Neural Network based models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 shows the distribution of classes in the  EmoContext dataset. The dataset is further subdi- vided into train, dev and test sets. In this work, we  use training set for model training and dev set for  validation and hyper-parameter tuning.", "labels": [], "entities": [{"text": "EmoContext dataset", "start_pos": 51, "end_pos": 69, "type": "DATASET", "confidence": 0.9680907130241394}, {"text": "hyper-parameter tuning", "start_pos": 224, "end_pos": 246, "type": "TASK", "confidence": 0.6836298704147339}]}, {"text": " Table 2: Model performance on dev & test dataset.", "labels": [], "entities": []}]}