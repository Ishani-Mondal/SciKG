{"title": [{"text": "SSN NLP at SemEval-2019 Task 6: Offensive Language Identification in Social Media using Traditional and Deep Machine Learning Approaches", "labels": [], "entities": [{"text": "SSN NLP", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.6737881302833557}, {"text": "Offensive Language Identification", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.7833918531735738}]}], "abstractContent": [{"text": "Offensive language identification (OLI) in user generated text is automatic detection of any profanity, insult, obscenity, racism or vulgarity that degrades an individual or a group.", "labels": [], "entities": [{"text": "Offensive language identification (OLI) in user generated text is automatic detection of any profanity, insult, obscenity, racism or vulgarity that degrades an individual or a group", "start_pos": 0, "end_pos": 181, "type": "Description", "confidence": 0.7968255810199245}]}, {"text": "It is helpful for hate speech detection, flame detection and cyber bullying.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.889648973941803}, {"text": "flame detection", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.8748655915260315}]}, {"text": "Due to immense growth of accessibility to social media, OLI helps to avoid abuse and hurts.", "labels": [], "entities": []}, {"text": "In this paper , we present deep and traditional machine learning approaches for OLI.", "labels": [], "entities": [{"text": "OLI", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.955376386642456}]}, {"text": "In deep learning approach, we have used bi-directional LSTM with different attention mechanisms to build the models and in traditional machine learning , TF-IDF weighting schemes with classi-fiers namely Multinomial Naive Bayes and Support Vector Machines with Stochastic Gradient Descent optimizer are used for model building.", "labels": [], "entities": []}, {"text": "The approaches are evaluated on the OffensEval@SemEval2019 dataset and our team SSN NLP submitted runs for three tasks of OffensEval shared task.", "labels": [], "entities": [{"text": "OffensEval@SemEval2019 dataset", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.7431286126375198}]}, {"text": "The best runs of SSN NLP obtained the F1 scores as 0.53, 0.48, 0.3 and the accuracies as 0.63, 0.84 and 0.42 for the tasks A, B and C respectively.", "labels": [], "entities": [{"text": "SSN NLP", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.7462103962898254}, {"text": "F1 scores", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9789412319660187}, {"text": "accuracies", "start_pos": 75, "end_pos": 85, "type": "METRIC", "confidence": 0.9852415919303894}]}, {"text": "Our approaches improved the baseline F1 scores by 12%, 26% and 14% for Task A, B and C respectively .", "labels": [], "entities": [{"text": "baseline", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9231638312339783}, {"text": "F1 scores", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.92246013879776}]}], "introductionContent": [{"text": "Offensive language identification (OLI) is a process of detecting offensive language classes () such as slurs, homophobia, profanity, extremism, insult, disguise, obscenity, racism or vulgarity that hurts or degrades an individual or a group from user-generated text like social media postings.", "labels": [], "entities": [{"text": "Offensive language identification (OLI) is a process of detecting offensive language classes () such as slurs, homophobia, profanity, extremism, insult, disguise, obscenity, racism or vulgarity that hurts or degrades an individual or a group from user-generated text like social media postings", "start_pos": 0, "end_pos": 293, "type": "Description", "confidence": 0.8275323295593262}]}, {"text": "OLI is useful for several applications such as hate speech detection, flame detection, aggression detection and cyber bullying.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.838856558005015}, {"text": "flame detection", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.8242476880550385}, {"text": "aggression detection", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.7231348901987076}]}, {"text": "Recently, several research work have been reported to identify the offensive languages using social media content.", "labels": [], "entities": []}, {"text": "Several workshops such as TA-COS 1 , TRAC 2 (), Abusive Language Online 3 and GermEval () have been organized recently in this research area.", "labels": [], "entities": [{"text": "TRAC 2", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.7115451097488403}, {"text": "Abusive Language Online", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.8588072260220846}]}, {"text": "In this line, OffensEval@SemEval2019 ( shared task focuses on identification and categorization of offensive language in social media.", "labels": [], "entities": [{"text": "identification and categorization of offensive language in social media", "start_pos": 62, "end_pos": 133, "type": "TASK", "confidence": 0.5908996992641025}]}, {"text": "It focuses on three subtasks namely offensive language detection, categorization of offensive language and offensive language target identification.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.6829169193903605}, {"text": "offensive language target identification", "start_pos": 107, "end_pos": 147, "type": "TASK", "confidence": 0.6438838690519333}]}, {"text": "Sub Task A aims to detect text as offensive (OFF) or not offensive (NOT).", "labels": [], "entities": [{"text": "OFF", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9139913320541382}]}, {"text": "Sub Task B aims to categorize the offensive type as targeted text (TIN) or untargeted text (UNT).", "labels": [], "entities": []}, {"text": "Sub Task C focuses on identification of target as individual (IND), group (GRP) or others (OTH).", "labels": [], "entities": []}, {"text": "Our team SSN NLP participated in all the three subtasks. classifier.", "labels": [], "entities": [{"text": "SSN NLP", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.8198038935661316}]}, {"text": "learnt distributed low-dimensional representations of social media comments using neural language models for hate speech detection.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.6889093319574991}]}, {"text": "used n-gram (bigram, unigram, and trigram) features with TF-IDF score along with crowd-sourced hate speech lexicon and employed several classifiers including logistic regression with L1 regularization to separate hate speech from other offensive languages.", "labels": [], "entities": [{"text": "TF-IDF score", "start_pos": 57, "end_pos": 69, "type": "METRIC", "confidence": 0.7915989458560944}]}, {"text": "used n-grams, skip-grams and clustering-based word representations as features with ensemble classifier for hate speech detection.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7790244221687317}]}, {"text": "performed linguistic and psycholinguistic analysis to detect the hate speech is either \"directed\" towards a target, or \"generalized\" towards a group.", "labels": [], "entities": []}, {"text": "used deep learning using CNN models to detect the hate speech as \"racism\", \"sexism\", \"both\" and \"nonhate-speech\".", "labels": [], "entities": []}, {"text": "They used character 4-grams, word vectors based on word2vec, randomly generated word vectors, and word vectors combined with character n-grams as features in their approach.", "labels": [], "entities": []}, {"text": "used convolution-GRU based deep neural network for detecting hate speech.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.8062122066815695}]}, {"text": "Many research work have been carried out in aggression detection).", "labels": [], "entities": [{"text": "aggression detection", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8854173421859741}]}, {"text": "used LSTM and CNN respectively to detect aggression in text.", "labels": [], "entities": [{"text": "CNN", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.6673194766044617}]}, {"text": "presented the findings of the shared task on aggression identification which aims to detect different scales of aggression namely \"Overtly Aggressive\", \"Covertly Aggressive\", and \"Non-aggressive\".", "labels": [], "entities": [{"text": "aggression identification", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.747240424156189}]}, {"text": "used CNN, LSTM and Bi-LSTM to detect the above scales of aggression.", "labels": [], "entities": [{"text": "CNN", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.821894109249115}, {"text": "Bi-LSTM", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9755139350891113}]}, {"text": "presented the methodologies on abusive language identification using deep neural networks.", "labels": [], "entities": [{"text": "abusive language identification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6745690107345581}]}, {"text": "applied transfer learning to detect three classes namely \"nonoffensive\", \"abusive\" and \"hate-speech\" from Hindi-English code switched language.", "labels": [], "entities": []}, {"text": "presented a framework to annotate offensive labels in Slovene.", "labels": [], "entities": []}, {"text": "rephrased profanity in Chinese text after detecting them from social media text.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Models for the Tasks", "labels": [], "entities": []}, {"text": " Table 2: Results for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 3: Results for Sub-task B.", "labels": [], "entities": []}, {"text": " Table 4: Results for Sub-task C.", "labels": [], "entities": []}, {"text": " Table 5: Confusion Matrix for Task A DL SL.", "labels": [], "entities": []}, {"text": " Table 7: Confusion Matrix for Task C TL SVM.", "labels": [], "entities": []}]}