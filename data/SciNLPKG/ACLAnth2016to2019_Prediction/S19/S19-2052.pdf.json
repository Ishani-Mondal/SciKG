{"title": [{"text": "Sentim at SemEval-2019 Task 3: Convolutional Neural Networks For Sentiment in Conversations", "labels": [], "entities": []}], "abstractContent": [{"text": "In this work convolutional neural networks were used in order to determine the sentiment in a conversational setting.", "labels": [], "entities": []}, {"text": "This paper's contributions include a method for handling any sized input and a method for breaking down the conversation into separate parts for easier processing.", "labels": [], "entities": []}, {"text": "Finally, clustering was shown to improve results and that such a model for handling sentiment in conversations is both fast and accurate.", "labels": [], "entities": [{"text": "handling sentiment in conversations", "start_pos": 75, "end_pos": 110, "type": "TASK", "confidence": 0.875967264175415}]}], "introductionContent": [{"text": "The model for this paper was created for Task 3 of.", "labels": [], "entities": []}, {"text": "The basic idea of the task is to classify the emotion (as \"angry\", \"sad\", \"happy\", or \"others\") that someone is expressing in the third turn of a three part conversation, given the previous two turns as context.", "labels": [], "entities": [{"text": "classify the emotion (as \"angry\", \"sad\", \"happy\", or \"others\") that someone is expressing in the third turn of a three part conversation", "start_pos": 33, "end_pos": 169, "type": "Description", "confidence": 0.7397098488667432}]}, {"text": "The dominant approach in many natural language tasks is to use recurrent neural networks or convolutional neural networks (CNN) (.", "labels": [], "entities": []}, {"text": "For classification tasks, recurrent neural networks have a natural advantage because of their ability to take in any size input and output a fixed size output.", "labels": [], "entities": [{"text": "classification tasks", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9399404525756836}]}, {"text": "This ability allows for greater generalization as no data is removed nor added in order for the inputs to match in length.", "labels": [], "entities": []}, {"text": "While CNN's can also support input of any size, they lack the ability to generate a fixed size output from any sized input.", "labels": [], "entities": []}, {"text": "In text classification tasks, this often means that the input is fixed in size in order for the output to also have a fixed size.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.8694548408190409}]}, {"text": "This work expands upon a previous work), away of using CNN's for classification to allow for any sized input length without adding or removing data.", "labels": [], "entities": []}, {"text": "That work was expanded upon in this paper by making it simpler, using it in a different setting, and applying anew method to compensate for the previous model's deficiencies.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments for this paper were all run on the dataset provided by the EmoContext organizers.", "labels": [], "entities": [{"text": "EmoContext organizers", "start_pos": 75, "end_pos": 96, "type": "DATASET", "confidence": 0.9276675581932068}]}, {"text": "The main dataset contains roughly 30,000 conversations, while the test dataset contains roughly 2,750, and the final evaluation dataset contains about 5,500.", "labels": [], "entities": []}, {"text": "The order of each conversation goes Person A, Person B, then Person A again for all of the datasets.", "labels": [], "entities": []}, {"text": "The first submission on the evaluation dataset was an ensemble of 118 networks.", "labels": [], "entities": []}, {"text": "In total, the 118 networks came from 100 different training cycles: 50 runs using causal padding as the padding method in the dilated residual convolutional stack, and 50 runs using the \"same\" padding method.", "labels": [], "entities": []}, {"text": "Each run was trained against the full dataset for nine epochs and tested against the test dataset, so the checkpoints chosen were the ones that performed the best on the test dataset.", "labels": [], "entities": []}, {"text": "The remaining 18 networks came from checkpoints that were not the best checkpoint of the training run but still had a micro f1 score above 0.7 on the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Micro f1 score on the final evaluation set for  each of my submissions.", "labels": [], "entities": [{"text": "Micro f1 score", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9557674924532572}]}, {"text": " Table 2: Micro f1 score of the first, second, and third  place submissions as well as the average and median  scores of all submissions as compared to my best sub- mission.", "labels": [], "entities": [{"text": "Micro f1 score", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9639694889386495}]}, {"text": " Table 2. Addition- ally, I show the micro f1 score as well as the f1  score for the happy, angry, and sad labels for a few  of my models in", "labels": [], "entities": [{"text": "micro f1 score", "start_pos": 37, "end_pos": 51, "type": "METRIC", "confidence": 0.8316633900006613}, {"text": "f1  score", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9413336217403412}]}, {"text": " Table 3: Micro f1 score as well as the f1 score for  the angry, happy, and sad labels. Best single model  is abbreviated as BSM, as well as the ensemble of all  models that scored higher than a certain f1 score as f1  >score.", "labels": [], "entities": [{"text": "Micro f1 score", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.7801833748817444}, {"text": "BSM", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.736479640007019}]}]}