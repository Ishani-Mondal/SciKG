{"title": [], "abstractContent": [{"text": "In this paper, we propose the use of a Convo-lutional Neural Network (CNN) to identify offensive tweets.", "labels": [], "entities": []}, {"text": "We use an end-to-end model (i.e., no preprocessing) and fine-tune pre-trained embeddings (FastText) during training for learning words' representation.", "labels": [], "entities": [{"text": "learning words' representation", "start_pos": 120, "end_pos": 150, "type": "TASK", "confidence": 0.660882443189621}]}, {"text": "We compare the proposed CNN model to a baseline model, such as Linear Regression, and several neural models.", "labels": [], "entities": []}, {"text": "The results show that CNN outperforms other models, and stands as a simple but strong baseline in comparison to other systems submitted to the Shared Task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The fast growth of online social networks (OSNs) has provided a medium for users to express their ideas and opinions about any topic.", "labels": [], "entities": []}, {"text": "However, some users post offensive content which may deter other users from engaging in online discussions.", "labels": [], "entities": []}, {"text": "Despite the tools provided by some OSNs to block other users and report offensive content, the manual verification of these events are limited in scale and costs due to a large number of malicious events performed by users or bots.", "labels": [], "entities": []}, {"text": "Therefore, it is critical to developing automated tools to moderate the content that are robust to ambiguity, sarcasm, and adversarial attacks.", "labels": [], "entities": []}, {"text": "Offensive language detection is an active research area, and several research efforts aim to contribute datasets, propose taxonomies, and improve current models to identify offensive content.", "labels": [], "entities": [{"text": "Offensive language detection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8087043960889181}]}, {"text": "In this direction, proposed a shared task for Identifying and Categorizing Offensive Language in Social Media.", "labels": [], "entities": [{"text": "Identifying and Categorizing Offensive Language in Social Media", "start_pos": 46, "end_pos": 109, "type": "TASK", "confidence": 0.7673007100820541}]}, {"text": "The shared task is composed of the following subtasks: a) Offensive language identification, b) Automatic categorization of offense types, and c) Offense target identification.", "labels": [], "entities": [{"text": "Offensive language identification", "start_pos": 58, "end_pos": 91, "type": "TASK", "confidence": 0.7282455563545227}, {"text": "Offense target identification", "start_pos": 146, "end_pos": 175, "type": "TASK", "confidence": 0.7956004540125529}]}, {"text": "shows some examples in the dataset of the shared task, and the labels in each of the subtasks.", "labels": [], "entities": []}, {"text": "The labels indicate if the tweet is Offensive (OFF) and if it is an untargeted (UNT) or targeted (TIN) offense.", "labels": [], "entities": []}, {"text": "The targets of the offensive tweets are individual (IND), group (GRP), other (OTH).", "labels": [], "entities": []}, {"text": "This paper contributes specifically to the subtask A in the shared task.", "labels": [], "entities": []}, {"text": "The unstructured and noisy nature of usergenerated content on OSNs poses a challenge for classification models.", "labels": [], "entities": []}, {"text": "Traditional approaches use a sparse representation for text data, such as the bag of words (BOW) or TF-IDF (.", "labels": [], "entities": []}, {"text": "We propose a model based on Convolutional Neural Networks (CNN) to identify and categorize offensive language on tweets.", "labels": [], "entities": []}, {"text": "The learning representation relies on FastText pre-trained word embeddings (.", "labels": [], "entities": []}, {"text": "Although, this paper focus only on the first subtask, it can be extended to learn the other subtasks.", "labels": [], "entities": []}, {"text": "The rest of the paper describes related work in section 2.", "labels": [], "entities": []}, {"text": "Then, we explain in detail our proposed model in section 3, and section 4 shows the results.", "labels": [], "entities": []}, {"text": "Finally, we outline the conclusions and future work in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experimental settings and the results for the subtask A: identifying offensive tweets.", "labels": [], "entities": []}, {"text": "We use the data provided in the shared task OffensEval described in. describe the label distribution for each of the subtasks.", "labels": [], "entities": []}, {"text": "We use the F 1 score as an evaluation metric for the models, and it is the official ranking metric for the shared task is macro-averaged F1.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9775795936584473}, {"text": "F1", "start_pos": 137, "end_pos": 139, "type": "METRIC", "confidence": 0.8225655555725098}]}, {"text": "Subtask A tweets NOT 8840 OFF 4400", "labels": [], "entities": [{"text": "NOT 8840 OFF 4400", "start_pos": 17, "end_pos": 34, "type": "METRIC", "confidence": 0.690326452255249}]}], "tableCaptions": [{"text": " Table 3: Evaluation of different embeddings.", "labels": [], "entities": []}, {"text": " Table 4: Benchmark of supervised learning models. CNN yields the best performance based on the metric F 1 .", "labels": [], "entities": [{"text": "CNN", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.7806879878044128}]}, {"text": " Table 5: Results for Sub-task A using CNN model  compared to simple baseline.", "labels": [], "entities": []}]}