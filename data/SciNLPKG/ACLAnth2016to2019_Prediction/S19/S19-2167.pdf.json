{"title": [{"text": "NLP@UIT at SemEval-2019 Task 4: The Paparazzo Hyperpartisan News Detector", "labels": [], "entities": [{"text": "Hyperpartisan News Detector", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.5684639712174734}]}], "abstractContent": [{"text": "This paper describes the system of NLP@UIT that participated in Task 4 of SemEval-2019.", "labels": [], "entities": []}, {"text": "We developed a system that predicts whether an English news article follows a hyperparti-san argumentation.", "labels": [], "entities": []}, {"text": "Paparazzo is the name of our system and is also the code name of our team in Task 4 of SemEval-2019.", "labels": [], "entities": [{"text": "Paparazzo", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8054388165473938}]}, {"text": "The Pa-parazzo system, in which we use tri-grams of words and hepta-grams of characters, officially ranks thirteen with an accuracy of 0.747.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9989222288131714}]}, {"text": "Another system of ours, which utilizes tri-grams of words, tri-grams of characters, tri-grams of part-of-speech, syntactic dependency sub-trees, and named-entity recognition tags, achieved an accuracy of 0.787 and is proposed after the deadline of Task 4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.9993226528167725}]}], "introductionContent": [{"text": "Fake news is a noteworthy term in recent years.", "labels": [], "entities": [{"text": "Fake news", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9282607734203339}]}, {"text": "The rise of users and rapid spread information on social networking have made on automatic controlling of fake news more difficult.", "labels": [], "entities": [{"text": "automatic controlling of fake news", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.7283522963523865}]}, {"text": "Fake news articles are typically extremely one-sided (hyperpartisan), inflammatory, emotional, and often riddled with untruths.", "labels": [], "entities": [{"text": "Fake news articles", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8300664226214091}]}, {"text": "The influence of misinformation varies depending on the style it is written in.", "labels": [], "entities": []}, {"text": "For example, sarcasm in a sports news article will have less of an impact than news written in the hyper-partisan argumentation style, which can sway voter decision in an election.", "labels": [], "entities": []}, {"text": "Hyperpartisan detection in news articles is one of the ways to control fake news on the media and public.", "labels": [], "entities": [{"text": "Hyperpartisan detection in news articles", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8694067239761353}]}, {"text": "provided anew task, which they name \"Hyperpartisan News Detection,\" to decide whether a news article text follows a hyperpartisan argumentation.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.552471250295639}]}, {"text": "We approach this task following traditional text classification by extracting style features.", "labels": [], "entities": [{"text": "text classification", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7403375804424286}]}, {"text": "The bag-of-words model is the way of text representation and is applied to sentiment analysis effectively).", "labels": [], "entities": [{"text": "text representation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7243756502866745}, {"text": "sentiment analysis", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.9524445533752441}]}, {"text": "applied text mining techniques on dependency sub-trees as features for sentiment analysis at the document level.", "labels": [], "entities": [{"text": "text mining", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.7685588598251343}, {"text": "sentiment analysis", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.9406859278678894}]}, {"text": "Our results show that n-grams of words and dependency sub-trees features from sentences of the document have certain impacts on the performance of the classifier.", "labels": [], "entities": []}, {"text": "The details of the features in our systems and the results are described in Section 3 and Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Metric summary of fully trained models on  the official test dataset.", "labels": [], "entities": [{"text": "official test dataset", "start_pos": 57, "end_pos": 78, "type": "DATASET", "confidence": 0.897702674070994}]}]}