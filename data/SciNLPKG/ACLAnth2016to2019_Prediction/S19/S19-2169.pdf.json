{"title": [{"text": "Rouletabille at SemEval-2019 Task 4: Neural Network Baseline for Identification of Hyperpartisan Publishers", "labels": [], "entities": [{"text": "Identification of Hyperpartisan Publishers", "start_pos": 65, "end_pos": 107, "type": "TASK", "confidence": 0.7425725162029266}]}], "abstractContent": [{"text": "This paper describes the Rouletabille participation to the Hyperpartisan News Detection task.", "labels": [], "entities": [{"text": "Hyperpartisan News Detection task", "start_pos": 59, "end_pos": 92, "type": "TASK", "confidence": 0.7547624707221985}]}, {"text": "We propose the use of different text classification methods for this task.", "labels": [], "entities": [{"text": "text classification", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7201969474554062}]}, {"text": "Preliminary experiments using a similar collection used in Potthast et al.", "labels": [], "entities": []}, {"text": "(2018) show that neural-based classification methods reach state-of-the art results.", "labels": [], "entities": []}, {"text": "Our final submission is composed of a unique run that ranks among all runs at 3/49 position for the by-publisher test dataset and 43/96 for the by-article test dataset in terms of Accuracy.", "labels": [], "entities": [{"text": "by-article test dataset", "start_pos": 144, "end_pos": 167, "type": "DATASET", "confidence": 0.6518028974533081}, {"text": "Accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9990448355674744}]}], "introductionContent": [{"text": "Printed press have been in the last decades the main way to access to news in written format.", "labels": [], "entities": []}, {"text": "This tendency is changing with the appearance of online channels but usually the main factors of the journalistic content generation are still there: events, journalists, and editors.", "labels": [], "entities": []}, {"text": "One of the problems of the generation of this content is the influence of each factor in the veracity of the generated content.", "labels": [], "entities": []}, {"text": "Two main factors may influence the final view of an article: writer's preferences and affiliation of the editor house.", "labels": [], "entities": []}, {"text": "Identifying partisan preferences in news, based only on text content, has been shown to be a challenging task.", "labels": [], "entities": [{"text": "Identifying partisan preferences in news", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8258273720741272}]}, {"text": "This problem requires to identify if a news article was written in such away that it includes an overrated appreciation of one of the participants in the news (a political party, a person, a company, etc.).", "labels": [], "entities": []}, {"text": "Despite the fact that sharply polarized documents are not necessarily fake, it is an early problem to solve for the identification of fake content.", "labels": [], "entities": [{"text": "identification of fake content", "start_pos": 116, "end_pos": 146, "type": "TASK", "confidence": 0.8205669969320297}]}, {"text": "A recent paper claims that stylometric features area key factor to tackle this task.", "labels": [], "entities": []}, {"text": "In this paper, we present the description of our participation to the Hyperpartisan classification task at.", "labels": [], "entities": [{"text": "Hyperpartisan classification task", "start_pos": 70, "end_pos": 103, "type": "TASK", "confidence": 0.8674617409706116}]}, {"text": "This task was composed of two subtasks, the first consist to identify hyperpartisan bias in documents classified by its individual content (bias of the writer or by-article category) and the second by the editorial house that published the article (bias of the editorial house or by-publisher category) as depicted in 1 . To address this problem, we experimented with well-known models based on deep learning.", "labels": [], "entities": []}, {"text": "They achieve state-of-the-art results on a publicly available collection, showing that neural models can effectively address the task of hyperpartisan detection without including stylometric features.", "labels": [], "entities": []}, {"text": "Our final submission ranked in the top-3 for the by-publisher category, and 43/96 for the by-article category (or 21/42 in the official ranking).", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were performed using two collections, the ACL2018 collection () and the SemEval19 collection (  mainstream manually annotated documents.", "labels": [], "entities": [{"text": "ACL2018 collection", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.9791666269302368}, {"text": "SemEval19 collection", "start_pos": 84, "end_pos": 104, "type": "DATASET", "confidence": 0.8328419327735901}]}, {"text": "As this collection is not originally split in training-test sets, results are presented using cross-validation.", "labels": [], "entities": []}, {"text": "The second collection was split in train, validation, and test sets for the by-publisher category, and in train and test for the by-article category as presented in.", "labels": [], "entities": []}, {"text": "Results in this second collection are exclusively calculated using the TIRA evaluation system . In order to determine the best configuration to our participation using the SemEval collection, we decided to perform experiments and fix hyperparameters using the ACL2018 collection.", "labels": [], "entities": [{"text": "SemEval collection", "start_pos": 172, "end_pos": 190, "type": "DATASET", "confidence": 0.7463527917861938}, {"text": "ACL2018 collection", "start_pos": 260, "end_pos": 278, "type": "DATASET", "confidence": 0.9759061336517334}]}, {"text": "We only used the first fold produced by the authors' code 6 . As our results are not directly comparable with the values reported in, we re-evaluated their approach on this single fold.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of documents used for training, vali- dation, and test used in the SemEval19 collection.", "labels": [], "entities": [{"text": "SemEval19 collection", "start_pos": 84, "end_pos": 104, "type": "DATASET", "confidence": 0.7360298484563828}]}, {"text": " Table 1. Results in this second col- lection are exclusively calculated using the TIRA  evaluation system", "labels": [], "entities": [{"text": "TIRA", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.8608328700065613}]}, {"text": " Table 2: Macro, micro and weighted F-measure for the  ACL2018 collection.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.8747549653053284}, {"text": "ACL2018 collection", "start_pos": 55, "end_pos": 73, "type": "DATASET", "confidence": 0.969775527715683}]}, {"text": " Table 3: Official results for the by-publisher test  dataset.", "labels": [], "entities": [{"text": "by-publisher test  dataset", "start_pos": 35, "end_pos": 61, "type": "DATASET", "confidence": 0.6976737976074219}]}, {"text": " Table 4: Official results for the by-article test dataset.", "labels": [], "entities": [{"text": "by-article test dataset", "start_pos": 35, "end_pos": 58, "type": "DATASET", "confidence": 0.8595359524091085}]}]}