{"title": [{"text": "Orwellian-times at SemEval-2019 Task 4: A Stylistic and Content-based Classifier", "labels": [], "entities": [{"text": "Orwellian-times", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.953019917011261}, {"text": "SemEval-2019 Task", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.6407366096973419}]}], "abstractContent": [{"text": "While fake news detection received quite a bit of attention in recent years, hyperparti-san news detection is still an underresearched topic.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.7161473433176676}, {"text": "hyperparti-san news detection", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.8030400474866232}]}, {"text": "This paper presents our work towards building a classification system for hyperpar-tisan news detection in the context of the Se-mEval2019 shared task 4.", "labels": [], "entities": [{"text": "hyperpar-tisan news detection", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.7097626725832621}]}, {"text": "We experiment with two different approaches-a more stylistic one, and a more content related one-achieving average results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have seen a noticeable change in the political discourse: Political polarization has increased and political opinions have become more hyperpartisan.", "labels": [], "entities": []}, {"text": "This affects the media, especially news media and is therefore a topic of considerable interest for science and society.", "labels": [], "entities": []}, {"text": "We present an approach for the detection of high polarization and hyperpartisan news articles.", "labels": [], "entities": []}, {"text": "Our approach addresses stylistic and content related features.", "labels": [], "entities": []}, {"text": "The latter are implemented by identifying n-grams that are typical for either a hyperpartisan or a more balanced perspective.", "labels": [], "entities": []}], "datasetContent": [{"text": "For building a classification system the organizers of the task provided several data sets extracted from different American news sites: a) a set of 600.000 articles for training (classification: by publisher's general orientation) b) a set of 150.000 articles for validation (classification: by publisher's general orientation) c) 645 training articles (classified individually by humans using a crowd sourcing approach) d) validation set (classified by publisher, unknown size as this data set has been hidden during the task) e) validation set (classified individually, unknown size as this data set has been hidden during the task) All data -the articles themselves as well as the ground truth data -is provided in an proprietary but simple and well parsable XML format defined by the task owners.", "labels": [], "entities": []}, {"text": "The individual data records includes a globally unique ID, the title, the source URL and publication time.", "labels": [], "entities": []}, {"text": "Additionally the ground truth data for a) and b) contains information about a left-right bias of the publisher in general.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results, Model 1 and Model 2 with validation  dataset used, accuracy, precision, recall and F1 score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.999670147895813}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.999642014503479}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9997133612632751}, {"text": "F1 score", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9805138111114502}]}]}