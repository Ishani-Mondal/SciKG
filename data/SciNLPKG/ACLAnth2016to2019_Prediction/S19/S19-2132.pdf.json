{"title": [{"text": "TECHSSN at SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Tweets using Deep Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Task 6 of SemEval 2019 involves identifying and categorizing offensive language in social media.", "labels": [], "entities": [{"text": "SemEval 2019", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9313343465328217}]}, {"text": "The systems developed by TECHSSN team uses multi-level classification techniques.", "labels": [], "entities": [{"text": "TECHSSN team", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.8719031810760498}]}, {"text": "We have developed two systems.", "labels": [], "entities": []}, {"text": "In the first system, the first level of classification is done by a multi-branch 2D CNN classi-fier with Google's pre-trained Word2Vec embedding and the second level of classification by string matching technique supported by offensive and bad words dictionary.", "labels": [], "entities": []}, {"text": "The second system uses a multi-branch 1D CNN classi-fier with Glove pre-trained embedding layer for the first level of classification and string matching for the second level of classification.", "labels": [], "entities": []}, {"text": "Input data with a probability of less than 0.70 in the first level are passed onto the second level.", "labels": [], "entities": []}, {"text": "The misclassified examples are classified correctly in the second level.", "labels": [], "entities": []}], "introductionContent": [{"text": "The growth of social media networks in recent days has been phenomenal and Twitter is no exception.", "labels": [], "entities": []}, {"text": "However, this rapid growth of social media also poses a serious challenge of maintaining ethics in social media because of the degradation of moral values in society.", "labels": [], "entities": []}, {"text": "Offensive micro tweets are generated on a daily basis targeting a particular person, organization, race, caste, community, religion, gender and so forth.", "labels": [], "entities": []}, {"text": "For this reason, our task for the SemEval2019 () mainly focuses on the detection of offensive language in tweets and classify them.", "labels": [], "entities": []}, {"text": "In Subtask-A, we tried to classify the tweets into two classes, namely offensive and non-offensive.", "labels": [], "entities": []}, {"text": "The offensive tweets in the Subtask-A are then categorized in Subtask-B into targeted and untargeted tweets, where targeted tweets are aimed at a specific person, organization, religion or political parties.", "labels": [], "entities": []}, {"text": "Further, Subtask-C deals with the finegrained classification of offensive tweets into three classes viz person, organization and others.", "labels": [], "entities": []}, {"text": "The training dataset provided by the organizers contains 13240 tweets.", "labels": [], "entities": []}, {"text": "The given dataset is used as the preliminary dataset to train our model.", "labels": [], "entities": []}, {"text": "In addition, Impermium dataset from Kaggle and TRAC dataset are added to improve the accuracy of the model.", "labels": [], "entities": [{"text": "Impermium dataset", "start_pos": 13, "end_pos": 30, "type": "DATASET", "confidence": 0.8951651155948639}, {"text": "Kaggle", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.8434836864471436}, {"text": "TRAC dataset", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.8467830419540405}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9994021654129028}]}, {"text": "We have also used a dictionary of offensive words in the second level of classification.", "labels": [], "entities": []}, {"text": "Manually classifying the tweets is ambiguous and highly subjective, and is one of the biggest challenges.", "labels": [], "entities": []}, {"text": "The mix of colloquial slang in tweets, veiled references, missing data, usage of symbols and emojis are further hurdles that lowered the prediction accuracy ().", "labels": [], "entities": [{"text": "prediction", "start_pos": 137, "end_pos": 147, "type": "TASK", "confidence": 0.9401345252990723}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9256239533424377}]}], "datasetContent": [{"text": "The classifier can make a well-informed decision if we procure and supply more data to it.", "labels": [], "entities": []}, {"text": "For good performance, deep learning requires sufficiently large amount of data.", "labels": [], "entities": [{"text": "deep learning", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.866864025592804}]}, {"text": "Therefore, in addition to the dataset given by, we also compiled a variety of datasets for our tweet classification.", "labels": [], "entities": [{"text": "tweet classification", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.808578222990036}]}, {"text": "We have added the TRAC training, and used a comprehensive list of known offensive words banned by Google in all their different forms.", "labels": [], "entities": [{"text": "TRAC", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.880169689655304}]}, {"text": "TRAC dataset is based on multiclass classification (OAG, CAG, NAG).", "labels": [], "entities": [{"text": "TRAC dataset", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8746618330478668}]}, {"text": "We have considered OAG and CAG class labels as OFF label and NAG as NOT for the subtask A.", "labels": [], "entities": [{"text": "OAG", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.7615792155265808}, {"text": "OFF label", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9603273868560791}, {"text": "NAG", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9631701111793518}, {"text": "NOT", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9894792437553406}]}], "tableCaptions": [{"text": " Table 1. Lin- ear SVM is found to be better for text classifica- tion since most of the text classification problems  are linearly separable", "labels": [], "entities": [{"text": "Lin- ear SVM", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.4162603095173836}, {"text": "text classification", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.7245586216449738}]}, {"text": " Table 1: Linear SVM with TF-IDF model", "labels": [], "entities": []}, {"text": " Table 2: Comparison of F1-scores of the Models Used", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.98878014087677}]}, {"text": " Table 4: Results for Subtask A", "labels": [], "entities": [{"text": "Subtask", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.963104784488678}]}, {"text": " Table 5: Results for Subtask B", "labels": [], "entities": [{"text": "Subtask", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9665696620941162}]}]}