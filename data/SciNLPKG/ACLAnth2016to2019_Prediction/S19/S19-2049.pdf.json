{"title": [{"text": "PKUSE at SemEval-2019 Task 3: Emotion Detection with Emotion-Oriented Neural Attention Network", "labels": [], "entities": [{"text": "Emotion Detection", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.8987461030483246}]}], "abstractContent": [{"text": "This paper presents the system in SemEval-2019 Task 3, \"EmoContext: Contextual Emotion Detection in Text\".", "labels": [], "entities": [{"text": "SemEval-2019 Task 3", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8076189359029134}, {"text": "EmoContext: Contextual Emotion Detection in Text", "start_pos": 56, "end_pos": 104, "type": "TASK", "confidence": 0.6431000701018742}]}, {"text": "We propose a deep learning architecture with bidirectional LSTM networks, augmented with an emotion-oriented attention network that is capable of extracting emotion information from an utterance.", "labels": [], "entities": []}, {"text": "Experimental results show that our model outperforms its variants and the base-line.", "labels": [], "entities": []}, {"text": "Overall, this system has achieved 75.57% for the microaveraged F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9648988544940948}]}], "introductionContent": [{"text": "With the rapid development of social media platforms like Twitter, a huge number of textual dialogues has increasingly emerged.", "labels": [], "entities": []}, {"text": "It is a challenge for chat bots to generate responses based on user emotions which can avoid inappropriate conversations.", "labels": [], "entities": []}, {"text": "Emotion detection in text () is a research area within Natural Language Processing which is aim to detect the emotion of user expressed in text.", "labels": [], "entities": [{"text": "Emotion detection in text", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.899609386920929}]}, {"text": "Many techniques have been proposed, Wang et al.,Hasan et al.,Liew and Turtle used feature engineering to extract features manually.", "labels": [], "entities": []}, {"text": "In this area, deep learning-based approches have performed well in recent years.", "labels": [], "entities": []}, {"text": "Some methods) used recurrent neural network to model the sequence of utterances for emotion detection.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7291317135095596}]}, {"text": "However, those models did not highlight the emotion-related parts.", "labels": [], "entities": []}, {"text": "We use attention mechanism to locate the parts expressing emotions in the utterance.", "labels": [], "entities": []}, {"text": "The Task3 in Semeval-2019 is to detect contextual emotions in text.", "labels": [], "entities": []}, {"text": "For this task, we propose a deep learning approach which is a combination of * * These authors have contributed equally to this work.", "labels": [], "entities": []}, {"text": "Long Short-Term Memory network and attention mechanism.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 provides system overview.", "labels": [], "entities": []}, {"text": "Section 3 describes our approach in detail.", "labels": [], "entities": []}, {"text": "Our experiment is discussed in Section 4.", "labels": [], "entities": []}, {"text": "We conclude our work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Happy  The model is implemented using Keras 2.0 (Chollet et al., 2017).", "labels": [], "entities": []}, {"text": "We experiment with Stanford's GloVe 300 dimensional word embeddings trained on 840 billion words from Common Crawl.", "labels": [], "entities": []}, {"text": "Our model is trained with Adam Optimizer () with initial learning rate of 0.001 and batch size of 64.", "labels": [], "entities": []}, {"text": "We use BiLSTMs with hidden state size 256, with dropout rate 0.5 on the first BiLSTM layer and dropout rate 0.3 on the second one to prevent our neural network from overfitting ().", "labels": [], "entities": []}, {"text": "In our task, the size of samples for each class is not balanced, which will result in the model tending to be biased toward the majority class with poor accuracy for the minority class.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9989879727363586}]}, {"text": "For this, we adjust the parameter 'class weight' to weight the loss function of each class during training.", "labels": [], "entities": []}, {"text": "This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.", "labels": [], "entities": []}, {"text": "In this case, we set the parameter 'class weight' (Happy : 2, Sad : 1, Angry : 1, Others : 4)", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Datasets for Semeval-2019 Task 3.", "labels": [], "entities": [{"text": "Semeval-2019 Task 3", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.9019364515940348}]}, {"text": " Table 2: Performance of our system and its variants.", "labels": [], "entities": []}]}