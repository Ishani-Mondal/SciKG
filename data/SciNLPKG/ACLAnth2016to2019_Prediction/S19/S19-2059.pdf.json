{"title": [{"text": "THU NGN at SemEval-2019 Task 3: Dialog Emotion Classification using Attentional LSTM-CNN", "labels": [], "entities": [{"text": "THU NGN", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6124535501003265}, {"text": "Dialog Emotion Classification", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.8879735271135966}]}], "abstractContent": [{"text": "With the development of the Internet, dialog systems are widely used in online platforms to provide personalized services for their users.", "labels": [], "entities": []}, {"text": "It is important to understand the emotions through conversations to improve the quality of dialog systems.", "labels": [], "entities": []}, {"text": "To facilitate the researches on dialog emotion recognition, the SemEval-2019 Task 3 named EmoContext is proposed.", "labels": [], "entities": [{"text": "dialog emotion recognition", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7774844169616699}]}, {"text": "This task aims to classify the emotions of user utterance along with two short turns of dialogues into four categories.", "labels": [], "entities": []}, {"text": "In this paper, we propose an attentional LSTM-CNN model to participate in this shared task.", "labels": [], "entities": []}, {"text": "We use a combination of convolutional neural networks and long-short term neural networks to capture both local and long-distance con-textual information in conversations.", "labels": [], "entities": []}, {"text": "In addition , we apply attention mechanism to recognize and attend to important words within conversations.", "labels": [], "entities": []}, {"text": "Besides, we propose to use ensemble strategies by combing the variants of our model with different pre-trained word embeddings via weighted voting.", "labels": [], "entities": []}, {"text": "Our model achieved 0.7542 micro-F1 score in the final test data, ranking 15 th out of 165 teams.", "labels": [], "entities": []}], "introductionContent": [{"text": "The analysis of emotions in dialog systems where limited number of words appear with strong semantic relations between them deserves special attention in domain of natural language processing (NLP) due to both interesting language novelties and wide future prospects (.", "labels": [], "entities": []}, {"text": "By analyzing the emotions through conversations, service providers can design better chatting strategies according to users' emotion patterns, which can improve user experience.", "labels": [], "entities": []}, {"text": "Therefore, aims to call for research in this field.", "labels": [], "entities": []}, {"text": "Given a textual dialogue, i.e., a user utterance along with two turns of context, systems need to classify the emotion of user utterance into four emotion classes: happy, sad, angry or others.", "labels": [], "entities": []}, {"text": "The field of sentiment analysis has been extensively studied.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.965899795293808}]}, {"text": "For example, SemEval-2018 Task 2 () once called for the study on relevance between tweet texts and emojis.", "labels": [], "entities": []}, {"text": "However, understanding textual conversations is challenging in absence of voice modulations and facial expressions, which participants at this task are asked to deal with.", "labels": [], "entities": []}, {"text": "Apart from diminishing the negative impact caused by class size imbalance, ambiguity, misspellings and slang, their systems should mainly focus on capturing the intricate interplay between two turns of conversations.", "labels": [], "entities": []}, {"text": "Traditional sentiment analysis requires a lot of feature engineering, such as n-grams and features extracted from sentiment lexicons, and then feed them into a classifier such as Support Vector Machines (SVM)).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.9005241692066193}]}, {"text": "However, manual feature engineering usually needs a large amount of domain knowledge.", "labels": [], "entities": [{"text": "manual feature engineering", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.611078123251597}]}, {"text": "With the rapid development and ambiguity of social dialogues, these feature engineering strategies fade gradually and begin to be supplanted by neural networks, which usually take word embeddings as inputs to incorporate rich semantic and syntactic information.", "labels": [], "entities": []}, {"text": "However, dialog emotion analysis is still very challenging, since dialog conversations can be very noisy and informal.", "labels": [], "entities": [{"text": "dialog emotion analysis", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.91128538052241}]}, {"text": "In addition, the emotions evoked by conversations are usually highly context-dependent.", "labels": [], "entities": []}, {"text": "In this work, we propose an end-to-end attentional LSTM-CNN network as a unified model without hand-crafted features.", "labels": [], "entities": []}, {"text": "In our approach, we use a combination of LSTM and CNN to capture both local and long-distance information.", "labels": [], "entities": []}, {"text": "We use attention mechanism to select important words to learn more informative word representations.", "labels": [], "entities": []}, {"text": "In addition, we use a data balancing method by setting a cost-sensitive loss function for training.", "labels": [], "entities": [{"text": "data balancing", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.6852413415908813}]}, {"text": "Besides, we use ensemble strategies by using a combination of the variants of our model with different pre-trained word embeddings.", "labels": [], "entities": []}, {"text": "Our model achieved 0.7542 micro-F1 score on the test set, and extensive experiments validate the effectiveness of our approach.", "labels": [], "entities": []}, {"text": "The source code can be found in our repository on github.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, the word2vec-twitter embedding () was trained on 400 million microposts, which has a vocabulary of 3,039,345 words and 400-dimensional word representations.", "labels": [], "entities": []}, {"text": "The Ekphrasis model leverages a collection of 330 million Twitter messages to generate word embeddings.", "labels": [], "entities": []}, {"text": "It also uses GloVe as pretrained word vectors.", "labels": [], "entities": []}, {"text": "Besides, a pre-processing pipeline is developed to enable users to get word vectors in a directly numerical form 2 . We also incorporate the GloVe embedding model and select the cased 300-dimension version 3 obtained by training on 2.2M data crawling from the Internet, containing 840B tokens in total.", "labels": [], "entities": []}, {"text": "With word2vec-twitter embedding and GloVe embedding, we send raw texts to NLTK TweetTokenizer and randomly generate word vectors for all emojis and those out of vocabulary words appearing more than 3 times.", "labels": [], "entities": [{"text": "NLTK TweetTokenizer", "start_pos": 74, "end_pos": 93, "type": "DATASET", "confidence": 0.893960565328598}]}, {"text": "Moreover, as to ekphrasis embedding, we use the pipeline provided by it.", "labels": [], "entities": []}, {"text": "The pre-processing steps included in it are: Twitter-specic tokenization, spell correction, word normalization, word segmentation (for splitting hashtags) and word annotation.", "labels": [], "entities": [{"text": "spell correction", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.731891006231308}, {"text": "word normalization", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7926940023899078}, {"text": "word segmentation", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.7422923147678375}]}, {"text": "In the experiment, we pertain the original dimension of the word embeddings and send them to a 400 dimension Bi-LSTM, adding to totally 800 dimension in LSTM layer.", "labels": [], "entities": []}, {"text": "In the next CNN layer, the number of filters is 256, with filter length of 3.", "labels": [], "entities": []}, {"text": "After each layer, we employ dropout with a drop rate of 0.2 to mitigate overfitting.", "labels": [], "entities": []}, {"text": "Additionally, rmsprop) is chosen as optimizer and Keras library is used for implementation.", "labels": [], "entities": []}, {"text": "The final submission which scores micro F 1 75.42 is equipped with both the attention mechanism and weighted soft voting ensemble.", "labels": [], "entities": [{"text": "micro F 1 75.42", "start_pos": 34, "end_pos": 49, "type": "METRIC", "confidence": 0.9208660423755646}]}, {"text": "The final result is shown in table 1, it suggests that our model performs relatively lower on happy emotion due to lack of training data and ambiguity.", "labels": [], "entities": []}, {"text": "We evaluate parts of our network in the following paragraphs.", "labels": [], "entities": []}, {"text": "The baseline we use is LSTM-CNN architecture(LSTM-CNN), baseline with concatenating layer is denoted as LSTM-CNN+CL.", "labels": [], "entities": []}, {"text": "Upon this, attention mechanism is added, which is written as LSTM-CNN+CL+AT.", "labels": [], "entities": [{"text": "LSTM-CNN+CL+AT", "start_pos": 61, "end_pos": 75, "type": "METRIC", "confidence": 0.5133189618587494}]}, {"text": "Finally, a weighted soft voting is introduced, namely LSTM-CNN+CL+AT+WE.", "labels": [], "entities": [{"text": "LSTM-CNN+CL+AT+WE", "start_pos": 54, "end_pos": 71, "type": "METRIC", "confidence": 0.562254901443209}]}, {"text": "The result comparison is shown in table 2.", "labels": [], "entities": []}, {"text": "By combining the outputs of Bi-LSTM and CNN layer, the model learns both local feature and long-term context, with the most obvious improvement in Word2vec-twitter, F1 score increasing from 0.7307 to 0.7483.", "labels": [], "entities": [{"text": "Word2vec-twitter", "start_pos": 147, "end_pos": 163, "type": "DATASET", "confidence": 0.9107199907302856}, {"text": "F1 score", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9849092364311218}]}, {"text": "Adding attention into network helps our network select those more essential words in the case of Ekphrasis and Glove word embeddings, but Word2vec-twitter witnesses a slight decline.", "labels": [], "entities": [{"text": "Glove word embeddings", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.5425516963005066}, {"text": "Word2vec-twitter", "start_pos": 138, "end_pos": 154, "type": "DATASET", "confidence": 0.9427077174186707}]}, {"text": "This maybe due to the randomness of out-of-vocabulary words and emoji word vectors.", "labels": [], "entities": []}, {"text": "Overall speaking, attention benefits the study of word importance to some degree.", "labels": [], "entities": [{"text": "word importance", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.6861821711063385}]}, {"text": "We place    the highest weight on those showing good performances on dev dataset in our final submission.", "labels": [], "entities": []}, {"text": "The significant improvement of F1 score at the bottom of table 2 indicates the power of ensemble.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9865416884422302}]}, {"text": "Results show that GloVe performs better than other two word embeddings, thus given more weight in practice.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.7297754883766174}]}, {"text": "The result is ensembled from eight predictions , with the quantity we use of Word2vec-twitter, Ekphrasis, GloVe is respectively 2:3:3.", "labels": [], "entities": [{"text": "Word2vec-twitter", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.9629383087158203}, {"text": "GloVe", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.6426390409469604}]}, {"text": "Since many methods in sentiment analysis rely heavily on high quality labeled data, we test our model with different reduction portion rate of training data.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9752033650875092}]}, {"text": "It can be seen in that although there exists certain degree of performance reduction when the data amount is limited, our approach remain a F1 score of approximately 0.70 even with only 20% data, which proves that our approach can be widely applied to even when there exists shortage of labeled data.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9869873523712158}]}, {"text": "The oversampling rate is defined to be the rate of loss weight between the class \"others\" and other three emotion categories.", "labels": [], "entities": [{"text": "oversampling rate", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.9588029682636261}]}, {"text": "We officially set the oversampling rate k to be 3, meaning the loss weight rate between \"others\" and other three emotion categories is 3:1:1:1.", "labels": [], "entities": [{"text": "oversampling rate k", "start_pos": 22, "end_pos": 41, "type": "METRIC", "confidence": 0.9539616306622823}, {"text": "loss weight rate", "start_pos": 63, "end_pos": 79, "type": "METRIC", "confidence": 0.8732590874036154}]}, {"text": "To test the effectiveness of our choice of k, we select k to be in range from 0.5 to 7 and report the changes on F1 score, precision and recall in.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9763615429401398}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.999325156211853}, {"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9997698664665222}]}, {"text": "It should be noticed that the scores are extremely unstable when k < 2, which may due to the sparsity of emotion labels in training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation result on our final submission.", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9686610698699951}]}, {"text": " Table 2: Results on test data under various system framework.", "labels": [], "entities": []}]}