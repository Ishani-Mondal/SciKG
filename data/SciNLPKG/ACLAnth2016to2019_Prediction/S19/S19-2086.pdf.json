{"title": [{"text": "sthruggle at SemEval-2019 Task 5: An Ensemble Approach to Hate Speech Detection", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.6417719125747681}, {"text": "Hate Speech Detection", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.8419875303904215}]}], "abstractContent": [{"text": "In this paper, we present our approach to detection of hate speech against women and immigrants in tweets for our participation in the SemEval-2019 Task 5.", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.8829593658447266}]}, {"text": "We trained an SVM and an RF classifier using character bi-and trigram features and a BiLSTM pre-initialized with external word embeddings.", "labels": [], "entities": []}, {"text": "We combined the predictions of the SVM, RF and BiLSTM in two different ensemble models.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9624240398406982}]}, {"text": "The first was a majority vote of the binary values, and the second used the average of the confidence scores.", "labels": [], "entities": []}, {"text": "For development, we got the highest accuracy (75%) by the final ensemble model with majority voting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9994624257087708}]}, {"text": "For testing, all models scored substantially lower and the scores between the classifiers varied more.", "labels": [], "entities": []}, {"text": "We believe that these large differences between the higher accuracies in the development phase and the lower accuracies we obtained in the testing phase have partly to do with differences between the training, development and testing data.", "labels": [], "entities": []}], "introductionContent": [{"text": "An unwanted phenomenon that can be found across social media, is the publication of texts with hateful content.", "labels": [], "entities": []}, {"text": "In, it is defined as any communication that disparages a person or group.", "labels": [], "entities": []}, {"text": "We focused on immigrants and women, which are two of the most targeted groups of people who are victims to this kind of discourse.", "labels": [], "entities": []}, {"text": "The micro-blogging service Twitter is a medium on which posts containing hateful content can be found in abundance.", "labels": [], "entities": []}, {"text": "In order to filter out tweets with such content, machine learning and neural network techniques can be used to discriminate tweets which do contain hate speech from tweets which do not.", "labels": [], "entities": []}, {"text": "Among the characteristics of Twitter data we can point out its noisiness and the use of emojis and hashtags, which can betaken into account for the classification task.", "labels": [], "entities": []}, {"text": "In this paper, we tried to solve this problem for English, by incorporating a variety of classification algorithms including Support Vector Machine (SVM), Random Forest (RF), and Bidirectional Long Short-Term Memory (BiLSTM).", "labels": [], "entities": []}, {"text": "For the classical machine learning classification algorithms (SVM and RF) we used character n-grams and for the BiLSTM we used word embeddings trained on a huge amount of Twitter data.", "labels": [], "entities": [{"text": "machine learning classification", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.7525975505510966}, {"text": "BiLSTM", "start_pos": 112, "end_pos": 118, "type": "DATASET", "confidence": 0.777363121509552}]}, {"text": "By combining these three models into an ensemble learning model, we achieved our best results on the development data, so we submitted this model for this shared task.", "labels": [], "entities": []}, {"text": "We start the paper by discussing some earlier work done in this field.", "labels": [], "entities": []}, {"text": "Then, we describe the dataset we used for this task.", "labels": [], "entities": []}, {"text": "In chapter 4, we present our approach.", "labels": [], "entities": []}, {"text": "In chapter 5, we continue with the results of our methods and the discussion.", "labels": [], "entities": []}, {"text": "Finally, we end with a conclusion and future work in chapter 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation measures (in percentage) of all models for development and testing on task A (hate speech  detection). Precision and recall are averaged over the two classes.", "labels": [], "entities": [{"text": "hate speech  detection)", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.7580392211675644}, {"text": "Precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9986428618431091}, {"text": "recall", "start_pos": 138, "end_pos": 144, "type": "METRIC", "confidence": 0.9989041090011597}]}]}