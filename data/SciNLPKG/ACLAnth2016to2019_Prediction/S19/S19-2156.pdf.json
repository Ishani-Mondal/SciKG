{"title": [{"text": "DM NLP at SemEval-2019 Task 12: A Pipeline System for Toponym Resolution", "labels": [], "entities": [{"text": "DM NLP", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7219655513763428}, {"text": "SemEval-2019 Task 12", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.5599416395028433}, {"text": "Toponym Resolution", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.8807481825351715}]}], "abstractContent": [{"text": "This paper describes DM-NLP's system for to-ponym resolution task at Semeval 2019.", "labels": [], "entities": [{"text": "to-ponym resolution task at Semeval 2019", "start_pos": 41, "end_pos": 81, "type": "TASK", "confidence": 0.6897106369336446}]}, {"text": "Our system was developed for toponym detection , disambiguation and end-to-end resolution which is a pipeline of the former two.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.844143271446228}, {"text": "end-to-end resolution", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.6779405325651169}]}, {"text": "For toponym detection, we utilized the state-of-the-art sequence labeling model, namely, BiLSTM-CRF model as backbone.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8827553689479828}]}, {"text": "A lot of strategies are adopted for further improvement , such as pre-training, model ensemble, model averaging and data augment.", "labels": [], "entities": [{"text": "model averaging", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.7878801822662354}]}, {"text": "For to-ponym disambiguation, we adopted the widely used searching and ranking framework.", "labels": [], "entities": [{"text": "to-ponym disambiguation", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6561088562011719}]}, {"text": "For ranking, we proposed several effective features for measuring the consistency between the detected toponym and toponyms in GeoNames.", "labels": [], "entities": [{"text": "GeoNames", "start_pos": 127, "end_pos": 135, "type": "DATASET", "confidence": 0.9288818836212158}]}, {"text": "Eventually, our system achieved the best performance among all the submitted results in each sub task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The toponym resolution task is aimed to detect toponyms in scientific papers and link them to entities in a geographical knowledge base (GeoNames 1 in this task).", "labels": [], "entities": [{"text": "toponym resolution", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7998567223548889}]}, {"text": "A toponym is a proper name of a place or geographical entity that is named, and can be designated by a geographical coordinate, including cities, countries, lakes or monuments.", "labels": [], "entities": []}, {"text": "We developed an end-to-end toponym resolution system (for subtask 3) which is a pipeline of toponym detection (for subtask 1) and disambiguation (for subtask 2).", "labels": [], "entities": [{"text": "toponym resolution", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7160982936620712}, {"text": "toponym detection", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.7091216593980789}]}, {"text": "We model the detection task as a Named Entity Recognition (NER) and address it with popular sequence labeling framework.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.7686342795689901}]}, {"text": "For disambiguation task, we adopted the searching and ranking framework which is widely used in Entity linking task.", "labels": [], "entities": [{"text": "Entity linking task", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7859644293785095}]}, {"text": "Toponym is a special type of entity similar to the location entity in the general NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 82, "end_pos": 90, "type": "TASK", "confidence": 0.8420609831809998}]}, {"text": "Thus, https://geonames.org the well-studied NER models maybe effective for detecting toponyms.", "labels": [], "entities": []}, {"text": "The most successful NER models are sequence labeling models, including the traditional CRF (Conditional Random Field () and some variants of RNNs (Recurent Neural Networks) proposed recently, like LSTM-CRF, BiLSTM-CRF, BiLSTM-CNN-CRF, etc.", "labels": [], "entities": [{"text": "NER", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9565326571464539}, {"text": "sequence labeling", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.631205141544342}]}, {"text": "In this paper, We utilize the most popular model, i.e., BiLSTM-CRF for toponym detection.", "labels": [], "entities": [{"text": "BiLSTM-CRF", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.6264658570289612}, {"text": "toponym detection", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.8322299420833588}]}, {"text": "Beyond the model, a prevalent pre-training embedding named ELMo is used after fine-tuning.", "labels": [], "entities": [{"text": "ELMo", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.6845288276672363}]}, {"text": "Model averaging and model ensemble are used for avoiding overfitting.", "labels": [], "entities": [{"text": "Model averaging", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8042914569377899}]}, {"text": "Data sets from other NER tasks are exploited to augment the training data.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.8900726735591888}]}, {"text": "We also proposed a dictionary based method for detecting toponyms in tables separately.", "labels": [], "entities": []}, {"text": "Since tables have some peculiarities, i.e., well formatted yet without meaningful context for toponyms in them.", "labels": [], "entities": []}, {"text": "Toponym disambiguation can be seen as a variant of entity linking (EL) problem, which links entity mentions in articles to entities in knowledge base (KB) like Wikipedia.", "labels": [], "entities": [{"text": "Toponym disambiguation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8343713283538818}, {"text": "entity linking (EL) problem", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.8347049256165823}]}, {"text": "A typical EL system consists of candidate entity generation and ranking as well as unlinkable mention prediction.", "labels": [], "entities": [{"text": "candidate entity generation", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.6271580755710602}, {"text": "unlinkable mention prediction", "start_pos": 83, "end_pos": 112, "type": "TASK", "confidence": 0.7143921852111816}]}, {"text": "The major challenge is that the KB of toponym lacks of background information other than toponym names, types and coordinates.", "labels": [], "entities": []}, {"text": "Therefore, we follow the typical EL method) for toponym disambiguation and propose a classification based ranking method.", "labels": [], "entities": [{"text": "toponym disambiguation", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7148807942867279}]}, {"text": "Specifically, We recast the problem as a binary classification task asking that whether a toponym in GeoNames is a link forgiven toponym.", "labels": [], "entities": []}, {"text": "If more than one positives exist, they are ranked according to their confidence scores.", "labels": [], "entities": []}, {"text": "Coupled with the classifier, We introduce many features which measure the consistency between toponyms effectively, including name string similarity, candidate attributes, contextual features and mention list features.", "labels": [], "entities": []}, {"text": "Our contributions to this task can be summarized as follows: \u2022 Proposing an approach to process tables separately from the main body.", "labels": [], "entities": []}, {"text": "\u2022 Proposing a novel data augment approach to exploit external data.", "labels": [], "entities": []}, {"text": "\u2022 Designing many novel and effective features for disambiguation.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9750622510910034}]}], "datasetContent": [{"text": "Given 105 medical papers from PubMed Central 6 for developing system, we randomly divided the data into training, development and test set by a ratio of 5:1:1.", "labels": [], "entities": [{"text": "PubMed Central 6", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.9496189951896667}]}, {"text": "To avoiding instability of experimental results, we repeat this process 5 times and yield different distributions.", "labels": [], "entities": []}, {"text": "All the results shown below are average values among these five distributions.", "labels": [], "entities": []}, {"text": "Data Augment The official training data is smaller than the dataset used in general NER task.", "labels": [], "entities": [{"text": "Data Augment", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6387129426002502}, {"text": "NER task", "start_pos": 84, "end_pos": 92, "type": "TASK", "confidence": 0.8884084820747375}]}, {"text": "Therefore, we expanded the training data https://www.ncbi.nlm.nih.gov/pmc/ by selecting external data from CONLL2003 and ontonotes5.0.", "labels": [], "entities": [{"text": "CONLL2003", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.9843313694000244}]}, {"text": "Sentence containing GPE or LOC entities were selected.", "labels": [], "entities": []}, {"text": "A binary classifier 7 was applied to distinguish the external sentences from the official sentences and outputs a confidence score.", "labels": [], "entities": []}, {"text": "If the score lower than a threshold, in other words, the external sentence is similar to the official sentence, we add the external sentence into training data.", "labels": [], "entities": []}, {"text": "Finally, we obtained 8000 extra training sentences, about 32% of the total training data.", "labels": [], "entities": []}, {"text": "Preprocessing Articles are segmented into sentences by NLTK and segmentation errors are corrected based on NER results (generated by CoreNLP).", "labels": [], "entities": [{"text": "NLTK", "start_pos": 55, "end_pos": 59, "type": "DATASET", "confidence": 0.9161850810050964}]}, {"text": "For example, \"St. Louis\" is split by '.' incorrectly.", "labels": [], "entities": []}, {"text": "But it is a location according to NER Results.", "labels": [], "entities": [{"text": "NER Results", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.9264975190162659}]}, {"text": "shows the ablation study of the detection model.", "labels": [], "entities": [{"text": "ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9647770524024963}]}, {"text": "As mentioned above, the baseline model is a Char-LSTM-LSTM-CRF model.", "labels": [], "entities": []}, {"text": "We tried two types of pre-trained embeddings,) and PubMed 8 . Since the PubMed is trained on indomain data, it achieves better results.", "labels": [], "entities": []}, {"text": "Thus, all the rest results are based on embeddings trained on PubMed dataset.", "labels": [], "entities": [{"text": "PubMed dataset", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.985675036907196}]}], "tableCaptions": [{"text": " Table 1: Experiment results of Detection. Abbreviations: DA, Data Augment; PPE, Pubmed Pre-trained Embed- ding; PP, Post Process; TP, Table Process; LF, Linguistic Features; ME, Model Ensemble", "labels": [], "entities": [{"text": "Detection", "start_pos": 32, "end_pos": 41, "type": "TASK", "confidence": 0.9572188258171082}, {"text": "DA", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9449920058250427}, {"text": "Pubmed Pre-trained Embed- ding", "start_pos": 81, "end_pos": 111, "type": "METRIC", "confidence": 0.7816749811172485}, {"text": "ME", "start_pos": 175, "end_pos": 177, "type": "METRIC", "confidence": 0.9595483541488647}]}, {"text": " Table 2: Main results of Candidate Ranking on entire  trainset", "labels": [], "entities": []}, {"text": " Table 3: Ablation study for Ranking features", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9956022500991821}]}]}