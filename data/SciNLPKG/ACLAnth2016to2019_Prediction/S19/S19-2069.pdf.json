{"title": [{"text": "Grunn2019 at SemEval-2019 Task 5: Shared Task on Multilingual Detection of Hate", "labels": [], "entities": [{"text": "Multilingual Detection of Hate", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.8369705229997635}]}], "abstractContent": [{"text": "Hate speech occurs more often than ever and polarizes society.", "labels": [], "entities": [{"text": "Hate speech", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.885315477848053}]}, {"text": "To help counter this polarization , SemEval 2019 organizes a shared task called the Multilingual Detection of Hate.", "labels": [], "entities": [{"text": "Multilingual Detection of Hate", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.799918457865715}]}, {"text": "The first task (A) is to decide whether a given tweet contains hate against immigrants or women, in a multilingual perspective, for English and Spanish.", "labels": [], "entities": []}, {"text": "In the second task (B), the system is also asked to classify the following sub-tasks: hateful tweets as aggressive or not aggressive , and to identify the target harassed as individual or generic.", "labels": [], "entities": []}, {"text": "We evaluate multiple models, and finally combine them in an ensemble setting.", "labels": [], "entities": []}, {"text": "This ensemble setting is built of five and three submodels for the English and Spanish task respectively.", "labels": [], "entities": []}, {"text": "In the current setup it shows that using a bigger ensemble for English tweets performs mediocre, while a slightly smaller ensemble does work well for detecting hate speech in Spanish tweets.", "labels": [], "entities": [{"text": "detecting hate speech in Spanish tweets", "start_pos": 150, "end_pos": 189, "type": "TASK", "confidence": 0.8583022157351176}]}, {"text": "Our results on the test set for English show 0.378 macro F1 on task A and 0.553 macro F1 on task B.", "labels": [], "entities": [{"text": "F1", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9196920990943909}, {"text": "F1", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.8975198268890381}]}, {"text": "For Spanish the results are significantly higher, 0.701 macro F1 on task A and 0.734 macro F1 for task B.", "labels": [], "entities": [{"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.8107348680496216}, {"text": "F1", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.7871609926223755}]}], "introductionContent": [{"text": "The increasing popularity of social media platforms such as Twitter for both personal and political communication has seen a well-acknowledged rise in the presence of toxic and abusive speech on these platforms (.", "labels": [], "entities": []}, {"text": "Although the terms of services on these platforms typically forbid hateful and harassing speech, the volume of data requires that ways are found to classify online content automatically.", "labels": [], "entities": []}, {"text": "The problem of detecting, and therefore possibly limit the hate speech diffusion, is becoming fundamental (.", "labels": [], "entities": [{"text": "hate speech diffusion", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7730362812678019}]}, {"text": "Previous work concerning hate speech against immigrants and women such as observed that extremist violence tends to lead to an increase in online hate speech, particularly on messages directly advocating violence.", "labels": [], "entities": []}, {"text": "Also, contributed to the research field by (1) making a corpus of misogynous tweets, labelled from different perspective and (2) created an exploratory investigations on NLP features and ML models for detecting and classifying misogynistic language.", "labels": [], "entities": [{"text": "detecting and classifying misogynistic language", "start_pos": 201, "end_pos": 248, "type": "TASK", "confidence": 0.6528144955635071}]}, {"text": "proposed a shared task on the Multilingual Detection of Hate, where participants have to detect hate speech against immigrants and women in Twitter, in a multilingual perspective, for English and Spanish.", "labels": [], "entities": [{"text": "Multilingual Detection of Hate", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.7961430177092552}]}, {"text": "The task is divided in two related subtasks for both languages: a basic task about hate speech, and another one where fine-grained features of hateful contents will be investigated in order to understand how existing approaches may deal with the identification of especially dangerous forms of hate, for example those where the incitement is against an individual rather than against a group of people, and where an aggressive behavior of the author can be identified as a prominent feature of the expression of hate.", "labels": [], "entities": []}, {"text": "Within this experiment, Task A is a binary classification task where our system has to predict whether a tweet is hateful or not hateful.", "labels": [], "entities": []}, {"text": "For Task B, our system has to decide whether a tweet is aggressive or not aggressive, and whether that tweet targets an individual or generic group, to elaborate, a single human or group of people.", "labels": [], "entities": []}, {"text": "The paper is structures as follows.", "labels": [], "entities": []}, {"text": "In section 2 our system setup is described.", "labels": [], "entities": []}, {"text": "In section 3, the datasets together with the preprocessing steps are presented.", "labels": [], "entities": []}, {"text": "In section 4, obtained results are detailed.", "labels": [], "entities": []}, {"text": "Finally, in section 5 a discussion about the proposed system is outlined.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of English data, labels of the test  data were not specified.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of Spanish data. No trial data was  available, and test data labels were not specified.", "labels": [], "entities": [{"text": "Distribution of Spanish", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8040436704953512}]}, {"text": " Table 3: Scores with changes in preprocessing for En- glish, scores in bold means that it was higher than using  all preprocessing of the respective system.", "labels": [], "entities": []}, {"text": " Table 4: Scores with changes in preprocessing for  Spanish, csores in bold means that it was higher than  using all preprocessing of the respective system.", "labels": [], "entities": []}, {"text": " Table 5: Scores of our ensemble models on both sub- tasks and languages during testing phase, compared to  the top three systems in that subtask.", "labels": [], "entities": []}, {"text": " Table 6: Scores on the English development set of the  Support Vector Machine (SVM 2) classifier using dif- ferent word embeddings as input.", "labels": [], "entities": []}]}