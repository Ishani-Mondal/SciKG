{"title": [{"text": "NULI at SemEval-2019 Task 6: Transfer Learning for Offensive Language Detection using Bidirectional Transformers", "labels": [], "entities": [{"text": "SemEval-2019 Task 6", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.5409665505091349}, {"text": "Transfer Learning", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.8952357172966003}, {"text": "Offensive Language Detection", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.7930994232495626}]}], "abstractContent": [{"text": "Transfer learning and domain adaptive learning have been applied to various fields including computer vision (e.g., image recognition) and natural language processing (e.g., text classification).", "labels": [], "entities": [{"text": "Transfer learning", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9162519872188568}, {"text": "image recognition)", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.8156392375628153}, {"text": "text classification)", "start_pos": 174, "end_pos": 194, "type": "TASK", "confidence": 0.8290628989537557}]}, {"text": "One of the benefits of transfer learning is to learn effectively and efficiently from limited labeled data with a pre-trained model.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.958610475063324}]}, {"text": "In the shared task of identifying and categorizing offensive language in social media, we preprocess the dataset according to the language behaviors on social media, and then adapt and fine-tune the Bidi-rectional Encoder Representation from Transformer (BERT) pre-trained by Google AI Language team 1.", "labels": [], "entities": []}, {"text": "Our team NULI wins the first place (1st) in Sub-task A-Offensive Language Identification and is ranked 4th and 18th in Sub-task B-Automatic Categorization of Offense Types and Sub-task C-Offense Target Identification respectively.", "labels": [], "entities": [{"text": "NULI", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.8967145681381226}, {"text": "Sub-task A-Offensive Language Identification", "start_pos": 44, "end_pos": 88, "type": "TASK", "confidence": 0.6569287404417992}, {"text": "Sub-task C-Offense Target Identification", "start_pos": 176, "end_pos": 216, "type": "TASK", "confidence": 0.583610862493515}]}], "introductionContent": [{"text": "Anti-social online behaviors, including cyberbullying, trolling and offensive language (, are attracting more attention on different social networks.", "labels": [], "entities": []}, {"text": "The intervention of such behaviors should betaken at the earliest opportunity.", "labels": [], "entities": []}, {"text": "Automatic offensive language detection using machine learning algorithms becomes one solution to identifying such hostility and has shown promising performance.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.6872996687889099}, {"text": "identifying such hostility", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.8134503364562988}]}, {"text": "In SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (), the organizers collected tweets through Twitter API and annotated them hierarchically regarding offensive language, offense type, and offense target.", "labels": [], "entities": []}, {"text": "The task is divided into three sub-tasks: a) detecting if a post is offensive https://github.com/google-research/bert (OFF) or not (NOT); b) identifying the offense type of an offensive post as targeted insult (TIN), targeted threat (TTH), or untargeted (UNT); c) fora post labeled as TIN/TTH in sub-task B, identifying the target of offense as individual (IND), group of people (GRP), organization or entity (ORG), or other (OTH).", "labels": [], "entities": []}, {"text": "The three sub-tasks are independently evaluated by macro-F1 metric.", "labels": [], "entities": []}, {"text": "The challenges of this shared task include: a) comparatively small dataset makes it hard to train complex models; b) the characteristics of language on social media pose difficulties such as out-ofvocabulary words and ungrammatical sentences; c) the distribution of target classes is imbalanced and inconsistent between training and test data.", "labels": [], "entities": []}, {"text": "To address the problem of out-of-vocabulary words especially emoji and hashtags, we preprocess each tweet by interpreting emoji as meaningful English phrases and segmenting hashtags into space separated words.", "labels": [], "entities": []}, {"text": "The classifiers we experiment with include: linear model with features of word unigrams, word2vec, and Hatebase; word-based Long Short-Term Memory (LSTM); fine-tuned Bidirectional Encoder Representation from Transformer (BERT).", "labels": [], "entities": [{"text": "Long Short-Term Memory (LSTM)", "start_pos": 124, "end_pos": 153, "type": "METRIC", "confidence": 0.709071472287178}]}, {"text": "We choose BERT for our official submission, since it performs the best in our experiments.", "labels": [], "entities": [{"text": "BERT", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9969372749328613}]}, {"text": "In the rest of this paper, we organize the content as follows: related work of hostility on social media is stated in section 2; section 3 introduces data description, details of preprocessing, and the methodology of our models; experimental results are discussed in section 4.", "labels": [], "entities": []}, {"text": "We also present the conclusion of our work at the end of paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation metric of this task is Macro-F1, which is the unweighted-average F1 of all the classes.", "labels": [], "entities": [{"text": "F1", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.5177739262580872}]}, {"text": "The imbalance distribution makes the macro-F1 hard to achieve, and usually the score is penalized by the minority class.", "labels": [], "entities": []}, {"text": "Weighted-loss is one solution during the training time to balance the model not to lead to the majority class prediction.", "labels": [], "entities": [{"text": "majority class prediction", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.5753557682037354}]}, {"text": "In the table 2 and 3, we report the results of our dev-dataset and final test dataset.", "labels": [], "entities": []}, {"text": "From the table 2, we list the performance of our three selected models for each sub-task.", "labels": [], "entities": []}, {"text": "The data is stratified split into 9:1 as train and test.", "labels": [], "entities": []}, {"text": "There is also one independent validation set to determine the model selection that is split from train set.", "labels": [], "entities": []}, {"text": "One observation from the table shows the problem of imbalanced data, so that higher accuracy does not guarantee higher macro-F1 score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9984322190284729}]}, {"text": "Thus the stop criterion is based on average loss of validation set we mentioned before.", "labels": [], "entities": []}, {"text": "Based on the results of validation, we choose to use BERT as our selected model for the final submission.", "labels": [], "entities": [{"text": "BERT", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9954538345336914}]}, {"text": "In the table 3, it shows the results on official test dataset.", "labels": [], "entities": [{"text": "official test dataset", "start_pos": 40, "end_pos": 61, "type": "DATASET", "confidence": 0.7594624559084574}]}, {"text": "It should be noticed that in the subtask A, we also submit one result of a Bagging classifier with number 50, and Logistic Regression is the weak classifier.", "labels": [], "entities": []}, {"text": "The features are the same with linear model we mentioned before.", "labels": [], "entities": []}, {"text": "The result from BERT model sub-task A achieves the 1st place among all the participants.", "labels": [], "entities": [{"text": "BERT", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9814110398292542}]}, {"text": "BERT-3 denotes we train BERT with only 3 epochs.", "labels": [], "entities": [{"text": "BERT-3", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9265004396438599}, {"text": "BERT", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9506635665893555}]}, {"text": "Same notation with the latter two sub-tables.", "labels": [], "entities": []}, {"text": "In the sub-task B and sub-task C, the results are not as good as subtask A due to two reasons: 1) the class distribution is more skewed than that of sub-task A.", "labels": [], "entities": []}, {"text": "2) the number of training instance is much smaller than sub-task A.", "labels": [], "entities": []}, {"text": "The worst performance is sub-task C, (a) Sub-task A (b) Sub-task B (c) Sub-task C   In the previous section, we mentioned the discrepancy of class distribution between training and test datasets.", "labels": [], "entities": []}, {"text": "For example, in sub-task C, the class 'OTH' constitutes 0.101 of the training data, while it makes up 0.164 of the test data.", "labels": [], "entities": [{"text": "OTH", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.7757440805435181}]}, {"text": "This adds difficulty to the task, however, we are often confronted with the same situation in real-world problems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data Distribution: The first two rows are the  class distribution of sub-task A. The mid part two rows  are the class distribution of sub-task B. The last three  rows are the class distribution of sub-task C.", "labels": [], "entities": []}, {"text": " Table 2: Results on Dev Data.", "labels": [], "entities": [{"text": "Dev Data", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.778477132320404}]}, {"text": " Table 3: Results on Test Data.", "labels": [], "entities": [{"text": "Test Data", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.7653017044067383}]}]}