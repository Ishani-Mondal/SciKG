{"title": [{"text": "HAD-T \u00a8 ubingen at SemEval-2019 Task 6: Deep Learning Analysis of Offensive Language on Twitter: Identification and Categorization", "labels": [], "entities": [{"text": "HAD-T", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9730960726737976}]}], "abstractContent": [{"text": "This paper describes the submissions of our team, HAD-T\u00fcbingen, for the SemEval 2019-Task 6: \"OffensEval: Identifying and Categorizing Offensive Language in Social Me-dia\".", "labels": [], "entities": [{"text": "SemEval 2019-Task 6", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.8912506103515625}]}, {"text": "We participated in all the three sub-tasks: Sub-task A-\"Offensive language identifica-tion\", sub-task B-\"Automatic categorization of offense types\" and sub-task C-\"Offense target identification\".", "labels": [], "entities": [{"text": "Offense target identification", "start_pos": 164, "end_pos": 193, "type": "TASK", "confidence": 0.6452004710833231}]}, {"text": "As a baseline model we used a Long short-term memory recurrent neu-ral network (LSTM) to identify and categorize offensive tweets.", "labels": [], "entities": []}, {"text": "For all the tasks we experimented with external databases in a postpro-cessing step to enhance the results made by our model.", "labels": [], "entities": []}, {"text": "The best macro-average F 1 scores obtained for the sub-tasks A, B and C are 0.73, 0.52, and 0.37, respectively.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9321896632512411}]}], "introductionContent": [{"text": "The use of offensive language is an ubiquitous problem one faces when using social networking services like Twitter.", "labels": [], "entities": []}, {"text": "Users of such services often take advantage of the anonymity of the individual platforms for using the computer-mediated communication to engage in offensive behaviour against individuals, groups and/or organizations.", "labels": [], "entities": []}, {"text": "Due to increasing problems with offensive language and a raising demand for offensive language detection on platforms like Twitter, tasks, similar to the current one have already become popular for several different languages: English (), German () and Spanish (.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 76, "end_pos": 104, "type": "TASK", "confidence": 0.8054671684900919}]}, {"text": "With increasing popularity of Twitter, over 1.48 billion users (June 2013) and still new accounts signing up everyday, the need for improvement on tackling the well known problem of insults inside the platform has become more and more necessary.", "labels": [], "entities": []}, {"text": "The Twitter platform 1 describes itself as a connection to \"what's happening in the world and what people are talking about right now\".", "labels": [], "entities": []}, {"text": "For this reason alone, its data attracts more and more NLP researchers allover the world.", "labels": [], "entities": []}, {"text": "\"Tweets\", the messages one can send over this platform can be described as micro-texts, limited to 280 characters, over which users can interact with each other or simply post statements.", "labels": [], "entities": []}, {"text": "Since the input is up to the user, one could include misspellings, emoticons, hashtags but also slang and abusive words, what makes those messages a valuable source for different analyses.", "labels": [], "entities": []}, {"text": "As was mentioned in the beginning, the goal of this paper is to consider our approach for the SemEval 2019 -Task 6: \"OffensEval: Identifying and Categorizing Offensive Language in Social Media\", for task information (see) and for dataset description (see).", "labels": [], "entities": [{"text": "SemEval 2019 -Task 6", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.8346209049224853}, {"text": "Identifying and Categorizing Offensive Language in Social Media", "start_pos": 129, "end_pos": 192, "type": "TASK", "confidence": 0.7006767988204956}]}, {"text": "We took part in all of the three subtasks, using an LSTM based classifier.", "labels": [], "entities": []}, {"text": "In the remainder of the paper, we describe our methods and discuss both our results and suggestions for further work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 2. As before, the organizers  have also included random baseline generated re- sults by assigning the same labels for all instances.", "labels": [], "entities": []}, {"text": " Table 2: Results for Sub-task B.", "labels": [], "entities": []}, {"text": " Table 3: Results for Sub-task C.", "labels": [], "entities": []}]}