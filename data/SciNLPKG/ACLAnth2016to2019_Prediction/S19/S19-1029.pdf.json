{"title": [{"text": "Bayesian Inference Semantics: A Modelling System and A Test Suite", "labels": [], "entities": []}], "abstractContent": [{"text": "We present BIS, a Bayesian Inference Semantics , for probabilistic reasoning in natural language.", "labels": [], "entities": [{"text": "BIS", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9937724471092224}]}, {"text": "The current system is based on the framework of Bernardy et al.", "labels": [], "entities": []}, {"text": "(2018), but departs from it in important respects.", "labels": [], "entities": []}, {"text": "BIS makes use of Bayesian learning for inferring a hypothesis from premises.", "labels": [], "entities": [{"text": "BIS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7449842095375061}]}, {"text": "This involves estimating the probability of the hypothesis, given the data supplied by the premises of an argument.", "labels": [], "entities": []}, {"text": "It uses a syntactic parser to generate typed syntactic structures that serve as input to a model generation system.", "labels": [], "entities": []}, {"text": "Sentences are interpreted compositionally to probabilistic programs, and the corresponding truth values are estimated using sampling methods.", "labels": [], "entities": []}, {"text": "BIS successfully deals with various probabilistic semantic phenomena , including frequency adverbs, gener-alised quantifiers, generics, and vague predicates.", "labels": [], "entities": [{"text": "BIS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7187342643737793}]}, {"text": "It performs well on a number of interesting probabilistic reasoning tasks.", "labels": [], "entities": []}, {"text": "It also sustains most classically valid inferences (instan-tiation, de Morgan's laws, etc.).", "labels": [], "entities": []}, {"text": "To test BIS we have built an experimental test suite with examples of a range of probabilistic and classical inference patterns.", "labels": [], "entities": [{"text": "BIS", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.3772594630718231}]}], "introductionContent": [{"text": "On a traditional view of inference, the entailment relation between the premises of an argument and its conclusion holds iff the argument is logically valid in a proof or model theory.", "labels": [], "entities": []}, {"text": "More recently, computational approaches to entailment in natural text, such as Recognising Textual Entailment (RTE,) have attempted to capture inferences that depend on lexical meaning and real world knowledge, as well as logical structure.", "labels": [], "entities": [{"text": "Recognising Textual Entailment (RTE", "start_pos": 79, "end_pos": 114, "type": "TASK", "confidence": 0.6741528868675232}]}, {"text": "In the latter sorts of inference, the conclusions often follow from the premises within a certain range of probability values.", "labels": [], "entities": []}, {"text": "In this paper we present Bayesian Inference Semantics (BIS), a probabilistic semantics for natural language that assigns probability values, rather than Boolean truth-values, to sentences.", "labels": [], "entities": [{"text": "Bayesian Inference Semantics (BIS)", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.6666865050792694}]}, {"text": "The probability of a sentence is the likelihood that an idealised speaker, as represented by our model, would accept the assertion that it expresses.", "labels": [], "entities": []}, {"text": "Our framework builds on the approach proposed by.", "labels": [], "entities": []}, {"text": "It is Bayesian in that it constructs models in which asserted constraints provide Bayesian evidence that models use to determine whether objects satisfy particular properties.", "labels": [], "entities": []}, {"text": "Objects are represented as vectors in a model space S, and properties are subspaces in S.", "labels": [], "entities": []}, {"text": "Satisfaction of a property is expressed as membership in the corresponding subspace of S.", "labels": [], "entities": []}, {"text": "The probability density over the space of possible situations corresponds to the a priori density of objects in these subspaces, and is specified through Bayesian priors.", "labels": [], "entities": []}, {"text": "The system leverages the probabilistic functional programming language WebPPL) to evaluate Bayesian posteriors.", "labels": [], "entities": []}, {"text": "English sentences are parsed using Ranta's Grammatical Framework (GF, http://www.", "labels": [], "entities": []}, {"text": "grammaticalframework.org/, 2004), and the parses are compositionally mapped into interpretations within BIS's probabilistic models.", "labels": [], "entities": [{"text": "BIS", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.874069094657898}]}, {"text": "We apply BIS to inferences, most of which are probabilistic in nature, and so closely related to RTE concerns.", "labels": [], "entities": [{"text": "BIS", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9577730298042297}, {"text": "RTE", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9174915552139282}]}, {"text": "We have constructed a test suite of 78 inferences on which we have developed and tested BIS.", "labels": [], "entities": [{"text": "BIS", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.6960914731025696}]}, {"text": "The premises in each argument provide Bayesian evidence for the models in which the inference is interpreted, and its conclusion is assigned a (posterior) probability value.", "labels": [], "entities": []}, {"text": "In Section 2 we describe BIS.", "labels": [], "entities": [{"text": "BIS", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.7857799530029297}]}, {"text": "We explain the syntax-model interface that our GF parses provide, and we characterise how our models are constructed.", "labels": [], "entities": []}, {"text": "The models employ Monte Carlo Markov Chain (MCMC) sampling 2 on objects to estimate membership in the property classes that correspond to the predicates identified in GF parses of our input sentences.", "labels": [], "entities": []}, {"text": "Section 3 presents our inference system and our test set.", "labels": [], "entities": []}, {"text": "BIS currently handles a range of generalised quantifiers, sentential and VP negation, modal and temporal adverbs, measure and comparative adjectives, common nouns, and a variety of logical connectives.", "labels": [], "entities": [{"text": "BIS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8156157732009888}]}, {"text": "It treats VPs and common nouns as monadic predicates.", "labels": [], "entities": []}, {"text": "We show how BIS handles both probabilistic and logically valid inferences over a series of examples from the test set.", "labels": [], "entities": [{"text": "BIS", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.4942667782306671}]}, {"text": "We specify the coverage that the system currently achieves for this set.", "labels": [], "entities": [{"text": "coverage", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9612855911254883}]}, {"text": "We have designed BIS to capture inferences involving gradable predicates like tall, where the application of the predicate is clear for upper and lower bound cases, but increasingly indeterminate for intermediate instances between these points.", "labels": [], "entities": []}, {"text": "BIS handles arguments in which neither a predicate nor its contrary apply.", "labels": [], "entities": [{"text": "BIS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5245010256767273}]}, {"text": "It also covers both wide and narrow scope readings of certain quantifiers.", "labels": [], "entities": []}, {"text": "We discuss other approaches to probabilistic semantic inference in Section 4.", "labels": [], "entities": [{"text": "probabilistic semantic inference", "start_pos": 31, "end_pos": 63, "type": "TASK", "confidence": 0.6406724055608114}]}, {"text": "Finally, in Section 5 we identify the issues that we plan to take up in future work, and state our conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}