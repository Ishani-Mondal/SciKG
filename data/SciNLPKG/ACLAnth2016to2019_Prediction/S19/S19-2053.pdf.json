{"title": [{"text": "SINAI at SemEval-2019 Task 3: Using affective features for emotion classification in textual conversations", "labels": [], "entities": [{"text": "SemEval-2019 Task", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7591180205345154}, {"text": "emotion classification", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7728672623634338}]}], "abstractContent": [{"text": "Detecting emotions in textual conversation is a challenging problem in absence of nonverbal cues typically associated with emotion, like facial expression or voice modulations.", "labels": [], "entities": [{"text": "Detecting emotions in textual conversation", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8764815211296082}]}, {"text": "However , more and more users are using message platforms such as WhatsApp or telegram.", "labels": [], "entities": [{"text": "WhatsApp", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.9465314745903015}]}, {"text": "For this reason, it is important to develop systems capable of understanding human emotions in textual conversations.", "labels": [], "entities": []}, {"text": "In this paper, we carried out different systems to analyze the emotions of textual dialogue from SemEval-2019 Task 3: EmoContext for English language.", "labels": [], "entities": []}, {"text": "Our main contribution is the integration of emotional and sentimental features in the classification using the SVM algorithm.", "labels": [], "entities": []}], "introductionContent": [{"text": "Emotions seem to govern our daily lives since most of our decisions are guided by our mood.", "labels": [], "entities": []}, {"text": "They are complex and that is why they have been studied in many areas overtime.", "labels": [], "entities": []}, {"text": "Given the importance to develop systems to be able to mimic functioning of the human brain, emotions have attracted the attention in the field of affective computing.", "labels": [], "entities": []}, {"text": "To our knowledge, there are not many works that focus on studying how emotions are reflected verbally.", "labels": [], "entities": []}, {"text": "However, studying emotions on text messaging platforms such as WhatsApp, Facebook Messenger or Telegram is important as more and more users are using them to share their experiences and emotions.", "labels": [], "entities": [{"text": "WhatsApp", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9212515354156494}]}, {"text": "Currently, detecting emotions in instant messaging has multiple applications in different fields (), such as businesses intelligence to increase customer satisfaction knowing their preferences, social media to alert users if they are going to post an offensive tweet or psychology to detect some disorders like anorexia, anxiety or stress.", "labels": [], "entities": []}, {"text": "In this paper, we present the different systems we developed as part of our participation in SemEval-2019 Task 3: Contextual Emotion Detection in Text (EmoContext) (.", "labels": [], "entities": [{"text": "SemEval-2019 Task 3", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7927004297574362}, {"text": "Contextual Emotion Detection in Text", "start_pos": 114, "end_pos": 150, "type": "TASK", "confidence": 0.7343423247337342}]}, {"text": "It is an emotion classification task.", "labels": [], "entities": [{"text": "emotion classification task", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.7969303627808889}]}, {"text": "Given a textual dialogue along with two turns of context, its consists of classify the emotion of user utterance as one of the emotion classes: Happy, Sad, Angry or Others.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we explain the data used in our methods.", "labels": [], "entities": []}, {"text": "Section 3 introduces the lexical resources used for this work.", "labels": [], "entities": []}, {"text": "Section 4 presents the details of the proposed systems.", "labels": [], "entities": []}, {"text": "In Section 5, we discuss the analysis and evaluation results for our system.", "labels": [], "entities": []}, {"text": "We conclude in Section 6 with remarks and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "During the pre-evaluation phase we carried out several experiments and the best experiments were taken into account for the evaluation phase.", "labels": [], "entities": []}, {"text": "The architecture of the different systems can be seen in and are described below: \u2022 Basic system (BS).", "labels": [], "entities": []}, {"text": "For this experiment, we have combined the 3-turn conversations of the corpus in a text string separated by spaces.", "labels": [], "entities": []}, {"text": "For example, for turn 1: \"Hahah i loved it\" , turn 2: \"Yay!", "labels": [], "entities": []}, {"text": "Glad you loved it X3\" and turn 3: \"You always make us happy\", the final sentence is \"Hahah i loved it Yay!", "labels": [], "entities": []}, {"text": "Glad you loved it X3 You always make us happy\".", "labels": [], "entities": []}, {"text": "Then, each sentence is represented as a vector of unigrams and bigrams choosing the TF weighting scheme and it is used as feature for the classification using the SVM algorithm.", "labels": [], "entities": []}, {"text": "\u2022 Basic system with turn 1 and 2 (BS-2).", "labels": [], "entities": [{"text": "BS-2", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.8832479119300842}]}, {"text": "This experiment is similar to the previous one.", "labels": [], "entities": []}, {"text": "However, we have only taken into account the first and last conversation turns because analyzing the training data, we realized that the second conversation turn is not useful for the classification as it does not provide representative information.", "labels": [], "entities": [{"text": "classification", "start_pos": 184, "end_pos": 198, "type": "TASK", "confidence": 0.9651215672492981}]}, {"text": "For example, for turn 1: \"Hahah i loved it\" , turn 2: \"Yay!", "labels": [], "entities": []}, {"text": "Glad you loved it X3\" and turn 3: \"You always make us happy\", the final sentence is \"Hahah i loved it You always make us happy\".", "labels": [], "entities": []}, {"text": "We notice that the emotion is the same (happy) as if we consider the three turns.", "labels": [], "entities": []}, {"text": "\u2022 System with features (SF).", "labels": [], "entities": []}, {"text": "In this system, also we have only taken into account the first and last conversation turns.", "labels": [], "entities": []}, {"text": "With these turns of conversations, we have tested several combinations with the lexical resources during the development phase and we chose the best combination for the evaluation phase.", "labels": [], "entities": []}, {"text": "User name (ranking) F1 leo1020 0.79 gautam naik 0.72 fmplaza 0.68 emocontext organizers 0.59 waylensu 0.0143 systems in EmoContext task is the microaveraged F1 score (F1\u00b5) for the three emotion classes (Happy, Sad and Angry).", "labels": [], "entities": [{"text": "F1", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.9917030930519104}, {"text": "F1 score (F1\u00b5)", "start_pos": 157, "end_pos": 171, "type": "METRIC", "confidence": 0.8821394801139831}]}, {"text": "This metric is calculated between the real classes and the predicted classes.", "labels": [], "entities": []}, {"text": "The results of our participation in the task can be seen in.", "labels": [], "entities": []}, {"text": "In relation to our results, during the preevaluation phase and evaluation phase, we noticed that 1 and 3 conversation turns performed better the classification due to the reason that the 2 conversation turn is usually a contradiction or a question of the 1-turn.", "labels": [], "entities": []}, {"text": "In we can observed that the BS-2 experiments outperformed the BS experiments.", "labels": [], "entities": [{"text": "BS-2", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.8619863390922546}, {"text": "BS", "start_pos": 62, "end_pos": 64, "type": "DATASET", "confidence": 0.8332270979881287}]}, {"text": "According to the classification per emotion, we may note different issues.", "labels": [], "entities": []}, {"text": "On the one hand, the use of lexical features (SF experiment) improve about 2% of F1 with respect to the BS-2 experiment in the dev set.", "labels": [], "entities": [{"text": "F1", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9996047616004944}, {"text": "BS-2 experiment", "start_pos": 104, "end_pos": 119, "type": "DATASET", "confidence": 0.8852742314338684}]}, {"text": "Nevertheless, this is not the casein the test set.", "labels": [], "entities": []}, {"text": "On the other hand, the Happy emotion class perform worse than other emotion classes in both datasets, as it happens in other works (.", "labels": [], "entities": []}, {"text": "Besides, if we observed the SF experiment in test set, we can see that the emotional features do not help to improve the classification because there are some words like \"love\" or \"cool\" whose assigned emotion is Happy class but in the 3-turn conversation of test set have been marked as Others class by the judges.", "labels": [], "entities": []}, {"text": "Finally, in we can observe our official position in the competition.", "labels": [], "entities": []}, {"text": "We are ranked 92 out of 165 participating teams and our system outperforms the baseline system provided by the organizers of the task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of 3-turn conversations per EmoCon- text dataset", "labels": [], "entities": [{"text": "EmoCon- text dataset", "start_pos": 45, "end_pos": 65, "type": "DATASET", "confidence": 0.8151214718818665}]}, {"text": " Table 2: Results on the dev set.", "labels": [], "entities": []}, {"text": " Table 3: Results on the test set.", "labels": [], "entities": []}]}