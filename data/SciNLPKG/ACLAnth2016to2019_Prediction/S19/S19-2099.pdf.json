{"title": [{"text": "BNU-HKBU UIC NLP Team 2 at SemEval-2019 Task 6: Detecting Offensive Language Using BERT model", "labels": [], "entities": [{"text": "BNU-HKBU UIC NLP Team", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.7811122685670853}, {"text": "Detecting Offensive Language", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.8903177976608276}]}], "abstractContent": [{"text": "In this study we deal with the problem of identifying and categorizing offensive language in social media.", "labels": [], "entities": []}, {"text": "Our group, BNU-HKBU UIC NLP Team2, use supervised classification along with multiple version of data generated by different ways of pre-processing the data.", "labels": [], "entities": [{"text": "BNU-HKBU UIC NLP Team2", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.8244053274393082}]}, {"text": "We then use the state-of-the-art model Bidirec-tional Encoder Representations from Transformers , or BERT (Devlin et al.", "labels": [], "entities": [{"text": "Bidirec-tional Encoder Representations from Transformers", "start_pos": 39, "end_pos": 95, "type": "TASK", "confidence": 0.609258109331131}, {"text": "BERT", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9742761254310608}]}, {"text": "(2018)), to capture linguistic, syntactic and semantic features.", "labels": [], "entities": []}, {"text": "Long range dependencies between each part of a sentence can be captured by BERT's bidirectional encoder representations.", "labels": [], "entities": []}, {"text": "Our results show 85.12% accuracy and 80.57% F1 scores in Subtask A (offensive language identification), 87.92% accuracy and 50% F1 scores in Subtask B (categorization of offense types), and 69.95% accuracy and 50.47% F1 score in Subtask C (offense target identification).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9992415904998779}, {"text": "F1", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.998474657535553}, {"text": "Subtask A (offensive language identification", "start_pos": 57, "end_pos": 101, "type": "TASK", "confidence": 0.5683033814032873}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9985851049423218}, {"text": "F1", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.9966728687286377}, {"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9990311861038208}, {"text": "F1 score", "start_pos": 217, "end_pos": 225, "type": "METRIC", "confidence": 0.9854011237621307}, {"text": "offense target identification)", "start_pos": 240, "end_pos": 270, "type": "TASK", "confidence": 0.6328569203615189}]}, {"text": "Analysis of the results shows that distinguishing between targeted and untargeted offensive language is not a simple task.", "labels": [], "entities": [{"text": "distinguishing between targeted and untargeted offensive language", "start_pos": 35, "end_pos": 100, "type": "TASK", "confidence": 0.6968340107372829}]}, {"text": "More work needs to be done on the unbalance data problem in Subtasks B and C.", "labels": [], "entities": []}, {"text": "Some future work is also discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social media is an essential part of human communication today.", "labels": [], "entities": []}, {"text": "People can share their opinions in this platform with anonymity.", "labels": [], "entities": []}, {"text": "Some people use offensive language and hate speech casually and frequently without taking any responsibility for their behavior.", "labels": [], "entities": []}, {"text": "For this reason, SemEval 2019 () setup the task OffensEval: identifying and categorizing offensive language in social media.", "labels": [], "entities": []}, {"text": "This task is divided into three subtasks: offensive language identification, automatic categorization of offensive types, and offence target identification.", "labels": [], "entities": [{"text": "offensive language identification", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.7123293280601501}, {"text": "offence target identification", "start_pos": 126, "end_pos": 155, "type": "TASK", "confidence": 0.6384427150090536}]}, {"text": "Our group uses the Natural Language Processing (NLP) latest model, Bidirectional Encoder Representations from Transformers (BERT).", "labels": [], "entities": [{"text": "Bidirectional Encoder Representations from Transformers (BERT)", "start_pos": 67, "end_pos": 129, "type": "TASK", "confidence": 0.7073513716459274}]}, {"text": "It is a general-purpose \"language understanding\" model trained on a large text corpus such as Wikipedia ().", "labels": [], "entities": [{"text": "language understanding\"", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7777887284755707}]}, {"text": "After finetuning, the model can be used for downstream NLP tasks.", "labels": [], "entities": []}, {"text": "Because BERT is very complex and is the state-of-art model, it is prudent for us not to change its internal structure.", "labels": [], "entities": [{"text": "BERT", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9633577466011047}]}, {"text": "Hence, we focus on preprocessing the data and error analysis.", "labels": [], "entities": []}, {"text": "After much experimentation with the data, such as translating emoji into words, putting more weight on some metaphorical words, removing the hashtag and soon, we find that using the original data will give the best performance.", "labels": [], "entities": []}, {"text": "The reason for this is perhaps if we remove some information from the sentence, some features that affect the prediction result will be lost.", "labels": [], "entities": []}, {"text": "So we end up using the original data to train our model.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 3: Results for Sub-task B.", "labels": [], "entities": []}, {"text": " Table 4: Results for Sub-task C.", "labels": [], "entities": []}]}