{"title": [{"text": "USF at SemEval-2019 Task 6: Offensive Language Detection Using LSTM With Word Embeddings", "labels": [], "entities": [{"text": "USF at SemEval-2019 Task 6", "start_pos": 0, "end_pos": 26, "type": "DATASET", "confidence": 0.8011677026748657}, {"text": "Offensive Language Detection", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.7919683853785197}]}], "abstractContent": [{"text": "In this paper, we present a system description for the SemEval-2019 Task 6 submitted by our team.", "labels": [], "entities": [{"text": "SemEval-2019 Task 6", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7760039766629537}]}, {"text": "For the task, our system takes tweet as an input and determine if the tweet is offensive or non-offensive (Sub-task A).", "labels": [], "entities": []}, {"text": "In case a tweet is offensive, our system identifies if a tweet is targeted (insult or threat) or non-targeted like swearing (Sub-task B).", "labels": [], "entities": []}, {"text": "In targeted tweets, our system identifies the target as an individual or group (Sub-task C).", "labels": [], "entities": []}, {"text": "We used data pre-processing techniques like splitting hashtags into words, removing special characters , stop-word removal, stemming, lemmati-zation, capitalization, and offensive word dictionary.", "labels": [], "entities": []}, {"text": "Later, we used keras tokenizer and word embeddings for feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7822363376617432}]}, {"text": "For classification, we used the LSTM (Long short-term memory) model of keras framework.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9697727560997009}]}, {"text": "Our accuracy scores for Sub-task A, B and C are 0.8128, 0.8167 and 0.3662 respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996920824050903}]}, {"text": "Our results indicate that fine-grained classification to identify offense target was difficult for the system.", "labels": [], "entities": []}, {"text": "Lastly, in the future scope section, we will discuss the ways to improve system performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been a rapid rise in social media platforms and surge in the number of users registering in order to communicate, publish content, showcase their skills and express their views.", "labels": [], "entities": []}, {"text": "Social media platforms like Facebook and Twitter have millions of registered users influenced by the countless user-generated posts on daily basis).", "labels": [], "entities": []}, {"text": "While on one hand social media platforms facilitate the exchange of views, effective communication and can be seen as a helping mode in crisis.", "labels": [], "entities": []}, {"text": "On the other hand, they open up the window for anti-social behavior such as bullying, stalking, harassing, trolling and hate speech.", "labels": [], "entities": []}, {"text": "These platforms provide the anonymity and hence aid users to indulge in aggressive behavior which propagates due to the increased willingness of people sharing their opinions.", "labels": [], "entities": []}, {"text": "This aggression can lead to foul language which is seen as \"offensive\", \"abusive\", or \"hate speech\", terms, which are used interchangeably (.", "labels": [], "entities": []}, {"text": "In general, offensive language is defined as derogatory, hurtful/ obscene remarks or comments made by an individual (or group) to an individual (or group).", "labels": [], "entities": []}, {"text": "The offensive language can be targeted towards a race, religion, color, gender, sexual orientation, nationality, or any characteristics of a person or a group.", "labels": [], "entities": []}, {"text": "Hate Speech is slowly plaguing the social media users with depression and anxiety, which can be presented in the form of images, text or media such as audio, video, etc.", "labels": [], "entities": [{"text": "Hate Speech", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.6632714569568634}]}, {"text": "(. Our paper presents the data and task description followed by results, conclusion and future work.", "labels": [], "entities": []}, {"text": "The purpose of Task 6 is to address and provide an effective procedure for detecting offensive tweets from the data set provided by shared task report paper ().", "labels": [], "entities": []}, {"text": "The shared task is threefold.", "labels": [], "entities": []}, {"text": "The Sub-task A ask us to identify whether the given tweet is offensive or non-offensive.", "labels": [], "entities": []}, {"text": "In Sub-task B offensive tweets are to be classified as targeted (person/group) or non-targeted (general).", "labels": [], "entities": []}, {"text": "Sub-task C ask us to do classification of the offensive tweets into individual, group or others.", "labels": [], "entities": []}, {"text": "We apply the LSTM with word embeddings in order to perform the multilevel classification.", "labels": [], "entities": [{"text": "multilevel classification", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.6490321606397629}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for Sub-task A.", "labels": [], "entities": []}, {"text": " Table 2: Results for Sub-task B.", "labels": [], "entities": []}, {"text": " Table 3: Results for Sub-task C.", "labels": [], "entities": []}]}