{"title": [{"text": "LTL-UDE at SemEval-2019 Task 6: BERT and Two-Vote Classification for Categorizing Offensiveness", "labels": [], "entities": [{"text": "BERT", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9984207153320312}]}], "abstractContent": [{"text": "This paper describes LTL-UDE's systems for the SemEval 2019 Shared Task 6.", "labels": [], "entities": [{"text": "SemEval 2019 Shared Task 6", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.7386809706687927}]}, {"text": "We present results for Subtask A and C.", "labels": [], "entities": []}, {"text": "In Subtask A, we experiment with an embedding representation of postings and use a Multi-Layer Perceptron and BERT to categorize postings.", "labels": [], "entities": [{"text": "BERT", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9974070191383362}]}, {"text": "Our best result reaches the 10th place (out of 103) using BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9858389496803284}]}, {"text": "In Subtask C, we applied a two-vote classification approach with minority fallback, which is placed on the 19th rank (out of 65).", "labels": [], "entities": []}], "introductionContent": [{"text": "The Internet is frequently used for online debates and discussions, where individuals or groups are increasingly often verbally attacked.", "labels": [], "entities": []}, {"text": "Online platform providers aim to remove such attacking posts or ideally, prevent them from being published.", "labels": [], "entities": []}, {"text": "Manual verification of each posting by a human moderator is infeasible due to the high amount of postings created everyday.", "labels": [], "entities": []}, {"text": "Consequently, automated detection of such attacking postings is the only feasible way to counter this kind of hostility.", "labels": [], "entities": [{"text": "automated detection of such attacking postings", "start_pos": 14, "end_pos": 60, "type": "TASK", "confidence": 0.7933869808912277}]}, {"text": "In this work, we present our results for the SemEval 2019 Shared Task 6: Identifying and Categorizing Offensive Language in Social Media () on the OLID dataset ().", "labels": [], "entities": [{"text": "SemEval 2019 Shared Task 6", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6772117018699646}, {"text": "Identifying and Categorizing Offensive Language in Social Media", "start_pos": 73, "end_pos": 136, "type": "TASK", "confidence": 0.7009842805564404}, {"text": "OLID dataset", "start_pos": 147, "end_pos": 159, "type": "DATASET", "confidence": 0.9711306989192963}]}, {"text": "Subtask A focuses on the binary distinction if a post is offensive or not, while Subtask C determines if the target is an individual, group, or other entity.", "labels": [], "entities": []}, {"text": "Our submission for Subtask A ranks 10th, for Subtask C ranks 19th.", "labels": [], "entities": []}, {"text": "For Subtask A, we experiment with word listbased classification, using classifiers such as SVM or logistic regression based on sentence embeddings, and neural network-based models such as a Multi-layer Perceptron (MLP) and Bidirectional Encoder Representations from Transformers (BERT).", "labels": [], "entities": [{"text": "word listbased classification", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.6773278216520945}]}, {"text": "We find that the SVM performs best on our development set, but BERT reaches the best result on the test dataset.", "labels": [], "entities": [{"text": "BERT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9974843263626099}]}, {"text": "Moreover, a learning curve experiment suggests that more training data will lead only to minor improvements.", "labels": [], "entities": []}, {"text": "In Subtask C, we choose a two-vote classification approach, where we let two systems compete with a fallback to the minority class in case the systems disagree.", "labels": [], "entities": []}, {"text": "This fallback approach has a high robustness between our development and the official test dataset.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Subtask A: Results in term of macro F 1 on a  held-back development dataset containing 1,048 offen- sive postings and 2,192 not offensive (NOT) ones.", "labels": [], "entities": []}, {"text": " Table 2: Subtask C results", "labels": [], "entities": [{"text": "Subtask C", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.8794843256473541}]}]}