{"title": [{"text": "Offensive Language Identification Based on BiLSTM with Double Attention", "labels": [], "entities": [{"text": "Offensive Language Identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7404992381731669}]}], "abstractContent": [{"text": "Offensive language has become pervasive in social media.", "labels": [], "entities": []}, {"text": "In Offensive Language Identification tasks, it maybe difficult to predict accurately only according to the surface words.", "labels": [], "entities": [{"text": "Offensive Language Identification", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.7629217704137167}]}, {"text": "So we try to dig deeper semantic information of text.", "labels": [], "entities": []}, {"text": "This paper presents use an attention-based two layers bidirectional long-short memory neural network (BiLSTM) for semantic feature extraction.", "labels": [], "entities": [{"text": "semantic feature extraction", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.7525767087936401}]}, {"text": "Additionally, a residual connection mechanism is used to synthesize two different deep features, and an emoji attention mechanism is used to extract semantic information of emojis in text.", "labels": [], "entities": []}, {"text": "We participated in three sub-tasks of SemEval 2019 Task 6 as CN-HIT-MI.T team.", "labels": [], "entities": [{"text": "SemEval 2019 Task 6", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7627596408128738}]}, {"text": "Our macro-averaged F1-score in sub-task A is 0.768, ranking 28/103.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9687032699584961}]}, {"text": "We got 0.638 in sub-task B, ranking 30/75.", "labels": [], "entities": []}, {"text": "In sub-task C, we got 0.549, ranking 22/65.", "labels": [], "entities": []}, {"text": "We also tried some other methods of not submitting results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognition of Offensive information has research and application value in many aspects.", "labels": [], "entities": [{"text": "Recognition of Offensive information", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8974913507699966}]}, {"text": "With the popularity of social media, people's comments on social media has become an important part of public opinion.", "labels": [], "entities": []}, {"text": "Although freedom of speech is advocated, there are still some unacceptable words.", "labels": [], "entities": []}, {"text": "The study of offensive language has only recently arisen.", "labels": [], "entities": []}, {"text": "With the deepening of the research, we need to consider the different sub-tasks of its decomposition.", "labels": [], "entities": []}, {"text": "In OffensEval tasks (), offensive content was divided into three sub-tasks taking the type and target of offenses into account.", "labels": [], "entities": []}, {"text": "Sub-task A is offensive language identification.", "labels": [], "entities": [{"text": "offensive language identification", "start_pos": 14, "end_pos": 47, "type": "TASK", "confidence": 0.6926970680554708}]}, {"text": "We should identify a short text sentence as offensive or non-offensive.", "labels": [], "entities": []}, {"text": "Sub-task B is automatic categorization of offense types.", "labels": [], "entities": []}, {"text": "We need to classify a sentence as having an attack target or not, if this is an offensive sentence.", "labels": [], "entities": []}, {"text": "Sub-task C is offense target identification.", "labels": [], "entities": [{"text": "offense target identification", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.646731972694397}]}, {"text": "Its purpose is to identify the target of an attack sentence with an attack target.", "labels": [], "entities": []}, {"text": "The target is individual, group or other.", "labels": [], "entities": []}, {"text": "User's comments on Twitter are usually cluttered.", "labels": [], "entities": []}, {"text": "In order to cleanup the data, a series of preprocessing for the data is necessary.", "labels": [], "entities": []}, {"text": "Then, pretrained word vectors are helpful to extract semantic features from deep learning model.", "labels": [], "entities": []}, {"text": "For classification model, bidirectional long-short memory neural network can catch the contextual information in text, in order to get offensive semantics from text.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9737944602966309}]}, {"text": "A residual connection cascade the first layer's output and the second layer's output can get features of text at different levels.", "labels": [], "entities": []}, {"text": "Attention mechanism is used for the final output.", "labels": [], "entities": [{"text": "Attention", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9659852385520935}]}, {"text": "Besides, referring to , emojis in a sentence have a significant impact on sentiment.", "labels": [], "entities": []}, {"text": "We assume them may affect the offensive semantics of text too, and double attention mechanism can deal with this semantic relationship.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces some research advances in Aggression Identification and Hate Speech.", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.974999189376831}, {"text": "Hate Speech", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.7315459847450256}]}, {"text": "Section 3 describes the data we use and the detailed introduction of our system.", "labels": [], "entities": []}, {"text": "Section 4 shows the performance of our system and comparison with other models.", "labels": [], "entities": []}, {"text": "Section 5 describes some of our summaries and future work directions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 shows three  different levels of tasks and their corresponding  amount of data.", "labels": [], "entities": []}, {"text": " Table 2: The results of Sub-task A we submitted. The  system is a 2-layer BiLSTM with Double Attention  which is described in Section 3.2", "labels": [], "entities": []}, {"text": " Table 3: The results of Sub-task B we submitted. The  system is a 2-layer BiLSTM with Double Attention  which is described in Section 3.2. It has different hy- perparameter settings from Sub-task A", "labels": [], "entities": []}, {"text": " Table 4: The results of Sub-task C we submitted. The  system is a 2-layer BiLSTM with Double Attention  which is described in Section 3.2. It has different hy- perparameter settings from Sub-task A and Sub-task B", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.8535274863243103}]}, {"text": " Table 5: Some comparative experiments on closed val- idation sets", "labels": [], "entities": []}]}