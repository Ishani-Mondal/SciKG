{"title": [{"text": "UA at SemEval-2019 Task 5: Setting a Strong Linear Baseline for Hate Speech Detection", "labels": [], "entities": [{"text": "Hate Speech Detection", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.8708117802937826}]}], "abstractContent": [{"text": "This paper describes the system developed at the University of Alicante (UA) for the Se-mEval 2019 Task 5: Multilingual detection of hate speech against immigrants and women in Twitter.", "labels": [], "entities": [{"text": "Multilingual detection of hate speech", "start_pos": 107, "end_pos": 144, "type": "TASK", "confidence": 0.8507974505424499}]}, {"text": "The purpose of this work is to build a strong baseline for hate speech detection by means of a traditional machine learning approach with standard textual features, which could serve as a reference to compare with deep learning systems.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7812708020210266}]}, {"text": "We participated in both task A (Hate Speech Detection against Immigrants and Women) and task B (Aggres-sive behavior and Target Classification) for both English and Spanish.", "labels": [], "entities": [{"text": "Hate Speech Detection against Immigrants and Women)", "start_pos": 32, "end_pos": 83, "type": "TASK", "confidence": 0.8283951431512833}, {"text": "Target Classification)", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7292364041010538}]}, {"text": "Given the text of a tweet, task A consists of detecting hate speech against women or immigrants in the text, whereas task B consists of identifying the target harassed as individual or generic, and to classify hateful tweets as aggressive or not aggressive.", "labels": [], "entities": []}, {"text": "Despite its simplicity, our system obtained a remarkable macro-F1 score of 72.5 (sixth highest) and an accuracy of 73.6 (sec-ond highest) in Spanish (task A), outperform-ing more complex neural models from a total of 40 participant systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9995406866073608}]}], "introductionContent": [{"text": "Due to the massive rise of users in social media, the presence of verbal abuse, hate speech and bully-attitudes has increased over the years.", "labels": [], "entities": []}, {"text": "A clear example is Twitter, where users find ways to anonymously harass and offend other individuals or collectives.", "labels": [], "entities": []}, {"text": "This is especially troublesome as hate speech and hate crime are strongly related.", "labels": [], "entities": []}, {"text": "Therefore, an early detection of hate speech could help prevent the subsequent hate crime.", "labels": [], "entities": []}, {"text": "Online platforms like Twitter have been seeking to combat hate speech on their site, but it still requires a lot of manual work because there is not a reliable automatic method that can correctly identify hate speech behaviour.", "labels": [], "entities": []}, {"text": "Building such automatic (or semi-automatic) systems is therefore essential to effectively fight this problem.", "labels": [], "entities": []}, {"text": "Hate speech detection is still a challenging task due to a number of reasons.", "labels": [], "entities": [{"text": "Hate speech detection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9335781335830688}]}, {"text": "First, hate speech content tends to be ambiguous and context-dependant (.", "labels": [], "entities": []}, {"text": "Moreover, hate speech can cross sentence boundaries and be present in sarcastic comments in the same voice as the people that were producing abusive languages.", "labels": [], "entities": []}, {"text": "These and other issues for detecting hate speech are discussed in more detail in.", "labels": [], "entities": [{"text": "detecting hate speech", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.8563430309295654}]}, {"text": "In order to deal with these issues, over the past few years several techniques to detect hate speech and abusive language online have been proposed.", "labels": [], "entities": []}, {"text": "Previous works made use of heterogeneous features such as bag of words, n-grams, punctuation, as well as lexical features and user-related features (.", "labels": [], "entities": []}, {"text": "In addition to these features, previous approaches showed the effectiveness of using word embeddings to detect abusive language in social media ( and exposed how sentiment analysis can also contribute to hate speech and offensive language detection (.", "labels": [], "entities": [{"text": "offensive language detection", "start_pos": 220, "end_pos": 248, "type": "TASK", "confidence": 0.7731257279713949}]}, {"text": "In this paper we build on these earlier works and propose a comprehensive framework to develop a traditional machine learning-based approach to hate speech detection, with the purpose of serving as a strong baseline for future systems using deep learning techniques.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.7815154194831848}]}, {"text": "Our framework will be based on a linear classifier with standard textual features.", "labels": [], "entities": []}, {"text": "As we will show throughout the paper, n-grams provide a reliable starting point when facing hate speech classification, and the performance can be further improved when combined with word em-beddings and sentiment analysis features.", "labels": [], "entities": [{"text": "hate speech classification", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.7549464901288351}, {"text": "sentiment analysis", "start_pos": 204, "end_pos": 222, "type": "TASK", "confidence": 0.9043100476264954}]}, {"text": "In particular for this work, we focus on hate speech against women and immigrants, following the Task 5 of SemEval 2019 (.", "labels": [], "entities": []}, {"text": "Indeed, race and gender hate speech has become an increasingly important issue in social media, as it stands for 50% of the targets of hate speech in Twitter (.", "labels": [], "entities": []}, {"text": "Code and pre-trained models are available at https:// github.com/CPerelloC/UA-SemEval.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the experimental setup (Section 3.1) of our system along with the results obtained (Section 3.2), including a brief analysis of errors detected in the evaluation phase (Section 3.3).", "labels": [], "entities": []}, {"text": "In the following we present the datasets considered, details about the text preprocessing and feature selection procedures, the pre-trained models used as part of our model, and how parameter tuning was performed.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 182, "end_pos": 198, "type": "TASK", "confidence": 0.6665225178003311}]}, {"text": "We used the two datasets made available as part of the SemEval-2019 Task 5 competition: one for English and another for Spanish.", "labels": [], "entities": [{"text": "SemEval-2019 Task 5 competition", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.5889999270439148}]}, {"text": "The datasets consist of training, development and test splits.", "labels": [], "entities": []}, {"text": "For English, the number of tweets for each split is 9100, 1000 and 2971 for training, development and test, respectively.", "labels": [], "entities": []}, {"text": "Conversely, the Spanish splits contain 4600, 500 and 1600 tweets.", "labels": [], "entities": [{"text": "Spanish splits", "start_pos": 16, "end_pos": 30, "type": "DATASET", "confidence": 0.8669260740280151}]}, {"text": "Each tweet is tokenized using the spaCy NLP library . We experimented with various preprocessing variants and decided to work with raw words as tokens (i.e., without applying lemmatization), removing punctuation and URLs but keeping emojis and stopwords (pronouns and articles can be relevant in the context of hate speech classification).", "labels": [], "entities": [{"text": "spaCy NLP library", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8947428266207377}, {"text": "hate speech classification", "start_pos": 311, "end_pos": 337, "type": "TASK", "confidence": 0.6497331261634827}]}, {"text": "As explained in Section 2.3, a feature selection procedure is applied on the ngram features to reduce their noise and size.", "labels": [], "entities": []}, {"text": "After the feature selection is performed for the bagof-n-grams features, the featured space is reduced from 336,669 to 4,605 in English task A, and from 177,003 to 4,217 in Spanish task A.", "labels": [], "entities": []}, {"text": "We experimented with several kernels and parameter configurations to train the Support Vector Machines, including polynomial and linear kernels.", "labels": [], "entities": []}, {"text": "Since our system is trained with a large amount of features, it is hard to find an optimal parameter configuration for the polynomial kernel.", "labels": [], "entities": []}, {"text": "Therefore, we decided to use a linear kernel, as the SVM training was faster and implied tuning less parameters.", "labels": [], "entities": []}, {"text": "We fine-tuned the C parameter of the SVM using as validation the development set of the task.", "labels": [], "entities": []}, {"text": "This parameter tuning was performed using bag-of-n-grams as features and on the Spanish dataset only.", "labels": [], "entities": [{"text": "Spanish dataset", "start_pos": 80, "end_pos": 95, "type": "DATASET", "confidence": 0.9357298016548157}]}, {"text": "The value of C that achieved the highest accuracy in the development set was C = 2 \u22125 for Task A and Task B-target classification, and C = 3 for Task Baggressive behaviour, which were fixed across all experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9990099668502808}]}], "tableCaptions": [{"text": " Table 1: Task A results using different sets of features. The row marked with  *  was submitted to the task.", "labels": [], "entities": []}, {"text": " Table 2: Task B results in the development and evaluation phases.", "labels": [], "entities": []}, {"text": " Table 3: Macro-F1 results in Task B by using dif- ferent types of training data.", "labels": [], "entities": []}]}