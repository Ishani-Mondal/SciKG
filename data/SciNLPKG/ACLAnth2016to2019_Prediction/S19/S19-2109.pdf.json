{"title": [{"text": "Fermi at SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media using Sentence Embeddings", "labels": [], "entities": [{"text": "Identifying and Categorizing Offensive Language in Social Media", "start_pos": 30, "end_pos": 93, "type": "TASK", "confidence": 0.7585634961724281}]}], "abstractContent": [{"text": "This paper describes our system (Fermi) for Task 6: OffensEval: Identifying and Categorizing Offensive Language in Social Media of SemEval-2019.", "labels": [], "entities": []}, {"text": "We participated in all the three sub-tasks within Task 6.", "labels": [], "entities": []}, {"text": "We evaluate multiple sentence embeddings in conjunction with various supervised machine learning algorithms and evaluate the performance of simple yet effective embedding-ML combination algorithms.", "labels": [], "entities": []}, {"text": "Our team (Fermi)'s model achieved an F1-score of 64.40%, 62.00% and 62.60% for sub-task A, B and C respectively on the official leaderboard.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9996734857559204}]}, {"text": "Our model for sub-task C which uses pretrained ELMo embed-dings for transforming the input and uses SVM (RBF kernel) for training, scored third position on the official leaderboard.", "labels": [], "entities": [{"text": "official leaderboard", "start_pos": 160, "end_pos": 180, "type": "DATASET", "confidence": 0.7688478529453278}]}, {"text": "Through the paper we provide a detailed description of the approach, as well as the results obtained for the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social media provides anonymity which can be misused to target offensive comments to targeted parties.", "labels": [], "entities": []}, {"text": "Users may engage in generating offensive content on social media which may show aggressive behaviour and may also include hate speech.", "labels": [], "entities": []}, {"text": "As a result, it is imperative for social media platforms to invest heavily in creating solutions which can identify offensive language and to prevent such behaviour on social media.", "labels": [], "entities": []}, {"text": "Using computational methods to identify offense, aggression and hate speech in user generated content has been gaining attention in the recent years as evidenced in ( and workshops such as Abusive Language Workshop (ALW)", "labels": [], "entities": [{"text": "identify offense, aggression and hate speech in user generated content", "start_pos": 31, "end_pos": 101, "type": "TASK", "confidence": 0.6558101231401617}, {"text": "Abusive Language Workshop (ALW)", "start_pos": 189, "end_pos": 220, "type": "TASK", "confidence": 0.62067844470342}]}], "datasetContent": [{"text": "The data collection methods used to compile the dataset used in OffensEval is described in (.", "labels": [], "entities": []}, {"text": "Sub-task A (Offensive language Detection) deals with classifying", "labels": [], "entities": [{"text": "Offensive language Detection)", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.8159387707710266}, {"text": "classifying", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.8795161843299866}]}], "tableCaptions": [{"text": " Table 1: Dev Set Accuracy and Macro-F1 scores (in percentage) for Sub-Task A", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9708604216575623}]}, {"text": " Table 2: Dev Set Accuracy and Macro-F1 scores (in percentage) for Sub-Task B", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9751935601234436}]}, {"text": " Table 3: Dev Set Accuracy and Macro-F1 scores (in percentage) for Sub-Task C", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.976214587688446}]}, {"text": " Table 4: Sub-task A, ELMo sentence embeddings with  SVM classifier using RBF kernel", "labels": [], "entities": []}, {"text": " Table 5: Sub-task B, Concatenated p mean sentence  embeddings with XGBoost classifier", "labels": [], "entities": []}, {"text": " Table 6: Sub-task C, Universal Encoder sentence em- beddings with XGBoost classifier", "labels": [], "entities": []}, {"text": " Table 7: Results for Sub-task A using LexVec, Con- catenated p-mean and ELMo sentence embeddings  with SVM classifier using RBF kernel", "labels": [], "entities": [{"text": "LexVec", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.9540351629257202}]}, {"text": " Table 8: Results for Sub-task B. using Concatenated  p-mean, InferSent and Universal sentence embeddings  with XGBoost classifier", "labels": [], "entities": []}, {"text": " Table 9: Results for Sub-task C. using InferSent, Uni- versal and ELMo embeddings with XGBoost classifier", "labels": [], "entities": []}]}