{"title": [], "abstractContent": [{"text": "The objective of this paper is to provide a description fora classification system built for SemEval-2019 Task 6: OffensEval.", "labels": [], "entities": [{"text": "SemEval-2019 Task 6", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.782089114189148}]}, {"text": "This system classifies a tweet as either offensive or not offensive (Sub-task A) and further classifies offensive tweets into categories (Sub-tasks B-C).", "labels": [], "entities": []}, {"text": "The system consists of two phases; a brute-force grid search to find the best learners amongst a given set and an ensemble of a subset of these best learners.", "labels": [], "entities": []}, {"text": "The system achieved an F1-score of 0.728, ranking in subtask A, an F1-score score of 0.616 in subtask B and an F1-score of 0.509 in subtask C.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9997192025184631}, {"text": "F1-score score", "start_pos": 67, "end_pos": 81, "type": "METRIC", "confidence": 0.9839825332164764}, {"text": "F1-score", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9994365572929382}]}], "introductionContent": [{"text": "In OffensEval we breakdown offensive content into three sub-tasks taking the type and target of offenses into account.", "labels": [], "entities": []}, {"text": "Sub-task A -Offensive language identification; In this sub-task we are interested in the identification of offensive posts and posts containing any form of (untargeted) profanity.", "labels": [], "entities": [{"text": "Offensive language identification", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.6211984554926554}]}, {"text": "In this sub-task there are 2 categories in which the tweet could be classified Not Offensive -This post does not contain offense or profanity.", "labels": [], "entities": []}, {"text": "Nonoffensive posts do not include any form of offense or profanity.", "labels": [], "entities": []}, {"text": "Sub-task B -Automatic categorization of offense types; In this sub-task we are interested in categorizing offenses.", "labels": [], "entities": []}, {"text": "Tweets are labeled from one of the following categories Targeted Insult -A post containing an insult or a threat to an individual, group, or others; Untargeted -A post containing non-targeted profanity and swearing.", "labels": [], "entities": []}, {"text": "Posts containing general profanity are not targeted but they contain non-acceptable language.", "labels": [], "entities": []}, {"text": "On the other hand, insults and threats are targeted at an individual or group.", "labels": [], "entities": []}, {"text": "Sub-task C -Offense target identification.", "labels": [], "entities": [{"text": "Offense target identification", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.5914691587289175}]}, {"text": "Finally, in sub-task C we are interested in the target of offenses.", "labels": [], "entities": []}, {"text": "Only posts which are either insults or threats are included in this subtask.", "labels": [], "entities": []}, {"text": "The three categories included in sub-task C are the following: Individual -The target of the offensive post is an individual: a famous person, named individual or an unnamed person interacting in the conversation.", "labels": [], "entities": []}, {"text": "Group -The target of the offensive post is a group of people considered as a unity due to the same ethnicity, gender or sexual orientation, political affiliation, religious belief, or something else.", "labels": [], "entities": []}, {"text": "Other The target of the offensive post does not belong to any of the previous two categories (e.g. an organization, a situation, an event, or an issue).( To work with such complicated tasks our approach is an exhaustive one.", "labels": [], "entities": []}, {"text": "We try combinations of many techniques in pre-processing, feature extraction and classification while tuning their hyper-parameters to find the best models with the leading F1-scores.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.810644656419754}, {"text": "F1-scores", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9901111721992493}]}, {"text": "With the gained information an ensemble of the top three models is formed to get the optimum result.", "labels": [], "entities": []}, {"text": "Along side to this approach we try a deep-learning method with a simple 1D -CNN consisting of 3 convolutional layers and a softmax layer just to compare results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Top 3 models for each subtask, these 3 models will form an ensemble to enhance the performance.", "labels": [], "entities": []}, {"text": " Table 4: Results for Sub-task A. The ensemble  approach gave the best results.", "labels": [], "entities": []}, {"text": " Table 5: Results for Sub-task B. The best performer  was a simple TFIDF -Naive Bayes model.", "labels": [], "entities": []}, {"text": " Table 6: Results for Sub-task C. The ensemble got the  best accuracy but, LR got a better F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9994012117385864}, {"text": "F1-score", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9976805448532104}]}]}