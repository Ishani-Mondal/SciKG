{"title": [{"text": "A Question Answering Approach to Emotion Cause Extraction", "labels": [], "entities": [{"text": "Question Answering Approach", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.7751549780368805}, {"text": "Emotion Cause Extraction", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.8512782653172811}]}], "abstractContent": [{"text": "Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text.", "labels": [], "entities": [{"text": "Emotion cause extraction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8111852606137594}]}, {"text": "It is a much more difficult task compared to emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.757465124130249}]}, {"text": "Inspired by recent advances in using deep memory networks for question answering (QA), we propose anew approach which considers emotion cause identification as a reading comprehension task in QA.", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.8367399632930755}, {"text": "emotion cause identification", "start_pos": 128, "end_pos": 156, "type": "TASK", "confidence": 0.6836552023887634}]}, {"text": "Inspired by convolutional neural networks , we propose anew mechanism to store relevant context in different memory slots to model context information.", "labels": [], "entities": []}, {"text": "Our proposed approach can extract both word level sequence features and lexical features.", "labels": [], "entities": []}, {"text": "Performance evaluation shows that our method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 202, "end_pos": 211, "type": "METRIC", "confidence": 0.9930156469345093}]}], "introductionContent": [{"text": "With the rapid growth of social network platforms, more and more people tend to share their experiences and emotions online.", "labels": [], "entities": []}, {"text": "Emotion analysis of online text becomes anew challenge in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Emotion analysis of online text", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9043466925621033}, {"text": "Natural Language Processing (NLP)", "start_pos": 58, "end_pos": 91, "type": "TASK", "confidence": 0.6752991626660029}]}, {"text": "In recent years, studies in emotion analysis largely focus on emotion classification including detection of writers' emotions () as well as readers' emotions (.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7364223003387451}, {"text": "emotion classification", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.7684707939624786}]}, {"text": "There are also some information extraction tasks defined in emotion analysis), such as extracting the feeler of an emotion.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7279607355594635}, {"text": "emotion analysis", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.7537831366062164}, {"text": "extracting the feeler of an emotion", "start_pos": 87, "end_pos": 122, "type": "TASK", "confidence": 0.87585977713267}]}, {"text": "These methods \u2020 Corresponding Author: xuruifeng@hit.edu.cn assume that emotion expressions are already observed.", "labels": [], "entities": []}, {"text": "Sometimes, however, we care more about the stimuli, or the cause of an emotion.", "labels": [], "entities": []}, {"text": "For instance, Samsung wants to know why people love or hate Note 7 rather than the distribution of different emotions.", "labels": [], "entities": []}, {"text": "Ex.1 Ex.1 Because I lost my phone yesterday, I feel sad now.", "labels": [], "entities": []}, {"text": "In an example shown above, \"sad\" is an emotion word, and the cause of \"sad\" is \"I lost my phone\".", "labels": [], "entities": []}, {"text": "The emotion cause extraction task aims to identify the reason behind an emotion expression.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6658281087875366}]}, {"text": "It is a more difficult task compared to emotion classification since it requires a deep understanding of the text that conveys an emotions.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7259826362133026}]}, {"text": "Existing approaches to emotion cause extraction mostly rely on methods typically used in information extraction, such as rule based template matching, sequence labeling and classification based methods.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.834001620610555}, {"text": "information extraction", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.7330691069364548}, {"text": "rule based template matching", "start_pos": 121, "end_pos": 149, "type": "TASK", "confidence": 0.6749867796897888}]}, {"text": "Most of them use linguistic rules or lexicon features, but do not consider the semantic information and ignore the relation between the emotion word and emotion cause.", "labels": [], "entities": []}, {"text": "In this paper, we present anew method for emotion cause extraction.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.7434610724449158}]}, {"text": "We consider emotion cause extraction as a question answering (QA) task.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.761868417263031}, {"text": "question answering (QA) task", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.8229091664155325}]}, {"text": "Given a text containing the description of an event which mayor may not cause a certain emotion, we take an emotion word in context, such as \"sad\", as a query.", "labels": [], "entities": []}, {"text": "The question to the QA system is: \"Does the described event cause the emotion of sadness?\".", "labels": [], "entities": []}, {"text": "The expected answer is either \"yes\" or \"no\".", "labels": [], "entities": []}, {"text": "We build our QA system based on a deep memory network.", "labels": [], "entities": []}, {"text": "The memory network has two inputs: apiece of text, referred to as a story in QA systems, and a query.", "labels": [], "entities": []}, {"text": "The story is represented using a sequence of word embeddings.", "labels": [], "entities": []}, {"text": "A recurrent structure is implemented to mine the deep relation between a query and a text.", "labels": [], "entities": []}, {"text": "It measures the importance of each word in the text by an attention mechanism.", "labels": [], "entities": []}, {"text": "Based on the learned attention result, the network maps the text into a low dimensional vector space.", "labels": [], "entities": []}, {"text": "This vector is then used to generate an answer.", "labels": [], "entities": []}, {"text": "Existing memory network based approaches to QA use weighted sum of attentions to jointly consider short text segments stored in memory.", "labels": [], "entities": [{"text": "QA", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9442762136459351}]}, {"text": "However, they do not explicitly model sequential information in the context.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew deep memory network architecture to model the context of each word simultaneously by multiple memory slots which capture sequential information using convolutional operations, and achieves the state-of-the-art performance compared to existing methods which use manual rules, commonsense knowledge bases or other machine learning models.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a review of related works on emotion analysis.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7421979308128357}]}, {"text": "Section 3 presents our proposed deep memory network based model for emotion cause extraction.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.7343508998552958}]}, {"text": "Section 4 discusses evaluation results.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the work and outlines the future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first presents the experimental settings and then report the results in this section.", "labels": [], "entities": []}, {"text": "We conduct experiments on a simplified Chinese emotion cause corpus () * , the only publicly available dataset on this task to the best of our knowledge.", "labels": [], "entities": []}, {"text": "The corpus contains 2,105 documents from SINA city news \u2020 . Each document has only one emotion word and one or more emotion causes.", "labels": [], "entities": [{"text": "SINA city news \u2020", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.8524792492389679}]}, {"text": "The documents are segmented into clauses manually.", "labels": [], "entities": []}, {"text": "The main task is to identify which clause contains the emotion cause.", "labels": [], "entities": []}, {"text": "Details of the corpus are shown in.", "labels": [], "entities": []}, {"text": "The metrics we used in evaluation follows . It is commonly accepted so that we can compare our results with others.", "labels": [], "entities": []}, {"text": "If a proposed emotion cause clause covers the annotated answer, the word sequence is considered correct.", "labels": [], "entities": []}, {"text": "The precision, recall, and F-measure are defined by In the experiments, we randomly select 90% of the dataset as training data and 10% as testing data.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996101260185242}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.999298095703125}, {"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9995459914207458}]}, {"text": "In order to obtain statistically credible results, we evaluate our method and baseline methods 25 times with different train/test splits.", "labels": [], "entities": []}, {"text": "We compare with the following baseline methods: \u2022 RB (Rule based method): The rule based method proposed in ( ).", "labels": [], "entities": [{"text": "RB", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9898882508277893}]}, {"text": "\u2022 CB (Common-sense based method): This is the knowledge based method proposed by).", "labels": [], "entities": []}, {"text": "We use the Chinese Emotion Cognition Lexicon ( as the common-sense knowledge base.", "labels": [], "entities": [{"text": "Chinese Emotion Cognition Lexicon", "start_pos": 11, "end_pos": 44, "type": "DATASET", "confidence": 0.9079343974590302}]}, {"text": "The lexicon contains more than 5,000 kinds of emotion stimulation and their corresponding reflection words.", "labels": [], "entities": []}, {"text": "\u2022 RB+CB+ML (Machine learning method trained from rule-based features and facts from a common-sense knowledge base): This methods was previously proposed for emotion cause classification in . It takes rules and facts in a knowledge base as features for classifier training.", "labels": [], "entities": [{"text": "RB+CB+ML", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.7318593859672546}, {"text": "emotion cause classification", "start_pos": 157, "end_pos": 185, "type": "TASK", "confidence": 0.6963629126548767}]}, {"text": "We train a SVM using features extracted from the rules defined in ( ) and the Chinese Emotion Cognition Lexicon ().", "labels": [], "entities": [{"text": "Chinese Emotion Cognition Lexicon", "start_pos": 78, "end_pos": 111, "type": "DATASET", "confidence": 0.9218656271696091}]}, {"text": "\u2022  \u2022 Word2vec: This is a SVM classifier using word representations learned by) as features.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8543899357318878}]}, {"text": "\u2022 Multi-kernel: This is the state-of-the-art method using the multi-kernel method to identify the emotion cause.", "labels": [], "entities": []}, {"text": "We use the best performance reported in their paper.", "labels": [], "entities": []}, {"text": "\u2022 CNN: The convolutional neural network for sentence classification).", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.7127613574266434}]}, {"text": "\u2022 Memnet: The deep memory network described in Section 3.2.", "labels": [], "entities": []}, {"text": "Word embeddings are pre-trained by skip-grams.", "labels": [], "entities": []}, {"text": "The number of hops is set to 3.", "labels": [], "entities": []}, {"text": "\u2022 ConvMS-Memnet: The convolutional multiple-slot deep memory network we proposed in Section 3.3.", "labels": [], "entities": []}, {"text": "Word embeddings are pre-trained by skip-grams.", "labels": [], "entities": []}, {"text": "The number of hops is 3 in our experiments.", "labels": [], "entities": []}, {"text": "The rule based RB gives fairly high precision but with low recall.", "labels": [], "entities": [{"text": "RB", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.8972566723823547}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9994428753852844}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9991512298583984}]}, {"text": "CB, the common-sense based method, achieves the highest recall.", "labels": [], "entities": [{"text": "CB", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.8918092250823975}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9992634654045105}]}, {"text": "Yet, its precision is the worst.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.99936443567276}]}, {"text": "RB+CB, the combination of RB and CB gives higher the F-measure But, the improvement of 1.27% is only marginal compared to RB.", "labels": [], "entities": [{"text": "CB", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.6632336974143982}, {"text": "RB", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9831138849258423}, {"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9988662004470825}]}, {"text": "For machine learning methods, RB+CB+ML uses both rules and common-sense knowledge as features to train a machine learning classifier.", "labels": [], "entities": []}, {"text": "It achieves F-measure of 0.5597, outperforming RB+CB.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9996663331985474}, {"text": "RB+CB", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.8732609947522482}]}, {"text": "Both SVM and word2vec are word feature based methods and they have similar performance.", "labels": [], "entities": []}, {"text": "For word2vec, even though word representations are obtained from the SINA news raw corpus, it still performs worse than SVM trained using n-gram features only.", "labels": [], "entities": [{"text": "SINA news raw corpus", "start_pos": 69, "end_pos": 89, "type": "DATASET", "confidence": 0.8703916370868683}]}, {"text": "The multi-kernel method () is the best performer: Comparison of using pre-trained or randomly initialized word embedding.", "labels": [], "entities": []}, {"text": "among the baselines because it considers context information in a structured way.", "labels": [], "entities": []}, {"text": "It models text by its syntactic tree and also considers an emotion lexicon.", "labels": [], "entities": []}, {"text": "Their work shows that the structure information is important for the emotion cause extraction task.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.6916944483915964}]}, {"text": "Naively applying the original deep memory network or convolutional network for emotion cause extraction outperforms all the baselines except the convolutional multi-kernel method.", "labels": [], "entities": [{"text": "emotion cause extraction", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.6853976845741272}]}, {"text": "However, using our proposed ConvMS-Memnet architecture, we manage to boost the performance by 11.54% in precision, 4.84% in recall and 8.24% in Fmeasure respectively when compared to Memnet.", "labels": [], "entities": [{"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9996418952941895}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.999553382396698}, {"text": "Fmeasure", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9830354452133179}]}, {"text": "The improvement is very significant with p-value less than 0.01 in t-test.", "labels": [], "entities": []}, {"text": "The ConvMS-Memnet also outperforms the previous best-performing method, multi-kernel, by 3.01% in F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9760730266571045}]}, {"text": "It shows that by effectively capturing context information, ConvMS-Memnet is able to identify the emotion cause better compared to other methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Details of the dataset.", "labels": [], "entities": []}, {"text": " Table 2: Comparison with existing methods.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of using pre-trained or ran- domly initialized word embedding.", "labels": [], "entities": []}, {"text": " Table 4: Performance with different number of  hops in ConvMS-Memnet.", "labels": [], "entities": []}, {"text": " Table 5: The distribution of attention in different hops.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of word level emotion cause  extraction.", "labels": [], "entities": [{"text": "word level emotion cause  extraction", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.5891970634460449}]}, {"text": " Table 7: The probability of a clause containing the emotion cause in different iterations in the multiple- slot memory network.", "labels": [], "entities": []}]}