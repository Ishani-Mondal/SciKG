{"title": [{"text": "Identifying the Provision of Choices in Privacy Policy Text", "labels": [], "entities": [{"text": "Identifying the Provision of Choices", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7590457439422608}]}], "abstractContent": [{"text": "Websites' and mobile apps' privacy policies , written in natural language, tend to belong and difficult to understand.", "labels": [], "entities": []}, {"text": "Information privacy revolves around the fundamental principle of notice and choice, namely the idea that users should be able to make informed decisions about what information about them can be collected and how it can be used.", "labels": [], "entities": [{"text": "Information privacy", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7718083560466766}]}, {"text": "Internet users want control over their privacy, but their choices are often hidden in long and con-voluted privacy policy documents.", "labels": [], "entities": []}, {"text": "Moreover , little (if any) prior work has been done to detect the provision of choices in text.", "labels": [], "entities": []}, {"text": "We address this challenge of enabling user choice by automatically identifying and extracting pertinent choice language in privacy policies.", "labels": [], "entities": []}, {"text": "In particular, we present a two-stage architecture of classification models to identify opt-out choices in privacy policy text, labelling common varieties of choices with a mean F1 score of 0.735.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9836434423923492}]}, {"text": "Our techniques enable the creation of systems to help Internet users to learn about their choices, thereby effectuating notice and choice and improving In-ternet privacy.", "labels": [], "entities": []}], "introductionContent": [{"text": "Website privacy policies are long, verbose documents that are often difficult to understand.", "labels": [], "entities": []}, {"text": "It has been shown that an average Internet user would require an impractical amount of time to read the privacy policies of online services that they use and would not properly understand them.", "labels": [], "entities": []}, {"text": "Although Internet users are concerned about their privacy and would like to be informed about the privacy controls they can exercise, they are not willing or able to find these choices in policy text.", "labels": [], "entities": []}, {"text": "Choices for privacy controls, which are the most actionable pieces of information in these documents, are frequently \"hidden in plain sight\" among other information.", "labels": [], "entities": []}, {"text": "However, the nature of the text and the vocabulary used to present choices provide us with an opportunity to automatically identify choices, a goal that we focus upon in this paper.", "labels": [], "entities": []}, {"text": "We define a choice instance as a statement in a privacy policy that indicates that the user has discretion over aspects of their privacy.", "labels": [], "entities": []}, {"text": "An example (which notably features a hyperlink) is the following: If you would like more information on how to opt out of information collection practices, go to www.aboutads. info.", "labels": [], "entities": [{"text": "information collection", "start_pos": 122, "end_pos": 144, "type": "TASK", "confidence": 0.7340401709079742}]}, {"text": "Some examples of choices offered to users include opt-outs or controls for the sharing of personal information with third parties, receiving targeted ads, or receiving promotional emails.", "labels": [], "entities": []}, {"text": "Analyzing these choice instances in aggregate will help to understand how notice and choice is implemented in practice, which is of interest to legal scholars, policy makers and regulators.", "labels": [], "entities": []}, {"text": "Furthermore, extracted choice options can be presented to users in more concise and usable notice formats ( , such as a browser plug-in or a privacy based question answering system.", "labels": [], "entities": [{"text": "question answering", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.6758718639612198}]}, {"text": "For this paper, we treat the identification of choice instances as a binary classification problem, in which we label each sentence in the privacy policy text as containing a choice instance or not.", "labels": [], "entities": []}, {"text": "We use the OPP-115 Corpus () for training and evaluation of our models.", "labels": [], "entities": [{"text": "OPP-115 Corpus", "start_pos": 11, "end_pos": 25, "type": "DATASET", "confidence": 0.9002902209758759}]}, {"text": "We further annotate a second dataset 2 and develop a composite model architecture to automatically identify and label different types of opt-out choices offered in privacy policies.", "labels": [], "entities": []}, {"text": "We primarily focus on extracting opt-out instances with hyperlinks because these are some the most common and useful choices described in privacy policies.", "labels": [], "entities": []}, {"text": "Moreover, these choice expressions are actionable: the first step of the action to betaken (i.e., following a hyperlink) is clearly represented in the text of these instances.", "labels": [], "entities": []}, {"text": "The work presented in this paper has been conducted in the context of the 'Usable Privacy Policy' project, which combines crowdsourcing, machine learning and natural language processing to overcome the limitations of today's approach to 'notice and choice' in privacy ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We treated the problem of extracting choice instances as a binary classification problem where we labeled sentences from a privacy policy as containing a choice instance (positive) or not (negative).", "labels": [], "entities": []}, {"text": "We focused specifically on opt-out choices, as they are among the most common choices offered to Internet users and because opting out is notoriously difficult for users ().", "labels": [], "entities": []}, {"text": "All sentences that contained an opt-out user choice (as specified by the OPP-115 annotations) were considered positive, and the rest were considered negative.", "labels": [], "entities": [{"text": "OPP-115 annotations", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.9123699963092804}]}, {"text": "This resulted in a gold standard set of Differences between our problem formulation and the OPP-115 annotation scheme led to the need fora few label adjustments.", "labels": [], "entities": [{"text": "Differences", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.9793282151222229}, {"text": "OPP-115", "start_pos": 92, "end_pos": 99, "type": "DATASET", "confidence": 0.8484690189361572}]}, {"text": "Opt-out text spans which crossed sentence boundaries resulted in positive labels for all involved sentences, although often only one of the sentences in a span was positive.", "labels": [], "entities": []}, {"text": "Additionally, during the OPP-115 annotation procedure, the fact that hyperlinks were not shown to annotators meant that some choice instances were not correctly identified.", "labels": [], "entities": [{"text": "OPP-115 annotation", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.5307538509368896}]}, {"text": "This resulted in noisy labels in our derived dataset.", "labels": [], "entities": []}, {"text": "The unbalanced distribution of the opt-out labels allowed us to manually verify and correct labels in the positive class.", "labels": [], "entities": []}, {"text": "However, correcting errors in the much larger negative class (of 12K instances) was a challenge, since comprehensive manual verification was infeasible.", "labels": [], "entities": []}, {"text": "Instead, we adopted a semi-automated, iterative relabelling approach with active learning.", "labels": [], "entities": []}, {"text": "We randomly divided the dataset into train (70%) and test (30%) sets.", "labels": [], "entities": []}, {"text": "We trained a binary logistic regression classifier using bag of n-gram features on the training data, and then used it to classify the test data.", "labels": [], "entities": []}, {"text": "This was essentially a weak classifier, since it was trained on noisy (unverified) data.", "labels": [], "entities": []}, {"text": "We manually examined the false positives and false negatives as given by this model and relabelled incorrectly labelled instances, thus reducing noise in the dataset.", "labels": [], "entities": []}, {"text": "Performing multiple iterations of this approach, each time with a different train and test set, resulted in a much cleaner dataset.", "labels": [], "entities": []}, {"text": "Following this refinement, the model F1 scores improved and were also more accurate.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9739003479480743}, {"text": "accurate", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9903924465179443}]}, {"text": "For all our experiments thereon, we used this refined version of the dataset for training and evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of different annotation types.", "labels": [], "entities": []}, {"text": " Table 2: Results of ablation tests for the coarse- grained classifier.", "labels": [], "entities": []}, {"text": " Table 3: Fine-grained classifier results.", "labels": [], "entities": []}]}