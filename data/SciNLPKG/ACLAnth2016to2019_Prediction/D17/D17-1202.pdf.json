{"title": [{"text": "Shortest-Path Graph Kernels for Document Similarity", "labels": [], "entities": [{"text": "Document Similarity", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7823367416858673}]}], "abstractContent": [{"text": "In this paper, we present a novel document similarity measure based on the definition of a graph kernel between pairs of documents.", "labels": [], "entities": []}, {"text": "The proposed measure takes into account both the terms contained in the documents and the relationships between them.", "labels": [], "entities": []}, {"text": "By representing each document as a graph-of-words, we are able to model these relationships and then determine how similar two documents are by using a modified shortest-path graph kernel.", "labels": [], "entities": []}, {"text": "We evaluate our approach on two tasks and compare it against several baseline approaches using various performance metrics such as DET curves and macro-average F1-score.", "labels": [], "entities": [{"text": "DET", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.919601321220398}, {"text": "F1-score", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9295935034751892}]}, {"text": "Experimental results on a range of datasets showed that our proposed approach outperforms traditional techniques and is capable of measuring more accurately the similarity between two documents.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, we have witnessed a tremendous growth in the volume of textual documents available on the Web.", "labels": [], "entities": []}, {"text": "With this rapid increase in the number of available content, new opportunities for knowledge extraction have arisen.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.8257993757724762}]}, {"text": "Many text mining tasks such as information retrieval, text categorization and document clustering involve the direct comparison of two documents.", "labels": [], "entities": [{"text": "text mining", "start_pos": 5, "end_pos": 16, "type": "TASK", "confidence": 0.7581238448619843}, {"text": "information retrieval", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.7804418802261353}, {"text": "text categorization", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7408111393451691}, {"text": "document clustering", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.6841177046298981}]}, {"text": "It is thus crucial to be able to determine accurately how similar two documents are by defining a document similarity measure.", "labels": [], "entities": []}, {"text": "Generally speaking, a similarity measure is a real-valued function that quantifies the common information shared by two objects (in our case documents).", "labels": [], "entities": []}, {"text": "Determining the similarity between two documents is not a trivial task.", "labels": [], "entities": [{"text": "Determining the similarity between two documents", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8215272128582001}]}, {"text": "Whether two documents are similar or different is not always clear and may vary from application to application.", "labels": [], "entities": []}, {"text": "Similarity measures that make use of the vectorspace model () treat words in a document as if they were independent of one another, which is not realistic.", "labels": [], "entities": []}, {"text": "In fact, words relate to one another to form meaningful phrases and to develop ideas.", "labels": [], "entities": []}, {"text": "It is known that the human brain utilizes these relations between words to facilitate understanding (.", "labels": [], "entities": []}, {"text": "In general, we assume that two terms are related if they co-occur together in a small context, typically a phrase or a window of specific size, which resulted in n-gram features in many text mining tasks (an n-gram is a sequence of n terms in this paper).", "labels": [], "entities": [{"text": "text mining tasks", "start_pos": 186, "end_pos": 203, "type": "TASK", "confidence": 0.8211970527966818}]}, {"text": "But n-grams correspond to sequences of words and thus fail to capture word inversion and subset matching (e. g., \"article about news\" vs. \"news article\").", "labels": [], "entities": []}, {"text": "To take into account these statistical relations, we propose to represent each document as a graph-of-words instead.", "labels": [], "entities": []}, {"text": "And then, in order to measure the similarity between two documents, we capitalize on recent advances in graph kernels.", "labels": [], "entities": []}, {"text": "Kernels can bethought of as measures of similarity between pairs of objects (.", "labels": [], "entities": []}, {"text": "A graph kernel is a kernel function that measures the similarity between pairs of graphs.", "labels": [], "entities": []}, {"text": "Our aim in this paper is neither to define a similarity measure for only a certain category of documents based on background knowledge and features specific to that field nor to improve similarity estimation by using external knowledge.", "labels": [], "entities": [{"text": "similarity estimation", "start_pos": 186, "end_pos": 207, "type": "TASK", "confidence": 0.6724797785282135}]}, {"text": "In-stead, we propose to define a similarity measure that does not incorporate any background or external knowledge.", "labels": [], "entities": []}, {"text": "Hence it is, without changes, applicable to all types of textual documents even if they come from different areas.", "labels": [], "entities": []}, {"text": "The method takes as input a pair of documents and automatically computes how similar they are to each other based solely on their content.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of the related work and elaborates our contribution.", "labels": [], "entities": []}, {"text": "Section 3 provides a detailed description of our proposed graphof-words kernel.", "labels": [], "entities": []}, {"text": "Section 4 evaluates the proposed approach on a wide range of tasks.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes the work and presents potential future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the experiments we conducted to evaluate and validate our proposed kernel between documents.", "labels": [], "entities": []}, {"text": "To assess the effectiveness of the different approaches, we employed a set of well-known evaluation metrics inherited from Information Retrieval: accuracy, macro-average F1-score and for the story link detection task DET curves ().", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.7614644765853882}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9994662404060364}, {"text": "F1-score", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9252972602844238}, {"text": "story link detection task DET", "start_pos": 191, "end_pos": 220, "type": "TASK", "confidence": 0.787010395526886}]}, {"text": "The DET curve is a variant of the ROC curve that plots the missed detection probability (P miss = f n /(tp+fn)) versus the false alarm probability (P fa = f p /(tn+fp)) for various system operating points, which allows someone to get a greater insight into the effectiveness of the evaluated approaches.", "labels": [], "entities": [{"text": "missed detection probability (P miss = f n", "start_pos": 59, "end_pos": 101, "type": "METRIC", "confidence": 0.7712740533881717}, {"text": "false alarm probability", "start_pos": 123, "end_pos": 146, "type": "METRIC", "confidence": 0.9133970141410828}]}, {"text": "A method is considered to perform best at thresholds that correspond to points that are close to the lower-left of the graph (i. e. lower error probabilities) and the area under the curve should be minimal.", "labels": [], "entities": []}, {"text": "For the story link detection experiments, we also computed the normalized C Det costs, the: Summary of the 5 datasets that were used in our text categorization experiments.", "labels": [], "entities": [{"text": "story link detection", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.6359572410583496}, {"text": "normalized C Det costs", "start_pos": 63, "end_pos": 85, "type": "METRIC", "confidence": 0.7246111407876015}, {"text": "Summary", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9942036271095276}]}, {"text": "standard performance measure of TDT as described in ().", "labels": [], "entities": [{"text": "TDT", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9210274815559387}]}, {"text": "We evaluate the SPGK and the baselines on 5 standard datasets for text categorization: (1) WebKB: Web pages collected from Computer Science departments of various Universities manually classified into 7 categories (we removed Web pages that belong to the classes \"staff\", \"department\" and \"other\") (.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7480098009109497}]}, {"text": "shows statistics of the datasets that were used for the evaluation.", "labels": [], "entities": []}, {"text": "For the Story Link Detection task, we employed the TDT-5 corpus that contains stories from various newswire sources ().", "labels": [], "entities": [{"text": "Story Link Detection", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7973579367001852}, {"text": "TDT-5 corpus", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.9859571158885956}]}, {"text": "We only used the English part of the dataset for our experiments consisting of 221, 306 documents.", "labels": [], "entities": [{"text": "English part of the dataset", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.6762724339962005}]}, {"text": "WebKB News Subjectivity Amazon Polarity Accuracy F1-score Accuracy F1-score Accuracy F1-score Accuracy F1-score Accuracy F1-score: Performance of the 6 approaches in text categorization.", "labels": [], "entities": [{"text": "WebKB News Subjectivity Amazon Polarity Accuracy F1-score Accuracy F1-score Accuracy F1-score Accuracy F1-score Accuracy F1-score", "start_pos": 0, "end_pos": 129, "type": "METRIC", "confidence": 0.770915949344635}]}, {"text": "* indicates statistical significance inaccuracy improvement at p < 0.05 using the micro sign test against the Cosine (n = 2) baseline of the same column.", "labels": [], "entities": [{"text": "micro sign test", "start_pos": 82, "end_pos": 97, "type": "METRIC", "confidence": 0.8592217763264974}]}, {"text": "> 1 day indicates that the computation did not finish after 1 day.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of the 5 datasets that were used in our text categorization experiments.", "labels": [], "entities": []}, {"text": " Table 2: Performance of the 6 approaches in text categorization. * indicates statistical significance in  accuracy improvement at p < 0.05 using the micro sign test against the Cosine (n = 2) baseline of the  same column. > 1 day indicates that the computation did not finish after 1 day.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9986087679862976}]}, {"text": " Table 3: Performance of all similarity measures in  story link detection.", "labels": [], "entities": [{"text": "story link detection", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7537733117739359}]}]}