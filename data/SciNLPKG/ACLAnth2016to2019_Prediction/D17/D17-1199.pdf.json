{"title": [{"text": "Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones", "labels": [], "entities": []}], "abstractContent": [{"text": "Syllabification does not seem to improve word-level RNN language model-ing quality when compared to character-based segmentation.", "labels": [], "entities": []}, {"text": "However, our best syllable-aware language model, achieving performance comparable to the competitive character-aware model, has 18%-33% fewer parameters and is trained 1.2-2.2 times faster.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent advances in neural language modeling (NLM) are connected with character-aware models (.", "labels": [], "entities": [{"text": "neural language modeling (NLM)", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.8543790181477865}]}, {"text": "This is a promising approach, and we propose the following direction related to it: We would like to make sure that in the pursuit of the most fine-grained representations one has not missed possible intermediate ways of segmentation, e.g., by syllables.", "labels": [], "entities": []}, {"text": "Syllables, in our opinion, are better supported as linguistic units of language than single characters.", "labels": [], "entities": []}, {"text": "In most languages, words can be naturally split into syllables: ES: el par-la-men-to a-po-y\u00f3 la en-mien-da RU: \u043f\u0430\u0440-\u043b\u0430-\u043c\u0435\u043d\u0442 \u043f\u043e\u0434-\u0434\u0435\u0440-\u0436\u0430\u043b \u043f\u043e-\u043f\u0440\u0430\u0432-\u043a\u0443 (EN: the parliament supported the amendment) Based on this observation, we attempted to determine whether syllable-aware NLM has any advantages over character-aware NLM.", "labels": [], "entities": []}, {"text": "We experimented with a variety of models but could not find any evidence to support this hypothesis: splitting words into syllables does not seem to improve the language modeling quality when compared to splitting into characters.", "labels": [], "entities": []}, {"text": "However, there are some positive findings: while our best syllable-aware language model achieves performance comparable to the competitive character-aware model, it has 18%-33% fewer parameters and is 1.2-2.2 times faster to train.", "labels": [], "entities": []}], "datasetContent": [{"text": "We search for the best model in two steps: first, we block the word-level LSTM's architecture and pre-select the three best models under a small parameter budget (5M), and then we tune these three best models' hyperparameters under a larger budget (20M).", "labels": [], "entities": []}, {"text": "Pre-selection: We fix d LM (hidden layer size of the word-level LSTM) at 300 units per layer and run each syllable-aware word embedding method from Section 3 on the English PTB data set, keeping the total parameter budget at 5M.", "labels": [], "entities": [{"text": "English PTB data set", "start_pos": 165, "end_pos": 185, "type": "DATASET", "confidence": 0.9055462926626205}]}, {"text": "The architectural choices are specified in Appendix A. Hyperparameter tuning: The hyperparameters of the three best-performing models from the preselection step are then thoroughly tuned on the same English PTB data through a random search according to the marginal distributions:), with the restriction d S < d LM . The total parameter budget is kept at 20M to allow for easy comparison to the results of.", "labels": [], "entities": [{"text": "English PTB data", "start_pos": 199, "end_pos": 215, "type": "DATASET", "confidence": 0.6601308683554331}]}, {"text": "Then these three best models (with their hyperparameters tuned on PTB) are trained and evaluated on small-(DATA-S) and medium-sized (DATA-L) data sets in six languages.", "labels": [], "entities": [{"text": "PTB", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.7348484992980957}, {"text": "DATA-L) data sets", "start_pos": 133, "end_pos": 150, "type": "DATASET", "confidence": 0.741292767226696}]}, {"text": "Optimizaton is performed in almost the same way as in the work of", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pre-selection results. PPL stands for test  set perplexity, all models have \u2248 5M parameters.", "labels": [], "entities": []}, {"text": " Table 2: Hyperparameters tuning. In Syl-CNN,  d HW is a function of the primary hyperparameter  c = 195 (see Appendix A).", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of the syllable-aware mod- els against Char-CNN. In each case the smallest  model, Syl-Concat, has 18%-33% less parameters  than Char-CNN and is trained 1.2-2.2 times faster  (Appendix C).", "labels": [], "entities": [{"text": "Appendix", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9891372323036194}]}, {"text": " Table 4: Number of principle components when  PCA is applied to word embeddings produced by  each model, depending on % of variance to retain.", "labels": [], "entities": []}, {"text": " Table 5: Replacing LSTM with Variational RHN.", "labels": [], "entities": [{"text": "Replacing LSTM", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7550154626369476}, {"text": "RHN", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.5276544094085693}]}, {"text": " Table 6. Mod- els were implemented in TensorFlow, and were run  on NVIDIA Titan X (Pascal).", "labels": [], "entities": []}]}