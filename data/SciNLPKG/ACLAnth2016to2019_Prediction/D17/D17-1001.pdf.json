{"title": [{"text": "Monolingual Phrase Alignment on Parse Forests", "labels": [], "entities": [{"text": "Monolingual Phrase Alignment", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7797192533810934}, {"text": "Parse Forests", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.7565033733844757}]}], "abstractContent": [{"text": "We propose an efficient method to conduct phrase alignment on parse forests for paraphrase detection.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.8148816227912903}, {"text": "paraphrase detection", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.9432525336742401}]}, {"text": "Unlike previous studies, our method identifies syntactic paraphrases under linguistically motivated grammar.", "labels": [], "entities": []}, {"text": "In addition, it allows phrases to non-compositionally align to handle paraphrases with non-homographic phrase correspondences.", "labels": [], "entities": []}, {"text": "A dataset that provides gold parse trees and their phrase alignments is created.", "labels": [], "entities": []}, {"text": "The experimental results confirm that the proposed method conducts highly accurate phrase alignment compared to human performance.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.8796229958534241}]}], "introductionContent": [{"text": "Paraphrase detection is crucial in various applications, which has been actively studied for years.", "labels": [], "entities": [{"text": "Paraphrase detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8825656771659851}]}, {"text": "Due to difficulties caused by the non-homographic nature of phrase correspondences, the units of correspondence in previous studies are defined as sequences of words like in ( and not syntactic phrases.", "labels": [], "entities": []}, {"text": "On the other hand, syntactic structures are important in modeling sentences, e.g., their sentiments and semantic similarities (.", "labels": [], "entities": []}, {"text": "In this paper, we present an algorithm to align syntactic phrases in a paraphrased pair of sentences.", "labels": [], "entities": []}, {"text": "We show that (1) the problem of identifying a legitimate set of syntactic paraphrases under linguistically motivated grammar is formalized, (2) dynamic programing a la CKY) makes phrase alignment computationally feasible, (3) alignment quality of phrases can be improved using n-best parse forests instead of 1-best trees, and (4) noncompositional alignment allows non-homographic correspondences of phrases.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 179, "end_pos": 195, "type": "TASK", "confidence": 0.8274335861206055}]}, {"text": "Motivated by recent Source: Whenever I go to the ground floor fora smoke, I always come face to face with them.", "labels": [], "entities": []}, {"text": "Target: Whenever I go down to smoke a cigarette, I come face to face with one of them.", "labels": [], "entities": []}, {"text": "findings that syntax is important for phrase embedding () in which phrasal paraphrases allow semantic similarity to be replicated (, we focus on the syntactic paraphrase alignment.", "labels": [], "entities": [{"text": "phrase embedding", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7709087133407593}]}, {"text": "shows areal example of phrase alignments produced by our method.", "labels": [], "entities": [{"text": "phrase alignments", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7258379310369492}]}, {"text": "Alignment proceeds in a bottom-up manner using the compositional nature of phrase alignments.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9727733731269836}]}, {"text": "First, word alignments are given.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 7, "end_pos": 22, "type": "TASK", "confidence": 0.7436562478542328}]}, {"text": "Then, phrase alignments are recursively identified by supporting relations between phrase pairs.", "labels": [], "entities": [{"text": "phrase alignments", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.7366130948066711}]}, {"text": "Non-compositional alignment is triggered when the compositionality is violated, which is common in paraphrasing.", "labels": [], "entities": []}, {"text": "For systematic research on syntactic phrase alignment in paraphrases, we constructed a gold standard dataset of paraphrase sentences with phrase alignment (20, 678 phrases in 201 paraphrasal sentences).", "labels": [], "entities": [{"text": "syntactic phrase alignment", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.6751976211865743}, {"text": "phrase alignment", "start_pos": 138, "end_pos": 154, "type": "TASK", "confidence": 0.7007616013288498}]}, {"text": "This dataset will be made public for future research on paraphrase alignment.", "labels": [], "entities": [{"text": "paraphrase alignment", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.9556707143783569}]}, {"text": "The experiment results show that our method achieves 83.64% and 78.91% in recall and precision in terms of alignment pairs, which are 92% and 89% of human performance, respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9995841383934021}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9880861043930054}]}], "datasetContent": [{"text": "2, previous studies have not conducted syntactic phrase alignment on parse trees.", "labels": [], "entities": [{"text": "syntactic phrase alignment", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.623768150806427}]}, {"text": "A direct metric does not exist to compare paraphrases that cover different spans, i.e., our syntactic paraphrases and paraphrases of n-grams.", "labels": [], "entities": []}, {"text": "Thus, we compared the alignment quality to that of humans as a realistic way to evaluate the performance of our method.", "labels": [], "entities": []}, {"text": "We also evaluated the parsing quality.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9767308235168457}]}, {"text": "Similar to the alignment quality, differences in phrase structures disturb the comparisons (.", "labels": [], "entities": []}, {"text": "Our method applies an HPSG parser Enju (  to derive parse forests due to its state-of-the-art performance and ability to provide rich properties of phrases.", "labels": [], "entities": [{"text": "HPSG parser Enju", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.6674105922381083}]}, {"text": "Hence, we compared our parsing quality to the 1-best parses of Enju.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9530506730079651}]}, {"text": "Alignment Quality Alignment quality was evaluated by measuring the extent that the automatic alignment results agree with those of humans.", "labels": [], "entities": [{"text": "Alignment Quality Alignment", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7945325573285421}]}, {"text": "Specifically, we evaluated how goldalignments can be replicated by automatic alignment (called recall) and how automatic alignments overlap with alignments that at least an annotator aligned (called precision) as: where Ha is a set of alignments, while G and G are the ones that two of annotators produce, respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9948433637619019}, {"text": "precision", "start_pos": 199, "end_pos": 208, "type": "METRIC", "confidence": 0.9976488947868347}]}, {"text": "The function of | \u00b7 | counts the elements in a set.", "labels": [], "entities": []}, {"text": "There are three combinations for G and G because we had three annotators.", "labels": [], "entities": []}, {"text": "The final precision and recall values are their averages.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9749318361282349}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9988610744476318}]}, {"text": "Parsing Quality The parsing quality was evaluated using the CONLL-X () standard.", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9719820022583008}, {"text": "CONLL-X", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9238377213478088}]}, {"text": "Dependencies were extracted from the output HPSG trees, and evaluated using the official script 6 . Due to this conversion, the accuracy on the relation labels is less important.", "labels": [], "entities": [{"text": "HPSG trees", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.9384762942790985}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9991776347160339}]}, {"text": "Thus, we reported only the unlabeled attachment score (UAS) . The development and test sets provide 2, 371 and 6, 957 dependencies, respectively.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 27, "end_pos": 59, "type": "METRIC", "confidence": 0.8006199300289154}]}, {"text": "Roles of hyper-parameters \u00b5 n Control penalty for null-alignment \u00b5 c Control penalty for non-compositional alignment \u00b5 p Balance alignment and parsing prob.", "labels": [], "entities": [{"text": "Balance alignment", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.757360428571701}]}, {"text": "\u00b5 b Beam size at alignment \u00b5 g Generation gap to reach an LCA  Since all metrics were computed in a set, the approximate randomization) (B = 10K) was used for significance testing.", "labels": [], "entities": [{"text": "B", "start_pos": 137, "end_pos": 138, "type": "METRIC", "confidence": 0.9719371795654297}]}, {"text": "It has been shown to be more conservative than using bootstrap resampling ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of the hyper-parameters", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results on the test set, where  *   represents p-value < 0.05 against our method.", "labels": [], "entities": []}]}