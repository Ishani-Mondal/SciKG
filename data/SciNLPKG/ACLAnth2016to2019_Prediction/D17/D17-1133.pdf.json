{"title": [{"text": "Learning Contextually Informed Representations for Linear-Time Discourse Parsing", "labels": [], "entities": [{"text": "Learning Contextually Informed Representations for Linear-Time Discourse Parsing", "start_pos": 0, "end_pos": 80, "type": "TASK", "confidence": 0.6237649731338024}]}], "abstractContent": [{"text": "Recent advances in RST discourse parsing have focused on two modeling paradigms: (a) high order parsers which jointly predict the tree structure of the discourse and the relations it encodes; or (b) linear-time parsers which are efficient but mostly based on local features.", "labels": [], "entities": [{"text": "RST discourse parsing", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.9276915391286215}]}, {"text": "In this work, we propose a linear-time parser with a novel way of representing discourse constituents based on neural networks which takes into account global contextual information and is able to capture long-distance dependencies.", "labels": [], "entities": []}, {"text": "Experimental results show that our parser obtains state-of-the art performance on benchmark datasets, while being efficient (with time complexity linear in the number of sentences in the document) and requiring minimal feature engineering.", "labels": [], "entities": []}], "introductionContent": [{"text": "The computational treatment of discourse phenomena has recently attracted much attention, due to their increasing importance for potential applications.", "labels": [], "entities": [{"text": "computational treatment of discourse phenomena", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.8592071890830993}]}, {"text": "Knowing how text units can be composed into a coherent document and how they relate to each other e.g., whether they express contrast, cause, or elaboration, can usefully aid downstream tasks such summarization (), question answering (, and sentiment analysis.", "labels": [], "entities": [{"text": "summarization", "start_pos": 197, "end_pos": 210, "type": "TASK", "confidence": 0.9921924471855164}, {"text": "question answering", "start_pos": 215, "end_pos": 233, "type": "TASK", "confidence": 0.9125181138515472}, {"text": "sentiment analysis", "start_pos": 241, "end_pos": 259, "type": "TASK", "confidence": 0.9623440802097321}]}, {"text": "Rhetorical Structure Theory (RST,, one of the most influential frameworks in discourse processing, represents texts by trees whose leaves correspond to Elementary Discourse Units (EDUs) and whose nodes specify how these and larger units (e.g., multisentence segments) are linked to each other by rhetorical relations.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8169082522392273}]}, {"text": "Discourse units are further Figure 1: Example text (bottom) composed of two sentences (three EDUs) and its RST discourse tree representation (top).", "labels": [], "entities": []}, {"text": "characterized in terms of their importance in text: nuclei denote central segments, whereas satellites denote peripheral ones.", "labels": [], "entities": []}, {"text": "shows an example of a discourse tree representing two sentences with three EDUs (e 1 , e 2 , and e 3 ).", "labels": [], "entities": []}, {"text": "EDUs e 1 and e 2 are connected with a mononuclear relation (i.e., Consequence), where e 1 is the nucleus and e 2 the satellite (indicated by the left pointing arrow in the.", "labels": [], "entities": []}, {"text": "Span e 1:2 is related toe 3 via List, a multi-nuclear relation, expressing the fact that both spans are equally important and therefore both nucleus.", "labels": [], "entities": []}, {"text": "Given such tree-based representations of discourse structure, it is not surprising that RST-style document analysis is often viewed as a parsing task.", "labels": [], "entities": [{"text": "RST-style document analysis", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.9259995420773824}]}, {"text": "State-of-the-art performance on RST parsing is achieved by cubic-time parsers, with O(n 3 ) time complexity (where n denotes the number of sen-tences in the document).", "labels": [], "entities": [{"text": "RST parsing", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.9518470466136932}, {"text": "O(n 3 ) time complexity", "start_pos": 84, "end_pos": 107, "type": "METRIC", "confidence": 0.9075272509029934}]}, {"text": "These systems model the relations between all possible adjacent discourse segments and use a CKY-style algorithm to generate a global optimal tree.", "labels": [], "entities": []}, {"text": "The high order complexity renders such parsers inefficient in practice, especially when processing large documents.", "labels": [], "entities": []}, {"text": "As a result, more efficient linear-time discourse parsers have been proposed) which make local decisions and model the structure of the discourse and its relations separately.", "labels": [], "entities": []}, {"text": "In this case, features are extracted from a local context (i.e., a small window of discourse constituents) without considering document-level information, which has been previously found useful in discourse analysis.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 197, "end_pos": 215, "type": "TASK", "confidence": 0.7113085240125656}]}, {"text": "In this paper, we propose a simple and efficient linear-time discourse parser with a novel way of learning contextual representations for discourse constituents.", "labels": [], "entities": [{"text": "discourse parser", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7122383415699005}]}, {"text": "To guarantee linear-time complexity, we use a two-stage approach: we first parse each sentence in a document into a tree whose leaves correspond to EDUs, and then parse the document into a tree whose leaves correspond to already preprocessed sentences.", "labels": [], "entities": []}, {"text": "The feature learning process for both stages is based on neural network models.", "labels": [], "entities": []}, {"text": "At the sentence level, Long-Short Term Memory Networks (LSTMs; Hochreiter and Schmidhuber 1997) learn representations for EDUs and larger constituents, whereas at the document level, LSTMs learn representations for entire sentences.", "labels": [], "entities": []}, {"text": "Treating a sentence as a sequence of EDUs and a document as a sequence of sentences allows to incorporate important contextual information on both levels capturing long-distance dependencies.", "labels": [], "entities": []}, {"text": "Recurrent neural networks excel at modeling sequences, but cannot capture hierarchical structure which is important when analyzing multisentential discourse.", "labels": [], "entities": []}, {"text": "We therefore adopt a more structure-aware representation at the document level which we argue is complementary to the flat representations obtained from the LSTM.", "labels": [], "entities": []}, {"text": "We represent documents as trees using recursive neural networks.", "labels": [], "entities": []}, {"text": "Experimental evaluation on the RST Treebank shows that our parser yields comparable performance to previous lineartime systems, without requiring extensive manual feature engineering and improves upon related neural models () on discourse relation classification, while being more efficient.", "labels": [], "entities": [{"text": "RST Treebank", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.8211256563663483}, {"text": "discourse relation classification", "start_pos": 229, "end_pos": 262, "type": "TASK", "confidence": 0.6468839546044668}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We overview related work in the following section.", "labels": [], "entities": []}, {"text": "We describe the general flow of our parser in Section 3 and provide details on our parsing algorithm and feature learning method in Section 4.", "labels": [], "entities": []}, {"text": "Experimental results are reported in Section 5.", "labels": [], "entities": []}, {"text": "Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our experimental setup for assessing the performance of the discourse parser described above.", "labels": [], "entities": []}, {"text": "We give details on the datasets we used, evaluation protocol, and model training.", "labels": [], "entities": []}, {"text": "Evaluation We evaluated our model on the RST Discourse Treebank (RST-DT;, which is partitioned into 347 documents for training and 38 documents for testing.", "labels": [], "entities": [{"text": "RST Discourse Treebank (RST-DT;", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.7761745353539785}]}, {"text": "Following previous work, we converted non-binary relations into a cascade of right-branching binary relations.", "labels": [], "entities": []}, {"text": "Predicted RST-trees are typically evaluated by computing F1 against gold standard trees).", "labels": [], "entities": [{"text": "RST-trees", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.8058372139930725}, {"text": "F1", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9933974742889404}]}, {"text": "Evaluation metrics for RST-style discourse parsing include: (a) span (S) which measures whether the predicted subtrees match the goldstandard; (b) nucleus (N) which measures whether subtrees have the same nucleus as in the goldstandard and (c) relation (R) which measures whether discourse relations have been identified correctly.", "labels": [], "entities": [{"text": "RST-style discourse parsing", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.9248276948928833}, {"text": "span", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.979375422000885}]}, {"text": "The three metrics are interdependent, errors on the span metric propagate to the nuclearity metric, and in turn to the relation metric.", "labels": [], "entities": []}, {"text": "Following other RST-style discourse parsing systems (Hernault et al., 2010), we evaluate the relation metric using 18 coarse-grained relation classes, and with nuclearity attached, we have a total of 41 distinct relations.", "labels": [], "entities": [{"text": "RST-style discourse parsing", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.9171155095100403}]}, {"text": "Since EDU segmentation falls outside the scope of this work, we evaluate our system on gold-standard EDUs.", "labels": [], "entities": [{"text": "EDU segmentation", "start_pos": 6, "end_pos": 22, "type": "TASK", "confidence": 0.8289593160152435}]}, {"text": "Comparison systems are also assessed in the same setting.", "labels": [], "entities": []}, {"text": "Training Details Word embeddings were pretrained with the Gensim 2 implementation of word2vec () on the English GigaWord corpus (with case left intact).", "labels": [], "entities": [{"text": "English GigaWord corpus", "start_pos": 104, "end_pos": 127, "type": "DATASET", "confidence": 0.7176483472188314}]}, {"text": "The dimensionality of the word embeddings was set to 50.", "labels": [], "entities": []}, {"text": "Following, the embeddings were fine-tuned using a mapping matrix WW W \u2208 R 50\u00d750 trained with the following criterion: where LL LT T T tuned , and LL LT T T pre are lookup tables for fine-tuned and pre-trained word embeddings in the training set.", "labels": [], "entities": []}, {"text": "Matrix W can be subsequently used to to estimate fine-tuned embeddings for words in the test set.", "labels": [], "entities": []}, {"text": "Tokenization, POS tagging and sentence splitting were performed using the Stanford: CIDER performance using different constituent representations (RST-DT test set).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.870858371257782}, {"text": "sentence splitting", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7881139814853668}, {"text": "Stanford: CIDER performance", "start_pos": 74, "end_pos": 101, "type": "DATASET", "confidence": 0.901353731751442}, {"text": "RST-DT test set", "start_pos": 147, "end_pos": 162, "type": "DATASET", "confidence": 0.7522720396518707}]}, {"text": "All neural network parameters were initialized randomly with Xavier's initialization.", "labels": [], "entities": []}, {"text": "The hyper-parameters are tuned by crossvalidation on the training set.", "labels": [], "entities": []}, {"text": "Additional Features Most existing state-of-theart systems rely heavily on handcrafted features) some of which have been also proved helpful in neural network models (.", "labels": [], "entities": []}, {"text": "In our experiments, we use the following basic features which have been widely adopted in various discourse parsing models: (1) the first three words and the last two words of each constituent; (2) the POS tags of the first three words and the last two words of each constituent; (3) the number of EDUs; and (4) the number of tokens of each constituent.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7333941459655762}]}, {"text": "We concatenate these features with the constituent vectors learned by our neural networks, and train new CRF models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: CIDER performance using different con- stituent representations (RST-DT test set).", "labels": [], "entities": [{"text": "RST-DT test set", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.7521408994992574}]}, {"text": " Table 2: Comparison with state-of-the-art system- s (RST-DT test set). Speed indicates the average  number seconds taken to parse a document.", "labels": [], "entities": [{"text": "RST-DT test set", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.750241200129191}, {"text": "Speed", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9707732796669006}]}]}