{"title": [{"text": "Towards Automatic Construction of News Overview Articles by News Synthesis", "labels": [], "entities": [{"text": "Automatic Construction of News Overview", "start_pos": 8, "end_pos": 47, "type": "TASK", "confidence": 0.7318145275115967}]}], "abstractContent": [{"text": "In this paper we investigate anew task of automatically constructing an overview article from a given set of news articles about a news event.", "labels": [], "entities": []}, {"text": "We propose a news synthesis approach to address this task based on passage segmentation, ranking , selection and merging.", "labels": [], "entities": [{"text": "news synthesis", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.679029181599617}, {"text": "passage segmentation", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.8296740055084229}]}, {"text": "Our proposed approach is compared with several typical multi-document summarization methods on the Wikinews dataset, and achieves the best performance on both automatic evaluation and manual evaluation.", "labels": [], "entities": [{"text": "Wikinews dataset", "start_pos": 99, "end_pos": 115, "type": "DATASET", "confidence": 0.9549881517887115}]}], "introductionContent": [{"text": "There are usually many news articles about a news event, and news summaries can be used for readers to quickly learn the most salient information of the news articles.", "labels": [], "entities": []}, {"text": "News summaries in previous studies are usually very short, and most of them consist of about one or two hundred words.", "labels": [], "entities": [{"text": "News summaries", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.663504958152771}]}, {"text": "However, in many circumstances, readers want to learn more about an event, but the news summary is insufficient to read, and people are reluctant to read each news article one by one.", "labels": [], "entities": []}, {"text": "A possible solution to this problem is constructing along and comprehensive news overview article to summarize and present all important facts about the news event in an unbiased way.", "labels": [], "entities": []}, {"text": "The news overview articles can be considered long summaries, however, news overview articles are more comprehensive and the article texts are harder to arrange and organize.", "labels": [], "entities": []}, {"text": "In this paper, we conduct a pilot study to investigate the new task of automatic construction of a news overview article from a set of news articles about an event.", "labels": [], "entities": [{"text": "automatic construction of a news overview article from a set of news articles about an event", "start_pos": 71, "end_pos": 163, "type": "TASK", "confidence": 0.8333475142717361}]}, {"text": "We argue that traditional multidocument summarization methods can be applied to this task, but they do not perform well because sentence-based extraction used in these methods is not suitable for constructing and organizing along article.", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.5736766159534454}, {"text": "sentence-based extraction", "start_pos": 128, "end_pos": 153, "type": "TASK", "confidence": 0.7184455841779709}]}, {"text": "Instead, we propose a news synthesis approach to address this task.", "labels": [], "entities": [{"text": "news synthesis", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7460314631462097}]}, {"text": "Our approach uses passage as the basic unit.", "labels": [], "entities": []}, {"text": "In this study, passage does not mean a natural paragraph, but means a block of text (maybe multiple paragraphs) about a subtopic of an event.", "labels": [], "entities": []}, {"text": "Our approach first segments news articles into passages with the SenTiling algorithm, and then ranks the passages with the DivRank algorithm.", "labels": [], "entities": []}, {"text": "Finally, it selects and merges a few passages to construct the long news overview article.", "labels": [], "entities": [{"text": "long news overview article", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.5874164551496506}]}, {"text": "We automatically build an evaluation dataset based on English Wikinews 1 . Most Wikinews articles are synthesis articles and they are written using information from other online news sources.", "labels": [], "entities": []}, {"text": "All the important facts available from all sources about a news event are combined into a single article for the reader's convenience, and the information is presented in a neutral manner avoiding the bias that maybe present in other news sources.", "labels": [], "entities": []}, {"text": "Therefore, we treat a Wikinews article as an ideal overview article (i.e., reference) of the source news articles.", "labels": [], "entities": []}, {"text": "We compare our proposed approach with several typical multi-document summarization methods based on the Wikinews dataset.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.5242206454277039}, {"text": "Wikinews dataset", "start_pos": 104, "end_pos": 120, "type": "DATASET", "confidence": 0.9407303333282471}]}, {"text": "The results are very promising and our approach achieves the best performance on both automatic evaluation and manual evaluation.", "labels": [], "entities": []}, {"text": "In this study, we demonstrate the feasibility of automatic construction of long overview articles from a set of news articles.", "labels": [], "entities": [{"text": "automatic construction of long overview articles from a set of news articles", "start_pos": 49, "end_pos": 125, "type": "TASK", "confidence": 0.7412185991803805}]}, {"text": "The contributions of this paper are summarized as follows: 1) we are the first to investigate the task of automatic construction of news overview articles from a set of source news articles; 2) we automatically build an evaluation dataset based on Wikinews; 3) we propose a news passage-based synthesis approach to address this task; 4) evaluation results verify the efficacy of our approach.", "labels": [], "entities": [{"text": "automatic construction of news overview articles from a set of source news articles", "start_pos": 106, "end_pos": 189, "type": "TASK", "confidence": 0.7999153687403753}]}], "datasetContent": [{"text": "As mentioned in the introduction section, we used Wikinews to construct the evaluation dataset.", "labels": [], "entities": []}, {"text": "We first crawled 18121 English Wikinews and their source news articles via the associated URLs.", "labels": [], "entities": [{"text": "18121 English Wikinews and their source news articles", "start_pos": 17, "end_pos": 70, "type": "DATASET", "confidence": 0.8988201841711998}]}, {"text": "However, many Wikinews articles have very few source news articles and they are very short, and moreover, the URLs for many of the source news are out of date.", "labels": [], "entities": []}, {"text": "We filtered the Wikinews articles for which the number of available source news articles are less than 5.", "labels": [], "entities": [{"text": "Wikinews articles", "start_pos": 16, "end_pos": 33, "type": "DATASET", "confidence": 0.9185991883277893}]}, {"text": "Finally, we selected 100 longest Wikinews from the remaining set for testing 2 . The average number of words of Wikinews in the test set is 598 and the average number of total words of their source news articles is 2136.", "labels": [], "entities": []}, {"text": "The dataset is accompanied and it will be released soon.", "labels": [], "entities": []}, {"text": "Accordingly, the length limit of overview articles produced by different methods is 600 words.", "labels": [], "entities": []}, {"text": "Our approach is compared with several typical multi-document summarization methods: Lead, Coverage,), TextRank (), ClusterCM-RW () and Submodular ().", "labels": [], "entities": []}, {"text": "We also implement SenDivRank that applies the DivRank algorithm on sentences.", "labels": [], "entities": []}, {"text": "For our approach, \u03c4 is set to 0.4 and \u03be is set to 0.5 based on an additional small development set chosen from the remaining Wikinews set.", "labels": [], "entities": []}, {"text": "\u03bb in the DivRank algorithm is set to 0.85 by default.", "labels": [], "entities": []}, {"text": "Under the control of these thresholds, we only merge a very small number of passages and insert very few sentences from one passage to another passage, so the influence of passage merging on the coherence is very subtle.", "labels": [], "entities": []}, {"text": "Automatic Evaluation: Similar to traditional summarization tasks, we use the ROUGE metrics ( to automatically evaluate the quality of peer overview articles against the gold-standard references.", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.9053530991077423}, {"text": "ROUGE", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9693989753723145}]}, {"text": "We use ROUGE-1.5.5 and report the F-scores of ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGE-SU4 (R-SU4).", "labels": [], "entities": [{"text": "ROUGE-1.5.5", "start_pos": 7, "end_pos": 18, "type": "METRIC", "confidence": 0.8213253617286682}, {"text": "F-scores", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9976406097412109}, {"text": "ROUGE-1", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.964917778968811}]}, {"text": "Firstly, we perform evaluation on the whole articles and shows the comparison results.", "labels": [], "entities": []}, {"text": "We can see that our approach outperforms all the baseline methods with respect to ROUGE-2 and ROUGE-SU4.", "labels": [], "entities": []}, {"text": "The Submodular method achieves the highest ROUGE-1 score, but our approach also achieves very high ROUGE-1 score, which is very close to that of the Submodular method.: Comparison results on two-part evaluation II tent organization in long articles, we split each article (both peer article and reference article) into two parts with equal length, and compare the first parts in the peer and reference articles, and then compare the second parts in the peer and reference articles.", "labels": [], "entities": [{"text": "ROUGE-1 score", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9791958332061768}, {"text": "ROUGE-1", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9958730340003967}]}, {"text": "Lastly, the ROUGE scores are averaged across the two parts.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.9968454241752625}]}, {"text": "shows the comparison results based on this evaluation protocol (twopart evaluation I).", "labels": [], "entities": []}, {"text": "Furthermore, we allow the first part in a reference article to match with the second part in a peer article, and vice versa.", "labels": [], "entities": []}, {"text": "We allow one-to-one matching and find the optimal matching between the two sets of parts, which refers to the matching with the largest sum of the similarity values of the matched parts.", "labels": [], "entities": []}, {"text": "We then compute and average the ROUGE scores of the matched parts.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.9702100157737732}]}, {"text": "shows the comparison results based on this evaluation protocol (two-part evaluation II).", "labels": [], "entities": []}, {"text": "We can see from Tables 2 and 3 that our proposed approach performs much better than the baseline methods overall three metrics.", "labels": [], "entities": []}, {"text": "Manual Evaluation: We randomly select 30 test cases for manual evaluation.", "labels": [], "entities": []}, {"text": "We employ: Manual evaluation results three students as human judges and each judge is asked to read the reference Wikinews and the peer overview article produced by each method, and then give a rating score between 1 and 5 with respect to three aspects: content coverage, readability and overall responsiveness.", "labels": [], "entities": []}, {"text": "5 means \"very good\", 3 means \"acceptable\", and 1 means \"very bad\".", "labels": [], "entities": []}, {"text": "The methods producing the articles are blind to the judges.", "labels": [], "entities": []}, {"text": "Finally, the rating scores with respect to each aspect across different test cases are averaged, and then averaged across the three judges.", "labels": [], "entities": []}, {"text": "shows the manual evaluation results.", "labels": [], "entities": []}, {"text": "We can see that our proposed approach can produce news overview articles with better content coverage, readability and overall responsiveness than baseline methods.", "labels": [], "entities": []}, {"text": "The quality of the news overview articles is generally acceptable by the human judges.", "labels": [], "entities": []}, {"text": "In all, our proposed approach are more effective than typical multi-document summarization methods for addressing this challenging task.", "labels": [], "entities": []}, {"text": "It is feasible to automatically construct news overview articles with news synthesis.", "labels": [], "entities": [{"text": "news overview articles", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7589906056722006}]}], "tableCaptions": [{"text": " Table 3: Comparison results on two-part evalua- tion II", "labels": [], "entities": []}, {"text": " Table 4: Manual evaluation results", "labels": [], "entities": []}]}