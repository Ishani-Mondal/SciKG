{"title": [{"text": "The Impact of Modeling Overall Argumentation with Tree Kernels", "labels": [], "entities": [{"text": "Modeling Overall Argumentation", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.8283380468686422}]}], "abstractContent": [{"text": "Several approaches have been proposed to model either the explicit sequential structure of an argumentative text or its implicit hierarchical structure.", "labels": [], "entities": []}, {"text": "So far, the adequacy of these models of overall argumentation remains unclear.", "labels": [], "entities": []}, {"text": "This paper asks what type of structure is actually important to tackle downstream tasks in computational argu-mentation.", "labels": [], "entities": []}, {"text": "We analyze patterns in the overall argumentation of texts from three corpora.", "labels": [], "entities": []}, {"text": "Then, we adapt the idea of positional tree kernels in order to capture sequential and hierarchical argumentative structure together for the first time.", "labels": [], "entities": []}, {"text": "In systematic experiments for three text classification tasks, we find strong evidence for the impact of both types of structure.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7842837572097778}]}, {"text": "Our results suggest that either of them is necessary while their combination maybe beneficial.", "labels": [], "entities": []}], "introductionContent": [{"text": "Argumentation theory has established a number of major argument models focusing on different aspects, such as the roles of an argument's units, the inference scheme of an argument (, or the support and attack relations between arguments (Freeman, 2011).", "labels": [], "entities": [{"text": "Argumentation theory", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8849886655807495}]}, {"text": "The common ground of these models is that they conceptualize an argument as a conclusion (in terms of a claim) inferred from a set of pro and con premises (reasons), which in turn maybe the conclusions of other arguments.", "labels": [], "entities": []}, {"text": "For the overall argumentation of a monological argumentative text such as the one in(a), this results in an implicit hierarchical structure with the text's main claim at the lowest depth.", "labels": [], "entities": []}, {"text": "In addition, the text has an explicit linguistic structure that can be seen as a regulated sequence of speech acts).", "labels": [], "entities": []}, {"text": "pro argument unit (support of parent node) The death penalty is a legal means that as such is not practicable in Germany.", "labels": [], "entities": []}, {"text": "For one thing, inviolable human dignity is anchored in our constitution, and furthermore no one may have the right to adjudicate upon the death of another human being.", "labels": [], "entities": []}, {"text": "Even if many people think that a murderer has already decided on the life or death of another person, this is precisely the crime that we should not repay with the same.", "labels": [], "entities": []}, {"text": "Natural language processing research has largely adopted the outlined hierarchical models for mining arguments from text (.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6650939186414083}]}, {"text": "However, the adequacy of the resulting overall structure for downstream analysis tasks of computational argumentation has rarely been evaluated (see Section 2 for details).", "labels": [], "entities": []}, {"text": "In fact, a computational approach that can capture patterns in hierarchical overall argumentation is missing so far.", "labels": [], "entities": []}, {"text": "Even more, our previous work indicates that a sequential model of overall structure is preferable for analysis tasks such as stance classification or quality assessment ( . In this paper, we ask and investigate what model of (monological) overall argumentation is important to tackle argumentation-related analysis tasks.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.9316990375518799}]}, {"text": "To this end, we consider three corpora with fully annotated argument structure (Section 3).", "labels": [], "entities": []}, {"text": "Each corpus allows studying one text classification task, two of which we hypothesize to benefit from modeling argumentation (myside bias, stance), the third not (genre).", "labels": [], "entities": [{"text": "text classification task", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.7910246253013611}]}, {"text": "An empirical analysis of the corpora reveals class-specific patterns of how people argue (Section 4).", "labels": [], "entities": []}, {"text": "In order to combine the explicit sequential and the implicit hierarchical structure of an argumentative text for the first time, we then adapt the approach of route kernels, modeling overall argumentation inform of a positional tree (Section 5).", "labels": [], "entities": []}, {"text": "On this basis, we design an experiment to evaluate the impact of the different types of argumentative structure (Section 6).", "labels": [], "entities": []}, {"text": "In particular, we decompose our approach into four complementary modeling steps, both fora general model of overall argumentation and for the specific models of the given corpora.", "labels": [], "entities": []}, {"text": "Using the structure annotated in the corpora, we systematically compare the effectiveness of all eight resulting models and two standard baselines in the three classification tasks.", "labels": [], "entities": []}, {"text": "Our results provide strong evidence that both sequential and hierarchical structure are important.", "labels": [], "entities": []}, {"text": "As indicated by related work, sequential structure nearly competes with hierarchical structure, at least based on the specific argument models.", "labels": [], "entities": []}, {"text": "Even more impressively, modeling hierarchical structure practically solves the task of identifying argumentation with myside bias, achieving an outstanding accuracy of 97.1%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9994101524353027}]}, {"text": "For stance classification, the combination captured by positional trees works best.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.9260303378105164}]}, {"text": "In contrast, all types of structure fail in distinguishing genres, suggesting that they indeed capture properties of argumentation.", "labels": [], "entities": []}, {"text": "We conclude that the impact of modeling overall structure on downstream analysis tasks is high, while the required type may vary.", "labels": [], "entities": []}, {"text": "Contributions To summarize, the main contributions of this paper are the following: 1.", "labels": [], "entities": []}, {"text": "Empirical insights into how people structure argumentative texts in overall terms.", "labels": [], "entities": []}, {"text": "2. The first approach to model and analyze the sequential and hierarchical overall structure of argumentative texts in combination.", "labels": [], "entities": []}, {"text": "3. Evidence that modeling overall structure impacts argumentation-related analysis tasks.", "labels": [], "entities": [{"text": "argumentation-related analysis", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.872052937746048}]}], "datasetContent": [{"text": "We seek to study the impact of modeling overall argumentation on downstream tasks without the noise from argument mining errors.", "labels": [], "entities": []}, {"text": "To this end, we rely on three ground-truth argument corpora.", "labels": [], "entities": []}, {"text": "Each corpus is suitable for evaluating one text classification task and comes with a specific model of overall argumentation, as detailed in the following.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.7984006603558859}]}, {"text": "Myside Bias on AAE-v2 The Argument Annotated Essays corpus was originally been presented by.", "labels": [], "entities": [{"text": "Myside Bias on AAE-v2 The Argument Annotated Essays corpus", "start_pos": 0, "end_pos": 58, "type": "DATASET", "confidence": 0.6295626991324954}]}, {"text": "We use version 2 of the corpus (available on the website of the authors), which consists of 402 persuasive student essays.", "labels": [], "entities": []}, {"text": "In each essay, all main claims, claims, and premises are annotated as such.", "labels": [], "entities": []}, {"text": "Each claim has a pro or con stance towards each instance of the main claim, whereas each premise supports or attacks a claim or another premise.", "labels": [], "entities": []}, {"text": "Thereby, argumentation is modeled as one tree structure for each major claim.", "labels": [], "entities": []}, {"text": "Stab and Gurevych (2016) added a myside bias class to each essay, reflecting whether its argumentation is one-sided considering only arguments for the own stance (251 cases) or not (151 cases).", "labels": [], "entities": []}, {"text": "Stance on Arg-Microtexts The Arg-Microtexts corpus of contains 112 short argumentative texts.", "labels": [], "entities": [{"text": "Arg-Microtexts corpus", "start_pos": 29, "end_pos": 50, "type": "DATASET", "confidence": 0.7326614707708359}]}, {"text": "They cover 18 different controversial topics and are annotated according to: Each argument unit takes the role of the proponent or opponent of a main claim.", "labels": [], "entities": []}, {"text": "What the main claim is follows from a tree-like overall structure emerging from four types of relations: normal or example support from one unit to another, a rebuttal of units by other units, and undercutters where a relation is attacked by another unit.", "labels": [], "entities": []}, {"text": "For 88 texts, the stance towards a specified topic is labeled as pro or con (42).", "labels": [], "entities": []}, {"text": "We use these labels for classification, but we do not access the topic.", "labels": [], "entities": []}, {"text": "This way, stance needs to be identified only based on a text itself -a very challenging task.", "labels": [], "entities": []}, {"text": "Genre on Web Discourse Finally, we consider the Argument Annotated User-Generated Web Discourse corpus of.", "labels": [], "entities": [{"text": "Argument Annotated User-Generated Web Discourse corpus", "start_pos": 48, "end_pos": 102, "type": "DATASET", "confidence": 0.5088462432225546}]}, {"text": "There, 340 texts are annotated according to a modified version of the specific model of where claims are supported by premises or attacked by rebuttals.", "labels": [], "entities": []}, {"text": "Rebuttals in turn maybe attacked by refutations.", "labels": [], "entities": []}, {"text": "Besides, emotional units not participating in the actual arguments are marked as pathos.", "labels": [], "entities": []}, {"text": "The support and attack relations buildup the overall argumentation of a text.", "labels": [], "entities": []}, {"text": "The corpus composes argumentative texts of four genres, namely, 5 articles, 216 comments to articles, 46 blog posts, and 73 forum posts.", "labels": [], "entities": []}, {"text": "The genre is specified inform of a label for each text.", "labels": [], "entities": []}, {"text": "Due to the low number, we ignore the articles below.", "labels": [], "entities": []}, {"text": "To give an idea of the sequential and hierarchical overall structure in each corpus, presents statistics of the argument units, the arguments (in terms of relations between two or more units), and the depth of the resulting argumentation.", "labels": [], "entities": []}, {"text": "While the size of the given corpora and the variety of tasks are limited, the only other available corpus with fully annotated argument structure that we are aware of is AraucariaDB (Reed and Rowe,  Finally, we evaluate all four approaches to model overall argumentation from Section 5 on the three tasks associated to the corpora from Section 3. 8  Our goal is to assess the theoretical impact of each introduced step of modeling overall argumentation as far as possible.", "labels": [], "entities": []}, {"text": "To this end, we conduct a systematic experiment where we use the ground-truth argument structure in each corpus for the associated downstream task based on the following set-up:: Accuracy in 10-fold cross-validation (10 repetitions, fairness in training) of all evaluated approaches on each of the three task/corpus combinations, both based on a general model of arguments and based on the specific model of the respective corpus.", "labels": [], "entities": []}, {"text": "The highest value on each corpus is marked in bold; the best bi and a j in each column are italicized.", "labels": [], "entities": []}, {"text": "In parenthesis: The confidence level in percent at which the respective approach is significantly better than the specified approach and all worse approaches.", "labels": [], "entities": []}, {"text": "Approaches The modeling steps are reflected by the approaches a 1 -a 4 from Section 5.", "labels": [], "entities": [{"text": "Approaches", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9746213555335999}]}, {"text": "For each task, we measure the accuracy of all four approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9995307922363281}]}, {"text": "We do this once for our general model of overall argumentation from Section 4 and once for the specific model annotated in the respective corpus, in order to assess the loss of resorting to our always applicable general model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the argument units and argu- ments in the three corpora analyzed in this paper.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy in 10-fold cross-validation (10 repetitions, fairness in training) of all evaluated  approaches on each of the three task/corpus combinations, both based on a general model of arguments  and based on the specific model of the respective corpus. The highest value on each corpus is marked in  bold; the best b i and a j in each column are italicized. In parenthesis: The confidence level in percent at  which the respective approach is significantly better than the specified approach and all worse approaches.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9881812930107117}]}]}