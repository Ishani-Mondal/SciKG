{"title": [{"text": "Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.9683415591716766}]}], "abstractContent": [{"text": "Relation extraction is a fundamental task in information extraction.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9649538397789001}, {"text": "information extraction", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.9087407290935516}]}, {"text": "Most existing methods have heavy reliance on annotations labeled by human experts, which are costly and time-consuming.", "labels": [], "entities": []}, {"text": "To overcome this drawback, we propose a novel framework , REHESSION, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics.", "labels": [], "entities": [{"text": "REHESSION", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9201347231864929}, {"text": "relation extractor learning", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.8493064840634664}]}, {"text": "These annotations, referred as heterogeneous supervision, often conflict with each other, which brings anew challenge to the original relation extraction task: how to infer the true label from noisy labels fora given instance.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7866092026233673}]}, {"text": "Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8767369985580444}, {"text": "true label discovery", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.6565949221452078}]}, {"text": "Extensive experimental results demonstrate the superiority of REHESSION over the state-of-the-art.", "labels": [], "entities": [{"text": "REHESSION", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9863329529762268}]}], "introductionContent": [{"text": "One of the most important tasks towards text understanding is to detect and categorize semantic relations between two entities in a given context.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8038371801376343}]}, {"text": "For example, in, with regard to the sentence of c 1 , relation between Jesse James and Missouri should be categorized as died in.", "labels": [], "entities": []}, {"text": "With accurate identification, relation extraction systems can provide essential support for many applications.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.9179398417472839}]}, {"text": "example is question answering, regarding a specific question, relation among entities can provide valuable information, which helps to seek better answers ().", "labels": [], "entities": [{"text": "question answering", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.910258412361145}]}, {"text": "Similarly, for medical science literature, relations like protein-protein interactions ( and gene disease associations () can be extracted and used in knowledge base population.", "labels": [], "entities": []}, {"text": "Additionally, relation extractors can be used in ontology construction ().", "labels": [], "entities": [{"text": "relation extractors", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7891039550304413}, {"text": "ontology construction", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.8356182873249054}]}, {"text": "Typically, existing methods follow the supervised learning paradigm, and require extensive annotations from domain experts, which are costly and time-consuming.", "labels": [], "entities": []}, {"text": "To alleviate such drawback, attempts have been made to build relation extractors with a small set of seed instances or humancrafted patterns, based on which more patterns and instances will be iteratively generated by bootstrap learning.", "labels": [], "entities": [{"text": "relation extractors", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7917511165142059}]}, {"text": "However, these methods often suffer from semantic drift (.", "labels": [], "entities": []}, {"text": "Besides, knowledge bases like Freebase have been leveraged to automatically generate training data and provide distant supervision (.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.9681201577186584}]}, {"text": "Nevertheless, for many domain-specific applications, distant supervision is either non-existent or insufficient (usually less than 25% of relation mentions are covered).", "labels": [], "entities": []}, {"text": "Only recently have preliminary studies been developed to unite different supervisions, including knowledge bases and domain specific patterns, which are referred as heterogeneous supervision.", "labels": [], "entities": []}, {"text": "As shown in, these supervisions often conflict with each other.", "labels": [], "entities": []}, {"text": "To address these conflicts, data programming) employs a generative model, which encodes supervisions as labeling functions, and adopts the source consistency assumption: a source is likely to provide true information with Robert Newton \"Bob\" Ford was an American outlaw best known for killing his gang leader Jesse James ( ) in Missouri ( ) Hussein ( ) was born in Amman ( ) on 14 November 1935.", "labels": [], "entities": []}, {"text": "Gofraid ( ) died in 989, said to be killed in Dal Riata ( ).", "labels": [], "entities": []}, {"text": "return died_in for < , , s> if DiedIn( , ) in KB return born_in for < , , s> if match(' * born in * ', s) return died_in for < , , s> if match(' * killed in * ', s) return born_in for < , , s> if", "labels": [], "entities": [{"text": "DiedIn", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.9640679955482483}]}], "datasetContent": [{"text": "In this section, we empirically validate our method by comparing to the state-of-the-art relation extraction methods on news and Wikipedia articles.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.724568709731102}]}, {"text": "In the experiments, we conduct investigations on two benchmark datasets from different domains: 1 NYT (  In our experiments, labeling functions are employed to encode two kinds of supervision information.", "labels": [], "entities": [{"text": "NYT", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.7122401595115662}]}, {"text": "One is knowledge base, the other is handcrafted domain-specific patterns.", "labels": [], "entities": []}, {"text": "For domain-specific patterns, we manually design a number of labeling functions ; for knowledge base, annotations are generated following the procedure in.", "labels": [], "entities": []}, {"text": "Regarding two kinds of supervision information, the statistics of the labeling functions are summarized in.", "labels": [], "entities": []}, {"text": "We can observe that heuristic patterns can identify more relation types for KBP datasets, while for NYT datasets, knowledge base can provide supervision for more relation types.", "labels": [], "entities": [{"text": "KBP datasets", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.9296978414058685}, {"text": "NYT datasets", "start_pos": 100, "end_pos": 112, "type": "DATASET", "confidence": 0.934331625699997}]}, {"text": "This observation aligns with our intuition that single kind of information might be insufficient while different kinds of information can complement each other.", "labels": [], "entities": []}, {"text": "We further summarize the statistics of annotations in.", "labels": [], "entities": []}, {"text": "It can be observed that a large portion of instances is only annotated as None, while lots of conflicts exist among other instances.", "labels": [], "entities": []}, {"text": "This phenomenon justifies the motivation to employ true label discovery model to resolve the conflicts among supervision.", "labels": [], "entities": [{"text": "label discovery", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.7123025506734848}]}, {"text": "Also, we can observe most conflicts involve None type, accordingly, our proposed method should have more advantages over traditional true label discovery methods on the relation extraction task comparing to the relation classification task that excludes None type.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 169, "end_pos": 193, "type": "TASK", "confidence": 0.8757364352544149}, {"text": "relation classification task", "start_pos": 211, "end_pos": 239, "type": "TASK", "confidence": 0.7942056655883789}]}, {"text": "For relation classification task, which excludes None type from training / testing, we use the classification accuracy (Acc) for evaluation, and for relation extraction task, precision (Prec), recall (Rec) and F1 score () are employed.", "labels": [], "entities": [{"text": "relation classification task", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.9111528197924296}, {"text": "classification accuracy (Acc)", "start_pos": 95, "end_pos": 124, "type": "METRIC", "confidence": 0.745440137386322}, {"text": "relation extraction task", "start_pos": 149, "end_pos": 173, "type": "TASK", "confidence": 0.861970583597819}, {"text": "precision (Prec)", "start_pos": 175, "end_pos": 191, "type": "METRIC", "confidence": 0.8517911434173584}, {"text": "recall (Rec)", "start_pos": 193, "end_pos": 205, "type": "METRIC", "confidence": 0.948323518037796}, {"text": "F1 score", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.9910787642002106}]}, {"text": "Notice that both relation extraction and relation classification are conducted and evaluated in sentence-level ().", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8535918593406677}, {"text": "relation classification", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.8655103147029877}]}, {"text": "Based on the semantic meaning of proficient subset, we set \u03d5 2 to 1/|R\u222a{None}|, i.e., the probability of generating right label with random guess.", "labels": [], "entities": []}, {"text": "Then we set \u03d5 1 to 1 \u2212 \u03d5 2 , \u03bb 1 = \u03bb 2 = 1, and the learning rate \u03b1 = 0.025.", "labels": [], "entities": [{"text": "learning rate \u03b1", "start_pos": 52, "end_pos": 67, "type": "METRIC", "confidence": 0.9660327633221945}]}, {"text": "As for other parameters, they are tuned on the validation sets for each dataset.", "labels": [], "entities": []}, {"text": "Similarly, all parameters of compared methods are tuned on validation set, and the parameters achieving highest F1 score are chosen for relation extraction.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9899334907531738}, {"text": "relation extraction", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.8805744647979736}]}], "tableCaptions": [{"text": " Table 5: Performance comparison of relation extraction and relation classification", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8080883324146271}, {"text": "relation classification", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.855027437210083}]}]}