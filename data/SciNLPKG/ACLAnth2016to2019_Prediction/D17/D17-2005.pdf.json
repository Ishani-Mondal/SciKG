{"title": [{"text": "SGNMT -A Flexible NMT Decoding Platform for Quick Prototyping of New Models and Search Strategies", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces SGNMT, our experimental platform for machine translation research.", "labels": [], "entities": [{"text": "SGNMT", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.6894280314445496}, {"text": "machine translation research", "start_pos": 59, "end_pos": 87, "type": "TASK", "confidence": 0.8846503694852194}]}, {"text": "SGNMT provides a generic interface to neural and symbolic scoring modules (predictors) with left-to-right semantic such as translation models like NMT, language models, translation lattices , n-best lists or other kinds of scores and constraints.", "labels": [], "entities": []}, {"text": "Predictors can be combined with other predictors to form complex decoding tasks.", "labels": [], "entities": []}, {"text": "SGNMT implements a number of search strategies for traversing the space spanned by the predictors which are appropriate for different predic-tor constellations.", "labels": [], "entities": []}, {"text": "Adding new predictors or decoding strategies is particularly easy, making it a very efficient tool for proto-typing new research ideas.", "labels": [], "entities": []}, {"text": "SGNMT is actively being used by students in the MPhil program in Machine Learning, Speech and Language Technology at the University of Cambridge for coursework and theses, as well as for most of the research work in our group.", "labels": [], "entities": [{"text": "SGNMT", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7727700471878052}]}], "introductionContent": [{"text": "We are developing an open source decoding framework called SGNMT, short for Syntactically Guided Neural Machine Translation.", "labels": [], "entities": [{"text": "Syntactically Guided Neural Machine Translation", "start_pos": 76, "end_pos": 123, "type": "TASK", "confidence": 0.6473887860774994}]}, {"text": "The software package supports a number of well-known frameworks, including TensorFlow 2 (,, Blocks/Theano (, and NPLM ().", "labels": [], "entities": []}, {"text": "The two central concepts in the SGNMT tool are predictors and decoders.", "labels": [], "entities": []}, {"text": "Predictors are scoring modules which define scores over the target language vocabulary given the current internal predictor state, the history, the source sentence, and external side information.", "labels": [], "entities": [{"text": "Predictors", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9270735383033752}]}, {"text": "Scores from multiple, diverse predictors can be combined for use in decoding.", "labels": [], "entities": []}, {"text": "Decoders are search strategies which traverse the space spanned by the predictors.", "labels": [], "entities": []}, {"text": "SGNMT provides implementations of common search tree traversal algorithms like beam search.", "labels": [], "entities": [{"text": "beam search", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.7865930497646332}]}, {"text": "Since decoders differ in runtime complexity and the kind of search errors they make, different decoders are appropriate for different predictor constellations.", "labels": [], "entities": []}, {"text": "The strict separation of scoring module and search strategy and the decoupling of scoring modules from each other makes SGNMT a very flexible decoding tool for neural and symbolic models which is applicable not only to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 219, "end_pos": 238, "type": "TASK", "confidence": 0.7431415617465973}]}, {"text": "SGNMT is based on the OpenFSTbased Cambridge SMT system).", "labels": [], "entities": [{"text": "SGNMT", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8246946930885315}, {"text": "OpenFSTbased Cambridge SMT system", "start_pos": 22, "end_pos": 55, "type": "DATASET", "confidence": 0.8914099335670471}]}, {"text": "Although the system is less than a year old, we have found it to be very flexible and easy for new researchers to adopt.", "labels": [], "entities": []}, {"text": "Our group has already integrated SGNMT into most of its research work.", "labels": [], "entities": [{"text": "SGNMT", "start_pos": 33, "end_pos": 38, "type": "TASK", "confidence": 0.6963742971420288}]}, {"text": "We also find that SGNMT is very well-suited for teaching and student research projects.", "labels": [], "entities": []}, {"text": "In the 2015-16 academic year, two students on the Cambridge MPhil in Machine Learning, Speech and Language Technology used SGNMT for their dissertation projects.", "labels": [], "entities": [{"text": "Cambridge MPhil", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.9506784379482269}]}, {"text": "The first project involved using SGNMT with OpenFST for applying subword models in SMT (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9596902132034302}]}, {"text": "The second project developed automatic music composition by LSTMs where WFSAs were used to define the space of allowable chord progressions in 'Bach' chorales Explore all outgoing edges of the current node and use arc weights as scores.", "labels": [], "entities": [{"text": "automatic music composition", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6610851089159647}]}, {"text": "Traverse the outgoing edge from the current node labelled with token and update the predictor state to the target node.", "labels": [], "entities": []}, {"text": "n-gram Current n-gram history Set the current n-gram history to the begin-ofsentence symbol.", "labels": [], "entities": []}, {"text": "Return the LM scores for the current n-gram history.", "labels": [], "entities": []}, {"text": "Add token to the current n-gram history.", "labels": [], "entities": []}, {"text": "Word For </s> use the logprobability of the current number of UNKs given \u03bb.", "labels": [], "entities": [{"text": "Word", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9214264154434204}]}, {"text": "Use zero for all other tokens.", "labels": [], "entities": []}, {"text": "Increase internal counter by 1 if token is UNK.: Predictor operations for the NMT, FST, n-gram LM, and counting modules. that the chorales must obey.", "labels": [], "entities": [{"text": "NMT", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.8481971621513367}, {"text": "FST", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.4983493983745575}]}, {"text": "This second project in particular demonstrates the versatility of the approach.", "labels": [], "entities": []}, {"text": "For the current, 2016-17 academic year, SGNMT is being used heavily in two courses.", "labels": [], "entities": [{"text": "SGNMT", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.7002026438713074}]}], "datasetContent": [], "tableCaptions": []}