{"title": [{"text": "Affinity-Preserving Random Walk for Multi-Document Summarization", "labels": [], "entities": [{"text": "Affinity-Preserving", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.9342342615127563}, {"text": "Summarization", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.7465006709098816}]}], "abstractContent": [{"text": "Multi-document summarization provides users with a short text that summarizes the information in a set of related documents.", "labels": [], "entities": [{"text": "Multi-document summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7574510872364044}]}, {"text": "This paper introduces affinity-preserving random walk to the summa-rization task, which preserves the affinity relations of sentences by an absorbing random walk model.", "labels": [], "entities": []}, {"text": "Meanwhile, we put forward adjustable affinity-preserving random walk to enforce the diversity constraint of summarization in the random walk process.", "labels": [], "entities": [{"text": "summarization", "start_pos": 108, "end_pos": 121, "type": "TASK", "confidence": 0.9661692380905151}]}, {"text": "The ROUGE evaluations on DUC 2003 topic-focused summarization task and DUC 2004 generic summariza-tion task show the good performance of our method, which has the best ROUGE-2 recall among the graph-based ranking methods.", "labels": [], "entities": [{"text": "DUC 2003 topic-focused", "start_pos": 25, "end_pos": 47, "type": "DATASET", "confidence": 0.8330689867337545}, {"text": "summarization task", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.4880263954401016}, {"text": "DUC 2004 generic summariza-tion task", "start_pos": 71, "end_pos": 107, "type": "DATASET", "confidence": 0.7578145265579224}, {"text": "ROUGE-2", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9305440187454224}, {"text": "recall", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.6981930732727051}]}], "introductionContent": [{"text": "Multi-document summarization provides users with summary that reflects the main information in a set of given documents.", "labels": [], "entities": [{"text": "Multi-document summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7021308243274689}]}, {"text": "The documents are often related and talk about more than one topics.", "labels": [], "entities": []}, {"text": "Generic multi-document summarization and topic-focused multi-document summarization are two typical kinds of summarization.", "labels": [], "entities": [{"text": "Generic multi-document summarization", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5630378822485606}, {"text": "topic-focused multi-document summarization", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.6203771233558655}, {"text": "summarization", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.973561704158783}]}, {"text": "The former is a summarization delivering the main information of the documents with no bias while the latter is a one delivering the main information biased to a given topic description (a few sentences or even phrases).", "labels": [], "entities": []}, {"text": "Most existing summarization systems are designed for these two kinds of summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.97258061170578}, {"text": "summarization", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.9751933217048645}]}, {"text": "There are two goals for generic multi-document summarization.", "labels": [], "entities": [{"text": "generic multi-document summarization", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.6535329023996989}]}, {"text": "The first one is saliency.", "labels": [], "entities": []}, {"text": "Summary sentences should be central sentences that capture the majority of information in a document cluster.", "labels": [], "entities": []}, {"text": "The sentences with little information about the document cluster should not be included in the summary.", "labels": [], "entities": []}, {"text": "The second one is diversity.", "labels": [], "entities": []}, {"text": "The information overlap between summary sentences should be as minimal as possible due to the length limit of summary.", "labels": [], "entities": []}, {"text": "In other words, the information coverage of summary is a determinant, which requires that the summary sentences should cover diverse aspects of information.", "labels": [], "entities": []}, {"text": "Besides the two goals, there is another goal for the topic-focused summarization and that is relevancy.", "labels": [], "entities": []}, {"text": "It requires that the summary sentences be relevant to the topic description.", "labels": [], "entities": []}, {"text": "A series of conferences and workshops on automatic text summarization (e.g. NTCIR, DUC), special topic sessions in ACL, EMNLP and SIGIR have advanced the techniques to achieve these goals and many approaches have been proposed so far.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.6514024585485458}, {"text": "NTCIR", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.82008296251297}, {"text": "ACL", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.9125791192054749}, {"text": "EMNLP", "start_pos": 120, "end_pos": 125, "type": "DATASET", "confidence": 0.708000659942627}]}, {"text": "In this paper, we focus on the extractive summarization methods, which extract the summary sentences from the input document cluster.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.5447848737239838}]}, {"text": "We propose affinity-preserving random walk for multidocument summarization.", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.6849432587623596}]}, {"text": "The method is a graphbased ranking method, which takes into account the global information collectively computed from the entire sentence affinity graph.", "labels": [], "entities": []}, {"text": "Different from the previous graph-based ranking methods, our method adopts \"global normalization\" to transform sentence affinity matrix into sentence transition matrix and formulates the sentence ranking process in an absorbing random walk model.", "labels": [], "entities": []}, {"text": "Meanwhile, the adjustable affinity-preserving random walk is proposed to facilitate the diversity of summary by adjusting the sentence transition matrix after each iteration of random walk.", "labels": [], "entities": []}, {"text": "Experimental results on DUC generic and topic-focused multi-document summarization tasks show the competitive performance of our method.", "labels": [], "entities": [{"text": "DUC generic and topic-focused multi-document summarization tasks", "start_pos": 24, "end_pos": 88, "type": "TASK", "confidence": 0.5150639010327203}]}, {"text": "To our best knowledge, our system has the best ROUGE-2 recall on both tasks among all existing graph-based ranking methods, which defeats most other methods.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9929252862930298}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.7787308096885681}]}, {"text": "We summarize our contributions as follows.", "labels": [], "entities": []}, {"text": "(1) We preserve the original affinity relations between sentences in a novel affinity-preserving random walk view for multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 118, "end_pos": 146, "type": "TASK", "confidence": 0.57674640417099}]}, {"text": "The preservation of affinity leads to a more salient summary.", "labels": [], "entities": []}, {"text": "And it is applicable to both generic and topic-focused summarization.", "labels": [], "entities": []}, {"text": "We propose adjustable affinity-preserving random walk to enforce the diversity constraint of summarization in the random walk process.", "labels": [], "entities": [{"text": "summarization", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.9627674221992493}]}, {"text": "(3) Experiments on DUC 2003 and DUC 2004 tasks demonstrate the competitive performance of our method.", "labels": [], "entities": [{"text": "DUC 2003 and DUC 2004 tasks", "start_pos": 19, "end_pos": 46, "type": "DATASET", "confidence": 0.8599799275398254}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes traditional random walk model for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.9930104613304138}]}, {"text": "Section 4 proposes affinity-preserving random walk for the saliency goal of summarization and this section also proposes adjustable affinity-preserving random walk to produce both salient and diverse summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.9902183413505554}]}, {"text": "Section 5 gives our evaluation results and the conclusion is made in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the ROUGE-1.5.5 (Lin and Hovy, 2003) toolkit for evaluation, which has been officially adopted by DUC for automatic summarization evaluation.", "labels": [], "entities": [{"text": "ROUGE-1.5.5 (Lin and Hovy, 2003) toolkit", "start_pos": 11, "end_pos": 51, "type": "DATASET", "confidence": 0.6714095407062106}, {"text": "DUC", "start_pos": 105, "end_pos": 108, "type": "DATASET", "confidence": 0.9184557199478149}, {"text": "summarization evaluation", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.9211524128913879}]}, {"text": "The toolkit measures summary quality by counting overlapping units such as the ngram, word sequences and word pairs between the candidate summary and the reference summary.", "labels": [], "entities": []}, {"text": "ROUGE-N is an n-gram based measure and the ROUGE-N recall is computed as follows where n stands for the length of the n-gram, and Count match (n-gram) is the maximum number of ngrams co-occurring in the candidate summary and the set of reference summaries.", "labels": [], "entities": [{"text": "ROUGE-N", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.7037380337715149}, {"text": "ROUGE-N", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.8925971388816833}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.5206913352012634}, {"text": "Count match (n-gram)", "start_pos": 130, "end_pos": 150, "type": "METRIC", "confidence": 0.9296192646026611}]}, {"text": "Count(n-gram) is the number of n-grams in the reference summaries.", "labels": [], "entities": [{"text": "Count(n-gram)", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.8893893659114838}]}, {"text": "We conduct our ROUGE experiments following the recommended standard in . We compute ROUGE-2 recall with stemming and stopwords not removed, which provides the best agreement with manual evaluations.", "labels": [], "entities": [{"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.8865192532539368}]}, {"text": "We also compute ROUGE-1 recall which has the highest recall of ability to identify the better summary in a pair, and ROUGE-4 recall which has the highest precision of ability to identify the better summary in a pair ().", "labels": [], "entities": [{"text": "ROUGE-1 recall", "start_pos": 16, "end_pos": 30, "type": "METRIC", "confidence": 0.8607164621353149}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9988582134246826}, {"text": "ROUGE-4 recall", "start_pos": 117, "end_pos": 131, "type": "METRIC", "confidence": 0.9024998247623444}, {"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9952947497367859}]}, {"text": "In the experiments, the parameters of our method are set as follows: the decay factor \u03bb is 2, the maximum number of iteration M is 100, the number of starting iteration B is 30, the damping factor \u00b5 is 0.85 and the minimum error \u03b5 is 1E-30..2: System comparisons on task 2 of DUC 2004 (%).", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 276, "end_pos": 284, "type": "DATASET", "confidence": 0.9502264857292175}]}, {"text": "*: Graph-based ranking methods..2 shows the performance of our method and other eleven well-known systems on task 2 of DUC 2004 according to ROUGE-1,2,4 recall, sorted by ROUGE-2 recall in the ascending order.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 119, "end_pos": 127, "type": "DATASET", "confidence": 0.9223487377166748}, {"text": "ROUGE-1,2,4", "start_pos": 141, "end_pos": 152, "type": "METRIC", "confidence": 0.9280416369438171}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.6913477778434753}, {"text": "ROUGE-2 recall", "start_pos": 171, "end_pos": 185, "type": "METRIC", "confidence": 0.782944530248642}]}, {"text": "Some of the results are from).", "labels": [], "entities": []}, {"text": "Cont.) is a graph-based ranking method and a representative of traditional random walk approach.", "labels": [], "entities": []}, {"text": "Here we employ the continuous version of LexPageRank.", "labels": [], "entities": [{"text": "LexPageRank", "start_pos": 41, "end_pos": 52, "type": "DATASET", "confidence": 0.96962970495224}]}, {"text": "FreqSum () is a simple approach to approximate the importance of words with their probability in the input and then select sentences with high average word probability.", "labels": [], "entities": []}, {"text": "CLASSY 04) was the participant of the official DUC 2004 evaluation with the best evaluation score.", "labels": [], "entities": [{"text": "CLASSY 04)", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9138152798016866}, {"text": "DUC 2004 evaluation", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.8995843529701233}]}, {"text": "It employs a Hidden Markov Model using topic signature feature and requires a linguistic preprocessing component.", "labels": [], "entities": []}, {"text": "CLASSY 11) is the successor of CLASSY 04 and selects the non-redundant sentences using the non-negative matrix factorization algorithm.", "labels": [], "entities": [{"text": "CLASSY 11", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8773773014545441}]}, {"text": "In the Submodular system (Lin and Bilmes, 2011), multi-document summarization is formulated as a submodular set function maximization problem.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.6349518299102783}]}, {"text": "DPP (Lin and Bilmes, 2011) combines a sentence saliency model with a global diversity model encouraging non-overlapping information.) aims at finding the globally optimal summary by formulating the summarization task in Integer Linear Programming.", "labels": [], "entities": [{"text": "DPP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7952495813369751}, {"text": "summarization", "start_pos": 198, "end_pos": 211, "type": "TASK", "confidence": 0.9770699739456177}]}, {"text": "WFS-NMF () extends the non-negative matrix factorization algorithm and provides a good framework for weighting different terms and documents.", "labels": [], "entities": [{"text": "WFS-NMF", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9043974280357361}]}, {"text": "GRASSHOPPER, DivRank and GCD are the three graph-based ranking models mentioned in Section 2.", "labels": [], "entities": [{"text": "GRASSHOPPER", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9622207880020142}, {"text": "GCD", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.6683449745178223}]}, {"text": "APRW and AAPRW are our methods.", "labels": [], "entities": [{"text": "APRW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7987582087516785}, {"text": "AAPRW", "start_pos": 9, "end_pos": 14, "type": "DATASET", "confidence": 0.5618492960929871}]}, {"text": "APRW is the method of affinitypreserving random walk described in Section 4.2 and AAPRW is the method of adjustable affinitypreserving random walk described in Section 4.3..", "labels": [], "entities": [{"text": "AAPRW", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9740788340568542}]}, {"text": "Manifold Ranking is the method proposed in ( to make use of both the relationships among all sentences in the documents and the relationships between the given topic de-scription and the sentences.", "labels": [], "entities": []}, {"text": "APRW and AAPRW are our methods.", "labels": [], "entities": [{"text": "APRW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7987582087516785}, {"text": "AAPRW", "start_pos": 9, "end_pos": 14, "type": "DATASET", "confidence": 0.5618492960929871}]}], "tableCaptions": [{"text": " Table 5.1: Summary of data sets used in our ex- periments.", "labels": [], "entities": []}, {"text": " Table 5.2: System comparisons on task 2 of DUC  2004 (%). *: Graph-based ranking methods.", "labels": [], "entities": [{"text": "DUC  2004", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.9546354115009308}]}, {"text": " Table 5.3: System comparisons on task 3 of DUC  2003 (%).", "labels": [], "entities": [{"text": "DUC  2003", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.9356269836425781}]}]}