{"title": [{"text": "Detecting and Explaining Causes From Text For a Time Series Event", "labels": [], "entities": [{"text": "Detecting and Explaining Causes From Text", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8799818158149719}]}], "abstractContent": [{"text": "Explaining underlying causes or effects about events is a challenging but valuable task.", "labels": [], "entities": [{"text": "Explaining underlying causes or effects about events", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.8946658458028521}]}, {"text": "We define a novel problem of generating explanations of a time series event by (1) searching cause and effect relationships of the time series with tex-tual data and (2) constructing a connecting chain between them to generate an explanation.", "labels": [], "entities": []}, {"text": "To detect causal features from text, we propose a novel method based on the Granger causality of time series between features extracted from text such as N-grams, topics, sentiments, and their composition.", "labels": [], "entities": []}, {"text": "The generation of the sequence of causal entities requires a com-monsense causative knowledge base with efficient reasoning.", "labels": [], "entities": []}, {"text": "To ensure good in-terpretability and appropriate lexical usage we combine symbolic and neural representations , using a neural reasoning algorithm trained on commonsense causal tu-ples to predict the next cause step.", "labels": [], "entities": []}, {"text": "Our quantitative and human analysis show empirical evidence that our method successfully extracts meaningful causality relationships between time series with textual features and generates appropriate explanation between them.", "labels": [], "entities": []}], "introductionContent": [{"text": "Producing true causal explanations requires deep understanding of the domain.", "labels": [], "entities": []}, {"text": "This is beyond the capabilities of modern AI.", "labels": [], "entities": []}, {"text": "However, it is possible to collect large amounts of causally related events, and, given powerful enough representational variability, to construct cause-effect chains by selecting individual pairs appropriately and linking them together.", "labels": [], "entities": []}, {"text": "Our hypothesis is that chains composed of locally coherent pairs can suggest overall causation.", "labels": [], "entities": []}, {"text": "In this paper, we view causality as (commonsense) cause-effect expressions that occur frequently in online text such as news articles or tweets.", "labels": [], "entities": []}, {"text": "For example, \"greenhouse gases causes global warming\" is a sentence that provides an 'atomic' link that can be used in a larger chain.", "labels": [], "entities": []}, {"text": "By connecting such causal facts in a sequence, the result can be regarded as a causal explanation between the two ends of the sequence (see for examples).", "labels": [], "entities": []}, {"text": "This paper makes the following contributions: \u2022 we define the problem of causal explanation generation, \u2022 we detect causal features of a time series event (CSPIKES) using Granger method with features extracted from text such as N-grams, topics, sentiments, and their composition, \u2022 we produce a large graph called CGRAPH of local cause-effect units derived from text and develop a method to produce causal explanations by selecting and linking appropriate units, using neural representations to enable unit matching and chaining.", "labels": [], "entities": [{"text": "causal explanation generation", "start_pos": 73, "end_pos": 102, "type": "TASK", "confidence": 0.7596563100814819}]}, {"text": "The problem of causal explanation generation arises for systems that seek to determine causal factors for events of interest automatically.", "labels": [], "entities": [{"text": "causal explanation generation", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.8351031939188639}]}, {"text": "For given time series events such as companies' stock market prices, our system called CSPIKES detects events that are deemed causally related by time series analysis using Granger Causality regression.", "labels": [], "entities": []}, {"text": "We consider a large amount of text and tweets related to each company, and produces for each company time series of values for hundreds of thousands of word n-grams, topic labels, sentiment values, etc.", "labels": [], "entities": []}, {"text": "shows an example of causal features that temporally causes Facebook's stock rise in August.", "labels": [], "entities": []}, {"text": "However, it is difficult to understand how the statistically verified factors actually cause the changes, and whether there is a latent causal structure relating the two.", "labels": [], "entities": []}, {"text": "This paper addresses the challenge of finding such latent causal structures, in the form of causal explanations that connect the given cause-effect pair.", "labels": [], "entities": []}, {"text": "shows example causal explanation that our system found between party and Facebook's stock fall (\u2193).", "labels": [], "entities": []}, {"text": "To construct a general causal graph, we extract all potential causal expressions from a large corpus of text.", "labels": [], "entities": []}, {"text": "We refer to this graph as CGRAPH.", "labels": [], "entities": [{"text": "CGRAPH", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.9296475052833557}]}, {"text": "We use FrameNet () semantics to provide various causative expressions (verbs, relations, and patterns), which we apply to a resource of 183, 253, 995 sentences of text and tweets.", "labels": [], "entities": []}, {"text": "These expressions are considerably richer than previous rule-based patterns (.", "labels": [], "entities": []}, {"text": "CGRAPH contains 5,025,636 causal edges.", "labels": [], "entities": []}, {"text": "Our experiment demonstrates that our causality detection algorithm outperforms other baseline methods for forecasting future time series values.", "labels": [], "entities": [{"text": "causality detection", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7448283433914185}]}, {"text": "Also, we tested the neural reasoner on the inference generation task using the BLEU score.", "labels": [], "entities": [{"text": "inference generation task", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.7911224464575449}, {"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9992735981941223}]}, {"text": "Additionally, our human evaluation shows the relative effectiveness of neural reasoners in generating appropriate lexicons in explanations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collect on-line social media from tweets, news articles, and blogs.", "labels": [], "entities": []}, {"text": "Our Twitter data has one million tweets per day from 2008 to 2013 that are crawled using Twitter's Garden Hose API.", "labels": [], "entities": []}, {"text": "News and Blog dataset have been crawled from 2010 to 2013 using Google's news API.", "labels": [], "entities": [{"text": "News and Blog dataset", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.7172400280833244}]}, {"text": "For target time series, we collect companies' stock prices in NASDAQ and NYSE from 2001 until present for 6,200 companies.", "labels": [], "entities": [{"text": "NYSE", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.9313342571258545}]}, {"text": "For presidential election polls, we collect polling data of the 2012 presidential election from 6 different websites, including USA Today , Huffington Post, Reuters, etc.", "labels": [], "entities": [{"text": "USA Today", "start_pos": 128, "end_pos": 137, "type": "DATASET", "confidence": 0.9526110291481018}]}, {"text": "For N-gram word features F word ,we choose the spiking words based on their temporal dynamics (See).", "labels": [], "entities": []}, {"text": "For example, if a word is too frequent or the time series is too burst, the word should be filtered out because the trend is too general to bean event.", "labels": [], "entities": []}, {"text": "We choose five types of temporal dynamics: Shannon entropy, mean, standard deviation, maximum slope of peak, and number of peaks; and delete words that have too low or high entropy, too low mean and deviation, or the number of peaks and its slope is less than a certain threshold.", "labels": [], "entities": []}, {"text": "Also, we filter out words whose frequency is less than five.", "labels": [], "entities": []}, {"text": "From the 1, 677, 583 original words, we retain 21, 120 words as final candidates for F words including uni-gram and bigram words.", "labels": [], "entities": []}, {"text": "For sentiment F senti and topic F topic features, we choose 50 topics generated for both politicians and companies separately using LDA, and then use top 10 words for each topic to calculate sen- Tasks.", "labels": [], "entities": []}, {"text": "To show validity of causality detector, first we conduct random analysis between target time series and randomly generated time series.", "labels": [], "entities": []}, {"text": "Then, we tested forecasting stock prices and election poll values with or without the detected textual features to check effectiveness of our causal features.", "labels": [], "entities": []}, {"text": "We evaluate our reasoning algorithm for generation ability compared to held-out causeeffect tuples using BLEU metric.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9975749850273132}]}, {"text": "Then, for some companies' time series, we describe some qualitative result of some interesting causal text features found with Granger causation and explanations generated by our reasoners between the target and the causal features.", "labels": [], "entities": []}, {"text": "We also conducted human evaluation on the explanations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Number of sentences parsed, number of  entities and tuples, and number of edges (KB-KB,  KBcross) expanded by Freebase in CGRAPH.", "labels": [], "entities": []}, {"text": " Table 4: Examples of F words with their temporal  dynamics: Shannon entropy, mean, standard devi- ation, slope of peak, and number of peaks.", "labels": [], "entities": []}, {"text": " Table 5: Forecasting errors (RMSE) on Stock  and Poll data with time series only (SpikeM and  LSTM) and with time series plus text feature (ran- dom, words, topics, sentiment, and composition).", "labels": [], "entities": [{"text": "Forecasting errors (RMSE)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.846574068069458}, {"text": "Stock  and Poll data", "start_pos": 39, "end_pos": 59, "type": "DATASET", "confidence": 0.8102452754974365}, {"text": "SpikeM", "start_pos": 83, "end_pos": 89, "type": "DATASET", "confidence": 0.7294939160346985}]}, {"text": " Table 7: BLEU ranking. Additional word rep- resentation +WE and relation specific alignment  +REL help the model learn the cause and effect  generation task especially for diverse patterns.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9970557689666748}, {"text": "word rep- resentation +WE", "start_pos": 35, "end_pos": 60, "type": "METRIC", "confidence": 0.7401906053225199}, {"text": "REL", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.5526328086853027}]}]}