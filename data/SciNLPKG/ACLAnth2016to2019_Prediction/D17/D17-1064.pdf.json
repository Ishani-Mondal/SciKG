{"title": [], "abstractContent": [{"text": "We propose anew sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.7069844752550125}]}, {"text": "Like sentence simplification, splitting-and-rephrasing has the potential of benefiting both natural language processing and societal applications.", "labels": [], "entities": [{"text": "splitting-and-rephrasing", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.9558877348899841}]}, {"text": "Because shorter sentences are generally better processed by NLP systems, it could be used as a preprocessing step which facilitates and improves the performance of parsers, semantic role labelers and machine translation systems.", "labels": [], "entities": [{"text": "semantic role labelers", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.6235532263914744}, {"text": "machine translation", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.6980443149805069}]}, {"text": "It should also be of use for people with reading disabilities because it allows the conversion of longer sentences into shorter ones.", "labels": [], "entities": []}, {"text": "This paper makes two contributions towards this new task.", "labels": [], "entities": []}, {"text": "First, we create and make available a benchmark consisting of 1,066,115 tu-ples mapping a single complex sentence to a sequence of sentences expressing the same meaning.", "labels": [], "entities": []}, {"text": "1 Second, we propose five models (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several sentence rewriting operations have been extensively discussed in the literature: sentence compression, multi-sentence fusion, sentence paraphrasing and sentence simplification.", "labels": [], "entities": [{"text": "sentence rewriting", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7367929220199585}, {"text": "sentence compression", "start_pos": 89, "end_pos": 109, "type": "TASK", "confidence": 0.7746781706809998}, {"text": "multi-sentence fusion", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7857688367366791}, {"text": "sentence paraphrasing", "start_pos": 134, "end_pos": 155, "type": "TASK", "confidence": 0.7368527054786682}, {"text": "sentence simplification", "start_pos": 160, "end_pos": 183, "type": "TASK", "confidence": 0.7314326167106628}]}, {"text": "Sentence compression rewrites an input sentence into a shorter paraphrase.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.902181088924408}]}, {"text": "Sentence fusion consists of combining two or more sentences with overlapping information content, preserving common information and deleting irrelevant details.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9243000149726868}]}, {"text": "Sentence paraphrasing aims to rewrite a sentence while preserving its meaning.", "labels": [], "entities": [{"text": "Sentence paraphrasing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9086188077926636}]}, {"text": "Finally, sentence (or text) simplification aims to produce a text that is easier to understand.", "labels": [], "entities": [{"text": "sentence (or text) simplification", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.6400174001852671}]}, {"text": "Because the vocabulary used, the length of the sentences and the syntactic structures occurring in a text are all factors known to affect readability, simplification systems mostly focus on modelling three main text rewriting operations: simplifying paraphrasing, sentence splitting and deletion.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 264, "end_pos": 282, "type": "TASK", "confidence": 0.776936948299408}]}, {"text": "We propose anew sentence simplification task, which we dub Split-and-Rephrase, where the goal is to split a complex input sentence into shorter sentences while preserving meaning.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.6928201168775558}]}, {"text": "In that task, the emphasis is on sentence splitting and rephrasing.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.7374659180641174}]}, {"text": "There is no deletion and no lexical or phrasal simplification but the systems must learn to split complex sentences into shorter ones and to make the syntactic transformations required by the split (e.g., turn a relative clause into a main clause).", "labels": [], "entities": []}, {"text": "Table 1 summarises the similarities and differences between the five sentence rewriting tasks.", "labels": [], "entities": [{"text": "sentence rewriting", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7337356209754944}]}, {"text": "Like sentence simplification, splitting-andrephrasing could benefit both natural language processing and societal applications.", "labels": [], "entities": []}, {"text": "Because shorter sentences are generally better processed by NLP systems, it could be used as a preprocess- ing step which facilitates and improves the performance of parsers, semantic role labelers and statistical machine translation (SMT) systems).", "labels": [], "entities": [{"text": "semantic role labelers", "start_pos": 175, "end_pos": 197, "type": "TASK", "confidence": 0.6200514237085978}, {"text": "statistical machine translation (SMT)", "start_pos": 202, "end_pos": 239, "type": "TASK", "confidence": 0.7762080579996109}]}, {"text": "In addition, because it allows the conversion of longer sentences into shorter ones, it should also be of use for people with reading disabilities) such as aphasia patients), low-literacy readers (, language learners) and children.", "labels": [], "entities": []}, {"text": "We make two main contributions towards the development of Split-andRephrase systems.", "labels": [], "entities": []}, {"text": "Our first contribution consists in creating and making available a benchmark for training and testing Split-and-Rephrase systems.", "labels": [], "entities": []}, {"text": "This benchmark (WEBSPLIT) differs from the corpora used to train sentence paraphrasing, simplification, compression or fusion models in three main ways.", "labels": [], "entities": []}, {"text": "First, it contains a high number of splits and rephrasings.", "labels": [], "entities": [{"text": "splits and rephrasings", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.6908103028933207}]}, {"text": "This is because (i) each complex sentence is mapped to a rephrasing consisting of at least two sentences and (ii) as noted above, splitting a sentence into two usually imposes a syntactic rephrasing (e.g., transforming a relative clause or a subordinate into a main clause).", "labels": [], "entities": []}, {"text": "Second, the corpus has a vocabulary of 3,311 word forms fora little over 1 million training items which reduces sparse data issues and facilitates learning.", "labels": [], "entities": []}, {"text": "This is in stark contrast to the relatively small size corpora with very large vocabularies used for simplification (cf. Section 2).", "labels": [], "entities": []}, {"text": "Third, complex sentences and their rephrasings are systematically associated with a meaning representation which can be used to guide learning.", "labels": [], "entities": []}, {"text": "This allows for the learning of semanticallyinformed models (cf. Section 5).", "labels": [], "entities": []}, {"text": "Our second contribution is to provide five models to understand the difficulty of the proposed Split-and-Rephrase task: (i) A basic encoderdecoder taking as input only the complex sentence; (ii) A hybrid probabilistic-SMT model taking as input a deep semantic representation (Discourse representation structures, of the complex sentence produced by Boxer; (iii) A multi-source encoderdecoder taking as input both the complex sentence and the corresponding set of RDF (Resource Description Format) triples; (iv,v) Two partition-andgenerate approaches which first, partition the semantics (set of RDF triples) of the complex sentence into smaller units and then generate a text for each RDF subset in that partition.", "labels": [], "entities": []}, {"text": "One model is multi-source and takes the input complex sentence into account when generating while the other does not.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the WEBNLG dataset, each item consists of a set of RDF triples (M ) and one or more texts (T i ) verbalising those triples.", "labels": [], "entities": [{"text": "WEBNLG dataset", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.973753035068512}]}, {"text": "An RDF (Resource Description Format) triple is a triple of the form subject|property|object where the subject is a URI (Uniform Resource Identifier), the property is a binary relation and the object is either a URI or a literal value such as a string, a date or a number.", "labels": [], "entities": [{"text": "RDF (Resource Description Format) triple", "start_pos": 3, "end_pos": 43, "type": "TASK", "confidence": 0.6195273058755058}]}, {"text": "In what follows, we refer to the sets of triples representing the meaning of a text as its meaning representation (MR  To construct the Split-and-Rephrase dataset, we make use of the fact that the WEBNLG dataset (i) associates texts with sets of RDF triples and (ii) contains texts of different lengths and complexity corresponding to different subsets of RDF triples.", "labels": [], "entities": [{"text": "Split-and-Rephrase dataset", "start_pos": 136, "end_pos": 162, "type": "DATASET", "confidence": 0.7110109478235245}, {"text": "WEBNLG dataset", "start_pos": 197, "end_pos": 211, "type": "DATASET", "confidence": 0.9718814790248871}]}, {"text": "The idea is the following.", "labels": [], "entities": []}, {"text": "Given a WEBNLG MRText pair of the form (M, T ) where T is a single complex sentence, we search the WEBNLG dataset fora set {(M 1 , T 1 ), . .", "labels": [], "entities": [{"text": "WEBNLG MRText pair", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.7941545049349467}, {"text": "WEBNLG dataset", "start_pos": 99, "end_pos": 113, "type": "DATASET", "confidence": 0.9777476787567139}]}, {"text": ", (M n , T n )} such that {M 1 , . .", "labels": [], "entities": []}, {"text": ", Mn } is a partition of M and T 1 , . .", "labels": [], "entities": []}, {"text": ", T n forms a text with more than one sentence.", "labels": [], "entities": []}, {"text": "To achieve this, we proceed in three main steps as follows.", "labels": [], "entities": []}, {"text": "Sentence segmentation We first preprocess all 13,308 distinct verbalisations contained in the WEBNLG corpus using the Stanford CoreNLP pipeline () to segment each verbalisation Ti into sentences.", "labels": [], "entities": [{"text": "Sentence segmentation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9135220646858215}, {"text": "WEBNLG corpus", "start_pos": 94, "end_pos": 107, "type": "DATASET", "confidence": 0.9766843020915985}, {"text": "Stanford CoreNLP pipeline", "start_pos": 118, "end_pos": 143, "type": "DATASET", "confidence": 0.922632892926534}]}, {"text": "Sentence segmentation allows us to associate each text T in the WEBNLG corpus with the number of sentences it contains.", "labels": [], "entities": [{"text": "Sentence segmentation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9246926307678223}, {"text": "WEBNLG corpus", "start_pos": 64, "end_pos": 77, "type": "DATASET", "confidence": 0.9432174563407898}]}, {"text": "This is needed to identify complex sentences with no split (the input to the Split-and-Rephrase task) and to know how many sentences are associated with a given set of RDF triples (e.g., 2 triples maybe realised by a single sentence or by two).", "labels": [], "entities": []}, {"text": "As the CoreNLP sentence segmentation often fails on complex/rare named entities thereby producing unwarranted splits, we verified the sentence segmentations produced by the CoreNLP sentence segmentation module for each WEBNLG verbalisation and manually corrected the incorrect ones.", "labels": [], "entities": [{"text": "CoreNLP sentence segmentation", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.8057834108670553}, {"text": "CoreNLP sentence segmentation", "start_pos": 173, "end_pos": 202, "type": "TASK", "confidence": 0.7770750721295675}, {"text": "WEBNLG", "start_pos": 219, "end_pos": 225, "type": "DATASET", "confidence": 0.8371605277061462}]}, {"text": "Pairing Using the semantic information given by WEBNLG RDF triples and the information about the number of sentences present in a WEBNLG text produced by the sentence segmentation step, we produce all items of the form \u2022 C is a single sentence with semantics MC . \u2022 T 1 . .", "labels": [], "entities": [{"text": "WEBNLG RDF triples", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.900590976079305}, {"text": "WEBNLG text", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9096928536891937}, {"text": "sentence segmentation", "start_pos": 158, "end_pos": 179, "type": "TASK", "confidence": 0.7414419949054718}]}, {"text": "T n is a sequence of texts that contains at least two sentences.", "labels": [], "entities": []}, {"text": "\u2022 The disjoint union of the semantics M 1 . .", "labels": [], "entities": []}, {"text": "Mn of the texts T 1 . .", "labels": [], "entities": []}, {"text": "T n is the same as the semantics MC of the complex sentence C.", "labels": [], "entities": []}, {"text": "That is, This pairing is made easy by the semantic information contained in the WEBNLG corpus and includes two subprocesses depending on whether complex and split sentences come from the same WEBNLG entry or not.", "labels": [], "entities": [{"text": "WEBNLG corpus", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9782634079456329}]}, {"text": "Given a set of RDF triples MC , a WEBNLG entry will usually contain several alternative verbalisations for MC (e.g., T 1 1 and T 2 1 in are two possible verbalisations of M 1 ).", "labels": [], "entities": [{"text": "WEBNLG", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.8038694858551025}]}, {"text": "We first search for entries where one verbalisation T C consists of a single sentence and another verbalisation T contains more than one sentence.", "labels": [], "entities": []}, {"text": "For such cases, we create an entry of the form (M C , T C ), {(M C , T )}} such that, T C is a single sentence and T is a text consisting of more than one sentence.", "labels": [], "entities": []}, {"text": "The second example item for WEB-SPLIT in   a WEBSPLIT item associating the complex sentence (T 1 1 ) with a text (T 2 1 ) made of three short sentences.", "labels": [], "entities": [{"text": "WEB-SPLIT", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.7255362868309021}]}, {"text": "Next we create (M, C), {(M 1 , T 1 ) . .", "labels": [], "entities": []}, {"text": "(M n , T n )}} entries by searching for all WEBNLG texts C consisting of a single sentence.", "labels": [], "entities": [{"text": "WEBNLG texts C", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.949955960114797}]}, {"text": "For each such text, we create all possible partitions of its semantics MC and for each partition, we search the WEBNLG corpus for matching entries i.e., fora set S of (M i , Ti ) pairs such that (i) the disjoint union of the semantics M i in S is equal to MC and (ii) the resulting set of texts contains more than one sentence.", "labels": [], "entities": [{"text": "WEBNLG corpus", "start_pos": 112, "end_pos": 125, "type": "DATASET", "confidence": 0.9747788310050964}]}, {"text": "The first example item for WEBSPLIT in is a casein point.", "labels": [], "entities": [{"text": "WEBSPLIT", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.5007768869400024}]}, {"text": "C(= T 1 1 ) is the single, complex sentence whose meaning is represented by the three triples M . T 2 , T 3 is the sequence of shorter texts C is mapped to.", "labels": [], "entities": []}, {"text": "And the semantics M 2 and M 3 of these two texts forms a partition over M . Ordering.", "labels": [], "entities": []}, {"text": "For each item (M C , C), {(M 1 , T 1 ) . .", "labels": [], "entities": []}, {"text": "(M n , T n )}} produced in the preceding step, we determine an order on T 1 . .", "labels": [], "entities": []}, {"text": "We observed that the WEBNLG texts mostly 5 follow the order in which the RDF triples are presented.", "labels": [], "entities": [{"text": "WEBNLG texts", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.971647322177887}]}, {"text": "Since this order corresponds to a left-to-right depth-first traversal of the RDF tree, we use this order to order the sentences in the Ti texts.", "labels": [], "entities": []}, {"text": "This section describes our experimental setup and results.", "labels": [], "entities": []}, {"text": "We also describe the implementation details to facilitate the replication of our results.", "labels": [], "entities": []}], "tableCaptions": []}