{"title": [{"text": "Human Centered NLP with User-Factor Adaptation", "labels": [], "entities": []}], "abstractContent": [{"text": "We pose the general task of user-factor adaptation-adapting supervised learning models to real-valued user factors inferred from a background of their language , reflecting the idea that apiece of text should be understood within the context of the user that wrote it.", "labels": [], "entities": [{"text": "user-factor adaptation-adapting supervised learning", "start_pos": 28, "end_pos": 79, "type": "TASK", "confidence": 0.8428440243005753}]}, {"text": "We introduce a continuous adaptation technique, suited for real-valued user factors that are common in social science and bringing us closer to personalized NLP, adapting to each user uniquely.", "labels": [], "entities": []}, {"text": "We apply this technique with known user factors including age, gender, and personality traits, as well as latent factors, evaluating over five tasks: POS tagging, PP-attachment, sentiment analysis, sarcasm detection, and stance detection.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 150, "end_pos": 161, "type": "TASK", "confidence": 0.8442409932613373}, {"text": "sentiment analysis", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.9523480236530304}, {"text": "sarcasm detection", "start_pos": 198, "end_pos": 215, "type": "TASK", "confidence": 0.9105165302753448}, {"text": "stance detection", "start_pos": 221, "end_pos": 237, "type": "TASK", "confidence": 0.9356504082679749}]}, {"text": "Adaptation provides statistically significant benefits for 3 of the 5 tasks: up to +1.2 points for PP-attachment, +3.4 points for sarcasm, and +3.0 points for stance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowing who wrote apiece of text can help to better understand it.", "labels": [], "entities": []}, {"text": "For instance, knowing the age and gender groups of authors has been shown to improve document classification and sentiment analysis (.", "labels": [], "entities": [{"text": "document classification", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.7590278387069702}, {"text": "sentiment analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.9541823863983154}]}, {"text": "However, putting people into discrete groups (e.g. age groups, binary gender) often relies on arbitrary boundaries which may not correspond to meaningful changes in language use.", "labels": [], "entities": []}, {"text": "A wealth of psychological research suggests people should not be characterized as discrete types (or domains) but rather as mixtures of continuous factors).", "labels": [], "entities": []}, {"text": "Here, we ask how one can adapt NLP models to real-valued human factors -continuous valued attributes that capture fine-grained differences between users (e.g. real-valued age, continuous gender scores).", "labels": [], "entities": []}, {"text": "We refer to this problem as userfactor adaptation, and investigate a solution to it in the context of social media, a genre where language is generated by a particularly diverse set of users).", "labels": [], "entities": [{"text": "userfactor adaptation", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7375188320875168}]}, {"text": "Importantly, user-factor adaptation brings us closer to personalized NLP in that with real-valued factors we can now adapt uniquely for each user.", "labels": [], "entities": [{"text": "user-factor adaptation", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7087173610925674}]}, {"text": "Our approach composes user factor information with the linguistic features, similar to feature augmentation, a widely used domain adaptation technique which allows for easy integration with most feature-based learning models.", "labels": [], "entities": []}, {"text": "Since relevant user information often is not explicitly available, we use a background of tweets from the user to infer user factors.", "labels": [], "entities": []}, {"text": "We evaluate our approach over five tasks -POS tagging, PPattachment, sentiment analysis, sarcasm detection, and stance detection -and with a variety of inferred user factors including (a) known factors: age, gender, and personality traits, as well as (b) latent factors derived from past user tweets.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.803201824426651}, {"text": "sentiment analysis", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.9442006349563599}, {"text": "sarcasm detection", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.8773028254508972}, {"text": "stance detection", "start_pos": 112, "end_pos": 128, "type": "TASK", "confidence": 0.8408990204334259}]}, {"text": "The main contributions of this work include (a) adaptation based simply on background language (e.g. past tweets; no required a priori user knowledge or \"domain\"), (b) a method for adapting models based on continuous variables, (c) adaptation to other user attributes beyond age and gender (personality and latent factors), and (d) empirical evidence that standard NLP models can often be improved by user-factor adaptation with a range of inferred factors.", "labels": [], "entities": []}], "datasetContent": [{"text": "We apply user-factor adaptation to five popular NLP tasks: part-of-speech tagging, prepositionalphrase attachment, sentiment analysis, sarcasm detection, and stance detection.", "labels": [], "entities": [{"text": "user-factor adaptation", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.7350947260856628}, {"text": "part-of-speech tagging", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7487181723117828}, {"text": "prepositionalphrase attachment", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.6839491277933121}, {"text": "sentiment analysis", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.950890302658081}, {"text": "sarcasm detection", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.8818409740924835}, {"text": "stance detection", "start_pos": 158, "end_pos": 174, "type": "TASK", "confidence": 0.8981209695339203}]}, {"text": "These represent both syntactic and semantic tasks; include some of the key steps in an NLP application pipeline; and use different types of learning formulations including logistic regression, conditional random fields, and support vector machines.", "labels": [], "entities": []}, {"text": "We demonstrate the value of user-factor adaptation on strong baselines for each task.", "labels": [], "entities": [{"text": "user-factor adaptation", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7090915590524673}]}, {"text": "provides the specific details for each task including the systems used and their configurations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Overview of the experimental setup for all tasks. Choices were dictated primarily by the  literature on top performing systems for each task.", "labels": [], "entities": []}, {"text": " Table 3: Results of user-factor adaptation across all tasks. Adaptation results are shown in comparison  with baseline performance (1) without adaptation and", "labels": [], "entities": [{"text": "user-factor adaptation", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7097262442111969}]}]}