{"title": [], "abstractContent": [{"text": "We present a method for translating texts between close language pairs.", "labels": [], "entities": [{"text": "translating texts between close language pairs", "start_pos": 24, "end_pos": 70, "type": "TASK", "confidence": 0.8613377014795939}]}, {"text": "The method does not require parallel data, and it does not require the languages to be written in the same script.", "labels": [], "entities": []}, {"text": "We show results for six language pairs: Afrikaans/Dutch, Bosnian/Serbian, Danish/Swedish, Mace-donian/Bulgarian, Malaysian/Indonesian, and Polish/Belorussian.", "labels": [], "entities": []}, {"text": "We report BLEU scores showing our method to outperform others that do not use parallel data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992800354957581}]}], "introductionContent": [{"text": "Statistical Natural Language Processing (NLP) tools often need large amounts of training data in order to achieve good performance.", "labels": [], "entities": [{"text": "Statistical Natural Language Processing (NLP)", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6990756349904197}]}, {"text": "This limits the use of current NLP tools to a few resourcerich languages.", "labels": [], "entities": []}, {"text": "Assume an incident happens in an area with a low-resource language, known as the Incident Language (IL).", "labels": [], "entities": []}, {"text": "For a quick response, we need to build NLP tools with available data, as finding or annotating new data is expensive and time consuming.", "labels": [], "entities": []}, {"text": "For many languages this means that we only have a small amount of often out-ofdomain parallel data (e.g. a Bible or Ubuntu manual), some monolingual data and almost no annotation such as part of speech tags.", "labels": [], "entities": []}, {"text": "Fortunately, many low-resource languages have one or more higher-resource, closely Related Languages (RL).", "labels": [], "entities": []}, {"text": "Examples of such IL/RL pairs are Afrikaans/Dutch and Bosnian/Serbian.", "labels": [], "entities": []}, {"text": "A natural idea is to use RL resources to improve the task for IL.", "labels": [], "entities": []}, {"text": "But this requires some kind of conversion between RL and IL.", "labels": [], "entities": [{"text": "RL", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.8375329971313477}]}, {"text": "Assume the required NLP capability is named entity tagging.", "labels": [], "entities": [{"text": "entity tagging", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.7296611964702606}]}, {"text": "If we can convert RL to IL, we can convert all RL training data along with annotations into IL and train the tagger for IL.", "labels": [], "entities": []}, {"text": "Or, if we can convert IL to RL we can use the potentially existing RL named entity tagger on converted IL data and project back the tags.", "labels": [], "entities": []}, {"text": "Following this idea, use a rule-based translation system to convert Italian and Portuguese into Spanish, to improve Spanish (here, IL) language modeling, convert RL/English parallel data to IL/English where both RL and IL have Latin orthography to improve IL/English machine translation.", "labels": [], "entities": [{"text": "IL) language modeling", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.6717014461755753}, {"text": "IL/English machine translation", "start_pos": 256, "end_pos": 286, "type": "TASK", "confidence": 0.5744759380817414}]}, {"text": "use cognates to adapt Spanish resources to Brazilian Portuguese to train a part-of-speech tagger.", "labels": [], "entities": []}, {"text": "use Spanish/Portuguese cognates to convert an English/Spanish lexicon to English/Portuguese.", "labels": [], "entities": []}, {"text": "These works prove the usefulness of RL data to improve NLP for IL, but they are designed for specific tasks and IL/RL pairs.", "labels": [], "entities": []}, {"text": "In this paper we propose a universal method for translating texts between closely related languages.", "labels": [], "entities": [{"text": "translating texts between closely related languages", "start_pos": 48, "end_pos": 99, "type": "TASK", "confidence": 0.8256967763106028}]}, {"text": "We assume that IL and RL are mostly cognates, having roughly the same word order.", "labels": [], "entities": []}, {"text": "Our method is orthography-agnostic for alphabetic systems, and crucially, it does not need any parallel data.", "labels": [], "entities": []}, {"text": "From now on, we talk about converting RL to IL, but the method does not distinguish between RL and IL; as mentioned above, each direction of translation can have its own potential uses.", "labels": [], "entities": []}, {"text": "To translate RL to IL, we train a character-based cipher model and connect it to a word-based language model.", "labels": [], "entities": [{"text": "translate RL", "start_pos": 3, "end_pos": 15, "type": "TASK", "confidence": 0.6401153206825256}]}, {"text": "The cipher model is trained in a noisy channel model where a character language model produces IL characters and the model converts them to RL.", "labels": [], "entities": []}, {"text": "Expectation Maximization is used to train the model parameters to maximize the likelihood of a set of RL monolingual data.", "labels": [], "entities": [{"text": "Expectation Maximization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8356573283672333}]}, {"text": "At decoding time, the cipher model reads the RL text character by character in which words are separated by a special character, and produces a weighted lattice of characters representing all the possible translations for each of the input tokens.", "labels": [], "entities": []}, {"text": "The word-based language model takes this lattice and produces a sequence of output words that maximize the language model score times the cipher model score.", "labels": [], "entities": []}, {"text": "Our cipher models one-to-one, one-to-two and two-to-one character mappings.", "labels": [], "entities": []}, {"text": "This allows us to handle cases like Cyrillic 'q' and Latin 'ch', and also subtle differences in pronunciation between RL and IL like Portuguese 'justi\u00e7a' and Spanish 'justicia'.", "labels": [], "entities": []}, {"text": "Using a character-based cipher model provides the flexibility to generate unseen words.", "labels": [], "entities": []}, {"text": "In other words, the vocabulary is limited by the decoding LM, not the cipher model.", "labels": [], "entities": []}, {"text": "Separation of training and decoding language models enables us to train the decoding LM on as much data as is available without worrying about training speed or memory issues.", "labels": [], "entities": []}, {"text": "We can also transliterate out of vocabulary words by spelling out the best path produced by cipher model in case no good match is found fora token in the decoding LM.", "labels": [], "entities": []}], "datasetContent": [{"text": "We translate the UDHR between the related languages using the following methods: Copy: Copying the text.", "labels": [], "entities": []}, {"text": "This is not applicable for languages with different orthography.", "labels": [], "entities": []}, {"text": "LS: One-to-one Letter Substitution cipher.", "labels": [], "entities": []}, {"text": "This is equivalent to using WFST1 without a decoding language model.", "labels": [], "entities": [{"text": "WFST1", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.9288415908813477}]}, {"text": "LS+1g LM: One-to-one letter substitution cipher with a 1-gram word language model at decoding.", "labels": [], "entities": []}, {"text": "PM+1g LM, PM+2g LM: The Proposed Method with respectively 1-gram and 2-gram word language model at decoding.", "labels": [], "entities": []}, {"text": "Results are reported for both directions of translation in.", "labels": [], "entities": [{"text": "translation", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9624801278114319}]}, {"text": "For all the language pairs except Malaysian(mal) / Indonesian(ind), the proposed method is the best model with a large margin.", "labels": [], "entities": []}, {"text": "Malaysian/Indonesian is a special case where, although the languages have a different vocabulary and a slightly different grammar, they have a common alphabet, and almost all of their cognates are exactly the same.", "labels": [], "entities": []}, {"text": "As a result the proposed method cannot learn much more than copying.", "labels": [], "entities": [{"text": "copying", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9547972679138184}]}, {"text": "afr\u2192dut bel\u2192pol bos\u2192srb dan\u2192swe mkd\u2192bul mal\u2192ind Copy    afr: alle menslike wesens word vry met gelyke --waardigheid en regte a2d: alle menslike wezens werd vrij met gelijke --waardigheid en rechte dut: alle mensen ------worden vrij en gelijk in waardigheid en rechten afr2en: all human beings are free with equal --dignity and rights a2d2en: all human beings were free with equal --dignity and straight dut2en: all people ------are free and equal in dignity and rights Figure 4: First sentence of the first article of UDHR in Afrikaans (afr), Dutch (dut) and its conversion from Afrikaans to Dutch using PM+2-gram LM (a2d), along with their translations to English.", "labels": [], "entities": []}, {"text": "The proposed method translates between Serbian (srb) and Bosnian (bos) almost perfectly.", "labels": [], "entities": []}, {"text": "For other pairs, we translate between a quarter and half of the words correctly, but we get few of the higher n-grams.", "labels": [], "entities": []}, {"text": "visualizes the conversion of the first sentence of the first article of UDHR from Afrikaans (afr) to Dutch (dut) using PM+2g LM (4.3 BLEU4, 36.2 BLEU1).", "labels": [], "entities": [{"text": "conversion of the first sentence of the first article of UDHR", "start_pos": 15, "end_pos": 76, "type": "TASK", "confidence": 0.7587614492936567}, {"text": "PM+2g LM", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9040711522102356}, {"text": "BLEU4", "start_pos": 133, "end_pos": 138, "type": "METRIC", "confidence": 0.9657407999038696}, {"text": "BLEU1", "start_pos": 145, "end_pos": 150, "type": "METRIC", "confidence": 0.990498960018158}]}, {"text": "Observe that 4 out of 10 tokens are translated correctly, close to the 36.2 BLEU1 score, and there is no 3 or 4-gram match.", "labels": [], "entities": [{"text": "BLEU1 score", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.9739920496940613}]}, {"text": "For other tokens except \"menslike\" the translation is either correct but non-existent in the dutch sentence (wezens = beings, met = with) or has a meaning similar enough that can be useful in the downstream applications (werd = were v.s. worden = are, gelijke = equal(noun) v.s. gelijk = equal(adjective), rechte = straight/right v.s. rechten = rights).", "labels": [], "entities": []}, {"text": "The token \"menslike\" in a2d is an OOV.", "labels": [], "entities": [{"text": "OOV", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9814786911010742}]}, {"text": "The model is notable to convert \"menslike\" (afr) to \"mensen\" (dut).", "labels": [], "entities": []}, {"text": "The language model does not accept other potential conversions and passes out \"menslike\" (a2d) as the best output of the cipher model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU scores for IL-to-RL translation of UDHR text. Format is BLEU4/BLEU1. Polish /  Belorussian and Serbian / Bosnian have different orthographies hence copying is not applicable.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991207718849182}, {"text": "IL-to-RL translation of UDHR text", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.6210690617561341}, {"text": "BLEU4", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.9982227683067322}, {"text": "BLEU1", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9535029530525208}]}, {"text": " Table 3: BLEU scores for RL-to-IL translation of UDHR text. Format is BLEU4/BLEU1. Polish /  Belorussian and Serbian / Bosnian have different orthographies hence copying is not applicable.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991934895515442}, {"text": "RL-to-IL translation of UDHR text", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.7915952444076538}, {"text": "BLEU4", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.9983038902282715}, {"text": "BLEU1", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9553028345108032}]}]}