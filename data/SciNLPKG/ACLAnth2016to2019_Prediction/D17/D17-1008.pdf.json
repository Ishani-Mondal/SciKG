{"title": [{"text": "Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.711074153582255}]}], "abstractContent": [{"text": "Annotating large numbers of sentences with senses is the heaviest requirement of current Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.606021523475647}]}, {"text": "We present Train-O-Matic, a language-independent method for generating millions of sense-annotated training instances for virtually all meanings of words in a language's vocabulary.", "labels": [], "entities": []}, {"text": "The approach is fully automatic: no human intervention is required and the only type of human knowledge used is a WordNet-like resource.", "labels": [], "entities": []}, {"text": "Train-O-Matic achieves consistently state-of-the-art performance across gold standard datasets and languages, while at the same time removing the burden of manual annotation.", "labels": [], "entities": []}, {"text": "All the training data is available for research purposes at http://trainomatic.org.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is a key task in computational lexical semantics, inasmuch as it addresses the lexical ambiguity of text by making explicit the meaning of words occurring in a given context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8059995273749033}, {"text": "computational lexical semantics", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.6985293130079905}]}, {"text": "Anyone who has struggled with frustratingly unintelligible translations from an automatic system, or with the meaning bias of search engines, can understand the importance for an intelligent system to go beyond the surface appearance of text.", "labels": [], "entities": []}, {"text": "There are two mainstream lines of research in WSD: supervised and knowledge-based WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9618368148803711}]}, {"text": "Supervised WSD frames the problem as a classical machine learning task in which, first a training phase occurs aimed at learning a classification model from sentences annotated with word senses and, second the model is applied to previouslyunseen sentences focused on a target word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.8453594446182251}]}, {"text": "A key difference from many other problems, however, is that the classes to choose from (i.e., the senses of a target word) vary for each word, therefore requiring a separate training process to be performed on a word byword basis.", "labels": [], "entities": []}, {"text": "As a result, hundreds of training instances are needed for each ambiguous word in the vocabulary.", "labels": [], "entities": []}, {"text": "This would necessitate a million-item training set to be manually created for each language of interest, an endeavour that is currently beyond reach even in resource-rich languages like English.", "labels": [], "entities": []}, {"text": "The second paradigm, i.e., knowledge-based WSD, takes a radically different approach: the idea is to exploit a general-purpose knowledge resource like WordNet) to develop an algorithm which can take advantage of the structural and lexical-semantic information in the resource to choose among the possible senses of a target word occurring in context.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 151, "end_pos": 158, "type": "DATASET", "confidence": 0.9326440095901489}]}, {"text": "For example, a PageRank-based algorithm can be developed to determine the probability of a given sense being reached starting from the senses of its context words.", "labels": [], "entities": []}, {"text": "Recent approaches of this kind have been shown to obtain competitive results).", "labels": [], "entities": []}, {"text": "However, due to its inherent nature, knowledge-based WSD tends to adopt bag-of-word approaches which do not exploit the local lexical context of a target word, including function and collocation words, which limits this approach in some cases.", "labels": [], "entities": [{"text": "WSD", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.8250090479850769}]}, {"text": "In this paper we get the best of both worlds and present Train-O-Matic, a novel method for generating huge high-quality training sets for all the words in a language's vocabulary.", "labels": [], "entities": []}, {"text": "The approach is language-independent, thanks to its use of a multilingual knowledge resource,, and it can be applied to any kind of corpus.", "labels": [], "entities": []}, {"text": "The training sets produced with Train-O-Matic are shown to provide competitive performance with those of manually and semi-automatically tagged corpora.", "labels": [], "entities": []}, {"text": "Moreover, state-ofthe-art performance is also reported for low resourced languages (i.e., Italian and Spanish) and domains, where manual training data is not available.", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpora for sense annotation We used two different corpora to extract sentences: Wikipedia and the United Nations Parallel Corpus ().", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 81, "end_pos": 90, "type": "DATASET", "confidence": 0.9738611578941345}, {"text": "United Nations Parallel Corpus", "start_pos": 99, "end_pos": 129, "type": "DATASET", "confidence": 0.8264290392398834}]}, {"text": "The first is the largest and most up-to-date encyclopedic resource, containing definitional information, the second, on the other hand, is a public collection of parliamentary documents of the United Nations.", "labels": [], "entities": [{"text": "definitional information", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.8850699663162231}]}, {"text": "The application of Train-O-Matic to the two corpora produced two senseannotated datasets, which we named T-O-M W iki and T-O-M UN , respectively.", "labels": [], "entities": []}, {"text": "Semantic Network We created sense-annotated corpora with Train-O-Matic both when using PPR vectors computed from vanilla WordNet and when using WordNet BN , our denser network obtained from the WordNet-induced subgraph of BabelNet (see Section 3).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.9300598502159119}, {"text": "WordNet BN", "start_pos": 144, "end_pos": 154, "type": "DATASET", "confidence": 0.8467709422111511}]}, {"text": "Gold standard datasets We performed our evaluations using the framework made available by on five different allwords datasets, namely: the Senseval-2 (Edmonds and Cotton, 2001), Senseval-3 (Snyder and Palmer, 2004),, and) WSD datasets.", "labels": [], "entities": [{"text": "WSD datasets", "start_pos": 222, "end_pos": 234, "type": "DATASET", "confidence": 0.8882461786270142}]}, {"text": "We focused on nouns only, given the fact that Wikipedia provides connections between nominal synsets only, and therefore contributes mainly to syntagmatic relations between nouns.", "labels": [], "entities": []}, {"text": "Comparison sense-annotated corpora To show the impact of our T-O-M corpora in WSD, we compared its performance on the above gold standard datasets, against training with: \u2022 SemCor (), a corpus containing about 226,000 words annotated manually with WordNet senses.", "labels": [], "entities": [{"text": "WSD", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.8802963495254517}]}, {"text": "\u2022 One Million Sense-Tagged Instances (Taghipour and Ng, 2015, OMSTI), a sense-annotated dataset obtained via a semi-automatic approach based on the disambiguation of a parallel corpus, i.e., the United Nations Parallel Corpus, performed by exploiting manually translated word senses.", "labels": [], "entities": [{"text": "OMSTI", "start_pos": 62, "end_pos": 67, "type": "DATASET", "confidence": 0.8218804001808167}, {"text": "United Nations Parallel Corpus", "start_pos": 195, "end_pos": 225, "type": "DATASET", "confidence": 0.8146149516105652}]}, {"text": "Because OMSTI integrates SemCor to increase coverage, to keep a level playing field we excluded the latter from the corpus.", "labels": [], "entities": []}, {"text": "We note that T-O-M, instead, is fully automatic and does not require any WSD-specific human intervention nor any aligned corpus.", "labels": [], "entities": [{"text": "WSD-specific human", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.8702929317951202}]}, {"text": "Reference system In all our experiments, we used It Makes Sense (, a state-of-the-art WSD system based on linear Support Vector Machines, as our reference system for comparing its performance when trained on T-O-M, against the same WSD system trained on other sense-annotated corpora (i.e., SemCor and OMSTI).", "labels": [], "entities": []}, {"text": "Following the WSD literature, unless stated otherwise, we report performance in terms of F1, i.e., the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "WSD literature", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.7987945675849915}, {"text": "F1", "start_pos": 89, "end_pos": 91, "type": "METRIC", "confidence": 0.9995198249816895}, {"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9903320670127869}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9954736828804016}]}, {"text": "We note that it is not the purpose of this paper to show that T-O-M, when integrated into IMS, beats all other configurations or alternative systems, but rather to fully automatize the WSD pipeline with performances which are competitive with the state of the art.", "labels": [], "entities": [{"text": "WSD pipeline", "start_pos": 185, "end_pos": 197, "type": "TASK", "confidence": 0.8529153168201447}]}, {"text": "Baseline As a traditional baseline in WSD, we used the Most Frequent Sense (MFS) baseline given by the first sense in WordNet.", "labels": [], "entities": [{"text": "WSD", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.848609983921051}, {"text": "Most Frequent Sense (MFS) baseline", "start_pos": 55, "end_pos": 89, "type": "METRIC", "confidence": 0.8356848359107971}, {"text": "WordNet", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.9556170105934143}]}, {"text": "The MFS is a very competitive baseline, due to the sense skewness phenomenon in language).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: F1 of IMS trained on T-O-M when PPR is  obtained from the WordNet graph (WN) and from  the WordNet-induced subgraph of BabelNet (BN).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9977121353149414}, {"text": "WordNet graph (WN)", "start_pos": 68, "end_pos": 86, "type": "DATASET", "confidence": 0.9297605037689209}]}, {"text": " Table 3: F1 of IMS trained on Train-O-Matic, OMSTI and SemCor, and MFS for the Senseval-2,  Senseval-3, SemEval-07, SemEval-13 and SemEval-15 datasets.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9959620833396912}, {"text": "IMS", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9374667406082153}, {"text": "OMSTI", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.7942385077476501}, {"text": "SemEval-15 datasets", "start_pos": 132, "end_pos": 151, "type": "DATASET", "confidence": 0.7044399231672287}]}, {"text": " Table 4: Number of nominal tokens for which at  least one training example is provided by OMSTI  or Train-O-Matic for each dataset.", "labels": [], "entities": [{"text": "OMSTI", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.8810122013092041}]}, {"text": " Table 5: Precision, Recall and F1 of IMS trained  on OMSTI and Train-O-Matic corpus without  MFS backoff strategy for Senseval-2, Senseval-3,  SemEval-07, SemEval-13 and SemEval-15.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.997161865234375}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9986829161643982}, {"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9990569949150085}]}, {"text": " Table 6: Performance comparison over SemEval-2013 domain-specific datasets.", "labels": [], "entities": [{"text": "SemEval-2013 domain-specific datasets", "start_pos": 38, "end_pos": 75, "type": "DATASET", "confidence": 0.7326851884524027}]}, {"text": " Table 7: Performance comparison over the Biomedical and Maths & Computer domains in SemEval-15.", "labels": [], "entities": []}, {"text": " Table 8: Performance comparison between T-O-M and SemEval-2015's best SUDOKU Run.", "labels": [], "entities": []}]}