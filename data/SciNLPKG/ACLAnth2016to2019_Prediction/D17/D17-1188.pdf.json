{"title": [{"text": "Context-Aware Representations for Knowledge Base Relation Extraction", "labels": [], "entities": [{"text": "Context-Aware Representations", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8446027934551239}, {"text": "Knowledge Base Relation Extraction", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.6856069266796112}]}], "abstractContent": [{"text": "We demonstrate that for sentence-level relation extraction it is beneficial to consider other relations in the sentential context while predicting the target relation.", "labels": [], "entities": [{"text": "sentence-level relation extraction", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.6180444161097208}]}, {"text": "Our architecture uses an LSTM-based encoder to jointly learn representations for all relations in a single sentence.", "labels": [], "entities": []}, {"text": "We combine the context representations with an attention mechanism to make the final prediction.", "labels": [], "entities": []}, {"text": "We use the Wikidata knowledge base to construct a dataset of multiple relations per sentence and to evaluate our approach.", "labels": [], "entities": [{"text": "Wikidata knowledge base", "start_pos": 11, "end_pos": 34, "type": "DATASET", "confidence": 0.9498886068662008}]}, {"text": "Compared to a baseline system, our method results in an average error reduction of 24% on a held-out set of relations.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 64, "end_pos": 79, "type": "METRIC", "confidence": 0.9676571488380432}]}, {"text": "The code and the dataset to replicate the experiments are made available at https://github.com/ukplab.", "labels": [], "entities": [{"text": "ukplab", "start_pos": 95, "end_pos": 101, "type": "DATASET", "confidence": 0.9240028858184814}]}], "introductionContent": [{"text": "The main goal of relation extraction is to determine a type of relation between two target entities that appear together in a text.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.803566038608551}]}, {"text": "In this paper, we consider the sentential relation extraction task: to each occurrence of the target entity pair e 1 , e 2 in some sentence s one has to assign a relation type r from a given set R (.", "labels": [], "entities": [{"text": "sentential relation extraction", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7214133540789286}]}, {"text": "A triple e 1 , r, e 2 is called a relation instance and we refer to the relation of the target entity pair as target relation.", "labels": [], "entities": []}, {"text": "Relation extraction is a fundamental task that enables a wide range of semantic applications from question answering () to fact checking ().", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9807958900928497}, {"text": "question answering", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.8549149036407471}, {"text": "fact checking", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.8969911932945251}]}, {"text": "For relation extraction, it is crucial to be able to extract relevant features from the sentential context (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9150500297546387}]}, {"text": "Modern approaches focus just on the relation between the target entities and disregard other relations that might be present in the same sentence (.", "labels": [], "entities": []}, {"text": "For example, in order to correctly identify the relation type between the movie e 1 and the director e 2 in (1), it is important to separate out the INSTANCE OF relation between the movie and its type e 3 : ( We present a novel architecture that considers other relations in the sentence as a context for predicting the label of the target relation.", "labels": [], "entities": [{"text": "INSTANCE OF relation", "start_pos": 149, "end_pos": 169, "type": "METRIC", "confidence": 0.8961849411328634}]}, {"text": "We use the term context relations to refer to them throughout the paper.", "labels": [], "entities": []}, {"text": "Our architecture uses an LSTM-based encoder to jointly learn representations for all relations in a single sentence.", "labels": [], "entities": []}, {"text": "The representation of the target relation and representations of the context relations are combined to make the final prediction.", "labels": [], "entities": []}, {"text": "To facilitate the experiments we construct a dataset that contains multiple positive and negative relation instances per sentence.", "labels": [], "entities": []}, {"text": "We employ a fast growing community managed knowledge base (KB) Wikidata) to build the dataset.", "labels": [], "entities": []}, {"text": "Our main contribution is the new neural network architecture for extracting relations between an entity pair that takes into account other relations in the sentence.", "labels": [], "entities": [{"text": "extracting relations between an entity pair", "start_pos": 65, "end_pos": 108, "type": "TASK", "confidence": 0.8271296421686808}]}], "datasetContent": [{"text": "As an additional baseline, we re-implement a sentence-level model based on convolutional neural networks (CNNs) described in.", "labels": [], "entities": []}, {"text": "This is a state-of-the-art model for fine-grained relation extraction that was previously tested on the single-relation dataset from.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7152975052595139}]}, {"text": "In addition to CNNs, their architecture uses a different position encoding scheme: position markers encode a relative position of each word with respect to the target entities.", "labels": [], "entities": []}, {"text": "We use the same GloVe word embeddings for this model and perform a hyperparameter optimization on the validation set.", "labels": [], "entities": []}, {"text": "Our dataset lets us compare the baseline models and the models that use context relations on the same data.", "labels": [], "entities": []}, {"text": "Following the previous work on rela-: Precision (P) and recall (R) for the top relations.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 38, "end_pos": 51, "type": "METRIC", "confidence": 0.9333662539720535}, {"text": "recall (R)", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.953404575586319}]}, {"text": "tion extraction, we report the aggregated precisionrecall curves for each model on the held-out data).", "labels": [], "entities": [{"text": "precisionrecall", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.9888870120048523}]}, {"text": "To compute the curves, we rank the predictions of each model by their confidence and traverse this list top to bottom measuring the precision and recall at each step.", "labels": [], "entities": [{"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9994744658470154}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9984466433525085}]}, {"text": "The models that take the context into account perform similar to the baselines at the smallest recall numbers, but start to positively deviate from them at higher recall rates.", "labels": [], "entities": [{"text": "recall numbers", "start_pos": 95, "end_pos": 109, "type": "METRIC", "confidence": 0.9737144708633423}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9976019263267517}]}, {"text": "In particular, the ContextAtt model performs better than any other system in our study over the entire recall range.", "labels": [], "entities": [{"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.9903157353401184}]}, {"text": "Compared to the competitive LSTM-baseline that uses the same relation encoder, the ContextAtt model achieves a 24% reduction of the average error: from 0.2096 \u00b1 0.002 to 0.1590 \u00b1 0.002.", "labels": [], "entities": []}, {"text": "The difference between the models is statistically significant (p = 0.009).", "labels": [], "entities": []}, {"text": "We also compute macro precision-recall curves that give equal weights to all relations in the dataset.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 22, "end_pos": 38, "type": "METRIC", "confidence": 0.9176962375640869}]}, {"text": "shows that the ContextAtt model performs best overall relation types.", "labels": [], "entities": []}, {"text": "One can also see that the ContextSum doesn't universally outperforms the LSTM-baseline.", "labels": [], "entities": []}, {"text": "It demonstrates again that using attention is crucial to extract relevant information from the context relations.", "labels": [], "entities": []}, {"text": "On the relation-specific results) we observe that the context-enabled model demonstrates the most improvement on precision and seems to be especially useful for taxonomy relations (see SUBCLASS OF, PART OF).", "labels": [], "entities": [{"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9994670748710632}, {"text": "OF", "start_pos": 194, "end_pos": 196, "type": "METRIC", "confidence": 0.5981686115264893}, {"text": "PART OF", "start_pos": 198, "end_pos": 205, "type": "METRIC", "confidence": 0.8132539689540863}]}, {"text": "We do not compare against the approach of that also performs sentence-level relation extraction, since the provided implementation does not feature the complete pipeline and is only applicable on a particular Freebase dataset.", "labels": [], "entities": [{"text": "sentence-level relation extraction", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.6312107741832733}, {"text": "Freebase dataset", "start_pos": 209, "end_pos": 225, "type": "DATASET", "confidence": 0.9469388425350189}]}, {"text": "The average error and the standard deviation are estimated on 5 training iterations for each model.", "labels": [], "entities": [{"text": "standard", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.966624915599823}]}, {"text": "The statistical significance is computed using the Wilcoxon rank-sum test on the error rates.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the generated dataset.", "labels": [], "entities": []}, {"text": " Table 2: Precision (P) and recall (R) for the top  relations.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9301542937755585}, {"text": "recall (R)", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9562778770923615}]}]}