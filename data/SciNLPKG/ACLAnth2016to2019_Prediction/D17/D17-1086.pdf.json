{"title": [{"text": "World Knowledge for Reading Comprehension: Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions", "labels": [], "entities": [{"text": "Rare Entity Prediction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.597511370976766}]}], "abstractContent": [{"text": "Humans interpret texts with respect to some background information, or world knowledge, and we would like to develop automatic reading comprehension systems that can do the same.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a task and several models to drive progress towards this goal.", "labels": [], "entities": []}, {"text": "In particular, we propose the task of rare entity prediction: given a web document with several entities removed, models are tasked with predicting the correct missing entities conditioned on the document context and the lexical resources.", "labels": [], "entities": [{"text": "rare entity prediction", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.6802491346995035}]}, {"text": "This task is challenging due to the diversity of language styles and the extremely large number of rare entities.", "labels": [], "entities": []}, {"text": "We propose two recurrent neural network architectures which make use of external knowledge in the form of entity descriptions.", "labels": [], "entities": []}, {"text": "Our experiments show that our hierarchical LSTM model performs significantly better at the rare entity prediction task than those that do not make use of external resources.", "labels": [], "entities": [{"text": "rare entity prediction", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.6766753296057383}]}], "introductionContent": [{"text": "Reading comprehension is the ability to process some text and understand its contents, in order to form some beliefs about the world.", "labels": [], "entities": []}, {"text": "The starting point of this paper is the fact that world knowledge plays a crucial role inhuman reading comprehension and language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7549594938755035}]}, {"text": "Work in the psychology of reading literature has demonstrated this point, for example by showing that readers are better able to recall the contents of a story when it describes a counter-intuitive but plausible sequence of events, rather than a bizarre or a highly predictable one).", "labels": [], "entities": []}, {"text": "This point is also central to work in the Schankian tradition of scripts (.", "labels": [], "entities": []}, {"text": "Despite the importance of world knowledge, previous data sets and tasks for reading comprehension have targeted other aspects of the reading comprehension problem, at times explicitly attempting to factor out its influence.", "labels": [], "entities": []}, {"text": "In the Daily Mail/CNN dataset (, named entities such Clarkson and Top Gear are replaced by anonymized entity tokens like ent212.", "labels": [], "entities": [{"text": "Daily Mail/CNN dataset", "start_pos": 7, "end_pos": 29, "type": "DATASET", "confidence": 0.9376555442810058}, {"text": "Clarkson and Top Gear", "start_pos": 53, "end_pos": 74, "type": "DATASET", "confidence": 0.7651738077402115}]}, {"text": "The Children's Book Test focuses on the role of context and memory, and the fictional genre makes it difficult to connect the entities in the stories to real-world knowledge about those entities.", "labels": [], "entities": [{"text": "Children's Book Test", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7456925213336945}]}, {"text": "As a result, language models have proved to be a highly competitive solution to these tasks.", "labels": [], "entities": []}, {"text": "showed that their attentionbased LSTM model achieves state-of-the-art results on the Daily Mail/CNN data set.", "labels": [], "entities": [{"text": "Daily Mail/CNN data set", "start_pos": 85, "end_pos": 108, "type": "DATASET", "confidence": 0.9567428727944692}]}, {"text": "In fact, their analysis shows that more than half of the questions can be answered by exact word matching and sentence-level paraphrase detection, and that many of the remaining errors are difficult to solve exactly because the entity anonymization procedure removes necessary world knowledge.", "labels": [], "entities": [{"text": "exact word matching", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.6243713796138763}, {"text": "sentence-level paraphrase detection", "start_pos": 110, "end_pos": 145, "type": "TASK", "confidence": 0.603622148434321}]}, {"text": "In this paper, we propose a novel task called rare entity prediction, which places the use of external knowledge at its core, with the following key features.", "labels": [], "entities": [{"text": "rare entity prediction", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.7026524543762207}]}, {"text": "First, our task is similar in flavour to the Children's Book and other language modeling tasks, in that the goal of the models is to predict missing elements in text.", "labels": [], "entities": [{"text": "Children's Book", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.8870930075645447}]}, {"text": "However, our task involves predicting missing named entities, rather than missing words.", "labels": [], "entities": [{"text": "predicting missing named entities", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.9072671383619308}]}, {"text": "Second, the number of unique named entities in the data set is very large, roughly on par with the number of documents.", "labels": [], "entities": []}, {"text": "As such, there are very few instances per named entity for systems to train on.", "labels": [], "entities": []}, {"text": "Instead, they must rely on external knowledge sources such as Freebase () in order to make inferences: An abbreviated example from the Wikilinks Rare Entity Prediction dataset.", "labels": [], "entities": [{"text": "Wikilinks Rare Entity Prediction dataset", "start_pos": 135, "end_pos": 175, "type": "DATASET", "confidence": 0.8278791189193726}]}, {"text": "Shown is an excerpt from the text (context), with a missing entity that must be predicted from a list of candidate entities.", "labels": [], "entities": []}, {"text": "Each candidate entity is also provided with its description from Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.9580894708633423}]}, {"text": "about the likely entities that fit the context.", "labels": [], "entities": []}, {"text": "For our task, we use a significantly enhanced version of the Wikilinks dataset (, with entity descriptions extracted from Freebase serving as the lexical resources, which we call the Wikilinks Rare Entity Prediction dataset.", "labels": [], "entities": [{"text": "Wikilinks dataset", "start_pos": 61, "end_pos": 78, "type": "DATASET", "confidence": 0.961083322763443}, {"text": "Wikilinks Rare Entity Prediction dataset", "start_pos": 183, "end_pos": 223, "type": "DATASET", "confidence": 0.778188943862915}]}, {"text": "An example from the Wikilinks Entity Prediction dataset is shown in.", "labels": [], "entities": [{"text": "Wikilinks Entity Prediction dataset", "start_pos": 20, "end_pos": 55, "type": "DATASET", "confidence": 0.7901068776845932}]}, {"text": "We also introduce several recurrent neural network-based models for this task which take in entity descriptions of candidate entities.", "labels": [], "entities": []}, {"text": "Our first model, DOUBENC, combines information derived from two encoders: one for the text passage being read, and one for the entity description.", "labels": [], "entities": []}, {"text": "Our second model, HIERENC, is an extension which considers information from a document-level context, in addition to the local sentential context.", "labels": [], "entities": [{"text": "HIERENC", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.6207275390625}]}, {"text": "We show that language modeling baselines that do not consider entity descriptions are unable to achieve good performance on the task.", "labels": [], "entities": []}, {"text": "RNN-based models that are trained to leverage external knowledge perform much better; in particular, HIERENC achieves a 17% increase inaccuracy over the language model baseline.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Wikilinks dataset () is a large dataset originally designed for cross-document coreference resolution, the task of grouping entity mentions from a set of documents into clusters that represent a single entity.", "labels": [], "entities": [{"text": "Wikilinks dataset", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9035239517688751}, {"text": "cross-document coreference resolution", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.8107004563013712}]}, {"text": "The dataset consists of a list of non-Wikipedia web pages (discovered using the Google search index) that contain hyperlinks to Wikipedia, such as random blog posts or news articles.", "labels": [], "entities": []}, {"text": "Every token with a hyperlink to Wikipedia is then marked and considered an entity mention in the dataset.", "labels": [], "entities": []}, {"text": "Each entity mention is also linked back to a knowledge base through their corresponding Freebase IDs In order to ensure the hyperlinks refer to the correct Wikipedia pages, additional filtering is conducted to ensure that either (1) at least one token in the hyperlink (or anchor) matches a token in the title of the Wikipedia page, or (2) the anchor text matches exactly an anchor from the Wikipedia page text, which can be considered an alias of the page.", "labels": [], "entities": []}, {"text": "As many near-duplicate copies of Wikipedia pages can be found online, any web pages where more than 70% of the sentences match those from their linked Wikipedia pages are discarded.", "labels": [], "entities": []}, {"text": "We use a significantly pre-processed and augmented version of the Wikilinks dataset for the purpose of entity prediction, which we call the Wikilinks Rare Entity Prediction dataset.", "labels": [], "entities": [{"text": "Wikilinks dataset", "start_pos": 66, "end_pos": 83, "type": "DATASET", "confidence": 0.9471568167209625}, {"text": "entity prediction", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7970232367515564}, {"text": "Wikilinks Rare Entity Prediction dataset", "start_pos": 140, "end_pos": 180, "type": "DATASET", "confidence": 0.800903570652008}]}, {"text": "In particular, we parse the HTML texts of the web pages and ex- 238,025 (97.1%): Statistics for the augmented version of the Wikilinks dataset, where n represents the entity frequency in the corpus.", "labels": [], "entities": [{"text": "Wikilinks dataset", "start_pos": 125, "end_pos": 142, "type": "DATASET", "confidence": 0.9120759069919586}]}, {"text": "Web documents with more than 10 blanks to fill are filtered out for computational reasons.", "labels": [], "entities": []}, {"text": "tract their page contents to form our corpus.", "labels": [], "entities": []}, {"text": "Entity mentions with hyperlinks to Wikipedia are marked and replaced by a special token (**blank**), serving as the placeholder for missing entities that we would like the models to predict.", "labels": [], "entities": []}, {"text": "The correct missing entity\u02dceentity\u02dc entity\u02dce is preserved as a target.", "labels": [], "entities": []}, {"text": "Additionally, we extract the lexical definitions of all entities that are marked in the corpus from Freebase using their Freebase IDs, which are available for all entities in the Wikilinks dataset.", "labels": [], "entities": [{"text": "Wikilinks dataset", "start_pos": 179, "end_pos": 196, "type": "DATASET", "confidence": 0.9280692040920258}]}, {"text": "These lexical definitions will serve as the external knowledge to our models.", "labels": [], "entities": []}, {"text": "shows some basic statistics of a subset of the corpus used in our experiments.", "labels": [], "entities": []}, {"text": "As we can see, unlike the Children's Book dataset, which has 50k candidate entities for almost 700k context and query pairs (), the number of unique entities found in our dataset has the same order of magnitude as the number of documents available.", "labels": [], "entities": [{"text": "Children's Book dataset", "start_pos": 26, "end_pos": 49, "type": "DATASET", "confidence": 0.9528505951166153}]}, {"text": "Moreover, the majority of entities appears a relatively small number of times, with 92.8% observed less than or equal to 10 times across the entire corpus.", "labels": [], "entities": []}, {"text": "This suggests that models that only rely on the surrounding context information may not be able to correctly predict the missing entities.", "labels": [], "entities": []}, {"text": "This further motivates us to incorporate additional information into the decision process to improve the performance.", "labels": [], "entities": []}, {"text": "In the experiments section, we show that the external entity descriptions are indeed necessary to achieve better results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics for the augmented version of  the Wikilinks dataset, where n represents the en- tity frequency in the corpus. Web documents with  more than 10 blanks to fill are filtered out for com- putational reasons.", "labels": [], "entities": [{"text": "Wikilinks dataset", "start_pos": 55, "end_pos": 72, "type": "DATASET", "confidence": 0.9356601536273956}]}, {"text": " Table 3: Empirical results on Wikilinks Entity Pre- diction dataset for proposed baselines and models.", "labels": [], "entities": [{"text": "Empirical", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9250370860099792}, {"text": "Wikilinks Entity Pre- diction dataset", "start_pos": 31, "end_pos": 68, "type": "DATASET", "confidence": 0.5394277175267538}]}]}