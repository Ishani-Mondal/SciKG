{"title": [{"text": "Cross-lingual, Character-Level Neural Morphological Tagging", "labels": [], "entities": [{"text": "Character-Level Neural Morphological Tagging", "start_pos": 15, "end_pos": 59, "type": "TASK", "confidence": 0.605173259973526}]}], "abstractContent": [{"text": "Even for common NLP tasks, sufficient supervision is not available in many languages-morphological tagging is no exception.", "labels": [], "entities": []}, {"text": "In the work presented here, we explore a transfer learning scheme, whereby we train character-level recurrent neural taggers to predict morphological taggings for high-resource languages and low-resource languages together.", "labels": [], "entities": [{"text": "predict morphological taggings", "start_pos": 128, "end_pos": 158, "type": "TASK", "confidence": 0.6125615735848745}]}, {"text": "Learning joint character representations among multiple related languages successfully enables knowledge transfer from the high-resource languages to the low-resource ones, improving accuracy by up to 30%.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7222500145435333}, {"text": "accuracy", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.9989058971405029}]}], "introductionContent": [{"text": "State-of-the-art morphological taggers require thousands of annotated sentences to train.", "labels": [], "entities": [{"text": "morphological taggers", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.7388252317905426}]}, {"text": "For the majority of the world's languages, however, sufficient large-scale annotation is not available and obtaining it would often be infeasible.", "labels": [], "entities": []}, {"text": "Accordingly, an important road forward in low-resource NLP is the development of methods that allow for the training of high-quality tools from smaller amounts of data.", "labels": [], "entities": []}, {"text": "In this work, we focus on transfer learning-we train a recurrent neural tagger fora low-resource language jointly with a tagger fora related highresource language.", "labels": [], "entities": [{"text": "transfer learning-we", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.9195653796195984}]}, {"text": "Forcing the models to share character-level features among the languages allows large gains inaccuracy when tagging the lowresource languages, while maintaining (or even improving) accuracy on the high-resource language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9982971549034119}]}, {"text": "Recurrent neural networks constitute the state of the art fora myriad of tasks in NLP, e.g., multilingual part-of-speech tagging, syntactic parsing (, morphological paradigm completion and language modeling; recently, such models have also improved morphological tagging.", "labels": [], "entities": [{"text": "multilingual part-of-speech tagging", "start_pos": 93, "end_pos": 128, "type": "TASK", "confidence": 0.6408459941546122}, {"text": "syntactic parsing", "start_pos": 130, "end_pos": 147, "type": "TASK", "confidence": 0.7595426440238953}, {"text": "morphological paradigm completion", "start_pos": 151, "end_pos": 184, "type": "TASK", "confidence": 0.6264662444591522}, {"text": "language modeling", "start_pos": 189, "end_pos": 206, "type": "TASK", "confidence": 0.7411365211009979}, {"text": "morphological tagging", "start_pos": 249, "end_pos": 270, "type": "TASK", "confidence": 0.7431437373161316}]}, {"text": "In addition to increased performance over classical approaches, neural networks also offer a second advantage: they admit a clean paradigm for multitask learning.", "labels": [], "entities": []}, {"text": "If the learned representations for all of the tasks are embedded jointly into a shared vector space, the various tasks reap benefits from each other and often performance improves for all).", "labels": [], "entities": []}, {"text": "We exploit this idea for language-to-language transfer to develop an approach for cross-lingual morphological tagging.", "labels": [], "entities": [{"text": "language-to-language transfer", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.7266160845756531}, {"text": "cross-lingual morphological tagging", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.7660137613614401}]}, {"text": "We experiment on 18 languages taken from four different language families.", "labels": [], "entities": []}, {"text": "Using the Universal Dependencies treebanks, we emulate a lowresource setting for our experiments, e.g., we attempt to train a morphological tagger for Catalan using primarily data from a related language like Spanish.", "labels": [], "entities": []}, {"text": "Our results demonstrate the successful transfer of morphological knowledge from the highresource languages to the low-resource languages without relying on an externally acquired bilingual lexicon or bitext.", "labels": [], "entities": []}, {"text": "We consider both the single-and multi-source transfer case and explore how similar two languages must be in order to enable highquality transfer of morphological taggers.", "labels": [], "entities": []}], "datasetContent": [{"text": "Empirically, we ask three questions of our architectures.", "labels": [], "entities": []}, {"text": "i) How well can we transfer morphological tagging models from high-resource languages to low-resource languages in each architecture?", "labels": [], "entities": []}, {"text": "(Does one of the three outperform the others?) ii) How many annotated data in the low-resource language do we need?", "labels": [], "entities": []}, {"text": "iii) How closely related do the languages need to be to get good transfer?", "labels": [], "entities": []}, {"text": "We experiment with the language families: Romance (Indo-European), Northern Germanic (IndoEuropean), Slavic (Indo-European) and Uralic.", "labels": [], "entities": []}, {"text": "In the Romance sub-grouping of the wider IndoEuropean family, we experiment on Catalan (ca), French (fr), Italian (it), Portuguese (pt), Romanian (ro) and Spanish (es).", "labels": [], "entities": []}, {"text": "In the Northern Germanic family, we experiment on Danish (da), Norwegian (no) and Swedish (sv).", "labels": [], "entities": [{"text": "Northern Germanic family", "start_pos": 7, "end_pos": 31, "type": "DATASET", "confidence": 0.7160054544607798}]}, {"text": "In the Slavic family, we experiment on Bulgarian (bg), Czech (bg), Polish (pl), Russian (ru), Slovak (sk) and Ukrainian (uk).", "labels": [], "entities": []}, {"text": "Finally, in the Uralic family we experiment on Estonian (et), Finnish (fi) and Hungarian (hu).", "labels": [], "entities": []}, {"text": "We use the morphological tagging datasets provided by the Universal Dependencies (UD) treebanks (the concatenation of the 4 th and 6 th columns of the file format) (.", "labels": [], "entities": [{"text": "Universal Dependencies (UD) treebanks", "start_pos": 58, "end_pos": 95, "type": "DATASET", "confidence": 0.5666521241267523}]}, {"text": "We list the size of the training, development and test splits of the UD treebanks we used in.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.8791500926017761}]}, {"text": "Also, we list the number of unique morphological tags in each language in, which serves as an approximate measure of the morphological complexity each language exhibits.", "labels": [], "entities": []}, {"text": "Crucially, the data are annotated in a cross-linguistically consistent manner, such that words in the different languages that have the same syntacto-semantic function have the same bundle of tags (see \u00a72 fora discussion).", "labels": [], "entities": []}, {"text": "Potentially, further gains would be possible by using a more universal scheme, e.g., the UNIMORPH scheme.", "labels": [], "entities": [{"text": "UNIMORPH scheme", "start_pos": 89, "end_pos": 104, "type": "DATASET", "confidence": 0.8504326641559601}]}, {"text": "We train our models with the following conditions.", "labels": [], "entities": []}, {"text": "We evaluate using average per token accuracy, as is standard for both POS tagging and morphological tagging, and per feature F 1 as employed in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9679000973701477}, {"text": "POS tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.65043605864048}]}, {"text": "The per feature F 1 calculates a key F k 1 for each key in the target language's tags by asking if the keyattribute pair k i =v i is in the predicted tag.", "labels": [], "entities": []}, {"text": "Then, the key-specific F k 1 values are averaged equally.", "labels": [], "entities": []}, {"text": "Note that F 1 is a more flexible metric as it gives partial credit forgetting some of the attributes in the bundle correct, where accuracy does not.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9913447797298431}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9984365105628967}]}, {"text": "Our networks are four layers deep (two LSTM layers for the character embedder, i.e., to compute vi and two LSTM layers for the tagger, i.e., to compute e i ) and we use an embedding size of 128 for the character input vector size and hidden layers of 256 nodes in all other cases.", "labels": [], "entities": []}, {"text": "All networks are trained with the stochastic gradient method RMSProp, with a fixed initial learning rate and a learning rate decay that is adjusted for the other languages according to the amount of training data.", "labels": [], "entities": [{"text": "RMSProp", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.6974607706069946}, {"text": "learning rate decay", "start_pos": 111, "end_pos": 130, "type": "METRIC", "confidence": 0.8306548595428467}]}, {"text": "The batch size is always 16.", "labels": [], "entities": []}, {"text": "Furthermore, we use dropout ().", "labels": [], "entities": []}, {"text": "The dropout probability is set to 0.2.", "labels": [], "entities": [{"text": "dropout probability", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.8859217166900635}]}, {"text": "We used Torch 7 ( to configure the computation graphs implementing the network architectures.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of tokens in each of the train, development  and test splits (organized by language family).", "labels": [], "entities": []}, {"text": " Table 4: Results for transfer learning with our joint model. The tables highlight that the best source languages are often  genetically and typologically closest. Also, we see that multi-source often helps, albeit more often in the |Dt| = 100 case.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.9152867496013641}]}, {"text": " Table 5: Comparison of our approach to various baselines for low-resource tagging under token-level accuracy. We compare on  only those languages in Buys and Botha (2016). Note that tag-level accuracy was not reported in the original B&B paper, but  was acquired through personal communication with the first author. All architectures presented in this work are used in their  multi-source setting. The B&B and MARMOT models are single-source.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 193, "end_pos": 201, "type": "METRIC", "confidence": 0.9106415510177612}, {"text": "B&B paper", "start_pos": 235, "end_pos": 244, "type": "DATASET", "confidence": 0.8034631162881851}, {"text": "B&B", "start_pos": 404, "end_pos": 407, "type": "DATASET", "confidence": 0.9410763581593832}]}, {"text": " Table 6: Comparison of our approach to various baselines for low-resource tagging under F1 to allow for a more complete  comparison to the model of Buys and Botha (2016). All architectures presented in this work are used in their multi-source setting.  The B&B and MARMOT models are single-source. We only compare on those languages used in B&B.", "labels": [], "entities": [{"text": "F1", "start_pos": 89, "end_pos": 91, "type": "METRIC", "confidence": 0.9693296551704407}, {"text": "B&B", "start_pos": 258, "end_pos": 261, "type": "DATASET", "confidence": 0.8548128803571066}]}]}