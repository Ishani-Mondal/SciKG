{"title": [{"text": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm", "labels": [], "entities": [{"text": "detecting sentiment, emotion and sarcasm", "start_pos": 76, "end_pos": 116, "type": "TASK", "confidence": 0.8131343225638071}]}], "abstractContent": [{"text": "NLP tasks are often limited by scarcity of manually annotated data.", "labels": [], "entities": []}, {"text": "In social media sentiment analysis and related tasks, researchers have therefore used binarized emoticons and specific hashtags as forms of distant supervision.", "labels": [], "entities": [{"text": "social media sentiment analysis", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7570755630731583}]}, {"text": "Our paper shows that by extending the distant supervision to a more diverse set of noisy labels, the models can learn richer representations.", "labels": [], "entities": []}, {"text": "Through emoji prediction on a dataset of 1246 million tweets containing one of 64 common emojis we obtain state-of-the-art performance on 8 benchmark datasets within emotion, sentiment and sarcasm detection using a single pretrained model.", "labels": [], "entities": [{"text": "emoji prediction", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.9225151836872101}, {"text": "emotion, sentiment and sarcasm detection", "start_pos": 166, "end_pos": 206, "type": "TASK", "confidence": 0.6790366421143214}]}, {"text": "Our analyses confirm that the diversity of our emotional labels yield a performance improvement over previous distant supervision approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "A variety of NLP tasks are limited by scarcity of manually annotated data.", "labels": [], "entities": []}, {"text": "Therefore, co-occurring emotional expressions have been used for distant supervision in social media sentiment analysis and related tasks to make the models learn useful text representations before modeling these tasks directly.", "labels": [], "entities": [{"text": "social media sentiment analysis", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.7265526354312897}]}, {"text": "For instance, the state-of-the-art approaches within sentiment analysis of social media data use positive/negative emoticons for training their models ().", "labels": [], "entities": [{"text": "sentiment analysis of social media", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.9075238108634949}]}, {"text": "Similarly, hashtags such as #anger, #joy, #happytweet, #ugh, #yuck and #fml have in previous research been mapped into emotional categories for emotion analysis.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 144, "end_pos": 160, "type": "TASK", "confidence": 0.7382368743419647}]}, {"text": "Distant supervision on noisy labels often enables a model to obtain better performance on the target task.", "labels": [], "entities": []}, {"text": "In this paper, we show that extending the distant supervision to a more diverse set of noisy labels enables the models to learn richer representations of emotional content in text, thereby obtaining better performance on benchmarks for detecting sentiment, emotions and sarcasm.", "labels": [], "entities": [{"text": "detecting sentiment, emotions and sarcasm", "start_pos": 236, "end_pos": 277, "type": "TASK", "confidence": 0.8287271857261658}]}, {"text": "We show that the learned representation of a single pretrained model generalizes across 5 domains.", "labels": [], "entities": []}, {"text": "Emojis are not always a direct labeling of emotional content.", "labels": [], "entities": []}, {"text": "For instance, a positive emoji may serve to disambiguate an ambiguous sentence or to complement an otherwise relatively negative text.", "labels": [], "entities": []}, {"text": "discuss a similar duality in the use of emotional hashtags such as #nice and #lame.", "labels": [], "entities": []}, {"text": "Nevertheless, our work shows that emojis can be used to classify the emotional content of texts accurately in many cases.", "labels": [], "entities": [{"text": "classify the emotional content of texts", "start_pos": 56, "end_pos": 95, "type": "TASK", "confidence": 0.799272229274114}]}, {"text": "For instance, our DeepMoji model captures varied usages of the word 'love' as well as slang such as 'this is the shit' being a positive statement (see).", "labels": [], "entities": []}, {"text": "We provide an online demo at deepmoji.mit.edu to allow others to explore the predictions of our model.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example sentences scored by our model.  For each text the top five most likely emojis are  shown with the model's probability estimates.", "labels": [], "entities": []}, {"text": " Table 2: The number of tweets in the pretraining  dataset associated with each emoji in millions.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of classifiers on the emoji  prediction task. d refers to the dimensionality of  each LSTM layer. Parameters are in millions.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.992051362991333}, {"text": "emoji  prediction task", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.8701839844385783}, {"text": "Parameters", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9452327489852905}]}, {"text": " Table 4: Description of benchmark datasets. Datasets without pre-existing training/test splits are split by  us (with splits publicly available). Data used for hyperparameter tuning is taken from the training set.", "labels": [], "entities": []}, {"text": " Table 5: Comparison across benchmark datasets. Reported values are averages across five runs. Varia- tions refer to transfer learning approaches in  \u00a73.3 with 'new' being a model trained without pretraining.", "labels": [], "entities": []}, {"text": " Table 6: Benchmarks using a smaller emoji set  (Pos/Neg emojis) or a classic architecture (stan- dard LSTM). Results for DeepMoji from", "labels": [], "entities": []}, {"text": " Table 5. Reported values are the averages  across five runs.", "labels": [], "entities": [{"text": "Reported", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9865899085998535}]}, {"text": " Table 7: Word coverage on benchmark test sets  using only the vocabulary generated by finding  words in the training data ('own'), the pretrain- ing vocabulary ('last') or a combination of both  vocabularies ('full / chain-thaw').", "labels": [], "entities": [{"text": "Word coverage", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7357205450534821}]}, {"text": " Table 8: Comparison of agreement between clas- sifiers and the aggregate opinion of Amazon  Mechanical Turkers on sentiment prediction of  tweets.", "labels": [], "entities": [{"text": "sentiment prediction of  tweets", "start_pos": 115, "end_pos": 146, "type": "TASK", "confidence": 0.8677851408720016}]}]}