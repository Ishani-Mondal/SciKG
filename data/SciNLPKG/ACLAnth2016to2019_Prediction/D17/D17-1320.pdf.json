{"title": [{"text": "Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of Concept Maps", "labels": [], "entities": []}], "abstractContent": [{"text": "Concept maps can be used to concisely represent important information and bring structure into large document collections.", "labels": [], "entities": []}, {"text": "Therefore, we study a variant of multi-document summarization that produces summaries in the form of concept maps.", "labels": [], "entities": []}, {"text": "However, suitable evaluation datasets for this task are currently missing.", "labels": [], "entities": []}, {"text": "To close this gap, we present a newly created corpus of concept maps that summarize heterogeneous collections of web documents on educational topics.", "labels": [], "entities": []}, {"text": "It was created using a novel crowdsourcing approach that allows us to efficiently determine important elements in large document collections.", "labels": [], "entities": []}, {"text": "We release the corpus along with a baseline system and proposed evaluation protocol to enable further research on this variant of summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 130, "end_pos": 143, "type": "TASK", "confidence": 0.961571216583252}]}], "introductionContent": [{"text": "Multi-document summarization (MDS), the transformation of a set of documents into a short text containing their most important aspects, is a longstudied problem in NLP.", "labels": [], "entities": [{"text": "Multi-document summarization (MDS)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8871960282325745}]}, {"text": "Generated summaries have been shown to support humans dealing with large document collections in information seeking tasks).", "labels": [], "entities": [{"text": "information seeking tasks", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.766084631284078}]}, {"text": "However, when exploring a set of documents manually, humans rarely write a fully-formulated summary for themselves.", "labels": [], "entities": []}, {"text": "Instead, user studies ( show that they note down important keywords and phrases, try to identify relationships between them and organize them accordingly.", "labels": [], "entities": []}, {"text": "Therefore, we believe that the study of summarization with similarly structured outputs is an important extension of the traditional task.", "labels": [], "entities": [{"text": "summarization", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.9730737209320068}]}, {"text": "A representation that is more inline with observed user behavior is a concept map, a labeled graph showing concepts as nodes and relationships between them as edges ().", "labels": [], "entities": []}, {"text": "Introduced in 1972 as a teaching tool, concept maps have found many applications in education, for writing assistance) or to structure information repositories ().", "labels": [], "entities": []}, {"text": "For summarization, concept maps make it possible to represent a summary concisely and clearly reveal relationships.", "labels": [], "entities": [{"text": "summarization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9788779616355896}]}, {"text": "Moreover, we see a second interesting use case that goes beyond the capabilities of textual summaries: When concepts and relations are linked to corresponding locations in the documents they have been extracted from, the graph can be used to navigate in a document collection, similar to a table of contents.", "labels": [], "entities": []}, {"text": "An implementation of this idea has been recently described by.", "labels": [], "entities": []}, {"text": "The corresponding task that we propose is concept-map-based MDS, the summarization of a document cluster in the form of a concept map.", "labels": [], "entities": []}, {"text": "In order to develop and evaluate methods for the task, gold-standard corpora are necessary, but no suitable corpus is available.", "labels": [], "entities": []}, {"text": "The manual creation of such a dataset is very time-consuming, as the annotation includes many subtasks.", "labels": [], "entities": []}, {"text": "In particular, an annotator would need to manually identify all concepts in the documents, while only a few of them will eventually end up in the summary.: Excerpt from a summary concept map on the topic \"students loans without credit history\".", "labels": [], "entities": []}, {"text": "To overcome these issues, we present a corpus creation method that effectively combines automatic preprocessing, scalable crowdsourcing and high-quality expert annotations.", "labels": [], "entities": [{"text": "corpus creation", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7027323693037033}]}, {"text": "Using it, we can avoid the high effort for single annotators, allowing us to scale to document clusters that are 15 times larger than in traditional summarization corpora.", "labels": [], "entities": []}, {"text": "We created anew corpus of 30 topics, each with around 40 source documents on educational topics and a summarizing concept map that is the consensus of many crowdworkers (see.", "labels": [], "entities": []}, {"text": "As a crucial step of the corpus creation, we developed anew crowdsourcing scheme called lowcontext importance annotation.", "labels": [], "entities": []}, {"text": "In contrast to traditional approaches, it allows us to determine important elements in a document cluster without requiring annotators to read all documents, making it feasible to crowdsource the task and overcome quality issues observed in previous work).", "labels": [], "entities": []}, {"text": "We show that the approach creates reliable data for our focused summarization scenario and, when tested on traditional summarization corpora, creates annotations that are similar to those obtained by earlier efforts.", "labels": [], "entities": [{"text": "summarization", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.9341059923171997}]}, {"text": "To summarize, we make the following contributions: (1) We propose a novel task, concept-mapbased MDS ( \u00a72), (2) present anew crowdsourcing scheme to create reference summaries ( \u00a74), (3) publish anew dataset for the proposed task ( \u00a75) and (4) provide an evaluation protocol and baseline ( \u00a77).", "labels": [], "entities": [{"text": "summarize", "start_pos": 3, "end_pos": 12, "type": "TASK", "confidence": 0.9809564352035522}]}, {"text": "We make these resources publicly available under a permissive license.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we briefly describe a baseline and evaluation scripts that we release, with a detailed documentation, along with the corpus.", "labels": [], "entities": []}, {"text": "Baseline Method We implemented a simple approach inspired by previous work on concept map generation and keyphrase extraction.", "labels": [], "entities": [{"text": "concept map generation", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6674203872680664}, {"text": "keyphrase extraction", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.8223512172698975}]}, {"text": "For a document cluster, it performs the following steps: 1.", "labels": [], "entities": []}, {"text": "Extract all NPs as potential concepts.", "labels": [], "entities": []}, {"text": "2. Merge potential concepts whose labels match after stemming into a single concept.", "labels": [], "entities": []}, {"text": "3. For each pair of concepts co-occurring in a sentence, select the tokens in between as a potential relation if they contain a verb.", "labels": [], "entities": []}, {"text": "4. If a pair of concepts has more than one relation, select the one with the shortest label.", "labels": [], "entities": []}, {"text": "5. Assign an importance score to every concept and rank them accordingly.", "labels": [], "entities": []}, {"text": "For, we trained a binary classifier to identify the important concepts in the set of all potential concepts.", "labels": [], "entities": []}, {"text": "We used common features for keyphrase extraction, including position, frequency and length, and Weka's Random Forest () implementation as the model.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.834793210029602}]}, {"text": "At inference time, we use the classifiers confidence fora positive classification as the score.", "labels": [], "entities": []}, {"text": "In step (6), we start with the full graph of all extracted concepts and relations and use a heuristic to find a subgraph that is connected, satisfies the size limit of 25 concepts and has many highscoring concepts: We iteratively remove the weakest concept until only one connected component of 25 concepts or less remains, which is used the summary concept map.", "labels": [], "entities": []}, {"text": "This approach guarantees that the concept map is connected, but might not find the subset of concepts that has the highest total importance score.", "labels": [], "entities": []}, {"text": "Evaluation Metrics In order to automatically compare generated concept maps with reference maps, we propose three metrics.", "labels": [], "entities": []}, {"text": "As a concept map is fully defined by the set of its propositions, we can compute precision, recall and F1-scores between the two proposition set of generated and reference map.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9994162321090698}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9994021654129028}, {"text": "F1-scores", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9983810186386108}]}, {"text": "A proposition is represented as the concatenation of concept and relation labels.", "labels": [], "entities": []}, {"text": "Strict Match compares them after stemming and only counts exact and complete matches.), we offer a second metric that takes synonyms and paraphrases into account and also scores partial matches.", "labels": [], "entities": []}, {"text": "And finally, we compute ROUGE-2) between the concatenation of all propositions from the maps.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9979414343833923}]}, {"text": "These automatic measures might be complemented with a human evaluation.", "labels": [], "entities": []}, {"text": "Results shows the performance of the baseline.", "labels": [], "entities": []}, {"text": "An analysis of the single pipeline steps revealed major bottlenecks of the method and challenges of the task.", "labels": [], "entities": []}, {"text": "First, we observed that around 76% of gold concepts are covered by the extraction (step 1+2), while the top 25 concepts (step 5) only contain 17% of the gold concepts.", "labels": [], "entities": []}, {"text": "Hence, content selection is a major challenge, stemming from the large cluster sizes in the corpus.", "labels": [], "entities": [{"text": "content selection", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7926454246044159}]}, {"text": "Second, while also 17% of gold concepts are contained in the final maps (step 6), scores for strict proposition matching are low, indicating a poor performance of the relation extraction (step 3).", "labels": [], "entities": [{"text": "proposition matching", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.704748272895813}, {"text": "relation extraction", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.7222344279289246}]}, {"text": "The propagation of these errors along the pipeline contributes to overall low scores.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Correlation of peer scores with manual  responsiveness scores on TAC2008 topics 01-03.", "labels": [], "entities": [{"text": "TAC2008 topics 01-03", "start_pos": 75, "end_pos": 95, "type": "DATASET", "confidence": 0.8486722906430563}]}, {"text": " Table 2: Topic clusters in comparison to classic corpora (size in token, mean with standard deviation).", "labels": [], "entities": []}, {"text": " Table 4: Baseline performance on test set.", "labels": [], "entities": []}]}