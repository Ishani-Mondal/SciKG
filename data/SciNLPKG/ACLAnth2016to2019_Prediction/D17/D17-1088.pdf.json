{"title": [{"text": "Deep Neural Solver for Math Word Problems", "labels": [], "entities": [{"text": "Math Word Problems", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7724041740099589}]}], "abstractContent": [{"text": "This paper presents a deep neural solver to automatically solve math word problems.", "labels": [], "entities": [{"text": "deep neural solver", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7083901564280192}]}, {"text": "In contrast to previous statistical learning approaches, we directly translate math word problems to equation templates using a recurrent neural network (RNN) model, without sophisticated feature engineering.", "labels": [], "entities": []}, {"text": "We further design a hybrid model that combines the RNN model and a similarity-based retrieval model to achieve additional performance improvement.", "labels": [], "entities": []}, {"text": "Experiments conducted on a large dataset show that the RNN model and the hybrid model significantly outperform state-of-the-art statistical learning methods for math word problem solving.", "labels": [], "entities": [{"text": "math word problem solving", "start_pos": 161, "end_pos": 186, "type": "TASK", "confidence": 0.7278867736458778}]}], "introductionContent": [{"text": "Developing computer models to automatically solve math word problems has been an interest of NLP researchers;;;.", "labels": [], "entities": []}, {"text": "Recently, machine learning techniques ;;; and semantic parsing methods; are proposed to tackle this problem and promising results are reported on some datasets.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7174225002527237}]}, {"text": "Although progress has been made in this task, performance of state-of-the-art techniques is still quite low on large datasets having diverse problem types.", "labels": [], "entities": []}, {"text": "A typical math word problems are shown in Table 1.", "labels": [], "entities": []}, {"text": "The reader is asked to infer how many pens Dan and Jessica have, based on constraints provided.", "labels": [], "entities": []}, {"text": "Given the success of deep neural networks (DNN) on many NLP tasks (like POS tagging, Problem: Dan have 2 pens, Jessica have 4 pens.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.7754463851451874}]}, {"text": "How many pens do they have in total ? Equation: x = 4+2 Solution: 6: A math word problem syntactic parsing, and machine translation), it maybe interesting to study whether DNN could also help math word problem solving.", "labels": [], "entities": [{"text": "Equation", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9913803935050964}, {"text": "math word problem syntactic parsing", "start_pos": 71, "end_pos": 106, "type": "TASK", "confidence": 0.5726155281066895}, {"text": "machine translation", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7115611135959625}, {"text": "math word problem solving", "start_pos": 192, "end_pos": 217, "type": "TASK", "confidence": 0.7450259774923325}]}, {"text": "In this paper, we propose a recurrent neural network (RNN) model for automatic math word problem solving.", "labels": [], "entities": [{"text": "automatic math word problem solving", "start_pos": 69, "end_pos": 104, "type": "TASK", "confidence": 0.6764570415019989}]}, {"text": "It is a sequence to sequence (seq2seq) model that transforms natural language sentences in math word problems to mathematical equations.", "labels": [], "entities": []}, {"text": "Experiments conducted on a large dataset show that the RNN model significantly outperforms state-of-the-art statistical learning approaches.", "labels": [], "entities": []}, {"text": "Since it has been demonstrated that a simple similarity based method performs as well as more sophisticated statistical learning approaches on large datasets, we implement a similarity-based retrieval model and compare with our seq2seq model.", "labels": [], "entities": []}, {"text": "We observe that although seq2seq performs better on average, the retrieval model is able to correctly solve many problems for which RNN generates wrong results.", "labels": [], "entities": []}, {"text": "We also find that the accuracy of the retrieval model positively correlate with the maximal similarity score between the target problem and the problems in training data: the larger the similarity score, the higher the average accuracy is.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.998704195022583}, {"text": "maximal similarity score", "start_pos": 84, "end_pos": 108, "type": "METRIC", "confidence": 0.7446217139561971}, {"text": "similarity", "start_pos": 186, "end_pos": 196, "type": "METRIC", "confidence": 0.9576773643493652}, {"text": "accuracy", "start_pos": 227, "end_pos": 235, "type": "METRIC", "confidence": 0.9966084957122803}]}, {"text": "Inspired by these observations, we design a hybrid model which combines the seq2seq model and the retrieval model.", "labels": [], "entities": []}, {"text": "In the hybrid model, the retrieval model is chosen if the maximal similarity score returned by the retrieval model is larger than a threshold, otherwise the seq2seq model is selected to solve the problem.", "labels": [], "entities": [{"text": "maximal similarity score returned", "start_pos": 58, "end_pos": 91, "type": "METRIC", "confidence": 0.7771369069814682}]}, {"text": "Experiments on our dataset show that, by introducing the hybrid model, the accuracy increases from 58.1% to 64.7%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9997356534004211}]}, {"text": "Our contributions are as follows: 1) To the best of our knowledge, this is the first work of using DNN technology for automatic math word problem solving.", "labels": [], "entities": [{"text": "automatic math word problem solving", "start_pos": 118, "end_pos": 153, "type": "TASK", "confidence": 0.6392283856868743}]}, {"text": "2) We propose a hybrid model where a seq2seq model and a similarity-based retrieval model are combined to achieve further performance improvement.", "labels": [], "entities": []}, {"text": "3) A large dataset is constructed for facilitating the study of automatic math problem solving.", "labels": [], "entities": [{"text": "automatic math problem solving", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.6504789218306541}]}, {"text": "The remaining part of this paper is organized as follows: After analyzing related work in Section 2, we formalize the problem and introduce our dataset in Section 3.", "labels": [], "entities": []}, {"text": "We present our RNN-based seq2seq model in Section 4, and the hybrid model in Section 5.", "labels": [], "entities": []}, {"text": "Then experimental results are shown and analyzed in Section 6.", "labels": [], "entities": []}, {"text": "Finally we conclude the paper in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "Most public datasets for automatic math word problem solving are quite small and contains limited types of problems.", "labels": [], "entities": [{"text": "automatic math word problem solving", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.6355160117149353}]}, {"text": "The most frequently used Alg514 ( ) dataset contains only 514 linear algebra problems with 28 equation templates.", "labels": [], "entities": [{"text": "Alg514 ( ) dataset", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.8104550838470459}]}, {"text": "There are 1,000 problems in the newly constructed DRAW-1K) dataset.", "labels": [], "entities": [{"text": "DRAW-1K) dataset", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.9484177430470785}]}, {"text": "Dophin1878 () includes 1,878 number word problems.", "labels": [], "entities": [{"text": "Dophin1878", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.953911304473877}]}, {"text": "An exception is the Dolphin18K dataset () which contains 18,000+ problems.", "labels": [], "entities": [{"text": "Dolphin18K dataset", "start_pos": 20, "end_pos": 38, "type": "DATASET", "confidence": 0.9876636564731598}]}, {"text": "However, this dataset has not been made publicly available so far.", "labels": [], "entities": []}, {"text": "Since DNN-based approaches typically need large training data, we have to build a large dataset of labeled math word problems.", "labels": [], "entities": []}, {"text": "We crawl over 60,000 Chinese math word problems from a couple of online education web sites.", "labels": [], "entities": []}, {"text": "All of them are real math word problems for elementary school students.", "labels": [], "entities": []}, {"text": "We focus on one-unknown-variable linear math word problems in this paper.", "labels": [], "entities": []}, {"text": "For other problem types, we would like to leave as future work.", "labels": [], "entities": []}, {"text": "Please pay attention that the solutions to the problems are in natural language, and we have to extract equation systems and structured answers from the solution text.", "labels": [], "entities": []}, {"text": "We implement a rule-based extraction method for this purpose, which achieves very high precision and medium recall.", "labels": [], "entities": [{"text": "rule-based extraction", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.6675644963979721}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9993618130683899}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9968354105949402}]}, {"text": "That is, most equations and structured answers extracted by our method are correct, and many problems are dropped from the dataset.", "labels": [], "entities": []}, {"text": "As a result, we get dataset Math23k which contains 23,161 problems labeled with structured equations and answers.", "labels": [], "entities": []}, {"text": "Please refer to for some statistics of the dataset and a comparison with other public datasets.", "labels": [], "entities": []}, {"text": "In this section, we conduct experiments on two datasets to examine the performance of the proposed models.", "labels": [], "entities": []}, {"text": "Our main experimental result is to show a significant improvement over the baseline Algorithm 1 Hybrid model Input: Q: problems in training data; PT : testing problem; \u03b8: pre-defined threshold of similarity Output: Problem solution 1: Get equation templates and number mappings for training problems Q and testing problem PT . 2: Number identification: identify significant numbers 3: Retrieval: choose problem Q 1 from Q that has the maximal Jaccard similarity with PT 4: if J(P T , Q 1 ) > \u03b8 then 5: Apply the retrieval model: select equation template T of Q 1 6: else  Datasets: As introduced in Section 3.2, we collected a dataset called Math23K which contains 23161 math word problems labeled with equation templates and answers.", "labels": [], "entities": [{"text": "Number identification", "start_pos": 330, "end_pos": 351, "type": "TASK", "confidence": 0.8193841874599457}, {"text": "Apply", "start_pos": 502, "end_pos": 507, "type": "METRIC", "confidence": 0.9909018874168396}]}, {"text": "All these problems are linear algebra questions with only one variable.", "labels": [], "entities": []}, {"text": "There are 2187 equation templates in the dataset.", "labels": [], "entities": []}, {"text": "In addition, we also evaluate our method on a public dataset Alg514 ( ).", "labels": [], "entities": [{"text": "public dataset Alg514", "start_pos": 46, "end_pos": 67, "type": "DATASET", "confidence": 0.6958748499552408}]}, {"text": "Baseline: We compare our proposed methods with two baselines.", "labels": [], "entities": []}, {"text": "The first baseline is the retrieval model introduced in Section 5.1.", "labels": [], "entities": []}, {"text": "The second one is ZDC (, which is an improved version of KAZB (: Result of significance test.", "labels": [], "entities": [{"text": "KAZB", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.6873710751533508}]}, {"text": "The meaning of abbreviations in this table is as follows: R: retrieval model w/o SNI; R(S): retrieval model w/ S-NI; Seq: seq2seq model w/o SNI; Seq(S): seq2seq model w/ SNI; H: hybrid model w/o SNI; H(S): hybrid model w/ SNI to Stanford coreNLP output formats.", "labels": [], "entities": [{"text": "Stanford coreNLP output formats", "start_pos": 229, "end_pos": 260, "type": "DATASET", "confidence": 0.7292401418089867}]}, {"text": "Each approach is evaluated on each dataset via 5-fold cross-validation: In each run, 4 folds are used for training and 1 fold is used for testing.", "labels": [], "entities": []}, {"text": "Evaluation results are summarized in.", "labels": [], "entities": []}, {"text": "First, to test the effectiveness of significant number identification (SNI), model performance before and after the application of SNI are compared.", "labels": [], "entities": [{"text": "significant number identification (SNI)", "start_pos": 36, "end_pos": 75, "type": "TASK", "confidence": 0.7810740768909454}]}, {"text": "Then, the performance of the hybrid model, seq2seq model, and retrieval model are examined on two datasets respectively.", "labels": [], "entities": []}, {"text": "To check whether the performance improvements are significant enough, we conduct statistical significance study upon pairs of methods.", "labels": [], "entities": []}, {"text": "Table 6 shows the results of sign test, where the symbol > indicates that the method in the row significantly (with p value < 0.05) improves the performance of the method in the column, and the symbol indicates that the performance improvement is extremely significant (with p value < 0.01).", "labels": [], "entities": []}, {"text": "Several observations can be made from the re-sults.", "labels": [], "entities": []}, {"text": "First, the seq2seq model significantly outperforms state-of-the-art statistical learning methods (ZDC and the retrieval model).", "labels": [], "entities": []}, {"text": "Second, by combining the retrieval model and the seq2seq model using a simple mechanism, our hybrid model achieves significant performance gain with respect to the seq2seq model.", "labels": [], "entities": []}, {"text": "Third, the SNI module can effectively improve model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9872866272926331}]}, {"text": "The accuracy of the hybrid model and seq2seq model gains approximately 4% increase after number identification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997318387031555}, {"text": "number identification", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.7002154588699341}]}, {"text": "Please pay attention that on the small dataset of Alg514, the seq2seq model behaves much worse than others.", "labels": [], "entities": []}, {"text": "This is not surprising, because deep neural networks typically need large training data.", "labels": [], "entities": []}, {"text": "shows the performance of different models on various scales of training data.", "labels": [], "entities": []}, {"text": "As expected, the seq2seq model performs very well on big datasets, but poorly on small datasets.", "labels": [], "entities": []}, {"text": "Ability to Generate New Equation Templates: please note that many problems in Math23K can be solved using the same equation template.", "labels": [], "entities": []}, {"text": "For example, a problem which corresponds to the equation x = (9 * 3) + 7 and a different problem that maps to x = (4 * 5) + 2 share the same equation template.", "labels": [], "entities": []}, {"text": "One nice property of the seq2seq model is its ability of generating new equation templates.", "labels": [], "entities": []}, {"text": "Most previous statistical learning methods (with a few exceptions) for math word problem solving are only able to select an equation template from those in the training data.", "labels": [], "entities": [{"text": "math word problem solving", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.7947598546743393}]}, {"text": "Experimental results on the new training set and test set are shown is shown in.", "labels": [], "entities": []}, {"text": "By comparing, it is clear that the gap between the seq2seq model and the baselines becomes larger in the new settings.", "labels": [], "entities": []}, {"text": "It is because the seq2seq model can effectively generate new equation templates for new problems, instead of selecting equation templates from the training set.", "labels": [], "entities": []}, {"text": "Although ZDC and the retrieval model cannot generate new templates, their accuracy is not zero in the new settings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.999315619468689}]}, {"text": "That is because one problem can be solved by multiple equation templates: Although one problem is labeled with template T 1 in the test set, it may also be solved by another template T 2 in the training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Statistics of our dataset and several publicly available datasets", "labels": [], "entities": []}, {"text": " Table 7: Experimental results of non-overlapping  templates between training data and test data", "labels": [], "entities": []}]}