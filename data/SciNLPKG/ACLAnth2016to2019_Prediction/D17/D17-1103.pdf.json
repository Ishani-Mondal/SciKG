{"title": [{"text": "Reinforced Video Captioning with Entailment Rewards", "labels": [], "entities": [{"text": "Reinforced Video Captioning", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.796565572420756}]}], "abstractContent": [{"text": "Sequence-to-sequence models have shown promising improvements on the temporal task of video captioning, but they optimize word-level cross-entropy loss during training.", "labels": [], "entities": [{"text": "video captioning", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.728876531124115}]}, {"text": "First, using policy gradient and mixed-loss methods for reinforcement learning, we directly optimize sentence-level task-based metrics (as rewards), achieving significant improvements over the baseline, based on both automatic metrics and human evaluation on multiple datasets.", "labels": [], "entities": []}, {"text": "Next, we propose a novel entailment-enhanced reward (CIDEnt) that corrects phrase-matching based metrics (such as CIDEr) to only allow for logically-implied partial matches and avoid contradictions, achieving further significant improvements over the CIDEr-reward model.", "labels": [], "entities": []}, {"text": "Overall, our CIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.", "labels": [], "entities": [{"text": "MSR-VTT dataset", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.9416452646255493}]}], "introductionContent": [{"text": "The task of video captioning ( is an important next step to image captioning, with additional modeling of temporal knowledge and action sequences, and has several applications in online content search, assisting the visuallyimpaired, etc.", "labels": [], "entities": [{"text": "video captioning", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.749830573797226}, {"text": "image captioning", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.7314669638872147}]}, {"text": "Advancements in neural sequenceto-sequence learning has shown promising improvements on this task, based on encoderdecoder, attention, and hierarchical models ().", "labels": [], "entities": []}, {"text": "However, these models are still trained using a wordlevel cross-entropy loss, which does not correlate well with the sentence-level metrics that the task is finally evaluated on (e.g., CIDEr, BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 192, "end_pos": 196, "type": "METRIC", "confidence": 0.9966304898262024}]}, {"text": "Moreover, these models suffer from exposure bias (Ran-: A correctly-predicted video caption generated by our CIDEnt-reward model., which occurs when a model is only exposed to the training data distribution, instead of its own predictions.", "labels": [], "entities": []}, {"text": "First, using a sequence-level training, policy gradient approach (, we allow video captioning models to directly optimize these nondifferentiable metrics, as rewards in a reinforcement learning paradigm.", "labels": [], "entities": []}, {"text": "We also address the exposure bias issue by using a mixed-loss (, i.e., combining the cross-entropy and reward-based losses, which also helps maintain output fluency.", "labels": [], "entities": []}, {"text": "Next, we introduce a novel entailment-corrected reward that checks for logically-directed partial matches.", "labels": [], "entities": []}, {"text": "Current reinforcement-based text generation works use traditional phrase-matching metrics (e.g., CIDEr, BLEU) as their reward function.", "labels": [], "entities": [{"text": "reinforcement-based text generation", "start_pos": 8, "end_pos": 43, "type": "TASK", "confidence": 0.6298457682132721}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9975383281707764}]}, {"text": "However, these metrics use undirected ngram matching of the machine-generated caption with the ground-truth caption, and hence fail to capture its directed logical correctness.", "labels": [], "entities": []}, {"text": "Therefore, they still give high scores to even those generated captions that contain a single but critical wrong word (e.g., negation, unrelated action or object), because all the other words still match with the ground truth.", "labels": [], "entities": []}, {"text": "We introduce CIDEnt, which penalizes the phrase-matching metric (CIDEr) based reward, when the entailment score is low.", "labels": [], "entities": []}, {"text": "This ensures that a generated caption gets a high re- ward only when it is a directed match with (i.e., it is logically implied by) the ground truth caption, hence avoiding contradictory or unrelated information (e.g., see).", "labels": [], "entities": [{"text": "re- ward", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9855802655220032}]}, {"text": "Empirically, we show that first the CIDEr-reward model achieves significant improvements over the cross-entropy baseline (on multiple datasets, and automatic and human evaluation); next, the CIDEnt-reward model further achieves significant improvements over the CIDEr-based reward.", "labels": [], "entities": []}, {"text": "Overall, we achieve the new state-of-the-art on the MSR-VTT dataset.", "labels": [], "entities": [{"text": "MSR-VTT dataset", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.9605523943901062}]}], "datasetContent": [{"text": "Datasets Human Evaluation We also present human evaluation for comparison of baseline-XE, CIDEr-RL, and CIDEnt-RL models, esp.", "labels": [], "entities": []}, {"text": "because the automatic metrics cannot be trusted solely.", "labels": [], "entities": []}, {"text": "Relevance measures how related is the generated caption w.r.t, to the video content, whereas coherence measures readability of the generated caption.", "labels": [], "entities": []}, {"text": "Training Details All the hyperparameters are tuned on the validation set.", "labels": [], "entities": []}, {"text": "All our results (including baseline) are based on a 5-avg-ensemble.", "labels": [], "entities": []}, {"text": "See supplementary for extra training details, e.g., about the optimizer, learning rate, RNN size, Mixed-loss, and CIDEnt hyperparameters.", "labels": [], "entities": []}, {"text": "shows our primary results on the popular MSR-VTT dataset.", "labels": [], "entities": [{"text": "MSR-VTT dataset", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9359497129917145}]}, {"text": "First, our baseline attention model trained on cross entropy loss ('Baseline-XE') achieves strong results w.r.t. the previous state-of-the-art methods.", "labels": [], "entities": []}, {"text": "Next, our policy gradient based mixed-loss RL model with reward as CIDEr ('CIDEr-RL') improves significantly 5 over the baseline on all metrics, and not just the CIDEr metric.", "labels": [], "entities": []}, {"text": "It also achieves statistically significant improvements in terms of human relevance evaluation (see below).", "labels": [], "entities": [{"text": "human relevance evaluation", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.7321434815724691}]}, {"text": "Finally, the last row in shows results for our novel CIDEnt-reward RL model ('CIDEnt-RL').", "labels": [], "entities": []}, {"text": "This model achieves statistically significant 6 improvements on top of the strong CIDEr-RL model, on all automatic metrics (as well as human evaluation).", "labels": [], "entities": []}, {"text": "Note that in, we also report the CIDEnt reward scores, and the CIDEnt-RL model strongly outperforms CIDEr and baseline models on this entailmentcorrected measure.", "labels": [], "entities": []}, {"text": "Overall, we are also the new Rank1 on the MSR-VTT leaderboard, based on their ranking criteria.", "labels": [], "entities": [{"text": "MSR-VTT leaderboard", "start_pos": 42, "end_pos": 61, "type": "DATASET", "confidence": 0.9461246132850647}]}, {"text": "We also tried our CIDEr and CIDEnt reward models on the YouTube2Text dataset.", "labels": [], "entities": [{"text": "YouTube2Text dataset", "start_pos": 56, "end_pos": 76, "type": "DATASET", "confidence": 0.9855145514011383}]}, {"text": "In, we first see strong improvements from our CIDEr-RL model on top of the cross-entropy baseline.", "labels": [], "entities": []}, {"text": "Next, the CIDEnt-RL model also shows some improvements over the CIDEr-RL model, e.g., on BLEU and the new entailment-corrected CIDEnt score.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9968170523643494}]}, {"text": "It also achieves significant improvements on human relevance evaluation (250 samples).", "labels": [], "entities": [{"text": "human relevance evaluation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.7236047188440958}]}], "tableCaptions": [{"text": " Table 1: Examples of captions sampled during policy gradient and their CIDEr vs Entailment scores.", "labels": [], "entities": []}, {"text": " Table 2: Our primary video captioning results on MSR-VTT. All CIDEr-RL results are statistically  significant over the baseline XE results, and all CIDEnt-RL results are stat. signif. over the CIDEr-RL  results. Human* refers to the 'pairwise' comparison of human relevance evaluation between CIDEr-RL  and CIDEnt-RL models (see full human evaluations of the 3 models in Table 3 and Table 4).", "labels": [], "entities": [{"text": "MSR-VTT", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.8816046118736267}]}, {"text": " Table 3: Human eval: Baseline-XE vs CIDEr-RL.", "labels": [], "entities": []}, {"text": " Table 4: Human eval: CIDEr-RL vs CIDEnt-RL.", "labels": [], "entities": []}, {"text": " Table 5: Results on YouTube2Text (MSVD)  dataset. CE = CIDEnt score. H* refer to the pair- wise human comparison of relevance.", "labels": [], "entities": [{"text": "YouTube2Text (MSVD)  dataset", "start_pos": 21, "end_pos": 49, "type": "DATASET", "confidence": 0.8942567467689514}, {"text": "CE", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9895219206809998}, {"text": "CIDEnt score", "start_pos": 56, "end_pos": 68, "type": "METRIC", "confidence": 0.9572876393795013}]}]}