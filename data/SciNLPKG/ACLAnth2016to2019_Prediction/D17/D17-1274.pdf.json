{"title": [{"text": "Improving Slot Filling Performance with Attentive Neural Networks on Dependency Structures", "labels": [], "entities": [{"text": "Improving Slot Filling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8220798969268799}]}], "abstractContent": [{"text": "Slot Filling (SF) aims to extract the values of certain types of attributes (or slots, such as person:cities of residence) fora given entity from a large collection of source documents.", "labels": [], "entities": [{"text": "Slot Filling (SF)", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8884450793266296}]}, {"text": "In this paper we propose an effective DNN architecture for SF with the following new strategies: (1).", "labels": [], "entities": [{"text": "SF", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.9674320220947266}]}, {"text": "Take a regu-larized dependency graph instead of a raw sentence as input to DNN, to compress the wide contexts between query and candidate filler; (2).", "labels": [], "entities": []}, {"text": "Incorporate two attention mechanisms: local attention learned from query and candidate filler, and global attention learned from external knowledge bases, to guide the model to better select indicative contexts to determine slot type.", "labels": [], "entities": []}, {"text": "Experiments show that this framework outperforms state-of-the-art on both relation extraction (16% absolute F-score gain) and slot filling validation for each individual system (up to 8.5% absolute F-score gain).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8296022415161133}, {"text": "F-score gain", "start_pos": 108, "end_pos": 120, "type": "METRIC", "confidence": 0.9120084047317505}, {"text": "slot filling validation", "start_pos": 126, "end_pos": 149, "type": "TASK", "confidence": 0.8761008183161417}]}], "introductionContent": [{"text": "The goal of Slot Filling (SF) is to extract pre-defined types of attributes or slots (e.g., per:cities of residence) fora given query entity from a large collection of documents.", "labels": [], "entities": [{"text": "Slot Filling (SF)", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.9499361872673034}]}, {"text": "The slot filler (attribute value) can bean entity, time expression or value (e.g., per:charges).", "labels": [], "entities": []}, {"text": "The TAC-KBP slot filling task () defined 41 slot types, including 25 types for person and 16 types for organization.", "labels": [], "entities": [{"text": "TAC-KBP slot filling task", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7369213104248047}]}, {"text": "One critical component of slot filling is relation extraction, namely to classify the relation between a pair of query entity and candidate slot * This work was carried out during an internship at IBM filler into one of the 41 types or none.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.8435329496860504}, {"text": "relation extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.8012973964214325}]}, {"text": "Most previous studies have treated SF in the same way as within-sentence relation extraction tasks in ACE 1 or SemEval ().", "labels": [], "entities": [{"text": "SF", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.8045146465301514}, {"text": "within-sentence relation extraction tasks", "start_pos": 57, "end_pos": 98, "type": "TASK", "confidence": 0.7082286700606346}]}, {"text": "They created training data based on crowd-sourcing or distant supervision, and then trained a multi-class classifier or multiple binary classifiers for each slot type based on a set of hand-crafted features.", "labels": [], "entities": []}, {"text": "Although Deep Neural Networks (DNN) such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) have achieved state-of-the-art results on within-sentence relation extraction (, there are limited studies on SF using DNN. and exploited DNN for SF but did not achieve comparable results as traditional methods.", "labels": [], "entities": [{"text": "within-sentence relation extraction", "start_pos": 158, "end_pos": 193, "type": "TASK", "confidence": 0.634221613407135}]}, {"text": "In this paper we aim to answer the following questions: What is the difference between SF and ACE/SemEval relation extraction task?", "labels": [], "entities": [{"text": "SF", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.9693183302879333}, {"text": "SemEval relation extraction", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.6705910364786783}]}, {"text": "How can we make DNN work for SF?", "labels": [], "entities": []}, {"text": "We argue that SF is different and more challenging than traditional relation extraction.", "labels": [], "entities": [{"text": "SF", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.9808821082115173}, {"text": "relation extraction", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8574587106704712}]}, {"text": "First, a query and its candidate filler are usually separated by much wider contexts than the entity pairs in traditional relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7250300794839859}]}, {"text": "As shows, in ACE data, for 70% of relations, two mentions are embedded in each other or separated by at most one word.", "labels": [], "entities": [{"text": "ACE data", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.727082371711731}]}, {"text": "In contrast, in SF, more than 46% of query, filler entity pairs are separated by at least 7 words.", "labels": [], "entities": [{"text": "SF", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9040704965591431}]}, {"text": "For example, in the following sentence: E1.", "labels": [], "entities": []}, {"text": "\"Arcandor query owns a 52-percent stake in Europe's second biggest tourism group Thomas Cook, the Karstadt chain of department stores and iconic shops such as the KaDeWe filler in what used to be the commercial heart of West Berlin.\", Here, Arcandor and KaDeWe are far separated and it's difficult to determine the slot type as org:subsidiaries based on the raw wide contexts.", "labels": [], "entities": [{"text": "Thomas Cook", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.9346516728401184}]}, {"text": "In addition, compared with relations defined in ACE (18 types) and SemEval (9 types), slot types are more fine-grained and heavily rely on indicative contextual words for disambiguation. and  demonstrate that many slot types can be specified by contextual trigger words.", "labels": [], "entities": []}, {"text": "Here, a trigger is defined as the word which is related to both the query and candidate filler, and can indicate the type of the target slot.", "labels": [], "entities": []}, {"text": "Considering E1 again, owns is a trigger word between Arcandor and KaDeWe, which can indicate the slot type as org:subsidiaries.", "labels": [], "entities": [{"text": "KaDeWe", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.8546549677848816}]}, {"text": "Most previous work manually constructed trigger lists for each slot type.", "labels": [], "entities": []}, {"text": "However, for some slot types, the triggers can be implicit and ambiguous.", "labels": [], "entities": []}, {"text": "To address the above challenges, we propose the following new solutions: \u2022 To compress wide contexts, we model the connection of query and candidate filler using dependency structures, and feed dependency graph to DNN.", "labels": [], "entities": []}, {"text": "To our knowledge, we are the first to directly take dependency graphs as input to CNN.", "labels": [], "entities": []}, {"text": "\u2022 Motivated by the definition of trigger, we design two attention mechanisms: a local attention and a global attention using large external knowledge bases (KBs), to better capture implicit clues that indicate slot types.", "labels": [], "entities": []}, {"text": "illustrates the pipeline of a SF system.", "labels": [], "entities": [{"text": "SF", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9540971517562866}]}, {"text": "Given a query and a source corpus, the system retrieves related documents, identifies candidate fillers (including entities, time, values, and titles), extracts the relation between query and each candidate filler occurring in the same sentence, and finally determines the filler for each slot.", "labels": [], "entities": []}, {"text": "Relation extraction plays a vital role in such a SF pipeline.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7639369070529938}, {"text": "SF pipeline", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.9472222328186035}]}, {"text": "In this work, we focus on relation extraction component and design a neural architecture.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8484296798706055}]}, {"text": "Given a query, a candidate filler, and a sentence, we first construct a regularized dependency graph and take all governor, dependent word pairs as input to Convolutional Neural Networks (CNN).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Approach Descriptions for Multi-Class Relation Classification", "labels": [], "entities": [{"text": "Approach", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9732170104980469}, {"text": "Multi-Class Relation Classification", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.8606256246566772}]}, {"text": " Table 3: Relation Extraction Component Perfor- mance on Slot Filling Data Set (%).", "labels": [], "entities": [{"text": "Relation Extraction Component Perfor- mance", "start_pos": 10, "end_pos": 53, "type": "METRIC", "confidence": 0.8032024006048838}, {"text": "Slot Filling Data Set", "start_pos": 57, "end_pos": 78, "type": "DATASET", "confidence": 0.7032954543828964}]}, {"text": " Table 4: Comparison Analysis for Each Slot Type.", "labels": [], "entities": [{"text": "Comparison Analysis", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.6548248380422592}]}, {"text": " Table 5: Overall Performance for SFV: all the  Baseline Systems are from Yu et al. (2014a).", "labels": [], "entities": [{"text": "SFV", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9282274842262268}]}, {"text": " Table 6: Statistical Significance Test.", "labels": [], "entities": [{"text": "Statistical Significance Test", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.4944109221299489}]}]}