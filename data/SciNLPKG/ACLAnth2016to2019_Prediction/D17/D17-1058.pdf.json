{"title": [{"text": "Sentiment Intensity Ranking among Adjectives Using Sentiment Bearing Word Embeddings", "labels": [], "entities": [{"text": "Sentiment Intensity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8468745648860931}, {"text": "Sentiment Bearing Word Embeddings", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.7637898325920105}]}], "abstractContent": [{"text": "Identification of intensity ordering among polar (positive or negative) words which have the same semantics can lead to a fine-grained sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.8321458101272583}]}, {"text": "For example , master, seasoned and familiar point to different intensity levels, though they all convey the same meaning (semantics), i.e., expertise: having a good knowledge of.", "labels": [], "entities": []}, {"text": "In this paper, we propose a semi-supervised technique that uses sentiment bearing word embeddings to produce a continuous ranking among adjectives that share common semantics.", "labels": [], "entities": []}, {"text": "Our system demonstrates a strong Spearman's rank correlation of 0.83 with the gold standard ranking.", "labels": [], "entities": [{"text": "Spearman's rank correlation", "start_pos": 33, "end_pos": 60, "type": "METRIC", "confidence": 0.8905477821826935}]}, {"text": "We show that sentiment bearing word embeddings facilitate a more accurate intensity ranking system than other standard word embeddings (word2vec and GloVe).", "labels": [], "entities": []}, {"text": "Word2vec is the state-of-the-art for intensity ordering task.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9201670289039612}, {"text": "intensity ordering task", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7705782254536947}]}], "introductionContent": [{"text": "The interchangeable use of semantically similar words stimulates sentiment intensity variation among sentences.", "labels": [], "entities": []}, {"text": "To understand the phenomenon, let us consider the following example: 1.", "labels": [], "entities": []}, {"text": "(a) We were pleased by the beauty of the island.", "labels": [], "entities": []}, {"text": "(Positively low intense) (b) We were delighted by the beauty of the island.", "labels": [], "entities": []}, {"text": "(Positively medium intense) (c) We were exhilarated by the beauty of the island.", "labels": [], "entities": []}, {"text": "(Positively high intense) Pleased, Exhilarated and delighted are the positive words bearing the same semantics, i.e., directing the emotion, but their use intensifies the positive sentiment in the sentences 1(a), 1(b) and respectively.", "labels": [], "entities": []}, {"text": "Identification of intensity ranking among the words which have the same semantics can facilitate such a fine-grained sentiment analysis as exemplified in 1(a), 1(b) and 1(c).", "labels": [], "entities": []}, {"text": "In this paper, we present a semi-supervised approach to establish a continuous intensity ranking among polar adjectives having the same semantics.", "labels": [], "entities": []}, {"text": "Essentially, our approach is a refinement of the work done by.", "labels": [], "entities": []}, {"text": "They also built a system that generates intensity of the words that bear the same semantics; however, their system considers only three discrete intensity levels, viz., low, medium and high.", "labels": [], "entities": []}, {"text": "The important feature of our approach is that it uses Sentiment Specific Word Embeddings (SSWE).", "labels": [], "entities": []}, {"text": "SSWE are an enhancement to the normal word embeddings with respect to the sentiment analysis task).", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.9322912096977234}]}, {"text": "SSWE capture syntactic, semantic as well as sentiment information, unlike normal word embeddings (word2vec and GloVe), which capture only syntactic and semantic information.", "labels": [], "entities": []}, {"text": "Our Contribution: We propose an approach that generates a continuous (finer) intensity ranking among polar words, which belong to the same semantic category.", "labels": [], "entities": []}, {"text": "In addition, we show that SSWE produce a significantly better intensity ranking scale than word2vec () and GloVe (), which do not capture sentiment information of the words.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.8851909041404724}]}, {"text": "The remaining paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the previous work related to intensity ranking task.", "labels": [], "entities": [{"text": "intensity ranking task", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.8030660351117452}]}, {"text": "Section 3 describes the different word embeddings explored in the paper.", "labels": [], "entities": []}, {"text": "Section 4 gives the description of the data and the resources.", "labels": [], "entities": []}, {"text": "Section 5 provides details of the gold standard data.", "labels": [], "entities": [{"text": "gold standard data", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.9447033007939657}]}, {"text": "Section 6 elaborates the proposed intensity ranking approach.", "labels": [], "entities": []}, {"text": "Section 7 presents the results and experimental setup.", "labels": [], "entities": []}, {"text": "Section 8 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the efficacy of our SSWE-based approach over word2vec-based system (state-of-theart) ( and GloVe-based system, we compute rank correlation and Macro-F1 between the intensity ranking produced by the embeddings and the gold standard intensity ranking.", "labels": [], "entities": []}, {"text": "Sharma et al.,) used Bing Liu's lexicon in their approach to identify polarity orientation of words.", "labels": [], "entities": [{"text": "identify polarity orientation of words", "start_pos": 61, "end_pos": 99, "type": "TASK", "confidence": 0.796255099773407}]}, {"text": "The use of SSWE in our approach helped us to remove the need of a sentiment lexicon to identify polarity of words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 shows the average rank correlation coef- ficient obtained for 52 polar semantic categories  of the FrameNet data using Spearman's \u03c1 and  Kendall's \u03c4 . Spearman's \u03c1 measures the degree of  association between the two rankings. Kendall's  \u03c4 finds the number of concordant and discordant  pairs in the rankings to measure association. We", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 108, "end_pos": 121, "type": "DATASET", "confidence": 0.9488911926746368}]}]}