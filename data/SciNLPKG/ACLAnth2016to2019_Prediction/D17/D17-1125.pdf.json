{"title": [{"text": "Macro Grammars and Holistic Triggering for Efficient Semantic Parsing", "labels": [], "entities": [{"text": "Holistic Triggering", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7263002097606659}]}], "abstractContent": [{"text": "To learn a semantic parser from denota-tions, a learning algorithm must search over a combinatorially large space of logical forms for ones consistent with the annotated denotations.", "labels": [], "entities": []}, {"text": "We propose anew online learning algorithm that searches faster as training progresses.", "labels": [], "entities": []}, {"text": "The two key ideas are using macro grammars to cache the abstract patterns of useful logical forms found thus far, and holistic triggering to efficiently retrieve the most relevant patterns based on sentence similarity.", "labels": [], "entities": []}, {"text": "On the WIKITABLEQUESTIONS dataset, we first expand the search space of an existing model to improve the state-of-the-art accuracy from 38.7% to 42.7%, and then use macro grammars and holistic triggering to achieve an 11x speedup and an accuracy of 43.7%.", "labels": [], "entities": [{"text": "WIKITABLEQUESTIONS dataset", "start_pos": 7, "end_pos": 33, "type": "DATASET", "confidence": 0.9619480967521667}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9985606074333191}, {"text": "accuracy", "start_pos": 236, "end_pos": 244, "type": "METRIC", "confidence": 0.9992495179176331}]}], "introductionContent": [{"text": "We consider the task of learning a semantic parser for question answering from questionanswer pairs.", "labels": [], "entities": [{"text": "question answering from questionanswer pairs", "start_pos": 55, "end_pos": 99, "type": "TASK", "confidence": 0.7929624259471894}]}, {"text": "To train such a parser, the learning algorithm must somehow search for consistent logical forms (i.e., logical forms that execute to the correct answer denotation).", "labels": [], "entities": []}, {"text": "Typically, the search space is defined by a compositional grammar over logical forms (e.g., a context-free grammar), which we will refer to as the base grammar.", "labels": [], "entities": []}, {"text": "To cover logical forms that answer complex questions, the base grammar must be quite general and compositional, leading to a huge search space that contains many useless logical forms.", "labels": [], "entities": []}, {"text": "For example, the parser of: A knowledge base for the question x = \"Who ranked right after Turkey?\".", "labels": [], "entities": []}, {"text": "The target denotation is y = {Sweden}.", "labels": [], "entities": [{"text": "Sweden}", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9314160645008087}]}, {"text": "Wikipedia table questions (with beam size 100) generates and featurizes an average of 8,400 partial logical forms per example.", "labels": [], "entities": []}, {"text": "Searching for consistent logical forms is thus a major computational bottleneck.", "labels": [], "entities": []}, {"text": "In this paper, we propose macro grammars to bias the search towards structurally sensible logical forms.", "labels": [], "entities": []}, {"text": "To illustrate the key idea, suppose we managed to parse the utterance \"Who ranked right after Turkey?\" in the context of into the following consistent logical form (in lambda DCS) (Section 2.1): R.R.Nation.Turkey, which identifies the cell under the Nation column in the row after Turkey.", "labels": [], "entities": []}, {"text": "From this logical form, we can abstract out all relations and entities to produce the following macro: .R.{Rel#1}.{Ent#2}, which represents the abstract computation: \"identify the cell under the {Rel#1} column in the row after {Ent#2}.\"", "labels": [], "entities": []}, {"text": "More generally, macros capture the overall shape of computations in away that generalizes across different utterances and knowledge bases.", "labels": [], "entities": []}, {"text": "Given the consistent logical forms of utterances parsed so far, we extract a set of macro rules.", "labels": [], "entities": []}, {"text": "The resulting macro grammar consisting of these rules generates only logical forms conforming to these macros, which is a much smaller and higher precision set compared to the base grammar.", "labels": [], "entities": [{"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9692155122756958}]}, {"text": "Though the space of logical forms defined by the macro grammar is smaller, it is still expensive to parse with them as the number of macro rules grows with the number of training examples.", "labels": [], "entities": []}, {"text": "To address this, we introduce holistic triggering: fora new utterance, we find the K most similar utterances and only use the macro rules induced from any of their consistent logical forms.", "labels": [], "entities": []}, {"text": "Parsing now becomes efficient as only a small subset of macro rules are triggered for any utterance.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9676187038421631}]}, {"text": "Holistic triggering can be contrasted with the norm in semantic parsing, in which logical forms are either triggered by specific phrases (anchored) or can be triggered in any context (floating).", "labels": [], "entities": [{"text": "Holistic triggering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.652093917131424}, {"text": "semantic parsing", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.7393858432769775}]}, {"text": "Based on the two ideas above, we propose an online algorithm for jointly inducing a macro grammar and learning the parameters of a semantic parser.", "labels": [], "entities": []}, {"text": "For each training example, the algorithm first attempts to find consistent logical forms using holistic triggering on the current macro grammar.", "labels": [], "entities": []}, {"text": "If it succeeds, the algorithm uses the consistent logical forms found to update model parameters.", "labels": [], "entities": []}, {"text": "Otherwise, it applies the base grammar fora more exhaustive search to enrich the macro grammar.", "labels": [], "entities": []}, {"text": "At test time, we only use the learned macro grammar.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the WIKITABLE-QUESTIONS dataset, which features a semantic parsing task with opendomain knowledge bases and complex questions.", "labels": [], "entities": [{"text": "WIKITABLE-QUESTIONS dataset", "start_pos": 32, "end_pos": 59, "type": "DATASET", "confidence": 0.9545709192752838}, {"text": "semantic parsing task", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7823799848556519}]}, {"text": "We first extend the model in to achieve anew state-of-the-art test accuracy of 42.7%, representing a 10% relative improvement over the best reported result ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9941145777702332}]}, {"text": "We then show that training with macro grammars yields an 11x speedup compared to training with only the base grammar.", "labels": [], "entities": []}, {"text": "At test time, using the learned macro grammar achieves a slightly better accuracy of 43.7% with a 16x run time speedup over using the base grammar.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9992734789848328}]}], "datasetContent": [{"text": "We report experiments on the WIKITABLEQUES-TIONS dataset.", "labels": [], "entities": [{"text": "WIKITABLEQUES-TIONS dataset", "start_pos": 29, "end_pos": 56, "type": "DATASET", "confidence": 0.9570910632610321}]}, {"text": "Our algorithm is compared with the parser trained only with the base grammar, the floating parser of Pasupat and Liang (2015) (PL15), the Neural Programmer parser) and the Neural Multi-Step Reasoning parser ().", "labels": [], "entities": [{"text": "Neural Multi-Step Reasoning parser", "start_pos": 172, "end_pos": 206, "type": "TASK", "confidence": 0.6277277693152428}]}, {"text": "Our algorithm not only outperforms the others, but also achieves an order-of-magnitude speedup over the parser trained with the base grammar and the parser in PL15.", "labels": [], "entities": []}, {"text": "We use the same features and logical form pruning strategies as PL15, but generalize their base grammar.", "labels": [], "entities": []}, {"text": "To control the search space, the actual system in PL15 restricts the superlative operators argmax and argmin to be applied only on the set of table rows.", "labels": [], "entities": [{"text": "argmax", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9790712594985962}, {"text": "argmin", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9308910369873047}]}, {"text": "We allow these operators to be applied on the set of tables cells as well, so that the grammar captures certain logical forms that are not covered by PL15 (see).", "labels": [], "entities": [{"text": "PL15", "start_pos": 150, "end_pos": 154, "type": "DATASET", "confidence": 0.873645544052124}]}, {"text": "Additionally, for terminal rule (3), we allow f (span) to produce entities that approximately match the token span in addition to exact matches.", "labels": [], "entities": []}, {"text": "For example, the phrase \"Greenville\" can trigger both entities Greenville Ohio and Greensville.", "labels": [], "entities": [{"text": "Greenville", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.7241261005401611}]}], "tableCaptions": [{"text": " Table 1: A knowledge base for the question x =  \"Who ranked right after Turkey?\". The target de- notation is y = {Sweden}.", "labels": [], "entities": []}, {"text": " Table 4: Results on WIKITABLEQUESTIONS.", "labels": [], "entities": [{"text": "WIKITABLEQUESTIONS", "start_pos": 21, "end_pos": 39, "type": "DATASET", "confidence": 0.7413120865821838}]}, {"text": " Table 5: Comparison and ablation study: the  columns report averaged prediction accuracy,  training time, and prediction time (milliseconds  per example) on the three train-dev splits.", "labels": [], "entities": [{"text": "ablation", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9965224266052246}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.822403609752655}, {"text": "prediction time", "start_pos": 111, "end_pos": 126, "type": "METRIC", "confidence": 0.9421242475509644}]}]}