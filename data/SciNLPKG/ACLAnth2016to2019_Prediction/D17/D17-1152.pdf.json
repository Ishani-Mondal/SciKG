{"title": [], "abstractContent": [{"text": "Bilingual Lexicon Induction is the task of learning word translations without bilingual parallel corpora.", "labels": [], "entities": [{"text": "Bilingual Lexicon Induction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7782471974690756}, {"text": "learning word translations", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.6527285774548849}]}, {"text": "We model this task as a matrix completion problem, and present an effective and extendable framework for completing the matrix.", "labels": [], "entities": [{"text": "matrix completion", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7209984511137009}]}, {"text": "This method harnesses diverse bilingual and monolingual signals, each of which maybe incomplete or noisy.", "labels": [], "entities": []}, {"text": "Our model achieves state-of-the-art performance for both high and low resource languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine translation (MT) models typically require large, sentence-aligned bilingual texts to learn good translation models (.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8835216045379639}]}, {"text": "However, for many language pairs, such parallel texts may only be available in limited quantities, which is problematic.", "labels": [], "entities": []}, {"text": "Alignments at the word-or subword-levels () can be inaccurate in the limited parallel texts, which can in turn lead to inaccurate translations.", "labels": [], "entities": []}, {"text": "Due to the low quantity and thus coverage of the texts, there may still be \"out-of-vocabulary\" words encountered at run-time.", "labels": [], "entities": []}, {"text": "The Bilingual Lexicon Induction (BLI) task, which learns word translations from monolingual or comparable corpora, is an attempt to alleviate this problem.", "labels": [], "entities": [{"text": "Bilingual Lexicon Induction (BLI) task", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.7388616119112287}, {"text": "learns word translations from monolingual or comparable corpora", "start_pos": 50, "end_pos": 113, "type": "TASK", "confidence": 0.8262407556176186}]}, {"text": "The goal is to use plentiful, more easily obtainable, monolingual or comparable data to infer word translations and reduce the need for parallel data to learn good translation models.", "labels": [], "entities": [{"text": "word translations", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.731291264295578}]}, {"text": "The word translations obtained by BLI can, for example, be used to augment MT systems and improve alignment accuracy, coverage, and translation quality (: Our framework allows us to use a diverse range of signals to learn translations, including incomplete bilingual dictionaries, information from related languages (like Indonesian loan words from Dutch shown here), word embeddings, and even visual similarity cues.", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9866233468055725}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9300782084465027}]}, {"text": "Previous research has explored different sources for estimating translation equivalence from monolingual corpora (;.", "labels": [], "entities": [{"text": "estimating translation equivalence", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.8032868107159933}]}, {"text": "These monolingual signals, when combined in a supervised model, can enhance end-to-end MT for low resource languages ().", "labels": [], "entities": [{"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.9856694936752319}]}, {"text": "More recently, similarities between words in different languages have been approximated by constructing a shared bilingual word embedding space with different forms of bilingual supervision ().", "labels": [], "entities": []}, {"text": "We present a framework for learning translations by combining diverse signals of translation that are each potentially sparse or noisy.", "labels": [], "entities": []}, {"text": "We use matrix factorization (MF), which has been shown to be effective for harnessing incomplete or noisy distant supervision from multiple sources of information (.", "labels": [], "entities": []}, {"text": "MF is also shown to result in good crosslingual representations for tasks such as alignment (), QA (, and cross-lingual word embeddings ().", "labels": [], "entities": [{"text": "MF", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.904524564743042}]}, {"text": "Specifically, we represent translation as a matrix with source words in the columns and target words in the rows, and model the task of learning translations as a matrix completion problem.", "labels": [], "entities": []}, {"text": "Starting from some observed translations (e.g., from existing bilingual dictionaries,) we infer missing translations in the matrix using MF with a Bayesian Personalized Ranking (BPR) objective).", "labels": [], "entities": []}, {"text": "We select BPR fora number of reasons: (1) BPR has been shown to outperform traditional supervised methods in the presence of positive-only data (, which is true in our case since we only observe positive translations.", "labels": [], "entities": [{"text": "BPR", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.7018163800239563}]}, {"text": "(2) BPR is easily extendable to incorporate additional signals for inferring missing values in the matrix.", "labels": [], "entities": [{"text": "BPR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.835015058517456}]}, {"text": "Since observed translations maybe sparse, i.e. the \"cold start\" problem in the matrix completion task, incorporating additional signals of translation equivalence estimated on monolingual corpora is useful.", "labels": [], "entities": [{"text": "matrix completion task", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.7899433175722758}]}, {"text": "(3) BPR is also shown to be effective for multilingual transfer learning ().", "labels": [], "entities": [{"text": "BPR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8558329939842224}, {"text": "multilingual transfer learning", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.7773059407869974}]}, {"text": "For low resource source languages, there maybe related, higher resource languages from which we can project available translations (e.g., translations of loan words) to the target language ().", "labels": [], "entities": []}, {"text": "We conduct large scale experiments to learn translations from both low and high resource languages to English and achieve state-of-the-art performance on these languages.", "labels": [], "entities": []}, {"text": "Our main contributions are as follows: \u2022 We introduce a MF framework that learns translations by integrating diverse bilingual and monolingual signals of translation, each potentially noisy/incomplete.", "labels": [], "entities": [{"text": "MF", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9647583961486816}]}, {"text": "\u2022 The framework is easily extendable to incorporate additional signals of translation equivalence.", "labels": [], "entities": []}, {"text": "Since ours is a framework for integration, each signal can be improved separately to improve the overall system.", "labels": [], "entities": []}, {"text": "\u2022 Large scale experiments on both low and high resource languages show the effectiveness of our model, outperforming the current stateof-the-art.", "labels": [], "entities": []}, {"text": "\u2022 We make our code, datasets, and output translations publicly available.", "labels": [], "entities": []}], "datasetContent": [{"text": "To implement our approach, we extend the implementation of BPR in LIBREC 3 which is a publicly available Java library for recommender systems.", "labels": [], "entities": []}, {"text": "We evaluate our model for the task of Bilingual Lexicon Induction (BLI).", "labels": [], "entities": [{"text": "Bilingual Lexicon Induction (BLI)", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.7368880609671274}]}, {"text": "Given a source word f , the task is to rank all candidate target words e by their predicted translation scores\u02c6xscores\u02c6 scores\u02c6x e,f . We conduct large-scale experiments on 27 low-and highresource source languages and evaluate their translations to English.", "labels": [], "entities": []}, {"text": "We use the 100K most frequent words from English Wikipedia as candidate English target words (E).", "labels": [], "entities": []}, {"text": "At test time, for each source language, we evaluate the top-10 accuracy (Acc 10 ): the percent of source language words in the test set for which a correct English translation appears in the top-10 ranked English candidates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9963744282722473}, {"text": "Acc 10 )", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9705546299616495}]}], "tableCaptions": [{"text": " Table 1: Acc 10 performance on VULIC1000", "labels": [], "entities": [{"text": "Acc 10", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9458646178245544}, {"text": "VULIC1000", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.8399178981781006}]}, {"text": " Table 2: Top-5 translations of the Indonesian word kesadaran (awareness) using different model variants", "labels": [], "entities": [{"text": "Indonesian word kesadaran (awareness)", "start_pos": 36, "end_pos": 73, "type": "TASK", "confidence": 0.5391496221224467}]}, {"text": " Table 3: Acc 10 performance on the multilingual  image corpus test set (Callahan, 2017)", "labels": [], "entities": [{"text": "Acc 10", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9479285180568695}, {"text": "multilingual  image corpus test set (Callahan, 2017)", "start_pos": 36, "end_pos": 88, "type": "DATASET", "confidence": 0.7780352115631104}]}]}