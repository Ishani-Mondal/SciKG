{"title": [{"text": "Deriving continous grounded meaning representations from referentially structured multimodal contexts", "labels": [], "entities": []}], "abstractContent": [{"text": "Corpora of referring expressions paired with their visual referents area good source for learning word meanings directly grounded in visual representations.", "labels": [], "entities": []}, {"text": "Here, we explore additional ways of extracting from them word representations linked to multi-modal context: through expressions that refer to the same object , and through expressions that refer to different objects in the same scene.", "labels": [], "entities": []}, {"text": "We show that continuous meaning representations derived from these contexts capture complementary aspects of similarity , even if not outperforming tex-tual embeddings trained on very large amounts of raw text when tested on standard similarity benchmarks.", "labels": [], "entities": []}, {"text": "We propose anew task for evaluating grounded meaning representations-detection of potentially co-referential phrases-and show that it requires precise denotational representations of attribute meanings, which our method provides.", "labels": [], "entities": []}], "introductionContent": [{"text": "Various routes for linking language to extralinguistic context have been explored in recent years.", "labels": [], "entities": []}, {"text": "A lot of research has looked at integrating visual representations, either directly ( or through mapping into a multi-modal distributional space.", "labels": [], "entities": []}, {"text": "have explored a less direct link, by representing the extension of phrasal expressions as sets of images, and deriving from this a precise notion of denotational similarity.", "labels": [], "entities": []}, {"text": "In very re- grounded language, and similarity relations that can be derived from it, image from MSCOCO ( cent work, use spatial context from geo-located tweets to induce word embeddings that capture situational similarity between lexical items.", "labels": [], "entities": []}, {"text": "In this paper, we explore an approach that combines aspects of several of these paths.", "labels": [], "entities": []}, {"text": "Starting point is the observation that corpora of exophoric referring expressions provide richly structured contexts that go beyond just linking individual expressions with their denotations.", "labels": [], "entities": []}, {"text": "As an example consider the scene in depicting several referents and corresponding referring expressions produced by different speakers.", "labels": [], "entities": []}, {"text": "This scene provides a learner not only with an example of a referent for the word lady, it also provides the information that lady can co-refer with girl, and that its denotations can spatially / situationally co-occur with those of table and cake.", "labels": [], "entities": []}, {"text": "From these types of information we infer word embeddings, following the method from for training embeddings on arbi-trary non-linear context, and we show that these capture complementary aspects of word similarity that purely textual induction methods conflate.", "labels": [], "entities": []}, {"text": "We also show that these representations handle a more directly referential similarity task better.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Word similarity and relatedness evaluation", "labels": [], "entities": []}, {"text": " Table 4: Accuracies for co-referential expression detection", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9867392778396606}]}]}