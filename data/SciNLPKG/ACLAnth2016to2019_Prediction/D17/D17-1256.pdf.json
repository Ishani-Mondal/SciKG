{"title": [{"text": "Part-of-Speech Tagging for Twitter with Adversarial Neural Networks", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7958130240440369}]}], "abstractContent": [{"text": "In this work, we study the problem of part-of-speech tagging for Tweets.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.738054633140564}]}, {"text": "In contrast to newswire articles, Tweets are usually informal and contain numerous out-of-vocabulary words.", "labels": [], "entities": []}, {"text": "Moreover, there is alack of large scale labeled datasets for this domain.", "labels": [], "entities": []}, {"text": "To tackle these challenges, we propose a novel neural network to make use of out-of-domain labeled data, unlabeled in-domain data, and labeled in-domain data.", "labels": [], "entities": []}, {"text": "Inspired by adversarial neural networks, the proposed method tries to learn common features through adversarial discriminator.", "labels": [], "entities": []}, {"text": "In addition, we hypothesize that domain-specific features of target domain should be preserved in some degree.", "labels": [], "entities": []}, {"text": "Hence, the proposed method adopts a sequence-to-sequence au-toencoder to perform this task.", "labels": [], "entities": []}, {"text": "Experimental results on three different datasets show that our method achieves better performance than state-of-the-art methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "During the last decade, social media have become extremely popular, on which billions of usergenerated contents are posted everyday.", "labels": [], "entities": []}, {"text": "Many users have been writing about their thoughts and lives on the go.", "labels": [], "entities": []}, {"text": "The massive unstructured data from social media provides valuable information fora variety of applications such as stock prediction, public health analysis (), real-time event detection (, and soon.", "labels": [], "entities": [{"text": "stock prediction", "start_pos": 115, "end_pos": 131, "type": "TASK", "confidence": 0.824711412191391}, {"text": "public health analysis", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.6983788808186849}, {"text": "real-time event detection", "start_pos": 160, "end_pos": 185, "type": "TASK", "confidence": 0.6048005918661753}]}, {"text": "The quality of these applications is highly impacted by the performance of natural language processing tasks.", "labels": [], "entities": []}, {"text": "Part-of-speech (POS) tagging is one of the most important natural language processing tasks.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5853758454322815}]}, {"text": "It has also been widely used in the social media analysis systems ().", "labels": [], "entities": [{"text": "social media analysis", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.586238960425059}]}, {"text": "Most stateof-the-art POS tagging approaches are based on supervised methods.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.9094189703464508}]}, {"text": "Hence, they usually require a large amount of annotated data to train models.", "labels": [], "entities": []}, {"text": "Many datasets have been constructed for POS tagging task.", "labels": [], "entities": [{"text": "POS tagging task", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.9174022078514099}]}, {"text": "Because newswire articles are carefully edited, benchmarks usually use them for annotation).", "labels": [], "entities": []}, {"text": "However, usergenerated contents on social media are usually informal and contain many nonstandard lexical items.", "labels": [], "entities": []}, {"text": "Moreover, the difference in domains between training data and evaluation data may heavily impact the performance of approaches based on supervised methods).", "labels": [], "entities": []}, {"text": "Hence, most POS tagging methods cannot achieve the same performance as reported on newswire domain when applied on Twitter (.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.8068288564682007}]}, {"text": "To perform the Twitter POS tagging task, some approaches have been proposed to perform the task.", "labels": [], "entities": [{"text": "POS tagging task", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7531088689963022}]}, {"text": "manually annotated 1,827 tweets and carefully studied various fea-tures.", "labels": [], "entities": []}, {"text": "also constructed a labeled dataset, which contained 787 tweets, to empirically evaluate the performance of supervised methods on Twitter.", "labels": [], "entities": []}, {"text": "incorporated word clusters into the feature sets and further improved the performance.", "labels": [], "entities": []}, {"text": "From these works, we can observe that the size of the training data was much smaller than the newswire domain's.", "labels": [], "entities": []}, {"text": "Besides the challenge of lack of training data, the frequent use of out-of-vocabulary words also makes this problem difficult to address.", "labels": [], "entities": []}, {"text": "Social media users often use informal ways of expressing their ideas and often spell words phonetically (e.g., \"2mor\" for \"tomorrow\").", "labels": [], "entities": []}, {"text": "In addition, they also make extensive use of emoticons and abbreviations (e.g., \":-)\" for smiling emotion and \"LOL\" for laughing out loud).", "labels": [], "entities": [{"text": "LOL", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9822311997413635}]}, {"text": "Moreover, new symbols, abbreviations, and words are constantly being created.", "labels": [], "entities": []}, {"text": "shows an example of tagged Tweet.", "labels": [], "entities": []}, {"text": "To tackle the challenges posed by the lack of training data and the out-of-vocabulary words, in this paper, we propose a novel recurrent neural network, which we call Target Preserved Adversarial Neural Network (TPANN) to perform the task.", "labels": [], "entities": []}, {"text": "It can make use of a large quantity of annotated data from other resourcerich domains, unlabeled in-domain data, and a small amount of labeled in-domain data.", "labels": [], "entities": []}, {"text": "All of these datasets can be easily obtained.", "labels": [], "entities": []}, {"text": "To make use of unlabeled data, motivated by the work of and, the proposed method extends the bi-directional long short-term memory recurrent neural network (bi-LSTM) with an adversarial predictor.", "labels": [], "entities": []}, {"text": "To overcome the defect that adversarial networks can merely learn the common features, we propose to use an autoencoder only acting on target dataset to preserve its own specific features.", "labels": [], "entities": []}, {"text": "For tackling the out-of-vocabulary problem, the proposed method also incorporates a character level convolutional neutral network to leverage subword information.", "labels": [], "entities": []}, {"text": "The contributions of this work are as follows: \u2022 We propose to incorporate large scale unlabeled in-domain data, out-of-domain labeled data, and in-domain labeled data for Twitter part-of-speech tagging task.", "labels": [], "entities": [{"text": "part-of-speech tagging task", "start_pos": 180, "end_pos": 207, "type": "TASK", "confidence": 0.7337750991185507}]}, {"text": "\u2022 We introduce a novel recurrent neural network, which can learn domain-invariant representations through in-domain and out-ofdomain data and construct across domain POS tagger through the learned representations.", "labels": [], "entities": []}, {"text": "The proposed method also tries to preserve the specific features of target domain.", "labels": [], "entities": []}, {"text": "\u2022 Experimental results demonstrate that the proposed method can lead to better performance inmost of cases on three different datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will detail the datasets used for experiments and experimental setup.", "labels": [], "entities": []}, {"text": "The methods proposed in this work incorporate out-of-domain labeled data from resource-rich domains, large scale unlabeled in-domain data, and a small number of labeled in-domain data., and ARKTwitter ().", "labels": [], "entities": [{"text": "ARKTwitter", "start_pos": 190, "end_pos": 200, "type": "DATASET", "confidence": 0.7302259206771851}]}, {"text": "For training the adversarial network, we need to use a dataset that has large scale unlabeled tweets.", "labels": [], "entities": []}, {"text": "Hence, in this work, we construct large scale unlabeled data (UNL), from Twitter using its API.", "labels": [], "entities": []}, {"text": "The detailed data statistics of the datasets used in this work are listed in.", "labels": [], "entities": []}, {"text": "We select both state-of-the-art and classic methods for comparison, as follows: \u2022 Stanford POS Tagger: Stanford POS Tagger is a widely used tool for newswire domains (.", "labels": [], "entities": []}, {"text": "In this work, we train it using two different sets, the WSJ (sections 0-18) and a WSJ, IRC, and Twitter mixed corpus.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.9607264399528503}, {"text": "WSJ, IRC, and Twitter mixed corpus", "start_pos": 82, "end_pos": 116, "type": "DATASET", "confidence": 0.6649588495492935}]}, {"text": "We use Stanford-WSJ and Stanford-MIX to represent them, respectively.", "labels": [], "entities": []}, {"text": "\u2022 T-POS: T-Pos () adopts the Conditional Random Fields and clustering algorithm to perform the task.", "labels": [], "entities": []}, {"text": "It was trained from a mixture of hand-annotated tweets and existing POS-labeled data.", "labels": [], "entities": [{"text": "POS-labeled data", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.8531381189823151}]}, {"text": "\u2022 GATE Tagger: GATE tagger () is based on vote-constrained bootstrapping with unlabeled data.", "labels": [], "entities": [{"text": "GATE Tagger", "start_pos": 2, "end_pos": 13, "type": "TASK", "confidence": 0.7008043527603149}, {"text": "GATE tagger", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.7245093286037445}]}, {"text": "It combines cases where available taggers use different tagsets.", "labels": [], "entities": []}, {"text": "\u2022 ARK Tagger: ARK tagger () is a system that reports the best accuracy on the RIT dataset.", "labels": [], "entities": [{"text": "ARK Tagger", "start_pos": 2, "end_pos": 12, "type": "TASK", "confidence": 0.6162668764591217}, {"text": "ARK tagger", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.6469369679689407}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9983981251716614}, {"text": "RIT dataset", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.8521996736526489}]}, {"text": "It uses unsupervised word clustering and a variety of lexical features.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.738322526216507}]}, {"text": "\u2022 bi-LSTM: Bidirectional Long Short-Term Memory (LSTM) networks have been widely used in a variety of sequence labeling tasks (.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.6651893655459086}]}, {"text": "In this work, we evaluate it at character level, word level, and combining them together.", "labels": [], "entities": []}, {"text": "bi-LSTM (word level) uses one layer of bi-LSTM to extract word-level features and adopts a random initialization method to transform words to vectors.", "labels": [], "entities": []}, {"text": "bi-LSTM (character level) represents a method that combines bi-LSTM and CNN-based character embedding, a similar approach with character-aware neural network described in () to handle the out-ofvocabulary words.", "labels": [], "entities": []}, {"text": "bi-LSTM (word level pretrain) architecture is the same as that of bi-LSTM(word level) but adopts word2vec tool () to vectorize.", "labels": [], "entities": []}, {"text": "bi-LSTM (combine) concatenates word to character features.", "labels": [], "entities": []}, {"text": "The hyper-parameters used for our model are as follows.", "labels": [], "entities": []}, {"text": "AdaGrad optimizer trained with crossentropy loss is used with 0.1 as the default learning rate.", "labels": [], "entities": [{"text": "AdaGrad", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8976971507072449}]}, {"text": "The dimensionality of word embedding is set to 200.", "labels": [], "entities": []}, {"text": "The dimensionality for random initialized character embedding is set to 25.", "labels": [], "entities": []}, {"text": "We adopt a bi-LSTM for encoding with each layer consisting of 250 hidden neurons.", "labels": [], "entities": []}, {"text": "We set three layers of standard LSTM for decoding.", "labels": [], "entities": []}, {"text": "Each LSTM layer consists of 500 hidden neurons.", "labels": [], "entities": []}, {"text": "Adam optimizer trained with cross-entropy loss is used to fine-tune with 0.0001 as the default learning rate.", "labels": [], "entities": []}, {"text": "Finetuning is run for 100 epochs using early stop.", "labels": [], "entities": [{"text": "Finetuning", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.767406702041626}]}, {"text": "The RIT-Twitter is split into training, development and evaluation sets (RIT-Train, RIT-Dev, RITTest).", "labels": [], "entities": []}, {"text": "The splitting method is shown in, and the dataset statistics are listed in. shows the results of our method and other approaches on the RIT-Twitter dataset.", "labels": [], "entities": [{"text": "RIT-Twitter dataset", "start_pos": 136, "end_pos": 155, "type": "DATASET", "confidence": 0.9732559323310852}]}, {"text": "RIT-Twitter uses the PTB tagset with several Twitter-specific tags: retweets, @user-names, hashtags, and urls.", "labels": [], "entities": [{"text": "RIT-Twitter", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.7418780326843262}, {"text": "PTB tagset", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.9449204206466675}]}, {"text": "Since words in these categories can be tagged almost perfectly using simple regular expressions, similar to (, we use regular expressions to tags these words appropriately for all systems.", "labels": [], "entities": []}, {"text": "From the results of the Stanford-WSJ, we can observe that the newswire domain is different from Twitter.", "labels": [], "entities": []}, {"text": "Although the token-level accuracy of the Stanford POS Tagger is higher than 97.0% on the PTB dataset, its performance on Twitter drops sharply to 73.37%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9922784566879272}, {"text": "Stanford POS Tagger", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.7693485816319784}, {"text": "PTB dataset", "start_pos": 89, "end_pos": 100, "type": "DATASET", "confidence": 0.990888774394989}]}, {"text": "By incorporating some indomain labeled data for training, the accuracy of Stanford POS Tagger can reach up to 83.14%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9997319579124451}, {"text": "POS Tagger", "start_pos": 83, "end_pos": 93, "type": "TASK", "confidence": 0.6271229982376099}]}, {"text": "Taking a variety of linguistic features and many other resources into consideration, the T-POS, GATE tagger, and ARK tagger can achieve better performance.", "labels": [], "entities": [{"text": "GATE tagger", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.6356789767742157}, {"text": "ARK tagger", "start_pos": 113, "end_pos": 123, "type": "TASK", "confidence": 0.6438971161842346}]}, {"text": "The second part of shows the results of the bi-LSTM based methods, which are trained on the RIT-Train dataset.", "labels": [], "entities": [{"text": "RIT-Train dataset", "start_pos": 92, "end_pos": 109, "type": "DATASET", "confidence": 0.9068614542484283}]}, {"text": "According to the results of word level, we can see that word2vec can provide valuable information.", "labels": [], "entities": []}, {"text": "The pre-trained word vectors in bi-LSTM(word level pretrain) give almost 10% higher accuracy than bi-LSTM(word level).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9984448552131653}]}, {"text": "Comparing the character-level bi-LSTM with word-level bi-LSTM with random initialization, we can observe that the character-level method can achieve better performance than the word-level method.", "labels": [], "entities": []}, {"text": "bi-LSTM(combine) combines word with character features, as described in Section 2.1, which achieves the best results at 89.48% in the bi-LSTM based baseline systems and shows that the morphological features and pre-trained word vectors are both useful for POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 256, "end_pos": 267, "type": "TASK", "confidence": 0.9235527217388153}]}, {"text": "The third part of shows the results of our methods incorporating out-of-domain labeled data, in-domain unlabeled data, and in-domain labeled data.", "labels": [], "entities": []}, {"text": "Putting everything together, our model can achieve 90.92% on this dataset.", "labels": [], "entities": []}, {"text": "Compared with the architecture without an adversarial model, our method is almost 1% better.", "labels": [], "entities": []}, {"text": "It demonstrates that adversarial networks can significantly help with tasks of this nature.", "labels": [], "entities": []}, {"text": "Through introducing the autoencoder in target domain, we can preserve domain-specific features for better performance.", "labels": [], "entities": []}, {"text": "Compared with the ARK tagger, which achieves the previous best result on this dataset, our model is also 0.52% better, the error reduction rate is more than 5.5%.", "labels": [], "entities": [{"text": "ARK tagger", "start_pos": 18, "end_pos": 28, "type": "TASK", "confidence": 0.6483875811100006}, {"text": "error reduction rate", "start_pos": 123, "end_pos": 143, "type": "METRIC", "confidence": 0.9661626815795898}]}, {"text": "To better understand why adversarial networks can help transfer domains from newswire to Twitter, in this work we also followed the method used to visualize the outputs of LSTM with t-SNE (Van Der Maaten, 2013).", "labels": [], "entities": []}, {"text": "From the figure, we can see that the adversary in our method makes the two distributions of features much more similar, which means that the outputs of bi-LSTM are domain-invariant.", "labels": [], "entities": []}, {"text": "Hence, the PTB training data can provide much more help than directly combining PTB and RIT-Train together.", "labels": [], "entities": [{"text": "PTB training data", "start_pos": 11, "end_pos": 28, "type": "DATASET", "confidence": 0.8663760622342428}, {"text": "PTB", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.927983283996582}]}, {"text": "IRC, which contains Internet relay room messages from 2006, is a medium of online conversational text.", "labels": [], "entities": [{"text": "IRC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8974239230155945}]}, {"text": "Its content is very similar to tweets.", "labels": [], "entities": []}, {"text": "We evaluate the proposed method on the NPSChat corpus, a PTB-part-of-speech annotated dataset of IRC.", "labels": [], "entities": [{"text": "NPSChat corpus, a PTB-part-of-speech annotated dataset of IRC", "start_pos": 39, "end_pos": 100, "type": "DATASET", "confidence": 0.77184483077791}]}, {"text": "We compared our method with a tagger in the same setup as experiments with.", "labels": [], "entities": []}, {"text": "The training part contains 90% of the data.", "labels": [], "entities": []}, {"text": "The testing part contains the other 10%.", "labels": [], "entities": []}, {"text": "shows the results of the ARK Tagger and our method.", "labels": [], "entities": [{"text": "ARK Tagger", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.9497517049312592}]}, {"text": "We used PTB, unlabeled Twitter, and the training part of NPSChat to train our model.", "labels": [], "entities": [{"text": "PTB", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.949995219707489}, {"text": "NPSChat", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9796955585479736}]}, {"text": "From the results, we can see that our model achieved 94.1% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.999178946018219}]}, {"text": "This is significantly better than the result Forsyth (2007) reported, which was 90.8%.", "labels": [], "entities": []}, {"text": "They trained their tagger with a mix of several POS-annotated corpora (12K from Twitter, 40K from IRC, and 50K from PTB).", "labels": [], "entities": [{"text": "IRC", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.9211368560791016}, {"text": "PTB", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.9783961176872253}]}, {"text": "Our method also outperforms state-of-the-art results 93.4%\u00b10.3%, which was achieved by the ARK Tagger with various external corpus and features, e.g., Brown clustering, PTB, Freebase lists of celebrities, and video games.: Tagging accuracies on DAILY547.", "labels": [], "entities": [{"text": "ARK Tagger", "start_pos": 91, "end_pos": 101, "type": "DATASET", "confidence": 0.8843866288661957}, {"text": "PTB", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.8833702802658081}, {"text": "DAILY547", "start_pos": 245, "end_pos": 253, "type": "DATASET", "confidence": 0.8742974996566772}]}, {"text": "ARK-Twitter data contains an entire dataset consisting of a number of tweets sampled from one particular day (October 27, 2010) described in ().", "labels": [], "entities": [{"text": "ARK-Twitter data", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9696578979492188}]}, {"text": "This part is used for training.", "labels": [], "entities": []}, {"text": "They also created another dataset, which consists of 547 tweets, for evaluation (DAILY547).", "labels": [], "entities": [{"text": "DAILY547", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.7743484377861023}]}, {"text": "This dataset consists of one random English tweet from everyday between January 1, 2011 and June 30, 2012.", "labels": [], "entities": []}, {"text": "The distribution of training data maybe slightly different from the testing data, for example a substantial fraction of the messages in the training data are about a basketball game.", "labels": [], "entities": []}, {"text": "Since ARK-Twitter uses a different tagset with PTB, we manually construct a table to link tags for the two datasets.", "labels": [], "entities": [{"text": "ARK-Twitter", "start_pos": 6, "end_pos": 17, "type": "DATASET", "confidence": 0.910920262336731}, {"text": "PTB", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.8764023780822754}]}, {"text": "shows the results of different methods on this dataset.", "labels": [], "entities": []}, {"text": "From the results, we can see that our method can achieve a better result than).", "labels": [], "entities": []}, {"text": "However, the performance of our method is worse than the ARK Tagger.", "labels": [], "entities": [{"text": "ARK Tagger", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.9132512807846069}]}, {"text": "Through analyzing the errors, we find that 16.7% errors occurr between nouns and proper nouns.", "labels": [], "entities": []}, {"text": "Since our method do not include any ontology or knowledge, proper nouns cannot be easily detected.", "labels": [], "entities": []}, {"text": "However, the ATK Tagge add a tokenlevel name list feature.", "labels": [], "entities": [{"text": "ATK Tagge", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.9178338646888733}]}, {"text": "The name list is useful for proper nouns recognition, which fires on names from many sources, such as Freebase lists of celebrities, the Moby Words list of US Locations, proper names from Mark Kantrowitz's name corpus and soon.", "labels": [], "entities": [{"text": "proper nouns recognition", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.865531325340271}, {"text": "Moby Words list of US Locations", "start_pos": 137, "end_pos": 168, "type": "DATASET", "confidence": 0.9006629983584086}]}, {"text": "So, our model is also competitive when lacking of manual feature knowledge.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The statistics of the datasets used in our  experiments.", "labels": [], "entities": []}, {"text": " Table 4: Tagging accuracies on DAILY547.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9671738147735596}, {"text": "DAILY547", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.6770452857017517}]}]}