{"title": [{"text": "Massive Exploration of Neural Machine Translation Architectures", "labels": [], "entities": [{"text": "Massive Exploration of Neural Machine Translation Architectures", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.7905836275645665}]}], "abstractContent": [{"text": "Neural Machine Translation (NMT) has shown remarkable progress over the past few years, with production systems now being deployed to end-users.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8415244321028391}]}, {"text": "As the field is moving rapidly, it has become unclear which elements of NMT architec-tures have a significant impact on translation quality.", "labels": [], "entities": [{"text": "translation quality", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.855562299489975}]}, {"text": "In this work, we present a large-scale analysis of the sensitivity of NMT architectures to common hyper-parameters.", "labels": [], "entities": []}, {"text": "We report empirical results and variance numbers for several hundred experimental runs, corresponding to over 250,000 GPU hours on a WMT English to German translation task.", "labels": [], "entities": [{"text": "WMT English to German translation task", "start_pos": 133, "end_pos": 171, "type": "TASK", "confidence": 0.6799913098414739}]}, {"text": "Our experiments provide practical insights into the relative importance of factors such as embedding size, network depth, RNN cell type, residual connections, attention mechanism, and decoding heuristics.", "labels": [], "entities": []}, {"text": "As part of this contribution , we also release an open-source NMT framework in TensorFlow to make it easy for others to reproduce our results and perform their own experiments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT)) is an end-to-end approach to machine translation.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT))", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7689729779958725}, {"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7734853029251099}]}, {"text": "NMT has shown impressive results () surpassing those of phrase-based systems while addressing shortcomings, such as the need for handengineered features.", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.822020947933197}]}, {"text": "The most popular approaches to NMT are based on sequence-to-sequence models, an encoder-decoder architecture consisting of two recurrent neural networks (RNNs) and an attention mechanism that aligns target with source tokens (.", "labels": [], "entities": [{"text": "NMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9614279866218567}]}, {"text": "One drawback of current NMT architectures is the huge amount of compute required to train them.", "labels": [], "entities": []}, {"text": "Training on real-world datasets of several million examples typically requires dozens of GPUs and convergence time is on the order of days to weeks (.", "labels": [], "entities": []}, {"text": "While sweeping across large hyperparameter spaces is common in Computer Vision (), such exploration would be prohibitively expensive for NMT models, limiting researchers to well-established architecture and hyperparameter choices.", "labels": [], "entities": []}, {"text": "Furthermore, there have been no large-scale studies of how these hyperparameters affect the performance of NMT systems.", "labels": [], "entities": []}, {"text": "As a result, it remains unclear why these models perform as well as they door how we might improve them.", "labels": [], "entities": []}, {"text": "In this work, we present an extensive analysis of architectural hyperparameters for NMT systems.", "labels": [], "entities": []}, {"text": "Using a total of more than 250,000 GPU hours, we explore common variations of NMT architectures and provide insights into which architectural choices matter most.", "labels": [], "entities": []}, {"text": "We report BLEU scores, perplexities, model sizes, and convergence time for all experiments, including variance numbers calculated across several runs of each experiment.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9704015851020813}, {"text": "convergence time", "start_pos": 54, "end_pos": 70, "type": "METRIC", "confidence": 0.9401710331439972}]}, {"text": "In addition, we release the software framework that we wrote to facilitate this exploration.", "labels": [], "entities": []}, {"text": "In summary, the main contributions of this work are as follows: \u2022 We provide immediately applicable insights into the optimization of NMT models, as well as promising directions for future research.", "labels": [], "entities": []}, {"text": "For example, we found that deep encoders are more difficult to optimize than decoders, that dense residual connections yield better performance than regular residual connections, and that a well-tuned beam search is surprisingly critical to obtaining state-of-the-art results.", "labels": [], "entities": []}, {"text": "By presenting practical advice for choosing baseline architectures, we help researchers avoid wasting time on unpromising model variations.", "labels": [], "entities": []}, {"text": "\u2022 We also establish the extent to which metrics such as BLEU are influenced by random initialization and slight hyperparameter variation, allowing researchers to better distinguish statistically significant results from noise.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9981860518455505}]}, {"text": "\u2022 Finally, we release an open-source TensorFlow package, specifically designed to implement reproducible state-of-the-art sequence-to-sequence models.", "labels": [], "entities": []}, {"text": "All experiments were run using this framework and we include all configuration files and processing scripts needed to reproduce the experiments in this paper.", "labels": [], "entities": []}, {"text": "We hope to accelerate future research by releasing this framework to the public.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run all experiments on the WMT'15 English\u2192German task consisting of 4.5M sentence pairs, obtained by combining the Europarl v7, News Commentary v10, and Common Crawl corpora.", "labels": [], "entities": [{"text": "WMT'15 English\u2192German task", "start_pos": 30, "end_pos": 56, "type": "DATASET", "confidence": 0.8073962688446045}, {"text": "Europarl", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.9796120524406433}, {"text": "Common Crawl corpora", "start_pos": 156, "end_pos": 176, "type": "DATASET", "confidence": 0.8621787230173746}]}, {"text": "We use newstest2013 as our validation set and newstest2014 and newstest2015 as our test sets.", "labels": [], "entities": []}, {"text": "We focus on WMT English\u2192German because it is a morphologically rich language therefore has been a standard benchmark in previous important work in Neural Machine Translation ( To test for generality, we also ran a small number of experiments on English\u2192French translation, and we found that the performance was highly correlated with that of English\u2192German but that it took much longer to train models on the larger English\u2192French dataset.", "labels": [], "entities": [{"text": "WMT English\u2192German", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7119486778974533}, {"text": "Neural Machine Translation", "start_pos": 147, "end_pos": 173, "type": "TASK", "confidence": 0.8018794655799866}, {"text": "English\u2192French translation", "start_pos": 245, "end_pos": 271, "type": "TASK", "confidence": 0.6356550827622414}]}, {"text": "Given that translation from the morphologically richer German is also considered a more challenging task, we felt justified in using the English\u2192German translation task for this hyperparameter sweep.", "labels": [], "entities": []}, {"text": "We tokenize and clean all datasets with the scripts in Moses 1 and learn shared subword units using Byte Pair Encoding (BPE) () using 32,000 merge operations fora final vocabulary size of approximately 37k.", "labels": [], "entities": []}, {"text": "We discovered that data preprocessing can have a large impact on final numbers, and since we wish to enable reproducibility, we release our data preprocessing scripts together with the NMT framework to the public.", "labels": [], "entities": [{"text": "NMT framework", "start_pos": 185, "end_pos": 198, "type": "DATASET", "confidence": 0.924299031496048}]}, {"text": "For more details on data preprocessing parameters, we refer the reader to the code release.", "labels": [], "entities": []}, {"text": "For the sake of brevity, we only report mean BLEU, standard deviation, highest BLEU in parentheses, and model size in the following tables.", "labels": [], "entities": [{"text": "mean", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9524240493774414}, {"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9018144607543945}, {"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9940897226333618}]}, {"text": "Log perplexity, tokens/sec and convergence times can be found in the supplementary material tables.", "labels": [], "entities": []}, {"text": "All reported p-values were calculated with a two-sample t-test that assumed equal variances.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU scores on newstest2013, varying  the embedding dimensionality.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990373849868774}, {"text": "newstest2013", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.965630054473877}]}, {"text": " Table 3: BLEU scores on newstest2013, varying  the encoder and decoder depth and type of residual  connections.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9982109069824219}]}, {"text": " Table 4: BLEU scores on newstest2013, varying  the type of encoder. The \"R\" suffix indicates a  reversed source sequence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.998529314994812}, {"text": "newstest2013", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9627310633659363}]}, {"text": " Table 5: BLEU scores on newstest2013, varying  the type of attention mechanism.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989457726478577}, {"text": "newstest2013", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9245184659957886}]}, {"text": " Table 6: BLEU scores on newstest2013, varying  the beam width and adding length penalties (LP).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.997186005115509}, {"text": "newstest2013", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9718915820121765}, {"text": "length penalties (LP)", "start_pos": 74, "end_pos": 95, "type": "METRIC", "confidence": 0.9703076004981994}]}, {"text": " Table 7: Hyperparameter settings for our final  combined model, consisting of all of the individu- ally optimized values.", "labels": [], "entities": []}]}