{"title": [{"text": "Learning Fine-Grained Expressions to Solve Math Word Problems", "labels": [], "entities": [{"text": "Solve Math Word Problems", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.8570844382047653}]}], "abstractContent": [{"text": "This paper presents a novel template-based method to solve math word problems.", "labels": [], "entities": []}, {"text": "This method learns the mappings between math concept phrases in math word problems and their math expressions from training data.", "labels": [], "entities": []}, {"text": "For each equation template , we automatically construct a rich template sketch by aggregating information from various problems with the same template.", "labels": [], "entities": []}, {"text": "Our approach is implemented in a two-stage system.", "labels": [], "entities": []}, {"text": "It first retrieves a few relevant equation system templates and aligns numbers in math word problems to those templates for candidate equation generation.", "labels": [], "entities": [{"text": "candidate equation generation", "start_pos": 124, "end_pos": 153, "type": "TASK", "confidence": 0.7021821141242981}]}, {"text": "It then does a fine-grained inference to obtain the final answer.", "labels": [], "entities": []}, {"text": "Experiment results show that our method achieves an accuracy of 28.4% on the linear Dolphin18K benchmark, which is 10% (54% relative) higher than previous state-of-the-art systems while achieving an accuracy increase of 12% (59% relative) on the TS6 benchmark subset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.999293327331543}, {"text": "Dolphin18K benchmark", "start_pos": 84, "end_pos": 104, "type": "DATASET", "confidence": 0.9577856063842773}, {"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9989816546440125}, {"text": "TS6 benchmark subset", "start_pos": 246, "end_pos": 266, "type": "DATASET", "confidence": 0.9553837776184082}]}], "introductionContent": [{"text": "The research topic of automatically solving math word problems dates back to the 1960s.", "labels": [], "entities": [{"text": "automatically solving math word problems", "start_pos": 22, "end_pos": 62, "type": "TASK", "confidence": 0.8384764432907105}]}, {"text": "Recently many systems have been proposed to these types of problems (.", "labels": [], "entities": []}, {"text": "On a recent evaluation conducted by, current state-of-the-art systems only achieved an * Work done while this author was an intern at Microsoft Research.", "labels": [], "entities": []}, {"text": "18.3% accuracy on their published dataset Dolphin18K.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9997707009315491}, {"text": "published dataset Dolphin18K", "start_pos": 24, "end_pos": 52, "type": "DATASET", "confidence": 0.7816124558448792}]}, {"text": "Their results indicate that math word problem solving is a very challenging task.", "labels": [], "entities": [{"text": "math word problem solving", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8540358245372772}]}, {"text": "To solve a math word problem, a system needs to understand natural language text to extract information from the problem as local context.", "labels": [], "entities": []}, {"text": "Also, it should provide an external knowledge base, including commonsense knowledge (e.g. \"a chicken has two legs\") and mathematical knowledge (e.g. \"the perimeter of a rectangle = 2 * length + 2 * width\").", "labels": [], "entities": []}, {"text": "The system can then perform reasoning based on the above two resources to generate an answer.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the acquisition of mathematical knowledge, or deriving math concepts from natural language.", "labels": [], "entities": []}, {"text": "Consider the first two problems P 1 and P 2 in.", "labels": [], "entities": []}, {"text": "The math concept in the problems tells you to takeaway a percentage from one and get the resulting percentage of a total.", "labels": [], "entities": []}, {"text": "Using mathematical language, it can be formulated as (1\u2212n 1 ) * n 2 , where n 1 , n 2 are quantities.", "labels": [], "entities": []}, {"text": "In this example, we can derive the concept of subtraction from the text \" % off \" and \" % discount\".", "labels": [], "entities": []}, {"text": "Acquisition of mathematical knowledge is nontrivial.", "labels": [], "entities": []}, {"text": "Initial statistical approaches) derive math concepts based on observations from their dataset of specific types of problems, e.g. problems with one single equation.", "labels": [], "entities": []}, {"text": "For example, assumes verbs and only verbs embed math concepts and map them to addition/subtraction.; assume there is only one unknown variable in the problem and cannot derive math concepts involving constants or more than one unknown variables, such as \"the product of two unknown numbers\".", "labels": [], "entities": []}, {"text": "Template-based approaches (, on the other hand, leverage the built-in composition structure of equation system templates to formulate all types of math concepts seen in training data, such as (1 \u2212 n 1 ) * n 2 = x in.", "labels": [], "entities": []}, {"text": "However, they suffer from two major shortcomings.", "labels": [], "entities": []}, {"text": "First, the math concepts they learned, which is expressed as an entire template, fails to capture a lot of useful information with sparse training instances.", "labels": [], "entities": []}, {"text": "We argue that it would be more expressive if the math concept is learned in a finer granularity.", "labels": [], "entities": []}, {"text": "Second, their learning processes rely heavily on lexical and syntactic features, such as the dependency path between two slots in a template.", "labels": [], "entities": []}, {"text": "When applied to a large-scale dataset, they create a huge and sparse feature space and it is unclear how these template-related features would contribute.", "labels": [], "entities": []}, {"text": "To alleviate the sparseness problem of math concept learning and better utilize templates, we propose a novel approach to capture rich information contained in templates, including textual expressions that imply math concepts.", "labels": [], "entities": []}, {"text": "We parse the template into a tree structure and define \"template fragment\" as any subtree with at least one operator and two operands.", "labels": [], "entities": []}, {"text": "We learn fine-grained mappings between textual expressions and template fragments, based on longest common substring.", "labels": [], "entities": []}, {"text": "For example, given the three problems in, we can map \"[NUM] % off\" and \" % discount\" to 1 \u2212 n 1 , and \"[NUM] % off\" to (1 \u2212 n 1 ) * n 2 = x.", "labels": [], "entities": []}, {"text": "In this way, we can decompose the templates and learn math concepts in a finer grain.", "labels": [], "entities": []}, {"text": "Furthermore, we observe that problems of the same template share some common properties.", "labels": [], "entities": []}, {"text": "By aggregating problems of the same template and capturing these properties, we automatically construct a sketch for each template in the training data.", "labels": [], "entities": []}, {"text": "Our approach is implemented in a two-stage system.", "labels": [], "entities": []}, {"text": "We first retrieve a few relevant templates in the training data.", "labels": [], "entities": []}, {"text": "This narrows our search space to focus only on those templates that are likely to be relevant.", "labels": [], "entities": []}, {"text": "Then we align numbers in the problem to those few returned templates, and do finegrained inference to obtain the final answer.", "labels": [], "entities": []}, {"text": "We show that the textural expressions and template sketch we propose are effective for both stages.", "labels": [], "entities": []}, {"text": "In addition, our system significantly reduces the hypothesis space of candidate equations compared to previous systems, which benefits the learning process and inference at scale.", "labels": [], "entities": []}, {"text": "We evaluate our system on the benchmark dataset provided by.", "labels": [], "entities": []}, {"text": "Experiments show that our system outperforms two stateof-the-art baselines with a more than 10% absolute (54% relative) accuracy increase in the linear benchmark and a more than 20% absolute (71% relative) accuracy increase for the dataset with a template size greater than or equal to 6.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9740996360778809}, {"text": "accuracy", "start_pos": 206, "end_pos": 214, "type": "METRIC", "confidence": 0.9503784775733948}]}, {"text": "In the remaining parts of this paper, we introduce related work in Section 2, describe template sketch and textual expression learning in Section 3, present our two-stage system in Section 4, summarize experiment setup and results in Section 5, and conclude this paper in Section 6.", "labels": [], "entities": [{"text": "textual expression learning", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6230123142401377}]}], "datasetContent": [{"text": "Settings As demonstrated in, previous datasets for math problems are limited in both scale and diversity.", "labels": [], "entities": []}, {"text": "We conduct our experiment on their dataset Dolphin18K.", "labels": [], "entities": [{"text": "Dolphin18K", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.6030621528625488}]}, {"text": "We use the linear subset, containing 10,644 problems in total.", "labels": [], "entities": []}, {"text": "We use two baseline systems for comparison: (1) ZDC () is a statistical learning method that is an improved version of KAZB (  1 . (2) SIM () is a simple similarity based method.", "labels": [], "entities": []}, {"text": "We do not compare other systems because they only solve one specific type of problem, e.g. only handle addition/subtraction problems and Koncel- aim to solve problems with one single linear equation.", "labels": [], "entities": []}, {"text": "Experiments are conducted using 5-fold crossvalidation with 80% problems randomly selected as training data and the remaining 20% for testing.", "labels": [], "entities": []}, {"text": "We report the solution accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9986403584480286}]}, {"text": "From the table, we observe that our model consistently achieves better performance than the baselines on all template sizes.", "labels": [], "entities": []}, {"text": "As the template size becomes larger, all three systems achieve better performance.", "labels": [], "entities": []}, {"text": "When template size equals 6 (TS6, as a de-facto template size constrain adopted in ZDC), our model achieve an absolute increase of over 12% (59% relative).", "labels": [], "entities": []}, {"text": "This demonstrates the effectiveness of our proposed method.", "labels": [], "entities": []}, {"text": "When including long tail problems with a template size less than 2, performance of all three systems drop significantly.", "labels": [], "entities": []}, {"text": "This is because the templates of these problems are not seen in the training set, and thus are difficult to solve using these template-based methods.", "labels": [], "entities": []}, {"text": "Still, we have at least 10% absolute (54% relative) accuracy increase on the whole test set compared to the two baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.948215663433075}]}, {"text": "Previous template-based methods require templates size larger than 6 in the data as constraints.", "labels": [], "entities": []}, {"text": "From the result, we can see that our method relaxes the template size constraint and matches more problems with less frequent templates.", "labels": [], "entities": []}, {"text": "Next, we evaluate the performance of our twostage system.", "labels": [], "entities": []}, {"text": "Accuracy of template retrieval and alignment ranking is shown in.", "labels": [], "entities": []}, {"text": "For template retrieval accuracy, Hit@N means the correct template fora problem is included in the top N list returned by our model.", "labels": [], "entities": [{"text": "template retrieval", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7615480124950409}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9273642897605896}]}, {"text": "We estimate the best achievable performance by using oracle template retrieval.", "labels": [], "entities": []}, {"text": "The result is 47.1% (Hit@ALL), which means 47.1% of the templates exist more than once in the problem set.", "labels": [], "entities": []}, {"text": "Please note that our template retrieval evaluation maybe underestimated, since in some cases, a test problem can be solved by different templates.", "labels": [], "entities": [{"text": "template retrieval", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7722290754318237}]}, {"text": "We then use the top N templates as input for both our alignment ranking and ZDC.", "labels": [], "entities": [{"text": "alignment", "start_pos": 54, "end_pos": 63, "type": "TASK", "confidence": 0.933975338935852}, {"text": "ZDC", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.5480090975761414}]}, {"text": "From the table, we have the following observations: (1) Hit@3 performs better compared to Hit@1 for both systems.", "labels": [], "entities": []}, {"text": "This confirms our claim that some templates are similar and we need to incorporate more fine-grained features to differentiate in the alignment step; (2) It obtains the highest accuracy when N = 3 and decreases when N gets larger.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9987751841545105}]}, {"text": "Both systems get benefits from our template retrieval which helps retrieve relevant templates and reduce the hypothesis space of equations; (3) Given the same N templates input, our alignment ranking achieves better performance than ZDC.", "labels": [], "entities": []}, {"text": "This implies that our features are more indicative.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Overall evaluation results.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy Per Template. Template retrieval acc reports percent of templates appears in one of  the top 3 templates returned by our method.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988310933113098}]}, {"text": " Table 5: Results of template retrieval and final accuracy with different top N templates retrieved.", "labels": [], "entities": [{"text": "template retrieval", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8923982679843903}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9589163661003113}]}, {"text": " Table 6: Feature ablation of template retrieval.", "labels": [], "entities": []}, {"text": " Table 7: Feature ablation of alignment ranking.", "labels": [], "entities": [{"text": "alignment ranking", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.9128914773464203}]}]}