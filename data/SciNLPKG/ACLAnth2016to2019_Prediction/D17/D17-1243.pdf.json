{"title": [{"text": "A Factored Neural Network Model for Characterizing Online Discussions in Vector Space", "labels": [], "entities": [{"text": "Characterizing Online Discussions in Vector Space", "start_pos": 36, "end_pos": 85, "type": "TASK", "confidence": 0.8055719037850698}]}], "abstractContent": [{"text": "We develop a novel factored neural model that learns comment embeddings in an un-supervised way leveraging the structure of distributional context in online discussion forums.", "labels": [], "entities": []}, {"text": "The model links different context with related language factors in the embedding space, providing away to interpret the factored embeddings.", "labels": [], "entities": []}, {"text": "Evaluated on a community endorsement prediction task using a large collection of topic-varying Reddit discussions, the fac-tored embeddings consistently achieve improvement over other text representations.", "labels": [], "entities": [{"text": "community endorsement prediction task", "start_pos": 15, "end_pos": 52, "type": "TASK", "confidence": 0.7173865363001823}]}, {"text": "Qualitative analysis shows that the model captures community style and topic, as well as response trigger patterns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Massive user-generated content on social media has drawn interests in predicting community reactions in the form of virality), popularity), community endorsement, persuasive impact (, etc.", "labels": [], "entities": []}, {"text": "Many of these studies have analyzed content-agnostic factors such as submission timing and author social status, as well as language factors that underlie the textual content, e.g., the topic and idiosyncrasies of the community.", "labels": [], "entities": []}, {"text": "In particular, there is an increasing amount of work on online discussion forums such as Reddit that exploits the conversational and community-centric nature of the usergenerated content (, which contrasts with Twitter where the author's social status seems to play a larger role in popularity.", "labels": [], "entities": []}, {"text": "This paper focuses on Reddit, using the karma score 1 as a readily available measure of community endorsement.", "labels": [], "entities": []}, {"text": "Some of the prior work on Reddit investigates specific linguistic phenomena (e.g. politeness, topic relevance, community style matching) using feature engineering to understand their role in predicting community reactions.", "labels": [], "entities": [{"text": "community style matching", "start_pos": 111, "end_pos": 135, "type": "TASK", "confidence": 0.659352312485377}, {"text": "predicting community reactions", "start_pos": 191, "end_pos": 221, "type": "TASK", "confidence": 0.8489590684572855}]}, {"text": "In contrast, this paper explores methods for unsupervised text embedding learning using a model structured so as to provide some interpretability of the results when used in comment endorsement prediction.", "labels": [], "entities": [{"text": "comment endorsement prediction", "start_pos": 174, "end_pos": 204, "type": "TASK", "confidence": 0.8065383036931356}]}, {"text": "The model aims to characterize the interdependence of comment on its global context and subsequent responses that is characteristic of multi-party discussions.", "labels": [], "entities": []}, {"text": "Specifically, we propose a factored neural model with separate mechanisms for representing global context, comment content and response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.7238711267709732}]}, {"text": "By factoring the model, we hope unsupervised learning will pickup different components of interactive language in the resulting embeddings, which will improve prediction of community reactions.", "labels": [], "entities": [{"text": "prediction of community reactions", "start_pos": 159, "end_pos": 192, "type": "TASK", "confidence": 0.8193706274032593}]}, {"text": "Distributed representations of text, or text embeddings, have achieved great success in many language processing applications, using both supervised and unsupervised methods.", "labels": [], "entities": []}, {"text": "Unsupervised learning, in particular, has been successful at different levels, including words (), sentences (, and documents (.", "labels": [], "entities": []}, {"text": "Studies have also shown that the learned embedding captures both syntactic and semantic functions of words ().", "labels": [], "entities": []}, {"text": "At the same time, em-beddings are often viewed as uninterpretable -it is difficult to align embedding dimensions to existing semantic or syntactic classes.", "labels": [], "entities": []}, {"text": "This concern has triggered attempts in developing more interpretable embedding models, which is also a goal of our work.", "labels": [], "entities": []}, {"text": "We leverage the fact that the structure of the distributional context impacts what is learned in an unsupervised way and include multiple objectives for separating different types of context.", "labels": [], "entities": []}, {"text": "Here, we are interested in linking two types of context with corresponding language factors learned in the embedding space that may impact comment reception.", "labels": [], "entities": [{"text": "comment reception", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.6880803257226944}]}, {"text": "First, conformity to the topic and the language use of the community tends to make the content better accepted (.", "labels": [], "entities": []}, {"text": "Those global modes typically influence the author's generation of local content.", "labels": [], "entities": []}, {"text": "Second, characteristics of a comment can influence the responses it triggers.", "labels": [], "entities": []}, {"text": "Clearly, questions and statements will elicit different responses, and comments directed at a particular discussion participant may prompt that individual to respond.", "labels": [], "entities": []}, {"text": "Of more interest here are aspects of comments that might elicit minimal response or responses with different sentiments, which are relevant for eventual endorsement.", "labels": [], "entities": []}, {"text": "The primary contribution of this work is the development of a factored neural model to jointly learn these aspects of multi-party discussions from a large collection of Reddit comments in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "Extending the recent neural attention model (, the proposed model can interpret the learned latent global modes as community-related topic and style.", "labels": [], "entities": []}, {"text": "A comment-response generation model component captures aspects of the comment that are response triggers.", "labels": [], "entities": []}, {"text": "The multi-factored comment embedding is evaluated on the task of predicting the comment endorsement for three online communities different in topic trends and writing style.", "labels": [], "entities": []}, {"text": "The representation of textual information using our approach consistently outperforms multiple document embedding baselines, and analyses of the global modes and response trigger subvectors show that the model learns common communication strategies in discussion forums.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the effectiveness of the factored comment embeddings on the quantized karma prediction task.", "labels": [], "entities": [{"text": "karma prediction task", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.8843610485394796}]}, {"text": "We use the concatenation of the local mode vector and the content vector at the last time step as the factored comment embedding.", "labels": [], "entities": []}, {"text": "First, we study the overall prediction performance of four different classifiers under two settings, i.e., using factored comment embeddings or not.", "labels": [], "entities": []}, {"text": "Then we compare the factored comment embeddings inferred from the full model and its two Whether the comment author is the user who initiated the thread.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Content-agnostic features.  \u2020 means two  kinds of normalization are used: 1) zero-mean nor- malization; 2) divided by the squared-root-rank of  the feature value in the thread.", "labels": [], "entities": [{"text": "zero-mean nor- malization", "start_pos": 87, "end_pos": 112, "type": "METRIC", "confidence": 0.6912681758403778}]}, {"text": " Table 2: Averaged F1 scores of DeepOR classi- fiers using different text features. Baseline results  do not use any text features.", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9902741312980652}, {"text": "DeepOR classi- fiers", "start_pos": 32, "end_pos": 52, "type": "DATASET", "confidence": 0.8323479443788528}]}, {"text": " Table 3: Examples of comments associated with the learned global modes for Politics.", "labels": [], "entities": []}]}