{"title": [{"text": "Learning What's Easy: Fully Differentiable Neural Easy-First Taggers", "labels": [], "entities": [{"text": "Learning What's Easy: Fully Differentiable Neural Easy-First Taggers", "start_pos": 0, "end_pos": 68, "type": "TASK", "confidence": 0.5515985310077667}]}], "abstractContent": [{"text": "We introduce a novel neural easy-first de-coder that learns to solve sequence tagging tasks in a flexible order.", "labels": [], "entities": [{"text": "solve sequence tagging tasks", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.6901151984930038}]}, {"text": "In contrast to previous easy-first decoders, our models are end-to-end differentiable.", "labels": [], "entities": []}, {"text": "The decoder iteratively updates a \"sketch\" of the predictions over the sequence.", "labels": [], "entities": []}, {"text": "At its core is an attention mechanism that controls which parts of the input are strategically the best to process next.", "labels": [], "entities": []}, {"text": "We present anew constrained softmax transformation that ensures the same cumulative attention to every word, and show how to efficiently evaluate and backpropagate over it.", "labels": [], "entities": []}, {"text": "Our models compare favourably to BILSTM taggers on three sequence tagging tasks.", "labels": [], "entities": [{"text": "BILSTM taggers", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7369374632835388}, {"text": "sequence tagging tasks", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7671955823898315}]}], "introductionContent": [{"text": "In the last years, neural models have led to major advances in several structured NLP problems, including sequence tagging (, sequence-to-sequence prediction (, and sequence-totree ().", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 106, "end_pos": 122, "type": "TASK", "confidence": 0.7445773780345917}, {"text": "sequence-to-sequence prediction", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.6788675040006638}]}, {"text": "Part of the success comes from clever architectures such as (bidirectional) long-short term memories (BILSTMs;;) and attention mechanisms (, which are able to select the pieces of context relevant for prediction.", "labels": [], "entities": [{"text": "BILSTMs", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9355681538581848}]}, {"text": "A noticeable aspect about many of the systems above is that they typically decode from left to right, greedily or with a narrow beam.", "labels": [], "entities": []}, {"text": "While this is computationally convenient and reminiscent of the way humans process spoken language, the combination of unidirectional decoding and greediness leads to error propagation and suboptimal classification performance.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 167, "end_pos": 184, "type": "TASK", "confidence": 0.6495146751403809}]}, {"text": "This can partly be mitigated by globally normalized models () and imitation learning, however these techniques still have a left-to-right bias.", "labels": [], "entities": []}, {"text": "Easy-first decoders are an interesting alternative: instead of a fixed decoding order, these methods schedule their own actions by prefering \"easier\" decisions over more difficult ones.", "labels": [], "entities": []}, {"text": "A disadvantage is that these models are harder to learn, due to the factorial number of orderings leading to correct predictions.", "labels": [], "entities": []}, {"text": "Usually, gradients are not backpropagated over this combinatorial latent space, or a separate model is used to determine the easiest next move.", "labels": [], "entities": []}, {"text": "In this paper, we develop novel, fully differentiable, neural easy-first sequence taggers ( \u00a73).", "labels": [], "entities": [{"text": "neural easy-first sequence taggers", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.6329557299613953}]}, {"text": "Instead of taking discrete actions, our decoders use an attention mechanism to decide (in a soft manner) which word to focus on for the next tagging decision.", "labels": [], "entities": []}, {"text": "Our models are able to learn their own sense of \"easiness\": the words receiving focus may not be the ones the model is most confident about, but the best to avoid error propagation in the long run.", "labels": [], "entities": []}, {"text": "To make sure that all words receive the same cumulative attention, we further contribute with anew constrained softmax transformation ( \u00a74).", "labels": [], "entities": []}, {"text": "This transformation extends the softmax by permitting upper bound constraints on the amount of probability a word can receive.", "labels": [], "entities": []}, {"text": "We show how to evaluate this transformation and backpropagate its gradients.", "labels": [], "entities": []}, {"text": "We run experiments in three sequence tagging tasks: multilingual part-of-speech (POS) tagging, named entity recognition (NER), and word-level quality estimation ( \u00a75).", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7160516977310181}, {"text": "multilingual part-of-speech (POS) tagging", "start_pos": 52, "end_pos": 93, "type": "TASK", "confidence": 0.6104118128617605}, {"text": "named entity recognition (NER)", "start_pos": 95, "end_pos": 125, "type": "TASK", "confidence": 0.7654639035463333}, {"text": "word-level quality estimation", "start_pos": 131, "end_pos": 160, "type": "TASK", "confidence": 0.642287035783132}]}, {"text": "We complement our findings with a visual analysis of the attention distribu-", "labels": [], "entities": [{"text": "attention distribu-", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7600103616714478}]}], "datasetContent": [{"text": "We evaluate our neural easy-first models in three sequence tagging tasks: POS tagging, NER, and word quality estimation.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7090730667114258}, {"text": "POS tagging", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.7788015604019165}, {"text": "NER", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.7371857166290283}, {"text": "word quality estimation", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.7722232540448507}]}], "tableCaptions": [{"text": " Table 1: POS tagging accuracies. The average in the rightmost column is over the words of each treebank.   \u2020 Note that Gillick et al. (2016) and Plank et al. (2016) are not strictly comparable, since they use older  versions of the treebanks (UD1.1 and UD1.2, respectively).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7207238972187042}, {"text": "UD1.2", "start_pos": 254, "end_pos": 259, "type": "DATASET", "confidence": 0.7879822850227356}]}, {"text": " Table 2: F 1 scores for NER, computed by the  CoNLL 2002 evaluation script.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9791560371716818}, {"text": "NER", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8349792957305908}, {"text": "CoNLL 2002 evaluation script", "start_pos": 47, "end_pos": 75, "type": "DATASET", "confidence": 0.9626587182283401}]}, {"text": " Table 3: F 1 -MULT scores (product of F 1 for OK  and BAD words) for word-level quality estimation,  computed by the official shared task script.", "labels": [], "entities": [{"text": "F 1 -MULT scores", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8765098690986634}, {"text": "BAD", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.950031042098999}, {"text": "word-level quality estimation", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.6163003245989481}]}, {"text": " Table 4: Ablation experiments. Reported are F 1  scores for NER in the English test set.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9320723414421082}, {"text": "F 1  scores", "start_pos": 45, "end_pos": 56, "type": "METRIC", "confidence": 0.974601129690806}, {"text": "NER", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.4919290244579315}, {"text": "English test set", "start_pos": 72, "end_pos": 88, "type": "DATASET", "confidence": 0.9086414178212484}]}]}