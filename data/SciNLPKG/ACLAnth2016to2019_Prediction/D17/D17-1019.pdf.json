{"title": [{"text": "Neural Net Models of Open-domain Discourse Coherence", "labels": [], "entities": []}], "abstractContent": [{"text": "Discourse coherence is strongly associated with text quality, making it important to natural language generation and understanding.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.6750180522600809}]}, {"text": "Yet existing models of coherence focus on measuring individual aspects of coherence (lexical overlap, rhetorical structure, entity centering) in narrow domains.", "labels": [], "entities": []}, {"text": "In this paper, we describe domain-independent neural models of discourse coherence that are capable of measuring multiple aspects of coherence in existing sentences and can maintain coherence while generating new sentences.", "labels": [], "entities": []}, {"text": "We study both discriminative models that learn to distinguish coherent from incoherent discourse, and generative models that produce coherent text, including a novel neural latent-variable Markovian generative model that captures the latent discourse dependencies between sentences in a text.", "labels": [], "entities": []}, {"text": "Our work achieves state-of-the-art performance on multiple coherence evaluations, and marks an initial step in generating coherent texts given discourse contexts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modeling discourse coherence (the way parts of a text are linked into a coherent whole) is essential for summarization (), text planning) question-answering (, and even psychiatric diagnosis.", "labels": [], "entities": [{"text": "summarization", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.9860828518867493}, {"text": "text planning", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.7921300828456879}, {"text": "psychiatric diagnosis", "start_pos": 169, "end_pos": 190, "type": "TASK", "confidence": 0.7057541906833649}]}, {"text": "Various frameworks exist, each tackling aspects of coherence.", "labels": [], "entities": []}, {"text": "Lexical cohesion) models chains of words and synonyms.", "labels": [], "entities": []}, {"text": "Psychological models of discourse ( use LSA embeddings to generalize lexical cohesion.", "labels": [], "entities": []}, {"text": "Relational models like RST ( define relations that hierarchically structure texts.", "labels": [], "entities": [{"text": "RST", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9653042554855347}]}, {"text": "The entity grid model ( and its extensions 1 capture the referential coherence of entities moving in and out of focus across a text.", "labels": [], "entities": []}, {"text": "Each captures only a single aspect of coherence, and all focus on scoring existing sentences, rather than on generating coherent discourse for tasks like abstractive summarization.", "labels": [], "entities": []}, {"text": "Here we introduce two classes of neural models for discourse coherence.", "labels": [], "entities": []}, {"text": "Our discriminative models induce coherence by treating human generated texts as coherent examples and texts with random sentence replacements as negative examples, feeding LSTM sentence embeddings of pairs of consecutive sentences to a classifier.", "labels": [], "entities": []}, {"text": "These achieve stateof-the-art (96% accuracy) on the standard domainspecific sentence-pair-ordering dataset (, but suffer in a larger opendomain setting due to the small semantic space that negative sampling is able to cover.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9981662631034851}]}, {"text": "Our generative models are based on augumenting encoder-decoder models with latent variables to model discourse relationships across sentences, including (1) a model that incorporates an HMM-LDA topic model into the generative model and (2) an end-to-end model that introduces a Markovstructured neural latent variable, inspired by recent work on training latent-variable recurrent nets).", "labels": [], "entities": []}, {"text": "These generative models obtain the best result on a large open-domain setting, including on the difficult task of reconstructing the order of every sentence in a paragraph, and our latent variable generative model significantly improves the coherence of text generated by the model.", "labels": [], "entities": []}, {"text": "Our work marks an initial step in building endto-end systems to evaluate open-domain discourse coherence, and more importantly, generating coherent texts given discourse contexts.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe experimental results.", "labels": [], "entities": []}, {"text": "We first evaluate the proposed models on discriminative tasks such as sentence-pair ordering and full paragraph ordering reconstruction.", "labels": [], "entities": [{"text": "sentence-pair ordering", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.7168884873390198}, {"text": "full paragraph ordering reconstruction", "start_pos": 97, "end_pos": 135, "type": "TASK", "confidence": 0.6697196960449219}]}, {"text": "Then we look at the task of coherent text generation.", "labels": [], "entities": [{"text": "coherent text generation", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.6406411131223043}]}, {"text": "Both the tasks above are discriminative ones.", "labels": [], "entities": []}, {"text": "We also want to evaluate different models' ability to generate coherent text chunks.", "labels": [], "entities": []}, {"text": "The experiment is setup as follow: each encoder-decoder model is first given a set of context sentences (3 sentences).", "labels": [], "entities": []}, {"text": "The model then generates a succeeding sentence using beam-search given the contexts.", "labels": [], "entities": []}, {"text": "For the unidirectional setting, we directly take the most probable sequence and for the bi-directional and MMI, we rerank the N-best list using the backward probability and language model probability.", "labels": [], "entities": [{"text": "MMI", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.562048614025116}]}, {"text": "We conduct experiments on multi-sentence generation, in which we repeat the generative process described above for N times, where N =1,2,3.", "labels": [], "entities": [{"text": "multi-sentence generation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.8199968338012695}]}, {"text": "At the end of each turn, the context is updated by adding in the newly generated sequence, and this sequence is used as the source input to the encoderdecoder model for next sequence generation.", "labels": [], "entities": []}, {"text": "For example, when N is set to 2, given the three context sentences context-a, context-b and context-c, we first generate sen-d given the three context sentences and then generate sen-e given the sen-d, context-a, context-b and context-c.", "labels": [], "entities": []}, {"text": "For evaluation, standard word overlap metrics such as BLEU or ROUGE are not suited for our task, and we use adversarial evaluation;.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9985588192939758}, {"text": "ROUGE", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.9809587597846985}]}, {"text": "In adversarial evaluation, we train a binary discriminant function to classify a sequence as machine generated or human generated, in an attempt to evaluate the model's sentence generation capability.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.7169004082679749}]}, {"text": "The evaluator takes as input the concatenation of the contexts and the generated sentences (i.e., context-a, context-b and context-c, sen-d , sen-e in the example described above), and outputs a scalar, indicating the probability of the current text chunk being human-generated.", "labels": [], "entities": []}, {"text": "Training/dev/test sets are held-out sets from the one on which generative models are trained.", "labels": [], "entities": []}, {"text": "They respectively contain 128,000/12,800/12,800 instances.", "labels": [], "entities": []}, {"text": "Since discriminative models cannot generate sentences, and thus cannot be used for adversarial evaluation, they are skipped in this section.", "labels": [], "entities": []}, {"text": "We report Adversarial Success (AdverSuc for short), which is the fraction of instances in which a model is capable of fooling the evaluator.", "labels": [], "entities": []}, {"text": "Adver-: An overview of training the adversarial evaluator using a hierarchical neural model.", "labels": [], "entities": []}, {"text": "Red denotes a sentence from human-generated texts, treated as a positive example.", "labels": [], "entities": []}, {"text": "Purple denotes a sentence from machine-decoded texts, treated as a negative example.", "labels": [], "entities": []}, {"text": "Suc is the difference between 1 and the accuracy achieved by the evaluator.", "labels": [], "entities": [{"text": "Suc", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9870563745498657}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9995939135551453}]}, {"text": "Higher values of AdverSuc fora dialogue generation model are better.", "labels": [], "entities": [{"text": "dialogue generation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7281927615404129}]}, {"text": "AdverSuc-N denotes the adversarial accuracy value on machine-generated texts with N turns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9942863583564758}]}, {"text": "show AdverSuc numbers for different models.", "labels": [], "entities": []}, {"text": "As can be seen, the latent variable model VLV-GM is able to generate chunk of texts that are most indistinguishable from coherent texts from humans.", "labels": [], "entities": []}, {"text": "This is due to its ability to handle the dependency between neighboring sentences.", "labels": [], "entities": []}, {"text": "Performance declines as the number of turns increases due to the accumulation of errors and current models' inability to model long-term sentence-level dependency.", "labels": [], "entities": []}, {"text": "All models perform poorly on the adver-3 evaluation metric, with the best adversarial success value being 0.081 (the trained evaluator is able to distinguish between human-generated and machine generated dialogues with greater than 90 percent accuracy for all models).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 243, "end_pos": 251, "type": "METRIC", "confidence": 0.9967057108879089}]}], "tableCaptions": [{"text": " Table 1: Results from different coherence models. Results for  the Recursive model is reprinted from Li and Hovy (2014),  Entity Grid Model from Louis and Nenkova (2012), HMM,  HMM+Entity and HMM+Content from Louis and Nenkova  (2012), Graph from Guinaudeau and Strube (2013), and the  final two lexical models are recomputed using Glove and LDA  to replace the original LSA model of Foltz et al. (1998).", "labels": [], "entities": [{"text": "Glove", "start_pos": 333, "end_pos": 338, "type": "METRIC", "confidence": 0.8628273606300354}]}, {"text": " Table 2: Performance on the open-domain binary classification  dataset of 984 Wikipedia paragraphs.", "labels": [], "entities": [{"text": "open-domain binary classification  dataset of 984 Wikipedia paragraphs", "start_pos": 29, "end_pos": 99, "type": "DATASET", "confidence": 0.7823006212711334}]}, {"text": " Table 3: Performances of the proposed models on the open- domain paragraph reconstruction dataset.", "labels": [], "entities": [{"text": "open- domain paragraph reconstruction", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.5469405651092529}]}, {"text": " Table 4: Adversarial Success for different models.", "labels": [], "entities": []}]}