{"title": [{"text": "Identifying and Tracking Sentiments and Topics from Social Media Texts during Natural Disasters", "labels": [], "entities": [{"text": "Identifying and Tracking Sentiments and Topics from Social Media Texts during Natural Disasters", "start_pos": 0, "end_pos": 95, "type": "TASK", "confidence": 0.8552914261817932}]}], "abstractContent": [{"text": "We study the problem of identifying the topics and sentiments and tracking their shifts from social media texts in different geographical regions during emergencies and disasters.", "labels": [], "entities": []}, {"text": "We propose a location-based dynamic sentiment-topic model (LDST) which can jointly model topic, sentiment, time and Geolocation information.", "labels": [], "entities": []}, {"text": "The experimental results demonstrate that LDST performs very well at discovering topics and sentiments from social media and tracking their shifts in different geographical regions during emergencies and disasters 1 .", "labels": [], "entities": [{"text": "LDST", "start_pos": 42, "end_pos": 46, "type": "TASK", "confidence": 0.9505072832107544}]}], "introductionContent": [{"text": "Social media has become pervasive in our daily life, and it is a great way to spread important information efficiently.", "labels": [], "entities": []}, {"text": "Using social media (e.g., Twitter, Facebook, Pinterest), people can conveniently inform others and express support during emergencies and disasters.", "labels": [], "entities": []}, {"text": "Nowadays, the social media is keeping producing a huge amount of information.", "labels": [], "entities": []}, {"text": "Unlike before, people are not only interested in identifying the static topics and sentiments from given texts, but also, perhaps more concerned with tracking the evolution of topics and sentiments among different geographical regions.", "labels": [], "entities": []}, {"text": "On the one hand, this new requirement can be very helpful, especially in the case of emergencies, such as pre-disaster preparation and post-disaster relief in local natural disasters (.", "labels": [], "entities": [{"text": "pre-disaster preparation", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.6998754143714905}]}, {"text": "For example, people's sentiments on the topics related to medical and rescue may guide the management and distribution of emergency supplies.", "labels": [], "entities": [{"text": "medical and rescue", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7574552496274313}]}, {"text": "On the other hand, the existing models do not take the temporal evolution and the impact of location over topics and sentiments into consideration, which makes them unable to fulfill the new requirement of tracking the evolution of topics and sentiments in different geographical places.", "labels": [], "entities": []}, {"text": "In this paper, we aim to identify the topics and sentiments and track their shifts in different geographical regions during emergencies and disasters.", "labels": [], "entities": []}, {"text": "We are inspired by several observations.", "labels": [], "entities": []}, {"text": "First, people are interested in not only the overall sentiment or topic distribution of the documents but also the sentiments towards specific topics.", "labels": [], "entities": []}, {"text": "For example, a person maybe happy with that the disaster passed away, but at the meanwhile he/she maybe unsatisfied with the post-disaster relief.", "labels": [], "entities": []}, {"text": "Second, most existing sentiment-topic models ignore the temporal evolution of topics and sentiment in a time-variant data corpus such as the Twitter stream.", "labels": [], "entities": []}, {"text": "There are strong evidences which indicate that people's attitudes toward a disaster will gradually changeover time with the distribution of emergency supplies).", "labels": [], "entities": []}, {"text": "Third, people in different places tend to have different opinions towards particular topics.", "labels": [], "entities": []}, {"text": "This motivated us to find the influence of specific topics and the relationship between different topics in different regions, which may improve people's awareness to help themselves during disasters.", "labels": [], "entities": []}, {"text": "We propose a location-based dynamic sentiment-topic model (LDST) which generalizes latent Dirichlet allocation (LDA) (, by jointly modeling topic, sentiment, time and geolocation information.", "labels": [], "entities": []}, {"text": "After learning the LDST model, we can identify the topics and sentiments held by people in different locations overtime.", "labels": [], "entities": [{"text": "LDST", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.8156506419181824}]}, {"text": "Our model works in an unsupervised way, and we learn the model according to the frequency of terms co-occurring in different contexts.", "labels": [], "entities": []}, {"text": "To leverage the prior knowledge, we construct a small set of seed words for each topic of interest to enable the model to group semantically related terms into the same topic.", "labels": [], "entities": []}, {"text": "Consequently, the topic words will be more related to the seed words of the same topic.", "labels": [], "entities": []}, {"text": "We conduct experiments using a Hurricane Sandy Twitter corpus which consists of 159,880 geotagged Twitter posts from the geographic area and time period of the 2012 Hurricane Sandy.", "labels": [], "entities": []}, {"text": "We show the evolution of people's topics and sentiments, which change according to not only the time the disaster happens, but also people's locations during the hurricane Sandy.", "labels": [], "entities": []}], "datasetContent": [{"text": "This dataset contains nearly 15 million tweets posted on Twitter while Hurricane Sandy was hitting the United States.", "labels": [], "entities": []}, {"text": "Tweets were collected from October 25, 2012 to November 4, using the keywords 'hurricane' and 'sandy'.", "labels": [], "entities": []}, {"text": "In this paper, we only keep the geotagged tweets.", "labels": [], "entities": []}, {"text": "The final experimental dataset consists of 159,880 geotagged tweets.", "labels": [], "entities": []}, {"text": "The original geographical information is expressed by using longitude and latitude in decimal degree.", "labels": [], "entities": []}, {"text": "We set the granularity of location as a state via Google Maps Geocoding API 2 and analyze the tweets within the United States.", "labels": [], "entities": []}, {"text": "We first compare our model with the baseline models in terms of perplexity which is a widely used measurement of how well a probability model predicts a sample.", "labels": [], "entities": []}, {"text": "The lower the perplexity, the better the model.", "labels": [], "entities": []}, {"text": "We calculate the average perplexity (log-likelihood) using 1000 held-out documents which are randomly selected from the test data.", "labels": [], "entities": []}, {"text": "The average test perplexity of each word is calculated as exp{\u2212 1 N w log p(w)}, where N is the total number of words in the held-out test documents.", "labels": [], "entities": []}, {"text": "shows the perplexity results for Hurricane Sandy dataset.", "labels": [], "entities": [{"text": "Hurricane Sandy dataset", "start_pos": 33, "end_pos": 56, "type": "DATASET", "confidence": 0.608376125494639}]}, {"text": "Our model outperforms the baseline models.", "labels": [], "entities": []}, {"text": "In particular, the perplexity of our model is 1122, which is 40 and 116 lower than that of JST and TS.", "labels": [], "entities": [{"text": "JST", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.7307424545288086}, {"text": "TS", "start_pos": 99, "end_pos": 101, "type": "DATASET", "confidence": 0.5456737875938416}]}, {"text": "The perplexity of LDST is 35 lower than that of LDST-w/oS, which indicates that the seed words can further improve the performance of our model.", "labels": [], "entities": [{"text": "LDST", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.7050297856330872}]}, {"text": "Following the same evaluation as in ( , we also present and discuss the experimental results of sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.9357930719852448}]}, {"text": "The docu-ment sentiment is classified based on the probability of sentiment label given document, which can be approximated by\u02c6\u03c7by\u02c6 by\u02c6\u03c7 (a) u and\u02c6\u03c7and\u02c6 and\u02c6\u03c7 v dv . Similar to ( , we only consider the probability of positive and negative label given document, with the neutral label probability being ignored.", "labels": [], "entities": []}, {"text": "We define that a document dis classified as a positivesentiment document if its probability of positive sentiment label given document is greater than its probability of negative sentiment label given document, and vice versa.", "labels": [], "entities": []}, {"text": "The ground truth of sentiment classification labels of tweets are set by using human annotation.", "labels": [], "entities": [{"text": "sentiment classification labels of tweets", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.8828768968582154}]}, {"text": "Specifically, we randomly select 1000 documents from the dataset, and label each document as positive, negative or neutral manually.", "labels": [], "entities": []}, {"text": "We measure the performance of our model using the tweets with positive or negative labels.", "labels": [], "entities": []}, {"text": "The classification accuracies are summarization in: Sentiment classification accuracy.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.8374330997467041}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9531077146530151}]}, {"text": "We present the sentiments and topics discovered by LDST to see whether LDST captured meaningful semantics.", "labels": [], "entities": []}, {"text": "We analyze the extracted topics under positive and negative sentiment labels.", "labels": [], "entities": []}, {"text": "Due to the limited space, we only report Hurricane impact and public utility topics under positive and negative sentiments for New York and Florida states on Oct..", "labels": [], "entities": []}, {"text": "For each topic, we visualize it using the top 5 words which are most likely generated from the topic.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of test perplexity per word", "labels": [], "entities": []}, {"text": " Table 2. LDST significantly outperforms  other methods on test data. This verifies the effec- tiveness of the proposed approach.", "labels": [], "entities": [{"text": "LDST", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.45340612530708313}]}, {"text": " Table 2: Sentiment classification accuracy.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9697805941104889}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9749837517738342}]}]}