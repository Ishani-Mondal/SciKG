{"title": [{"text": "Sentence Simplification with Deep Reinforcement Learning", "labels": [], "entities": [{"text": "Sentence Simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9522480070590973}]}], "abstractContent": [{"text": "Sentence simplification aims to make sentences easier to read and understand.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9361072480678558}]}, {"text": "Most recent approaches draw on insights from machine translation to learn simplification rewrites from monolingual corpora of complex and simple sentences.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7147232890129089}]}, {"text": "We address the simplification problem with an encoder-decoder model coupled with a deep reinforcement learning framework.", "labels": [], "entities": []}, {"text": "Our model, which we call DRESS (as shorthand for Deep REinforcement Sentence Simplification), explores the space of possible simplifications while learning to optimize a reward function that encourages outputs which are simple, fluent , and preserve the meaning of the input.", "labels": [], "entities": [{"text": "DRESS", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.7273030281066895}, {"text": "Deep REinforcement Sentence Simplification", "start_pos": 49, "end_pos": 91, "type": "TASK", "confidence": 0.5511243864893913}]}, {"text": "Experiments on three datasets demonstrate that our model outperforms competitive simplification systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "The main goal of sentence simplification is to reduce the linguistic complexity of text, while still retaining its original information and meaning.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.7199709862470627}]}, {"text": "The simplification task has been the subject of several modeling efforts in recent years due to its relevance for NLP applications and individuals alike.", "labels": [], "entities": []}, {"text": "For instance, a simplification component could be used as a preprocessing step to improve the performance of parsers (, summarizers), and semantic role labelers).", "labels": [], "entities": []}, {"text": "Automatic simplification would also benefit people with low-literacy skills (), such as children and non-native speakers as well as individuals with autism (), aphasia), or dyslexia ().", "labels": [], "entities": []}, {"text": "The most prevalent rewrite operations which give rise to simplified text include substituting rare words with more common words or phrases, rendering syntactically complex structures simpler, and deleting elements of the original text).", "labels": [], "entities": []}, {"text": "Earlier work focused on individual aspects of the simplification problem.", "labels": [], "entities": [{"text": "simplification problem", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.9371492564678192}]}, {"text": "For example, several systems performed syntactic simplification only, using rules aimed at sentence splitting () while others turned to lexical simplification by substituting difficult words with more common WordNet synonyms or paraphrases).", "labels": [], "entities": [{"text": "syntactic simplification", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.7315673232078552}, {"text": "sentence splitting", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7179617881774902}]}, {"text": "Recent approaches view the simplification process more holistically as a monolingual textto-text generation task borrowing ideas from statistical machine translation.", "labels": [], "entities": [{"text": "textto-text generation", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.7299099117517471}, {"text": "statistical machine translation", "start_pos": 134, "end_pos": 165, "type": "TASK", "confidence": 0.635369340578715}]}, {"text": "Simplification rewrites are learned automatically from examples of complex-simple sentences extracted from online resources such as the ordinary and simple English Wikipedia.", "labels": [], "entities": [{"text": "Simplification rewrites", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8652754127979279}]}, {"text": "For example, draw inspiration from syntax-based translation and propose a model similar to which additionally performs simplification-specific rewrite operations (e.g., sentence splitting).", "labels": [], "entities": [{"text": "syntax-based translation", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.711432933807373}, {"text": "sentence splitting", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.7504115402698517}]}, {"text": "formulate simplification in the framework of Quasi-synchronous grammar) and use integer linear programming to score the candidate translations/simplifications.", "labels": [], "entities": []}, {"text": "propose a two-stage model: initially, a standard phrase-based machine translation (PBMT) model is trained on complex-simple sentence pairs.", "labels": [], "entities": [{"text": "phrase-based machine translation (PBMT)", "start_pos": 49, "end_pos": 88, "type": "TASK", "confidence": 0.7621015657981237}]}, {"text": "During inference, the K-best outputs of the PBMT model are reranked according to their dis-similarity to the (complex) input sentence.", "labels": [], "entities": []}, {"text": "The hybrid model developed in also operates in two phases.", "labels": [], "entities": []}, {"text": "Initially, a probabilistic model performs sentence splitting and deletion operations over discourse representation structures assigned by Boxer.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7407379448413849}]}, {"text": "The resulting sentences are further simplified by a model similar to. train a syntax-based machine translation model on a large scale paraphrase dataset () using simplification-specific objective functions and features to encourage simpler output.", "labels": [], "entities": []}, {"text": "In this paper we propose a simplification model which draws on insights from neural machine translation ().", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.7121984759966532}]}, {"text": "Central to this approach is an encoderdecoder architecture implemented by recurrent neural networks.", "labels": [], "entities": []}, {"text": "The encoder reads the source sequence into a list of continuous-space representations from which the decoder generates the target sequence.", "labels": [], "entities": []}, {"text": "Although our model uses the encoder-decoder architecture as its backbone, it must also meet constraints imposed by the simplification task itself, i.e., the predicted output must be simpler, preserve the meaning of the input, and grammatical.", "labels": [], "entities": []}, {"text": "To incorporate this knowledge, the model is trained in a reinforcement learning framework: it explores the space of possible simplifications while learning to maximize an expected reward function that encourages outputs which meet simplificationspecific constraints.", "labels": [], "entities": []}, {"text": "Reinforcement learning has been previously applied to extractive summarization (, information extraction (, dialogue generation (, machine translation, and image caption generation (.", "labels": [], "entities": [{"text": "Reinforcement learning", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8979538381099701}, {"text": "extractive summarization", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6909013092517853}, {"text": "information extraction", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.8005982935428619}, {"text": "dialogue generation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.8060286045074463}, {"text": "machine translation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.7379653006792068}, {"text": "image caption generation", "start_pos": 156, "end_pos": 180, "type": "TASK", "confidence": 0.8260881106058756}]}, {"text": "We evaluate our system on three publicly available datasets collated automatically from Wikipedia () and human-authored news articles ().", "labels": [], "entities": []}, {"text": "We experimentally show that the reinforcement learning framework is the key to successful generation of simplified text bringing significant improvements over strong simplification models across datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our experimental setup for assessing the performance of the simplification model described above.", "labels": [], "entities": []}, {"text": "We give details on our datasets, model training, evaluation protocol, and the systems used for comparison.", "labels": [], "entities": []}, {"text": "Our third dataset is Newsela, a corpus collated by who argue that Wikipediabased resources are suboptimal due to the automatic sentence alignment which unavoidably introduces errors, and their uniform writing style which leads to systems that generalize poorly.", "labels": [], "entities": [{"text": "Newsela", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.9519155025482178}, {"text": "sentence alignment", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.7297860085964203}]}, {"text": "Newsela 2 consists of 1,130 news articles, each rewritten four times by professional editors for children at different grade levels (0 is the most complex level and 4 is simplest).", "labels": [], "entities": []}, {"text": "provide multiple aligned complex-simple pairs within each article.", "labels": [], "entities": []}, {"text": "We removed sentence pairs corresponding to levels 0-1, 1-2, and 2-3, since they were too similar to each other.", "labels": [], "entities": []}, {"text": "The first 1,070 documents were used for training (94,208 sentence pairs), the next 30 documents for development (1,129 sentence pairs) and the last 30 documents for testing (1,076 sentence pairs).", "labels": [], "entities": []}, {"text": "We are not aware of any published results on this dataset.", "labels": [], "entities": []}, {"text": "Training Details We trained our models on an Nvidia GPU card.", "labels": [], "entities": [{"text": "Nvidia GPU card", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.9484977126121521}]}, {"text": "We used the same hyperparameters across datasets.", "labels": [], "entities": []}, {"text": "We first trained an encoder-decoder model, and then performed reinforcement learning training (Section 3), and trained the lexical simplification model (Section 4).", "labels": [], "entities": []}, {"text": "Encoder-decoder parameters were uniformly initialized to [\u22120.1, 0.1].", "labels": [], "entities": []}, {"text": "We used Adam () to optimize the model with learning rate 0.001; the first momentum coefficient was set to 0.9 and the second momentum coefficient to 0.999.", "labels": [], "entities": []}, {"text": "The gradient was rescaled when the norm exceeded 5 (.", "labels": [], "entities": []}, {"text": "Both encoder and decoder LSTMs have two layers with 256 hidden neurons in each layer.", "labels": [], "entities": []}, {"text": "We regularized all LSTMs with a dropout rate of 0.2 ().", "labels": [], "entities": []}, {"text": "We initialized the encoder and decoder word embedding matrices with 300 dimensional Glove vectors (.", "labels": [], "entities": []}, {"text": "During reinforcement training, we used plain stochastic gradient descent with a learning rate of 0.01.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.9658163189888}]}, {"text": "We set \u03b2 = 0.1, \u03bb S = 1, \u03bb R = 0.25 and \u03bb F = 0.5.", "labels": [], "entities": [{"text": "F", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9351436495780945}]}, {"text": "Training details for the lexical 2 https://newsela.com If a sentence has multiple references in the development or test set, we use the reference with highest simplicity level.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 159, "end_pos": 169, "type": "METRIC", "confidence": 0.9931647181510925}]}, {"text": "Weights were tuned on the development set of the Newsela dataset and kept fixed for the other two datasets.", "labels": [], "entities": [{"text": "Newsela dataset", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.9850989580154419}]}, {"text": "simplification model are identical to the encoderdecoder model except that word embedding matrices were randomly initialized.", "labels": [], "entities": []}, {"text": "The weight of the lexical simplification model was set to \u03b7 = 0.1.", "labels": [], "entities": []}, {"text": "To reduce vocabulary size, named entities were tagged with the Stanford CoreNLP ( ) and anonymized with a NE@N token, where NE \u2208 {PER, LOC, ORG, MISC} and N indicates NE@N is the N -th distinct NE typed entity.", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.9356374144554138}]}, {"text": "For example, \"John and Bob are . .", "labels": [], "entities": []}, {"text": "\" becomes \"PER@1 and PER@2 are . .", "labels": [], "entities": [{"text": "PER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9751847982406616}]}, {"text": "\". At test time, we de-anonymize NE@N tokens in the output by looking them up in their source sentences.", "labels": [], "entities": []}, {"text": "Note that the de-anonymization may fail, but the chance is small (around 2% of the time on the Newsela development set).", "labels": [], "entities": [{"text": "Newsela development set", "start_pos": 95, "end_pos": 118, "type": "DATASET", "confidence": 0.9732720653216044}]}, {"text": "We replaced words occurring three times or less in the training set with UNK.", "labels": [], "entities": [{"text": "UNK", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.8967793583869934}]}, {"text": "At test time, when our models predict UNK, we adopt the UNK replacement method proposed in.", "labels": [], "entities": [{"text": "UNK", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.6156911849975586}, {"text": "UNK replacement", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.5874602794647217}]}, {"text": "Evaluation Following previous work) we evaluated system output automatically adopting metrics widely used in the simplification literature.", "labels": [], "entities": []}, {"text": "Specifically, we used BLEU 5 () to assess the degree to which generated simplifications differed from gold standard references and the Flesch-Kincaid Grade Level index (FKGL;) to measure the readability of the output (lower FKGL 6 implies simpler output).", "labels": [], "entities": [{"text": "BLEU 5", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9698484539985657}, {"text": "Flesch-Kincaid Grade Level index (FKGL", "start_pos": 135, "end_pos": 173, "type": "METRIC", "confidence": 0.9327850540479025}]}, {"text": "In addition, we used SARI (, which evaluates the quality of the output by comparing it against the source and reference simplifications.", "labels": [], "entities": [{"text": "SARI", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9805527329444885}]}, {"text": "7 BLEU, FKGL, and SARI are all measured at corpus-level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9989066123962402}, {"text": "FKGL", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.7335789799690247}, {"text": "SARI", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9882908463478088}]}, {"text": "We also evaluated system output by eliciting human judgments via Amazon's Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 65, "end_pos": 89, "type": "DATASET", "confidence": 0.8671642243862152}]}, {"text": "Specifically (selfreported) native English speakers were asked to rate simplifications on three dimensions: Fluency (is the output grammatical and well formed?), Adequacy (to what extent is the meaning expressed in the original sentence preserved in the output?) and Simplicity (is the output simpler than the original sentence?).", "labels": [], "entities": [{"text": "Fluency", "start_pos": 108, "end_pos": 115, "type": "METRIC", "confidence": 0.9766189455986023}, {"text": "Adequacy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9646010994911194}, {"text": "Simplicity", "start_pos": 267, "end_pos": 277, "type": "METRIC", "confidence": 0.9724090099334717}]}, {"text": "All ratings were obtained using a five point Likert scale.", "labels": [], "entities": []}, {"text": "lingual phrase-based machine translation system with a reranking post-processing step and Hybrid, a model which first performs sentence splitting and deletion operations over discourse representation structures and then further simplifies sentences with PBMT-R ().", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.6423135995864868}, {"text": "sentence splitting", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.7314794659614563}]}, {"text": "Hybrid 9 is state of the art on the WikiSmall dataset.", "labels": [], "entities": [{"text": "WikiSmall dataset", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.9490486979484558}]}, {"text": "Comparisons with SBMT-SARI, a syntax-based translation model trained on PPDB ( and tuned with SARI (), are problematic due to the size of PPDB which is considerably larger than any of the datasets used in this work (it contains 106 million sentence pairs with 2 billion words).", "labels": [], "entities": []}, {"text": "Nevertheless, we compare 10 against SBMT-SARI, but only models trained on Wikilarge, our largest dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatic evaluation on Newsela, Wik- iSmall, and WikiLarge test sets.", "labels": [], "entities": [{"text": "Newsela", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9753604531288147}, {"text": "WikiLarge test sets", "start_pos": 60, "end_pos": 79, "type": "DATASET", "confidence": 0.8868693709373474}]}, {"text": " Table 2: Mean ratings elicited by humans on  Newsela, WikiSmall, and WkiLarge test sets. Rat- ings significantly different from DRESS-LS are  marked with * (p < 0.05) and ** (p < 0.01). Sig- nificance tests were performed using a student  t-test.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9763866066932678}, {"text": "Newsela", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.9831864833831787}, {"text": "WkiLarge test sets", "start_pos": 70, "end_pos": 88, "type": "DATASET", "confidence": 0.973119060198466}]}, {"text": " Table 4: Output length (average number of to- kens), TER scores and number of edits by type  (Insertions, Deletions, Substitutions, Shifts) on  the Newsela test set. Higher TER means that more  rewriting operations are performed.", "labels": [], "entities": [{"text": "Output length", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9494556784629822}, {"text": "TER", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9987455606460571}, {"text": "Newsela test set", "start_pos": 149, "end_pos": 165, "type": "DATASET", "confidence": 0.9798826177914938}, {"text": "TER", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.9974128603935242}]}]}