{"title": [{"text": "Do LSTMs really work so well for PoS tagging? - A replication study", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.9394925236701965}]}], "abstractContent": [{"text": "A recent study by Plank et al.", "labels": [], "entities": []}, {"text": "(2016) found that LSTM-based PoS taggers considerably improve over the current state-of-the-art when evaluated on the corpora of the Universal Dependencies project that use a coarse-grained tagset.", "labels": [], "entities": [{"text": "LSTM-based PoS taggers", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.6871310770511627}]}, {"text": "We replicate this study using afresh collection of 27 corpora of 21 languages that are annotated with fine-grained tagsets of varying size.", "labels": [], "entities": []}, {"text": "Our replication confirms the result in general , and we additionally find that the advantage of LSTMs is even bigger for larger tagsets.", "labels": [], "entities": []}, {"text": "However, we also find that for the very large tagsets of morphologically rich languages, hand-crafted morphological lexicons are still necessary to reach state-of-the-art performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Part-of-Speech (PoS) tagging is an important processing step for many NLP applications.", "labels": [], "entities": [{"text": "Part-of-Speech (PoS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5752702832221985}]}, {"text": "When researchers want to use a PoS tagger, they would ideally choose an off-the-shelf PoS tagger which is optimized fora specific language.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.7234347462654114}]}, {"text": "If a suited tagger is not available two options remain: a) implementation of your own tagger, which requires technical knowledge and experience, or b) using an existing tagger and hope that the resulting model will be sufficiently accurate.", "labels": [], "entities": []}, {"text": "One can assume that many taggers fit more languages than the one for which they have been constructed originally.", "labels": [], "entities": []}, {"text": "Ideally, researchers should be able to fallback to a well-evaluated language-independent tagger if no reference implementation fora language is available.", "labels": [], "entities": []}, {"text": "A recent study by evaluated an LSTM PoS tagger and compared the results to Conditional Random Fields (CRF)) and Hidden-Markov (HMM) implementations on corpora of various languages.", "labels": [], "entities": [{"text": "LSTM PoS tagger", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.6707099080085754}]}, {"text": "Their evaluation concludes that the LSTM tagger reaches better results than the CRF and HMM tagger.", "labels": [], "entities": []}, {"text": "The evaluation corpora were all annotated with a coarse-grained tagset with 17 tags.", "labels": [], "entities": []}, {"text": "Thus, this LSTM tagger seems to be a well-performing, language-independent choice for learning models on coarse-grained tagsets.", "labels": [], "entities": [{"text": "LSTM tagger", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.8549431264400482}]}, {"text": "While for many tasks a coarse-grained tagset might be sufficient some tasks require more fine-grained tagsets.", "labels": [], "entities": []}, {"text": "We, thus, consider it worthwhile to explore if the results are reproducible using corpora with fine-grained tagsets.", "labels": [], "entities": []}, {"text": "We use the LSTM tagger provided by and compare the results likewise to CRF and an off-the-shelf HMM tagger implementation.", "labels": [], "entities": [{"text": "CRF", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.7181402444839478}]}, {"text": "We compile afresh set of 27 corpora of 21 languages which uses the commonly used fine-grained tagset of the respective language.", "labels": [], "entities": []}, {"text": "We suggest these corpora as evaluation set for tasks which require fine-grained PoS tags, as all corpora are freely available for research purposes.", "labels": [], "entities": []}, {"text": "Our intention is to replicate the findings of, which have been achieved on a coarse-grained tagset and investigate if they transfer to fine-grained tagsets.", "labels": [], "entities": []}], "datasetContent": [{"text": "Selection To ensure reproducibility, we preferably selected corpora which are directly available via the Internet except German-3, Hungarian and Swedish-2.", "labels": [], "entities": []}, {"text": "We intentionally exclude languages such as Chinese or Japanese, which do not provide whitespace delimiters to mark word boundaries.", "labels": [], "entities": []}, {"text": "Tagging those languages requires a morpho-D an is h Du tc h E n g li sh Ge rm an -1 Ge rm an -2 Ge rm an -3 Is la n d ic It a li an Sp an is h C ro a ti an -1 C ro a ti an -2 C z e ch Po li sh Ru s s ia n S lo v a k S lo v en e -1 S lo v en e -2 Afr ik a an s F inn is h He b re w H u n g a ri an 0: Coarse-grained PoS tag distribution of corpora by language group logical analysis which is a different task than the tagging task on which we are focusing here.", "labels": [], "entities": []}, {"text": "Most corpora are manually annotated or were at least human-verified.", "labels": [], "entities": []}, {"text": "There are four exceptions which we decided to add anyway to increase the number of languages represented in our setup.", "labels": [], "entities": []}, {"text": "The tagset granularity of the corpora ranges from coarse (12 tags) to morphologically fine (1574 tags) to evaluate all taggers on various stages of granularity.", "labels": [], "entities": []}, {"text": "Language & Corpora Diversity We analyzed the distribution of PoS tags in the corpora by mapping all tags to the 17 coarse-grained PoS tags of the Universal Dependencies (UD) project) in.", "labels": [], "entities": [{"text": "Language & Corpora Diversity", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5404246300458908}]}, {"text": "The mappings to the UD tagset have been manually created.", "labels": [], "entities": [{"text": "UD tagset", "start_pos": 20, "end_pos": 29, "type": "DATASET", "confidence": 0.8376745283603668}]}, {"text": "The partly large differences between the syntactical classes help to better understand the challenge in construction a tagger that is suited for all those languages.", "labels": [], "entities": []}, {"text": "For instance, Germanic and Romanic languages have a lot of determiners while they do not occur at all in Slavic languages.", "labels": [], "entities": []}, {"text": "We reviewed the recent literature to determine the most commonly used features for training PoS taggers.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.8960391879081726}]}, {"text": "As re-occurring features, we found word ngrams, fixed character sequences focusing on either pre-, in-, or suffixes of words and word distributional knowledge for PoS taggers of various languages.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 163, "end_pos": 174, "type": "TASK", "confidence": 0.8626449406147003}]}, {"text": "Word-and characterngrams have been used with various parametrizations depending on the language and there is no agreement which parameters are most advisable.", "labels": [], "entities": []}, {"text": "We will, hence, run a series of parameter-search experiments over the word-and character-ngram parametrization to determine a configuration applicable to all languages.", "labels": [], "entities": []}, {"text": "For this, we evaluate all permutations of the subsequently introduced feature configurations with 10fold cross-validation.", "labels": [], "entities": []}, {"text": "The objective is to find a configuration that works well on all corpora, languages, and tagsets.", "labels": [], "entities": []}, {"text": "Word Features We experiment with adding the 1, 2, 3 words to the right and left of the current word as lower-cased string features.", "labels": [], "entities": []}, {"text": "Character Features Which character-ngram is discriminative fora PoS tag strongly depends on the language.", "labels": [], "entities": []}, {"text": "To avoid a language bias, we use a frequency-based approach in which we select the N most frequently occurring character-ngrams of length 1, 2, 3, 4 from the training dataset.", "labels": [], "entities": []}, {"text": "We experiment with the following frequency cut-off values of N \u03b5 {250, 500, 750, 1000} to select only frequent and potentially informative characterngrams as features.", "labels": [], "entities": []}, {"text": "These N features are boolean and are set to 1 if the respective character-ngram occurs in the current word.", "labels": [], "entities": []}, {"text": "Results In, we show the results of our parameter search experiment.", "labels": [], "entities": []}, {"text": "The triangles mark the results of the various feature configurations.", "labels": [], "entities": []}, {"text": "The diamond symbol shows the configuration which works best overall corpora.", "labels": [], "entities": []}, {"text": "We refer to this best working configuration as Best CRF subsequently, it uses a word-context window of 1 word to the left and right and the 750 most frequent character [1..4] grams with additionally adding word clusters.", "labels": [], "entities": [{"text": "Best CRF", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.8500802218914032}]}, {"text": "Especially for morphologically-rich languages, the spread is quite large which is caused by the lower number of character-ngrams in those configurations.", "labels": [], "entities": [{"text": "spread", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9663301706314087}]}, {"text": "For corpora such as Slovene-1, we see that more accurate configurations exist than Best CRF but more importantly, the selected configuration is always among the best working ones.", "labels": [], "entities": [{"text": "Slovene-1", "start_pos": 20, "end_pos": 29, "type": "DATASET", "confidence": 0.9783728718757629}]}, {"text": "When using neural networks, the details of how word and character information is provided greatly influences the learning success of the network.", "labels": [], "entities": []}, {"text": "We will reproduce network setups which have also been used in to ensure comparability to the coarse-grained results to which we compare our results: Word In this setup, we train a network on the word embeddings only and provide them to a bidirectional LSTM.", "labels": [], "entities": []}, {"text": "This setup will serve as baseline.", "labels": [], "entities": []}, {"text": "Char The character embeddings of a word are provided to a bidirectional LSTM.", "labels": [], "entities": []}, {"text": "The last state of the forward and the backward character LSTM are combined ( and provided to another bidirectional LSTM layer.", "labels": [], "entities": []}, {"text": "Word-Char This architecture is a combination of the previous two architectures.", "labels": [], "entities": [{"text": "Word-Char", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8934776782989502}]}, {"text": "The last state of the character LSTMs is added to the word embedding information before it is provided to the next LSTM layer.", "labels": [], "entities": []}, {"text": "Word-Char+ The architecture by combines word and character level information and additionally considers the logfrequency of the next word during training.", "labels": [], "entities": []}, {"text": "This tagger reported state-of-the-art results and we use the provided reference implementation of this tagger in our setup.", "labels": [], "entities": []}, {"text": "LSTMs have the reputation to require larger amounts of training data.", "labels": [], "entities": []}, {"text": "With the 50k tokens we use this is barely fulfilled, however, find this sensitivity to be less severe and set a corpus size of 60k tokens as lower bound for their coarse-grained tagging experiments.", "labels": [], "entities": []}, {"text": "We will comeback to this data size issue in Section 7, where we evaluate using all tokens in a corpus (and arriving at the same conclusions as for our 50k token datasets).", "labels": [], "entities": []}, {"text": "Furthermore, in many cases only smaller dataset sizes are available, sometimes even less than 50k tokens.", "labels": [], "entities": []}, {"text": "It is, thus, important to know if considering neural network taggers makes sense at all (on fine-grained tagsets), thus we will train LSTM models on smaller dataset sizes.", "labels": [], "entities": []}, {"text": "We implement the LSTM taggers in DyNet ( and use the hyper-parameter settings by, i.e. we train 20 epochs using Statistical-Gradient-Descent with a learning rate of 0.1 and adding Gaussian noise of 0.2 to the embedding layer.", "labels": [], "entities": [{"text": "LSTM taggers", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.8002566993236542}, {"text": "DyNet", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9112976789474487}]}, {"text": "We train word embeddings on the data we already used for the semantic feature in the CRF experiments by using fastText) . The the character-level embeddings are trained on-the-fly.", "labels": [], "entities": []}, {"text": "Results In, we show the results for the LSTM architectures.", "labels": [], "entities": []}, {"text": "The Word-Char+ tagger performs best followed by Word-Char, which is not surprising as Word-Char+ is based on this architecture.", "labels": [], "entities": [{"text": "Word-Char", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.9370821714401245}]}, {"text": "For the Germanic and Romanic languages, the accuracy of the various architectures is similar but for Slavic languages, which use much more fine-grained tagsets, the differences are rather large.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9992994070053101}]}, {"text": "For instance, the Char architecture reaches only small improvements over the Word baseline on Croatian or Czech while on Spanish, or Hungarian the character architecture is clearly better than the baseline.", "labels": [], "entities": []}, {"text": "shows the detailed results and additionally reports the accuracy values on OOV with best results highlighted in grey.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9996917247772217}, {"text": "OOV", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.776617705821991}]}, {"text": "The Char architecture is in many cases competitive to the HunPos reference system.", "labels": [], "entities": [{"text": "HunPos reference", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.8952776193618774}]}, {"text": "This shows that the performance of many off-theshelf taggers is rather easy to approximate by relying only on character-level information.", "labels": [], "entities": []}, {"text": "The results by the Char architecture also explains why the Word-Char architecture performs so well although the amount of syntactical information is quite limited with 50k tokens.", "labels": [], "entities": []}, {"text": "A large part of the necessary information is already obtained by the character model, which requires a lot less training data than a model on the word level.", "labels": [], "entities": []}, {"text": "Thus, the results of on coarsetagsets are reproducible for fine-grained tagsets with the Word-Char architecture being the essential property to achieving high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9651983976364136}]}], "tableCaptions": [{"text": " Table 1: Corpora used in our experiments", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of CRF taggers (10fold CV)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984173774719238}, {"text": "CRF taggers", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.8333075940608978}]}, {"text": " Table 3: Accuracy of LSTM taggers (10fold CV)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984637498855591}, {"text": "LSTM taggers", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.8150649070739746}]}, {"text": " Table 4: Results of reproducing setups in the literature using the full corpus size", "labels": [], "entities": []}]}