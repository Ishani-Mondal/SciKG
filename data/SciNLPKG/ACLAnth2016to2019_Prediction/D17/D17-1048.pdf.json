{"title": [{"text": "A Cognition Based Attention Model for Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.9704420566558838}]}], "abstractContent": [{"text": "Attention models are proposed in sentiment analysis because some words are more important than others.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9592272341251373}]}, {"text": "However, most existing methods either use local context based text information or user preference information.", "labels": [], "entities": []}, {"text": "In this work, we propose a novel attention model trained by cognition grounded eye-tracking data.", "labels": [], "entities": []}, {"text": "A reading prediction model is first built using eye-tracking data as dependent data and other features in the context as independent data.", "labels": [], "entities": [{"text": "reading prediction", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.9335867762565613}]}, {"text": "The predicted reading time is then used to build a cognition based attention (CBA) layer for neural sentiment analysis.", "labels": [], "entities": [{"text": "neural sentiment analysis", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7426885962486267}]}, {"text": "As a comprehensive model, We can capture attentions of words in sentences as well as sentences in documents.", "labels": [], "entities": []}, {"text": "Different attention mechanisms can also be incorporated to capture other aspects of attentions.", "labels": [], "entities": []}, {"text": "Evaluations show the CBA based method outperforms the state-of-the-art local context based attention methods significantly.", "labels": [], "entities": []}, {"text": "This brings insight to how cognition grounded data can be brought into NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is critical for many applications such as sentimental product recommendation (, public opinion detection (, and human-machine interaction (, etc.Sentiment analysis has been well-explored ().Recently, deep learning based methods have further elevated the performance of sentiment analysis without the need for labor intensive feature engineering.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9421190917491913}, {"text": "sentimental product recommendation", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.9155161579449972}, {"text": "public opinion detection", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.6592754224936167}, {"text": "sentiment analysis", "start_pos": 288, "end_pos": 306, "type": "TASK", "confidence": 0.9524480998516083}]}, {"text": "Attention models are incorporated into sentiment analysis because not all words are created equal.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.9630317091941833}]}, {"text": "Some words are more important than others in conveying the message in a sentence.", "labels": [], "entities": []}, {"text": "Similarly, some sentences are more important than others in a document.", "labels": [], "entities": []}, {"text": "Although the overall reading time as a cognitive process may reflect the syntax and discourse complexity, reading time of individual words is also an indicator of their semantic importance in text.", "labels": [], "entities": []}, {"text": "Previous attention models are built using information embedded in text including users, products and text in local context for sentiment classification (.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 127, "end_pos": 151, "type": "TASK", "confidence": 0.9514357447624207}]}, {"text": "However, attention models using local context based text through distributional similarity lack theoretical foundation to reflect the cognitive basis.", "labels": [], "entities": []}, {"text": "But, the key in sentiment analysis lies in its cognitive basis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.9815880060195923}]}, {"text": "Thus, we envision that cognition grounded data obtained in text reading should be helpful in building an attention model.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel cognition based attention(CBA) model for sentiment analysis learned from cognition grounded eye-tracking data.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.9733366668224335}]}, {"text": "Eye-tracking is the process of measuring either the point of gaze or the motion of an eye relative to the head . In psycho-linguistics experiments, shows that readers are less likely to fixate on close-class words that are predictable from context.", "labels": [], "entities": []}, {"text": "Readers also fixate longer on words which play significant semantic roles) in addition to infrequent words, ambiguous words, and morphological complex words.", "labels": [], "entities": []}, {"text": "Since reading time can be learned from an eye-tracking dataset, predicted reading time of words in its context can be used as indicators of attention weights.", "labels": [], "entities": []}, {"text": "We first build a regression model to map syntax, and context features of a word to its reading time based on eye-tracking data.", "labels": [], "entities": []}, {"text": "We then apply the model to sentiment analysis text to obtain the estimated reading time of words at the sentence level.", "labels": [], "entities": [{"text": "sentiment analysis text", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.910242756207784}]}, {"text": "The estimated reading time can then be used as the attention weights in its context to build the attention layer in a neural network based sentiment analysis model.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.8969464302062988}]}, {"text": "Evaluation on the four sentiment analysis benchmark datasets (IMDB, show that our proposed model can significantly improve the performance compared to the state-of-the-art attention methods.", "labels": [], "entities": []}, {"text": "To sum up, we have two major contributions: (1) We propose a novel cognition grounded attention model to improve the state-of-the-art neural network based sentiment analysis models by learning attention information from eye-tracking data.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.9065805971622467}]}, {"text": "This is one of the first attempts to use cognition grounded data in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9670818746089935}]}, {"text": "The CBA model not only can capture attention of words at the sentence level, it can also be aggregated to work at the document level.", "labels": [], "entities": []}, {"text": "(2) Evaluation on several real-world datasets in sentiment analysis shows that our method outperforms other state-of-the-art methods significantly.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9605515599250793}]}, {"text": "This work validates the effectiveness of cognition grounded data in building attention models.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our Two commonly used performance evaluation metrics are used.", "labels": [], "entities": []}, {"text": "The first one is accuracy and the second one is rooted mean square error (RMSE) . Let GR i be the golden sentiment ratings, PR i be the predicted sentiment rating, and T be the number of documents where GR i = PR i . Accuracy is then defined by and RMSE is defined by We train the skip-gram word embedding () on each dataset separately to initialize the word vectors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9992713332176208}, {"text": "rooted mean square error (RMSE)", "start_pos": 48, "end_pos": 79, "type": "METRIC", "confidence": 0.8146949197564807}, {"text": "Accuracy", "start_pos": 217, "end_pos": 225, "type": "METRIC", "confidence": 0.9968104958534241}]}, {"text": "All embedding sizes on the model are set to 200, a commonly used size.", "labels": [], "entities": []}, {"text": "Three sets of experiments are conducted.", "labels": [], "entities": []}, {"text": "The first is on the selection of the regression model for reading time prediction.", "labels": [], "entities": [{"text": "reading time prediction", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.7149798174699148}]}, {"text": "The second set of experiments compares our proposed CBA with another sentiment analysis method which use text only.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.9319852888584137}]}, {"text": "The third set of experiments evaluates the effectiveness of combining different attention models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 list the statistics of the datasets in- cluding number of classes, number of docu- ments, and average length of sentence. We split", "labels": [], "entities": []}, {"text": " Table 2: RMSE for reading time predic- tion(Unit:Milliseconds)", "labels": [], "entities": [{"text": "RMSE", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9568156003952026}, {"text": "predic- tion", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.8541135589281718}]}, {"text": " Table 4: Evaluation on sentiment classification using review text for training", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.9754929542541504}]}, {"text": " Table 5: Evaluation on sentiment classification on using dual attention", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.9835429489612579}]}]}