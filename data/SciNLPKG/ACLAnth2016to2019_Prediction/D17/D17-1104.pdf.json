{"title": [{"text": "Evaluating Hierarchies of Verb Argument Structure with Hierarchical Clustering", "labels": [], "entities": []}], "abstractContent": [{"text": "Verbs can only be used with a few specific arrangements of their arguments (syn-tactic frames).", "labels": [], "entities": []}, {"text": "Most theorists note that verbs can be organized into a hierarchy of verb classes based on the frames they admit.", "labels": [], "entities": []}, {"text": "Here we show that such a hierarchy is objectively well-supported by the patterns of verbs and frames in English, since a systematic hierarchical clustering algorithm converges on the same structure as the handcrafted taxonomy of VerbNet, a broad-coverage verb lexicon.", "labels": [], "entities": []}, {"text": "We also show that the hierarchies capture meaningful psychological dimensions of generalization by predicting novel verb coercions by human participants.", "labels": [], "entities": []}, {"text": "We discuss limitations of a simple hierarchical representation and suggest similar approaches for identifying the representations underpinning verb argument structure.", "labels": [], "entities": []}], "introductionContent": [{"text": "Why can Sally like to read but not *appreciate to read?", "labels": [], "entities": []}, {"text": "Key to the grammar of sentences are verbs and the arguments with which they appear.", "labels": [], "entities": []}, {"text": "How children learn the constraints that govern the ways verbs and arguments combine is a central question in language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.721083477139473}]}, {"text": "Theorists have long noted that verbs can be organized into classes based on their syntactic constructions and the events they express (see for review).", "labels": [], "entities": []}, {"text": "Verb classes are included inmost theories of argument structure acquisition, whether as first class objects ( or mere epiphenomena of other claims about the structure of form-meaning mappings.", "labels": [], "entities": [{"text": "argument structure acquisition", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.6726866960525513}]}, {"text": "Most theories also propose further structure between classes.", "labels": [], "entities": []}, {"text": "One common assumption is that verb argument structure can beat least partially described by a hierarchy: Each verb belongs to a class, which itself may belong to a number of broader superclasses.", "labels": [], "entities": [{"text": "verb argument structure", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7040935754776001}]}, {"text": "While many theories predict more complex structure (e.g. cross-cutting categories;), providing (psycho)linguistic evidence fora simple hierarchy of verbs is an important starting point for investigating more complex theories., the largest English verb argument structure resource, 1 organizes verbs and classes into a shallow hierarchy, but its structure has been handcrafted incrementally overtime (starting with seminal work by.", "labels": [], "entities": []}, {"text": "On the other hand, recently-developed, state-of-the-art machine learning methods offer a unique alternative approach to constructing such a hierarchy.", "labels": [], "entities": []}, {"text": "In this paper, we first conduct a broad-coverage analysis of how verbs might be hierarchically arranged by comparing VerbNet's handcrafted hierarchy to structure systematically inferred by a Bayesian hierarchical clustering algorithm.", "labels": [], "entities": []}, {"text": "We find that the two arrive at similar structure, thus substantiating both methods (i.e. intuition vs. clustering) and the common hierarchy they find.", "labels": [], "entities": []}, {"text": "Second, we investigate the psychological validity of this representation: if classes capture meaningful dimensions of generalization, one would intuit that a verb in a class should behave more similarly to verbs in nearby classes than distant classes according to some measure of \"distance\".", "labels": [], "entities": []}, {"text": "Indeed, this kind of assumption plays an important role in theoretical ( and empirical) work.", "labels": [], "entities": []}, {"text": "We thus ask human participants to rate the compatibility of a wide range of existing verbs in attested and unattested syntactic frames.", "labels": [], "entities": []}, {"text": "We find that such coercions are indeed predicted by a hierarchical taxonomy of verbs.", "labels": [], "entities": []}], "datasetContent": [{"text": "Here we evaluated the extent to which BHC converged on VerbNet's structure at low (sub and standard classes) and high levels (superclasses).", "labels": [], "entities": [{"text": "VerbNet's structure", "start_pos": 55, "end_pos": 74, "type": "DATASET", "confidence": 0.9167140523592631}]}, {"text": "We consider ground truth classes across the levels of VerbNet granularity: low-level subclasses (H sub , C sub ), standard classes (H standard , C standard ), and superclasses (H super , C super ) (.", "labels": [], "entities": []}, {"text": "The important comparison is with superclasses, for which both H and C were high.", "labels": [], "entities": []}, {"text": "This indicates that BHC clusters rarely included verbs from multiple VerbNet superclasses (H super = .88) and rarely split verbs from the same VerbNet superclass into different BHC clusters (C super = .72).", "labels": [], "entities": []}, {"text": "Tanglegram While H and C focus on the size and membership of two clustering solutions, tanglegrams (Huson and Scornavacca, 2012) allow a more general visualization and comparison of two hierarchies.", "labels": [], "entities": []}, {"text": "Using the heuristic of Scornavacca et al.", "labels": [], "entities": []}, {"text": "(2011), we drew the optimal tanglegram of VerbNet and BHC, where the two trees are drawn such that lines connect common leaves and the number of intersections made by these lines is minimized.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9189985990524292}, {"text": "BHC", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8182926774024963}]}, {"text": "We computed the entanglement of the tanglegram by normalizing the number of intersections to the 0-1 interval by dividing by the worst case; this is a holistic measure of the similarity of the hierarchies.", "labels": [], "entities": []}, {"text": "The tanglegram shows that qualitatively, much of VerbNet's structure aligns well between the trees.", "labels": [], "entities": []}, {"text": "We observed an entanglement of 0.20, compared to a random baseline of 0.66.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Homogeneity and completeness. Ran- dom baselines are mean statistics across 1000  clusterings made by uniformly sampling a BHC  cluster for each verb. C sub is trivially 1, since  members of VerbNet subclasses have identical fea- tures and were always grouped into the same class  by BHC.", "labels": [], "entities": []}, {"text": " Table 2: 2 sampled frames and their correspond- ing sentence templates, each with 3 example  verbs and predicted compatibilities. To form the  stimuli, each verb is placed into the sentence  template, e.g. Beyond the place arose the thing.", "labels": [], "entities": []}]}