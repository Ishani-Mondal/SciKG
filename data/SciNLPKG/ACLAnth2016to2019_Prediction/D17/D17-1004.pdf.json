{"title": [{"text": "Position-aware Attention and Supervised Data Improve Slot Filling", "labels": [], "entities": [{"text": "Supervised Data Improve Slot Filling", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.7077557921409607}]}], "abstractContent": [{"text": "Organized relational knowledge in the form of \"knowledge graphs\" is important for many applications.", "labels": [], "entities": []}, {"text": "However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly.", "labels": [], "entities": []}, {"text": "This paper simultaneously addresses two issues that have held back prior work.", "labels": [], "entities": []}, {"text": "We first propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.883795291185379}]}, {"text": "Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset, obtained via crowdsourcing and targeted towards TAC KBP relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7170991599559784}]}, {"text": "The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.8529031872749329}]}, {"text": "When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot filling system, its F 1 score increases markedly from 22.2% to 26.7%.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7158495187759399}, {"text": "TAC KBP 2015 slot filling", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.8038320541381836}, {"text": "F 1 score", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.990260899066925}]}], "introductionContent": [{"text": "A basic but highly important challenge in natural language understanding is being able to populate a knowledge base with relational facts contained in apiece of text.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.652553915977478}]}, {"text": "For the text shown in, the system should extract triples, or equivalently, knowledge graph edges, such as hPenner, per:spouse, Lisa Dillmani.", "labels": [], "entities": []}, {"text": "Combining such extractions, a system can produce a knowledge graph of relational facts between persons, organizations, and locations in the text.", "labels": [], "entities": []}, {"text": "This task involves entity recognition, mention coreference and/or entity linking, and relation extraction; we focus on the  most challenging \"slot filling\" task of filling in the relations between entities in the text.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7789285778999329}, {"text": "mention coreference", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7334150075912476}, {"text": "entity linking", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.7240768074989319}, {"text": "relation extraction", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8279220759868622}, {"text": "slot filling\"", "start_pos": 142, "end_pos": 155, "type": "TASK", "confidence": 0.7864970366160074}]}, {"text": "Organized relational knowledge in the form of \"knowledge graphs\" has become an important knowledge resource.", "labels": [], "entities": []}, {"text": "These graphs are now extensively used by search engine companies, both to provide information to end-users and internally to the system, as away to understand relationships.", "labels": [], "entities": []}, {"text": "However, up until now, automatic knowledge extraction has proven sufficiently difficult that most of the facts in these knowledge graphs have been built up by hand.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7451539933681488}]}, {"text": "It is therefore a key challenge to show that NLP technology can effectively contribute to this important problem.", "labels": [], "entities": []}, {"text": "Existing work on relation extraction (e.g., has been unable to achieve sufficient recall or precision for the results to be usable versus hand-constructed knowledge bases.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9291259348392487}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9987351298332214}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9769442677497864}]}, {"text": "Supervised training data has been scarce and, while techniques like distant supervision appear to be a promising way to extend knowledge bases at low cost, in practice the training data has often been too noisy for reliable training of relation extraction systems.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 236, "end_pos": 255, "type": "TASK", "confidence": 0.8358173668384552}]}, {"text": "As a result most systems fail to make correct extractions even in apparently straightforward cases like,", "labels": [], "entities": []}], "datasetContent": [{"text": "Previous research has shown that slot filling systems can greatly benefit from supervised data.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.9487430453300476}]}, {"text": "For example, showed that even a small amount of supervised data can boost the end-to-end F 1 score by 3.9% on the TAC KBP tasks.", "labels": [], "entities": [{"text": "end-to-end F 1 score", "start_pos": 78, "end_pos": 98, "type": "METRIC", "confidence": 0.8412457853555679}, {"text": "TAC KBP tasks", "start_pos": 114, "end_pos": 127, "type": "DATASET", "confidence": 0.7821029225985209}]}, {"text": "However, existing relation extraction datasets such as the SemEval-2010 Task 8 dataset () and the Automatic Content Extraction (ACE) () dataset are less useful for this purpose.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7408839464187622}, {"text": "SemEval-2010 Task 8 dataset", "start_pos": 59, "end_pos": 86, "type": "DATASET", "confidence": 0.6592368483543396}, {"text": "Automatic Content Extraction (ACE)", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.7176177054643631}]}, {"text": "This is mainly because: (1) these datasets are relatively small for effectively training high-capacity models (see), and (2) they capture very different types of relations.", "labels": [], "entities": []}, {"text": "For example, the SemEval dataset focuses on semantic relations (e.g., CauseEffect, Component-Whole) between two nominals.", "labels": [], "entities": [{"text": "SemEval dataset", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.8559227883815765}]}, {"text": "One can further argue that it is easy to obtain a large amount of training data using distant supervision ().", "labels": [], "entities": []}, {"text": "In practice, however, due to the large amount of noise in the induced data, training relation extractors that perform well becomes very difficult.", "labels": [], "entities": [{"text": "training relation extractors", "start_pos": 76, "end_pos": 104, "type": "TASK", "confidence": 0.6600811084111532}]}, {"text": "For example, show that up to 31% of the distantly supervised labels are wrong when creating training data from aligning Freebase to newswire text.", "labels": [], "entities": []}, {"text": "To tackle these challenges, we collect a large supervised dataset TACRED, targeted towards the TAC KBP relations.", "labels": [], "entities": [{"text": "TACRED", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.6346986889839172}, {"text": "TAC KBP relations", "start_pos": 95, "end_pos": 112, "type": "DATASET", "confidence": 0.780097504456838}]}, {"text": "We create TACRED based on query entities and annotated system responses in the yearly TAC KBP evaluations.", "labels": [], "entities": [{"text": "TAC KBP evaluations", "start_pos": 86, "end_pos": 105, "type": "DATASET", "confidence": 0.7232338786125183}]}, {"text": "In each year of the TAC KBP evaluation, 100 entities (people or organizations) are given as queries,  for which participating systems should find associated relations and object entities.", "labels": [], "entities": [{"text": "TAC KBP", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.5658677220344543}]}, {"text": "We make use of Mechanical Turk to annotate each sentence in the source corpus that contains one of these query entities.", "labels": [], "entities": []}, {"text": "For each sentence, we ask crowd workers to annotate both the subject and object entity spans and the relation types.", "labels": [], "entities": []}, {"text": "Due to space constraints, we describe the data collection and validation process, system interfaces, and more statistics and examples of TAC-RED in the supplementary material.", "labels": [], "entities": [{"text": "data collection and validation", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.7322947978973389}]}, {"text": "We will make TACRED publicly available through the LDC.", "labels": [], "entities": [{"text": "LDC", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.8528686761856079}]}, {"text": "In this section we evaluate the effectiveness of our proposed model and TACRED on improving slot filling systems.", "labels": [], "entities": [{"text": "TACRED", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9867159128189087}, {"text": "slot filling", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.897752195596695}]}, {"text": "Specifically, we run two sets of experiments: (1) we evaluate model performance on the relation extraction task using TACRED, and (2) we evaluate model performance on the TAC KBP 2015 cold start slot filling task, by training the models on TACRED.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.8285627166430155}, {"text": "TAC KBP 2015 cold start slot filling task", "start_pos": 171, "end_pos": 212, "type": "TASK", "confidence": 0.8011635839939117}, {"text": "TACRED", "start_pos": 240, "end_pos": 246, "type": "DATASET", "confidence": 0.9216561913490295}]}, {"text": "We first evaluate all models on TACRED.", "labels": [], "entities": [{"text": "TACRED", "start_pos": 32, "end_pos": 38, "type": "DATASET", "confidence": 0.6845242381095886}]}, {"text": "We train each model for 5 separate runs with independent random initializations.", "labels": [], "entities": []}, {"text": "For each run we perform early stopping using the dev set.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.7960229516029358}]}, {"text": "We then select the run (among 5) that achieves the median F 1 score on the dev set, and report its test set performance.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9777763883272806}]}, {"text": "We observe that all neural models achieve higher F 1 scores than the logistic regression and patterns systems, which demonstrates the effectiveness of neural models for relation extraction.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9886508782704672}, {"text": "relation extraction", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.9131224155426025}]}, {"text": "Although positional embeddings help increase the F 1 by around 2% over the plain CNN model, a simple (2-layer) LSTM model performs surprisingly better than CNN and dependency-based models.", "labels": [], "entities": [{"text": "F 1", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9872958958148956}]}, {"text": "Lastly, our proposed position-aware mechanism is very effective and achieves an F 1 score of 65.4%, with an absolute increase of 3.9% over the best baseline neural model (LSTM) and 7.9% over the baseline logistic regression system.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9944000840187073}]}, {"text": "We also run an ensemble of our position-aware attention model which takes majority votes from 5 runs with random initializations and it further pushes the F 1 score up by 1.6%.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9628642797470093}]}, {"text": "We find that different neural architectures show a different balance between precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9992127418518066}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9943422079086304}]}, {"text": "CNN-based models tend to have higher precision; RNN-based models have better recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9993267059326172}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9991042017936707}]}, {"text": "This can be explained by noting that the filters in CNNs are essentially a form of \"fuzzy n-gram patterns\".", "labels": [], "entities": []}, {"text": "Second, we evaluate the slot filling performance of all models using the TAC KBP 2015 cold start slot filling task (.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.889885663986206}, {"text": "TAC KBP 2015", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.8668940862019857}, {"text": "cold start slot filling", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.8521360456943512}]}, {"text": "In this task, about 50k newswire and Web forum documents are selected as the evaluation corpus.", "labels": [], "entities": []}, {"text": "A slot filling system is asked to answer a series of queries with two-hop slots): The first slot asks about fillers of a relation with the query entity as the subject (Mike Penner), and we term this a hop-0 slot; the second slot asks about fillers with the system's hop-0 output as the subject, and we term this a hop-1 slot.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 2, "end_pos": 14, "type": "TASK", "confidence": 0.7585179805755615}]}, {"text": "System predictions are then evaluated against gold annotations, and micro-averaged precision, recall and F 1 scores are calculated at the hop-0 and hop-1 levels.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9506898522377014}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9992338418960571}, {"text": "F 1 scores", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9882423679033915}]}, {"text": "Lastly hop-all scores are calculated by combining hop-0 and hop-1 scores.", "labels": [], "entities": []}, {"text": "Evaluating relation extraction systems on slot filling is particularly challenging in that: (1) Endto-end cold start slot filling scores conflate the performance of all modules in the system (i.e., entity recognizer, entity linker and relation extractor).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7280007898807526}, {"text": "slot filling", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.8521464467048645}, {"text": "slot filling", "start_pos": 117, "end_pos": 129, "type": "TASK", "confidence": 0.6911078095436096}, {"text": "relation extractor", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.7041978091001511}]}, {"text": "(2) Errors in hop-0 predictions can easily propagate to hop-1 predictions.", "labels": [], "entities": [{"text": "Errors", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9858865737915039}]}, {"text": "To fairly evaluate each relation extraction model on this task, we use Stanford's 2015 slot filling system as our basic pipeline.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7890982329845428}, {"text": "slot filling", "start_pos": 87, "end_pos": 99, "type": "TASK", "confidence": 0.6799119710922241}]}, {"text": "3 It is a very strong baseline specifically tuned for TAC KBP evaluation and ranked top in the 2015 evaluation.", "labels": [], "entities": [{"text": "TAC KBP evaluation", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.7381078004837036}]}, {"text": "We then plugin the corresponding relation extractor trained on TACRED, keeping all other modules unchanged.", "labels": [], "entities": [{"text": "relation extractor", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.6992230713367462}, {"text": "TACRED", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.7505433559417725}]}, {"text": "We find that: (1) by only training our logistic regression model on TACRED (in contrast to on the 2 million bootstrapped examples used in the 2015 Stanford system) and combining it with patterns, we obtain a higher hop-0 F 1 score than the 2015 Stanford sys-: An ablation test of our position-aware attention model, evaluated on TACRED dev set.", "labels": [], "entities": [{"text": "hop-0 F 1 score", "start_pos": 215, "end_pos": 230, "type": "METRIC", "confidence": 0.7619111761450768}, {"text": "TACRED dev set", "start_pos": 329, "end_pos": 343, "type": "DATASET", "confidence": 0.8986344734827677}]}, {"text": "Scores are median of 5 models.", "labels": [], "entities": []}, {"text": "tem, and a similar hop-all F 1 ; (2) our proposed position-aware attention model substantially outperforms the 2015 Stanford system on all hop-0, hop-1 and hop-all F 1 scores.", "labels": [], "entities": [{"text": "tem", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8283442258834839}]}, {"text": "Combining it with the patterns, we achieve a hop-all F 1 of 26.7%, an absolute improvement of 4.5% over the previous state-of-the-art result.", "labels": [], "entities": [{"text": "hop-all F 1", "start_pos": 45, "end_pos": 56, "type": "METRIC", "confidence": 0.9298673868179321}]}], "tableCaptions": [{"text": " Table 2: A comparison of existing datasets and our  proposed TACRED dataset. % Neg. denotes the  percentage of negative examples (no relation).", "labels": [], "entities": [{"text": "TACRED dataset", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.912555605173111}]}, {"text": " Table 3: Statistics on TACRED: number of exam- ples and the source of each portion.", "labels": [], "entities": [{"text": "TACRED", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.8556806445121765}]}, {"text": " Table 4: Model performance on the test set of  TACRED, micro-averaged over instances. LR =  Logistic Regression.", "labels": [], "entities": [{"text": "TACRED", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.5894293189048767}, {"text": "LR", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.9775958061218262}]}, {"text": " Table 5: Model performance on TAC KBP 2015 slot filling evaluation, micro-averaged over queries.  Hop-0 scores are calculated on the simple single-hop slot filling results; hop-1 scores are calculated  on slot filling results chained on systems' hop-0 predictions; hop-all scores are calculated based on the  combination of the two. LR = logistic regression.", "labels": [], "entities": [{"text": "TAC KBP 2015 slot filling evaluation", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.8040037751197815}, {"text": "LR", "start_pos": 334, "end_pos": 336, "type": "METRIC", "confidence": 0.9876790642738342}]}, {"text": " Table 6: An ablation test of our position-aware  attention model, evaluated on TACRED dev set.  Scores are median of 5 models.", "labels": [], "entities": [{"text": "TACRED dev set", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.7885017991065979}]}]}