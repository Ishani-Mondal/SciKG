{"title": [{"text": "End-to-End Neural Relation Extraction with Global Optimization", "labels": [], "entities": [{"text": "Neural Relation Extraction", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.8062561551729838}]}], "abstractContent": [{"text": "Neural networks have shown promising results for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9341574013233185}]}, {"text": "State-of-the-art models cast the task as an end-to-end problem, solved incrementally using a local classifier.", "labels": [], "entities": []}, {"text": "Yet previous work using statistical models have demonstrated that global optimization can achieve better performances compared to local classification.", "labels": [], "entities": [{"text": "global optimization", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7822637856006622}]}, {"text": "We build a globally optimized neural model for end-to-end relation extraction, proposing novel LSTM features in order to better learn context representations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.708883672952652}]}, {"text": "In addition, we present a novel method to integrate syntactic information to facilitate global learning, yet requiring little background on syntactic grammars thus being easy to extend.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed model is highly effective , achieving the best performances on two standard benchmarks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extracting entities and relations () from unstructured texts have been two central tasks in information extraction).", "labels": [], "entities": [{"text": "Extracting entities and relations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.847417876124382}, {"text": "information extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7905580103397369}]}, {"text": "Traditional approaches to relation extraction take entity recognition as a predecessor step in a pipeline (, predicting relations between given entities.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8883263468742371}, {"text": "entity recognition", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7286118566989899}]}, {"text": "In recent years, there has been a surge of interest in performing end-to-end relation extraction, jointly recognizing entities and relations given free text inputs (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7404764145612717}]}, {"text": "End-to-end learning prevents error propagation in the pipeline approach, and allows cross-task dependencies to be modeled explicitly for entity recognition.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7449344992637634}]}, {"text": "As a result, it gives better relation extraction accuracies compared to pipelines. were among the first to use neural networks for end-to-end relation extraction, showing highly promising results.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.831170529127121}, {"text": "relation extraction", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7069104164838791}]}, {"text": "In particular, they used bidirectional LSTM () to learn hidden word representations under a sentential context, and further leveraged treestructured LSTM to encode syntactic information, given the output of a parser.", "labels": [], "entities": []}, {"text": "The resulting representations are then used for making local decisions for entity and relation extraction incrementally, leading to much improved results compared with the best statistical model (.", "labels": [], "entities": [{"text": "entity and relation extraction", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.6224050968885422}]}, {"text": "This demonstrates the strength of neural representation learning for end-to-end relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7018061876296997}]}, {"text": "On the other hand,'s model is trained locally, without considering structural correspondences between incremental decisions.", "labels": [], "entities": []}, {"text": "This is unlike existing statistical methods, which utilize well-studied structured prediction methods to address the problem ().", "labels": [], "entities": []}, {"text": "As has been commonly understood, learning local decisions for structured prediction can lead to label bias (), which prevents globally optimal structures from receiving optimal scores by the model.", "labels": [], "entities": []}, {"text": "We address this potential issue by building a structural neural model for end-to-end relation extraction, following a recent line of efforts on globally optimized models for neural structured prediction (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7212327271699905}, {"text": "neural structured prediction", "start_pos": 174, "end_pos": 202, "type": "TASK", "confidence": 0.8280073404312134}]}, {"text": "In particular, we follow, casting the task as an end-to-end tablefilling problem.", "labels": [], "entities": []}, {"text": "This is different from the actionbased method of, yet has shown to be more flexible and accurate.", "labels": [], "entities": []}, {"text": "We take a different approach to representation learning, addressing two potential limitations of.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.9673250317573547}]}, {"text": "First, rely on external syntactic parsers for obtaining syntactic information, which is crucial for relation extraction (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.8703939914703369}]}, {"text": "However, parsing errors can lead to encoding inaccuracies of tree-LSTMs, thereby hurting relation extraction potentially.", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9602683782577515}, {"text": "relation extraction", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.876100480556488}]}, {"text": "We take an alternative approach to integrating syntactic information, by taking the hidden LSTM layers of a bi-affine attention parser to augment input representations.", "labels": [], "entities": []}, {"text": "Pretrained for parsing, such hidden layers contain rich syntactic information on each word, yet do not explicitly represent parsing decisions, thereby avoiding potential issues caused by incorrect parses.", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9784212112426758}]}, {"text": "Our method is also free from a particular syntactic formalism, such as dependency grammar, constituent grammar or combinatory categorial grammar, requiring only hidden representations on word that contain syntactic information.", "labels": [], "entities": []}, {"text": "In contrast, the method of Miwa and Bansal (2016) must consider tree LSTM formulations that are specific to grammar formalisms, which can be structurally different).", "labels": [], "entities": []}, {"text": "Second, Miwa and Bansal (2016) did not explicitly learn the representation of segments when predicting entity boundaries or making relation classification decisions, which can be intuitively highly useful, and has been investigated in several studies (.", "labels": [], "entities": [{"text": "predicting entity boundaries or making relation classification", "start_pos": 92, "end_pos": 154, "type": "TASK", "confidence": 0.6408900959151131}]}, {"text": "We take the LSTM-Minus method of, modelling a segment as the difference between its last and first LSTM hidden vectors.", "labels": [], "entities": []}, {"text": "This method is highly efficient, yet gives as accurate results as compared to more complex neural network structures to model a span of words.", "labels": [], "entities": []}, {"text": "Evaluation on two benchmark datasets shows that our method outperforms previous methods of, and, giving the best reported results on both benchmarks.", "labels": [], "entities": []}, {"text": "Detailed analysis shows that our integration of syntactic features is as effective as traditional approaches based on discrete parser outputs.", "labels": [], "entities": []}, {"text": "We make our code publicly ORG-AFF PHYS: Relation extraction.", "labels": [], "entities": [{"text": "ORG-AFF PHYS", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.7687069773674011}, {"text": "Relation extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8117038905620575}]}, {"text": "The example is chosen from the ACE05 dataset, where ORG, PER and GPE denote organization, person and geo-political entities, respectively; ORG-AFF and PHYS denote organization affiliation and physical relations, respectively.", "labels": [], "entities": [{"text": "ACE05 dataset", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9882416725158691}, {"text": "ORG", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9876711368560791}, {"text": "PER", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.859234094619751}, {"text": "GPE", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.7134396433830261}, {"text": "ORG-AFF", "start_pos": 139, "end_pos": 146, "type": "METRIC", "confidence": 0.8952752947807312}]}, {"text": "available under Apache License 2.0. 1", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the proposed model on two datasets, namely the ACE05 data and the corpus of Roth and Yih (2004) (CONLL04), respectively.", "labels": [], "entities": [{"text": "ACE05 data and the corpus of Roth and Yih (2004) (CONLL04)", "start_pos": 59, "end_pos": 117, "type": "DATASET", "confidence": 0.7837553143501281}]}, {"text": "The ACE05 dataset defines seven coarse-grained entity types and six coarse-grained relation categories, while the CONLL04 dataset defines four entity types and five relation categories.", "labels": [], "entities": [{"text": "ACE05 dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9839602708816528}, {"text": "CONLL04 dataset", "start_pos": 114, "end_pos": 129, "type": "DATASET", "confidence": 0.9828372597694397}]}, {"text": "For the ACE05 dataset, we follow and, splitting and preprocessing the dataset into training, development and test sets.", "labels": [], "entities": [{"text": "ACE05 dataset", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.9844341576099396}]}, {"text": "For the CONLL04 dataset, we follow to split the data into training and test corpora, and then divide 10% of the training corpus for development.", "labels": [], "entities": [{"text": "CONLL04 dataset", "start_pos": 8, "end_pos": 23, "type": "DATASET", "confidence": 0.976684182882309}]}, {"text": "We use the micro F1-measure as the major metric to evaluate model performances, treating an entity as correct when its head region and type are both correct, and regard a relation as correct when the argument entities and the relation category are all correct.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.8789985179901123}]}, {"text": "We exploit pairwise t-test for measuring significance values.: Feature ablation tests.", "labels": [], "entities": []}, {"text": "We conduct several development experiments on the ACE05 development dataset.", "labels": [], "entities": [{"text": "ACE05 development dataset", "start_pos": 50, "end_pos": 75, "type": "DATASET", "confidence": 0.9553027351697286}]}], "tableCaptions": [{"text": " Table 3: Feature ablation tests.", "labels": [], "entities": []}, {"text": " Table 2. All the hyper-parameters are tuned by  development experiments. All experiments are  conducted using gcc version 4.9.4 (Ubuntu 4.9.4- 2ubuntu1 14.04.1), on an Intel(R) Xeon(R) CPU  E5-2670 @ 2.60GHz.", "labels": [], "entities": []}, {"text": " Table 4: Comparisons between local and global  models, where SS denotes scheduled sampling,  and speed is measured by the number of sentences  per second.", "labels": [], "entities": [{"text": "speed", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.9897569417953491}]}, {"text": " Table 5: The influence of syntactic features.", "labels": [], "entities": []}, {"text": " Table 6: Final results on the test datasets.", "labels": [], "entities": []}]}