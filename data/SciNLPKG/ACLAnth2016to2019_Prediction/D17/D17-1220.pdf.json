{"title": [{"text": "Break it Down for Me: A Study in Automated Lyric Annotation", "labels": [], "entities": []}], "abstractContent": [{"text": "Comprehending lyrics, as found in songs and poems, can pose a challenge to human and machine readers alike.", "labels": [], "entities": []}, {"text": "This motivates the need for systems that can understand the ambiguity and jargon found in such creative texts, and provide commentary to aid readers in reaching the correct interpretation.", "labels": [], "entities": []}, {"text": "We introduce the task of automated lyric annotation (ALA).", "labels": [], "entities": [{"text": "automated lyric annotation (ALA)", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.7558185905218124}]}, {"text": "Like text simplification , a goal of ALA is to rephrase the original text in a more easily understandable manner.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.7715775668621063}, {"text": "ALA", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9503490924835205}]}, {"text": "However, in ALA the system must often include additional information to clarify niche terminology and abstract concepts.", "labels": [], "entities": []}, {"text": "To stimulate research on this task, we release a large collection of crowdsourced annotations for song lyrics.", "labels": [], "entities": []}, {"text": "We analyze the performance of translation and retrieval models on this task, measuring performance with both automated and human evaluation.", "labels": [], "entities": [{"text": "translation and retrieval", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.8657486836115519}]}, {"text": "We find that each model captures a unique type of information important to the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Song lyrics and poetry often make use of ambiguity, symbolism, irony, and other stylistic elements to evoke emotive responses.", "labels": [], "entities": []}, {"text": "These characteristics sometimes make it challenging to interpret obscure lyrics, especially for readers or listeners who are unfamiliar with the genre.", "labels": [], "entities": []}, {"text": "To address this problem, several online lyric databases have been created where users can explain, contextualize, or discuss lyrics.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collect a dataset of crowdsourced annotations, generated by users of the Genius online lyric database.", "labels": [], "entities": [{"text": "Genius online lyric database", "start_pos": 76, "end_pos": 104, "type": "DATASET", "confidence": 0.7434387058019638}]}, {"text": "For a given song, users can navigate to a particular stanza or line, view existing annotations for the target lyric, or provide their own annotation.", "labels": [], "entities": []}, {"text": "Discussion between users acts to improve annotation quality, as it does with other collaborative online databases like Wikipedia.", "labels": [], "entities": []}, {"text": "This process is gamified: users earn IQ points for producing high quality annotations.", "labels": [], "entities": [{"text": "IQ", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.8561245799064636}]}, {"text": "We collect 736,423 lyrics having a total 1,404,107 lyric annotation pairs from all subsections (rap, poetry, news, etc.) of Genius.", "labels": [], "entities": []}, {"text": "We limit the initial release of the annotation data to be English-only, and filter out non-English annotations using a pre-trained language identifier.", "labels": [], "entities": []}, {"text": "We also remove annotations which are solely links to external resources, and do not provide useful textual annotations.", "labels": [], "entities": []}, {"text": "This reduces the dataset to 803,720 lyric annotation pairs.", "labels": [], "entities": []}, {"text": "We list several properties of the collected dataset in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Properties of gathered dataset (V lyrics and  V annot denote the vocabulary for lyrics and annota- tions, denotes the average amount).", "labels": [], "entities": []}, {"text": " Table 3: Lyrics excerpts with annotations from Genius ('Human') and automated annotators.", "labels": [], "entities": []}, {"text": " Table 4: Quantitative evaluation of different automated annotators.", "labels": [], "entities": []}]}