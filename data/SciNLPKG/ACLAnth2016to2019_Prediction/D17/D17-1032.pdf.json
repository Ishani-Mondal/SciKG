{"title": [{"text": "VecShare: A Framework for Sharing Word Representation Vectors", "labels": [], "entities": [{"text": "Sharing Word Representation Vectors", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.8681074678897858}]}], "abstractContent": [{"text": "Many Natural Language Processing (NLP) models rely on distributed vector representations of words.", "labels": [], "entities": []}, {"text": "Because the process of training word vectors can require large amounts of data and computation , NLP researchers and practitioners often utilize pre-trained embeddings downloaded from the Web.", "labels": [], "entities": []}, {"text": "However, finding the best embeddings fora given task is difficult, and can be computation-ally prohibitive.", "labels": [], "entities": []}, {"text": "We present a framework, called VecShare, that makes it easy to share and retrieve word embeddings on the Web.", "labels": [], "entities": []}, {"text": "The framework leverages a public data-sharing infrastructure to host embedding sets, and provides automated mechanisms for retrieving the embed-dings most similar to a given corpus.", "labels": [], "entities": []}, {"text": "We perform an experimental evaluation of VecShare's similarity strategies, and show that they are effective at efficiently retrieving embeddings that boost accuracy in a document classification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9965419173240662}, {"text": "document classification task", "start_pos": 170, "end_pos": 198, "type": "TASK", "confidence": 0.7872349123160044}]}, {"text": "Finally, we provide an open-source Python library for using the VecShare framework.", "labels": [], "entities": [{"text": "VecShare framework", "start_pos": 64, "end_pos": 82, "type": "DATASET", "confidence": 0.8906169235706329}]}], "introductionContent": [{"text": "Word embeddings capture syntactic and semantic properties of words, and area key component of many modern NLP models (.", "labels": [], "entities": []}, {"text": "However, high-quality embeddings can be expensive to train.", "labels": [], "entities": []}, {"text": "As a result, rather than training their own embeddings, NLP researchers and practitioners often download pre-trained embeddings from the Web, e.g. ().", "labels": [], "entities": []}, {"text": "1 https://github.com/JaredFern/VecShare However, existing methods for sharing embeddings on the Web are suboptimal.", "labels": [], "entities": []}, {"text": "Current practice primarily consists of contributors posting embedding sets to their own Web sites.", "labels": [], "entities": []}, {"text": "No central embedding repository exists, and it is difficult for users to know which embedding sets are available.", "labels": [], "entities": []}, {"text": "Furthermore, determining the utility of an embedding set fora particular NLP task entails significant time and computational costs, as users must manually download and evaluate multiple complete embedding sets.", "labels": [], "entities": []}, {"text": "Methods exist for automatically scoring an embedding set, but these are limited to specific tasks and lack integration with existing code bases.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to introduce a framework that makes sharing word embeddings easier for NLP researchers and practitioners.", "labels": [], "entities": []}, {"text": "It should be simple and fast to post, browse, and retrieve embeddings from a public data store.", "labels": [], "entities": []}, {"text": "Additionally, integration with existing NLP codebases should be more seamless: software libraries should automatically identify and download the particular embeddings that are likely to be relevant to a user's corpus.", "labels": [], "entities": []}, {"text": "This paper presents VecShare, a framework for sharing word embeddings.", "labels": [], "entities": []}, {"text": "As its data store, it uses an existing public data-sharing platform, which provides searching and browsing capability.", "labels": [], "entities": []}, {"text": "To solve the critical challenge of helping users quickly find relevant embeddings, we introduce embedding indexers.", "labels": [], "entities": []}, {"text": "The indexers compute and share compact representations, called signatures, for each embedding set.", "labels": [], "entities": []}, {"text": "Users employ a software library that downloads the signatures and compares them against the user's corpus.", "labels": [], "entities": []}, {"text": "Using the signatures, the library efficiently evaluates the utility of each shared embedding set and determines which sets are most likely to be relevant.", "labels": [], "entities": []}, {"text": "The library can then automatically download the relevant embeddings and make them available within the user's code.", "labels": [], "entities": []}, {"text": "Finally, VecShare is an open source framework: new embeddings, indexers, and signature methods can be independently added at anytime.", "labels": [], "entities": [{"text": "VecShare", "start_pos": 9, "end_pos": 17, "type": "DATASET", "confidence": 0.8627924919128418}]}, {"text": "We perform experiments evaluating different signature methods in selecting embeddings for document classification tasks, and demonstrate that an ensemble signature based on simple features (e.g. vocabulary overlap with the user's corpus, or similarities between a sample of embedding pairs) can select helpful embeddings.", "labels": [], "entities": [{"text": "document classification tasks", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.7860167026519775}]}, {"text": "We release a Python library for NLP researchers and practitioners that can query the embedding library, and automatically select and download relevant embeddings fora given corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now evaluate the effectiveness of the signature methods described in the previous section at identifying high-quality embedding sets fora given corpus, for the task of text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.8236015141010284}]}, {"text": "We also quantify the improvement in efficiency when using VecShare rather than following the current practice of downloading and testing multiple embedding sets.", "labels": [], "entities": [{"text": "VecShare", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9033900499343872}]}, {"text": "In our experiments, we set the parameters T v = 5, 000 and T s = 1, 000, and we discard the top 100 most frequent words as stopwords.", "labels": [], "entities": []}, {"text": "When training embeddings on the user's corpus, we use word2vec.", "labels": [], "entities": []}, {"text": "We perform experiments in two settings: first with large-corpus embeddings, where we use word2vec and GloVe embedding sets trained on billions of tokens.", "labels": [], "entities": []}, {"text": "The large-corpus embeddings are representative of state-of-the-art models, but are trained over very broad-topic corpora (billions of tokens of newswire, Web or social media text).", "labels": [], "entities": []}, {"text": "To better measure whether VecShare can harness more specific, targeted embedding sets, we also evaluate over small-corpus embeddings.", "labels": [], "entities": []}, {"text": "For the large-corpus embeddings, we utilize three sets of GloVe embeddings): wik+, 100-dimensional embeddings trained on six billion tokens of Wikipedia and the Gigaword corpus; web, 300-dimensional embeddings trained on 42 billion tokens of the Common Crawl Web dataset; and twtr, 100-dimensional embeddings trained on 27 billion tokens of Twitter posts.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 161, "end_pos": 176, "type": "DATASET", "confidence": 0.8330979645252228}, {"text": "Common Crawl Web dataset", "start_pos": 246, "end_pos": 270, "type": "DATASET", "confidence": 0.7600251138210297}]}, {"text": "We also utilize gnws, 300-dimensional word2vec embeddings trained on three billion tokens of Google News data.", "labels": [], "entities": [{"text": "Google News data", "start_pos": 93, "end_pos": 109, "type": "DATASET", "confidence": 0.8097525636355082}]}, {"text": "For the small corpus embeddings, we created a topically diverse collection of subsets of the New York Times corpus, across seven categories (agriculture, arts, books, economics, government, movies, and weather).", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 93, "end_pos": 114, "type": "DATASET", "confidence": 0.8950102031230927}]}, {"text": "We then trained word2vec embeddings on each subset, to create seven distinct similarly-sized, small corpus embedding sets.", "labels": [], "entities": []}, {"text": "For our experiments, we utilize the embeddings as features for document classification within a convolutional neural network.", "labels": [], "entities": [{"text": "document classification", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.7473011314868927}]}, {"text": "We evaluate on four document classification tasks: Reuters-21578 newswire topic classification (, subjectivity classification (), IMDB movie review classification (, and the 20news classification task.: Experimental results using large-corpus embeddings.", "labels": [], "entities": [{"text": "document classification", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7126934230327606}, {"text": "Reuters-21578 newswire topic classification", "start_pos": 51, "end_pos": 94, "type": "TASK", "confidence": 0.8882921934127808}, {"text": "subjectivity classification", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.703079029917717}, {"text": "IMDB movie review classification", "start_pos": 130, "end_pos": 162, "type": "TASK", "confidence": 0.7136632353067398}]}, {"text": "All of the signature methods outperform the random baseline, and the All method performs best in terms of both correlation \u03c1 and text classification accuracy.: Experimental results using small-corpus embeddings.", "labels": [], "entities": [{"text": "correlation \u03c1", "start_pos": 111, "end_pos": 124, "type": "METRIC", "confidence": 0.9612484872341156}, {"text": "text classification", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.7268669307231903}, {"text": "accuracy.", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.857784628868103}]}, {"text": "The VocabRk and SimCorr methods outperform the baselines, and the All method performs best in terms of both correlation \u03c1 and text classification accuracy.", "labels": [], "entities": [{"text": "VocabRk", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.8764887452125549}, {"text": "correlation \u03c1", "start_pos": 108, "end_pos": 121, "type": "METRIC", "confidence": 0.9385117888450623}, {"text": "text classification", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.704107329249382}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.8886966705322266}]}, {"text": "We also evaluated the relative gain in time and space efficiency that VecShare provides over the current practice of manually evaluating each embedding set and selecting the embedding that performs best.", "labels": [], "entities": [{"text": "VecShare", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.8462488651275635}]}, {"text": "The efficiency experiment was performed on a single machine with a 2.3 GHz quadcore CPU and 8GB of main memory, using a test framework containing 11 embedding sets.", "labels": [], "entities": []}, {"text": "Embedding selection was performed using both the VocabRk signature method on VecShare and the conventional method of selecting embeddings, which trains models for each embedding set and then evaluates those models on the test corpus.", "labels": [], "entities": [{"text": "Embedding selection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9252743124961853}, {"text": "VecShare", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.9529488682746887}]}, {"text": "The conventional approach required an average of 177 minutes to train, evaluate, and select an embedding set for each test corpus.", "labels": [], "entities": []}, {"text": "Whereas, the VocabRk signature method on the VecShare framework required an average of 38 seconds to select an embedding for each test corpus, an average speedup of 280x.", "labels": [], "entities": [{"text": "VecShare framework", "start_pos": 45, "end_pos": 63, "type": "DATASET", "confidence": 0.9199356436729431}]}, {"text": "Additionally, VecShare substantially reduces space cost: the total size of the signatures in the experiments is 4-5 orders of magnitude smaller than the full embedding sets.", "labels": [], "entities": [{"text": "VecShare", "start_pos": 14, "end_pos": 22, "type": "DATASET", "confidence": 0.7535998821258545}]}], "tableCaptions": [{"text": " Table 1: Experimental results using large-corpus embeddings. All of the signature methods outperform  the random baseline, and the All method performs best in terms of both correlation \u03c1 and text classifica- tion accuracy.", "labels": [], "entities": [{"text": "correlation \u03c1", "start_pos": 174, "end_pos": 187, "type": "METRIC", "confidence": 0.9433518648147583}, {"text": "text classifica- tion accuracy", "start_pos": 192, "end_pos": 222, "type": "METRIC", "confidence": 0.4616275131702423}]}, {"text": " Table 2: Experimental results using small-corpus embeddings. The VocabRk and SimCorr methods  outperform the baselines, and the All method performs best in terms of both correlation \u03c1 and text clas- sification accuracy.", "labels": [], "entities": [{"text": "VocabRk", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.8704019784927368}, {"text": "correlation \u03c1", "start_pos": 171, "end_pos": 184, "type": "METRIC", "confidence": 0.9238300323486328}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.6632780432701111}]}]}