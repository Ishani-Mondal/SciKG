{"title": [{"text": "The Labeled Segmentation of Printed Books", "labels": [], "entities": [{"text": "Labeled Segmentation of Printed Books", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.7739088058471679}]}], "abstractContent": [{"text": "We introduce the task of book structure labeling: segmenting and assigning a fixed category (such as TABLE OF CONTENTS, PREFACE, INDEX) to the document structure of printed books.", "labels": [], "entities": [{"text": "book structure labeling", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.685174802939097}, {"text": "TABLE", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.8746392130851746}, {"text": "INDEX", "start_pos": 129, "end_pos": 134, "type": "METRIC", "confidence": 0.8332779407501221}]}, {"text": "We manually annotate the page-level structural categories fora large dataset totaling 294,816 pages in 1,055 books evenly sampled from 1750-1922, and present empirical results comparing the performance of several classes of models.", "labels": [], "entities": []}, {"text": "The best-performing model, a bidirectional LSTM with rich features, achieves an overall accuracy of 95.8 and a class-balanced macro F-score of 71.4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9995585083961487}, {"text": "F-score", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.9103474617004395}]}], "introductionContent": [{"text": "The availability of large-scale book corpora (such as those created by Google Books, the Internet Archive and the HathiTrust) has driven a flurry of work in cultural analytics over the past decade, in which the text contained in historical books has provided the raw material for the analysis of genre, literary character (), geographic attention, fame (, and much more.", "labels": [], "entities": []}, {"text": "Books, however, are not undifferentiated streams of text in the same way that born-digital documents like tweets or emails are; they are physical objects with materiality and are arranged in a complex structure steeped in along design tradition, with the core content of the work placed between structured frontmatter (such as a table of contents and introduction) and backmatter (such as an appendix and index).", "labels": [], "entities": []}, {"text": "Not all of this content is desirable for all analyses; as we show below, 11% of all pages in books belong to the peritext that surrounds the core content, with wide variability from book to book.", "labels": [], "entities": []}, {"text": "For other analyses, such as those addressing questions in book history, isolating this structure in a consistent way across historical documents can enable research into how the form of the printed book has, for example, changed overtime.", "labels": [], "entities": []}, {"text": "While other work has focused on extracting the idiosyncratic structure inherent in each book, such as recognizing chapter boundaries in order to automatically generate a table of contents, or link a parsed table of contents to positions in a book, labeling document segments with a fixed typology has complementary benefits, allowing researchers to identify consistent categories in all books regardless of the names assigned by a specific author or publisher, or popular at a given time.", "labels": [], "entities": []}, {"text": "At the same time, book structure labeling presents real challenges to automatic identification.", "labels": [], "entities": [{"text": "book structure labeling", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.6041550437609354}, {"text": "automatic identification", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6351875215768814}]}, {"text": "While large-scale digital collections originate in page scans of the books, the most common form of access by researchers is through the output of OCR; raw image files are prohibitively expensive both in terms of disk space (15.1 million books from the HathiTrust consumes 677 ter-  abytes of space 2 ) and in the resources required for computational processing.", "labels": [], "entities": []}, {"text": "While people are able to distinguish the different sections of a book with ease, the degraded nature of the OCR output (especially for historical books) blurs the clear markers that signal the category to human readersboth in terms of the lexical signals like \"Preface\" or \"Index\" that head a page, and its visual structure as well.", "labels": [], "entities": []}, {"text": "illustrates an example of three pages from a single book drawn from the HathiTrust; displays the corresponding OCR output; the degradation introduced by OCR affects not only the accuracy of character and word identification, but also the structural layout as well.", "labels": [], "entities": [{"text": "HathiTrust", "start_pos": 72, "end_pos": 82, "type": "DATASET", "confidence": 0.9391704201698303}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9973583817481995}, {"text": "word identification", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.6448082625865936}]}, {"text": "To address these limitations and enable research that depends on reasoning over fine-grained document structure within books, we introduce the task of labeled segmentation, and make the following contributions: \u2022 We create an human-annotated gold standard of 294,816 pages in 1,055 printed books drawn from the HathiTrust Digital Library.", "labels": [], "entities": [{"text": "labeled segmentation", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.6947671324014664}, {"text": "HathiTrust Digital Library", "start_pos": 311, "end_pos": 337, "type": "DATASET", "confidence": 0.9540911316871643}]}, {"text": "\u2022 We approach this problem in the most common resource-deficient scenario researchers most frequently encounter: with access only to the pre-existing output of OCR.", "labels": [], "entities": []}, {"text": "\u2022 We compare several different classes of models, including a fast independent predictor (a random forest), a simple linear sequence labeling model (CRF), and a sequence labeling bidirectional LSTM that can capture non-linearities in the feature space.", "labels": [], "entities": []}, {"text": "All data and pre-trained models are openly available to the public at https://github.com/ dbamman/book-segmentation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare the performance of the three models described above at the task of page-level labeling: both the multiclass classification problem of predicting which of the 10 labels applies to each page, and the binary task of {TEXT, NON-TEXT} prediction, in which the nine front-and backmatter labels are collapsed into the single label NON-TEXT; while the former allows access to fine-grained categories of (e.g.) indices and tables of contents, the latter covers the common scenario where researchers are interested only in isolating where the core text begins and ends.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.6646079868078232}, {"text": "NON-TEXT} prediction", "start_pos": 231, "end_pos": 251, "type": "TASK", "confidence": 0.47739405433336896}]}, {"text": "Experimentally, we divide the full training data into two partitions: a training-only partition of 400 books, on which we experiment with feature and model development, and a test partition of the remaining 655 books.", "labels": [], "entities": []}, {"text": "All results presented below are the result of tenfold cross-validation on the test partition.", "labels": [], "entities": []}, {"text": "Each fold trains on 10 of the test data, uses 10 of the 655 books as development for model selection (e.g., to optimize the 2 regularization parameter for the CRF, terminate training for the BiLSTM, and optimize the depth of the random forest), and uses 1 10 of the 655 for test.", "labels": [], "entities": []}, {"text": "We supplement each training fold with the 400 books from the training-only partition, but this data is never used for evaluation below.", "labels": [], "entities": []}, {"text": "In total, we evaluate the performance on 655 books and calculate 95% confidence intervals for each metric using the non-parametric bootstrap, drawing B = 10, 000 resamples of books (not individual pages) in order to account for the statistical dependence between page-level predictions.", "labels": [], "entities": []}, {"text": "presents the results for full multiclass segment labeling.", "labels": [], "entities": [{"text": "multiclass segment labeling", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.6369262337684631}]}, {"text": "To contextualize these results, we also provide a simple baseline of predicting the majority class (TEXT) for all pages; since most pages in a book are core content, this yields a high absolute accuracy against which to compare, but a low macro precision/recall/F score (which evenly weights the importance of each class).", "labels": [], "entities": [{"text": "predicting the majority class (TEXT)", "start_pos": 69, "end_pos": 105, "type": "METRIC", "confidence": 0.6437419482639858}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.8564439415931702}, {"text": "precision", "start_pos": 245, "end_pos": 254, "type": "METRIC", "confidence": 0.9272363185882568}, {"text": "recall", "start_pos": 255, "end_pos": 261, "type": "METRIC", "confidence": 0.799588143825531}, {"text": "F score", "start_pos": 262, "end_pos": 269, "type": "METRIC", "confidence": 0.868040919303894}]}], "tableCaptions": [{"text": " Table 1: Full segment labeling, along with 95% bootstrap confidence intervals.", "labels": [], "entities": [{"text": "segment labeling", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.4544796943664551}, {"text": "bootstrap confidence intervals", "start_pos": 48, "end_pos": 78, "type": "METRIC", "confidence": 0.8290026982625326}]}, {"text": " Table 2: Individual category results, BiLSTM.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.7206880450248718}]}, {"text": " Table 3: Content/non-content labeling, along with 95% bootstrap confidence intervals.", "labels": [], "entities": [{"text": "Content/non-content labeling", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.5784354731440544}, {"text": "bootstrap confidence intervals", "start_pos": 55, "end_pos": 85, "type": "METRIC", "confidence": 0.9022519191106161}]}, {"text": " Table 4: Feature ablation results for the BiLSTM  model, illustrating the change in macro F-score  that results by removing a given feature class from  the full model.", "labels": [], "entities": [{"text": "F-score", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.8441329002380371}]}]}