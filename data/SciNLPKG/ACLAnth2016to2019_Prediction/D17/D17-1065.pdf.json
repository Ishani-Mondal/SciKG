{"title": [{"text": "Neural Response Generation via GAN with an Approximate Embedding Layer *", "labels": [], "entities": [{"text": "Neural Response Generation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8997480471928915}, {"text": "Approximate", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9741111397743225}]}], "abstractContent": [{"text": "This paper presents a Generative Adver-sarial Network (GAN) to model single-turn short-text conversations, which trains a sequence-to-sequence (Seq2Seq) network for response generation simultaneously with a discriminative classifier that measures the differences between human-produced responses and machine-generated ones.", "labels": [], "entities": [{"text": "response generation", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.7169869840145111}]}, {"text": "In addition, the proposed method introduces an approximate embedding layer to solve the non-differentiable problem caused by the sampling-based output decoding procedure in the Seq2Seq generative model.", "labels": [], "entities": []}, {"text": "The GAN setup provides an effective way to avoid non-informative responses (a.k.a \"safe re-sponses\"), which are frequently observed in traditional neural response generators.", "labels": [], "entities": []}, {"text": "The experimental results show that the proposed approach significantly outper-forms existing neural response generation models in diversity metrics, with slight increases in relevance scores as well, when evaluated on both a Mandarin corpus and an English corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "After achieving remarkable successes in Machine Translation (), neural networks with the encoder-decoder architectures (a.k.a sequence-to-sequence models, Seq2Seq) have been proven to be a functioning method to model short-text conversations), where the corresponding task is often called Neural Response Generation.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8564235270023346}, {"text": "Neural Response Generation", "start_pos": 289, "end_pos": 315, "type": "TASK", "confidence": 0.8200579086939493}]}, {"text": "The advantage of applying * The work was done when the first author was an intern at Tricorn (Beijing) Technology Co., Ltd.", "labels": [], "entities": [{"text": "Tricorn (Beijing) Technology Co., Ltd", "start_pos": 85, "end_pos": 122, "type": "DATASET", "confidence": 0.9186192899942398}]}, {"text": "Seq2Seq models to conversation generation is that the training procedure can be performed end-to-end in an unsupervised manner, based on human-generated conversational utterances (typically query-response pairs mined from social networks).", "labels": [], "entities": [{"text": "conversation generation", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.8339629769325256}]}, {"text": "One of the potential applications of such neural response generators is to improve the capability of existing conversational interfaces (informally also known as chatbots) by enabling them to go beyond predefined tasks and chat with human users in an open domain.", "labels": [], "entities": []}, {"text": "However, previous research has indicated that na\u00a8\u0131vena\u00a8\u0131ve implementations of Seq2Seq based conversation models tend to suffer from the so-called \"safe response\" problem (), i.e. such models tend to generate non-informative responses that can be associated to most queries, e.g. \"I don't know\", \"I think so\", etc.", "labels": [], "entities": []}, {"text": "This is due to the fundamental nature of statistical models, which fit sufficiently observed examples better than insufficiently observed ones.", "labels": [], "entities": []}, {"text": "Concretely, the space of open-domain conversations is so large that in any sub-sample of it (i.e. a training set), the distribution of most pieces of information are relatively much sparser when compared to safe response patterns.", "labels": [], "entities": []}, {"text": "Furthermore, since a safe response can be of relevance to a large amount of diverse queries, a statistical learner will tend to minimize its empirical risk in the response generation process by capturing those safe responses if na\u00a8\u0131vena\u00a8\u0131ve relevance-oriented loss metrics are employed.", "labels": [], "entities": [{"text": "response generation", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.7135989665985107}]}, {"text": "Frequent occurrences of safe responses can dramatically reduce the attractiveness of a chat agent, which therefore should be avoided to the best extent possible when designing the learning algorithms.", "labels": [], "entities": []}, {"text": "The pathway to achieve this purpose is to seek a more expressive model with better capacity that can take relevance and diversity (or informativeness) into account simultaneously when modelling the underlying distribution of human conversations.", "labels": [], "entities": []}, {"text": "Generative Adversarial Nets (GANs)) offers an effective architecture of jointly training a generative model and a discriminative classifier to generate sharp and realistic images.", "labels": [], "entities": []}, {"text": "This architecture could also potentially be applied to conversational response generation to relieve the safe response problem, where the generative part can bean Seq2Seq-based model that generates response utterances forgiven queries, and the discriminative part can evaluate the quality of the generated utterances from diverse dimensions according to human-produced responses.", "labels": [], "entities": [{"text": "conversational response generation", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.7343257466952006}]}, {"text": "However, unlike the image generation problems, training such a GAN for text generation here is not straightforward.", "labels": [], "entities": [{"text": "image generation", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7484211623668671}, {"text": "text generation", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.7801908254623413}]}, {"text": "The decoding phase of the Seq2Seq model usually involves sampling discrete words from the predicted distributions, which will be fed into the training of the discriminator.", "labels": [], "entities": []}, {"text": "The sampling procedure is non-differentiable, and will therefore break the back-propagation.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, Reinforcement Learning (RL) is first introduced to address the above problem (, where the score predicted by a discriminator was used as the reinforcement to train the generator, yielding a hybrid model of GAN and RL.", "labels": [], "entities": []}, {"text": "But to train the RL phrase, introduced two approximations for reward computing at each action (word) selection step, including a Markov Chain Monte Carlo (MCMC) sampling method and a partial utterance scoring approach.", "labels": [], "entities": []}, {"text": "It has been stated in their work that the former approach is time-consuming and the latter one will result in lower performance due to the overfitting problem caused by adding a large amount of partial utterances into the training set.", "labels": [], "entities": []}, {"text": "Nevertheless, we also want to argue that, besides the time complexity issue of MCMC, RL itself is not an optimal choice either.", "labels": [], "entities": [{"text": "RL", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.8470233678817749}]}, {"text": "As shown in our experimental results in Section 5.1, a more elegant design of an end-toend differentiable GAN can significantly increase the model's performance in this text generation task.", "labels": [], "entities": [{"text": "text generation task", "start_pos": 169, "end_pos": 189, "type": "TASK", "confidence": 0.8238555788993835}]}, {"text": "In this paper, we propose a novel variant of GAN for conversational response generation, which introduces an approximate embedding layer to replace the sampling-based decoding phase, such that the entire model is continuous and differentiable.", "labels": [], "entities": [{"text": "conversational response generation", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.7506279746691386}]}, {"text": "Empirical experiments are conducted based on two datasets, of which the results show that the proposed method significantly outperforms three representative existing approaches in both relevance and diversity oriented automatic metrics.", "labels": [], "entities": []}, {"text": "In addition, human evaluations are carried out as well, demonstrating the potential of the proposed model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test our model on two datasets: Baidu Tieba and OpenSubtitles (.", "labels": [], "entities": [{"text": "Baidu Tieba", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9463169276714325}, {"text": "OpenSubtitles", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.916495680809021}]}, {"text": "The Baidu Tieba dataset is composed of single-turn conversations collected from the threads of Baidu Tieba 1 , of which the utterance length ranging from 3 to 30 words.", "labels": [], "entities": [{"text": "Baidu Tieba dataset", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9223254521687826}, {"text": "Baidu Tieba 1", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.8441550930341085}]}, {"text": "The OpenSubtitles dataset contains movie scripts organised by characters, where we follow to retain subtitles containing 5-50 words in the following experiments.", "labels": [], "entities": [{"text": "OpenSubtitles dataset", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.8717449307441711}]}, {"text": "From each of the two datasets, we sample 5,000,000 unique singleturn conversations as the training data, 200,000 additional unique pairs for validation, and another 10,000 as the test set.", "labels": [], "entities": []}, {"text": "For automatic evaluations, the following commonly accepted metrics are employed.", "labels": [], "entities": []}, {"text": "Note here, the goal of our model is to obtain responses not only semantically relevant to the corresponding queries, but also of good diversity and novelty.", "labels": [], "entities": []}, {"text": "Therefore, in this work, embedding-based metrics ( ) are adopted to evaluate semantic the relevance between queries and their corresponding generated responses, while dist-1, dist-2 () are used as diversity measures.", "labels": [], "entities": []}, {"text": "In addition, we also introduce a Novelty measure as detailed below.", "labels": [], "entities": []}, {"text": "Relevance Metrics: The following three word embedding based metrics 3 are used to compute the semantic relevance of two utterances.", "labels": [], "entities": []}, {"text": "The Greedy metric is to greedily match words in two given utterances based on the cosine similarities of their embeddings, and to average the obtained scores.", "labels": [], "entities": []}, {"text": "Alternatively, an utterance representation can be obtained by averaging the embeddings of all the words in that utterance, of which the cosine similarity gives the Average metric (.", "labels": [], "entities": [{"text": "Average", "start_pos": 164, "end_pos": 171, "type": "METRIC", "confidence": 0.9683108925819397}]}, {"text": "In addition, one can also achieve an utterance representation by taking the largest extreme values among the embedding vectors of all the words it contains, before computing the cosine similarities between utterance vectors, which yields the Extreme metric ().", "labels": [], "entities": []}, {"text": "Diversity Metrics: To measure the informativeness and diversity of the generated responses, we follow the dist-1 and dist-2 metrics proposed by and , and introduce a Novelty metric.", "labels": [], "entities": []}, {"text": "The dist-1 (dist-2) is defined as the number of unique unigrams (bigrams for dist-2).", "labels": [], "entities": []}, {"text": "A common drawback of dist-1 and dist-2 is that in the computation, less informative words (such as \"I\", \"is\", etc.) are considered equally with those more informative ones.", "labels": [], "entities": []}, {"text": "Therefore, in this paper, we define an extra Novelty metric, which is the number of infrequent words observed in the generated responses.", "labels": [], "entities": []}, {"text": "Here we take all the words except the top 2000 most frequent ones in the vocabulary as infrequent words.", "labels": [], "entities": []}, {"text": "Note here, the dist-1 and Novelty values are normalised by utterance length, and dist-2 is normalised by the total number of bigrams in the The implementation of all these metrics follows the code at https://github.com/ julianser/hed-dlg-truncated/tree/master/ Evaluation.", "labels": [], "entities": []}, {"text": "Human Evaluation: To evaluate the performance of our model from human perspectives, this paper conducts a human subject experiement by comparing the responses generated by Adver-REGS (which is one of the most competitive existing approaches) with those by the proposed model.", "labels": [], "entities": []}, {"text": "Three experienced annotators are invited to evaluate 200 groups of examples.", "labels": [], "entities": []}, {"text": "In the evaluation, for every given query, the annotators will see 10 generated responses from each model.", "labels": [], "entities": []}, {"text": "Since the proposed method aims at improving the diversity of the responses generated by Seq2Seq models, while maintaining their relevance to the input queries, we ask the annotators to evaluate the diversity performance of the two systems only if there is no obvious difference between the performance of their relevance.", "labels": [], "entities": []}, {"text": "This experimental setting is due to the following two reasons.", "labels": [], "entities": []}, {"text": "Firstly, it is difficult to judge a systems diversity based on one single response (.", "labels": [], "entities": []}, {"text": "Secondly, the practical deployment of a chat-oriented conversational system will usually decode an N-best list of candidate responses, from which it random samples the final reply.", "labels": [], "entities": []}, {"text": "Considering that all the annotators use Mandarin as their first language, the above evaluation is only done on the Tieba dataset.", "labels": [], "entities": [{"text": "Tieba dataset", "start_pos": 115, "end_pos": 128, "type": "DATASET", "confidence": 0.9668911099433899}]}, {"text": "From and 2, it can be observed that the proposed GAN-AEL model outperforms the baselines on both datasets in all metrics, especially for the diversity oriented scores.", "labels": [], "entities": []}, {"text": "The improvements can be explained from the following two angles.", "labels": [], "entities": []}, {"text": "a) Since a vanilla Seq2Seq model does not take diversity, novelty or informativeness into account, the discriminator tends to capture such information to distinguish model-generated responses and human responses.", "labels": [], "entities": []}, {"text": "By backpropagating the discriminator's feedback to the generator, the adversarially trained generator gains significantly better performance in such aspects.", "labels": [], "entities": []}, {"text": "On the other hand, the relevance is also retained during the adversarial training, as one can imagine that the human produced references given to the discriminator are usually semantically highly relevant to the corresponding queries.", "labels": [], "entities": []}, {"text": "b) The proposed approximation layer is an effective way to couple the response generator and the discriminator.", "labels": [], "entities": []}, {"text": "Through this differentiable component, the loss of the discriminator is properly propagated to the generator and guide the tuning of the latter's parameters.", "labels": [], "entities": []}, {"text": "It can also be seen from the results that the performance of all the models on the three semantic relevance oriented metrics are comparable to each other.", "labels": [], "entities": []}, {"text": "This implies that all the models, including the baseline methods and the proposed model, have the capability to generate responses of reasonable relevance to given queries, which satisfies the primary goal of the response generation task.", "labels": [], "entities": [{"text": "response generation task", "start_pos": 213, "end_pos": 237, "type": "TASK", "confidence": 0.7797626256942749}]}, {"text": "It further suggests that the Seq2Seq architecture works properly in modelling the semantics of entire utterances.", "labels": [], "entities": []}, {"text": "Nevertheless, although the decoder mechanism can select topic-relevant words to construct responses based on the given query, the limitation of na\u00a8\u0131vena\u00a8\u0131ve Seq2Seq models tend to yield less diverse or informative outputs.", "labels": [], "entities": []}, {"text": "Furthermore, when compared to Adver-REGS, the proposed GAN-AEL gains 30%-60% relative improvement in the dist-1, dist-2 and novelty metrics on both datasets, which indicates that coupling the generator and the discriminator with a differentiable component is a more preferable methodology for text generation tasks, and is a meaningful analogy to standard GANs for image generation.", "labels": [], "entities": [{"text": "novelty", "start_pos": 124, "end_pos": 131, "type": "METRIC", "confidence": 0.9815692901611328}, {"text": "text generation tasks", "start_pos": 293, "end_pos": 314, "type": "TASK", "confidence": 0.8160688877105713}, {"text": "image generation", "start_pos": 365, "end_pos": 381, "type": "TASK", "confidence": 0.7311516106128693}]}, {"text": "Interestingly, all the models achieve significantly higher novelty scores on the Tieba dataset than on the OpenSubtitle dataset.", "labels": [], "entities": [{"text": "novelty scores", "start_pos": 59, "end_pos": 73, "type": "METRIC", "confidence": 0.9784574508666992}, {"text": "Tieba dataset", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9547868371009827}, {"text": "OpenSubtitle dataset", "start_pos": 107, "end_pos": 127, "type": "DATASET", "confidence": 0.9643040597438812}]}, {"text": "This is due to the difference of the coverages of highfrequency words in the two corpora.", "labels": [], "entities": []}, {"text": "Concretely, since we exclude top 2,000 most frequent words when computing the novelty scores on both datasets, which covers 70% and 82% of the words in Tieba and OpenSubtitle respectively, it is more likely to observe novel words on the Tieba data.", "labels": [], "entities": [{"text": "novelty", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9731453061103821}, {"text": "OpenSubtitle", "start_pos": 162, "end_pos": 174, "type": "DATASET", "confidence": 0.8592829704284668}, {"text": "Tieba data", "start_pos": 237, "end_pos": 247, "type": "DATASET", "confidence": 0.9413470327854156}]}, {"text": "In addition, it can be seen that GAN-AEL improves the greedy score to a much greater extent than the average and extreme scores, which further suggests that the responses generated by GAN-AEL are more informative.", "labels": [], "entities": []}, {"text": "Concretely, the calculations of the average and extreme scores maybe dominated by generic non-informative words.", "labels": [], "entities": []}, {"text": "By contrast, since the greedy metric is computed based on a (simple and greedy) wordwise semantic alignments between two utterances, the influence of those generic words will be reduced.", "labels": [], "entities": []}, {"text": "gives the human evaluation results, which indicates that the proposed GAN-AEL is more preferable than Adver-REGS from human perspectives.", "labels": [], "entities": []}, {"text": "This again implies that the approximate embedding layer is more effective in propagating the discriminator's feedback to the generator than the reinforcement learning mechanism of ().", "labels": [], "entities": []}, {"text": "The result is statistically significant with p < 0.01 according to sign test.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Relevance and diversity evaluation on the Tieba dataset.", "labels": [], "entities": [{"text": "Relevance", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9609025120735168}, {"text": "Tieba dataset", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.9570592045783997}]}, {"text": " Table 2: Relevance and diversity evaluation on the OpenSubtitles dataset.", "labels": [], "entities": [{"text": "Relevance", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9533363580703735}, {"text": "OpenSubtitles dataset", "start_pos": 52, "end_pos": 73, "type": "DATASET", "confidence": 0.965474933385849}]}, {"text": " Table 3: Evaluations of GAN-AEL and Adver- REGS based on human subjects,", "labels": [], "entities": [{"text": "Adver- REGS", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.7397450804710388}]}]}