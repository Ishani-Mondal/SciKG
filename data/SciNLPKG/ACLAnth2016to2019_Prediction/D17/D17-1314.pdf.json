{"title": [{"text": "DOC: Deep Open Classification of Text Documents", "labels": [], "entities": [{"text": "DOC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.781061053276062}, {"text": "Deep Open Classification of Text Documents", "start_pos": 5, "end_pos": 47, "type": "TASK", "confidence": 0.6542617628971735}]}], "abstractContent": [{"text": "Traditional supervised learning makes the closed-world assumption that the classes appeared in the test data must have appeared in training.", "labels": [], "entities": []}, {"text": "This also applies to text learning or text classification.", "labels": [], "entities": [{"text": "text learning", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.8543286025524139}, {"text": "text classification", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7854967415332794}]}, {"text": "As learning is used increasingly in dynamic open environments where some new/test documents may not belong to any of the training classes, identifying these novel documents during classification presents an important problem.", "labels": [], "entities": []}, {"text": "This problem is called open-world classification or open classification.", "labels": [], "entities": [{"text": "open-world classification or open classification", "start_pos": 23, "end_pos": 71, "type": "TASK", "confidence": 0.64499152302742}]}, {"text": "This paper proposes a novel deep learning based approach.", "labels": [], "entities": []}, {"text": "It outperforms existing state-of-the-art techniques dramatically.", "labels": [], "entities": []}], "introductionContent": [{"text": "A key assumption made by classic supervised text classification (or learning) is that classes appeared in the test data must have appeared in training, called the closed-world assumption.", "labels": [], "entities": [{"text": "text classification", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7645241916179657}]}, {"text": "Although this assumption holds in many applications, it is violated in many others, especially in dynamic or open environments.", "labels": [], "entities": []}, {"text": "For example, in social media, a classifier built with past topics or classes may not be effective in classifying future data because new topics appear constantly in social media . This is clearly true in other domains too, e.g., self-driving cars, where new objects may appear in the scene all the time.", "labels": [], "entities": []}, {"text": "Ideally, in the text domain, the classifier should classify incoming documents to the right existing classes used in training and also detect those documents that don't belong to any of the existing classes.", "labels": [], "entities": []}, {"text": "This problem is called open world classi with a positive region bounded by two parallel hyperplanes.", "labels": [], "entities": []}, {"text": "Similar works were also done in a probability setting by  and . Both approaches use probability threshold, but choosing thresholds need prior knowledge, which is a weakness of the methods.", "labels": [], "entities": []}, {"text": "proposed a multi-class semisupervised method based on the EM algorithm.", "labels": [], "entities": []}, {"text": "It has been shown that these methods are poorer than the method in . The work closest to ours is that in, which leverages an algorithm called OpenMax to add the rejection capability by utilizing the logits that are trained via closed-world softmax function.", "labels": [], "entities": []}, {"text": "One weak assumption of OpenMax is that examples with equally likely logits are more likely from the unseen or rejection class, which can be examples that are hard to classify.", "labels": [], "entities": []}, {"text": "Another weakness is that it requires validation examples from the unseen/rejection class to tune the hyperparameters.", "labels": [], "entities": []}, {"text": "Our method doesn't make these weak assumptions and performs markedly better.", "labels": [], "entities": []}, {"text": "Our proposed method, called DOC (Deep Open Classification), uses deep learning (.", "labels": [], "entities": []}, {"text": "Unlike traditional classifiers, DOC builds a multi-class classifier with a 1-vs-rest final layer of sigmoids rather than softmax to reduce the open space risk.", "labels": [], "entities": []}, {"text": "It reduces the open space risk further for rejection by tightening the decision boundaries of sigmoid functions with Gaussian fitting.", "labels": [], "entities": [{"text": "rejection", "start_pos": 43, "end_pos": 52, "type": "TASK", "confidence": 0.9874852299690247}]}, {"text": "Experimental results show that DOC dramatically outperforms state-of-the-art existing approaches from both text classification and image classification domains.", "labels": [], "entities": [{"text": "text classification and image classification", "start_pos": 107, "end_pos": 151, "type": "TASK", "confidence": 0.7361506819725037}]}], "datasetContent": [{"text": "We perform evaluation using two publicly available datasets, which are exactly the same datasets used in . (1) 20 Newsgroups 2 (Rennie, 2008): The 20 newsgroups data set contains 20 non-overlapping classes.", "labels": [], "entities": []}, {"text": "Each class has about 1000 documents.", "labels": [], "entities": []}, {"text": "(2) 50-class reviews (Chen and Liu, 2014): The dataset has Amazon reviews of 50 classes of products.", "labels": [], "entities": []}, {"text": "Each class has 1000 reviews.", "labels": [], "entities": []}, {"text": "Although product reviews are used, we do not do sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.9347547292709351}]}, {"text": "We still perform topic-based classification.", "labels": [], "entities": [{"text": "topic-based classification", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.7561629116535187}]}, {"text": "That is, given a review, the system decides what class of product the review is about.", "labels": [], "entities": []}, {"text": "For every dataset, we keep a 20000 frequent word vocabulary.", "labels": [], "entities": []}, {"text": "Each document is fixed to 2000-word length (cutting or padding when necessary).", "labels": [], "entities": []}, {"text": "For a fair comparison, we use exactly the same settings as in . For each class in each dataset, we randomly sampled 60% of documents for training, 10% for validation and 30% for testing.", "labels": [], "entities": []}, {"text": "did not use a validation set, but the test data is the same 30%.", "labels": [], "entities": []}, {"text": "We use the validation set to avoid overfitting.", "labels": [], "entities": []}, {"text": "For openworld evaluation, we holdout some classes (as unseen) in training and mix them back during testing.", "labels": [], "entities": [{"text": "openworld evaluation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7631169557571411}]}, {"text": "We vary the number of training classes and use 25%, 50%, 75%, or 100% classes for training and all classes for testing.", "labels": [], "entities": []}, {"text": "Here using 100% classes for training is the same as the traditional closedworld classification.", "labels": [], "entities": []}, {"text": "Taking 20 newsgroups as an example, for 25% classes, we use 5 classes (we randomly choose 5 classes from 20 classes for 10 times and average the results, as in ) for training and all 20 classes for testing (15 classes are unseen in training).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Macro-F 1 scores for 20 newsgroups  % of seen classes 25% 50% 75% 100%  cbsSVM  59.3 70.1 72.0  85.2  OpenMax  35.7 59.9 76.2  91.9  DOC (t = 0.5)  75.9 84.0 87.4  92.6  DOC  82.3 85.2 86.2  92.6", "labels": [], "entities": [{"text": "DOC", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.6488685607910156}]}, {"text": " Table 2: Macro-F 1 scores for 50-class reviews  % of seen classes 25% 50% 75% 100%  cbsSVM  55.7 61.5 58.6  63.4  OpenMax  41.6 57.0 64.2  69.2  DOC (t = 0.5)  51.1 63.6 66.2  69.8  DOC  61.2 64.8 66.6  69.8", "labels": [], "entities": []}]}