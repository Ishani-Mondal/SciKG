{"title": [], "abstractContent": [{"text": "Adversarial training is a mean of regu-larizing classification algorithms by generating adversarial noise to the training data.", "labels": [], "entities": [{"text": "regu-larizing classification", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.8402596712112427}]}, {"text": "We apply adversarial training in relation extraction within the multi-instance multi-label learning framework.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.9368922710418701}]}, {"text": "We evaluate various neural network architectures on two different datasets.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate that adversarial training is generally effective for both CNN and RNN models and significantly improves the precision of predicted relations.", "labels": [], "entities": [{"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9965984225273132}]}], "introductionContent": [{"text": "Despite the recent successes of deep neural networks on various applications, neural network models tend to be overconfident about the noise in input signals.", "labels": [], "entities": []}, {"text": "Adversarial examples ( are examples generated by adding noise in the form of small perturbations to the original data, which are often indistinguishable for humans but drastically increase the loss incurred in a deep model.", "labels": [], "entities": []}, {"text": "Adversarial training) is a technique for regularizing deep models by encouraging the neural network to correctly classify both unmodified examples and perturbed ones, which in practice not only enhances the robustness of the neural network but also improves its generalizability.", "labels": [], "entities": []}, {"text": "Previous work has largely applied adversarial training on straightforward classification tasks, including image classification () and text classification (, where the goal is simply predicting a single label for every example and the training examples are able to provide strong supervision.", "labels": [], "entities": [{"text": "image classification", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.7976759076118469}, {"text": "text classification", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.839747279882431}]}, {"text": "It remains unclear whether adversarial training could be still effective for tasks with much weaker supervision, e.g., distant supervision (, or a different evaluation metric other than prediction accuracy (e.g., F1 score).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.4875032603740692}, {"text": "F1 score)", "start_pos": 213, "end_pos": 222, "type": "METRIC", "confidence": 0.977133055528005}]}, {"text": "This paper focuses on the task of relation extraction, where the goal is to predict the relation that exists between a particular entity pair given several text mentions.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8379454016685486}]}, {"text": "One popular way to handle this problem is the multi-instance multi-label learning framework (MIML) () with distant supervision (, where the mentions for an entity pair are aligned with the relations in Freebase (.", "labels": [], "entities": []}, {"text": "In this setting, relation extraction is much harder than the canonical classification problem in two respects: (1) although distant supervision can provide a large amount of data, the training labels are very noisy, and due to the multi-instance framework, the supervision is much weaker; (2) the evaluation metric of relation extraction is often the precisionrecall curve or F1 score, which cannot be represented (and thereby optimized) directly in the loss function.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9356935024261475}, {"text": "relation extraction", "start_pos": 318, "end_pos": 337, "type": "TASK", "confidence": 0.82076695561409}, {"text": "precisionrecall curve", "start_pos": 351, "end_pos": 372, "type": "METRIC", "confidence": 0.9775606095790863}, {"text": "F1 score", "start_pos": 376, "end_pos": 384, "type": "METRIC", "confidence": 0.9528636336326599}]}, {"text": "In order to evaluate the effectiveness of adversarial training for relation extraction, we apply it to two different architectures (a convoluational neural network and a recurrent neural network) on two different datasets.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.9345878064632416}]}, {"text": "Experimental results show that even on this harder task with much weaker supervision, adversarial training can still improve the performance on all of the cases we studied.", "labels": [], "entities": []}], "datasetContent": [{"text": "To measure the effectiveness of adversarial training on relation extraction, we evaluate both the CNN (PCNN) and RNN (bi-GRU) models on two different datasets, the NYT dataset (NYT) developed by and the UW dataset (UW) by . All code is implemented in Tensorflow () and available at https://github.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.9185871183872223}, {"text": "NYT dataset (NYT", "start_pos": 164, "end_pos": 180, "type": "DATASET", "confidence": 0.9347986578941345}, {"text": "UW dataset (UW", "start_pos": 203, "end_pos": 217, "type": "DATASET", "confidence": 0.8900946825742722}]}, {"text": "com/jxwuyi/AtNRE.", "labels": [], "entities": [{"text": "AtNRE", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.8341370820999146}]}, {"text": "We adopt Adam optimizer () with learning rate 0.001, batch size 50 and dropout rate 0.5.", "labels": [], "entities": []}, {"text": "For adversarial training, the only parameter is . In each of the following experiments, we fixed all the hyper-parameters of the base model, performed a binary search solely on and showed the most effective value of .  The statistics of the two datasets are summarized in.", "labels": [], "entities": []}, {"text": "We exclude sentences longer than SentLen during training and randomly split data for entity pairs with more than 500 mentions.", "labels": [], "entities": []}, {"text": "Note that the number of target relations in these two datasets are significantly different, which helps   demonstrate the applicability of adversarial training on various evaluation settings.", "labels": [], "entities": []}, {"text": "Since the test set of the UW dataset only contains 200 sentences, we adopt a subset of the test set from the NYT dataset: all the entity pairs with the corresponding 4 relations in UW and another 1500 randomly selected NA pairs.", "labels": [], "entities": [{"text": "UW dataset", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.9370298385620117}, {"text": "NYT dataset", "start_pos": 109, "end_pos": 120, "type": "DATASET", "confidence": 0.9784290790557861}]}, {"text": "We train a word embedding of d w = 200 dimensions using Glove () on the New York Times Corpus in this experiment.", "labels": [], "entities": [{"text": "Glove", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9850053787231445}, {"text": "New York Times Corpus", "start_pos": 72, "end_pos": 93, "type": "DATASET", "confidence": 0.8462146669626236}]}, {"text": "For model parameters, we set the entity feature dimension d e = 5 and sentence feature dimension d s = 250 for PCNN and d e = 3 and d s = 200 for RNN.", "labels": [], "entities": [{"text": "PCNN", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.8657682538032532}]}, {"text": "For adversarial training, we choose = 0.05 for PCNN and = 0.5 for RNN.", "labels": [], "entities": [{"text": "PCNN", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.8391556739807129}]}, {"text": "Since here word embedding dimension d w is larger than that used for the NYT dataset, which implies that we now have word embeddings with larger norms, accordingly the optimal value of increases.", "labels": [], "entities": [{"text": "NYT dataset", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.9690333902835846}]}, {"text": "The precision-recall curves on the test data are shown in, where adversarial training again significantly improves the precision for both models.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9990119934082031}, {"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9994924068450928}]}, {"text": "The precision numbers for some particular recall values as well as the AUC numbers are demonstrated in.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9992396831512451}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9956028461456299}, {"text": "AUC", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.8000562191009521}]}, {"text": "Similarly RNN yields superior performances on the UW dataset.", "labels": [], "entities": [{"text": "RNN", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9039241671562195}, {"text": "UW dataset", "start_pos": 50, "end_pos": 60, "type": "DATASET", "confidence": 0.9873686730861664}]}], "tableCaptions": [{"text": " Table 1: Dataset statistics (#Rel includes NA).", "labels": [], "entities": [{"text": "Rel", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.861437201499939}]}, {"text": " Table 2: Precisions of various models for differ- ent recalls on the NYT dataset, with best values in  bold.", "labels": [], "entities": [{"text": "Precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9924216866493225}, {"text": "differ- ent recalls", "start_pos": 43, "end_pos": 62, "type": "METRIC", "confidence": 0.7538990527391434}, {"text": "NYT dataset", "start_pos": 70, "end_pos": 81, "type": "DATASET", "confidence": 0.9739025831222534}]}, {"text": " Table 3: Precisions of various models for different  recalls on the UW dataset, with best values in bold.", "labels": [], "entities": [{"text": "Precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9955124258995056}, {"text": "UW dataset", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.9879077076911926}]}]}