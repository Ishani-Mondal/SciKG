{"title": [{"text": "Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision", "labels": [], "entities": [{"text": "Margin Reward", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.7909364998340607}]}], "abstractContent": [{"text": "Neural networks have achieved state-of-the-art performance on several structured-output prediction tasks, trained in a fully supervised fashion.", "labels": [], "entities": []}, {"text": "However, annotated examples in structured domains are often costly to obtain, which thus limits the applications of neural networks.", "labels": [], "entities": []}, {"text": "In this work, we propose Maximum Margin Reward Networks, a neural network-based framework that aims to learn from both explicit (full structures) and implicit supervision signals (delayed feedback on the correctness of the predicted structure).", "labels": [], "entities": []}, {"text": "On named entity recognition and semantic parsing, our model outperforms previous systems on the benchmark datasets, CoNLL-2003 and WebQuestionsSP.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.6134117245674133}, {"text": "semantic parsing", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7324527204036713}, {"text": "CoNLL-2003", "start_pos": 116, "end_pos": 126, "type": "DATASET", "confidence": 0.9056940674781799}]}], "introductionContent": [{"text": "Structured-output prediction problems, where the goal is to determine values of a set of interdependent variables, are ubiquitous in NLP.", "labels": [], "entities": [{"text": "Structured-output prediction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8355043828487396}]}, {"text": "Structures of such problems can range from simple sequences like part-of-speech tagging (  and named entity recognition (, to complex syntactic or semantic analysis such as dependency parsing  and semantic parsing.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7446897327899933}, {"text": "named entity recognition", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.690776546796163}, {"text": "dependency parsing", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.8066083192825317}, {"text": "semantic parsing", "start_pos": 197, "end_pos": 213, "type": "TASK", "confidence": 0.7257703840732574}]}, {"text": "Stateof-the-art methods of these tasks are often neural network models trained using fully annotated structures, which can be costly or time-consuming to obtain.", "labels": [], "entities": []}, {"text": "Weakly supervised learning settings, where the algorithm assumes only the existence of implicit signals on whether a prediction is correct, are thus more appealing in many scenarios.", "labels": [], "entities": []}, {"text": "For example, shows a weakly supervised setting of learning semantic parsers using only question-answer pairs.", "labels": [], "entities": []}, {"text": "When the system generates a candidate semantic parse during training, the quality needs to be indirectly measured by: Learning a semantic parser using implicit supervision signals (labeled answers).", "labels": [], "entities": []}, {"text": "Since there are no gold parses, a model needs to explore different parses, where their quality can only be indirectly verified by comparing retrieved answers and the labeled answers.", "labels": [], "entities": []}, {"text": "comparing the derived answers from the knowledge base and the provided labeled answers.", "labels": [], "entities": []}, {"text": "This setting of implicit supervision increases the difficulty of learning a neural model, not only because the signals are vague and noisy, but also delayed.", "labels": [], "entities": []}, {"text": "For instance, among different semantic parses that result in the same answers, typically only few of them correctly represent the meaning of the question.", "labels": [], "entities": []}, {"text": "Moreover, the correctness of answers corresponding to a parse can only be evaluated through an external oracle (e.g., executing the query on the knowledge base) after the parse is fully constructed.", "labels": [], "entities": []}, {"text": "Early model update before the search of a full semantic parse is complete is generally infeasible.", "labels": [], "entities": []}, {"text": "1 It is also not clear how to leverage implicit and explicit signals integrally during learning when both kinds of labels are present.", "labels": [], "entities": []}, {"text": "In this work, we propose Maximum Margin Reward Networks (MMRN), which is a general neural network-based framework that is able to learn from both implicit and explicit supervision signals.", "labels": [], "entities": [{"text": "Maximum Margin Reward Networks (MMRN)", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.7057940108435494}]}, {"text": "By casting structured-output learning as a search problem, the key insight in MMRN is the special mechanism of rewards.", "labels": [], "entities": [{"text": "MMRN", "start_pos": 78, "end_pos": 82, "type": "TASK", "confidence": 0.9110602140426636}]}, {"text": "Rewards can be viewed as the training signals that drive the model to explore the search space and to find the correct structure.", "labels": [], "entities": []}, {"text": "The explicit supervision signals can be viewed as a source of immediate rewards, as we can often instantly know the correctness of the current action.", "labels": [], "entities": []}, {"text": "On the other hand, the implicit supervision can be viewed as a source of delayed rewards, where the reward of the actions can only be revealed later.", "labels": [], "entities": []}, {"text": "We unify these two types of reward signals by using a maximum margin update, inspired by structured SVM ( . The effectiveness of MMRN is demonstrated on three NLP tasks: named entity recognition, entity linking and semantic parsing.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 170, "end_pos": 194, "type": "TASK", "confidence": 0.6063459714253744}, {"text": "entity linking", "start_pos": 196, "end_pos": 210, "type": "TASK", "confidence": 0.7781215906143188}, {"text": "semantic parsing", "start_pos": 215, "end_pos": 231, "type": "TASK", "confidence": 0.7315219640731812}]}, {"text": "MMRN outperforms the current best results on CoNLL-2003 named entity recognition dataset, reaching 91.4% F 1 , in the close setting where no gazetteer is allowed.", "labels": [], "entities": [{"text": "MMRN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6112619638442993}, {"text": "CoNLL-2003 named entity recognition dataset", "start_pos": 45, "end_pos": 88, "type": "DATASET", "confidence": 0.8398413896560669}, {"text": "F 1", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9952013492584229}]}, {"text": "It also performs comparably to the existing state-of-theart systems on entity linking.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.7774990200996399}]}, {"text": "Models for these two tasks are trained using explicit supervision.", "labels": [], "entities": []}, {"text": "For semantic parsing, where only implicit supervision signals are provided, MMRN is able to learn from delayed rewards, improving the entity linking component and the overall semantic parsing framework jointly, and outperforms the best published system by 1.4% absolute on the WebQSP dataset ( . In the rest of the paper, we survey the most related work in Sec.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7702189683914185}, {"text": "semantic parsing", "start_pos": 175, "end_pos": 191, "type": "TASK", "confidence": 0.7519778907299042}, {"text": "WebQSP dataset", "start_pos": 277, "end_pos": 291, "type": "DATASET", "confidence": 0.976936548948288}]}, {"text": "2 and give an in-depth discussion on comparing MMRN and other learning frameworks in Sec.", "labels": [], "entities": []}, {"text": "7. We start the description of our method from the search formulation and the state-action spaces in our targeted tasks in Sec.", "labels": [], "entities": []}, {"text": "3, followed by the reward and learning algorithm in Sec.", "labels": [], "entities": []}, {"text": "4 and the detailed neural model design in Sec.", "labels": [], "entities": []}, {"text": "6 reports the experimental results and Sec.", "labels": [], "entities": []}], "datasetContent": [{"text": "It is important to have a general machine learning model working for both implicit and explicit supervision signals.", "labels": [], "entities": []}, {"text": "We valid our learning framework when the explicit supervision signals are presented, as well as demonstrate the support of the scenario where supervision signals are mixed.", "labels": [], "entities": []}, {"text": "Specifically, in this section, we report the experimental results of MMRN on named entity recognition and entity linking, both using explicit supervision, and on semantic parsing, using implicit supervision.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.6259511510531107}, {"text": "entity linking", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.6989719420671463}, {"text": "semantic parsing", "start_pos": 162, "end_pos": 178, "type": "TASK", "confidence": 0.72838494181633}]}, {"text": "In all our experiments, we tuned hyperparameters on the development set (each task respectively), and then re-trained the models on the combination of the training and development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Explicit Supervision: Named Entity  Recognition. Our MMRN with beam size 20 out- performs current best systems, which are based on  neural networks.", "labels": [], "entities": [{"text": "Named Entity  Recognition", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.6749505798021952}]}, {"text": " Table 2: Explicit Supervision: Entity Linking.", "labels": [], "entities": [{"text": "Explicit Supervision", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7802016139030457}, {"text": "Entity Linking", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.6714517921209335}]}, {"text": " Table 3: Implicit Supervision: Semantic Pars- ing. By updating the entity linking and semantic  parsing models jointly, MMRN-JOINT improves over  MMRN-PIPELINE by 5 points in F 1 and outperforms  REINFORCE+ (SP). It also improves the entity  linking result on the WebQSP questions (EL).", "labels": [], "entities": [{"text": "Implicit Supervision", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7853505909442902}, {"text": "entity linking and semantic  parsing", "start_pos": 68, "end_pos": 104, "type": "TASK", "confidence": 0.6987182855606079}, {"text": "F 1", "start_pos": 176, "end_pos": 179, "type": "METRIC", "confidence": 0.9481086730957031}, {"text": "REINFORCE+ (SP)", "start_pos": 197, "end_pos": 212, "type": "METRIC", "confidence": 0.9291159510612488}, {"text": "WebQSP questions (EL)", "start_pos": 265, "end_pos": 286, "type": "DATASET", "confidence": 0.9344079732894898}]}]}