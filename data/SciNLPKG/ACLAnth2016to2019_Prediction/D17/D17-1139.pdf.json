{"title": [{"text": "Learning to Rank Semantic Coherence for Topic Segmentation", "labels": [], "entities": [{"text": "Topic Segmentation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7793930470943451}]}], "abstractContent": [{"text": "Topic segmentation plays an important role for discourse parsing and information retrieval.", "labels": [], "entities": [{"text": "Topic segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8029221892356873}, {"text": "discourse parsing", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7016496807336807}, {"text": "information retrieval", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7859658300876617}]}, {"text": "Due to the absence of training data, previous work mainly adopts un-supervised methods to rank semantic coherence between paragraphs for topic seg-mentation.", "labels": [], "entities": []}, {"text": "In this paper, we present an intuitive and simple idea to automatically create a \"quasi\" training dataset, which includes a large amount of text pairs from the same or different documents with different semantic coherence.", "labels": [], "entities": []}, {"text": "With the training corpus, we design asymmetric CNN neural network to model text pairs and rank the semantic coherence within the learning to rank framework.", "labels": [], "entities": []}, {"text": "Experiments show that our algorithm is able to achieve competitive performance over strong base-lines on several real-world datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of topic segmentation is to segment a document into several topically coherent parts, with different parts corresponding to different topics.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7726990878582001}]}, {"text": "Topic segmentation enables better understanding of document structure, and makes long document much easier to navigate.", "labels": [], "entities": [{"text": "Topic segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8092020750045776}]}, {"text": "It also provides helpful information for tasks such as information retrieval, topic tracking etc.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.8243058919906616}, {"text": "topic tracking", "start_pos": 78, "end_pos": 92, "type": "TASK", "confidence": 0.8769277632236481}]}, {"text": "Due to the lack of large scale annotated topic segmentation dataset, previous work mainly focus on unsupervised models to measure the coherence between two textual segments.", "labels": [], "entities": []}, {"text": "The intuition behind unsupervised models is that two adjacent segments from the same topic are more coherent than those from different topics.", "labels": [], "entities": []}, {"text": "Under this intuition, one direction of research attempts to measure coherence by computing text similarity.", "labels": [], "entities": []}, {"text": "The typical methods include TextTiling (Hearst, 1997) and its variants, such as C99), TopicTiling ( etc.", "labels": [], "entities": [{"text": "TextTiling (Hearst, 1997)", "start_pos": 28, "end_pos": 53, "type": "DATASET", "confidence": 0.7884817520777384}]}, {"text": "The other direction of research develops topic modeling techniques to explore topic representation of text and topic change between textual segments.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.7457027435302734}]}, {"text": "With carefully designed generative process and efficient inference algorithm, topic models are able to model coherence as latent variables and outperform lexical similarity based models.", "labels": [], "entities": []}, {"text": "Though unsupervised models make progress in modeling text coherence, they mostly suffer from one of the following two limitations.", "labels": [], "entities": []}, {"text": "First, it is not precise to measure coherence with text similarity, since text similarity is just one aspect to influence coherence.", "labels": [], "entities": []}, {"text": "Second, many assumptions and manually set parameters are usually involved in the complex modeling techniques, due to the absence of supervised information.", "labels": [], "entities": []}, {"text": "To overcome aforementioned limitations, we prefer to directly model the text coherence by exploring possible supervised information.", "labels": [], "entities": []}, {"text": "Then, we can learn a function f (s1, s2) which takes two textual segments s1 and s2 as input, and directly measure their semantic coherence.", "labels": [], "entities": []}, {"text": "As we know, it is hard to directly compile and collect a large number of samples with coherence scores labeling.", "labels": [], "entities": []}, {"text": "Here we propose an intuitive and simple strategy to automatically create a \"quasi\" training corpus for supervision.", "labels": [], "entities": []}, {"text": "It is a commonsense that the original documents written by human are generally more coherent than a patchwork of sentences or paragraphs randomly extracted from different documents.", "labels": [], "entities": []}, {"text": "In such cases, two textual segments from the same document are more coherent than those from different documents, and two segments from the same paragraph are more coherent than those from different paragraphs.", "labels": [], "entities": []}, {"text": "Then, we can get a large set of text pairs with partial ordering relations, which denote some text pairs are more coherent than other text pairs.", "labels": [], "entities": []}, {"text": "With these ordering information, we propose to apply the learning to rank framework to model the semantic coherence function f (s1, s2), based on which topic boundaries are identified.", "labels": [], "entities": []}, {"text": "The next key problem is how to model and represent text pairs.", "labels": [], "entities": []}, {"text": "It is fortunate that neural networks have emerged as a powerful tool for modeling text pairs (), freeing us from feature engineering.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.7627129554748535}]}, {"text": "In this paper, we develop asymmetric convolutional neural network (CNN) framework, whose main idea is to jointly model text representation and interaction between texts.", "labels": [], "entities": []}, {"text": "With our acquired large amount of training data, our CNN-based method is capable of reasonably rank semantic coherence and further conduct topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7092148065567017}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overview of four datasets.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results. (a) Ours-pair-finetune is pairwise ranking model with word embedding  fine-tuning. (b) Ours-point-static is pointwise ranking model without word embedding fine-tuning, etc.", "labels": [], "entities": []}]}