{"title": [{"text": "Sentiment Lexicon Construction with Representation Learning Based on Hierarchical Sentiment Supervision", "labels": [], "entities": [{"text": "Sentiment Lexicon Construction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9086397687594095}, {"text": "Hierarchical Sentiment Supervision", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.5909372468789419}]}], "abstractContent": [{"text": "Sentiment lexicon is an important tool for identifying the sentiment polarity of words and texts.", "labels": [], "entities": []}, {"text": "How to automatically construct sentiment lexicons has become a research topic in the field of sentiment analysis and opinion mining.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.9189740419387817}, {"text": "opinion mining", "start_pos": 117, "end_pos": 131, "type": "TASK", "confidence": 0.744768425822258}]}, {"text": "Recently there were some attempts to employ representation learning algorithms to construct a sentiment lexicon with sentiment-aware word embedding.", "labels": [], "entities": []}, {"text": "However, these methods were normally trained under document-level sentiment supervision.", "labels": [], "entities": [{"text": "document-level sentiment", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.6196404099464417}]}, {"text": "In this paper, we develop a neural architecture to train a sentiment-aware word embedding by integrating the sentiment supervision at both document and word levels, to enhance the quality of word embedding as well as the sentiment lexicon.", "labels": [], "entities": []}, {"text": "Experiments on the SemEval 2013-2016 datasets indicate that the sentiment lexicon generated by our approach achieves the state-of-the-art performance in both supervised and unsuper-vised sentiment classification, in comparison with several strong sentiment lexicon construction methods.", "labels": [], "entities": [{"text": "SemEval 2013-2016 datasets", "start_pos": 19, "end_pos": 45, "type": "DATASET", "confidence": 0.7870263457298279}]}], "introductionContent": [{"text": "Sentiment lexicon is a set of words (or phrases) each of which is assigned with a sentiment polarity score.", "labels": [], "entities": []}, {"text": "Sentiment lexicon plays an important role in many practical sentiment analysis and opinion mining tasks.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8248736560344696}, {"text": "opinion mining", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.7892326712608337}]}, {"text": "There were some manually annotated universal sentiment lexicons such as General Inquireer (GI) and HowNet.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 99, "end_pos": 105, "type": "DATASET", "confidence": 0.9697339534759521}]}, {"text": "However, due to the ubiquitous domain diversity and absence of domain prior knowledge, the automatic construction technique for domain-specific sentiment lex- * The corresponding author of this paper.", "labels": [], "entities": []}, {"text": "icons has become a challenging research topic in the field of sentiment analysis and opinion mining (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9578073024749756}, {"text": "opinion mining", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.7648179531097412}]}, {"text": "The early work employed unsupervised learning for sentiment lexicon construction.", "labels": [], "entities": [{"text": "sentiment lexicon construction", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.9364860653877258}]}, {"text": "They normally labelled a set of seed words at first, and then learned the polarity of each candidate word, based on either word conjunction relations (e.g., constellation and transition in texts), or the word co-occurrence information (such as pointwise mutual information, PMI), between the candidate word and the seed words.", "labels": [], "entities": []}, {"text": "However, the unsupervised manner showed limited effect in sentiment prediction, and the performance greatly depends on the quality of the seed words.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.977957010269165}]}, {"text": "To fully exploit the sentiment labeling information in texts, a series of supervised learning methods was further proposed to learn the sentiment lexicons.", "labels": [], "entities": [{"text": "sentiment labeling information", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.8137189348538717}]}, {"text": "For example, proposed to construct sentiment lexicons by calculating PMI between the word and the distantly supervised sentiment labels (such as emoticons) in tweets and the word's sentiment orientation (SO).", "labels": [], "entities": [{"text": "PMI", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.8736163973808289}]}, {"text": "The resulting lexicons obtained the best results in SemEval 2013.", "labels": [], "entities": [{"text": "SemEval 2013", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.7044757604598999}]}, {"text": "More advanced representation learning models were also utilized, with the aim to construct the sentiment lexicons with efficient word embeddings (.", "labels": [], "entities": []}, {"text": "The traditional representation learning framework such as Word2Vec only captures the syntactic information in the texts, but ignores the sentiment relations between words.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.933902382850647}]}, {"text": "Therefore, some researchers attempted to add sentiment supervision into the network structure, in order to train a sentimentaware word embedding.", "labels": [], "entities": []}, {"text": "For example, exploited a dedicated neural architecture to integrate document-level sentiment supervision and the syntactic knowledge for representation learning.", "labels": [], "entities": [{"text": "document-level sentiment supervision", "start_pos": 68, "end_pos": 104, "type": "TASK", "confidence": 0.6962211032708486}, {"text": "representation learning", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.9373782575130463}]}, {"text": "The sentiment-aware word embedding is then used to construct a sentiment lexicon.", "labels": [], "entities": []}, {"text": "proposed to learn a two-dimensional sentiment representation based on a simple neural network.", "labels": [], "entities": [{"text": "sentiment representation", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.8219024837017059}]}, {"text": "The sentiment lexicons generated by their approach obtained better performance to predict the tweet sentiment labels, in comparison with the PMI-based method.", "labels": [], "entities": []}, {"text": "Although these supervised learning methods canto some extent exploit the sentiment labeling information in the texts and can learn a sentiment-aware word embedding, the manner of using document-level sentiment supervision suffers from some complex linguistic phenomena such as negation, transition and comparative degree, and hence unable to capture the fine-grained sentiment information in the text.", "labels": [], "entities": []}, {"text": "For example, in the following tweet \"Four more fake people added me.", "labels": [], "entities": []}, {"text": "Is this why people don't like Twitter?", "labels": [], "entities": []}, {"text": ":( \", the document-level sentiment label is negative, but there is a positive word \"like\" in the text.", "labels": [], "entities": []}, {"text": "In representation learning, the embeddings of words are summed up to represent the document, and the word \"like\" will be falsely associated with the negative sentiment label.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.8922329545021057}]}, {"text": "Such linguistic phenomena occur frequently in review texts, and makes sentiment-aware word representation learning less effective.", "labels": [], "entities": [{"text": "sentiment-aware word representation learning", "start_pos": 70, "end_pos": 114, "type": "TASK", "confidence": 0.7364508137106895}]}, {"text": "To address this problem, in this paper, we propose anew representation learning framework called HSSWE, to learn sentiment-aware word embeddings based on hierarchical sentiment supervision.", "labels": [], "entities": []}, {"text": "In HSSWE, the learning algorithm is supervised under both document-level sentiment labels and word-level sentiment annotations (e.g., labeling \"like\" as a positive word).", "labels": [], "entities": []}, {"text": "By leveraging the sentiment supervision at both document and word level, our approach can avoid the sentiment learning flaws caused by coarse-grained document-level supervision by incorporating finegrained word-level supervision, and improve the quality of sentiment-aware word embedding.", "labels": [], "entities": []}, {"text": "Finally, following, a simple classifier was constructed to obtain the domainspecific sentiment lexicon by using word embeddings as inputs.", "labels": [], "entities": []}, {"text": "The main contributions of this work are as follows: 1.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that learns the sentiment-aware word representation under supervision at both document and word levels.", "labels": [], "entities": [{"text": "sentiment-aware word representation", "start_pos": 69, "end_pos": 104, "type": "TASK", "confidence": 0.6653770307699839}]}, {"text": "2. Our approach supports several kinds of wordlevel sentiment annotations such as 1) predefined sentiment lexicon; 2) PMI-SO lexicon with hard sentiment annotation; 3) PMI-SO lexicon with soft sentiment annotation.", "labels": [], "entities": []}, {"text": "By using PMI-SO dictionary as word-level sentiment annotation, our approach is totally corpus-based, without any external resource.", "labels": [], "entities": []}, {"text": "3. Our approach obtains the state-of-the-art performance in comparison with several strong sentiment lexicon construction methods, on the benchmark SemEval 2013-2016 datasets for twitter sentiment classification.", "labels": [], "entities": [{"text": "SemEval 2013-2016 datasets", "start_pos": 148, "end_pos": 174, "type": "DATASET", "confidence": 0.7288570900758108}, {"text": "twitter sentiment classification", "start_pos": 179, "end_pos": 211, "type": "TASK", "confidence": 0.7033160428206126}]}], "datasetContent": [{"text": "We utilize the public distant-supervision corpus 2 () to learn our lexicons.", "labels": [], "entities": []}, {"text": "We set M , the dimension of embedding, as 50.", "labels": [], "entities": []}, {"text": "The learning rate is 0.3 for stochastic gradient descent optimizer.", "labels": [], "entities": [{"text": "learning", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9577538967132568}]}, {"text": "We tune the hyper-parameter \u03b1 in the training process.", "labels": [], "entities": []}, {"text": "We evaluate the sentiment lexicons in both supervised and unsupervised sentiment classification tasks, on the SemEval 2013-2016 datasets.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.7771375775337219}, {"text": "SemEval 2013-2016 datasets", "start_pos": 110, "end_pos": 136, "type": "DATASET", "confidence": 0.8969238797823588}]}, {"text": "The statistics of evaluation datasets are shown in.", "labels": [], "entities": []}, {"text": "Supervised Sentiment Classification Evaluation: To evaluate the effect of the sentiment lexicon in supervised sentiment classification, we report the supervised sentiment classification performance by using some pre-defined lexicon features.", "labels": [], "entities": [{"text": "Sentiment Classification Evaluation", "start_pos": 11, "end_pos": 46, "type": "TASK", "confidence": 0.8561346729596456}, {"text": "supervised sentiment classification", "start_pos": 99, "end_pos": 134, "type": "TASK", "confidence": 0.6861968040466309}]}, {"text": "We follow ( to extract the lexicon features as follows: \u2022 Total count of words in the tweet score of which is greater than 0; \u2022 Total count of words in the tweet score of which is less than 0; \u2022 The sum of scores for all word great than 0; 2 http://help.sentiment140.com/for-students \u2022 The sum of scores for all wordless than 0; \u2022 The max score greater than 0; \u2022 The min scoreless than 0; \u2022 Non-zero score of the last positive word in the tweet; \u2022 Non-zero score of the last negative word in the tweet.", "labels": [], "entities": []}, {"text": "We report the performance of SVM by using these lexicon features.", "labels": [], "entities": []}, {"text": "The LIBSVM 3 toolkit is used with a linear kernel and the penalty parameter is set as the default value.", "labels": [], "entities": []}, {"text": "The metric is F 1 score.", "labels": [], "entities": [{"text": "metric", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9632773399353027}, {"text": "F 1 score", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9804068406422933}]}, {"text": "Unsupervised Sentiment Classification Evaluation: For unsupervised sentiment classification, we sum up the scores of all sentiment words in the document, according to the sentiment lexicon.", "labels": [], "entities": [{"text": "Unsupervised Sentiment Classification Evaluation", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6876611262559891}, {"text": "sentiment classification", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.7322486788034439}]}, {"text": "If the sum is greater than 0, the document will be considered as positive, otherwise negative.", "labels": [], "entities": []}, {"text": "The unsupervised learning evaluation metric is accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9990578293800354}]}], "tableCaptions": [{"text": " Table 2: Statistics of Evaluation Datasets", "labels": [], "entities": []}, {"text": " Table 3: Supervised Evaluation for External Comparison (F 1 Score)", "labels": [], "entities": [{"text": "F 1 Score", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9598283569018046}]}, {"text": " Table 4: Unsupervised Evaluation for External Comparison (Accuracy)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9878528118133545}]}, {"text": " Table 5: Supervised Evaluation for Internal Comparison (F 1 Score), where HSSWE (hard) and HSSWE  (soft) utilize the PMI-SO lexicon with hard sentiment annotation and soft sentiment annotation at the  word level, respectively.", "labels": [], "entities": [{"text": "F 1 Score)", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9617129862308502}, {"text": "HSSWE", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.8653953671455383}, {"text": "HSSWE", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.869044840335846}]}, {"text": " Table 6: Unsupervised Evaluation for Internal Comparison (Accuracy)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.98712557554245}]}, {"text": " Table 7: Sentiment Lexicon Analysis, where s- core with (F) means falsely predicted polarity or  strength.", "labels": [], "entities": [{"text": "Sentiment Lexicon Analysis", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.875639279683431}]}]}