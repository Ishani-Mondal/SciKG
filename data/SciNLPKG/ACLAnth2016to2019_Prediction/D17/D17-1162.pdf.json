{"title": [{"text": "Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection", "labels": [], "entities": [{"text": "Finer", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.8647651076316833}, {"text": "Metaphor Detection", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7144441455602646}]}], "abstractContent": [{"text": "The ubiquity of metaphor in our everyday communication makes it an important problem for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.672701100508372}]}, {"text": "Yet, the majority of metaphor processing systems to date rely on hand-engineered features and there is still no consensus in the field as to which features are optimal for this task.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.9131105244159698}]}, {"text": "In this paper, we present the first deep learning architecture designed to capture metaphorical composition.", "labels": [], "entities": []}, {"text": "Our results demonstrate that it outperforms the existing approaches in the metaphor identification task.", "labels": [], "entities": [{"text": "metaphor identification task", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.8861698110898336}]}], "introductionContent": [{"text": "Metaphor is pervasive in our everyday communication, enriching it with sophisticated imagery and helping us to reconcile our experience in the world with our conceptual system.", "labels": [], "entities": []}, {"text": "In the most influential account of metaphor to date, Lakoff and Johnson explain the phenomenon through the presence of systematic metaphorical associations between two distinct concepts or domains.", "labels": [], "entities": []}, {"text": "For instance, when we talk about \"curing juvenile delinquency\" or \"corruption transmitting through the government ranks\", we view the general concept of crime (the target concept) in terms of the properties of a disease (the source concept).", "labels": [], "entities": [{"text": "curing juvenile delinquency", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.818037211894989}]}, {"text": "Such metaphorical associations are broad generalisations that allow us to project knowledge and inferences across domains; and our metaphorical use of language is a reflection of this process.", "labels": [], "entities": []}, {"text": "Given its ubiquity, metaphorical language poses an important problem for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.6710953414440155}]}, {"text": "A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.9473861157894135}]}, {"text": "They experimented with a range of features, including lexical and syntactic information) and higher-level features such as semantic roles), domain types, concreteness), imageability ( and WordNet supersenses ().", "labels": [], "entities": []}, {"text": "While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them.", "labels": [], "entities": []}, {"text": "In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features ( and dense neural word embeddings (.", "labels": [], "entities": []}, {"text": "Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patterns of metaphor usage from linguistic data.", "labels": [], "entities": [{"text": "learn the patterns of metaphor usage from linguistic", "start_pos": 139, "end_pos": 191, "type": "TASK", "confidence": 0.7188273780047894}]}, {"text": "We take this intuition a step further and present the first deep learning architecture designed to capture metaphorical composition.", "labels": [], "entities": []}, {"text": "Deep learning methods have already been shown successful in many other semantic tasks (e.g., which suggests that designing a specialised neural network architecture for metaphor detection will lead to improved performance.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.9050138592720032}]}, {"text": "In this paper, we present a novel architecture which (1) models the interaction between the source and target domains in the metaphor via a gating function; (2) specialises word representations for the metaphor identification task via supervised training; (3) quantifies metaphoricity via a weighted similarity function that automatically selects the relevant dimensions of similarity.", "labels": [], "entities": [{"text": "metaphor identification task", "start_pos": 202, "end_pos": 230, "type": "TASK", "confidence": 0.8048462470372518}]}, {"text": "We experimented with two types of word representations as inputs to the network: the standard skip-gram word embeddings () and the cognitively-driven attribute-based vectors, as well as a combination thereof.", "labels": [], "entities": []}, {"text": "We evaluate our method in the metaphor identification task, focusing on adjective-noun, verbsubject and verb-direct object constructions where the verbs and adjectives can be used metaphorically.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.8220686316490173}]}, {"text": "Our results show that our architecture outperforms both a metaphor agnostic deep learning baseline (a basic feed forward network) and the previous corpus-based approaches to metaphor identification.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 174, "end_pos": 197, "type": "TASK", "confidence": 0.738564595580101}]}, {"text": "We also investigate the effects of training data on this task, and demonstrate that with a sufficiently large training set our method also outperforms the best existing systems based on hand-coded lexical knowledge.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method using two datasets of phrases manually annotated for metaphoricity.", "labels": [], "entities": []}, {"text": "Since these datasets include examples for different senses (both metaphorical and literal) of the same verbs or adjectives, they allow us to test the extent to which our model is able to discriminate between different word senses, as opposed to merely selecting the most frequent class fora given word.  that had between three and ten senses and extracted the sentences exemplifying them in the corresponding glosses, yielding a total of 1639 verb uses in sentences.", "labels": [], "entities": []}, {"text": "Each of these was annotated for metaphoricity by 10 annotators via the crowdsourcing platform CrowdFlower 1 . Mohammad et al. selected the verbs that were tagged by at least 70% of the annotators as metaphorical or literal to create their dataset.", "labels": [], "entities": []}, {"text": "We extracted verb-direct object and verb-subject relations of the annotated verbs from this dataset, discarding the instances with pronominal or clausal subject or object.", "labels": [], "entities": []}, {"text": "This resulted in a dataset of 647 verb-noun pairs (316 metaphorical and 331 literal).", "labels": [], "entities": []}, {"text": "Some examples of annotated verb phrases from MOH are presented in. construct a dataset of adjective-noun pairs annotated for metaphoricity.", "labels": [], "entities": []}, {"text": "This is divided into a training set consisting of 884 literal and 884 metaphorical pairs (TSV-TRAIN) and a test set containing 100 literal and 100 metaphorical pairs (TSV-TEST).", "labels": [], "entities": [{"text": "TSV-TRAIN", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9372438788414001}, {"text": "TSV-TEST", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.6484618186950684}]}, {"text": "shows a portion of annotated adjective-noun phrases from TSV-TEST.", "labels": [], "entities": [{"text": "TSV-TEST", "start_pos": 57, "end_pos": 65, "type": "DATASET", "confidence": 0.8078563213348389}]}, {"text": "TSV-TRAIN was collected from publicly available metaphor collections on the web and manually curated by removing duplicates and metaphorical phrases that depend on wider context for their interpretation (e.g. drowning students).", "labels": [], "entities": []}, {"text": "TSV-TEST was constructed by extracting nouns that co-occur with a list of 1000 frequent adjectives in the TenTen Web Corpus 2 using SketchEngine.", "labels": [], "entities": [{"text": "TSV-TEST", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.6970327496528625}, {"text": "TenTen Web Corpus 2", "start_pos": 106, "end_pos": 125, "type": "DATASET", "confidence": 0.9729926288127899}]}, {"text": "The selected adjective-noun pairs were annotated for metaphoricity by 5 annotators with an interannotator agreement of \u03ba = 0.76.", "labels": [], "entities": [{"text": "interannotator agreement", "start_pos": 91, "end_pos": 115, "type": "METRIC", "confidence": 0.9163819253444672}]}, {"text": "Since TSV-TRAIN and TSV-TEST were constructed differently, we follow previous work and report performance on TSV-TEST.", "labels": [], "entities": [{"text": "TSV-TRAIN", "start_pos": 6, "end_pos": 15, "type": "DATASET", "confidence": 0.7882094383239746}, {"text": "TSV-TEST", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.7989003658294678}, {"text": "TSV-TEST", "start_pos": 109, "end_pos": 117, "type": "DATASET", "confidence": 0.8541357517242432}]}, {"text": "We randomly separated 200 (out of the 1536) examples from the training set to use for development experiments.", "labels": [], "entities": []}, {"text": "The word representations in our model were initialised with either the 100-dimensional skip-gram embeddings or the 2,526-dimensional attribute vectors (Section 4).", "labels": [], "entities": []}, {"text": "These were kept fixed and not updated, which reduces overfitting on the available training examples.", "labels": [], "entities": []}, {"text": "For both word representations we use the same embeddings as, which makes the results directly comparable and shows that the improvements are coming from the novel architecture and are not due to a different embedding initialisation.", "labels": [], "entities": []}, {"text": "The network was optimised using AdaDelta for controlling adaptive learning rates.", "labels": [], "entities": [{"text": "AdaDelta", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9353621006011963}]}, {"text": "The models were evaluated after each full pass over the training data and training was stopped if the F-score on the development set had not improved for 5 epochs.", "labels": [], "entities": [{"text": "F-score", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9985939860343933}]}, {"text": "The transformed embeddings z 1 and z 2 were set to size 300, layer d was set to size 50.", "labels": [], "entities": []}, {"text": "The values for these hyperparameters were chosen experimentally using the development dataset.", "labels": [], "entities": []}, {"text": "In order to avoid drawing conclusions based on outlier results due to random initialisations, we ran each experiment 25 times with random seeds and present the averaged results in this paper.", "labels": [], "entities": []}, {"text": "We implemented the framework using Theano (Al-Rfou et al., 2016) and are making the source code publicly available.", "labels": [], "entities": [{"text": "Theano", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.9567573070526123}]}, {"text": "3 contains results of different system configurations on the TSV dataset.", "labels": [], "entities": [{"text": "TSV dataset", "start_pos": 61, "end_pos": 72, "type": "DATASET", "confidence": 0.9434776604175568}]}, {"text": "The original Fscore by is still the highest, as they used a range of highly-engineered features that require manual annotation, such as: System performance on the Tsvetkov et al. dataset (TSV) in terms of accuracy (Acc), precision (P), recall (R) and F-score (F1).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9378412365913391}, {"text": "accuracy (Acc)", "start_pos": 205, "end_pos": 219, "type": "METRIC", "confidence": 0.9256837964057922}, {"text": "precision (P)", "start_pos": 221, "end_pos": 234, "type": "METRIC", "confidence": 0.9564198553562164}, {"text": "recall (R)", "start_pos": 236, "end_pos": 246, "type": "METRIC", "confidence": 0.9636584520339966}, {"text": "F-score (F1)", "start_pos": 251, "end_pos": 263, "type": "METRIC", "confidence": 0.911415234208107}]}, {"text": "the lexical abstractness, imageability scores and the relative number of supersenses for each word in the dataset.", "labels": [], "entities": []}, {"text": "Our setup is more similar to the linguistic experiments by , where metaphor detection is performed using pretrained word embeddings.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.8128761649131775}]}, {"text": "They also proposed combining the linguistic model with a system using visual word representations and achieved performance improvements.", "labels": [], "entities": []}, {"text": "Recently, compared different types of embeddings and showed that attribute-based representations can outperform regular skip-gram embeddings.", "labels": [], "entities": []}, {"text": "As an additional baseline, we report the performance on metaphor detection using a basic feedforward network (FFN).", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.9477288126945496}]}, {"text": "In this configuration, the word embeddings x 1 and x 2 are directly connected to the hidden layer d, skipping all the intermediate network structure.", "labels": [], "entities": []}, {"text": "The FFN achieves 74.4% F-score on showing that even such a simple model can perform relatively well in a supervised setting.", "labels": [], "entities": [{"text": "FFN", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.5818554162979126}, {"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9997518658638}]}, {"text": "Using attribute vectors instead of skip-gram embeddings gives a slight improvement, especially on the recall metric, which is consistent with the findings by.", "labels": [], "entities": [{"text": "recall metric", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.9764706194400787}]}, {"text": "The architecture described in Section 3, which we refer to as a supervised similarity network (SSN), outperforms the baseline and achieves 80.1% F-score using skip-gram embeddings and 80.6% with attribute-based representations.", "labels": [], "entities": [{"text": "F-score", "start_pos": 145, "end_pos": 152, "type": "METRIC", "confidence": 0.9994648098945618}]}, {"text": "We also created a fusion of these two models where the predictions from both are combined as a weighted average.", "labels": [], "entities": []}, {"text": "In this setting, the two networks are trained in tandem and a real-valued weight, which is also optimised during training, is by 5.6% absolute, using the same word representations as input.", "labels": [], "entities": []}, {"text": "contains results of different system architectures on the MOH dataset.", "labels": [], "entities": [{"text": "MOH dataset", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.9486570954322815}]}, {"text": "reported 75% F-score on this dataset with a multimodal system, after randomly separating a subset for testing.", "labels": [], "entities": [{"text": "F-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9995414018630981}]}, {"text": "Since this corpus contains only 647 annotated examples, we instead evaluated the systems using 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "The feedforward baseline with skip-gram embeddings returns an F-score that is close to the linguistic configuration of Shutova et al, whereas the best results are achieved by the similarity network with skip-gram embeddings.", "labels": [], "entities": [{"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9990202188491821}]}, {"text": "In this setting, the attribute-based representations did not improve performance -this is expected, as the attribute norms by are designed for nouns, whereas the MOH dataset is centered on verbs.", "labels": [], "entities": [{"text": "MOH dataset", "start_pos": 162, "end_pos": 173, "type": "DATASET", "confidence": 0.8493377566337585}]}, {"text": "contains examples from the TSV development set, together with gold annotations and predicted scores.", "labels": [], "entities": [{"text": "TSV development set", "start_pos": 27, "end_pos": 46, "type": "DATASET", "confidence": 0.8660169243812561}]}, {"text": "The system confidently detects literal phrases such as sunny country and meaningless discussion, along with metaphorical phrases such as unforgiving heights and blind hope.", "labels": [], "entities": []}, {"text": "The predicted output disagrees with the annotation on: Examples from the Tsvetkov development set, together with the gold label, predicted label, and the predicted score from the best model.", "labels": [], "entities": [{"text": "Tsvetkov development set", "start_pos": 73, "end_pos": 97, "type": "DATASET", "confidence": 0.6971019705136617}]}, {"text": "cases such as humane treatment and rich programmer -some of these examples could also be argued as being metaphorical, depending on the specific sense of the words.", "labels": [], "entities": []}, {"text": "While the system was relatively unsure about the false positives (the scores were close to 0.5), it tended to assign more decisive scores to the false negatives.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: System performance on the Tsvetkov et  al. dataset (TSV) in terms of accuracy (Acc), pre- cision (P), recall (R) and F-score (F1).", "labels": [], "entities": [{"text": "Tsvetkov et  al. dataset (TSV)", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.7661678663321904}, {"text": "accuracy (Acc)", "start_pos": 79, "end_pos": 93, "type": "METRIC", "confidence": 0.9099427163600922}, {"text": "pre- cision (P)", "start_pos": 95, "end_pos": 110, "type": "METRIC", "confidence": 0.9513809780279795}, {"text": "recall (R)", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9565218091011047}, {"text": "F-score (F1)", "start_pos": 127, "end_pos": 139, "type": "METRIC", "confidence": 0.9044059962034225}]}, {"text": " Table 4: System performance on the Mohammad  et al. dataset (MOH) in terms of accuracy (Acc),  precision (P), recall (R) and F-score (F1).", "labels": [], "entities": [{"text": "Mohammad  et al. dataset (MOH)", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.772218895809991}, {"text": "accuracy (Acc)", "start_pos": 79, "end_pos": 93, "type": "METRIC", "confidence": 0.9009482860565186}, {"text": "precision (P)", "start_pos": 96, "end_pos": 109, "type": "METRIC", "confidence": 0.9595458507537842}, {"text": "recall (R)", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9608639031648636}, {"text": "F-score (F1)", "start_pos": 126, "end_pos": 138, "type": "METRIC", "confidence": 0.9227629899978638}]}, {"text": " Table 5: Examples from the Tsvetkov develop- ment set, together with the gold label, predicted  label, and the predicted score from the best model.", "labels": [], "entities": []}, {"text": " Table 6: System performance on the Tsvetkov et  al. dataset (TSV), using additional training data.", "labels": [], "entities": [{"text": "Tsvetkov et  al. dataset (TSV)", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.7430040793759483}]}]}