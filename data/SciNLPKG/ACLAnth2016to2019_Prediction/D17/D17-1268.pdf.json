{"title": [{"text": "Learning Language Representations for Typology Prediction", "labels": [], "entities": [{"text": "Learning Language Representations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5952848295370737}, {"text": "Prediction", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.5302426218986511}]}], "abstractContent": [{"text": "One central mystery of neural NLP is what neural models \"know\" about their subject matter.", "labels": [], "entities": []}, {"text": "When a neural machine translation system learns to translate from one language to another, does it learn the syntax or semantics of the languages?", "labels": [], "entities": []}, {"text": "Can this knowledge be extracted from the system to fill holes inhuman scientific knowl-edge?", "labels": [], "entities": []}, {"text": "Existing typological databases contain relatively full feature specifications for only a few hundred languages.", "labels": [], "entities": []}, {"text": "Exploiting the existence of parallel texts in more than a thousand languages, we build a massive many-to-one neural machine translation (NMT) system from 1017 languages into English, and use this to predict information missing from typological databases.", "labels": [], "entities": []}, {"text": "Experiments show that the proposed method is able to infer not only syntactic , but also phonological and phonetic inventory features, and improves over a baseline that has access to information about the languages' geographic and phy-logenetic neighbors.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic typology is the classification of human languages according to syntactic, phonological, and other classes of features, and the investigation of the relationships and correlations between these classes/features.", "labels": [], "entities": []}, {"text": "This study has been a scientific pursuit in its own right since the 19th century, but recently typology has borne practical fruit within various subfields of NLP, particularly on problems involving lower-resource languages., has proven useful in many NLP tasks, such as multilingual dependency parsing, generative parsing in low-resource settings, phonological language modeling and loanword prediction, POStagging (, and machine translation (.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 270, "end_pos": 301, "type": "TASK", "confidence": 0.6891469955444336}, {"text": "generative parsing", "start_pos": 303, "end_pos": 321, "type": "TASK", "confidence": 0.9522966742515564}, {"text": "phonological language modeling", "start_pos": 348, "end_pos": 378, "type": "TASK", "confidence": 0.6628882984320322}, {"text": "loanword prediction", "start_pos": 383, "end_pos": 402, "type": "TASK", "confidence": 0.7751492261886597}, {"text": "machine translation", "start_pos": 422, "end_pos": 441, "type": "TASK", "confidence": 0.8059020936489105}]}, {"text": "However, the needs of NLP tasks differ in many ways from the needs of scientific typology, and typological databases are often only sparsely populated, by necessity or by design.", "labels": [], "entities": []}, {"text": "In NLP, on the other hand, what is important is having a relatively full set of features for the particular group of languages you are working on.", "labels": [], "entities": []}, {"text": "This mismatch of needs has motivated various proposals to reconstruct missing entries, in WALS and other databases, from known entries.", "labels": [], "entities": []}, {"text": "In this study, we examine whether we can tackle the problem of inferring linguistic typology from parallel corpora, specifically by training a massively multi-lingual neural machine translation (NMT) system and using the learned representations to infer typological features for each language.", "labels": [], "entities": [{"text": "multi-lingual neural machine translation (NMT)", "start_pos": 153, "end_pos": 199, "type": "TASK", "confidence": 0.8182928306715829}]}, {"text": "This is motivated both by prior work in linguistics) demonstrating strong links between translation studies and tools for contrastive linguistic analysis, work in inferring typology from bilingual data and English as Second Language texts), as well as work in NLP ( showing that syntactic knowledge can be extracted from neural nets on the word-by-word or sentence-by-sentence level.", "labels": [], "entities": [{"text": "contrastive linguistic analysis", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.7067421078681946}]}, {"text": "This work presents a more holistic analysis of whether we can discover what neural networks learn about the linguistic concepts of an entire language by aggregating their representations over a large number of the sentences in the language.", "labels": [], "entities": []}, {"text": "We examine several methods for discovering feature vectors for typology prediction, including those learning a language vector specifying the language while training multilingual neural language models) or neural machine translation systems.", "labels": [], "entities": [{"text": "typology prediction", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7615098357200623}, {"text": "neural machine translation", "start_pos": 206, "end_pos": 232, "type": "TASK", "confidence": 0.6880155404408773}]}, {"text": "We further propose a novel method for aggregating the values of the latent state of the encoder neural network to a single vector representing the entire language.", "labels": [], "entities": []}, {"text": "We calculate these feature vectors using an NMT model trained on 1017 languages, and use them for typlogy prediction both on their own and in composite with feature vectors from previous work based on the genetic and geographic distance between languages (.", "labels": [], "entities": [{"text": "typlogy prediction", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7855866551399231}]}, {"text": "Results show that the extracted representations do in fact allow us to learn about the typology of languages, with particular gains for syntactic features like word order and the presence of case markers.", "labels": [], "entities": []}], "datasetContent": [{"text": "Typology Database: To perform our analysis, we use the URIEL language typology database (, which is a collection of binary features extracted from multiple typological, phylogenetic, and geographical databases such as WALS (World Atlas of Language Structures) (), PHOIBLE), Ethnologue (, and).", "labels": [], "entities": [{"text": "URIEL language typology database", "start_pos": 55, "end_pos": 87, "type": "DATASET", "confidence": 0.8216813653707504}, {"text": "PHOIBLE", "start_pos": 264, "end_pos": 271, "type": "DATASET", "confidence": 0.6915492415428162}, {"text": "Ethnologue", "start_pos": 274, "end_pos": 284, "type": "DATASET", "confidence": 0.8405978679656982}]}, {"text": "These features are divided into separate classes regarding syntax (e.g. whether a language has prepositions or postpositions), phonology (e.g. whether a language has complex syllabic onset clusters), and phonetic inventory (e.g. whether a language has interdental fricatives).", "labels": [], "entities": []}, {"text": "There are 103 syntactical features, 28 phonology features and 158 phonetic inventory features in the database.", "labels": [], "entities": []}, {"text": "Baseline Feature Vectors: Several previous methods take advantage of typological implicature, the fact that some typological traits correlate strongly with others, to use known features of a language to help infer other unknown features of the language.", "labels": [], "entities": [{"text": "Baseline Feature Vectors", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5512109895547231}]}, {"text": "As an alternative that does not necessarily require pre-existing knowledge of the typological features in the language at hand, have proposed a method for inferring typological features directly from the language's k nearest neighbors (k-NN) according to geodesic distance (distance on the Earth's surface) and genetic distance (distance according to a phylogenetic family tree).", "labels": [], "entities": [{"text": "genetic distance", "start_pos": 311, "end_pos": 327, "type": "METRIC", "confidence": 0.952135294675827}]}, {"text": "In our experiments, our baseline uses this method by taking the 3-NN for each language according to normalized geodesic+genetic distance, and calculating an average feature vector of these three neighbors.", "labels": [], "entities": []}, {"text": "Typology Prediction: To perform prediction, we trained a logistic regression classifier 3 with the baseline k-NN feature vectors described above and the proposed NMT feature vectors described in the next section.", "labels": [], "entities": [{"text": "Typology Prediction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6640792191028595}, {"text": "prediction", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.9739090800285339}]}, {"text": "We train individual classifiers for predicting each typological feature in a class (syntax etc).", "labels": [], "entities": []}, {"text": "We performed 10-fold crossvalidation over the URIEL database, where we train on 9/10 of the languages to predict 1/10 of the languages for 10 folds over the data.", "labels": [], "entities": [{"text": "URIEL database", "start_pos": 46, "end_pos": 60, "type": "DATASET", "confidence": 0.9357401728630066}]}], "tableCaptions": [{"text": " Table 2: Top 5 improvements from \"NONE -Aux\"  to \"MTBOTH -Aux\" in the syntax (\"S \"), phonol- ogy (\"P \"), and inventory (\"I \") classes.", "labels": [], "entities": []}]}