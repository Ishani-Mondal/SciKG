{"title": [{"text": "Inducing Semantic Micro-Clusters from Deep Multi-View Representations of Novels", "labels": [], "entities": []}], "abstractContent": [{"text": "Automatically understanding the plot of novels is important both for informing literary scholarship and applications such as summarization or recommendation.", "labels": [], "entities": [{"text": "Automatically understanding the plot of novels", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.720400889714559}, {"text": "summarization or recommendation", "start_pos": 125, "end_pos": 156, "type": "TASK", "confidence": 0.7061187028884888}]}, {"text": "Various models have addressed this task, but their evaluation has remained largely intrinsic and qualitative.", "labels": [], "entities": []}, {"text": "Here, we propose a principled and scalable framework leveraging expert-provided semantic tags (e.g., mystery, pirates) to evaluate plot representations in an extrinsic fashion, assessing their ability to produce locally coherent groupings of novels (micro-clusters) in model space.", "labels": [], "entities": []}, {"text": "We present a deep recurrent autoencoder model that learns richly structured multi-view plot representations, and show that they i) yield better micro-clusters than less structured representations ; and ii) are interpretable, and thus useful for further literary analysis or labelling of the emerging micro-clusters.", "labels": [], "entities": [{"text": "literary analysis", "start_pos": 253, "end_pos": 270, "type": "TASK", "confidence": 0.6919111162424088}]}], "introductionContent": [{"text": "For the literature aficionado, the quest for the next novel to read can be daunting: the sheer number of novels of different styles, topics and genres is difficult to navigate.", "labels": [], "entities": []}, {"text": "It is intuitively clear that readers select novels based on specific but potentially diverse and structured preferences (e.g., they might prefer novels of a particular theme (small-town romance), mood (dark) or based on character types (grumpy boss), character relations (love, enmity) and their development).", "labels": [], "entities": []}, {"text": "These preferences also manifest in the organization of online book stores or recommendation platforms.", "labels": [], "entities": []}, {"text": "For example, the Amazon book catalog contains semantic tags provided by experts (publishers), including labels of character types (pirates) or theme (secret baby romance) to aid focused search for novels of interest.", "labels": [], "entities": [{"text": "Amazon book catalog", "start_pos": 17, "end_pos": 36, "type": "DATASET", "confidence": 0.902294913927714}]}, {"text": "Although these tags are already fairly granular, many cover large sets of novels (e.g., the tag secret baby romance covers almost 4, 000 novels), limiting their utility for exhaustive exploration and call for even finer grained micro-groupings.", "labels": [], "entities": []}, {"text": "Can we instead automatically induce fine-grained novel clusters in an unsupervised, data-driven way?", "labels": [], "entities": []}, {"text": "We propose a framework to learn structured, interpretable book representations that capture different aspects of the plot, and verify that such representations are rich enough to support downstream tasks like generating interpretable book groupings.", "labels": [], "entities": []}, {"text": "A real-world application of this work is content-based book recommendation based on diverse and interpretable book characteristics.", "labels": [], "entities": []}, {"text": "Content-based recommendation has been criticized by the limited complexity of typically employed features (limited content analysis;;).", "labels": [], "entities": [{"text": "Content-based recommendation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6646775156259537}]}, {"text": "This work addresses this problem by inducing complex, structured and interpretable representations.", "labels": [], "entities": []}, {"text": "First, assuming that richly structured book tags call for rich content representations (which expert taggers arguably possess), we describe a deep unsupervised model for learning multi-view representations of novel plots.", "labels": [], "entities": []}, {"text": "We use the term view to refer to specific types of plot characteristics (e.g., pertaining to events, characters or mood), and multi-view to refer to combinations of these views.", "labels": [], "entities": []}, {"text": "We use multi-view book representations to construct meaningful and locally coherent neighbourhoods in model space, which we will refer to as micro-clusters.", "labels": [], "entities": []}, {"text": "To this end, we extend a recent autoencoder model) to learn multi-view representations of books.", "labels": [], "entities": []}, {"text": "Our model encodes properties of characters (view v 1 ), relations between characters (view v 2 ), and their respective trajectories over the plot.", "labels": [], "entities": []}, {"text": "View-specific encodings are learnt in an unsupervised way from raw text as separate sets of word clusters which are jointly optimized to encode relevant and distinct information.", "labels": [], "entities": []}, {"text": "These properties are crucial for applications such as book recommendation, because they allow to i) explain why particular books are similar based on the inferred latent structure and ii) find similarities based on important and distinct aspects of a novel (character types or interactions).", "labels": [], "entities": [{"text": "book recommendation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7557704448699951}]}, {"text": "Our framework of unsupervised multi-view learning is very flexible and can straightforwardly be applied to learn arbitrary kinds and numbers of views from raw text.", "labels": [], "entities": []}, {"text": "Secondly, we propose an empirical evaluation framework.", "labels": [], "entities": []}, {"text": "Before we can use models to extend existing categories as discussed above, it must be shown that the representations capture existing associations.", "labels": [], "entities": []}, {"text": "To this end, we investigate whether micro-clusters derived from induced representations resemble reference clusters defined as groups of novels sharing tags in the Amazon catalog.", "labels": [], "entities": []}, {"text": "While automatic induction of plot representations has attracted considerable attention (see), evaluation has remained largely qualitative and intrinsic.", "labels": [], "entities": [{"text": "automatic induction of plot representations", "start_pos": 6, "end_pos": 49, "type": "TASK", "confidence": 0.762674880027771}]}, {"text": "To the best of our knowledge, we are the first to investigate the utility of automatically induced plot representations on an extrinsic task at scale.", "labels": [], "entities": []}, {"text": "We evaluate micro-clusters as local neighbourhoods in model space containing 10, 000 novels under 50 reference tags.", "labels": [], "entities": []}, {"text": "We show that rich multi-view representations produce better micro-clusters compared to competitive but simpler models, and that interpretability of the learnt representations is not compromised despite the more complex objective.", "labels": [], "entities": []}, {"text": "We also qualitatively demonstrate that high-quality micro-clusters emerge from a smaller, more homogeneous data set of Gutenberg 3 novels.", "labels": [], "entities": []}], "datasetContent": [{"text": "MVPlot induces structured representations of a novel b as relation trajectories between characters pairs in b, and property trajectories of individual characters in b.", "labels": [], "entities": []}, {"text": "Are those representations rich and informative enough to produce meaningful and interpretable micro-clusters of novels?", "labels": [], "entities": []}, {"text": "In Section 6.1 we evaluate the quality of such micro-clusters, i.e., local novel neighbourhoods in model space.", "labels": [], "entities": []}, {"text": "We propose an objective and empirical evaluation employing expert-provided semantic novel tags in the Amazon catalog.", "labels": [], "entities": [{"text": "Amazon catalog", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.9571472704410553}]}, {"text": "Novels listed in the Amazon catalog are tagged with respect to their genre (e.g., mystery, romance).", "labels": [], "entities": []}, {"text": "They are further labelled with refinements pertaining to diverse information like character types or mood, which take different sets of values, depending on the genre, and are as such predestined as an objective reference for evaluating the diverse information captured by our model.", "labels": [], "entities": []}, {"text": "lists example tags for the refinement character type.", "labels": [], "entities": []}, {"text": "All tags are provided by publishers and can consequently betaken as a reliable source of information.", "labels": [], "entities": []}, {"text": "In our evaluation we assume that novels which share a tag are related to each other.", "labels": [], "entities": []}, {"text": "We use this tag-overlap metric to evaluate local neighbourhoods of book representations in model space.: The number of novels and property (v 1 ) relation (v 2 ) input sequences for the Gutenberg and the Amazon corpus.", "labels": [], "entities": []}, {"text": "We selected a set of 50 representative tags from the Amazon catalog and did not tune this set for our evaluation.", "labels": [], "entities": [{"text": "Amazon catalog", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.8825601637363434}]}, {"text": "The full tag set is included in the supplementary material.", "labels": [], "entities": []}, {"text": "Note that while this scheme provides an empirical way of evaluating plot representations, it may not capture their full potential: our models are not explicitly tuned towards producing microclusters which are coherent with respect to our gold-standard tags, and may encode additional structure which is not probed in this evaluation.", "labels": [], "entities": []}, {"text": "That said, we consider this evaluation as a good procedure to evaluate the relative quality of different models in the sense that a better model should produce micro-clusters that better correspond to reference clusters derived from gold-standard tags.", "labels": [], "entities": []}, {"text": "Section 6.1 quantitatively evaluates the quality of local neighbourhoods in model space induced from the Amazon corpus against our proposed gold-standard.", "labels": [], "entities": [{"text": "Amazon corpus", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.7743447721004486}]}, {"text": "Section 6.2 evaluates the quality of the induced descriptors from both the Amazon and Gutenberg corpus both through crowd sourcing and illustrative examples.", "labels": [], "entities": [{"text": "Amazon and Gutenberg corpus", "start_pos": 75, "end_pos": 102, "type": "DATASET", "confidence": 0.6931987851858139}]}, {"text": "Models We set the MVPlot performance into perspective comparing it against the RMN.", "labels": [], "entities": [{"text": "RMN", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.8789052367210388}]}, {"text": "6 MVPlot induces both character properties and relations, and is trained on both the relation-view and property-view input, while the RMN only induces pair relationships and can only utilize relationview input.", "labels": [], "entities": []}, {"text": "In addition, we report a frequency baseline, which is trained on both property and relation-view input.", "labels": [], "entities": []}, {"text": "We concatenate all input spans of a given view fora particular novel; construct its term frequency vector and use cosine similarity to compute the nearest neighbours to each novel.", "labels": [], "entities": []}, {"text": "Parameter settings Across all experiments and corpus-specific models, we set \u03b2=0.99 for MVPlot, and for both MVPlot and RMN we set \u03b1=0.5, \u03bb=10 \u22125 , k=50.", "labels": [], "entities": [{"text": "Parameter", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9620829224586487}]}, {"text": "We train both RMN and MVPlot for 15 epochs using SGD and ADAM).", "labels": [], "entities": [{"text": "RMN", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.7711741924285889}, {"text": "MVPlot", "start_pos": 22, "end_pos": 28, "type": "DATASET", "confidence": 0.839231550693512}]}, {"text": "We evaluate local neighbourhoods in model space using the 500 most popular novels by their number of Amazon reviews as reference novels from the Amazon corpus.", "labels": [], "entities": [{"text": "Amazon corpus", "start_pos": 145, "end_pos": 158, "type": "DATASET", "confidence": 0.8250139951705933}]}, {"text": "For each reference novel we compute the 10 nearest neighbours as described below.", "labels": [], "entities": []}, {"text": "We measure neighbourhood quality using the gold-standard tags from Section 4, regarding neighbours as relevant if at least one tag is shared with the reference novel.", "labels": [], "entities": []}, {"text": "We report precision at rank 10 (P @10) and mean average precision (M AP ).", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9987167119979858}, {"text": "mean average precision (M AP )", "start_pos": 43, "end_pos": 73, "type": "METRIC", "confidence": 0.9057965704372951}]}, {"text": "Method MVPlot represents a book bin terms of trajectories of weight vectors over relation descriptors Tb v2 and property descriptors Tb v1 . RMN only learns relation descriptors and their trajectories.", "labels": [], "entities": []}, {"text": "For both models, we map each induced trajectory for book b to a fixed-sized kdimensional vector representation by averaging the time-specific weight vectors, for example fora v 2 trajectory, and equivalently for v 1 trajectories, T c,b v1 . We compute the similarity between two books {b r , b c } as follows.", "labels": [], "entities": []}, {"text": "We align the v 2 trajectory for each character pair {c 1 , c 2 } in b r , Tc 1 ,c 2 ,br , to its closest neighbouring character pair vector in b c , Tc 1 ,c 2 ,bc , by Euclidean distance, and compute the overall book similarity in terms of character relations between b rand b c as the average overall distances.", "labels": [], "entities": []}, {"text": "We obtain sim br,bc v1 in an analogous process.", "labels": [], "entities": []}, {"text": "For cosine and MVPlot we obtain a final, multi-view similarity by averaging similarity scores obtained in each view's space, For RMN we compute similarity only in character relation space.", "labels": [], "entities": []}, {"text": "Results presents micro-cluster quality in terms of precision@10 and M AP . The full MVPlot model statistically significantly outperfoms all other models.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9975774884223938}, {"text": "M AP", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.7049855887889862}]}, {"text": "The same pattern emerges Also, intra-view comparisons except for MVPlot v1 and cosine v1 are statistically significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The number of novels and property (v 1 )  relation (v 2 ) input sequences for the Gutenberg  and the Amazon corpus.", "labels": [], "entities": []}]}