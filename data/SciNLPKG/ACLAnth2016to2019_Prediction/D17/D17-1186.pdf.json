{"title": [{"text": "Incorporating Relation Paths in Neural Relation Extraction", "labels": [], "entities": [{"text": "Neural Relation Extraction", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7802173495292664}]}], "abstractContent": [{"text": "Distantly supervised relation extraction has been widely used to find novel rela-tional facts from plain text.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.6850648671388626}]}, {"text": "To predict the relation between a pair of two target entities, existing methods solely rely on those direct sentences containing both entities.", "labels": [], "entities": []}, {"text": "In fact, there are also many sentences containing only one of the target entities, which also provide rich useful information but not yet employed by relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8893856108188629}]}, {"text": "To address this issue, we build inference chains between two target entities via intermediate entities, and propose a path-based neural relation extraction model to encode the relational semantics from both direct sentences and inference chains.", "labels": [], "entities": [{"text": "path-based neural relation extraction", "start_pos": 118, "end_pos": 155, "type": "TASK", "confidence": 0.7075863629579544}]}, {"text": "Experimental results on real-world datasets show that, our model can make full use of those sentences containing only one target entity, and achieves significant and consistent improvements on relation extraction as compared with strong baselines.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.8064814209938049}]}, {"text": "The source code of this paper can be obtained from https:// github.com/thunlp/PathNRE.", "labels": [], "entities": [{"text": "PathNRE", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9089873433113098}]}], "introductionContent": [{"text": "Knowledge Bases (KBs) provide effective structured information for real world facts and have been used as crucial resources for several natural language processing (NLP) applications such as Web search and question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.932793527841568}]}, {"text": "Typical KBs such as Freebase (, DBpedia ( and usually describe knowledge as multirelational data and represent them as triple facts.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.9696782231330872}, {"text": "DBpedia", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.9273775219917297}]}, {"text": "As the real-world facts are infinite and increasing * * Corresponding author: Z.", "labels": [], "entities": []}, {"text": "Liu (liuzy@tsinghua.edu.cn).", "labels": [], "entities": []}, {"text": "everyday, existing KBs are still far from complete.", "labels": [], "entities": []}, {"text": "Recently, petabytes of natural-language text containing thousands of different structure types are readily available, which is an important resource for automatically finding unknown relational facts.", "labels": [], "entities": []}, {"text": "Hence, relation extraction (RE), defined as the task of extracting structured information from plain text, has attracted much interest.", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 7, "end_pos": 31, "type": "TASK", "confidence": 0.9314522385597229}]}, {"text": "Most existing supervised RE systems usually suffer from the issue that lacks sufficient labelled relation-specific training data.", "labels": [], "entities": [{"text": "RE", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9517353773117065}]}, {"text": "Manual annotation is very time consuming and labor intensive.", "labels": [], "entities": [{"text": "Manual annotation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6929081082344055}]}, {"text": "One promising approach to address this limitation is distant supervision.", "labels": [], "entities": []}, {"text": "() generates training data automatically by aligning a KB with plain text.", "labels": [], "entities": []}, {"text": "They assume that if two target entities have a relation in KB, then all sentences that contain these two entities will express this relation and can be regarded as a positive training instance.", "labels": [], "entities": []}, {"text": "Since neural models have been verified to be effective for classifying relations from plain text,) incorporate neural networks method with distant supervision relation extraction.", "labels": [], "entities": [{"text": "classifying relations from plain text", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.8283190131187439}, {"text": "distant supervision relation extraction", "start_pos": 139, "end_pos": 178, "type": "TASK", "confidence": 0.5774693116545677}]}, {"text": "Further, () considers finer-grained information, and achieves the state-of-the-art performance.", "labels": [], "entities": []}, {"text": "Although existing RE systems have achieved promising results with the help of distant supervision and neural models, they still suffer from a major drawback: the models only learn from those sentences contain both two target entities.", "labels": [], "entities": [{"text": "RE", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9734547138214111}]}, {"text": "However, those sentences containing only one of the entities could also provide useful information and help build inference chains.", "labels": [], "entities": []}, {"text": "For example, if we know that \"h is the father of e\" and \"e is the father of t\", we can infer that h is the grandfather oft.", "labels": [], "entities": []}, {"text": "In this work, as illustrated in, we introduce a path-based neural relation extraction model  with relation paths.", "labels": [], "entities": [{"text": "path-based neural relation extraction", "start_pos": 48, "end_pos": 85, "type": "TASK", "confidence": 0.6786323264241219}]}, {"text": "First, we employ convolutional neural networks (CNN) to embed the semantics of sentences.", "labels": [], "entities": []}, {"text": "Afterward, we build a relation path encoder, which measures the probability of relations given an inference chain in the text.", "labels": [], "entities": []}, {"text": "Finally, we combine information from direct sentences and relation paths to predict the relation.", "labels": [], "entities": []}, {"text": "We evaluate our model on a real-world dataset for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.92437744140625}]}, {"text": "The experimental results show that our model achieves significant and consistent improvements as compared with baselines.", "labels": [], "entities": []}, {"text": "Besides, with the help of those sentences containing one of the target entities, our model is more robust and performs well even when the number of noisy instances increases.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first effort to consider the information of relation path in plain text for neural relation extraction.", "labels": [], "entities": [{"text": "neural relation extraction", "start_pos": 118, "end_pos": 144, "type": "TASK", "confidence": 0.6193048556645712}]}], "datasetContent": [{"text": "We build a novel dataset for evaluating relation extraction task.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8635280728340149}]}, {"text": "We first describe the most commonly used previous dataset and then explain the reason and how we construct the new dataset.", "labels": [], "entities": []}, {"text": "A commonly used benchmark dataset for this task was developed by (.", "labels": [], "entities": []}, {"text": "This dataset was built by aligning Freebase Snapshot) with New York Times corpus (NYT).", "labels": [], "entities": [{"text": "New York Times corpus (NYT)", "start_pos": 59, "end_pos": 86, "type": "DATASET", "confidence": 0.8205982361521039}]}, {"text": "There are 53 possible relationships between two entities, including a special relation type NA, meaning that there is no relation between head and tail entities.", "labels": [], "entities": []}, {"text": "For each relational fact in a filtered Freebase dataset, a sentence from NYT would be regarded as a mention of this relation if both the head and tail entity appear in that sentence.", "labels": [], "entities": [{"text": "Freebase dataset", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.9304896295070648}, {"text": "NYT", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.9371762871742249}]}, {"text": "While this previous dataset has been frequently used for evaluating relation extraction systems, we observe some limitations of it.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8117441833019257}]}, {"text": "First, the relational facts are extracted from a 2009 snapshot of Freebase.", "labels": [], "entities": [{"text": "2009 snapshot of Freebase", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.7079875245690346}]}, {"text": "Therefore, this dataset is too old to contain many updated facts.", "labels": [], "entities": []}, {"text": "This will underestimate the performance of a relation extraction system, since some real-world facts are missing from the dataset and labeled as NA.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.8599406182765961}]}, {"text": "Second, the relational facts in this dataset are scattered, i.e. there are not sufficient relation paths in this dataset, while relational facts in real-world always have connections with each other.", "labels": [], "entities": []}, {"text": "Third, Freebase will no longer update after 2016.These limitations mean that this dataset is somewhat improper for evaluating RE systems.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.9712586998939514}]}, {"text": "Although other relation extraction datasets exist, e.g. ACE 1 and (, they are too small to train an effective neural relation extraction model.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7642852067947388}, {"text": "ACE 1", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.8346539735794067}, {"text": "relation extraction", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7227783501148224}]}, {"text": "Moreover, each relational fact in () only corresponds with one sentence, which prevents it from evaluating multi-instance relation extraction systems.", "labels": [], "entities": [{"text": "multi-instance relation extraction", "start_pos": 107, "end_pos": 141, "type": "TASK", "confidence": 0.667553037405014}]}, {"text": "Hence, we constructed a novel relation extraction dataset to address these issues, and will make it available to the community.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7997791767120361}]}, {"text": "Our dataset contains more updated facts and richer structures of relations, e.g. more relations / relation paths, as compared to existing similar datasets.", "labels": [], "entities": []}, {"text": "The dataset is expected to be more similar to real-world cases, and thus be more appropriate for evaluating RE systems' performances.", "labels": [], "entities": [{"text": "RE", "start_pos": 108, "end_pos": 110, "type": "TASK", "confidence": 0.9763756990432739}]}, {"text": "We build the dataset by aligning Wikidata 2 re-lations with the New York Times Corpus (NYT).", "labels": [], "entities": [{"text": "New York Times Corpus (NYT)", "start_pos": 64, "end_pos": 91, "type": "DATASET", "confidence": 0.7785022173609052}]}, {"text": "Wikidata is a large, growing knowledge base, which contains more than 80 million triple facts and 20 million entities.", "labels": [], "entities": [{"text": "Wikidata", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8875696659088135}]}, {"text": "Different from Freebase, Wikidata is still in maintenance and could be easily accessed by APIs.", "labels": [], "entities": []}, {"text": "We first pick those entities simultaneously appeared in both Wikidata and Freebase, and relational facts associated with them.", "labels": [], "entities": []}, {"text": "Then, we filtered out a subset S, reserving those facts associating with the 99 highest frequency relations.", "labels": [], "entities": []}, {"text": "This results in 4, 574, 665 triples with 1, 045, 385 entities and 99 relations.", "labels": [], "entities": []}, {"text": "Next, we align those facts with NYT corpus, following the assumption of distant supervision.", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.9501651227474213}]}, {"text": "For each pair of entities appearing in our S, we traverse the corpus and pick those sentences where both entities appear.", "labels": [], "entities": []}, {"text": "These sentences will be regarded as mentions of this fact, and labeled by this relation type.", "labels": [], "entities": []}, {"text": "To simulate noise in the real world, we also add sentences corresponding to \"No Relation\" entity pairs into our dataset.", "labels": [], "entities": []}, {"text": "To get those \"No Relation\" instances, we first create a fake knowledge base S \u2212 by randomly replacing the head or tail entities in triples, i.e., S \u2212 = {(h , r, t)}\u222a{(h, r, t )} and then align them with NYT corpus.", "labels": [], "entities": [{"text": "No Relation\"", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.755275696516037}, {"text": "NYT corpus", "start_pos": 203, "end_pos": 213, "type": "DATASET", "confidence": 0.9858160614967346}]}, {"text": "Finally, we randomly split all those selected sentences into training, validation and testing set, assuring that a relational fact could be only mentioned by sentences in one set.", "labels": [], "entities": []}, {"text": "The statistics of our dataset and ( are listed in.", "labels": [], "entities": []}, {"text": "Following the previous work, we evaluate our model by extracting relational facts from the sentences in test set, and compare them with those in Wikidata.", "labels": [], "entities": []}, {"text": "We report Precision/Recall curves, Precision@N (P@N) and F1 scores for comparison in our experiments.", "labels": [], "entities": [{"text": "Precision/Recall curves", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.8168815225362778}, {"text": "Precision@N (P@N)", "start_pos": 35, "end_pos": 52, "type": "METRIC", "confidence": 0.9064611047506332}, {"text": "F1", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9940913319587708}]}], "tableCaptions": [{"text": " Table 1: Statistics of datasets.", "labels": [], "entities": []}, {"text": " Table 2: P@N and F1 for relation extraction in texts containing different percentage of no-relation facts.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9988662004470825}, {"text": "relation extraction", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.901418149471283}]}, {"text": " Table 3: F1 score for long tail situation.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9685458838939667}]}, {"text": " Table 5: Accuracy of different models in zero-shot  situation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9963181018829346}]}]}