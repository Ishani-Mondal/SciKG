{"title": [{"text": "Labeling Gaps Between Words: Recognizing Overlapping Mentions with Mention Separators", "labels": [], "entities": [{"text": "Labeling Gaps Between Words", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.919857531785965}, {"text": "Recognizing Overlapping Mentions with Mention Separators", "start_pos": 29, "end_pos": 85, "type": "TASK", "confidence": 0.7514211187760035}]}], "abstractContent": [{"text": "In this paper, we propose anew model that is capable of recognizing overlapping mentions.", "labels": [], "entities": []}, {"text": "We introduce a novel notion of mention separators that can be effectively used to capture how mentions overlap with one another.", "labels": [], "entities": []}, {"text": "On top of a novel multigraph representation that we introduce, we show that efficient and exact inference can still be performed.", "labels": [], "entities": []}, {"text": "We present some theoretical analysis on the differences between our model and a recently proposed model for recognizing overlapping mentions, and discuss the possible implications of the differences.", "labels": [], "entities": []}, {"text": "Through extensive empirical analysis on standard datasets, we demonstrate the effectiveness of our approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entity recognition (NER), or in general the task of recognizing entity mentions 1 in a text, has been a research topic for many years.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8103597561518351}]}, {"text": "However, as noted by, many previous works ignored overlapping mentions, although they are quite common.", "labels": [], "entities": []}, {"text": "illustrates some examples of overlapping mentions adapted from existing datasets.", "labels": [], "entities": []}, {"text": "For example, the location mention Pennsylvania appears within the mention of type organization a Pennsylvania radio station.", "labels": [], "entities": []}, {"text": "In practice, overlapping mentions have been found in many existing datasets across different domains ().", "labels": [], "entities": []}, {"text": "Developing algorithms that can effectively and efficiently extract overlapping mentions can be crucial for the At issue is the liability of a Pennsylvania  performance of many downstream tasks such as relation extraction, event extraction (, coreference resolution, question answering (, and equation parsing (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 201, "end_pos": 220, "type": "TASK", "confidence": 0.8367807567119598}, {"text": "event extraction", "start_pos": 222, "end_pos": 238, "type": "TASK", "confidence": 0.7935982048511505}, {"text": "coreference resolution", "start_pos": 242, "end_pos": 264, "type": "TASK", "confidence": 0.9649922847747803}, {"text": "question answering", "start_pos": 266, "end_pos": 284, "type": "TASK", "confidence": 0.8996203541755676}, {"text": "equation parsing", "start_pos": 292, "end_pos": 308, "type": "TASK", "confidence": 0.8290038108825684}]}, {"text": "Overlapping mention recognition is non-trivial, as existing methods that model mention recognition as a sequence prediction problem -e.g., using linear-chain conditional random fields (CRF) () -have difficulties in handling overlapping mentions (.", "labels": [], "entities": [{"text": "Overlapping mention recognition", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7058311303456625}, {"text": "mention recognition as a sequence prediction", "start_pos": 79, "end_pos": 123, "type": "TASK", "confidence": 0.6594475557406744}]}, {"text": "proposed to use a treebased constituency parsing model to handle nested entities.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.6637848764657974}]}, {"text": "Due to the tree structured representation used, the resulting algorithm has a time complexity that is cubic inn for its inference procedure with n being the number of words in the sentence.", "labels": [], "entities": []}, {"text": "This effectively makes the algorithm less scalable compared to models such as linearchain CRF where the complexity is linear inn.", "labels": [], "entities": []}, {"text": "proposed an alternative approach which shows a time complexity that is linear inn.", "labels": [], "entities": []}, {"text": "Their method differs from the conven-tional sequence labeling approach, in that a hypergraph representation was used in their model.", "labels": [], "entities": [{"text": "conven-tional sequence labeling", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.649090846379598}]}, {"text": "In this work, we make an observation that there exists an efficient model for recognizing overlapping mentions while still regarding the problem as a sequence labeling problem.", "labels": [], "entities": [{"text": "sequence labeling problem", "start_pos": 150, "end_pos": 175, "type": "TASK", "confidence": 0.7316076358159384}]}, {"text": "As opposed to the conventional approach where we assign labels to natural language words, in our new approach we assign labels to the gaps between words, modeling the mention boundaries instead of modeling the role of words in forming mentions.", "labels": [], "entities": []}, {"text": "Furthermore, while these gap-based labels can be modeled using conventional graphical models like linear-chain CRFs, we also propose a novel multigraph representation to utilize such gap-based labels efficiently.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first structured prediction model utilizing a gap-based annotation scheme to predict overlapping structures.", "labels": [], "entities": []}, {"text": "In this paper we make the following major contributions: \u2022 We propose a set of mention separators which can be collectively used to define all possible mention combinations together with a novel multigraph representation, on top of which efficient and exact inference can be performed.", "labels": [], "entities": []}, {"text": "\u2022 Theoretically, we show that unlike a recently proposed state-of-the-art model that we compare against, our model does not exhibit the spurious structures issue in its learning procedure.", "labels": [], "entities": []}, {"text": "On the other hand, it still maintains the same inference time complexity as the previous model.", "labels": [], "entities": [{"text": "inference time complexity", "start_pos": 47, "end_pos": 72, "type": "METRIC", "confidence": 0.7998372515042623}]}, {"text": "\u2022 Empirically, we show that our model is able to achieve higher F 1 -scores compared to previous models in multiple datasets.", "labels": [], "entities": [{"text": "F 1 -scores", "start_pos": 64, "end_pos": 75, "type": "METRIC", "confidence": 0.9868835806846619}]}, {"text": "We believe our proposed approach and the novel representations can be applied in other research problems involving predicting overlapping structures, and we hope this work can inspire further research along such a direction.", "labels": [], "entities": [{"text": "predicting overlapping structures", "start_pos": 115, "end_pos": 148, "type": "TASK", "confidence": 0.8548455238342285}]}], "datasetContent": [{"text": "To assess our model's capability in recognizing overlapping mentions and make comparisons with previous models, we looked at datasets where overlapping mentions are explicitly annotated.", "labels": [], "entities": []}, {"text": "Following the previous work (, our main results are based on the standard).", "labels": [], "entities": []}, {"text": "We also additionally looked at the GE-NIA dataset ( , which was used in the previous works.", "labels": [], "entities": [{"text": "GE-NIA dataset", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.979592889547348}]}, {"text": "For ACE datasets, we used the same splits as used in our previous work (, published on our website 6 . For GENIA, we used GENIAcorpus3.02p 7 that comes with POS tags for each word ().", "labels": [], "entities": [{"text": "ACE datasets", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9304545819759369}, {"text": "GENIA", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.9265121817588806}]}, {"text": "Following previous works, we first split the last 10% of the data as the test set.", "labels": [], "entities": []}, {"text": "Next we used the first 80% and the subsequent 10% for training and development, respectively.", "labels": [], "entities": []}, {"text": "We made the same modifications as described by by collapsing all DNA, RNA, and protein subtypes into DNA, RNA, and protein, keeping cell line and cell type, and removing other mention types, resulting in 5 mention types.", "labels": [], "entities": []}, {"text": "The statistics of each dataset are shown in.", "labels": [], "entities": []}, {"text": "We can see overlapping mentions are common in such datasets.", "labels": [], "entities": []}, {"text": "For more details on the dataset preprocessing, please refer to the supplemental material.", "labels": [], "entities": []}, {"text": "We trained each model in the training set, then tuned the l 2 -regularization parameter based on the development set.", "labels": [], "entities": []}, {"text": "For GENIA experiments, we also tuned the number of Brown clusters.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.8363327383995056}]}, {"text": "Following, we also used each development set to tune the mention penalty to optimize the F 1 -score and report the scores on the corresponding test sets separately.", "labels": [], "entities": [{"text": "mention penalty", "start_pos": 57, "end_pos": 72, "type": "METRIC", "confidence": 0.9448343813419342}, {"text": "F 1 -score", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9842565506696701}]}, {"text": "Similar to, as another baseline model we also trained a standard linear-chain CRF using the BILOU scheme.", "labels": [], "entities": [{"text": "BILOU", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.9912791848182678}]}, {"text": "Although this model does not support overlapping mentions, it gives us a baseline to seethe extent to which our model's ability to recognize overlapping mentions can help the overall performance.", "labels": [], "entities": []}, {"text": "There is also a simple extension 8 of this linear-chain CRF model that can support overlapping mentions of different types by considering each type separately using multiple chains, one for each type.", "labels": [], "entities": []}, {"text": "We call this multiple-chain variant LCRF (multiple) and the earlier standard approach LCRF (single).", "labels": [], "entities": [{"text": "LCRF", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.8334882259368896}]}, {"text": "In all models, we also implement the mention penalty feature, adapted accordingly so that increasing the feature weight will increase the number of mentions predicted by the model.", "labels": [], "entities": []}, {"text": "See supplemental material for more details.", "labels": [], "entities": []}, {"text": "We implemented all models using Java, and also made additional comparisons on running time by running them under the same machine.", "labels": [], "entities": []}, {"text": "In addition, we also analyzed the convergence rate for different models.", "labels": [], "entities": [{"text": "convergence rate", "start_pos": 34, "end_pos": 50, "type": "METRIC", "confidence": 0.9760884046554565}]}, {"text": "shows the results on the ACE datasets, and these are our main results.", "labels": [], "entities": [{"text": "ACE datasets", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9833148717880249}]}, {"text": "Following previous works, we report standard precision (P ), recall (R) and F 1 -score percentage scores.", "labels": [], "entities": [{"text": "standard precision (P )", "start_pos": 36, "end_pos": 59, "type": "METRIC", "confidence": 0.9072830319404602}, {"text": "recall (R)", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9698319882154465}, {"text": "F 1 -score percentage scores", "start_pos": 76, "end_pos": 104, "type": "METRIC", "confidence": 0.9748574296633402}]}, {"text": "The highest results (F 1 -score) and those results that are not significantly different from the highest results are highlighted in bold (based on bootstrap resampling test, where p > 0.01).", "labels": [], "entities": [{"text": "F 1 -score)", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9639724493026733}]}, {"text": "For ACE datasets, we make comparisons with the two versions of the linear-chain CRF baseline: LCRF (single) which does not support overlapping mentions at all and LCRF (multiple) which does not support overlapping mentions of the same type, as well as our implementation of the mention hypergraph baseline (.", "labels": [], "entities": [{"text": "ACE datasets", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7544955313205719}, {"text": "LCRF", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.8904790282249451}]}, {"text": "On different types of sentences: As these datasets consist of both overlapping and nonoverlapping mentions, to further understand the model's effectiveness in recognizing overlapping mentions (and non-overlapping mentions), we performed some additional experiments on the mention hypergraph model and our model.", "labels": [], "entities": []}, {"text": "Specifically, we split the test data into two portions, one that consists of only sentences that contain overlapping mentions (O) and those which do not (\u00d8).", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We can see that in ACE datasets, our model achieves higher F 1 -scores compared to the mention hypergraph for both portions, but it achieves slightly lower results in GENIA dataset for the portion that contains overlapping mentions.", "labels": [], "entities": [{"text": "ACE datasets", "start_pos": 19, "end_pos": 31, "type": "DATASET", "confidence": 0.8827483355998993}, {"text": "F 1 -scores", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9902363121509552}, {"text": "GENIA dataset", "start_pos": 167, "end_pos": 180, "type": "DATASET", "confidence": 0.9433042109012604}]}, {"text": "We believe that our models learn parameters so as to obtain an optimal overall performance, and since the proportion of the overlapping mentions in GENIA is much smaller compared to that in ACE datasets, it learns to focus more on the nonoverlapping mentions.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 148, "end_pos": 153, "type": "DATASET", "confidence": 0.8397829532623291}, {"text": "ACE datasets", "start_pos": 190, "end_pos": 202, "type": "DATASET", "confidence": 0.848357766866684}]}, {"text": "This is supported by the fact that the difference of F 1 -score between the mention hypergraph model and our model in GE-NIA is larger compared to the difference in ACE   These results also lead to the interesting empirical finding that our model appears to be able to do well also on recognizing non-overlapping mentions.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.9840967804193497}, {"text": "GE-NIA", "start_pos": 118, "end_pos": 124, "type": "DATASET", "confidence": 0.9354172945022583}]}, {"text": "This motivates us to conduct the next set of experiments.", "labels": [], "entities": []}, {"text": "On data without overlapping mentions: We also performed one additional set of experiments, on the standard CoNLL-2003 dataset, which has no overlapping mentions.", "labels": [], "entities": [{"text": "CoNLL-2003 dataset", "start_pos": 107, "end_pos": 125, "type": "DATASET", "confidence": 0.9746192395687103}]}, {"text": "The results (without optimizing F 1 -score) are shown in.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9777314364910126}]}, {"text": "We see that our models based on mention separators outperform baseline models such as the Illinois NER system where external resources are not used, and a linear-chain CRF model, although the linearchain CRF baseline models some interactions between distinct mention types and our models do not.", "labels": [], "entities": [{"text": "Illinois NER system", "start_pos": 90, "end_pos": 109, "type": "DATASET", "confidence": 0.9269769191741943}]}, {"text": "Such results also suggest that modeling the interactions between distinct mention types may not be crucial to get a good performance in mention recognition.", "labels": [], "entities": [{"text": "mention recognition", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.7731819748878479}]}, {"text": "This is further corroborated by the result of LCRF (multiple), which is higher than the result of LCRF (single) by about 0.5 points.", "labels": [], "entities": [{"text": "LCRF", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9665055274963379}]}, {"text": "When comparing our model against the mention hypergraph model, we note that our model consistently yields a higher recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9989511966705322}]}, {"text": "We speculate this is due to the fact that as our model does not exhibit the issue of spurious structures we discussed in Section 3.1, it is more confident in making its predictions.", "labels": [], "entities": []}, {"text": "On convergence: We also empirically analyzed the convergence properties of the two models.", "labels": [], "entities": []}, {"text": "Empirically, as illustrated in which shows how the objective improves when the training progresses on ACE-2004, GENIA, and CoNLL-2003, we found that our EDGE-based model requires significantly less iterations to converge than the mention hypergraph on the former two datasets which contain overlapping mentions.", "labels": [], "entities": [{"text": "ACE-2004", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.9671941995620728}, {"text": "GENIA", "start_pos": 112, "end_pos": 117, "type": "DATASET", "confidence": 0.9166178703308105}, {"text": "CoNLL-2003", "start_pos": 123, "end_pos": 133, "type": "DATASET", "confidence": 0.8984540104866028}]}, {"text": "We believe it is possible that this slower convergence is due to the spurious structures issue in mention hypergraphs, which causes the objective function to be more complex to optimize.", "labels": [], "entities": []}, {"text": "However, some further analyses on the convergence issue and the impact of different ways of exploiting features (over different hyperedges) for the hypergraph-based models are needed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the datasets used in the experiments. w/ o.l.: sentences containing overlapping  mentions; o.l.: overlapping mentions; o.l. (s): overlapping mentions with the same type.", "labels": [], "entities": []}, {"text": " Table 2: Main results (on ACE).", "labels": [], "entities": [{"text": "Main", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.8399019241333008}, {"text": "ACE)", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.7713969647884369}]}, {"text": " Table 3: Results on GENIA.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.900719404220581}]}, {"text": " Table 4: Results on different types of sentences.", "labels": [], "entities": []}, {"text": " Table 5: Results on CoNLL-2003 (without opti- mizing F 1 -score).", "labels": [], "entities": [{"text": "CoNLL-2003", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.8740746378898621}, {"text": "F 1 -score", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9674486666917801}]}]}