{"title": [{"text": "ParlAI: A Dialog Research Software Platform", "labels": [], "entities": [{"text": "ParlAI", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.6680957674980164}]}], "abstractContent": [{"text": "We introduce ParlAI (pronounced \"par-lay\"), an open-source software platform for dialog research implemented in Python, available at http://parl.ai.", "labels": [], "entities": [{"text": "dialog research", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.8718686997890472}]}, {"text": "Its goal is to provide a unified framework for sharing, training and testing dialog models; integration of Amazon Mechanical Turk for data collection, human evaluation, and online/reinforcement learning; and a repository of machine learning models for comparing with others' models, and improving upon existing architectures.", "labels": [], "entities": []}, {"text": "Over 20 tasks are supported in the first release, including popular datasets such as SQuAD, bAbI tasks, MCTest, WikiQA, QACNN, QADaily-Mail, CBT, bAbI Dialog, Ubuntu, OpenSubti-tles and VQA.", "labels": [], "entities": [{"text": "VQA", "start_pos": 186, "end_pos": 189, "type": "DATASET", "confidence": 0.9391636848449707}]}, {"text": "Several models are integrated, including neural models such as memory networks , seq2seq and attentive LSTMs.", "labels": [], "entities": []}], "introductionContent": [{"text": "The purpose of language is to accomplish communication goals, which typically involve a dialog between two or more communicators.", "labels": [], "entities": []}, {"text": "Hence, trying to solve dialog is a fundamental goal for researchers in the NLP community.", "labels": [], "entities": [{"text": "solve dialog", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.7152924835681915}]}, {"text": "From a machine learning perspective, building a learning agent capable of dialog is also fundamental for various reasons, chiefly that the solution involves achieving most of the subgoals of the field, and in many cases those subtasks are directly impactful to the task.", "labels": [], "entities": []}, {"text": "On the one hand dialog can be seen as a single task (learning how to talk) and on the other hand as thousands of related tasks that require different skills, all using the same input and output format.", "labels": [], "entities": []}, {"text": "The task of booking a restaurant, chatting about sports or the news, or answering factual or perceptually-grounded questions all fall under dialog.", "labels": [], "entities": []}, {"text": "Hence, methods that perform task transfer appear crucial for the end-goal.", "labels": [], "entities": [{"text": "task transfer", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.7153453379869461}]}, {"text": "Memory, logical and commonsense reasoning, planning, learning from interaction, learning compositionality and other AI subgoals also have clear roles in dialog.", "labels": [], "entities": []}, {"text": "However, to pursue these research goals, we require software tools that unify the different dialog sub-tasks  and the agents that can learn from them.", "labels": [], "entities": []}, {"text": "Working on individual datasets can lead to siloed research, where the overfitting to specific qualities of a dataset do not generalize to solving other tasks.", "labels": [], "entities": []}, {"text": "For example, methods that do not generalize beyond WebQuestions (Berant et al., 2013) because they specialize on knowledge bases only,) because they predict start and end context indices (see Sec.", "labels": [], "entities": []}, {"text": "7), or bAbI ( ) because they use supporting facts or make use of its simulated nature.", "labels": [], "entities": []}, {"text": "In this paper we present a software platform, ParlAI (pronounced \"par-lay\"), that provides researchers a unified framework for training and testing dialog models, especially multitask training or evaluation over many tasks at once, as well as seamless integration with Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 269, "end_pos": 291, "type": "DATASET", "confidence": 0.883488674958547}]}, {"text": "Over 20 tasks are supported in the first release, including many popular datasets, see.", "labels": [], "entities": []}, {"text": "Included are examples of training neural models with PyTorch and Lua Torch 1 . Using Theano 2 or Tensorflow 3 instead is also straightforward.", "labels": [], "entities": []}, {"text": "The overarching goal of ParlAI is to build a community-based platform for easy access to both tasks and learning algorithms that perform well on them, in order to push the field forward.", "labels": [], "entities": []}, {"text": "This paper describes our goals in detail, and gives a technical overview of the platform.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate ParlAI inaction, we give results in Table 1 of DrQA, an attentive LSTM architecture with single task and multitask training on the SQuAD and bAbI tasks, a combination not shown before with any method, to our knowledge.", "labels": [], "entities": [{"text": "DrQA", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.9704384803771973}]}, {"text": "This experiment simultaneously shows the power of ParlAI -how easy it is to setup this experiment -and the limitations of current methods.", "labels": [], "entities": [{"text": "ParlAI", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9359615445137024}]}, {"text": "Almost all methods working well on SQuAD have been designed to predict a phrase from the given context (they are given labeled start and end indices in training).", "labels": [], "entities": []}, {"text": "Hence, those models cannot be applied to all dialog datasets, e.g. some of the bAbI tasks include yes/no questions, where yes and no do not appear in the context.", "labels": [], "entities": []}, {"text": "This highlights that researchers should not focus models on a single dataset.", "labels": [], "entities": []}, {"text": "ParlAI does not provide start and end label indices as its API is dialog only, see.", "labels": [], "entities": [{"text": "ParlAI", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.89388108253479}]}, {"text": "This is a deliberate choice that discourages such dataset overfitting/ specialization.", "labels": [], "entities": []}, {"text": "However, this also results in a slight drop in performance because less information is given, which is still in the range of many existing well-performing methods, see https://stanford-qa.com).", "labels": [], "entities": []}, {"text": "Overall, while DrQA can solve some of the bAbI tasks and performs well on SQuAD, it does not match the best performing methods on bAbI (, and multitasking does not help.", "labels": [], "entities": [{"text": "DrQA", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.9320996403694153}]}, {"text": "Hence, ParlAI lays out the challenge to the community to find learning algorithms that are generally applicable and that benefit from training over many dialog datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test Accuracy of DrQA on bAbI 10k and  SQuAD (Exact Match metric) using ParlAI. The subset  of bAbI tasks for which the answer is exactly contained  in the text is used.", "labels": [], "entities": [{"text": "Test", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9190670251846313}, {"text": "Accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.7402476668357849}, {"text": "DrQA", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.8030717968940735}, {"text": "Exact Match metric)", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.7582967728376389}, {"text": "ParlAI", "start_pos": 82, "end_pos": 88, "type": "DATASET", "confidence": 0.7526029348373413}]}]}