{"title": [{"text": "NeuroNER: an easy-to-use program for named-entity recognition based on neural networks", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7224999815225601}]}], "abstractContent": [{"text": "Named-entity recognition (NER) aims at identifying entities of interest in a text.", "labels": [], "entities": [{"text": "Named-entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8672446489334107}]}, {"text": "Artificial neural networks (ANNs) have recently been shown to outperform existing NER systems.", "labels": [], "entities": []}, {"text": "However, ANNs remain challenging to use for non-expert users.", "labels": [], "entities": [{"text": "ANNs", "start_pos": 9, "end_pos": 13, "type": "TASK", "confidence": 0.9176490306854248}]}, {"text": "In this paper, we present NeuroNER, an easy-to-use named-entity recognition tool based on ANNs.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7138415426015854}]}, {"text": "Users can annotate entities using a graphical web-based user interface (BRAT): the annotations are then used to train an ANN, which in turn predict entities' locations and categories in new texts.", "labels": [], "entities": [{"text": "BRAT", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9270672798156738}]}, {"text": "NeuroNER makes this annotation-training-prediction flow smooth and accessible to anyone.", "labels": [], "entities": [{"text": "NeuroNER", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8523316383361816}]}], "introductionContent": [{"text": "Named-entity recognition (NER) aims at identifying entities of interest in the text, such as location, organization and temporal expression.", "labels": [], "entities": [{"text": "Named-entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.864952802658081}]}, {"text": "Identified entities can be used in various downstream applications such as patient note de-identification and information extraction systems.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7876869738101959}]}, {"text": "They can also be used as features for machine learning systems for other natural language processing tasks.", "labels": [], "entities": []}, {"text": "Early systems for NER relied on rules defined by humans.", "labels": [], "entities": [{"text": "NER", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9871909618377686}]}, {"text": "Rule-based systems are timeconsuming to develop, and cannot be easily transferred to new types of texts or entities.", "labels": [], "entities": []}, {"text": "To address these issues, researchers have developed machinelearning-based algorithms for NER, using a variety of learning approaches, such as fully supervised learning, semi-supervised learning, unsupervised learning, and active learning.", "labels": [], "entities": [{"text": "NER", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9510177373886108}]}, {"text": "NeuroNER is based on a fully supervised learning algorithm, which is the most studied approach (.", "labels": [], "entities": []}, {"text": "* These authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "Fully supervised approaches to NER include support vector machines (SVM), maximum entropy models (), decision trees () as well as sequential tagging methods such as hidden Markov models (), Markov maximum entropy models (), and conditional random fields (CRFs)).", "labels": [], "entities": [{"text": "NER", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.964260458946228}]}, {"text": "Similar to rule-based systems, these approaches rely on handcrafted features, which are challenging and time-consuming to develop and may not generalize well to new datasets.", "labels": [], "entities": []}, {"text": "More recently, artificial neural networks (ANNs) have been shown to outperform other supervised algorithms for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.9529240131378174}]}, {"text": "The effectiveness of ANNs can be attributed to their ability to learn effective features jointly with model parameters directly from the training dataset, instead of relying on handcrafted features developed from a specific dataset.", "labels": [], "entities": []}, {"text": "However, ANNs remain challenging to use for non-expert users.", "labels": [], "entities": [{"text": "ANNs", "start_pos": 9, "end_pos": 13, "type": "TASK", "confidence": 0.9176490306854248}]}, {"text": "Contributions NeuroNER makes state-of-theart named-entity recognition based on ANN available to anyone, by focusing on usability.", "labels": [], "entities": [{"text": "named-entity recognition based on ANN", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.7758689284324646}]}, {"text": "To enable users to create or modify annotations fora new or existing corpus, NeuroNER interfaces with the web-based annotation program BRAT (.", "labels": [], "entities": [{"text": "BRAT", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.919871985912323}]}, {"text": "NeuroNER makes the annotationtraining-prediction flow smooth and accessible to anyone, while leveraging the state-of-the-art prediction capabilities of ANNs.", "labels": [], "entities": []}, {"text": "NeuroNER is open source and freely available online 1 .", "labels": [], "entities": [{"text": "NeuroNER", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7847694158554077}]}], "datasetContent": [{"text": "Test set Test set with predicted entities", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F1-scores (%) on the test set compar- ing NeuroNER with the best published methods in  the literature, viz. (Passos et al., 2014) for CoNLL  2003, (Dernoncourt et al., 2016) for i2b2 2014.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9993106126785278}, {"text": "CoNLL  2003", "start_pos": 144, "end_pos": 155, "type": "DATASET", "confidence": 0.888953685760498}]}]}