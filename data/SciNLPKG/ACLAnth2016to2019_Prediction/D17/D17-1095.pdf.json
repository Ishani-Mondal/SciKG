{"title": [{"text": "An empirical study on the effectiveness of images in Multimodal Neural Machine Translation", "labels": [], "entities": [{"text": "Multimodal Neural Machine Translation", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.7128116339445114}]}], "abstractContent": [{"text": "In state-of-the-art Neural Machine Translation (NMT), an attention mechanism is used during decoding to enhance the translation.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.8406675358613332}]}, {"text": "At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most useful information before outputting its target word.", "labels": [], "entities": []}, {"text": "Recently, the effectiveness of the attention mechanism has also been explored for multimodal tasks, where it becomes possible to focus both on sentence parts and image regions that they describe.", "labels": [], "entities": []}, {"text": "In this paper, we compare several attention mechanism on the multimodal translation task (English, image \u2192 German) and evaluate the ability of the model to make use of images to improve translation.", "labels": [], "entities": [{"text": "multimodal translation task", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.7576381166776022}]}, {"text": "We surpass state-of-the-art scores on the Multi30k data set, we nevertheless identify and report different misbehavior of the machine while translating.", "labels": [], "entities": [{"text": "Multi30k data set", "start_pos": 42, "end_pos": 59, "type": "DATASET", "confidence": 0.978460431098938}]}], "introductionContent": [{"text": "In machine translation, neural networks have attracted a lot of research attention.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7807019948959351}]}, {"text": "Recently, the attention-based encoder-decoder framework) has been largely adopted.", "labels": [], "entities": []}, {"text": "In this approach, Recurrent Neural Networks (RNNs) map source sequences of words to target sequences.", "labels": [], "entities": []}, {"text": "The attention mechanism is learned to focus on different parts of the input sentence while decoding.", "labels": [], "entities": []}, {"text": "Attention mechanisms have shown to work with other modalities too, like images, where their are able to learn to attend the salient parts of an image, for instance when generating text captions ().", "labels": [], "entities": []}, {"text": "For such applications, Convolutional Neural Networks (CNNs) such as Deep Residual () have shown to work best to represent images.", "labels": [], "entities": []}, {"text": "Multimodal models of texts and images empower new applications such as visual question answering or multimodal caption translation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.6774556636810303}, {"text": "multimodal caption translation", "start_pos": 100, "end_pos": 130, "type": "TASK", "confidence": 0.82895427942276}]}, {"text": "Also, the grounding of multiple modalities against each other may enable the model to have a better understanding of each modality individually, such as in natural language understanding applications.", "labels": [], "entities": []}, {"text": "In the field of Machine Translation (MT), the efficient integration of multimodal information still remains a challenging task.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.8683257937431336}]}, {"text": "It requires combining diverse modality vector representations with each other.", "labels": [], "entities": []}, {"text": "These vector representations, also called context vectors, are computed in order the capture the most relevant information in a modality to output the best translation of a sentence.", "labels": [], "entities": []}, {"text": "To investigate the effectiveness of information obtained from images, a multimodal machine translation shared task (  has been addressed to the MT community . The best results of NMT model were those of who used LSTM fed with global visual features or multiple regional visual features followed by rescoring.", "labels": [], "entities": [{"text": "MT", "start_pos": 144, "end_pos": 146, "type": "TASK", "confidence": 0.9413731098175049}]}, {"text": "Recently, proposed a doubly-attentive decoder that outperformed this baseline with less data and without rescoring.", "labels": [], "entities": []}, {"text": "Our paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2, we briefly describe our NMT model as well as the conditional GRU activation used in the decoder.", "labels": [], "entities": []}, {"text": "We also explain how multi-modalities can be implemented within this framework.", "labels": [], "entities": []}, {"text": "In the following sections (3 and 4), we detail three attention mechanisms and explain how we tweak them to work as well as possible with images.", "labels": [], "entities": []}, {"text": "Finally, we report and analyze our results in section 5 then conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "For this experiments on Multimodal Machine Translation, we used the Multi30K dataset  which is an extended version of the Flickr30K Entities.", "labels": [], "entities": [{"text": "Multimodal Machine Translation", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.7282048662503561}, {"text": "Multi30K dataset", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.8811835944652557}, {"text": "Flickr30K Entities", "start_pos": 122, "end_pos": 140, "type": "DATASET", "confidence": 0.9301010370254517}]}, {"text": "For each image, one of the English descriptions was selected and manually translated into German by a professional translator.", "labels": [], "entities": []}, {"text": "As training and development data, 29,000 and 1,014 triples are used respectively.", "labels": [], "entities": []}, {"text": "A test set of size 1000 is used for metrics evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the 1000 test triples of the Multi30K dataset. We pick Calixto et al.", "labels": [], "entities": [{"text": "Multi30K dataset", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.9667108654975891}]}]}