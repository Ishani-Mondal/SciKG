{"title": [{"text": "Visual Denotations for Recognizing Textual Entailment", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.8646078705787659}]}], "abstractContent": [{"text": "In the logic approach to Recognizing Textual Entailment, identifying phrase-to-phrase semantic relations is still an unsolved problem.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.8922937711079916}, {"text": "identifying phrase-to-phrase semantic relations", "start_pos": 57, "end_pos": 104, "type": "TASK", "confidence": 0.7727380096912384}]}, {"text": "Resources such as the Paraphrase Database offer limited coverage despite their large size whereas unsu-pervised distributional models of meaning often fail to recognize phrasal entailments.", "labels": [], "entities": []}, {"text": "We propose to map phrases to their visual denotations and compare their meaning in terms of their images.", "labels": [], "entities": []}, {"text": "We show that our approach is effective in the task of Recognizing Textual Entailment when combined with specific linguistic and logic features.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.9166614413261414}]}], "introductionContent": [], "datasetContent": [{"text": "Our system is independent from the logic backend but we use ccg2lambda ( for its high precision and capabilities to solve word-to-word divergences using WordNet and VerbOcean (.", "labels": [], "entities": [{"text": "ccg2lambda", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.9241359233856201}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9977079629898071}, {"text": "WordNet", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.9580367207527161}]}, {"text": "We evaluate our system on the SemEval-2014 version of the SICK dataset () with train/trial/test splits of 4, 500/500/4, 927 T-H pairs and a yes/no/unk label distribution of .29/.15/.56.", "labels": [], "entities": [{"text": "SICK dataset", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.8212706744670868}]}, {"text": "We chose SICK for its relatively limited vocabulary (2, 409 words) and short sentences.", "labels": [], "entities": []}, {"text": "The average T and H sentence length was 10.6 where 3.6 to 3.8 words appeared in T and not in H or vice versa.", "labels": [], "entities": []}, {"text": "We used scipy's Random Forests) as our entailment classifier with 500 trees and feature value standardization, trained and evaluated on those T-H pairs for which ccg2lambda outputs unknown (around 71% of the problems).", "labels": [], "entities": []}, {"text": "Using the tree mapping algorithm, we obtained an average of 9.8 phrase pairs per T-H problem.", "labels": [], "entities": []}, {"text": "We obtained n = 30 images for every phrase using Google Image Search API which we consider as our visual denotations.", "labels": [], "entities": []}, {"text": "The images and their vector representations were obtained between Sept. 2016 and Feb. 2017 using the image miner and the feature extractor of.", "labels": [], "entities": []}, {"text": "Our main baseline is ccg2lambda when using only WordNet and VerbOcean to account for word-to-word lexical divergences.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9782731533050537}, {"text": "VerbOcean", "start_pos": 60, "end_pos": 69, "type": "DATASET", "confidence": 0.890320360660553}]}, {"text": "ccg2lambda is augmented with a classifier c that uses either text and logic features tor image features from 10, 20, or 30 images.", "labels": [], "entities": [{"text": "ccg2lambda", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.947114884853363}]}, {"text": "On the training data, ccg2lambda obtains an accuracy of 82.89%.", "labels": [], "entities": [{"text": "ccg2lambda", "start_pos": 22, "end_pos": 32, "type": "DATASET", "confidence": 0.8556618094444275}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9997690320014954}]}, {"text": "Using our classifier with all features, we carried out 10 runs of a 10-fold crossvalidation on the training data and we obtained an accuracy (standard deviation) of 84.14 (0.06), 84.30 (0.14) and 84.28 (0.11) when using 10, 20 and 30 images, respectively.", "labels": [], "entities": [{"text": "accuracy (standard deviation)", "start_pos": 132, "end_pos": 161, "type": "METRIC", "confidence": 0.8002835750579834}]}, {"text": "Thus, no significant differences inaccuracy were observed for different numbers of images.", "labels": [], "entities": []}, {"text": "When using only text and logic features (c-t), the accuracy dropped: Results on the test split of SICK dataset using precision, recall and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9996346235275269}, {"text": "SICK dataset", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.8229518830776215}, {"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9994912147521973}, {"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9992129802703857}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9989376664161682}]}, {"text": "The system \"ccg2lambda + images\" uses text and logics features and 20 images per phrase: c-t-20i.", "labels": [], "entities": []}, {"text": "to 76.60 (0.03); when using only image features (c-20i), the accuracy dropped to 82.85%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9997397065162659}]}, {"text": "These results show that using visual denotations to recognize phrasal entailments contributes to improvements inaccuracy and that the interaction with text and logic features produces further gains.", "labels": [], "entities": []}, {"text": "On the test data, we obtained 1.1% higher accuracy (84.29 versus 83.13) over the ccg2lambda baseline with a standard deviation of 0.07% over 10 runs (see) when using the setting c-t-20i.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9995081424713135}, {"text": "ccg2lambda baseline", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.9107474982738495}]}, {"text": "As a comparison, Lai and Hockenmaier (2017) obtain a similar accuracy increase when using visual denotations (1.2%) with a substantially more complex approach that requires training on the SNLI dataset (), a much larger corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9991676807403564}, {"text": "SNLI dataset", "start_pos": 189, "end_pos": 201, "type": "DATASET", "confidence": 0.9119271337985992}]}, {"text": "The best SemEval-2014 system obtained an accuracy of 84.57 ) and other heavily engineered, finely-tuned systems ( reported up to 3% points of accuracy improvement since then.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9996088147163391}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9993465542793274}]}, {"text": "Thus, our results are still below the state of the art.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results (accuracy and standard devia- tion) of the classifier c in a cross-validation on the  training split of SICK dataset using text and logic  features t for 10i, 20i and 30i images.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9994593262672424}, {"text": "SICK dataset", "start_pos": 122, "end_pos": 134, "type": "DATASET", "confidence": 0.8598976731300354}]}, {"text": " Table 2: Results on the test split of SICK dataset  using precision, recall and accuracy. The system  \"ccg2lambda + images\" uses text and logics  features and 20 images per phrase: c-t-20i.", "labels": [], "entities": [{"text": "SICK dataset", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.8208734095096588}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9994556307792664}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9988272786140442}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9983899593353271}]}]}