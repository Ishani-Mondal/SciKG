{"title": [{"text": "Learning what to read: Focused machine reading", "labels": [], "entities": [{"text": "machine reading", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.6741279363632202}]}], "abstractContent": [{"text": "Recent efforts in bioinformatics have achieved tremendous progress in the machine reading of biomedical literature, and the assembly of the extracted biochemical interactions into large-scale models such as protein signaling pathways.", "labels": [], "entities": []}, {"text": "However , batch machine reading of literature at today's scale (PubMed alone indexes over 1 million papers per year) is unfea-sible due to both cost and processing overhead.", "labels": [], "entities": [{"text": "batch machine reading of literature", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7655682504177094}, {"text": "PubMed alone indexes", "start_pos": 64, "end_pos": 84, "type": "DATASET", "confidence": 0.9217731952667236}]}, {"text": "In this work, we introduce a focused reading approach to guide the machine reading of biomedical literature towards what literature should be read to answer a biomedical query as efficiently as possible.", "labels": [], "entities": [{"text": "machine reading of biomedical literature", "start_pos": 67, "end_pos": 107, "type": "TASK", "confidence": 0.7642442047595978}]}, {"text": "We introduce a family of algorithms for focused reading, including an intuitive, strong baseline, and a second approach which uses a reinforcement learning (RL) framework that learns when to explore (widen the search) or exploit (narrow it).", "labels": [], "entities": []}, {"text": "We demonstrate that the RL approach is capable of answering more queries than the baseline, while being more efficient, i.e., reading fewer documents.", "labels": [], "entities": [{"text": "RL", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9574756622314453}]}], "introductionContent": [{"text": "The millions of academic papers in the biomedical domain contain avast amount of information that may lead to new hypotheses for disease treatment.", "labels": [], "entities": []}, {"text": "However, scientists are faced with a problem of \"undiscovered public knowledge,\" as they struggle to read and assimilate all of this information.", "labels": [], "entities": []}, {"text": "Furthermore, the literature is growing at an exponential rate; PubMed 1 has been adding more than a million papers per year since 2011.", "labels": [], "entities": [{"text": "PubMed 1", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.8993315100669861}]}, {"text": "We have surpassed our 1 http://www.ncbi.nlm.nih.gov/pubmed ability to keep up with and integrate these findings through manual reading alone.", "labels": [], "entities": []}, {"text": "Large ongoing efforts, such as the BioNLP task community) and the DARPA Big Mechanism Program, are making progress in advancing methods for machine reading and assembly of extracted biochemical interactions into large-scale models.", "labels": [], "entities": [{"text": "BioNLP task community", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.6717876195907593}]}, {"text": "However, to date, these methods rely either on the manual selection of relevant documents, or on the processing of large batches of documents that mayor may not be relevant to the model being constructed.", "labels": [], "entities": []}, {"text": "Batch machine reading of literature at this scale poses anew, growing set of problems.", "labels": [], "entities": []}, {"text": "First, access to some documents is costly.", "labels": [], "entities": []}, {"text": "The PubMedCentral (PMC) Open Access Subset 2 (OA) is estimated to comprise 20% 4 of the total literature; the remaining full-text documents are only available through paid access.", "labels": [], "entities": [{"text": "PubMedCentral (PMC) Open Access Subset 2 (OA)", "start_pos": 4, "end_pos": 49, "type": "DATASET", "confidence": 0.8379242420196533}]}, {"text": "Second, while there have been great advances in quality, machine reading is still not solved.", "labels": [], "entities": [{"text": "machine reading", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.8418463170528412}]}, {"text": "Updates to our readers requires reprocessing the documents.", "labels": [], "entities": []}, {"text": "For large document corpora, this quickly becomes the chief bottleneck in information extraction for model construction and analysis.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7327372282743454}, {"text": "model construction and analysis", "start_pos": 100, "end_pos": 131, "type": "TASK", "confidence": 0.7579373419284821}]}, {"text": "Finally, even if we could cache all reading results, the search for connections between concepts within the extracted results should not be done blindly.", "labels": [], "entities": []}, {"text": "At least in the biology domain, the many connections between biological entities and processes leads to a very high branching factor, making blind search for paths intractable.", "labels": [], "entities": []}, {"text": "To effectively read at this scale, we need to incorporate methods for focused reading: develop the ability to pose queries about concepts of interest and perform targeted, incremental search through the literature for connections between concepts while minimizing reading documents that are likely irrelevant.", "labels": [], "entities": []}, {"text": "In this paper we present what we believe is the first algorithm for focused reading.", "labels": [], "entities": [{"text": "focused reading", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7365083396434784}]}, {"text": "We make the following contributions: (1) Present a general framework fora family of possible focused reading algorithms along with a baseline instance.", "labels": [], "entities": []}, {"text": "(2) Cast the design of focused reading algorithms in a reinforcement learning (RL) setting, where the machine decides if it should explore (i.e., cast a wider net) or exploit (i.e., focus reading on a specific topic).", "labels": [], "entities": []}, {"text": "(3) Evaluate our focused reading policies in terms of search efficiency and quality of information extracted.", "labels": [], "entities": []}, {"text": "The evaluation demonstrates the effectiveness of the RL method: this approach found more information than the strong baseline we propose, while reading fewer documents.", "labels": [], "entities": [{"text": "RL", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9664335250854492}]}], "datasetContent": [{"text": "The main functions that affect the search behavior of Algorithm 1 are ENDPOINTSTRATEGY and CHOOSEQUERY.", "labels": [], "entities": [{"text": "ENDPOINTSTRATEGY", "start_pos": 70, "end_pos": 86, "type": "METRIC", "confidence": 0.9041079878807068}]}, {"text": "Here we describe a baseline focused reading implementation in which END-POINTSTRATEGY and CHOOSEQUERY aim to find any path between Sand D as quickly as possible.", "labels": [], "entities": [{"text": "END-POINTSTRATEGY", "start_pos": 68, "end_pos": 85, "type": "METRIC", "confidence": 0.9502992630004883}]}, {"text": "For ENDPOINTSTRATEGY, we follow the intuition that some participants in a biological graph tend to be connected to more participants than others, and therefore more likely to yield interactions providing paths between participants in general.", "labels": [], "entities": []}, {"text": "Our heuristic is therefore to choose new participants to query that currently have the most inward and outgoing edges (i.e., highest vertex degree) in the current state of G (disallowing choosing an entity pair used in a previous query).", "labels": [], "entities": []}, {"text": "Now that we have our candidate participants (A, B), our next step is to formulate how we will use these participants to retrieve new papers.", "labels": [], "entities": []}, {"text": "Here we consider two classes of query: (1) we restrict our query to only retrieve papers that simultaneously mention both A and B, therefore more likely retrieving a paper with a direct link between A and B (exploit), or (2) we retrieve papers that mention either A or B, therefore generally retrieving more papers that will introduce more new participants (explore).", "labels": [], "entities": []}, {"text": "For our baseline, where we are trying to find a path between Sand D as quickly as possible, we implement a greedy CHOOSEQUERY: first try the conjunctive exploitation query; if no documents are retrieved, then \"relax\" the search to the disjunctive exploration query.", "labels": [], "entities": []}, {"text": "To evaluate the baseline, we constructed a data set based on a collection of papers seeded by a set of 132 entities that come from the University of Pittsburgh DyCE 7 model, a biomolecular model of pancreatic cancer.", "labels": [], "entities": []}, {"text": "Using these entities, we retrieved 70,719 papers that mention them.", "labels": [], "entities": []}, {"text": "We processed all papers using REACH, extracting all of the interactions mentioned, and converted them into a single graph.", "labels": [], "entities": [{"text": "REACH", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9345821142196655}]}, {"text": "The resulting graph consisted of approximately 80,000 vertices, 115,000 edges, and had an average (undirected) vertex degree of 24.", "labels": [], "entities": []}, {"text": "We will refer to this graph as the REACH graph, as it represents what can be retrieved by REACH from the set of 70K papers.", "labels": [], "entities": [{"text": "REACH", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.7443050742149353}]}, {"text": "Next, we identified which pairs of the original 132 entities are connected by directed paths in DyCE.", "labels": [], "entities": []}, {"text": "A total of 789 pairs were found.", "labels": [], "entities": []}, {"text": "We used 289 of these entity pairs as testing queries (i.e., generating queries that aim to explain how a given pair is connected according to the literature).", "labels": [], "entities": []}, {"text": "The other 500 pairs were held out to train the RL method described below.", "labels": [], "entities": [{"text": "RL", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.6012467741966248}]}, {"text": "We ran this baseline focused reading algorithm on each of the 289 pairs of participants, in each case attempting to recover a directed path from one to the other.", "labels": [], "entities": []}, {"text": "The results are summarized in the middle column of.", "labels": [], "entities": []}, {"text": "By issuing 573 queries, the baseline read 26,197 papers out of the total 70,719 papers (37% of the corpus), in order to recover 189 of the 289 paths (65%).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the baseline and RL Query Policy for the focused reading of biomedical literature.", "labels": [], "entities": [{"text": "RL Query", "start_pos": 38, "end_pos": 46, "type": "TASK", "confidence": 0.6690157353878021}]}, {"text": " Table 2: Ablation test on the features used to represent the RL state.", "labels": [], "entities": []}, {"text": " Table 3: Error analysis on 18 queries that failed  under the RL algorithm.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9827438592910767}]}]}