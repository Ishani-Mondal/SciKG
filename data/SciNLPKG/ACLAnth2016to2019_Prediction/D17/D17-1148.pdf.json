{"title": [{"text": "Neural Machine Translation Leveraging Phrase-based Models in a Hybrid Search", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7728492617607117}]}], "abstractContent": [{"text": "In this paper, we introduce a hybrid search for attention-based neural machine translation (NMT).", "labels": [], "entities": [{"text": "attention-based neural machine translation (NMT)", "start_pos": 48, "end_pos": 96, "type": "TASK", "confidence": 0.7034340500831604}]}, {"text": "A target phrase learned with statistical MT models extends a hypothesis in the NMT beam search when the attention of the NMT model focuses on the source words translated by this phrase.", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9528203010559082}]}, {"text": "Phrases added in this way are scored with the NMT model, but also with SMT features including phrase-level translation probabilities and a target language model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9806872010231018}, {"text": "phrase-level translation probabilities", "start_pos": 94, "end_pos": 132, "type": "TASK", "confidence": 0.7526229421297709}]}, {"text": "Experimental results on German\u2192English news domain and English\u2192Russian e-commerce domain translation tasks show that using phrase-based models in NMT search improves MT quality by up to 2.3% BLEU absolute as compared to a strong NMT baseline.", "labels": [], "entities": [{"text": "English\u2192Russian e-commerce domain translation tasks", "start_pos": 55, "end_pos": 106, "type": "TASK", "confidence": 0.653588571718761}, {"text": "MT", "start_pos": 166, "end_pos": 168, "type": "TASK", "confidence": 0.9853910207748413}, {"text": "BLEU absolute", "start_pos": 191, "end_pos": 204, "type": "METRIC", "confidence": 0.9590294063091278}]}], "introductionContent": [{"text": "Neural machine translation has become state-ofthe-art in recent years, reaching higher translation quality than statistical phrase-based machine translation (PBMT) on many tasks.", "labels": [], "entities": [{"text": "Neural machine translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7928163409233093}, {"text": "statistical phrase-based machine translation (PBMT)", "start_pos": 112, "end_pos": 163, "type": "TASK", "confidence": 0.7251836998122079}]}, {"text": "Human analysis ( showed that NMT makes significantly fewer reordering errors, and also is able to select correct word forms more often than PBMT in the case of morphologically rich target languages.", "labels": [], "entities": []}, {"text": "Overall, the fluency of the MT output improves when NMT is used, and the number of lexical choice errors is also reduced.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9691286683082581}]}, {"text": "However, state-of-the-art NMT approaches based on an encoder-decoder architecture with an attention mechanism as introduced by ( ) exhibit weaknesses that sometimes lead to MT errors which a phrase-based MT system does not make.", "labels": [], "entities": [{"text": "MT", "start_pos": 173, "end_pos": 175, "type": "TASK", "confidence": 0.9768837094306946}]}, {"text": "In particular, PBMT usually can better translate rare words (e.g. singletons), as well as memorize and use phrasal translations.", "labels": [], "entities": []}, {"text": "NMT has problems translating rare words because of limitations on the vocabulary size, as well as the fact that word embeddings are used to represent both source and target words.", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8096084594726562}, {"text": "translating rare words", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.8651359677314758}]}, {"text": "A rare word's embedding cannot be trained reliably.", "labels": [], "entities": []}, {"text": "Another handicap of NMT is a general difficulty of fixing errors made by a neural MT system.", "labels": [], "entities": [{"text": "NMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9037071466445923}]}, {"text": "Since NMT does not explicitly use or save word-to-word or phrase-to-phrase mappings, and its search is a target word beam search with almost no constraints, it is difficult to fix errors by an NMT system.", "labels": [], "entities": [{"text": "NMT", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.8789459466934204}]}, {"text": "It is important to quickly fix certain errors in real-life applications of MT systems to avoid negative user feedback or other (e.g. legal) consequences.", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9846274256706238}]}, {"text": "An error identified in the output of a PBMT system can be fixed by tracing which phrase pair was used that resulted in the error, and down-weighting or even removing the phrase pair.", "labels": [], "entities": []}, {"text": "Also, in PBMT it is easy to add an \"override\" translation.", "labels": [], "entities": []}, {"text": "In this work, we combine the strengths of NMT and PBMT approaches by introducing a novel hybrid search algorithm.", "labels": [], "entities": []}, {"text": "In this algorithm, the standard NMT beam search is extended with phrase translation hypotheses from a statistical phrase table.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.765942394733429}]}, {"text": "The decision on when to use what phrasal translations is taken based on the attention mechanism of the NMT model, which provides a soft coverage of the source sentence words.", "labels": [], "entities": []}, {"text": "All partial phrasal translations are scored with the NMT decoder and can be continued with a word-based NMT translation candidate or another phrasal translation candidate.", "labels": [], "entities": [{"text": "NMT decoder", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.8296244442462921}]}, {"text": "The proposed search algorithm uses a log-linear model in which the NMT translation score is combined with standard phrase translation scores, including a target n-gram language model (LM) score.", "labels": [], "entities": [{"text": "NMT translation", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.6195908486843109}, {"text": "phrase translation", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.7123511135578156}]}, {"text": "Thus, a LM trained on additional monolingual data can be used.", "labels": [], "entities": []}, {"text": "The decisions on the word order in the produced target translation are taken based only on the states of the NMT decoder.", "labels": [], "entities": [{"text": "NMT decoder", "start_pos": 109, "end_pos": 120, "type": "DATASET", "confidence": 0.8556530773639679}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We review related work in Section 1.1.", "labels": [], "entities": []}, {"text": "The baseline NMT model we use is described in Section 2, where we also recap the log-linear model combination used in PBMT.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.8043367266654968}]}, {"text": "Section 3 presents the details of the proposed hybrid search.", "labels": [], "entities": []}, {"text": "Experimental results are presented in Section 4, followed by conclusions and outlook in Section 5.", "labels": [], "entities": [{"text": "outlook", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9517492055892944}]}], "datasetContent": [{"text": "We perform experiments comparing the translation quality of our hybrid approach to phrasebased and pure end-to-end NMT baselines.", "labels": [], "entities": []}, {"text": "We present results on two tasks: an inhouse English\u2192Russian e-commerce task (translation of real product/item descriptions from an e-commerce site), and the WMT 2016 German\u2192English task (news domain).", "labels": [], "entities": [{"text": "translation of real product/item descriptions from an e-commerce site)", "start_pos": 77, "end_pos": 147, "type": "TASK", "confidence": 0.8799243569374084}, {"text": "WMT 2016 German\u2192English task", "start_pos": 157, "end_pos": 185, "type": "DATASET", "confidence": 0.856565793355306}]}, {"text": "The corpus statistics are shown in For the English\u2192Russian task, the parallel training data consists of an in-domain part (ca.", "labels": [], "entities": []}, {"text": "5.5M running words) of product/item titles and descriptions and other e-commerce content.", "labels": [], "entities": []}, {"text": "The rest is out-of-domain data (UN, subtitles, TAUS data collections, etc.) sampled to have significant ngram overlap with the in-domain description data.", "labels": [], "entities": [{"text": "TAUS data collections", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.8160298566023508}]}, {"text": "Item descriptions are provided by private sellers and, like any user-generated content, may contain ungrammatical sentences, spelling errors, and other noise.", "labels": [], "entities": []}, {"text": "Product descriptions usually originate from product catalogs and are more \"clean\", but on the other hand, are difficult to translate because of rare domain-specific terminology.", "labels": [], "entities": []}, {"text": "Both types of text contain itemizations, measurement units, and other structures which are usually not found in normal sentences.", "labels": [], "entities": []}, {"text": "We tune the system on a development set that is a mix of product and item descriptions, and evaluate on separate product/item description test sets.", "labels": [], "entities": []}, {"text": "For development and test sets, two reference translations are used.", "labels": [], "entities": []}, {"text": "For the phrase-based baselines, we use an inhouse phrase-decoder ( which is similar to the Moses decoder ().", "labels": [], "entities": []}, {"text": "We use standard SMT features, including word-level and phrase-level translation probabilities, the distortion model, 5-gram LMs, and a 7-gram joint translation and reordering model reimplemented based on the work of ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9884428381919861}, {"text": "phrase-level translation", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.6038894951343536}]}, {"text": "The language model for the ecommerce task is trained on additional monolingual Russian item description data containing 28.2M words.", "labels": [], "entities": []}, {"text": "For the WMT task, we use the English News Crawl data containing 3.8B words for additional language model data.", "labels": [], "entities": [{"text": "WMT task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.905147135257721}, {"text": "English News Crawl data", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.8899979591369629}]}, {"text": "The tuning is performed using MERT to increase the BLEU score on the development set.", "labels": [], "entities": [{"text": "MERT", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.984117865562439}, {"text": "BLEU score", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9858255982398987}]}, {"text": "To stabilize the optimization on the English\u2192Russian task, we detach Russian morphological suffixes from the word stems both in hypotheses and references using a context-independent \"poor man's\" morphological analysis.", "labels": [], "entities": []}, {"text": "We prefix each suffix with a special symbol and treat them as separate tokens.", "labels": [], "entities": []}, {"text": "We have implemented our NMT model in.", "labels": [], "entities": []}, {"text": "We set the dropout probability for input and recurrent connections of the RNN to 0.2 and word embedding dropout probability to 0.1.", "labels": [], "entities": []}, {"text": "On the English\u2192Russian task, the model is then fine-tuned on in-domain data for 10 epochs.", "labels": [], "entities": []}, {"text": "The vocabulary is limited using byte pair encoding (BPE) () with 40K splits separately for each language.", "labels": [], "entities": []}, {"text": "To speedup training we use approximate loss as described in).", "labels": [], "entities": []}, {"text": "For pure NMT experiments, we employ length normalization ( , as otherwise short translations would be favored.", "labels": [], "entities": []}, {"text": "For the hybrid approach, we use the same trained end-to-end model as in the NMT baseline.", "labels": [], "entities": [{"text": "NMT baseline", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.8633560538291931}]}, {"text": "We use all the phrase-based model features plus the NMT score and run MERT as described in Section 3.1.", "labels": [], "entities": [{"text": "NMT score", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.5175950974225998}]}, {"text": "Language models are trained on the level of BPE tokens.", "labels": [], "entities": [{"text": "BPE tokens", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.48980316519737244}]}, {"text": "We consider at most 100 translation options for each source phrase.", "labels": [], "entities": []}, {"text": "If not specified otherwise, we use abeam size of 96 for phrase hypotheses and abeam size of 32 for word hypotheses, resulting in a combined beam size of 128.", "labels": [], "entities": []}, {"text": "Furthermore, we set the focus threshold \u03c4 focus = 0.3 and the coverage threshold \u03c4 cov = 0.7 by default.", "labels": [], "entities": [{"text": "focus threshold \u03c4 focus", "start_pos": 24, "end_pos": 47, "type": "METRIC", "confidence": 0.9434541910886765}, {"text": "coverage threshold \u03c4 cov", "start_pos": 62, "end_pos": 86, "type": "METRIC", "confidence": 0.9651061296463013}]}, {"text": "We also perform experiments where these hyper-parameters are varied.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics for the WMT German\u2192English and e-commerce English\u2192Russian MT tasks.", "labels": [], "entities": [{"text": "WMT German\u2192English and e-commerce English\u2192Russian MT", "start_pos": 36, "end_pos": 88, "type": "TASK", "confidence": 0.4620345920324326}]}, {"text": " Table 1.  For the English\u2192Russian task, the parallel  training data consists of an in-domain part (ca.  5.5M running words) of product/item titles and de- scriptions and other e-commerce content. The rest  is out-of-domain data (UN, subtitles, TAUS data  collections, etc.) sampled to have significant n- gram overlap with the in-domain description data.  Item descriptions are provided by private sellers  and, like any user-generated content, may con- tain ungrammatical sentences, spelling errors, and  other noise. Product descriptions usually originate  from product catalogs and are more \"clean\", but  on the other hand, are difficult to translate because  of rare domain-specific terminology. Both types", "labels": [], "entities": [{"text": "TAUS data  collections", "start_pos": 245, "end_pos": 267, "type": "DATASET", "confidence": 0.7483432193597158}]}, {"text": " Table 2: Overview of translation results on the e-commerce English\u2192Russian task.", "labels": [], "entities": [{"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.962841808795929}]}, {"text": " Table 3: Translation results of the hybrid approach on the e-commerce English\u2192Russian task with  different SMT model combinations. The first row shows results with all models enabled. In the following  rows, we either remove or limit exactly one model compared to the full system.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.961730420589447}, {"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9648499488830566}]}, {"text": " Table 4: Effect of the beam size (word beam size  N w + phrase beam size N p ) for the hybrid ap- proach on the e-commerce English\u2192Russian task.", "labels": [], "entities": []}, {"text": " Table 5: Effect of the threshold parameters  on the hybrid approach on the e-commerce  English\u2192Russian task.", "labels": [], "entities": []}, {"text": " Table 6: Overview of translation results on the WMT German\u2192English task.", "labels": [], "entities": [{"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9715245366096497}, {"text": "WMT German\u2192English task", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.5220212817192078}]}]}