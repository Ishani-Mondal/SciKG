{"title": [{"text": "Analogs of Linguistic Structure in Deep Representations", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate the compositional structure of message vectors computed by a deep network trained on a communication game.", "labels": [], "entities": []}, {"text": "By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning.", "labels": [], "entities": []}, {"text": "We then search for struc-tured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation , conjunction, and disjunction.", "labels": [], "entities": []}, {"text": "Our results suggest that neural representations are capable of spontaneously developing a \"syntax\" with functional analogues to qualitative properties of natural language.", "labels": [], "entities": []}], "introductionContent": [{"text": "The past year has seen a renewal of interest in endto-end learning of communication strategies between pairs of agents represented with deep networks ().", "labels": [], "entities": []}, {"text": "Approaches of this kind make it possible to learn decentralized policies from scratch (, with multiple agents coordinating via learned communication protocol.", "labels": [], "entities": []}, {"text": "More generally, any encoder-decoder model) can be viewed as implementing an analogous communication protocol, with the input encoding playing the role of a message in an artificial \"language\" shared by the encoder and decoder (.", "labels": [], "entities": []}, {"text": "Earlier work has found that under suitable conditions, these protocols acquire simple interpretable lexical () and sequential structure: Overview of our task.", "labels": [], "entities": []}, {"text": "Given a dataset of referring expression games, example human expressions, and their associated logical forms, we compute explicit denotations both for the original task and in other possible tasks-giving rise to a truth-conditional representation of the natural language.", "labels": [], "entities": []}, {"text": "We train a recurrent encoder-decoder model to solve the same tasks directly, and use the decoder to generate comparable truth-conditional representations of neural encodings.", "labels": [], "entities": []}, {"text": "One of the distinguishing features of natural language is compositionality: the existence of operations like negation and coordination that can be applied to utterances with predictable effects on meaning.", "labels": [], "entities": []}, {"text": "RNN models trained for natural language processing tasks have been found to learn representations that encode some of this compositional structure-for example, sentence representations for machine translation encode explicit features for certain syntactic phenomena ( and represent some semantic relationships translationally (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 189, "end_pos": 208, "type": "TASK", "confidence": 0.753954291343689}]}, {"text": "It is thus natural to ask whether these \"language-like\" structures also arise spontaneously in models trained directly from an environment signal.", "labels": [], "entities": []}, {"text": "Rather than using language as a form of supervision, we propose to use it as a probe-exploiting post-hoc statistical correspondences between natural language descriptions and neural encodings to discover regular structure in representation space.", "labels": [], "entities": []}, {"text": "To do this, we need to find (vector, string) pairs with matching semantics, which requires first aligning unpaired examples of human-human communication with network hidden states.", "labels": [], "entities": []}, {"text": "This is similar to the problem of \"translating\" RNN representations recently investigated in.", "labels": [], "entities": []}, {"text": "Here we build on that approach in order to perform a detailed analysis of compositional structure in learned \"languages\".", "labels": [], "entities": []}, {"text": "We investigate a communication game previously studied by, and make two discoveries: in a model trained without any access to language data, 1.", "labels": [], "entities": []}, {"text": "The strategies employed by human speakers in a given communicative context are surprisingly good predictors of RNN behavior in the same context: humans and RNNs send messages whose interpretations agree on nearly 90% of object-level decisions, even outside the contexts in which they were produced.", "labels": [], "entities": []}, {"text": "2. Interpretable language-like structure naturally arises in the space of representations.", "labels": [], "entities": []}, {"text": "We identify geometric regularities corresponding to negation, conjunction, and disjunction, and show that it is possible to linearly transform representations in ways that approximately correspond to these logical operations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Agreement with predicted model behavior for the  high-level semantic correspondence task, computed for ob- jects (single entries in tabular representation), worlds (rows),  and full tables. Referring expressions e generated by humans  in a single communicative context are highly predictive of  how learned representations f will be interpreted by the de- coder across multiple contexts.", "labels": [], "entities": []}, {"text": " Table 2: Agreement with predicted model behavior for nega- tion, conjunction, and disjunction tasks (top to bottom). Eval- uation is performed on transformed message vectors as de- scribed in Section 5. We discover a robust linear transforma- tion of message vectors corresponding to negation, as well as  evidence of structured representations of binary operations.", "labels": [], "entities": []}]}