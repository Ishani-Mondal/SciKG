{"title": [{"text": "Cheap Translation for Cross-Lingual Named Entity Recognition", "labels": [], "entities": [{"text": "Cross-Lingual Named Entity Recognition", "start_pos": 22, "end_pos": 60, "type": "TASK", "confidence": 0.6976279616355896}]}], "abstractContent": [{"text": "Recent work in NLP has attempted to deal with low-resource languages but still assumed a resource level that is not present for most languages, e.g., the availability of Wikipedia in the target language.", "labels": [], "entities": []}, {"text": "We propose a simple method for cross-lingual named entity recognition (NER) that works well in settings with very minimal resources.", "labels": [], "entities": [{"text": "cross-lingual named entity recognition (NER)", "start_pos": 31, "end_pos": 75, "type": "TASK", "confidence": 0.7362543089049203}]}, {"text": "Our approach makes use of a lexicon to \"translate\" annotated data available in one or several high resource language(s) into the target language, and learns a standard monolingual NER model there.", "labels": [], "entities": []}, {"text": "Further, when Wikipedia is available in the target language, our method can enhance Wikipedia based methods to yield state-of-the-art NER results; we evaluate on 7 diverse languages, improving the state-of-the-art by an average of 5.5% F1 points.", "labels": [], "entities": [{"text": "F1", "start_pos": 236, "end_pos": 238, "type": "METRIC", "confidence": 0.9990803003311157}]}, {"text": "With the minimal resources required , this is an extremely portable cross-lingual NER approach, as illustrated using a truly low-resource language, Uyghur.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, interest in the natural language processing (NLP) community has expanded to include multilingual applications.", "labels": [], "entities": [{"text": "natural language processing (NLP) community", "start_pos": 33, "end_pos": 76, "type": "TASK", "confidence": 0.7711870329720634}]}, {"text": "Although this uptick of interest has produced diverse annotated corpora, most languages are still classified as lowresource.", "labels": [], "entities": []}, {"text": "In order to build NLP tools for lowresource languages, we either need to annotate data (a costly exercise, especially for languages with few native speakers), or find away to use annotated data in other languages in service to the cause.", "labels": [], "entities": []}, {"text": "We refer to the latter techniques as crosslingual techniques.", "labels": [], "entities": []}, {"text": "In this paper, we address cross-lingual named: We show dramatic improvement on 3 European languages in a low-resource setting.", "labels": [], "entities": []}, {"text": "More detailed results in show that this improvement continues to a wide variety of languages.", "labels": [], "entities": []}, {"text": "The baseline is a simple direct transfer model.", "labels": [], "entities": []}, {"text": "The previous state-of-the-art (SOA) is  entity recognition (NER).", "labels": [], "entities": [{"text": "entity recognition (NER)", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.7986994981765747}]}, {"text": "Prior methods (described in detail in Section 2) depend heavily on limited and expensive resources such as Wikipedia or large parallel text.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.9374473690986633}]}, {"text": "Concretely, there are about 3800 written languages in the world.", "labels": [], "entities": []}, {"text": "Wikipedia exists in about 280 languages, but most versions are too sparse to be useful.", "labels": [], "entities": []}, {"text": "Parallel text maybe found on an ad-hoc basis for some languages, but it is hardly a general solution.", "labels": [], "entities": []}, {"text": "Religious texts, such as the Bible and the Koran, exist in many languages, but the unique domain makes them hard to use.", "labels": [], "entities": []}, {"text": "This leaves the vast majority of the world's languages with no general method for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9651980996131897}]}, {"text": "We propose a simple solution that requires only minimal resources.", "labels": [], "entities": []}, {"text": "We translate annotated data in a high-resource language into a low-resource language, using just a lexicon.", "labels": [], "entities": []}, {"text": "We refer to this as cheap translation, because in general, lexicons are much cheaper and easier to find than parallel text (.", "labels": [], "entities": []}, {"text": "One of the biggest efforts at gathering lexicons is Panlex (), which has lexicons for 10,000 language varieties available to download today.", "labels": [], "entities": [{"text": "Panlex", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.9586802124977112}]}, {"text": "The quality and size of these dic-tionaries may vary, but in Section 5.3 we showed that even small dictionaries can give improvements.", "labels": [], "entities": []}, {"text": "If there is no dictionary, or if the quality is poor, then the Uyghur case study outlined in Section 6 suggests that effort is best spent in developing a high-quality dictionary, rather than gathering questionable-quality parallel text.", "labels": [], "entities": []}, {"text": "We show that our approach gives non-trivial scores across several languages, and when combined with orthogonal features from Wikipedia, improves on state-of-the-art scores.", "labels": [], "entities": []}, {"text": "compares a simple direct transfer baseline, the previous state-of-the-art in cross-lingual NER, and our proposed algorithm.", "labels": [], "entities": []}, {"text": "For these languages, we beat the baseline by 25.4 points, and the state-of-the-art by 5.9 points.", "labels": [], "entities": []}, {"text": "In addition, we found that translating from a language related to the target language gives a further boost.", "labels": [], "entities": []}, {"text": "We conclude with a case study of a truly low-resource language, Uyghur, and show a good score, despite having almost no target language resources.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before we describe our experiments, we describe some of the tools we used.", "labels": [], "entities": []}, {"text": "We use data from CoNLL2002/2003 shared tasks).", "labels": [], "entities": [{"text": "CoNLL2002/2003 shared tasks", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.9128287434577942}]}, {"text": "The 4 languages represented are English, German, Spanish, and Dutch.", "labels": [], "entities": []}, {"text": "All training is on the train set, and testing is on the test set (TestB).", "labels": [], "entities": []}, {"text": "The evaluation metric for all experiments is phrase level F1, as explained in Tjong Kim Sang.", "labels": [], "entities": [{"text": "phrase level F1", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.791059136390686}, {"text": "Tjong Kim Sang", "start_pos": 78, "end_pos": 92, "type": "DATASET", "confidence": 0.8733319838841757}]}, {"text": "In order to experiment on a broader range of languages, we also use data from the RE-FLEX (, and LORELEI projects.", "labels": [], "entities": [{"text": "RE-FLEX", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.47227340936660767}, {"text": "LORELEI", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9620183706283569}]}, {"text": "From LORELEI, we use Turkish and Hausa From REFLEX, we use Bengali, Tamil, and Yoruba.", "labels": [], "entities": [{"text": "LORELEI", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.9452170729637146}, {"text": "REFLEX", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.8816776275634766}]}, {"text": "We use the same set of test documents as used in . We also use Hindi and Malayalam data from FIRE 2013, pre-processed to contain only PER, ORG, and LOC tags.", "labels": [], "entities": [{"text": "Malayalam data from FIRE 2013", "start_pos": 73, "end_pos": 102, "type": "DATASET", "confidence": 0.752763032913208}, {"text": "PER", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9754480123519897}, {"text": "ORG", "start_pos": 139, "end_pos": 142, "type": "METRIC", "confidence": 0.9585938453674316}, {"text": "LOC", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.8961867094039917}]}, {"text": "While several of these languages are decidedly high-resource, we limit the resources used in order to show that our techniques will work in truly low-resource settings.", "labels": [], "entities": []}, {"text": "In practice, this means generating training data where high-quality manually annotated data is already available, and using dictionaries where translation is available.", "labels": [], "entities": []}, {"text": "We performed two different sets of experiments: first translating only from English, then translating from additional languages selected to be similar to the target language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: We show dramatic improvement on 3 Eu- ropean languages in a low-resource setting. More  detailed results in", "labels": [], "entities": []}, {"text": " Table 2: Baseline is naive direct transfer, with no gazetteers. 'Cheap Translation' translates from English  into the target. Google Translate translates whole sentences, and does not use gazetteers. 'Cheap Trans- lation+Wiki' incorporates wikifier features. 'Best Combination' uses language combinations from Table  3 for source training data.  \u2020 denotes that this run does not use word features.", "labels": [], "entities": []}, {"text": " Table 4: F1 scores of official submissions in  LoReHLT16. The numbers in the \"All\" column  are the scores on the entire evaluation data re- ported from NIST. We evaluate our submissions  on the unsequestered data in order to compare with  the results in", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9993046522140503}, {"text": "LoReHLT16", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.9660794734954834}, {"text": "NIST", "start_pos": 153, "end_pos": 157, "type": "DATASET", "confidence": 0.951172947883606}]}, {"text": " Table 5: F1 scores for Uyghur. Monolingual  scores are on the 41 document test set. All other  scores are on the full unsequestered data. We omit  forms or gazetteers but use Brown clusters. 'Stan- dard Translation' uses the same resources as the  scores in Table 2 (e.g. without stemming)", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9987645149230957}, {"text": "41 document test set", "start_pos": 63, "end_pos": 83, "type": "DATASET", "confidence": 0.8034517467021942}]}]}