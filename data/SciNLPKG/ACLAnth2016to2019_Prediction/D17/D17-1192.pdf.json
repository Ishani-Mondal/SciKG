{"title": [{"text": "Noise-Clustered Distant Supervision for Relation Extraction: A Nonparametric Bayesian Perspective", "labels": [], "entities": [{"text": "Noise-Clustered Distant Supervision", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6937709947427114}, {"text": "Relation Extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.9755035936832428}]}], "abstractContent": [{"text": "For the task of relation extraction, distant supervision is an efficient approach to generate labeled data by aligning knowledge base with free texts.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.9323267340660095}]}, {"text": "The essence of it is a challenging incomplete multi-label classification problem with sparse and noisy features.", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.7121336460113525}]}, {"text": "To address the challenge, this work presents a novel nonparametric Bayesian formulation for the task.", "labels": [], "entities": []}, {"text": "Experiment results show substantially higher top-precision improvements over the traditional state-of-the-art approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "To efficiently generate structured relation information from free texts, the research on distantly supervised Relation Extraction (RE) () has been attracting much attention, because it can greatly reduce the manual annotation for training.", "labels": [], "entities": [{"text": "distantly supervised Relation Extraction (RE)", "start_pos": 89, "end_pos": 134, "type": "TASK", "confidence": 0.7528993359633854}]}, {"text": "It essentially based on the assumption that the relation between two entities in a Knowledge Base (KB), is also likely hold within a sentence that mentions the two entities in free texts.", "labels": [], "entities": []}, {"text": "This assumption plays a crucial role in distant supervision, which is quite effective in real applications.", "labels": [], "entities": [{"text": "distant supervision", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7154064178466797}]}, {"text": "However, the assumption of distant alignment can also lead to the noisy training corpus problem), which is challenging for the task as follows: i) Noisy features.", "labels": [], "entities": []}, {"text": "Not all relations existed in a KB keep the same meaning of that relation for the corresponding entities in a free text.", "labels": [], "entities": []}, {"text": "For example, the second relation mention in does not explicitly describe any relation instance, so features extracted from this sentence can be noisy.", "labels": [], "entities": []}, {"text": "Such analogous cases commonly exist in feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8066088557243347}]}, {"text": "Similar to noisy features, the gener-: Aligned Example (): the relation instances related to the entity pair BarackObama, U.S. in the KB, and its mentions in the free text.", "labels": [], "entities": [{"text": "U.S. in the KB", "start_pos": 122, "end_pos": 136, "type": "DATASET", "confidence": 0.6322810500860214}]}, {"text": "ated label can be incomplete due to the incomplete knowledge base ().", "labels": [], "entities": []}, {"text": "For example, the fourth relation mention in should be labeled by the relation Senate-of.", "labels": [], "entities": []}, {"text": "However, the corresponding relation instance (Senate-of(Barack Obama, U.S.)) is missing in the knowledge base.", "labels": [], "entities": []}, {"text": "Such analogous cases are also common in real applications.", "labels": [], "entities": []}, {"text": "Sophisticated features extracted from the mentions can result in a large number of sparse features (.", "labels": [], "entities": []}, {"text": "The generalization ability of feature based prediction models will be badly hurt, when the features do not match between testing and training.", "labels": [], "entities": []}, {"text": "To tackle the problem, we develop a novel distant supervision approach from a nonparametric Bayesian perspective (, along with the previously most effective research line) of using matrix completion) for relation extraction.", "labels": [], "entities": [{"text": "matrix completion", "start_pos": 181, "end_pos": 198, "type": "TASK", "confidence": 0.7075691819190979}, {"text": "relation extraction", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.9478550553321838}]}, {"text": "Our goal is to design a noise-tolerant relation extraction model for distantly supervised corpus with noise and sparsity problems.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7477176785469055}]}, {"text": "Different from) as one state-of-the-art method in this line, we model noisy data corpus using adaptive variance modeling approach , based on Dirichlet Process () instead of a fixed way of controlling complex noise weighting.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, we are the first to apply this technique on relation extraction with distant supervision.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.9480979442596436}]}], "datasetContent": [{"text": "We evaluate our method on two widely used datasets as shown in with the same setting in.", "labels": [], "entities": []}, {"text": "NYT'10, was developed by (.", "labels": [], "entities": [{"text": "NYT'10", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9427894949913025}]}, {"text": "NYT'13, was also released by (, in which they only regarded the lexicalized dependency path between two entities as features.", "labels": [], "entities": [{"text": "NYT'13", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9655652642250061}]}, {"text": "Both are automatically generated by aligning Freebase to New York Times corpus.", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 57, "end_pos": 78, "type": "DATASET", "confidence": 0.9053003340959549}]}, {"text": "For all the conducted experiments, the model hyperparameters are fixed without further tuning: a 0 = b 0 = 10 \u22124 , a 1 = b 1 = 0.1 and \u03b1 = 1.", "labels": [], "entities": []}, {"text": "Model comparison.) achieves the state-of-the-art performance on the two datasets, we mainly compare our method with that in the same setting, to verify the effectiveness.", "labels": [], "entities": []}, {"text": "NYT'10 dataset: indicates that our model achieves the highest precision performance among all of the competitors.", "labels": [], "entities": [{"text": "NYT'10 dataset", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9879895150661469}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9991806149482727}]}, {"text": "Although the recall performance is not competitive, the F1 score is also comparable to DRMC-b.(a) further shows the strong precision performance when the recall is not large.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9975181818008423}, {"text": "F1 score", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9827238619327545}, {"text": "DRMC-b.", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.7893275618553162}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9989362359046936}, {"text": "recall", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.9776216745376587}]}, {"text": "NYT'13 dataset:(b) illustrates that our approach outperforms the state-of-the-art methods, which shows that our approach can maintain a fairly high precision even when recall is larger.", "labels": [], "entities": [{"text": "NYT'13 dataset", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9918702840805054}, {"text": "precision", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9932489395141602}, {"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.9916734099388123}]}, {"text": "In addition, in practical applications, we also concern about the precision on: Results at the highest F1 point in the Precision-Recall (P-R) curve on NYT'13 dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9994799494743347}, {"text": "F1", "start_pos": 103, "end_pos": 105, "type": "METRIC", "confidence": 0.998699426651001}, {"text": "Precision-Recall (P-R) curve", "start_pos": 119, "end_pos": 147, "type": "METRIC", "confidence": 0.9186846733093261}, {"text": "NYT'13 dataset", "start_pos": 151, "end_pos": 165, "type": "DATASET", "confidence": 0.9830222427845001}]}, {"text": "shows that our model achieves much significant improvements on that.", "labels": [], "entities": []}, {"text": "Moreover, shows that our method can achieve the best F1, compared with the baselines.", "labels": [], "entities": [{"text": "F1", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9995036125183105}]}, {"text": "NYT'10 and NYT'13 have different performance records, which could be explained as follows.", "labels": [], "entities": [{"text": "NYT'10", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9740104079246521}, {"text": "NYT'13", "start_pos": 11, "end_pos": 17, "type": "DATASET", "confidence": 0.8722145557403564}]}, {"text": "From the dataset perspective, NYT'10 is a dataset with multi-label instances, which is more complex than NYT'13 only having single label instances.", "labels": [], "entities": [{"text": "NYT'10", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.9336594343185425}, {"text": "NYT'13", "start_pos": 105, "end_pos": 111, "type": "DATASET", "confidence": 0.9302365183830261}]}, {"text": "This is one reason of why the trends are quite different between them.", "labels": [], "entities": []}, {"text": "More essentially, we further discuss the differences from the model mechanism perspective, to explain the reasons.", "labels": [], "entities": []}, {"text": "In)'s work, it has no explicit noise modeling mechanism.", "labels": [], "entities": []}, {"text": "The noise is modeled implicitly as the error of cost functions.", "labels": [], "entities": []}, {"text": "From the probabilistic view, that error is sampled from single Gaussian with zero mean and fixed variance.", "labels": [], "entities": []}, {"text": "In contrast, our method uses infinite Gaussian with automatically learnt variance.", "labels": [], "entities": []}, {"text": "It may cause overfitting for complex dataset with sparse features.", "labels": [], "entities": []}, {"text": "In addition, we guess the reason is that in)'s work, they use two separate cost functions for features and labels, while in our work we use one unified noise component for both of them, which shows the promising precision performance in NYT'10 when recall is less than 0.4.", "labels": [], "entities": [{"text": "precision", "start_pos": 212, "end_pos": 221, "type": "METRIC", "confidence": 0.9979956150054932}, {"text": "NYT'10", "start_pos": 237, "end_pos": 243, "type": "DATASET", "confidence": 0.9338529706001282}, {"text": "recall", "start_pos": 249, "end_pos": 255, "type": "METRIC", "confidence": 0.9977259039878845}]}, {"text": "In addition, in our experiments, we found that early stopping is crucial for achieving good results while model learning.", "labels": [], "entities": []}, {"text": "This also verifies that the potential overfitting problem should be further considered while using the more flexible nonparametric method for NLP task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics about the two widely used datasets.", "labels": [], "entities": []}, {"text": " Table 3: Precision of Top-N predicted instances  on NYT'13 dataset. NFE-13 (Riedel et al., 2013);  DRMC-b(1) (Fan et al., 2014).", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9615286588668823}, {"text": "NYT'13 dataset", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.9811391532421112}, {"text": "NFE-13", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.8832862377166748}, {"text": "DRMC-b", "start_pos": 100, "end_pos": 106, "type": "DATASET", "confidence": 0.8730543255805969}]}, {"text": " Table 4: Results at the highest F1 point in the  Precision-Recall (P-R) curve on NYT'13 dataset.  DRMC-b(1)", "labels": [], "entities": [{"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9991697072982788}, {"text": "Precision-Recall (P-R) curve", "start_pos": 50, "end_pos": 78, "type": "METRIC", "confidence": 0.9296780824661255}, {"text": "NYT'13 dataset", "start_pos": 82, "end_pos": 96, "type": "DATASET", "confidence": 0.9856315851211548}, {"text": "DRMC-b", "start_pos": 99, "end_pos": 105, "type": "DATASET", "confidence": 0.8792031407356262}]}]}