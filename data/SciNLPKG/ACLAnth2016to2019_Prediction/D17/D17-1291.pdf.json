{"title": [{"text": "Identifying Semantically Deviating Outlier Documents *", "labels": [], "entities": [{"text": "Identifying Semantically Deviating Outlier Documents", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.9046773433685302}]}], "abstractContent": [{"text": "A document outlier is a document that substantially deviates in semantics from the majority ones in a corpus.", "labels": [], "entities": []}, {"text": "Automatic identification of document outliers can be valuable in many applications, such as screening health records for medical mistakes.", "labels": [], "entities": [{"text": "Automatic identification of document outliers", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7387406408786774}]}, {"text": "In this paper, we study the problem of mining semantically deviating document outliers in a given corpus.", "labels": [], "entities": []}, {"text": "We develop a generative model to identify frequent and characteristic semantic regions in the word embedding space to represent the given corpus, and a robust outlierness measure which is resistant to noisy content in documents.", "labels": [], "entities": []}, {"text": "Experiments conducted on two real-world textual data sets show that our method can achieve an up to 135% improvement over baselines in terms of recall at top-1% of the outlier ranking.", "labels": [], "entities": [{"text": "recall", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.999306321144104}]}], "introductionContent": [{"text": "The technology today has made it unprecedentedly easy to collect and store documents in an increasing number of domains.", "labels": [], "entities": []}, {"text": "Automatic text analysis (e.g. document clustering, summarization, topic modeling) becomes more useful and demanded as the corpus size grows.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.741412878036499}, {"text": "document clustering", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7209793925285339}, {"text": "summarization", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.9501005411148071}, {"text": "topic modeling", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.7223266363143921}]}, {"text": "Some trending * Research was sponsored in part by the U.S. Army Research Lab.", "labels": [], "entities": [{"text": "U.S. Army Research Lab", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.6777991950511932}]}, {"text": "under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), National Science Foundation IIS-1320617, IIS 16-18481, and NSF IIS 17-04532, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov).", "labels": [], "entities": [{"text": "National Science Foundation IIS-1320617", "start_pos": 58, "end_pos": 97, "type": "DATASET", "confidence": 0.91054268181324}, {"text": "NSF IIS 17-04532", "start_pos": 117, "end_pos": 133, "type": "DATASET", "confidence": 0.8176233371098837}]}, {"text": "The views and conclusions contained in this document are those of the author(s) and should not be interpreted as representing the official policies of the U.S. Army Research Laboratory or the U.S. Government.", "labels": [], "entities": []}, {"text": "The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.", "labels": [], "entities": []}, {"text": "domains (e.g. health records) call fora new analytical task, mining outlier documents: given a corpus, identify a small number of documents which substantially deviate from the semantic focuses of the given corpus.", "labels": [], "entities": []}, {"text": "Outlier documents can provide valuable insights or imply potential errors.", "labels": [], "entities": []}, {"text": "For example, an outlier health record from records of the same disease could indicate anew variation of the disease if it has an abnormal symptom description, or a medical error if it has an abnormal treatment description.", "labels": [], "entities": []}, {"text": "A previous study) uses structured data in health records to show the importance of this application, and points out that further improvement should be achieved by leveraging text data.", "labels": [], "entities": []}, {"text": "Existing work has studied a related albeit different task, novel document detection), where one aims to identify from a document stream if a newly arriving document is novel or redundant.", "labels": [], "entities": [{"text": "novel document detection", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.6811710596084595}]}, {"text": "In other words, this task assumes all the previous documents are known to be \"normal\", and only checks if anew document is novel.", "labels": [], "entities": []}, {"text": "In our task, no document is known to be normal, and there could be multiple outliers in the corpus.", "labels": [], "entities": []}, {"text": "Outlier detection () is a popular topic in data mining but few focus on text data.", "labels": [], "entities": [{"text": "Outlier detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8467671275138855}, {"text": "data mining", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.7347159832715988}]}, {"text": "A study identifies anomalous text segments in a document, but mainly based on writing styles.", "labels": [], "entities": []}, {"text": "We focus on studying semantically deviating documents.", "labels": [], "entities": []}, {"text": "The problem of detecting outlier documents has its unique challenges.", "labels": [], "entities": []}, {"text": "First, different words or phrases maybe used to indicate the same semantic meaning, which introduces lexical sparsity.", "labels": [], "entities": []}, {"text": "Second, finding proper words or phrases to characterize the corpus is non-trivial.", "labels": [], "entities": []}, {"text": "Semantically frequent words or phrases can still be too general or too vague.", "labels": [], "entities": []}, {"text": "Third, a document can carry extremely rich and noisy signals, most of which are not helpful to determine whether it is an outlier.", "labels": [], "entities": []}, {"text": "We tackle the problem of mining outlier documents in the following steps.", "labels": [], "entities": []}, {"text": "We leverage word embedding () to capture the semantic proximities between words and/or phrases, in order to solve the sparsity issue.", "labels": [], "entities": []}, {"text": "Then we propose a generative model to identify semantic regions in the embedded space frequently mentioned by documents in the corpus.", "labels": [], "entities": []}, {"text": "The model represents each semantic region with a von MisesFisher distribution.", "labels": [], "entities": []}, {"text": "We also learn a concentration parameter for each region with our model, and develop a selection method to identify semantically specific regions which can better represent the corpus, and filter regions with largely uninformative words.", "labels": [], "entities": []}, {"text": "As the final step, we design a robust outlierness measure emphasizing only the words or phrases in a document relatively close to the semantic focuses identified, and eliminating the noises and redundant information.", "labels": [], "entities": []}, {"text": "The remaining of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the preprocessing of data sets and clarifies the notations.", "labels": [], "entities": []}, {"text": "Section 3 proposes the methodology to mine outlier documents.", "labels": [], "entities": []}, {"text": "Section 4 describes the experiment setup, Section 5 presents the results and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In most outlier detection applications, people are more concerned with recall.", "labels": [], "entities": [{"text": "outlier detection", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7778226137161255}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9969229102134705}]}, {"text": "We measure the performance by recall at a certain percentage.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9994532465934753}]}, {"text": "More specifically, we compute the recall of outlier detection if the user checks a certain percentage r of the top-ranked documents in the output results.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9988952875137329}, {"text": "outlier detection", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.695571094751358}]}, {"text": "Since in our benchmark generation, the percentage of outliers does not exceed 1%.", "labels": [], "entities": []}, {"text": "Therefore, the perfect results for any r \u2265 1% should be 1.0.", "labels": [], "entities": []}, {"text": "We chooser to be 1%, 2%, and 5% respectively and evaluate different methods with recall at top-r (percentage).", "labels": [], "entities": [{"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9993435740470886}]}, {"text": "We also report the performance in terms of mean average precision (MAP).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 43, "end_pos": 71, "type": "METRIC", "confidence": 0.9150509933630625}]}], "tableCaptions": [{"text": " Table 1: Data set statistics.", "labels": [], "entities": []}, {"text": " Table 2: Performance comparison of different out- lier document detection methods. All results are  shown as percents.", "labels": [], "entities": [{"text": "out- lier document detection", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6615516602993011}]}]}