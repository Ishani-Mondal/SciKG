{"title": [{"text": "A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Learning word embeddings has received a significant amount of attention recently.", "labels": [], "entities": []}, {"text": "Often, word embeddings are learned in an unsupervised manner from a large collection of text.", "labels": [], "entities": []}, {"text": "The genre of the text typically plays an important role in the effectiveness of the resulting embeddings.", "labels": [], "entities": []}, {"text": "How to effectively train word embedding models using data from different domains remains a problem that is underexplored.", "labels": [], "entities": []}, {"text": "In this paper, we present a simple yet effective method for learning word embeddings based on text from different domains.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of our approach through extensive experiments on various downstream NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, the learning of distributed representations for natural language words (or word embeddings) has received a significant amount of attention (.", "labels": [], "entities": []}, {"text": "Such representations were shown to be able to capture syntactic and semantic level information associated with words (.", "labels": [], "entities": []}, {"text": "Word embeddings were shown effective in tasks such as named entity recognition, sentiment analysis ( and syntactic parsing.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6562576492627462}, {"text": "sentiment analysis", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.9621147513389587}, {"text": "syntactic parsing", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7248319983482361}]}, {"text": "One common assumption made by most of the embedding methods is that, the text corpus is from one single domain; e.g., articles from bioinformatics.", "labels": [], "entities": []}, {"text": "However, in practice, there are often text corpora from multiple domains; e.g., we may have text collections from broadcast news or Web blogs, whose words are not necessarily limited to bioinformatics.", "labels": [], "entities": []}, {"text": "Can these corpora from different domains help learn better word embeddings, so as to improve the downstream NLP applications in a target domain like bioinformatics?", "labels": [], "entities": []}, {"text": "Our answer is yes, because despite the domain differences, these additional domains do introduce more text data converying useful information (i.e., more words, more word co-occurrences), which can be helpful for consolidating the word embeddings in the target bioinformatics domain.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple and easyto-implement approach for learning cross-domain word embeddings.", "labels": [], "entities": []}, {"text": "Our model can be seen as a regularized skip-gram model (, where the source domain information is selectively incorporated for learning the target domain word embeddings in a principled manner.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present extensive evaluations to assess the effectiveness of our approach.", "labels": [], "entities": []}, {"text": "Following recent advice by and, to assess the quality of the learned word embeddings, we considered employing the learned word embeddings as continuous features in several down-stream NLP tasks, including entity recognition, sentiment classification, and targeted sentiment analysis.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 205, "end_pos": 223, "type": "TASK", "confidence": 0.8378550410270691}, {"text": "sentiment classification", "start_pos": 225, "end_pos": 249, "type": "TASK", "confidence": 0.94151571393013}, {"text": "targeted sentiment analysis", "start_pos": 255, "end_pos": 282, "type": "TASK", "confidence": 0.676210621992747}]}, {"text": "We have used various datasets from different domains for learning cross-domain word embeddings under different tasks.", "labels": [], "entities": []}, {"text": "We list the data statistics in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for datasets used for embedding learning in all experiments.", "labels": [], "entities": []}, {"text": " Table 2: Results on entity recognition.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.895595133304596}]}, {"text": " Table 3: Results on targeted sentiment analysis.", "labels": [], "entities": [{"text": "targeted sentiment analysis", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.8123166362444559}]}]}