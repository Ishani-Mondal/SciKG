{"title": [{"text": "Investigating Different Syntactic Context Types and Context Representations for Learning Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "The number of word embedding models is growing every year.", "labels": [], "entities": []}, {"text": "Most of them are based on the co-occurrence information of words and their contexts.", "labels": [], "entities": []}, {"text": "However, it is still an open question what is the best definition of context.", "labels": [], "entities": []}, {"text": "We provide a system-atical investigation of 4 different syntactic context types and context representations for learning word embeddings.", "labels": [], "entities": []}, {"text": "Comprehensive experiments are conducted to evaluate their effectiveness on 6 extrinsic and intrinsic tasks.", "labels": [], "entities": []}, {"text": "We hope that this paper , along with the published code, would be helpful for choosing the best context type and representation fora given task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, there is a growing interest in word embedding models, where words are embedded into low-dimensional (dense) real-valued vectors.", "labels": [], "entities": []}, {"text": "The trained word embeddings can be directly used for solving intrinsic tasks like word similarity and word analogy.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.7488663792610168}, {"text": "word analogy", "start_pos": 102, "end_pos": 114, "type": "TASK", "confidence": 0.7837028801441193}]}, {"text": "They are also helpful for solving extrinsic tasks, such as part-of-speech tagging, chunking, named entity recognition) and text classification (.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7076195180416107}, {"text": "named entity recognition", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.6176687180995941}, {"text": "text classification", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.8184517920017242}]}, {"text": "The training objectives of word embedding models are based on the Distributional Hypothesis) that can be stated as follows: \"words that occur in similar contexts tend to have similar meanings\".", "labels": [], "entities": []}, {"text": "In most word embedding models, the \"context\" is defined as the words which precede and follow the target word within some fixed distance ().", "labels": [], "entities": []}, {"text": "Among them, Global Vectors (GloVe) proposed by, Continuous Skip-Gram (CSG) and Continuous BagOf-Words (CBOW) proposed by achieve state-of-the-art results on a range of linguistic tasks, and scale to corpora with billions of words.", "labels": [], "entities": []}, {"text": "The traditional sparse vector-space models have explored many different types of context.;; have discussed a set of context definitions beyond simple linear context.", "labels": [], "entities": []}, {"text": "For example, a sentence or document could be used as the boundary instead of window size.", "labels": [], "entities": []}, {"text": "Contextual words could be associated with their relative sides (left/right) or positions (+1/-2) to the target word.", "labels": [], "entities": []}, {"text": "They could also be associated with part-of-speech or grammatical relation labels.", "labels": [], "entities": []}, {"text": "The weight of each contextual word can be explicitly defined.", "labels": [], "entities": []}, {"text": "Moreover, words that are connected to target word in dependency parse: Summary of prior research on word embedding models with different syntactic context types and context representations.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.7116008251905441}]}, {"text": "For linear context, bound indicates words associated with positional information.", "labels": [], "entities": []}, {"text": "For DEPS context, bound indicates words associated with dependency relation.", "labels": [], "entities": []}, {"text": "tree can be considered as context.", "labels": [], "entities": []}, {"text": "Recent word embedding models have also explored some of the above context types.; improve CSG and CBOW by introducing positionaware context representation.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 98, "end_pos": 102, "type": "DATASET", "confidence": 0.7179329991340637}]}, {"text": "propose dependency-based context (DEP-S) for CSG.", "labels": [], "entities": []}, {"text": "However, different types of syntactic context have not been systematically compared for different word embeddings.", "labels": [], "entities": []}, {"text": "This paper explores two context types (linear or DEPS) and two context representations (bound or unbound), as shown in.", "labels": [], "entities": []}, {"text": "Three popular word embedding models (CBOW, GloVe, and CSG) are compared on word similarity, word analogy, part-of-speech tagging, chunking, named entity recognition, and text classification tasks.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7100945264101028}, {"text": "word analogy", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.778035044670105}, {"text": "part-of-speech tagging", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.71123106777668}, {"text": "named entity recognition", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.6040451327959696}, {"text": "text classification tasks", "start_pos": 170, "end_pos": 195, "type": "TASK", "confidence": 0.8189785679181417}]}], "datasetContent": [{"text": "We experiment with 3 training conditions: BOW5 (bag-of-words contexts with k = 5), BOW2 (same, with k = 2) and DEPS (dependency-based syntactic contexts).", "labels": [], "entities": [{"text": "BOW5", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.8574360609054565}, {"text": "BOW2", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9345260858535767}, {"text": "DEPS", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.8974729776382446}]}, {"text": "We modified word2vec to support arbitrary contexts, and to output the context embeddings in addition to the word embeddings.", "labels": [], "entities": []}, {"text": "For bag-of-words contexts we used the original word2vec implementation, and for syntactic contexts, we used our modified version.", "labels": [], "entities": []}, {"text": "The negative-sampling parameter (how many negative contexts to sample for every correct one) was 15.", "labels": [], "entities": []}, {"text": "We evaluate the effectiveness of different syntactic context types and context representations on word similarity, word analogy, part-of-speech tagging, chunking, named entity recognition, and text classification tasks.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.7189712077379227}, {"text": "word analogy", "start_pos": 115, "end_pos": 127, "type": "TASK", "confidence": 0.7729580998420715}, {"text": "part-of-speech tagging", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.7255669236183167}, {"text": "named entity recognition", "start_pos": 163, "end_pos": 187, "type": "TASK", "confidence": 0.6381267309188843}, {"text": "text classification tasks", "start_pos": 193, "end_pos": 218, "type": "TASK", "confidence": 0.825507660706838}]}, {"text": "In this section we describe our models, and then report and discuss the experimental results on each task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Numerical results on word similarity datasets. Best results in group are marked Bold.", "labels": [], "entities": []}, {"text": " Table 5: Numerical results on word analogy datasets. Best results in group are marked Bold.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.7109333425760269}]}, {"text": " Table 6: Numerical results on Part-of-Speech Tag- ging, Chunking and Named Entity Recognition  tasks. Best results in group are marked Bold.", "labels": [], "entities": [{"text": "Part-of-Speech Tag- ging", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.7057235240936279}, {"text": "Chunking and Named Entity Recognition  tasks", "start_pos": 57, "end_pos": 101, "type": "TASK", "confidence": 0.6881552239259084}]}, {"text": " Table 7: Accuracy results on 5 text classification  datasets. Best results in group are Bold", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990725517272949}, {"text": "text classification", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.6912166923284531}]}]}