{"title": [{"text": "Identifying Humor in Reviews using Background Text Sources", "labels": [], "entities": [{"text": "Identifying Humor in Reviews", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9213111400604248}]}], "abstractContent": [{"text": "We study the problem of automatically identifying humorous text from anew kind of text data, i.e., online reviews.", "labels": [], "entities": []}, {"text": "We propose a generative language model, based on the theory of incongruity, to model humorous text, which allows us to leverage background text sources, such as Wikipedia entry descriptions, and enables construction of multiple features for identifying humorous reviews.", "labels": [], "entities": []}, {"text": "Evaluation of these features using supervised learning for classifying reviews into humorous and non-humorous reviews shows that the features constructed based on the proposed generative model are much more effective than the major features proposed in the existing literature, allowing us to achieve almost 86% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 312, "end_pos": 320, "type": "METRIC", "confidence": 0.9975415468215942}]}, {"text": "These humorous review predictions can also supply good indicators for identifying helpful reviews.", "labels": [], "entities": []}], "introductionContent": [{"text": "The growth of online feedback systems, such as online reviews in which users can write about their preferences and opinions, has allowed for creativity in the written communication of user ideas.", "labels": [], "entities": []}, {"text": "As such, these feedback systems have become ubiquitous, and it's not difficult to imagine a future with smart systems reacting to user's behaviour in a human-like manner).", "labels": [], "entities": []}, {"text": "An essential component for personal communication is the expression of humor.", "labels": [], "entities": []}, {"text": "Although many people have studied the theory of humor, it still remains loosely defined, this leads to difficulties in modelling humor.", "labels": [], "entities": []}, {"text": "While the task for identifying humor in text has been previously studied, most approaches have focused on shorter text such as Twitter data) (see Section 6 fora more complete review of related work).", "labels": [], "entities": [{"text": "identifying humor in text", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.88889080286026}]}, {"text": "In this paper, we study the problem of automatically identifying humorous text from anew kind of text data, i.e., online reviews.", "labels": [], "entities": []}, {"text": "In order to quantitatively test whether the review is humorous, we devise a novel approach, using the theory of incongruity, to model the reviewer's humorous intent when writing the review.", "labels": [], "entities": []}, {"text": "The theory of incongruity states that we laugh because there is something incongruous, in other words, there is a change from our expectation.", "labels": [], "entities": []}, {"text": "Specifically, we propose a general generative language model to model the generation of humorous text.", "labels": [], "entities": []}, {"text": "The proposed model is a mixture model with multinomial distributions as component models (i.e., models of topics), similar to Probabilistic Latent Semantic Analysis.", "labels": [], "entities": [{"text": "Probabilistic Latent Semantic Analysis", "start_pos": 126, "end_pos": 164, "type": "TASK", "confidence": 0.5296441167593002}]}, {"text": "However, the main difference is that the component word distributions (i.e., component language models) are all assumed to be known in our model, and they are designed to model the two types of language used in a humorous text, including 1) the general background model estimated using all the reviews, and 2) the reference language models of all the topical aspects covered in the review that capture the typical words used when each of the covered aspects is discussed.", "labels": [], "entities": []}, {"text": "Thus the model only has the parameters indicating the relative coverage of these component language models.", "labels": [], "entities": []}, {"text": "The idea here is to use these parameters to assess how well a review can be explained by collectively by the reference language models corresponding to all the topical aspects covered in the review, which are estimated using an external text source (e.g., Wikipedia).", "labels": [], "entities": []}, {"text": "We construct multiple features based on the generative model and evaluate them using supervised learning for classifying reviews into humorous and non-humorous reviews.", "labels": [], "entities": []}, {"text": "Experiment re-sults on a Yelp 1 review data set show that the features constructed based on the proposed generative model are much more effective than the major features proposed in the existing literature, allowing us to achieve almost 86% accuracy.", "labels": [], "entities": [{"text": "Yelp 1 review data set", "start_pos": 25, "end_pos": 47, "type": "DATASET", "confidence": 0.9673058271408081}, {"text": "generative", "start_pos": 105, "end_pos": 115, "type": "TASK", "confidence": 0.9626870155334473}, {"text": "accuracy", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.9980764389038086}]}, {"text": "We also experimented with using the results of humorous review prediction to further predict helpful reviews, and the results show that humorous review prediction can supply good indicators for identifying helpful reviews for consumers.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments we obtained the reviews from the Yelp Dataset Challenge 5 , this dataset contains over 1.6 million reviews from 10 different cities.", "labels": [], "entities": [{"text": "Yelp Dataset Challenge 5", "start_pos": 53, "end_pos": 77, "type": "DATASET", "confidence": 0.9824994206428528}]}, {"text": "We also crawled reviews from Yelp in the Los Angeles area which is not included in the  Yelp Dataset Challenge.", "labels": [], "entities": [{"text": "Yelp Dataset Challenge", "start_pos": 88, "end_pos": 110, "type": "DATASET", "confidence": 0.9444454709688822}]}, {"text": "This dataset was particularly interesting since the readers are able to vote whether a review is considered cool, funny, and/or helpful.", "labels": [], "entities": []}, {"text": "It also allows the flexibility for the reviewers to write longer pieces of text to express their overall rating of a restaurant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification accuracies, using 5-fold cross validation, the 95% confidence is given inside the  parenthesis.", "labels": [], "entities": []}, {"text": " Table 2: Precision of useful reviews.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.961713433265686}]}]}