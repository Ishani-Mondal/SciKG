{"title": [{"text": "Dict2vec : Learning Word Embeddings using Lexical Dictionaries", "labels": [], "entities": []}], "abstractContent": [{"text": "Learning word embeddings on large unla-beled corpus has been shown to be successful in improving many natural language tasks.", "labels": [], "entities": []}, {"text": "The most efficient and popular approaches learn or retrofit such representations using additional external data.", "labels": [], "entities": []}, {"text": "Resulting embeddings are generally better than their corpus-only counterparts, although such resources cover a fraction of words in the vocabulary.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew approach, Dict2vec, based on one of the largest yet refined datasource for describing words-natural language dictionaries.", "labels": [], "entities": []}, {"text": "Dict2vec builds new word pairs from dictionary entries so that semantically-related words are moved closer, and negative sampling filters out pairs whose words are unrelated in dictionaries.", "labels": [], "entities": []}, {"text": "We evaluate the word representations obtained using Dict2vec on eleven datasets for the word similarity task and on four datasets fora text classification task.", "labels": [], "entities": [{"text": "word similarity task", "start_pos": 88, "end_pos": 108, "type": "TASK", "confidence": 0.7792311211427053}, {"text": "text classification task", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.7668552696704865}]}], "introductionContent": [{"text": "Learning word embeddings usually relies on the distributional hypothesis -words appearing in similar contexts must have similar meanings, and thus close representations.", "labels": [], "entities": [{"text": "Learning word embeddings", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6616394420464834}]}, {"text": "Finding such representations for words and sentences has been one hot topic over the last few years in Natural Language Processing (NLP) () and has led to many improvements in core NLP tasks such as Word Sense Disambiguation (, Machine Translation (), Machine Comprehension (, and Semantic Role Labeling () -to name a few.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 199, "end_pos": 224, "type": "TASK", "confidence": 0.7046784162521362}, {"text": "Machine Translation", "start_pos": 228, "end_pos": 247, "type": "TASK", "confidence": 0.807814747095108}, {"text": "Semantic Role Labeling", "start_pos": 281, "end_pos": 303, "type": "TASK", "confidence": 0.7499943772951762}]}, {"text": "These methods suffer from a classic drawback of unsupervised learning: the lack of supervision between a word and those appearing in the associated contexts.", "labels": [], "entities": []}, {"text": "Indeed, it is likely that some terms of the context are not related to the considered word.", "labels": [], "entities": []}, {"text": "On the other hand, the fact that two words do not appear together -or more likely, not often enough together -in any context of the training corpora is not a guarantee that these words are not semantically related.", "labels": [], "entities": []}, {"text": "Recent approaches have proposed to tackle this issue using an attentive model for context selection (, or by using external sources -like knowledge graphsin order to improve the embeddings ( ).", "labels": [], "entities": [{"text": "context selection", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7396241426467896}]}, {"text": "Similarities derived from such resources are part of the objective function during the learning phase ( or used in a retrofitting scheme.", "labels": [], "entities": []}, {"text": "These approaches tend to specialize the embeddings to the resource used and its associated similarity measures -while the construction and maintenance of these resources area set of complex, time-consuming, and error-prone tasks.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel word embedding learning strategy, called Dict2vec, that leverages existing online natural language dictionaries.", "labels": [], "entities": []}, {"text": "We assume that dictionary entries (a definition of a word) contain latent word similarity and relatedness information that can improve language representations.", "labels": [], "entities": []}, {"text": "Such entries provide, in essence, an additional context that conveys general semantic coverage for most words.", "labels": [], "entities": []}, {"text": "Dict2vec adds new co-occurrences information based on the terms occurring in the definitions of a word.", "labels": [], "entities": []}, {"text": "This information introduces weak supervision that can be used to improve the embeddings.", "labels": [], "entities": []}, {"text": "We can indeed distinguish word pairs for which each word appears in the definition of the other (strong pairs) and pairs where only one appears in the definition of the other (weak pairs) -each having their own weight as two hyperparameters.", "labels": [], "entities": []}, {"text": "Not only this information is useful at learning time to control words vectors to be close for such word pairs, but also it becomes possible to devise a controlled negative sampling.", "labels": [], "entities": []}, {"text": "Controlled negative sampling as introduced in Dict2vec consists in filtering out random negative examples in conventional negative sampling that forms a (strong or weak) pair with the target word -they are obviously non-negative examples.", "labels": [], "entities": []}, {"text": "Processing online dictionaries in Dict2vec does not require a human-in-the-loop -it is fully automated.", "labels": [], "entities": []}, {"text": "The neural network architecture from Dict2vec (Section 3) extends Word2vec () approach which uses a Skip-gram model with negative sampling.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.9343408942222595}]}, {"text": "Our main results are as follows : \u2022 Dict2vec exhibits a statistically significant improvement around 12.5% against state-ofthe-art solutions on eleven most common evaluation datasets for the word similarity task when embeddings are learned using the full Wikipedia dump.", "labels": [], "entities": [{"text": "word similarity task", "start_pos": 191, "end_pos": 211, "type": "TASK", "confidence": 0.8139333724975586}]}, {"text": "\u2022 This edge is even more significant for small training datasets (50 millions first tokens of Wikipedia) than using the full dataset, as the average improvement reaches 30%.", "labels": [], "entities": []}, {"text": "\u2022 Since Dict2vec does significantly better than competitors for small dimensions (in the range) for small corpus, it can yield smaller yet efficient embeddings -even when trained on smaller corpus -which is one of the utmost practical interest for the working natural language processing practitioners.", "labels": [], "entities": []}, {"text": "\u2022 We also show that the embeddings learned by Dict2vec perform similarly to other baselines on an extrinsic text classification task.", "labels": [], "entities": [{"text": "extrinsic text classification task", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.6920993030071259}]}, {"text": "Dict2vec software is an extension and an optimization from the original Word2vec framework leading to a more efficient learning.", "labels": [], "entities": [{"text": "Word2vec framework", "start_pos": 72, "end_pos": 90, "type": "DATASET", "confidence": 0.9305291473865509}]}, {"text": "Source code to fetch dictionaries, train Dict2vec models and evaluate word embeddings are publicly availabe 1 and can be used by the community as a seed for future works.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents related works, along with a special focus on Word2vec, which we later derive in our 1 https://github.com/tca19/dict2vec approach presented in Section 3.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.95543372631073}]}, {"text": "Our experimental setup and evaluation settings are introduced in Section 4 and we discuss the results in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We follow the standard method for word similarity evaluation by computing the Spearman's rank correlation coefficient between human similarity evaluation of pairs of words, and the cosine similarity of the corresponding word vectors.", "labels": [], "entities": [{"text": "word similarity evaluation", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.8095899820327759}, {"text": "Spearman's rank correlation coefficient", "start_pos": 78, "end_pos": 117, "type": "METRIC", "confidence": 0.7006132006645203}]}, {"text": "A score close to 1 indicates an embedding close to the human judgement.) classic datasets.", "labels": [], "entities": [{"text": "classic datasets", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.750158965587616}]}, {"text": "We follow the same protocol used by Word2vec and fastText by discarding pairs which contain a word that is not in our embedding.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.9175553917884827}]}, {"text": "Since all models are trained with the same corpora, the embeddings have the same words, therefore all competitors share the same OOV rates.", "labels": [], "entities": [{"text": "OOV", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.9321669936180115}]}, {"text": "We run each experiment 3 times and report in the average score to minimize the effect of the neural network random initialization.", "labels": [], "entities": []}, {"text": "We compute the average by weighting each score by the number of pairs evaluated in its dataset in the same way as.", "labels": [], "entities": []}, {"text": "We multiply each score by 1, 000 to improve readability.", "labels": [], "entities": []}, {"text": "Our text classification task follows the same setup as the one for fastText in . We train a neural network composed of a single hidden layer where the input layer corresponds to the bag of words of a document and the output layer is the probability to belong to each label.", "labels": [], "entities": [{"text": "text classification", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.791231095790863}]}, {"text": "The weights between the input and the hidden layer are initialized with the generated embeddings and are fixed during training, so that the evaluation score solely depends on the embedding.", "labels": [], "entities": []}, {"text": "We update the weights of the neural network classifier with gradient descent.", "labels": [], "entities": []}, {"text": "We use the datasets AG-News 6 , DBpedia ( and Yelp reviews (polarity and full) . We split each datasets into a training and a test file.", "labels": [], "entities": [{"text": "AG-News 6", "start_pos": 20, "end_pos": 29, "type": "DATASET", "confidence": 0.836350679397583}, {"text": "DBpedia", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.8627076745033264}]}, {"text": "We use the same training and test files for all models and report the classification accuracy obtained on the test file.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9011372923851013}]}], "tableCaptions": [{"text": " Table 1: Training time (in min) of Word2vec, fast- Text and Dict2vec models for several corpus.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.9626349806785583}]}, {"text": " Table 2: Spearman's rank correlation coefficients between vectors' cosine similarity and human judge- ment for several datasets (top) and accuracies on text classification task (bottom). We train and evaluate  each model 3 times and report the average score for each dataset, as well as the weighted average for all  word similarity datasets.", "labels": [], "entities": [{"text": "text classification", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.7650863826274872}]}, {"text": " Table 4: Weighted average Spearman correla- tion score of raw vectors and after retrofitting  with WordNet pairs (R W N ) and dictionary pairs  (R dict ).", "labels": [], "entities": []}, {"text": " Table 5: Weighted average Spearman correlation  score of Dict2vec vectors when trained without  pairs and with WordNet or dictionary pairs.", "labels": [], "entities": [{"text": "Spearman correlation  score", "start_pos": 27, "end_pos": 54, "type": "METRIC", "confidence": 0.7326845725377401}]}]}