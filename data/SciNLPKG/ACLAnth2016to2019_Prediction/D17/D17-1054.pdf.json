{"title": [{"text": "Capturing User and Product Information for Document Level Sentiment Analysis with Deep Memory Network", "labels": [], "entities": [{"text": "Document Level Sentiment Analysis", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.7345238029956818}]}], "abstractContent": [{"text": "Document-level sentiment classification is a fundamental problem which aims to predict a user's overall sentiment about a product in a document.", "labels": [], "entities": [{"text": "Document-level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7881634632746378}]}, {"text": "Several methods have been proposed to tackle the problem whereas most of them fail to consider the influence of users who express the sentiment and products which are evaluated.", "labels": [], "entities": []}, {"text": "To address the issue, we propose a deep memory network for document-level sentiment classification which could capture the user and product information at the same time.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 59, "end_pos": 98, "type": "TASK", "confidence": 0.7526480754216512}]}, {"text": "To prove the effectiveness of our algorithm , we conduct experiments on IMDB and Yelp datasets and the results indicate that our model can achieve better performance than several existing methods.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.9132691025733948}, {"text": "Yelp datasets", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.799620121717453}]}], "introductionContent": [{"text": "Sentiment analysis, sometimes known as opinion mining, is the field of study that analyzes people's opinions, sentiments, evaluations, attitudes and emotions from written language.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9126377403736115}, {"text": "opinion mining", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.6727924644947052}, {"text": "analyzes people's opinions, sentiments, evaluations, attitudes and emotions from written language", "start_pos": 82, "end_pos": 179, "type": "TASK", "confidence": 0.6006541927655538}]}, {"text": "It is one of the most active and critical research areas in natural language processing ().", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.6363683541615804}]}, {"text": "On the one hand, from the industry point of view, knowing the feelings among consumers based on their comments is beneficial and may support strategic market decisions.", "labels": [], "entities": []}, {"text": "On the other hand, potential customers are often interested in other people's opinion in order to find out the choices that best fits their preferences.", "labels": [], "entities": []}, {"text": "Previous studies tackled the sentiment analysis problem at various levels of granularity, from document level to sentence level due to different objectives of applications (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9650791585445404}]}, {"text": "In this work, we mainly focus on document-level sentiment classification Basically, the task is to predict user's overall sentiment or polarity in a document about a product.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 33, "end_pos": 72, "type": "TASK", "confidence": 0.647028515736262}]}, {"text": "Most existing methods mainly utilize local text information whereas ignoring the influences of users and products (.", "labels": [], "entities": []}, {"text": "As is often the case, there are certain consistencies for both users and products.", "labels": [], "entities": []}, {"text": "To illustrate, lenient users may always give higher ratings than fastidious ones even if they post the same review.", "labels": [], "entities": []}, {"text": "Also, it is not surprising that some products may always receive low ratings because of their poor quality and vice versa.", "labels": [], "entities": []}, {"text": "Therefore, it is necessary to leverage individual preferences of users and overall qualities of products in order to achieve better performance.", "labels": [], "entities": []}, {"text": "proposed a novel method dubbed User Product Neural Network (UPNN) which capture user-and product-level information for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 119, "end_pos": 143, "type": "TASK", "confidence": 0.9525821805000305}]}, {"text": "Their approach has shown great promise but one major drawback of their work is that for users and products with limited information, it is hard to train the representation vector and matrix for them.", "labels": [], "entities": []}, {"text": "Inspired by the recent success of computational models with attention mechanism and explicit memory (, we addressed the aforementioned issue by proposing a method based on deep memory network and Long Short-Term Memory (LSTM)).", "labels": [], "entities": []}, {"text": "The model can be divided into two separate parts.", "labels": [], "entities": []}, {"text": "In the first fart, we utilize LSTM to represent each document.", "labels": [], "entities": []}, {"text": "Afterwards, we apply deep memory network consists of multiple computational layers to predict the ratings for each document and each layer is a content-based attention model.", "labels": [], "entities": []}, {"text": "To prove the effectiveness of our algorithm, we have conducted experiments on three datasets derived from IMDB and Yelp Dataset Challenge and compare to several other algorithms.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.9317442178726196}, {"text": "Yelp Dataset Challenge", "start_pos": 115, "end_pos": 137, "type": "DATASET", "confidence": 0.9304483532905579}]}, {"text": "Experimental results show that our algorithm can outperform baseline methods for sentiment classification of documents by leveraging users and products for document-level sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification of documents", "start_pos": 81, "end_pos": 118, "type": "TASK", "confidence": 0.9270381331443787}, {"text": "document-level sentiment classification", "start_pos": 156, "end_pos": 195, "type": "TASK", "confidence": 0.7015579839547476}]}], "datasetContent": [{"text": "In this section, we will first discuss the experimental setting and then display the results.: Experimental results.", "labels": [], "entities": []}, {"text": "We use the same datasets as, which are derived from IMDB ( and Yelp Dataset Challenge in 2013 and 2014 . Statistical information of the datasets are given in.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9039387702941895}, {"text": "Yelp Dataset Challenge in 2013", "start_pos": 63, "end_pos": 93, "type": "DATASET", "confidence": 0.9453972578048706}]}, {"text": "In order to measure the performance of our model, here we use three metrics.", "labels": [], "entities": []}, {"text": "Specifically, we use accuracy to measure the overall sentiment classification performance, M AE and RM SE to measure the divergences between prediction py and ground truth gy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9994713664054871}, {"text": "sentiment classification", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.8511278331279755}, {"text": "M AE", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.8457156717777252}, {"text": "RM SE", "start_pos": 100, "end_pos": 105, "type": "METRIC", "confidence": 0.8067978620529175}]}, {"text": "The formulas for these three metrics are listed as follows:  The experimental results are given in.", "labels": [], "entities": []}, {"text": "The results of baseline models are reported in.", "labels": [], "entities": []}, {"text": "Our model is abbreviated to, where k is the number of hops.", "labels": [], "entities": []}, {"text": "With the increase of the number of hops, the performance of UPDMN will get better intially, which indicates that multiple hops can indeed capture more information to improve the performance.", "labels": [], "entities": []}, {"text": "However, if there are too many hops, the performance would be not as well as before, which maybe caused by over-fitting.", "labels": [], "entities": []}, {"text": "Compared with other models, we can see that with proper setting, our model achieve superior results.", "labels": [], "entities": []}, {"text": "All these results prove the effectiveness of UPDMN and the necessity to utilizing user and product information at document level.", "labels": [], "entities": [{"text": "UPDMN", "start_pos": 45, "end_pos": 50, "type": "TASK", "confidence": 0.8181219696998596}]}, {"text": "It should be noticed that there are still several improvements can be made, such as better representation of documents or more sophisticated attention mechanism.", "labels": [], "entities": []}, {"text": "We believe that our model has great potential and can be improved in many ways.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistical information of datasets.", "labels": [], "entities": []}]}