{"title": [{"text": "Hierarchically-Attentive RNN for Album Summarization and Storytelling", "labels": [], "entities": [{"text": "Album Summarization", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.59542116522789}]}], "abstractContent": [{"text": "We address the problem of end-to-end visual storytelling.", "labels": [], "entities": [{"text": "end-to-end visual storytelling", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.7329914371172587}]}, {"text": "Given a photo album, our model first selects the most representative (summary) photos, and then composes a natural language story for the album.", "labels": [], "entities": []}, {"text": "For this task, we make use of the Visual Sto-rytelling dataset and a model composed of three hierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album photos, select representative (summary) photos, and compose the story.", "labels": [], "entities": [{"text": "Visual Sto-rytelling dataset", "start_pos": 34, "end_pos": 62, "type": "DATASET", "confidence": 0.6642025510470072}]}, {"text": "Automatic and human evaluations show our model achieves better performance on selection, generation, and retrieval than baselines.", "labels": [], "entities": [{"text": "selection, generation", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.6575461030006409}]}], "introductionContent": [{"text": "Since we first developed language, humans have always told stories.", "labels": [], "entities": []}, {"text": "Fashioning a good story is an act of creativity and developing algorithms to replicate this has been along running challenge.", "labels": [], "entities": [{"text": "Fashioning a good story", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8416720032691956}]}, {"text": "Adding pictures as input can provide information for guiding story construction by offering visual illustrations of the storyline.", "labels": [], "entities": [{"text": "story construction", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.8049158751964569}]}, {"text": "In the related task of image captioning, most methods try to generate descriptions only for individual images or for short videos depicting a single activity.", "labels": [], "entities": [{"text": "image captioning", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7355525195598602}]}, {"text": "Very recently, datasets have been introduced that extend this task to longer temporal sequences such as movies or photo albums (.", "labels": [], "entities": []}, {"text": "The type of data we consider in this paper provides input illustrations for story generation in the form of photo albums, sampled over a few minutes to a few days of time.", "labels": [], "entities": [{"text": "story generation", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7607488334178925}]}, {"text": "For this type of data, generating textual descriptions involves telling a temporally consistent story about the depicted visual information, where stories must be coherent and take into account the temporal context of the images.", "labels": [], "entities": []}, {"text": "Applications of this include constructing visual and textual summaries of albums, or even enabling search through personal photo collections to find photos of life events.", "labels": [], "entities": [{"text": "constructing visual and textual summaries of albums", "start_pos": 29, "end_pos": 80, "type": "TASK", "confidence": 0.6369399087769645}]}, {"text": "Previous visual storytelling works can be classified into two types, vision-based and languagebased, where image or language stories are constructed respectively.", "labels": [], "entities": []}, {"text": "Among the vision-based approaches, unsupervised learning is commonly applied: e.g.,) learns the latent temporal dynamics given a large amount of albums, and) formulate the photo selection as a sparse time-varying directed graph.", "labels": [], "entities": []}, {"text": "However, these visual summaries tend to be difficult to evaluate and selected photos may not agree with human selections.", "labels": [], "entities": []}, {"text": "For languagebased approaches, a sequence of natural language sentences are generated to describe a set of photos.", "labels": [], "entities": []}, {"text": "To drive this work) collected a dataset mined from Blog Posts.", "labels": [], "entities": [{"text": "Blog Posts", "start_pos": 51, "end_pos": 61, "type": "DATASET", "confidence": 0.9440487027168274}]}, {"text": "However, this kind of data often contains contextual information or loosely related language.", "labels": [], "entities": []}, {"text": "A more direct dataset was recently released ( , where multi-sentence stories are collected describing photo albums via Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 119, "end_pos": 141, "type": "DATASET", "confidence": 0.8713076512018839}]}, {"text": "In this paper, we make use of the Visual Storytelling Dataset ( . While the authors provide a seq2seq baseline, they only deal with the task of generating stories given 5-representative (summary) photos hand-selected by people from an album.", "labels": [], "entities": [{"text": "Visual Storytelling Dataset", "start_pos": 34, "end_pos": 61, "type": "DATASET", "confidence": 0.5907902518908182}]}, {"text": "Instead, we focus on the more challenging and realistic problem of end-toend generation of stories from entire albums.", "labels": [], "entities": []}, {"text": "This requires us to either generate a story from all of the album's photos or to learn selection mechanisms to identify representative photos and then generate stories from those summary photos.", "labels": [], "entities": []}, {"text": "We evaluate each type of approach.", "labels": [], "entities": []}, {"text": "Ultimately, we propose a model of hierarchically-attentive recurrent neural nets, consisting of three RNN stages.", "labels": [], "entities": []}, {"text": "The first RNN encodes the whole album context and each photo's content, the second RNN provides weights for photo selection, and the third RNN takes the weighted representation and decodes to the resulting sentences.", "labels": [], "entities": []}, {"text": "Note that during training, we are only given the full input albums and the output stories, and our model needs to learn the summary photo selections latently.", "labels": [], "entities": []}, {"text": "We show that our model achieves better performance over baselines under both automatic metrics and human evaluations.", "labels": [], "entities": []}, {"text": "As aside product, we show that the latent photo selection also reasonably mimics human selections.", "labels": [], "entities": []}, {"text": "Additionally, we propose an album retrieval task that can reliably pick the correct photo album given a sequence of sentences, and find that our model also outperforms the baselines on this task.", "labels": [], "entities": [{"text": "album retrieval", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7441608011722565}]}], "datasetContent": [{"text": "We use the Visual Storytelling Dataset ( , consisting of 10,000 albums with 200,000 photos.", "labels": [], "entities": [{"text": "Visual Storytelling Dataset", "start_pos": 11, "end_pos": 38, "type": "DATASET", "confidence": 0.5791475574175516}]}, {"text": "Each album contains 10-50 photos taken within a 48-hour span with two annotations: 1) 2 album summarizations, each with 5 selected representative photos, and 2) 5 stories describing the selected photos.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Story generation evaluation.", "labels": [], "entities": [{"text": "Story generation evaluation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8880505363146464}]}, {"text": " Table 2: Human evaluation showing how often  people prefer one model over the other.", "labels": [], "entities": []}, {"text": " Table 3: Album summarization evaluation.", "labels": [], "entities": [{"text": "summarization", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.6936792135238647}]}, {"text": " Table 4: 1000 album retrieval evaluation.", "labels": [], "entities": [{"text": "1000 album retrieval evaluation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.759529709815979}]}]}