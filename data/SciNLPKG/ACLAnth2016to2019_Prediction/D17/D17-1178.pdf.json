{"title": [{"text": "Effective Inference for Generative Neural Parsing", "labels": [], "entities": [{"text": "Effective Inference", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7325001657009125}, {"text": "Generative Neural Parsing", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.6549879113833109}]}], "abstractContent": [{"text": "Generative neural models have recently achieved state-of-the-art results for constituency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.9269976019859314}]}, {"text": "However, without a feasible search procedure, their use has so far been limited to reranking the output of external parsers in which decoding is more tractable.", "labels": [], "entities": []}, {"text": "We describe an alternative to the conventional action-level beam search used for discriminative neural models that enables us to decode directly in these gen-erative models.", "labels": [], "entities": []}, {"text": "We then show that by improving our basic candidate selection strategy and using a coarse pruning function, we can improve accuracy while exploring significantly less of the search space.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9986785054206848}]}, {"text": "Applied to the model of Choe and Char-niak (2016), our inference procedure obtains 92.56 F1 on section 23 of the Penn Treebank, surpassing prior state-of-the-art results for single-model systems.", "labels": [], "entities": [{"text": "F1", "start_pos": 89, "end_pos": 91, "type": "METRIC", "confidence": 0.9926672577857971}, {"text": "Penn Treebank", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.9820125102996826}]}], "introductionContent": [{"text": "A recent line of work has demonstrated the success of generative neural models for constituency parsing (.", "labels": [], "entities": [{"text": "generative neural", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.9106666147708893}, {"text": "constituency parsing", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.8953908383846283}]}, {"text": "As with discriminative neural parsers, these models lack a dynamic program for exact inference due to their modeling of unbounded dependencies.", "labels": [], "entities": []}, {"text": "However, while discriminative neural parsers are able to obtain strong results using greedy search or beam search with a small beam (, we find that a simple action-level approach fails outright in the generative setting.", "labels": [], "entities": []}, {"text": "Perhaps because of this, the application of generative neural models has so far been restricted to reranking the output of external parsers.", "labels": [], "entities": [{"text": "generative neural", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.9104146063327789}]}, {"text": "Intuitively, because a generative parser defines a joint distribution over sentences and parse trees, probability mass will be allocated unevenly between a small number of common structural actions and a large vocabulary of lexical items.", "labels": [], "entities": []}, {"text": "This imbalance is a primary cause of failure for search procedures in which these two types of actions compete directly.", "labels": [], "entities": []}, {"text": "A notion of equal competition among hypotheses is then desirable, an idea that has previously been explored in generative models for constituency parsing and dependency parsing), among other tasks.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.8101471960544586}, {"text": "dependency parsing", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.784868061542511}]}, {"text": "We describe a related state-augmented beam search for neural generative constituency parsers in which lexical actions compete only with each other rather than with structural actions.", "labels": [], "entities": [{"text": "neural generative constituency parsers", "start_pos": 54, "end_pos": 92, "type": "TASK", "confidence": 0.7561801224946976}]}, {"text": "Applying this inference procedure to the generative model of, we find that it yields a self-contained generative parser that achieves high performance.", "labels": [], "entities": [{"text": "generative parser", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.8365554213523865}]}, {"text": "Beyond this, we propose an enhanced candidate selection strategy that yields significant improvements for all beam sizes.", "labels": [], "entities": []}, {"text": "Additionally, motivated by the look-ahead heuristic used in the top-down parsers of, we also experiment with a simple coarse pruning function that allows us to reduce the number of states expanded per candidate by several times without compromising accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 249, "end_pos": 257, "type": "METRIC", "confidence": 0.9971035122871399}]}, {"text": "Using our final search procedure, we surpass prior state-ofthe-art results among single-model parsers on the Penn Treebank, obtaining an F1 score of 92.56.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 109, "end_pos": 122, "type": "DATASET", "confidence": 0.9951953291893005}, {"text": "F1 score", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9775829315185547}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Development F1 scores using word-level  search with various beam sizes k and two choices  of word beam size k w .", "labels": [], "entities": [{"text": "F1", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9358123540878296}]}, {"text": " Table 2: Development F1 scores using the settings  from", "labels": [], "entities": [{"text": "F1", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.7003852725028992}]}, {"text": " Table 3: Cumulative distributions of the number  of unique OPEN outputs per input for an order- c pruning function, computed over pruning inputs  with at least one OPEN output.", "labels": [], "entities": []}, {"text": " Table 4: Results when the best setting from Sec- tion 6 is rerun with OPEN action pruning with con- text size c = 2 and various pruning fractions p.  Lower values of p indicate more aggressive prun- ing, while p = 1 means no pruning is performed.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of F1 scores on section 23 of  the Penn Treebank. Here we only include models  trained without external silver training data. Re- sults in the first two sections are for single-model  systems.", "labels": [], "entities": [{"text": "F1", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9963944554328918}, {"text": "Penn Treebank", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.9939494132995605}, {"text": "Re- sults", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9645999670028687}]}]}