{"title": [{"text": "SUPWSD: A Flexible Toolkit for Supervised Word Sense Disambiguation", "labels": [], "entities": [{"text": "Supervised Word Sense Disambiguation", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.6672136038541794}]}], "abstractContent": [{"text": "In this demonstration we present SUP-WSD, a Java API for supervised Word Sense Disambiguation (WSD).", "labels": [], "entities": [{"text": "supervised Word Sense Disambiguation (WSD)", "start_pos": 57, "end_pos": 99, "type": "TASK", "confidence": 0.7143642008304596}]}, {"text": "This toolkit includes the implementation of a state-of-the-art supervised WSD system , together with a Natural Language Processing pipeline for preprocessing and feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.7664707899093628}]}, {"text": "Our aim is to provide an easy-to-use tool for the research community, designed to be modular, fast and scalable for training and testing on large datasets.", "labels": [], "entities": []}, {"text": "The source code of SUPWSD is available at http: //github.com/SI3P/SupWSD.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation, is one of the long-standing challenges of Natural Language Understanding.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6940972010294596}, {"text": "Natural Language Understanding", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.6680117547512054}]}, {"text": "Given a word in context and a pre-specified sense inventory, the task of WSD is to determine the intended meaning of that word depending on the context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9287034869194031}]}, {"text": "Several WSD approaches have been proposed over the years and extensively studied by the research community, ranging from knowledgebased systems to semi-supervised and fully supervised models.", "labels": [], "entities": [{"text": "WSD", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9809219241142273}]}, {"text": "Nowadays anew line of research is emerging, and WSD is gradually shifting from a purely monolingual (i.e. English) setup to a wider multilingual setting.", "labels": [], "entities": [{"text": "WSD", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9409109950065613}]}, {"text": "Since scaling up to multiple languages is considerably easier for knowledgebased systems, as they do not require senseannotated training data, various efforts have been made towards the automatic construction of highquality sense-annotated corpora for multiple languages (), aimed at overcoming the so-called knowledge acquisition bottleneck of supervised models.", "labels": [], "entities": []}, {"text": "These efforts include the use of Wikipedia, which can be considered a full-fledged, manually sense-annotated resource for numerous languages, and hence exploited as training data (.", "labels": [], "entities": []}, {"text": "Beside the automatic harvesting of senseannotated data for different languages, a variety of multilingual preprocessing pipelines has also been developed across the years ().", "labels": [], "entities": []}, {"text": "To date, however, very few attempts have been made to integrate these data and tools with a supervised WSD framework; as a result, multilingual WSD has been almost exclusively tackled with knowledge-based systems, despite the fact that supervised models have been proved to consistently outperform knowledge-based ones in all standard benchmarks.", "labels": [], "entities": []}, {"text": "As regards supervised WSD, It Makes Sense ( is indeed the de-facto state-ofthe-art system used for comparison in WSD, but it is available only for English, with the last major update dating back to 2010.", "labels": [], "entities": [{"text": "WSD", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.8277537226676941}]}, {"text": "The publicly available implementation of IMS also suffers from two crucial drawbacks: (i) the design of the software makes the current code difficult to extend (e.g. with classes taking as input more than 15 parameters); (ii) the implementation is not optimized for larger datasets, being rather time-and resource-consuming.", "labels": [], "entities": []}, {"text": "These difficulties hamper the work of contributors willing to update it, as well as the effort of researchers that would like to use it with languages other than English.", "labels": [], "entities": []}, {"text": "In this paper we present SUPWSD, whose objective is to overcome the aforementioned drawbacks, and facilitate the use of a supervised WSD software for both end users and researchers.", "labels": [], "entities": [{"text": "SUPWSD", "start_pos": 25, "end_pos": 31, "type": "TASK", "confidence": 0.530687689781189}]}, {"text": "SUP- WSD is designed to be modular and highly flexible, enabling contributors to extend it with ease.", "labels": [], "entities": [{"text": "SUP- WSD", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.5702499548594157}]}, {"text": "Its usage is simple and immediate: it is based on ajar file with only 2 commands and 3 parameters, along with an XML configuration file for specifying customized settings.", "labels": [], "entities": []}, {"text": "SUPWSD supports the most widely used preprocessing tools in the research community: Stanford coreNLP (), openNLP 1 , and TreeTagger; as such, SUPWSD can directly handle all the languages supported by these tools.", "labels": [], "entities": []}, {"text": "Finally, its architecture design relies on commonly used design patterns in Java (such as Factory and Observer among others), which make it flexible fora programmatic use and easily expandable.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated SUPWSD on the evaluation framework of 8 , which includes five test sets from the Senseval/Semeval series and two training corpus of different size, i.e. SemCor ( and OMSTI (Taghipour and Ng, 2015a).", "labels": [], "entities": [{"text": "SUPWSD", "start_pos": 13, "end_pos": 19, "type": "TASK", "confidence": 0.7584803700447083}]}, {"text": "As sense inventory, we used WordNet 3.0 () for all open-class parts of speech.", "labels": [], "entities": []}, {"text": "We compared SUPWSD with the original implementation of IMS, including the best configurations reported in which exploit word embedding as features.", "labels": [], "entities": []}, {"text": "As shown in, the performance of SUPWSD consistently matches up to the original implementation of IMS in terms of F-Measure, sometimes even outperforming its competitor by a considerable margin; this suggests that a neat and flexible implementation not only brings benefits in terms of usability of the software, but also impacts on the accuracy of the model.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.951155424118042}, {"text": "accuracy", "start_pos": 336, "end_pos": 344, "type": "METRIC", "confidence": 0.9984900951385498}]}], "tableCaptions": [{"text": " Table 1: F-scores (%) of different models in five all-words WSD datasets.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9951158761978149}, {"text": "WSD datasets", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.7908429503440857}]}]}