{"title": [{"text": "In Other News: A Bi-style Text-to-speech Model for Synthesizing Newscaster Voice with Limited Data", "labels": [], "entities": []}], "abstractContent": [{"text": "Neural text-to-speech synthesis (NTTS) models have shown significant progress in generating high-quality speech, however they require a large quantity of training data.", "labels": [], "entities": [{"text": "Neural text-to-speech synthesis (NTTS)", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7354527910550436}]}, {"text": "This makes creating models for multiple styles expensive and time-consuming.", "labels": [], "entities": []}, {"text": "In this paper different styles of speech are analysed based on prosodic variations, from this a model is proposed to synthesise speech in the style of a newscaster, with just a few hours of supplementary data.", "labels": [], "entities": []}, {"text": "We pose the problem of syn-thesising in a target style using limited data as that of creating a bi-style model that can synthesise both neutral-style and newscaster-style speech via a one-hot vector which fac-torises the two styles.", "labels": [], "entities": []}, {"text": "We also propose conditioning the model on contextual word em-beddings, and extensively evaluate it against neutral NTTS, and neutral concatenative-based synthesis.", "labels": [], "entities": []}, {"text": "This model closes the gap in perceived style-appropriateness between natural recordings for newscaster-style of speech, and neutral speech synthesis by approximately two-thirds.", "labels": [], "entities": [{"text": "neutral speech synthesis", "start_pos": 124, "end_pos": 148, "type": "TASK", "confidence": 0.7520055572191874}]}], "introductionContent": [{"text": "Newscasters have a clearly identifiable dynamic style of speech.", "labels": [], "entities": []}, {"text": "As more people are using virtual assistants, in their mobile devices and home appliances, for listening to daily news, synthesising newscaster-style of speech becomes commercially relevant.", "labels": [], "entities": []}, {"text": "A newscaster-style of speech gives users a better experience when listening to news as compared to news generated in the neutral-style speech, which is typically used in text-to-speech synthesis.", "labels": [], "entities": [{"text": "text-to-speech synthesis", "start_pos": 170, "end_pos": 194, "type": "TASK", "confidence": 0.7328803241252899}]}, {"text": "In addition, synthesising news using textto-speech is more cost-effective and flexible than having to record new snippets of news with professional newscasters every time anew story breaks in.", "labels": [], "entities": []}, {"text": "Recent advances in neural text-to-speech (NTTS) synthesis (Van Den Oord et al., 2016; have enabled researchers to generate high-quality speech with a wide range of prosodic variations.", "labels": [], "entities": [{"text": "text-to-speech (NTTS) synthesis", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.6927912712097168}]}, {"text": "For many years, concatenative-based speech synthesis) has been the industry standard.", "labels": [], "entities": [{"text": "concatenative-based speech synthesis", "start_pos": 16, "end_pos": 52, "type": "TASK", "confidence": 0.6561407446861267}]}, {"text": "Concatenative-based speech synthesis methods can produce high-quality speech, but are limited by the coverage of units in its database.", "labels": [], "entities": [{"text": "Concatenative-based speech synthesis", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6542425453662872}]}, {"text": "When it comes to more expressive styles of speech, this problem is aggravated by the many hours of speech data that would be needed to cover an acceptable range of prosodic variations present in a particular style of speech.", "labels": [], "entities": []}, {"text": "The concatenative approaches also require extensive hand-crafting of relevant low-level features, and arduous engineering efforts.", "labels": [], "entities": []}, {"text": "Recently proposed models based on sequenceto-sequence (seq2seq) architecture () attempt to alleviate some of these issues by transforming the low-level feature representation into a learning task.", "labels": [], "entities": []}, {"text": "These models function as acoustic models which take text, in the form of characters or phonemes as input, and output low-level acoustic features that can be then converted into speech waveform using one of the several 'vocoding' techniques ().", "labels": [], "entities": []}, {"text": "Seq2seq models also allow us to condition the model on additional observed or latent attributes that help in improving the flexibility (modelling different speaker, and styles), and naturalness (.", "labels": [], "entities": []}, {"text": "have explored transformer networks for context generation.", "labels": [], "entities": [{"text": "context generation", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7820590734481812}]}, {"text": "This improves training efficiency while capturing long-range dependencies.", "labels": [], "entities": []}, {"text": "Even though transformers have enabled parallel training, they still suffer from slow inference due to autoregres-sion.", "labels": [], "entities": []}, {"text": "LSTM-based seq2seq architectures, having lesser number of trainable parameters, allow for faster inference.", "labels": [], "entities": []}, {"text": "Several works have explored the \"controllability\" of style in synthesised speech through latentvariable modelling techniques ().", "labels": [], "entities": []}, {"text": "These models not only enable us to jointly model different styles, but also allow the user to control the style through modification of disentangled latent variable during the inference.", "labels": [], "entities": []}, {"text": "Although flexible, these models usually require a large amount of data to capture the idiosyncrasies of speaking styles, and to disentangle the characteristics of speech (pitch, duration, amplitude etc.)", "labels": [], "entities": []}, {"text": "Additionally, these models are slow to train and are potentially overly complex for modelling styles of speech that are expressive but do not display large prosodic variations.", "labels": [], "entities": []}, {"text": "During inference, the user would need to input the latent variables to synthesise, which is not ideal for production systems.", "labels": [], "entities": []}, {"text": "Conventional seq2seq models for NTTS rely on a single encoder for linguistic inputs (phonemes/character embeddings).", "labels": [], "entities": [{"text": "NTTS", "start_pos": 32, "end_pos": 36, "type": "TASK", "confidence": 0.9183220267295837}]}, {"text": "This encoder cannot be solely relied upon to capture higher-level text characteristics like syntax or semantics.", "labels": [], "entities": []}, {"text": "The relation between syntax, semantics and prosody is complex.", "labels": [], "entities": []}, {"text": "Many linguistic theories try to tie these phenomena but they struggle to explain some edge cases and are mutually inconsistent . Thus, it might be unsatisfactory to apply linguistic knowledge directly to prosody modelling by conditioning the model on manually selected features.", "labels": [], "entities": [{"text": "prosody modelling", "start_pos": 204, "end_pos": 221, "type": "TASK", "confidence": 0.8455488383769989}]}, {"text": "Recent advances in representation learning for text have allowed us to come up with linguistic representations that not only capture the semantics of a word, but are also context-dependent as a function of the entire sentence.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.8796491622924805}]}, {"text": "Contextual word embeddings (CWE) can be used to present to the model additional conditioning features that can help model the prosodic variations in each word, based on the context in which it is present.", "labels": [], "entities": []}, {"text": "Latorre et. al (2018) investigated the effect of data reduction on seq2seq acoustic models.", "labels": [], "entities": []}, {"text": "They train a multispeaker model with limited data from several speakers.", "labels": [], "entities": []}, {"text": "pre-train the decoder of their acoustic model on a large amount of unpaired data where the decoder learns the task of predicting the next frame.", "labels": [], "entities": []}, {"text": "They also propose conditioning the model on traditional word-vectors like) to provide additional linguistic information.", "labels": [], "entities": []}, {"text": "Both these works don't look at varying prosody or speakingstyle.", "labels": [], "entities": []}, {"text": "There has been a growing interest in adaptive techniques for voice cloning, and style adaptation () with limited data.", "labels": [], "entities": [{"text": "style adaptation", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.7250768691301346}]}, {"text": "However, these models require extensive fine-tuning.", "labels": [], "entities": []}, {"text": "Additional investigation is needed on the performance of such adaptive models on more multistyle setting.", "labels": [], "entities": []}, {"text": "The contribution of this work is two-fold: (1) We propose a 'bi-style' model that is capable of generating both a distinct newscaster style of speech, and neutral style of speech, trained only on few hours of supplementary newscaster-style data, (2) we explore the use of CWE as an additional conditioning input for prosody modelling.", "labels": [], "entities": [{"text": "prosody modelling", "start_pos": 316, "end_pos": 333, "type": "TASK", "confidence": 0.8700349926948547}]}], "datasetContent": [{"text": "Even though the objective metrics give us a general indication on the prosody and segmental quality of synthesised speech, the metrics may not directly correlate to the perceptual quality.", "labels": [], "entities": []}, {"text": "We conduct additional subjective evaluations with human listeners and consider these as the final outcome of our experiments.", "labels": [], "entities": []}, {"text": "For subjective evaluations, we concatenate the synthesised news-style sentences into full news stories, to capture the overall experience of our intended use-case.", "labels": [], "entities": []}, {"text": "Each utterance is 3-5 sentences long, and the average duration is 33.47seconds.", "labels": [], "entities": [{"text": "duration", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9904933571815491}]}, {"text": "We test our system with 10 expert listeners with native linguistic proficiency in English, using the MUltiple Stimuli with Hidden Reference and Anchor (MUSHRA) methodology).", "labels": [], "entities": []}, {"text": "The systems used in this evaluation are described in.", "labels": [], "entities": []}, {"text": "The listeners are asked to rate the appropriateness of each system as a newscaster voice on a scale of 0 to 100.", "labels": [], "entities": []}, {"text": "For each utterance, 5 stimuli are presented to the listeners side-by-side on the same screen, representing the 5 test systems in a random order.", "labels": [], "entities": []}, {"text": "Each listener rates 51 screens.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Analysis of mean prosodic variations based  on lf0 per utterance", "labels": [], "entities": []}, {"text": " Table 3: Objective metrics for analysis of prosody and segmental quality. High FCORR indicates better prosody.  For all other metrics, lower value indicates better performance.", "labels": [], "entities": [{"text": "FCORR", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9936338663101196}]}, {"text": " Table 4: Listener ratings from the MUSHRA evaluation", "labels": [], "entities": [{"text": "MUSHRA", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.7274530529975891}]}, {"text": " Table 5: Preference test between systems with and wi- thout CWE conditioning", "labels": [], "entities": []}, {"text": " Table 6: Speech tempo: recordings vs test systems", "labels": [], "entities": []}]}