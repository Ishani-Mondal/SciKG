{"title": [{"text": "Unsupervised Extraction of Partial Translations for Neural Machine Translation", "labels": [], "entities": [{"text": "Unsupervised Extraction of Partial Translations", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7028463304042816}, {"text": "Neural Machine Translation", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.6904723743597666}]}], "abstractContent": [{"text": "In neural machine translation (NMT), mono-lingual data are usually exploited through a so-called back-translation: sentences in the target language are translated into the source language to synthesize new parallel data.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.8604689836502075}]}, {"text": "While this method provides more training data to better model the target language, on the source side, it only exploits translations that the NMT system is already able to generate using a model trained on existing parallel data.", "labels": [], "entities": []}, {"text": "In this work, we assume that new translation knowledge can be extracted from monolingual data, without relying at all on existing parallel data.", "labels": [], "entities": []}, {"text": "We propose anew algorithm for extracting from monolingual data what we call partial translations: pairs of source and target sentences that contain sequences of tokens that are translations of each other.", "labels": [], "entities": []}, {"text": "Our algorithm is fully unsupervised and takes only source and target monolingual data as input.", "labels": [], "entities": []}, {"text": "Our empirical evaluation points out that our partial translations can be used in combination with back-translation to further improve NMT models.", "labels": [], "entities": []}, {"text": "Furthermore, while partial translations are particularly useful for low-resource language pairs, they can also be successfully exploited in resource-rich scenarios to improve translation quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural machine translation (NMT) systems usually require a large quantity of high-quality bilingual parallel data for training.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8579212625821432}]}, {"text": "However, for most language pairs, we do not have such resources, or only in very small quantities, mainly because they are costly to produce.", "labels": [], "entities": []}, {"text": "On the other hand, monolingual corpora are readily available in large quantity for many languages.", "labels": [], "entities": []}, {"text": "Previous work has proposed various strategies to integrate monolingual data into NMT systems and has confirmed their usefulness to improve NMT systems.", "labels": [], "entities": [{"text": "NMT", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.9295096397399902}]}, {"text": "The so-called backtranslation of monolingual data) is undoubtedly the most prevalent one.", "labels": [], "entities": []}, {"text": "This approach simply uses a target-to-source MT system to translate monolingual data in the target language into the source language.", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9463651180267334}]}, {"text": "The produced new synthetic parallel corpus can be used together with the original parallel data to increase the size of the training data, and eventually to improve NMT systems significantly and consistently.", "labels": [], "entities": [{"text": "NMT", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.928388237953186}]}, {"text": "However, on the source side, the synthetic data only contain data that can be generated by the back-translation system trained on some existing parallel data.", "labels": [], "entities": []}, {"text": "Previous work has also studied the extraction of translation pairs of source and target sentences from monolingual data in their respective languages.", "labels": [], "entities": [{"text": "extraction of translation pairs of source and target sentences from monolingual", "start_pos": 35, "end_pos": 114, "type": "TASK", "confidence": 0.8516288562254473}]}, {"text": "They have been shown to be useful to train better statistical machine translation (SMT) systems, especially in low-resource conditions.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 50, "end_pos": 87, "type": "TASK", "confidence": 0.7910179148117701}]}, {"text": "Existing methods on sentence pair extraction mainly rely on the availability of comparable corpora as the source of accurate sentence pairs, or on the robustness of SMT against noise () because sentence pairs extracted from unrelated monolingual corpora tend to be noisy ().", "labels": [], "entities": [{"text": "sentence pair extraction", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.6873635749022166}, {"text": "SMT", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.9847424030303955}]}, {"text": "Most of them also require pre-trained accurate translation models, those of SMT systems for instance, that we may not have in low-resource conditions.", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9865731000900269}]}, {"text": "Moreover, unlike SMT, NMT has been shown to deal very poorly with noisy training data and still largely underperforms SMT for low-resource language pairs ( for which comparable corpora are usually not available.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9909448623657227}, {"text": "SMT", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.987044632434845}]}, {"text": "Even without an accurate translation model, we still have the possibility of extracting sentence pairs from unrelated source and target monolingual data.", "labels": [], "entities": []}, {"text": "However, this is very challenging since we have no guarantee that there are sentence pairs actually retrievable from a given Source sentence der Mann wurde festgenommen . Partial translation a man was arrested at the scene . Post-processed UNKPP man was arrested UNKPP UNKPP UNKPP . Figure 1: Example of a source sentence in our German monolingual data, its best partial translation found in our English monolingual data by our algorithm, and its post-processed version.", "labels": [], "entities": []}, {"text": "The bold tokens translate tokens of the source sentence.", "labels": [], "entities": []}, {"text": "pair of source and target monolingual corpora.", "labels": [], "entities": []}, {"text": "In this work, we assume (i) that a given pair of monolingual corpora contain sentence pairs that are at least partial translations, i.e., pairs of source and target sentences containing phrases (sequences of tokens) that are translations of each other and (ii) that such pairs can help train better NMT systems.", "labels": [], "entities": []}, {"text": "On these assumptions, we propose anew algorithm that extracts partial translations from trillions of candidate sentence pairs without any supervision.", "labels": [], "entities": [{"text": "extracts partial translations from trillions of candidate sentence pairs", "start_pos": 53, "end_pos": 125, "type": "TASK", "confidence": 0.7581813434759775}]}, {"text": "Relying on an unsupervised phrase table, our algorithm identifies phrases in a source sentence that have likely translations in a target sentence.", "labels": [], "entities": []}, {"text": "The extracted partial translations often contain unrelated parts besides aligned phrases.", "labels": [], "entities": []}, {"text": "Therefore, we also apply a simple but very effective post-processing to make such noisy sentence pairs exploitable fora target-to-source NMT model, as exemplified in.", "labels": [], "entities": []}, {"text": "We report on significant improvements in translation quality for two language pairs and under different experimental conditions when using our extracted partial translations to train NMT systems.", "labels": [], "entities": []}, {"text": "While our method is especially designed to provide new training data for low-resource language pairs, we also observed significant improvements over a strong NMT system trained on large quantity of parallel data.", "labels": [], "entities": []}, {"text": "Furthermore, we demonstrate the complementarity of our approach with backtranslation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented on three language pairs with different degrees of relatedness between the languages of each pair: English\u2192German (en\u2192de), English\u2192Turkish (en\u2192tr), and Bengali\u2192Malay (bn\u2192ms).", "labels": [], "entities": []}, {"text": "While our approach is dedicated to improve translation quality for low-resource language pairs, we included the en\u2192de pair fora detailed analysis on the impact of using partial translations in addition to much more training data.", "labels": [], "entities": [{"text": "translation", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.9593984484672546}]}, {"text": "bn\u2192ms is expected to bean extremely difficult translation task, because only small quantity of parallel data are available to start with (Section 3.1) and Bengali and Malay are very distant languages which makes very difficult the training of useful unsupervised bilingual word embeddings (, which is a key element for inducing the phrase table.", "labels": [], "entities": [{"text": "translation", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.963905930519104}]}], "tableCaptions": [{"text": " Table 3: BLEU scores of NMT systems based on a  phrase table induced from monolingual data or based  on a standard phrase table trained on the same parallel  data also used to train the baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991212487220764}]}, {"text": " Table 4: BLEU scores of NMT systems trained on par- tial translations with (dropped, partial) and with- out (original) post-processing.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988131523132324}]}, {"text": " Table 5: BLEU scores of NMT systems trained on  different combinations of original parallel data (para.),  back-translated data (backtr), and partial translations  (partial). \"all\" denotes the use of all the parallel  data provided by the WMT18 News Translation Task:  around 5.6M and 207k sentence pairs for en\u2192de and  en\u2192tr, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.998878538608551}, {"text": "WMT18 News Translation Task", "start_pos": 240, "end_pos": 267, "type": "TASK", "confidence": 0.7786018252372742}]}]}