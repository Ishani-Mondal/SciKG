{"title": [{"text": "pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference", "labels": [], "entities": [{"text": "Cross-Sentence Inference", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.7405413687229156}]}], "abstractContent": [{"text": "Reasoning about implied relationships (e.g. paraphrastic, commonsense, encyclopedic) between pairs of words is crucial for many cross-sentence inference problems.", "labels": [], "entities": [{"text": "cross-sentence inference", "start_pos": 128, "end_pos": 152, "type": "TASK", "confidence": 0.789140522480011}]}, {"text": "This paper proposes new methods for learning and using embeddings of word pairs that implicitly represent background knowledge about such relationships.", "labels": [], "entities": []}, {"text": "Our pairwise embeddings are computed as a compositional function on word representations, which is learned by maximizing the pointwise mutual information (PMI) with the contexts in which the two words co-occur.", "labels": [], "entities": [{"text": "pointwise mutual information (PMI)", "start_pos": 125, "end_pos": 159, "type": "METRIC", "confidence": 0.7019608666499456}]}, {"text": "We add these representations to the cross-sentence attention layer of existing inference models (e.g. BiDAF for QA, ESIM for NLI), instead of extending or replacing existing word embeddings.", "labels": [], "entities": []}, {"text": "Experiments show again of 2.7% on the recently released SQuAD 2.0 and 1.3% on MultiNLI.", "labels": [], "entities": [{"text": "SQuAD 2.0", "start_pos": 56, "end_pos": 65, "type": "DATASET", "confidence": 0.8800987899303436}, {"text": "MultiNLI", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9809694290161133}]}, {"text": "Our representations also aid in better generalization with gains of around 6-7% on adversarial SQuAD datasets, and 8.8% on the adversarial entail-ment test set by Glockner et al.", "labels": [], "entities": [{"text": "generalization", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.9793152809143066}, {"text": "SQuAD datasets", "start_pos": 95, "end_pos": 109, "type": "DATASET", "confidence": 0.673640102148056}]}], "introductionContent": [{"text": "Reasoning about relationships between pairs of words is crucial for cross sentence inference problems such as question answering (QA) and natural language inference (NLI).", "labels": [], "entities": [{"text": "Reasoning about relationships between pairs of words", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.8234862770353045}, {"text": "cross sentence inference", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.7070806423823038}, {"text": "question answering (QA)", "start_pos": 110, "end_pos": 133, "type": "TASK", "confidence": 0.84011812210083}]}, {"text": "In NLI, for example, given the premise \"golf is prohibitively expensive\", inferring that the hypothesis \"golf is a cheap pastime\" is a contradiction requires one to know that expensive and cheap are antonyms.", "labels": [], "entities": []}, {"text": "Recent work ( has shown that current models, which rely heavily on unsupervised single-word embeddings, struggle to learn such relationships.", "labels": [], "entities": []}, {"text": "In this paper, we show that they can be learned with word pair vectors (pair2vec  which are trained unsupervised, and which significantly improve performance when added to existing cross-sentence attention mechanisms.", "labels": [], "entities": []}, {"text": "Unlike single-word representations, which typically model the co-occurrence of a target word x with its context c, our word-pair representations are learned by modeling the three-way cooccurrence between words (x, y) and the context c that ties them together, as seen in.", "labels": [], "entities": []}, {"text": "While similar training signals have been used to learn models for ontology construction and knowledge base completion (, this paper shows, for the first time, that large scale learning of pairwise embeddings can be used to directly improve the performance of neural cross-sentence inference models.", "labels": [], "entities": [{"text": "ontology construction", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.9127380549907684}, {"text": "knowledge base completion", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.6325419942537943}]}, {"text": "More specifically, we train a feedforward network R(x, y) that learns representations for the individual words x and y, as well as how to compose them into a single vector.", "labels": [], "entities": []}, {"text": "Training is done by maximizing a generalized notion of the pointwise mutual information (PMI) among x, y, and their context c using a variant of negative sampling ().", "labels": [], "entities": []}, {"text": "Making R(x, y) a compositional function on individual words alleviates the sparsity that necessarily comes with embedding pairs of words, even at a very large scale.", "labels": [], "entities": []}, {"text": "We show that our embeddings can be added to existing cross-sentence inference models, such as BiDAF++ ( for QA and ESIM for NLI.", "labels": [], "entities": []}, {"text": "Instead of changing the word embeddings that are fed into the encoder, we add the pretrained pair representations to higher layers in the network where cross sentence attention mechanisms are used.", "labels": [], "entities": []}, {"text": "This allows the model to use the background knowledge that the pair embeddings implicitly encode to reason about the likely relationships between the pairs of words it aligns.", "labels": [], "entities": []}, {"text": "Experiments show that simply adding our wordpair embeddings to existing high-performing models, which already use ELMo (, results in sizable gains.", "labels": [], "entities": [{"text": "ELMo", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.8527226448059082}]}, {"text": "We show 2.72 F1 points over the BiDAF++ model on SQuAD 2.0 (, as well as a 1.3 point gain over ESIM () on MultiNLI (.", "labels": [], "entities": [{"text": "F1", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9992365837097168}, {"text": "SQuAD 2.0", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.9160025119781494}, {"text": "MultiNLI", "start_pos": 106, "end_pos": 114, "type": "DATASET", "confidence": 0.9367057085037231}]}, {"text": "Additionally, our approach generalizes well to adversarial examples, with a 6-7% F1 increase on adversarial SQuAD (Jia and Liang, 2017) and a 8.8% gain on the NLI benchmark.", "labels": [], "entities": [{"text": "F1", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9997685551643372}, {"text": "NLI benchmark", "start_pos": 159, "end_pos": 172, "type": "DATASET", "confidence": 0.9005703628063202}]}, {"text": "An analysis of pair2vec on word analogies suggests that it complements the information in single-word representations, especially for encyclopedic and lexicographic relations.", "labels": [], "entities": []}], "datasetContent": [{"text": "For   Data We use the January 2018 dump of English Wikipedia, containing 96M sentences to train pair2vec.", "labels": [], "entities": [{"text": "January 2018 dump of English Wikipedia", "start_pos": 22, "end_pos": 60, "type": "DATASET", "confidence": 0.8203418850898743}]}, {"text": "We restrict the vocabulary to the 100K most frequent words.", "labels": [], "entities": []}, {"text": "Preprocessing removes all out-of-vocabulary words in the corpus.", "labels": [], "entities": []}, {"text": "We consider each word pair within a window of 5 in the preprocessed corpus, and subsample 5 instances based on pair probability with a threshold of 5\u00b710 \u22127 . We define the context as one word each to the left and right, and all the words in between each pair, replacing both target words with placeholders X and Y (see).", "labels": [], "entities": []}, {"text": "More details can be found in the supplementary material.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performance on SQuAD 2.0 and adversarial  SQuAD (AddSent and AddOneSent) benchmarks, with  and without pair2vec. All models have ELMo.", "labels": [], "entities": [{"text": "ELMo", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.9600998163223267}]}, {"text": " Table 4: Performance on MultiNLI, with and without  pair2vec. All models have ELMo.", "labels": [], "entities": [{"text": "ELMo", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9940707087516785}]}, {"text": " Table 5: Performance on the adversarial NLI test set of  Glockner et al. (2018).", "labels": [], "entities": [{"text": "NLI test set", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.7299426595369974}]}, {"text": " Table 6: Ablations on the Squad 2.0 development set  show that argument sampling as well as using a deeper  composition function are useful.", "labels": [], "entities": [{"text": "Squad 2.0 development set", "start_pos": 27, "end_pos": 52, "type": "DATASET", "confidence": 0.915030762553215}, {"text": "argument sampling", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.8132346868515015}]}, {"text": " Table 7: The top 10 analogy relations for which inter- polating with pair2vec improves performance. \u03b1  *   is the optimal interpolation parameter for each relation.", "labels": [], "entities": []}]}