{"title": [{"text": "CCG Parsing Algorithm with Incremental Tree Rotation", "labels": [], "entities": [{"text": "Incremental Tree Rotation", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.6130365331967672}]}], "abstractContent": [{"text": "The main obstacle to incremental sentence processing arises from right-branching constituent structures, which are present in the majority of English sentences, as well as from optional constituents that adjoin on the right, such as right adjuncts and right conjuncts.", "labels": [], "entities": [{"text": "incremental sentence processing", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.7310645778973898}]}, {"text": "In CCG, many right-branching derivations can be replaced by semantically equivalent left-branching incremental derivations.", "labels": [], "entities": []}, {"text": "The problem of right-adjunction is more resistant to solution, and has been tackled in the past using revealing-based approaches that often rely either on the higher-order unification over lambda terms (Pareschi and Steedman, 1987) or heuristics over dependency representations that do not cover the whole CCGbank (Ambati et al., 2015).", "labels": [], "entities": []}, {"text": "We propose anew incremental parsing algorithm for CCG following the same revealing tradition of work but having a purely syntactic approach that does not depend on access to a distinct level of semantic representation.", "labels": [], "entities": []}, {"text": "This algorithm can cover the whole CCGbank, with greater incrementality and accuracy than previous proposals.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9573122262954712}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9987179040908813}]}], "introductionContent": [{"text": "Combinatory Categorial Grammar (CCG)) is a mildly context sensitive grammar formalism that is attractive both from a cognitive and an engineering perspective.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG))", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7584880143404007}]}, {"text": "Compared to other grammar formalisms, the aspect in which CCG excels is incremental sentence processing.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7347067892551422}]}, {"text": "CCG has a very flexible notion of constituent structure which allows (mostly) left-branching derivation trees that are easier to process incrementally.", "labels": [], "entities": [{"text": "CCG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8714960813522339}]}, {"text": "Take for instance the derivation tree in.", "labels": [], "entities": []}, {"text": "If we use a nonincremental shift-reduce parser (as done in the majority of transition-based parsers for CCG; Xu, 2016)) we will be able to establish the semantic connection between the subject \"Nada\" and the verb \"eats\" only when we reach the end of the sentence.", "labels": [], "entities": []}, {"text": "This is undesirable for several reasons.", "labels": [], "entities": []}, {"text": "First, human sentence processing is much more incremental, so that the meaning of the prefix \"Nada eats\" is available as soon as it is read).", "labels": [], "entities": []}, {"text": "Second, if we want a predictive model-either for better parsing or language modelling-it is crucial to establish relations between the words in the prefix as early as possible.", "labels": [], "entities": [{"text": "language modelling-it", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.6703890562057495}]}, {"text": "To address this problem, a syntactic theory needs to be able to represent partial constituents like \"Nada eats\" and have mechanisms to build them just by observing the prefix.", "labels": [], "entities": []}, {"text": "In CCG solutions for these problems come out of the theory naturally.", "labels": [], "entities": []}, {"text": "CCG categories can represent partial structures and these partial structures can combine into bigger (partial) structures using CCG combinators recursively.", "labels": [], "entities": []}, {"text": "shows how CCG can incrementally process the example sentence via a different derivation tree that generates the same semantics more incrementally by being leftbranching.", "labels": [], "entities": []}, {"text": "This way of doing incremental processing seems straightforward except for one obstacle: optional constituents that attach from the right, i.e. right adjuncts.", "labels": [], "entities": []}, {"text": "Because they are optional, it is impossible to predict them with certainty.", "labels": [], "entities": []}, {"text": "This forces an eager incremental processor to make an uninformed decision very early and, if later that decision turns out to be wrong, to backtrack to repair the mistake.", "labels": [], "entities": []}, {"text": "This behaviour would imply that human processors have difficulty in processing right adjuncts, but that does not seem to be the case.", "labels": [], "entities": []}, {"text": "For instance, let's say that after incrementally processing \"Nada eats apples\" we encounter right adjunct \"regularly\" as in.", "labels": [], "entities": []}, {"text": "The parser will be stuck at this point because there is noway to at-  >T S /(S \\NP ) >B S /NP > S (a) Problem -S\\NP that needs to be modified was never built.", "labels": [], "entities": []}, {"text": "Nada eats apples regularly Nada eats apples regularly  tach the right adjunct of a verb phrase to a sentence constituent.", "labels": [], "entities": []}, {"text": "A simple solution would be some sort of limited back-tracking where we would look if we could extract the verb-phrase, attach its right adjunct, and then put the derivation back together.", "labels": [], "entities": []}, {"text": "But how do we do the extraction of the verb-phrase \"eats apples\" when that constituent was never built during the incremental left-branching derivation?", "labels": [], "entities": []}, {"text": "proposed to reveal the constituent that is needed, the verb-phrase in our example, by having an elegant way of reanalysing the derivation.", "labels": [], "entities": []}, {"text": "This reanalysis does not repeat parsing from scratch but instead runs a single CCG combinatory rule backwards.", "labels": [], "entities": []}, {"text": "In the example at hand, first we recognise that right adjunction needs to take place because we have a category of shape X\\X (concretely (S\\NP)\\(S\\NP) but in the present CCG notation slashes \"associate to the left\", so we drop the first pair of brackets).", "labels": [], "entities": []}, {"text": "Thanks to the type of the adjunct we know that the constituent that needs to be revealed is of type X, in our case S\\NP.", "labels": [], "entities": []}, {"text": "Now, we take the constituent on the left of the right adjunct, in our example constituent S, and look for CCG category Y and combinatory rule C that satisfies the following relation: C(Y, S\\NP) = S.", "labels": [], "entities": []}, {"text": "The solution to this type equation is Y=NP and C=<.", "labels": [], "entities": []}, {"text": "To confine revealing to delivering constituents that the parser could have built if it had been less greedy for incrementality, and exclude revelation of unsupported types, such as PP in, the process must be constrained by the actual derivation.", "labels": [], "entities": []}, {"text": "Pareschi and Steedman proposed to do so by accessing the semantic representation in parallel, using higher-order unification, which is in general undecidable and maybe unsound unless defined over a specific semantic representation.", "labels": [], "entities": []}, {"text": "propose an alternative method for revealing where dependencies are used as a semantic representation (instead of first-order logic) and special heuristics are used for revealing (instead of higher order unification).", "labels": [], "entities": []}, {"text": "This is computationally a much more efficient approach and appears sound, but requires distinct revealing rules for each constituent type and has specific difficulties with punctuation.", "labels": [], "entities": []}, {"text": "In this paper we propose a method of revealing that does not depend on any specific choice of semantic representation, can discover multiple possible revealing options if they are available, is sound and complete and computationally efficient, and gives state-of-the-art parsing results.", "labels": [], "entities": []}, {"text": "The algorithm works by building leftbranching derivations incrementally, but, following Niv, as soon as a left branching derivation is built, its derivation tree is rebalanced to be right-branching.", "labels": [], "entities": []}, {"text": "When all such constituents' derivation trees are right-branching, revealing becomes a trivial operation where we just traverse the right spine looking for the constituent(s) of the right type to be modified by the right adjunct.", "labels": [], "entities": []}, {"text": "We call this rebalancing operation tree rota-tion since it is a technical term established in the field of data structures for similar operation of balanced binary search trees).", "labels": [], "entities": []}, {"text": "shows the right rotated derivation \"Nada eats apples\" next to the adjunct.", "labels": [], "entities": []}, {"text": "Here we can just lookup the required S\\NP and attach the right adjunct to it as in.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Train set measure of incrementality. *: taken  from (Ambati et al., 2015)", "labels": [], "entities": []}, {"text": " Table 2: Development set F1 results with greedy de- coding for CCG dependencies.", "labels": [], "entities": [{"text": "F1", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9869599938392639}]}, {"text": " Table 3: Test set F1 results for prediction of supertags  (Tag), unlabelled (UF) and labelled (LF) CCG de- pendencies extracted using scripts from Hockenmaier  (2003) parser.", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9973517656326294}]}, {"text": " Table 4: F1 results for labelled dependencies extracted  with generate program of C&C parser (Clark and Cur- ran, 2007).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9985038042068481}]}]}