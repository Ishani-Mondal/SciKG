{"title": [{"text": "Left-to-Right Dependency Parsing with Pointer Networks", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.8729522526264191}]}], "abstractContent": [{"text": "We propose a novel transition-based algorithm that straightforwardly parses sentences from left to right by building n attachments, with n being the length of the input sentence.", "labels": [], "entities": [{"text": "parses sentences from left to right", "start_pos": 69, "end_pos": 104, "type": "TASK", "confidence": 0.8453485369682312}]}, {"text": "Similarly to the recent stack-pointer parser by Ma et al.", "labels": [], "entities": []}, {"text": "(2018), we use the pointer network framework that, given a word, can directly point to a position from the sentence.", "labels": [], "entities": []}, {"text": "However , our left-to-right approach is simpler than the original top-down stack-pointer parser (not requiring a stack) and reduces transition sequence length in half, from 2n \u2212 1 actions ton.", "labels": [], "entities": []}, {"text": "This results in a quadratic non-projective parser that runs twice as fast as the original while achieving the best accuracy to date on the English PTB dataset (96.04% UAS, 94.43% LAS) among fully-supervised single-model dependency parsers, and improves over the former top-down transition system in the majority of languages tested.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9983924031257629}, {"text": "English PTB dataset", "start_pos": 139, "end_pos": 158, "type": "DATASET", "confidence": 0.780587395032247}, {"text": "UAS", "start_pos": 167, "end_pos": 170, "type": "METRIC", "confidence": 0.8256935477256775}, {"text": "LAS", "start_pos": 179, "end_pos": 182, "type": "METRIC", "confidence": 0.9755934476852417}]}], "introductionContent": [{"text": "Dependency parsing, the task of automatically obtaining the grammatical structure of a sentence expressed as a dependency tree, has been widely studied by natural language processing (NLP) researchers in the last decades.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8439338207244873}]}, {"text": "Most of the models providing competitive accuracies fall into two broad families of approaches: graph-based,b) and transition-based) dependency parsers.", "labels": [], "entities": []}, {"text": "Given an input sentence, a graph-based parser scores trees by decomposing them into factors, and performs a search for the highest-scoring tree.", "labels": [], "entities": []}, {"text": "In the past two years, this kind of dependency parsers have been ahead in terms of accuracy thanks to the graph-based neural architecture developed by, which not only achieved state-of-the-art accuracies on the Stanford Dependencies conversion of the English Penn Treebank (hereinafter, PTB-SD), but also obtained the best results in the majority of languages in the.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9987717270851135}, {"text": "English Penn Treebank", "start_pos": 251, "end_pos": 272, "type": "DATASET", "confidence": 0.7138957579930624}, {"text": "PTB-SD", "start_pos": 287, "end_pos": 293, "type": "DATASET", "confidence": 0.9128373265266418}]}, {"text": "This tendency recently changed, since a transition-based parser developed by managed to outperform the best graphbased model in the majority of datasets tested.", "labels": [], "entities": []}, {"text": "Transition-based parsers incrementally build a dependency graph for an input sentence by applying a sequence of transitions.", "labels": [], "entities": []}, {"text": "This results in more efficient parsers with linear time complexity for parsing projective sentences, or quadratic for handling non-projective structures, when implemented with greedy or beam search.", "labels": [], "entities": [{"text": "parsing projective sentences", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.8907967209815979}]}, {"text": "However, their main weakness is the lack of access to global context information when transitions are greedily chosen.", "labels": [], "entities": []}, {"text": "This favours error propagation, mainly affecting long dependencies that require a larger number of transitions to be built ().", "labels": [], "entities": [{"text": "error propagation", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7121537327766418}]}, {"text": "Many attempts have been made to alleviate the impact of error propagation in transition-based dependency parsing, but the latest and most successful approach was developed by.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7279033958911896}, {"text": "transition-based dependency parsing", "start_pos": 77, "end_pos": 112, "type": "TASK", "confidence": 0.5993775824705759}]}, {"text": "In particular, they make use of pointer networks) to implement anew neural network architecture called stack-pointer network.", "labels": [], "entities": []}, {"text": "The proposed framework provides a global view of the input sentence by capturing information from the whole sentence and all the arcs previously built, crucial for reducing the effect of error propagation; and, thanks to an attention mechanism (, is able to return a position in that sentence that corresponds to a word related to the word currently on top of the stack.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 187, "end_pos": 204, "type": "TASK", "confidence": 0.7019708156585693}]}, {"text": "They take advantage of this and propose a novel transition system that follows a top-down depth-first strategy to perform the syntactic analysis.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.7657591700553894}]}, {"text": "Concretely, it considers the word pointed by the neural network as the child of the word on top of the stack, and builds the corresponding dependency relation between them.", "labels": [], "entities": []}, {"text": "This results in a transition-based algorithm that can process unrestricted non-projective sentences in O(n 2 ) time complexity and requires 2n-1 actions to successfully parse a sentence with n words.", "labels": [], "entities": []}, {"text": "We also take advantage of pointer network capabilities and use the neural network architecture introduced by to design a nonprojective left-to-right transition-based algorithm, where the position value pointed by the network has the opposite meaning: it denotes the index that corresponds to the head node of the current focus word.", "labels": [], "entities": []}, {"text": "This results in a straightforward transition system that can parse a sentence in just n actions, without the need of any additional data structure and by just attaching each word from the sentence to another word (including the root node).", "labels": [], "entities": []}, {"text": "Apart from increasing the parsing speed twofold (while keeping the same quadratic time complexity), it achieves the best accuracy to date among fully-supervised single-model dependency parsers on the PTB-SD, and obtains competitive accuracies on twelve different languages in comparison to the original top-down version.", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9674884676933289}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9983783960342407}, {"text": "PTB-SD", "start_pos": 200, "end_pos": 206, "type": "DATASET", "confidence": 0.9607934355735779}]}, {"text": "propose a novel neural network architecture whose main backbone is a pointer network (.", "labels": [], "entities": []}, {"text": "This kind of neural networks are able to learn the conditional probability of a sequence of discrete numbers that correspond to positions in an input sequence (in this case, indexes of words in a sentence) and, by means of attention (, implement a pointer that selects a position from the input at decoding time.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Parsing accuracy of the top-down and left-to- right pointer-network-based parsers on test datasets of  twelve languages from UD. Best results for each lan- guage are shown in bold and, apart from the average  UAS and LAS, we also report the corresponding stand- ard deviation over 3 runs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.946284830570221}, {"text": "UD", "start_pos": 135, "end_pos": 137, "type": "DATASET", "confidence": 0.8564512133598328}, {"text": "LAS", "start_pos": 227, "end_pos": 230, "type": "METRIC", "confidence": 0.970424473285675}]}]}