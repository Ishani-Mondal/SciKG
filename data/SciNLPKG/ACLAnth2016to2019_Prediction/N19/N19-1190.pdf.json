{"title": [{"text": "Improving Robustness of Machine Translation with Synthetic Noise", "labels": [], "entities": [{"text": "Improving Robustness of Machine Translation", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8057093977928161}]}], "abstractContent": [{"text": "Modern Machine Translation (MT) systems perform remarkably well on clean, in-domain text.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 7, "end_pos": 31, "type": "TASK", "confidence": 0.8672834634780884}]}, {"text": "However most human generated text, particularly in the realm of social media, is full of typos, slang, dialect, idiolect and other noise which can have a disastrous impact on the accuracy of MT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9972841739654541}, {"text": "MT", "start_pos": 191, "end_pos": 193, "type": "TASK", "confidence": 0.981088399887085}]}, {"text": "In this paper we propose methods to enhance the robustness of MT systems by emulating naturally occurring noise in otherwise clean data.", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9948399662971497}]}, {"text": "Synthesizing noise in this manner we are ultimately able to make a vanilla MT system more resilient to naturally occurring noise, partially mitigating loss inaccuracy resulting therefrom 1 .", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9442063570022583}]}], "introductionContent": [{"text": "Machine Translation (MT) systems have been shown to exhibit severely degraded performance when required to translate of out-of-domain or noisy data (.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8756056904792786}]}, {"text": "This is particularly pronounced when systems trained on clean, formalized parallel data such as Europarl (, are tasked with translation of unedited, human generated text such as is common in domains such as social media, where accurate translation is becoming of widespread relevance (.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.980653703212738}, {"text": "translation of unedited, human generated text", "start_pos": 124, "end_pos": 169, "type": "TASK", "confidence": 0.802250896181379}]}, {"text": "Improving the robustness of MT systems to naturally occurring noise presents an important and interesting task.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9914849400520325}]}, {"text": "Recent work on MT robustness has demonstrated the need to build or adapt systems that are resilient to such noise.", "labels": [], "entities": [{"text": "MT robustness", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.9757808446884155}]}, {"text": "We approach the problem of adapting to noisy data aiming to answer two primary research questions: 1.", "labels": [], "entities": []}, {"text": "Can we artificially synthesize the types of noise common to social media text in otherwise clean data?", "labels": [], "entities": []}, {"text": "2. Are we able to improve the performance of vanilla MT systems on noisy data by leveraging artificially generated noise?", "labels": [], "entities": [{"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.939434289932251}]}, {"text": "In this work we present two primary methods of synthesizing natural noise, in accordance with the types of noise identified in prior work as naturally occurring in internet and social media based text).", "labels": [], "entities": []}, {"text": "Specifically, we introduce a synthetic noise induction model which heuristically introduces types of noise unique to social media text and labeled back translation (), a data-driven method to emulate target noise.", "labels": [], "entities": []}, {"text": "We present a series of experiments based on the Machine Translation of Noisy Text (MTNT) data set () through which we demonstrate improved resilience of a vanilla MT system by adaptation using artificially noised data.", "labels": [], "entities": [{"text": "Machine Translation of Noisy Text (MTNT) data set", "start_pos": 48, "end_pos": 97, "type": "DATASET", "confidence": 0.8410626947879791}]}, {"text": "demonstrate the fragility of neural networks to noisy input.", "labels": [], "entities": []}, {"text": "This fragility has been shown to extend to MT systems ( where both artificial and natural noise are shown to negatively affect performance.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9795743823051453}]}], "datasetContent": [{"text": "We propose two primary approaches to increasing the resilience of our baseline model to the MTNT data, outlined as follows:", "labels": [], "entities": [{"text": "MTNT data", "start_pos": 92, "end_pos": 101, "type": "DATASET", "confidence": 0.7703372836112976}]}], "tableCaptions": [{"text": " Table 1: Statistics about different datasets used in our  experiments. We prune each dataset to retain sentences  with length \u2264 50.", "labels": [], "entities": []}]}