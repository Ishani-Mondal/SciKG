{"title": [], "abstractContent": [{"text": "We improve the informativeness of models for conditional text generation using techniques from computational pragmatics.", "labels": [], "entities": [{"text": "conditional text generation", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7176572680473328}]}, {"text": "These techniques formulate language production as a game between speakers and listeners, in which a speaker should generate output text that a listener can use to correctly identify the original input that the text describes.", "labels": [], "entities": [{"text": "formulate language production", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.7740458846092224}]}, {"text": "While such approaches are widely used in cognitive science and grounded language learning, they have received less attention for more standard language generation tasks.", "labels": [], "entities": [{"text": "language generation tasks", "start_pos": 143, "end_pos": 168, "type": "TASK", "confidence": 0.8201522628466288}]}, {"text": "We consider two pragmatic modeling methods for text generation: one where pragmatics is imposed by information preservation, and another where pragmat-ics is imposed by explicit modeling of distrac-tors.", "labels": [], "entities": [{"text": "text generation", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.765072375535965}]}, {"text": "We find that these methods improve the performance of strong existing systems for ab-stractive summarization and generation from structured meaning representations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computational approaches to pragmatics cast language generation and interpretation as gametheoretic or Bayesian inference procedures.", "labels": [], "entities": [{"text": "language generation and interpretation", "start_pos": 44, "end_pos": 82, "type": "TASK", "confidence": 0.7837114930152893}]}, {"text": "While such approaches are capable of modeling a variety of pragmatic phenomena, their main application in natural language processing has been to improve the informativeness of generated text in grounded language learning problems (.", "labels": [], "entities": []}, {"text": "In this paper, we show that pragmatic reasoning can be similarly used to improve performance in more traditional language generation tasks like generation from structured meaning representations () and summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 202, "end_pos": 215, "type": "TASK", "confidence": 0.9817250370979309}]}, {"text": "Our work builds on a line of learned Rational Speech Acts (RSA) models, in which generated strings are selected to optimize the behav-", "labels": [], "entities": [{"text": "Rational Speech Acts (RSA)", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.7542232672373453}]}], "datasetContent": [{"text": "For each of our two conditional generation tasks we evaluate on a standard benchmark dataset, following past work by using automatic evaluation against human-produced reference text.", "labels": [], "entities": [{"text": "conditional generation", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7136282920837402}]}, {"text": "We choose hyperparameters for our models (beam size, and parameters \u03b1 and \u03bb) to maximize task metrics on each dataset's development set; see Appendix A..", "labels": [], "entities": []}, {"text": "We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test results for the E2E generation task, in  comparison to the T-Gen baseline (Du\u0161ek and Jur\u010d\u00ed\u010dek,  2016) and the best results from the E2E challenge, re- ported by Du\u0161ek et al. (2018):  \u2020 Juraska et al. (2018),   \u2021 Puzikov and Gurevych (2018), Zhang et al. (2018),  and \u2022 Gong", "labels": [], "entities": [{"text": "E2E generation task", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.8431706031163534}]}, {"text": " Table 2: Test results for the non-anonymized  CNN/Daily Mail summarization task. We compare to  extractive baselines, and the best previous abstractive  results of  \u2020 Celikyilmaz et al. (2018),  \u2021 Paulus et al.  (2018) and", "labels": [], "entities": [{"text": "CNN/Daily Mail summarization task", "start_pos": 47, "end_pos": 80, "type": "DATASET", "confidence": 0.8767633239428202}]}]}