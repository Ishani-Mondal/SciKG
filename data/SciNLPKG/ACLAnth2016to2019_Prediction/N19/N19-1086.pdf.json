{"title": [{"text": "Sentence Embedding Alignment for Lifelong Relation Extraction", "labels": [], "entities": [{"text": "Sentence Embedding Alignment", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9328306516011556}, {"text": "Lifelong Relation Extraction", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.7694907089074453}]}], "abstractContent": [{"text": "Conventional approaches to relation extraction usually require a fixed set of pre-defined relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.9300430715084076}]}, {"text": "Such requirement is hard to meet in many real applications, especially when new data and relations are emerging incessantly and it is computationally expensive to store all data and retrain the whole model every time new data and relations come in.", "labels": [], "entities": []}, {"text": "We formulate such a challenging problem as lifelong relation extraction and investigate memory-efficient incremental learning methods without catastrophically forgetting knowledge learned from previous tasks.", "labels": [], "entities": [{"text": "lifelong relation extraction", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.6667764882246653}]}, {"text": "We first investigate a modified version of the stochastic gradient methods with a replay memory, which surprisingly outperforms recent state-of-the-art lifelong learning methods.", "labels": [], "entities": []}, {"text": "We further propose to improve this approach to alleviate the forgetting problem by anchoring the sentence embedding space.", "labels": [], "entities": []}, {"text": "Specifically, we utilize an explicit alignment model to mitigate the sentence embedding distortion of the learned model when training on new data and new relations.", "labels": [], "entities": []}, {"text": "Experiment results on multiple benchmarks show that our proposed method significantly outperforms the state-of-the-art lifelong learning approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of relation detection/extraction aims to recognize entity pairs' relationship from given contexts.", "labels": [], "entities": [{"text": "relation detection/extraction", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.8310145288705826}]}, {"text": "As an essential component for structured information extraction, it has been widely used in downstream tasks such as automatic knowledgebased completion () and question answering.", "labels": [], "entities": [{"text": "structured information extraction", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.6409296194712321}, {"text": "automatic knowledgebased completion", "start_pos": 117, "end_pos": 152, "type": "TASK", "confidence": 0.5581436355908712}, {"text": "question answering", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.9092745184898376}]}, {"text": "Existing relation detection methods always assume a closed set of relations and perform once-and-for-all training on a fixed dataset.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8630774319171906}]}, {"text": "While making the evaluation straightforward, this setting clearly limits the usage of these methods in realistic applications, where new relations keep emerging overtime.", "labels": [], "entities": []}, {"text": "To build an evolving system which automatically keeps up with the dynamic data, we consider a more practical lifelong learning setting (also called continual learning), where a learning agent learns from a sequence of tasks, where each of them includes a different set of relations.", "labels": [], "entities": []}, {"text": "In such scenarios, it is often infeasible to combine the new data with all previous data and re-train the model using the combined dataset, especially when the training set for each task is huge.", "labels": [], "entities": []}, {"text": "To enable efficient learning in such scenarios, recent lifelong learning research propose to learn the tasks incrementally, while at the same time preventing catastrophic forgetting), i.e., the model abruptly forgets knowledge learned on previous tasks when learning on the new task.", "labels": [], "entities": []}, {"text": "Current lifelong learning approaches address such challenge by either preserving the training loss on previously learned tasks (GEM) (, or selectively dimming the updates on important model parameters (EWC).", "labels": [], "entities": []}, {"text": "These methods usually involve adding additional constraints on the model's parameters or the updates of parameters by utilizing stored samples.", "labels": [], "entities": []}, {"text": "Despite the effectiveness of these methods on simple image classification tasks, there is little research validating the practical usage of these methods in realistic NLP tasks.", "labels": [], "entities": [{"text": "image classification tasks", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.7958156168460846}]}, {"text": "In fact, when applying these methods to our relation extraction task, we observe that they underperform a simple baseline that updates the model parameters (i.e., learning by SGD) with a mix of stored samples from previous tasks and new samples from the incoming task.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.8409128387769064}]}, {"text": "We further test this simple baseline on commonly used continual learning benchmarks and get similar observations.", "labels": [], "entities": []}, {"text": "In this work, we thoroughly investigate two existing continual learning algorithms on the proposed lifelong relation extraction task.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 108, "end_pos": 132, "type": "TASK", "confidence": 0.814333458741506}]}, {"text": "We observe that recent lifelong learning methods only operate on the models' parameter space or gradient space, and do not explicitly constraint the feature or embedding space of neural models.", "labels": [], "entities": []}, {"text": "As we train the model on the new task, the embedding space might be distorted a lot, and become infeasible for previous tasks.", "labels": [], "entities": []}, {"text": "We argue that the embedding space should not be distorted much in order to let the model work consistently on previous tasks.", "labels": [], "entities": []}, {"text": "To achieve this, we propose an alignment model that explicitly anchors the sentence embeddings derived by the neural model.", "labels": [], "entities": []}, {"text": "Specifically, the alignment model treats the saved data from previous tasks as anchor points and minimizes the distortion of the anchor points in the embedding space in the lifelong relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 182, "end_pos": 201, "type": "TASK", "confidence": 0.7150896191596985}]}, {"text": "The aligned embedding space is then utilized for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9237659573554993}]}, {"text": "Experiment results show that our method outperforms the state-of-the-art significantly inaccuracy while remaining efficient.", "labels": [], "entities": []}, {"text": "The main contributions of this work include: \u2022 We introcduce the lifelong relation detection problem and construct lifelong relation detection benchmarks from two datasets with large relation vocabularies: SimpleQuestions (.", "labels": [], "entities": [{"text": "lifelong relation detection", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.6127014855543772}, {"text": "relation detection", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.7229761779308319}]}, {"text": "\u2022 We propose a simple memory replay approach and find that current popular methods such as EWC and GEM underperform this method.", "labels": [], "entities": [{"text": "memory replay", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.7813534438610077}, {"text": "EWC", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.8970736861228943}, {"text": "GEM", "start_pos": 99, "end_pos": 102, "type": "DATASET", "confidence": 0.711046576499939}]}, {"text": "\u2022 We propose an alignment model which aims to alleviate the catastrophic forgetting problem by slowing down the fast changes in the embedding space for lifelong learning.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on our lifelong benchmarks: lifelong SimpleQuestions () and lifelong FewRel () to compare our proposed methods EA-EMR, EA-EMR without Selection (EA-EMR NoSel), EA-EMR without Alignment (EA-EMR noAlign), and EMR with the following baselines.", "labels": [], "entities": [{"text": "FewRel", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.8464561104774475}]}, {"text": "\u2022 Origin, which simply trains on new tasks based on the previous model.", "labels": [], "entities": [{"text": "Origin", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.844092845916748}]}, {"text": "\u2022 EWC ( , which slows down updates on important parameters by adding L 2 regularization of parameter changes to the loss.", "labels": [], "entities": [{"text": "EWC", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.966703474521637}]}, {"text": "\u2022 GEM (, which projects the gradient to benefit all the tasks so far by keeping a constraint for each previous task.", "labels": [], "entities": [{"text": "GEM", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.7664255499839783}]}, {"text": "\u2022 AGEM (Anonymous, 2019), which only uses one constraint that the projected gradient should decrease the average loss on previous tasks.", "labels": [], "entities": [{"text": "AGEM", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.82368403673172}]}, {"text": "On both FewRel and SimpleQuestions, the epoch to train on each task is set to be 3.", "labels": [], "entities": [{"text": "FewRel", "start_pos": 8, "end_pos": 14, "type": "DATASET", "confidence": 0.9253454208374023}]}, {"text": "Learning rate for the basic model is set to be 0.001.", "labels": [], "entities": [{"text": "Learning rate", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.974303275346756}]}, {"text": "The hidden size of LSTM is set to be 200.", "labels": [], "entities": []}, {"text": "The batch size is set to be 50.", "labels": [], "entities": []}, {"text": "For each sample in the memory, 10 candidate relations is randomly chosen from all observed relations to alleviate the problem that new relations are emerging incessantly.", "labels": [], "entities": []}, {"text": "Parameters for our model and baselines are set as follows.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9639630317687988}]}, {"text": "For EA-EMR and EA-EMR NoSel, when training the alignment model, the learning rate is set to be 0.0001, and the training epoch is set to be 20 and 10 for FewRel and SimpleQuestions respectively.", "labels": [], "entities": [{"text": "EA-EMR NoSel", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.7653793096542358}, {"text": "FewRel", "start_pos": 153, "end_pos": 159, "type": "DATASET", "confidence": 0.9313383102416992}]}, {"text": "For AGEM, 100 samples are: This table shows the accuracy on the whole testing data (\"Whole\" column), and average accuracy on all observed tasks (\"Avg\" column) after the last time step.", "labels": [], "entities": [{"text": "AGEM", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.5199985504150391}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9993977546691895}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9868302941322327}, {"text": "Avg\" column)", "start_pos": 146, "end_pos": 158, "type": "METRIC", "confidence": 0.961770549416542}]}, {"text": "The average performance of 5 runs are listed here and the best result on each dataset is marked in bold.", "labels": [], "entities": []}, {"text": "randomly chosen from all the previous tasks to form a constraint.", "labels": [], "entities": []}, {"text": "For EWC, we set the balancing parameter \u03b1 = 100.", "labels": [], "entities": [{"text": "EWC", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.7238036394119263}, {"text": "balancing parameter \u03b1", "start_pos": 20, "end_pos": 41, "type": "METRIC", "confidence": 0.945367157459259}]}, {"text": "For GEM and EMR related methods, memory size of each task is set to be 50.", "labels": [], "entities": [{"text": "GEM", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8943212628364563}, {"text": "memory size", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9405632615089417}]}, {"text": "We use two metrics to evaluate the performance of the model: \u2022 Average performance on all seen tasks after time step k, which highlights the catastrophic problem: \u2022 Accuracy on the whole testing data of all tasks: Results on FewRel and SimpleQuestions We run each experiment 5 times independently by shuffling sequence of tasks, and the average performance is reported.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9980315566062927}, {"text": "FewRel", "start_pos": 225, "end_pos": 231, "type": "DATASET", "confidence": 0.9024462699890137}]}, {"text": "The average accuracy overall observed tasks during the whole lifelong learning process is presented in, and the accuracy on the whole testing data during the process is shown in Appendix A.1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9967880249023438}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9987908005714417}, {"text": "Appendix A.1", "start_pos": 178, "end_pos": 190, "type": "DATASET", "confidence": 0.6498354971408844}]}, {"text": "We also list the result at last step in.", "labels": [], "entities": []}, {"text": "From the results, we can see that EWC and GEM are better than the Origin baseline on both two datasets, which indicates that they are able to reduce the catastrophic forgetting problem.", "labels": [], "entities": [{"text": "EWC", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.618851363658905}, {"text": "GEM", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.5356991291046143}, {"text": "Origin baseline", "start_pos": 66, "end_pos": 81, "type": "DATASET", "confidence": 0.8324851095676422}]}, {"text": "However, our EA-EMR perform significantly better than these previous state-of-the-arts.", "labels": [], "entities": []}, {"text": "The proposed EMR method itself achieves better results than all baselines on both datasets.", "labels": [], "entities": []}, {"text": "The ablation study shows that both the selection and the alignment modules help on both tasks.", "labels": [], "entities": []}, {"text": "The Effect of Embedding Alignment To investigate the effect of our embedding alignment approach, we conduct two ablation studies as below: First, we remove both the alignment loss in equation 5.1, as well as the alignment module a, which results in significant drop on most of the cases (the line \"w/o Alignment\" in).", "labels": [], "entities": []}, {"text": "Second, to make sure that our good results do not come from introducing a deeper model with the module a, we propose to only remove the embedding alignment loss, but keep everything else unchanged.", "labels": [], "entities": []}, {"text": "That means, we still keep the module a and the training steps, with the only change on replacing the loss in step 2 with the one in step 1 (the line \"w/o Alignment but keep the architecture\" in).", "labels": [], "entities": []}, {"text": "We can see that this decreases the performance a lot.", "labels": [], "entities": []}, {"text": "The above results indicate that by explicitly doing embedding alignment, the performance of the model can be improved by alleviating the distortion of previous embedding space.: Comparison of different methods to select data for EMR.", "labels": [], "entities": [{"text": "embedding alignment", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.778658926486969}, {"text": "EMR", "start_pos": 229, "end_pos": 232, "type": "TASK", "confidence": 0.8829514980316162}]}, {"text": "The accuracy on the whole testing data (\"Whole\" column), and average accuracy on all observed tasks (\"Avg\" column) is reported.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995692372322083}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9826967716217041}, {"text": "Avg\" column)", "start_pos": 102, "end_pos": 114, "type": "METRIC", "confidence": 0.9709890484809875}]}, {"text": "We run each method 5 times, and give their average results.", "labels": [], "entities": []}, {"text": "Following the setting in (, the size of memory for each task is set to be 256.", "labels": [], "entities": []}, {"text": "The learning rate is set to be 0.1.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9412672519683838}]}, {"text": "The epoch for training the model on each task is set to be 1.", "labels": [], "entities": []}, {"text": "Plain SGD and minibatch of 10 samples are used.", "labels": [], "entities": []}, {"text": "For the MNIST dataset, each task has 1000 samples of 10 classes.", "labels": [], "entities": [{"text": "MNIST dataset", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.8688637018203735}]}, {"text": "For the CIFAR dataset, each task has 2500 samples of 5 classes.", "labels": [], "entities": [{"text": "CIFAR dataset", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.9265830814838409}]}], "tableCaptions": [{"text": " Table 1: The average accuracy across all the tasks at  last time step for EMR and GEM on both non-NLP  and our lifelong relation detection benchmarks. For the  experiments on MNIST and CIFAR, we follow the set- ting in (Lopez-Paz and Ranzato, 2017) (see Appendix  A.2 for details). For the experiments on FewRel and  SimpleQuestions, we use the same setting in Section  6. We only implement task-level EMR for MNIST and  CIFAR because of the relatively easy implementation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9975576400756836}, {"text": "GEM", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.7346993684768677}, {"text": "relation detection", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.7104327231645584}]}, {"text": " Table 2: This table shows the accuracy on the whole  testing data (\"Whole\" column), and average accuracy  on all observed tasks (\"Avg\" column) after the last time  step. The average performance of 5 runs are listed here  and the best result on each dataset is marked in bold.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9994008541107178}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9705159664154053}, {"text": "Avg\" column)", "start_pos": 131, "end_pos": 143, "type": "METRIC", "confidence": 0.9643733650445938}]}, {"text": " Table 2. From the results, we can  see that EWC and GEM are better than the Origin  baseline on both two datasets, which indicates that  they are able to reduce the catastrophic forgetting  problem. However, our EA-EMR perform signif- icantly better than these previous state-of-the-arts.  The proposed EMR method itself achieves better  results than all baselines on both datasets. The ab- lation study shows that both the selection and the  alignment modules help on both tasks.", "labels": [], "entities": [{"text": "GEM", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.4837856888771057}, {"text": "ab- lation", "start_pos": 388, "end_pos": 398, "type": "METRIC", "confidence": 0.8918179273605347}]}]}