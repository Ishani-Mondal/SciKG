{"title": [{"text": "Speak Up, Fight Back! Detection of Social Media Disclosures of Sexual Harassment", "labels": [], "entities": [{"text": "Detection of Social Media Disclosures of Sexual Harassment", "start_pos": 22, "end_pos": 80, "type": "TASK", "confidence": 0.8764584437012672}]}], "abstractContent": [{"text": "The #MeToo movement is an ongoing prevalent phenomenon on social media aiming to demonstrate the frequency and widespread of sexual harassment by providing a platform to speak up and narrate personal experiences of such harassment.", "labels": [], "entities": []}, {"text": "The aggregation and analysis of such disclosures pave the way to the development of technology-based prevention of sexual harassment.", "labels": [], "entities": [{"text": "technology-based prevention of sexual harassment", "start_pos": 84, "end_pos": 132, "type": "TASK", "confidence": 0.7139586687088013}]}, {"text": "We contend that the lack of specificity in generic sentence classification models may not be the best way to tackle text subtleties that intrinsically prevail in a classification task as complex as identifying disclosures of sexual harassment.", "labels": [], "entities": [{"text": "generic sentence classification", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6521134078502655}]}, {"text": "We propose the Disclosure Language Model, a three-part ULMFiT architecture, consisting of a Language model, a Medium-Specific (Twit-ter) model, and a Task-Specific classifier to tackle this problem and create a manually annotated real-world dataset to test our technique on this, to show that using a Discourse Language Model often yields better classification performance over (i) Generic deep learning based sentence classification models (ii) existing models that rely on handcrafted stylistic features.", "labels": [], "entities": [{"text": "Generic deep learning based sentence classification", "start_pos": 382, "end_pos": 433, "type": "TASK", "confidence": 0.6620899240175883}]}, {"text": "An extensive comparison with state-of-the-art generic and specific models along with a detailed error analysis presents the case for our proposed methodology.", "labels": [], "entities": []}], "introductionContent": [{"text": "Thirty-five percent of women, including people in the LGBTQIA+ community, are globally subjected to sexual or physical assault, according * Denotes equal contribution.", "labels": [], "entities": []}, {"text": "to a study by UN Women . With the advent of the #MeToo movement, discussions about sexual abuse have finally seen the light as compared to before, without the fear of shame or retaliation.", "labels": [], "entities": []}, {"text": "Abuse in general and sexual harassment, in particular, is one topic that is socially stigmatized and difficult for people to talk about in both non-computer-mediated and computer-mediated contexts.", "labels": [], "entities": []}, {"text": "The Disclosure Processes Model (DPM) ( examines when and why interpersonal disclosure maybe beneficial and focuses on people with concealable stigmatized identities (e.g., abuse, rape) in non-computer-mediated contexts.", "labels": [], "entities": []}, {"text": "It has been found that disclosure of abuse has positive psychological impacts (;), and the #MeToo movement has managed to make social media avenues like Twitter a safer place to share personal experiences.", "labels": [], "entities": []}, {"text": "The information gathered from these kinds of online discussions can be leveraged to create better campaigns for social change by analyzing how users react to these stories and obtaining a better insight into the consequences of sexual abuse.", "labels": [], "entities": []}, {"text": "Prior studies noted that developing an automated framework for classifying a tweet is quite challenging due to the inherent complexity of the natural language constructs (.", "labels": [], "entities": [{"text": "classifying a tweet", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8510504961013794}]}, {"text": "Tweets are entirely different from other text forms like movie reviews and news forums.", "labels": [], "entities": []}, {"text": "Tweets are often short and ambiguous because of the limitation of characters.", "labels": [], "entities": []}, {"text": "There are more mis-spelled words, slangs, and acronyms on Twitter because of its casual form (.", "labels": [], "entities": []}, {"text": "This motivates our study to build a mediumspecific Language Model for the segregation of tweets containing disclosures of sexual harassment.", "labels": [], "entities": [{"text": "segregation of tweets containing disclosures of sexual harassment", "start_pos": 74, "end_pos": 139, "type": "TASK", "confidence": 0.8388005718588829}]}, {"text": "While there is a developing body of literature on the topic of identifying patterns in the language used on social media that analyze sexual harassment disclosure (;, very few attempts have been made to segregate texts containing discussions about sexual abuse from texts containing personal recollections of sexual harassment experiences.", "labels": [], "entities": []}, {"text": "Efforts have been made to segregate domestic abuse stories from Reddit by and Karlekar and Bansal.", "labels": [], "entities": []}, {"text": "However, these approaches do not take into consideration the model's domain understanding of the syntactic and semantic attributes of the specific medium in which the text is present.", "labels": [], "entities": []}, {"text": "In that regard, our paper makes two significant contributions.", "labels": [], "entities": []}, {"text": "1. Generation of a labeled real-world dataset for identifying social media disclosures of sexual abuse, by manual annotation.", "labels": [], "entities": [{"text": "identifying social media disclosures of sexual abuse", "start_pos": 50, "end_pos": 102, "type": "TASK", "confidence": 0.8045968243053981}]}, {"text": "2. Comparison of the proposed MediumSpecific Disclosure Language Model architecture for segregation of tweets containing disclosure, with various deep learning architectures and machine learning models, in terms of four evaluation metrics.", "labels": [], "entities": [{"text": "segregation of tweets containing disclosure", "start_pos": 88, "end_pos": 131, "type": "TASK", "confidence": 0.8559362292289734}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Human Annotation examples for Non Disclosure", "labels": [], "entities": [{"text": "Human Annotation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.5132741630077362}]}, {"text": " Table 4: Cohen's Kappa for Annotators H 1 , H 2 , and  H 3", "labels": [], "entities": [{"text": "Cohen's Kappa", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.6481146713097891}]}, {"text": " Table 5: Dropout used by", "labels": [], "entities": []}, {"text": " Table 8: Comparison with baselines in terms of four evaluation metrics", "labels": [], "entities": []}]}