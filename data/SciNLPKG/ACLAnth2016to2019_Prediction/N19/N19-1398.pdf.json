{"title": [{"text": "News Article Teaser Tweets and How to Generate Them", "labels": [], "entities": [{"text": "News Article Teaser Tweets", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7338224276900291}]}], "abstractContent": [{"text": "In this work, we define the task of teaser generation and provide an evaluation benchmark and baseline systems for the process of generating teasers.", "labels": [], "entities": [{"text": "teaser generation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.826746255159378}]}, {"text": "A teaser is a short reading suggestion for an article that is illustrative and includes curiosity-arousing elements to entice potential readers to read particular news items.", "labels": [], "entities": []}, {"text": "Teasers are one of the main vehicles for transmitting news to social media users.", "labels": [], "entities": []}, {"text": "We compile a novel dataset of teasers by systematically accumulating tweets and selecting those that conform to the teaser definition.", "labels": [], "entities": []}, {"text": "We have compared a number of neural abstractive ar-chitectures on the task of teaser generation and the overall best performing system is See et al.", "labels": [], "entities": [{"text": "teaser generation", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.8103391826152802}]}, {"text": "(2017)'s seq2seq with pointer network.", "labels": [], "entities": []}], "introductionContent": [{"text": "A considerable number of people get their news in some digital format.", "labels": [], "entities": []}, {"text": "The trend has made many publishers and editors shift their focus to the web and experiment with new techniques to lure an Internet-savvy generation of readers to read their news stories.", "labels": [], "entities": []}, {"text": "Therefore, there has been a noticeable increase in the sharing of short illustrative pieces of texts about the news on social media.", "labels": [], "entities": []}, {"text": "We define a ShortcutText as a short text (about 15 words or less) describing and pointing to a news article and whose purpose is to invite the recipient to read the article.", "labels": [], "entities": []}, {"text": "A headline is a ShortcutText that optimizes the relevance of the story to its reader by including interesting and high news value content from the article.", "labels": [], "entities": []}, {"text": "Clickbait is a pejorative term for web content whose main goal is to make a user click an adjoining link by exploiting the information gap.", "labels": [], "entities": []}, {"text": "According to the definition, a principal part of the headline is an http://www.journalism.org/2008/07/21/the-influence-ofthe-web/ extract of the article, thereby creating an impression of the upcoming story.", "labels": [], "entities": []}, {"text": "However, click-bait, a ShortcutText, contains mostly elements that create anticipation, thereby making a reader click on the link; however, the reader comes to regret their decision when the story does not match the clickbait's impression.", "labels": [], "entities": []}, {"text": "Thus, click-bait provides a false impression (non-bona fide) and contains insufficient information (highly abstractive We introduce the new concept of teaser and define it as a ShortcutText devised by fusing curiosity-arousing elements with interesting facts from the article in a manner that concurrently creates a valid impression of an upcoming story and a sense of incompleteness, which motivates the audience to read the article.", "labels": [], "entities": []}, {"text": "A teaser is one of the main vehicles for transmitting news on social media.", "labels": [], "entities": [{"text": "transmitting news on social media", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.8262224197387695}]}, {"text": "shows some teasers from a popular newswire The Wall Street Journal.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.8699366648991903}]}, {"text": "We also introduce properties such as teasing, abstractive, and bona-fide, which not only differentiate teasers from other ShortcutTexts but also help in compiling a dataset for the study.", "labels": [], "entities": []}, {"text": "Teasing indicates whether curiosity-arousing elements are included in the ShortcutText.", "labels": [], "entities": [{"text": "ShortcutText", "start_pos": 74, "end_pos": 86, "type": "DATASET", "confidence": 0.9736277461051941}]}, {"text": "Abstractive indicates whether a fair proportion of the ShortcutText is distilled out of the news article.", "labels": [], "entities": [{"text": "Abstractive", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9911648631095886}, {"text": "ShortcutText", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9523107409477234}]}, {"text": "Bona-fide answers whether the news story matches the impression created by the ShortcutText.  above.", "labels": [], "entities": [{"text": "ShortcutText.  above", "start_pos": 79, "end_pos": 99, "type": "DATASET", "confidence": 0.9798781077067057}]}, {"text": "In this study, we focus on teasers shared on Twitter 2 , asocial media platform whose role as a news conduit is rapidly increasing.", "labels": [], "entities": []}, {"text": "An indicative tweet is a Twitter post containing a link to an external web page that is primarily composed of text.", "labels": [], "entities": []}, {"text": "The presence of the URL in an indicative tweet signals that it functions to help users decide whether to read the article, and the short length confirms it as a ShortcutText like a headline or teaser.", "labels": [], "entities": []}, {"text": "made an early attempt at generating indicative tweets using off-the-shelf extractive summarization models, and graded the generated texts as informative but uninteresting.", "labels": [], "entities": []}, {"text": "Additionally, Sidhaye and Cheung (2015)'s analysis showed extractive summarization as an inappropriate method for generating such tweets as the overlaps between the tweets and the corresponding articles often are low.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.7574633955955505}]}, {"text": "Our study shows that teasers, bona fide indicative tweets, do exhibit significant, though not complete, overlaps, and, therefore, are not appropriate for extractive but certainly for abstractive summarization.", "labels": [], "entities": []}, {"text": "Our contributions: 1) To the best of our knowledge, this is the first attempt to compare different types of ShortcutTexts associated with a news article.", "labels": [], "entities": []}, {"text": "Furthermore, we introduce a novel concept of a teaser, an amalgamation of article content and curiosityarousing elements, used for broadcasting news on social media by a news publisher.", "labels": [], "entities": []}, {"text": "2) We compiled a novel dataset to address the task of teaser generation.", "labels": [], "entities": [{"text": "teaser generation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.8006271719932556}]}, {"text": "The dataset is a collection of news articles, ShortcutTexts (both teasers and headlines), and story-highlights.", "labels": [], "entities": []}, {"text": "Unlike ShortcutText, a story-highlight is brief and includes self-contained sentences (about 25-40 words) that allow the recipient to gather information on news stories quickly.", "labels": [], "entities": []}, {"text": "As all corpora based on news articles include only one of these short texts, our dataset provides the NLP community with a unique opportunity fora joint study of the generation of many short texts.", "labels": [], "entities": []}, {"text": "3) We propose techniques like unigram overlap and domain relevance score to establish abstractivity and teasingness in the teasers.", "labels": [], "entities": [{"text": "unigram overlap", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.6232745498418808}]}, {"text": "We also apply these techniques to headlines and compare the results with teasers.", "labels": [], "entities": []}, {"text": "The comparison shows teasers are more abstractive than headlines.", "labels": [], "entities": []}, {"text": "4) High abstractivity makes teaser generation a tougher task; however, we show seq2seq methods trained on such a corpus are quite effective.", "labels": [], "entities": [{"text": "teaser generation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.8640139102935791}]}, {"text": "A comparison of different seq2seq methods for teaser generation shows a seq2seq combining two levels of vocabularies, source and corpus, is better than one using only the corpus level.", "labels": [], "entities": [{"text": "teaser generation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.8017628490924835}]}, {"text": "Therefore, we set a strong baseline on the teaser generation task with a seq2seq model of.", "labels": [], "entities": [{"text": "teaser generation task", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.8702296813329061}]}, {"text": "The remaining paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we provide a detailed description of the data collection and analyses.", "labels": [], "entities": []}, {"text": "In Section 3, we describe and discuss the experiments.", "labels": [], "entities": []}, {"text": "In Section 4, we describe a user study of model-generated teasers.", "labels": [], "entities": []}, {"text": "In Section 5, we discuss the related works.", "labels": [], "entities": []}, {"text": "Section 6 concludes the study.", "labels": [], "entities": []}], "datasetContent": [{"text": "Several linguistic patterns invoke curiosity, e.g., provocative questions and extremes for comparison.", "labels": [], "entities": []}, {"text": "A retrieval of teasers from asocial media platform using such patterns requires the formulation of a large number of complex rules as these patterns often involve many marker words and correspondingly many grammar rules.", "labels": [], "entities": []}, {"text": "A computationally easy approach is to compile circulations from bona-fide agents involved in luring business on such media, and then filtering out those that don't comply with defined characteristics of a teaser; see.", "labels": [], "entities": []}, {"text": "We followed the latter approach and chose Twitter to conduct our study.", "labels": [], "entities": []}, {"text": "The quantitative evaluations show that state-ofthe-art models perform moderately on the novel task.", "labels": [], "entities": []}, {"text": "This is mostly due to deficiencies of Rouge, which fails to reward heterogeneous contents.", "labels": [], "entities": []}, {"text": "We took a closer look at some of the generated examples, see, and observed frequent cases where the generation suffered from the typical seq2seq issues, e.g., repetition of words; however, there are also cases where generation is more distinctive than ground-truth and is well formed too.", "labels": [], "entities": []}, {"text": "Thus, we carried out a small user study to understand the quality of the generated teasers; however, we only selected non-repeating and non-\u2022 pres . trump lashed out on twitter at the hosts of \" msnbcs morning \" \u2022 migration agency says more than %% people drowned and presumed dead in myanmar to bangladesh \u2022 computer glitch led to google to be dramatically undervalued this morning \u2022 alt-right activist jason kessler says he was swarmed by a group of charlottesville \u2022 of identical triplets who beat the incredible odds of %%% million to survive \u2022 singer and guitar player who declined to appear on britain 's got talent  UNK generations to anonymize the source.", "labels": [], "entities": []}, {"text": "The participants in the user study are undergraduate or graduate students with some computer science background and familiarity with social media platforms.", "labels": [], "entities": []}, {"text": "Additionally, all the participants have used or have been using twitter.", "labels": [], "entities": []}, {"text": "We assembled a set of texts by randomly sampling 40 seq2seq point teasers, 40 ground-truth teasers, and 40 lead sentences (baseline), and also established equal representation of the domains.", "labels": [], "entities": []}, {"text": "We then assigned 72 sentences (3 per domain per category) to ten participants and asked them to rate texts for two questions: 1) How likely is it that the text is shared on Twitter fora news story by a news organization? and 2) How likely is it that the text makes a reader want to read the story?", "labels": [], "entities": []}, {"text": "The first question helps us recognize the participant's understanding of the teasers, as an informed reader will rate a ground-truth significantly higher than the baseline, and 8 of them recognized it correctly, and their ratings are selected for the evaluation.", "labels": [], "entities": []}, {"text": "The second question provides a cue as to the model capacity in generating teasing texts by learning interesting aspects present in the teaser corpus.", "labels": [], "entities": []}, {"text": "The annotators rated samples on a scale of 1 to 5; however, we normalized the ratings to avoid the influence of annotators having different rating personalities.", "labels": [], "entities": []}, {"text": "The results, summarized in Table 13, show that the human written teasers are most likely to be recognized as social media texts due to their style, which is distinct from the lead sentence; the model trained on such teasers closely follows it.", "labels": [], "entities": []}, {"text": "Similarly, human written teasers are good at stimulating readers to read a story compared to the lead sentence and the generated teasers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The table shows dr score range. IN and Out  refer to in-domain and out-of-domain respectively.", "labels": [], "entities": [{"text": "dr score range", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.8030188878377279}, {"text": "IN", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9945088028907776}]}, {"text": " Table 5: Teaser words and their dr values. Non- overlaps are in bold blue.", "labels": [], "entities": []}, {"text": " Table 6: The table shows clusters of domains and corresponding frequent-keywords and average article size (words)  in them.", "labels": [], "entities": []}, {"text": " Table 8: Rouge scores on the standard task of Headline  Generation (Gigaword). seq2seq and seq2seq point are  reimplementations of Bahdanau et al. (2014) and See  et al. (2017) respectively.", "labels": [], "entities": [{"text": "Headline  Generation (Gigaword)", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.6721700072288513}]}, {"text": " Table 9: Rouge F1 scores for seq2seq model and  seq2seq point models on the teaser task.", "labels": [], "entities": [{"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.8646724224090576}]}, {"text": " Table 10: Rouge F1 scores for seq2seq model and  seq2seq point models on the teaser, headline and high- lights generation task.", "labels": [], "entities": [{"text": "F1", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.9068000912666321}, {"text": "headline and high- lights generation task", "start_pos": 86, "end_pos": 127, "type": "TASK", "confidence": 0.6787552663258144}]}, {"text": " Table 12: The table shows seq2seq point generated  teasers used in the survey-based study. More examples  in supplementary A.2.", "labels": [], "entities": [{"text": "A.2", "start_pos": 124, "end_pos": 127, "type": "DATASET", "confidence": 0.8664663434028625}]}, {"text": " Table 13: The table shows the mean values and stan- dard deviations of the likelihood of being social-media  text and stimulating for users to read. Baseline = lead  sentences", "labels": [], "entities": [{"text": "stan- dard deviations", "start_pos": 47, "end_pos": 68, "type": "METRIC", "confidence": 0.8716857582330704}]}]}