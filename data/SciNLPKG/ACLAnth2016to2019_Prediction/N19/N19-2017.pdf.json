{"title": [{"text": "Extraction of Message Sequence Charts from Software Use-Case Descriptions", "labels": [], "entities": [{"text": "Extraction of Message Sequence Charts from Software Use-Case Descriptions", "start_pos": 0, "end_pos": 73, "type": "TASK", "confidence": 0.8013039032618204}]}], "abstractContent": [{"text": "Software Requirement Specification documents provide natural language descriptions of the core functional requirements as a set of use-cases.", "labels": [], "entities": [{"text": "Software Requirement Specification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7620208064715067}]}, {"text": "Essentially, each use-case contains a set of actors and sequences of steps describing the interactions among them.", "labels": [], "entities": []}, {"text": "Goals of use-case reviews and analyses include their cor-rectness, completeness, detection of ambiguities , prototyping, verification, test case generation and traceability.", "labels": [], "entities": [{"text": "test case generation", "start_pos": 135, "end_pos": 155, "type": "TASK", "confidence": 0.6323344508806864}]}, {"text": "Message Sequence Charts (MSC) have been proposed as an expressive , rigorous yet intuitive visual representation of use-cases.", "labels": [], "entities": [{"text": "Message Sequence Charts (MSC)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7835257252057394}]}, {"text": "In this paper, we describe a linguistic knowledge-based approach to extract MSCs from use-cases.", "labels": [], "entities": [{"text": "extract MSCs from use-cases", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.7260108888149261}]}, {"text": "Compared to existing techniques, we extract richer constructs of the MSC notation such as timers, conditions and alt-boxes.", "labels": [], "entities": []}, {"text": "We apply this tool to extract MSCs from several real-life software use-case descriptions and show that it performs better than the existing techniques.", "labels": [], "entities": []}], "introductionContent": [{"text": "Software Development Life Cycle (SDLC) processes generate large and complex natural language text documents, which provide a rich playground for NLP tecnhiques.", "labels": [], "entities": []}, {"text": "In particular, NLP techniques have been extensively applied to analyze requirements specifications for early detection of problems such as ambiguity and incompleteness during reviews and inspections; e.g.,.", "labels": [], "entities": []}, {"text": "Another line of research is concerned with automatically translating software requirements in natural language to various formal models, in order to provide assistance in downstream SDLC tasks like prototyping, verification, test case generation and traceability.", "labels": [], "entities": [{"text": "test case generation", "start_pos": 225, "end_pos": 245, "type": "TASK", "confidence": 0.6476407746473948}]}, {"text": "Specifically, use-cases provide a textual description of the core functional requirements as sequences of interactions among actors.", "labels": [], "entities": []}, {"text": "Hence, Message Sequence Charts (MSC) have been proposed as an expressive, rigorous yet intuitive visual representation of use-cases.", "labels": [], "entities": [{"text": "Message Sequence Charts (MSC)", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.8205955624580383}]}, {"text": "In extracting the MSC from a use-case description, we have to first identify actors, which refer to human users, physical objects, systems, subsystems and components.", "labels": [], "entities": []}, {"text": "Next, we need to identify interactions among the actors in the form of messages of the MSC.", "labels": [], "entities": []}, {"text": "The actor which initiates an interaction i.e. sends a message is called the sender and the actors which receive (or experience) the interaction are called receivers.", "labels": [], "entities": []}, {"text": "NLP techniques face various challenges in these steps.", "labels": [], "entities": []}, {"text": "Firstly, an actor (or an interaction) maybe referred in different ways (actor or event co-reference).", "labels": [], "entities": []}, {"text": "Secondly, since there is no standardized way of writing use-cases, there is tremendous variety in expressing various aspects of the functionality; e.g., main and alternate flows.", "labels": [], "entities": []}, {"text": "While restrictions such as templates or structured English have been imposed for writing use-cases e.g.,, we assume that a use-case is written as a sequence of numbered steps in the main flow, and an alternate flow for any steps in the main flow is specified separately.", "labels": [], "entities": []}, {"text": "We impose no linguistic restriction in writing each step in the use-case.", "labels": [], "entities": []}, {"text": "Finally, MSC is a rich notation with many complex facilities apart from representing actors and messages.", "labels": [], "entities": []}, {"text": "Some of these include alt-boxes, conditions and timers.", "labels": [], "entities": []}, {"text": "It is challenging to detect appropriate parts of the input text which can be mapped to these constructs.", "labels": [], "entities": []}, {"text": "shows an example usecase and shows the corresponding MSC.", "labels": [], "entities": [{"text": "MSC", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.8130656480789185}]}, {"text": "In this paper, we describe our approach to extract MSCs from use-cases based on Open Information Extraction (OpenIE).", "labels": [], "entities": [{"text": "Open Information Extraction (OpenIE)", "start_pos": 80, "end_pos": 116, "type": "TASK", "confidence": 0.6585085988044739}]}, {"text": "OpenIE extracts structured information from a sentence in the form of relation tuples representing a relation between its subject and one or more objects.", "labels": [], "entities": [{"text": "OpenIE extracts structured information from a sentence in the form of relation tuples representing a relation between its subject and one or more objects", "start_pos": 0, "end_pos": 153, "type": "Description", "confidence": 0.7086031051973501}]}, {"text": "We use OpenIE to extract candidate messages and their senders / receivers.", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 7, "end_pos": 13, "type": "DATASET", "confidence": 0.9386220574378967}]}, {"text": "We further use WordNet and dependency parsing 1 for filtering the OpenIE candidates and obtaining the final set of messages to be depicted on the MSC.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9534316062927246}, {"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.6658903360366821}, {"text": "OpenIE candidates", "start_pos": 66, "end_pos": 83, "type": "DATASET", "confidence": 0.8919506371021271}, {"text": "MSC", "start_pos": 146, "end_pos": 149, "type": "DATASET", "confidence": 0.9406333565711975}]}, {"text": "The MSC representation supports richer constructs such as timers, conditions and alt-boxes.", "labels": [], "entities": []}, {"text": "Timers represent start and end of specific time durations related to the messages and are shown by hourglass shaped markers.", "labels": [], "entities": []}, {"text": "For instance, to capture the information that part loading should be completed in 10 seconds (Step 8 in), a timer can be used.", "labels": [], "entities": [{"text": "part loading", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.7862513959407806}]}, {"text": "Accordingly, shows a timer of duration 10 seconds on the timeline of the actor \"the AGV system\".", "labels": [], "entities": []}, {"text": "Conditions represent state or situation of one or more actors and are shown as text labels inside hexagonal boxes.", "labels": [], "entities": []}, {"text": "In, a condition is shown on the timeline of the actors -\"the AGV system\" and \"the motor\" denoting the state of the system to beat the destination station.", "labels": [], "entities": []}, {"text": "Alt-boxes are used to represent an alternate control flow with respect to a certain condition applicable to a set of actors.", "labels": [], "entities": []}, {"text": "They are denoted using demarcating lines separating the normal and alternate set of messages.", "labels": [], "entities": []}, {"text": "In the example, based on the condition of the station at which the vehicle has arrived, the step mentioned as alteranate flow or the steps 6 to 10 of the normal flow need to be followed.", "labels": [], "entities": []}, {"text": "This branching is depicted using the alt-box shown in.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 covers the related work; Section 3 describes the MSC extraction approach; Section 4 describes the experiments and discusses one of the use-cases in detail; Section 5 concludes the paper.", "labels": [], "entities": [{"text": "MSC extraction", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.9766721427440643}]}], "datasetContent": [{"text": "We report results in this paper on a set of 4 usecases obtained from publicly available Software Requirement Specifications (SRS) of real life software systems).", "labels": [], "entities": [{"text": "Software Requirement Specifications (SRS)", "start_pos": 88, "end_pos": 129, "type": "TASK", "confidence": 0.6959904034932455}]}, {"text": "These usecases are AGV (Automated Guided Vehicle System), G6 & G16 (gamma-j web order system) and EMS (Electronic Monitoring System).", "labels": [], "entities": []}, {"text": "Additionally, we use one more use-case (TRAIN) from an internal project dealing with Automatic Train Control systems.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9730896353721619}]}, {"text": "We manually create the gold standard MSC for each use-case and use them to evaluate our extraction system.", "labels": [], "entities": []}, {"text": "As part of the evaluation, we compare the performance of our system with a baseline technique proposed in.", "labels": [], "entities": []}, {"text": "We evaluate the proposed approach on five levels of increasing complexity starting from actor identification to complete message extraction: 1.", "labels": [], "entities": [{"text": "actor identification", "start_pos": 88, "end_pos": 108, "type": "TASK", "confidence": 0.7842855155467987}, {"text": "message extraction", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.6948747783899307}]}, {"text": "Actors : At this level we evaluate the predicted actors with respect to the gold actors.", "labels": [], "entities": []}, {"text": "A predicted actor is a true positive if its complete phrase is present exactly in the set of gold actors.", "labels": [], "entities": []}, {"text": "False positives and false negatives are accordingly computed.", "labels": [], "entities": [{"text": "False", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9702694416046143}]}, {"text": "2. Message label : At this level we evaluate only the message label of each predicted message with respect to labels of gold messages.", "labels": [], "entities": []}, {"text": "A predicted message label from a sentence is considered as a true positive if the main verb of the label matches the main verb of a gold message from the same sentence.", "labels": [], "entities": []}, {"text": "False positives and false negatives are accordingly computed.", "labels": [], "entities": [{"text": "False", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9702694416046143}]}, {"text": "3. Message label + Sender : At this level we evaluate the combination of message label and sender of each predicted message with respect to the same combination for gold messages.", "labels": [], "entities": []}, {"text": "A predicted combination from a sentence is considered as a true positive if it matches the combination from a gold message from the same sentence.", "labels": [], "entities": []}, {"text": "receiver of each predicted message with respect to the same combination for gold messages.", "labels": [], "entities": []}, {"text": "We compute F1-measure on similar lines as above.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9976601600646973}]}, {"text": "5. Message label + Sender + Receiver : At this level we evaluate the complete message i.e. combination of message label, sender and receiver with respect to the complete gold messages.", "labels": [], "entities": []}, {"text": "We compute F1-measure on similar lines as above.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9976601600646973}]}, {"text": "As each level's performance, we report the F1-measure in.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9990735054016113}]}, {"text": "Our approach outperforms the baseline on all datasets on all evaluation levels.", "labels": [], "entities": []}, {"text": "For extraction of the complex constructs like conditions, alt-boxes and timers, we employ a set of simple rules described earlier.", "labels": [], "entities": []}, {"text": "The baseline technique proposed in does not focus on identifying these constructs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparative performance for MSC Extraction. M: Our approach described in Algorithm 1. B: Baseline  approach based on", "labels": [], "entities": [{"text": "MSC Extraction", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.9032019078731537}]}]}