{"title": [{"text": "A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource Languages", "labels": [], "entities": [{"text": "Unsupervised Universal Part-of-Speech Tagger", "start_pos": 11, "end_pos": 55, "type": "TASK", "confidence": 0.6838725805282593}]}], "abstractContent": [{"text": "Unsupervised part of speech (POS) tagging is often framed as a clustering problem, but practical taggers need to ground their clusters as well.", "labels": [], "entities": [{"text": "Unsupervised part of speech (POS) tagging", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5796297416090965}]}, {"text": "Grounding generally requires reference labeled data, a luxury a low-resource language might not have.", "labels": [], "entities": []}, {"text": "In this work, we describe an approach for low-resource unsupervised POS tagging that yields fully grounded output and requires no labeled training data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.8393727540969849}]}, {"text": "We find the classic method of Brown et al.", "labels": [], "entities": []}, {"text": "(1992) clusters well in our use case and employ a decipherment-based approach to grounding.", "labels": [], "entities": []}, {"text": "This approach presumes a sequence of cluster IDs is a 'ciphertext' and seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence.", "labels": [], "entities": []}, {"text": "We show intrinsically that, despite the difficulty of the task, we obtain reasonable performance across a variety of languages.", "labels": [], "entities": []}, {"text": "We also show extrinsically that incorporating our POS tagger into a name tagger leads to state-of-the-art tagging performance in Sinhalese and Kinyarwanda, two languages with nearly no labeled POS data available.", "labels": [], "entities": []}, {"text": "We further demonstrate our tagger's utility by incorporating it into a true 'zero-resource' variant of the MALOPA (Ammar et al., 2016) dependency parser model that removes the current reliance on multilingual resources and gold POS tags for new languages.", "labels": [], "entities": [{"text": "MALOPA (Ammar et al., 2016) dependency parser", "start_pos": 107, "end_pos": 152, "type": "TASK", "confidence": 0.6091058641672135}]}, {"text": "Experiments show that including our tagger makes up much of the accuracy lost when gold POS tags are unavailable.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9992675185203552}]}], "introductionContent": [{"text": "While cellular, satellite, and hardware advances have ensured that sophisticated NLP technology can reach all corners of the earth, the language barrier upon reaching remote locales still remains.", "labels": [], "entities": []}, {"text": "As an example, when international aid organizations respond to new disasters, they are often unable to deploy technology to understand local reports detailing specific events ().", "labels": [], "entities": []}, {"text": "An inability to communicate: Overview of our approach to grounded POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8664827942848206}]}, {"text": "We use an unsupervised clustering method (Section 3.2) then reduce and ground the clusters using a decipherment approach informed by POS tag sequence data from many languages (Section 3.3). with partner governments or civilian populations in a timely manner leads to preventable casualties.", "labels": [], "entities": []}, {"text": "The lack of adequate labeled training data has been the major obstacle to expanding NLP's outreach more multilingually.", "labels": [], "entities": []}, {"text": "Developments in unsupervised techniques that require only monolingual corpora ( and the ability to leverage labeled resources in other languages have been proposed to address this issue (.", "labels": [], "entities": []}, {"text": "Unfortunately, these methods either do notwork in practice on true lowresource cases or unrealistically assume the availability of some amount of supervision.", "labels": [], "entities": []}, {"text": "Consider syntactic parsing as a prime example.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7762039303779602}]}, {"text": "Past editions of the CoNLL Shared Task on Multilingual Parsing () featured a category of target languages for which either little or no training data was provided.", "labels": [], "entities": [{"text": "CoNLL Shared Task on Multilingual Parsing", "start_pos": 21, "end_pos": 62, "type": "TASK", "confidence": 0.6613955895105997}]}, {"text": "However, even in the 'no-resource' scenario that most closely matches our use case, gold part-of-speech (POS) tags for test data were provided for the participants to use.", "labels": [], "entities": []}, {"text": "Prior to these shared tasks, proposed a variant of their main model, MALOPA, that was meant to produce reasonable parses for languages under \"zeroresource\" conditions.", "labels": [], "entities": [{"text": "MALOPA", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.6936537623405457}]}, {"text": "In order to function, however, the model requires users to provide gold POS tags and word mappings from these languages into a common semantic space, using approaches that require parallel data (.", "labels": [], "entities": []}, {"text": "Indeed, the compulsion to use POS tag-labeled data in zero-resource circumstances extends to the vast, varied lines of research in unsupervised POS tagging itself!", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 144, "end_pos": 155, "type": "TASK", "confidence": 0.827481746673584}]}, {"text": "Every approach explored so far ultimately requires POS-annotated resources for the language being studied in order to produce a final, grounded output.", "labels": [], "entities": []}, {"text": "Even the most conservative strategies () that do not require any supervised signal during training still ultimately produce only ungrounded clusters, and require a reference annotated corpus to map the inferred clusters or states to actual POS tags.", "labels": [], "entities": []}, {"text": "Making matters worse, evaluation is generally offered in terms of the 'many-to-one.", "labels": [], "entities": []}, {"text": "These metrics use a reference corpus to determine the optimal mapping of clusters to tags.", "labels": [], "entities": []}, {"text": "While this evaluation approach is intuitively sensible for measuring cluster purity, to actually use such an output, an entire annotated training corpus is required.", "labels": [], "entities": []}, {"text": "1 It is not enough to simply rely on ungrounded clusters in real-world systems; grounded labels offer a sort of universal API between other resources such as rule-based modules that operate on certain word types or between resources built from other annotated high-resource language data.", "labels": [], "entities": []}, {"text": "Since POS tag and parallel data resources for 1 Additionally, Headden demonstrated that these metrics are not indicative of downstream performance.", "labels": [], "entities": []}, {"text": "new languages are often unavailable or unreliable, we make the following contributions to ensure the surprise of anew language does not immobilize us: \u2022 We introduce a decipherment-based approach to POS grounding, which yields fully grounded output and does not require any annotated data or parallel corpora in the language to be analyzed.", "labels": [], "entities": [{"text": "POS grounding", "start_pos": 199, "end_pos": 212, "type": "TASK", "confidence": 0.8419377207756042}]}, {"text": "The approach uses preexisting human-labeled POS tag sequences from high-resource parent languages (PL) but no labeled data or sequences for the target, or child language (CL).", "labels": [], "entities": []}, {"text": "An overview of the approach is shown in.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate our approach by evaluating over a variety of languages spanning 4 families and 8 genera (Germanic, Romance, Slavic, Japanese, Semitic, Iranian, Indic, and Bantoid), and show across-the-board reasonable intrinsic performance, given the difficulty of the task and the stringency (straightforward accuracy) in comparison to other unsupervised evaluation strategies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 311, "end_pos": 319, "type": "METRIC", "confidence": 0.9048658013343811}]}, {"text": "\u2022 We test the utility of our grounded tags in a name tagging task, obtaining state-of-the-art performance for Sinhalese and Kiryarwanda, two languages with nearly no labeled POS or named entity resources.", "labels": [], "entities": [{"text": "name tagging task", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.8398161133130392}]}, {"text": "\u2022 We further pare down the annotated resources required in an existing 'zero-resource' dependency parser model and show that our unsupervised and grounded tags are helpful at closing the gap between a nihilistic tag-free setting and an unrealistic gold tag setting.", "labels": [], "entities": []}, {"text": "\u2022 We release our code so that others may create zero-resource syntactic analysis and information extraction systems at the onset of the next new emergency.", "labels": [], "entities": [{"text": "zero-resource syntactic analysis", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.6702710191408793}, {"text": "information extraction", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.7248233705759048}]}], "datasetContent": [{"text": "For intrinsic evaluation and optimization of the tagging pipeline, including all preliminary experiments, we use annotated corpora from Universal Dependencies (UD) v2.2 3 for the following languages: English (en), German (de), French (fr), Italian (it), Spanish (es), Japanese (ja), Czech (cs), Russian (ru), Arabic (ar), and Farsi (fa).", "labels": [], "entities": []}, {"text": "For Swahili (sw), we use the Helsinki Corpus of Swahili 2.0.", "labels": [], "entities": [{"text": "Helsinki Corpus of Swahili 2.0", "start_pos": 29, "end_pos": 59, "type": "DATASET", "confidence": 0.9827283263206482}]}, {"text": "Overall in these experiments we cover 11 languages and 4 language families.", "labels": [], "entities": []}, {"text": "In our dependency parsing experiments, we use the Universal Treebank v2.0 ( ) for en, de, fr, es, it, Portuguese (pt), and Swedish (sv).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.7614450752735138}, {"text": "Universal Treebank v2.0", "start_pos": 50, "end_pos": 73, "type": "DATASET", "confidence": 0.8663145899772644}]}, {"text": "This set of treebanks is chosen instead of UD in order to obtain results comparable to those of previous work on simulated zeroresource parsing scenarios (.", "labels": [], "entities": [{"text": "UD", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.8437472581863403}, {"text": "zeroresource parsing", "start_pos": 123, "end_pos": 143, "type": "TASK", "confidence": 0.6517344117164612}]}, {"text": "In our name tagging experiments, we use monolingual texts for Sinhalese (si) and Kinyarwanda (rw) provided by DARPA's Low Resource Languages for Emergent Incidents (LORELEI) Program during the 2018 Low Resource Human Languages Technologies (LoReHLT) evaluation.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 7, "end_pos": 19, "type": "TASK", "confidence": 0.7734411656856537}]}, {"text": "In the name tagging task, our LSTM-CNN baseline obtains 78.76% and 70.76% F1 score for Kinyarwanda and Sinhalese, respectively.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 7, "end_pos": 19, "type": "TASK", "confidence": 0.8364959061145782}, {"text": "LSTM-CNN baseline", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.6679909527301788}, {"text": "F1 score", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9828816652297974}]}, {"text": "When enriching the input representation with CIPHER-AVG tags, the performance goes up to 80.16% and 71.71% respectively.", "labels": [], "entities": []}, {"text": "These results suggest that the signal provided by the combined cipher grounder is significant enough for relevant tags such as common, proper nouns and noun modifiers.", "labels": [], "entities": []}, {"text": "As an example, consider the sentence Kwizera Peace Ndaruhutse , wari wambaye nomero 11.", "labels": [], "entities": []}, {"text": "The baseline model fails to recognize Kwizera Peace Ndaruhutse as a person name.", "labels": [], "entities": []}, {"text": "In contrast, with the PROPN tag assigned by CIPHER-AVG to Kwizera, Peace, and Ndaruhutse, our model is able to identify this name.", "labels": [], "entities": [{"text": "PROPN", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.8736972212791443}]}, {"text": "Likewise, the utility of CIPHER-AVG tags for dependency parsing under zero-resource scenarios is summarized in.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8346972465515137}]}, {"text": "It is important to point out that, even though the MALOPA setup follows the no-treebank setup of, parsing scores in the first row of differ from those reported by them in).", "labels": [], "entities": [{"text": "MALOPA", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.7444469928741455}, {"text": "parsing", "start_pos": 98, "end_pos": 105, "type": "TASK", "confidence": 0.9465792179107666}]}, {"text": "Such difference is to be expected since the underlying parser used in our experiments is a graph-based neural parser) instead of a transition-based one ( . As mentioned earlier, our objective is to analyze the effect of our tagger's signal on parsing performance under no-resource scenarios, instead of pushing the state-of-the-art for the task.", "labels": [], "entities": []}, {"text": "We first analyze the effect of POS tag information attest time for the MALOPA setup in Table 4.", "labels": [], "entities": [{"text": "POS tag information attest time", "start_pos": 31, "end_pos": 62, "type": "METRIC", "confidence": 0.6976386308670044}]}, {"text": "First we remove all POS signal except trivial punctuation information (NONE row), and, predictably, the scores drop significantly across all target languages.", "labels": [], "entities": [{"text": "NONE row)", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9554106394449869}]}, {"text": "Then, we use our cipher tags (CIPHER row) and see improvements for all languages in LAS and for all but one language in UAS (de).", "labels": [], "entities": [{"text": "CIPHER row", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9194249510765076}, {"text": "UAS", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.9119288325309753}]}, {"text": "This demonstrates the value of our cipher approach.", "labels": [], "entities": []}, {"text": "We then take the next logical step and remove the parallel data-grounded embeddings, replacing them with fully unsupervised MUSE embeddings.", "labels": [], "entities": []}, {"text": "Let us compare MUSE-NONE setup (no POS signal at train or test time) with MUSE-GOLD (gold POS signal at train and test time).", "labels": [], "entities": [{"text": "MUSE-NONE", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.49175646901130676}, {"text": "MUSE-GOLD", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.6254672408103943}]}, {"text": "It can be observed that POS signal improves performance greatly for all languages when using MUSE embeddings.", "labels": [], "entities": []}, {"text": "However, consider GUO-GOLD and MUSE-NONE.", "labels": [], "entities": [{"text": "GUO-GOLD", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9703143239021301}, {"text": "MUSE-NONE", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.8358632922172546}]}, {"text": "Here we note a mixed result: whilst de, sv, and it do benefit from POS information, the other languages do not, obtaining great improvements from MUSE embed-dings instead.", "labels": [], "entities": []}, {"text": "Finally, consider MUSE-CIPHER (gold POS tags during training, cipher tags during testing).", "labels": [], "entities": [{"text": "MUSE-CIPHER", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9341632127761841}]}, {"text": "When compared to MUSE-NONE setup, it can be observed that, unfortunately, the heuristic POS tagger is too noisy and gets in MUSE's way.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 88, "end_pos": 98, "type": "TASK", "confidence": 0.5405929684638977}]}], "tableCaptions": [{"text": " Table 1: Comparison of labeling strategies using many-to-one mapping for target languages with available test  data, using 500 clusters or number of states. Accuracy is shown in percentage points.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9991196990013123}]}, {"text": " Table 2: Performance of cipher grounder using BROWN (|C| = 500) as labeler. The best PL for each CL besides  itself, is shown in bold. The artificial case where we have CL POS data (PL=CL) is shown for comparison, as is  the ultimately used CIPHER-AVG method.", "labels": [], "entities": [{"text": "BROWN", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9863496422767639}]}, {"text": " Table 3: Comparison of performance over the NOUN tag, as measured by precision (P), recall (R), and F1 scores,  between our combined cipher grounder (CIPHER-AVG) and a supervised tagger.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 70, "end_pos": 83, "type": "METRIC", "confidence": 0.9546448439359665}, {"text": "recall (R)", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9540178030729294}, {"text": "F1", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9956164360046387}]}, {"text": " Table 4: Impact of grounded unsupervised POS tagging on MALOPA's 'zero-resource' condition. Bold entries  indicate an improvement over the baseline condition of having no POS tag information (beyond punctuation)", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.726394772529602}, {"text": "MALOPA", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.7546283602714539}]}, {"text": " Table 5: Changing to unsupervised MUSE embeddings boosts MALOPA's zero-resource performance significantly  (bold entries), in many cases doing so even without any POS tag information (italic entries), however noisy  decipherment-based POS tags are no longer helpful.", "labels": [], "entities": []}]}