{"title": [{"text": "Paraphrase Generation for Semi-Supervised Learning in NLU", "labels": [], "entities": [{"text": "Paraphrase Generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8876489996910095}, {"text": "NLU", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8341888189315796}]}], "abstractContent": [{"text": "Semi-supervised learning is an efficient way to improve performance for natural language processing systems.", "labels": [], "entities": []}, {"text": "In this work, we propose Para-SSL, a scheme to generate candidate utterances using paraphrasing and methods from semi-supervised learning.", "labels": [], "entities": []}, {"text": "In order to perform paraphrase generation in the context of a dialog system, we automatically extract paraphrase pairs to create a paraphrase corpus.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.9150965511798859}]}, {"text": "Using this data, we build a paraphrase generation system and perform one-to-many generation, followed by a validation step to select only the utterances with good quality.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7391545474529266}]}, {"text": "The paraphrase-based semi-supervised learning is applied to five functionalities in a natural language understanding system.", "labels": [], "entities": []}, {"text": "Our proposed method for semi-supervised learning using paraphrase generation does not require user utterances and can be applied prior to releasing anew functionality to a system.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7709619402885437}]}, {"text": "Experiments show that we can achieve up to 19% of relative semantic error reduction without an access to user utterances, and up to 35% when leveraging live traffic utterances.", "labels": [], "entities": [{"text": "relative semantic error reduction", "start_pos": 50, "end_pos": 83, "type": "METRIC", "confidence": 0.5917106419801712}]}], "introductionContent": [{"text": "Task-oriented dialog systems are used frequently, either providing mobile support (e.g. Siri, Bixby) or at-home service (e.g. Alexa, Google Home).", "labels": [], "entities": []}, {"text": "Natural language understanding (NLU) technology is one of the components for dialog systems, producing interpretation for an input utterance.", "labels": [], "entities": [{"text": "Natural language understanding (NLU)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7603469242652258}]}, {"text": "Namely, an NLU system takes recognized speech input and produces intents, domains, and slots for the utterance to support the user request).", "labels": [], "entities": []}, {"text": "For example, fora user request \"turn off the lights in living room,\" the NLU system would generate domain Device, intent LightControl, and slot values of \"off\" for OffTrigger and \"living room\" for Location.", "labels": [], "entities": []}, {"text": "In this work, we define functionality as a dialog system's capability given NLU output (e.g., turning off alight, playing a user's playlist).", "labels": [], "entities": []}, {"text": "It is crucial for applications to add support for new functionalities and improve them continuously.", "labels": [], "entities": []}, {"text": "An efficient method for this is semisupervised learning (SSL), where the model learns from both unlabeled as well as labeled data.", "labels": [], "entities": [{"text": "semisupervised learning (SSL)", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.6913893401622773}]}, {"text": "One SSL method for NLU is to find functionalityrelevant user utterances in live traffic and use them to augment the training data.", "labels": [], "entities": []}, {"text": "In this work, we explore an alternative SSL approach \"Para-SSL,\" where we generate functionality-relevant utterances and augment them by applying a conservative validation.", "labels": [], "entities": []}, {"text": "To generate functionality-relevant utterances, we use paraphrasing, a task to generate an alternative surface form to express the same semantic content.", "labels": [], "entities": []}, {"text": "Paraphrasing has been used for many natural language processing (NLP) tasks to additionally generate training data).", "labels": [], "entities": []}, {"text": "We view the generation work as a translation task), where we translate an utterance into its paraphrase that supports the same functionality.", "labels": [], "entities": []}, {"text": "In our task, it is crucial to perform one-tomany generation so that we can obtain a bigger candidate pool for utterance augmentation.", "labels": [], "entities": [{"text": "one-tomany generation", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.748402863740921}, {"text": "utterance augmentation", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.8901053071022034}]}, {"text": "In this work, we use beam search to generate n-best list from paraphrase generation model.", "labels": [], "entities": []}, {"text": "We then apply a validation step for utterances in the generated nbest list and augment the ones that could be successfully validated.", "labels": [], "entities": []}, {"text": "In order to model paraphrases that fit to the style of dialog system, we build a paraphrase corpus for NLU modeling by automatically extracting paraphrases in terms of NLU functionality.", "labels": [], "entities": [{"text": "NLU modeling", "start_pos": 103, "end_pos": 115, "type": "TASK", "confidence": 0.8066796362400055}]}, {"text": "Experiments on five functionalities of our dialog system show that we can achieve up to 35% of relative error reduction by using generated paraphrases for semi-supervised learning.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 95, "end_pos": 119, "type": "METRIC", "confidence": 0.6834874550501505}]}], "datasetContent": [{"text": "We apply paraphrase generation to five functionalities of our spoken dialog system, where each functionality consists of one to two intents (e.g. PlayMusic, PlayVideo, etc.).", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.7335403561592102}]}, {"text": "Five functionalities come from four different domains, as shown in Table 1.", "labels": [], "entities": []}, {"text": "By applying paraphrase generation to various functionalities across multiple domains, we show the applicability of the technique.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7916930317878723}]}, {"text": "shows the number of intents and slots covered by each functionality.", "labels": [], "entities": []}, {"text": "Additionally, the number of new slots introduced by modeling this functionality is shown in parentheses.", "labels": [], "entities": []}, {"text": "Each functionality has a designated test set, which contains 1k to 3k functionality-specific utterances of live traffic data annotated.", "labels": [], "entities": []}, {"text": "shows test set size for each functionality.", "labels": [], "entities": []}, {"text": "In this work, we evaluate the impact of generated paraphrases in terms of the NLU model performance, measured in Semantic Error Rate (SemER) ().", "labels": [], "entities": [{"text": "Semantic Error Rate (SemER)", "start_pos": 113, "end_pos": 140, "type": "METRIC", "confidence": 0.7651307135820389}]}, {"text": "There are three types of slot errors in a hypothesis with respect to reference interpretation: substitution error (S), insertion error (I), and deletion error (D).", "labels": [], "entities": [{"text": "substitution error (S)", "start_pos": 95, "end_pos": 117, "type": "METRIC", "confidence": 0.9476093769073486}, {"text": "insertion error (I)", "start_pos": 119, "end_pos": 138, "type": "METRIC", "confidence": 0.9614388465881347}, {"text": "deletion error (D)", "start_pos": 144, "end_pos": 162, "type": "METRIC", "confidence": 0.9028224229812623}]}, {"text": "We treat intent of NLU interpretation as one of slots using the metric, where an intent error is considered as a substitution.", "labels": [], "entities": [{"text": "intent of NLU interpretation", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.5988596901297569}]}, {"text": "SemER is calculated as follows: where C denotes the number of correct slots/intents.", "labels": [], "entities": [{"text": "SemER", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.7530352473258972}]}, {"text": "Numbers we report in this work are the relative performance in terms of SemER.", "labels": [], "entities": [{"text": "SemER", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9470517039299011}]}], "tableCaptions": [{"text": " Table 1: Five functionalities considered in this work", "labels": [], "entities": []}, {"text": " Table 4: Data statistics on the number of validated utterances in live phase, per annotation increment", "labels": [], "entities": []}]}