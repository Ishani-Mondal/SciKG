{"title": [{"text": "Topic Spotting using Hierarchical Networks with Self Attention", "labels": [], "entities": [{"text": "Topic Spotting", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8984200060367584}]}], "abstractContent": [{"text": "Success of deep learning techniques have renewed the interest in development of dialogue systems.", "labels": [], "entities": []}, {"text": "However, current systems struggle to have consistent long term conversations with the users and fail to build rapport.", "labels": [], "entities": []}, {"text": "Topic spotting , the task of automatically inferring the topic of a conversation, has been shown to be helpful in making a dialog system more engaging and efficient.", "labels": [], "entities": [{"text": "Topic spotting", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8197338283061981}]}, {"text": "We propose a hierarchical model with self attention for topic spotting.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7718086242675781}]}, {"text": "Experiments on the Switchboard corpus show the superior performance of our model over previously proposed techniques for topic spotting and deep models for text classification.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 19, "end_pos": 37, "type": "DATASET", "confidence": 0.8215815126895905}, {"text": "topic spotting", "start_pos": 121, "end_pos": 135, "type": "TASK", "confidence": 0.7924999594688416}, {"text": "text classification", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7923314571380615}]}, {"text": "Additionally, in contrast to offline processing of dialog, we also analyze the performance of our model in a more realistic setting i.e. in an online setting where the topic is identified in real time as the dialog progresses.", "labels": [], "entities": []}, {"text": "Results show that our model is able to generalize even with limited information in the online setting.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, a number of commercial conversation systems have been introduced e.g. Alexa, Google Assistant, Siri, Cortana, etc.", "labels": [], "entities": []}, {"text": "Most of the available systems perform well on goal-oriented conversations which spans over few utterances in a dialogue.", "labels": [], "entities": []}, {"text": "However, with longer conversations (in open domains), existing systems struggle to remain consistent and tend to deviate from the current topic during the conversation.", "labels": [], "entities": []}, {"text": "This hinders the establishment of long term social relationship with the users ().", "labels": [], "entities": []}, {"text": "In order to have coherent and engaging conversations with humans, besides other relevant natural language understanding (NLU) techniques, a system, while responding, should take into account the topic of the current conversation i.e. Topic Spotting.", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 89, "end_pos": 125, "type": "TASK", "confidence": 0.7879525323708853}, {"text": "Topic Spotting", "start_pos": 234, "end_pos": 248, "type": "TASK", "confidence": 0.8313489556312561}]}, {"text": "Topic spotting has been shown to be important in commercial dialog systems) directly dealing with the customers.", "labels": [], "entities": [{"text": "Topic spotting", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.81263467669487}]}, {"text": "Topical information is useful for speech recognition systems) as well as in audio document retrieval systems).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8151660859584808}]}, {"text": "Importance of topic spotting can be gauged from the work of Alexa team (, who have proposed topic based metrics for evaluating the quality of conversational bots.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7973066866397858}, {"text": "Alexa team", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.9220685660839081}]}, {"text": "The authors empirically show that topic based metrics correlate with human judgments.", "labels": [], "entities": []}, {"text": "Given the importance of topical information in a dialog system, this paper proposes self attention based hierarchical model for predicting topics in a dialog.", "labels": [], "entities": []}, {"text": "We evaluate our model on Switchboard (SWBD) corpus and show that our model supersedes previously applied techniques for topic spotting.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 120, "end_pos": 134, "type": "TASK", "confidence": 0.791910856962204}]}, {"text": "We address the evaluative limitations of the current SWBD corpus by creating anew version of the corpus referred as SWBD2.", "labels": [], "entities": [{"text": "SWBD corpus", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.900254100561142}, {"text": "SWBD2", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.9462031126022339}]}, {"text": "We hope that SWBD2 corpus would provide anew standard for evaluating topic spotting models.", "labels": [], "entities": [{"text": "SWBD2 corpus", "start_pos": 13, "end_pos": 25, "type": "DATASET", "confidence": 0.7420224547386169}, {"text": "topic spotting", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7423624992370605}]}, {"text": "We also experiment with an online setting where we examine the performance of our topic classifier as the length of the dialog is varied and show that our model can be used in areal time dialog system as well.", "labels": [], "entities": []}], "datasetContent": [{"text": "As in previous work ( \u00a72), we use Switchboard (SWBD) ( corpus for training our model.", "labels": [], "entities": []}, {"text": "SWBD is a corpus of human-human conversations, created by recording (and later transcribing) telephonic conversations between two participants who were primed with a topic.", "labels": [], "entities": []}, {"text": "Table 1 gives the corpus statistics.", "labels": [], "entities": []}, {"text": "Topics in SWBD range over a variety of domains, for example, politics, health, sports, entertainment, hobbies, etc., making the task of topic spotting challenging.", "labels": [], "entities": [{"text": "SWBD", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.8858005404472351}, {"text": "topic spotting", "start_pos": 136, "end_pos": 150, "type": "TASK", "confidence": 0.7493666112422943}]}, {"text": "Dialogues in the test set of the original SWBD cover a limited number of topics (12 vs 66).", "labels": [], "entities": []}, {"text": "The test set is not ideal for evaluating topic spotting system.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.8105230629444122}]}, {"text": "We address this shortcoming by creating anew split and we refer to this version of the corpus as SWBD2.", "labels": [], "entities": [{"text": "SWBD2", "start_pos": 97, "end_pos": 102, "type": "DATASET", "confidence": 0.9362354874610901}]}, {"text": "The new split provides opportunity for more rigorous evaluation of a topic spotting system.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7458938658237457}]}, {"text": "SWBD2 was created by removing infrequent topics (< 10 dialogues) from the corpus and then randomly moving dialogues between the train/development set and the test set, in order to have instances of each topic in the test set.", "labels": [], "entities": []}, {"text": "The majority class baseline in SWBD2 is around 5%.", "labels": [], "entities": [{"text": "SWBD2", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.7002568244934082}]}, {"text": "In transcribed SWBD corpus some punctuation symbols such as #, ?, have special meanings and non-verbal sounds have been mapped to special symbols e.g. <Laughter>.", "labels": [], "entities": []}, {"text": "To preserve the meanings of special symbols we performed minimal preprocessing.", "labels": [], "entities": []}, {"text": "Dialog Corpora is different from text classification corpora (e.g. product reviews).", "labels": [], "entities": []}, {"text": "If we roughly equate a dialog to a document and an utterance to a sentence, dialogs are very long documents with short sentences.", "labels": [], "entities": []}, {"text": "Moreover, the vocabulary distribution in a dialog corpus is fundamentally different, e.g. presence of back-channel words like 'uhm' and 'ah'.", "labels": [], "entities": []}, {"text": "Model Hyper-parameters: We use GloVe embeddings () with dimensionality of 300.", "labels": [], "entities": []}, {"text": "The embeddings are updated during training.", "labels": [], "entities": []}, {"text": "Each of the LSTM cell in the utterance and dialog encoder uses hidden state of dimension 256.", "labels": [], "entities": []}, {"text": "The weight matrices in the attention network have dimension of 128.", "labels": [], "entities": []}, {"text": "The hyperparameters were found by experimenting with the  development set.", "labels": [], "entities": []}, {"text": "We trained the model by minimizing the cross-entropy loss using Adam optimizer () with an initial learning rate of 0.001.", "labels": [], "entities": []}, {"text": "The learning rate was reduced by half when development set accuracy did not changeover successive epochs.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9803000390529633}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9529158473014832}]}, {"text": "Model took around 30 epochs to train.", "labels": [], "entities": []}, {"text": "We compare the performance of our model) with traditional Bag of Words (BoW), TF-IDF, and n-grams features based classifiers.", "labels": [], "entities": []}, {"text": "We also compare against averaged Skip-Gram (),), CNN, Hierarchical Attention (HN-ATT) () and hierarchical network (HN) models.", "labels": [], "entities": [{"text": "CNN", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.8306766152381897}]}, {"text": "HN it is similar to our model HN-SA but without any self attention.", "labels": [], "entities": [{"text": "HN", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8865260481834412}]}, {"text": "Analysis: As is evident from the experiments on both the versions of SWBD, our model (HN-SA) outperforms traditional feature based topic spotting models and deep learning based document classification models.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.7162399441003799}, {"text": "document classification", "start_pos": 177, "end_pos": 200, "type": "TASK", "confidence": 0.6945877075195312}]}, {"text": "It is interesting to see that simple BoW and n-gram baselines are quite competitive and outperform some of the deep learning based document classification model.", "labels": [], "entities": [{"text": "BoW", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.7942860722541809}, {"text": "document classification", "start_pos": 131, "end_pos": 154, "type": "TASK", "confidence": 0.6589033454656601}]}, {"text": "Similar observation has also been reported by for the task of sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.958783358335495}]}, {"text": "The task of topic spotting is arguably more challenging than document classification.", "labels": [], "entities": [{"text": "topic spotting", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.8239944577217102}, {"text": "document classification", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.7529164552688599}]}, {"text": "In the topic spotting task, the number of output classes (66/42 classes) is much more than those in document classification (5/6 classes), which is done mainly on the texts from customer reviews.", "labels": [], "entities": [{"text": "topic spotting task", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7992934783299764}, {"text": "document classification", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7504799664020538}]}, {"text": "Dialogues in SWBD have on an average 200 utterances and are much longer texts than customer reviews.", "labels": [], "entities": []}, {"text": "Additionally, the number of dialogues available for training the model is significantly lesser than customer reviews.", "labels": [], "entities": []}, {"text": "We further investigated the performance on SWBD2 by examining the confusion matrix of the model.", "labels": [], "entities": [{"text": "confusion matrix", "start_pos": 66, "end_pos": 82, "type": "METRIC", "confidence": 0.9429924786090851}]}, {"text": "shows the heatmap of the normalized confusion matrix of the model on SWBD2.", "labels": [], "entities": [{"text": "SWBD2", "start_pos": 69, "end_pos": 74, "type": "DATASET", "confidence": 0.9248085021972656}]}, {"text": "For most of the classes the classifier is able to predict accurately.", "labels": [], "entities": []}, {"text": "However, the model gets confused between the classes which are semantically close (w.r.t. terms used) to each other, for example, the model gets confused between pragmatically similar topics e.g. HOBBIES vs GARDENING, MOVIES vs TV PROGRAMS, RIGHT TO PRIVACY vs DRUG TESTING.", "labels": [], "entities": []}, {"text": "Online Setting: In an online conversational system, a topic spotting model is required to predict the topic accurately and as soon as possible during the dialog.", "labels": [], "entities": [{"text": "Online Setting", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6831783354282379}, {"text": "topic spotting", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7016175091266632}]}, {"text": "We investigated the relationship between dialog length (in terms of number of utterances) and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9976288676261902}]}, {"text": "This would give us an idea about how many utterances are required to reach a desirable level of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9959625601768494}]}, {"text": "For this experiment, we varied the length of the dialogues from the test set that was available to the model for making prediction.", "labels": [], "entities": []}, {"text": "We created sub-dialogues of length starting with 1/32 of the dialog length and increasing it in multiples of 2, up to the full dialog.", "labels": [], "entities": []}, {"text": "shows both the absolute accuracy and the accuracy relative to that on the full dialog.", "labels": [], "entities": [{"text": "absolute", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9812511205673218}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9218447804450989}, {"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9995303153991699}]}, {"text": "With just a few (3.125%) initial utterances available, the model is already 72% confident about the topic.", "labels": [], "entities": []}, {"text": "This maybe partly due to the fact that in a discussion, the first few utterances explicitly talk about the topic.", "labels": [], "entities": []}, {"text": "However, as we have seen, since SWBD covers many different topics which are semantically close to each other but are assigned distinct classes, it is equally challenging to predict the topic with the same model.", "labels": [], "entities": [{"text": "SWBD", "start_pos": 32, "end_pos": 36, "type": "TASK", "confidence": 0.9215239882469177}]}, {"text": "By the time the system has processed half the dialog in SWBD2 it is already within 99% accuracy of the full system.", "labels": [], "entities": [{"text": "SWBD2", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.8396855592727661}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9978929162025452}]}, {"text": "The experiment shows the possibility of using the model in an online setting where the model predicts the topic with high confidence as the conversation progresses.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics for both versions of SWBD", "labels": [], "entities": [{"text": "SWBD", "start_pos": 49, "end_pos": 53, "type": "TASK", "confidence": 0.48658451437950134}]}, {"text": " Table 2: Accuracy (in %) of our model and other text  classification models on both versions of SWBD.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987435936927795}, {"text": "SWBD", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.8771902322769165}]}]}