{"title": [{"text": "No Permanent Friends or Enemies: Tracking Relationships between Nations from News", "labels": [], "entities": [{"text": "Tracking Relationships between Nations from", "start_pos": 33, "end_pos": 76, "type": "TASK", "confidence": 0.8882814168930053}]}], "abstractContent": [{"text": "Understanding the dynamics of international politics is important yet challenging for civilians.", "labels": [], "entities": []}, {"text": "In this work, we explore unsupervised neural models to infer relations between nations from news articles.", "labels": [], "entities": []}, {"text": "We extend existing models by incorporating shallow linguistics information and propose anew automatic evaluation metric that aligns relationship dynamics with manually annotated key events.", "labels": [], "entities": []}, {"text": "As understanding international relations requires carefully analyzing complex relationships , we conduct in-person human evaluations with three groups of participants.", "labels": [], "entities": [{"text": "understanding international relations", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.6672225197156271}]}, {"text": "Overall , humans prefer the outputs of our model and give insightful feedback that suggests future directions for human-centered models.", "labels": [], "entities": []}, {"text": "Furthermore, our model reveals interesting regional differences in news coverage.", "labels": [], "entities": []}, {"text": "For instance , with respect to US-China relations, Singaporean media focus more on \"strength-ening\" and \"purchasing\", while US media focus more on \"criticizing\" and \"denouncing\".", "labels": [], "entities": []}], "introductionContent": [{"text": "In the context of growing globalization (, understanding complex international relations is increasingly relevant to our daily life.", "labels": [], "entities": []}, {"text": "Yet this is a challenging task due to the inherently dynamic nature of international relations.", "labels": [], "entities": []}, {"text": "As Kissinger famously said, \"America has no permanent friends or enemies, only interests.\"", "labels": [], "entities": []}, {"text": "Staying informed becomes even harder in the continuous streams of information from news outlets and social media.", "labels": [], "entities": []}, {"text": "This very availability of such information, however, opens up exciting opportunities for natural language processing to support individuals in understanding international relations.", "labels": [], "entities": [{"text": "understanding international relations", "start_pos": 143, "end_pos": 180, "type": "TASK", "confidence": 0.7971518834431967}]}, {"text": "Supervised extraction has been incredibly useful at identifying pre-defined relations and events) but fails to capture emerging or complex information needs.", "labels": [], "entities": [{"text": "Supervised extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7445078492164612}]}, {"text": "Topic models and neural models have been proposed to explore relations between entities without supervision).", "labels": [], "entities": []}, {"text": "In particular, introduces an unsupervised neural model for tracking relations between fictional characters, and this approach outperforms baselines from topic models and hidden Markov models.", "labels": [], "entities": []}, {"text": "In this work, we incorporate linguistic insights into this model to track relation dynamics between nations from news articles.", "labels": [], "entities": []}, {"text": "Our model reconstructs textual information in the embedding space using relation embeddings, as proposed in.", "labels": [], "entities": []}, {"text": "We integrate simple yet effective linguistic insights: verbal predicates often describe the relationship between entities, 1 while nouns and proper nouns provide the context of this relationship.", "labels": [], "entities": []}, {"text": "For example, in \"U.S. denounces Russia for its interference in the 2016 election\", denounce describes the relation, and election and interference provide the context.", "labels": [], "entities": []}, {"text": "We show that this intuition leads the model to discover relation descriptors that are easier to interpret and less noisy.", "labels": [], "entities": []}, {"text": "Evaluating these exploratory models for subjective tasks poses a challenge as there are no gold labels.", "labels": [], "entities": []}, {"text": "Along with the model, we propose new approaches for evaluation.", "labels": [], "entities": []}, {"text": "We introduce a quantitative metric which aligns preannotated key events with the temporal trends of relationships produced by the models.", "labels": [], "entities": []}, {"text": "Since this task requires careful analysis of complex international relations, we conduct in-person user studies with NLP researchers and undergraduate students recruited from political science and linguistics courses.", "labels": [], "entities": []}, {"text": "Both quantitative evaluation and human evaluation indicate that our model better rep-resents the dynamic relationships between nations than the prior model: 75.9% of participants preferred our model for finding natural language words describing international relations and 85.5% preferred temporal trends generated by our model.", "labels": [], "entities": [{"text": "rep-resents", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9574570655822754}, {"text": "finding natural language words describing international relations", "start_pos": 203, "end_pos": 268, "type": "TASK", "confidence": 0.7231444716453552}]}, {"text": "Finally, we qualitatively explore the context of relations provided by an attention-based mechanism and demonstrate a practical application of our model by studying regional differences in news coverage of relationships between two countries.", "labels": [], "entities": []}, {"text": "We conclude with discussions on future directions for buildings models that can support individuals in navigating a large collection of news articles.", "labels": [], "entities": []}, {"text": "Our code is available at https:// github.com/BoulderDS/LARN.", "labels": [], "entities": [{"text": "BoulderDS/LARN", "start_pos": 45, "end_pos": 59, "type": "METRIC", "confidence": 0.7249989708264669}]}], "datasetContent": [{"text": "In this section, we compare our model to RMN.", "labels": [], "entities": [{"text": "RMN", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.6916214823722839}]}, {"text": "For both models, we fixed the number of descriptors to 30 following.", "labels": [], "entities": []}, {"text": "As tracking dynamic international relations requires careful analysis, we hosted onsite user studies for quality control and in-person feedback.", "labels": [], "entities": []}, {"text": "We first describe the model outputs, and then present both quantitative and qualitative evaluation results.", "labels": [], "entities": []}, {"text": "We leverage our manually annotated key events to develop a novel automatic metric to evaluate how well the temporal trends from our model are aligned with key events.", "labels": [], "entities": []}, {"text": "We define a change rate at each month \u2206 t as the weighted average of changes in relation weights in the top three relations: where d t,i is the average weight for the i-th relation in all the articles published at t, d tprev,i is the average weight before tin a window of W preceding months ( 1 WW w=1 d (t\u2212w),i ), and weight w t,i is the normalized weight for top three descriptors ( ).", "labels": [], "entities": []}, {"text": "Our results are robust to the choices of W , and we set it to 6 for presentation.", "labels": [], "entities": []}, {"text": "We expect change rates to be greater when significant events happen in international politics.", "labels": [], "entities": []}, {"text": "compares the change rate at months where key events occurred with other months for eight nation pairs for which we annotated key events.", "labels": [], "entities": [{"text": "change rate", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.9683650135993958}]}, {"text": "Both models present more abrupt changes when key events occurred.", "labels": [], "entities": []}, {"text": "Unlike RMN, our model does not have temporal dependencies between relation distributions overtime, and thus has a higher discontinuity in general.", "labels": [], "entities": []}, {"text": "However, even in relative terms, our model fluctuated more substantially than RMN when key events occurred.", "labels": [], "entities": [{"text": "RMN", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.8321143388748169}]}, {"text": "We also did a robustness check with another set of independently annotated key events and the results can be found in the appendix.", "labels": [], "entities": []}, {"text": "This measure captures whether the model can detect the change points, but does not measure whether the model correctly captures the semantics of the key events, i.e., did a negative relation increase after hostile events such as war?", "labels": [], "entities": []}, {"text": "To this end, we performed human evaluations.", "labels": [], "entities": []}, {"text": "We hosted three human evaluations with participants from different demographics: undergraduate students from political science classes, graduate students from a computer science department (mostly in NLP), and undergraduate students taking a linguistics class.", "labels": [], "entities": []}, {"text": "The total number of participants was 29, roughly equally divided among the three groups.", "labels": [], "entities": []}, {"text": "The participants were shown outputs from RMN and LARN, and asked to choose the output that better aligns with their intuitions.", "labels": [], "entities": []}, {"text": "Each participant answered about 10 questions and provided justification for their answers to each question, taking roughly 30 minutes to an hour.", "labels": [], "entities": []}, {"text": "summarizes the results of our human evaluations.", "labels": [], "entities": []}, {"text": "The participants were shown a list of top five descriptors (as in) from two models, and prompted to select a set which adequately covers possible relationships that can occur between countries.", "labels": [], "entities": []}, {"text": "75.9% of participants preferred our model.", "labels": [], "entities": []}, {"text": "We showed temporal trends between nation pairs annotated with key events, one from RMN and the other from LARN (as in).", "labels": [], "entities": [{"text": "RMN", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.8654218316078186}, {"text": "LARN", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.6003609299659729}]}, {"text": "We asked them to evaluate whether the temporal trends accurately reflect the dynamics in nation-to-nation relationships.", "labels": [], "entities": []}, {"text": "Each participant evaluated four randomly chosen nation pairs.", "labels": [], "entities": []}, {"text": "The temporal trend from our model was preferred more frequently (85.5% of total responses).", "labels": [], "entities": []}, {"text": "We designed a novel task where we showed the participants the other four temporal trends without annotated key events and asked them to match each trend with the corresponding nation pair from the four candidates, based on their world knowledge about nationnation relations.", "labels": [], "entities": []}, {"text": "Each participant did the matching twice, once for RMN and once for LARN.", "labels": [], "entities": [{"text": "RMN", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.694496214389801}, {"text": "LARN", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.8027780055999756}]}, {"text": "The participants found correct temporal trends for 45.2% of entity pairs for RMN, and 38.0% of entity pairs for LARN, when random pairing would yield 25.0%.", "labels": [], "entities": []}, {"text": "The difference between two models here is not statistically significant.", "labels": [], "entities": []}, {"text": "Most participants found this task very challenging, as they did not know much about the relationship between certain entity pairs (e.g., a participant said \"As an American, there's noway to know the relation between China and India.\").", "labels": [], "entities": []}, {"text": "Even political science students do not perform better than the other two groups.", "labels": [], "entities": [{"text": "political science", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.8690047860145569}]}, {"text": "Overall the output from our model is preferred by the participants.", "labels": [], "entities": []}, {"text": "We found that political science students paid more attention to detail, took a longer time to finish, and were more ambivalent between the performance of the two models.", "labels": [], "entities": []}, {"text": "For example, for temporal trends, they preferred our model for 71.4% of the examples, compared to other groups which preferred our model for 90% of the examples.", "labels": [], "entities": []}, {"text": "They also preferred RMN's relation descriptors slightly (42.9% selected our model) and commented that a few concepts from RMN, like \"infrastructure, supply, and value\", are more concrete (e.g., a participant said \"I chose the left one (RMN), because it is easy to determine and remember the positive of items such as infrastructure, value, and supply.", "labels": [], "entities": [{"text": "remember", "start_pos": 278, "end_pos": 286, "type": "METRIC", "confidence": 0.9452829360961914}]}, {"text": "Those have more positive undertones, while it is easy to gauge negative sentiments with 'terrorism,' 'condemn' and those.\").", "labels": [], "entities": []}, {"text": "As LARN encodes the background context specific to each nation pair separately, our relation descriptors do not contain such \"concrete\" concepts.", "labels": [], "entities": []}, {"text": "In the next section, we will discuss contexts for relations, where these concepts appear in LARN.", "labels": [], "entities": [{"text": "LARN", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.8305644392967224}]}], "tableCaptions": [{"text": " Table 3: Human evaluation results: The first two rows  represents the number of votes, while the last row rep- resents % of nation pairs matched correctly with its  temporal trend. We did a two-tail binomial test for the  relation descriptor and temporal trend evaluation and  an independent t-test for the nation pair matching eval- uation. We show the p-values in the last column.", "labels": [], "entities": []}]}