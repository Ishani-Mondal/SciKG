{"title": [{"text": "Adversarial Training for Weakly Supervised Event Detection", "labels": [], "entities": [{"text": "Weakly Supervised Event Detection", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.7188236266374588}]}], "abstractContent": [{"text": "Modern weakly supervised methods for event detection (ED) avoid time-consuming human annotation and achieve promising results by learning from auto-labeled data.", "labels": [], "entities": [{"text": "event detection (ED)", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.8755170822143554}]}, {"text": "However, these methods typically rely on sophisticated pre-defined rules as well as existing instances in knowledge bases for automatic annotation and thus suffer from low coverage, topic bias, and data noise.", "labels": [], "entities": []}, {"text": "To address these issues, we build a large event-related candidate set with good coverage and then apply an adversar-ial training mechanism to iteratively identify those informative instances from the candidate set and filter out those noisy ones.", "labels": [], "entities": []}, {"text": "The experiments on two real-world datasets show that our candidate selection and adversarial training can cooperate together to obtain more diverse and accurate training data for ED, and significantly outperform the state-of-the-art methods in various weakly supervised scenarios.", "labels": [], "entities": [{"text": "ED", "start_pos": 179, "end_pos": 181, "type": "TASK", "confidence": 0.9753196239471436}]}, {"text": "The datasets and source code can be obtained from https://github.com/ thunlp/Adv-ED.", "labels": [], "entities": []}], "introductionContent": [{"text": "Event detection (ED) aims at detecting event triggers, which are often words or phrases evoking events in instances, and then identifying their specific event types.", "labels": [], "entities": [{"text": "Event detection (ED)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8466547966003418}]}, {"text": "For example, we can extract the trigger \"married\" of the event \"Marry\" from the text \"Mark Twain and Olivia Langdon married in 1870\".", "labels": [], "entities": []}, {"text": "Detecting and identifying events is an important subtask of event extraction and also beneficial for various downstream NLP applications, such as question answering (, information retrieval (, and reading comprehension.", "labels": [], "entities": [{"text": "Detecting and identifying events", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.764092244207859}, {"text": "event extraction", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.729141429066658}, {"text": "question answering", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.9044787883758545}, {"text": "information retrieval", "start_pos": 168, "end_pos": 189, "type": "TASK", "confidence": 0.8110297322273254}]}, {"text": "Hence, many efforts have been devoted to detecting event triggers and types.", "labels": [], "entities": [{"text": "detecting event triggers and types", "start_pos": 41, "end_pos": 75, "type": "TASK", "confidence": 0.8383056879043579}]}, {"text": "* indicates equal contribution \u2020 Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) Most prior methods for ED are based on feature engineering, such as the token-level features and the structured features (.", "labels": [], "entities": [{"text": "ED", "start_pos": 107, "end_pos": 109, "type": "TASK", "confidence": 0.9491035342216492}]}, {"text": "As the rapid development of neural networks, various neural models have been proposed to directly embed textual semantic information into a low-dimensional space and then detect event triggers based on those feature vectors.", "labels": [], "entities": []}, {"text": "These methods follow a supervised learning approach to train models on human-annotated data, and their requirement of human-annotated data is a bottleneck in practice.", "labels": [], "entities": []}, {"text": "Considering weak supervision is widely adopted to take full advantages of large-scale raw data, especially some specific work for information extraction, weak supervision has been explored to automatically label training data for ED.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.837326854467392}, {"text": "ED", "start_pos": 230, "end_pos": 232, "type": "TASK", "confidence": 0.9168282151222229}]}, {"text": "Compared with those supervised ED methods, the weakly supervised methods can be generalized to real-world ED applications efficiently without intensive labor.", "labels": [], "entities": []}, {"text": "Although promising results have been achieved by these weakly supervised methods, there are still some severe problems for these weakly supervised ED models: (1) Weakly supervised methods naturally suffer from the inevitable noise in data.", "labels": [], "entities": []}, {"text": "(2) Current weakly supervised ED models adopt sophisticated pre-defined rules and incomplete knowledge bases to automatically obtain data, which results in the auto-labeled data with low coverage and topic bias.", "labels": [], "entities": []}, {"text": "In order to construct a large-scale dataset with better coverage and reduce topic bias, we avoid adopting sophisticated pre-defined rules and heavy toolkits for semantic component analysis.", "labels": [], "entities": [{"text": "semantic component analysis", "start_pos": 161, "end_pos": 188, "type": "TASK", "confidence": 0.6576116681098938}]}, {"text": "Instead,: The overall architecture of adversarial training method for ED.", "labels": [], "entities": [{"text": "ED", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9537090063095093}]}, {"text": "The event type is Contact.", "labels": [], "entities": []}, {"text": "we propose a simple trigger-based latent instance discovery strategy, by applying an assumption that if a given word 1 serves as the trigger in a known event instance, all instances mentioning this word may also express an event.", "labels": [], "entities": [{"text": "trigger-based latent instance discovery", "start_pos": 20, "end_pos": 59, "type": "TASK", "confidence": 0.6547890082001686}]}, {"text": "As compared with the sophisticated rules, this strategy is less restrictive in the correlation among words, triggers and event types.", "labels": [], "entities": []}, {"text": "Hence, our strategy can obtain a candidate set covering more topics and instances without any manual design.", "labels": [], "entities": []}, {"text": "We further propose an adversarial training mechanism like;, which cannot only distill those informative instances from the candidate set but also improve the performance of ED model on a noisy scenario such as distant supervision.", "labels": [], "entities": []}, {"text": "As shown in, we split the dataset into a reliable set and an unreliable set respectively, and design a discriminator and a generator.", "labels": [], "entities": []}, {"text": "The discriminator is applied to judge whether a given instance is informative and annotated correctly, and the generator is used to select the most confusing instances from raw data to fool the discriminator.", "labels": [], "entities": []}, {"text": "The discriminator is trained with the reliable data as positive instances and the data selected by the generator as negative ones.", "labels": [], "entities": []}, {"text": "Meanwhile, the generator is trained to select data to fool the discriminator.", "labels": [], "entities": []}, {"text": "During the training process, the generator can provide large amounts of latent noisy data to enhance the discriminator, and the discriminator can influence the generator to select those more informative data.", "labels": [], "entities": []}, {"text": "Since noisy data makes no effect on optimizing both the generator and the discriminator, We treat phrases as words in this paper.", "labels": [], "entities": []}, {"text": "when the generator and the discriminator reach a balance, the discriminator can boost resistance to noise and better categorize events, and the generator can effectively select informative instances to the discriminator.", "labels": [], "entities": []}, {"text": "We conduct experiments on both semisupervised and distantly supervised scenarios.", "labels": [], "entities": []}, {"text": "The experimental results demonstrate that our trigger-based latent instance discovery strategy and adversarial training method can cooperate to obtain more diverse and accurate training data as well as reduce the side effect of the noise problem, and thus significantly outperform the state-of-the-art ED models.", "labels": [], "entities": [{"text": "trigger-based latent instance discovery", "start_pos": 46, "end_pos": 85, "type": "TASK", "confidence": 0.6209350824356079}]}], "datasetContent": [{"text": "We evaluate our models on both semi-supervised and distantly supervised scenarios.", "labels": [], "entities": []}, {"text": "Before introducing the detailed experimental settings and results, we list the hyperparameters first.", "labels": [], "entities": []}, {"text": "For semi-supervised scenarios, we conduct experiments on a widely-used benchmark dataset) containing 599 documents annotated with 8 types and 33 subtypes of events.", "labels": [], "entities": []}, {"text": "Following the previous work, we use the same test set containing 40 newswire documents, development set with 30 randomly selected documents and training set with the remaining 529 documents.", "labels": [], "entities": []}, {"text": "As described in Section 3.4, using existing triggers in ACE-2005 training set as heuristic seeds and our trigger-based latent instance discovery strategy, we construct a large-scale candidate set from the New York Times corpus and use our adversarial training strategy to filter out the noisy instances to build anew ACEstyle dataset.", "labels": [], "entities": [{"text": "ACE-2005 training set", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.9175668756167094}, {"text": "trigger-based latent instance discovery", "start_pos": 105, "end_pos": 144, "type": "TASK", "confidence": 0.6426597833633423}, {"text": "New York Times corpus", "start_pos": 205, "end_pos": 226, "type": "DATASET", "confidence": 0.7176614180207253}, {"text": "ACEstyle dataset", "start_pos": 317, "end_pos": 333, "type": "DATASET", "confidence": 0.9302559792995453}]}, {"text": "We extend the ACE-2005 training set with the new dataset, and then test the models trained on the extended training set on the orig-inal test set.", "labels": [], "entities": [{"text": "ACE-2005 training set", "start_pos": 14, "end_pos": 35, "type": "DATASET", "confidence": 0.9517696499824524}]}, {"text": "Our models trained on the original training set are named DMCNN and DM-BERT, and our bootstrapped models trained on the extended dataset are named DMCNN+Boot and DMBERT+Boot.", "labels": [], "entities": [{"text": "DMBERT+Boot", "start_pos": 162, "end_pos": 173, "type": "DATASET", "confidence": 0.7639296452204386}]}, {"text": "We compare our bootstrapped models with various state-of-the-art methods on the ACE-2005 dataset, including: (1) The feature-based models.", "labels": [], "entities": [{"text": "ACE-2005 dataset", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.9856270551681519}]}, {"text": "We select Li's joint ( as the representative, which achieves the best performance among feature-based models.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "From the results, we have the following observations: (1) As compared with the basic DMCNN and DM-BERT, the bootstrapped models achieve significant improvement (+1.7% and +0.5%).", "labels": [], "entities": [{"text": "DMCNN", "start_pos": 85, "end_pos": 90, "type": "DATASET", "confidence": 0.9050837159156799}, {"text": "DM-BERT", "start_pos": 95, "end_pos": 102, "type": "DATASET", "confidence": 0.8251187801361084}]}, {"text": "Furthermore, our DMCNN+Boot model achieves similar performance with the ANN-FN and DLRNN which design complex architectures to utilize the additional information.", "labels": [], "entities": []}, {"text": "These results indicate that our methods can construct high-quality dataset without sophisticated rules and large-scale knowledge bases, and can effectively collect diverse instances which will benefit training models.", "labels": [], "entities": []}, {"text": "DMBERT and DMBERT+Boot achieve the best performance among all the models.", "labels": [], "entities": [{"text": "DMBERT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8579854965209961}, {"text": "DMBERT+Boot", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.6758726437886556}]}, {"text": "This is benefiting from the effective architecture and the largescale pre-training information of BERT, as well as the dynamic multi-pooling mechanism for ED.", "labels": [], "entities": [{"text": "BERT", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.903205931186676}]}, {"text": "Our methods augment the training data to further enhance BERT, which achieve better performance and demonstrate the effectiveness of our models.", "labels": [], "entities": [{"text": "BERT", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9899752736091614}]}, {"text": "To perform a fine-grained evaluation for the quality of the dataset constructed with our triggerbased instance discovery strategy and adversarial training strategy, we manually evaluate the precision of the constructed dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 190, "end_pos": 199, "type": "METRIC", "confidence": 0.9982929825782776}]}, {"text": "To be specific, we randomly select 150 instances from the newly constructed dataset and recruit four well-trained annotators to annotate the instances independently.", "labels": [], "entities": []}, {"text": "We ask the annotators to label an instance as correct if and only if the trigger and event-type are both correct.", "labels": [], "entities": []}, {"text": "We use the Fleiss' kappa to measure the annotation consistency among these annotators.", "labels": [], "entities": []}, {"text": "The results of the data distilled in different iterations during adversarial training are shown in.", "labels": [], "entities": []}, {"text": "From the results, we can observe that the precision of the dataset constructed with our models is comparable to existing distant supervision methods () using sophisticated human-designed rules and knowledge bases, and even outperforms them in the first iteration.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9990513920783997}]}, {"text": "It indicates that our models can distill informative instances with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9924726486206055}]}], "tableCaptions": [{"text": " Table 2: The AUC results (%) of various models.", "labels": [], "entities": [{"text": "AUC", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.6297817826271057}]}, {"text": " Table 3: The overall performance (%) of different mod- els on ACE-2005.", "labels": [], "entities": [{"text": "ACE-2005", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9290695786476135}]}, {"text": " Table 4: The human evaluation results (%) of auto- labeled data in different iterations.", "labels": [], "entities": []}]}