{"title": [{"text": "Learning Unsupervised Multilingual Word Embeddings with Incremental Multilingual Hubs", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent research has discovered that a shared bilingual word embedding space can be induced by projecting monolingual word embedding spaces from two languages using a self-learning paradigm without any bilingual supervision.", "labels": [], "entities": []}, {"text": "However, it has also been shown that for distant language pairs such fully unsuper-vised self-learning methods are unstable and often get stuck in poor local optima due to reduced isomorphism between starting monolin-gual spaces.", "labels": [], "entities": []}, {"text": "In this work, we propose anew robust framework for learning unsupervised multilingual word embeddings that mitigates the instability issues.", "labels": [], "entities": []}, {"text": "We learn a shared multilingual embedding space fora variable number of languages by incrementally adding new languages one by one to the current multilingual space.", "labels": [], "entities": []}, {"text": "Through the gradual language addition our method can leverage the interdependencies between the new language and all other languages in the current multilingual hub/space.", "labels": [], "entities": []}, {"text": "We find that it is beneficial to project more distant languages later in the iterative process.", "labels": [], "entities": []}, {"text": "Our fully unsupervised multilingual embedding spaces yield results that are on par with the state-of-the-art methods in the bilingual lexicon induction (BLI) task, and simultaneously obtain state-of-the-art scores on two downstream tasks: multilingual document classification and multilingual dependency parsing , outperforming even supervised baselines.", "labels": [], "entities": [{"text": "bilingual lexicon induction (BLI) task", "start_pos": 124, "end_pos": 162, "type": "TASK", "confidence": 0.7422203762190682}, {"text": "multilingual document classification", "start_pos": 239, "end_pos": 275, "type": "TASK", "confidence": 0.6395407617092133}, {"text": "multilingual dependency parsing", "start_pos": 280, "end_pos": 311, "type": "TASK", "confidence": 0.6606630881627401}]}, {"text": "This finding also accentuates the need to establish evaluation protocols for cross-lingual word embeddings beyond the omnipresent intrinsic BLI task in future work.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ubiquitous use and success of word embeddings in monolingual tasks inspired further research on inducing cross-lingual word embeddings for two or more languages in the same vector space.", "labels": [], "entities": []}, {"text": "Embeddings of translations and words with similar meaning are geometrically close in the shared cross-lingual vector space.", "labels": [], "entities": []}, {"text": "This property makes them effective features for cross-lingual NLP tasks such as cross-lingual document classification), cross-lingual information retrieval, bilingual lexicon induction (, and (unsupervised) machine translation ().", "labels": [], "entities": [{"text": "cross-lingual document classification", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.6806464393933614}, {"text": "cross-lingual information retrieval", "start_pos": 120, "end_pos": 155, "type": "TASK", "confidence": 0.7094550331433614}, {"text": "bilingual lexicon induction", "start_pos": 157, "end_pos": 184, "type": "TASK", "confidence": 0.6876466472943624}, {"text": "machine translation", "start_pos": 207, "end_pos": 226, "type": "TASK", "confidence": 0.7549902498722076}]}, {"text": "Most prior work has focused on methods for constructing bilingual word embeddings (BWEs), yielding word representations for exactly two languages.", "labels": [], "entities": []}, {"text": "For problems such as multilingual document classification, however, it is highly-desirable to represent words in a multilingual space.", "labels": [], "entities": [{"text": "multilingual document classification", "start_pos": 21, "end_pos": 57, "type": "TASK", "confidence": 0.6499393979708353}]}, {"text": "A favourable property is that it enables fitting a single classifier on the union of training datasets in many languages, which results in 1) knowledge transfer across languages that may lead to better classification performance, and 2) a setup that is easier to maintain as it is no longer required to train many different monolingual or bilingual classifiers.", "labels": [], "entities": []}, {"text": "Multilingual word embedding (MWE) methods typically generalize existing BWE methods by mapping multiple source language spaces to the space of one target language (, which is used as a pivot/hub language.", "labels": [], "entities": [{"text": "Multilingual word embedding (MWE)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.745915412902832}]}, {"text": "This approach may lead to suboptimal solutions as it does not account for interdependencies between the source languages.", "labels": [], "entities": []}, {"text": "Most BWE and MWE methods rely on cross-lingual supervision to some extent: e.g., bilingual lexicons (), parallel corpora (, or subjectaligned document pairs.", "labels": [], "entities": []}, {"text": "In such paradigms, modeling dependencies between all languages is impractical as it requires supervision for all language pair combinations.", "labels": [], "entities": []}, {"text": "Recent research has shown that BWEs can also be learned without cross-lingual supervision and can even outperform supervised BWE variants on bilingual lexicon induction benchmarks).", "labels": [], "entities": []}, {"text": "took a first step towards learning multilingual spaces without supervision while incorporating dependencies between all languages but their approach extends the work of, which has known limitations concerning optimization stability with distant language pairs (.", "labels": [], "entities": []}, {"text": "In this work, we investigate robust methods to induce MWEs without any cross-lingual supervision.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 54, "end_pos": 58, "type": "TASK", "confidence": 0.9232357740402222}]}, {"text": "The robustness of our approach is illustrated in good performance for distant languages such as Finnish and Bulgarian.", "labels": [], "entities": []}, {"text": "This paper makes the following contributions.", "labels": [], "entities": []}, {"text": "First, based on a reformulation of the BWE method of, we propose two novel methods for inducing MWEs: 1) the single hub space model (SHS) uses the classical idea of mapping source languages to a single hub language; 2) the incremental hub space model (IHS) incorporates dependencies between all languages by incrementally expanding the multilingual space by one language in each step.", "labels": [], "entities": []}, {"text": "IHS results in mappings that are more robust and coherent across languages.", "labels": [], "entities": [{"text": "IHS", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6714457273483276}]}, {"text": "Both SHS and IHS only require monolingual data.", "labels": [], "entities": [{"text": "IHS", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.8616217374801636}]}, {"text": "Second, we evaluate our method on benchmarks for bilingual lexicon induction (BLI), multilingual document classification, and dependency parsing.", "labels": [], "entities": [{"text": "bilingual lexicon induction (BLI)", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.7609401047229767}, {"text": "multilingual document classification", "start_pos": 84, "end_pos": 120, "type": "TASK", "confidence": 0.6527330279350281}, {"text": "dependency parsing", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.8661230206489563}]}, {"text": "We find that the IHS method is competitive with state-of-the-art BWE methods on the bilingual lexicon induction benchmarks, while yielding the highest scores on the multilingual document classification and dependency parsing benchmarks.", "labels": [], "entities": [{"text": "multilingual document classification", "start_pos": 165, "end_pos": 201, "type": "TASK", "confidence": 0.6254956126213074}, {"text": "dependency parsing", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.7407884001731873}]}, {"text": "Third, unlike the majority of prior work, inter alia), we do not limit our evaluation to the intrinsic BLI task only.", "labels": [], "entities": [{"text": "BLI", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.8177922368049622}]}, {"text": "Consequently, we investigate if embedding reweighting, a recently proposed best practice for BWEs, is useful for extrinsic tasks such as document classification and dependency parsing in multilingual settings.", "labels": [], "entities": [{"text": "document classification", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.7703504860401154}, {"text": "dependency parsing", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.8136661052703857}]}], "datasetContent": [{"text": "The induced embeddings are evaluated in three tasks: bilingual lexicon induction (BLI), multilingual dependency parsing, and multilingual document classification.", "labels": [], "entities": [{"text": "bilingual lexicon induction (BLI)", "start_pos": 53, "end_pos": 86, "type": "TASK", "confidence": 0.6986879408359528}, {"text": "multilingual dependency parsing", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.6106947163740793}, {"text": "multilingual document classification", "start_pos": 125, "end_pos": 161, "type": "TASK", "confidence": 0.6444735527038574}]}, {"text": "BLI is currently the most widely used method to evaluate bilingual embedding spaces.", "labels": [], "entities": [{"text": "BLI", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8935863375663757}]}, {"text": "Although BLI performance is not the primary goal of our multilingual embedding spaces, it provides a fast means to address the following questions: 1) Is the incremental construction of multilingual embedding spaces indeed an effective regularization method?", "labels": [], "entities": [{"text": "BLI", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.7761124968528748}]}, {"text": "Is it still necessary to perform value dropping in this case?", "labels": [], "entities": [{"text": "value dropping", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.8785283863544464}]}, {"text": "; 2) Is the reweighting of embedding spaces also beneficial for BLI in multilingual settings?; 3) Does multilingual training improve bilingual lexicon induction performance?", "labels": [], "entities": [{"text": "bilingual lexicon induction", "start_pos": 133, "end_pos": 160, "type": "TASK", "confidence": 0.6034502784411112}]}, {"text": "How do our multilingual models compare to each other and to the state-of-the-art unsupervised BLI methods?", "labels": [], "entities": []}, {"text": "We report Precision@1 (P@1) BLI performance on two standard BLI datasets.", "labels": [], "entities": [{"text": "Precision@1 (P@1) BLI", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8810012075636122}, {"text": "BLI datasets", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.7590793967247009}]}, {"text": "1) DIN-UARTETXE is the extended version of, the monolingual WMT Common Crawl corpus for Finnish, and the WMT News Crawl for Spanish ().", "labels": [], "entities": [{"text": "WMT Common Crawl corpus", "start_pos": 60, "end_pos": 83, "type": "DATASET", "confidence": 0.8600307703018188}, {"text": "WMT News Crawl", "start_pos": 105, "end_pos": 119, "type": "DATASET", "confidence": 0.9130322337150574}]}, {"text": "The test dictionary sizes are between 1.869 and 1,993 word pairs for each language pair.", "labels": [], "entities": []}, {"text": "As our methods are unsupervised, we do not use the provided training dictionaries.", "labels": [], "entities": []}, {"text": "2) EURMUSEWIKI is the dataset compiled from dictionaries for all combinations of the following European languages: English, German, Spanish, French, Italian, and Portuguese.", "labels": [], "entities": [{"text": "EURMUSEWIKI", "start_pos": 3, "end_pos": 14, "type": "DATASET", "confidence": 0.8059104084968567}]}, {"text": "The test set sizes range between 1,513 and 3,660 word pairs.", "labels": [], "entities": []}, {"text": "We rely on publicly available monolingual fastText embeddings (.", "labels": [], "entities": []}, {"text": "All monolingual word embeddings are 300-dimensional and represent the 200k most frequent words as in prior work (.", "labels": [], "entities": []}, {"text": "Multilingual dependency parsing and multilingual document classification tasks assess the embeddings w.r.t. their actual goal: enabling transfer learning across multiple languages.", "labels": [], "entities": [{"text": "Multilingual dependency parsing", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7536841432253519}, {"text": "multilingual document classification", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.6120661298433939}]}, {"text": "The word embeddings are used as feature vectors for classifiers in the respective downstream tasks.", "labels": [], "entities": []}, {"text": "We address the following research questions: 4) Is reweighting of embedding spaces also beneficial in downstream tasks?; 5) How do our methods compare against Value dropping significantly slows down training time and leads to non-deterministic outcomes.", "labels": [], "entities": []}, {"text": "However, it has been shown to be crucial in the bilingual setting to obtain good results when mapping distant language pairs in previous work : the users submit their multilingual embeddings and obtain the final scores, which ensures that the classifiers we use are identical to the ones used in prior work (.", "labels": [], "entities": []}, {"text": "REUTERSMLDC is a multilingual document classification dataset covering seven languages: English, German, French, Italian, Spanish, Danish, and Swedish.", "labels": [], "entities": [{"text": "REUTERSMLDC", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.4330979287624359}]}, {"text": "The final performance is reported as the average accuracy across all languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9982661604881287}]}, {"text": "The respective training and test set consist of 7,000 and 13,058 documents.", "labels": [], "entities": []}, {"text": "The dataset is well balanced in the number of documents per language.", "labels": [], "entities": []}, {"text": "The architecture of the document classifier is the average perceptron used by.", "labels": [], "entities": []}, {"text": "MLPARSING is a multilingual dependency parsing dataset sampled from the Universal Dependencies 1.1 corpus . It contains 12 languages: English, German, French, Spanish, Italian, Bulgarian, Czech, Danish, Swedish, Greek, Finnish, and Hungarian.", "labels": [], "entities": [{"text": "MLPARSING", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8561325669288635}, {"text": "multilingual dependency parsing", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.6402948002020518}, {"text": "Universal Dependencies 1.1 corpus", "start_pos": 72, "end_pos": 105, "type": "DATASET", "confidence": 0.8963818699121475}]}, {"text": "The respective training and test set contain 6,748 and 1,200 sentences.", "labels": [], "entities": []}, {"text": "The test set contains 100 sentences for each language, while for the training set the number of sentences fora language ranges between 98 and 6,694.", "labels": [], "entities": []}, {"text": "The parser used is the stack-LSTM parser by.", "labels": [], "entities": []}, {"text": "The parser is not allowed to use any partof-speech and morphology features, and keeps the input word embeddings fixed to isolate the effect of the evaluated embeddings on the parsing performance (.", "labels": [], "entities": []}, {"text": "The reported scores are UAS scores averaged across languages.", "labels": [], "entities": []}, {"text": "For comparison with related work, we train 512-dimensional monolingual embeddings on the text collections used by and.", "labels": [], "entities": []}, {"text": "The monolingual embeddings are again trained using fastText.", "labels": [], "entities": [{"text": "fastText", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.8748866319656372}]}, {"text": "In all experiments, we set the following hyper-parameters to values that were used in prior research ().", "labels": [], "entities": []}, {"text": "When constructing the seed lexicon the 4,000 most frequent words of each language are considered (C seed = 4, 000), and during the refinement step the 20,000 most frequent words 10 https://github.com/wammar/ multilingual-embeddings-eval-portal As the dataset is not publicly available this information was provided by the first author of of each language are used (C refinement = 20, 000).", "labels": [], "entities": []}, {"text": "When using value dropping, the keep probability p is initialized is 0.1, N patience is set to 50, and the stochastic multiplier is set to 2. Dictionaries are constructed symmetrically: from hub language(s) to the secondary language and from the secondary language to the hub language(s): during refinement each dictionary consists of 2 \u00d7 20, 000 translation pairs.", "labels": [], "entities": [{"text": "keep probability p", "start_pos": 31, "end_pos": 49, "type": "METRIC", "confidence": 0.9512574474016825}, {"text": "N patience", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.7954810857772827}]}, {"text": "We use CSLS with k = 10 nearest neighbors following the setup of.", "labels": [], "entities": []}, {"text": "In this section, we report an additional bilingual lexicon induction experiment that further supports our claim that the IHS model is still applicable when mapping languages with different characteristics, we performed an additional bilingual lexicon induction experiment on the following language pairs: Dutch-Turkish, Spanish-Hungarian, and FinnishBulgarian.", "labels": [], "entities": []}, {"text": "We induced multilingual spaces with the IHS model and the model of Chen and Cardie (2018) using the publicly available monolingual embeddings trained with fastText.", "labels": [], "entities": [{"text": "IHS", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.7996688485145569}]}, {"text": "IHS is run with reweighting (q = 0.5), without value dropping, and with the following language order Dutch, Spanish, Bulgarian, Finnish, Hungarian, Turkish.", "labels": [], "entities": [{"text": "IHS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8907215595245361}, {"text": "reweighting", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.9786070585250854}]}, {"text": "The model of is run with Dutch as the target language and with the recommended hyper-parameters.", "labels": [], "entities": []}, {"text": "For evaluation, we obtained dictionaries for each language pair using Panlex ().", "labels": [], "entities": [{"text": "Panlex", "start_pos": 70, "end_pos": 76, "type": "DATASET", "confidence": 0.9286958575248718}]}, {"text": "The results are reported in.", "labels": [], "entities": []}, {"text": "We find average BLI accuracy scores of 28.24% (IHS) and.", "labels": [], "entities": [{"text": "BLI", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9876168370246887}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9359416365623474}, {"text": "IHS", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.7009927034378052}]}, {"text": "The fact that both models are robust to distant languages without using value dropping further supports our hypothesis that mapping multiple languages simultaneously is an effective regularization mechanism.", "labels": [], "entities": []}, {"text": "In this section, we report all the results of Experiment 3 of the paper.", "labels": [], "entities": []}, {"text": "In we report the results for the SHS model with different hub languages and in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of P@1 scores for SHS and IHS  models with and without value dropping (Drop) on the  DINUARTETXE BLI dataset.", "labels": [], "entities": [{"text": "P@1 scores", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.8653905689716339}, {"text": "DINUARTETXE BLI dataset", "start_pos": 106, "end_pos": 129, "type": "DATASET", "confidence": 0.7685514489809672}]}, {"text": " Table 2: BLI P @1 scores on DINUARTETXE: SHS and  IHS are evaluated for different values of the reweight- ing parameter q. The state-of-the-art results (Artetxe  et al., 2018a) are added as a reference. The result with  the highest average score obtained when trying differ- ent language orders is in the bottom row.", "labels": [], "entities": [{"text": "BLI P @1", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9432225525379181}, {"text": "IHS", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.6923601031303406}, {"text": "reweight- ing parameter q", "start_pos": 97, "end_pos": 122, "type": "METRIC", "confidence": 0.9357577443122864}]}, {"text": " Table 3: BLI P @1 scores on EURMUSEWIKI averaged  per language: SHS and IHS are tested for different val- ues of the reweighting parameter q. The results of Chen  and Cardie (2018) (UME) are added as a reference.", "labels": [], "entities": [{"text": "BLI P @1", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9398010969161987}, {"text": "EURMUSEWIKI", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.8764907121658325}, {"text": "IHS", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.7426905632019043}]}, {"text": " Table 4: Results on the MLPARSING (dependency pars- ing) and REUTERSMLDC (document classification)  benchmarks: SHS and IHS are compared with and with- out reweighting and we show the state-of-the-art results  of supervised embedding mapping methods as a refer- ence. The results for Invariance, MultiSkip, MultiClus- ter, MultiCCA are from (Ammar et al., 2016).", "labels": [], "entities": [{"text": "MLPARSING", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.8057168126106262}, {"text": "REUTERSMLDC", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.9818617105484009}, {"text": "document classification)", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.7074505885442098}]}, {"text": " Table 5: Precision@1 scores for a bilingual lexicon ex- periment on three distant language pairs.", "labels": [], "entities": [{"text": "Precision@1", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9576199452082316}]}, {"text": " Table 6: Influence of the hub language of the SHS  model on precision@1 scores evaluated on the DIN- UARTETXE BLI dataset.", "labels": [], "entities": [{"text": "precision@1 scores", "start_pos": 61, "end_pos": 79, "type": "METRIC", "confidence": 0.9440307021141052}, {"text": "DIN- UARTETXE BLI dataset", "start_pos": 97, "end_pos": 122, "type": "DATASET", "confidence": 0.667457103729248}]}]}