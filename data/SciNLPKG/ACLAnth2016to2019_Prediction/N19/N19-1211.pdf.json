{"title": [{"text": "Detecting Derogatory Compounds -An Unsupervised Approach", "labels": [], "entities": [{"text": "Detecting Derogatory Compounds", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9162292083104452}]}], "abstractContent": [{"text": "We examine the new task of detecting derogatory compounds (e.g. curry muncher).", "labels": [], "entities": []}, {"text": "Derogatory compounds are much more difficult to detect than derogatory unigrams (e.g. idiot) since they are more sparsely represented in lexical resources previously found effective for this task (e.g. Wiktionary).", "labels": [], "entities": []}, {"text": "We propose an unsupervised classification approach that incorporates linguistic properties of compounds.", "labels": [], "entities": []}, {"text": "It mostly depends on a simple distri-butional representation.", "labels": [], "entities": []}, {"text": "We compare our approach against previously established methods proposed for extracting derogatory unigrams.", "labels": [], "entities": []}], "introductionContent": [{"text": "Abusive or offensive language is commonly defined as hurtful, derogatory or obscene utterances made by one person to another person.", "labels": [], "entities": []}, {"text": "Examples are (1)-(3).", "labels": [], "entities": []}, {"text": "In the literature, closely related terms include hate speech ( or cyber bullying (.", "labels": [], "entities": []}, {"text": "While there maybe nuanced differences in meaning, they are all compatible with the general definition above.", "labels": [], "entities": []}, {"text": "(1) stop editing this, you dumbass.", "labels": [], "entities": []}, {"text": "(2) Just want to slap the stupid out of these bimbos!!!", "labels": [], "entities": []}, {"text": "(3) Go lick a pig you arab muslim piece of scum.", "labels": [], "entities": []}, {"text": "Due to the rise of user-generated web content, in particular on social media networks, the amount of abusive language is also steadily growing.", "labels": [], "entities": []}, {"text": "NLP methods are required to focus human review efforts towards the most relevant microposts.", "labels": [], "entities": []}, {"text": "A substantial amount of abusive utterances comprises derogatory words (e.g. bimbo or scum).", "labels": [], "entities": []}, {"text": "Automatic extraction methods of such words are required since new derogatory words constantly enter language.", "labels": [], "entities": []}, {"text": "extracted a large list of such expressions and demonstrated its importance for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8387879431247711}]}, {"text": "In this work, we focus on a subtype of derogatory terms, namely derogatory compounds (e.g. booze hound, curry muncher, fault finder).", "labels": [], "entities": [{"text": "fault finder", "start_pos": 119, "end_pos": 131, "type": "TASK", "confidence": 0.7097404450178146}]}, {"text": "Distinguishing such multi-word expressions from nonderogatory ones (e.g. foxhound, mile muncher, branch finder) is more difficult than classifying unigrams since they are only sparsely represented in general-purpose lexical resources which have previously been found an effective source from which to learn abusive language, such as Wiktionary.", "labels": [], "entities": [{"text": "branch finder)", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.7989887893199921}]}, {"text": "For example, while 97% of the derogatory unigrams of the gold standard lexicon in are contained in Wiktionary, less than 17% of the derogatory compounds used as our gold standard in this work can be found.", "labels": [], "entities": [{"text": "Wiktionary", "start_pos": 99, "end_pos": 109, "type": "DATASET", "confidence": 0.9277607798576355}]}, {"text": "Despite their sparsity in lexical resources derogatory compounds area frequent phenomenon, particularly in German data, which is why we study this task on that language.", "labels": [], "entities": []}, {"text": "On the German benchmark corpus for abusive language detection, the GermEval corpus (, we found that of the abusive microposts in the test set that include at least one derogatory expression, 39% contain a derogatory compound.", "labels": [], "entities": [{"text": "German benchmark corpus", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.8521120150883993}, {"text": "abusive language detection", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.6084147294362386}, {"text": "GermEval corpus", "start_pos": 67, "end_pos": 82, "type": "DATASET", "confidence": 0.887484073638916}]}, {"text": "In our work, we focus on noun-noun compounds.", "labels": [], "entities": []}, {"text": "Each compound (e.g. curry muncher) comprises two constituents, a modifier (i.e. curry) and ahead (i.e. muncher).", "labels": [], "entities": []}, {"text": "On the GermEval corpus, 77% of the derogatory compounds are nounnoun compounds.", "labels": [], "entities": [{"text": "GermEval corpus", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.8674027025699615}]}, {"text": "We only consider compounds whose constituents are not derogatory.", "labels": [], "entities": []}, {"text": "58% of the derogatory compounds on the GermEval corpus fall under this category.", "labels": [], "entities": [{"text": "GermEval corpus", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9161964356899261}]}, {"text": "Given publicly available lists of derogatory unigrams, the detection of derogatory compounds containing derogatory constituents (e.g. motherfucker) is rather trivial.", "labels": [], "entities": []}, {"text": "There even exist abusive word generators employing such compounds.", "labels": [], "entities": []}, {"text": "We present the first study to detect derogatory noun-noun compounds and propose an unsupervised classification approach based on distributional information that does not require any properly labeled training data.", "labels": [], "entities": []}, {"text": "We demonstrate that linguistic features that have previously been found effective for the classification of derogatory unigrams are notably less effective for the detection of derogatory compounds.", "labels": [], "entities": [{"text": "classification of derogatory unigrams", "start_pos": 90, "end_pos": 127, "type": "TASK", "confidence": 0.8291975110769272}]}, {"text": "We created anew dataset of derogatory compounds which will be made publicly available.", "labels": [], "entities": []}, {"text": "Our task is framed as a binary classification problem.", "labels": [], "entities": []}, {"text": "Each given compound is to be classified out of context as either derogatory or not.", "labels": [], "entities": []}, {"text": "For the sake of accessibility, we use English translations of our German compounds in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "PRANK produces a very high precision on the high ranks, outperforming the individual rankings and COMB.", "labels": [], "entities": [{"text": "PRANK", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.46649613976478577}, {"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9993045330047607}, {"text": "COMB", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9569440484046936}]}, {"text": "We also tested a modification, PRANK N EG , which applies personalized PageRank on the output of NEG, which is the strongest individual ranking.", "labels": [], "entities": [{"text": "PRANK N EG", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9090688625971476}]}, {"text": "Since PRANK outperforms PRANK N EG , we conclude that the high precision of PRANK also depends on the combination of the individual rankings.", "labels": [], "entities": [{"text": "PRANK N EG", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.5455768207708994}, {"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.99936443567276}]}, {"text": "LP manages to notably raise scores on the lower ranks (e.g. P@300) which proves the advantage of LP over PRANK.", "labels": [], "entities": [{"text": "P@300)", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9118216335773468}, {"text": "PRANK", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.7976114749908447}]}, {"text": "compares our proposed method (LP) against supervised classifiers.", "labels": [], "entities": []}, {"text": "We evaluate the entire classification output (with F1-measure) rather than a ranking.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9982283711433411}]}, {"text": "The classifiers are trained on our unigram or compound gold standard ( \u00a73).", "labels": [], "entities": []}, {"text": "For the latter case, we conducted 10-fold crossvalidation.", "labels": [], "entities": []}, {"text": "500 of the 3500 compounds were reserved as a development set on which we tuned hyperparameters of the supervised classifiers.", "labels": [], "entities": []}, {"text": "(The supplementary notes contain more details.)", "labels": [], "entities": []}, {"text": "As features we consider word embeddings and the linguistic features from.", "labels": [], "entities": []}, {"text": "They are based on knowledge that is expensive to produce, such as sentiment views, polar intensity, or information from Wiktionary.", "labels": [], "entities": []}, {"text": "12 shows that learning from the compound gold standard is more effective than learning from the existing unigram gold standard.", "labels": [], "entities": []}, {"text": "Given the     strong performance of embeddings, we also examined the performance of (publicly available) offthe-shelf embeddings and found that the high classification scores can be mainly ascribed to the large corpus on which we induced our embeddings (i.e. COW16).", "labels": [], "entities": [{"text": "COW16", "start_pos": 259, "end_pos": 264, "type": "DATASET", "confidence": 0.9373014569282532}]}, {"text": "Our unsupervised approach (LP) is almost on a par with the most complex SVM.", "labels": [], "entities": []}, {"text": "This is particularly appealing since we produced that classifier without manually labeled training data and those manually-created resources required for the linguistic features.", "labels": [], "entities": []}, {"text": "Compound embeddings are the most predictive information for our task, but even from the large COW16 corpus, we only obtained embeddings for 60% of our compounds.", "labels": [], "entities": [{"text": "COW16 corpus", "start_pos": 94, "end_pos": 106, "type": "DATASET", "confidence": 0.9672748446464539}]}, {"text": "In, we evaluate compositional information, which can also be used for compounds that lack an embedding.", "labels": [], "entities": []}, {"text": "We apply an SVM with the best previous feature set: Compound embedding augmentation ( * : statistically better than the plain classifier using a paired t-test at p < 0.05).", "labels": [], "entities": []}, {"text": "(of which embeddings are the main contributor) on the constituents of the compounds.", "labels": [], "entities": []}, {"text": "Moreover, we train an LSTM on the sequence of characters of the compound.", "labels": [], "entities": []}, {"text": "shows that information drawn from units other than the compound itself is less effective.", "labels": [], "entities": []}, {"text": "The feature combination of head, modifier and compound is not effective either.", "labels": [], "entities": []}, {"text": "Instead of applying embeddings on constituents and concatenating them, we also examine a sophisticated compositional model (Wmask) based on a masking process that takes into account the variation of a constituent depending on whether it is ahead or a modifier.", "labels": [], "entities": []}, {"text": "shows the performance of the two best previous classifiers where compounds lacking an embedding are represented by an embedding approximated by Wmask (rather than a dummy vector).", "labels": [], "entities": []}, {"text": "The table shows that the two classifiers can be improved by adding the approximated embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Some statistics of the gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.8036326766014099}]}, {"text": " Table 2: Comparison of different rankings, evaluated by precision at rank n (P@n). (PRANK N EG is the ranking  applied solely on the output of NEG; PRANK is the ranking applied on the output of COMB.)", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9986675977706909}, {"text": "PRANK N EG", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9354870319366455}, {"text": "COMB", "start_pos": 195, "end_pos": 199, "type": "DATASET", "confidence": 0.9605081081390381}]}, {"text": " Table 3: Comparison of different classifiers.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of compositional approaches.", "labels": [], "entities": []}, {"text": " Table 5: Compound embedding augmentation (  *  : sta- tistically better than the plain classifier using a paired  t-test at p < 0.05).", "labels": [], "entities": []}]}