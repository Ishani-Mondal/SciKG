{"title": [{"text": "Relation Extraction using Explicit Context Conditioning", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9800856113433838}]}], "abstractContent": [{"text": "Relation Extraction (RE) aims to label relations between groups of marked entities in raw text.", "labels": [], "entities": [{"text": "Relation Extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9014959216117859}]}, {"text": "Most current RE models learn context-aware representations of the target entities that are then used to establish relation between them.", "labels": [], "entities": [{"text": "RE", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9801480770111084}]}, {"text": "This works well for intra-sentence RE and we call them first-order relations.", "labels": [], "entities": []}, {"text": "However, this methodology can sometimes fail to capture complex and long dependencies.", "labels": [], "entities": []}, {"text": "To address this, we hypothesize that at times two target entities can be explicitly connected via a context token.", "labels": [], "entities": []}, {"text": "We refer to such indirect relations as second-order relations and describe an efficient implementation for computing them.", "labels": [], "entities": []}, {"text": "These second-order relation scores are then combined with first-order relation scores.", "labels": [], "entities": []}, {"text": "Our empirical results show that the proposed method leads to state-of-the-art performance over two biomedical datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "There are wide applications for Information Extraction in general ( and Relation Extraction (RE) in particular, one reason why relation extraction continues to bean active area of research (.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8217776715755463}, {"text": "Relation Extraction (RE)", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.7959835529327393}, {"text": "relation extraction", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.9435291588306427}]}, {"text": "Traditionally, a standard RE model would start with entity recognition and then pass the extracted entities as inputs to a separate relation extraction model, which meant that the errors in entity recognition were propagated to RE.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.723978117108345}, {"text": "entity recognition", "start_pos": 190, "end_pos": 208, "type": "TASK", "confidence": 0.7296195924282074}]}, {"text": "This problem was addressed by end-to-end models () that jointly learn both NER and RE.", "labels": [], "entities": [{"text": "RE", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.49936220049858093}]}, {"text": "Generally, these models consist of an encoder followed by a relationship classification (RC) unit (; * G.", "labels": [], "entities": []}, {"text": "Singh was an intern at Amazon at the time of work Su et al., 2018).", "labels": [], "entities": [{"text": "Amazon", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.9660043716430664}]}, {"text": "The encoder provides contextaware vector representations for both target entities, which are then merged or concatenated before being passed to the relation classification unit, where a two layered neural network or multilayered perceptron classifies the pair into different relation types.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 148, "end_pos": 171, "type": "TASK", "confidence": 0.7240949273109436}]}, {"text": "Such RE models rely on the encoder to learn 'perfect' context-aware entity representations that can capture complex dependencies in the text.", "labels": [], "entities": [{"text": "RE", "start_pos": 5, "end_pos": 7, "type": "TASK", "confidence": 0.9657421112060547}]}, {"text": "This works well for intra-sentence relation extraction i.e. the task of extracting relation from entities contained in a sentence (.", "labels": [], "entities": [{"text": "intra-sentence relation extraction", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.6983373165130615}]}, {"text": "As these entities are closer together, the encoder can more easily establish connection based on the language used in the sentence.", "labels": [], "entities": []}, {"text": "Additionally, these intra-sentence RE models can use linguistic/syntactical features for an improved performance e.g. shortest dependency path.", "labels": [], "entities": [{"text": "RE", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9343681931495667}]}, {"text": "Unfortunately, success in intra-sentence RE has not been replicated for cross-sentence RE.", "labels": [], "entities": [{"text": "cross-sentence RE", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.5863365828990936}]}, {"text": "As an example, a recent RE method called BRAN ( proposed to use encoder of Transformer () for obtaining token representations and then used these representations for RE.", "labels": [], "entities": [{"text": "BRAN", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.916538417339325}]}, {"text": "However, our analysis revealed that it wrongly marks many cross-sentence relations as negative, especially when the two target entities were connected by a string of logic spanning over multiple sentences.", "labels": [], "entities": []}, {"text": "This showed that reliance on the encoder alone to learn these complex dependencies does notwork well.", "labels": [], "entities": []}, {"text": "In this work we address this issue of overreliance on the encoder.", "labels": [], "entities": []}, {"text": "We propose a model based on the hypothesis that two target entities, whether intra-sentence or cross-sentence, could also be explicitly connected via a third context token ().", "labels": [], "entities": []}, {"text": "More specifically, we find a token in the text that is most related to both target entities, and compute the score for relation between the two target entities as the summation of their relation scores with this token.", "labels": [], "entities": []}, {"text": "We refer to these relations as second-order relations.", "labels": [], "entities": []}, {"text": "At the end, we combine these second-order scores with firstorder scores derived from a traditional RE model, and achieve state-of-the-art performance over two biomedical datasets.", "labels": [], "entities": []}, {"text": "To summarize the contribution of this work: 1.", "labels": [], "entities": []}, {"text": "We propose using second-order relation scores for improved relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.8782629370689392}]}, {"text": "2. We describe an efficient algorithm to obtain second-order relation scores.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have used three datasets in this work, i2b2 2010 challenge (Uzuner et al., 2011) dataset, a de-identified clinical notes dataset and a chemicaldisease relations dataset known as BioCreative V (CDR) ( . First is a publicly available subset of the dataset used for the i2b2 2010 challenge.", "labels": [], "entities": []}, {"text": "It consists of documents describing relations between different diseases and treatments.", "labels": [], "entities": []}, {"text": "Out of the 426 documents available publicly, 10% are used each for both dev and test and the rest for training.", "labels": [], "entities": []}, {"text": "There are 3244/409 relations in train/test set and 6 predefined relations types including one negative relation e.g. TrCP (Treatment Causes Problem), TrIP (Tr Improves Pr), TrWP (Tr Worsens Pr).", "labels": [], "entities": [{"text": "TrCP", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.9365259408950806}, {"text": "TrIP", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.9233372807502747}]}, {"text": "We have used the exact same dataset as.", "labels": [], "entities": []}, {"text": "Second is a dataset of 4200 de-identified clinical notes (DCN), with vocabulary size of 50K.", "labels": [], "entities": [{"text": "vocabulary size", "start_pos": 69, "end_pos": 84, "type": "METRIC", "confidence": 0.8614225387573242}]}, {"text": "It contains approximately 170K relations in the train set and 50K each in dev/test set.", "labels": [], "entities": []}, {"text": "There are 7 predefined relation types including one negative relation type.", "labels": [], "entities": []}, {"text": "These are mostly between medication name and other entities e.g. \"paracetamol every day\",\"aspirin with dosage 100mg\".", "labels": [], "entities": []}, {"text": "The frequency of different relations in this dataset is fairly balanced.", "labels": [], "entities": []}, {"text": "Third is a widely used and publicly available dataset called CDR ( . It was derived from Comparative Toxicogenomics Database (CTD) and contains documents describing the effect of chemicals (drugs) on diseases.", "labels": [], "entities": [{"text": "Comparative Toxicogenomics Database (CTD)", "start_pos": 89, "end_pos": 130, "type": "DATASET", "confidence": 0.7011597255865732}]}, {"text": "There are only two relation types between any two target entities i.e. positive/negative and these relations are annotated at the document level.", "labels": [], "entities": []}, {"text": "It consists of 1500 documents that are divided equally between train/dev/test sets.", "labels": [], "entities": []}, {"text": "There are 1038/1012/1066 positive and 4280/4136/4270 negative relations in train/dev/test sets respectively.", "labels": [], "entities": []}, {"text": "We performed the same preprocessing as done in BRAN ().", "labels": [], "entities": [{"text": "BRAN", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.47057631611824036}]}, {"text": "We jointly solve for NER and RE tasks using cross-entropy loss.", "labels": [], "entities": [{"text": "NER and RE tasks", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.5649254992604256}]}, {"text": "During training we alternate between mini-batches derived from each task.", "labels": [], "entities": []}, {"text": "We fix the learn rate to 0.0005 and clip gradient for both tasks at 5.0.", "labels": [], "entities": [{"text": "learn rate", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9596658647060394}, {"text": "clip gradient", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.9875708222389221}]}, {"text": "For training, we used adams optimizer with \u03b2 = (\u03b2 1 , \u03b2 2 ) = (0.1, 0.9).", "labels": [], "entities": []}, {"text": "We tune over the weight of second-order relations denoted by \u03b1 to get \u03b1 = 0.2 for DCN/i2b2 and \u03b1 = 0.0 for CDR dataset.", "labels": [], "entities": [{"text": "DCN/i2b2", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.8838276664415995}, {"text": "CDR dataset", "start_pos": 107, "end_pos": 118, "type": "DATASET", "confidence": 0.9600634872913361}]}, {"text": "Our final network had two encoder layers, with 8 attention heads in each multi-head attention sublayer and 256 filters for convolution layers in position-wise feedforward sublayer.", "labels": [], "entities": []}, {"text": "We used dropout with probability 0.3 after: embedding layer, head/tail MLPs, output of each encoder sublayer.", "labels": [], "entities": []}, {"text": "We also used a word dropout with probability 0.15 before the embedding layer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The performance of proposed model using  second-order relations. BRAN is the model used in  (Verga et al., 2018) and +SOR is our proposed model  with second-order relations. Results for HDLA are  quoted from", "labels": [], "entities": [{"text": "BRAN", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9984036087989807}, {"text": "HDLA", "start_pos": 196, "end_pos": 200, "type": "DATASET", "confidence": 0.667481541633606}]}]}