{"title": [{"text": "Goal-Oriented End-to-End Conversational Models with Profile Features in a Real-World Setting", "labels": [], "entities": []}], "abstractContent": [{"text": "End-to-end neural models for goal-oriented conversational systems have become an increasingly active area of research, though results in real-world settings are few.", "labels": [], "entities": []}, {"text": "We present real-world results for two issue types in the customer service domain.", "labels": [], "entities": []}, {"text": "We train models on historical chat transcripts and test on live contacts using a human-in-the-loop research platform.", "labels": [], "entities": []}, {"text": "Additionally, we incorporate customer profile features to assess their impact on model performance.", "labels": [], "entities": []}, {"text": "We experiment with two approaches for response generation: (1) sequence-to-sequence generation and (2) template ranking.", "labels": [], "entities": [{"text": "response generation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7893990278244019}, {"text": "sequence-to-sequence generation", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.6601568907499313}]}, {"text": "To test our models, a customer service agent handles live contacts and at each turn we present the top four model responses and allow the agent to select (and optionally edit) one of the suggestions or to type their own.", "labels": [], "entities": []}, {"text": "We present results for turn acceptance rate, response coverage, and edit rate based on approximately 600 contacts, as well as qualitative analysis on patterns of turn rejection and edit behavior.", "labels": [], "entities": [{"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.6228030323982239}, {"text": "edit rate", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.8484426438808441}]}, {"text": "Top-4 turn acceptance rate across all models ranges from 63%-80%.", "labels": [], "entities": [{"text": "acceptance", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9558750987052917}]}, {"text": "Our results suggest that these models are promising for an agent-support application.", "labels": [], "entities": []}], "introductionContent": [{"text": "While interest in training conversational models has been steadily increasing, recent research has largely focused on how algorithmic improvements help model performance on fabricated datasets.", "labels": [], "entities": []}, {"text": "In this work, we explore how two general approaches to conversational modeling perform on real-world data in a customer service setting, with the goal of developing an application that provides customer service agents with recommended responses to enable them to help customers more quickly.", "labels": [], "entities": [{"text": "conversational modeling", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.747474730014801}]}, {"text": "Conversational systems are typically divided into two broad categories: chit-chat systems () and goaloriented systems, with the latter designed to accomplish specific tasks such as restaurant reservations ().", "labels": [], "entities": []}, {"text": "Many of these systems use separate components for dialog state (belief) tracking and natural language generation (, while others are end-toend.", "labels": [], "entities": [{"text": "dialog state (belief) tracking", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7091050942738851}, {"text": "natural language generation", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.696141242980957}]}, {"text": "Recent work in end-to-end approaches can be further categorized into sequence-to-sequence models that generate responses word byword (, and template-based approaches that score pairs of conversation history and candidate response (.", "labels": [], "entities": []}, {"text": "Sequence-to-sequence models are easily scaled to new domains but tend to generate safe, generic responses that may not be effective in helping the user achieve their goal (.", "labels": [], "entities": []}, {"text": "End-to-end templated models are less expensive to develop than belief tracking systems, but still require domain knowledge and may not coverall situations.", "labels": [], "entities": []}, {"text": "As a result, some research has focused on hybrid approaches (.", "labels": [], "entities": []}, {"text": "Regardless of the approach, there is a shortage of work investigating the performance of taskoriented conversational systems in a real-world setting.", "labels": [], "entities": []}, {"text": "The majority of the literature on taskoriented models describes performance on fabricated datasets, which may not translate to realworld data (.", "labels": [], "entities": []}, {"text": "Furthermore, research on sequence-to-sequence models often borrows automated evaluation metrics from the Machine Translation literature such as BLEU score (, which have been shown to correlate only weakly with human judgment (.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.762689620256424}, {"text": "BLEU score", "start_pos": 144, "end_pos": 154, "type": "METRIC", "confidence": 0.9879173636436462}]}, {"text": "In addition, there has been only limited research on using customer profile information to augment textual features in end-to-end conversational models (.", "labels": [], "entities": []}, {"text": "In this work, we seek to address these gaps by training task-oriented, multi-turn conversational models for the customer service domain and reporting results on interactions with real customers.", "labels": [], "entities": []}, {"text": "Our use case is an agent-support application that recommends responses, similar to the smart reply feature in Gmail ( and.", "labels": [], "entities": []}, {"text": "We incorporate user profile information as features to enable our models to generate relevant, personalized responses.", "labels": [], "entities": []}, {"text": "Our research goals are to explore the effect of customer profile features in two different model formulations, and to present a practical comparison of these two general approaches in a real-world setting.", "labels": [], "entities": []}, {"text": "In Section 2, we describe the training data used to develop these models.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the end-to-end models we developed, which include both sequence-to-sequence and templatebased models.", "labels": [], "entities": []}, {"text": "In Section 4, we introduce a research platform for testing our models in a realworld, human-in-the-loop setting, and in Section 5, we report results on conversations with real customers.", "labels": [], "entities": []}, {"text": "In Section 6, we describe the impact of profile features, conduct an analysis of rejected and edited turns, and comment on the performance of each type of model.", "labels": [], "entities": []}, {"text": "In Section 7, we summarize the conclusions drawn from this work and propose future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained response generation and response ranking models using only the conversation history for Repeat until the contact is resolved: Every time the customer types into their chat window: 1.", "labels": [], "entities": [{"text": "response generation", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7144431322813034}, {"text": "Repeat", "start_pos": 99, "end_pos": 105, "type": "TASK", "confidence": 0.8839668035507202}]}, {"text": "E2E model suggests four responses.", "labels": [], "entities": [{"text": "E2E", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9117826223373413}]}, {"text": "CSA may wait for customer if still typing.", "labels": [], "entities": [{"text": "CSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.709861159324646}]}], "tableCaptions": [{"text": " Table 1: Results of the different experiments on both cancel order and return refund status domains.", "labels": [], "entities": []}, {"text": " Table 2: Rate of edit distances between accepted and sent turns", "labels": [], "entities": [{"text": "Rate of edit distances", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.9052944630384445}]}]}