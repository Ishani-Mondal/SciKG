{"title": [{"text": "Understanding the Behaviour of Neural Abstractive Summarizers using Contrastive Examples", "labels": [], "entities": [{"text": "Neural Abstractive Summarizers", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.6012235283851624}]}], "abstractContent": [{"text": "Neural abstractive summarizers generate summary texts using a language model conditioned on the input source text, and have recently achieved high ROUGE scores on benchmark summarization datasets.", "labels": [], "entities": [{"text": "Neural abstractive summarizers generate summary texts", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8306270937124888}, {"text": "ROUGE", "start_pos": 147, "end_pos": 152, "type": "METRIC", "confidence": 0.9858128428459167}]}, {"text": "We investigate how they achieve this performance with respect to human-written gold-standard abstracts , and whether the systems are able to understand deeper syntactic and semantic structures.", "labels": [], "entities": []}, {"text": "We generate a set of contrastive summaries which are perturbed, deficient versions of human-written summaries, and test whether existing neural summarizers score them more highly than the human-written summaries.", "labels": [], "entities": []}, {"text": "We analyze their performance on different datasets and find that these systems fail to understand the source text, in a majority of the cases.", "labels": [], "entities": []}], "introductionContent": [{"text": "Open-domain abstractive summarization is a longstanding goal of the field of automatic summarization.", "labels": [], "entities": [{"text": "Open-domain abstractive summarization", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.4906246066093445}]}, {"text": "Compared to extractive techniques, abstraction offers the potential to generate much more useful summaries by simplifying and rephrasing the source text (, and furthermore by aggregating information and performing operations which are not possible with extractive techniques.", "labels": [], "entities": []}, {"text": "Recently, a number of abstractive summarization systems based on neural sequence-tosequence architectures have been proposed.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.532690703868866}]}, {"text": "These systems learn a compressed representation of the source text using an encoder, then generate the output summary using a conditional decoder.", "labels": [], "entities": []}, {"text": "Such neural abstractive systems have achieved very good ROUGE scores on different datasets.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9728112816810608}]}], "datasetContent": [{"text": "We apply our set of contrastive summaries to evaluate a number of neural abstractive summarizers.", "labels": [], "entities": []}, {"text": "For each summarizer under evaluation, we assume access to a conditional language model which defines a probability distribution over words conditioned on the source.", "labels": [], "entities": []}, {"text": "Formally, such a language model is given by Equation 1: here S is the source, \u03b8 are model parameters, y i \u2208 V sm represents the i th word in the summary, V sm is the vocabulary space of the summary and P is the conditional probability.", "labels": [], "entities": [{"text": "Equation", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9787100553512573}]}, {"text": "S \u2286 (s 1 , ..., s n ) where s i \u2208 V so , V so is the vocabulary space of the source and n is the maximum source length.", "labels": [], "entities": []}, {"text": "Further, we use Equation 2 as our scoring function, log P (y i |\u03b8, S, y 1 ...y i\u22121 ), here m is maximum summary length and y represents a gold or contrastive summary.", "labels": [], "entities": []}, {"text": "For a given triple of source, gold (g) and contrastive (c) summary, if p(g) > p(c), then we label the triple 'dodged', since the summarizer successfully dodged the generated contrastive summary.", "labels": [], "entities": []}, {"text": "If a system is able to dodge all contrastive summaries generated from a source and gold summary tuple, then we label the tuple as 'escaped'.", "labels": [], "entities": []}, {"text": "We experimented on two datasets, for two abstractive summarization tasks.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.5087841600179672}]}, {"text": "The first is a short summarization task, where the summary is one sentence long, for which we use the Gigaword corpus ().", "labels": [], "entities": [{"text": "summarization task", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8709505498409271}, {"text": "Gigaword corpus", "start_pos": 102, "end_pos": 117, "type": "DATASET", "confidence": 0.9547630250453949}]}, {"text": "We use the scripts provided by to process the Gigaword corpus, which contains the first sentence of the article and the headline as source and gold summary pairs.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.9698047041893005}]}, {"text": "The test set contains about 250K source-summary pairs from which we randomly selected 10K pairs and generated 509K contrastive summaries.", "labels": [], "entities": []}, {"text": "The second is along summarization task, in which the summary consists of multiple sentences.", "labels": [], "entities": [{"text": "summarization", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9780046343803406}]}, {"text": "We use the CNN/Dailymail corpus, where the highlights of the articles are used as the gold summary (.", "labels": [], "entities": [{"text": "CNN/Dailymail corpus", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.9350768178701401}]}, {"text": "We used the scripts from to get the data and use the non-anonymized version like).", "labels": [], "entities": []}, {"text": "The ABS+ system uses an attention-based neural language model as an encoder and a feed-forward neural network for decoding, and is trained on the Gigaword corpus.", "labels": [], "entities": [{"text": "ABS+", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8926168382167816}, {"text": "Gigaword corpus", "start_pos": 146, "end_pos": 161, "type": "DATASET", "confidence": 0.9716799557209015}]}, {"text": "The GTP system is a seq2seq model with attention on the encoder and a pointer-generator mechanism to choose words from the source in the decoder and, is trained on the CNN/Dailymail corpus.", "labels": [], "entities": [{"text": "CNN/Dailymail corpus", "start_pos": 168, "end_pos": 188, "type": "DATASET", "confidence": 0.945173516869545}]}, {"text": "FAS uses reinforcement learning algorithm to extract the most important sentences from the source text, and then summarizes each sentence using a similar architecture as GTP on the CNN/Dailymail corpus.", "labels": [], "entities": [{"text": "FAS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5122926831245422}, {"text": "CNN/Dailymail corpus", "start_pos": 181, "end_pos": 201, "type": "DATASET", "confidence": 0.9285232275724411}]}, {"text": "These systems have performed well on small and large text summarization tasks, and have open-source implementation available from the authors.", "labels": [], "entities": [{"text": "text summarization tasks", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.7827911376953125}]}, {"text": "We would have liked to test other relevant systems (), but were unable to obtain their implementations.", "labels": [], "entities": []}, {"text": "contrastive summaries is very large.", "labels": [], "entities": []}, {"text": "To restrict the number of contrastive summaries we randomly select approximately 50 generated summaries, while maintaining the rule-wise distribution.", "labels": [], "entities": []}, {"text": "The rule-wise distribution was estimated based upon contrastive summaries, generated from a subset of 100 gold standard summaries from CNN/Dailymail corpus.", "labels": [], "entities": [{"text": "CNN/Dailymail corpus", "start_pos": 135, "end_pos": 155, "type": "DATASET", "confidence": 0.9234788864850998}]}, {"text": "In order to correctly evaluate the FAS system, for each extracted sentence we generate all sentences in the gold summary, and pick the set of summaries with the maximum probability.", "labels": [], "entities": [{"text": "FAS", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.6346091032028198}]}, {"text": "To ensure that we are generating incorrect contrastive summaries, 200 randomly sampled summaries from the Gigaword corpus were evaluated by a human annotator, to verify if a semantic discrepancy or a readability issue was present.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 106, "end_pos": 121, "type": "DATASET", "confidence": 0.9470257461071014}]}, {"text": "We ensured that we sample equally across all the 8 rules, and that we restrict our set of contrastive summaries which the ABS+ system was notable to 'dodge'.", "labels": [], "entities": [{"text": "ABS+ system", "start_pos": 122, "end_pos": 133, "type": "DATASET", "confidence": 0.9108978907267252}]}, {"text": "We found that 49.5% had a readability issue while 43.5% had a discrepancy issue, and 93% of the examples had at least one of these issues.", "labels": [], "entities": []}, {"text": "This indicates that the vast majority of our contrastive examples are \"true negatives\"; i.e., a perfect summarization system should score them lower than the gold standard summary.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Rule-wise Performance, here Source and  Gold are based upon rule perturbations in Section 3", "labels": [], "entities": []}, {"text": " Table 4: Performance on dodged, escaped metrics.", "labels": [], "entities": []}]}