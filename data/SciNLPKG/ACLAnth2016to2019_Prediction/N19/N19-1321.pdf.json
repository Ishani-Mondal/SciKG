{"title": [{"text": "Adapting RNN Sequence Prediction Model to Multi-label Set Prediction", "labels": [], "entities": [{"text": "Adapting RNN Sequence Prediction", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8278715163469315}, {"text": "Multi-label Set Prediction", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.6070743302504221}]}], "abstractContent": [{"text": "We present an adaptation of RNN sequence models to the problem of multi-label classification for text, where the target is a set of labels , not a sequence.", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.7695437073707581}]}, {"text": "Previous such RNN models define probabilities for sequences but not for sets; attempts to obtain a set probability are afterthoughts of the network design, including pre-specifying the label order, or relating the sequence probability to the set probability in ad hoc ways.", "labels": [], "entities": []}, {"text": "Our formulation is derived from a princi-pled notion of set probability, as the sum of probabilities of corresponding permutation sequences for the set.", "labels": [], "entities": []}, {"text": "We provide anew training objective that maximizes this set probability, and anew prediction objective that finds the most probable set on a test document.", "labels": [], "entities": []}, {"text": "These new objectives are theoretically appealing because they give the RNN model freedom to discover the best label order, which often is the natural one (but different among documents).", "labels": [], "entities": []}, {"text": "We develop efficient procedures to tackle the computation difficulties involved in training and prediction.", "labels": [], "entities": []}, {"text": "Experiments on benchmark datasets demonstrate that we outperform state-of-the-art methods for this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multi-label text classification is an important machine learning task wherein one must predict a set of labels to associate with a given document; for example, a news article might be tagged with labels sport, football, 2018 world cup, and Russia.", "labels": [], "entities": [{"text": "Multi-label text classification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.755603035291036}]}, {"text": "Formally, we are given a set of label candidates L = {1, 2, ..., L}, and we aim to build a classifier which maps a document x to a set of labels y \u2282 L.", "labels": [], "entities": []}, {"text": "The label set y is typically written as a binary vector y \u2208 {0, 1} L , with each bit y indicating the presence or absence of a label.", "labels": [], "entities": []}, {"text": "Naively, one could predict each label independently without considering label dependencies.", "labels": [], "entities": []}, {"text": "This approach is called Binary Relevance (, and is widely used due to its simplicity, but it often does not deliver good performance.", "labels": [], "entities": [{"text": "Binary Relevance", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.623833179473877}]}, {"text": "Intuitively, knowing some labels-such as sport and football-should make it easier to predict 2018 world cup and then Russia.", "labels": [], "entities": []}, {"text": "There are several methods that try to capture label dependencies by building a joint probability estimation overall labels p(y = (y 1 , y 2 , ..., y L )|x) (.", "labels": [], "entities": []}, {"text": "The most popular approach, Probabilistic Classifier Chain (PCC)) learns labels one-by-one in a predefined fixed order: for each label, it uses one classifier to estimate the probability of that label given all previous labels predictions, p(y l |y 1 , ..., y l\u22121 , x).", "labels": [], "entities": []}, {"text": "PCC's well known drawback is that errors in early probability estimations tend to affect subsequent predictions, and can become massive when the total number of label candidates L is large.", "labels": [], "entities": []}, {"text": "Recurrent neural network (RNN) is originally designed to output a sequential structure, such as a sentence ( . Recently, RNNs have also been applied to multi-label classification by mapping the label set to a sequence (.", "labels": [], "entities": [{"text": "Recurrent neural network (RNN)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.638540784517924}, {"text": "multi-label classification", "start_pos": 152, "end_pos": 178, "type": "TASK", "confidence": 0.7822511792182922}]}, {"text": "In contrast to PCC where a binary decision is made for each label sequentially, RNN only predicts the positive labels explicitly and therefore its decision chain length is equal to the number of positive labels, not the number of all labels.", "labels": [], "entities": []}, {"text": "This makes RNN suffer less from early estimation errors than PCC.", "labels": [], "entities": []}, {"text": "Both PCC and RNN rely heavily on label orders in training and prediction.", "labels": [], "entities": []}, {"text": "In multi-label data, the labels are given as sets, not necessarily with natural orders.", "labels": [], "entities": []}, {"text": "RNN defines a sequence probability, while PCC defines set probability.", "labels": [], "entities": [{"text": "PCC", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.9091767072677612}]}, {"text": "Various ways of arranging sets as sequences have been explored: ordering alphabetically, by frequency, based on a label hierarchy, or according to some label ranking algorithm (.", "labels": [], "entities": []}, {"text": "Previous experimental results show that which order to choose can have a significant impact on learning and prediction ().", "labels": [], "entities": []}, {"text": "In the above example, starting label predictions sequence with Russia, while correct, would make the other predictions very difficult.", "labels": [], "entities": []}, {"text": "Previous work has shown that it is possible to train an RNN on multi-label data without specifying the label order in advance.", "labels": [], "entities": []}, {"text": "With special training objectives, RNN can explore different label orders and converge to some order automatically (.", "labels": [], "entities": []}, {"text": "In this paper we follow the same line of study: We consider how to adapt RNN sequence model to multi-label set prediction without specifying the label order.", "labels": [], "entities": [{"text": "multi-label set prediction", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.6531984309355418}]}, {"text": "Specifically, we make the following contributions: 1.", "labels": [], "entities": []}, {"text": "We analyze existing RNN models proposed for multi-label prediction, and show that existing training and prediction objectives are not well justified mathematically and have undesired consequences in practice.", "labels": [], "entities": [{"text": "multi-label prediction", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7962435781955719}]}, {"text": "2. We develop efficient approximate training and prediction methods.", "labels": [], "entities": []}, {"text": "We propose new training and prediction objectives based on a principled notion of set probability.", "labels": [], "entities": []}, {"text": "Our new formulation avoids the drawbacks of existing ones and gives the RNN model freedom to discover the best label order.", "labels": [], "entities": []}, {"text": "3. We crawl two new datasets for multi-label prediction task, and apply our method to them.", "labels": [], "entities": [{"text": "multi-label prediction task", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8131285111109415}]}, {"text": "We also test our method on two existing multi-label datasets.", "labels": [], "entities": []}, {"text": "The experimental results show that our method outperforms stateof-the-art methods on all datasets.", "labels": [], "entities": []}, {"text": "We release the datasets at http://www.ccis.neu.", "labels": [], "entities": []}, {"text": "edu/home/kechenqin.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test our proposed set-RNN method on 4 realworld datasets, RCV1-v2, Slashdot, TheGuardian, and Arxiv Academic Paper Dataset (AAPD) ().", "labels": [], "entities": [{"text": "TheGuardian", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.9542834758758545}, {"text": "Arxiv Academic Paper Dataset (AAPD)", "start_pos": 97, "end_pos": 132, "type": "DATASET", "confidence": 0.7249250752585275}]}, {"text": "We take the public RCV1-v2 release 1 and randomly sample 50,000 documents.", "labels": [], "entities": [{"text": "RCV1-v2 release 1", "start_pos": 19, "end_pos": 36, "type": "DATASET", "confidence": 0.9045929908752441}]}, {"text": "We crawl Slashdot and TheGuardian documents from their websites 2 and treat the official editor tags as ground truth.", "labels": [], "entities": [{"text": "TheGuardian documents", "start_pos": 22, "end_pos": 43, "type": "DATASET", "confidence": 0.9472485184669495}]}, {"text": "We also gather a list of user tags   To process documents, we filter out stopwords and punctuations.", "labels": [], "entities": []}, {"text": "Each document is truncated to have maximum 500 words for TheGuardian and AAPD, and 120 for Slashdot and RCV1-v2.", "labels": [], "entities": [{"text": "TheGuardian", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.9836199283599854}, {"text": "AAPD", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.8223901987075806}]}, {"text": "Zero padding is used if the document contains less words than the maximum number.", "labels": [], "entities": []}, {"text": "Numbers and out-of-vocabulary words are replaced with special tokens.", "labels": [], "entities": []}, {"text": "Words, user tags and labels are all encoded as 300-dimensional vectors using WORD2VEC (.", "labels": [], "entities": [{"text": "WORD2VEC", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.757291853427887}]}, {"text": "We implement RNNs with attention using TENSORFLOW-1.4.0 ().", "labels": [], "entities": [{"text": "TENSORFLOW-1.4.0", "start_pos": 39, "end_pos": 55, "type": "METRIC", "confidence": 0.8643072247505188}]}, {"text": "The dynamic function for RNNs is chosen to be Gated recurrent units (GRU) with 2 layers and at most 50 units in decoder.", "labels": [], "entities": []}, {"text": "The size of the GRU unit is 300.", "labels": [], "entities": [{"text": "GRU unit", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.7461452782154083}]}, {"text": "We set dropout rate to 0.3, and train the model with Adam optimizer) with learning rate 0.0005.", "labels": [], "entities": []}, {"text": "Beam size is set to be 12 at both training and inference stages.", "labels": [], "entities": [{"text": "Beam size", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8670995831489563}]}, {"text": "We adopt label-F1 (average F1 over labels) and instance-F1: Predicting the most probable sequence vs. predicting the most probable set.", "labels": [], "entities": []}, {"text": "Numbers before the arrow: predicting the most probable sequence.", "labels": [], "entities": []}, {"text": "Numbers after the arrow: predicting the most probable set.", "labels": [], "entities": []}, {"text": "We highlight scores which get significantly improved in bold (improvement is larger than 0.01).", "labels": [], "entities": []}, {"text": "(average F1 over instances) as our main evaluation metrics, as defined below: where for each instance n, y given label in ground truth; \u02c6 y We compare our method with the following methods: \u2022 Binary Relevance (BR)) with both independent training and prediction; \u2022 Binary Relevance with support inference (BR-support) ( ) which trains binary classifiers independently but imposes label constraints at prediction time by only considering label sets observed during training, namely\u02c6ynamely\u02c6 namely\u02c6y = arg max observed y L =1 p(y |x); \u2022 Probabilistic Classifier Chain (PCC)) which transforms the multi-label classification task into a chain of binary classification problems.", "labels": [], "entities": [{"text": "F1", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.9637505412101746}, {"text": "multi-label classification task", "start_pos": 594, "end_pos": 625, "type": "TASK", "confidence": 0.7827623089154562}]}, {"text": "Predictions are made with Beam Search.", "labels": [], "entities": [{"text": "Beam Search", "start_pos": 26, "end_pos": 37, "type": "DATASET", "confidence": 0.7327980399131775}]}, {"text": "\u2022 Sequence to Sequence RNN (seq2seq-RNN)) which maps each set to a sequence by decreasing label frequency and solves the multi-label task with an RNN designed for sequence prediction (see).", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.6963030844926834}]}, {"text": "\u2022 Vinyals-RNN-uniform, Vinyals-RNNsample, and Vinyals-RNN-max are three variants of RNNs proposed by.", "labels": [], "entities": []}, {"text": "They are trained with different objectives that correspond to different transformations between sets and sequences.", "labels": [], "entities": []}, {"text": "See fora summary of their training objectives.", "labels": [], "entities": []}, {"text": "Following the approach taken by, Vinyals-RNNsample and Vinyals-RNN-max are initialized by Vinyals-RNN-uniform.", "labels": [], "entities": [{"text": "Vinyals-RNNsample", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.8827181458473206}, {"text": "Vinyals-RNN-max", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.8988279104232788}, {"text": "Vinyals-RNN-uniform", "start_pos": 90, "end_pos": 109, "type": "DATASET", "confidence": 0.9167848825454712}]}, {"text": "We have also tested training Vinyals-RNN-max directly without having Vinyals-RNN-uniform as an initialization, and we name it as Vinyals-RNN-max-direct.", "labels": [], "entities": [{"text": "Vinyals-RNN-uniform", "start_pos": 69, "end_pos": 88, "type": "DATASET", "confidence": 0.9190123677253723}, {"text": "Vinyals-RNN-max-direct", "start_pos": 129, "end_pos": 151, "type": "DATASET", "confidence": 0.9211653470993042}]}, {"text": "\u2022 Sequence Generation Model (SGM) ( which trains the RNN model similar to seq2seq-RNN but uses anew decoder structure that computes a weighted global embedding based on all labels as opposed to just the top one at each timestep.", "labels": [], "entities": [{"text": "Sequence Generation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7718309760093689}]}, {"text": "In BR and PCC, logistic regressions with L1 and L2 regularizations are used as the underlying binary classifiers.", "labels": [], "entities": []}, {"text": "seq2seq-RNN, PCC, and SGM rely on a particular label order.", "labels": [], "entities": [{"text": "PCC", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.8464457988739014}]}, {"text": "We adopt the decreasing label frequency order, which is the most popular choice.", "labels": [], "entities": []}, {"text": "shows the performance of different methods in terms of label-F1 and instance-F1.", "labels": [], "entities": []}, {"text": "The SGM results are taken directly from (, and are originally reported only on AAPD dataset in terms of hamming-loss and micro-F1.", "labels": [], "entities": [{"text": "SGM", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9396795034408569}, {"text": "AAPD dataset", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.9753686189651489}]}, {"text": "Definitions of these two metrics can be found in (.", "labels": [], "entities": []}, {"text": "Our method performs the best in all metrics on all datasets (except hamming loss on AAPD, see table 3).", "labels": [], "entities": [{"text": "AAPD", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.6327531337738037}]}, {"text": "In general, RNN based methods perform better than traditional methods BR, BRsupport and PCC.", "labels": [], "entities": [{"text": "BR", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.936631441116333}, {"text": "BRsupport", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.6782350540161133}]}, {"text": "Among the Vinyals-RNN variants, Vinyals-RNN-max and Vinyals-sample work the best and have similar performance.", "labels": [], "entities": [{"text": "Vinyals-RNN-max", "start_pos": 32, "end_pos": 47, "type": "DATASET", "confidence": 0.9141201376914978}]}, {"text": "However, they have to be initialized by Vinyals-RNNuniform.", "labels": [], "entities": [{"text": "Vinyals-RNNuniform", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.9199485778808594}]}, {"text": "Otherwise, the training gets stuck in early stage and the performance degrades significantly.", "labels": [], "entities": []}, {"text": "One can seethe clear degradation by comparing the Vinyals-RNN-max row (with initialization) with the Vinyals-RNN-max-direct row (without initialization).", "labels": [], "entities": [{"text": "Vinyals-RNN-max", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.8899846076965332}, {"text": "Vinyals-RNN-max-direct row", "start_pos": 101, "end_pos": 127, "type": "DATASET", "confidence": 0.9066810607910156}]}, {"text": "By contrast, our training objective in set-RNN does not suffer from this issue and can serve as a stable standalone training objective.", "labels": [], "entities": []}, {"text": "On TheGuardian dataset, set-RNN performs slightly better than seq2seq-RNN in terms of instance-F1, but much better in terms of label-F1.", "labels": [], "entities": [{"text": "TheGuardian dataset", "start_pos": 3, "end_pos": 22, "type": "DATASET", "confidence": 0.9541193246841431}]}, {"text": "It is known that instance-F1 is basically determined by the popular labels' performance while label-F1 is also sensitive to the performance on rare labels.", "labels": [], "entities": []}, {"text": "shows that set-RNN predicts rare labels better than seq2seq-RNN.", "labels": [], "entities": []}, {"text": "Next we analyze how much benefit our new set prediction strategy brings in.", "labels": [], "entities": [{"text": "set prediction", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.7924153506755829}]}, {"text": "For each RNNbased method, we test two prediction strategies: 1) finding the sequence with the highest probability and outputting the corresponding set (this is the default prediction strategy for all models except set-RNN); 2) outputting the set with the highest probability (this is the default prediction strategy for set-RNN).", "labels": [], "entities": []}, {"text": "shows how each method performs with these two prediction strategies.", "labels": [], "entities": []}, {"text": "One can see that Vinyals-RNN-uniform and set-RNN benefit most from predicting the top set, Vinyals-RNN-sample, Vinyals-RNN-max and Vinyals-RNN-max-direct benefit less, and seq2seq RNN does not benefit at all.", "labels": [], "entities": []}, {"text": "Intuitively, for the top-set prediction to be different from the topsequence prediction, the model has to spread probability mass across different sequence permutations of the same set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the datasets.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of different approaches. \"-\" means result not available. For hamming loss, the lower the  value is, the better the model performs. For all other measures, the higher the better.", "labels": [], "entities": []}, {"text": " Table 4: Predicting the most probable sequence vs. predicting the most probable set. Numbers before the arrow:  predicting the most probable sequence. Numbers after the arrow: predicting the most probable set. We highlight  scores which get significantly improved in bold (improvement is larger than 0.01).", "labels": [], "entities": []}]}