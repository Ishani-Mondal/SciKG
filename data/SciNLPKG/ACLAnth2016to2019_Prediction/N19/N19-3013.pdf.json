{"title": [{"text": "Deep Learning and Sociophonetics: Automatic Coding of Rhoticity Using Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Automated extraction methods are widely available for vowels (Rosenfelder et al., 2014), but automated methods for coding rhoticity have lagged far behind.", "labels": [], "entities": []}, {"text": "R-fulness versus r-lessness (in words like park, store, etc.) is a classic and frequently cited variable (Labov, 1966), but it is still commonly coded by human analysts rather than automated methods.", "labels": [], "entities": []}, {"text": "Human-coding requires extensive resources and lacks replicability, making it difficult to compare large datasets across research groups (Yaeger-Dror et al., 2008; Heselwood et al., 2008).", "labels": [], "entities": []}, {"text": "Can reliable automated methods be developed to aid in coding rhoticity?", "labels": [], "entities": [{"text": "coding rhoticity", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.8995455205440521}]}, {"text": "In this study, we use Neural Networks/Deep Learning , training our model on 208 Boston-area speakers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite advances in automation for phonetic alignment and extraction of vowel formants, there is still no reliable automated method for classifying r-dropping, that is, whether a given word is pronounced with an /r/ in words like park (pahk), start (staht), and soon.", "labels": [], "entities": [{"text": "phonetic alignment", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7080214023590088}]}, {"text": "R-dropping, also known as non-rhotic speech, is an important sociolinguistic variable in modern dialect research.", "labels": [], "entities": []}, {"text": "But unfortunately most researchers continue to depend on human judgments, which is an inconsistent and time-consuming method that lacks replicability.", "labels": [], "entities": []}, {"text": "Turning to the field of machine learning, our deep learning approach investigates anew way to distinguish rhotic versus non-rhotic pronunciations in recorded data.", "labels": [], "entities": []}, {"text": "This is the first study to use neural networks to classify rhotic versus non-rhotic speech.", "labels": [], "entities": []}, {"text": "Although human-coding requires extensive resources and lacks consistency and replicability), making it difficult to compare large datasets across different research groups, it is the only method we have right now.", "labels": [], "entities": [{"text": "consistency", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.9584362506866455}]}, {"text": "How soon will computers be able to quickly and reliably code rhoticity up to this standard?", "labels": [], "entities": []}, {"text": "In terms of other machine learning approaches, McLarty, Jones, and Hall work on this challenge using Support Vector Machines (SVMs) ().", "labels": [], "entities": []}, {"text": "The present study uses Neural Networks/Deep Learning, one of the most effective and fastest-growing approaches in machine-learning.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first attempt to use neural networks for automatic coding of any sociophonetic variable.", "labels": [], "entities": []}, {"text": "This new method was developed using audio recordings from over 200 New England speakers from Boston, Maine, and central New Hampshire (Stanford, forthcoming), and is here compared to other work on rhoticity (.", "labels": [], "entities": []}, {"text": "In what ways can neural networks be effective tools in assisting the coding of rhoticity?", "labels": [], "entities": [{"text": "coding of rhoticity", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8573275605837504}]}, {"text": "To what level can they perform compared to traditional coding methods and other approaches?", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Metrics showing the performance of different  models -our top performing model was using GRUs  with MFCCs as input (as described previously).", "labels": [], "entities": []}]}