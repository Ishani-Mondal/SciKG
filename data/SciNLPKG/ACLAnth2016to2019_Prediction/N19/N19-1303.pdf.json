{"title": [], "abstractContent": [{"text": "Language is gendered if the context surrounding a mention is suggestive of a particular binary gender for that mention.", "labels": [], "entities": []}, {"text": "Detecting the different ways in which language is gendered is an important task since gendered language can bias NLP models (such as for coreference resolution).", "labels": [], "entities": [{"text": "Detecting", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9614578485488892}, {"text": "coreference resolution", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.9671646654605865}]}, {"text": "This task is challenging since gen-deredness is often expressed in subtle ways.", "labels": [], "entities": []}, {"text": "Existing approaches need considerable annotation efforts for each language, domain, and author, and often require handcrafted lexicons and features.", "labels": [], "entities": []}, {"text": "Additionally, these approaches do not provide a quantifiable measure of how gendered the text is, nor are they applicable at the fine-grained mention level.", "labels": [], "entities": []}, {"text": "In this paper, we use existing NLP pipelines to automatically annotate gender of mentions in the text.", "labels": [], "entities": []}, {"text": "On corpora labeled using this method, we train a supervised classifier to predict the gender of any mention from its context and evaluate it on unseen text.", "labels": [], "entities": []}, {"text": "The model confidence fora mention's gender can be used as a proxy to indicate the level of gendered-ness of the context.", "labels": [], "entities": []}, {"text": "We test this gendered language detector on movie summaries, movie reviews , news articles, and fiction novels, achieving an AUC-ROC of up to 0.71, and observe that the model predictions agree with human judgments collected for this task.", "labels": [], "entities": [{"text": "AUC-ROC", "start_pos": 124, "end_pos": 131, "type": "METRIC", "confidence": 0.9986345171928406}]}, {"text": "We also provide examples of detected gendered sentences from aforementioned domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language can be extraordinarily gendered.", "labels": [], "entities": []}, {"text": "Genderedness in language is when we use words or phrases that are stereotypical or indicative of a particular gender (we only consider male vs female in this work).", "labels": [], "entities": []}, {"text": "It is important to detect this bias in language since not only is this bias propagated to the readers (, but also machine learning algorithms trained on gendered corpora tend to become biased (, often aggravating the disparity (.", "labels": [], "entities": []}, {"text": "Bias in language and machine learning systems can lead to unfair treatment, e.g., early work by shows that males have an advantage in contexts where they are referred to by a putative neutral term.", "labels": [], "entities": []}, {"text": "Recent work on coreference resolution systems ( shows that bias in machine learning systems originates from training on existing corpora, resulting in malestereotyped professions like surgeon and president incorrectly resolved to males instead of females.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.966084748506546}]}, {"text": "Such biases in machine learning systems can lead to unintentional biases in downstream tasks producing effects like preferential treatment to male candidates over female candidates when selecting resumes.", "labels": [], "entities": []}, {"text": "Detecting these biases is the first step in finding a solution.", "labels": [], "entities": [{"text": "Detecting", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9540520906448364}]}, {"text": "Most of the current works for related problems tend to be domain-specific (, rely on techniques such as simple counting of gender occurrences (, or use manually constructed lexicons and features for analysis, and thus do not generalize well and require expensive manual supervision.", "labels": [], "entities": []}, {"text": "Existing approaches also tend to either focus on the whole corpus/article being gendered () or a specific word being gendered, thus failing to capture the subtle occurrences of genderedness at mention-level or giving a quantifiable measure of how gendered the text is.", "labels": [], "entities": []}, {"text": "In this paper, we develop a method that eliminates the manual annotation requirement, and can generalize to words, phrases, sentences, articles, as well as whole corpora.", "labels": [], "entities": []}, {"text": "We present a framework for automated data labeling by combining existing NLP pipelines to identify sentence boundaries and mentions (using NER tagger) and using a gen-Female Their client is who has got gorgeous hair.", "labels": [], "entities": [{"text": "automated data labeling", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.6285490393638611}]}, {"text": "Male intends to marry lovely Gauri.", "labels": [], "entities": []}, {"text": "Female Raja intends to marry lovely . der classifier for names to get the gender of the mentions.", "labels": [], "entities": []}, {"text": "We build a classifier using this annotation to predict gender of a mention only from its context and quantitatively analyze the genderedness of various contexts using this model.", "labels": [], "entities": []}, {"text": "shows example inputs and outputs for our model.", "labels": [], "entities": []}, {"text": "Input to the model is the context sentence around a target mention (indicated by colored boxes), and the model prediction is the gender of this mention.", "labels": [], "entities": []}, {"text": "For the first sentence, the model uses context information coming from 'gorgeous hair' to predict the gender of mention to be female, indicating a more gendered sentence.", "labels": [], "entities": []}, {"text": "Similarly for the third sentence, model uses contextual information from the adjective 'lovely' and its proximity to the target mention to predict female.", "labels": [], "entities": []}, {"text": "For the second sentence, the target mention is subject for the verb in phrase 'intends to marry' and the object to be married is 'lovely Gauri'.", "labels": [], "entities": []}, {"text": "Our model uses this information to predict gender of target mention as male.", "labels": [], "entities": []}, {"text": "Since our data labeling pipeline is automated, we can easily annotate millions of documents and train complex classifiers that can accurately model the context.", "labels": [], "entities": []}, {"text": "These classifiers can be used to predict the gender of a mention from given context and quantify genderedness.", "labels": [], "entities": []}, {"text": "We present instantiations of this framework on four domains: news articles, novels, movie summaries, and movie reviews.", "labels": [], "entities": [{"text": "movie summaries", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.6172893643379211}]}, {"text": "Since we are the first to study the task of mention-level gender detection, we evaluate the difficulty of the task and introduce the first benchmark using a user study.", "labels": [], "entities": [{"text": "mention-level gender detection", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.7127915620803833}]}, {"text": "We find that the task is challenging, and our model predictions corroborate with human predictions.", "labels": [], "entities": []}, {"text": "We present qualitative results of our model showing genderedness at different granularitiesword, phrase, sentence, and corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we give details about the datasets, our pipeline for automated data labeling, filtering and processing applied to contexts in order to remove obvious gender information, and the classifiers used to classify gender of a given mention.", "labels": [], "entities": []}, {"text": "To illustrate the utility of our proposed approach, we analyze text from four different domains: \u2022 New York Times articles from the Annotated Gigaword corpus (Napoles et al., 2012) \u2022 Novels from Gutenberg corpus \u2022 IMDB Movie Reviews ( \u2022 Movie Summaries () These domains cover a variety of writing styles.", "labels": [], "entities": [{"text": "Movie Summaries", "start_pos": 237, "end_pos": 252, "type": "TASK", "confidence": 0.6558537632226944}]}, {"text": "While the novels represent fictional writing, news articles are non-fictional.", "labels": [], "entities": []}, {"text": "Movie summaries dataset describes the plot of the movies, i.e., how gender is represented in the plots, and the movie reviews dataset provides the ways in which people express their views on the plots, i.e., how gender is represented in user perception of the movie.", "labels": [], "entities": [{"text": "Movie summaries dataset", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.7325804432233175}]}, {"text": "We train classifiers for each domain to predict the gender of mentions from the context they appear in, and use the resulting classifiers to detect gendered language.", "labels": [], "entities": []}, {"text": "Similar idea is explored in to detect the type of mention from the context.", "labels": [], "entities": []}, {"text": "For news, data from the first 6 months for every year is used for training, next three for validation, and last three for testing.", "labels": [], "entities": []}, {"text": "For novels and movie summaries, we divide the data randomly into 50 : 20 : 30 split for train, validation 1 Miss Mary Briganza will go to Korea with her parents.", "labels": [], "entities": []}, {"text": "2 Miss <female> will go to Korea with her parents.", "labels": [], "entities": []}, {"text": "3 <Title> <female> will go to Korea with <their> parents.", "labels": [], "entities": []}, {"text": "4 <Title> will go to Korea with <Their> parents.", "labels": [], "entities": []}, {"text": "Figure 3: Annotation pipeline.", "labels": [], "entities": []}, {"text": "We show the annotation and data processing pipeline step-by-step.", "labels": [], "entities": []}, {"text": "1 is the original sentence.", "labels": [], "entities": []}, {"text": "2 is the sentence after detecting positions of all mentions in the sentence, and replacing them with a placeholder for gender of that mention.", "labels": [], "entities": []}, {"text": "3 is the sentence after removing obvious gender information such as replacing gendered-pronouns (he, she) with a gender-neutral pronoun (them), and titles Mr., Mrs., Miss with a placeholder title word.", "labels": [], "entities": []}, {"text": "4 is the final input to our classifier where is the position of mention for which classifier needs to predict gender (male or female). and test data.", "labels": [], "entities": []}, {"text": "For movie reviews, we use the predefined split for train and test data, further dividing the training data into training and validation data.", "labels": [], "entities": []}, {"text": "Labeling Gender for Mentions We illustrate our processing pipeline via the example sentence in.", "labels": [], "entities": [{"text": "Labeling Gender for Mentions", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8487644642591476}]}, {"text": "For mention-level gender prediction, we need a dataset with identified person mentions and their genders.", "labels": [], "entities": [{"text": "mention-level gender prediction", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.6624265909194946}]}, {"text": "Since we do not have labeled data, we need to identify mentions in contexts, and assign gender labels to them.", "labels": [], "entities": []}, {"text": "Along with pronouns 'he' and 'she', we use spacy 3 to tag all corpora with NER tags to identify the set of person mentions.", "labels": [], "entities": []}, {"text": "We use the SSN baby names dataset 4 from 1880 to 2016 to assign gender to each name.", "labels": [], "entities": [{"text": "SSN baby names dataset 4 from 1880 to 2016", "start_pos": 11, "end_pos": 53, "type": "DATASET", "confidence": 0.9091053207715353}]}, {"text": "If a name is associated with more than one sex, we exclude it if it is ambiguous (being less than 4 times more frequent for one sex), but otherwise assign it to the more frequent sex.", "labels": [], "entities": []}, {"text": "If a name is absent from our list of names, we replace the mention with a placeholder <Person>.", "labels": [], "entities": []}, {"text": "shows the count of male and female mention-context pairs generated using this pipeline.", "labels": [], "entities": []}, {"text": "Processed sentence after this step is sentence 2 in.", "labels": [], "entities": []}, {"text": "Filtering and Input Context Processing To remove obvious, uninteresting gender information, we discard sentences that contain any word from a gender-specific lexicon as used by  such as gender-specific occupation words and gender-specific familial relation words, e.g., 'man', 'woman', 'prince', and 'hostess'.", "labels": [], "entities": []}, {"text": "Complete list is given in Appendix A. For contexts that contain gender-indicative pronounshers', 'himself', 'herself'), we replace them with a gender-neutral pronoun ('them', 'their').", "labels": [], "entities": []}, {"text": "All other mentions in the context (including 'he' and 'she') are replaced with a gender neutral word, and titles ('Mr','Mrs','Miss') are replaced with a genderneutral title word.", "labels": [], "entities": []}, {"text": "Sentence 3 in is the result after this stage.", "labels": [], "entities": [{"text": "Sentence", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9025353789329529}]}, {"text": "To assess the difficulty of this task and to compare performance of our gendered language detector against a human baseline, we use Amazon Mechanical Turk to get human annotations for 500 random sentences from the test sets of each domain.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 132, "end_pos": 154, "type": "DATASET", "confidence": 0.9124676783879598}]}, {"text": "Task Description Turkers are shown sentences with missing mention, e.g., 'Sandwich maker said mojo and fresh roasted pork are key to a great Cuban sandwich', and are asked to guess the gender of the missing mention.", "labels": [], "entities": []}, {"text": "We sample the sentences such that the true labels (male/female) are balanced.", "labels": [], "entities": []}, {"text": "For our study, we use two tasks that slightly differ from one another in the decisions turkers need to make.", "labels": [], "entities": []}, {"text": "In one task, turkers are given only two options, male and female, forcing them to make a choice.", "labels": [], "entities": []}, {"text": "In the second task, turkers are given five options on the Likert scale: extremely likely male, likely male, neutral, likely female, extremely likely female allowing fora finer scale of decision.", "labels": [], "entities": [{"text": "Likert scale", "start_pos": 58, "end_pos": 70, "type": "METRIC", "confidence": 0.9538697004318237}]}, {"text": "We include examples in the instructions, and a few extremely easy examples as probes to verify quality (.", "labels": [], "entities": []}, {"text": "Each worker is shown 35 sentences from a single domain.", "labels": [], "entities": []}, {"text": "On average, we collect 7 human annotations per sentence.", "labels": [], "entities": []}, {"text": "Do humans predict gender well?", "labels": [], "entities": []}, {"text": "Sentences that do not have a clear majority are removed from our analysis.", "labels": [], "entities": []}, {"text": "As a measure of inter-rater reliability, we compute pairwise and majority agreement, in.", "labels": [], "entities": []}, {"text": "Percentage improvement over chance agreement is higher for 5-scale rating compared to 2-scale rating indicating that users tend to agree more when they are able to tag the borderline (possibly confusing) mentions as gender-neutral (chance agreement is 0.5 for 2-scale, and 0.2 for: Pairwise and majority inter-annotator agreement for instances with clear majority.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9585870504379272}]}, {"text": "2-Scale indicates when users are asked to indicate male or female, while 5-Scale indicates gender on a scale of 5.", "labels": [], "entities": []}, {"text": "x-axis represents the human prediction for mentions, while the green and pink bars represent counts of true male and female mentions respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset details. Number of male and female  mentions in the different datasets are shown.", "labels": [], "entities": []}, {"text": " Table 2: AUC-ROCs for different models (evaluated  on test data).", "labels": [], "entities": [{"text": "AUC-ROCs", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.6659635901451111}]}, {"text": " Table 3: Pairwise and majority inter-annotator  agreement for instances with clear majority. 2-Scale  indicates when users are asked to indicate male or fe- male, while 5-Scale indicates gender on a scale of 5.", "labels": [], "entities": [{"text": "Pairwise", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9749234318733215}]}]}