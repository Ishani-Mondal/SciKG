{"title": [{"text": "Enhancing Key-Value Memory Neural Networks for Knowledge Based Question Answering", "labels": [], "entities": [{"text": "Knowledge Based Question Answering", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.6154434308409691}]}], "abstractContent": [{"text": "Traditional Key-value Memory Neural Networks (KV-MemNNs) are proved to be effective to support shallow reasoning over a collection of documents in domain specific Question Answering or Reading Comprehension tasks.", "labels": [], "entities": [{"text": "Question Answering or Reading Comprehension tasks", "start_pos": 163, "end_pos": 212, "type": "TASK", "confidence": 0.8236870567003886}]}, {"text": "However, extending KV-MemNNs to Knowledge Based Question Answering (KB-QA) is not trivia, which should properly decompose a complex question into a sequence of queries against the memory, and update the query representations to support multi-hop reasoning over the memory.", "labels": [], "entities": [{"text": "Knowledge Based Question Answering (KB-QA)", "start_pos": 32, "end_pos": 74, "type": "TASK", "confidence": 0.7477788754871914}]}, {"text": "In this paper, we propose a novel mechanism to enable conventional KV-MemNNs models to perform in-terpretable reasoning for complex questions.", "labels": [], "entities": []}, {"text": "To achieve this, we design anew query updating strategy to mask previously-addressed memory information from the query representations , and introduce a novel STOP strategy to avoid invalid or repeated memory reading without strong annotation signals.", "labels": [], "entities": []}, {"text": "This also enables KV-MemNNs to produce struc-tured queries and work in a semantic parsing fashion.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 73, "end_pos": 89, "type": "TASK", "confidence": 0.7405507266521454}]}, {"text": "Experimental results on benchmark datasets show that our solution, trained with question-answer pairs only, can provide conventional KV-MemNNs models with better reasoning abilities on complex questions, and achieve state-of-art performances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Memory Neural Networks (MemNNs) area family of neural network models that aim to learn how to reason with a long-term memory component and various inference components.", "labels": [], "entities": []}, {"text": "The memory component serves as a knowledge base to recall facts from the past.", "labels": [], "entities": []}, {"text": "MemNNs have been successfully applied in many natural language processing applications such as question answering and reading comprehension (RC).", "labels": [], "entities": [{"text": "question answering and reading comprehension (RC)", "start_pos": 95, "end_pos": 144, "type": "TASK", "confidence": 0.6690396033227444}]}, {"text": "Recently, proposed a variant of MemNNs, namely Key-Value Memory Neural Networks (KV-MemNNs), which generalizes the original MemNNs by storing facts in a key-value structured memory.", "labels": [], "entities": []}, {"text": "illustrates the basic architecture of KV-MemNNs, which consists of five components.", "labels": [], "entities": []}, {"text": "The question is first fed to the Embedding component and the Hashing component.", "labels": [], "entities": []}, {"text": "The former converts the incoming question to an internal feature representation.", "labels": [], "entities": []}, {"text": "The Hashing component uses the question to pre-select a list of facts to compose the key-value memory.", "labels": [], "entities": [{"text": "Hashing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9592632055282593}]}, {"text": "The Key Addressing component takes the input question representation and the current memory to compute the relevance probability between the question and each key in the memory.", "labels": [], "entities": []}, {"text": "The Value Reading component reads the values of all addressed memories by taking their weighted sum using the relevance probabilities.", "labels": [], "entities": []}, {"text": "The obtained value representation is then added to the query representation to change the query focus for the next round of memory reading.", "labels": [], "entities": []}, {"text": "After multiple hops of reasoning over the memories, the final value representation is treated as the answer representation to perform the final prediction overall candidate answers in the Rank-ing component.", "labels": [], "entities": []}, {"text": "The KV-MemNNs have been shown to support shallow reasoning in domain-specific knowledge based question answering (KB-QA) tasks such as MovieQA.", "labels": [], "entities": [{"text": "domain-specific knowledge based question answering (KB-QA) tasks", "start_pos": 62, "end_pos": 126, "type": "TASK", "confidence": 0.7039643095599281}, {"text": "MovieQA", "start_pos": 135, "end_pos": 142, "type": "DATASET", "confidence": 0.8992033004760742}]}, {"text": "However, when applied to a more challenging scenario, e.g., open domain KB-QA, the KV-MemNNs models do not perform as well as expected, possibly due to two reasons.", "labels": [], "entities": []}, {"text": "First of all, the focus of conventional KVMemNNs is about understanding the facts in the memory rather than properly understanding the questions, where the latter requires incrementally decomposing a complex natural language question into a set of focused queries with the help of the facts in the memory.", "labels": [], "entities": []}, {"text": "However, in open domain KB-QA, questions are usually more complicated, e.g., multi-relation questions such as who does maggie grace play in taken, where more than one entity and relation are mentioned.", "labels": [], "entities": []}, {"text": "Secondly, as shown in, KV-MemNNs usually work in an information retrieval (IR) fashion, which first retrieve a set of candidate answers from KB, then rank them by computing the similarity between the value representation and candidates, and finally select the top one or a fixed number of top candidates as the answer.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.7548532247543335}]}, {"text": "We can imagine that it is not trivial for such IR-styled KV-MemNNs to properly resolve complex constraints from natural language questions, or to handle questions with multiple answers.", "labels": [], "entities": []}, {"text": "We believe that an ideal framework for open domain KB-QA should first understand the natural language questions, explicitly represent the meaning, and make the answer retrieval process more interpretable.", "labels": [], "entities": []}, {"text": "To build such an interpretable KVMemNN KB-QA model, we need to deal with the following challenges: (1) KV-MemNNs often read the memory repeatedly since they do not know when to stop; (2) during multiple memory readings, conventional KV-MemNNs often fail to precisely update the queries for multi-relation questions; (3) strong annotations are usually required to train an interpretable QA model, e.g., the supervision for the memory selection at each hop.", "labels": [], "entities": []}, {"text": "To address the challenges, we propose a novel solution to make conventional KV-MemNNs feasible to open domain KB-QA.", "labels": [], "entities": []}, {"text": "In particular, we introduce a flexible KV-MemNN solution that can work in both the IR and semantic parsing style with large-scale memory.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.6641989946365356}]}, {"text": "To this end, we first present a novel query updating method that is able to decompose complex questions and precisely address a relevant key at each hop.", "labels": [], "entities": []}, {"text": "Secondly, we introduce anew STOP strategy during memory readings, which imports a special key STOP into the memory and guides our model to avoid repeated or invalid memory readings.", "labels": [], "entities": [{"text": "STOP", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.914426863193512}]}, {"text": "In addition, our proposed model can learn to reason over memory slots with weak supervision, e.g., questionanswer pairs only, opposing the strong supervision that most current neural semantic parsers demand, which incurs high labor costs.", "labels": [], "entities": []}, {"text": "Experimental results on two benchmark datasets show that our proposed model cannot only enhance the reasoning capability of KV-MemNNs, but also be flexible enough to work as a semantic parser, with state-of-the-art performances.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our model on two benchmark datasets to investigate whether our enhanced KV-MemNNs model can better perform reasoning over the memory in the open domain KB-QA task, and whether it can make the QA procedure more interpretable.", "labels": [], "entities": []}, {"text": "Semantic Paring Method Answer F1 Berant et al.", "labels": [], "entities": [{"text": "Semantic Paring", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.5800182521343231}]}, {"text": "35.7% 39.9% Yih et al.", "labels": [], "entities": []}, {"text": "52.5% Bast and Haussmann 49.4% Xu et al.", "labels": [], "entities": [{"text": "Bast", "start_pos": 6, "end_pos": 10, "type": "TASK", "confidence": 0.9029593467712402}]}], "tableCaptions": [{"text": " Table 1: The performance of different models on the  test set of WebQuestions.", "labels": [], "entities": []}, {"text": " Table 3:  Performance (answer F 1 ) of  STOP+KVQU+SQ and STOP+KVQU+AR with  different hop sizes on the development set of  WebQuestions.", "labels": [], "entities": []}, {"text": " Table 4: Results of the models on the test set of QALD.", "labels": [], "entities": [{"text": "QALD", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.5982571244239807}]}, {"text": " Table 2. We failed to perform reason- ing over the time constraint 2011 due to limited  context left for 2011 after we addressed play for  in earlier hops. Also due to this same reason, our  model can not correctly answer the second ques- tion in", "labels": [], "entities": []}]}