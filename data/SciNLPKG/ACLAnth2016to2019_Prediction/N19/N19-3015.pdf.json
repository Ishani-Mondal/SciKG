{"title": [{"text": "Expectation and Locality Effects in the Prediction of Disfluent Fillers and Repairs in English Speech", "labels": [], "entities": [{"text": "Prediction of Disfluent Fillers and Repairs in English Speech", "start_pos": 40, "end_pos": 101, "type": "TASK", "confidence": 0.7378495335578918}]}], "abstractContent": [{"text": "This study examines the role of three influential theories of language processing, viz., Surprisal Theory, Uniform Information Density (UID) hypothesis and Dependency Locality Theory (DLT), in predicting disfluencies in speech production.", "labels": [], "entities": []}, {"text": "To this end, we incorporate features based on lexical surprisal, word duration and DLT integration and storage costs into logistic regression classifiers aimed to predict disfluencies in the Switchboard corpus of En-glish conversational speech.", "labels": [], "entities": [{"text": "Switchboard corpus of En-glish conversational speech", "start_pos": 191, "end_pos": 243, "type": "DATASET", "confidence": 0.8930301666259766}]}, {"text": "We find that dis-fluencies occur in the face of upcoming difficulties and speakers tend to handle this by lessening cognitive load before disfluencies occur.", "labels": [], "entities": []}, {"text": "Further, we see that reparandums behave differently from disfluent fillers possibly due to the lessening of the cognitive load also happening in the word choice of the reparandum, i.e., in the disfluency itself.", "labels": [], "entities": []}, {"text": "While the UID hypothesis does not seem to play a significant role in disfluency prediction, lexical surprisal and DLT costs do give promising results in explaining language production.", "labels": [], "entities": [{"text": "disfluency prediction", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.8280455768108368}]}, {"text": "Further, we also find that as a means to lessen cognitive load for upcoming difficulties speakers take more time on words preceding disfluencies, making duration a key element in understanding disflu-encies.", "labels": [], "entities": [{"text": "duration", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9880205988883972}]}], "introductionContent": [{"text": "In contrast to written text which can be rewritten or edited, speech happens spontaneously making it more prone to mistakes.", "labels": [], "entities": []}, {"text": "Speakers tend not to speak fluently and take pauses or even repeat words.", "labels": [], "entities": []}, {"text": "Such errors where speakers interrupt their flow of speech are known as disfluencies.", "labels": [], "entities": []}, {"text": "One of the primary reasons for speech disfluencies is difficulties in language production.", "labels": [], "entities": [{"text": "speech disfluencies", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.6937261521816254}]}, {"text": "In this study, we aim to understand the role of disfluencies and classify disfluencies into two categories namely, disfluent fillers and reparandums.", "labels": [], "entities": []}, {"text": "Disfluent fillers are utterances like uh, um which break fluency by interjecting and creating an interruption between words.", "labels": [], "entities": []}, {"text": "For example, suppose a speaker says \"thinking about the uh day when I\".", "labels": [], "entities": []}, {"text": "Here, there is a break of fluency between the words the and day due to the interjection of the filler uh.", "labels": [], "entities": []}, {"text": "Reparandums involve cases where speakers break fluency by making corrections in their speech.", "labels": [], "entities": [{"text": "Reparandums", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.973783016204834}]}, {"text": "For example, when a speaker says \"Go to the righ-to the left\".", "labels": [], "entities": []}, {"text": "Here, the speaker makes a correction to to the righ-by restarting with the intended (corrected) speech to the left.", "labels": [], "entities": [{"text": "righ-by", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9881149530410767}]}, {"text": "We call the words to be corrected as the reparandum (to the righ-) and the correction the speaker follows with as the repair (to the left).", "labels": [], "entities": [{"text": "righ-)", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9452290534973145}, {"text": "repair", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.963841438293457}]}, {"text": "In order to study disfluencies, we use transcribed data from the Switchboard corpus, a corpus of fully spontaneous speech of American English.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 65, "end_pos": 83, "type": "DATASET", "confidence": 0.9153343439102173}]}, {"text": "We focus on testing the role of three influential linguistic theories, viz., Surprisal Theory (), Uniform Information Density (UID) hypothesis (Jaeger and and Dependency Locality Theory) in accounting for disfluencies.", "labels": [], "entities": []}, {"text": "Surprisal Theory defines an information-theoretic measure of comprehension difficulty viz., surprisal.", "labels": [], "entities": [{"text": "Surprisal Theory", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7336330115795135}]}, {"text": "Recently, showed that syntactic surprisal is a significant predictor of word duration in spontaneous speech even amidst the presence of competing controls like lexical frequency.", "labels": [], "entities": []}, {"text": "Thus surprisal can be used to model language production as well, with words with high surprisal associated with speech disfluencies i.e., fillers and repairs.", "labels": [], "entities": []}, {"text": "The UID hypothesis predicts that in language production, speakers prefer to minimize variation of information density (mathematically same as surprisal) across the speech signal.", "labels": [], "entities": []}, {"text": "Thus based on the UID hypothesis, it is plausible to assume that disfluencies are associated with higher informa-tion density variation.", "labels": [], "entities": []}, {"text": "Finally, DLT posits integration and storage costs as measures of comprehension difficulty.", "labels": [], "entities": []}, {"text": "showed that for English relative clause production, locality results in greater speech disfluencies and starting time for object relatives compared to subject relatives.", "labels": [], "entities": [{"text": "English relative clause production", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.6034217402338982}]}, {"text": "Thus, we conceive higher values of integration and storage costs leading to disfluencies in language production.", "labels": [], "entities": []}, {"text": "We predict disfluencies in the Switchboard corpus using a one-vs-all logistic regression classifier containing features based on lexical surprisal, UID, DLT-inspired costs and duration.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 31, "end_pos": 49, "type": "DATASET", "confidence": 0.9020139873027802}, {"text": "duration", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9844672679901123}]}, {"text": "Further, by looking into the classifier's regression weights and accuracies, we get an insight behind how these theories affect disfluencies in speech.", "labels": [], "entities": []}, {"text": "Our results do not uncover evidence to indicate UID hypothesis plays a significant role in disfluency prediction; however, lexical surprisal and DLT costs do give promising results in explaining language production.", "labels": [], "entities": [{"text": "disfluency prediction", "start_pos": 91, "end_pos": 112, "type": "TASK", "confidence": 0.860381156206131}]}, {"text": "The latter two theories indicate that disfluencies tend to be followed with upcoming difficulties and speakers lower cognitive load on words preceding these disfluencies to ease this difficulty.", "labels": [], "entities": []}, {"text": "Apart from these three theories, we look into how duration behaves in disfluent contexts and find that speakers take more time in words preceding disfluencies which we explain as a means to lower cognitive load for upcoming difficulties by buying more processing time.", "labels": [], "entities": []}, {"text": "Further, we see that reparandums do not occur prior to words with lower surprisal like in the case of disfluent fillers.", "labels": [], "entities": []}, {"text": "This effect maybe due to the lessening of the cognitive load also happening in the word choice of the reparandum, i.e., in the disfluency itself.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our study focuses on 3 classes of words in the Switchboard corpus: reparandum, disfluent filler and fluent word.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.8492711186408997}]}, {"text": "We use the corpus provided by the switchboard NXT project) and base our features for machine learning from the fluent words that immediately follow or precede these disfluencies (for reparandum based disfluencies, these are taken as the words that immediately follow repair and precede the reparandum), this was done out of uniformity as disfluencies such as a disfluent filler uh do not posses the The change inaccuracy relative to the baseline on adding features, viz., lexical surprisal, UID, DLT costs and duration, tells us whether these theories explain the presence of disfluent contexts.", "labels": [], "entities": [{"text": "UID", "start_pos": 491, "end_pos": 494, "type": "METRIC", "confidence": 0.8797387480735779}, {"text": "duration", "start_pos": 510, "end_pos": 518, "type": "METRIC", "confidence": 0.9975213408470154}]}, {"text": "Further, using the regression weights we look at whether the correlations are indeed as the theory expects.", "labels": [], "entities": []}, {"text": "The next three subsections will describe these results in depth.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy and weights for lexical surprisal.  Here * denotes p-value < 0.05 and ** denotes p-value  < 0.01 for McNemar's test relative to the baseline.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985659718513489}, {"text": "McNemar's test", "start_pos": 120, "end_pos": 134, "type": "DATASET", "confidence": 0.782623291015625}]}, {"text": " Table 2: Accuracy for UID measures.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984017014503479}, {"text": "UID", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.7773141264915466}]}, {"text": " Table 3: Accuracy and weights for DLT costs.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990612864494324}, {"text": "DLT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9039373993873596}]}, {"text": " Table 4: Accuracy and weights for duration features.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993355870246887}, {"text": "duration", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.966092586517334}]}]}