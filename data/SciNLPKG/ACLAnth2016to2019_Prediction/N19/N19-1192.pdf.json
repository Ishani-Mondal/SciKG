{"title": [{"text": "Online Distilling from Checkpoints for Neural Machine Translation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.6880944569905599}]}], "abstractContent": [{"text": "Current predominant neural machine translation (NMT) models often have a deep structure with large amounts of parameters, making these models hard to train and easily suffering from over-fitting.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.8581979870796204}]}, {"text": "A common practice is to utilize a validation set to evaluate the training process and select the best checkpoint.", "labels": [], "entities": []}, {"text": "Average and ensemble techniques on checkpoints can lead to further performance improvement.", "labels": [], "entities": []}, {"text": "However, as these methods do not affect the training process, the system performance is restricted to the checkpoints generated in the original training procedure.", "labels": [], "entities": []}, {"text": "In contrast, we propose an online knowledge distillation method.", "labels": [], "entities": [{"text": "online knowledge distillation", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.6849452257156372}]}, {"text": "Our method on-the-fly generates a teacher model from checkpoints, guiding the training process to obtain better performance.", "labels": [], "entities": []}, {"text": "Experiments on several datasets and language pairs show steady improvement over a strong self-attention-based baseline system.", "labels": [], "entities": []}, {"text": "We also provide analysis on data-limited setting against over-fitting.", "labels": [], "entities": []}, {"text": "Furthermore, our method leads to an improvement on a machine reading experiment as well.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT) () has been rapidly developed during the past several years.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8202258547147115}]}, {"text": "For further performance improvement, deeper and more expressive structures) have been exploited.", "labels": [], "entities": []}, {"text": "However, all of these models have more than hundreds of millions of parameters, which makes the training process more challenging.", "labels": [], "entities": []}, {"text": "During the training of NMT models, we notice the following two problematic phenomena: First, the training process is unstable.", "labels": [], "entities": []}, {"text": "This is evidenced by the decreasing of training loss with * Corresponding Author.", "labels": [], "entities": [{"text": "training loss", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.9553273022174835}]}, {"text": "fluctuate performance on the validation set.", "labels": [], "entities": [{"text": "validation", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.954699695110321}]}, {"text": "Second, the performance on validation set usually begins to worsen after several epochs, while the training loss keeps decreasing, which suggests the model being at risk of over-fitting.", "labels": [], "entities": []}, {"text": "In order to alleviate these issues, the common practice is to periodically evaluate models on a held-out set (with each evaluated model saved as a checkpoint).", "labels": [], "entities": []}, {"text": "Training is terminated when m consecutive checkpoints show no improvement and select the checkpoint with best evaluation score as the final model.", "labels": [], "entities": []}, {"text": "Further improvement can be achieved by utilizing more checkpoints, by smoothing, which averages these checkpoints' parameters to generate more desirable parameters (Sennrich et al., 2016a); or by ensemble, which averages these checkpoints' output probabilities at every step during inference . However, we notice that all of these methods have a limitation.", "labels": [], "entities": []}, {"text": "Once the training process gets parameters with poor performance, selecting, smoothing or ensemble from the checkpoints in this process may have limited generalization performance as well.", "labels": [], "entities": []}, {"text": "We impute the limitation to the \"offline\" property of these methods.", "labels": [], "entities": []}, {"text": "In other words, only employing checkpoints after training cannot affect the original training process.", "labels": [], "entities": []}, {"text": "In this paper, we propose to utilize checkpoints to lead the training process.", "labels": [], "entities": []}, {"text": "Our method is carried out in a knowledge distillation manner.", "labels": [], "entities": []}, {"text": "At each training step, because being evaluated on the heldout validation data, the best checkpoint up to the current training step can be seen as a model with the best generalization ability so far.", "labels": [], "entities": []}, {"text": "Therefore, we employ this checkpoint as the teacher model, and let the current training model, as the student, learn from the output probability distributions of the teacher model, as well as truth translations in the training data.", "labels": [], "entities": []}, {"text": "Such kind of knowledge distillation is performed on-the-fly because the teacher model could always be updated once any latest better checkpoint is generated.", "labels": [], "entities": [{"text": "knowledge distillation", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7401095926761627}]}, {"text": "We call our method Online Distillation from Checkpoints (ODC).", "labels": [], "entities": [{"text": "Online Distillation from Checkpoints (ODC)", "start_pos": 19, "end_pos": 61, "type": "TASK", "confidence": 0.8162208497524261}]}, {"text": "We conduct experiments on four translation tasks (including two low-resource tasks), and one machine reading comprehension task.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.9073164761066437}, {"text": "machine reading comprehension task", "start_pos": 93, "end_pos": 127, "type": "TASK", "confidence": 0.770285502076149}]}, {"text": "All the results demonstrate that our ODC method can achieve improvement upon strong baseline systems.", "labels": [], "entities": []}, {"text": "ODC also outperforms checkpoint smoothing and ensemble methods, without extra cost during inference.", "labels": [], "entities": [{"text": "ODC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6000852584838867}, {"text": "checkpoint smoothing", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.7048380672931671}]}, {"text": "We can achieve further improvement by combining ODC with those methods.", "labels": [], "entities": []}, {"text": "Major contributions of our work include: 1.", "labels": [], "entities": []}, {"text": "In contrast to checkpoint smoothing and ensemble which do not affect the training process, we explore the way to distill knowledge from checkpoints to lead the training process in an on-the-fly manner( \u00a73.1, \u00a73.2).", "labels": [], "entities": [{"text": "checkpoint smoothing", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7138450741767883}]}, {"text": "We obtain better performance by replacing the best checkpoint with moving average parameters at that step.", "labels": [], "entities": []}, {"text": "( \u00a73.3) 2.", "labels": [], "entities": []}, {"text": "We conduct experiments on four translation tasks, including two low resource tasks.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.9173601269721985}]}, {"text": "In all the tasks our method outperforms strong baseline systems ( \u00a74.2, \u00a74.3).", "labels": [], "entities": []}, {"text": "We also conduct an experiment on machine reading comprehension task and the result shows that our method can be applied to other tasks too ( \u00a74.4).", "labels": [], "entities": []}, {"text": "3. We conduct comprehensive analysis and show that our method can significantly alleviate over-fitting issue in low-resource condition ( \u00a75.1), and help to find a wider minimum which brings better generation ( \u00a75.2).", "labels": [], "entities": []}], "datasetContent": [{"text": "We first evaluate the capability of our method for improving performance when there are plenty of training data.", "labels": [], "entities": []}, {"text": "We conduct experiments on both NIST and WMT17 Chinese-English Translation tasks.", "labels": [], "entities": [{"text": "NIST", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.9102333784103394}, {"text": "WMT17 Chinese-English Translation tasks", "start_pos": 40, "end_pos": 79, "type": "TASK", "confidence": 0.8006456941366196}]}, {"text": "Results on NIST Dataset We compare our method with several ways to utilize checkpoints 8 : \u2022 last-k-smoothing: After training the baseline model, we average the parameters of the last k checkpoints as the final model.", "labels": [], "entities": [{"text": "NIST Dataset", "start_pos": 11, "end_pos": 23, "type": "DATASET", "confidence": 0.9743676781654358}]}, {"text": "\u2022 best-k-smoothing: Average the parameters of the best k checkpoints, instead of the last k, as the final model.", "labels": [], "entities": []}, {"text": "In this case, checkpoints may have better performance but higher variance which could be harmful to parameters averaging.", "labels": [], "entities": [{"text": "parameters averaging", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.6566129177808762}]}, {"text": "\u2022 best-k-ensemble: Do ensemble inference (average the output probabilities) with the best k checkpoints ( ).", "labels": [], "entities": []}, {"text": "As shown in, our baseline is comparable to the other two recent published results (,).", "labels": [], "entities": []}, {"text": "In consistent with , using checkpoints for smoothing or ensemble does improve the baseline system.", "labels": [], "entities": []}, {"text": "Using EMA parameters also improve the baseline system as well, which is in consist with).", "labels": [], "entities": []}, {"text": "Compared to the baseline, our approach ODC brings translation improvement across different test sets and achieves 42.48 BLEU scores on average(+1.09 BLEU v.s. baseline).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.9990816116333008}, {"text": "BLEU", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.995209276676178}]}, {"text": "This result confirms that using best checkpoint as teacher indeed helps improving the performance of the translation model.", "labels": [], "entities": [{"text": "translation", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.9661402106285095}]}, {"text": "Besides, ODC is comparable to the best results among smoothing and ensemble on baseline's checkpoints (achieved by best-k-ensemble).", "labels": [], "entities": [{"text": "ODC", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9769359230995178}]}, {"text": "Considering that best-k-ensemble needs to decode with k models, while ODC decodes only one, our model enjoys a better efficiency.", "labels": [], "entities": []}, {"text": "Furthermore, we can achieve further improvement by combining these methods on checkpoints generated by ODC.", "labels": [], "entities": [{"text": "ODC", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.8621238470077515}]}, {"text": "Results also show that ODC-EMA ( \u00a73.3) could achieve additional improvement from ODC itself (43.13 v.s.", "labels": [], "entities": [{"text": "ODC-EMA", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.7046467661857605}, {"text": "ODC", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.8021698594093323}]}, {"text": "42.48 BLEU), demonstrating that using EMA of the best checkpoint instead can bring better knowledge distillation performance, as it generates a better teacher model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9985259175300598}, {"text": "EMA", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9155566096305847}, {"text": "knowledge distillation", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.707395002245903}]}, {"text": "We present the results on WMT17 Chinese-English translation task in.", "labels": [], "entities": [{"text": "WMT17 Chinese-English translation task", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.776866003870964}]}, {"text": "We report the results of the baseline, ODC and a recent result published by.", "labels": [], "entities": [{"text": "ODC", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.6432918906211853}]}, {"text": "To make a fair comparison, we follow the experiment setting in.", "labels": [], "entities": []}, {"text": "The experiment results show similar trends with those on the NIST datasets.", "labels": [], "entities": [{"text": "NIST datasets", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.9870992302894592}]}, {"text": "Applying ODC leads to the result of 24.22 BLEU, which is 0.85 BLEU higher compared with baseline.", "labels": [], "entities": [{"text": "ODC", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9831269979476929}, {"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9992546439170837}, {"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9988319277763367}]}, {"text": "We also apply our method to two low resource translation tasks, i.e., IWSLT2015 English-Vietnamese  (EN2VI) and WMT17 English-Turkish (EN2TR).", "labels": [], "entities": [{"text": "IWSLT2015 English-Vietnamese  (EN2VI)", "start_pos": 70, "end_pos": 107, "type": "DATASET", "confidence": 0.8468425512313843}, {"text": "WMT17 English-Turkish (EN2TR)", "start_pos": 112, "end_pos": 141, "type": "DATASET", "confidence": 0.8466022729873657}]}, {"text": "Due to the limited amount of training data, models are more likely to suffer from over-fitting.", "labels": [], "entities": []}, {"text": "Therefore, we use a higher dropout rate of 0.2 and weight decay, another common technique against overfitting, with decay weight set as 10 \u22123 as the default setting.", "labels": [], "entities": [{"text": "weight decay", "start_pos": 51, "end_pos": 63, "type": "METRIC", "confidence": 0.9147166609764099}]}, {"text": "We implement weight decay as AdamW () does.", "labels": [], "entities": [{"text": "AdamW", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.968532383441925}]}, {"text": "Besides, we further experiment with grid search on the validation set for optimal hyper-parameters of dropout rate and weight decay, which may lead to better results.", "labels": [], "entities": [{"text": "weight decay", "start_pos": 119, "end_pos": 131, "type": "METRIC", "confidence": 0.8436597883701324}]}, {"text": "We adopt a simple heuristic, which first searches an optimal dropout rate, and then further searches weight decay coefficients based on this dropout.", "labels": [], "entities": []}, {"text": "We experiment with dropout as 0.2, 0.3, 0.4, and weight decay as 10 \u22121 , 10 \u22122 and 10 \u22123 .  Although our main research is focused for the task of machine translation, the idea of ODC could be applied to other tasks as well.", "labels": [], "entities": [{"text": "weight decay", "start_pos": 49, "end_pos": 61, "type": "METRIC", "confidence": 0.9252831935882568}, {"text": "machine translation", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.8252103328704834}]}, {"text": "We experiments on the Stanford Question Answering Dataset (SQuAD) (), a machine reading comprehension task.", "labels": [], "entities": [{"text": "Stanford Question Answering Dataset (SQuAD)", "start_pos": 22, "end_pos": 65, "type": "DATASET", "confidence": 0.8742119414465768}]}, {"text": "SQuAD contains 107,785 human-generated reading comprehension questions, with 536 Wikipedia articles.", "labels": [], "entities": [{"text": "SQuAD", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7780921459197998}]}, {"text": "Each question is associated with a paragraph extracted from an article, and the corresponding answer is a span from this article.", "labels": [], "entities": []}, {"text": "A machine reading comprehension model is designed to predict the start and end positions in the article of the answer.", "labels": [], "entities": []}, {"text": "The state-of-the-art machine reading comprehension system also employs a deep neural network structure, which is similar to NMT.", "labels": [], "entities": [{"text": "machine reading comprehension", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.7364199161529541}]}, {"text": "We apply our ODC method on BiDAF++ (, a multi-layer SQuAD model that augments BiDAF () with self-attention and contextualized embeddings.", "labels": [], "entities": []}, {"text": "We evaluate the model after each epoch and implement the knowledge distillation by teaching the student with the output distribution of answer start and end positions predicted by the best checkpoint.", "labels": [], "entities": []}, {"text": "For the results, ODC improves abase BiDAF++ from 76.83 to 77.40, in EM scores, showing that our method can be applied to a broader range of tasks.", "labels": [], "entities": [{"text": "ODC", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.48149794340133667}, {"text": "BiDAF", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.8862910270690918}]}], "tableCaptions": [{"text": " Table 1: Case-insensitive BLEU scores of Chinese-English translation on NIST datasets. \"Average\"means average  scores on NIST04, 05 and 06.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9261722564697266}, {"text": "NIST datasets", "start_pos": 73, "end_pos": 86, "type": "DATASET", "confidence": 0.9890904724597931}, {"text": "NIST04", "start_pos": 122, "end_pos": 128, "type": "DATASET", "confidence": 0.9834896326065063}]}, {"text": " Table 2: Case-sensitive BLEU scores on WMT17  Chinese-English Translation", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9134214520454407}, {"text": "WMT17  Chinese-English Translation", "start_pos": 40, "end_pos": 74, "type": "DATASET", "confidence": 0.8387151757876078}]}, {"text": " Table 3: Case-sensitive BLEU scores on two low re- source translation tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9585403203964233}, {"text": "re- source translation tasks", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.7064483523368835}]}]}