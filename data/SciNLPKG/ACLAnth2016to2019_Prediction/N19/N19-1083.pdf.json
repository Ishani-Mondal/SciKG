{"title": [{"text": "OpenKI: Integrating Open Information Extraction and Knowledge Bases with Relation Inference", "labels": [], "entities": [{"text": "Integrating Open Information Extraction", "start_pos": 8, "end_pos": 47, "type": "TASK", "confidence": 0.6367503106594086}]}], "abstractContent": [{"text": "In this paper, we consider advancing web-scale knowledge extraction and alignment by integrating OpenIE extractions in the form of (subject, predicate, object) triples with Knowledge Bases (KB).", "labels": [], "entities": [{"text": "web-scale knowledge extraction", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.6210967600345612}, {"text": "OpenIE extractions", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.676551878452301}]}, {"text": "Traditional techniques from universal schema and from schema mapping fall in two extremes: either they perform instance-level inference relying on embedding for (subject, object) pairs, thus cannot handle pairs absent in any existing triples; or they perform predicate-level mapping and completely ignore background evidence from individual entities, thus cannot achieve satisfying quality.", "labels": [], "entities": []}, {"text": "We propose OpenKI to handle sparsity of Ope-nIE extractions by performing instance-level inference: for each entity, we encode the rich information in its neighborhood in both KB and OpenIE extractions, and leverage this information in relation inference by exploring different methods of aggregation and attention.", "labels": [], "entities": []}, {"text": "In order to handle unseen entities, our model is designed without creating entity-specific parameters.", "labels": [], "entities": []}, {"text": "Extensive experiments show that this method not only significantly improves state-of-the-art for conventional OpenIE extractions like ReVerb, but also boosts the performance on OpenIE from semi-structured data, where new entity pairs are abundant and data are fairly sparse.", "labels": [], "entities": [{"text": "OpenIE extractions", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.7051519751548767}]}], "introductionContent": [{"text": "Web-scale knowledge extraction and alignment has been a vision held by different communities for decades.", "labels": [], "entities": [{"text": "Web-scale knowledge extraction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.549731026093165}]}, {"text": "The Natural Language Processing (NLP) community has been focusing on knowledge extraction from texts.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.7272284229596456}, {"text": "knowledge extraction from texts", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.829874075949192}]}, {"text": "They apply either closed information extraction according to an ontology (), restricting to a subset of relations pre-defined in the ontology, or open information extraction (OpenIE) * This work was performed while at Amazon.", "labels": [], "entities": [{"text": "closed information extraction", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.7336332201957703}, {"text": "open information extraction", "start_pos": 146, "end_pos": 173, "type": "TASK", "confidence": 0.6299571593602499}]}, {"text": "to extract free-text relations (), leaving the relations unaligned and thus potentially duplicated.", "labels": [], "entities": []}, {"text": "The Database (DB) community has been focusing on aligning relational data or by schema mapping, but the quality is far below adequate for assuring correct data integration.", "labels": [], "entities": []}, {"text": "We propose advancing progress in this direction by applying knowledge integration from OpenIE extractions.", "labels": [], "entities": []}, {"text": "OpenIE extracts SPO (subject, predicate, object) triples, where each element is a text phrase, such as E1: (\"Robin Hood\", \"Full Cast and Crew\", \"Leonardo Decaprio\") and E2: (\"Ang Lee\", \"was named best director for\", \"Brokeback\").", "labels": [], "entities": []}, {"text": "OpenIE has been studied for text extraction extensively (, and also for semi-structured sources (, thus serves an effective tool for web-scale knowledge extraction.", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8745453357696533}, {"text": "text extraction", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.8111311793327332}, {"text": "web-scale knowledge extraction", "start_pos": 133, "end_pos": 163, "type": "TASK", "confidence": 0.6281599303086599}]}, {"text": "The remaining problem is to align text-phrase predicates 1 from OpenIE to knowledge bases (KB).", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.9234408736228943}]}, {"text": "Knowledge integration answers the following question: given an OpenIE extraction (s, p, o), how can one populate an existing KB using relations in the pre-defined ontology?", "labels": [], "entities": [{"text": "Knowledge integration", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7929488122463226}]}, {"text": "The problem of knowledge integration is not completely new.", "labels": [], "entities": [{"text": "knowledge integration", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.8486747443675995}]}, {"text": "The DB community has been solving the problem using schema mapping techniques, identifying mappings from a source schema (OpenIE extractions in our context) to a target schema (KB ontology in our context)).", "labels": [], "entities": []}, {"text": "Existing solutions consider predicate-level (i.e., attribute) similarity on names, types, descriptions, instances, and soon, and generate mappings like \"email\" mapped to \"email-address\"; \"first name\" and \"last name\" together mapped to \"full name\".", "labels": [], "entities": []}, {"text": "However, for our example \"Full Cast and Crew\", which is a union of multiple KB relations such as \"directed by\", \"written by\", and \"actor\", it is very hard to determine a mapping at the predicate level.", "labels": [], "entities": []}, {"text": "On the other hand, the NLP community has proposed Universal Schema ( to apply instance-level inference from both OpenIE extractions and knowledge in existing knowledge bases: given a set of extractions regarding an entity pair (s, o) and also information of each entity, infer new relations for this pair.", "labels": [], "entities": []}, {"text": "One drawback of this method is that it cannot handle unseen entities and entity pairs.", "labels": [], "entities": []}, {"text": "Also, the technique tends to overfit when the data is sparse due to large number of parameters for entities and entity pairs.", "labels": [], "entities": []}, {"text": "Unfortunately, in the majority of the real extractions we examined in our experiments, we can find only 1.4 textual triples on average between the subject and object.", "labels": [], "entities": []}, {"text": "The latest proposal Rowless Universal) removes the entityspecific parameters and makes the inference directly between predicates and relations, thereby allowing us to reason about unseen entity pairs.", "labels": [], "entities": []}, {"text": "However, it completely ignores the entities themselves, so in a sense falls back to predicate-level decisions, especially when only one text predicate is observed.", "labels": [], "entities": []}, {"text": "In this paper we propose a solution that leverages information about the individual entities whenever possible, and falls back to predicatelevel decisions only when both involved entities are new.", "labels": [], "entities": []}, {"text": "Continuing with our example E1 -if we know from existing knowledge that \"Leonardo\" is a famous actor and has rarely directed or written a movie, we can decide with a high confidence that this predicate maps to @film.actor in this triple, even if our knowledge graph knows nothing about the new movie \"Robin Hood\".", "labels": [], "entities": []}, {"text": "In particular, we make three contributions in this paper.", "labels": [], "entities": []}, {"text": "1. We design an embedding for each entity by exploring rich signals from its neighboring relations and predicates in KB and OpenIE.", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 124, "end_pos": 130, "type": "DATASET", "confidence": 0.894527792930603}]}, {"text": "This embedding provides a soft constraint on which relations the entities are likely to be involved in, while keeping our model free from creating new entity-specific parameters so allowing us to handle unseen entities during inference.", "labels": [], "entities": []}, {"text": "2. Inspired by predicate-level mapping from schema mapping and instance-level inference from universal schema, we design a joint model that leverages the neighborhood embedding of entities and relations with different methods of aggregation and attention.", "labels": [], "entities": []}], "datasetContent": [{"text": "OpenIE extractions and KB, we show that our method improves over state-of-the-arts by 33.5% on average across different datasets.", "labels": [], "entities": [{"text": "OpenIE extractions", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8218896985054016}, {"text": "KB", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9000552892684937}]}, {"text": "In the rest of the paper, we define the problem formally in Section 2, present our method in Section 3, describe experimental results in Section 4, and discuss related work in Section 5.", "labels": [], "entities": []}, {"text": "(2015) employ point-wise mutual information (PMI) between target relations and observed predicates to map OpenIE predicates to KB relations.", "labels": [], "entities": []}, {"text": "This is similar to our Bayes conditional probability P (p|p ).", "labels": [], "entities": []}, {"text": "This baseline operates at predicate-level.", "labels": [], "entities": []}, {"text": "To indicate the usefulness of entity neighborhood information, we also compare with P (p|s, p , o) as mentioned in Section 4.2.", "labels": [], "entities": []}, {"text": "For the advanced embedding-based baselines, we compare with the E-model and the Rowless model (with MaxR and query attention) introduced in Section 2.1.", "labels": [], "entities": []}, {"text": "Hyper-parameters: In our experiments, we use 25 dimensional embedding vectors for the Rowless model, and 12 dimensional embedding vectors for the E-and ENE models.", "labels": [], "entities": []}, {"text": "We use a batchsize of 128, and 16 negative samples for each positive sample in a batch.", "labels": [], "entities": []}, {"text": "Due to memory constraints, we sample at most 8 predicates between entities and 16 neighbors for each entity during training.", "labels": [], "entities": []}, {"text": "We use \u03b3 = 1.0 and set the learning rate to 5e-3 for ReVerb and 1e-3 for Ceres datasets.", "labels": [], "entities": [{"text": "ReVerb", "start_pos": 53, "end_pos": 59, "type": "DATASET", "confidence": 0.8718863725662231}, {"text": "Ceres datasets", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.8671809434890747}]}, {"text": "Evaluation measures: Our task is a multi-label task, where each entity pair can share multiple KB relations.", "labels": [], "entities": []}, {"text": "Therefore, we consider each KB relation as a query and compute the Mean Average Precision (MAP) -where entity pairs sharing the query relation should be ranked higher than those without the relation.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP) -", "start_pos": 67, "end_pos": 97, "type": "METRIC", "confidence": 0.9781122377940586}]}, {"text": "In Section 4.4 we report MAP statistics for the 50 most common KB relations for ReVerb and Freebase dataset, and for the 10 most common relations in other domain specific datasets.", "labels": [], "entities": [{"text": "MAP", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.5762022137641907}, {"text": "ReVerb", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.9386386275291443}, {"text": "Freebase dataset", "start_pos": 91, "end_pos": 107, "type": "DATASET", "confidence": 0.8186256587505341}]}, {"text": "The left out relations involve few triples to report any significant statistics.", "labels": [], "entities": []}, {"text": "We also report the area under the precision recall curve (AUC-PR) for evaluation in Section 4.5.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9989005327224731}, {"text": "recall curve (AUC-PR)", "start_pos": 44, "end_pos": 65, "type": "METRIC", "confidence": 0.8777506232261658}]}, {"text": "shows that the overall results.", "labels": [], "entities": []}, {"text": "OpenKI achieves significant performance improvement overall the baselines.", "labels": [], "entities": [{"text": "OpenKI", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9032959938049316}]}, {"text": "Overall, we observe 33.5% MAP improvement on average across different datasets.", "labels": [], "entities": [{"text": "MAP", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.8030984997749329}]}, {"text": "Overall, OpenKI obtains 35% MAP improvement over the best performing PCNN baseline.", "labels": [], "entities": [{"text": "OpenKI", "start_pos": 9, "end_pos": 15, "type": "DATASET", "confidence": 0.7923398613929749}, {"text": "MAP", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9965993762016296}, {"text": "PCNN baseline", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.8507413864135742}]}, {"text": "In contrast to baseline models, our approach leverages the neighborhood information of each entity from the text predicates in the 2007 corpus and predicates / relations from the 2005-2006 corpus.", "labels": [], "entities": []}, {"text": "This background knowledge contributes to the significant performance improvement.", "labels": [], "entities": []}, {"text": "Note that, our model uses only the graph information from the entity neighborhood and does not use any text encoder such as Piecewise Convolutional Neural Nets (PCNN) (, where convolutional neural networks were applied with piecewise max pooling to encode textual sentences.", "labels": [], "entities": []}, {"text": "This further demonstrates the importance of entity neighborhood information for relation inference.", "labels": [], "entities": [{"text": "relation inference", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.8973243236541748}]}, {"text": "It is possible to further improve the performance of our model by incorporating text encoders as an additional signal.", "labels": [], "entities": []}, {"text": "Some prior works () also leverage text encoders for relation inference.", "labels": [], "entities": [{"text": "relation inference", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8736794590950012}]}], "tableCaptions": [{"text": " Table 2: Data Statistics (Avg: Average, Med: Median).", "labels": [], "entities": [{"text": "Avg: Average", "start_pos": 27, "end_pos": 39, "type": "METRIC", "confidence": 0.8821760416030884}]}, {"text": " Table 3: Mean average precision (MAP) of different models over four data settings.", "labels": [], "entities": [{"text": "Mean average precision (MAP)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.9548323055108389}]}, {"text": " Table 4: Statistics for unseen entities in test data.  \"Both seen\" indicates both entities exist in training  data; \"One unseen\" indicates only one of the entities in  the pair exist in training data; \"Both unseen\" indicates  both entities were unobserved during training.", "labels": [], "entities": []}, {"text": " Table 5: Mean average precision (MAP) of Rowless  and OpenKI on ReVerb + Freebase (/film) dataset.", "labels": [], "entities": [{"text": "Mean average precision (MAP)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.9328488906224569}, {"text": "ReVerb + Freebase (/film) dataset", "start_pos": 65, "end_pos": 98, "type": "DATASET", "confidence": 0.9152592420578003}]}, {"text": " Table 7: Performances on NYT + Freebase data.", "labels": [], "entities": [{"text": "NYT + Freebase data", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.9600384384393692}]}]}