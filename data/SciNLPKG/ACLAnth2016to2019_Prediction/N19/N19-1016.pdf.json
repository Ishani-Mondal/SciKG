{"title": [{"text": "Implementation of a Chomsky-Sch\u00fctzenbergerSch\u00a8Sch\u00fctzenberger n-Best Parser for Weighted Multiple Context-Free Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "Constituent parsing has been studied extensively in the last decades.", "labels": [], "entities": [{"text": "Constituent parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.882489949464798}]}, {"text": "Chomsky-Sch\u00fctzenberger parsing as an approach to constituent parsing has only been investigated theoretically , yet.", "labels": [], "entities": [{"text": "Chomsky-Sch\u00fctzenberger parsing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.544859766960144}, {"text": "constituent parsing", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.6895885169506073}]}, {"text": "It uses the decomposition of a language into a regular language, a ho-momorphism, and a bracket language to divide the parsing problem into simpler subprob-lems.", "labels": [], "entities": []}, {"text": "We provide the first implementation of Chomsky-Sch\u00fctzenberger parsing.", "labels": [], "entities": []}, {"text": "It employs multiple context-free grammars and incorporates many refinements to achieve feasibility.", "labels": [], "entities": []}, {"text": "We compare its performance to state-of-the-art grammar-based parsers.", "labels": [], "entities": []}], "introductionContent": [{"text": "The description of the syntax of natural languages (such as Danish, English, and German) with the help of formal grammars has been studied since.", "labels": [], "entities": []}, {"text": "With a formal grammar, computers can calculate a syntactic representation (called parse) of a sentence in a natural language.", "labels": [], "entities": []}, {"text": "Of the grammar classes in the Chomsky hierarchy, context-free grammars (short: CFGs) lack the expressive power necessary to model natural languages and parsing with context-sensitive grammars cannot be done efficiently (i.e. in polynomial time).", "labels": [], "entities": []}, {"text": "This led to the introduction of a series of classes of mildly context-sensitive grammars that allow parsing in polynomial time but also capture an increasing amount of phenomena present in natural languages.", "labels": [], "entities": []}, {"text": "Tree adjoining grammars (, linear context-free string-rewriting systems (short: LCFRSs,, and multiple CFGs (short: MCFGs,) are among those classes.", "labels": [], "entities": []}, {"text": "Chomsky-Sch\u00fctzenberger (short: CS) parsing was introduced by for CFGs and extended to.", "labels": [], "entities": [{"text": "Chomsky-Sch\u00fctzenberger (short: CS) parsing", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.4750877150467464}, {"text": "CFGs", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.8553816676139832}]}, {"text": "It uses a classical theorem by or the generalisation by, which states that the language L(G) of a CFG (or an MCFG) G can be represented by a regular language R, a homomorphism h, and a Dyck language (resp. multiple Dyck language) D such that L(G) = h(R \u2229 D).", "labels": [], "entities": []}, {"text": "The elements of R \u2229 D correspond to parses in G.", "labels": [], "entities": []}, {"text": "For a sentence w, a CS parser calculates the elements of h \u22121 (w)\u2229R\u2229D and transforms them into parses.", "labels": [], "entities": []}, {"text": "CS parsing can be viewed as a coarse-tofine mechanism where R corresponds to the coarse grammar and R \u2229 D to the fine grammar.", "labels": [], "entities": [{"text": "CS parsing", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6778881549835205}]}, {"text": "The respective coarse-to-fine pipeline consists of (conceptually) simple operations such ash \u22121 or the intersection with R, which provides great flexibility.", "labels": [], "entities": []}, {"text": "The flexibility is used to provide a fallback mechanism in case a finer stage of the pipeline rejects all proposals of a coarser stage.", "labels": [], "entities": []}, {"text": "It also permits CS parsing in a broader setting than usual (for parsing) with minimal modification (see sec. 6).", "labels": [], "entities": [{"text": "CS parsing", "start_pos": 16, "end_pos": 26, "type": "TASK", "confidence": 0.7172363102436066}]}, {"text": "We suspected that the coarse-to-fine view on CS parsing leads to an efficient implementation.", "labels": [], "entities": [{"text": "CS parsing", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.6210856437683105}]}, {"text": "Since initial tests revealed that the original algorithm for MCFGs, recalled in sec.", "labels": [], "entities": []}, {"text": "2) is not feasible in practice, we explore numerous optimisations (sec.", "labels": [], "entities": []}, {"text": "4), one of which is the use of a context-free approximation of the multiple Dyck language D.", "labels": [], "entities": []}, {"text": "We introduce component-wise derivations (sec. 3) to relate this context-free approximation to D.", "labels": [], "entities": []}, {"text": "Employing the optimisations, we provide the first implementation of a CS parser.", "labels": [], "entities": []}, {"text": "5, we compare our parser's performance to Grammatical Framework (), rparse, and disco-dop.", "labels": [], "entities": []}, {"text": "We restrict our comparison to (discontinuous) grammarbased parsers (excluding e.g. transition systems,) since the principle of CS parsing requires a grammar.", "labels": [], "entities": []}], "datasetContent": [{"text": "We implemented the parser with the modifications sketched in sec.", "labels": [], "entities": []}, {"text": "4 for \u03b5-free and simple wMCFGs, 4 but no problems should arise generalising this implementation to arbitrary wMCFGs.", "labels": [], "entities": []}, {"text": "The implementation is available as apart of Rustomata, 5 a framework for weighted automata with storage written in the programming language Rust.", "labels": [], "entities": []}, {"text": "We used the NeGra corpus (German newspaper articles, 20,602 sentences, 355,096 tokens;) to compare our parser to, rparse, and discodop) with respect to parse time and accuracy.", "labels": [], "entities": [{"text": "NeGra corpus", "start_pos": 12, "end_pos": 24, "type": "DATASET", "confidence": 0.9674529135227203}, {"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9971529245376587}]}, {"text": "Our experiments were conducted on defoliated trees, i.e. we removed the leaves from each tree in the corpus.", "labels": [], "entities": []}, {"text": "Parsing was performed on gold part-of-speech tags.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9622183442115784}]}, {"text": "We performed a variant of ten-fold cross validation (short: TFCV; cf., i.e. we split the corpus into ten consecutive parts; each part becomes the validation set in one iteration while the others serve as training set.", "labels": [], "entities": []}, {"text": "We used the first iteration to select suitable values for our meta-parameters and the remaining nine for validation.", "labels": [], "entities": []}, {"text": "In case of Rustomata, a binarised and markovized grammar was induced with discodop (head-outward binarisation, v = 1, h = 2, cf.) in each iteration.", "labels": [], "entities": [{"text": "Rustomata", "start_pos": 11, "end_pos": 20, "type": "TASK", "confidence": 0.8358580470085144}, {"text": "discodop", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9516679048538208}]}, {"text": "For all other parsers, we induced a proba-4 A wMCFG G is called \u03b5-free and simple if each composition function that occurs in the rules of G is either of the form [u1, . .", "labels": [], "entities": []}, {"text": ", us] for some non-empty strings of variables u1, . .", "labels": [], "entities": []}, {"text": ", us, or of the form for some terminal symbol t.", "labels": [], "entities": []}, {"text": "5 available on https://github.com/tud-fop/ rustomata.", "labels": [], "entities": []}, {"text": "We used commit 867a451 for evaluation.", "labels": [], "entities": []}, {"text": "The evaluation scripts are available on https:// github.com/truprecht/rustomata-eval.", "labels": [], "entities": []}, {"text": "bilistic LCFRS with the respective default configurations (for details, cf. the evaluation scripts).", "labels": [], "entities": []}, {"text": "After that, we ran our parser on each sentence of the validation set and recorded the parse time and the computed 1-best parse.", "labels": [], "entities": []}, {"text": "The computed parses were evaluated against the gold parses of the validation set w.r.t. precision, recall, and f 1 -score (according to the labelled parseval measures, cf., we used the implementation by van.", "labels": [], "entities": [{"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9885494112968445}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9994350075721741}, {"text": "f 1 -score", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9314017742872238}]}, {"text": "Previous experiments with an implementation of the vanilla parser already struggled with small subsets (we used grammars extracted from 250-1500 parse trees) of the NeGra corpus.", "labels": [], "entities": [{"text": "vanilla parser", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.781752198934555}, {"text": "NeGra corpus", "start_pos": 165, "end_pos": 177, "type": "DATASET", "confidence": 0.9516817927360535}]}, {"text": "Therefore, we omit evaluation of the vanilla parser.", "labels": [], "entities": [{"text": "vanilla parser", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7629959881305695}]}, {"text": "A grid search for metaparameters was performed on sentences of up to 20 tokens (see the appendix, tab. 2, fora detailed listing).", "labels": [], "entities": []}, {"text": "The results suggested to set the beam width to 200 and the candidate count to 10,000.", "labels": [], "entities": [{"text": "beam width", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.7378988265991211}]}, {"text": "The experiments were performed on sentences with up to 30 tokens.", "labels": [], "entities": []}, {"text": "We instructed rparse, Grammatical Framework (short: GF) and Rustomata (short: OP) to stop parsing each sentence after 30 seconds (timeout).", "labels": [], "entities": []}, {"text": "Disco-dop did not permit passing a timeout.", "labels": [], "entities": []}, {"text": "In the case of disco-dop's LCFRS parser (short: ddlcfrs), we limited the validation set to sentences: Precision, recall, f 1 -score, and coverage of at most 20 tokens, since ddlcfrs frequently exceeded 30 seconds of parse time for longer sentences in preliminary tests.", "labels": [], "entities": [{"text": "Precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9977284073829651}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9988064765930176}, {"text": "f 1 -score", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.9736617207527161}, {"text": "coverage", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.993653416633606}]}, {"text": "Disco-dop's coarseto-fine data-oriented parser (short: ddctf-dop) and disco-dop's coarse-to-fine LCFRS parser (short: ddctf-lcfrs) rarely exceeded 30 seconds of parse time in preliminary tests and we let them run on sentences of up to 30 tokens without the timeout.", "labels": [], "entities": []}, {"text": "shows the parse times for each sentence length and parser.", "labels": [], "entities": []}, {"text": "The parsers ddctf-dop, ddctf-lcfrs, GF, and OP perform similar for sentences of up to 20 tokens.", "labels": [], "entities": []}, {"text": "The parse times of rparse and ddlcfrs grow rapidly after 10 and 16 tokens, respectively.", "labels": [], "entities": []}, {"text": "Rparse even exceeds the timeout for more than half of the test sentences that are longer than 15 tokens.", "labels": [], "entities": [{"text": "Rparse", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.631142258644104}]}, {"text": "For sentences with up to 30 tokens, the parse times of ddctf-dop, ddctf-lcfrs and OP seem to remain almost constant.", "labels": [], "entities": [{"text": "OP", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9660345911979675}]}, {"text": "shows the accuracy (i.e. precision, recall, and f 1 -score) and the coverage (i.e. the percentage of sentences that could be parsed) for each parser on the validation set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995917677879333}, {"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9992653727531433}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9987257122993469}, {"text": "f 1 -score", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9588321596384048}, {"text": "coverage", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9809302091598511}]}, {"text": "We report these scores to assert a correct implementation of our parser and to compare the different approximation strategies (and our fallback mechanism) implemented in the parsers.", "labels": [], "entities": []}, {"text": "The low coverage of rparse stems from the frequent occurrences of timeouts.", "labels": [], "entities": [{"text": "coverage", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9805058240890503}]}, {"text": "They also depress the recall for rparse.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9967173933982849}]}, {"text": "For sentences with at most 20 tokens, ddlcfrs, ddctf-lcfrs and OP perform very similar.", "labels": [], "entities": [{"text": "OP", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.864447295665741}]}, {"text": "These three parsers are outperformed by ddctf-dop in all aspects.", "labels": [], "entities": []}, {"text": "For sentences of up to 30 tokens, the scores of all tested parsers drop similarly.", "labels": [], "entities": []}, {"text": "However, ddctfdop's scores drop the least amount.", "labels": [], "entities": []}, {"text": "We repeated apart of the experiments with the Lassy corpus (Lassy Small, various kinds of written Dutch, 65,200 sentences, 975,055 tokens; van.", "labels": [], "entities": []}, {"text": "Since it is considerably larger than the NeGra corpus, we limited the experiments to one iteration of TFCV, and we only investigate OP, ddctf-lcfrs, and ddctf-dop.", "labels": [], "entities": [{"text": "NeGra corpus", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.9609347879886627}, {"text": "TFCV", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.7741982936859131}]}, {"text": "The results are shown in and at the bottom of tab.", "labels": [], "entities": []}, {"text": "shows the difference of ddctf-lcfrs, ddctf-dop and OP in terms of parse times (which is not discernible in).", "labels": [], "entities": [{"text": "OP", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9834449291229248}]}, {"text": "This plot shows that OP maintains very small parse times -even for large copora -compared to the state-of-the-art parser disco-dop.", "labels": [], "entities": []}, {"text": "All in all, our parser performs comparable to state-of-the-art MCFG parsers (GF, rparse, ddlcfrs, ddctf-lcfrs) and, using the NeGra corpus, it shows excellent results in parse time and good results inaccuracy.", "labels": [], "entities": [{"text": "NeGra corpus", "start_pos": 126, "end_pos": 138, "type": "DATASET", "confidence": 0.9602536857128143}]}, {"text": "Moreover, our parser can deal with any \u03b5-free and simple MCFG provided by an external tool, making it more flexible than discodop and rparse.", "labels": [], "entities": []}, {"text": "However, we are notable to compete with ddctf-dop in terms of accuracy, since discontinuous data-oriented parsing is a more accurate formalism).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9991796612739563}]}], "tableCaptions": [{"text": " Table 1: Precision, recall, f 1 -score, and coverage", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9966885447502136}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9994031190872192}, {"text": "f 1 -score", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9780577272176743}, {"text": "coverage", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9943746328353882}]}, {"text": " Table 2: Results of the grid search for meta-parameters.", "labels": [], "entities": []}]}