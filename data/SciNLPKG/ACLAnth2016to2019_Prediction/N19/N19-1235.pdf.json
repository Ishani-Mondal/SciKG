{"title": [{"text": "Neural Text Generation from Rich Semantic Representations", "labels": [], "entities": [{"text": "Neural Text Generation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8761163353919983}]}], "abstractContent": [{"text": "We propose neural models to generate high-quality text from structured representations based on Minimal Recursion Semantics (MRS).", "labels": [], "entities": [{"text": "Minimal Recursion Semantics (MRS)", "start_pos": 96, "end_pos": 129, "type": "TASK", "confidence": 0.6707234134276708}]}, {"text": "MRS is a rich semantic representation that encodes more precise semantic detail than other representations such as Abstract Meaning Representation (AMR).", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 115, "end_pos": 152, "type": "TASK", "confidence": 0.7511877516905466}]}, {"text": "We show that a sequence-to-sequence model that maps a lin-earization of Dependency MRS, a graph-based representation of MRS, to English text can achieve a BLEU score of 66.11 when trained on gold data.", "labels": [], "entities": [{"text": "Dependency MRS", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.5382335633039474}, {"text": "BLEU score", "start_pos": 155, "end_pos": 165, "type": "METRIC", "confidence": 0.9826289415359497}]}, {"text": "The performance can be improved further using a high-precision, broad coverage grammar-based parser to generate a large silver training corpus, achieving a final BLEU score of 77.17 on the full test set, and 83.37 on the subset of test data most closely matching the silver data domain.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 162, "end_pos": 172, "type": "METRIC", "confidence": 0.9805512428283691}]}, {"text": "Our results suggest that MRS-based representations area good choice for applications that need both structured semantics and the ability to produce natural language text as output.", "labels": [], "entities": [{"text": "MRS-based representations", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.9300174117088318}]}], "introductionContent": [{"text": "Text generation systems often generate their output from an intermediate semantic representation.", "labels": [], "entities": [{"text": "Text generation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7306060642004013}]}, {"text": "However many semantic representations are task-or domain-specific (, while rule-based text generation systems often have incomplete coverage.", "labels": [], "entities": []}, {"text": "In this work we combine the advantages of Minimal Recursion Semantics (MRS;) with the robustness and fluency of neural sequence-to-sequence models trained on large datasets.", "labels": [], "entities": [{"text": "Minimal Recursion Semantics (MRS", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.7415751039981842}]}, {"text": "We hypothesize that MRS is particularly well-suited for text generation, as it is explicitly compositional, capturing the contribution to sentence meaning of all parts of the surface form ().", "labels": [], "entities": [{"text": "MRS", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9576423764228821}, {"text": "text generation", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.7493174076080322}]}, {"text": "In contrast, semantic representations such as Abstract Meaning Representation (AMR;) seek to abstract away from the syntax of a sentence as much as possible.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR", "start_pos": 46, "end_pos": 82, "type": "TASK", "confidence": 0.7594307899475098}]}, {"text": "Therefore MRS captures meaning distinctions that AMR fails to represent (see).", "labels": [], "entities": [{"text": "MRS", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9718959331512451}]}, {"text": "Our approach ( \u00a72) uses neural sequence-tosequence models) to map linearizations of directed acyclic graphs (DAGs) to text, similar to the approach proposed by to generate text from AMR.", "labels": [], "entities": []}, {"text": "We use Dependency MRS (DMRS; Copestake, 2009), a graph-based representation in which nodes are MRS predicates (annotated with additional attributes) and edges represent relations between predicates.", "labels": [], "entities": [{"text": "Dependency MRS (DMRS; Copestake, 2009)", "start_pos": 7, "end_pos": 45, "type": "TASK", "confidence": 0.5654792288939158}]}, {"text": "MRS and DMRS are interconvertible and the graph-based representation enables more convenient linearization and manipulation than MRS's variable-based representation (.", "labels": [], "entities": [{"text": "MRS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9164963960647583}, {"text": "DMRS", "start_pos": 8, "end_pos": 12, "type": "DATASET", "confidence": 0.8496376276016235}]}, {"text": "Results ( \u00a73) show that neural DMRS to English text generation can obtain up to 83.37 BLEU and 32% exact match, substantially higher than previous work.", "labels": [], "entities": [{"text": "English text generation", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.5658497313658396}, {"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9885851740837097}, {"text": "exact match", "start_pos": 99, "end_pos": 110, "type": "METRIC", "confidence": 0.8848600685596466}]}, {"text": "In particular, we obtain an 11.6 BLEU improvement through semi-supervised training using the output of a grammar-based parser, compared to training on gold data only.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.995205819606781}]}, {"text": "In comparison a grammar-based generator obtained 62.05 BLEU, and an approach based on DAG 68.07 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9976183772087097}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.8522088527679443}]}, {"text": "Ablation experiments show that node attributes encoding fine-grained morpho-semantic information such as number and tense contribute more than 12 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.9978982210159302}]}, {"text": "The highest reported result for AMR generation is 33.8 BLEU (); on the same dataset our best model obtains 75.8 BLEU.", "labels": [], "entities": [{"text": "AMR generation", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.9801669418811798}, {"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9983888864517212}, {"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.996837854385376}]}, {"text": "While a more detailed meaning representation is harder to produce, our results suggest that MRS could be suitable for text generation applications where precise semantic representations are required.: DMRS and AMR graphs for the sentence Kim sees a boy.", "labels": [], "entities": [{"text": "MRS", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.5669289827346802}, {"text": "text generation", "start_pos": 118, "end_pos": 133, "type": "TASK", "confidence": 0.724933847784996}, {"text": "DMRS", "start_pos": 201, "end_pos": 205, "type": "DATASET", "confidence": 0.8594714403152466}]}, {"text": "Because DMRS includes tense and number, and has anode for the determiner, it can distinguish between, e.g. Kim sees a boy and Kim saw the boys, which AMR does not do.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the in-and out-of-domain performance of our approach by training models on either WSJ gold data only, or both WSJ gold data and Gigaword silver data, and evaluating on different domains.", "labels": [], "entities": [{"text": "WSJ gold data", "start_pos": 94, "end_pos": 107, "type": "DATASET", "confidence": 0.9325872262318929}, {"text": "WSJ gold data", "start_pos": 122, "end_pos": 135, "type": "DATASET", "confidence": 0.933984617392222}, {"text": "Gigaword silver data", "start_pos": 140, "end_pos": 160, "type": "DATASET", "confidence": 0.8881992300351461}]}, {"text": "The results in show that while the generator performs best on test data which matches the training domain (news), semisupervised training leads to substantial out-ofdomain improvements on the Wikipedia and the Brown corpus portions of the test set.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 210, "end_pos": 222, "type": "DATASET", "confidence": 0.8213063180446625}]}], "tableCaptions": [{"text": " Table 1: BLEU and exact-match scores over held-out test set", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992604851722717}, {"text": "exact-match", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.9195587038993835}]}, {"text": " Table 2: BLEU scores for domain match experiments", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986729621887207}]}, {"text": " Table 3: Results of semantic feature ablation, model  trained with gold data only", "labels": [], "entities": [{"text": "semantic feature ablation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7276952862739563}]}, {"text": " Table 5: Percentage of errors of each type, across 99  sampled items, grouped by BLEU score", "labels": [], "entities": [{"text": "Percentage of errors", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8728731473286947}, {"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9993568062782288}]}]}