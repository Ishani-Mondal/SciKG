{"title": [{"text": "Joint Detection and Location of English Puns", "labels": [], "entities": [{"text": "Joint Detection and Location of English Puns", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7501447073050908}]}], "abstractContent": [{"text": "A pun is a form of wordplay for an intended humorous or rhetorical effect, where a word suggests two or more meanings by exploiting polysemy (homographic pun) or phonologi-cal similarity to another word (heterographic pun).", "labels": [], "entities": []}, {"text": "This paper presents an approach that addresses pun detection and pun location jointly from a sequence labeling perspective.", "labels": [], "entities": [{"text": "pun detection", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.9237854182720184}, {"text": "pun location", "start_pos": 65, "end_pos": 77, "type": "TASK", "confidence": 0.7782955467700958}, {"text": "sequence labeling", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.6844314634799957}]}, {"text": "We employ anew tagging scheme such that the model is capable of performing such a joint task, where useful structural information can be properly captured.", "labels": [], "entities": []}, {"text": "We show that our proposed model is effective in handling both ho-mographic and heterographic puns.", "labels": [], "entities": []}, {"text": "Empirical results on the benchmark datasets demonstrate that our approach can achieve new state-of-the-art results.", "labels": [], "entities": []}], "introductionContent": [{"text": "There exists a class of language construction known as pun in natural language texts and utterances, where a certain word or other lexical items are used to exploit two or more separate meanings.", "labels": [], "entities": []}, {"text": "It has been shown that understanding of puns is an important research question with various real-world applications, such as human-computer interaction and machine translation.", "labels": [], "entities": [{"text": "understanding of puns", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.9051264723141988}, {"text": "machine translation", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7987877428531647}]}, {"text": "Recently, many researchers show their interests in studying puns, like detecting pun sentences, locating puns in the text, interpreting pun sentences () and generating sentences containing puns (.", "labels": [], "entities": [{"text": "interpreting pun sentences", "start_pos": 123, "end_pos": 149, "type": "TASK", "confidence": 0.8748672405878702}]}, {"text": "A pun is a wordplay in which a certain word suggests two or more meanings by exploiting polysemy, homonymy, or phonological similarity to another sign, for an intended humorous or rhetorical effect.", "labels": [], "entities": []}, {"text": "Puns can be generally categorized into two groups, namely heterographic puns (where the pun and its latent target are phonologically similar) and homographic puns (where the two meanings of the pun reflect its two distinct senses) (.", "labels": [], "entities": []}, {"text": "Consider the following two examples: (1) When the church bought gas for their annual barbecue, proceeds went from the sacred to the propane.", "labels": [], "entities": []}, {"text": "(2) Some diets cause a gut reaction.", "labels": [], "entities": []}, {"text": "The first punning joke exploits the sound similarity between the word \"propane\" and the latent target \"profane\", which can be categorized into the group of heterographic puns.", "labels": [], "entities": []}, {"text": "Another categorization of English puns is homographic pun, exemplified by the second instance leveraging distinct senses of the word \"gut\".", "labels": [], "entities": []}, {"text": "Pun detection is the task of detecting whether there is a pun residing in the given text.", "labels": [], "entities": [{"text": "Pun detection", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.898281455039978}, {"text": "detecting whether there is a pun residing in the given text", "start_pos": 29, "end_pos": 88, "type": "TASK", "confidence": 0.6812767548994585}]}, {"text": "The goal of pun location is to find the exact word appearing in the text that implies more than one meanings.", "labels": [], "entities": [{"text": "pun location", "start_pos": 12, "end_pos": 24, "type": "TASK", "confidence": 0.8977893590927124}]}, {"text": "Most previous work addresses such two tasks separately and develop separate systems.", "labels": [], "entities": []}, {"text": "Typically, a system for pun detection is built to make a binary prediction on whether a sentence contains a pun or not, where all instances (with or without puns) are taken into account during training.", "labels": [], "entities": [{"text": "pun detection", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.8607940375804901}]}, {"text": "For the task of pun location, a separate system is used to make a single prediction as to which word in the given sentence in the text that trigger more than one semantic interpretations of the text, where the training data involves only sentences that contain a pun.", "labels": [], "entities": [{"text": "pun location", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.8979397118091583}]}, {"text": "Therefore, if one is interested in solving both problems at the same time, a pipeline approach that performs pun detection followed by pun location can be used.", "labels": [], "entities": [{"text": "pun detection", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.8367987871170044}]}, {"text": "Compared to the pipeline methods, joint learning has been shown effective) since it is able to re-duce error propagation and allows information exchange between tasks which is potentially beneficial to all the tasks.", "labels": [], "entities": []}, {"text": "In this work, we demonstrate that the detection and location of puns can be jointly addressed by a single model.", "labels": [], "entities": [{"text": "detection and location of puns", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.7844897508621216}]}, {"text": "The pun detection and location tasks can be combined as a sequence labeling problem, which allows us to jointly detect and locate a pun in a sentence by assigning each word a tag.", "labels": [], "entities": [{"text": "pun detection", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.7961303293704987}, {"text": "sequence labeling", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.6737053394317627}]}, {"text": "Since each context contains a maximum of one pun, we design a novel tagging scheme to capture this structural constraint.", "labels": [], "entities": []}, {"text": "Statistics on the corpora also show that a pun tends to appear in the second half of a context.", "labels": [], "entities": []}, {"text": "To capture such a structural property, we also incorporate word position knowledge into our structured prediction model.", "labels": [], "entities": []}, {"text": "Experiments on the benchmark datasets show that detection and location tasks can reinforce each other, leading to new state-of-the-art performance on these two tasks.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that performs joint detection and location of English puns by using a sequence labeling approach.", "labels": [], "entities": [{"text": "joint detection and location of English puns", "start_pos": 67, "end_pos": 111, "type": "TASK", "confidence": 0.7705945330006736}, {"text": "sequence labeling", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.6765578091144562}]}], "datasetContent": [{"text": "We evaluate our model on two benchmark datasets ().", "labels": [], "entities": []}, {"text": "The homographic dataset contains 2,250 contexts, 1,607 of which contain a pun.", "labels": [], "entities": []}, {"text": "The heterographic dataset consists of 1,780 contexts with 1,271 containing a pun.", "labels": [], "entities": []}, {"text": "We notice there is no standard splitting information provided for both datasets.", "labels": [], "entities": []}, {"text": "Thus we apply 10-fold cross validation.", "labels": [], "entities": []}, {"text": "To make direct comparisons with prior studies, following, we accumulated the predictions for all ten folds and calculate the scores in the end.", "labels": [], "entities": []}, {"text": "For each fold, we randomly select 10% of the instances from the training set for development.", "labels": [], "entities": []}, {"text": "Word embeddings are initialized with the 100-dimensional Glove ().", "labels": [], "entities": [{"text": "Glove", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.8751656413078308}]}, {"text": "The dimension of character embeddings is 30 and they are randomly initialized, which can be fine tuned during training.", "labels": [], "entities": []}, {"text": "The pre-trained word embeddings are not updated during training.", "labels": [], "entities": []}, {"text": "The dimensions of hidden vectors for both char-level and wordlevel LSTM units are set to 300.", "labels": [], "entities": []}, {"text": "We adopt stochastic gradient descent (SGD) (Bottou, 1991) with a learning rate of 0.015.", "labels": [], "entities": [{"text": "stochastic gradient descent (SGD)", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.721297045548757}, {"text": "learning rate", "start_pos": 65, "end_pos": 78, "type": "METRIC", "confidence": 0.9802162349224091}]}, {"text": "For the pun detection task, if the predicted tag sequence contains at least one P tag, we regard the output (i.e., the prediction of our pun detection model) for this task as true, otherwise false.", "labels": [], "entities": [{"text": "pun detection task", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.8731879393259684}, {"text": "pun detection", "start_pos": 137, "end_pos": 150, "type": "TASK", "confidence": 0.7002442330121994}]}, {"text": "For the pun location task, a predicted pun is regarded as correct if and only if it is labeled as the gold pun in the dataset.", "labels": [], "entities": [{"text": "pun location task", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.8290825088818868}]}, {"text": "As to pun location, to make fair comparisons with prior studies, we only consider the instances that are labeled as the ones containing a pun.", "labels": [], "entities": []}, {"text": "We report precision, recall and F 1 score in.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9998193383216858}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9998383522033691}, {"text": "F 1 score", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9889199733734131}]}, {"text": "A list of prior works that did not employ joint learning are also shown in the first block of.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison results on two benchmark datasets. (P.: Precision, R.: Recall, F 1 : F 1 score.)", "labels": [], "entities": [{"text": "Recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9508609771728516}, {"text": "F 1 : F 1 score", "start_pos": 84, "end_pos": 99, "type": "METRIC", "confidence": 0.881991058588028}]}]}