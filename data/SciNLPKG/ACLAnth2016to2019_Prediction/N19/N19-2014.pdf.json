{"title": [{"text": "Are the Tools up to the Task? An evaluation of commercial dialog tools in developing conversational enterprise-grade dialog systems", "labels": [], "entities": []}], "abstractContent": [{"text": "There has been a significant investment in dialog systems (tools and runtime) for building conversational systems by major companies including Google, IBM, Microsoft, and Amazon.", "labels": [], "entities": []}, {"text": "The question remains whether these tools are up to the task of building conversational , task-oriented dialog applications at the enterprise level.", "labels": [], "entities": []}, {"text": "In our company, we are exploring and comparing several toolsets in an effort to determine their strengths and weaknesses in meeting our goals for dialog system development: accuracy, time to market, ease of replicating and extending applications, and efficiency and ease of use by developers.", "labels": [], "entities": [{"text": "dialog system development", "start_pos": 146, "end_pos": 171, "type": "TASK", "confidence": 0.8098315993944804}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9985418319702148}]}, {"text": "In this paper, we provide both quantitative and qualitative results in three main areas: natural language understanding, dialog, and text generation.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.6577839553356171}, {"text": "text generation", "start_pos": 133, "end_pos": 148, "type": "TASK", "confidence": 0.7833687365055084}]}, {"text": "While existing toolsets were all incomplete , we hope this paper will provide a roadmap of where they need to go to meet the goal of building effective dialog systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the explosion of smart devices and the significant improvement in speech recognition over the past few years, the demand for intelligent, conversational dialog systems is rising quickly.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7134991437196732}]}, {"text": "At our company we are working to meet that demand in the enterprise market to provide secure and natural means for accessing information and improving business processes.", "labels": [], "entities": []}, {"text": "Essential to meeting this demand is getting dialog systems into the hands of customers as quickly as possible while ensuring accurate interpretation of utterances as well as conversational means of handling ambiguity, error, and out of domain/out of scope utterances.", "labels": [], "entities": []}, {"text": "In this paper we explore whether the dialog tools available from a number of companies are up to the task of creating complete systems efficiently.", "labels": [], "entities": []}, {"text": "We provide both quantitative and qualitative results in three main areas: \u2022 Natural language understanding: intent and entity accuracy, out-of-domain and out-ofscope identification, and anaphora and coreference resolution.", "labels": [], "entities": [{"text": "Natural language understanding", "start_pos": 76, "end_pos": 106, "type": "TASK", "confidence": 0.6668432553609213}, {"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9459985494613647}, {"text": "out-ofscope identification", "start_pos": 154, "end_pos": 180, "type": "TASK", "confidence": 0.7344521880149841}, {"text": "coreference resolution", "start_pos": 199, "end_pos": 221, "type": "TASK", "confidence": 0.864305317401886}]}, {"text": "\u2022 Dialog management: frame-based and contextual dialog control, dialog structure, and digression.", "labels": [], "entities": [{"text": "Dialog management", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.8973682820796967}, {"text": "dialog structure", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7746116518974304}]}, {"text": "\u2022 Response generation: text generation, error correction and clarification.", "labels": [], "entities": [{"text": "Response generation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.9275053143501282}, {"text": "text generation", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7890311777591705}, {"text": "error correction", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.7389198541641235}]}, {"text": "We provide results and examples across multiple domains to illustrate the challenges in developing a truly conversational dialog system.", "labels": [], "entities": []}, {"text": "As we will show, there is considerable progress inaccuracy of intents and entities in constrained domains across all of the toolsets.", "labels": [], "entities": []}, {"text": "However, capturing subtle differences in in-scope vs. out-of-scope utterances is still difficult, as is partial understanding, which is important for clarification.", "labels": [], "entities": []}, {"text": "For dialog management, all of the tools offer some ability to use frames, however they differ in how robust they are to context.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.9438389241695404}]}, {"text": "Similarly, for error correction and clarification, the ability to react based on context is limited.", "labels": [], "entities": [{"text": "error correction", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7306528985500336}]}, {"text": "Finally, in text generation, we found there was no support beyond template-based generation, which impacts not only naturalness, but the ability to interpret a user's follow-on utterance.", "labels": [], "entities": [{"text": "text generation", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.7621134519577026}]}, {"text": "There has been other work comparing just the accuracy of these tools (e.g.().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9993882179260254}]}, {"text": "as well as the ability of applications built with them to handle particular dialog structures, such as subdialogs) and question answering behavior.", "labels": [], "entities": [{"text": "question answering behavior", "start_pos": 119, "end_pos": 146, "type": "TASK", "confidence": 0.8757439851760864}]}, {"text": "Our focus is on the tools themselves and our goal is to not just look at what they do, but what we need them to do.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Test domain numbers", "labels": [], "entities": []}, {"text": " Table 2: Intent accuracy comparing training amounts", "labels": [], "entities": [{"text": "Intent", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8926461935043335}, {"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.7416494488716125}]}, {"text": " Table 3: Results of data augmentation on the standard  test set.", "labels": [], "entities": [{"text": "standard  test set", "start_pos": 46, "end_pos": 64, "type": "DATASET", "confidence": 0.9073718190193176}]}, {"text": " Table 4. List  had better performance, but required listing all the  variations. Learned requires annotation, which is  also a cost, but it is not the case that every variant  has to be accounted for.", "labels": [], "entities": []}, {"text": " Table 4: Test for Entities and Slots", "labels": [], "entities": [{"text": "Test", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.8326408267021179}, {"text": "Slots", "start_pos": 32, "end_pos": 37, "type": "TASK", "confidence": 0.4660246670246124}]}]}