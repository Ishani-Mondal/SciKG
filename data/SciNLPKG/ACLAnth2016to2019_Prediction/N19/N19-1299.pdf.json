{"title": [{"text": "Bidirectional Attentive Memory Networks for Question Answering over Knowledge Bases", "labels": [], "entities": [{"text": "Question Answering over Knowledge Bases", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.8557332277297973}]}], "abstractContent": [{"text": "When answering natural language questions over knowledge bases (KBs), different question components and KB aspects play different roles.", "labels": [], "entities": []}, {"text": "However, most existing embedding-based methods for knowledge base question answering (KBQA) ignore the subtle interrelationships between the question and the KB (e.g., entity types, relation paths and context).", "labels": [], "entities": [{"text": "knowledge base question answering (KBQA)", "start_pos": 51, "end_pos": 91, "type": "TASK", "confidence": 0.7104492613247463}]}, {"text": "In this work, we propose to directly model the two-way flow of interactions between the questions and the KB via a novel Bidi-rectional Attentive Memory Network, called BAMnet.", "labels": [], "entities": [{"text": "BAMnet", "start_pos": 169, "end_pos": 175, "type": "DATASET", "confidence": 0.8539841175079346}]}, {"text": "Requiring no external resources and only very few hand-crafted features, on the WebQuestions benchmark, our method significantly outperforms existing information-retrieval based methods, and remains competitive with (hand-crafted) semantic parsing based methods.", "labels": [], "entities": [{"text": "WebQuestions benchmark", "start_pos": 80, "end_pos": 102, "type": "DATASET", "confidence": 0.904845803976059}, {"text": "semantic parsing", "start_pos": 231, "end_pos": 247, "type": "TASK", "confidence": 0.7541846632957458}]}, {"text": "Also, since we use attention mechanisms, our method offers better inter-pretability compared to other baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapid growth in large-scale knowledge bases (KBs) such as DBPedia ( and FreeBase, knowledge base question answering (KBQA) has drawn increasing attention over the past few years.", "labels": [], "entities": [{"text": "DBPedia", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.9497058987617493}, {"text": "knowledge base question answering (KBQA)", "start_pos": 91, "end_pos": 131, "type": "TASK", "confidence": 0.7146909705230168}]}, {"text": "Given questions in natural language (NL), the goal of KBQA is to automatically find answers from the underlying KB, which provides a more natural and intuitive way to access the vast underlying knowledge resources.", "labels": [], "entities": []}, {"text": "One of the most prominent challenges of KBQA is the lexical gap.", "labels": [], "entities": []}, {"text": "For instance, the same question can be expressed in various ways in NL while a KB usually has a canonical lexicon.", "labels": [], "entities": []}, {"text": "It is therefore nontrivial to map an NL question to a structured KB.", "labels": [], "entities": []}, {"text": "The approaches proposed to tackle the KBQA task can be roughly categorized into two groups: semantic parsing (SP) and information retrieval (IR) approaches.", "labels": [], "entities": [{"text": "semantic parsing (SP)", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.8185054063796997}, {"text": "information retrieval (IR)", "start_pos": 118, "end_pos": 144, "type": "TASK", "confidence": 0.799200052022934}]}, {"text": "SP-based approaches address the problem by constructing a semantic parser that converts NL questions into intermediate logic forms, which can be executed against a KB.", "labels": [], "entities": []}, {"text": "Traditional semantic parsers) require annotated logical forms as supervision, and are limited to narrow domains with a small number of logical predicates.", "labels": [], "entities": []}, {"text": "Recent efforts overcome these limitations via the construction of hand-crafted rules or features () schema matching, and using weak supervision from external resources.", "labels": [], "entities": []}, {"text": "Unlike SP-based approaches that usually assume a pre-defined set of lexical triggers or rules, which limit their domains and scalability, IR-based approaches directly retrieve answers from the KB in light of the information conveyed in the questions.", "labels": [], "entities": []}, {"text": "These IR-based approaches usually do not require hand-made rules and can therefore scale better to large and complex KBs.", "labels": [], "entities": []}, {"text": "Recently, deep neural networks have been shown to produce strong results on many NLP tasks.", "labels": [], "entities": []}, {"text": "In the field of KBQA, under the umbrella of IR-based approaches, many embedding-based methods () have been proposed and have shown promising results.", "labels": [], "entities": []}, {"text": "These methods adopt various ways to encode questions and KB subgraphs into a common embedding space and directly match them in that space, and can be typically trained in an end-to-end manner.", "labels": [], "entities": []}, {"text": "Compared to existing embedding-based methods that encode questions and KB subgraphs independently, we introduce a novel Bidirectional Attentive Memory network, called BAMnet that captures the mutual interactions between questions and the underlying KB, which is stored in a contentaddressable memory.", "labels": [], "entities": []}, {"text": "We assume that the world knowledge (i.e., the KB) is helpful for better understanding the questions.", "labels": [], "entities": []}, {"text": "Similarly, the questions themselves can help us focus on important KB aspects.", "labels": [], "entities": []}, {"text": "To this end, we design a two-layered bidirectional attention network.", "labels": [], "entities": []}, {"text": "The primary attention network is intended to focus on important parts of a question in light of the KB and important KB aspects in light of the question.", "labels": [], "entities": []}, {"text": "Built on top of that, the secondary attention network is intended to enhance the question and KB representations by further exploiting the two-way attention.", "labels": [], "entities": []}, {"text": "Through this idea of hierarchical two-way attention, we are able to distill the information that is the most relevant to answering the questions on both sides of the question and KB.", "labels": [], "entities": []}, {"text": "We highlight the contributions of this paper as follows: 1) we propose a novel bidirectional attentive memory network for the task of KBQA which is intended to directly model the two-way interactions between questions and the KB; 2) by design, our method offers good interpretability thanks to the attention mechanisms; 3) on the WebQuestions benchmark, our method significantly outperforms previous information-retrieval based methods while remaining competitive with (handcrafted) semantic parsing based methods.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 483, "end_pos": 499, "type": "TASK", "confidence": 0.7526990473270416}]}], "datasetContent": [{"text": "This section provides an extensive evaluation of our proposed BAMnet model against state-ofthe-art KBQA methods.", "labels": [], "entities": []}, {"text": "The implementation of BAMnet is available at https://github.", "labels": [], "entities": [{"text": "BAMnet", "start_pos": 22, "end_pos": 28, "type": "DATASET", "confidence": 0.690848708152771}]}, {"text": "com/hugochan/BAMnet.", "labels": [], "entities": [{"text": "BAMnet", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.7634720802307129}]}], "tableCaptions": [{"text": " Table 1: Results on the WebQuestions test set. Bold:  best in-category performance.", "labels": [], "entities": [{"text": "WebQuestions test set", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.9545933604240417}]}, {"text": " Table 2: Ablation results on the WebQuestions test set.  Gold topic entity is assumed to be known.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9976250529289246}, {"text": "WebQuestions test set", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.9521438876787821}]}]}