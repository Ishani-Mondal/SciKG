{"title": [{"text": "Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a portfolio of natural legal language processing and document curation services currently underdevelopment in a collab-orative European project.", "labels": [], "entities": [{"text": "natural legal language processing and document curation", "start_pos": 26, "end_pos": 81, "type": "TASK", "confidence": 0.6223307720252446}]}, {"text": "First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable mi-croservices architecture.", "labels": [], "entities": []}, {"text": "Their orchestration is operationalised using a content and document curation workflow manager.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present a portfolio of various Natural Legal Language Processing and Document Curation services currently underdevelopment in the collaborative EU project LYNX, in which a consortium of partners from academia and industry develops a platform for the easier and more efficient processing of documents from the legal domain.", "labels": [], "entities": [{"text": "Natural Legal Language Processing and Document Curation", "start_pos": 34, "end_pos": 89, "type": "TASK", "confidence": 0.661225071975163}]}, {"text": "First, our platform is acquiring data and documents related to compliance from multiple jurisdictions in different languages with a focus on Spanish, German, Dutch, Italian and English, along with terminologies, dictionaries and other language resources.", "labels": [], "entities": []}, {"text": "Based on this collection of structured data and unstructured documents we create the multilingual Legal Knowledge Graph (LKG).", "labels": [], "entities": []}, {"text": "Second, a set of flexible language processing services is developed to analyse and process the data and documents to integrate them into the LKG.", "labels": [], "entities": [{"text": "LKG", "start_pos": 141, "end_pos": 144, "type": "DATASET", "confidence": 0.9471362829208374}]}, {"text": "Semantic processing components annotate, structure, and interlink the LKG contents.", "labels": [], "entities": []}, {"text": "The LKG is incrementally augmented by linking to external data sets, by discovering topics and entities linked implicitly, as well as by using machine translation services to provide access to documents, previously unavailable, in certain languages.", "labels": [], "entities": []}, {"text": "Finally, three pilots are developed that exploit the LKG in industry use cases.", "labels": [], "entities": [{"text": "LKG", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.8854342103004456}]}, {"text": "The remainder of this article is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the different use cases, while, in the main part of the article (Section 3), we focus upon the 13 different processing services used in the prototype applications . The orchestration of the services is operationalised using a content and document curation workflow manager (Section 4).", "labels": [], "entities": []}, {"text": "After a brief review of related work (Section 5) we summarise the article and take a look at future work (Section 6).", "labels": [], "entities": [{"text": "summarise", "start_pos": 52, "end_pos": 61, "type": "TASK", "confidence": 0.943375289440155}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: F 1 values of the CRF and BiLSTM models for the coarse-grained classes.", "labels": [], "entities": [{"text": "F", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9927553534507751}, {"text": "CRF", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.8271599411964417}, {"text": "BiLSTM", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.7858754396438599}]}, {"text": " Table 2: Cocktails WSID accuracy scores", "labels": [], "entities": [{"text": "Cocktails WSID", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.4996722489595413}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.7994116544723511}]}, {"text": " Table 3: MeSH WSID accuracy scores", "labels": [], "entities": [{"text": "MeSH WSID", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.5528627187013626}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.7057316899299622}]}, {"text": " Table 4: Comparison of the results of the original version of HeidelTime (HT) with the modified (HT nV) on the  evaluation corpus. The last line indicates the improvement.", "labels": [], "entities": [{"text": "HeidelTime (HT)", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.8151141554117203}]}, {"text": " Table 5: Evaluation results of NMT systems", "labels": [], "entities": []}]}