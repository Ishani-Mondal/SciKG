{"title": [{"text": "Learning to Respond to Mixed-code Queries using Bilingual Word Embeddings", "labels": [], "entities": [{"text": "Respond to Mixed-code Queries", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.746095672249794}]}], "abstractContent": [{"text": "We present a method for learning bilingual word embeddings in order to support second language (L2) learners in finding recurring phrases and example sentences that match mixed-code queries (e.g., \"\u63a5 \u53d7 sentence\") composed of words in both target language and native language (L1).", "labels": [], "entities": []}, {"text": "In our approach, mixed-code queries are transformed into target language queries aimed at maximizing the probability of retrieving relevant target language phrases and sentences.", "labels": [], "entities": []}, {"text": "The method involves converting a given parallel corpus into mixed-code data, generating word embeddings from mixed-code data, and expanding queries in target languages based on bilingual word embeddings.", "labels": [], "entities": []}, {"text": "We present a prototype search engine, x.Linggle, that applies the method to a linguistic search engine fora parallel corpus.", "labels": [], "entities": []}, {"text": "Preliminary evaluation on a list of common word-translation shows that the method performs reasonably well.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many queries are submitted to search engines on the Web everyday to retrieve linguistic information for learning a second language (L2), and an increasing number of search engines specifically target queries for finding translations of phrases and sentences.", "labels": [], "entities": []}, {"text": "For example, Linguee (www. linguee.com) accepts L1 queries and retrieves bilingual sentences (L1+L2), while Google Translate (translate.google.com) is used to translate (mixed-code) texts, and return L2 results.", "labels": [], "entities": []}, {"text": "Due to limited L2 vocabulary knowledge, users often submit mix-coded queries, but search engines such as Linguee only retrieve sentences similar to queries without converting them into target language queries.", "labels": [], "entities": []}, {"text": "By transforming L1 keywords in the original query into relevant L2 keywords, we can bias the search engine toward retrieving relevant L2 phrases and sentences for language learning.", "labels": [], "entities": []}, {"text": "We present a system, x.Linggle, that automatically processes mixed-code queries into monolingual queries and retrieves relevant phrases and examples to users.", "labels": [], "entities": []}, {"text": "See for an example of x.Linggle search results of the query \"\u63a5\u53d7 education\".", "labels": [], "entities": []}, {"text": "As shown in, x.Linggle is accessible at https://x.linggle.com.", "labels": [], "entities": []}, {"text": "x.Linggle has determined several L2 keywords for the L1 keyword \"\u63a5\u53d7\" by calculating cosine similarities between word vectors in the bilingual embedding space and convert the query into L2 queries (e.g., \"receive education\", \"obtain education\", \"accept education\").", "labels": [], "entities": []}, {"text": "Then, x.Linggle retrieves and ranks the results of these L2 queries according to occurrence counts, and finally returns relevant phrases with example sentences.", "labels": [], "entities": []}, {"text": "The rest of the article is organized as follows.", "labels": [], "entities": []}, {"text": "First, we present our method for deriving bilingual word embeddings to support mixed-code queries.", "labels": [], "entities": []}, {"text": "Next, we introduce the search engine in which we integrate our mixed-code query system.", "labels": [], "entities": []}, {"text": "Then, we conduct a preliminary evaluation on the most common 7000 vocabulary for ESL learners.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}