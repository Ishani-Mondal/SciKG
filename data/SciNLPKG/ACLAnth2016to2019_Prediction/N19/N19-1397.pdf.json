{"title": [{"text": "Jointly Extracting and Compressing Documents with Summary State Representations", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew neural model for text sum-marization that first extracts sentences from a document and then compresses them.", "labels": [], "entities": []}, {"text": "The proposed model offers a balance that sidesteps the difficulties in abstractive methods while generating more concise summaries than extractive methods.", "labels": [], "entities": []}, {"text": "In addition, our model dynamically determines the length of the output summary based on the gold summaries it observes during training, and does not require length constraints typical to extractive summarization.", "labels": [], "entities": []}, {"text": "The model achieves state-of-the-art results on the CNN/DailyMail and Newsroom datasets, improving over current extractive and abstrac-tive methods.", "labels": [], "entities": [{"text": "CNN/DailyMail and Newsroom datasets", "start_pos": 51, "end_pos": 86, "type": "DATASET", "confidence": 0.8340313931306204}]}, {"text": "Human evaluations demonstrate that our model generates concise and informative summaries.", "labels": [], "entities": []}, {"text": "We also make available anew dataset of oracle compressive summaries derived automatically from the CNN/DailyMail reference summaries.", "labels": [], "entities": [{"text": "CNN/DailyMail reference summaries", "start_pos": 99, "end_pos": 132, "type": "DATASET", "confidence": 0.9444520354270936}]}], "introductionContent": [{"text": "Text summarization is an important NLP problem with a wide range of applications in data-driven industries (e.g., news, health, and defense).", "labels": [], "entities": [{"text": "Text summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.762155294418335}]}, {"text": "Single document summarization-the task of generating a short summary of a document preserving its informative content)-has been a highly studied research topic in recent years (.", "labels": [], "entities": [{"text": "Single document summarization-the task of generating a short summary of a document preserving its informative content", "start_pos": 0, "end_pos": 117, "type": "TASK", "confidence": 0.7592670228332281}]}, {"text": "Modern approaches to single document summarization using neural network architectures Our dataset and code is available at https:// github.com/Priberam/exconsumm.", "labels": [], "entities": [{"text": "single document summarization", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6026284495989481}]}, {"text": "* Now at Google London.", "labels": [], "entities": [{"text": "Google London", "start_pos": 9, "end_pos": 22, "type": "DATASET", "confidence": 0.8398714661598206}]}, {"text": "(EXCONSUMM Extractive) \u2022 (CNN) A top al Qaeda in the Arabian Peninsula leader-who a few years ago was in a U.S. detention facility-was among five killed in an airstrike in Yemen, the terror group said, showing the organization is vulnerable even as Yemen appears close to civil war.", "labels": [], "entities": []}, {"text": "\u2022 Ibrahim al-Rubaish died Monday night in what AQAP's media wing, Al-Malahem Media, called a \"crusader airstrike.\"", "labels": [], "entities": []}, {"text": "(EXCONSUMM Compressive) \u2022 (CNN) A top al Qaeda in the Arabian Peninsula leader-who a few years ago was in a U.S. detention facility-was among five killed in an airstrike in Yemen , the terror group said, showing the organization is vulnerable even as Yemen appears close to civil war.", "labels": [], "entities": []}, {"text": "\u2022 Ibrahim al-Rubaish died Monday night in what AQAP's media wing, Al-Malahem Media, called a \"crusader airstrike.\"", "labels": [], "entities": []}, {"text": "Figure 1: Summaries produced by our model.", "labels": [], "entities": []}, {"text": "For illustration, the compressive summary shows the removed spans strike-through.", "labels": [], "entities": []}, {"text": "have primarily focused on two strategies: extractive and abstractive.", "labels": [], "entities": []}, {"text": "The former select a subset of the sentences to assemble a summary.", "labels": [], "entities": []}, {"text": "The latter generates sentences that do not appear in the original document.", "labels": [], "entities": []}, {"text": "Both methods suffer from significant drawbacks: extractive systems are wasteful since they cannot trim the original sentences to fit into the summary, and they lack a mechanism to ensure overall coherence.", "labels": [], "entities": []}, {"text": "In contrast, abstractive systems require natural language generation and semantic representation, problems that are inherently harder to solve than just extracting sentences from the original document.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.8149847388267517}]}, {"text": "In this paper, we present a novel architecture that attempts to mitigate the problems above via a middle ground, compressive summarization.", "labels": [], "entities": []}, {"text": "Our model selects a set of sentences from the input document, and compresses them by removing unnecessary words, while keeping the summaries informative, concise and grammatical.", "labels": [], "entities": []}, {"text": "We achieve this by dynamically modeling the generated summary using a Long Short Term Memory (LSTM;) to produce summary state representations.", "labels": [], "entities": []}, {"text": "This state provides crucial information to iteratively increment summaries based on previously extracted information.", "labels": [], "entities": []}, {"text": "It also facilitates the generation of variable length summaries as opposed to fixed lengths, in previous extractive systems.", "labels": [], "entities": []}, {"text": "Our model can be trained in both extractive (labeling sentences for extraction) or compressive (labeling words for extraction) settings.", "labels": [], "entities": []}, {"text": "shows a summary example generated by our model.", "labels": [], "entities": []}, {"text": "Our contributions in this paper are three-fold: \u2022 we present the first end-to-end neural architecture for EXtractive and COmpressive Neural SUMMarization (dubbed EXCONSUMM, see \u00a73), \u2022 we validate this architecture on the CNN/DailyMail and the Newsroom datasets (, showing that our model generates variablelength summaries which correlate well with gold summaries in length and are concise and informative (see \u00a75), and \u2022 we provide anew CNN/DailyMail dataset annotated with automatic compressions for each sentence, and a set of compressed oracle summaries (see \u00a74).", "labels": [], "entities": [{"text": "CNN/DailyMail", "start_pos": 221, "end_pos": 234, "type": "DATASET", "confidence": 0.9089106321334839}, {"text": "Newsroom datasets", "start_pos": 243, "end_pos": 260, "type": "DATASET", "confidence": 0.939024955034256}, {"text": "CNN/DailyMail dataset", "start_pos": 437, "end_pos": 458, "type": "DATASET", "confidence": 0.9112767428159714}]}, {"text": "Experimental results show that when evaluated automatically, both the extractive and compressive variants of our model provide state-of-the-art results.", "labels": [], "entities": []}, {"text": "Human evaluation further shows that our model is better than previous state-of-the-art systems at generating informative and concise summaries.", "labels": [], "entities": []}], "datasetContent": [{"text": "We mainly used the CNN/DailyMail corpus () to evaluate our models.", "labels": [], "entities": [{"text": "CNN/DailyMail corpus", "start_pos": 19, "end_pos": 39, "type": "DATASET", "confidence": 0.9299154281616211}]}, {"text": "We used the standard splits of  We evaluated summarization quality using F 1 ROUGE (.", "labels": [], "entities": [{"text": "F 1", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9373155832290649}, {"text": "ROUGE", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.5380631685256958}]}, {"text": "We report results We show examples of both oracles in Appendix \u00a7A.1.", "labels": [], "entities": [{"text": "Appendix \u00a7A.1", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9029961824417114}]}, {"text": "in terms of unigram and bigram overlap (R1) and (R2) as a means of assessing informativeness, and the longest common subsequence (RL) as a means of assessing fluency.", "labels": [], "entities": [{"text": "unigram and bigram overlap (R1)", "start_pos": 12, "end_pos": 43, "type": "METRIC", "confidence": 0.7534761726856232}, {"text": "longest common subsequence (RL)", "start_pos": 102, "end_pos": 133, "type": "METRIC", "confidence": 0.709320863087972}]}, {"text": "In addition to ROUGE, which can be misleading when used as the only means to assess summaries, we also conducted a question-answering based human evaluation to assess the informativeness of our summaries in their ability to preserve key information from the document ().", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.9898186326026917}, {"text": "summaries", "start_pos": 84, "end_pos": 93, "type": "TASK", "confidence": 0.9327301979064941}]}, {"text": "EX-CONSUMM Compressive reports superior performance compared to LATENT+COMPRESS (+4.2 for R1, +2.6 for R2 and +3.1 for RL).", "labels": [], "entities": [{"text": "LATENT+COMPRESS", "start_pos": 64, "end_pos": 79, "type": "METRIC", "confidence": 0.6990228295326233}]}, {"text": "Our results demonstrate that our compressive system is more suitable for document summarization.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7619902193546295}]}, {"text": "It first selects sentences and then compresses them by removing irrelevant spans of words.", "labels": [], "entities": []}, {"text": "It makes use of an advance oracle sentence compressor trained on a dedicated sentence compression dataset (Sec. 4.1).", "labels": [], "entities": []}, {"text": "In contrast, LA-TENT+COMPRESS naively trains a sequence-tosequence compressor to map a sentence in the document to a sentence in the summary.", "labels": [], "entities": []}, {"text": "Both EXCONSUMM Extractive and Compressive outperform most of the abstractive systems including Pointer+Coverage (.", "labels": [], "entities": []}, {"text": "When comparing with more recent methods (, our model has comparable performance.", "labels": [], "entities": []}, {"text": "We evaluate the ability of our model to generate variable length summaries.", "labels": [], "entities": []}, {"text": "show the Pearson correlation coefficient between the lengths of the human generated summaries against each unbounded model.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 9, "end_pos": 40, "type": "METRIC", "confidence": 0.9298044244448344}]}, {"text": "Our compressive approach obtains the best results, with a Pearson correlation coefficient of 0.72 (p < 0.001).", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 58, "end_pos": 89, "type": "METRIC", "confidence": 0.9540455937385559}]}, {"text": "also shows the distribution of words: QA evaluations: limited length (Bounded) and full length (Unbounded) summaries.", "labels": [], "entities": []}, {"text": "We also show ROUGE scores for the summaries being evaluated.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.99850994348526}]}, {"text": "We report the Pearson correlation coefficient between the human and predicted summary lengths per summary for the models where predictions were available.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 14, "end_pos": 45, "type": "METRIC", "confidence": 0.9712341030438741}]}, {"text": "Interestingly, both EXCON-SUMM Extractive and Compressive follow the human distribution much better than other extractive systems (LEAD, REFRESH and LATENT), since they are able to generate variable-length summaries depending on the input text.", "labels": [], "entities": [{"text": "LEAD", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9409470558166504}, {"text": "REFRESH", "start_pos": 137, "end_pos": 144, "type": "METRIC", "confidence": 0.9893605709075928}, {"text": "LATENT", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.8561895489692688}]}, {"text": "Our compressive model generates a word distribution much closer to the abstractive Pointer+Coverage model but achieves better compression ratio; the summaries generated by Pointer+Coverage contain 59.8 words, while those generated by EXCON-SUMM Compressive have 54.3 words on average.", "labels": [], "entities": []}, {"text": "shows results from our question answering based human evaluation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.6905359923839569}]}, {"text": "We elicited human judgements in two settings: the \"Unbounded\", where participants were shown the full system produced summaries; and the \"Bounded\", where participants were shown summaries that were limited to the same size as the gold summaries.", "labels": [], "entities": []}, {"text": "For the \"Unbounded\" setting, the output summaries produced by REFRESH were able to answer most of the questions correctly, our Compressive and Extractive systems were placed at the 2nd and 3rd places respectively.", "labels": [], "entities": [{"text": "REFRESH", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.5654446482658386}]}, {"text": "We observed that our systems were able to produce more concise summaries than those produced by REFRESH (avg.", "labels": [], "entities": [{"text": "REFRESH", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.5821576118469238}]}, {"text": "length in words: 76.0 for REFRESH, 56.2 for EXCONSUMM Extractive and 54.3 for EXCONSUMM Compressive; see.", "labels": [], "entities": [{"text": "length", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9893830418586731}, {"text": "REFRESH", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9873746037483215}]}, {"text": "REFRESH is prone to generating verbose summaries, consequently it has an advantage of accumulating more information.", "labels": [], "entities": [{"text": "REFRESH", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.40353381633758545}]}, {"text": "In the \"Bounded\" setting, we aim to reduce this unfair advantage.", "labels": [], "entities": []}, {"text": "Scores are overall lower since the summary sizes are truncated to gold size.", "labels": [], "entities": []}, {"text": "The EX-CONSUMM Compressive summaries rank first and can answer 39.44% of questions correctly.", "labels": [], "entities": []}, {"text": "EX-CONSUMM Extractive retains its 3rd place answering 36.34% of questions correctly.", "labels": [], "entities": [{"text": "EX-CONSUMM Extractive", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.8635360896587372}]}, {"text": "These results demonstrate that our models generate concise and informative summaries that correlate well with the human summary lengths.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Oracle scores obtained for the CNN and Dai- lyMail testsets. We report ROUGE-1 (R1), ROUGE-2  (R2) and ROUGE-L (RL) F1 scores.", "labels": [], "entities": [{"text": "CNN", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.9626734852790833}, {"text": "Dai- lyMail testsets", "start_pos": 49, "end_pos": 69, "type": "DATASET", "confidence": 0.8530759960412979}, {"text": "ROUGE-1", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.9789039492607117}, {"text": "ROUGE-L (RL) F1", "start_pos": 113, "end_pos": 128, "type": "METRIC", "confidence": 0.7555829405784606}]}, {"text": " Table 2: Results on the CNN, DailyMail and Newsroom test sets. We report ROUGE R1, R2 and RL F 1 scores.  Extractive systems are in the first block, compressive in the second and abstractive in the third. We use -whenever  results are not available. Models marked with   *  are not directly comparable to ours as they are based on an  anonymized version of the dataset. The model marked with  show here the results for the best configuration of  See et al. (2017), referred to as Pointer-N in Grusky et al. (2018), which is trained on the whole Newsroom dataset.", "labels": [], "entities": [{"text": "CNN", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.9392359852790833}, {"text": "DailyMail", "start_pos": 30, "end_pos": 39, "type": "DATASET", "confidence": 0.7313231229782104}, {"text": "Newsroom test sets", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.9060626228650411}, {"text": "ROUGE R1", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9567417502403259}, {"text": "RL F 1 scores", "start_pos": 91, "end_pos": 104, "type": "METRIC", "confidence": 0.9503751248121262}, {"text": "Newsroom dataset", "start_pos": 546, "end_pos": 562, "type": "DATASET", "confidence": 0.9818071126937866}]}, {"text": " Table 3: Results for combined CNN/DailyMail test set.", "labels": [], "entities": [{"text": "CNN/DailyMail test set", "start_pos": 31, "end_pos": 53, "type": "DATASET", "confidence": 0.9108062982559204}]}, {"text": " Table 4: QA evaluations: limited length (Bounded) and full length (Unbounded) summaries. We also show  ROUGE scores for the summaries being evaluated. We report the Pearson correlation coefficient between the  human and predicted summary lengths", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.9980981945991516}, {"text": "Pearson correlation coefficient", "start_pos": 166, "end_pos": 197, "type": "METRIC", "confidence": 0.9657296339670817}]}]}