{"title": [{"text": "Be Consistent! Improving Procedural Text Comprehension using Label Consistency", "labels": [], "entities": [{"text": "Improving Procedural Text Comprehension", "start_pos": 15, "end_pos": 54, "type": "TASK", "confidence": 0.8135072290897369}]}], "abstractContent": [{"text": "Our goal is procedural text comprehension, namely tracking how the properties of entities (e.g., their location) change with time given a procedural text (e.g., a paragraph about pho-tosynthesis, a recipe).", "labels": [], "entities": []}, {"text": "This task is challenging as the world is changing throughout the text, and despite recent advances, current systems still struggle with this task.", "labels": [], "entities": []}, {"text": "Our approach is to leverage the fact that, for many procedural texts, multiple independent descriptions are readily available, and that predictions from them should be consistent (label consistency).", "labels": [], "entities": []}, {"text": "We present anew learning framework that leverages label consistency during training, allowing consistency bias to be built into the model.", "labels": [], "entities": []}, {"text": "Evaluation on a standard benchmark dataset for procedural text, ProPara (Dalvi et al., 2018), shows that our approach significantly improves prediction performance (F1) over prior state-of-the-art systems.", "labels": [], "entities": [{"text": "ProPara (Dalvi et al., 2018)", "start_pos": 64, "end_pos": 92, "type": "DATASET", "confidence": 0.8911182060837746}, {"text": "F1)", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.9346951246261597}]}], "introductionContent": [{"text": "We address the task of procedural text comprehension, namely tracking how the properties of entities (e.g., their location) change with time throughout the procedure (e.g., photosynthesis, a cooking recipe).", "labels": [], "entities": []}, {"text": "This ability is an important part of text understanding, allowing the reader to infer unstated facts such as how ingredients change during a recipe, what the inputs and outputs of a scientific process are, or who met whom in a news article about apolitical meeting.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.8160568177700043}, {"text": "infer unstated facts such as how ingredients change during a recipe, what the inputs and outputs of a scientific process are, or who met whom in a news article about apolitical meeting", "start_pos": 80, "end_pos": 264, "type": "Description", "confidence": 0.7808094340212205}]}, {"text": "Although several procedural text comprehension systems have emerged recently (e.g.,), NPN , and ProStruct (Tandon et al., 2018)), they still make numerous prediction errors.", "labels": [], "entities": [{"text": "NPN", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.8492490649223328}]}, {"text": "A major challenge is that fully annotated training data for this task is expensive to collect, because * Work done while at the Allen Institute for Artificial Intelligence.", "labels": [], "entities": []}, {"text": "(1) ...oxygen is given off...", "labels": [], "entities": []}, {"text": "(2) ...the plant produces oxygen...", "labels": [], "entities": []}, {"text": "(3) ...is used to create sugar and oxygen... is ambiguous as to whether oxygen is being created or merely moved, evidence from (2) and (3) suggests it is being created, helping to correctly interpret (1).", "labels": [], "entities": []}, {"text": "More generally, encouraging consistency between predictions from different paragraphs about the same process/procedure can improve performance.", "labels": [], "entities": []}, {"text": "many state changes by multiple entities may occur in a single text, requiring complex annotation.", "labels": [], "entities": []}, {"text": "To address this challenge, and thus improve performance, our goals are two-fold: first, to better leverage the training data for procedural text comprehension that is available, and second, to utilize additional unlabeled data for the task (semisupervised learning).", "labels": [], "entities": []}, {"text": "Our approach in each case is to exploit label consistency, the property that two distinct texts covering the same procedure should be generally consistent in terms of the state changes that they describe, which constitute the labels to be predicted for the text.", "labels": [], "entities": []}, {"text": "For example, in different texts describing photosynthesis, we expect them to be generally consistent about what happens to oxygen (e.g., that it is created), even if the wordings differ ().", "labels": [], "entities": []}, {"text": "Using multiple, distinct passages to understand a processor procedure is challenging.", "labels": [], "entities": []}, {"text": "Although the texts describe the same process, they might express the underlying facts at different levels of granularity, using different wordings, and including or omitting different details.", "labels": [], "entities": []}, {"text": "As a result, the details may differ between paragraphs, making them hard to align and to check for consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 99, "end_pos": 110, "type": "METRIC", "confidence": 0.974338710308075}]}, {"text": "Nonetheless, even if the details differ, we conjecture that the top-level summaries of each paragraph, which: Three (simplified) passages from ProPara describing photosynthesis, the (gold) state changes each entity undergoes at each step s 1 , s 2 , . .", "labels": [], "entities": []}, {"text": ", s T , and the summary of state changes that each entity undergoes (an aggregation of the step-by-step changes), where M = MOVED, D = DESTROYED, C = CREATED.", "labels": [], "entities": [{"text": "MOVED", "start_pos": 124, "end_pos": 129, "type": "METRIC", "confidence": 0.9716022610664368}, {"text": "DESTROYED", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.7133325338363647}]}, {"text": "Although the language and detailed changes for each passage differ considerably, the overall summaries are largely consistent (e.g., sugar is CREATED in all three).", "labels": [], "entities": [{"text": "CREATED", "start_pos": 142, "end_pos": 149, "type": "METRIC", "confidence": 0.9695815443992615}]}, {"text": "We exploit this consistency when training a model to make these predictions, by biasing the model to prefer predictions whose summary is consistent with the (predicted) summaries of other passages about the same topic.", "labels": [], "entities": []}, {"text": "Note that in the summary, we do not care about the order in which state changes happen, so summary M, D for participant CO 2 in passage 1 denotes a set of state changes rather than a sequence of state changes.", "labels": [], "entities": []}, {"text": "describe the types of state change that each entity undergoes, will be mostly consistent.", "labels": [], "entities": []}, {"text": "For example, although independent texts describing photosynthesis vary tremendously, we expect them to be consistent about what generally happens to sugar, e.g., that it is created).", "labels": [], "entities": []}, {"text": "In this paper, we introduce anew training framework, called LaCE (Label Consistency Explorer), that leverages label consistency among paragraph summaries.", "labels": [], "entities": []}, {"text": "In particular, it encourages label consistency during end-to-end training of a neural model, allowing consistency bias to improve the model itself, rather than be enforced in a post-processing step, e.g., posterior regularization (.", "labels": [], "entities": []}, {"text": "We evaluate on a standard benchmark for procedural text comprehension, called ProPara ( . We show that this approach achieves anew state-of-the-art performance in the fully supervised setting (when all paragraphs are annotated), and also demonstrate that it improves performance in the semi-supervised setting (using additional, unlabeled paragraphs) with limited training data.", "labels": [], "entities": [{"text": "ProPara", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.8173280358314514}]}, {"text": "In the latter case, summary predictions from labeled data act as noisy gold labels for the unlabeled data, allowing additional learning to occur.", "labels": [], "entities": []}, {"text": "Our contributions are thus: 1.", "labels": [], "entities": []}, {"text": "A new learning framework, LaCE, applied to procedural text comprehension that improves the label consistency among different paragraphs on the same topic.", "labels": [], "entities": []}], "datasetContent": [{"text": "LaCE achieves state-of-the-art performance on a standard benchmark dataset, ProPara, for procedural text.", "labels": [], "entities": []}, {"text": "We now present results on ProPara, the procedural text comprehension dataset introduced in ( . There are 187 topics in this dataset and a total of 488 labeled paragraphs (around 3 labeled paragraphs per topic).", "labels": [], "entities": [{"text": "ProPara", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.8655909299850464}]}, {"text": "The task is to track how entities change state through the paragraph (as described in Section 3.2) and answer 4 classes of questions about those changes (7043/913/1095 questions in each of the train/dev/test partitions respectively).", "labels": [], "entities": []}, {"text": "We compare LaCE with the baselines and prior state-of-the-art model ProStruct ( ) in two settings: (1) Fully supervised learning (using all the training data).", "labels": [], "entities": []}, {"text": "(2) Semisupervised learning (using some or all of the training data, plus additional unlabeled data).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparing the performance of LaCE with  prior methods on the test partition of ProPara.", "labels": [], "entities": [{"text": "ProPara", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9680402278900146}]}, {"text": " Table 2: LaCE ablation results", "labels": [], "entities": [{"text": "LaCE", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.4997657537460327}, {"text": "ablation", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.6369705200195312}]}, {"text": " Table 3: Comparing LaCE vs. ProStruct with vary- ing amount of labeled paragraphs available per training  topic. We compare their performance in terms of F1 on  ProPara test partition.", "labels": [], "entities": [{"text": "ProStruct", "start_pos": 29, "end_pos": 38, "type": "DATASET", "confidence": 0.8667192459106445}, {"text": "F1", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.9983910918235779}, {"text": "ProPara test partition", "start_pos": 162, "end_pos": 184, "type": "DATASET", "confidence": 0.9546542366345724}]}, {"text": " Table 5: Consistency score comparison", "labels": [], "entities": []}]}