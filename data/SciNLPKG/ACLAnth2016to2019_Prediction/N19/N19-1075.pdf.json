{"title": [{"text": "Syntax-aware Neural Semantic Role Labeling with Supertags", "labels": [], "entities": [{"text": "Neural Semantic Role Labeling", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.6562635749578476}]}], "abstractContent": [{"text": "We introduce anew syntax-aware model for dependency-based semantic role labeling that outperforms syntax-agnostic models for En-glish and Spanish.", "labels": [], "entities": [{"text": "dependency-based semantic role labeling", "start_pos": 41, "end_pos": 80, "type": "TASK", "confidence": 0.6067153960466385}]}, {"text": "We use a BiLSTM to tag the text with supertags extracted from dependency parses, and we feed these supertags, along with words and parts of speech, into a deep highway BiLSTM for semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 179, "end_pos": 201, "type": "TASK", "confidence": 0.6426666080951691}]}, {"text": "Our model combines the strengths of earlier models that performed SRL on the basis of a full dependency parse with more recent models that use no syntactic information at all.", "labels": [], "entities": [{"text": "SRL", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9852831363677979}]}, {"text": "Our local and non-ensemble model achieves state-of-the-art performance on the CoNLL 09 English and Spanish datasets.", "labels": [], "entities": [{"text": "CoNLL 09 English and Spanish datasets", "start_pos": 78, "end_pos": 115, "type": "DATASET", "confidence": 0.9433613320191702}]}, {"text": "SRL models benefit from syntactic information, and we show that supertagging is a simple, powerful , and robust way to incorporate syntax into a neural SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9447295665740967}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) is the task of identifying the semantic relationships between each predicate in a sentence and its arguments ().", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8504140873750051}]}, {"text": "While early research assumed that SRL models required syntactic information to perform well (, recent work has demonstrated that neural networks can achieve competitive and even state-of-the-art performance without any syntactic information at all (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9755634665489197}]}, {"text": "These systems have the benefits of being simpler to implement and performing more robustly on foreign languages and outof-domain data, cases where syntactic parsing is more difficult . In this paper, we show that using supertags is an effective middle ground between using full syntactic parses and using no syntactic information * Work partially done at Yale University.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.7301676869392395}]}, {"text": "A supertag is a linguistically rich description assigned to a lexical item.", "labels": [], "entities": []}, {"text": "Supertags impose complex constraints on their local context, so supertagging can bethought of as \"almost parsing\" (.", "labels": [], "entities": []}, {"text": "Supertagging has been shown to facilitate Tree-Adjoining Grammar (TAG) parsing ( and Combinatory Categorial Grammar (CCG) parsing.", "labels": [], "entities": [{"text": "Tree-Adjoining Grammar (TAG) parsing", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.6904031932353973}, {"text": "Combinatory Categorial Grammar (CCG) parsing", "start_pos": 85, "end_pos": 129, "type": "TASK", "confidence": 0.6641725046294076}]}, {"text": "We propose that supertags can serve as a rich source of syntactic information for downstream tasks without the need for full syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.706234335899353}]}, {"text": "Following, who used supertags to improve dependency parsing, we extract various forms of supertags from the dependencyannotated CoNNL 09 corpus.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.881023108959198}, {"text": "CoNNL 09 corpus", "start_pos": 128, "end_pos": 143, "type": "DATASET", "confidence": 0.9209040403366089}]}, {"text": "This contrasts with prior SRL work that uses TAG or CCG supertags).", "labels": [], "entities": [{"text": "SRL", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.974187433719635}]}, {"text": "We train a bidirectional LSTM (BiLSTM) to predict supertags and feed the predicted supertag embedding, along with word and predicted part-ofspeech embeddings, to another BiLSTM for semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 181, "end_pos": 203, "type": "TASK", "confidence": 0.6598180830478668}]}, {"text": "Predicted supertags are represented by real-valued vectors, contrasting with approaches based on syntactic paths and syntactic edges.", "labels": [], "entities": []}, {"text": "This way of incorporating information alleviates the issue of error propagation from parsing.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.6800986677408218}]}, {"text": "Supertagging has many advantages as part of a natural language processing pipeline.", "labels": [], "entities": []}, {"text": "First, as a straightforward sequence-labeling task, the supertagging architecture is much simpler than comparable systems for structured parsing.", "labels": [], "entities": []}, {"text": "Second, it is simple to extract different forms of supertags from a dependency corpus to test different hypotheses about which kinds of syntactic information are most useful for downstream tasks.", "labels": [], "entities": []}, {"text": "Our re-  sults show that supertags, by encoding just enough information, can improve SRL performance even compared to systems that incorporate complete dependency parses.", "labels": [], "entities": [{"text": "SRL", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.985872209072113}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Supertags for the sentence \"No, it wasn't black  Monday.\"", "labels": [], "entities": []}, {"text": " Table 3: Supertagging accuracies for English and Spanish. ID and OOD indicate the in-domain and out-of-domain  evaluation data respectively. The # Stags columns show the number of supertags in the corresponding training set.", "labels": [], "entities": [{"text": "ID", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9304813742637634}, {"text": "OOD", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9841219186782837}]}, {"text": " Table 4: Results on the CoNLL 2009 dev set for En- glish. BDH stands for BiLSTM + Dropout + Highway.", "labels": [], "entities": [{"text": "CoNLL 2009 dev set", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.9601891487836838}, {"text": "BDH", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9898942112922668}]}, {"text": " Table 5: Results on the CoNLL 2009 in-domain test set  for English. All standard deviations in F 1 < 0.12.", "labels": [], "entities": [{"text": "CoNLL 2009 in-domain test set", "start_pos": 25, "end_pos": 54, "type": "DATASET", "confidence": 0.9304171562194824}, {"text": "F 1", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9807717800140381}]}, {"text": " Table 6: Results on the CoNLL 2009 out-of-domain  test set for English. The standard deviation in F 1 ranges  between 0.2 and 0.35.", "labels": [], "entities": [{"text": "CoNLL 2009 out-of-domain  test set", "start_pos": 25, "end_pos": 59, "type": "DATASET", "confidence": 0.9331649661064148}, {"text": "F 1", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9502131044864655}]}, {"text": " Table 7: Results on the CoNLL 2009 test set for Span- ish. All standard deviations in F 1 < 0.1.", "labels": [], "entities": [{"text": "CoNLL 2009 test set", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9659925401210785}, {"text": "F 1", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9731542468070984}]}, {"text": " Table 8: English in-domain test results by predicate category and role label. The mate-tools (Bj\u00f6rkelund et al.,  2009) and Path-LSTM results are taken from Roth and Lapata (2016).", "labels": [], "entities": []}, {"text": " Table 11: Spanish Language Model Hyperparameters.", "labels": [], "entities": []}]}