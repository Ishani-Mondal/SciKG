{"title": [{"text": "Modeling Long-Distance Cue Integration in Spoken Word Recognition", "labels": [], "entities": [{"text": "Modeling Long-Distance Cue Integration", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8227802366018295}, {"text": "Spoken Word Recognition", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.766754945119222}]}], "abstractContent": [{"text": "Cues to linguistic categories are distributed across the speech signal.", "labels": [], "entities": []}, {"text": "Optimal categoriza-tion thus requires that listeners maintain gradient representations of incoming input in order to integrate that information with later cues.", "labels": [], "entities": []}, {"text": "There is now evidence that listeners can and do integrate cues that occur far apart in time.", "labels": [], "entities": []}, {"text": "Computational models of this integration have however been lacking.", "labels": [], "entities": []}, {"text": "We take a first step at addressing this gap by mathematically formalizing four models of how listeners may maintain and use cue information during spoken language understanding and test them on two perception experiments.", "labels": [], "entities": []}, {"text": "In one experiment, we find support for rational integration of cues at long distances.", "labels": [], "entities": []}, {"text": "Ina second, more memory and attention-taxing experiment, we find evidence in favor of a switching model that avoids maintaining detailed representations of cues in memory.", "labels": [], "entities": []}, {"text": "These results area first step in understanding what kinds of mechanisms listeners use for cue integration under different memory and attentional constraints.", "labels": [], "entities": [{"text": "cue integration", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.7189217507839203}]}], "introductionContent": [{"text": "Language is a fast, temporally unfolding signal.", "labels": [], "entities": []}, {"text": "Humans must quickly compress large amounts of information into abstract linguistic representations and meanings that contain more manageable amounts of information.", "labels": [], "entities": []}, {"text": "However, cues to linguistic categories often do not temporallly co-occur, but are distributed quite broadly across the signal.", "labels": [], "entities": []}, {"text": "Rational information integration thus requires maintenance of gradient subcategorical information so as to integrate cues that occur at different points in time.", "labels": [], "entities": [{"text": "Rational information integration", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8704025546709696}]}, {"text": "For example, one of the primary cues to the voicing of a syllable-final stop consonant in English is the duration of the preceding vowel.", "labels": [], "entities": [{"text": "duration", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9607166647911072}]}, {"text": "Thus, in order to obtain a good estimate of the voicing of a syllable-final stop, listeners must retain some subcategorical information about the preceding vowel in memory.", "labels": [], "entities": []}, {"text": "This is typical across languages and occurs at multiple timescales: cues to sound categories can come not only from proximate acoustic properties, but also from, e.g., later semantic context that could potentially occur an unlimited distance away from the target.", "labels": [], "entities": []}, {"text": "This poses a memory challenge for language comprehenders: how can one possibly maintain subcategorical information for later use when such maintenance should overload working memory?", "labels": [], "entities": [{"text": "language comprehenders", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.7414947152137756}]}, {"text": "This challenge has motivated theories of language processing that contend that listeners compress input into abstract representations as quickly as possible and discard all gradient information after a categorical perceptual decision has been reached.", "labels": [], "entities": [{"text": "language processing", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7534767687320709}]}, {"text": "According to these accounts, listeners cannot maintain gradient sub-categorical information for cue integration at any significant timescale, at certainly not beyond word boundaries.", "labels": [], "entities": [{"text": "cue integration", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.7059312909841537}]}, {"text": "However, a growing body of literature has suggested that listeners are in principle capable of maintaining subcategorical representations), including at timescales beyond the word boundary (.", "labels": [], "entities": []}, {"text": "For example, exposed participants to sentences that contained two cues about a target word, \"tent\" or \"dent\" in the sentence.", "labels": [], "entities": []}, {"text": "The first cue was the voice-onset time (VOT) of the first sound in the word, which was varied to form a continuum from more /t/-like to more /d/-like.", "labels": [], "entities": [{"text": "voice-onset time (VOT)", "start_pos": 22, "end_pos": 44, "type": "METRIC", "confidence": 0.7971716403961182}]}, {"text": "The second cue was a subsequent word that contextually biased toward either the \"tent\" interpretation (e.g., \"campground\") or the \"dent\" interpretation (e.g., \"teapot\").", "labels": [], "entities": []}, {"text": "Participants heard sentences like \"When the ?ent Sue had found in the [campground/teapot]...\", and were asked to categorize whether they heard the word \"tent\" or \"dent\" in the sentence.", "labels": [], "entities": []}, {"text": "They found that participants' categorizations were influenced both by the VOT of the sound and by subsequent context, suggesting that listeners maintained a gradient representation of the initial sound for later use in cue integration and categorization.", "labels": [], "entities": [{"text": "VOT", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9408613443374634}, {"text": "cue integration", "start_pos": 219, "end_pos": 234, "type": "TASK", "confidence": 0.7232522368431091}]}, {"text": "Subsequent studies have confirmed that listeners can maintain subcategorical representations well beyond word boundaries.", "labels": [], "entities": []}, {"text": "Despite recent interest in this phenomenon, to date there has been no comprehensive effort to spell out and quantitatively compare different models of long-distance cue integration under different memory/information constraints.", "labels": [], "entities": [{"text": "long-distance cue integration", "start_pos": 151, "end_pos": 180, "type": "TASK", "confidence": 0.6974181731541952}]}, {"text": "This paper is a first attempt to explore this space, driven largely by previous conceptual proposals.", "labels": [], "entities": []}, {"text": "We consider four different models that vary in the extent to which they maintain sub-categorical information and utilize multiple time-distant cues.", "labels": [], "entities": []}, {"text": "Two of the models maintain subcategorical information about cues overtime, and two do not.", "labels": [], "entities": []}, {"text": "These four models make distinct quantitative and qualitative predictions about how human categorization judgments should be affected by two cues.", "labels": [], "entities": []}, {"text": "We first present the mathematical models along with their predictions.", "labels": [], "entities": []}, {"text": "We then evaluate the models against human data from two behavioral experiments.", "labels": [], "entities": []}, {"text": "In these experiments, participants hear sentences like those in Connine et al. paradigm.", "labels": [], "entities": []}, {"text": "We manipulated the same two types of cues as in the Connine et al. paradigm (i.e., VOT and subsequent semantic context).", "labels": [], "entities": [{"text": "VOT", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.6245722770690918}]}], "datasetContent": [{"text": "The human data we analyze here stem from two experiments originally reported in Bushong and Jaeger (under review).", "labels": [], "entities": []}, {"text": "In both experiments, participants are exposed to sentences and have to make categorization judgments about a target word in the sentence.", "labels": [], "entities": []}, {"text": "We varied a critical word in the sentence to vary acoustically between \"tent\" and \"dent\", and a subsequent word in the sentence provides a contextual bias relevant to the critical target word (e.g., \"campgrounds\" biases towards a \"tent\" interpretation over a \"dent\" interpretation).", "labels": [], "entities": []}, {"text": "The critical difference between the two experiments is which words participants needed to categorize.", "labels": [], "entities": []}, {"text": "In Experiment 1, participants always were asked to make categorization decisions about our critical target words, \"tent\" and \"dent\".", "labels": [], "entities": []}, {"text": "In Experiment 2, this was only their task on half of the trials; on the other half, they were asked to categorize a different word in the sentence that was neither our critical target word nor the subsequent contextually biasing word (see.", "labels": [], "entities": []}, {"text": "The basic conceptual difference here is that in Experiment 1, it is relatively easy for participants to ideally integrate cues: they always know which cue they need to maintain a gradient representation of (i.e., the initial sound of the target word).", "labels": [], "entities": []}, {"text": "Experiment 2 increases the memory and attentional burden of maintaining gradient representations, however: now participants have several possible words they could be asked about and thus cannot perfectly predict which parts of the signal will be relevant for the task.", "labels": [], "entities": [{"text": "memory", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9950546026229858}]}, {"text": "We hypothesized that structure of Experiment 2 might bias participants towards discarding subcategorical information about the speech input (like the categorize-&-discard and categorize-discard-&-switch models).", "labels": [], "entities": []}, {"text": "\"After the ?ent Sue had found in the campgrounds collapsed, we went to a hotel.\"", "labels": [], "entities": []}, {"text": "Press X for \"tent\" Press M for \"dent\" (48 trials) Press X for \"tent\" Press M for \"dent\" (24 trials) OR Press X for \"hotel\" Press M for \"motel\" (24 trials) Experiment 1  Analysis 3 was the best fit to the Experiment 2 data both by standard likelihood ratio tests and Bayes Factor.", "labels": [], "entities": []}, {"text": "Within Analysis 3, we found effects of z-scored VOT ( \u02c6 \u03b2 = 0.73, z = 2.5, p = 0.01), z-scored squared VOT ( \u02c6 \u03b2 = 1.67, z = 4.873, p < 0.001), subsequent context ( \u02c6 \u03b2 = 1.28, z = 9.75, p < 0.001), and an interaction between z-scored squared VOT and susbequent context ( \u02c6 \u03b2 = 0.23, z = 2.494, p = 0.01).", "labels": [], "entities": []}, {"text": "Analysis 2 (corresponding to the ideal-integration model) was the best fit both by standard likeli- hood ratio tests and Bayes Factor.", "labels": [], "entities": [{"text": "likeli- hood ratio", "start_pos": 92, "end_pos": 110, "type": "METRIC", "confidence": 0.6897939443588257}]}, {"text": "Within Analysis 2, we found significant effects of z-scored VOT ( \u02c6 \u03b2 = 1.43, z = 5.72, p < 0.001), z-scored squared VOT ( \u02c6 \u03b2 = 2.43, z = 6.62, p < 0.001), and subsequent context ( \u02c6 \u03b2 = 0.8, z = 6.67, p < 0.001).", "labels": [], "entities": [{"text": "VOT", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.8758410215377808}]}], "tableCaptions": [{"text": " Table 1: Model comparisons for Experiments 1 and 2, both in terms of likelihood ratio tests and Bayes Factor.  Best-fitting model is bolded for each experiment.", "labels": [], "entities": [{"text": "likelihood ratio tests", "start_pos": 70, "end_pos": 92, "type": "METRIC", "confidence": 0.9413202206293741}, {"text": "Bayes Factor", "start_pos": 97, "end_pos": 109, "type": "METRIC", "confidence": 0.9402939081192017}]}]}