{"title": [{"text": "Combining Sentiment Lexica with a Multi-View Variational Autoencoder", "labels": [], "entities": []}], "abstractContent": [{"text": "When assigning quantitative labels to a dataset, different methodologies may rely on different scales.", "labels": [], "entities": []}, {"text": "In particular, when assigning polarities to words in a sentiment lexicon, annotators may use binary, categorical, or continuous labels.", "labels": [], "entities": []}, {"text": "Naturally, it is of interest to unify these labels from disparate scales to both achieve maximal coverage over words and to create a single, more robust sentiment lexicon while retaining scale coherence.", "labels": [], "entities": []}, {"text": "We introduce a generative model of sentiment lexica to combine disparate scales into a common latent representation.", "labels": [], "entities": []}, {"text": "We realize this model with a novel multi-view variational autoencoder (VAE), called SentiVAE.", "labels": [], "entities": [{"text": "VAE", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.5537035465240479}]}, {"text": "We evaluate our approach via a downstream text classification task involving nine English-Language sentiment analysis datasets; our representation outperforms six individual sentiment lexica, as well as a straightforward combination thereof.", "labels": [], "entities": [{"text": "text classification", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7282336354255676}, {"text": "English-Language sentiment analysis datasets", "start_pos": 82, "end_pos": 126, "type": "DATASET", "confidence": 0.6321569606661797}]}], "introductionContent": [{"text": "Sentiment lexica provide an easy way to automatically label texts with polarity values, and are also frequently transformed into features for supervised models, including neural networks (.", "labels": [], "entities": []}, {"text": "Indeed, given their utility, a veritable cottage industry has emerged focusing on the design of sentiment lexica.", "labels": [], "entities": []}, {"text": "In practice, using any single lexicon, unless specifically and carefully designed for the particular domain of interest, has several downsides.", "labels": [], "entities": []}, {"text": "For example, any lexicon will typically have low coverage compared to the language's entire vocabulary, and may have misspecified labels for the domain.", "labels": [], "entities": []}, {"text": "In many cases, it may therefore be desirable to combine multiple sentiment lexica into a single representation.", "labels": [], "entities": []}, {"text": "Indeed, some research on unifying such lexica has emerged, borrowing ideas from crowdsourcing (.", "labels": [], "entities": []}, {"text": "However, this is a non-trivial task, because lexica can use binary, categorical, or continuous scales to quantify polarity-in addition to different interpretations for each-and thus cannot easily be combined.", "labels": [], "entities": []}, {"text": "In, we show an example of the same word labeled using different lexica to illustrate the nature of the challenge.", "labels": [], "entities": []}, {"text": "To combine sentiment lexica with disparate scales, we introduce SentiVAE, a novel multiview variant of the variational autoencoder (VAE)).", "labels": [], "entities": []}, {"text": "SentiVAE, visualized as a graphical model in, differs from the original VAE in two ways: (i) it uses a Dirichlet latent variable (rather than a Gaussian) for each word in the combined vocabulary, and (ii) it has multiple emission distributions-one for each lexicon.", "labels": [], "entities": []}, {"text": "Because the latent variables are shared across the lex- ica, we are able to derive a common latent representation of the words' polarities.", "labels": [], "entities": []}, {"text": "The resulting model is spiritually related to a multi-view learning approach, where each view corresponds to a different lexicon.", "labels": [], "entities": []}, {"text": "Experimentally, we use SentiVAE to combine six commonly used Englishlanguage sentiment lexica with disparate scales.", "labels": [], "entities": []}, {"text": "We evaluate the resulting representation via a text classification task involving nine Englishlanguage sentiment analysis datasets.", "labels": [], "entities": [{"text": "text classification", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7149566113948822}, {"text": "Englishlanguage sentiment analysis datasets", "start_pos": 87, "end_pos": 130, "type": "DATASET", "confidence": 0.7884796410799026}]}, {"text": "For each dataset, we transform each text into an average polarity value using either our representation, one of the six commonly used sentiment lexica, or a straightforward combination thereof.", "labels": [], "entities": []}, {"text": "We then train a classifier to predict the overall sentiment of each text from its average polarity value.", "labels": [], "entities": []}, {"text": "We find that our representation outperforms the individual lexica, as well as the straightforward combination for some datasets.", "labels": [], "entities": []}, {"text": "Our representation is particularly efficacious for datasets from domains that are not well-supported by standard sentiment lexica.", "labels": [], "entities": []}, {"text": "The existing research that is most closely related to our work is SentiMerge), a Bayesian approach for aligning sentiment lexica with different continuous scales.", "labels": [], "entities": []}, {"text": "SentiMerge consists of two steps: (i) aligning the lexica via rescaling, and (ii) combining the rescaled lexica using a Gaussian distribution.", "labels": [], "entities": []}, {"text": "The authors perform token-level evaluation using a single sentiment analysis dataset where each token is labeled with its contextually dependent sentiment.", "labels": [], "entities": []}, {"text": "Because SentiMerge can only combine lexica with continuous scales, we do not include it in our evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "Source  is a two-dimensional Gaussian with mean \u03c1 w d and a diagonal covariance matrix equal to 0.01I; for VADER, Pd consists often nine-dimensional categorical distributions, collectively parameterized by \u03c1 w d ; for MPQA, Hu-Liu, and GI, Pd is a Bernoulli distribution, parameterized by \u03c1 w d ; and for SenticNet, Pd is a univariate Gaussian with mean and variance each an element in a two-dimensional \u03c1 w d . Inference.", "labels": [], "entities": [{"text": "VADER", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.4896119236946106}]}, {"text": "Inference involves forming the posterior distribution over the latent polarity values Z given the observed polarity labels X . Because computing the normalizing constant P (X ) is intractable, we instead approximate the posterior with a family of distributions Q \u03bb (Z), indexed by variational parameters \u03bb.", "labels": [], "entities": []}, {"text": "Specifically, we use To construct \u03b2 w , we first define a neural network g(\u00b7; \u03c6 d ), with a single 32-dimensional hidden layer, which \"encodes\" x w d into a threedimensional vector.", "labels": [], "entities": []}, {"text": "The output of this neural network is then transformed via a softmax as follows: The intuition behind \u03b2 w can be understood by appealing to the \"pseudocount\" interpretation of Dirichlet parameters.", "labels": [], "entities": []}, {"text": "Each lexicon contributes exactly one pseudocount, divided among positive, negative, and neutral, to what would otherwise be asymmetric, uniform Dirichlet distribution.", "labels": [], "entities": []}, {"text": "As a consequence of this construction, words that appear in more lexica will have more concentrated Dirichlets.", "labels": [], "entities": [{"text": "Dirichlets", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9729232788085938}]}, {"text": "Intuitively, this property is appealing.", "labels": [], "entities": []}, {"text": "We optimize the resulting ELBO objective) with respect to the variational parameters via stochastic variational inference (Hoffman  To evaluate our approach, we first use SentiVAE to combine the six lexica described in \u00a72.", "labels": [], "entities": [{"text": "ELBO objective", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.933491051197052}]}, {"text": "For each word win the combined vocabulary, we obtain an estimate of z w by taking the mean of Q \u03b2 w (z w ) = Dir(\u03b2 w )-i.e., by normalizing \u03b2 w . We compare this representation to using \u03b2 w directly, because \u03b2 w contains information about SentiVAE's certainty about the word's latent polarity value.", "labels": [], "entities": [{"text": "Dir", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.976239025592804}, {"text": "certainty", "start_pos": 250, "end_pos": 259, "type": "METRIC", "confidence": 0.8940801620483398}]}, {"text": "We evaluate our common latent representation via a text classification task involving nine English-language sentiment analysis datasets:.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7686473826567332}, {"text": "English-language sentiment analysis", "start_pos": 91, "end_pos": 126, "type": "TASK", "confidence": 0.6697028776009878}]}, {"text": "Each dataset consists of multiple texts (e.g., tweets, articles), each labeled with an overall sentiment (e.g., positive).", "labels": [], "entities": []}, {"text": "Descriptive statistics for each dataset are shown in Tab.", "labels": [], "entities": [{"text": "Tab", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.9555996060371399}]}, {"text": "2. For the datasets with more than three sentiment labels, we consider two versions-the original and aversion with only three (bucketed) sentiment labels.", "labels": [], "entities": []}, {"text": "For each dataset, we transform each text into an average polarity value using either our representation, one of the six lexica, 4 or a straightforward combination thereof, where the polarity value for We bucket the upper four and lower four points of VADER's nine-point scale, to yield a three-point scale.", "labels": [], "entities": [{"text": "VADER", "start_pos": 251, "end_pos": 256, "type": "DATASET", "confidence": 0.6308151483535767}]}, {"text": "Without this bucketing, our representation outperforms VADER on four of the nine datasets.", "labels": [], "entities": [{"text": "VADER", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9902620911598206}]}, {"text": "We do not bucket VADER when using it in SentiVAE or in the straightforward combination.", "labels": [], "entities": [{"text": "VADER", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9978421926498413}]}, {"text": "each word in the (combined) vocabulary is a 16-dimensional vector that consists of a concatenation of polarity values.", "labels": [], "entities": []}, {"text": "(Unlike SentiVAE, this concatenation does not yield a single sentiment lexicon that retains scale coherence, while achieving maximal coverage over words.)", "labels": [], "entities": []}, {"text": "Specifically, we replace each token with its corresponding polarity value, and then average the these values ().", "labels": [], "entities": []}, {"text": "We then use the training portion of the dataset to learn a logistic regression classifier to predict the overall sentiment of each text from its average polarity value.", "labels": [], "entities": []}, {"text": "Finally, we use the testing portion to compute the accuracy of the classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9992526173591614}]}, {"text": "3 show that our representation using \u03b2 w outperforms the individual lexica for all but one dataset, and that our representation using the mean of Q \u03b2 w (z w ) outperforms them for six datasets.", "labels": [], "entities": []}, {"text": "This is likely because Senti-VAE has a richer representation of sentiment than any individual lexicon, and it has greater coverage over words (see).", "labels": [], "entities": []}, {"text": "5 support the former reason: even when we limit the words in our representation to match those in an individual lexicon, our representation still outperforms the individual lexicon.", "labels": [], "entities": []}, {"text": "Unsurprisingly, our representation especially outperforms lexica with unidimensional scales.", "labels": [], "entities": []}, {"text": "We also find that our representation outperforms the straightforward combination for datasets from domains that are not well supported by the individual lexica (see Tabs.", "labels": [], "entities": []}, {"text": "1 and 2 for lexicon and dataset sources, respectively).", "labels": [], "entities": []}, {"text": "By combining lexica from different domains, our representation captures a general notion of sentiment that is not tailored to any specific domain.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Descriptive statistics for the training portions  of the sentiment analysis datasets. N : number of texts.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.8923637270927429}]}, {"text": " Table 3: Classification accuracies for our representation, six lexica, and a straightforward combination thereof.", "labels": [], "entities": []}, {"text": " Table 4: Coverage over words (percentage) by lexicon  for the training portions of four of the nine datasets.", "labels": [], "entities": []}, {"text": " Table 5: Classification accuracies for a 10% validation  portion of two of the datasets. The first row, labeled  SentiVAE, contains the classification accuracy for our  representation using \u03b2 w . Subsequent (lexicon-specific)  rows compare our representation (SV), restricted to the  vocabulary of that lexicon, to the lexicon itself (Lex).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9572200179100037}]}]}