{"title": [{"text": "Transfer Learning in Natural Language Processing Tutorial", "labels": [], "entities": [{"text": "Transfer Learning in Natural Language Processing Tutorial", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.7121811934879848}]}], "abstractContent": [], "introductionContent": [{"text": "The classic supervised machine learning paradigm is based on learning in isolation, a single predictive model fora task using a single dataset.", "labels": [], "entities": []}, {"text": "This approach requires a large number of training examples and performs best for well-defined and narrow tasks.", "labels": [], "entities": []}, {"text": "Transfer learning refers to a set of methods that extend this approach by leveraging data from additional domains or tasks to train a model with better generalization properties.", "labels": [], "entities": [{"text": "Transfer learning", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9436987340450287}]}, {"text": "Over the last two years, the field of Natural Language Processing (NLP) has witnessed the emergence of several transfer learning methods and architectures which significantly improved upon the state-of-the-art on a wide range of NLP tasks.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.7735249797503153}]}, {"text": "These improvements together with the wide availability and ease of integration of these methods are reminiscent of the factors that led to the success of pretrained word embeddings ( and ImageNet pretraining in computer vision, and indicate that these methods will likely become a common tool in the NLP landscape as well as an important research direction.", "labels": [], "entities": []}, {"text": "We will present an overview of modern transfer learning methods in NLP, how models are pretrained, what information the representations they learn capture, and review examples and case studies on how these models can be integrated and adapted in downstream NLP tasks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}