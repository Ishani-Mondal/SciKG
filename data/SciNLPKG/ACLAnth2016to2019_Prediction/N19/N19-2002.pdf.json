{"title": [{"text": "Locale-agnostic Universal Domain Classification Model in Spoken Language Understanding", "labels": [], "entities": [{"text": "Locale-agnostic Universal Domain Classification", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.543413981795311}]}], "abstractContent": [{"text": "In this paper, we introduce an approach for leveraging available data across multiple lo-cales sharing the same language to 1) improve domain classification model accuracy in Spoken Language Understanding and user experience even if new locales do not have sufficient data and 2) reduce the cost of scaling the domain classifier to a large number of lo-cales.", "labels": [], "entities": [{"text": "domain classification model", "start_pos": 135, "end_pos": 162, "type": "TASK", "confidence": 0.8040996392567953}, {"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.8846122622489929}, {"text": "Spoken Language Understanding", "start_pos": 175, "end_pos": 204, "type": "TASK", "confidence": 0.8810823758443197}]}, {"text": "We propose a locale-agnostic universal domain classification model based on selective multi-task learning that learns a joint representation of an utterance over locales with different sets of domains and allows locales to share knowledge selectively depending on the domains.", "labels": [], "entities": [{"text": "locale-agnostic universal domain classification", "start_pos": 13, "end_pos": 60, "type": "TASK", "confidence": 0.696611613035202}]}, {"text": "The experimental results demonstrate the effectiveness of our approach on domain classification task in the scenario of multiple locales with imbalanced data and dis-parate domain sets.", "labels": [], "entities": [{"text": "domain classification task", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.8673930565516154}]}, {"text": "The proposed approach outperforms other baselines models especially when classifying locale-specific domains and also low-resourced domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent success of intelligent personal digital assistants (IPDA) such as Amazon Alexa, Google Assistant, Apple Siri, Microsoft Cortana) in USA has led to their expansion to multiple locales and languages.", "labels": [], "entities": []}, {"text": "Some of those virtual assistant systems have been released in the United States (US), the United Kingdom (GB), Canada (CA), India (IN), and soon.", "labels": [], "entities": []}, {"text": "Such expansion typically leads to building a separate domain classification model for each new locale, and it brings two challenging issues: 1) having a separate model per locale becomes a bottleneck for rapid scaling of virtual assistant due to the resource and maintenance costs that grow linearly with the number of locales, and 2) new locales typically comes without much training data and cannot take full advantage of useful data available in other mature locales to achieve the high model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 496, "end_pos": 504, "type": "METRIC", "confidence": 0.984715461730957}]}, {"text": "In this study, we propose anew approach that reduces the cost of scaling natural language understanding to a large number of locales, given the sufficient amount of data in one of the locales of that language, while achieving high domain classification accuracy overall locales.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.7120921611785889}]}, {"text": "The approach is based on a multi-task learning framework that aims to share available data to learn a joint representation, and we introduce away to selectively share knowledge across locales while considering locale-specificity in the joint learning.", "labels": [], "entities": []}, {"text": "Multi-task learning has been widely used to tackle the problem of low-resource tasks or leveraging data between correlated targets (), but none of them consider locale-specificity when sharing knowledge to learn a joint representation.", "labels": [], "entities": [{"text": "Multi-task learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7659790515899658}]}, {"text": "We evaluate our proposed approach on the realworld utterance data spoken by customers to an intelligent personal digital assistant across different locales.", "labels": [], "entities": []}, {"text": "The experimental results empirically demonstrate that the proposed universal model scales to multiple locales, while achieving higher domain classification accuracy compared to competing locale-unified models as well as per-locale separate models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.931002676486969}]}, {"text": "The proposed model named universal model is able to successfully predict domains for locale-specific utterances while sharing common knowledge across locales without sacrificing the accuracy of predicting localeindependent domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9962109327316284}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss several design considerations that motivate our model design.", "labels": [], "entities": []}, {"text": "In Section 3, we define the problem of domain classification with multiple locales that have different domain sets, and then introduce a novel universal domain classifi-cation model with several technical details.", "labels": [], "entities": [{"text": "domain classification", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7438115179538727}]}, {"text": "We present our experimental observations over different approaches on the Amazon Alexa dataset in Section 4.", "labels": [], "entities": [{"text": "Amazon Alexa dataset", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.9286239743232727}]}, {"text": "Finally, we conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Test set breakdown", "labels": [], "entities": []}, {"text": " Table 3: Domain overlaps between locales", "labels": [], "entities": []}, {"text": " Table 4: Domain classification accuracy over different domain categories and different locales.", "labels": [], "entities": [{"text": "Domain classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8397960960865021}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9656282663345337}]}]}