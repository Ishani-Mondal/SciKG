{"title": [{"text": "Modeling performance differences on cognitive tests using LSTMs and skip-thought vectors trained on reported media consumption", "labels": [], "entities": []}], "abstractContent": [{"text": "Cognitive tests have traditionally resorted to standardizing testing materials in the name of equality and because of the onerous nature of creating test items.", "labels": [], "entities": []}, {"text": "This approach ignores participants' diverse language experiences that potentially significantly affect testing outcomes.", "labels": [], "entities": []}, {"text": "Here, we seek to explain our prior finding of significant performance differences on two cognitive tests (reading span and SPiN) between clusters of participants based on their media consumption.", "labels": [], "entities": []}, {"text": "Here, we model the language contained in these media sources using an LSTM trained on corpora of each cluster's media sources to predict target words.", "labels": [], "entities": []}, {"text": "We also model semantic similarity of test items with each cluster's corpus using skip-thought vectors.", "labels": [], "entities": []}, {"text": "We find robust, significant correlations between performance on the SPiN test and the LSTMs and skip-thought models we present here, but not the reading span test.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generalization of experimental results crucially relies on the validity and representativeness of the experiment to study the phenomenon of interest.", "labels": [], "entities": [{"text": "validity", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.979597270488739}]}, {"text": "Researchers therefore invest considerable resources in experimental design, particularly in controlling for systematic confounds.", "labels": [], "entities": []}, {"text": "When experiments rely on language samples for stimuli, this issue is further complicated because participants bring their complex and diverse language histories into the lab.", "labels": [], "entities": []}, {"text": "When participants' language experiences differ systematically and the experiment does not control for this, a confound arises that compromises experimental validity and leads to systematic bias.", "labels": [], "entities": []}, {"text": "This is the case for many cognitive tests that standardize language materials in the name of equality, whereas a more equitable approach would be to normalize test difficulty for individuals based on their experience.", "labels": [], "entities": []}, {"text": "One of the primary reasons for the traditional standardization approach over a normalization approach is that creating stimuli that are natural and free from confounds is a difficult laborious undertaking (e.g. as attested by;;).", "labels": [], "entities": []}, {"text": "The time required to create language stimuli is made worse by the fact that experiments can typically only use each target word or phrase once over the course of the experiment, meaning each stimulus must be uniquely created.", "labels": [], "entities": []}, {"text": "In addition to the effort required, experimenter bias and error possibly significantly affect results.", "labels": [], "entities": [{"text": "error", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9852681159973145}]}, {"text": "While previous automation attempts have reduced experimenter bias, error, and workload (e.g., vs.'s manual selection) the process still relies on language statistics calculated from corpora unrepresentative of many participants' language experiences (e.g.;;;).", "labels": [], "entities": [{"text": "error", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.9666433334350586}]}, {"text": "This mismatch between the language statistics used to generate test items and participants' actual language experiences represents a persistent confound detracting from experimental validity and perpetuating testing bias.", "labels": [], "entities": []}, {"text": "Our method allows participants to report for themselves the language they are comfortable with and regularly consume.", "labels": [], "entities": []}, {"text": "Allowing participants to define their own language experiences ensures stimulus representativeness, increases fairness, and captures individual variability.", "labels": [], "entities": []}, {"text": "This moves away from a model that gives researchers the power to define which language materials are representative across all participants (e.g. Black) and moves towards a model that empowers participants to define their own language variety.", "labels": [], "entities": []}, {"text": "To this end, we develop a method for evaluating lan-guage experience's effect on cognitive test performance.", "labels": [], "entities": []}, {"text": "In this work, we examine the relationship between the language that participants report consuming in media and their performance on two language-based cognitive tasks.", "labels": [], "entities": []}, {"text": "We predict that participants' greater familiarity with the particular language variety of test items (as measured by semantic similarity and statistical predictability) will decrease test difficulty, resulting in higher scores.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 188, "end_pos": 198, "type": "METRIC", "confidence": 0.8847697377204895}]}, {"text": "Our previous results showed that participants cluster into distinct populations based on media consumption habits).", "labels": [], "entities": []}, {"text": "We determined media consumption habits by administering a self-report survey, asking participants what media content they currently consume in a variety of categories (Movies, Books, TV, etc.) as well as what they consumed in their formative years.", "labels": [], "entities": []}, {"text": "K-means clustering identified two main clusters of participants based on the media sources they share in common.", "labels": [], "entities": []}, {"text": "These clusters differ significantly in their performance on a test of verbal working memory and test of functional hearing (.", "labels": [], "entities": []}, {"text": "This is especially noteworthy considering we found the clusters to be orthogonal to (i.e. evenly distributed across) the traditionally used demographic variables we elicited at the end of the survey (e.g. Race, Socioeconomic Status, etc.).", "labels": [], "entities": []}, {"text": "Here, we pursue a linguistic explanation for this performance difference by modeling the language comprising the sources participants reported consuming and examining its relationship to their performance on the behavioral tests.", "labels": [], "entities": []}, {"text": "To accomplish this, we use neural network language models to learn the joint probability function of word appearances in a corpus.", "labels": [], "entities": []}, {"text": "Learning the probability of a word appearing at a certain position in a sentence can be difficult due to sparse representation in the training corpus.", "labels": [], "entities": []}, {"text": "However, we choose these models based on their ability to capture long-distance statistical dependencies within a sentence: an advantage they enjoy over n-grams ().", "labels": [], "entities": []}, {"text": "We examine a vanilla long short-term memory (LSTM) model and an attention-based model ().", "labels": [], "entities": []}, {"text": "Both are based on recurrent neural networks and are designed to exploit semantic information distributed throughout a sentence to model the probability distribution of vocabulary words appearing as the sentence-final word).", "labels": [], "entities": []}, {"text": "In addition to modeling the predictability of sentence-final words, we also use a recurrent neural network based encoder to capture sentence-level semantics (.", "labels": [], "entities": []}, {"text": "We use this model to examine whether semantic familiarity affects participants' performances.", "labels": [], "entities": []}, {"text": "We model semantics by embedding test items and corpus sentences in a high dimensional vector space and observing the distances between each item and its neighbors from the corpus.", "labels": [], "entities": []}, {"text": "We predict that greater semantic similarity and greater sentencefinal word predictability as captured by these models will correlate with participants' performance on our cognitive tasks.", "labels": [], "entities": [{"text": "sentencefinal word predictability", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.6338578263918558}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Mean behavioral performance on SPiN target  items is significantly rank correlated to both LSTM ac- tivations and skip-thought distances for both clusters.  We find no significant correlations with the span test  for either cluster.", "labels": [], "entities": []}]}