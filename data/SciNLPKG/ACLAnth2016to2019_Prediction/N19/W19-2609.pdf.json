{"title": [{"text": "Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text", "labels": [], "entities": [{"text": "Action Graph Extraction from Text", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.7756584644317627}]}], "abstractContent": [{"text": "Understanding procedural text requires tracking entities, actions and effects as the narrative unfolds.", "labels": [], "entities": []}, {"text": "We focus on the challenging real-world problem of action-graph extraction from materials science papers, where language is highly specialized and data annotation is expensive and scarce.", "labels": [], "entities": [{"text": "action-graph extraction from materials science papers", "start_pos": 50, "end_pos": 103, "type": "TASK", "confidence": 0.8502813776334127}]}, {"text": "We propose a novel approach , TEXT2QUEST, where procedural text is interpreted as instructions for an interactive game.", "labels": [], "entities": [{"text": "TEXT2QUEST", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.8871998190879822}]}, {"text": "A learning agent completes the game by executing the procedure correctly in a text-based simulated lab environment.", "labels": [], "entities": []}, {"text": "The framework can complement existing approaches and enables richer forms of learning compared to static texts.", "labels": [], "entities": []}, {"text": "We discuss potential limitations and advantages of the approach, and release a prototype proof-of-concept, hoping to encourage research in this direction.", "labels": [], "entities": []}], "introductionContent": [{"text": "Materials science literature includes avast amount of synthesis procedures described in natural language.", "labels": [], "entities": []}, {"text": "The ability to automatically parse these texts into a structured form could allow for datadriven synthesis planning, a key enabler in the design and discovery of novel materials.", "labels": [], "entities": [{"text": "datadriven synthesis planning", "start_pos": 86, "end_pos": 115, "type": "TASK", "confidence": 0.7710671126842499}]}, {"text": "A particularly useful parsing is action graph extraction, which maps a passage describing a procedure to a symbolic action-graph representation of the core entities, operations and their accompanying arguments, as they unfold throughout the text.", "labels": [], "entities": [{"text": "action graph extraction", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.6684021155039469}]}, {"text": "Procedural text understanding is a highly challenging task for today's learning algorithms (.", "labels": [], "entities": [{"text": "Procedural text understanding", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8176535566647848}]}, {"text": "Synthesis procedures are especially challenging, as they are written in difficult and highly technical language assuming prior knowledge.", "labels": [], "entities": []}, {"text": "Some texts are long, many follow a non-linear narrative, or include logical quantifiers (\"all synthesis steps were performed in an argon atmosphere...\").", "labels": [], "entities": []}, {"text": "Furthermore, annotated data is scarce and expensive to obtain.", "labels": [], "entities": []}, {"text": "Two related research areas are grounded semantic parsing and state-tracking readingcomprehension.", "labels": [], "entities": [{"text": "grounded semantic parsing", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6170641779899597}]}, {"text": "Grounded (or executable) semantic parsers map natural language to a symbolic representation which can also bethought of as a sequence of instructions in some pre-defined programming language.", "labels": [], "entities": []}, {"text": "Such \"neural-programing\" architectures offer strong symbolic reasoning capabilities, compositionality modelling, and strong generalization (Reed and de Freitas, 2015), but are typically applied to simple texts due to prohibitive annotation costs (.", "labels": [], "entities": [{"text": "compositionality modelling", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.8688296675682068}]}, {"text": "State-tracking models ( can model complex relations between entities as they unfold, with easier training but less symbolic reasoning abilities.", "labels": [], "entities": []}, {"text": "Their applicability to longer texts is hindered as well by the lack of fine-grained annotated data.", "labels": [], "entities": []}, {"text": "In this work we describe an approach, TEXT2QUEST, that attempts to combine the strengths of both methods.", "labels": [], "entities": [{"text": "TEXT2QUEST", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.8903589844703674}]}, {"text": "Instead of trying to learn from static text, we propose to treat procedural text as instructions for an interactive game (or \"quest\").", "labels": [], "entities": []}, {"text": "The learning agent interacts with entities defined in the text by executing symbolic actions.", "labels": [], "entities": []}, {"text": "A text-based symbolic interpreter handles execution and tracking of the agent's state and actions.", "labels": [], "entities": []}, {"text": "The game is completed by \"simulating\" the instructions correctly; i.e., mapping instructions to a sequence of actions.", "labels": [], "entities": []}, {"text": "Correct simulation thus directly yields the desired action graph.", "labels": [], "entities": []}, {"text": "While there is some engineering overhead required for the simulator, we demonstrate that it is relatively straightforward to convert an annotation schema to a text-based game.", "labels": [], "entities": []}, {"text": "We believe that the benefits make it worth pursuing: the game for-: Sample surface text (left) and possible corresponding action-graph (right) for typical partial material synthesis procedure.", "labels": [], "entities": [{"text": "partial material synthesis", "start_pos": 155, "end_pos": 181, "type": "TASK", "confidence": 0.688217043876648}]}, {"text": "Operation numbers in parentheses are added for clarity.", "labels": [], "entities": [{"text": "clarity", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9501771926879883}]}, {"text": "Nodes are entities, edges are relations linking them, equivalent to actions in the text-based game.", "labels": [], "entities": []}, {"text": "mat allows applying powerful neural programming methods, with a significantly richer training environment, including advances such as curriculum learning, common-sense and domain-specific constraints, and full state tracking.", "labels": [], "entities": []}, {"text": "Such \"friendly\" environments that assist the learning agent have been shown to be valuable ( and enable learning of patterns that are often hard to learn from surface annotations alone, such as implicit effects of operations (i.e., filtering a mixture splits it into two entities).", "labels": [], "entities": []}, {"text": "Interestingly, understanding by simulation aligns well with models of human cognition; mental simulation, the ability to construct and manipulate an internal world model, is a cornerstone of human intelligence involved in many unique behaviors, including language comprehension.", "labels": [], "entities": []}, {"text": "In this work we take first steps towards this idea.", "labels": [], "entities": []}, {"text": "Our contributions are: \u2022 We propose a novel formulation of the problem of procedural text understanding as a textbased game, enabling the use of neural programming and text-based reinforcement learning (RL) methods.", "labels": [], "entities": [{"text": "procedural text understanding", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.658782829840978}, {"text": "text-based reinforcement learning (RL)", "start_pos": 168, "end_pos": 206, "type": "TASK", "confidence": 0.6644522001345953}]}, {"text": "\u2022 We present and release TEXTLABS 1 , an instance of TEXT2QUEST designed for interaction with synthesis procedure texts.", "labels": [], "entities": []}, {"text": "We focus on the material-science setting, but the approach is intended to be more generally applicable.", "labels": [], "entities": []}, {"text": "\u2022 We propose to address the problem of obtaining full-graph annotations at scale by coupling the simulator with controllable natural language generation (NLG) to generate synthetic data, also enabling curriculum learning.", "labels": [], "entities": []}, {"text": "While this work is preliminary in nature, neural programming and text-based reinforcement learning approaches are attracting significant and growing interest, and we expect advances in these areas to directly benefit future versions of the system.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a very preliminary sanity check for the TEXT-LABS environment, we train a simple text-based RL agent on synthetic games in increasingly difficult environments.", "labels": [], "entities": []}, {"text": "Difficulty is measured by maximum quest length, and the number of entities in the target action graph.", "labels": [], "entities": [{"text": "Difficulty", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9469711184501648}]}, {"text": "We use the basic LSTM-DQN agent of Narasimhan (2017) adapted to the TEXTLABS setting.", "labels": [], "entities": [{"text": "TEXTLABS setting", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.6979063600301743}]}, {"text": "The action space is where W v consists of 8 action-verbs corresponding to the entity relations tracked and additional native TextWorld actions like take (see Sec. A.1 for details).", "labels": [], "entities": []}, {"text": "W o 1 , W o 2 are (identical) sets of potential arguments corresponding to the active entities which can be interacted within the game (single and double argument actions allowed).", "labels": [], "entities": []}, {"text": "As this basic agent is not conditioned on previous actions, we further concatenate the last four commands taken to the current observation.", "labels": [], "entities": []}, {"text": "For the same reason, we also append the full quest instructions at every timestep's observation.", "labels": [], "entities": []}, {"text": "All illegal actions are pruned at each state to reduce search space size.", "labels": [], "entities": []}, {"text": "We train the agent on 100 games per level and test on 10 games.", "labels": [], "entities": []}, {"text": "Evaluation is measured by avg.", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.6753416061401367}]}, {"text": "normalized reward per game: 1 |K| T t=1 r i , where K is the true action sequence, T is the episode length (set to 50) and r i = 1 for each action in K and \u22121 for otherwise (and 0 for neutral actions like examine).", "labels": [], "entities": []}, {"text": "A normalized score of 1 means the agent performed the required actions exactly.", "labels": [], "entities": []}, {"text": "As can be seen in, the agent learns to successfully perform the required actions only for the easiest levels.", "labels": [], "entities": []}, {"text": "Examining longer games the agent did not complete, we note that the lack of conditioning on previous states is a serious limitation.", "labels": [], "entities": []}, {"text": "Equipping agents with better sequence encoding (e.g., attention), recurrent memory, and utilizing state information is expected to significantly improve performance.", "labels": [], "entities": []}, {"text": "Furthermore, due to technical limitations of the current implementation, some actions cannot be reversed.", "labels": [], "entities": []}, {"text": "This adds to the difficulty of the task, and will be addressed in future versions.", "labels": [], "entities": []}, {"text": "Finally, learning good initial policies for semantic parsers is known to be a hard problem with RL alone, and related approaches commonly use hybrid RL/supervised training methods ().", "labels": [], "entities": []}], "tableCaptions": []}