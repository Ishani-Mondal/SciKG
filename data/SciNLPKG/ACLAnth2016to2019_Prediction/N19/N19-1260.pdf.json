{"title": [{"text": "Abstractive Summarization of Reddit Posts with Multi-level Memory Networks", "labels": [], "entities": [{"text": "Abstractive Summarization of Reddit Posts", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.681559932231903}]}], "abstractContent": [{"text": "We address the problem of abstractive summa-rization in two directions: proposing a novel dataset and anew model.", "labels": [], "entities": []}, {"text": "First, we collect Reddit TIFU dataset, consisting of 120K posts from the online discussion forum Red-dit.", "labels": [], "entities": [{"text": "Reddit TIFU dataset", "start_pos": 18, "end_pos": 37, "type": "DATASET", "confidence": 0.898134191830953}]}, {"text": "We use such informal crowd-generated posts as text source, in contrast with existing datasets that mostly use formal documents as source such as news articles.", "labels": [], "entities": []}, {"text": "Thus, our dataset could less suffer from some biases that key sentences usually locate at the beginning of the text and favorable summary candidates are already inside the text in similar forms.", "labels": [], "entities": []}, {"text": "Second, we propose a novel ab-stractive summarization model named multi-level memory networks (MMN), equipped with multi-level memory to store the information of text from different levels of abstraction.", "labels": [], "entities": []}, {"text": "With quantitative evaluation and user studies via Amazon Mechanical Turk, we show the Reddit TIFU dataset is highly abstrac-tive and the MMN outperforms the state-of-the-art summarization models.", "labels": [], "entities": [{"text": "Reddit TIFU dataset", "start_pos": 86, "end_pos": 105, "type": "DATASET", "confidence": 0.8937190969785055}]}, {"text": "The code and dataset are available at http://vision.", "labels": [], "entities": []}, {"text": "snu.ac.kr/projects/reddit-tifu.", "labels": [], "entities": []}], "introductionContent": [{"text": "Abstractive summarization methods have been under intensive study, yet they often suffer from inferior performance compared to extractive methods ().", "labels": [], "entities": [{"text": "Abstractive summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.47329607605934143}]}, {"text": "Admittedly, by task definition, abstractive summarization is more challenging than extractive summarization.", "labels": [], "entities": []}, {"text": "However, we argue that such inferior performance is partly due to some biases of existing summarization datasets.", "labels": [], "entities": []}, {"text": "The source text of most datasets) originates from formal documents such as news articles, which have some structural patterns of which extractive methods better take advantage.", "labels": [], "entities": []}, {"text": "In formal documents, there could be a strong tendency that key sentences locate at the beginning of the text and favorable summary candidates are already inside the text in similar forms.", "labels": [], "entities": []}, {"text": "Hence, summarization methods could generate good summaries by simply memorizing keywords or phrases from particular locations of the text.", "labels": [], "entities": [{"text": "summarization", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.989126980304718}]}, {"text": "Moreover, if abstractive methods are trained on these datasets, they may not show much abstraction (), because they are implicitly forced to learn structural patterns (. and recently report similar extractive bias in existing datasets.", "labels": [], "entities": []}, {"text": "They alleviate this bias by collecting articles from diverse news publications or regarding intro sentences as gold summary.", "labels": [], "entities": []}, {"text": "Different from previous approaches, we propose to alleviate such bias issue by changing the source of summarization dataset.", "labels": [], "entities": [{"text": "summarization", "start_pos": 102, "end_pos": 115, "type": "TASK", "confidence": 0.9573573470115662}]}, {"text": "We exploit usergenerated posts from the online discussion forum Reddit, especially TIFU subreddit, which are more casual and conversational than news articles.", "labels": [], "entities": [{"text": "TIFU subreddit", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.9020474553108215}]}, {"text": "We observe that the source text in Reddit does not follow strict formatting and disallows models to simply rely on locational biases for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 137, "end_pos": 150, "type": "TASK", "confidence": 0.9692061543464661}]}, {"text": "Moreover, the passages rarely contain sentences that are nearly identical to the gold summary.", "labels": [], "entities": []}, {"text": "Our new large-scale dataset for abstractive summarization named as Reddit TIFU contains 122,933 pairs of an online post as source text and its corresponding long or short summary sentence.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.8195011615753174}, {"text": "Reddit TIFU", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.8586808443069458}]}, {"text": "These posts are written by many different users, but each pair of post and summary is created by the same user.", "labels": [], "entities": []}, {"text": "Another key contribution of this work is to propose a novel memory network model named multilevel memory networks (MMN).", "labels": [], "entities": []}, {"text": "Our model is equipped with multi-level memory networks, storing the information of source text from different levels of abstraction (i.e. word-level, sentencelevel, paragraph-level and document-level).", "labels": [], "entities": []}, {"text": "This design is motivated by that abstractive summarization is highly challenging and requires not only to understand the whole document, but also to find salient words, phrases and sentences.", "labels": [], "entities": []}, {"text": "Our model can sequentially read such multiple levels of information to generate a good summary sentence.", "labels": [], "entities": []}, {"text": "Most abstractive summarization methods employ sequence-to-sequence (seq2seq) models) where an RNN encoder embeds an input document and another RNN decodes a summary sentence.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 5, "end_pos": 30, "type": "TASK", "confidence": 0.5766783952713013}]}, {"text": "Our MMN has two major advantages over seq2seq-based models.", "labels": [], "entities": []}, {"text": "First, RNNs accumulate information in a few fixed-length memories at every step regardless of the length of an input sequence, and thus may fail to utilize far-distant information due to vanishing gradient.", "labels": [], "entities": []}, {"text": "It is more critical in summarization tasks, since input text is usually very long (>300 words).", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.9305150210857391}]}, {"text": "On the other hand, our convolutional memory explicitly captures long-term information.", "labels": [], "entities": []}, {"text": "Second, RNNs cannot build representations of different ranges, since hidden states are sequentially connected over the whole sequence.", "labels": [], "entities": []}, {"text": "This still holds even with hierarchical RNNs that can learn multiple levels of representation.", "labels": [], "entities": []}, {"text": "In contrast, our model exploits a set of convolution operations with different receptive fields; hence, it can build representations of not only multiple levels but also multiple ranges (e.g. sentences, paragraphs, and the whole document).", "labels": [], "entities": []}, {"text": "Our experimental results show that the proposed MMN model improves abstractive summarization performance on both our new Reddit TIFU and existing Newsroom-Abs () and XSum () datasets.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.6286614537239075}]}, {"text": "It outperforms several state-of-the-art abstractive models with seq2seq architecture such as (.", "labels": [], "entities": []}, {"text": "We evaluate with quantitative language metrics (e.g. perplexity and ROUGE) and user studies via Amazon Mechanical Turk (AMT).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 68, "end_pos": 73, "type": "METRIC", "confidence": 0.9898322820663452}]}, {"text": "The contributions of this work are as follows.", "labels": [], "entities": []}, {"text": "1. We newly collect a large-scale abstractive summarization dataset named Reddit TIFU.", "labels": [], "entities": [{"text": "Reddit TIFU", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.8600474298000336}]}, {"text": "As far as we know, our work is the first to use non-formal text for abstractive summarization.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.5540580749511719}]}, {"text": "2. We propose a novel model named multi-level memory networks (MMN).", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our model is the first attempt to leverage memory networks for the abstractive summarization.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.5970306396484375}]}, {"text": "We discuss the unique updates of the MMN over existing memory networks in Section 2. 3. With quantitative evaluation and user studies via AMT, we show that our model outperforms state-of-the-art abstractive summarization methods on both Reddit TIFU, Newsroom abstractive subset and XSum dataset.", "labels": [], "entities": [{"text": "AMT", "start_pos": 138, "end_pos": 141, "type": "DATASET", "confidence": 0.8455235958099365}, {"text": "Newsroom abstractive subset", "start_pos": 250, "end_pos": 277, "type": "DATASET", "confidence": 0.8720416824022929}, {"text": "XSum dataset", "start_pos": 282, "end_pos": 294, "type": "DATASET", "confidence": 0.8569084107875824}]}], "datasetContent": [{"text": "We introduce the Reddit TIFU dataset whose key statistics are outlined in.", "labels": [], "entities": [{"text": "Reddit TIFU dataset", "start_pos": 17, "end_pos": 36, "type": "DATASET", "confidence": 0.921613355477651}]}, {"text": "We collect data from Reddit, which is a discussion forum platform with a large number of subreddits on diverse topics and interests.", "labels": [], "entities": []}, {"text": "Specifically, we crawl all the posts from 2013-Jan to 2018-Mar in the TIFU subreddit, where every post should strictly follow the posting rules, otherwise they are removed.", "labels": [], "entities": [{"text": "TIFU subreddit", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.9867959022521973}]}, {"text": "Thanks to the following rules 1 , the posts in this subreddit can bean excellent corpus for abstractive summarization: Rule 3: Posts and titles without context will be removed.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.7148786187171936}]}, {"text": "Your title must make an attempt to encapsulate the nature of your f***up.", "labels": [], "entities": []}, {"text": "Rule 11: All posts must end with a TL;DR summary that is descriptive of your f***up and its consequences.", "labels": [], "entities": [{"text": "TL;DR summary", "start_pos": 35, "end_pos": 48, "type": "METRIC", "confidence": 0.9039734452962875}]}, {"text": "Thus, we regard the body text as source, the title as short summary, and the TL;DR summary as long summary.", "labels": [], "entities": [{"text": "TL;DR summary", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.469703733921051}]}, {"text": "As a result, we make two sets of datasets: TIFU-short and TIFU-long.", "labels": [], "entities": []}, {"text": "shows an example post of the TIFU subreddit.: Comparison of F1 ROUGE scores between different datasets (row) and methods (column).", "labels": [], "entities": [{"text": "TIFU subreddit.", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.9473257064819336}, {"text": "F1 ROUGE scores", "start_pos": 60, "end_pos": 75, "type": "METRIC", "confidence": 0.8309076428413391}]}, {"text": "PG is a stateof-the-art abstractive summarization method, and Lead and Ext-Oracle are extractive ones.", "labels": [], "entities": [{"text": "PG", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8722034692764282}]}, {"text": "PG/Lead and PG/Oracle are the ROUGE-L ratios of PG with Lead and Ext-Oracle, respectively.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9966801404953003}]}, {"text": "We report the numbers for each dataset (row) from the corresponding cited papers.", "labels": [], "entities": []}, {"text": "We evaluate the summarization performance with two language metrics: perplexity and standard F1 ROUGE scores).", "labels": [], "entities": [{"text": "summarization", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.9537080526351929}, {"text": "F1 ROUGE scores", "start_pos": 93, "end_pos": 108, "type": "METRIC", "confidence": 0.8381791909535726}]}, {"text": "We remind that lower perplexity and higher ROUGE scores indicate better performance.", "labels": [], "entities": [{"text": "perplexity", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.982395589351654}, {"text": "ROUGE", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.9983068704605103}]}, {"text": "In addition to Reddit TIFU, we also evaluate on two existing datasets: abstractive subset of Newsroom ().", "labels": [], "entities": [{"text": "Newsroom", "start_pos": 93, "end_pos": 101, "type": "DATASET", "confidence": 0.9643805027008057}]}, {"text": "These are suitable benchmarks for evaluation of our model in two aspects.", "labels": [], "entities": []}, {"text": "First, they are specialized for abstractive summarization, which meets well the goal of this work.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.6509394347667694}]}, {"text": "Second, they have larger vocabulary size (40K, 50K) than Reddit TIFU (15K), and thus we can evaluate the learning capability of our model.", "labels": [], "entities": []}, {"text": "We compare with three abstractive summarization methods, one basic seq2seq model, two heuristic extractive methods and variants of our model.", "labels": [], "entities": []}, {"text": "We choose PG (), SEASS (), DRGD ( as the state-of-the-art methods of abstractive summarization.", "labels": [], "entities": [{"text": "SEASS", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.6857692003250122}, {"text": "DRGD", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.5143468976020813}]}, {"text": "We test the attention based seq2seq model denoted as s2s-att (.", "labels": [], "entities": []}, {"text": "As heuristic extractive methods, the Lead-1 uses the first sentence in the text as summary, and the Ext-Oracle takes the sentence with the highest average score of F1 ROUGE-1/2/L with the gold summary in the text.", "labels": [], "entities": [{"text": "F1 ROUGE-1/2/L", "start_pos": 164, "end_pos": 178, "type": "METRIC", "confidence": 0.8768789867560068}]}, {"text": "Thus, Ext-Oracle can be viewed as an upper-bound for extractive methods.", "labels": [], "entities": []}, {"text": "We also test variants of our method MMN-* . To validate the contribution of each component, we exclude one of key components from our model as follows: (i) -NoDilated with conventional convolutions instead, (ii) -NoMulti with no multi-level memory (iii) -NoNGTU with existing gated linear units.", "labels": [], "entities": []}, {"text": "That is, -NoDilated quantifies the improvement by the dilated convolution, -NoMulti assesses the effect of multi-level memory, and -NoNGTU validates the normalized gated tanh unit.", "labels": [], "entities": []}, {"text": "Please refer to the Appendix for implementation details of our method.) and XSum ().", "labels": [], "entities": []}, {"text": "Except MMN, all scores are referred to the original papers.", "labels": [], "entities": [{"text": "MMN", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.3681788742542267}]}, {"text": "T-ConvS2S is the topic-aware convolutional seq2seq model.", "labels": [], "entities": []}, {"text": "compares the summarization performance of different methods on the TIFU-short/long dataset.", "labels": [], "entities": [{"text": "TIFU-short/long dataset", "start_pos": 67, "end_pos": 90, "type": "DATASET", "confidence": 0.7642452567815781}]}, {"text": "Our model outperforms the state-of-theart abstractive methods in both ROUGE and perplexity scores.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9817051887512207}]}, {"text": "PG utilizes a pointer network to copy words from the source text, but it may not be a good strategy in our dataset, which is more abstractive as discussed in.", "labels": [], "entities": []}, {"text": "SEASS shows strong performance in DUC and Gigaword dataset, in which the source text is a single long sentence and the gold summary is its shorter version.", "labels": [], "entities": [{"text": "SEASS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7175845503807068}, {"text": "Gigaword dataset", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9354495704174042}]}, {"text": "Yet, it may not be sufficient to summarize much longer articles of our dataset, even with its second-level representation.", "labels": [], "entities": []}, {"text": "DRGD is based on the variational autoencoder with latent variables to capture the structural patterns of gold summaries.", "labels": [], "entities": [{"text": "DRGD", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9349203109741211}]}, {"text": "This idea can be useful for the similarly structured formal documents but may not go well with di-  verse online text in the TIFU dataset.", "labels": [], "entities": [{"text": "TIFU dataset", "start_pos": 125, "end_pos": 137, "type": "DATASET", "confidence": 0.9722430109977722}]}, {"text": "These state-of-the-art abstractive methods are not as good as our model, but still perform better than extractive methods.", "labels": [], "entities": []}, {"text": "Although the Ext-Oracle heuristic is an upper-bound for extractive methods, it is not successful in our highly abstractive dataset; it is not effective to simply retrieve existing sentences from the source text.", "labels": [], "entities": []}, {"text": "Moreover, the performance gaps between abstractive and extractive methods are much larger in our dataset than in other datasets (, which means too that our dataset is highly abstractive.", "labels": [], "entities": []}, {"text": "compares the performance of our MMN on Newsroom-Abs and XSum dataset.", "labels": [], "entities": [{"text": "XSum dataset", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.8701768219470978}]}, {"text": "We report the numbers from the original papers.", "labels": [], "entities": []}, {"text": "Our model outperforms not only the RNN-based abstractive methods but also the convolutional-based methods in all ROUGE scores.", "labels": [], "entities": []}, {"text": "Especially, even trained on single end-to-end training procedure, our model outperforms T-ConvS2S, which necessitates two training stages of LDA and ConvS2S.", "labels": [], "entities": [{"text": "LDA", "start_pos": 141, "end_pos": 144, "type": "DATASET", "confidence": 0.74663245677948}]}, {"text": "These results assure that even on formal documents with large vocabulary sizes, our multi-level memory is effective for abstractive datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the Reddit TIFU dataset com- pared to existing opinion summarization corpora, Rot- tenTomatoes and Idebate (Wang and Ling, 2016). We  show average and median (in parentheses) values.", "labels": [], "entities": [{"text": "Reddit TIFU dataset", "start_pos": 28, "end_pos": 47, "type": "DATASET", "confidence": 0.8030318816502889}]}, {"text": " Table 2: Comparison of F1 ROUGE scores between different datasets (row) and methods (column). PG is a state- of-the-art abstractive summarization method, and Lead and Ext-Oracle are extractive ones. PG/Lead and  PG/Oracle are the ROUGE-L ratios of PG with Lead and Ext-Oracle, respectively. We report the numbers  for each dataset (row) from the corresponding cited papers.", "labels": [], "entities": []}, {"text": " Table 3: Summarization results measured by perplexity  and ROUGE-1/2/L on the TIFU-short/long dataset.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.8923619985580444}, {"text": "ROUGE-1/2/L", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9227909445762634}, {"text": "TIFU-short/long dataset", "start_pos": 79, "end_pos": 102, "type": "DATASET", "confidence": 0.8444792330265045}]}, {"text": " Table 4: Summarization results in terms of ROUGE- 1/2/L on Newsroom-Abs (", "labels": [], "entities": [{"text": "ROUGE- 1/2/L", "start_pos": 44, "end_pos": 56, "type": "METRIC", "confidence": 0.9326399138995579}, {"text": "Newsroom-Abs", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.955274760723114}]}, {"text": " Table 5: AMT results on the TIFU-short/long between  our MMN and four baselines and gold summary. We  show percentages of responses that turkers vote for our  approach over baselines.", "labels": [], "entities": [{"text": "AMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.44833189249038696}, {"text": "TIFU-short", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9129690527915955}, {"text": "MMN", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.857342004776001}]}, {"text": " Table 6: Model hyperparameters in experiments on  TIFU-short/long, Newsroom abstractive subset and  XSum.", "labels": [], "entities": [{"text": "Newsroom abstractive subset", "start_pos": 68, "end_pos": 95, "type": "DATASET", "confidence": 0.862440844376882}]}, {"text": " Table 7: Comparison of novel N-gram ratios between  Reddit TIFU and other summarization datasets.", "labels": [], "entities": [{"text": "Reddit TIFU", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.9068895280361176}]}]}