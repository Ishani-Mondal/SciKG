{"title": [{"text": "Predicting Suicide Risk from Online Postings in Reddit The UGent-IDLab submission to the CLPysch 2019 Shared Task A", "labels": [], "entities": [{"text": "Predicting Suicide Risk from Online Postings", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8704919020334879}, {"text": "CLPysch 2019 Shared Task", "start_pos": 89, "end_pos": 113, "type": "DATASET", "confidence": 0.8577485531568527}]}], "abstractContent": [{"text": "This paper describes IDLab's text classification systems submitted to Task A as part of the CLPsych 2019 shared task.", "labels": [], "entities": [{"text": "text classification", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.6211809664964676}, {"text": "CLPsych 2019 shared task", "start_pos": 92, "end_pos": 116, "type": "DATASET", "confidence": 0.7988093346357346}]}, {"text": "The aim of this shared task was to develop automated systems that predict the degree of suicide risk of people based on their posts on Reddit.", "labels": [], "entities": []}, {"text": "1 Bag-of-words features, emotion features and post-level predictions are used to derive user-level predictions.", "labels": [], "entities": []}, {"text": "Linear models and ensembles of these models are used to predict final scores.", "labels": [], "entities": []}, {"text": "We find that predicting fine-grained risk levels is much more difficult than flagging potentially at-risk users.", "labels": [], "entities": [{"text": "predicting fine-grained risk", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.8124469121297201}]}, {"text": "Furthermore, we do not find clear added value from building richer ensembles compared to simple baselines, given the available training data and the nature of the prediction task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of the CLPysch 2019 shared task is to predict the degree of suicide risk based on online postings of users.", "labels": [], "entities": [{"text": "CLPysch 2019 shared task", "start_pos": 16, "end_pos": 40, "type": "DATASET", "confidence": 0.8202877640724182}]}, {"text": "This shared task is motivated by the long-term lack of progress in predicting suicide risk., after reviewing more than 70 studies, argues that suicidality cannot be predicted effectively using traditional standard procedures, e.g., questions of clinicians about suicidal thoughts: the authors claim that a large fraction of patients (i.e., 80%) who committed suicide, did not admit contemplating suicide when asked by a general practitioner.", "labels": [], "entities": []}, {"text": "Another study by also concludes that prediction of suicide risks has not improved over the last 50 years and suggests that machine learning learning methods can contribute towards solving that challenge.", "labels": [], "entities": [{"text": "prediction of suicide", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7568587064743042}]}, {"text": "Typically, there are long periods of time between clinical encounters of patients.", "labels": [], "entities": []}, {"text": "During these periods, some patients are engaged infrequent use of social media.", "labels": [], "entities": []}, {"text": "states www.reddit.com that such usage of social media can be exploited to build binary risk classifiers.", "labels": [], "entities": []}, {"text": "However, when such systems are deployed, the number of people flagged as \"at risk\" will exceed clinical capacity for intervention.", "labels": [], "entities": []}, {"text": "This in turn motivates the design of more fine-grained prediction models, predicting various risk levels, as proposed for the current shared task.", "labels": [], "entities": []}, {"text": "Our system uses a combination of (i) bag-ofword features, (ii) emotion labels, and (iii) information derived from post-level risk features (see Section 3.1 for more details).", "labels": [], "entities": []}, {"text": "Using these features, we apply linear models to predict the scores.", "labels": [], "entities": []}, {"text": "We explore different combinations to evaluate the performance of the different models.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: Section 2 describes the data and the shared task.", "labels": [], "entities": []}, {"text": "Section 3 presents the details of the implemented system and the features.", "labels": [], "entities": []}, {"text": "Section 4 shows the experimental results obtained from the test data.", "labels": [], "entities": []}, {"text": "To compare our results to other participants in the shared task, we refer the reader to.", "labels": [], "entities": []}, {"text": "To conclude, we summarize our findings and present future directions in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the final test results of the three submitted systems on the official test set.", "labels": [], "entities": [{"text": "official test set", "start_pos": 89, "end_pos": 106, "type": "DATASET", "confidence": 0.7829351226488749}]}, {"text": "The test set consists of a total of 189 posts from 125 different users.", "labels": [], "entities": []}, {"text": "The official evaluation metric used in the shared task is the macro F 1 score on all four classes.", "labels": [], "entities": [{"text": "macro F 1 score", "start_pos": 62, "end_pos": 77, "type": "METRIC", "confidence": 0.8043287247419357}]}, {"text": "depicts the official models' performance on the test data.", "labels": [], "entities": []}, {"text": "Our baseline classifier outperforms the ensemble models.", "labels": [], "entities": []}, {"text": "This can be explained by (i) bias in the training/test split during development, (ii) the small number of annotated training instances, or (iii) the partly subjective nature of the task, and in particular the distinction between fine-grained levels such as 'low risk' and 'moderate risk'.", "labels": [], "entities": []}, {"text": "Note that, however, our most advanced model did perform best for the simpler task of detecting potentially at-risk ('flagged') users.", "labels": [], "entities": []}, {"text": "Further research is required to investigate these potential issues.", "labels": [], "entities": []}, {"text": "In addition, two more metrics were used.", "labels": [], "entities": []}, {"text": "The first metric is the F 1 score for flagged versus nonflagged users.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9901270866394043}]}, {"text": "The flagged vs. non-flagged F 1 is relevant fora use casein which the goal is to distinguish users that can be safely ignored (category (a), no risk) from those that require attention (i.e., categories (b), (c), (d)), such as when human moderators need to investigate the risk further.", "labels": [], "entities": [{"text": "F 1", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9625739753246307}]}, {"text": "shows the performance of the models in binary classification of flagged and non-flagged users, whereby the ensemble with sentiment features ('Ensemble w/o Risk) outperforms the linear baseline, but the overall ensemble with binary post-level risk predictions performs slightly better still.", "labels": [], "entities": []}, {"text": "Given the much higher scores, the task of flagging potentially at-risk users appears much simpler than making fine-grained risk-level predictions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Flagged vs Non-flagged", "labels": [], "entities": []}, {"text": " Table 3: Urgent vs Non-urgent", "labels": [], "entities": []}]}