{"title": [{"text": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents", "labels": [], "entities": [{"text": "Multimodal Information Extraction from Visually Rich Documents", "start_pos": 22, "end_pos": 84, "type": "TASK", "confidence": 0.7785381334168571}]}], "abstractContent": [{"text": "Visually rich documents (VRDs) are ubiquitous in daily business and life.", "labels": [], "entities": []}, {"text": "Examples are purchase receipts, insurance policy documents , custom declaration forms and soon.", "labels": [], "entities": [{"text": "soon", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9829234480857849}]}, {"text": "In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information.", "labels": [], "entities": [{"text": "document understanding", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.6992544084787369}]}, {"text": "Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.7200666517019272}]}, {"text": "In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs.", "labels": [], "entities": []}, {"text": "Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text em-beddings for entity extraction.", "labels": [], "entities": [{"text": "summarize the context of a text segment", "start_pos": 32, "end_pos": 71, "type": "TASK", "confidence": 0.7545155882835388}, {"text": "entity extraction", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.7739192247390747}]}, {"text": "Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF base-lines by significant margins, on two real-world datasets.", "labels": [], "entities": []}, {"text": "Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information Extraction (IE) is the process of extracting structured information from unstructured documents.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.84036203622818}]}, {"text": "IE is a classic and fundamental Natural Language Processing (NLP) task, and extensive research has been made in this area.", "labels": [], "entities": [{"text": "IE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9818469882011414}]}, {"text": "Traditionally, IE research focuses on extracting entities and relationships from plain texts, where information is primarily expressed in the format of natural language text.", "labels": [], "entities": [{"text": "IE", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.993310809135437}, {"text": "extracting entities and relationships from plain texts", "start_pos": 38, "end_pos": 92, "type": "TASK", "confidence": 0.7789059707096645}]}, {"text": "However, a large amount of information remains untapped in VRDs.", "labels": [], "entities": [{"text": "VRDs", "start_pos": 59, "end_pos": 63, "type": "TASK", "confidence": 0.7360291481018066}]}, {"text": "VRDs present information in the form of both text and vision.", "labels": [], "entities": []}, {"text": "The semantic structure of the document is not only determined by the text within it but also the visual features such as layout, tabular structure and font size of the document.", "labels": [], "entities": []}, {"text": "Examples of VRDs are purchase receipts, insurance policy documents, custom declaration forms and soon.", "labels": [], "entities": [{"text": "VRDs", "start_pos": 12, "end_pos": 16, "type": "TASK", "confidence": 0.8484053015708923}, {"text": "soon", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9796671867370605}]}, {"text": "shows example VRDs and example entities to extract.", "labels": [], "entities": []}, {"text": "VRDs can be represented as a graph of text segments), where each text segment is comprised of the position of the segment and the text within it.", "labels": [], "entities": []}, {"text": "The position of the text segment is determined by the four coordinates that generate the bounding box of the text.", "labels": [], "entities": []}, {"text": "There are other potentially useful visual features in VRDs, such as fonts and colors, which are complementary to the position of the text.", "labels": [], "entities": []}, {"text": "They are out of the scope of this paper, and we leave them to future works.", "labels": [], "entities": []}, {"text": "The problem we address in this paper is to extract the values of pre-defined entities from VRDs.", "labels": [], "entities": []}, {"text": "We propose a graph convolution based method to combine textual and visual information presented in VRDs.", "labels": [], "entities": []}, {"text": "The graph embeddings produced by graph convolution summarize the context of a text segment in the document, which are further combined with text embeddings for entity extraction using a standard BiLSTM-CRF model.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 160, "end_pos": 177, "type": "TASK", "confidence": 0.7509166896343231}]}, {"text": "The following paragraphs summarize the challenges of the task and the contributions of our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We apply our model for information extraction from two real-world datasets.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8084518611431122}]}, {"text": "They are ValueAdded Tax Invoices (VATI) and International Purchase Receipts (IPR).", "labels": [], "entities": [{"text": "ValueAdded Tax Invoices (VATI)", "start_pos": 9, "end_pos": 39, "type": "DATASET", "confidence": 0.6559383968512217}]}, {"text": "VATI consists of 3000 user-uploaded pictures and has 16 entities to exact.", "labels": [], "entities": [{"text": "VATI", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8344862461090088}]}, {"text": "Example entities are the names of buyer/seller, date and tax amount.", "labels": [], "entities": [{"text": "date", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9671430587768555}]}, {"text": "The invoices are in Chinese, and it has a fixed template since it is national standard invoice.", "labels": [], "entities": []}, {"text": "However, there are many noises in the documents which include distracting objects in the image and skewed document orientation to name a few.", "labels": [], "entities": []}, {"text": "IPR is a data set of 1500 scanned receipt documents in English which has 4 entities to exact (Invoice Number, Vendor Name, Payer Name and Total Amount).", "labels": [], "entities": [{"text": "IPR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9134407639503479}, {"text": "Total Amount", "start_pos": 138, "end_pos": 150, "type": "METRIC", "confidence": 0.8487540483474731}]}, {"text": "There exist 146 templates for the receipts.", "labels": [], "entities": []}, {"text": "Variable templates introduce additional difficulties to the IPR dataset.", "labels": [], "entities": [{"text": "IPR dataset", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.7357626706361771}]}, {"text": "For both datasets, we assign 70% of each dataset for training, 15% for validation and 15% for the test.", "labels": [], "entities": []}, {"text": "The number of text segments varies per document from 100 to 300.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F 1 score. Performance comparisons.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9774405558904012}]}, {"text": " Table 2: F 1 score. Performance comparisons for indi- vidual entities from VATI dataset.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9785760243733724}, {"text": "VATI dataset", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.9374857544898987}]}, {"text": " Table 3: F 1 score. Ablation studies of individual com- ponent of graph convolution.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9699745376904806}, {"text": "Ablation", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9657422304153442}]}, {"text": " Table 4: F 1 score. Performance comparisons of dif- ferent graph convolution layers for individual entities  from VATI dataset.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9755799571673075}, {"text": "VATI dataset", "start_pos": 115, "end_pos": 127, "type": "DATASET", "confidence": 0.883184552192688}]}, {"text": " Table 5: F 1 score. Effectiveness of multi-task learning  approach.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9775013526280721}]}]}