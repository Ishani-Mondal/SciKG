{"title": [{"text": "Self-Discriminative Learning for Unsupervised Document Embedding", "labels": [], "entities": [{"text": "Unsupervised Document Embedding", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6257663865884145}]}], "abstractContent": [{"text": "Unsupervised document representation learning is an important task providing pre-trained features for NLP applications.", "labels": [], "entities": [{"text": "Unsupervised document representation learning", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.695940874516964}]}, {"text": "Unlike most previous work which learn the embedding based on self-prediction of the surface of text, we explicitly exploit the inter-document information and directly model the relations of documents in embedding space with a discrimi-native network and a novel objective.", "labels": [], "entities": []}, {"text": "Extensive experiments on both small and large public datasets show the competitiveness of the proposed method.", "labels": [], "entities": []}, {"text": "In evaluations on standard document classification, our model has errors that are relatively 5 to 13% lower than state-of-the-art unsupervised embedding models.", "labels": [], "entities": [{"text": "document classification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7296550869941711}]}, {"text": "The reduction in error is even more pronounced in scarce label setting.", "labels": [], "entities": [{"text": "error", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9644277691841125}]}], "introductionContent": [{"text": "Rapid advance in deep methods for natural language processing has contributed to a growing need for vector representation of documents as input features.", "labels": [], "entities": []}, {"text": "Applications for such vector representations include machine translation), text classification (, image captioning (, multi-lingual document matching (, question answering (, and more.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7618545293807983}, {"text": "text classification", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8211899101734161}, {"text": "image captioning", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.7166014909744263}, {"text": "multi-lingual document matching", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.6942138671875}, {"text": "question answering", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.8340857923030853}]}, {"text": "This work studies unsupervised training for encoders that can efficiently encode long paragraph of text into compact vectors to be used as pre-trained features.", "labels": [], "entities": []}, {"text": "Existing solutions are mostly based on the assumption that a good document embedding can be learned through modeling the intra-document information by predicting the occurrence of terms inside the document itself.", "labels": [], "entities": []}, {"text": "We argue that such an assumption might not be sufficient to obtain mean- * Equally contribution.", "labels": [], "entities": []}, {"text": "ingful a document embedding as they do not consider inter-document relationships.", "labels": [], "entities": []}, {"text": "Traditional document representation models such as Bag-of-words (BoW) and TF-IDF show competitive performance in some tasks (.", "labels": [], "entities": []}, {"text": "However, these models treat words as flat tokens which may neglect other useful information such as word order and semantic distance.", "labels": [], "entities": []}, {"text": "This in turn can limit the models effectiveness on more complex tasks that require deeper level of understanding.", "labels": [], "entities": []}, {"text": "Further, BoW models suffer from high dimensionality and sparsity.", "labels": [], "entities": []}, {"text": "This is likely to prevent them from being used as input features for downstream NLP tasks.", "labels": [], "entities": []}, {"text": "Continuous vector representations for documents are being developed.", "labels": [], "entities": []}, {"text": "A successful thread of work is based on the distributional hypothesis, and use contextual information for context-word predictions.", "labels": [], "entities": []}, {"text": "Similar to, PV () is optimized by predicting the next words given their contexts in a document, but it is conditioned on a unique document vector.", "labels": [], "entities": []}, {"text": "Word2Vec-based methods for computing document embeddings achieve stateof-the-art performance on document embedding.", "labels": [], "entities": [{"text": "Word2Vec-based", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9078890681266785}]}, {"text": "Such methods rely on one strong underlying assumption: it is necessary to train the document embedding to optimize the prediction of the target words in the document.", "labels": [], "entities": []}, {"text": "In other words, the objective requires the model to learn to predict the target words in surface text.", "labels": [], "entities": []}, {"text": "We argue that there are several concerns with such a self-prediction assumption.", "labels": [], "entities": []}, {"text": "The strategy of predicting target words therefore only exploits in-document information, and do not explicitly model the inter-document distances.", "labels": [], "entities": [{"text": "predicting target words", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.880482812722524}]}, {"text": "We believe an ideal embedding space should also infer the relations among training documents.", "labels": [], "entities": []}, {"text": "For example, if all documents in the corpus are about machine learning, then the con-cept of machine learning becomes less critical in the embedding.", "labels": [], "entities": []}, {"text": "However, if the corpus contains documents from different areas of computer science, then the concept of machine learning should be encoded in any document relevant to it.", "labels": [], "entities": []}, {"text": "We therefore claim that the embedding of a document should not only depend on the document itself but also the other documents in the corpus, even though previous work seldom makes this consideration.", "labels": [], "entities": []}, {"text": "In addition, accurate predictions at the lexicon or word level do not necessarily reflect that the \"true semantics\" have been learned.", "labels": [], "entities": []}, {"text": "For example, in IMDB dataset review No.10007: \"...", "labels": [], "entities": [{"text": "IMDB dataset review No.10007", "start_pos": 16, "end_pos": 44, "type": "DATASET", "confidence": 0.9089555740356445}]}, {"text": "the father did such a good job.\"", "labels": [], "entities": []}, {"text": "Obviously, good can be replaced with synonyms like nice without significantly altering the meaning of the sentence.", "labels": [], "entities": []}, {"text": "However, since the synonyms are treated as independent tokens in PV and Doc2VecC, the lexicon good must be predicted exactly.", "labels": [], "entities": []}, {"text": "Moreover, to accurately predict the final word job, the embedding probably only needs to know that did a good job is a very common phrase, without having to understand the true meaning of job.", "labels": [], "entities": []}, {"text": "This example shows that in order to accurately predict a local lexicon, the embedding might opt to encode the syntactic relationship instead of true semantics.", "labels": [], "entities": []}, {"text": "Enforcing document embeddings to make predictions at the word level could be too strong of an objective.", "labels": [], "entities": []}, {"text": "More specifically, we argue that the true semantics should not only depend on a small context, but also the relations with other training documents at document level.", "labels": [], "entities": []}, {"text": "To address the above concerns we propose a novel model for learning document embedding unsupervisedly.", "labels": [], "entities": []}, {"text": "In contrast with previous work (PV and Doc2Vec), we model documents according to two aspects.", "labels": [], "entities": []}, {"text": "First, we abandon the concept of context word prediction when training an embedding model.", "labels": [], "entities": [{"text": "context word prediction", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.609522412220637}]}, {"text": "Instead we propose a self-supervision learning framework to model inter-document information.", "labels": [], "entities": []}, {"text": "Conceptually, we use the embedding to determine whether a sentence belongs to a document.", "labels": [], "entities": []}, {"text": "Our encoder is equipped with a discriminator to classify whether a sentence embedding is derived from a document given that document's embedding.", "labels": [], "entities": []}, {"text": "This explicitly enforces documents to be spread reasonably in the embedding space without any labels so that they can be discriminated.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first deep embedding work to explicitly model the inter-document relationship.", "labels": [], "entities": []}, {"text": "Second, in our approach the predictions are inferred at the sentence level.", "labels": [], "entities": []}, {"text": "This avoids the effect of only predicting the surface meaning in word level (e.g. good vs. nice).", "labels": [], "entities": []}, {"text": "Unlike previous work, our model is explicitly optimized to represent documents as combinations of sequence embedding beyond words seen in training.", "labels": [], "entities": []}, {"text": "Below we summarize the key contributions: \u2022 We present a deep and general framework and a novel objective for learning document representation unsupervisedly.", "labels": [], "entities": [{"text": "learning document representation", "start_pos": 110, "end_pos": 142, "type": "TASK", "confidence": 0.6277043024698893}]}, {"text": "Our models are end-to-end, easy to implement, and flexible to extend.", "labels": [], "entities": []}, {"text": "\u2022 We perform experiments through sentiment analysis and topic classification to show that our model, referred to as self-discriminative document embedding (SDDE), is competitive to the state-of-the-art solutions based on traditional context-prediction objectives.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9407556056976318}, {"text": "topic classification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7349468171596527}]}, {"text": "\u2022 Our extensive experiments quantitatively and qualitatively show that SDDE learns more effective features that capture more documentlevel information.", "labels": [], "entities": [{"text": "SDDE", "start_pos": 71, "end_pos": 75, "type": "TASK", "confidence": 0.9677671790122986}]}, {"text": "To the best of our knowledge, SDDE is the first deep network to model inter-instance information at document level.", "labels": [], "entities": []}, {"text": "\u2022 We further propose to evaluate unsupervised document embedding models in weaklysupervised classification.", "labels": [], "entities": []}, {"text": "That is, lots of unlabeled documents with only few labels attached to some of them, which is a realistic scenario that unsupervised embedding could be particularly useful.", "labels": [], "entities": []}], "datasetContent": [{"text": "Generally, it is not easy to evaluate an unsupervised embedding model.", "labels": [], "entities": []}, {"text": "In Section 4.3 and 4.4, we evaluate the performance on standard document classification following the common practice used by previous work: a classification task with a linear SVM () trained on the labels in each dataset.", "labels": [], "entities": [{"text": "standard document classification", "start_pos": 55, "end_pos": 87, "type": "TASK", "confidence": 0.7007273634274801}]}, {"text": "Next, we study unsupervised document embedding on two novel aspects.", "labels": [], "entities": []}, {"text": "In Section 4.5, we study a weakly-supervised classification setting that fits the realistic scenario of using unsupervised embedding with only a few labels.", "labels": [], "entities": []}, {"text": "In Section 4.6, we provide a metric to evaluate the effectiveness of modeling inter-document information.", "labels": [], "entities": []}, {"text": "We first compare our models with the others stateof-the-art competitors.", "labels": [], "entities": []}, {"text": "RNN-LM ( and Skip-thought ( are RNN-based.", "labels": [], "entities": [{"text": "RNN-LM", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.76655513048172}]}, {"text": "SIF (), W2V-AVG ( , and WME () are two-stage approach that post-processing on word embedding.", "labels": [], "entities": []}, {"text": "We collect the results reported on the widely-used benchmark sentiment classification dataset IMDB.", "labels": [], "entities": [{"text": "benchmark sentiment classification dataset IMDB", "start_pos": 51, "end_pos": 98, "type": "TASK", "confidence": 0.7172527015209198}]}, {"text": "For PV, we use Gensim implementation; versions https://www.nltk.org/  Next, we borrow some public large-scale dataset in to further validate the effectiveness of SDDE compared to the other models.", "labels": [], "entities": []}, {"text": "For Doc2vecC and SIF, we use the code from the au-Label: 1 i don t even like watching those late night talk shows , but i found this one really interesting . i imagine it s probably close to the truth -it feels like an honest account , if that means anything . kinda feel for the people somewhat when you watch it . a nice movie fora saturday night . SDDE: 0.89 Doc2VecC: 0.27 Label: 0 i ma boorman fan but this is arguably his least successful film . comedy has never been his strong suit , and here his attempts at screwball farce are clumsily done . still , it s almost worth seeing for boorman s eye for talent : this is one of uma thurman s first starring roles , and as always she is ravishing to watch . on a sad side note boorman wrote the script with his daughter , <UNK> who died a couple years ago . SDDE: 0.12 Doc2VecC: 0.75 Label: 0 michael dudikoff stars as joe armstrong a martial artist who fights ninjas who are stealing weapons from the u s army , in this entertaining yet admittedly brainless martial arts actioner , which is hampered by too many long pauses without action , but helped by some high energy action <UNK> as well as steve james performance . SDDE: 0.77 Doc2VecC: 0.10   thors.", "labels": [], "entities": []}, {"text": "We use SIF to generate document embedding with Word2Vec trained on each dataset as its inputs.", "labels": [], "entities": []}, {"text": "SDDE-AVG performs slightly better across different dataset.", "labels": [], "entities": []}, {"text": "We hypothesis SDDE gets larger improvement on IMDB dataset since SDDE can handle longer documents better by exploiting sentence embeddings.", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8955251276493073}]}, {"text": "On the other hand, the RNN version of SDDE performs significantly worse than the word-averaging version.", "labels": [], "entities": []}, {"text": "We may remind the reader that state-ofthe-art unsupervised document embedding models are not RNN-based.", "labels": [], "entities": []}, {"text": "The effects of word order are still unclear.", "labels": [], "entities": [{"text": "word order", "start_pos": 15, "end_pos": 25, "type": "TASK", "confidence": 0.7664452493190765}]}, {"text": "provides a study of sentence embedding.", "labels": [], "entities": []}, {"text": "We hypothesize that it maybe difficult for an RNN encoder to learn to incorporate multi-domain information in datasets with many classes (e.g., DBpedia) unsupervisedly.", "labels": [], "entities": []}, {"text": "This would be our future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the datasets. Length of document  and sentence in words (mean\u00b1variance), which could  be high for real-world scenarios such as online reviews.", "labels": [], "entities": [{"text": "Length", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9934064149856567}, {"text": "mean\u00b1variance)", "start_pos": 81, "end_pos": 95, "type": "METRIC", "confidence": 0.7805923968553543}]}, {"text": " Table 2: Hyperparameters used in experiments. The  document embedding trained with the same hyperpa- rameters are used for all the evaluations without task- specific tuning.", "labels": [], "entities": []}, {"text": " Table 2. All the models use the same embedding  size for fair comparison. The trained document  embedding are used for all the evaluations without  specific tuning.", "labels": [], "entities": []}, {"text": " Table 3: Sentiment Classification on IMDB Bench- mark. *Results are collected from Chen (2017).", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9593097865581512}, {"text": "IMDB Bench- mark", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.9146369397640228}]}, {"text": " Table 4: Mean of #sentence per document in IMDB  dataset, in groups of classification correctness.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9977929592132568}, {"text": "IMDB  dataset", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.9803829193115234}, {"text": "classification correctness", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.7546696662902832}]}, {"text": " Table 5: IMDB Examples with scores 0 to 1 for negative to positive assigned by SVM.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.8426616191864014}, {"text": "SVM", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.9033752679824829}]}, {"text": " Table 7: Testing error (%) in weakly-supervised set- ting. Only 1k labeled data per class were used. 4.5).", "labels": [], "entities": [{"text": "Testing error", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.8978817760944366}]}, {"text": " Table 8: Distances of Intra & Inter-class cosine similarity. A for IntraCos and E for InterCos, note that they cannot  be compared across different models. Instead, distance A-E defined in Equation 7 is reported to study a method's  effectiveness of modeling inter-document features. The higher the number the better.", "labels": [], "entities": []}]}