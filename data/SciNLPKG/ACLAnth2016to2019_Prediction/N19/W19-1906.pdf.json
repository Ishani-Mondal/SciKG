{"title": [{"text": "A Novel System for Extractive Clinical Note Summarization using EHR Data", "labels": [], "entities": [{"text": "Extractive Clinical Note Summarization", "start_pos": 19, "end_pos": 57, "type": "TASK", "confidence": 0.8155267685651779}, {"text": "EHR", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.7825623154640198}]}], "abstractContent": [{"text": "While much data within a patient's electronic health record (EHR) is coded, crucial information concerning the patient's care and management remain buried in unstructured clinical notes, making it difficult and time-consuming for physicians to review during their usual clinical workflow.", "labels": [], "entities": []}, {"text": "In this paper, we present our clinical note processing pipeline, which extends beyond basic medical natural language processing (NLP) with concept recognition and relation detection to also include components specific to EHR data, such as structured data associated with the encounter, sentence-level clinical aspects, and structures of the clinical notes.", "labels": [], "entities": [{"text": "medical natural language processing (NLP)", "start_pos": 92, "end_pos": 133, "type": "TASK", "confidence": 0.7596523676599775}, {"text": "concept recognition", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.7367701381444931}, {"text": "relation detection", "start_pos": 163, "end_pos": 181, "type": "TASK", "confidence": 0.803491473197937}]}, {"text": "We report on the use of this pipeline in a disease-specific extractive text summarization task on clinical notes, focus-ing primarily on progress notes by physicians and nurse practitioners.", "labels": [], "entities": [{"text": "disease-specific extractive text summarization task", "start_pos": 43, "end_pos": 94, "type": "TASK", "confidence": 0.6959792673587799}]}, {"text": "We show how the addition of EHR-specific components to the pipeline resulted in an improvement in our overall system performance and discuss the potential impact of EHR-specific components on other higher-level clinical NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "EHRs area longitudinal record of the patient's health information consisting of structured (e.g. vitals, medications, labs, procedures) and unstructured (e.g. progress notes, discharge summaries, diagnostic test reports) information.", "labels": [], "entities": [{"text": "EHRs area longitudinal record of the patient's health information consisting of structured (e.g. vitals, medications, labs, procedures) and unstructured (e.g. progress notes, discharge summaries, diagnostic test reports) information", "start_pos": 0, "end_pos": 232, "type": "Description", "confidence": 0.7225832241146188}]}, {"text": "Clinical notes within EHRs are traditionally a rich source of data where detailed information about the patient's medical history and clinical care process is documented.", "labels": [], "entities": []}, {"text": "However, physicians at the point of care are mostly unable to review much of this unstructured information due to the abundance of notes within a patient EHR and the time constraint inherent in the clinical setting.", "labels": [], "entities": []}, {"text": "Also, the move from paper records to EHRs have unintentionally resulted in issues of note bloat, where use of templates and copy-paste have introduced unnecessary or redundant data into clinical notes, worsening the problem of information overload and making it more difficult for physicians to identify key clinical data with potentially negative consequences.", "labels": [], "entities": []}, {"text": "In the clinical care process, what is considered key clinical data within a clinical document depends greatly on the user and their task; what is important fora physician to know while diagnosing a patient is different from what is important fora social worker to know when arranging post-discharge home care.", "labels": [], "entities": []}, {"text": "Building off the idea of a problem-oriented medical record introduced by, we decided to approach this problem of information overload within EHRs from a disease-specific perspective.", "labels": [], "entities": []}, {"text": "We propose an automated summarization system that produces an extractive summary for each note containing only the most important information relevant for managing a patient's hypertension or diabetes mellitus at the point of care.", "labels": [], "entities": []}, {"text": "There are multiple challenges in generating a disease-specific extractive summary on clinical text.", "labels": [], "entities": []}, {"text": "First of all, the abundance of domain-specific terminology and presence of non-standard abbreviations and misspellings make machine comprehension of clinical text a much more complex task.", "labels": [], "entities": [{"text": "machine comprehension of clinical text", "start_pos": 124, "end_pos": 162, "type": "TASK", "confidence": 0.8623216867446899}]}, {"text": "Secondly, the use of temporal narratives with reference to multiple diseases and the inherent interrelatedness of different diseases and other clinical concepts makes it difficult to determine what is \"diseasespecific\" in the context of our summary.", "labels": [], "entities": []}, {"text": "Moreover, the heavy use of templates, copy-paste, and imported data within clinical notes ( suggests that medical NLP at the concept level is insufficient for differentiation between \"important\" and \"unimportant\" information.", "labels": [], "entities": []}, {"text": "Last of all, due to the regulations surrounding use and sharing of protected health information, and the need for expert annotation, clinical NLP systems typically only have access to a limited amount of labeled data.", "labels": [], "entities": []}, {"text": "To address these concerns, we leverage individual components, trained on separate labeled datasets, that target lower level clinical NLP tasks such as identifying note structure and specific clinical events of interest, and chain these individual components together into a pipeline that automatically generates diseasespecific summaries from clinical notes.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset consists of patient EHRs within a large ambulatory multi-specialty medical group in the US that contain a known diagnosis of hypertension and/or diabetes mellitus based on their structured encounter diagnosis list.", "labels": [], "entities": []}, {"text": "We selected notes within these patient EHRs authored by physicians or nurse practitioners and manually reviewed approximately half of the selected notes to ensure that at least one of our diseases of interest, hypertension or diabetes mellitus, was addressed at the visit documented in that note.", "labels": [], "entities": []}, {"text": "We made the decision to focus on physician and nurse practitioner notes because those providers are the primary decisionmaker in the patients' clinical care management.", "labels": [], "entities": []}, {"text": "Manual review was performed on approximately half of the notes to ensure a sufficient number of positive examples from the ground truth generation effort.", "labels": [], "entities": [{"text": "ground truth generation", "start_pos": 123, "end_pos": 146, "type": "TASK", "confidence": 0.6539974709351858}]}, {"text": "The resulting corpus consisted of 3,453 outpatient clinical notes over 762 patients, with an average length of 138 sentences per note.", "labels": [], "entities": []}, {"text": "The corpus was annotated by 12 internal medicine or family medicine physicians over the course of 6 months.", "labels": [], "entities": []}, {"text": "Physicians were asked to review each note and annotate information relevant to the physicians' decision-making for management of the patient's hypertension or diabetes mellitus, with the understanding that the annotated information would be presented together as a disease-focused summary of the note.", "labels": [], "entities": []}, {"text": "Examples of relevant information included in the summary are statements about the current problem status, any signs or symptoms experienced by the patient, desirable and undesirable effects of current treat- ment, and any changes to current treatment plan.", "labels": [], "entities": []}, {"text": "Each note was independently reviewed and annotated by two physicians, and then adjudicated by a third MD.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement is reported in the \"Results\" section.", "labels": [], "entities": []}, {"text": "shows an example of a clinical note and its extractive summaries for hypertension and diabetes mellitus.", "labels": [], "entities": []}, {"text": "Evaluating a text summary is challenging.", "labels": [], "entities": []}, {"text": "Generally, the ways of evaluating the performance of automatically generated summarizations can be categorized into intrinsic and extrinsic evaluation methods.", "labels": [], "entities": []}, {"text": "Intrinsic evaluation directly compares the generated summary to the ground truth summary.", "labels": [], "entities": []}, {"text": "For example, co-selection measures calculate the precision, recall, and F-score at the sentence level; and contentbased measures such as ROUGE) compares at word level using n-gram and/or longest common subsequence.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9996163845062256}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9978017210960388}, {"text": "F-score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9990841150283813}, {"text": "ROUGE", "start_pos": 137, "end_pos": 142, "type": "METRIC", "confidence": 0.9905290007591248}]}, {"text": "Intrinsic evaluation can also be done qualitatively, by domain experts using a Likert-type scale.", "labels": [], "entities": [{"text": "Intrinsic evaluation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6632972806692123}]}, {"text": "Extrinsic evaluation measures the quality of the automatic summaries indirectly, fora given task.", "labels": [], "entities": []}, {"text": "For example, how much time a physician can save in their daily practice with or without the help of such summarization.", "labels": [], "entities": []}, {"text": "In this work we present our results using intrinsic evaluation with co-selection measures.", "labels": [], "entities": []}, {"text": "Studies using qualitative intrinsic measurements and quantitative extrinsic evaluation are being planned  for the future; those results will be reported at a later time and are beyond the scope of this paper.", "labels": [], "entities": []}, {"text": "In this work, we evaluated the system using the co-selection measures, i.e., calculating sentence level F-score between system-identified span and a physician-annotated span, using 10-fold cross validation.", "labels": [], "entities": [{"text": "F-score", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.565575897693634}]}, {"text": "In this study, we use an intrinsic evaluation of our generated summary using precision, recall, and Fscore to compare against ground truth created by physicians.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9995610117912292}, {"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9988428354263306}, {"text": "Fscore", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9997534155845642}]}, {"text": "However, these metrics do not fully capture the nuances of what should or should not be included in a clinical summary.", "labels": [], "entities": []}, {"text": "The wide spectrum of what could be considered \"important\" to a physician means that not all false negatives are equivalent; some information is critical to patient management and should never be missed, while the importance and relevance of some other pieces of information are debatable amongst different physicians.", "labels": [], "entities": []}, {"text": "Similarly, not all false positives are equivalent; some false positives are completely wrong and unrelated to the disease at hand, while others comprise of sentences that were not included in the ground truth but still provide relevant and useful information.", "labels": [], "entities": []}, {"text": "Adverse drug events are an example of important information that physicians are particularly sensitive to.", "labels": [], "entities": []}, {"text": "ADEs have great impact on patient safety and is considered an important insight to extract per our annotation guidelines.", "labels": [], "entities": []}, {"text": "These are rare yet important events for physicians to be aware of when managing a patient's care.", "labels": [], "entities": []}, {"text": "We have been actively participating in recent ADE detection related challenges and developed our component using BiLSTM-CRF (.", "labels": [], "entities": [{"text": "ADE detection", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9426719546318054}, {"text": "BiLSTM-CRF", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.669269859790802}]}, {"text": "A major task for this component is to distinguish adverse drug events (e.g. \"His cough improved off lisinopril\") from indication fora drug (e.g. \"His hypertension improved on lisinopril\"), i.e., to identify the type of relation between a drug and a signor symptom.", "labels": [], "entities": []}, {"text": "This is often impossible without medical knowledge, and is an example of why a generic summarization algorithm from other domains will notwork on clinical narratives out of the box, as the importance of a sentence depends on medical", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: F-scores for hypertension and diabetes melli- tus summarization using different models.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984346032142639}]}]}