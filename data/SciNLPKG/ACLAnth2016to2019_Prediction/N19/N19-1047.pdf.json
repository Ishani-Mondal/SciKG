{"title": [{"text": "Content Differences in Syntactic and Semantic Representations", "labels": [], "entities": [{"text": "Content Differences", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6902556419372559}, {"text": "Syntactic and Semantic Representations", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.5851046964526176}]}], "abstractContent": [{"text": "Syntactic analysis plays an important role in semantic parsing, but the nature of this role remains a topic of ongoing debate.", "labels": [], "entities": [{"text": "Syntactic analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8826842606067657}, {"text": "semantic parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.839817076921463}]}, {"text": "The debate has been constrained by the scarcity of empirical comparative studies between syntactic and semantic schemes, which hinders the development of parsing methods informed by the details of target schemes and constructions.", "labels": [], "entities": []}, {"text": "We target this gap, and take Universal Dependencies (UD) and UCCA as a test case.", "labels": [], "entities": [{"text": "UCCA", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.8489534854888916}]}, {"text": "After abstracting away from differences of convention or formalism, we find that most content divergences can be ascribed to: (1) UCCA's distinction between a Scene and a non-Scene; (2) UCCA's distinction between primary relations , secondary ones and participants; (3) different treatment of multi-word expressions, and (4) different treatment of inter-clause linkage.", "labels": [], "entities": []}, {"text": "We further discuss the long tail of cases where the two schemes take markedly different approaches.", "labels": [], "entities": []}, {"text": "Finally, we show that the proposed comparison methodology can be used for fine-grained evaluation of UCCA parsing , highlighting both challenges and potential sources for improvement.", "labels": [], "entities": [{"text": "UCCA parsing", "start_pos": 101, "end_pos": 113, "type": "TASK", "confidence": 0.7051073908805847}]}, {"text": "The substantial differences between the schemes suggest that semantic parsers are likely to benefit downstream text understanding applications beyond their syntactic counterparts.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7278011441230774}]}], "introductionContent": [{"text": "Semantic representations hold promise due to their ability to transparently reflect distinctions relevant for text understanding applications.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.7863465249538422}]}, {"text": "For example, syntactic representations are usually sensitive to distinctions based on POS (part of speech), such as between compounds and possessives.", "labels": [], "entities": []}, {"text": "Semantic schemes are less likely to make this distinction since a possessive can often be paraphrased as a compound and vice versa (e.g., \"US president\"/\"president of the US\"), but may distinguish different senses of possessives (e.g., \"some of the presidents\" and \"inauguration of the presidents\").", "labels": [], "entities": []}, {"text": "Nevertheless, little empirical study has been done on what distinguishes semantic schemes from syntactic ones, which are still in many cases the backbone of text understanding systems.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.8021823763847351}]}, {"text": "Such studies are essential for (1) determining whether and to what extent semantic methods should be adopted for text understanding applications; (2) defining better inductive biases for semantic parsers, and allowing better use of information encoded in syntax; (3) pointing at semantic distinctions unlikely to be resolved by syntax.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7511112987995148}]}, {"text": "The importance of such an empirical study is emphasized by the ongoing discussion as to what role syntax should play in semantic parsing, if any (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.758483350276947}]}, {"text": "This paper aims to address this gap, focusing on content differences.", "labels": [], "entities": []}, {"text": "As a test case, we compare relatively similar schemes ( \u00a72): the syntactic Universal Dependencies (UD;, and the semantic Universal Conceptual Cognitive Annotation (UCCA;.", "labels": [], "entities": []}, {"text": "We UCCA-annotate the entire web reviews section of the UD EWT corpus ( \u00a73), and develop a converter to assimilate UD and UCCA, which use formally different graphs ( \u00a74).", "labels": [], "entities": [{"text": "UD EWT corpus", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.9241377313931783}]}, {"text": "We then align their nodes, and identify which UCCA categories match which UD relations, and which are unmatched.", "labels": [], "entities": []}, {"text": "Most content differences are due to ( \u00a75): 1.", "labels": [], "entities": []}, {"text": "UCCA's distinction between words and phrases that evoke Scenes (events) and ones that do not.", "labels": [], "entities": [{"text": "UCCA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9395498037338257}]}, {"text": "For example, eventive and non-eventive nouns are treated differently in UCCA, but similarly in UD.", "labels": [], "entities": [{"text": "UCCA", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.8252059817314148}]}, {"text": "2. UCCA's distinction between primary relations, secondary relations and Participants, in contrast to UD's core/non-core distinction.", "labels": [], "entities": [{"text": "UCCA", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.7789261937141418}]}, {"text": "3. Different treatment of multi-word expressions (MWEs), where UCCA has a stronger tendency to explicitly mark them.", "labels": [], "entities": [{"text": "multi-word expressions (MWEs)", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.7296806097030639}, {"text": "UCCA", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.8639973998069763}]}, {"text": "4. UCCA's conflation of several syntactic realizations of inter-clause linkage, and disambiguation of other cases that UD treats similarly.", "labels": [], "entities": [{"text": "UCCA", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.7843630313873291}]}, {"text": "We show that the differences between the schemes are substantial, and suggest that UCCA parsing in particular and semantic parsing in general are likely to benefit downstream text understanding applications.", "labels": [], "entities": [{"text": "UCCA parsing", "start_pos": 83, "end_pos": 95, "type": "TASK", "confidence": 0.7529067397117615}, {"text": "semantic parsing", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.7259919196367264}, {"text": "text understanding", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.7510142624378204}]}, {"text": "For example, only 72.9% of UCCA Participants are UD syntactic arguments, i.e., many semantic participants cannot be recovered from UD.", "labels": [], "entities": []}, {"text": "Our findings are relevant to other semantic representations, given their significant overlap in content . A methodology for comparing syntactic and semantic treebanks can also support fine-grained error analysis of semantic parsers, as illustrated by for AMR (.", "labels": [], "entities": [{"text": "fine-grained error analysis of semantic parsers", "start_pos": 184, "end_pos": 231, "type": "TASK", "confidence": 0.5766210854053497}, {"text": "AMR", "start_pos": 255, "end_pos": 258, "type": "DATASET", "confidence": 0.8639301657676697}]}, {"text": "To demonstrate the utility of our comparison methodology, we perform fine-grained error analysis on UCCA parsing, according to UD relations ( \u00a76).", "labels": [], "entities": [{"text": "UCCA parsing", "start_pos": 100, "end_pos": 112, "type": "TASK", "confidence": 0.7815452814102173}]}, {"text": "Results highlight challenges for current parsing technology, and expose cases where UCCA parsers may benefit from modeling syntactic structure more directly.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9707566499710083}]}], "datasetContent": [{"text": "In \u00a75 we used our comparison methodology, consisting of the conversion to a shared format and matching units by terminal yield, to compare goldstandard UD and UCCA.", "labels": [], "entities": [{"text": "goldstandard UD", "start_pos": 139, "end_pos": 154, "type": "DATASET", "confidence": 0.839875340461731}, {"text": "UCCA", "start_pos": 159, "end_pos": 163, "type": "DATASET", "confidence": 0.8615327477455139}]}, {"text": "In this section we ap- The A G column is omitted from as this category combination occurs in only 0.02% of edges in the corpus.", "labels": [], "entities": []}, {"text": "ply the same methodology to parser outputs, using gold-standard UD for fine-grained evaluation.", "labels": [], "entities": [{"text": "parser outputs", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.8818893432617188}]}, {"text": "In addition to the UCCA EWT data ( \u00a73), we use the reviews section of the UD v2.3 English_EWT treebank (, annotated over the exact same sentences.", "labels": [], "entities": [{"text": "UCCA EWT data", "start_pos": 19, "end_pos": 32, "type": "DATASET", "confidence": 0.9718467195828756}, {"text": "UD v2.3 English_EWT treebank", "start_pos": 74, "end_pos": 102, "type": "DATASET", "confidence": 0.9132240414619446}]}, {"text": "We additionally use UDPipe v1., trained on English_EWT, 13 for feature extraction.", "labels": [], "entities": [{"text": "English_EWT, 13", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.7783931255340576}, {"text": "feature extraction", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7489673495292664}]}, {"text": "We apply the extended converter to UD as before ( \u00a74.2).", "labels": [], "entities": [{"text": "UD", "start_pos": 35, "end_pos": 37, "type": "DATASET", "confidence": 0.7162330150604248}]}, {"text": "We train TUPA v1.3) on the UCCA EWT data, with the standard train/development/test split.", "labels": [], "entities": [{"text": "UCCA EWT data", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.9672746459643046}]}, {"text": "TUPA uses POS tags and syntactic dependencies as features.", "labels": [], "entities": [{"text": "TUPA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9344391822814941}]}, {"text": "We experiment both with using gold UD for feature extraction, and with using UDPipe outputs.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7424286603927612}]}, {"text": "UCCA evaluation is generally carried out by considering a predicted unit as correct if there is a gold unit that matches it in terminal yield and labels.", "labels": [], "entities": [{"text": "UCCA evaluation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7348303496837616}]}, {"text": "Precision, Recall and F-score (F1) are computed accordingly.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9960630536079407}, {"text": "Recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9977722764015198}, {"text": "F-score", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9991745352745056}, {"text": "F1)", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9289743006229401}]}, {"text": "For the fine-grained analysis, we split the goldstandard, predicted and matched UCCA units according to the labels of the UD relations whose dependents have the same terminal yield (if any).", "labels": [], "entities": []}, {"text": "UCCA categories (see), possibly by making lexical distinctions (e.g., modals and auxiliary verbs are both UD auxiliaries, but are annotated as Adverbials and Functions, respectively).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: UD-UCCA confusion matrix calculated based on EWT gold-standard annotations from the training and  development sets ( \u00a73), after applying our extended converter to UD ( \u00a74), by matching UD vertices and UCCA  units with the same terminal yield. The last column (row), labeled NO MATCH, shows the number of edges of  each UD (UCCA) category that do not match any UCCA (UD) unit. Zero counts are omitted.", "labels": [], "entities": [{"text": "EWT gold-standard annotations", "start_pos": 55, "end_pos": 84, "type": "DATASET", "confidence": 0.9497517546017965}, {"text": "NO", "start_pos": 284, "end_pos": 286, "type": "METRIC", "confidence": 0.9920245409011841}, {"text": "MATCH", "start_pos": 287, "end_pos": 292, "type": "METRIC", "confidence": 0.5825019478797913}]}, {"text": " Table 4: Labeled precision, recall and F1 (in %) for pri- mary and remote edges output by TUPA on the UCCA  EWT development (top) and test (bottom) sets, using  either gold-standard UD or UDPipe for TUPA features.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9614642262458801}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9996273517608643}, {"text": "F1", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9995393753051758}, {"text": "UCCA  EWT development", "start_pos": 103, "end_pos": 124, "type": "DATASET", "confidence": 0.950274129708608}]}]}