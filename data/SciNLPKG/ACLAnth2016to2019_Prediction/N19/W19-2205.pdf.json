{"title": [{"text": "Legal Linking: Citation Resolution and Suggestion in Constitutional Law", "labels": [], "entities": [{"text": "Legal Linking", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7400067448616028}, {"text": "Citation Resolution", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.6880185157060623}, {"text": "Constitutional Law", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.6347125917673111}]}], "abstractContent": [{"text": "This paper describes a dataset and baseline systems for linking paragraphs from court cases to clauses or amendments in the US Constitution.", "labels": [], "entities": []}, {"text": "We implement a rule-based system , a linear model, and a neural architecture for matching pairs of paragraphs, taking training data from online databases in a distantly-supervised fashion.", "labels": [], "entities": []}, {"text": "In experiments on a manually-annotated evaluation set, we find that our proposed neural system outper-forms a rules-driven baseline.", "labels": [], "entities": []}, {"text": "Qualitatively, this performance gap seems largest for abstract or indirect links between documents, which suggests that our system might be useful for answering political science and legal research questions or discovering novel links.", "labels": [], "entities": [{"text": "answering political science and legal research", "start_pos": 151, "end_pos": 197, "type": "TASK", "confidence": 0.8633096516132355}]}, {"text": "We release the dataset along with the manually-annotated evaluation set to foster future work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Authors of legal texts are frequently interested in understanding how their document relates to a knowledge base or to some reference text or corpus.", "labels": [], "entities": []}, {"text": "Because legal reasoning relies on references to preexisting precedent, identifying the documents or document sections (e.g. court cases; constitutional provisions) that relate to the author's current argument or topic of interest is an important task.", "labels": [], "entities": [{"text": "identifying the documents or document sections (e.g. court cases; constitutional provisions) that relate to the author's current argument or topic of interest", "start_pos": 71, "end_pos": 229, "type": "TASK", "confidence": 0.6741029998430839}]}, {"text": "However, constructing these reference links is labor-intensive, particularly if the set of reference texts is large or the link is ambiguous.", "labels": [], "entities": []}, {"text": "Automating this linkage task therefore offers useful assistance for authors of legal texts.", "labels": [], "entities": []}, {"text": "Linking systems of this kind are also useful for answering important political science and legal research questions.", "labels": [], "entities": [{"text": "answering important political science and legal research questions", "start_pos": 49, "end_pos": 115, "type": "TASK", "confidence": 0.7830572426319122}]}, {"text": "For example, in US Constitutional law, the Supreme Court has anecdotally appeared more receptive to arguments that combine * Authors contributed equally.", "labels": [], "entities": [{"text": "US Constitutional law", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.65178249279658}]}, {"text": "Order chosen by coin flip.", "labels": [], "entities": []}, {"text": "However, without an automated linking system, identifying instances of rhetorical \"commingling\" of rights is laborintensive.", "labels": [], "entities": []}, {"text": "Outside the American context, even simple data on the frequency with which judges invoke particular constitutional rights are difficult to gather.", "labels": [], "entities": []}, {"text": "A generic, automated system capable of inferring links between sections of judicial opinions and related legal texts 2 would therefore be valuable for legal and political science researchers.", "labels": [], "entities": []}, {"text": "With this motivation, we present a method for linking pairs of documents -here, Supreme Court case paragraphs and Constitution sections -based on distantly-annotated training data.", "labels": [], "entities": []}, {"text": "Our model operates on the level of short pieces of text, such as paragraphs, and gives a binary decision between pairs of texts, marking a presence or absence of a link.", "labels": [], "entities": []}, {"text": "As we describe, a key challenge we face is that our training data are generated using rulesbased heuristics, and are thus highly incomplete.", "labels": [], "entities": []}, {"text": "As a result, one of our main contributions is a data preprocessing step that \"strips\" rules-based language from the training data.", "labels": [], "entities": []}, {"text": "In our experiments, we find that this step combined with a modern neural network model allows our system to substantially outperform both rules-driven and nonneural baselines on a manually-tagged evaluation set.", "labels": [], "entities": []}, {"text": "Qualitatively, this performance gap appears largest for paragraphs that contain abstract or indirect references to Constitutional provisions, which suggests that the system we propose might also be useful for discovering new links not identified by existing techniques.", "labels": [], "entities": []}, {"text": "1 E.g., Lamb's Chapel v.", "labels": [], "entities": [{"text": "Lamb's Chapel", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.9708281954129537}]}, {"text": "Center Moriches Union Free School District (508 U.S. 384) and related religious speech cases, which successfully combine free speech and free exercise of religion arguments.", "labels": [], "entities": [{"text": "Center Moriches Union Free School District", "start_pos": 0, "end_pos": 42, "type": "DATASET", "confidence": 0.9115011195341746}]}, {"text": "See) for further discussion.", "labels": [], "entities": []}, {"text": "2 E.g. other national constitutions, as in.", "labels": [], "entities": []}], "datasetContent": [{"text": "During training, we tuned according to a split of the original train data.", "labels": [], "entities": []}, {"text": "Since this data is automatically generated, it is not a good indicator of performance.", "labels": [], "entities": []}, {"text": "Instead, we report all of our results on the manually annotated test set, described in Section 3.1.", "labels": [], "entities": []}, {"text": "Since the decision from most of the classifiers will be 0, we evaluate the outputs of our model using F1 measure, calculated without regard to any individual class.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.9830017685890198}]}, {"text": "All of our code, data, and trained models are available online.", "labels": [], "entities": []}, {"text": "As expected, the rules-based approach gives high precision but low recall on the manually annotated set.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9987917542457581}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.999106228351593}]}], "tableCaptions": [{"text": " Table 1: Results on the manually annotated test set.  The top row uses the rule based classifier. The bottom  two rows use the neural network model trained on the  original and stripped training sets respectively.", "labels": [], "entities": []}]}