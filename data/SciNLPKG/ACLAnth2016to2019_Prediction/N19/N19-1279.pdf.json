{"title": [{"text": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings", "labels": [], "entities": [{"text": "Improving Cross-Domain Chinese Word Segmentation", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8622405290603637}]}], "abstractContent": [{"text": "Cross-domain Chinese Word Segmentation (CWS) remains a challenge despite recent progress in neural-based CWS.", "labels": [], "entities": [{"text": "Cross-domain Chinese Word Segmentation (CWS)", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.721962319953101}]}, {"text": "The limited amount of annotated data in the target domain has been the key obstacle to a satisfactory performance.", "labels": [], "entities": []}, {"text": "In this paper, we propose a semi-supervised word-based approach to improving cross-domain CWS given a baseline segmenter.", "labels": [], "entities": []}, {"text": "Particularly, our model only deploys word embeddings trained on raw text in the target domain, discarding complex hand-crafted features and domain-specific dictionaries.", "labels": [], "entities": []}, {"text": "Innovative subsampling and negative sampling methods are proposed to derive word embeddings optimized for CWS.", "labels": [], "entities": []}, {"text": "We conduct experiments on five datasets in special domains , covering domains in novels, medicine, and patent.", "labels": [], "entities": []}, {"text": "Results show that our model can obviously improve cross-domain CWS, especially in the segmentation of domain-specific noun entities.", "labels": [], "entities": [{"text": "cross-domain CWS", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.5886176824569702}, {"text": "segmentation of domain-specific noun entities", "start_pos": 86, "end_pos": 131, "type": "TASK", "confidence": 0.7733265042304993}]}, {"text": "The word F-measure increases by over 3.0% on four datasets, outperform-ing state-of-the-art semi-supervised and unsu-pervised cross-domain CWS approaches with a large margin.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.7258639335632324}]}, {"text": "We make our code and data available on Github.", "labels": [], "entities": [{"text": "Github", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.934884250164032}]}], "introductionContent": [{"text": "Chinese Word Segmentation (CWS) is the first step for many Chinese Natural Language Processing (NLP) tasks.", "labels": [], "entities": [{"text": "Chinese Word Segmentation (CWS)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.771752804517746}, {"text": "Chinese Natural Language Processing (NLP) tasks", "start_pos": 59, "end_pos": 106, "type": "TASK", "confidence": 0.6840631030499935}]}, {"text": "Approaches to CWS could be categorized into two categories: character-based and wordbased.", "labels": [], "entities": []}, {"text": "The former treats CWS as a sequence labeling problem, labeling each character in a sequence with B/I/E/S (Beginning, Internal, End, Single) labels ().", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.6624169647693634}]}, {"text": "Traditional character-based approaches often use Conditional * Yuxiao Ye and Yue Zhang contributed equally to this work.", "labels": [], "entities": [{"text": "Conditional", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.8340048789978027}]}, {"text": "Random Fields (CRF) models to label sequences, with complex hand-crafted discrete features ().", "labels": [], "entities": []}, {"text": "Unlike character based CWS, word-based CWS operates on a word-level, directly exploiting word-level features.", "labels": [], "entities": []}, {"text": "Typical CRF models are replaced with semi-CRF models, in which labels are assigned to subsequences instead of characters ().", "labels": [], "entities": []}, {"text": "Transitionbased approaches have also been used to exploit larger feature contexts (.", "labels": [], "entities": []}, {"text": "More recent approaches exploit neural networks including Recurrent Neural Networks (RNN) to replace hand-crafted discrete features with realvalued features.", "labels": [], "entities": []}, {"text": "Existing studies have achieved satisfactory results for in-domain CWS, with F-scores over 96.0% in the newspaper domain . Nevertheless, cross-domain CWS remains a big challenge (.", "labels": [], "entities": [{"text": "CWS", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9187523722648621}, {"text": "F-scores", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9988622665405273}, {"text": "cross-domain CWS", "start_pos": 136, "end_pos": 152, "type": "TASK", "confidence": 0.5194215178489685}]}, {"text": "The main reason is the lack of annotated data in the target domain, which makes supervised approaches less useful.", "labels": [], "entities": []}, {"text": "To tackle this problem, some unsupervised and semi-supervised approaches have been proposed.", "labels": [], "entities": []}, {"text": "One way is to exploit complex features including character types, lexical features and accessor varieties ( ), which requires much efforts on feature engineering.", "labels": [], "entities": []}, {"text": "Another way is to deploy machine learning algorithms including self-training and model ensemble (, which is time-consuming and inefficient.", "labels": [], "entities": []}, {"text": "In this paper, we investigate a different approach to deploying unsupervised data for crossdomain CWS, in order to completely break free from the reliance on manual annotation, complex feature engineering, and even parametric training to some extent.", "labels": [], "entities": [{"text": "crossdomain CWS", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.7016525268554688}]}, {"text": "We propose a Word-Embedding-Based CWS (WEB-CWS) model, which aims to improve the performance of an existing baseline segmenter in cross-domain CWS.", "labels": [], "entities": [{"text": "Word-Embedding-Based CWS (WEB-CWS)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.45824089646339417}]}, {"text": "WEB-CWS is a conceptually simple word-based model, using word embeddings, which are expected to carry semantic and syntax information, as the only input of a non-parametric word segmentor.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9452247619628906}]}, {"text": "The basic intuition is that embeddings of words within a same context window should be close to each other (.", "labels": [], "entities": []}, {"text": "If a sequence is incorrectly segmented, those incorrectly segmented words are likely to be semantically and syntactically inconsistent with their surrounding words.", "labels": [], "entities": []}, {"text": "Consequently, the embedding of an incorrectly segmented word should be faraway from embeddings of its surrounding words.", "labels": [], "entities": []}, {"text": "Based on the hypothesis above, we propose WEB-CWS.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.5136265754699707}]}, {"text": "Word embeddings are first derived with a CWS-oriented word embedding model with innovative subsampling and negative sampling methods.", "labels": [], "entities": []}, {"text": "A word-embedding-based decoder is then used for segmentation, with cosine similarities among word embeddings as the metric for probability calculation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.9657769203186035}]}, {"text": "WEB-CWS is a semisupervised model, because it only uses word embeddings trained on raw text in the target domain, which is first automatically segmented by the baseline segmenter.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9451198577880859}]}, {"text": "The model is also crossdomain in the sense that it can improve the performance of the baseline segmenter, when the source text for training the baseline segmenter and the target text to be segmented are in different domains.", "labels": [], "entities": []}, {"text": "The main contributions of this paper include: \u2022 To our knowledge, we are the first to directly use word embeddings for CWS, without any neural structures, which makes our model conceptually simpler and run faster.", "labels": [], "entities": []}, {"text": "\u2022 We have proposed novel sampling methods to make the embeddings optimized for CWS, which has never been used for embedding training.", "labels": [], "entities": []}, {"text": "\u2022 Our model can be used on top of any existing CWS models to improve their performances, without the need to re-train those models with annotated domain specific data.", "labels": [], "entities": []}, {"text": "\u2022 On four datasets in different special domains, our model improves the word F-measure by more than 3.0%, compared with the state-ofthe-art baseline segmenter.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.6442896723747253}]}, {"text": "We release our code and data on Github 1 .", "labels": [], "entities": [{"text": "Github 1", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.8861879706382751}]}], "datasetContent": [{"text": "We conduct experiments on various datasets in different domains to thoroughly evaluate the performance of our model.", "labels": [], "entities": []}, {"text": "We evaluate our model in terms of cross-domain CWS on five datasets, including three Chinese novel datasets (: DL (DouLuoDaLu), FR (FanRenXiuXianZhuan) and ZX (ZhuXian), and two CWS datasets in special domains ( : DM (dermatology) and PT (patent).", "labels": [], "entities": [{"text": "FR", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.9442724585533142}, {"text": "PT", "start_pos": 235, "end_pos": 237, "type": "METRIC", "confidence": 0.9746742248535156}]}, {"text": "We use the standard split for all datasets as they are published.", "labels": [], "entities": []}, {"text": "Raw test data is also included for deriving word embeddings.", "labels": [], "entities": []}, {"text": "Statistics of these datasets are shown in.", "labels": [], "entities": []}, {"text": "Since there are no gold segmentation of full novels for three Chinese novel datasets, their statistics are: Statistics of full and evaluation datasets.", "labels": [], "entities": []}, {"text": "based on the segmentation given by the baseline segmenter.", "labels": [], "entities": []}, {"text": "For consistency, all segmentation results are automatically calculated with the script provided in the SIGHAN Bakeoff ( and are reported as word F-measures.", "labels": [], "entities": [{"text": "consistency", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9512194991111755}, {"text": "segmentation", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.9782081246376038}, {"text": "SIGHAN Bakeoff", "start_pos": 103, "end_pos": 117, "type": "DATASET", "confidence": 0.8520007431507111}]}, {"text": "In ablation experiments, we study the influence of two CWS-oriented negative sampling and multicharacter words subsampling.", "labels": [], "entities": []}, {"text": "Results in show that WEB-CWS using word embeddings derived with the basic Skip-gram model ('basic') performs obviously worse than the baseline segmenter.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.60831218957901}]}, {"text": "When CWS-oriented negative sampling is applied alone, either context ('c n') or in-word ('w n') negative sampling, the performance of WEB-CWS is obviously better than or similar to that of the baseline segmenter.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.7280089855194092}]}, {"text": "When both CWSoriented negative sampling methods are applied together ('c w n'), WEB-CWS is ensured to obviously outperform the baseline segmenter.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.4074198007583618}]}, {"text": "Also, when multi-character subsampling ('m s') is applied, the performance of WEB-CWS can further improve a little.", "labels": [], "entities": [{"text": "WEB-CWS", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.7848812341690063}]}], "tableCaptions": [{"text": " Table 1: Statistics of full and evaluation datasets.", "labels": [], "entities": []}, {"text": " Table 3: F-measures of the baseline segmenter and WEB-CWS on datasets in special domains, and F-measure  improvement rates (IR) of WEB-CWS, Qiu and Zhang (2015) and Liu and Zhang (2012).", "labels": [], "entities": [{"text": "F-measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.990284264087677}, {"text": "WEB-CWS", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9052326083183289}, {"text": "F-measure  improvement rates (IR)", "start_pos": 95, "end_pos": 128, "type": "METRIC", "confidence": 0.9573762615521749}]}, {"text": " Table 4: F-measures of WEB-CWS with different sub- sampling and negative sampling methods.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9855491518974304}, {"text": "WEB-CWS", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.8071383237838745}]}, {"text": " Table 5: Ten most improved words in terms of segmen- tation precision. Pre base: segmentation precision by  the baseline segmenter. Pre WEB: segmentation preci- sion by WEB-CWS.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.6918668150901794}, {"text": "Pre base", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9326514601707458}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.847298800945282}, {"text": "Pre WEB", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.6820720881223679}, {"text": "WEB-CWS", "start_pos": 170, "end_pos": 177, "type": "DATASET", "confidence": 0.8884113430976868}]}]}