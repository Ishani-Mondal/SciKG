{"title": [], "abstractContent": [{"text": "Understanding procedural language requires reasoning about both hierarchical and temporal relations between events.", "labels": [], "entities": []}, {"text": "For example, \"boiling pasta\" is a sub-event of \"making a pasta dish\", typically happens before \"draining pasta,\" and requires the use of omitted tools (e.g. a strainer, sink...).", "labels": [], "entities": []}, {"text": "While people are able to choose when and how to use abstract versus concrete instructions, the NLP community lacks corpora and tasks for evaluating if our models can do the same.", "labels": [], "entities": []}, {"text": "In this paper, we introduce KIDSCOOK, a parallel script corpus, as well as a cloze task which matches video captions with missing procedural details.", "labels": [], "entities": []}, {"text": "Experimental results show that state-of-the-art models struggle at this task, which requires inducing functional commonsense knowledge not explicitly stated in text.", "labels": [], "entities": []}], "introductionContent": [{"text": "The level of detail used in natural language communication varies: descriptive or instructive text for experts may elide over details the reader can seamlessly infer, while text for more novice audiences maybe more verbose.", "labels": [], "entities": []}, {"text": "A given document typically adheres to a single level of verbosity suited to its presumed audience, so learning correspondences between abstract and detailed descriptions of similar concepts from text is a challenging problem.", "labels": [], "entities": [{"text": "learning correspondences between abstract and detailed descriptions of similar concepts from text", "start_pos": 102, "end_pos": 199, "type": "TASK", "confidence": 0.6496031334002813}]}, {"text": "Commonsense knowledge of how complex events decompose into stereotypical sequences of simpler events is a necessary component of a system that can automatically understand and reason about different types of discourse.", "labels": [], "entities": []}, {"text": "Hierarchical correspondences between abstract and detailed representations of concepts and events were an important aspect of the original formulation of scripts for natural language understanding (Schank and: An example KIDSCOOK sequence with multiple types of hierarchy and abstraction: the example contains sequences of complex instructions, given both as sentences and sequences of simpler instructions.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 166, "end_pos": 196, "type": "TASK", "confidence": 0.6848844885826111}]}, {"text": "but required handwritten data structures encoding world knowledge.", "labels": [], "entities": []}, {"text": "However, the automatic induction of such commonsense knowledge from open-domain noisy text corpora remains an open problem.", "labels": [], "entities": []}, {"text": "As a step towards solving this problem we consider textual descriptions of actions in a cooking domain.", "labels": [], "entities": []}], "datasetContent": [{"text": "During generation, we provide the model with the number of words in each blank to be predicted.", "labels": [], "entities": []}, {"text": "We consider two setups for evaluating examples with multiple blanks, both assuming that predictions are made left-to-right: Oracle, where the gold prediction of each blank is fed into the model to condition on for future predictions, and Greedy, where the model prediction is used for future predictions.", "labels": [], "entities": []}, {"text": "We compute the proportion of exact word matches over each blank and the precision of the top k = 5 predictions for both setups.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9995754361152649}]}, {"text": "Additionally we compute the average surprisal of the gold prediction (conditioning on oracle predictions).", "labels": [], "entities": []}, {"text": "The surprisal of a word) is its negative log probability under the model: \u2212log(P (w i |w 1:i\u22121 )).", "labels": [], "entities": []}, {"text": "The higher the probability of the ground truth, the lower the model's \"surprise\" at seeing it in that context.", "labels": [], "entities": [{"text": "surprise", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.981880784034729}]}, {"text": "Finally, as a quantitative proxy for interpretability, we report the length of the transducer models' average Viterbi alignment span: our goal is a model which balances low average alignment lengths and high matching or ranking scores.", "labels": [], "entities": [{"text": "interpretability", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.9708279967308044}]}], "tableCaptions": [{"text": " Table 1: KIDSCOOK corpus statistics", "labels": [], "entities": [{"text": "KIDSCOOK", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.7324950098991394}]}, {"text": " Table 3: Example Viterbi Alignments. For concrete to abstract, we match any phrase containing the word(s).", "labels": [], "entities": []}]}