{"title": [{"text": "Fake News Detection using Deep Markov Random Fields", "labels": [], "entities": [{"text": "Fake News Detection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7940135399500529}]}], "abstractContent": [{"text": "Deep-learning-based models have been successfully applied to the problem of detecting fake news on social media.", "labels": [], "entities": [{"text": "detecting fake news on social media", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.8761237760384878}]}, {"text": "While the correlations among news articles have been shown to be effective cues for online news analysis , existing deep-learning-based methods often ignore this information and only consider each news article individually.", "labels": [], "entities": [{"text": "online news analysis", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.706847627957662}]}, {"text": "To overcome this limitation, we develop a graph-theoretic method that inherits the power of deep learning while at the same time utilizing the correlations among the articles.", "labels": [], "entities": []}, {"text": "We formulate fake news detection as an inference problem in a Markov random field (MRF) which can be solved by the iterative mean-field algorithm.", "labels": [], "entities": [{"text": "formulate fake news detection", "start_pos": 3, "end_pos": 32, "type": "TASK", "confidence": 0.7209295928478241}]}, {"text": "We then unfold the mean-field algorithm into hidden layers that are composed of common neural network operations.", "labels": [], "entities": []}, {"text": "By integrating these hidden layers on top of a deep network, which produces the MRF potentials, we obtain our deep MRF model for fake news detection.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.7212402025858561}]}, {"text": "Experimental results on well-known datasets show that the proposed model improves upon various state-of-the-art models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The term \"fake news\" refers to news articles that is intentionally and verifiably false ( . The problem of fake news has existed since the appearance of the printing press, but only gained a lot of momentum and visibility during the age of social media.", "labels": [], "entities": []}, {"text": "This is due to the large audience, easy access and fast dissemination mechanism of social media, where more and more users are consuming news in a daily basis ( . Traditional methods for verifying the veracity of news that rely on human experts, despite being reliable, do not scale well to the massive volume of news nowadays.", "labels": [], "entities": []}, {"text": "This renders the automatic detection of fake news on social media an important problem, drawing a lot of attention from both the academic and industrial communities.", "labels": [], "entities": [{"text": "automatic detection of fake news on social media", "start_pos": 17, "end_pos": 65, "type": "TASK", "confidence": 0.8502355068922043}]}, {"text": "The recent literature has witnessed the success of deep learning models in detecting fake news on social media (.", "labels": [], "entities": [{"text": "detecting fake news on social media", "start_pos": 75, "end_pos": 110, "type": "TASK", "confidence": 0.8404170175393423}]}, {"text": "By leveraging the capability of deep networks in learning high-level representations, these models have achieved state-of-the-art performance on various benchmark datasets.", "labels": [], "entities": []}, {"text": "Nevertheless, one limitation of existing deep-learning-based methods is that they often ignore the correlations among news articles, which have been proved to be effective for analysing online events (.", "labels": [], "entities": []}, {"text": "To overcome this limitation, we aim at a model that leverages the capability of deep neural networks while effectively incorporating the correlations among articles when determining their credibility.", "labels": [], "entities": []}, {"text": "To this end, we first model the relationship between two articles by the number of the com- mon users that engage to them, e.g., by means of tweeting, re-tweeting, commenting.", "labels": [], "entities": []}, {"text": "An example is illustrated in: the articles a 2 and a 3 have a strong relationship as they are engaged to by 5 common users, whereas, there is no relationship between the articles a 1 and a 2 because there is no user engage to both of them.", "labels": [], "entities": []}, {"text": "With this modeling, we can construct a news graph, where each node corresponds to an article and an edge encodes the relationship between two articles.", "labels": [], "entities": []}, {"text": "Our underlying assumption is that if there exists a strong relationship between two articles, they are likely to share the same labels.", "labels": [], "entities": []}, {"text": "To verify this assumption, we calculate the percentages of the edges that connect two articles with the same labels, among those whose weights are equal to certain values, and plot the results for the news graph constructed from the Weibo dataset () in.", "labels": [], "entities": [{"text": "Weibo dataset", "start_pos": 233, "end_pos": 246, "type": "DATASET", "confidence": 0.9860264956951141}]}, {"text": "It is clear from that the higher the edge weight, the more likely it is that the corresponding articles share the same labels (fake or true).", "labels": [], "entities": []}, {"text": "Similar patterns are observed on other datasets such as the Twitter ( and the PHEME () datasets.", "labels": [], "entities": [{"text": "PHEME () datasets", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.8471150795618693}]}, {"text": "Evidently, these results support our assumption.", "labels": [], "entities": []}, {"text": "In order to incorporate the correlations among news articles, we formulate fake news detection as an inference problem in a Markov random field (MRF).", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.6349057058493296}]}, {"text": "Our motivation behind this formulation is to leverage the capability of MRF in capturing dependencies among random variables.", "labels": [], "entities": []}, {"text": "We solve the resulting inference problem using the meanfield algorithm.", "labels": [], "entities": []}, {"text": "We then propose a method to unfold this algorithm into hidden layers that can be integrated on top of a deep network that computes the potentials of the MRF.", "labels": [], "entities": [{"text": "MRF", "start_pos": 153, "end_pos": 156, "type": "DATASET", "confidence": 0.691944420337677}]}, {"text": "By doing this, we obtain our deep MRF model for detecting fake news, referred to as the DMFN model.", "labels": [], "entities": [{"text": "detecting fake news", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8594047625859579}]}, {"text": "To the best of our knowledge, this is the first integration of deep networks and MRF for detecting fake news.", "labels": [], "entities": [{"text": "detecting fake news", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.8758931358655294}]}, {"text": "Our main contributions are as follows: \u2022 We formulate fake news detection as an inference problem in an MRF model.", "labels": [], "entities": [{"text": "formulate fake news detection", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.8386626988649368}]}, {"text": "This allows us to incorporate the correlations among news articles when deciding their credibility.", "labels": [], "entities": []}, {"text": "\u2022 We propose a method to unfold the meanfield algorithm into specially-designed neural network layers, and build a deep MRF model for detecting fake news.", "labels": [], "entities": [{"text": "detecting fake news", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.8683781027793884}]}, {"text": "\u2022 We carryout comprehensive experiments on widely-used datasets collected from popular social networks.", "labels": [], "entities": []}, {"text": "Experimental results show the effectiveness of the proposed model compared to various state-of-the-art models.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: we review the related work in Section 2, and describe our formulation of fake news detection as an inference problem MRF in Section 3.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.6616184115409851}]}, {"text": "In Section 4, we describe our model in detail.", "labels": [], "entities": []}, {"text": "We present our experimental studies in Section 5 and finally draw the conclusions in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We employ three well-known benchmark datasets, namely the Twitter, Weibo ( and PHEME datasets ( for our experiments.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.8991320729255676}, {"text": "PHEME datasets", "start_pos": 79, "end_pos": 93, "type": "DATASET", "confidence": 0.8477185666561127}]}, {"text": "The Twitter dataset consists of 992 events, involving 233.7 thousand users and 592.4 thousand tweets.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8116480112075806}]}, {"text": "The Weibo dataset is larger, with 4, 664 events, 2.8 million users and 3.8 million posts.", "labels": [], "entities": [{"text": "Weibo dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9875991344451904}]}, {"text": "Events in these datasets are labeled as either fake or true, and the two labels are relatively balanced.", "labels": [], "entities": []}, {"text": "The PHEME dataset consists of 5, 802 comment threads collected from Twitter, with approximately 103 thousand tweets in total.", "labels": [], "entities": [{"text": "PHEME dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.8893199265003204}]}, {"text": "This dataset is imbalanced, with 1, 972 threads labeled as rumour and 3, 830 threads labeled as nonrumour.", "labels": [], "entities": []}, {"text": "We compare the results of different models in two experimental settings, namely late detection and early detection.", "labels": [], "entities": [{"text": "late detection", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.8114935159683228}, {"text": "early detection", "start_pos": 99, "end_pos": 114, "type": "TASK", "confidence": 0.7789422571659088}]}, {"text": "The former setting allows the models to use all the available users posts in the entire time span of the given datasets, whereas in the latter setting, the models are only allowed to use posts that have appeared within a specific deadline (in hours) since the appearances of the events.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of the DMFN model when varying  \u03bb on the Weibo datasets (Ma et al., 2016).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9947156310081482}, {"text": "Weibo datasets", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.9824552536010742}]}, {"text": " Table 2: Accuracy of the DMFN model when varying  T on the Weibo datasets (Ma et al., 2016).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9953889846801758}, {"text": "Weibo datasets", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.9846988916397095}]}, {"text": " Table 3: Results for different models on the Twitter and Weibo datasets (Ma et al., 2016).", "labels": [], "entities": [{"text": "Weibo datasets", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.9563944339752197}]}, {"text": " Table 4: Results for different models on the PHEME datasets (Zubiaga et al., 2017).", "labels": [], "entities": [{"text": "PHEME datasets", "start_pos": 46, "end_pos": 60, "type": "DATASET", "confidence": 0.9217243492603302}]}, {"text": " Table 5: Results of different variants of the DMFN model on the three datasets.", "labels": [], "entities": []}]}