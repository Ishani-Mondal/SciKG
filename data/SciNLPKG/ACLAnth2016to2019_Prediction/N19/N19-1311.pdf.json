{"title": [{"text": "Neural Machine Translation of Text from Non-Native Speakers", "labels": [], "entities": [{"text": "Neural Machine Translation of Text from Non-Native Speakers", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8497625067830086}]}], "abstractContent": [{"text": "Neural Machine Translation (NMT) systems are known to degrade when confronted with noisy data, especially when the system is trained only on clean data.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.799747496843338}]}, {"text": "In this paper, we show that augmenting training data with sentences containing artificially-introduced grammatical errors can make the system more robust to such errors.", "labels": [], "entities": []}, {"text": "In combination with an automatic grammar error correction system, we can recover 1.0 BLEU out of 2.4 BLEU lost due to grammatical errors.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9976903200149536}, {"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9958680868148804}]}, {"text": "We also present a set of Spanish translations of the JFLEG grammar error correction corpus, which allows for testing NMT robustness to real grammatical errors.", "labels": [], "entities": [{"text": "JFLEG grammar error correction corpus", "start_pos": 53, "end_pos": 90, "type": "DATASET", "confidence": 0.8134907484054565}]}], "introductionContent": [{"text": "Neural Machine Translation (NMT) is undeniably a success story: public benchmarks () are dominated by neural systems, and neural approaches are the de facto option for industrial systems (.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8480460147062937}]}, {"text": "Even under low-resource conditions, neural models were recently shown to outperform traditional statistical approaches.", "labels": [], "entities": []}, {"text": "However, there are still several shortcomings of NMT that need to be addressed: a (nonexhaustive) list of six challenges is discussed by, including outof-domain testing, rare word handling, the widebeam problem, and the large amount of data needed for learning.", "labels": [], "entities": [{"text": "rare word handling", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.6617056330045065}]}, {"text": "An additional challenge is robustness to noise, both during training and at inference time.", "labels": [], "entities": []}, {"text": "In this paper, we study the effect of a specific type of noise in NMT: grammatical errors.", "labels": [], "entities": []}, {"text": "We primarily focus on errors that are made by non-native \u2020 Equal contribution.", "labels": [], "entities": []}, {"text": "Work performed at the University of Notre Dame.", "labels": [], "entities": []}, {"text": "source-language speakers (as opposed to dialectal language, SMS or Twitter language).", "labels": [], "entities": []}, {"text": "Not only is this linguistically important, but we believe that it would potentially have great social impact.", "labels": [], "entities": []}, {"text": "First, we confirm that NMT is vulnerable to source-side noise when trained on clean data, losing up to 3.6 BLEU on our test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9991664886474609}]}, {"text": "This is consistent with previous work, yet orthogonal to it, since we use more realistic noise for our experiments.", "labels": [], "entities": []}, {"text": "Second, we explore training methods that can deal with noise, and show that including noisy synthetic data in the training data makes NMT more robust to handling similar types of errors in test data.", "labels": [], "entities": []}, {"text": "Combining this simple method with an automatic grammar correction system, we find that we can recover 1.5 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.992448091506958}]}, {"text": "Third, we release Spanish translations of the JFLEG corpus, 1 a standard benchmark for English Grammar Error Correction (GEC) systems.", "labels": [], "entities": [{"text": "JFLEG corpus", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8745713531970978}, {"text": "English Grammar Error Correction (GEC)", "start_pos": 87, "end_pos": 125, "type": "TASK", "confidence": 0.7020990891116006}]}, {"text": "We also release all other data and code used in this paper.", "labels": [], "entities": []}, {"text": "Our additional annotations on both the JFLEG corpus and the English WMT data will enable the evaluation of the robustness of NMT systems on realistic, natural noise: a robust system would ideally produce the same output when presented with either the original or the noisy source sentence.", "labels": [], "entities": [{"text": "JFLEG corpus", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.9552479982376099}, {"text": "English WMT data", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9230255087216696}]}, {"text": "We hope that our datasets will become a benchmark for noise-robust NMT, because we believe that deployed systems should also be able to handle source-side noise.", "labels": [], "entities": [{"text": "NMT", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8711795806884766}]}], "datasetContent": [{"text": "In this section, we provide implementation details and the results of our NMT experiments.", "labels": [], "entities": []}, {"text": "For convenience, we will refer to each model with the same name as the dataset it was trained on; e.g. the mix-all model will refer to the model trained on the mix-all dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics on the original and synthetic En-Es  datasets. Each (synthetic) sentence has exactly one in- troduced error, wherever possible. clean+[error] is the  concatenation of the [error] with the original clean  dataset, while mix-all includes six versions of each  training sentence, one without errors and one for each  error.", "labels": [], "entities": [{"text": "En-Es  datasets", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.8043479025363922}]}, {"text": " Table 4: BLEU scores on the WMT test set without (clean) and with synthetic grammar errors. The best performing  models for each test set are highlighted. When training and test match (highlighted) we generally observe higher  results. However, including all clean and noisy data in the training set (mix-all) yields the best results across almost  all datasets, with the highest average BLEU and the lowest variance.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989369511604309}, {"text": "WMT test set", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.9146939317385355}, {"text": "BLEU", "start_pos": 389, "end_pos": 393, "type": "METRIC", "confidence": 0.9992837309837341}]}, {"text": " Table 5: BLEU scores on the JFLEG-es dev and test datasets. Our proposed mix-all model is slightly behind the  clean model on manually corrected input (cor", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994072914123535}, {"text": "JFLEG-es dev and test datasets", "start_pos": 29, "end_pos": 59, "type": "DATASET", "confidence": 0.8567060708999634}]}, {"text": " Table 9: BLEU scores on the WMT test set without (clean) and with synthetic grammar errors using an LSTM  encoder-decoder model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9982885718345642}, {"text": "WMT test set", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.936527947584788}]}, {"text": " Table 10: BLEU scores on the JFLEG-es dev and test datasets with the LSTM encoder-decoder model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9979717135429382}, {"text": "JFLEG-es dev and test datasets", "start_pos": 30, "end_pos": 60, "type": "DATASET", "confidence": 0.8044752717018128}]}]}