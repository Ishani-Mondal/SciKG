{"title": [{"text": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms", "labels": [], "entities": [{"text": "Interpretable Math Word Problem Solving", "start_pos": 16, "end_pos": 55, "type": "TASK", "confidence": 0.6053858578205109}]}], "abstractContent": [{"text": "We introduce a large-scale dataset of math word problems and an interpretable neural math problem solver that learns to map problems to operation programs.", "labels": [], "entities": [{"text": "interpretable neural math problem solver", "start_pos": 64, "end_pos": 104, "type": "TASK", "confidence": 0.6419879794120789}]}, {"text": "Due to annotation challenges, current datasets in this domain have been either relatively small in scale or did not offer precise operational annotations over diverse problem types.", "labels": [], "entities": []}, {"text": "We introduce anew representation language to model precise operation programs corresponding to each math problem that aim to improve both the performance and the inter-pretability of the learned models.", "labels": [], "entities": []}, {"text": "Using this representation language, our new dataset, MathQA, significantly enhances the AQuA dataset with fully-specified operational programs.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 88, "end_pos": 100, "type": "DATASET", "confidence": 0.8471592664718628}]}, {"text": "We additionally introduce a neu-ral sequence-to-program model enhanced with automatic problem categorization.", "labels": [], "entities": []}, {"text": "Our experiments show improvements over competitive baselines in our MathQA as well as the AQuA datasets.", "labels": [], "entities": [{"text": "MathQA", "start_pos": 68, "end_pos": 74, "type": "DATASET", "confidence": 0.926314115524292}, {"text": "AQuA datasets", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.9525810778141022}]}, {"text": "The results are still significantly lower than human performance indicating that the dataset poses new challenges for future research.", "labels": [], "entities": []}, {"text": "Our dataset is available at: https: //math-qa.github.io/math-QA/.", "labels": [], "entities": []}], "introductionContent": [{"text": "Answering math word problems poses unique challenges for logical reasoning over implicit or explicit quantities expressed in text.", "labels": [], "entities": [{"text": "Answering math word problems", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8905507773160934}]}, {"text": "Math wordproblem solving requires extraction of salient information from natural language narratives.", "labels": [], "entities": [{"text": "Math wordproblem solving", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6977211435635885}]}, {"text": "Automatic solvers must transform the textual narratives into executable meaning representations, a process that requires both high precision and, in the case of story problems, significant world knowledge.", "labels": [], "entities": [{"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9965243935585022}]}, {"text": "As shown by the geometry question in, math word problems are generally narratives describing the progress of actions and relations over some entities and quantities.", "labels": [], "entities": []}, {"text": "The operation pro- gram underlying the problem in highlights the complexity of the problem-solving task.", "labels": [], "entities": []}, {"text": "Here, we need the ability to deduce implied constants (pi) and knowledge of domain-specific formulas (area of the square).", "labels": [], "entities": []}, {"text": "In this paper, we introduce anew operationbased representation language for solving math word problems.", "labels": [], "entities": []}, {"text": "We use this representation language to construct MathQA 1 , anew large-scale, diverse dataset of 37k English multiple-choice math word problems covering multiple math domain categories by modeling operation programs corresponding to word problems in the AQuA dataset ().", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 254, "end_pos": 266, "type": "DATASET", "confidence": 0.9610587358474731}]}, {"text": "We introduce a neural model for mapping problems to operation programs with domain categorization.", "labels": [], "entities": []}, {"text": "Most current datasets in this domain are small in scale () or do not offer precise operational annotations over diverse problem types (.", "labels": [], "entities": []}, {"text": "This is mainly due to the fact that annotating math word problems precisely across diverse problem categories is challenging even for humans, requiring background math knowledge for annotators.", "labels": [], "entities": []}, {"text": "Our representation language facilitates the annotation task for crowd-sourcing and increases the interpretability of the proposed model.", "labels": [], "entities": []}, {"text": "Our sequence-to-program model with categorization trained on our MathQA dataset outperforms previous state-of-the-art on the AQuA test set in spite of the smaller training size.", "labels": [], "entities": [{"text": "MathQA dataset", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.9835085868835449}, {"text": "AQuA test set", "start_pos": 125, "end_pos": 138, "type": "DATASET", "confidence": 0.9449165860811869}]}, {"text": "These results indicate the superiority of our representation language and the quality of the formal annotations in our dataset.", "labels": [], "entities": []}, {"text": "Our model achieves competitive results on MathQA, but is still lower than human performance indicating that the dataset poses new challenges for future research.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: \u2022 We introduce a large-scale dataset of math word problems that are densely annotated with operation programs \u2022 We introduce anew representation language to model operation programs corresponding to each math problem that aim to improve both the performance and the interpretability of the learned models.", "labels": [], "entities": []}, {"text": "\u2022 We introduce a neural architecture leveraging a sequence-to-program model with automatic problem categorization, achieving competitive results on our dataset as well as the AQuA dataset The scale and diversity of this dataset makes it particularly suited for use in training deeplearning models to solve word problems.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 175, "end_pos": 187, "type": "DATASET", "confidence": 0.9642452597618103}]}, {"text": "However there is a significant amount of unwanted noise in the dataset, including problems with incorrect solutions, problems that are unsolvable without brute-force enumeration of solutions, and rationales that contain few or none of the steps required to solve the corresponding problem.", "labels": [], "entities": []}, {"text": "The motivation for our dataset comes from the fact we want to maintain the challenging nature of the problems included in the AQuA dataset, while removing noise that hinders the ability of neuralized models to learn the types of signal neccessary for problem-solving by logical reasoning.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 126, "end_pos": 138, "type": "DATASET", "confidence": 0.9546359181404114}]}, {"text": "Additional Datasets Several smaller datasets have been compiled in recent years.", "labels": [], "entities": []}, {"text": "Most of these works have focused on algebra word problems, including MaWPS (), Alg514 (, and DRAW-1K ().", "labels": [], "entities": [{"text": "MaWPS", "start_pos": 69, "end_pos": 74, "type": "DATASET", "confidence": 0.9111632704734802}, {"text": "DRAW-1K", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.8080118894577026}]}, {"text": "Many of these datasets have sought to align underlying equations or systems of equations with word problem text.", "labels": [], "entities": []}, {"text": "While recent works like () have explored representing math word problems with logical formalisms and regular expressions, our work is the first to provide well-defined formalisms for representing intermediate problem-solving steps that are shown to be generalizable beyond algebra problems.", "labels": [], "entities": []}, {"text": "Solving with Handcrafted Features Due to sparsity of suitable data, early work on math word problem solving used pattern-matching to map word problems to mathematical expressions, as well as non-neural statistical modeling and semantic parsing approaches (.", "labels": [], "entities": [{"text": "math word problem solving", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.6455937549471855}, {"text": "semantic parsing", "start_pos": 227, "end_pos": 243, "type": "TASK", "confidence": 0.7342570275068283}]}, {"text": "Some effort has been made on parsing the problems to extract salient entities (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9638450145721436}]}, {"text": "This approach views entities as containers, which can be composed into an equation tree representation.", "labels": [], "entities": []}, {"text": "The equation tree representation is changed overtime by operations implied by the problem text.", "labels": [], "entities": []}, {"text": "Many early works focused on solving addition and subtraction problems.", "labels": [], "entities": [{"text": "solving addition and subtraction", "start_pos": 28, "end_pos": 60, "type": "TASK", "confidence": 0.7204323038458824}]}, {"text": "As word problems become more diverse and complex, we require models capable of solving simultaneous equation systems.", "labels": [], "entities": []}, {"text": "This has led to an increasing focus on finding semantic alignment of math word problems and mentions of numbers.", "labels": [], "entities": [{"text": "semantic alignment of math word problems", "start_pos": 47, "end_pos": 87, "type": "TASK", "confidence": 0.8101542890071869}]}, {"text": "The main idea behind those work is to find all possible patterns of equations and rank them based on the problem.", "labels": [], "entities": []}, {"text": "Neural Word Problem Solvers Following the increasing availability of large-scale datasets like AQuA, several recent works have explored deep neural approaches to math word problem solving (.", "labels": [], "entities": [{"text": "Neural Word Problem Solvers", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7162132561206818}, {"text": "math word problem solving", "start_pos": 162, "end_pos": 187, "type": "TASK", "confidence": 0.7158254086971283}]}, {"text": "Our representation language is motivated by exploration of using intermediate formalisms in the training of deep neural problem-solving networks, as is done in the work of) to solve problems with sequence to sequence models.", "labels": [], "entities": []}, {"text": "While this work focused on single-variable arithmetic problems, our work introduces a formal language of operations for covering more complex multivariate problems and systems of equations.", "labels": [], "entities": []}, {"text": "Interpretability of Solvers While the statistical models with handcrafted features introduced by prior work are arguably \"interpretable\" due to the relative sparsity of features as well as the clear alignments between inputs and outputs, new neuralized approaches present new challenges to model interpretability of math word problem solvers (.", "labels": [], "entities": [{"text": "Interpretability of Solvers", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7130019466082255}, {"text": "math word problem solvers", "start_pos": 316, "end_pos": 341, "type": "TASK", "confidence": 0.6527023613452911}]}, {"text": "While this area is relatively unexplored, a prior approach to increasing robustness and interpretability of math word problem-solving models looks at using an adversarial dataset to determine if models are learning logical reasoning or exploiting dataset biases through pattern-matching ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset (called MathQA) consists of 37,200 math word problems, corresponding lists of multiple-choice options and aligned operation programs.", "labels": [], "entities": []}, {"text": "We use problems in the AQuA dataset and carefully annotate those problems with formal operation programs.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.9589152336120605}]}, {"text": "Math problems are first categorized into math domains using term frequencies (more details in Section 5.2).", "labels": [], "entities": []}, {"text": "These domains are used to prune the search space of possible operations to align with the word problem text.", "labels": [], "entities": []}, {"text": "shows: Statistics for our dataset; the total number of operations in the dataset is 58.", "labels": [], "entities": []}, {"text": "the category-based hierarchies for operation formalisms.", "labels": [], "entities": []}, {"text": "We use crowdsourcing to carefully align problems with operation programs (Section 4.1).", "labels": [], "entities": []}, {"text": "Table 1 shows overall statistics of the dataset.", "labels": [], "entities": []}, {"text": "Our dataset consists of 37k problems which are randomly split in (80/12/8)% training/dev/test problems.", "labels": [], "entities": []}, {"text": "Our dataset significantly enhances the AQuA dataset by fully annotating a portion of solvable problems in the AQuA dataset into formal operation programs.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.960328221321106}, {"text": "AQuA dataset", "start_pos": 110, "end_pos": 122, "type": "DATASET", "confidence": 0.956548422574997}]}, {"text": "We carefully study the AQuA dataset.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.9179642200469971}]}, {"text": "Many of the problems are near-duplicates with slight changes to the math word problem stories or numerical values since they are expanded from a set of 30,000 seed problems through crowdsourcing ().", "labels": [], "entities": []}, {"text": "These changes are not always reflected in the rationales, leading to incorrect solutions.", "labels": [], "entities": []}, {"text": "There are also some problems that are not solvable given current math word problem solving frameworks because they require a level of reasoning not yet modeled by neural networks.", "labels": [], "entities": [{"text": "math word problem solving", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.662362203001976}]}, {"text": "Sequence problems, for example, require understanding of patterns that are difficult to intuit without domain knowledge like sequence formulas, and can only be solved automatically through brute-force or guessing.", "labels": [], "entities": []}, {"text": "shows a full breakdown of the AQuA dataset by solvability.", "labels": [], "entities": [{"text": "AQuA dataset", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9228417277336121}]}], "tableCaptions": [{"text": " Table 1: Statistics for our dataset; the total number of  operations in the dataset is 58.", "labels": [], "entities": []}, {"text": " Table 2: Full original AQuA solvability statistics.", "labels": [], "entities": []}]}