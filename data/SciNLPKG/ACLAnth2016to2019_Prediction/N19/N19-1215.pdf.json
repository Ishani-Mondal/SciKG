{"title": [{"text": "Modeling Personal Biases in Language Use by Inducing Personalized Word Embeddings", "labels": [], "entities": [{"text": "Modeling Personal Biases in Language Use", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8062702814737955}]}], "abstractContent": [{"text": "There exist biases in individual's language use; the same word (e.g., cool) is used for expressing different meanings (e.g., temperature range) or different words (e.g., cloudy, hazy) are used for describing the same meaning.", "labels": [], "entities": []}, {"text": "In this study, we propose a method of modeling such personal biases in word meanings (here-after, semantic variations) with personalized word embeddings obtained by solving a task on subjective text while regarding words used by different individuals as different words.", "labels": [], "entities": []}, {"text": "To prevent personalized word embeddings from being contaminated by other irrelevant biases, we solve a task of identifying a review-target (objective output) from a given review.", "labels": [], "entities": []}, {"text": "To stabilize the training of this extreme multi-class classification, we perform a multi-task learning with metadata identification.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.6794599741697311}, {"text": "metadata identification", "start_pos": 108, "end_pos": 131, "type": "TASK", "confidence": 0.7131793349981308}]}, {"text": "Experimental results with reviews retrieved from RateBeer confirmed that the obtained personalized word embeddings improved the accuracy of sentiment analysis as well as the target task.", "labels": [], "entities": [{"text": "RateBeer", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.9461873769760132}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9993195533752441}, {"text": "sentiment analysis", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.9590542018413544}]}, {"text": "Analysis of the obtained personalized word embed-dings revealed trends in semantic variations related to frequent and adjective words.", "labels": [], "entities": []}], "introductionContent": [{"text": "When we verbalize what we have sensed, there exist inevitable personal biases in word meanings (hereafter, (personal) semantic variations).", "labels": [], "entities": []}, {"text": "For example, when we say \"this pizza is greasy,\" how greasy can vary widely among individuals.", "labels": [], "entities": []}, {"text": "When we seethe same beer, we may use different words (e.g., red, amber) to refer its color.", "labels": [], "entities": []}, {"text": "The semantic variations will thereby cause problems not only in communicating with each other, but also in building natural language processing (NLP) systems.", "labels": [], "entities": []}, {"text": "Several studies have attempted to personalize models to improve the performance on NLP tasks such as sentiment analysis () and dialogue systems (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.9582310914993286}]}, {"text": "All of these studies, however, tried to estimate subjective output from subjective input (e.g., estimating sentiment scores given by reviewers).", "labels": [], "entities": []}, {"text": "These personalized models are thereby affected by not only semantic variations in subjective input but also annotation bias (deviation of outputs given by the annotators) and selection bias (deviation of outputs caused by the deviation of input).", "labels": [], "entities": []}, {"text": "This makes it difficult to understand the pure impact of the personal semantic variations.", "labels": [], "entities": []}, {"text": "In this study, aiming at understanding semantic variations and their impact on NLP tasks, we propose a method for modeling personal semantic variations with personalized word embeddings obtained through the review-target identification task.", "labels": [], "entities": []}, {"text": "This task estimates the review-target (objective output) from a given review (subjective input) ( \u00a7 3), and is free from annotation bias since output labels are given a priori.", "labels": [], "entities": []}, {"text": "Also, selection bias can be suppressed by using a dataset in which the same reviewer evaluates the same target only once, so as not to learn the deviation of output labels caused by the choice of inputs.", "labels": [], "entities": []}, {"text": "To stabilize the training of this extreme multi-class classification, we apply multi-task learning (MTL) with metadata estimation of the review-target to effectively learn a reliable model (personalized word embeddings).", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.6574680358171463}]}, {"text": "We validate our hypothesis that words related to the five senses have large semantic variations.", "labels": [], "entities": []}, {"text": "We first confirm the impact of personalized word embeddings in the review-target identification using a review dataset obtained from RateBeer, and next evaluate their usefulness in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 181, "end_pos": 199, "type": "TASK", "confidence": 0.965239018201828}]}, {"text": "Analysis of the obtained personalized word embeddings on three metrics (frequency, dissemination and polysemy) reveals trends on which words have large semantic variations ( \u00a7 4.3).", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: \u2022 We established a method to obtain personal semantic variations via multi-task learning on a task with objective outputs ( \u00a7 3).", "labels": [], "entities": []}, {"text": "\u2022 We categorized personal biases in NLP ( \u00a7 2).", "labels": [], "entities": []}, {"text": "\u2022 We confirmed the usefulness of personalized word embeddings in review-target identification and sentiment analysis tasks ( \u00a7 4.2).", "labels": [], "entities": [{"text": "review-target identification and sentiment analysis tasks", "start_pos": 65, "end_pos": 122, "type": "TASK", "confidence": 0.7293614645799001}]}, {"text": "\u2022 We revealed trends in personal semantic variations ( \u00a7 4.3).", "labels": [], "entities": [{"text": "personal semantic variations", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.6824720998605093}]}], "datasetContent": [{"text": "We first evaluate the effect of personalization in the target identification task.", "labels": [], "entities": [{"text": "target identification task", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.8175253470738729}]}, {"text": "Next, to confirm the usefulness of the obtained personalized embeddings, we exploit them to solve a sentiment analysis task for extrinsic evaluation.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.9241006970405579}, {"text": "extrinsic evaluation", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.7258708477020264}]}, {"text": "Finally, we analyze the degree and tendencies of semantic variations captured by the obtained personalized word embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hyperparameters of our model.", "labels": [], "entities": []}, {"text": " Table 2: Results on the review-target and its meta- data identification.", "labels": [], "entities": []}, {"text": " Table 3: Results on the sentiment analysis: embed- ding layers are kept fixed to those of the corre- sponding models in", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9440783262252808}]}]}