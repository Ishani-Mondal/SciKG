{"title": [{"text": "Litigation Analytics: Case outcomes extracted from US federal court dockets", "labels": [], "entities": []}], "abstractContent": [{"text": "Dockets contain a wealth of information for planning a litigation strategy, but the information is locked up in semi-structured text.", "labels": [], "entities": []}, {"text": "Manually deriving the outcomes for each party (e.g., settlement, verdict) would be very labor intensive.", "labels": [], "entities": [{"text": "settlement, verdict)", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7809753865003586}]}, {"text": "Having such information available for every past court case, however, would be very useful for developing a strategy because it potentially reveals tendencies and trends of judges and courts and the opposing counsel.", "labels": [], "entities": []}, {"text": "We used Natural Language Processing (NLP) techniques and deep learning methods allowing us to scale the automatic analysis of millions of US federal court dockets.", "labels": [], "entities": []}, {"text": "The automatically extracted information is fed into a Litigation Analytics tool that is used by lawyers to plan how they approach concrete litigations.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper focuses on the creation of an index of case outcomes fora given docket, which we define as the legal procedure which resolves the case.", "labels": [], "entities": []}, {"text": "By the nature of this definition, a case may have only one outcome.", "labels": [], "entities": []}, {"text": "The case outcome is distinguishable from the outcomes for each party in the case, as some parties maybe dismissed or receive judgment prior to the end of the case.", "labels": [], "entities": []}, {"text": "Dockets of US Federal Court cases contain the description of the various steps that lead to the overall outcome (e.g., settlement, verdict).", "labels": [], "entities": []}, {"text": "The language describing these steps (i.e., filing a motion, an order by a judge, a dismissal) are not standardized among the various courts.", "labels": [], "entities": []}, {"text": "In addition, the outcome is derived from a sequence of docket entries and requires global information.", "labels": [], "entities": []}, {"text": "The current work explores how various machine learning approaches can be used in order to solve the problem of assigning an outcome to a given docket.", "labels": [], "entities": []}, {"text": "We start with an SVM approach inspired: The final case outcome is Settled, as entry indicates.", "labels": [], "entities": [{"text": "Settled", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9474743008613586}]}, {"text": "Entries are candidate entries for potential outcomes, but ultimately incorrect because of. by, who developed an approach determining one specific procedure type (i.e., summary judgment).", "labels": [], "entities": []}, {"text": "This approach does not take into account any sequence information, whereas the other two deep learning based approaches we utilized do.", "labels": [], "entities": []}, {"text": "The first approach uses a CNN-GRU architecture based on the TF-IDF vectors created for each docket entry.", "labels": [], "entities": []}, {"text": "The second approach is a simplified hierarchical RNN approach called Nested GRU modeling the words of each docket entry and using those for modeling the sequence of all docket entries in an RNN sequence model.", "labels": [], "entities": []}, {"text": "Finally, an ensemble method via a GBM combines the outputs of all three classifiers in order to determine the final outcome.", "labels": [], "entities": []}, {"text": "Results show that the deep learning approaches outperform the SVM based approach, but there is no statistically significant difference between the two deep learning methods and the system that combines all three approaches.", "labels": [], "entities": []}, {"text": "The combined system also provided the input for an actual system deployed to customers who utilize the analytics derived from the 8 million US Federal dockets for their litigation planning.", "labels": [], "entities": []}, {"text": "The US Federal Court system, including district trial courts, bankruptcy courts, and appellate courts, all use an electronic records system that provides public access via a government computer system called PACER (Public Access to Court Electronic Records).", "labels": [], "entities": []}, {"text": "The system maintains databases giving metadata associations of parties to cases, attorneys to parties, filing and closing dates of the cases, related groups of filings, and a high-level outcome of each case.", "labels": [], "entities": []}, {"text": "Pacer also holds the official record of the case, which is all the documents pertaining to the case filed by the parties, their counsel, and the court.", "labels": [], "entities": []}, {"text": "In addition to the documents themselves, there is a concise summary of each document written by the filer (and in recent times, based on a generated suggested text created by template), as well as the record of events for which no record document exists such as minor hearings.", "labels": [], "entities": []}, {"text": "We believe that the intricacy and nuance of court procedures, as well as attorneys' perception of how to use procedure to their clients' advantage, has and will continue to cause the court system to be resistant to the adoption of fully digital workflows.", "labels": [], "entities": []}, {"text": "Thus, dockets will contain significant unstructured data for the foreseeable future, and the task of defining, extracting, and indexing important litigation events falls to third parties and requires NLP techniques.", "labels": [], "entities": [{"text": "defining, extracting, and indexing important litigation events", "start_pos": 101, "end_pos": 163, "type": "TASK", "confidence": 0.7844079037507375}]}, {"text": "The metadata outcome information from PACER and the case outcome that we seek to index are indeed similar.", "labels": [], "entities": [{"text": "PACER", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.5411927700042725}]}, {"text": "There are two reasons why the metadata element is not sufficient by itself: First, it is frequently inaccurate, apparently because of differences in interpretation among the clerks of different courts.", "labels": [], "entities": []}, {"text": "Second, a more specific taxonomy can be defined and extracted.", "labels": [], "entities": []}, {"text": "Applying machine learning and NLP capabilities to all federal dockets allowed us to collect outcomes for almost 8 million past dockets and also enables us to keep up with all newly closed dockets.", "labels": [], "entities": []}, {"text": "In addition to extracting the outcome, the system is able to accurately determine a small percentage of cases that are likely to have an inaccurate extracted outcome, which should be reviewed by a human.", "labels": [], "entities": []}, {"text": "The case outcome task is distinguishable from other classic problem formulations in the NLP space.", "labels": [], "entities": []}, {"text": "Classical approaches to document classification fail for several reasons: First, distributional assumptions in document classification are not valid because parties can spend a great deal of effort on issues that ultimately have no bearing on the outcome of the case.", "labels": [], "entities": [{"text": "document classification", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.7803562581539154}, {"text": "document classification", "start_pos": 111, "end_pos": 134, "type": "TASK", "confidence": 0.7475241124629974}]}, {"text": "For example, a docket may contain minutes of many days at trial, but the judgment was granted as a matter of law, indicated by a few terse words in the docket.", "labels": [], "entities": []}, {"text": "Second, negation is frequently critical.", "labels": [], "entities": [{"text": "negation", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.9903034567832947}]}, {"text": "For example, there area significant number of docket entries which say something like, \"Settlement conference held.", "labels": [], "entities": [{"text": "Settlement conference", "start_pos": 88, "end_pos": 109, "type": "TASK", "confidence": 0.7942106425762177}]}, {"text": "Finally, the problem requires extraction of a large classes of related facts.", "labels": [], "entities": []}, {"text": "For example, a great deal of time and effort may pass before a judge issues a ruling on a motion.", "labels": [], "entities": []}, {"text": "In addition, even though the case outcome problem is inherently sequential, dockets don't satisfy the Markov assumption, as events can have skipping dependencies., 1 for example, describes a case that ends with a settlement even though the last two entries simply state that the case was closed (i.e., dismissed) and all pending motions including a motion for summary judgment were dismissed.", "labels": [], "entities": []}, {"text": "Based only on these entries, the case would be dismissed, but entry contains language that points to a settlement without actually mentioning settlement, but the acceptance of an offer of judgment indicates this kind of outcome.", "labels": [], "entities": []}, {"text": "This paper describes in more detail how the problem of detecting the outcome fora case can be solved and provides an overview of how we utilized machine learning including deep learning capabilities in combination with manual review.", "labels": [], "entities": []}, {"text": "First, we describe the background of the case outcome problem and previous work in this area in section 2.", "labels": [], "entities": [{"text": "case outcome problem", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.8826547265052795}]}, {"text": "Then, we describe the overall solution architecture and the underlying machine learning approaches used in section 3.", "labels": [], "entities": []}, {"text": "Section 4 provides more details on evaluating the different approaches.", "labels": [], "entities": []}, {"text": "Section 5 outlines the content of a demo of the live system and section 6 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the overall system's performance by comparing how much the three different ML approaches contribute to the overall performance.", "labels": [], "entities": [{"text": "ML", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.9411380290985107}]}, {"text": "shows how the singular approaches behave.", "labels": [], "entities": []}, {"text": "The nested GRU approach has the best overall performance and almost all individual outcomes are detected with higher F1-scores by this method (except for docketed elsewhere).", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.998498797416687}]}, {"text": "The CNN-GRU methods shows better or equal results for each outcome compared to the results achieved by the SVM method we deployed.", "labels": [], "entities": []}, {"text": "We tested whether the performance of the respective system combinations are statistically different.", "labels": [], "entities": []}, {"text": "We used the McNemar's test for identifying whether a machine learning classifier outperforms another one following the study by indicates that the results created by the CNN-GRU and the Nested GRU approaches are significantly different from the baseline system that only uses SVM features for the GBM classification.", "labels": [], "entities": []}, {"text": "The combined approach utilizing both CNN-GRU and Nested GRU features in addition to the SVM features outperforms the baseline system as well, but the performances of the CNN-GRU and Nested GRU looked at individually are not significantly different as indicated by the pvalues obtained from the McNemar's test.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 294, "end_pos": 308, "type": "DATASET", "confidence": 0.895067552725474}]}, {"text": "There is also no statistically significant difference between the results of the combined approach and each of the results of the two deep learning approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Single approaches and respective performances", "labels": [], "entities": []}, {"text": " Table 2: Results of all approaches combined", "labels": [], "entities": []}, {"text": " Table 3: P-values for the McNemar's test for system  combinations", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.8320493896802267}]}]}