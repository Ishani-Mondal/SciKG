{"title": [{"text": "Language Learning and Processing in People and Machines", "labels": [], "entities": [{"text": "Language Learning and Processing in People and Machines", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8006575033068657}]}], "abstractContent": [{"text": "1 A Brief Description The ambitious goal of computational linguistics (CL) is to develop systems that process, understand , and produce natural languages.", "labels": [], "entities": [{"text": "computational linguistics (CL)", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.8243694543838501}]}, {"text": "To achieve this goal, most work in CL has focused on developing models for different linguistic tasks such as semantic role labeling and natural language inference.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.63396817445755}]}, {"text": "However, recent research in CL has started investigating the missing ingredients required to move towards building systems with general linguistic intelligence.", "labels": [], "entities": []}, {"text": "For example, one area of focus is multitask learning-building models that perform well on a number of linguistic tasks (e.g., Devlin et al., 2018).", "labels": [], "entities": []}, {"text": "Other research has investigated the importance of introducing common-sense into natural language processing models (e.g., Rashkin et al., 2018).", "labels": [], "entities": []}, {"text": "Despite the recent advances in the field, we are still far from systems that exhibit human-level linguistic intelligence: great performance on a set of predefined linguistics tasks does not result in systems that can understand and produce natural language in general settings.", "labels": [], "entities": []}, {"text": "An alternative research direction is to build systems that mimic language acquisition and processing as it is performed by humans.", "labels": [], "entities": [{"text": "language acquisition and processing", "start_pos": 65, "end_pos": 100, "type": "TASK", "confidence": 0.7972953170537949}]}, {"text": "Such a system might achieve the linguistic efficacy required for understanding and producing human languages.", "labels": [], "entities": []}, {"text": "But we first need to understand how children so effortlessly learn their language.", "labels": [], "entities": []}, {"text": "Aline of research aims to reverse-engineer child language acquisition: the idea is to shed light on the cognitive processes that might be responsible for language acquisition ; we can in turn use the learned lessons in designing computational (cognitive) models that exhibit human-like language performance.", "labels": [], "entities": [{"text": "reverse-engineer child language acquisition", "start_pos": 26, "end_pos": 69, "type": "TASK", "confidence": 0.6194424480199814}, {"text": "language acquisition", "start_pos": 154, "end_pos": 174, "type": "TASK", "confidence": 0.7213204354047775}]}, {"text": "Understanding language acquisition is also beneficial to natural language processing (NLP) applications: we can explore how the mechanisms (such as attention) and inductive biases that facilitate human learning can be explicitly incorporated into our algorithms.", "labels": [], "entities": []}, {"text": "Moreover, we can evaluate our NLP systems with respect to human behavior which helps us understand the limitations of these systems.", "labels": [], "entities": []}, {"text": "The goal of this tutorial is to bring the fields of computational linguistics and computational cog-nitive science closer: we will introduce different stages of language acquisition and their parallel problems in NLP.", "labels": [], "entities": []}, {"text": "As an example, one of the early challenges children face is mapping the meaning of word labels (such as \"cat\") to their referents (the furry animal in the living room).", "labels": [], "entities": []}, {"text": "Word learning is similar to the word alignment problem in machine translation.", "labels": [], "entities": [{"text": "Word learning", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8341371417045593}, {"text": "word alignment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7625553607940674}, {"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7068164646625519}]}, {"text": "We explain the current computational models of human language acquisition, their limitations , and how the insights from these models can be incorporated into NLP applications.", "labels": [], "entities": [{"text": "human language acquisition", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.6393491923809052}]}, {"text": "Moreover , we discuss how we can take advantage of the cognitive science of language in computational linguistics: for example, by designing cognitively-motivated evaluation tasks or building language-learning inductive biases into our models.", "labels": [], "entities": []}, {"text": "We believe now is a great time for this tuto-rial.", "labels": [], "entities": []}, {"text": "Using end-to-end and deep neural approaches has resulted in significant improvements in various NLP tasks in the past years.", "labels": [], "entities": []}, {"text": "But in 2018, we observed a shift in the field from building models to creating datasets; this mainly happened because given the current compute power and access to vast amount of data, the existing NLP tasks were not challenging enough for our models.", "labels": [], "entities": []}, {"text": "Revisit-ing challenges in language acquisition will spark interest in the community in two ways: Some will be inspired to design more challenging problems, and others may work on developing models of language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.705049604177475}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}