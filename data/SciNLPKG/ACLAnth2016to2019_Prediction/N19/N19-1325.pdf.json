{"title": [{"text": "Exploiting Noisy Data in Distant Supervision Relation Classification", "labels": [], "entities": [{"text": "Distant Supervision Relation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.916335662206014}]}], "abstractContent": [{"text": "Distant supervision has obtained great progress on relation classification task.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.9502489566802979}]}, {"text": "However, it still suffers from noisy labeling problem.", "labels": [], "entities": []}, {"text": "Different from previous works that underutilize noisy data which inherently characterize the property of classification, in this paper, we propose RCEND, a novel framework to enhance Relation Classification by Exploiting Noisy Data.", "labels": [], "entities": [{"text": "Relation Classification", "start_pos": 183, "end_pos": 206, "type": "TASK", "confidence": 0.9838694334030151}]}, {"text": "First, an instance discriminator with reinforcement learning is designed to split the noisy data into correctly labeled data and incorrectly labeled data.", "labels": [], "entities": []}, {"text": "Second, we learn a robust relation classifier in semi-supervised learning way, whereby the correctly and incorrectly labeled data are treated as labeled and unlabeled data respectively.", "labels": [], "entities": []}, {"text": "The experimental results show that our method outperforms the state-of-the-art models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relation classification plays a crucial role in natural language processing (NLP) tasks, such as question answering and knowledge base completion ().", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9389353692531586}, {"text": "question answering", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.8649888932704926}, {"text": "knowledge base completion", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.6043582459290823}]}, {"text": "The goal of relation classification is to predict relations of the target entity pair given a plain text.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.8379324078559875}]}, {"text": "Traditional supervised learning methods (;) heavily rely on large scale annotated data which is time and labor consuming.", "labels": [], "entities": []}, {"text": "proposed distant supervision (DS) to automatically generate training data for relation classification based on the assumption that if two target entities have a relation in knowledge base (KB), sentences containing this entity pair might express the relation.", "labels": [], "entities": [{"text": "distant supervision (DS)", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.6692367434501648}, {"text": "relation classification", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7833481729030609}]}, {"text": "For example, if a relational fact <Apple, founder, Steve Jobs> exists in KB, distant supervision will assign founder as the label of all sentences that contain \"Apple\" and \"Steve Jobs\" together.", "labels": [], "entities": []}, {"text": "Sentence DS Gold S1:Al Gore was waiting to board a commercial flight from Nashville to Miami...", "labels": [], "entities": [{"text": "Sentence DS Gold S1", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.7503472566604614}]}], "datasetContent": [{"text": "We evaluate our model on a widely used dataset that is generated by aligning entity pairs from   Following previous works, we evaluate our model on the held-out evaluation, which compares relation facts extracted from the test corpus with those in Freebase.", "labels": [], "entities": []}, {"text": "We adopt aggregated precision/recall curves and precision@N (P@N) to illustrate the performance of our model.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9139299988746643}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.8414291143417358}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9974875450134277}]}, {"text": "We adopt the following baselines with which we compare our model:   based on the at-least-one assumption and selective attention.", "labels": [], "entities": []}, {"text": "PCNN+HATT () is a attention-based method which employs hierarchical attention to exploit correlations among relations.", "labels": [], "entities": [{"text": "HATT", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.8319885730743408}]}, {"text": "\u2022 PCNN+ONE+SL and PCNN+ATT+SL() use a soft-label method to alleviate the negative impact of the noisy labeling problem.", "labels": [], "entities": []}, {"text": "We compare our model with aforementioned baselines and the results are shown in.", "labels": [], "entities": []}, {"text": "From the overall result we can see that: (1) All feature-based models preform poorly as their features are derived from NLP tools, which will generate errors that propagate through in model.", "labels": [], "entities": []}, {"text": "PCNN+ONE and PCNN+ATT boost the performance because they reduce noise in the bag of entity pair by selecting the most confident sentence or de-emphasize the incorrectly labeled sentences with an attention mechanism.", "labels": [], "entities": [{"text": "ONE", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.5796065330505371}]}, {"text": "(3) When PCNN+ONE and PCNN+ATT use soft labels, they achieve an improvement.", "labels": [], "entities": [{"text": "ONE", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.759182333946228}, {"text": "PCNN+ATT", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.808220644791921}]}, {"text": "This indicates correcting the noisy label is helpful to relation classification in MIL scheme.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.9329929053783417}]}, {"text": "PCNN+HATT further enhances the performance as it incorporates hierarchical information of relations to improve the attention mechanism.", "labels": [], "entities": [{"text": "HATT", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.8813269138336182}]}, {"text": "(5) Our method RCEND achieves the best precision over the entire recall  range compared with all baselines.", "labels": [], "entities": [{"text": "RCEND", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.7125405669212341}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9993581175804138}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9972224235534668}]}, {"text": "The performance achieves further improvement when we regard the incorrectly labeled sentences as unlabeled data and adopt a semi-supervised learning method to train our model.", "labels": [], "entities": []}, {"text": "It shows that exploiting noisy data with our method is beneficial to promote distant supervision relation classification.", "labels": [], "entities": [{"text": "distant supervision relation classification", "start_pos": 77, "end_pos": 120, "type": "TASK", "confidence": 0.6605312079191208}]}, {"text": "We also report the result of Precisions@N (100, 200, 300) in.", "labels": [], "entities": [{"text": "Precisions", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.971601128578186}]}, {"text": "We can see that our method outperforms the baselines on the precision values of top N triples extracted.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9941879510879517}]}], "tableCaptions": [{"text": " Table 3: Top-N precision (P@N) of our model and  baselines", "labels": [], "entities": [{"text": "Top-N precision (P@N)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8378178221838815}]}, {"text": " Table 4: Top-N precision (P@N) of our model with  different settings.", "labels": [], "entities": [{"text": "Top-N precision (P@N)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8203629936490741}]}, {"text": " Table 5: Examples for case study. The first three sentences are examples of false negative case and the final three  are examples of false positive case.", "labels": [], "entities": [{"text": "case study", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.9106890559196472}]}]}