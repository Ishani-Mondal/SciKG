{"title": [{"text": "Predicting Helpful Posts in Open-Ended Discussion Forums: A Neural Architecture", "labels": [], "entities": [{"text": "Predicting Helpful Posts in Open-Ended Discussion Forums", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.800606506211417}]}], "abstractContent": [{"text": "Users participate in online discussion forums to learn from others and share their knowledge with the community.", "labels": [], "entities": []}, {"text": "They often start a thread with a question or by sharing their new findings on a certain topic.", "labels": [], "entities": []}, {"text": "Unlike in Community Question Answering, where questions are mostly factoid based, we find that the threads in a forum are often open-ended (e.g., asking for recommendations from others) without a definitive correct answer.", "labels": [], "entities": [{"text": "Community Question Answering", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.649868369102478}]}, {"text": "We thus address the task of identifying helpful posts in a forum thread to help users comprehend long-running discussion threads, which often contain repetitive or irrelevant posts.", "labels": [], "entities": []}, {"text": "We propose a recurrent neural network based architecture to model (i) the relevance of a post regarding the original post starting the thread, and (ii) the novelty it brings to the discussion, compared to the previous posts in the thread.", "labels": [], "entities": []}, {"text": "Experimental results on five different types of online forum datasets show that our model significantly outperforms the state-of-the-art neural network models for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.8446169495582581}]}], "introductionContent": [{"text": "Online discussion forums are widely used in many domains such as in generic web content 1 , e-health 2 , Massive Open Online Courses (MOOCs) , and e-commerce, among others.", "labels": [], "entities": [{"text": "generic web content 1", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.6277281045913696}]}, {"text": "Users participate in these forums to gain knowledge from the collective wisdom of the community.", "labels": [], "entities": []}, {"text": "Typically, users start a discussion thread by posting a question or asking others for opinions on a topic.", "labels": [], "entities": []}, {"text": "Others then reply to threads relevant to their interests.", "labels": [], "entities": []}, {"text": "Importantly, as these forums are indexed by search engines, they need to be discoverable by a wider audience -apart from just registered users -by enabling threads to be found in response to queries.", "labels": [], "entities": []}, {"text": "Due to the open nature of the forums and the various expertise level of users, the posts in the discussion threads vary in helpfulness.", "labels": [], "entities": []}, {"text": "To address this, some websites provide actions for users to signal this, as in \"Upvote\" (reddit, stackoverflow) and \"Highlight\" (coursera).", "labels": [], "entities": []}, {"text": "Such feedback is helpful for identifying important posts among the many.", "labels": [], "entities": []}, {"text": "Such feedback rarely comes immediately following new post creation, affecting their visibility to the users (.", "labels": [], "entities": []}, {"text": "We can devise technology to proactively identify such helpful posts as they arrive, in a helpfulness prediction task, enabling users to efficiently assess relevance.", "labels": [], "entities": [{"text": "helpfulness prediction task", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.7717444101969401}]}, {"text": "We observe that there is a key structural difference between online discussion forums and Community Question Answering (CQA) websites.", "labels": [], "entities": [{"text": "Community Question Answering (CQA)", "start_pos": 90, "end_pos": 124, "type": "TASK", "confidence": 0.7890714704990387}]}, {"text": "shows the distribution of normalized helpful votes for the top-5 posts across a popular discussion forum (reddit), and a CQA website (stackoverflow 4 ).", "labels": [], "entities": []}, {"text": "In CQA, the vote distribution decays exponentially, indicating that usually there is a single correct answer with the largest number of votes ().", "labels": [], "entities": []}, {"text": "In contrast, votes for less helpful posts in discussion forums decay at a much lower rate, suggesting that discussion forum threads are more open-ended.", "labels": [], "entities": []}, {"text": "shows a sample thread from reddit to understand the dynamics of online discussion.", "labels": [], "entities": []}, {"text": "We observe the following two major differences compared to threads in CQA domain: (1) The first post (hereafter, original post) is not necessarily a question, but can be personal anecdotes or new findings on a certain topic, attracting more discussion.", "labels": [], "entities": []}, {"text": "(2) Instead of searching fora single relevant answer as in CQA, discussion forum users find a post helpful when it introduces some relevant (with respect to the original post) and novel (i.e., not presented in the earlier posts within the same thread) information.", "labels": [], "entities": [{"text": "CQA", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.904959499835968}]}, {"text": "Motivated by these observations, we address helpfulness prediction by considering both the target post and its preceding posts.", "labels": [], "entities": [{"text": "helpfulness prediction", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7678510248661041}]}, {"text": "We propose a novel neural architecture to predict the helpfulness of a post in a discussion thread.", "labels": [], "entities": []}, {"text": "Our approach consists of two components: (1) modeling the relevance of a post and (2) determining the novelty with respect to the sequence of preceding posts.", "labels": [], "entities": []}, {"text": "It combines the output from both components to predict the overall post helpfulness.", "labels": [], "entities": []}, {"text": "As recurrent neural networks (RNNs) have shown good performance in sequence modeling tasks), we apply it to our architecture to model the (i) sequence of words in the post text, and the (ii) sequence of posts in a thread.", "labels": [], "entities": []}, {"text": "Our model significantly outperforms other state-of-the-art models across experiments on five varied and large forum datasets.", "labels": [], "entities": []}, {"text": "Our main contributions are: \u2022 We reveal the key differences between posts in CQA and online discussion forums; \u2022 We analyze the confounding factors behind the perceived helpfulness of posts in discussion forums.", "labels": [], "entities": []}, {"text": "We observe that both relevance and novelty play important roles in determining the helpfulness of a post; \u2022 We propose a novel neural network architecture to predict the helpfulness by using textual content of a target post as well as sequence of posts preceding it in the thread; \u2022 We compare our model with current neural network classifiers and analyze the factors that influence our model's performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first describe the datasets, evaluation metrics, and baseline models before our main results.", "labels": [], "entities": []}, {"text": "We also conducted additional experiments to answer specific research questions about our model.", "labels": [], "entities": []}, {"text": "We experiment with five real-world online discussion forums to validate model effectiveness.", "labels": [], "entities": []}, {"text": "Typical of other research work, we also remove threads that have less than two posts.", "labels": [], "entities": []}, {"text": "Reddit is a popular platform for discussions on a wide-variety of topics on the web.", "labels": [], "entities": []}, {"text": "We  use a large number of discussion threads from a reddit data dump 8 . To diversify the datasets in terms of average thread length, we set different thresholds, and created two datasets: Reddit 10+ (\u2265 10 posts) and Reddit 3+ (\u2265 3 posts).", "labels": [], "entities": []}, {"text": "Along with a chronologically ordered set of posts, reddit also has \"Upvote\" counts for every post.", "labels": [], "entities": []}, {"text": "Coursera is a large MOOC platform, providing a discussion forum for the course participants.", "labels": [], "entities": [{"text": "Coursera", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9772676229476929}]}, {"text": "We select two courses with the largest number of posts: \"Matrix-001\" and \"Android Apps 101-001\" from a MOOC dataset (.", "labels": [], "entities": [{"text": "Matrix-001", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.9597182273864746}, {"text": "MOOC dataset", "start_pos": 103, "end_pos": 115, "type": "DATASET", "confidence": 0.9033343195915222}]}, {"text": "Course participants can \"vote\" fora post if they find it helpful.", "labels": [], "entities": []}, {"text": "We refer to these datasets as Matrix and Android Apps, hereafter.", "labels": [], "entities": []}, {"text": "5. Travel Stack Exchange is one of many QA websites in the Stack Exchange community.", "labels": [], "entities": [{"text": "Travel Stack Exchange", "start_pos": 3, "end_pos": 24, "type": "DATASET", "confidence": 0.9057174126307169}]}, {"text": "We use a data dump 9 of the website and refer to it as Travel dataset.", "labels": [], "entities": [{"text": "Travel dataset", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.9758838415145874}]}, {"text": "In Travel Stack Exchange, a user can \"Upvote\" a post if she deems it helpful.", "labels": [], "entities": []}, {"text": "Although not strictly a discussion forum, the threads in this forum appear to be less objective (by our vote distribution analysis, similar to), compared to other CQA sites like stackoverflow.", "labels": [], "entities": []}, {"text": "We use the user-provided feedback inform of \"mark as helpful\", \"like\", \"upvote\" actions as a proxy of the actual helpfulness of a post.", "labels": [], "entities": []}, {"text": "Vote counts vary widely across posts and threads, (i.e., 0 to 3,100 for the reddit dataset), making it infeasible to formulate the task as a regression problem.", "labels": [], "entities": [{"text": "Vote counts", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.8629863560199738}, {"text": "reddit dataset", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.8396452069282532}]}, {"text": "Following by prior published research (), we model it as a binary classification problem, and use the 80 th percentile expected value of helpful vote count across all the posts as the boundary between the two classes.", "labels": [], "entities": []}, {"text": "We assume that a post is helpful if it has received more helpful votes than the 80 th percentile, and not helpful otherwise.", "labels": [], "entities": []}, {"text": "Since our goal is to predict the helpful posts and the class distribution is inherently skewed from our definition, we evaluate the model performance in terms of prediction accuracy for only the positive, helpful class.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9369925856590271}]}, {"text": "We evaluate using standard precision, recall, and F 1 score across all datasets.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9981010556221008}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9996800422668457}, {"text": "F 1 score", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9892022808392843}]}], "tableCaptions": [{"text": " Table 3: (P)recision, (R)ecall and F 1 comparison of model performances across our five datasets representing three  domains. Our model outperforms other state-of-the-art neural text classifiers consistently. Ablation study with  Answer Selection, Relevance-based, and Novelty-based model shows that modelling both relevance, and novelty  is important.", "labels": [], "entities": [{"text": "recision", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.924702525138855}, {"text": "F", "start_pos": 36, "end_pos": 37, "type": "METRIC", "confidence": 0.9987969398498535}, {"text": "Answer Selection", "start_pos": 231, "end_pos": 247, "type": "TASK", "confidence": 0.8297292590141296}]}, {"text": " Table 5: F 1 obtained by the model variation that uses  the average tensor of the past post tensors as the context  tensor, compared to our GRU context based model.", "labels": [], "entities": [{"text": "F", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9888126850128174}]}]}