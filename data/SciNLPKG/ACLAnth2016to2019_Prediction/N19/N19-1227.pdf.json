{"title": [{"text": "Partial Or Complete, That Is The Question", "labels": [], "entities": [{"text": "Complete", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9406970143318176}]}], "abstractContent": [{"text": "For many structured learning tasks, the data annotation process is complex and costly.", "labels": [], "entities": []}, {"text": "Existing annotation schemes usually aim at acquiring completely annotated structures, under the common perception that partial structures are of low quality and could hurt the learning process.", "labels": [], "entities": []}, {"text": "This paper questions this common perception, motivated by the fact that structures consist of interdependent sets of variables.", "labels": [], "entities": []}, {"text": "Thus, given a fixed budget, partly annotating each structure may provide the same level of supervision, while allowing for more structures to be annotated.", "labels": [], "entities": []}, {"text": "We provide an information theoretic formulation for this perspective and use it, in the context of three diverse structured learning tasks, to show that learning from partial structures can sometimes outperform learning from complete ones.", "labels": [], "entities": []}, {"text": "Our findings may provide important insights into structured data annotation schemes and could support progress in learning protocols for structured tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many machine learning tasks require structured outputs, and the goal is to assign values to a set of variables coherently.", "labels": [], "entities": []}, {"text": "Specifically, the variables in a structure need to satisfy some global properties required by the task.", "labels": [], "entities": []}, {"text": "An important implication is that once some variables are determined, the values taken by other variables are constrained.", "labels": [], "entities": []}, {"text": "For instance, in the temporal relation extraction problem in, if met happened before leaving and leaving happened on Thursday, then we know that met must either be before Thursday (\"met (1)\") or has to happen on Thursday, too (\"met (2)\") ().", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6215848028659821}]}, {"text": "Similarly, in the semantic frame of the predicate gave () in, if the boy is ARG0 (short for argument 0), then it rules out the possibility of a frog  The boy gave a frog to the girl. or to the girl taking the same role.", "labels": [], "entities": [{"text": "ARG0", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.8077223896980286}]}, {"text": "further shows an example of part-labeling of images (; given the position of FORE-HEAD and LEFT EYE of the cat in the picture, we roughly know that its NECK should be somewhere in the red solid box, while the blue dashed box is likely to be wrong.", "labels": [], "entities": [{"text": "FORE-HEAD", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9985322952270508}, {"text": "LEFT", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9990686774253845}, {"text": "EYE", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.627005934715271}, {"text": "NECK", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9208673238754272}]}, {"text": "Data annotation for these structured tasks is complex and costly, thus requiring one to make the most of a given budget.", "labels": [], "entities": [{"text": "Data annotation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6571058332920074}]}, {"text": "This issue has been investigated for decades from the perspective of active learning for classification tasks and for structured tasks.", "labels": [], "entities": [{"text": "classification tasks", "start_pos": 89, "end_pos": 109, "type": "TASK", "confidence": 0.893671840429306}]}, {"text": "While active learning aims at selecting the next structure to label, we try to investigate, from a different perspective, whether we should annotate each structure completely or partially.", "labels": [], "entities": []}, {"text": "Conventional annotation schemes typically require complete structures, under the common perception that partial annotation could adversely affect the performance of the learning algorithm.", "labels": [], "entities": []}, {"text": "But note that partial annotations will allow for more structures to be annotated (see).", "labels": [], "entities": []}, {"text": "Therefore, a fair comparison should be done while maintaining a fixed annotation budget, which was not done before.", "labels": [], "entities": []}, {"text": "Moreover, even if partial annotation leads to comparable learning performance to conventional complete schemes, it provides more flexibility in data annotation.", "labels": [], "entities": []}, {"text": "Another potential benefit of partial annotation is that it imposes constraints on the remaining parts of a structure.", "labels": [], "entities": []}, {"text": "As illustrated by, with partial annotations, we already have some knowledge about the unannotated parts.", "labels": [], "entities": []}, {"text": "Therefore, further annotations of these variables may use the available budget less efficiently; this effect was first discussed in.", "labels": [], "entities": []}, {"text": "Motivated by the observations in, we think it is important to study partialness systematically, before we hastily assume that completeness should always be favored in data collection.", "labels": [], "entities": []}, {"text": "To study whether the above benefits of partialness can offset its weakness for learning, our first contribution is the proposal of early stopping partial annotation (ESPA) scheme, which randomly picks up instances to label in the beginning, and stops before a structure is completed.", "labels": [], "entities": []}, {"text": "We do not claim that ESPA should always be preferred; instead, it serves as an alternative to conventional, complete annotation schemes that we should keep in mind, because, as we show later, it can be comparable to (and sometimes even better than) complete annotation schemes.", "labels": [], "entities": []}, {"text": "ESPA is straightforward to implement even in crowdsourcing; instances to annotate can be selected offline and distributed to crowdsourcers; this can be contrasted with the difficulties of implementing active learning protocols in these settings ().", "labels": [], "entities": []}, {"text": "We think that ESPA is a good representative fora systematic study of partialness.", "labels": [], "entities": []}], "datasetContent": [{"text": "2, we argued from an information theoretic view that ESPA is beneficial for structured tasks if we have a fixed annotation resource.", "labels": [], "entities": []}, {"text": "We then proposed SSPAN in Sec.", "labels": [], "entities": [{"text": "SSPAN", "start_pos": 17, "end_pos": 22, "type": "TASK", "confidence": 0.9221429228782654}]}, {"text": "3 to learn from the resulting partial structures.", "labels": [], "entities": []}, {"text": "However, on one hand, there is still a gap between the I k analysis and the actual system performance; on the other hand, whether the benefit can be realized in practice also depends on how effective the algorithm exploits partial annotations.", "labels": [], "entities": []}, {"text": "Therefore, it remains to be seen how ESPA works in practice.", "labels": [], "entities": [{"text": "ESPA", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.8508768081665039}]}, {"text": "Here we use three NLP tasks: temporal relation (TempRel) extraction, semantic role classification (SRC), and shallow parsing, analogous to the chain, assignment, and BIO structures, respectively.", "labels": [], "entities": [{"text": "temporal relation (TempRel) extraction", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.6033631910880407}, {"text": "semantic role classification (SRC)", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.7573342323303223}]}, {"text": "For all tasks, we compare the following two schemes in, where we use graph structures for demonstration.", "labels": [], "entities": []}, {"text": "Initially, we have a relatively small but complete dataset T 0 , an unannotated dataset U 0 , and some budget to annotate U 0 . The conventional scheme I, also our baseline here, is to annotate each structure completely before randomly picking up the next one.", "labels": [], "entities": []}, {"text": "Due to the limited budget, some U 0 remain untouched (denoted by U ).", "labels": [], "entities": []}, {"text": "The proposed scheme II adopts ESPA so that all structures at hand are annotated but only partially.", "labels": [], "entities": [{"text": "ESPA", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.751646101474762}]}, {"text": "For fair comparisons, we use CoDL to incorporate U into scheme I as well.", "labels": [], "entities": []}, {"text": "Finally, the systems trained on the dataset from I/II via CoDL/SSPAN are evaluated on unseen but complete testset T test . Note that because ESPA is anew annotation scheme, there exists no dataset collected this way.", "labels": [], "entities": []}, {"text": "We use existing complete datasets and randomly throw out some annotations to mimic ESPA in the following.", "labels": [], "entities": []}, {"text": "Due to the randomness in selecting which structures/instances to keep in scheme I/II, we repeat the whole process multiple times and report the mean F 1 . The budget, defined as the total number of individual instances that can be annotated, ranges from 10% to 100% with a stepsize of 10%, where x% means x% of all instances in U 0 can be annotated.", "labels": [], "entities": []}, {"text": "Finally, they are tested on an unseen and complete dataset (black).", "labels": [], "entities": []}], "tableCaptions": []}