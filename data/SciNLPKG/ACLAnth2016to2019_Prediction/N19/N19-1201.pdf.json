{"title": [{"text": "Subword-Level Language Identification for Intra-Word Code-Switching", "labels": [], "entities": [{"text": "Subword-Level Language Identification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7712191541989645}]}], "abstractContent": [{"text": "Language identification for code-switching (CS), the phenomenon of alternating between two or more languages in conversations, has traditionally been approached under the assumption of a single language per token.", "labels": [], "entities": [{"text": "Language identification for code-switching (CS)", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7479248344898224}]}, {"text": "However , if at least one language is morphologically rich, a large number of words can be composed of morphemes from more than one language (intra-word CS).", "labels": [], "entities": []}, {"text": "In this paper, we extend the language identification task to the subword level, such that it includes splitting mixed words while tagging each part with a language ID.", "labels": [], "entities": [{"text": "language identification task", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.8096283078193665}]}, {"text": "We further propose a model for this task, which is based on a segmental recurrent neural network.", "labels": [], "entities": []}, {"text": "In experiments on anew Spanish-Wixarika dataset and on an adapted German-Turkish dataset, our proposed model performs slightly better than or roughly on par with our best baseline, respectively.", "labels": [], "entities": [{"text": "Spanish-Wixarika dataset", "start_pos": 23, "end_pos": 47, "type": "DATASET", "confidence": 0.8720533549785614}]}, {"text": "Considering only mixed words, however, it strongly outperforms all baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "In settings where multilingual speakers share more than one language, mixing two or more languages within a single piece of text, for example a tweet, is getting increasingly common.", "labels": [], "entities": []}, {"text": "This constitutes a challenge for natural language processing (NLP) systems, since they are commonly designed to handle one language at a time.", "labels": [], "entities": []}, {"text": "Code-switching (CS) can be found in multiple non-exclusive variants.", "labels": [], "entities": [{"text": "Code-switching (CS)", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6274906247854233}]}, {"text": "For instance, sentences in different languages can be mixed within one text, or words from different languages can be combined into sentences.", "labels": [], "entities": []}, {"text": "CS can also occur on the subword level, when speakers combine morphemes from different languages (intra-word CS).", "labels": [], "entities": []}, {"text": "This last phenomenon can mostly be found if at least one of the languages is morphologically rich.", "labels": [], "entities": []}, {"text": "An example for intra-word CS between the Ro- mance language Spanish and the Yuto-Aztecan language Wixarika 1 is shown in.", "labels": [], "entities": []}, {"text": "CS language identification (LID) , i.e., predicting the language of each token in a text, has attracted a lot of attention in recent years (cf.;).", "labels": [], "entities": [{"text": "CS language identification (LID)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.732494980096817}, {"text": "predicting the language of each token in a text", "start_pos": 41, "end_pos": 88, "type": "TASK", "confidence": 0.8340288268195258}]}, {"text": "However, intra-word mixing is mostly not handled explicitly: words with morphemes from more than one language are simply tagged with a mixed label.", "labels": [], "entities": []}, {"text": "While this works reasonably well for previously studied language pairs, overlooking intra-word CS leads to a major loss of information for highly polsynthetic languages.", "labels": [], "entities": []}, {"text": "A mixed word is unknown for NLP systems, yet a single word contains much more information, cf..", "labels": [], "entities": []}, {"text": "Furthermore, we find intra-word CS to be much more frequent for Spanish-Wixarika than for previously studied language pairs, such that it is crucial to handle it.", "labels": [], "entities": []}, {"text": "Motivated by these considerations, we extend the LID task to the subword level (from (a) to (b) in).", "labels": [], "entities": []}, {"text": "We introduce anew CS dataset for Spanish-Wixarika (ES-WIX) and modify an existing German-Turkish (DE-TR) CS corpus (C \u00b8 etino\u02d8 glu, 2016) for our purposes.", "labels": [], "entities": [{"text": "German-Turkish (DE-TR) CS corpus (C \u00b8 etino\u02d8 glu, 2016)", "start_pos": 82, "end_pos": 137, "type": "DATASET", "confidence": 0.7602394302686055}]}, {"text": "We then intro-duce a segmental recurrent neural network (Seg-RNN) model for the task, which we compare against several strong baselines.", "labels": [], "entities": []}, {"text": "Our experiments show clear advantages of SegRNNs overall baselines for intra-word CS.", "labels": [], "entities": []}], "datasetContent": [{"text": "German-Turkish The German-Turkish Twitter Corpus (C \u00b8 etino\u02d8 glu and C \u00b8 \u00a8 oltekin, 2016) consists of 1029 tweets with 17K tokens.", "labels": [], "entities": [{"text": "German-Turkish Twitter Corpus", "start_pos": 19, "end_pos": 48, "type": "DATASET", "confidence": 0.6387022236982981}]}, {"text": "They are manually normalized, tokenized, and annotated with language IDs.", "labels": [], "entities": []}, {"text": "The language ID tag set consists of TR (Turkish), DE (German), LANG3 (other language), MIXED (intra-word CS), AMBIG (ambiguous language ID in context), and OTHER (punctuation, numbers, emoticns, symbols, etc.).", "labels": [], "entities": [{"text": "DE", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9861412048339844}, {"text": "LANG3", "start_pos": 63, "end_pos": 68, "type": "METRIC", "confidence": 0.9309309720993042}, {"text": "MIXED", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.9708685278892517}, {"text": "AMBIG", "start_pos": 110, "end_pos": 115, "type": "METRIC", "confidence": 0.9786834716796875}, {"text": "OTHER", "start_pos": 156, "end_pos": 161, "type": "METRIC", "confidence": 0.9515069723129272}]}, {"text": "Named entities are tagged with a combination of NE and their language ID: NE.TR, NE.DE, NE.LANG3.", "labels": [], "entities": []}, {"text": "In the original corpus, some Turkish and mixed words undergo a morphosyntactic split, 2 with splitting points not usually corresponding to language boundaries.", "labels": [], "entities": []}, {"text": "For the purpose of subwordlevel LID, these morphosyntactic splits are merged back into single words.", "labels": [], "entities": []}, {"text": "We then manually segment MIXED words at language boundaries, and replace their labels with more fine-grained language ID tags.", "labels": [], "entities": []}, {"text": "The total percentage of mixed words is 2.75%.", "labels": [], "entities": []}, {"text": "However, the percentage of sentences with mixed words is 15.66%.", "labels": [], "entities": []}, {"text": "The complete dataset statistics can be found in 50, 000 people in the Mexican states of Durango, Jalisco, Nayarit and Zacatecas () and is polysynthetic, with most morphemes ocurring in verbs.", "labels": [], "entities": []}, {"text": "The data is collected from public postings and comments from Facebook accounts.", "labels": [], "entities": []}, {"text": "To ensure the public characteristic of these posts, we manually collect data that is accessible publicly without being logged in to Facebook, to comply with the terms of use and privacy of the users.", "labels": [], "entities": []}, {"text": "These posts and comments are taken from 34 users: 14 women, 10 men, and the rest does not publically reveal their gender.", "labels": [], "entities": []}, {"text": "None of them have publically mentioned their age.", "labels": [], "entities": []}, {"text": "To get a dataset that focuses on the LID task, we only consider threads where the CS phenomenon appears.", "labels": [], "entities": []}, {"text": "We replace usernames with @username in order to preserve privacy.", "labels": [], "entities": []}, {"text": "Afterwards, we tokenize the text, segment mixed words, and add language IDs to words and segments.", "labels": [], "entities": []}, {"text": "The tag set is parallel to that of GermanTurkish: ES (Spanish), WIX (Wixarika), EN (English), AMBIG (ambiguous) OTHER (punctuation, numbers, emoticons, etc), NE.ES, NE.WIX and NE.EN (named entities).", "labels": [], "entities": [{"text": "AMBIG", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.9260977506637573}, {"text": "OTHER", "start_pos": 112, "end_pos": 117, "type": "METRIC", "confidence": 0.6984876394271851}]}, {"text": "Mixed words are segmented and each segment is labeled with its corresponding language (ES, WIX, EN).", "labels": [], "entities": []}, {"text": "Our main system is a neural architecture that jointly solves the segmentation and language identification tasks.", "labels": [], "entities": [{"text": "segmentation and language identification", "start_pos": 65, "end_pos": 105, "type": "TASK", "confidence": 0.6716899797320366}]}, {"text": "We compare it to multiple pipeline systems and another joint system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The frequency breakdown of tokens by lan- guage IDs in the German-Turkish dataset. All: the total  number of tokens per tag, %: the percentage of them  with respect to the total number of tokens; Unique: the  number of unique word types, and Unique %: the per- centage of them with respect the total number of unique  word types.", "labels": [], "entities": [{"text": "German-Turkish dataset", "start_pos": 69, "end_pos": 91, "type": "DATASET", "confidence": 0.7573099136352539}]}, {"text": " Table 3: Segmentation and LID test results for mixed words only.", "labels": [], "entities": [{"text": "LID", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9957675933837891}]}, {"text": " Table 4: Test set results for entire datasets.", "labels": [], "entities": []}]}