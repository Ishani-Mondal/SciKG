{"title": [{"text": "An Effective Label Noise Model for DNN Text Classification", "labels": [], "entities": [{"text": "DNN Text Classification", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.6821092764536539}]}], "abstractContent": [{"text": "Because large, human-annotated datasets suffer from labeling errors, it is crucial to be able to train deep neural networks in the presence of label noise.", "labels": [], "entities": []}, {"text": "While training image classification models with label noise have received much attention, training text classification models have not.", "labels": [], "entities": [{"text": "image classification", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7184570580720901}, {"text": "text classification", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.7566074430942535}]}, {"text": "In this paper, we propose an approach to training deep networks that is robust to label noise.", "labels": [], "entities": []}, {"text": "This approach introduces a non-linear processing layer (noise model) that models the statistics of the label noise into a convolutional neural network (CNN) architecture.", "labels": [], "entities": []}, {"text": "The noise model and the CNN weights are learned jointly from noisy training data, which prevents the model from overfitting to erroneous labels.", "labels": [], "entities": []}, {"text": "Through extensive experiments on several text classification datasets, we show that this approach enables the CNN to learn better sentence representations and is robust even to extreme label noise.", "labels": [], "entities": [{"text": "text classification", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7049694955348969}]}, {"text": "We find that proper initialization and regularization of this noise model is critical.", "labels": [], "entities": []}, {"text": "Further, by contrast to results focusing on large batch sizes for mitigating label noise for image classification, we find that altering the batch size does not have much effect on classification performance.", "labels": [], "entities": [{"text": "image classification", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.7322356104850769}]}], "introductionContent": [{"text": "Deep Neural Networks (DNNs) have led to significant advances in the fields of computer vision (, speech processing () and natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 122, "end_pos": 149, "type": "TASK", "confidence": 0.6458934247493744}]}, {"text": "To be effective, supervised DNNs rely on large amounts of carefully labeled training data.", "labels": [], "entities": []}, {"text": "However, it is not always realistic to assume that example labels are clean.", "labels": [], "entities": []}, {"text": "Humans make mistakes and, depending on the complexity of the task, there maybe disagreement even among expert labelers.", "labels": [], "entities": []}, {"text": "Further, samples drawn from the class conditional densities with overlapping supports gives rise to the label noise in training datasets.", "labels": [], "entities": []}, {"text": "To support noisy labels in data, we need new training methods that can be used to train DNNs directly from the corrupted labels to significantly reduce human labeling efforts.", "labels": [], "entities": []}, {"text": "perform an extensive study on the effect of label noise on classification performance of a classifier and find that noise in input features is less important than noise in training labels.", "labels": [], "entities": []}, {"text": "In this work, we add a noise model layer on top of our target model to account for label noise in the training set, following).", "labels": [], "entities": []}, {"text": "We provide extensive experiments on several text classification datasets with artificially injected label noise.", "labels": [], "entities": [{"text": "text classification", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7328178882598877}]}, {"text": "We study the effect of two different types of label noise; Uniform label flipping (Uni), where a clean label is swapped with another label sampled uniformly at random; and Random label flipping (Rand) where a clean label is swapped with another label from the given number of labels sampled randomly over a unit simplex.", "labels": [], "entities": [{"text": "Uniform label flipping", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.598396768172582}, {"text": "Random label flipping (Rand)", "start_pos": 172, "end_pos": 200, "type": "TASK", "confidence": 0.6582339058319727}]}, {"text": "We also study the effect of different initialization, regularization, and batch sizes when training with noisy labels.", "labels": [], "entities": []}, {"text": "We observe that proper initialization and regularization helps the noise model learn to be robust to even extreme amounts of noise.", "labels": [], "entities": []}, {"text": "Finally, we use low-dimensional projections of the features of the training examples to understand the effectiveness of the noise model.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the various approaches in literature to handle label noise.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the problem statement along with the proposed approach.", "labels": [], "entities": []}, {"text": "We describe the experimental setup and datasets in Section 4.", "labels": [], "entities": []}, {"text": "We empirically evaluate the performance of the proposed approach along with the discussion in Section 5 and finally conclude our work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we empirically evaluate the performance of the proposed approach for text classification and compare our results with the other methods.", "labels": [], "entities": [{"text": "text classification", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8426476418972015}]}, {"text": "Here, we describe all the text classification datasets used to evaluate the performance of the proposed approach.", "labels": [], "entities": [{"text": "text classification", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.6848885267972946}]}, {"text": "The base model architecture is the same for all datasets.", "labels": [], "entities": []}, {"text": "For each set, we tune the number of filter windows and filter lengths using the development set.", "labels": [], "entities": []}, {"text": "Along with the description, we also provide the hyper-parameters we selected for each.", "labels": [], "entities": []}, {"text": "For all the datasets, we use Rectified Linear Units (ReLU) and fix the base model architecture.", "labels": [], "entities": []}, {"text": "We use early stopping on dev.", "labels": [], "entities": []}, {"text": "sets for all the datasets.", "labels": [], "entities": []}, {"text": "We run all the experiments 5 times and report the average classification accuracy in.", "labels": [], "entities": [{"text": "classification", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.772562563419342}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.8830623030662537}]}, {"text": "We train all the networks endto-end via stochastic gradient descent over shuffled mini-batches with the Adadelta update rule except for the DBpedia, where we use SGD.", "labels": [], "entities": [{"text": "Adadelta update rule", "start_pos": 104, "end_pos": 124, "type": "METRIC", "confidence": 0.7837324539820353}, {"text": "DBpedia", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.982086181640625}]}, {"text": "In order to improve base model performance, we initialize the word embedding layer with the publicly available word2vec word vectors () for all the datasets except for DBpedia, where we use GloVe embeddings ().", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 168, "end_pos": 175, "type": "DATASET", "confidence": 0.9499927759170532}]}], "tableCaptions": [{"text": " Table 1: Summary of text classification datasets; K:  denotes the number of classes, L: represents the aver- age length of sentence, N: denotes the number of train- ing samples, T: represents the number of test samples,  Type: describes whether the dataset is balanced.", "labels": [], "entities": []}, {"text": " Table 2: Test performance for different text classification datasets", "labels": [], "entities": [{"text": "text classification", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7519542872905731}]}]}