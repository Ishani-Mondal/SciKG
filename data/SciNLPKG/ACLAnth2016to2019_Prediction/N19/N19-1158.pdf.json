{"title": [{"text": "Analyzing Bayesian Crosslingual Transfer in Topic Models", "labels": [], "entities": [{"text": "Analyzing Bayesian Crosslingual Transfer", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7089055180549622}]}], "abstractContent": [{"text": "We introduce a theoretical analysis of crosslin-gual transfer in probabilistic topic models.", "labels": [], "entities": [{"text": "crosslin-gual transfer", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7512461543083191}]}, {"text": "By formulating posterior inference through Gibbs sampling as a process of language transfer, we propose anew measure that quantifies the loss of knowledge across languages during this process.", "labels": [], "entities": [{"text": "language transfer", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7132846564054489}]}, {"text": "This measure enables us to derive a PAC-Bayesian bound that elucidates the factors affecting model quality, both during training and in downstream applications.", "labels": [], "entities": []}, {"text": "We provide experimental validation of the analysis on a diverse set of five languages, and discuss best practices for data collection and model design based on our analysis.", "labels": [], "entities": [{"text": "data collection", "start_pos": 118, "end_pos": 133, "type": "TASK", "confidence": 0.7374401688575745}]}], "introductionContent": [{"text": "Crosslingual learning is an important area of natural language processing that has driven applications including text mining in multiple languages (, cultural difference detection (, and various linguistic studies.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.7072365681330363}, {"text": "text mining", "start_pos": 113, "end_pos": 124, "type": "TASK", "confidence": 0.7545060217380524}, {"text": "cultural difference detection", "start_pos": 150, "end_pos": 179, "type": "TASK", "confidence": 0.6564589738845825}]}, {"text": "Crosslingual learning methods generally extend monolingual algorithms by using various multilingual resources.", "labels": [], "entities": []}, {"text": "In contrast to traditional high-dimensional vector space models, modern crosslingual models tend to rely on learning lowdimensional word representations that are more efficient and generalizable.", "labels": [], "entities": []}, {"text": "A popular approach to representation learning comes from the word embedding community, in which words are represented as vectors in an embedding space shared by multiple languages ().", "labels": [], "entities": [{"text": "representation learning", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.9360605776309967}]}, {"text": "Another direction is from the topic modeling community, where words are projected into a probabilistic topic space.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.7787036001682281}]}, {"text": "While formulated differently, both types of models apply the same principleslow-dimensional vectors exist in a shared crosslingual space, wherein vector representations of similar concepts across languages (e.g., \"dog\" and \"hund\") should be nearby in the shared space.", "labels": [], "entities": []}, {"text": "To enable crosslingual representation learning, knowledge is transferred from a source language to a target language, so that representations have similar values across languages.", "labels": [], "entities": [{"text": "crosslingual representation learning", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.7925208210945129}]}, {"text": "In this study, we will focus on probabilistic topic models, and \"knowledge\" refers to a word's probability distribution over topics.", "labels": [], "entities": []}, {"text": "Little is known about the characteristics of crosslingual knowledge transfer in topic models, and thus this paper provides an analysis, both theoretical and empirical, of crosslingual transfer in multilingual topic models.", "labels": [], "entities": [{"text": "crosslingual knowledge transfer", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.632730096578598}, {"text": "crosslingual transfer", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.7354834973812103}]}], "datasetContent": [{"text": "We experiment with five languages: Arabic (AR, Semitic), German (DE, Germanic), Spanish (ES, Romance), Russian (RU, Slavic), and Chinese (ZH, Sinitic).", "labels": [], "entities": []}, {"text": "In the first two experiments, we pair each with English (EN, Germanic) and train PLTM on each language pair individually.", "labels": [], "entities": [{"text": "PLTM", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9377580881118774}]}, {"text": "Training Data For each language pair, we use a subsample of 3,000 Wikipedia comparable documents, i.e., 6,000 documents in total.", "labels": [], "entities": []}, {"text": "We set K = 50, and train PLTM with default hyperparameters).", "labels": [], "entities": []}, {"text": "We run each experiment five times and average the results.", "labels": [], "entities": []}, {"text": "Test Data For experiments with document classification, we use Global Voices (GV) in all five language pairs as test sets.", "labels": [], "entities": [{"text": "document classification", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.7242750525474548}]}, {"text": "Each document in this dataset has a \"categories\" attribute that can be used as the document label.", "labels": [], "entities": []}, {"text": "In our classification experiments, we use culture, technology, and education as the labels to perform multiclass classification.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 102, "end_pos": 127, "type": "TASK", "confidence": 0.7281231582164764}]}, {"text": "Evaluation To evaluate topic qualities, we use Crosslingual Normalized Pointwise Mutual Information (, an intrinsic metric of crosslingual topic coherence.", "labels": [], "entities": []}, {"text": "For any bilingual word pair (w T , w S ), where Pr (w T , w S ) is the occurrence of w T and w S appearing in the same pair of comparable documents.", "labels": [], "entities": [{"text": "Pr", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.9911284446716309}]}, {"text": "We use 10,000 Wikipedia comparable document pairs outside PLTM training data for each language pair to calculate CNPMI scores.", "labels": [], "entities": [{"text": "PLTM training data", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.7664059599240621}]}, {"text": "All datasets are publicly available at http:// opus.nlpl.eu/ (Tiedemann, 2012).", "labels": [], "entities": []}, {"text": "Additional details of our datasets and experiment setup can be found in the appendix.", "labels": [], "entities": []}, {"text": "Topic coherence evaluation for multilingual topic models was proposed by, where a comparable corpus is used to calculate bilingual word pair co-occurrence and CNPMI scores.", "labels": [], "entities": []}, {"text": "We use a Wikipedia corpus to calculate this score, and the statistics are shown in.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 9, "end_pos": 25, "type": "DATASET", "confidence": 0.912115067243576}]}, {"text": "This Wikipedia corpus does not overlap with the training set.", "labels": [], "entities": []}], "tableCaptions": []}