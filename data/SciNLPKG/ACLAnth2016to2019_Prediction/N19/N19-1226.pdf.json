{"title": [{"text": "A Capsule Network-based Embedding Model for Knowledge Graph Completion and Search Personalization", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we introduce an embedding model, named CapsE, exploring a capsule network to model relationship triples (subject, relation , object).", "labels": [], "entities": []}, {"text": "Our CapsE represents each triple as a 3-column matrix where each column vector represents the embedding of an element in the triple.", "labels": [], "entities": []}, {"text": "This 3-column matrix is then fed to a convolution layer where multiple filters are operated to generate different feature maps.", "labels": [], "entities": []}, {"text": "These feature maps are reconstructed into corresponding capsules which are then routed to another capsule to produce a continuous vector.", "labels": [], "entities": []}, {"text": "The length of this vector is used to measure the plausibility score of the triple.", "labels": [], "entities": []}, {"text": "Our proposed CapsE obtains better performance than previous state-of-the-art embedding models for knowledge graph completion on two benchmark datasets WN18RR and FB15k-237, and outperforms strong search personalization baselines on SEARCH17.", "labels": [], "entities": [{"text": "knowledge graph completion", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.6558867394924164}, {"text": "WN18RR", "start_pos": 151, "end_pos": 157, "type": "DATASET", "confidence": 0.7165557146072388}, {"text": "FB15k-237", "start_pos": 162, "end_pos": 171, "type": "DATASET", "confidence": 0.8652358651161194}, {"text": "SEARCH17", "start_pos": 232, "end_pos": 240, "type": "DATASET", "confidence": 0.9462437629699707}]}], "introductionContent": [{"text": "Knowledge graphs (KGs) containing relationship triples (subject, relation, object), denoted as (s, r, o), are the useful resources for many NLP and especially information retrieval applications such as semantic search and question answering (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.9019352495670319}]}, {"text": "However, large knowledge graphs, even containing billions of triples, are still incomplete, i.e., missing a lot of valid triples).", "labels": [], "entities": []}, {"text": "Therefore, much research efforts have focused on the knowledge graph completion task which aims to predict missing triples in KGs, i.e., predicting whether a triple not in KGs is likely to be valid or not.", "labels": [], "entities": [{"text": "knowledge graph completion task", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.7613432109355927}]}, {"text": "To this end, many embedding models have been proposed to learn vector representations for entities (i.e., subject/head entity and object/tail entity) and relations in KGs, and obtained stateof-the-art results as summarized by and.", "labels": [], "entities": []}, {"text": "These embedding models score triples (s, r, o), such that valid triples have higher plausibility scores than invalid ones.", "labels": [], "entities": []}, {"text": "For example, in the context of KGs, the score for (Melbourne, cityOf, Australia) is higher than the score for (Melbourne, cityOf, United Kingdom).", "labels": [], "entities": []}, {"text": "Triple modeling is applied not only to the KG completion, but also for other tasks which can be formulated as a triple-based prediction problem.", "labels": [], "entities": [{"text": "Triple modeling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8037823140621185}, {"text": "KG completion", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.6604664027690887}]}, {"text": "An example is in search personalization, one would aim to tailor search results to each specific user based on the user's personal interests and preferences.", "labels": [], "entities": []}, {"text": "Here the triples can be formulated as (submitted query, user profile, returned document) and used to re-rank documents returned to a user given an input query, by employing an existing KG embedding method such as TransE (, as proposed by.", "labels": [], "entities": []}, {"text": "Previous studies have shown the effectiveness of modeling triple for either KG completion or search personalization.", "labels": [], "entities": [{"text": "KG completion", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.934090793132782}]}, {"text": "However, there has been no single study investigating the performance on both tasks.", "labels": [], "entities": []}, {"text": "Conventional embedding models, such as TransE (), DISTMULT ( and, use addition, subtraction or simple multiplication operators, thus only capture the linear relationships between entities.", "labels": [], "entities": []}, {"text": "Recent research has raised interest in applying deep neural networks to triplebased prediction problems.", "labels": [], "entities": [{"text": "triplebased prediction", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.6495879292488098}]}, {"text": "For example, proposed ConvKB-a convolutional neural network (CNN)-based model for KG completion and achieved state-of-the-art results.", "labels": [], "entities": [{"text": "KG completion", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.9034906923770905}]}, {"text": "Most of KG embedding models are constructed to modeling entries at the same dimension of the given triple, where presumably each dimension captures some relation-specific attribute of entities.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, however, none of the existing models has a \"deep\" architecture for modeling the entries in a triple at the same dimension.", "labels": [], "entities": []}, {"text": "introduced capsule networks (CapsNet) that employ capsules (i.e., each capsule is a group of neurons) to capture entities in images and then uses a routing process to specify connections from capsules in a layer to those in the next layer.", "labels": [], "entities": []}, {"text": "Hence CapsNet could encode the intrinsic spatial relationship between apart and a whole constituting viewpoint invariant knowledge that automatically generalizes to novel viewpoints.", "labels": [], "entities": []}, {"text": "Each capsule accounts for capturing variations of an objector object part in the image, which can be efficiently visualized.", "labels": [], "entities": []}, {"text": "Our high-level hypothesis is that embedding entries at the same dimension of the triple also have these variations, although it is not straightforward to be visually examined.", "labels": [], "entities": []}, {"text": "To that end, we introduce CapsE to explore a novel application of CapsNet on triple-based data for two problems: KG completion and search personalization.", "labels": [], "entities": [{"text": "KG completion", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.8514406383037567}]}, {"text": "Different from the traditional modeling design of CapsNet where capsules are constructed by splitting feature maps, we use capsules to model the entries at the same dimension in the entity and relation embeddings.", "labels": [], "entities": []}, {"text": "In our CapsE, v s , v rand v o are unique k-dimensional embeddings of s, rand o, respectively.", "labels": [], "entities": [{"text": "CapsE", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.8927579522132874}]}, {"text": "The embedding triple [v s , v r , v o ] of (s, r, o) is fed to the convolution layer where multiple filters of the same 1\u00d73 shape are repeatedly operated over every row of the matrix to produce k-dimensional feature maps.", "labels": [], "entities": []}, {"text": "Entries at the same dimension from all feature maps are then encapsulated into a capsule.", "labels": [], "entities": []}, {"text": "Thus, each capsule can encode many characteristics in the embedding triple to represent the entries at the corresponding dimension.", "labels": [], "entities": []}, {"text": "These capsules are then routed to another capsule which outputs a continuous vector whose length is used as a score for the triple.", "labels": [], "entities": []}, {"text": "Finally, this score is used to predict whether the triple (s, r, o) is valid or not.", "labels": [], "entities": []}, {"text": "In summary, our main contributions from this paper are as follows: \u2022 We propose an embedding model CapsE using the capsule network () for modeling relationship triples.", "labels": [], "entities": []}, {"text": "To our best of knowledge, our work is the first consideration of exploring the capsule network to knowledge graph completion and search personalization.", "labels": [], "entities": [{"text": "knowledge graph completion", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.6100597480932871}]}, {"text": "\u2022 We evaluate our CapsE for knowledge graph completion on two benchmark datasets WN18RR and.", "labels": [], "entities": [{"text": "CapsE", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9405452013015747}, {"text": "knowledge graph completion", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.7567297418912252}, {"text": "WN18RR", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.8897334337234497}]}, {"text": "CapsE obtains the best mean rank on WN18RR and the highest mean reciprocal rank and highest Hits@10 on FB15k-237.", "labels": [], "entities": [{"text": "CapsE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.5924108624458313}, {"text": "mean rank", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.936741441488266}, {"text": "WN18RR", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.9753119945526123}, {"text": "Hits@10", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9550416469573975}, {"text": "FB15k-237", "start_pos": 103, "end_pos": 112, "type": "DATASET", "confidence": 0.9849454164505005}]}, {"text": "\u2022 We restate the prospective strategy of expanding the triple embedding models to improve the ranking quality of the search personalization systems.", "labels": [], "entities": []}, {"text": "We adapt our model to search personalization and evaluate on SEARCH17 ( -a dataset of the web search query logs.", "labels": [], "entities": [{"text": "SEARCH17", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.8108214735984802}]}, {"text": "Experimental results show that our CapsE achieves the new state-of-the-art results with significant improvements over strong baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the knowledge graph completion task (, the goal is to predict a missing entity given a relation and another entity, i.e, inferring ahead entity s given (r, o) or inferring a tail entity o given (s, r).", "labels": [], "entities": [{"text": "knowledge graph completion task", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.7454113215208054}]}, {"text": "The results are calculated based on ranking the scores produced by the score function f on test triples.", "labels": [], "entities": []}, {"text": "Dataset: We use the SEARCH17 dataset ( of query logs of 106 users collected by a large-scale web search engine.", "labels": [], "entities": [{"text": "SEARCH17 dataset", "start_pos": 20, "end_pos": 36, "type": "DATASET", "confidence": 0.8333595395088196}]}, {"text": "A log entity consists of a user identifier, a query, top-10 ranked documents returned by the search engine and clicked documents along with the user's dwell time.", "labels": [], "entities": []}, {"text": "constructed short-term (session-based) user profiles and used the profiles to personalize the returned results.", "labels": [], "entities": []}, {"text": "They then employed the SAT criteria () to identify whether a returned document is relevant from the query logs as either a clicked document with a dwell time of at least 30 seconds or the last clicked document in a search session (i.e., a SAT click).", "labels": [], "entities": [{"text": "SAT", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9951642751693726}]}, {"text": "After that, they assigned a relevant label to a returned document if it is a SAT click and also assigned irrelevant labels to the remaining top-10 documents.", "labels": [], "entities": []}, {"text": "The rank position of the relevant labeled documents is used as the ground truth to evaluate the search performance before and after re-ranking.", "labels": [], "entities": []}, {"text": "The dataset was uniformly split into the training, validation and test sets.", "labels": [], "entities": []}, {"text": "This split is for the purpose of using historical data in the training set to predict new data in the test set (.", "labels": [], "entities": []}, {"text": "The training, validation and test sets consist of 5,658, 1,184 and 1,210 relevant (i.e., valid) triples; and 40,239, 7,882 and 8,540 irrelevant (i.e., invalid) triples, respectively.", "labels": [], "entities": []}, {"text": "Evaluation protocol: Our CapsE is used to rerank the original list of documents returned by a search engine as follows: (i) We train our model and employ the trained model to calculate the score for each (s, r, o) triple.", "labels": [], "entities": []}, {"text": "(ii) We then sort the scores in the descending order to obtain anew ranked list.", "labels": [], "entities": []}, {"text": "To evaluate the performance of our proposed model, we use two standard evaluation metrics: mean reciprocal rank (MRR) and Hits@1.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 91, "end_pos": 117, "type": "METRIC", "confidence": 0.9597726464271545}]}, {"text": "For each metric, the higher value indi-cates better ranking performance.", "labels": [], "entities": []}, {"text": "We compare CapsE with the following baselines using the same experimental setup: (1) SE: The original rank is returned by the search engine., we use TransE as a strong baseline model for the search personalization task.", "labels": [], "entities": [{"text": "SE", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9991210103034973}]}, {"text": "Previous work shows that the well-known embedding model TransE, despite its simplicity, obtains very competitive results for the knowledge graph completion (.", "labels": [], "entities": [{"text": "knowledge graph completion", "start_pos": 129, "end_pos": 155, "type": "TASK", "confidence": 0.5840201477209727}]}, {"text": "The CNNbased model ConvKB is the most closely related model to our CapsE.", "labels": [], "entities": [{"text": "CNNbased model ConvKB", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.7781797647476196}, {"text": "CapsE", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.8965362310409546}]}, {"text": "Embedding initialization: We follow to initialize user profile, query and document embeddings for the baselines TransE and ConvKB, and our CapsE.", "labels": [], "entities": [{"text": "Embedding initialization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7563263475894928}, {"text": "CapsE", "start_pos": 139, "end_pos": 144, "type": "DATASET", "confidence": 0.9179141521453857}]}, {"text": "We train a LDA topic model () with 200 topics only on the relevant documents (i.e., SAT clicks) extracted from the query logs.", "labels": [], "entities": []}, {"text": "We then use the trained LDA model to infer the probability distribution over topics for every returned document.", "labels": [], "entities": []}, {"text": "We use the topic proportion vector of each document as its document embedding (i.e. k = 200).", "labels": [], "entities": []}, {"text": "In particular, the z th element (z = 1, 2, ..., k) of the vector embedding for document d is: v d,z = P(z | d) where P(z | d) is the probability of the topic z given the document d.", "labels": [], "entities": []}, {"text": "We also represent each query by a probability distribution vector over topics.", "labels": [], "entities": []}, {"text": "Let D q = {d 1 , d 2 , ..., d n } be the set of top n ranked documents returned fora query q (here, n = 10).", "labels": [], "entities": []}, {"text": "The z th element of the vector embedding for query q is defined as in (: , where \u03bb i = \u03b4 i\u22121 n j=1 \u03b4 j\u22121 is the exponential decay function of i which is the rank of d i in D q . And \u03b4 is the decay hyper-parameter (0 < \u03b4 < 1).", "labels": [], "entities": []}, {"text": "Following, we use \u03b4 = 0.8.", "labels": [], "entities": [{"text": "\u03b4", "start_pos": 18, "end_pos": 19, "type": "METRIC", "confidence": 0.9684915542602539}]}, {"text": "Note that if we learn query and document embeddings during training, the models will overfit to the data and will notwork for new queries and documents.", "labels": [], "entities": []}, {"text": "Thus, after the initialization process, we fix (i.e., not updating) query and document embeddings during training for TransE, Consearch engine, so Hits@10 scores are same for all models.", "labels": [], "entities": []}, {"text": "In addition, as mentioned by, the more recently clicked document expresses more about the user current search interest.", "labels": [], "entities": []}, {"text": "Hence, we make use of the user clicked documents in the training set with the temporal weighting scheme proposed by to initialize user profile embeddings for the three embedding models.", "labels": [], "entities": []}, {"text": "Hyper-parameter tuning: For our CapsE model, we set batch size to 128, and also the number of neurons within the capsule in the second capsule layer to 10 (d = 10).", "labels": [], "entities": []}, {"text": "The number of iterations in the routing algorithm is set to 1 (m = 1).", "labels": [], "entities": [{"text": "routing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9615486264228821}]}, {"text": "For the training model, we use the Adam optimizer with the initial learning rate \u2208 {5e \u22126 , 1e \u22125 , 5e \u22125 , 1e \u22124 , 5e \u22124 }.", "labels": [], "entities": []}, {"text": "We also use ReLU as the activation function g.", "labels": [], "entities": [{"text": "ReLU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9663577675819397}]}, {"text": "We select the number of filters N \u2208 {50, 100, 200, 400, 500}.", "labels": [], "entities": []}, {"text": "We run the model up to 200 epochs and perform a grid search to choose optimal hyper-parameters on the validation set.", "labels": [], "entities": []}, {"text": "We monitor the MRR score after each training epoch and obtain the highest MRR score on the validation set when using N = 400 and the initial learning rate at 5e \u22125 . We employ the TransE and ConvKB implementations provided by and and then follow their training protocols to tune hyper-parameters for TransE and ConvKB, respectively.", "labels": [], "entities": [{"text": "MRR", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.5296562314033508}, {"text": "MRR", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.8440961241722107}]}, {"text": "We also monitor the MRR score after each training epoch and attain the highest MRR score on the validation set when using margin = 5, l 1 -norm and SGD learning rate at 5e \u22123 for TransE; and N = 500 and the Adam initial learning rate at 5e \u22124 for ConvKB.", "labels": [], "entities": [{"text": "MRR", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.7509642839431763}, {"text": "MRR", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9530643224716187}, {"text": "margin", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9891253709793091}, {"text": "SGD learning rate", "start_pos": 148, "end_pos": 165, "type": "METRIC", "confidence": 0.7909114162127177}, {"text": "ConvKB", "start_pos": 247, "end_pos": 253, "type": "DATASET", "confidence": 0.9131942391395569}]}, {"text": "presents the experimental results of the baselines and our model.", "labels": [], "entities": []}, {"text": "Embedding models TranE, ConvKB and CapsE produce better ranking performances than traditional learning-to-rank search personalization models CI and SP.", "labels": [], "entities": []}, {"text": "This indicates a prospective strategy of expanding the triple embedding models to improve the ranking quality of the search personalization systems.", "labels": [], "entities": []}, {"text": "In particular, our MRR and Hits@1 scores are higher than those of TransE (with relative improvements of 14.5% and 22% over TransE, respectively).", "labels": [], "entities": [{"text": "MRR", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9820048809051514}, {"text": "Hits@1 scores", "start_pos": 27, "end_pos": 40, "type": "METRIC", "confidence": 0.9392806738615036}, {"text": "TransE", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.7663630247116089}, {"text": "TransE", "start_pos": 123, "end_pos": 129, "type": "DATASET", "confidence": 0.842621922492981}]}, {"text": "Specifically, our CapsE achieves the highest performances in both MRR and Hits@1 (our improvements overall five baselines are statistically   significant with p < 0.05 using the paired t-test).", "labels": [], "entities": [{"text": "CapsE", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.8510146737098694}, {"text": "MRR", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9504151344299316}, {"text": "Hits@1", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.8790461421012878}]}], "tableCaptions": [{"text": " Table 1: Statistics of the experimental datasets. #E is  the number of entities. #R is the number of relations.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results on the WN18RR and FB15k-237 test sets. Hits@10 (H@10) is reported in %.  Results of DISTMULT, ComplEx and ConvE are taken from Dettmers et al. (2018). Results of TransE on FB15k- 237 are taken from Nguyen et al. (2018). Our CapsE Hits@1 scores are 33.7% on WN18RR and 48.9% on  FB15k-237. Formulas of MRR and Hits@1 show a strong correlation, so using Hits@1 does not really reveal any  additional information for this task. The best score is in bold, while the second best score is in underline. denotes  our new results for TransE and ConvKB, which are better than those published by Nguyen et al. (2018).", "labels": [], "entities": [{"text": "WN18RR", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.9369050860404968}, {"text": "FB15k-237 test sets", "start_pos": 49, "end_pos": 68, "type": "DATASET", "confidence": 0.9536488652229309}, {"text": "DISTMULT", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.8390486836433411}, {"text": "FB15k- 237", "start_pos": 203, "end_pos": 213, "type": "DATASET", "confidence": 0.8921554883321127}, {"text": "WN18RR", "start_pos": 288, "end_pos": 294, "type": "DATASET", "confidence": 0.9622899889945984}, {"text": "FB15k-237", "start_pos": 309, "end_pos": 318, "type": "DATASET", "confidence": 0.9934758543968201}]}, {"text": " Table 3: Hits@10 on the WN18RR validation set with  N = 50 and the initial learning rate at 1e \u22125 w.r.t each  number of iterations in the routing algorithm m and  each 10 training epochs.", "labels": [], "entities": [{"text": "WN18RR validation set", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.9681004087130228}]}, {"text": " Table 4: Experimental results on the test set. [] de- notes the results reported in (Vu et al., 2017). Hits@1  (H@1) is reported in %. In information retrieval,  Hits@1 is also referred to as P@1. The subscripts de- note the relative improvement over our TransE results.", "labels": [], "entities": [{"text": "Hits@1  (H@1)", "start_pos": 104, "end_pos": 117, "type": "METRIC", "confidence": 0.7795362621545792}]}]}