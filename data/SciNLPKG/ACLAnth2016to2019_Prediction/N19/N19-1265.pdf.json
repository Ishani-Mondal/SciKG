{"title": [{"text": "Beyond Task Success: A Closer Look at Jointly Learning to See, Ask, and GuessWhat", "labels": [], "entities": [{"text": "GuessWhat", "start_pos": 72, "end_pos": 81, "type": "TASK", "confidence": 0.6137330532073975}]}], "abstractContent": [{"text": "We propose a grounded dialogue state encoder which addresses a foundational issue on how to integrate visual grounding with dialogue system components.", "labels": [], "entities": []}, {"text": "As a test-bed, we focus on the GuessWhat?!", "labels": [], "entities": [{"text": "GuessWhat?!", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.7533585826555887}]}, {"text": "game, a two-player game where the goal is to identify an object in a complex visual scene by asking a sequence of yes/no questions.", "labels": [], "entities": []}, {"text": "Our visually-grounded encoder leverages synergies between guessing and asking questions, as it is trained jointly using multi-task learning.", "labels": [], "entities": []}, {"text": "We further enrich our model via a cooperative learning regime.", "labels": [], "entities": []}, {"text": "We show that the introduction of both the joint architecture and cooperative learning lead to accuracy improvements over the baseline system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9987360835075378}]}, {"text": "We compare our approach to an alternative system which extends the baseline with reinforcement learning.", "labels": [], "entities": []}, {"text": "Our in-depth analysis shows that the linguistic skills of the two models differ dramatically, despite approaching comparable performance levels.", "labels": [], "entities": []}, {"text": "This points at the importance of analyzing the linguistic output of competing systems beyond numeric comparison solely based on task success.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the last few decades, substantial progress has been made in developing dialogue systems that address the abilities that need to be put to work during conversations: Understanding and generating natural language, planning actions, and tracking the information exchanged by the dialogue participants.", "labels": [], "entities": []}, {"text": "The latter is particularly critical since, for communication to be effective, participants need to represent the state of the dialogue and the common ground established through the conversation.", "labels": [], "entities": []}, {"text": "In addition to the challenges above, dialogue is often situated in a perceptual environment.", "labels": [], "entities": []}, {"text": "In Equal contribution by R. Shekhar and A. Venkatesh.", "labels": [], "entities": []}, {"text": "this study, we develop a dialogue agent that builds a representation of the context and the dialogue state by integrating information from both the visual and linguistic modalities.", "labels": [], "entities": []}, {"text": "We take the GuessWhat?!", "labels": [], "entities": [{"text": "GuessWhat", "start_pos": 12, "end_pos": 21, "type": "DATASET", "confidence": 0.9008030891418457}]}, {"text": "game (de  as our testbed, a two-player game where a Questioner faces the task of identifying a target object in a visual scene by asking a series of yes/no questions to an Oracle.", "labels": [], "entities": [{"text": "Questioner faces the task of identifying a target object in a visual scene by asking a series of yes/no questions to an Oracle", "start_pos": 52, "end_pos": 178, "type": "Description", "confidence": 0.7196913480758667}]}, {"text": "We model the agent in the Questioner's role.", "labels": [], "entities": []}, {"text": "To model the Questioner, previous work relies on two independent models to learn to ask questions and to guess the target object, each equipped with its own encoder (de.", "labels": [], "entities": []}, {"text": "We propose an end-to-end architecture with a single visually-grounded dialogue state encoder (cf. Figure 1).", "labels": [], "entities": []}, {"text": "Our system is trained jointly in a supervised learning setup, extended with a cooperative learning (CL) regime: By letting the model play the game with self-generated dialogues, the components of the Questioner agent learn to better perform the overall Questioner's task in a cooperative manner.", "labels": [], "entities": []}, {"text": "have explored the use of CL to train two visual dialogue agents that receive joint rewards when they play a game successfully.", "labels": [], "entities": []}, {"text": "To our knowledge, ours is the first ap-proach where cooperative learning is applied to the internal components of a grounded conversational agent.", "labels": [], "entities": []}, {"text": "Our cooperative learning regime can be seen as an interesting alternative to reinforcement learning (RL)-which was first applied to GuessWhat?! by -because it is entirely differentiable and computationally less expensive to train than RL.", "labels": [], "entities": [{"text": "GuessWhat", "start_pos": 132, "end_pos": 141, "type": "DATASET", "confidence": 0.8943079113960266}]}, {"text": "Little is known on how this learning approach compares to RL not only regarding task success, but also in terms of the quality of the linguistic output, a gap we seek to fill in this paper.", "labels": [], "entities": [{"text": "RL", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.8767467737197876}]}, {"text": "In particular, our contributions are: 2 \u2022 The introduction of a single visuallygrounded dialogue state encoder jointly trained with the guesser and question generator modules to address a foundational question of how to integrate visual grounding with dialogue system components; this yields up to 9% improvement on task success.", "labels": [], "entities": []}, {"text": "\u2022 The effectiveness of cooperative learning, which yields an additional increase of 8.7% accuracy, while being easier to train than RL.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9977951049804688}, {"text": "RL", "start_pos": 132, "end_pos": 134, "type": "METRIC", "confidence": 0.7599155306816101}]}, {"text": "\u2022 A first in-depth study to compare cooperative learning to a state-of-the-art RL system.", "labels": [], "entities": []}, {"text": "Our study shows that the linguistic skills of the models differ dramatically, despite approaching comparable task success levels.", "labels": [], "entities": []}, {"text": "This underlines the importance of linguistic analysis to complement solely numeric evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the same train (70%), validation (15%), and test (15%) splits as de . The test set contains new images not seen during training.", "labels": [], "entities": []}, {"text": "We use two experimental setups for the number of questions to be asked by the question generator, motivated by prior work: 5 questions (5Q) following de , and 8 questions (8Q) as in . As noted in Section 3, on average, there are 5.2 questions per dialogue in the GuessWhat?!", "labels": [], "entities": [{"text": "GuessWhat?!", "start_pos": 263, "end_pos": 274, "type": "DATASET", "confidence": 0.890703280766805}]}, {"text": "For evaluation, we report task success in terms of accuracy ( . To neutralize the effect of random sampling in training CL, we trained the model 3 times.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9993639588356018}]}, {"text": "RL is tested 3 times with sampling.", "labels": [], "entities": [{"text": "RL", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.4377603828907013}]}, {"text": "We report means and standard deviation (for some tables these are provided in the supplementary material; see footnote 2).: Test set accuracy for each model (for setups with 5 and 8 questions).", "labels": [], "entities": [{"text": "standard deviation", "start_pos": 20, "end_pos": 38, "type": "METRIC", "confidence": 0.9489694237709045}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9660745859146118}]}, {"text": "GDSE-SL is our grounded supervised learning system, GDSE-CL the cooperative learning setup, and RL the results we obtain with the reinforcement learning system by . and 9%).", "labels": [], "entities": [{"text": "GDSE-SL", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9106119275093079}, {"text": "RL", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.9950453042984009}]}, {"text": "To evaluate the impact of the multitask learning aspect, we did an ablation study and used the encoder-decoder architecture to train the QGen and Guesser modules independently.", "labels": [], "entities": []}, {"text": "With such a decoupled training we obtain lower results: 44% and 43.7% accuracy for 5Q and 8Q, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9996592998504639}]}, {"text": "Hence, the multi-task component brings an increase of up to 6% over the baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test set accuracy for each model (for setups  with 5 and 8 questions). GDSE-SL is our grounded  supervised learning system, GDSE-CL the cooperative  learning setup, and RL the results we obtain with the  reinforcement learning system by", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9717440605163574}, {"text": "RL", "start_pos": 179, "end_pos": 181, "type": "METRIC", "confidence": 0.9885343909263611}]}, {"text": " Table 2: Statistics of the linguistic output of all models  with the 8Q setting and of humans (H) in all test games.", "labels": [], "entities": []}, {"text": " Table 3: Percentage of questions per question type in  all the test set games played by humans (H) and the  models with the 8Q setting, and KL divergence from  human distribution of fine-grained question types.", "labels": [], "entities": []}, {"text": " Table 4: Proportion of question type shift vs. no type  shift in consecutive questions Q t \u2192 Q t+1 where Q t  has received a Yes answer.", "labels": [], "entities": []}]}