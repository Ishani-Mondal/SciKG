{"title": [{"text": "Bilingual-GAN: A Step Towards Parallel Text Generation", "labels": [], "entities": []}], "abstractContent": [{"text": "Latent space based GAN methods and attention based sequence to sequence models have achieved impressive results in text generation and unsupervised machine translation respectively.", "labels": [], "entities": [{"text": "GAN", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9458572268486023}, {"text": "text generation", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.8217308521270752}, {"text": "machine translation", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.7274722754955292}]}, {"text": "Leveraging the two domains, we propose an adversarial latent space based model capable of generating parallel sentences in two languages concurrently and translating bidi-rectionally.", "labels": [], "entities": []}, {"text": "The bilingual generation goal is achieved by sampling from the latent space that is shared between both languages.", "labels": [], "entities": [{"text": "bilingual generation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7065856158733368}]}, {"text": "First two denoising autoencoders are trained, with shared encoders and back-translation to enforce a shared latent state between the two languages.", "labels": [], "entities": []}, {"text": "The decoder is shared for the two translation directions.", "labels": [], "entities": []}, {"text": "Next, a GAN is trained to generate synthetic 'code' mimicking the languages' shared latent space.", "labels": [], "entities": []}, {"text": "This code is then fed into the decoder to generate text in either language.", "labels": [], "entities": []}, {"text": "We perform our experiments on Europarl and Multi30k datasets, on the English-French language pair, and document our performance using both supervised and unsupervised machine translation.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.9887946844100952}, {"text": "Multi30k datasets", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.8685615360736847}]}], "introductionContent": [{"text": "Many people in the world are fluent in at least two languages, yet most computer applications and services are designed fora monolingual audience.", "labels": [], "entities": []}, {"text": "Fully bilingual people do not think about a concept in one language and translate it to the other language but are adept at generating words in either language.", "labels": [], "entities": []}, {"text": "Inspired by this bilingual paradigm, the success of attention based neural machine translation (NMT) and the potential of Generative Adversarial Networks (GANs) for text generation we propose Bilingual-GAN, an agent capable of deriving a shared latent space between two languages, and then generating from that space in either language.", "labels": [], "entities": [{"text": "attention based neural machine translation (NMT)", "start_pos": 52, "end_pos": 100, "type": "TASK", "confidence": 0.7511158958077431}, {"text": "text generation", "start_pos": 165, "end_pos": 180, "type": "TASK", "confidence": 0.7516206502914429}]}, {"text": "Attention based NMT ( has achieved state of the art results on many different language pairs and is used in production translation systems (.", "labels": [], "entities": [{"text": "production translation", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.7447159886360168}]}, {"text": "These systems generally consist of an encoder-decoder based sequence to sequence model whereat least the decoder is auto-regressive.", "labels": [], "entities": []}, {"text": "Generally, they require massive amount of parallel data but recent methods that use shared autoencoders ( and cross-lingual word embeddings () have shown promise even without using parallel data.", "labels": [], "entities": []}, {"text": "Deep learning based text generation systems can be divided into three categories: Maximum Likelihood Estimation (MLE)-based, GAN-based and reinforcement learning (RL)-based.", "labels": [], "entities": [{"text": "Deep learning based text generation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6398456931114197}]}, {"text": "MLEbased methods) model the text as an auto-regressive generative process using Recurrent Neural Networks (RNNs) but generally suffer from exposure bias (.", "labels": [], "entities": []}, {"text": "A number of solutions have been proposed including scheduled sampling (), Gibbs sampling ( and Professor forcing (.", "labels": [], "entities": []}, {"text": "Recently, researchers have used GANs) as a potentially powerful generative model for text (, inspired by their great success in the field of image generation.", "labels": [], "entities": [{"text": "image generation", "start_pos": 141, "end_pos": 157, "type": "TASK", "confidence": 0.742701530456543}]}, {"text": "Text generation using GANs is challenging due to the discrete nature of text.", "labels": [], "entities": [{"text": "Text generation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8327935039997101}]}, {"text": "The discretized text output is not differentiable and if the softmax output is used instead it is trivial for the discriminator to distinguish between that and real text.", "labels": [], "entities": []}, {"text": "One of the proposed solutions ( ) is to generate the latent space of the autoencoder instead of generating the sentence and has shown impressive results.", "labels": [], "entities": []}, {"text": "We use the concept of shared encoders and multi-lingual embeddings to learn the aligned latent representation of two languages and a GAN that can generate this latent space.", "labels": [], "entities": []}, {"text": "Particularly, our contributions are as follows: \u2022 We introduce a GAN model, Bilingual-GAN, which can generate parallel sentences in two languages concurrently.", "labels": [], "entities": []}, {"text": "\u2022 Bilingual-GAN can match the latent distribution of the encoder of an attention based NMT model.", "labels": [], "entities": []}, {"text": "\u2022 We explore the ability to generate parallel sentences when using only monolingual corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the different experiments we did, on both translation and bilingual text generation, and the datasets we worked on.", "labels": [], "entities": [{"text": "translation and bilingual text generation", "start_pos": 64, "end_pos": 105, "type": "TASK", "confidence": 0.6110875010490417}]}, {"text": "The Europarl and the Multi30k datasets have been used for our experimentation.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9926734566688538}, {"text": "Multi30k datasets", "start_pos": 21, "end_pos": 38, "type": "DATASET", "confidence": 0.9705694913864136}]}, {"text": "The Europarl dataset is part of the WMT 2014 parallel corpora ( As preprocessing stepson the Europarl dataset, we removed sentences longer than 20 words and those with a ratio of number of words between translations is bigger than 1.5.", "labels": [], "entities": [{"text": "Europarl dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9804748594760895}, {"text": "WMT 2014 parallel corpora", "start_pos": 36, "end_pos": 61, "type": "DATASET", "confidence": 0.7802774012088776}, {"text": "Europarl dataset", "start_pos": 93, "end_pos": 109, "type": "DATASET", "confidence": 0.9510135352611542}]}, {"text": "Then, we tokenize the sentence using the Moses tokenizer (.", "labels": [], "entities": []}, {"text": "For the Multi30k dataset, we use the supplied tokenized version of the dataset with no further processing.", "labels": [], "entities": [{"text": "Multi30k dataset", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.971879243850708}]}, {"text": "For the BPE experiments, we use the sentencepiece subword tokenizer by Google 1 . Consequentially, the decoder also predicts subword tokens.", "labels": [], "entities": []}, {"text": "This results in a common embeddings table for both languages since English and French share the same subwords.", "labels": [], "entities": []}, {"text": "The BPE was trained on the training corpora that we created.", "labels": [], "entities": [{"text": "BPE", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.45996004343032837}]}, {"text": "For the training, validation and test splits, we used 200k, after filtering, randomly chosen sentences from the Europarl dataset for training and 40k sentences for testing.", "labels": [], "entities": [{"text": "validation", "start_pos": 18, "end_pos": 28, "type": "TASK", "confidence": 0.9496559500694275}, {"text": "Europarl dataset", "start_pos": 112, "end_pos": 128, "type": "DATASET", "confidence": 0.9967712163925171}]}, {"text": "When creating the splits for unsupervised training, we make sure that the sentences taken in one language have no translations in the other language's training set by randomly choosing different sentences for each of them with no overlap.", "labels": [], "entities": []}, {"text": "For the validation set in that case, we chose 80k sentences.", "labels": [], "entities": []}, {"text": "In the supervised case, we randomly choose the same sentences in both languages with a validation set of 40k.", "labels": [], "entities": []}, {"text": "For the Multi30k dataset, we use 12 850 and 449 sentences for training and validation respectively for each language for the unsupervised case and the whole provided split of 29k and 1014 sentences for training and validation respectively in the supervised case.", "labels": [], "entities": [{"text": "Multi30k dataset", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.9596910774707794}]}, {"text": "In both cases, the test set is the provided 1k sentences Flickr 2017 one.", "labels": [], "entities": [{"text": "Flickr 2017", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.9219626188278198}]}, {"text": "For the hyperparameter search phase, we chose a vocabulary size of 8k for the Europarl, the most common words appearing in the training corpora and for the final experiments with the best hyperparameters, we worked with a vocabulary size of 15k.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9877626895904541}]}, {"text": "For Multi30k, we used the 6800 most common words 1 https://github.com/google/sentencepiece as vocabulary.", "labels": [], "entities": []}, {"text": "Corpus-level BLEU We use the BLEU-N scores to evaluate the fluency of the generated sentences according to, where p n is the probability of n-gram and w n = 1 n . The results is described in.", "labels": [], "entities": [{"text": "Corpus-level", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.7107133865356445}, {"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.8356232643127441}, {"text": "BLEU-N", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9955289959907532}]}, {"text": "Here, we set BP to 1 as there is no reference length like in machine translation.", "labels": [], "entities": [{"text": "BP", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9933291673660278}, {"text": "machine translation", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.6947287917137146}]}, {"text": "For the evaluations, we generated 40 000 sentences for the model trained on Europarl and 1 000 on the model trained on Multi30k.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9952442049980164}, {"text": "Multi30k", "start_pos": 119, "end_pos": 127, "type": "DATASET", "confidence": 0.9589316248893738}]}, {"text": "Perplexity is also used to evaluate the fluency of the generated sentences.", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9299414753913879}]}, {"text": "For the perplexity evaluations, we generated 100 000 and 10 000 sentences for the Europarl and the Multi30k datasets respectively.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9931924939155579}, {"text": "Multi30k datasets", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.966867059469223}]}, {"text": "The forward and reverse perplexities of the LMs trained with maximum sentence length of 20 and 15 using the Europarl and he Multi30k datasets respectively are described in.", "labels": [], "entities": [{"text": "Europarl and he Multi30k datasets", "start_pos": 108, "end_pos": 141, "type": "DATASET", "confidence": 0.7420566320419312}]}, {"text": "The forward perplexities (F-PPL) are calculated by training an RNN language model (RNNLM) () on real training data and evaluated on the generated samples.", "labels": [], "entities": [{"text": "F-PPL", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.8812233209609985}]}, {"text": "This measure describe the fluency of the synthetic samples.", "labels": [], "entities": []}, {"text": "We also calculated the reverse perplexities (R-PPL) by training an RNNLM on the synthetic samples and evaluated on the real test data.", "labels": [], "entities": [{"text": "R-PPL", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.9316673278808594}]}, {"text": "The results are illustrated in.", "labels": [], "entities": []}, {"text": "The subjective judgments of the generated sentences of the models trained using the Europarl and the Multi30k datasets with maximum sentence length of size 20 and 15 is reported in.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.9951997995376587}, {"text": "Multi30k datasets", "start_pos": 101, "end_pos": 118, "type": "DATASET", "confidence": 0.9453251659870148}]}, {"text": "As we do not have ground truth for our translation we measure parallelism between our generated sentences only based on human evaluation.", "labels": [], "entities": []}, {"text": "We used 25 random generated sentences from each model and give them to a group of 4 bilingual people.", "labels": [], "entities": []}, {"text": "We asked them to first rate the sentences based on a 5-point scale according to their fluency.", "labels": [], "entities": []}, {"text": "The judges are asked to score 1 which corresponds to gibberish, 3 corresponds to understandable but ungrammatical, and 5 correspond to naturally constructed and understandable sentences (.", "labels": [], "entities": []}, {"text": "Then, we ask ask them to measure parallelism of the generated samples assuming that the sentences are translations of each other.", "labels": [], "entities": []}, {"text": "The scale is between 1 and 5 again with 1 corresponding to no parallelism, 3 to some parallelism and 5 to fully parallel sentences.", "labels": [], "entities": []}, {"text": "From, we can note that on text quality human evaluation results corresponds to our other quantitative metrics.", "labels": [], "entities": []}, {"text": "Our generated sentences show some parallelism even in the unsupervised scenario.", "labels": [], "entities": []}, {"text": "Some example generated sentences are shown in.", "labels": [], "entities": []}, {"text": "As expected, sentences generated by the supervised models exhibit more parallelism compared to ones generated by unsupervised models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Here, we set  BP to 1 as there is no reference length like in ma- chine translation. For the evaluations, we gener- ated 40 000 sentences for the model trained on Eu- roparl and 1 000 on the model trained on Multi30k.", "labels": [], "entities": [{"text": "BP", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9987720847129822}, {"text": "Multi30k", "start_pos": 218, "end_pos": 226, "type": "DATASET", "confidence": 0.950531005859375}]}, {"text": " Table 1: Notations that are used for this experiment", "labels": [], "entities": []}, {"text": " Table 2: The BLEU-4 scores for French to English and English to French translation. The *'ed experiments use  a vocabulary size of 15k words. The Multi30k experiments use the best hyperparameters found when training on  the Europarl dataset and a vocabulary size of 6800 words.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9992972612380981}, {"text": "English to French translation", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.7114936113357544}, {"text": "Europarl dataset", "start_pos": 225, "end_pos": 241, "type": "DATASET", "confidence": 0.9957855045795441}]}, {"text": " Table 3: Corpus-level BLEU scores for Text Generation on Europarl and Multi30k Datasets", "labels": [], "entities": [{"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.8849274516105652}, {"text": "Text Generation", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7616886496543884}, {"text": "Europarl", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9916338920593262}, {"text": "Multi30k Datasets", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.7949163317680359}]}, {"text": " Table 6. As  we do not have ground truth for our translation we  measure parallelism between our generated sen- tences only based on human evaluation. We used  25 random generated sentences from each model  and give them to a group of 4 bilingual people. We", "labels": [], "entities": []}, {"text": " Table 4: Forward (F) and Reverse (R) perplexity (PPL) results for the Europarl and Multi30k datasets using  synthetic sentences of maximum length 20 and 15 respectively. F-PPL: Perplexity of a language model trained  on real data and evaluated on synthetic samples. R-PPL: Perplexity of a language model trained on the synthetic  samples from Bilingual-GAN and evaluated on the real test data.", "labels": [], "entities": [{"text": "Forward (F)", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9067475646734238}, {"text": "Reverse (R) perplexity (PPL)", "start_pos": 26, "end_pos": 54, "type": "METRIC", "confidence": 0.9136628732085228}, {"text": "Europarl", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9940047860145569}, {"text": "Multi30k datasets", "start_pos": 84, "end_pos": 101, "type": "DATASET", "confidence": 0.8246558904647827}, {"text": "F-PPL", "start_pos": 171, "end_pos": 176, "type": "METRIC", "confidence": 0.9145742654800415}, {"text": "Bilingual-GAN", "start_pos": 344, "end_pos": 357, "type": "DATASET", "confidence": 0.9430038928985596}]}, {"text": " Table 5: Examples of aligned generated sentences", "labels": [], "entities": []}, {"text": " Table 6: Human evaluation on the generated sentences  by Bilingual-GAN using the Europarl and the Multi30k  dataset.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9951508045196533}, {"text": "Multi30k  dataset", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.9329857528209686}]}]}