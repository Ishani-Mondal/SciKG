{"title": [{"text": "Viable Dependency Parsing as Sequence Labeling", "labels": [], "entities": [{"text": "Viable Dependency Parsing as Sequence Labeling", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.6532623022794724}]}], "abstractContent": [{"text": "We recast dependency parsing as a sequence labeling problem, exploring several encodings of dependency trees as labels.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8335038423538208}]}, {"text": "While dependency parsing by means of sequence labeling had been attempted in existing work, results suggested that the technique was impractical.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.871628075838089}]}, {"text": "We show instead that with a conventional BIL-STM-based model it is possible to obtain fast and accurate parsers.", "labels": [], "entities": [{"text": "BIL-STM-based", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.8712199330329895}]}, {"text": "These parsers are conceptually simple, not needing traditional parsing algorithms or auxiliary structures.", "labels": [], "entities": []}, {"text": "However , experiments on the PTB and a sample of UD treebanks show that they provide a good speed-accuracy tradeoff, with results competitive with more complex approaches.", "labels": [], "entities": [{"text": "PTB", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.8781107068061829}, {"text": "UD treebanks", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.8211237490177155}]}], "introductionContent": [{"text": "The application of neural architectures to syntactic parsing, and especially the ability of long shortterm memories (LSTMs) to obtain context-aware feature representations (Hochreiter and Schmidhuber, 1997), has made it possible to parse natural language with conceptually simpler models than before.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7320208251476288}, {"text": "parse natural language", "start_pos": 232, "end_pos": 254, "type": "TASK", "confidence": 0.8695526917775472}]}, {"text": "For example, in dependency parsing, the rich feature models with dozens of features used in transition-based approaches (Zhang and Nivre, 2011) can be simplified when using feedforward neural networks, and even more with BiLSTM architectures, wherein fact two positional features can suffice (.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8303237557411194}]}, {"text": "Similarly, in graph-based approaches, have shown that an arc-factored model can achieve state-of-the-art accuracy, without the need for the higher-order features used in systems like ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9981400966644287}]}, {"text": "In the same way, neural feature representations have made it possible to relax the need for structured representations.", "labels": [], "entities": []}, {"text": "This is the case of sequenceto-sequence models that translate sentences into linearized trees, which were first applied to constituent () and later to dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 151, "end_pos": 169, "type": "TASK", "confidence": 0.7746132016181946}]}, {"text": "Recently, have shown that sequence labeling models, where each word is associated with a label (thus simpler than sequence to sequence, where the mapping from input to output is not one to one) can learn constituent parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.6734672486782074}]}, {"text": "Contribution We show that sequence labeling is useful for dependency parsing, in contrast to previous work.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7332203984260559}, {"text": "dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9076075851917267}]}, {"text": "We explore four different encodings to represent dependency trees fora sentence of length n as a set of n labels associated with its words.", "labels": [], "entities": []}, {"text": "We then use these representations to perform dependency parsing with an off-the-shelf sequence labeling model.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8461491465568542}]}, {"text": "The results show that we produce models with an excellent speed-accuracy tradeoff, without requiring any explicit parsing algorithm or auxiliary structure (e.g. stack or buffer).", "labels": [], "entities": []}, {"text": "The source code is available at https://github.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the English Penn Treebank (PTB) (  We first examine the four encodings on the PTB dev set.", "labels": [], "entities": [{"text": "English Penn Treebank (PTB)", "start_pos": 11, "end_pos": 38, "type": "DATASET", "confidence": 0.8684546152750651}, {"text": "PTB dev set", "start_pos": 85, "end_pos": 96, "type": "DATASET", "confidence": 0.9476321140925089}]}, {"text": "shows the results and also compares them against, who proposed seq2seq and sequence labeling models that use a relative positional encoding.", "labels": [], "entities": []}, {"text": "As the relative PoS-based encoding and bracketing-based encoding provide the best results, we will conduct the rest of our experiments with these two encodings.", "labels": [], "entities": []}, {"text": "Furthermore, we perform a small hyperparameter search involving encoding, number of hidden layers, their dimension and presence of character embeddings, as these parameters influence speed and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 193, "end_pos": 201, "type": "METRIC", "confidence": 0.9957109689712524}]}, {"text": "From now on, we write P z x,y fora PoS-based encoding model and B z x,y fora bracketing-based encoding  model, where z indicates whether character representation was used in the model, x the number of BiLSTM layers, and y the word hidden vector dimension.", "labels": [], "entities": []}, {"text": "We take as starting points the hyperparameters used by the BIST parser, as it uses a BiLSTM architecture analogous to ours, with the difference that it employs a transition-based algorithm that uses a stack data structure instead of plain sequence labeling without explicit representation of structure, and (2) the best hyperparameters used by for constituent parsing as sequence labeling, as it is an analogous task fora different parsing formalism.", "labels": [], "entities": [{"text": "BIST", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.899325430393219}, {"text": "constituent parsing", "start_pos": 348, "end_pos": 367, "type": "TASK", "confidence": 0.6934403330087662}]}, {"text": "From there, we explore different combinations of parameters and evaluate 20 models on the PTB development set, with respect to accuracy (UAS) and speed (sentences/second on a single CPU core), obtaining the Pareto front in.", "labels": [], "entities": [{"text": "PTB development set", "start_pos": 90, "end_pos": 109, "type": "DATASET", "confidence": 0.9515121579170227}, {"text": "accuracy (UAS)", "start_pos": 127, "end_pos": 141, "type": "METRIC", "confidence": 0.8112404495477676}, {"text": "speed", "start_pos": 146, "end_pos": 151, "type": "METRIC", "confidence": 0.9415889978408813}]}, {"text": "The two starting models based on previous literature (P 2,250 and PC 2,800 , respectively) happen to be in the Pareto front, confirming that they are reasonable hyperparameter choices also for this setting.", "labels": [], "entities": [{"text": "Pareto front", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.8658129572868347}]}, {"text": "In addition, we select two more models from the Pareto front (models PC 2,400 and B 2,250 ) for our test set experiments on PTB, as they also provide a good balance between speed and accuracy.", "labels": [], "entities": [{"text": "Pareto front", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.8531343042850494}, {"text": "PTB", "start_pos": 124, "end_pos": 127, "type": "DATASET", "confidence": 0.9111393690109253}, {"text": "speed", "start_pos": 173, "end_pos": 178, "type": "METRIC", "confidence": 0.9720759391784668}, {"text": "accuracy", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.9950788021087646}]}, {"text": "compares the chosen models, on the PTB test set, against state-of-the-art mod- In Hebrew, UPoS and XPoS tags are the same.", "labels": [], "entities": [{"text": "PTB test set", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.9735307693481445}]}, {"text": "Kazakh is missing a development set.", "labels": [], "entities": []}, {"text": "The scores are based on the test set.", "labels": [], "entities": []}, {"text": "Tamil was run on gold segmented and tokenized inputs, as there is no pretrained UDpipe model.", "labels": [], "entities": [{"text": "Tamil", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9233716726303101}]}, {"text": "We did not use pretrained word embeddings either.: Performance of the PC 2,800 model with UPoSand XPoS-based encoding for each language on the dev set.", "labels": [], "entities": []}, {"text": "# UPoS/XPoS represents the number of distinct UPoS/XPoS tags in the training set for each language. els.", "labels": [], "entities": []}, {"text": "Contrary to previous dependency-parsingas-sequence-labeling attempts, we are competitive and provide a good speed-accuracy tradeoff.", "labels": [], "entities": []}, {"text": "For instance, the PC 2,800 model runs faster than the BIST parser while being almost as accurate (-0.18 LAS).", "labels": [], "entities": [{"text": "BIST", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.6522414684295654}, {"text": "accurate", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9870657920837402}, {"text": "LAS", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9727721214294434}]}, {"text": "This comes in spite of its simplicity.", "labels": [], "entities": []}, {"text": "While our BiL-STM architecture is similar to that of BIST, the sequence labeling approach does not need a stack, a specific transition system or a dynamic oracle.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.6341194063425064}]}, {"text": "Using the BIST hyperparameters for our model (P 2,250 ) yields further increases in speed, at some cost to accuracy: 3.34x faster and -0.04 LAS score than the graph-based model, and 3.51x faster and: Impact of the PTB data size available for parsers during training on the results from the test set.", "labels": [], "entities": [{"text": "BIST hyperparameters", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.8915829062461853}, {"text": "speed", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.9915960431098938}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9994101524353027}, {"text": "LAS score", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9826316833496094}, {"text": "PTB data size", "start_pos": 214, "end_pos": 227, "type": "DATASET", "confidence": 0.7640110651652018}]}], "tableCaptions": [{"text": " Table 1: Performance of our encodings on the PTB dev  set with hyperparameters from G\u00f3mez-Rodr\u00edguez and  Vilares (2018). We compare against previous sequence  labeling and seq2seq models with more complex archi- tectures, beam search and subroot decomposition.", "labels": [], "entities": [{"text": "PTB dev  set", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.969898502031962}]}, {"text": " Table 2: Comparison of models on the PTB test set.  KG refers to Kiperwasser and Goldberg (2016), CM to  Chen and Manning (2014) and DM to Dozat and Man- ning (2017). indicates the speed is taken from their  paper.", "labels": [], "entities": [{"text": "PTB test set", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.9683599670728048}, {"text": "KG", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9591061472892761}, {"text": "DM", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.921119213104248}, {"text": "speed", "start_pos": 182, "end_pos": 187, "type": "METRIC", "confidence": 0.9722620844841003}]}, {"text": " Table 3: Performance of the P C  2,800 model with UPoS- and XPoS-based encoding for each language on the dev  set. # UPoS/XPoS represents the number of distinct  UPoS/XPoS tags in the training set for each language.", "labels": [], "entities": []}, {"text": " Table 4: Comparison on UD-CoNLL18 test sets.", "labels": [], "entities": [{"text": "UD-CoNLL18 test sets", "start_pos": 24, "end_pos": 44, "type": "DATASET", "confidence": 0.9556814630826315}]}]}