{"title": [{"text": "Fact Discovery from Knowledge Base via Facet Decomposition", "labels": [], "entities": [{"text": "Fact Discovery", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8953716456890106}]}], "abstractContent": [{"text": "During the past few decades, knowledge bases (KBs) have experienced rapid growth.", "labels": [], "entities": []}, {"text": "Nevertheless , most KBs still suffer from serious in-completion.", "labels": [], "entities": [{"text": "KBs", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.8022857904434204}]}, {"text": "Researchers proposed many tasks such as knowledge base completion and relation prediction to help build the representation of KBs.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.6972309152285258}, {"text": "relation prediction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8771069943904877}]}, {"text": "However, there are some issues unsettled towards enriching the KBs.", "labels": [], "entities": []}, {"text": "Knowledge base completion and relation prediction assume that we know two elements of the fact triples and we are going to predict the missing one.", "labels": [], "entities": [{"text": "Knowledge base completion", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6711671948432922}, {"text": "relation prediction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.9327583014965057}]}, {"text": "This assumption is too restricted in practice and prevents it from discovering new facts directly.", "labels": [], "entities": []}, {"text": "To address this issue, we propose anew task, namely, fact discovery from knowledge base.", "labels": [], "entities": [{"text": "fact discovery", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7994492053985596}]}, {"text": "This task only requires that we know the head entity and the goal is to discover facts associated with the head entity.", "labels": [], "entities": []}, {"text": "To tackle this new problem, we propose a novel framework that decomposes the discovery problem into several facet discovery components.", "labels": [], "entities": []}, {"text": "We also propose a novel auto-encoder based facet component to estimate some facets of the fact.", "labels": [], "entities": []}, {"text": "Besides, we propose a feedback learning component to share the information between each facet.", "labels": [], "entities": []}, {"text": "We evaluate our framework using a benchmark dataset and the experimental results show that our framework achieves promising results.", "labels": [], "entities": []}, {"text": "We also conduct extensive analysis of our framework in discovering different kinds of facts.", "labels": [], "entities": []}, {"text": "The source code of this paper can be obtained from https: //github.com/thunlp/FFD.", "labels": [], "entities": [{"text": "FFD", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.7448143362998962}]}], "introductionContent": [{"text": "Recent years have witnessed the emergence and growth of many large-scale knowledge bases (KBs) such as Freebase (), DBpedia (), YAGO and Wikidata (Vrande\u010di\u00b4Vrande\u010di\u00b4c and) to store facts of the real world.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 116, "end_pos": 123, "type": "DATASET", "confidence": 0.9244845509529114}]}, {"text": "Most KBs typically organize the complex structured information about facts in the form of triples (head entity, relation, tail entity), e.g., (Bill Gates, CEOof, Microsoft Inc.).", "labels": [], "entities": []}, {"text": "These KBs have been widely used in many AI and NLP tasks such as text analysis, question answering (, and information retrieval ().", "labels": [], "entities": [{"text": "text analysis", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.8402635157108307}, {"text": "question answering", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.9308721125125885}, {"text": "information retrieval", "start_pos": 106, "end_pos": 127, "type": "TASK", "confidence": 0.8020950555801392}]}, {"text": "The construction of these KBs is always an ongoing process due to the endless growth of realworld facts.", "labels": [], "entities": []}, {"text": "Hence, many tasks such as knowledge base completion (KBC) and relation prediction (RP) are proposed to enrich KBs.", "labels": [], "entities": [{"text": "knowledge base completion (KBC)", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.7405224144458771}, {"text": "relation prediction (RP)", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.8450492858886719}]}, {"text": "The KBC task usually assumes that one entity and the relation rare given, and another entity is missing and required to be predicted.", "labels": [], "entities": []}, {"text": "In general, we wish to predict the missing entity in (h, r, ?) or (?, r, t), where hand t denote ahead and tail entity respectively.", "labels": [], "entities": []}, {"text": "Similarly, the RP task predicts the missing relation given the head and tail entities and their evidence sentences, i.e. filling (h, ?, t).", "labels": [], "entities": [{"text": "RP task", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.8259954452514648}]}, {"text": "Nevertheless, the assumption of knowing two parts of the triple is too strong and is usually restricted in practice.", "labels": [], "entities": []}, {"text": "In many cases, we only know the entity of in-terest, and are required to predict both its attributive relations and the corresponding entities.", "labels": [], "entities": []}, {"text": "As shown in, the task is to predict the fact triples when given only the head entity, i.e. filling (h, ?, ?).", "labels": [], "entities": []}, {"text": "Since any entity can serve as the head entity for identifying its possible fact triples, this task should be more practical for real-world settings.", "labels": [], "entities": [{"text": "identifying its possible fact triples", "start_pos": 50, "end_pos": 87, "type": "TASK", "confidence": 0.6434782981872559}]}, {"text": "This task is non-trivial since less information is provided for prediction.", "labels": [], "entities": [{"text": "prediction", "start_pos": 64, "end_pos": 74, "type": "TASK", "confidence": 0.9567341804504395}]}, {"text": "We name the task as Fact Discovery from Knowledge Base (FDKB).", "labels": [], "entities": [{"text": "Fact Discovery from Knowledge Base (FDKB)", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.7193452827632427}]}, {"text": "Some existing methods such as knowledge base representation (KBR) can be applied to tackle the FDKB task with simple modifications.", "labels": [], "entities": [{"text": "knowledge base representation (KBR)", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.7055411090453466}, {"text": "FDKB task", "start_pos": 95, "end_pos": 104, "type": "TASK", "confidence": 0.5418626964092255}]}, {"text": "KBR models typically embed the semantics of both entities and relations into low-dimensional semantic space, i.e., embeddings.", "labels": [], "entities": []}, {"text": "For example,) learns low-dimensional and real-valued embeddings for both entities and relations by regarding the relation of each triple fact as a translation from its head entity to the tail entity.", "labels": [], "entities": []}, {"text": "TransE can thus compute the valid score for each triple by measuring how well the relation can play a translation between the head and tail entities.", "labels": [], "entities": []}, {"text": "Many methods have been proposed to extend TransE to deal with various characteristics of).", "labels": [], "entities": []}, {"text": "To solve the FDKB task using KBR, one feasible way is to exhaustively calculate the scores of all (r, t) combinations for the given head entity h.", "labels": [], "entities": [{"text": "FDKB task", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.5942424833774567}]}, {"text": "Afterwards, the highly-scored facts are returned as results.", "labels": [], "entities": []}, {"text": "However, this idea has some drawbacks: (1) It takes all relations to calculate ranking scores for each head entity, ignoring the nature of the head entity.", "labels": [], "entities": []}, {"text": "The combination of all possible relations and tail entities will lead to huge amount of computations.", "labels": [], "entities": []}, {"text": "(2) A large set of candidate triples immerses the correct triples into a lot of noisy triples.", "labels": [], "entities": []}, {"text": "Although the probability of invalid facts getting a high score is small, with the large size of the candidate set, the total number of invalid facts with high score is non-negligible.", "labels": [], "entities": []}, {"text": "To address the above issues, we propose anew framework named as fact facet decomposition (FFD).", "labels": [], "entities": [{"text": "fact facet decomposition (FFD)", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.7291622310876846}]}, {"text": "The framework follows human being's common practice to identify unknown facts: One typically firstly investigates which relation that ahead may have, and then predicts the tail entity based on the predicted relation.", "labels": [], "entities": []}, {"text": "This procedure actually utilizes information from several perspectives.", "labels": [], "entities": []}, {"text": "Similarly, FFD decomposes fact discovery into several facets, i.e., head-relation facet, tailrelation facet, and tail inference facet, and model each facet respectively.", "labels": [], "entities": [{"text": "FFD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9652851819992065}]}, {"text": "The candidate fact is considered to be correct when all of the facets are trustworthy.", "labels": [], "entities": []}, {"text": "We propose a novel auto-encoder based entity-relation component to discover the relatedness between entities and relations.", "labels": [], "entities": []}, {"text": "Besides, we also propose a feedback learning component to share the information between each facet.", "labels": [], "entities": []}, {"text": "We have conducted extensive experiments using a benchmark dataset to show that our framework achieves promising results.", "labels": [], "entities": []}, {"text": "We also conduct an extensive analysis of the framework in discovering different kinds of facts.", "labels": [], "entities": []}, {"text": "The contributions of this paper can be summarized as follows: (1) We introduce anew task of fact discovery from knowledge base, which is more practical.", "labels": [], "entities": [{"text": "fact discovery", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.7235768586397171}]}, {"text": "(2) We propose anew framework based on the facet decomposition which achieves promising results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our framework by re-splitting a widely used dataset FB15k (, which is sampled from Freebase.", "labels": [], "entities": [{"text": "FB15k", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.9324122667312622}, {"text": "Freebase", "start_pos": 95, "end_pos": 103, "type": "DATASET", "confidence": 0.953731894493103}]}, {"text": "It contains 1, 345 relations and 14, 951 entities.", "labels": [], "entities": []}, {"text": "In FB15k, some of the testing set's head entities do not appear in the training set as head.", "labels": [], "entities": [{"text": "FB15k", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9411147832870483}]}, {"text": "To evaluate our framework, we construct the new dataset.", "labels": [], "entities": []}, {"text": "We re-split FB15k into training (T train ), validation (T valid ) and testing (T test ) set, and make sure that there is no overlap between the three sets.", "labels": [], "entities": [{"text": "FB15k", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.8318006992340088}]}, {"text": "For all head entities in H, a relation ratio R% is used to assign the facts into training and testing set.", "labels": [], "entities": []}, {"text": "R% relations of ahead entity are in the training set while the other 1 \u2212 R% are in the testing set.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9228233098983765}]}, {"text": "In order to evaluate the task, we require that the head entities in H is the same as the testing head entity and is a subset of the training headset, i.e. H = {h|(h, r, t) \u2208 T test , \u2203r, t \u2208 E} \u2282 {h|(h, r, t) \u2208 T train , \u2203r, t \u2208 E}.", "labels": [], "entities": []}, {"text": "We set R = 50.", "labels": [], "entities": [{"text": "R", "start_pos": 7, "end_pos": 8, "type": "METRIC", "confidence": 0.9694086313247681}]}, {"text": "After the splitting, the training, testing and validation set size is 509, 339, 41, 861 and 41, 013 respectively.", "labels": [], "entities": []}, {"text": "There are 2,000 head entities in the testing set.", "labels": [], "entities": []}, {"text": "Therefore, we predict the corresponding relation and tail entity with respect to these 2,000 head entities.", "labels": [], "entities": []}, {"text": "In MF models, only relation-tail pairs that occur more than 3 times in the training set are considered (24,615 pairs in total).", "labels": [], "entities": [{"text": "MF", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9682530164718628}]}, {"text": "For each head entity, we set \u00af K = 50.", "labels": [], "entities": []}, {"text": "In KBR+, we also set \u00af K = 50.", "labels": [], "entities": []}, {"text": "For our framework, we set n h = n t = 30, n f = 10, \u00af K = 50, \u03bb 1 = 1.0, \u03bb 2 = 1.0, \u03bb 3 = 0.5.", "labels": [], "entities": []}, {"text": "The auto-encoder iterates for 1,000 epochs and the learning rate for Adam is 0.005.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 51, "end_pos": 64, "type": "METRIC", "confidence": 0.9521609246730804}]}, {"text": "For the feedback learning component, we set n f b = 20, 000.", "labels": [], "entities": []}, {"text": "With this setting, each model returns 100,000 facts.", "labels": [], "entities": []}, {"text": "We use four evaluation metrics, including precision, recall MAP, and F1 in relation prediction.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9996321201324463}, {"text": "recall MAP", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.8406353890895844}, {"text": "F1", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.999804675579071}, {"text": "relation prediction", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.9217633306980133}]}, {"text": "Precision is defined as the ratio of the true positive candidates' count over the number of all the retrieved candidates' count.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9800875782966614}]}, {"text": "Recall is defined as the ratio of the true positive candidates' count overall the positive facts' count in the testing set.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9793843626976013}]}, {"text": "MAP () is a common evaluation method in information retrieval tasks.", "labels": [], "entities": [{"text": "information retrieval tasks", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.8495563069979349}]}, {"text": "F1 is defined as the harmonic mean of the precision and recall.", "labels": [], "entities": [{"text": "F1", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9958589673042297}, {"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9995341300964355}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9971574544906616}]}, {"text": "The experimental result is shown in: Results of our framework and comparison models.", "labels": [], "entities": []}, {"text": "1. FFD based model outperforms other models in all metrics.", "labels": [], "entities": []}, {"text": "It illustrates the advantage of our decomposition design.", "labels": [], "entities": []}, {"text": "Moreover, in FFD, using Analogy to predict c(h, r, t) outperforms Complex.", "labels": [], "entities": [{"text": "FFD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9260660409927368}]}, {"text": "One reason is that the discovery algorithm harness the relatively large parameter space of Analogy and avoids some occasionally emerging wrong facts; 2.", "labels": [], "entities": []}, {"text": "The relation of the head entity can be correctly predicted.", "labels": [], "entities": []}, {"text": "This is because, in training, we remove some relations and the autoencoder is trained to learn to recover the missing relations based on the remaining relations.", "labels": [], "entities": []}, {"text": "3. The MF based models (i.e. SVD and NMF) perform not as good as KBR+ models and FFD.", "labels": [], "entities": []}, {"text": "The reason is partially due to the sparsity problem in MF models.", "labels": [], "entities": [{"text": "MF", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9500183463096619}]}, {"text": "A lot of relation- tail pairs have not been used as the feature and thus cannot be predicted; 4.", "labels": [], "entities": []}, {"text": "Different from the traditional KBC task, Complex performs slightly better than Analogy.", "labels": [], "entities": []}, {"text": "One reason is that Analogy's constraint is looser than Complex.", "labels": [], "entities": []}, {"text": "Therefore, it may easily predict wrong facts due to error propagation; 5.", "labels": [], "entities": []}, {"text": "The ablation experiment shows that the feedback learning can improve the performance effectively.", "labels": [], "entities": []}, {"text": "To illustrate the capability of handling different kinds of relations, we plot the accuracy with respect to different kinds of relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9994742274284363}]}, {"text": "We use heads per tail (hpt) and tails per head (tph) index to represent the difficulty of each relation.", "labels": [], "entities": []}, {"text": "If the relation's index is high, it means that each head of the relation may have more tails or vice versa.", "labels": [], "entities": []}, {"text": "These relations are more difficult to predict.", "labels": [], "entities": []}, {"text": "This is the similar problem of 1-N, N-1 and N-N relation in KBC task.", "labels": [], "entities": []}, {"text": "The plot is shown in.", "labels": [], "entities": []}, {"text": "From the figure, we can observe that: 1.", "labels": [], "entities": []}, {"text": "FFD can be adapted to all kinds of relations with different hpt and tph; 2.", "labels": [], "entities": [{"text": "FFD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6815828084945679}]}, {"text": "MF, KBR+, FFD models can handle relations with relatively high hpt but fail with high tph.", "labels": [], "entities": [{"text": "MF", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8108744621276855}, {"text": "FFD", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.898647665977478}]}, {"text": "This is because our goal is to predict relation and tail based on the head.", "labels": [], "entities": []}, {"text": "Therefore, the choice maybe harder to make with high tph; 3.", "labels": [], "entities": []}, {"text": "As the hpt grows, the precision of SVD model also grows.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9997078776359558}]}, {"text": "The reason is that as hpt grows, the sparsity problem is alleviated.", "labels": [], "entities": []}, {"text": "Therefore, the performance of SVD grows.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. From  the experiment result, we observe that:", "labels": [], "entities": []}, {"text": " Table 1: Results of our framework and comparison  models.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of dataset with different relation ra- tio.", "labels": [], "entities": []}, {"text": " Table 3: Result of dataset in different relation ratio.", "labels": [], "entities": [{"text": "Result", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8828705549240112}]}]}