{"title": [{"text": "Frowning Frodo, Wincing Leia, and a Seriously Great Friendship: Learning to Classify Emotional Relationships of Fictional Characters", "labels": [], "entities": [{"text": "Classify Emotional Relationships of Fictional Characters", "start_pos": 76, "end_pos": 132, "type": "TASK", "confidence": 0.7359989186127981}]}], "abstractContent": [{"text": "The development of a fictional plot is centered around characters who closely interact with each other forming dynamic social networks.", "labels": [], "entities": []}, {"text": "In literature analysis, such networks have mostly been analyzed without particular relation types or focusing on roles which the characters take with respect to each other.", "labels": [], "entities": []}, {"text": "We argue that an important aspect for the analysis of stories and their development is the emotion between characters.", "labels": [], "entities": [{"text": "analysis of stories", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.8602568109830221}]}, {"text": "In this paper, we combine these aspects into a unified framework to classify emotional relationships of fictional characters.", "labels": [], "entities": []}, {"text": "We formalize it as anew task and describe the annotation of a corpus, based on fan-fiction short stories.", "labels": [], "entities": []}, {"text": "The extraction pipeline which we propose consists of character identification (which we treat as given by an oracle here) and the relation classification.", "labels": [], "entities": [{"text": "character identification", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.8910750448703766}, {"text": "relation classification", "start_pos": 130, "end_pos": 153, "type": "TASK", "confidence": 0.8824011981487274}]}, {"text": "For the latter, we provide results using several approaches previously proposed for relation identification with neural methods.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.9586460292339325}]}, {"text": "The best result of 0.45 F 1 is achieved with a GRU with character position indicators on the task of predicting undirected emotion relations in the associated social network graph.", "labels": [], "entities": [{"text": "GRU", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.8056992888450623}]}], "introductionContent": [{"text": "Every fictional story is centered around characters in conflict which interact, grow closer or apart, as each of them has ambitions and concrete goals.", "labels": [], "entities": []}, {"text": "Previous work on computational literary studies includes two tasks, namely social network analysis and sentiment/emotion analysis, both contributing to a computational understanding of narrative structures.", "labels": [], "entities": [{"text": "social network analysis", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.6652655998865763}, {"text": "sentiment/emotion analysis", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.6883453726768494}]}, {"text": "We argue that joining these two tasks leverages simplifications that each approach makes when considered independently.", "labels": [], "entities": []}, {"text": "We are not aware of any such attempt and therefore propose the task of emotional character network extraction from fictional texts, in which, given a text, a network is to be generated, whose nodes correspond to characters and edges to emotions between characters.", "labels": [], "entities": [{"text": "emotional character network extraction from fictional texts", "start_pos": 71, "end_pos": 130, "type": "TASK", "confidence": 0.7651140008653913}]}, {"text": "One of the characters is part of a trigger/cause for the emotion experienced by the other.", "labels": [], "entities": []}, {"text": "depicts two examples for emotional character interactions at the text level.", "labels": [], "entities": []}, {"text": "Such relation extraction is the basis for generating social networks of emotional interactions.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.7398131042718887}]}, {"text": "Dynamic social networks of characters are analyzed in previous work with different goals, e.g., to test the differences in interactions between various adaptations of a book (; to understand the correlation between dialogue and setting (; to test whether social networks derived from Shakespeare's plays can be explained by a general sociological model; in the task of narrative generation; to better understand the nature of character interactions.", "labels": [], "entities": [{"text": "narrative generation", "start_pos": 369, "end_pos": 389, "type": "TASK", "confidence": 0.7204208821058273}]}, {"text": "Further, previous work analyses personality traits of characters (mostly) independently of each other).", "labels": [], "entities": []}, {"text": "Emotion analysis in literature has focused on the development of emotions overtime, abstracting away who experiences an emotion.", "labels": [], "entities": [{"text": "Emotion analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9411413371562958}]}, {"text": "Fewer works have ad- dressed the annotation of emotion causes, e.g.,,,, and . To the best of our knowledge, there is no previous research that deals with emotional relationships of literary characters.", "labels": [], "entities": []}, {"text": "The works that are conceptually the closest to our paper are and, who use a more general set of relationship categories.", "labels": [], "entities": []}, {"text": "Most approaches to emotion classification from text build on the classes proposed by and.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.8130542039871216}]}, {"text": "Here, we use a discrete emotion categorization scheme based on fundamental emotions as proposed by Plutchik.", "labels": [], "entities": []}, {"text": "This model has previously been used in computational analysis of literature.", "labels": [], "entities": []}, {"text": "We refer the reader to social psychology literature for more details on the emotional relationship between people.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are (1) to propose the new task of emotional relationship classification of fictional characters, (2) to provide a fan-fiction short story corpus annotated with characters and their emotional relationships, and (3) to provide results for relation extraction models for the task.", "labels": [], "entities": [{"text": "emotional relationship classification of fictional characters", "start_pos": 72, "end_pos": 133, "type": "TASK", "confidence": 0.7855422596136729}, {"text": "relation extraction", "start_pos": 275, "end_pos": 294, "type": "TASK", "confidence": 0.7763242721557617}]}, {"text": "We evaluate our models on the textual and the social network graph level and show that a neural model with positional indicators for character roles performs the best.", "labels": [], "entities": []}, {"text": "An additional analysis shows that the task of character relationship detection leads to higher performance scores for polarity detection than for more fine-grained emotion classes.", "labels": [], "entities": [{"text": "character relationship detection", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.7685842315355936}, {"text": "polarity detection", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.7094005048274994}]}, {"text": "Differences between models are minimal when the task is cast as a polarity classification but are striking for emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.7101535499095917}]}, {"text": "This work has potential to support a literary scholar in analyzing differences and commonalities across texts.", "labels": [], "entities": []}, {"text": "As an example, one may consider Goethe's The Sorrows of Young Werther (Goethe, 1774), a book that gave rise to a plethora of imitations by other writers, who attempted to depict a similar love triangle between main characters found in the original book.", "labels": [], "entities": [{"text": "Goethe's The Sorrows of Young Werther (Goethe, 1774)", "start_pos": 32, "end_pos": 84, "type": "TASK", "confidence": 0.5983596220612526}]}, {"text": "The results of our study can potentially be used to compare the derivative works with the original (see also).", "labels": [], "entities": []}], "datasetContent": [{"text": "In the classification experiments, we compare the performance of our models on different label sets.", "labels": [], "entities": []}, {"text": "Namely, we compare the complete emotion set with 8 classes to a 5 class scenario where we join anger and disgust, trust and joy, as well as anticipation and surprise (based on preliminary experiments and inspection of confusion matrices).", "labels": [], "entities": [{"text": "anticipation", "start_pos": 140, "end_pos": 152, "type": "METRIC", "confidence": 0.9505031704902649}]}, {"text": "The 2-class scenario consists of positive (anticipation, joy, trust, surprise) and negative relations (anger, fear, sadness, disgust).", "labels": [], "entities": []}, {"text": "For each set of classes, we consider a setting where directed relations are predicted with one where the direction is ignored.", "labels": [], "entities": []}, {"text": "Therefore, in the directed prediction scenario, each emotion constitutes two classes to be predicted for both possible directions (therefore, 16, 10, and 4 labels exist).", "labels": [], "entities": [{"text": "directed prediction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7347411513328552}]}, {"text": "The evaluation is performed with precision, recall and F 1 in a cross-story validation setting, in which each story is used as one separate test/validation source.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9996352195739746}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9993950128555298}, {"text": "F 1", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.984459787607193}]}, {"text": "For model selection and meta-parameter optimization, we use 50 % randomly sampled annotations from this respective test/validation instance as a validation set and the remainder as test data.", "labels": [], "entities": [{"text": "model selection", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7533493340015411}, {"text": "meta-parameter optimization", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.732852429151535}]}, {"text": "Further, we evaluate on three different levels of granularity: Given two character mentions, in the instance-level evaluation, we only accept the prediction to be correct if exactly the same mention has the according emotion annotation.", "labels": [], "entities": []}, {"text": "We then aggregate the different true positive, false positive and false negative values across all stories before averaging to an aggregated score (similar to microaveraging).", "labels": [], "entities": []}, {"text": "On the story-level, we also accept a prediction to be a true positive the same way, but first calculate the result P/R/F 1 for the whole story before averaging (similar to macro-averaging).", "labels": [], "entities": [{"text": "P/R/F 1", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.7164605756600698}]}, {"text": "On the graph-level, we accept a prediction fora character pair to be correct without considering the exact position.", "labels": [], "entities": []}, {"text": "shows the results (precision and recall shown in supplementary material) on development data and independent test data for the best models.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9993240833282471}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9978228807449341}]}, {"text": "The GRU+MRole model achieves the highest performance with improvement over BOW-RF on the instance and story levels, and shows a clear improvement over the GRU+NoInd.", "labels": [], "entities": [{"text": "GRU+MRole", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.5510072310765585}, {"text": "BOW-RF", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.924191415309906}]}, {"text": "model in the directed 8-class setting.", "labels": [], "entities": []}, {"text": "GRU+Role achieves the highest performance on the graph level in the directed 8-class setting.", "labels": [], "entities": []}, {"text": "In the undirected prediction setting, all models perform better in the 5-class experiment and 2-class experiment than in 8-class experiment.", "labels": [], "entities": []}, {"text": "This is not always the case for the directed prediction, where some models perform better in 8-class experiment (GRU+NoInd., GRU+Entity, BOW-RF).", "labels": [], "entities": [{"text": "directed prediction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.6938002705574036}, {"text": "GRU+Entity", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.6825945774714152}, {"text": "BOW-RF", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9821458458900452}]}, {"text": "We observe that the difference in F 1 score between the baseline, bag-of-words model and our GRU models in a 2-class experiment is marginal.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9876023729642233}]}, {"text": "This maybe an indicator that the binary representation harms the classification of emotional relations between characters, as they can be nuanced and do not always perfectly map to either positive and negative classes.", "labels": [], "entities": []}, {"text": "On the other side, a more sophisticated classification approach is necessary to capture these nuanced differences.", "labels": [], "entities": []}, {"text": "for the examples of the indicator implementation.", "labels": [], "entities": []}, {"text": "As expected, we observe a better performance on a graph level for all models, with the highest performance of 47 % F 1 (GRU+MEntity), 63 % F 1 (GRU+MEntity), and 73 % F 1 (GRU+MRole, GRU+MEntity, GRU+NoInd.) in undirected 8-, 5-, and 2-class experiments, respectively, on the development set.", "labels": [], "entities": [{"text": "F 1", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.9891582131385803}, {"text": "F 1", "start_pos": 139, "end_pos": 142, "type": "METRIC", "confidence": 0.9908231198787689}, {"text": "F 1 (GRU+MRole", "start_pos": 167, "end_pos": 181, "type": "METRIC", "confidence": 0.8195224503676096}]}, {"text": "In the directed scenario, the highest performances are 41 % F 1 (GRU+Role), 48 % F 1 (GRU+MRole), and 65 % F 1 (GRU+MRole).", "labels": [], "entities": [{"text": "F 1", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9934199452400208}, {"text": "F 1 (GRU+MRole)", "start_pos": 81, "end_pos": 96, "type": "METRIC", "confidence": 0.8963060889925275}, {"text": "F 1", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9941362738609314}]}, {"text": "The results show that the sequential and embedding information captured by a GRU as well as additional positional information are all relevant fora substantial performance, at least on the finegrained emotion prediction task.", "labels": [], "entities": [{"text": "finegrained emotion prediction task", "start_pos": 189, "end_pos": 224, "type": "TASK", "confidence": 0.7283682003617287}]}], "tableCaptions": [{"text": " Table 1: F 1 scores in % for agreement between anno- tators on different levels. a1, a2, and a3 are different  annotators.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9863981306552887}, {"text": "agreement", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9610362648963928}]}, {"text": " Table 2: Statistics of emotion and relation annotation.  \"All\" indicates the total number of emotion annota- tions. \"Rel.\" indicates total number of emotional re- lationships (including a causing character) instantiated  with the given emotion.", "labels": [], "entities": [{"text": "Rel.", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9794910550117493}]}, {"text": " Table 4: Cross-validated results in % F 1 score, average  of four runs. Inst. level: aggregated over all instances  in the dataset. Story level: averaged performance on all  stories. Graph-level: averaged performance on graph  level on all stories. Test results are reported for the  best indicator type. See", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9043734272321066}, {"text": "Inst. level", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9699970881144205}]}]}