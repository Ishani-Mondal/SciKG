{"title": [{"text": "GAN Driven Semi-distant Supervision for Relation Extraction", "labels": [], "entities": [{"text": "GAN Driven Semi-distant Supervision", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6655077785253525}, {"text": "Relation Extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.9577806293964386}]}], "abstractContent": [{"text": "Distant supervision has been widely used in relation extraction tasks without hand-labeled datasets recently.", "labels": [], "entities": [{"text": "relation extraction tasks", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.9052056868871053}]}, {"text": "However, the automatically constructed datasets comprise numbers of wrongly labeled negative instances due to the incompleteness of knowledge bases, which is neglected by current distant supervised methods resulting in seriously misleading in both training and testing processes.", "labels": [], "entities": []}, {"text": "To address this issue, we propose a novel semi-distant supervision approach for relation extraction by constructing a small accurate dataset and properly leveraging numerous instances without relation labels.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.9193851351737976}]}, {"text": "In our approach, we construct accurate instances by both knowledge base and entity descriptions determined to avoid wrong negative labeling and further utilize unlabeled instances sufficiently using generative adver-sarial network (GAN) framework.", "labels": [], "entities": []}, {"text": "Experimental results on real-world datasets show that our approach can achieve significant improvements in distant supervised relation extraction over strong baselines.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 107, "end_pos": 145, "type": "TASK", "confidence": 0.6176822558045387}]}], "introductionContent": [{"text": "Relation extraction aims to identify relations fora pair of entities in a sentence to construct relation triples like.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9481706321239471}]}, {"text": "It has been well studied by supervised approaches with hand-labeled data.", "labels": [], "entities": []}, {"text": "However, supervised methods are limited to costly hand-labeled training sets and hard to be extended to large-scale relations.", "labels": [], "entities": []}, {"text": "To break the bottleneck of hand-labeled training set, distant supervision () automatically construct datasets with knowledge bases.", "labels": [], "entities": []}, {"text": "It assumes that if two entities have a known relation in a knowledge base, all sentences that mention these two entities will probably express the same relation and can be called positive instances.", "labels": [], "entities": []}, {"text": "At the same time, it treats sentences as negative instances whose entity pairs do not have a known relation in knowledge bases.", "labels": [], "entities": []}, {"text": "Due to the strong assumption, instances are likely to be mislabeled.", "labels": [], "entities": []}, {"text": "To alleviate the wrong labeling problem, distant supervised methods have been implemented with multi-instance learning and neural networks (.", "labels": [], "entities": []}, {"text": "However, previous works focus on positive instances and few methods have addressed the issue of false negative instances.", "labels": [], "entities": []}, {"text": "The false negative instances, which contain true relations, are misclassified sentences in the negative set due to the incomplete nature of knowledge bases.", "labels": [], "entities": []}, {"text": "For example, over 70% of people included in Freebase have no known place of birth ().", "labels": [], "entities": [{"text": "Freebase", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.9645857810974121}]}, {"text": "As shown in, S1 presents the relation place of birth, while it is labeled as a negative instance.", "labels": [], "entities": []}, {"text": "The other three sentences are mislabeled in the same way.", "labels": [], "entities": []}, {"text": "The missing relation triples in knowledge bases yield numbers of false negative instances in the automatically labeled dataset.", "labels": [], "entities": []}, {"text": "These instances will not only mislead the training method to an unreliable convergence but also make the measurement criteria inaccurate in the testing process.", "labels": [], "entities": []}, {"text": "compares the precision of automatic and manual evaluation methods for top N predictions by the previous relation extractor () on the NYT dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9988154172897339}, {"text": "NYT dataset", "start_pos": 133, "end_pos": 144, "type": "DATASET", "confidence": 0.9835875928401947}]}, {"text": "From the table, we can see that manual evaluation is more precise than automatic evaluation by over 19.8%.", "labels": [], "entities": [{"text": "precise", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9712833166122437}]}, {"text": "The huge bias mainly comes from false negative instances in the testing set, which severely limits the upper bound of accuracy for relation extraction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9991507530212402}, {"text": "relation extraction", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8769470751285553}]}, {"text": "Therefore, handling false negative instances is a pivotal issue to improve the performance of distant supervised relation extraction.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 94, "end_pos": 132, "type": "TASK", "confidence": 0.6067387983202934}]}, {"text": "To alleviate the effect of false negative instances, there are two possible ways.", "labels": [], "entities": []}, {"text": "One is improving the accuracy of the automatically labeled dataset, and the other is properly leveraging unlabeled instances which cannot be labeled as positive or negative.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9988464117050171}]}, {"text": "The former way is to construct an accurate dataset by filtering credible negative instances but limited by high annotation cost and the resulting dataset size.", "labels": [], "entities": []}, {"text": "The latter way is to train relation extraction models with abundant unlabeled instances but restricted by the prerequisite of an accurate dataset used as ground truth.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.832720547914505}]}, {"text": "Therefore, we propose a novel semi-distant supervised approach by integrating both ways to decrease the influence of false negative instances for better relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.8736312091350555}]}, {"text": "In our approach, we additionally use entity descriptions together with a knowledge base to construct an accurate dataset.", "labels": [], "entities": []}, {"text": "Supervised by the dataset as ground truth, to effectively exploit numbers of unlabeled instances, we train our relation extractor using a generative adversarial network (GAN) framework.", "labels": [], "entities": [{"text": "relation extractor", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7223550528287888}]}, {"text": "In detail, We propose a threeplayer min-max game to generate proper relation representations for unlabeled instances in an adversarial way which minimizes the difference between labeled and unlabeled data and maximizes the probability of distinguishing from each other at the same time.", "labels": [], "entities": []}, {"text": "The experiments demonstrate that our approach is effective and outperforms the state-of-the-art work.", "labels": [], "entities": []}, {"text": "In summary, we make the following major contributions: \u2022 We propose a novel semi-distant supervision method for relation extraction to alleviate the influence of false negative instances.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.9353626370429993}]}, {"text": "\u2022 To the best of our knowledge, we are the first to generate valid relation representations for sentences by an adversarial algorithm.", "labels": [], "entities": []}, {"text": "Numbers of unlabeled instances are used to improve the performance of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8708714246749878}]}, {"text": "Moreover, our generative adversarial training strategy is proved effective on an additional sentiment classification with sixteen real-world datasets.", "labels": [], "entities": [{"text": "generative adversarial training", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.9029462933540344}, {"text": "sentiment classification", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.9118297100067139}]}, {"text": "\u2022 We construct anew accurate dataset for relation extraction extended from the NYT dataset.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.8728768229484558}, {"text": "NYT dataset", "start_pos": 79, "end_pos": 90, "type": "DATASET", "confidence": 0.9879864156246185}]}, {"text": "Our approach increases the area of the Precision-Recall curve from 0.39 to 0.56 over the baselines.", "labels": [], "entities": [{"text": "Precision-Recall curve", "start_pos": 39, "end_pos": 61, "type": "METRIC", "confidence": 0.9695940315723419}]}], "datasetContent": [{"text": "To reduce false negative instances, we construct anew reliable dataset extended from a widely used dataset NYT () with entity descriptions.", "labels": [], "entities": [{"text": "NYT", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.892977774143219}]}, {"text": "Entity descriptions are crawled from Wikipedia with entity name matching . We assume that if an entity is relevant to another entity, its name is possibly mentioned in the description of the other entity.", "labels": [], "entities": [{"text": "entity name matching", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.6545513172944387}]}, {"text": "For example, the entity Apple Inc. is mentioned in the description of Steve Jobs.", "labels": [], "entities": []}, {"text": "To verify the assumption, we count the number of all the accurate positive instances whose entity descriptions mention the other entity name in the NYT corpora.", "labels": [], "entities": [{"text": "NYT corpora", "start_pos": 148, "end_pos": 159, "type": "DATASET", "confidence": 0.9580565392971039}]}, {"text": "There are 163,108 positive sentences in total, in which 161,392 ones contain entity pairs that related to each other in their descriptions at least once.", "labels": [], "entities": []}, {"text": "In other words, over 98.9% instances in positive set fitting our assumption indicates that most entity pairs in positive instances contain each other in their descriptions.", "labels": [], "entities": []}, {"text": "Therefore, a former negative instance has a big chance to be credible negative if any of its entities is not mentioned in the description of the other one.", "labels": [], "entities": []}, {"text": "Excluding instances that contain entity pairs related to each other in their descriptions, we can obtain more confident negative instances.", "labels": [], "entities": []}, {"text": "Finally, we filter credible positive and negative instances from the dataset, and the other instances are unlabeled ones that cannot be labeled as positive or negative.", "labels": [], "entities": []}, {"text": "The experiments are proposed to answer the following three questions, 1) Is the proposed semidistant supervision method effective for the task of relation extraction?", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.8899067938327789}]}, {"text": "2) Is the constructed dataset credible enough?", "labels": [], "entities": []}, {"text": "3) Is the generative adversarial training helpful to relation extraction and other semi-supervised tasks?", "labels": [], "entities": [{"text": "generative adversarial", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8911801278591156}, {"text": "relation extraction", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.937486857175827}]}, {"text": "We conduct experiments on a widely used dataset NYT () and its new version Accurate-NYT (A-NYT).", "labels": [], "entities": [{"text": "Accurate-NYT", "start_pos": 75, "end_pos": 87, "type": "METRIC", "confidence": 0.9776106476783752}]}, {"text": "A-NYT is a credible dataset filtered by our data construction module.", "labels": [], "entities": []}, {"text": "We follow the previous work ( to partition training and testing sets for NYT and A-NYT.", "labels": [], "entities": [{"text": "NYT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.5187867879867554}]}, {"text": "Besides, we apply sixteen real-world datasets 3 (Liu et al., 2017a) to further verify the effectiveness of our generative adversarial training strategy on the task of sentiment classification.", "labels": [], "entities": [{"text": "generative adversarial training", "start_pos": 111, "end_pos": 142, "type": "TASK", "confidence": 0.8663792014122009}, {"text": "sentiment classification", "start_pos": 167, "end_pos": 191, "type": "TASK", "confidence": 0.9318776726722717}]}, {"text": "The dataset details are shown in  On the dataset NYT and A-NYT, we evaluate our method in the classical held-out evaluation.", "labels": [], "entities": [{"text": "NYT", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.6430053114891052}, {"text": "A-NYT", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.931978166103363}]}, {"text": "It evaluates our models by comparing relation facts discovered from the test sentences with those in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.9701428413391113}]}, {"text": "Specifically, we report both the aggregate Precision-Recall (PR) curves and Precision at top N predictions (P@N) in our experiments.", "labels": [], "entities": [{"text": "Precision-Recall (PR) curves", "start_pos": 43, "end_pos": 71, "type": "METRIC", "confidence": 0.9077428102493286}, {"text": "Precision at top N predictions", "start_pos": 76, "end_pos": 106, "type": "METRIC", "confidence": 0.9448902368545532}]}, {"text": "For the other datasets, we compute the precision of all the predictions.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9994520545005798}]}, {"text": "We adopt the following baselines for distant supervised relation extraction.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 37, "end_pos": 75, "type": "TASK", "confidence": 0.5915341898798943}]}, {"text": "shortened the training instances with the parser tree and pre-trained word embeddings with transfer learning, which is the latest state-of-the-art work.", "labels": [], "entities": []}, {"text": "Self-Training (ST) is a semi-supervised method that can be integrated with PCNN+ATT for unlabeled data, which generates relation types for unlabeled instances with the model itself.", "labels": [], "entities": [{"text": "PCNN+ATT", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.6875171661376953}]}, {"text": "In this section, we apply two previous methods and on NYT and A-NYT.", "labels": [], "entities": [{"text": "NYT", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.48645323514938354}]}, {"text": "PR curves for NYT are reported in their papers, while PR curves for A-NYT come from our implementations of the two baselines.", "labels": [], "entities": [{"text": "NYT", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8144705891609192}]}, {"text": "NYT and A-NYT share the same positive instances, while A-NYT set has less and credible negative instances.", "labels": [], "entities": [{"text": "NYT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.824061393737793}]}, {"text": "As shown in(a),", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The Precision at top N predictions (%) of the  model Lin et al. (2016) upon automatic and manual  evaluations on the NYT Dataset", "labels": [], "entities": [{"text": "Precision at top N predictions", "start_pos": 14, "end_pos": 44, "type": "METRIC", "confidence": 0.7572452783584595}, {"text": "NYT Dataset", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.9831528961658478}]}, {"text": " Table 2: Statistics of the datasets", "labels": [], "entities": []}, {"text": " Table 3. The hyper-parameters s i , s j and s k are  training steps for different modules of generative  adversarial training. Since the other parameters  have little effect on the results, we follow the set- tings as the previous work (", "labels": [], "entities": [{"text": "generative  adversarial training", "start_pos": 94, "end_pos": 126, "type": "TASK", "confidence": 0.8933119773864746}]}, {"text": " Table 4: Overall performance at P@Ns(%) and PR  curve areas", "labels": [], "entities": [{"text": "PR  curve", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9740430414676666}]}, {"text": " Table 5: P@Ns(%) of Lin et al. (2016) upon automatic  and manual evaluations", "labels": [], "entities": [{"text": "P@Ns", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.8881199558575948}]}, {"text": " Table 6: P@Ns(%) and PR curve areas on A- NYT. Methods with  \u2021 do not use unlabeled data.  PCNN+ATT+AT is a semi-supervised extension of  original method (", "labels": [], "entities": [{"text": "PR curve areas", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.9263760844866434}, {"text": "A- NYT", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.6601508756478628}, {"text": "AT", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.5543864965438843}]}, {"text": " Table 7: Precision for the sentiment classification task", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9867811799049377}, {"text": "sentiment classification", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.9828662276268005}]}]}