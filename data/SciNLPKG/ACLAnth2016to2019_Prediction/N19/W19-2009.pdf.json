{"title": [{"text": "Syntactic Interchangeability in Word Embedding Models", "labels": [], "entities": [{"text": "Syntactic Interchangeability", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8909419476985931}]}], "abstractContent": [{"text": "Nearest neighbors in word embedding models are commonly observed to be semantically similar, but the relations between them can vary greatly.", "labels": [], "entities": []}, {"text": "We investigate the extent to which word embedding models preserve syntactic interchangeability, as reflected by distances between word vectors, and the effect of hyper-parameters-context window size in particular.", "labels": [], "entities": []}, {"text": "We use part of speech (POS) as a proxy for syntactic interchangeability, as generally speaking, words with the same POS are syntactically valid in the same contexts.", "labels": [], "entities": []}, {"text": "We also investigate the relationship between in-terchangeability and similarity as judged by commonly-used word similarity benchmarks, and correlate the result with the performance of word embedding models on these benchmarks.", "labels": [], "entities": []}, {"text": "Our results will inform future research and applications in the selection of word embedding model, suggesting a principle for an appropriate selection of the context window size parameter depending on the use-case.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embedding algorithms ( attempt to capture the semantic space of words in a metric space of real-valued vectors.", "labels": [], "entities": []}, {"text": "While it is common knowledge that the hyper-parameters used to train these models affects the semantic properties of the distances arising from them (, and indeed, it has been shown that they capture many different semantic relations (, little has been done to quantify the effect of model hyperparameters on output tendencies.", "labels": [], "entities": []}, {"text": "Here we begin to answer this question, evaluating fastText on benchmarks designed to measure how well a model captures the degree of similarity between words ( \u00a72).", "labels": [], "entities": []}, {"text": "In our experiments, we investigate how syntactic interchangeability of words, represented by their part of speech ( \u00a73), is expressed in word embedding models and evaluation benchmarks.", "labels": [], "entities": []}, {"text": "Based on the distributional hypothesis, word embeddings are learned from text by first extracting co-occurrences-finding, for each word token, all words within a context window around it, whose size (or maximal size) is a hyperparameter of the training algorithm.", "labels": [], "entities": []}, {"text": "Word vectors are then learned by predicting these co-occurrences or factorizing a co-occurrence matrix.", "labels": [], "entities": []}, {"text": "We discover a clear relationship between the context window size hyper-parameter and the performance of a word embedding model in estimating the similarity between words.", "labels": [], "entities": []}, {"text": "To try to explain this relationship, we quantify how syntactic interchangeability is reflected in each benchmark, and its relation to the context window size.", "labels": [], "entities": []}, {"text": "Our experiments reveal that context window size is negatively correlated with the number of same-POS words among the nearest neighbors of words, but that this fact is not enough to explain the complex interaction between context window size and performance on word similarity benchmarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To investigate the effect of window size on a model's performance on the benchmarks, we evaluate each model on each benchmark, using cosine similarity as the model's prediction for each pair.", "labels": [], "entities": []}, {"text": "The performance is measured by Spearman correlation between the benchmark score and the word embedding cosine similarity ().", "labels": [], "entities": []}, {"text": "displays the performance of the CBOW and SGNS algorithms on each benchmark, with window sizes 1 to 15.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.8008812665939331}]}, {"text": "Apart from a small dip between windows 1 and 2 for CBOW, the performance is either nearly constant, or changes nearly monotonically with window size in each setting.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.8080028295516968}]}, {"text": "The relative improvement (or deterioration), in percents, with the increase of window size from 2 to 15, are shown in (\u2206win = 2 \u2192 15(%)).", "labels": [], "entities": []}, {"text": "Interestingly, CBOW exhibits a positive correlation of window size with model's performance for all benchmarks but SimLex999, while performance for SGNS barely changes with window size, except for SimLex999 and SimVerb3500, where we see a strong negative correlation.", "labels": [], "entities": []}, {"text": "In SimLex999 and in SimVerb3500, the words in each pair have the same part of speech by design (in particular, SimVerb3500 only contains verbs).", "labels": [], "entities": []}, {"text": "Hypothesizing that the effect of win- dow size is related to the model's implicitly learned concept of part of speech, we investigate this idea in the next section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Analysis of interchangeability (by same-POS) in word similarity and relatedness benchmarks. \u2206win =  2 \u2192 15(%) is the relative change, in percents, of the model's performance (by Spearman correlation) when going  from window size 2 to window size 15, for the CBOW and SGNS algorithms ( \u00a72.3). Related and Unrelated are the  top and bottom 30% of the pairs, by benchmark score, respectively. P-value is calculated using the hypergeometric  test, comparing the enrichment of interchangeable pairs within related pairs, with a background of all related and  unrelated pairs ( \u00a73.1).", "labels": [], "entities": [{"text": "P-value", "start_pos": 400, "end_pos": 407, "type": "METRIC", "confidence": 0.9851065874099731}]}, {"text": " Table 2: Percentage of interchangeable neighbors per  pivot POS for the smallest (1) and largest", "labels": [], "entities": []}]}