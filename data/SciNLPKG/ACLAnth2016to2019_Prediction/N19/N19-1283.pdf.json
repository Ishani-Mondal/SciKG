{"title": [{"text": "Acoustic-to-Word Models with Conversational Context Information", "labels": [], "entities": []}], "abstractContent": [{"text": "Conversational context information, higher-level knowledge that spans across sentences, can help to recognize along conversation.", "labels": [], "entities": []}, {"text": "However, existing speech recognition models are typically built at a sentence level, and thus it may not capture important conversational context information.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.710618257522583}]}, {"text": "The recent progress in end-to-end speech recognition enables integrating context with other available information (e.g., acoustic, linguistic resources) and directly recognizing words from speech.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.719041720032692}]}, {"text": "In this work, we present a direct acoustic-to-word, end-to-end speech recognition model capable of utilizing the conversational context to better process long conversations.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7499932050704956}]}, {"text": "We evaluate our proposed approach on the Switchboard conversational speech corpus and show that our system outperforms a standard end-to-end speech recognition system.", "labels": [], "entities": [{"text": "Switchboard conversational speech corpus", "start_pos": 41, "end_pos": 81, "type": "DATASET", "confidence": 0.6159663125872612}]}], "introductionContent": [{"text": "Many real-world speech recognition applications, including teleconferencing, and AI assistants, require recognizing and understand long conversations.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7476008534431458}]}, {"text": "Ina long conversation, there exists the tendency of semantically related words or phrases reoccur across sentences, or there exists topical coherence.", "labels": [], "entities": []}, {"text": "Thus, such conversational context information, higher-level knowledge that spans across sentences, provides important information that can improve speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.8213270902633667}]}, {"text": "However, the long conversations typically split into short sentencelevel audios to make building speech recognition models computationally feasible in current stateof-the-art recognition systems (.", "labels": [], "entities": []}, {"text": "Over the years, there have been many studies have attempted to inject a longer context information into language models.", "labels": [], "entities": []}, {"text": "Based on a recurrent neural network (RNNs) language models (,;, proposed using a context vector that would encode the longer context information as an additional network input.", "labels": [], "entities": []}, {"text": "However, all of these models have been developed on text data, and therefore, it must still be integrated with a conventional acoustic model which is built separately without a longer context information, for speech recognition on long conversations.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 209, "end_pos": 227, "type": "TASK", "confidence": 0.7369929105043411}]}, {"text": "Recently, new approaches to speech recognition models integrate all available information (e.g. acoustic, linguistic resources) in a so-called end-to-end manner proposed in (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.8015841245651245}]}, {"text": "In these approaches, a single neural network is trained to recognize graphemes or even words from speech directly.", "labels": [], "entities": []}, {"text": "Especially, the model using semantically meaningful units, such as words or sub-word (, rather than graphemes have been showing promising results.", "labels": [], "entities": []}, {"text": "In this work, motivated by such property of the end-to-end speech recognition approaches, we propose to integrate conversational context information within a direct acoustic-to-word, end-toend speech recognition to better process long conversations.", "labels": [], "entities": [{"text": "end-to-end speech recognition", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.729557454586029}]}, {"text": "Thus far, the research in speech recognition systems has focused on recognizing sentences and to the best of our knowledge, there have been no studies of word-based models incorporating conversational context information.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7125064730644226}]}, {"text": "There has been recent work attempted to use the conversational context information from the preceding graphemes, however, it is limited to encode semantically meaningful context representation.", "labels": [], "entities": []}, {"text": "Another recent work attempted to use a context information), however, their method requires a list of phrases at inference (i.e. personalized contact list).", "labels": [], "entities": []}, {"text": "We evaluate our proposed approach on the Switchboard conversational speech corpus, and show that our model outperforms the sentence-level end-toend speech recognition model.", "labels": [], "entities": [{"text": "Switchboard conversational speech corpus", "start_pos": 41, "end_pos": 81, "type": "DATASET", "confidence": 0.5950345695018768}, {"text": "sentence-level end-toend speech recognition", "start_pos": 123, "end_pos": 166, "type": "TASK", "confidence": 0.5780012682080269}]}], "datasetContent": [{"text": "We investigated the performance of the proposed model on the Switchboard LDC corpus (97S62) which has a 300 hours training set.", "labels": [], "entities": [{"text": "Switchboard LDC corpus (97S62)", "start_pos": 61, "end_pos": 91, "type": "DATASET", "confidence": 0.9039606948693594}]}, {"text": "We split the Switchboard data into two groups, then used 285 hours of data and Switchboard (SWB) evaluation sets.", "labels": [], "entities": []}, {"text": "We denote train nodup, train dev, SWB, and CH as our training, development, and two evaluation datasets for CH and SWB, respectively.", "labels": [], "entities": []}, {"text": "There are 2,402 conversations in training sets and 20 conversations in CH, and 20 conversations in SWB.", "labels": [], "entities": [{"text": "SWB", "start_pos": 99, "end_pos": 102, "type": "DATASET", "confidence": 0.7831843495368958}]}, {"text": "We sampled all audio data at 16kHz, and extracted 80-dimensional log-mel filterbank coefficients with 3-dimensional pitch features, from 25 ms frames with a 10ms frame shift.", "labels": [], "entities": []}, {"text": "We used 83-dimensional feature vectors to input to the network in total.", "labels": [], "entities": []}, {"text": "We used 9,840 distinct labels: 9,838 word-level BPE units, start-of-speech/endof-speech, and blank tokens.", "labels": [], "entities": []}, {"text": "Note that no pronunciation lexicon was used in any of the experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of word error rates (WER) on Switchboard 300h with standard end-to-end speech recognition  models and our proposed end-to-end speech recognition models with conversational context.", "labels": [], "entities": [{"text": "word error rates (WER)", "start_pos": 24, "end_pos": 46, "type": "METRIC", "confidence": 0.8266855428616205}]}, {"text": " Table 2: Perplexities on a held-out set of our proposed  conversational context LM and baselines.", "labels": [], "entities": []}]}