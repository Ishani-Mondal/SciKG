{"title": [], "abstractContent": [{"text": "Many clinical information needs can be stated as why-questions.", "labels": [], "entities": []}, {"text": "The answers to them represent important clinical reasoning and justification.", "labels": [], "entities": []}, {"text": "Clinical notes area rich source for such why-question answering (why-QA).", "labels": [], "entities": [{"text": "why-question answering", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.863609254360199}]}, {"text": "However, there are few dedicated corpora, and little is known about the characteristics of clinical why-QA narratives.", "labels": [], "entities": []}, {"text": "To address this gap, the study performed manual annotation of 277 sentences containing explicit why-QA cues and summarized their quantitative and qualitative properties.", "labels": [], "entities": []}, {"text": "The contributions are: 1) sharing a seed corpus that can be used for various QA-related training purposes, 2) adding to our knowledge about the diversity and distribution of clinical why-QA contents.", "labels": [], "entities": []}], "introductionContent": [{"text": "The thought process involved in clinical reasoning and decision-making can be naturally framed into a series of questions and answers.", "labels": [], "entities": []}, {"text": "In addition to the tangible value as handy assistance, making computers handle question-answering (QA) is considered a remarkable achievement in artificial intelligence.", "labels": [], "entities": [{"text": "computers handle question-answering (QA)", "start_pos": 62, "end_pos": 102, "type": "TASK", "confidence": 0.6642981072266897}]}, {"text": "Accordingly, there has been vital interest in developing clinical QA systems, e.g.,),, and MEANS.", "labels": [], "entities": [{"text": "QA", "start_pos": 66, "end_pos": 68, "type": "TASK", "confidence": 0.8930094242095947}, {"text": "MEANS", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.8445422649383545}]}, {"text": "Among the targets, why-QA represents a special category that deals with cause, motivation, circumstance, and purpose).", "labels": [], "entities": []}, {"text": "Within the top ten question types asked by family doctors), 20% of them can actually be paraphrased into a why-question.", "labels": [], "entities": []}, {"text": "Besides the sizable presence, clinical why-QA is both semantically and pragmatically rich because: 1) toward the deep explanatory end the task almost resembles expert-level synthesis and inference, 2) toward the shallower end it usually involves identifying the documented reason that a decision was made.", "labels": [], "entities": []}, {"text": "It is worth clarifying here two different scenarios that QA tasks are defined.", "labels": [], "entities": [{"text": "QA tasks", "start_pos": 57, "end_pos": 65, "type": "TASK", "confidence": 0.826200544834137}]}, {"text": "The first aligns more along consulting knowledge sources to answer a question that is not patient-specific, e.g., Why do phenobarbital and Dilantin counteract each other?", "labels": [], "entities": []}, {"text": "This is also the scenario that most of the existing clinical QA systems handle.", "labels": [], "entities": [{"text": "QA", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.8104605078697205}]}, {"text": "The second scenario (focus of this study) is to find the answer within a given document (a.k.a. reading comprehension), which can especially benefit patient-specific QA based on information mentioned in clinical notes.", "labels": [], "entities": []}, {"text": "In the general domain such reading comprehension QA has more than a decade of research, with widely used corpora such as the SQuAD and that by.", "labels": [], "entities": []}, {"text": "There have not been comparable resources in the clinical domain until a couple of works in 2018 (see Related work section).", "labels": [], "entities": []}, {"text": "The recently developed corpora in clinical reading comprehension QA are extremely valuable, but also limited with regard to why-QA research because 1) their coverage and analysis did not emphasize on why-questions, 2) the annotation methods could have missed many representative why-QA targets.", "labels": [], "entities": []}, {"text": "Therefore, the current study aims to compensate for these oversights through systematic inspection into clinical sentences that contain the intuitive cues \"because\" and \"due to\".", "labels": [], "entities": []}, {"text": "The rationale is: we might never know what can be missed by diving right into complex cases, unless the low-hanging offers are well understood first.", "labels": [], "entities": []}, {"text": "In fact, the results revealed many informative clinical topics and patterns involved in why-QA.", "labels": [], "entities": []}, {"text": "Along with the diverse topics, the well-formed linguistic constructs based on the two unambiguous cues make this small corpus an ideal seed training set to stabilize models or to bootstrap other solutions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Detailed distribution of QA pairs by type", "labels": [], "entities": [{"text": "Detailed", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.8977794647216797}]}]}