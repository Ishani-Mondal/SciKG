{"title": [{"text": "Simple dynamic word embeddings for mapping perceptions in the public sphere", "labels": [], "entities": []}], "abstractContent": [{"text": "Word embeddings trained on large-scale historical corpora can illuminate human biases and stereotypes that perpetuate social inequalities.", "labels": [], "entities": []}, {"text": "These embeddings are often trained in separate vector space models defined according to different attributes of interest.", "labels": [], "entities": []}, {"text": "In this paper, we develop a single, unified dynamic embedding model that learns attribute-specific word embeddings and apply it to a novel dataset-talk radio shows from around the US-to analyze perceptions about refugees.", "labels": [], "entities": []}, {"text": "We validate our model on a benchmark dataset and apply it to two corpora of talk radio shows averaging 117 million words produced over one month across 83 stations and 64 cities.", "labels": [], "entities": []}, {"text": "Our findings suggest that dynamic word em-beddings are capable of identifying nuanced differences in public discourse about contentious topics, suggesting their usefulness as a tool for better understanding how the public perceives and engages with different issues across time, geography, and other dimensions.", "labels": [], "entities": [{"text": "identifying nuanced differences in public discourse about contentious topics", "start_pos": 66, "end_pos": 142, "type": "TASK", "confidence": 0.6413283612993028}]}], "introductionContent": [{"text": "Language has long been described as both a cause and reflection of our psycho-social contexts (.", "labels": [], "entities": []}, {"text": "Recent work using word embeddings-low-dimensional vector representations of words trained on large datasets to capture key semantic informationhas demonstrated that language encodes several gender, racial, and other common contemporary biases that correlate with both implicit biases () and macro-scale historical trends (.", "labels": [], "entities": []}, {"text": "These studies have validated the use of word embeddings to measure a range of psychological and social contexts, yet inmost cases, they have failed to leverage the full power of available datasets.", "labels": [], "entities": []}, {"text": "For example, the historical biases presented in () are computed using decade-specific word embeddings produced by training different Word2Vec () models on a large corpus of historical text from that decade.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 133, "end_pos": 141, "type": "DATASET", "confidence": 0.9361583590507507}]}, {"text": "The authors then use a Procrustes alignment to project embeddings from different models into the same vector space so they can be compared across decades.", "labels": [], "entities": [{"text": "Procrustes alignment", "start_pos": 23, "end_pos": 43, "type": "DATASET", "confidence": 0.8879218995571136}]}, {"text": "While this approach is reasonable when there are large-scale datasets available fora given attribute of interest (e.g. decade), it requires an additional optimization step and also disregards valuable training data that could be pooled and leveraged across attribute values to help with both training and regularization.", "labels": [], "entities": []}, {"text": "This latter property is particularly appealing-and necessary-in the context of limited data.", "labels": [], "entities": []}, {"text": "In this paper, we use a simple, unified dynamic word embedding model that jointly trains linguistic information alongside any categorical variable of interest-e.g. year, geography, income bracket, etc.-that describes the context in which a particular word was used.", "labels": [], "entities": []}, {"text": "We apply this model to a novel data corpus-talk radio transcripts from stations located in over 64 US cities-to explore the evolution of perceptions about refugees during a onemonth period in late 2018.", "labels": [], "entities": []}, {"text": "The results from our model suggest the potential to use dynamic word embeddings to obtain a granular, near real-time pulse on how people feel about different issues in the public sphere.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our data is sourced from talk radio audio data collected by the media analytics nonprofit Cortico 3 . Audio data is ingested from nearly 170 different radio stations and automatically transcribed to text.", "labels": [], "entities": []}, {"text": "The data is further processed to identify different speaker turns into \"snippets\"; infer the gender of the speaker; and compute other useful metrics (more details on the radio data pipeline can be found in).", "labels": [], "entities": []}, {"text": "We train our dynamic embedding model on two talk radio datasets sourced from 83 stations located in 64 cities across the US.", "labels": [], "entities": []}, {"text": "Dataset 1 includes 4.4 million snippets comprised of 114 million words produced by 390 shows between September 1 and 30, 2018.", "labels": [], "entities": []}, {"text": "Dataset 2 includes over 4.8 million snippets comprised of 119 million total words produced by 433 shows between August 15, and September 15, 2018 . These datasets are used for analyses 1 and 2, respectively, described below.", "labels": [], "entities": []}, {"text": "Finally, we define bias towards refugees similar to how the authors of () define bias against Asians during the 20th century, measuring to what extent radio shows associate \"outsider\" adjectives like \"aggressive\", \"frightening\", \"illegal\", etc. with refugee and immigrant-related terms in comparison to all other adjectives.", "labels": [], "entities": []}, {"text": "To compute refugee bias scores with respect to the attribute set A, we use the relative norm distance metric from (: Where E(r, A) is the dynamic embedding fora given word refugee word r in the set of all refugeerelated words R (e.g. \"refugee\", \"immigrant\", \"asylum\", etc); all is the average dynamic embedding computed for each win the set of all adjectives with respect to A; out is analogously defined for outsider adjectives; and || \u00b7 || 2 is the L2 norm.: Bias towards refugees as outsiders across talk radio shows from mid-August to mid-September 2018: (a) depicts bias scores computed using a \"non-dynamic model\", i.e., training multiple Word2Vec models (one per day of data) and then projecting these models into the same vector space using orthogonal Procrustes alignment, and (b) depicts bias scores computed using our dynamic model.", "labels": [], "entities": []}, {"text": "From qualitative inspection, the dynamic model appears to regularize scores across days during which refugee-related news is likely less-salient in public discourse.", "labels": [], "entities": []}], "tableCaptions": []}