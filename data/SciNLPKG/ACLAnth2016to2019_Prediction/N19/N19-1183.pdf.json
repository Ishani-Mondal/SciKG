{"title": [{"text": "A Study of Latent Structured Prediction Approaches to Passage Reranking", "labels": [], "entities": [{"text": "Latent Structured Prediction Approaches", "start_pos": 11, "end_pos": 50, "type": "TASK", "confidence": 0.6694572195410728}, {"text": "Passage Reranking", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.9279716312885284}]}], "abstractContent": [{"text": "The structured output framework provides a helpful tool for learning to rank problems.", "labels": [], "entities": []}, {"text": "In this paper, we propose a structured output approach which regards rankings as latent variables.", "labels": [], "entities": []}, {"text": "Our approach addresses the complex optimization of Mean Average Precision (MAP) ranking metric.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP", "start_pos": 51, "end_pos": 78, "type": "METRIC", "confidence": 0.9500686764717102}]}, {"text": "We provide an inference procedure to find the max-violating ranking based on the decomposition of the corresponding loss.", "labels": [], "entities": []}, {"text": "The results of our experiments on WikiQA and TREC13 datasets show that our reranking based on structured prediction is a promising research direction.", "labels": [], "entities": [{"text": "WikiQA", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9200287461280823}, {"text": "TREC13 datasets", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.8654747009277344}]}], "introductionContent": [{"text": "The current state-of-the-art learning approaches for answer sentence reranking in question answering (QA) are mostly based on learning pairwise ranking signals or simple binary classification (relevant versus irrelevant labels).", "labels": [], "entities": [{"text": "answer sentence reranking in question answering (QA)", "start_pos": 53, "end_pos": 105, "type": "TASK", "confidence": 0.876833803123898}]}, {"text": "Intuitively, global information over a rank should improve the ranker accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9709792137145996}]}, {"text": "Thus, there have been promising attempts to learn global ranking functions which encompass the signals of all the candidates fora given query ().", "labels": [], "entities": []}, {"text": "These works employ the structured output learning framework to represent a ranking as a structured object, with respect to which it is possible to directly optimize a ranking measure.", "labels": [], "entities": []}, {"text": "Direct optimization of the target ranking measures is affordable when they are factorizable, e.g., the structural SVM of makes use of the factorization properties of the Normalized Discounted Cumulative Gain (NDCG) ranking score.", "labels": [], "entities": []}, {"text": "In contrast, MAP is rather complex making its treatment harder.", "labels": [], "entities": [{"text": "MAP", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8884226083755493}]}, {"text": "could still find an exact solution to the hinge-loss relaxation of Average Precision (AP) for the structural SVM approach.", "labels": [], "entities": [{"text": "Average Precision (AP)", "start_pos": 67, "end_pos": 89, "type": "METRIC", "confidence": 0.958547031879425}]}, {"text": "It is found for the particular case of a combined feature mapping of inputs and structured outputs.", "labels": [], "entities": []}, {"text": "Such a mapping accounts for respective orderings of the pairs of candidate items, where one item is relevant and the other is not, without explicitly encoding the order of all the items in the rank.", "labels": [], "entities": []}, {"text": "Encoding such order (, i.e., adding yet more complexity to the structural feature space, might lead to intractability of the previous exact max-violating inference with respect to MAP.", "labels": [], "entities": []}, {"text": "Furthermore, the feature representation of the gold standard rankings, which could be many fora given candidate list of items, is not unique anymore.", "labels": [], "entities": []}, {"text": "In this work, we study the effect of using structured ranking representations ( within the large-margin structured prediction framework versus direct MAP optimization on the most representative task of QA, i.e., passage reranking.", "labels": [], "entities": [{"text": "MAP optimization", "start_pos": 150, "end_pos": 166, "type": "TASK", "confidence": 0.8352631330490112}, {"text": "passage reranking", "start_pos": 212, "end_pos": 229, "type": "TASK", "confidence": 0.8904411196708679}]}, {"text": "To make two ends meet, we have to tackle the above two issues, i.e., i) intractability of the max-violating inference with respect to MAP, and ii) multiplicity of the ground truths.", "labels": [], "entities": [{"text": "intractability", "start_pos": 72, "end_pos": 86, "type": "METRIC", "confidence": 0.9518373012542725}]}, {"text": "Regarding the latter, it should be noted that different rankings can correspond to optimal performance, thus, select one among all possible correct rankings at random to build the ground truth for training.", "labels": [], "entities": []}, {"text": "bypass the necessity of comparison to a complete ranking during training and sample the candidate pairs.", "labels": [], "entities": []}, {"text": "In this work, we show how this issue can be seamlessly circumvent using the latent structured prediction formulation.", "labels": [], "entities": [{"text": "latent structured prediction formulation", "start_pos": 76, "end_pos": 116, "type": "TASK", "confidence": 0.6819683983922005}]}, {"text": "For optimizing MAP, we derive a strict decomposition of the loss corresponding to AP and propose an approximate method for inference of the max-violating constraint with respect to it.", "labels": [], "entities": []}, {"text": "More specifically, we provide two structured output approaches optimizing the MAP metric based on Latent Structured Perceptron (LSP) () and Latent Structural SVM (LSSVM) () algorithms.", "labels": [], "entities": []}, {"text": "We compare LSP and LSSVM using our MAP optimization strategy on WikiQA () and TREC13 () datasets against an SVM classifier and SVM map -the structural approach of.", "labels": [], "entities": [{"text": "WikiQA () and TREC13 () datasets", "start_pos": 64, "end_pos": 96, "type": "DATASET", "confidence": 0.7190823256969452}]}, {"text": "All the models use state-of-the-art traditional feature vectors for the task.", "labels": [], "entities": []}, {"text": "Our experiments on WikiQA dataset show a large improvement of our structural approaches over the SVM baseline, i.e., more than 7 absolute points in MAP, MRR and Precision@1.", "labels": [], "entities": [{"text": "WikiQA dataset", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.9803208112716675}, {"text": "MAP", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.812924861907959}, {"text": "MRR", "start_pos": 153, "end_pos": 156, "type": "METRIC", "confidence": 0.7798520922660828}, {"text": "Precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9515937566757202}]}, {"text": "However, we acknowledge the fact that neural models can produce better representations, which can lead to a superior performance.", "labels": [], "entities": []}, {"text": "Thus, to collocate our results in a more general setting, we also carried out experiments using the embeddings of questions and passages, produced by an accurate Convolutional Neural Network (CNN) for passage reranking.", "labels": [], "entities": [{"text": "passage reranking", "start_pos": 201, "end_pos": 218, "type": "TASK", "confidence": 0.7842128574848175}]}, {"text": "In this setting, the structured output models approach the state of the art, confirming the positive impact of our models, which may also be used to train neural networks.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we compare the proposed structural ranking approach with the classification and structural baselines.", "labels": [], "entities": []}, {"text": "We first report the results using standard similarity features in all of our models.", "labels": [], "entities": []}, {"text": "Then, we show the outcome of our models when fed with embeddings produced by the CNN.", "labels": [], "entities": [{"text": "CNN", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.9772207140922546}]}, {"text": "3, we repeat the main experiments in the cross-validation setting, using the similarity features.", "labels": [], "entities": []}, {"text": "On average, LSSVM-AP outperforms SVM map in terms of MAP and MRR, as in the standard setting, however, having relatively higher variance across the folds.", "labels": [], "entities": [{"text": "LSSVM-AP", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.7269544005393982}, {"text": "MAP", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9300458431243896}, {"text": "MRR", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9786630272865295}]}, {"text": "The LSP models sustain their superiority using the similarity features also in cross-validation, with LSP-AP scoring the best across the models and with the least variance.", "labels": [], "entities": []}, {"text": "The results of our cross-validation experiments on TREC13 are depicted in Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.9697943329811096}]}, {"text": "4. LSP-AP slightly improves over the baseline models in terms of MAP.", "labels": [], "entities": [{"text": "MAP", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9102503657341003}]}, {"text": "The baseline LSP this time deviates the least over the folds and reaches better P@1 among all the models.", "labels": [], "entities": [{"text": "P@1", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9679168462753296}]}, {"text": "LSSVM-AP instead underperforms in this experiment, which might be for the reason of shortage of the data for validation.", "labels": [], "entities": [{"text": "LSSVM-AP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7560716271400452}]}, {"text": "It is also true that in this work, by fixing the weighting schema v, we limited our study to one particular case of a structural ranking representation.", "labels": [], "entities": []}, {"text": "However, finding an appropriate structural feature space, e.g., to the extent enabled by tuning the positional weights v j for the particular application, can be potentially beneficial.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results on WikiQA.", "labels": [], "entities": [{"text": "WikiQA", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9400669932365417}]}, {"text": " Table 2: Models on WikiQA trained on CNN embed- dings.", "labels": [], "entities": [{"text": "CNN embed- dings", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.9141412973403931}]}, {"text": " Table 3: Cross-validation results on WikiQA.", "labels": [], "entities": [{"text": "WikiQA", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.9626584649085999}]}, {"text": " Table 4: Cross-validation results on TREC13.", "labels": [], "entities": [{"text": "TREC13", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.4446336627006531}]}]}