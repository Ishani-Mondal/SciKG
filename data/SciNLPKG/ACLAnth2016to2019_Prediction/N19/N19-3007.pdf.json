{"title": [{"text": "A bag-of-concepts model improves relation extraction in a narrow knowledge domain with limited data", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8600909113883972}]}], "abstractContent": [{"text": "This paper focuses on a traditional relation extraction task in the context of limited annotated data and a narrow knowledge domain.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.873935341835022}]}, {"text": "We explore this task with a clinical corpus consisting of 200 breast cancer follow-up treatment letters in which 16 distinct types of relations are annotated.", "labels": [], "entities": []}, {"text": "We experiment with an approach to extracting typed relations called window-bounded co-occurrence (WBC), which uses an adjustable context window around entity mentions of a relevant type, and compare its performance with a more typical intra-sentential co-occurrence baseline.", "labels": [], "entities": []}, {"text": "We further introduce anew bag-of-concepts (BoC) approach to feature engineering based on the state-of-the-art word embeddings and word synonyms.", "labels": [], "entities": []}, {"text": "We demonstrate the competitiveness of BoC by comparing with methods of higher complexity , and explore its effectiveness on this small dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Applying automatic relation extraction on small data sets in a narrow knowledge domain is challenging.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7376803755760193}]}, {"text": "Here, we consider the specific context of a small clinical corpus, in which we have a variety of relation types of interest but limited examples of each.", "labels": [], "entities": []}, {"text": "Transformation of clinical texts into structured sets of relations can facilitate the exploration of clinical research questions such as the potential risks of treatments for patients with certain characteristics, but large-scale annotation of these data sets is notoriously difficult due to the sensitivity of the data and the need for specialized clinical knowledge.", "labels": [], "entities": []}, {"text": "Rule-based methods) typically determine whether a particular type of relation exists in a given text by leveraging the context in which key clinical entities are mentioned.", "labels": [], "entities": []}, {"text": "For instance, if two entities with type TestName and TestResult, respectively, are observed in a given sentence, it is likely that a relation of type TestFinding exists between them.", "labels": [], "entities": []}, {"text": "However, construction of highprecision rules defining relevant contexts is timeconsuming and expensive, requiring extensive effort from domain experts.", "labels": [], "entities": []}, {"text": "The state-of-the-art machine learning algorithms such as neural network models) may over-fit in performing relation extraction in this context, due to a limited quantity of training instances.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.8291616141796112}]}, {"text": "In this work, we experiment with two automatic approaches to semantic relation extraction applied to a small corpus consisting of breast cancer follow-up treatment letters (, comparing a simple rule-based co-occurrence approach to machine learning classifiers.", "labels": [], "entities": [{"text": "semantic relation extraction", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8094136317571005}]}, {"text": "The first approach, simple co-occurrence, is based on the assumption that most relevant relations are intra-sentential, that is, the relation between a pair of named entities is expressed within the scope of a single sentence.", "labels": [], "entities": []}, {"text": "However, some relations maybe expressed across sentence boundaries, and thus a single sentence may not be the ideal choice of scope, as shown in prior work that considers inter-sentential relations (also known as non-sentence or cross-sentence relations).", "labels": [], "entities": []}, {"text": "We extend the co-occurrence approach to allow explicit adjustment of context window size, from one to two sentences, a method called WindowBounded Co-occurrence (WBC).", "labels": [], "entities": []}, {"text": "The best window size fora given relation is identified by choosing the one which produces the highest score under F 1 -measure on a development set.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 114, "end_pos": 126, "type": "METRIC", "confidence": 0.929320365190506}]}, {"text": "The second approach is based on supervised binary classification.", "labels": [], "entities": [{"text": "supervised binary classification", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.7301777601242065}]}, {"text": "We transform the multirelation extraction task into several independent binary tasks.", "labels": [], "entities": [{"text": "multirelation extraction task", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.8162958820660909}]}, {"text": "We build on a bag-of-concepts (BoC) () approach which models the text in terms of phrases or preidentified concepts, extending it with word embeddings and word synonyms.", "labels": [], "entities": []}, {"text": "We compare two different pre-trained word embedding models, and a number of other model variations.", "labels": [], "entities": []}, {"text": "We also explore grouping of synonyms into abstracted concepts.", "labels": [], "entities": [{"text": "grouping of synonyms into abstracted concepts", "start_pos": 16, "end_pos": 61, "type": "TASK", "confidence": 0.8400333523750305}]}, {"text": "We find that the intra-sentential rule-based approach outperforms the approach which allows fora larger context window.", "labels": [], "entities": []}, {"text": "The supervised learning models outperforms rule-based approaches under F 1 measure, and their results show that models using BoC features outperform models with BoW, dependency parse, or sentence embedding features.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.9289324680964152}, {"text": "dependency parse", "start_pos": 166, "end_pos": 182, "type": "TASK", "confidence": 0.6675456613302231}]}, {"text": "We also show that SVM outperforms complex models such as a feed-forward ANN in our low resource scenario, with less tendency to over-fitting.", "labels": [], "entities": [{"text": "SVM", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9347488284111023}]}], "datasetContent": [{"text": "Considering the dataset is small, we split the transformed dataset into three independent combinations of training, development, and test sets with the ratio of 6:1:3.", "labels": [], "entities": []}, {"text": "In training stage, we train independent models for each specific relation type.", "labels": [], "entities": []}, {"text": "We use crossvalidation and grid search to tune the hyperparameters of the classifiers.", "labels": [], "entities": []}, {"text": "In prediction stage, the decision of applying sentence-bounded or window-bounded approach is made by setting the size of sliding window.", "labels": [], "entities": [{"text": "prediction", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.960720956325531}]}, {"text": "Setting the window size to 0 will apply the sentencebounded co-occurrence constraint.", "labels": [], "entities": []}, {"text": "We choose window sizes of 0, 5, 10 to explore the value of additional context.", "labels": [], "entities": []}, {"text": "In supervised binary classification approach, utilizing a similarity threshold of 1 leads to strict use of BoW (word) features, while relaxing the similarity threshold \u00b5 of 0.9, 0.8 will generate BoC (concepts).", "labels": [], "entities": [{"text": "supervised binary classification", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.6737369298934937}]}, {"text": "We compare the influence of different word embeddings in generating BoC based on their relation extraction performance on the test set.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7539471387863159}]}, {"text": "Both rule-based approach and supervised binary classification approach will make predictions on the same test set, which allows empirical comparison between rule-based and machine learning approaches.", "labels": [], "entities": []}, {"text": "We compare the impact of increasing data size for BoW and BoC by sub-sampling the training set into nine instance-incremental and nonoverlapping sub-sets (combining them into sets representing 10% to 90% of the original training set) and visualize the performance variation.", "labels": [], "entities": [{"text": "BoW", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.911804735660553}, {"text": "BoC", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.7667914032936096}]}, {"text": "We explore whether word embeddings as a medium for generating BoC are more effective than the direct use of sentence embeddings in cases where the dataset is small and knowledge domain is restricted to the specific domain of breast cancer treatment.", "labels": [], "entities": [{"text": "generating BoC", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7094729244709015}]}, {"text": "We also explore the combination of BoC and sentence embeddings feature, in order to investigate how best to make integration of them Finally, we explore the possibility of applying more complex models for analysis of our small and specific knowledge domain dataset.", "labels": [], "entities": []}, {"text": "We start from simple linear models including logistic regression and lin-SVM, then apply rbf-SVM, feedforward ANN on Keras with 32 batch per time, and epochs of 2, 10, 100, and 500 for each relation type.", "labels": [], "entities": []}, {"text": "We evaluate both overall and per relation type performance.", "labels": [], "entities": []}, {"text": "Evaluation of the two approaches is performed on the same test set derived from the data preparation stage.", "labels": [], "entities": []}, {"text": "In addition, considering the dataset is small, we calculate the mean score from three independent combinations of training, development and test sets.", "labels": [], "entities": [{"text": "mean score", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9251974821090698}]}, {"text": "We evaluate results using micro F 1 -measure since the number of positives and negatives were highly imbalanced across all relation types.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.8095457553863525}]}, {"text": "We finally evaluate the performance growth over nine sub-sampled training sets of increasing size.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of supervised learning models with different features.", "labels": [], "entities": []}, {"text": " Table 2: F 1 score results per relation type of the best performing models.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9767365058263143}]}]}