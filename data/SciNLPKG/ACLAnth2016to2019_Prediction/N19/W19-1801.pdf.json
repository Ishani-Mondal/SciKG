{"title": [{"text": "Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects", "labels": [], "entities": [{"text": "Adversarial Regularization", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8153956830501556}, {"text": "Visual Question Answering", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.5895137985547384}]}], "abstractContent": [{"text": "Visual question answering (VQA) models have been shown to over-rely on linguistic biases in VQA datasets, answering questions \"blindly\" without considering visual context.", "labels": [], "entities": [{"text": "Visual question answering (VQA)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7529522826274236}, {"text": "VQA datasets", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.8422335982322693}]}, {"text": "Adversarial regularization (AdvReg) aims to address this issue via an adversary sub-network that encourages the main model to learn a bias-free representation of the question.", "labels": [], "entities": [{"text": "Adversarial regularization (AdvReg", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8043206632137299}]}, {"text": "In this work, we investigate the strengths and shortcomings of AdvReg with the goal of better understanding how it affects inference in VQA models.", "labels": [], "entities": []}, {"text": "Despite achieving anew state-of-the-art on VQA-CP, we find that AdvReg yields several undesirable side-effects, including unstable gradients and sharply reduced performance on in-domain examples.", "labels": [], "entities": [{"text": "VQA-CP", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.8806964159011841}]}, {"text": "We demonstrate that gradual introduction of regu-larization during training helps to alleviate, but not completely solve, these issues.", "labels": [], "entities": []}, {"text": "Through error analyses, we observe that AdvReg improves generalization to binary questions, but impairs performance on questions with heterogeneous answer distributions.", "labels": [], "entities": []}, {"text": "Qualitatively, we also find that regularized models tend to over-rely on visual features, while ignoring important linguistic cues in the question.", "labels": [], "entities": []}, {"text": "Our results suggest that AdvReg requires further refinement before it can be considered a viable bias mitigation technique for VQA.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, the Visual Question Answering (VQA) community has grown increasingly cognizant of the confounding role that bias plays in VQA research.", "labels": [], "entities": [{"text": "Visual Question Answering (VQA)", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.7815252443154653}]}, {"text": "Many popular VQA datasets have been shown to contain systematic language biases that enable models to cheat by answering questions \"blindly\" without considering visual context ().", "labels": [], "entities": [{"text": "VQA datasets", "start_pos": 13, "end_pos": 25, "type": "DATASET", "confidence": 0.7899869680404663}]}, {"text": "Efforts to address this problem have mainly focused on constructing more balanced datasets (.", "labels": [], "entities": []}, {"text": "However, any benchmark that involves crowdsourced data is likely to encode certain cognitive and/or social biases).", "labels": [], "entities": []}, {"text": "An alternate approach is to develop models that can generalize to novel domains with different biases.", "labels": [], "entities": []}, {"text": "In this spirit,  introduced VQA under Changing Priors (VQA-CP), anew benchmark in which the distribution of answers varies significantly between train and test splits.", "labels": [], "entities": [{"text": "VQA", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.7487951517105103}, {"text": "VQA-CP)", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.6769583523273468}]}, {"text": "Existing models, which tend to rely heavily on the distribution of answers in the training set, perform poorly on VQA-CP ( . One approach to mitigating bias that has recently gained interest is a technique called adversarial regularization (AdvReg).", "labels": [], "entities": [{"text": "VQA-CP", "start_pos": 114, "end_pos": 120, "type": "DATASET", "confidence": 0.7726487517356873}]}, {"text": "In AdvReg, an adversary sub-network performs an inference task based on a subset of the input features; in this case, the adversary attempts to predict answers based only on the question.", "labels": [], "entities": []}, {"text": "Successful performance by the adversary indicates that the main network has learned a biased input representation.", "labels": [], "entities": []}, {"text": "Negated gradient updates from the adversary are backpropagated to a shared encoder to encourage the main network to learn a bias-neutral representation of the question.", "labels": [], "entities": []}, {"text": "Recently, applied AdvReg to VQA and found that it improves generalization to out-of-domain examples on VQA-CP test.", "labels": [], "entities": [{"text": "VQA", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.9075458645820618}, {"text": "VQA-CP test", "start_pos": 103, "end_pos": 114, "type": "DATASET", "confidence": 0.9452421963214874}]}, {"text": "Despite this initial success, AdvReg is still a relatively new methodology, and its effects on representation learning in neural networks remain largely unknown.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.929466962814331}]}, {"text": "In this study, we explore AdvReg with the goal of better understanding how this technique affects inference in VQA models.", "labels": [], "entities": []}, {"text": "We apply AdvReg to the Pythia VQA architec-ture (, achieving anew stateof-the-art on VQA-CP v1 and v2.", "labels": [], "entities": [{"text": "Pythia VQA architec-ture", "start_pos": 23, "end_pos": 47, "type": "DATASET", "confidence": 0.817150870958964}]}, {"text": "However, we find that AdvReg yields a number of previously unreported and undesirable side-effects.", "labels": [], "entities": []}, {"text": "We first observe that AdvReg introduces significant noise into gradient updates that creates instability during training.", "labels": [], "entities": []}, {"text": "This finding motivates the introduction of anew scheduling technique that gradually introduces regularization over the course of training.", "labels": [], "entities": []}, {"text": "We find that scheduling improves gradient stability in the early phases of adversarial training and improves performance on VQA-CP v2.", "labels": [], "entities": []}, {"text": "However, even with scheduling, AdvReg significantly reduces performance on in-domain examples.", "labels": [], "entities": []}, {"text": "This side-effect suggests that like many statistical regularization methods, AdvReg offers a trade-off between in-domain and out-of-domain performance.", "labels": [], "entities": []}, {"text": "To investigate the strengths and weaknesses of regularized models, we perform quantitative and qualitative error analyses.", "labels": [], "entities": []}, {"text": "We find that AdvReg is especially helpful with Yes/No questions, but reduces performance on questions with heterogeneous answers.", "labels": [], "entities": []}, {"text": "We also visualize a number of successes and failures of AdvReg, revealing that regularized models often ignore linguistic cues in the question and are heavily swayed by salient visual features.", "labels": [], "entities": []}, {"text": "These findings suggest an underutilization of key information in the question.", "labels": [], "entities": []}, {"text": "The contributions of this work are two-fold.", "labels": [], "entities": []}, {"text": "First, we share practical tips for dealing with the idiosyncrasies of AdvReg.", "labels": [], "entities": []}, {"text": "Second, we highlight some core drawbacks of AdvReg that have not previously been reported in the literature.", "labels": [], "entities": []}, {"text": "By drawing attention to these shortcomings, we hope to motivate future efforts to refine AdvReg.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance comparison of baseline and adversarially-trained models on VQA-CP/VQA v1 and v2  datasets using the best-performing hyperparameters.", "labels": [], "entities": [{"text": "VQA-CP/VQA v1 and v2  datasets", "start_pos": 81, "end_pos": 111, "type": "DATASET", "confidence": 0.8374566095215934}]}]}