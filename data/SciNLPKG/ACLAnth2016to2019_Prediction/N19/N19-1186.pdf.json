{"title": [{"text": "Word Embedding-Based Automatic MT Evaluation Metric using Word Position Information", "labels": [], "entities": [{"text": "MT Evaluation Metric", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.8563626408576965}]}], "abstractContent": [{"text": "We propose anew automatic evaluation metric for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8083126544952393}]}, {"text": "Our proposed metric is obtained by adjusting the Earth Mover's Distance (EMD) to the evaluation task.", "labels": [], "entities": [{"text": "Earth Mover's Distance (EMD)", "start_pos": 49, "end_pos": 77, "type": "METRIC", "confidence": 0.6692023873329163}]}, {"text": "The EMD measure is used to obtain the distance between two probability distributions consisting of some signatures having a feature and a weight.", "labels": [], "entities": [{"text": "EMD measure", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9705353677272797}]}, {"text": "We use word embeddings, sentence-level tf \u00b7 idf , and cosine similarity between two word embeddings, respectively, as the features, weight, and the distance between two features.", "labels": [], "entities": []}, {"text": "Results show that our proposed metric can evaluate machine translation based on word meaning.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7420620918273926}]}, {"text": "Moreover, for distance, cosine similarity and word position information are used to address word-order differences.", "labels": [], "entities": []}, {"text": "We designate this metric as Word Embedding-based automatic MT evaluation using Word Position Information (WE WPI).", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.9066188931465149}]}, {"text": "A meta-evaluation using WMT16 metrics shared task set indicates that our WE WPI achieves the highest correlation with human judgment among several representative metrics.", "labels": [], "entities": [{"text": "WMT16 metrics shared task set", "start_pos": 24, "end_pos": 53, "type": "DATASET", "confidence": 0.8352064490318298}, {"text": "WE WPI", "start_pos": 73, "end_pos": 79, "type": "DATASET", "confidence": 0.6434520184993744}]}], "introductionContent": [{"text": "Recent advances in neural machine translation (NMT)) are remarkable.", "labels": [], "entities": [{"text": "neural machine translation (NMT))", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.8340865870316824}]}, {"text": "Results based on human evaluation have demonstrated that NMT outperforms statistical machine translations significantly ().", "labels": [], "entities": [{"text": "statistical machine translations", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.6105797489484152}]}, {"text": "The NMT achieved especially high performance in terms of fluency.", "labels": [], "entities": [{"text": "NMT", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.5888863801956177}]}, {"text": "However, it tends to generate more omission errors than statistical machine translations generate.", "labels": [], "entities": [{"text": "statistical machine translations", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.6361198425292969}]}, {"text": "Unfortunately, it is difficult for automatic evaluation metrics to evaluate outputs with omission errors because those errors are not included as non-match words between the translation and reference.", "labels": [], "entities": []}, {"text": "For such cases, the word embedding-based automatic MT evaluation metric, which is based on word position information, is effective.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.8828814625740051}]}, {"text": "Various automatic evaluation metrics have been proposed for machine translation, but none is sufficient for NMT.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8164852857589722}, {"text": "NMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.8987588286399841}]}, {"text": "Actually, BLEU () is the representative metric based on ngram matching.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989029169082642}]}, {"text": "Unfortunately, because it is a surface-level metric, it is difficult to address word meaning during evaluation for MT outputs.", "labels": [], "entities": [{"text": "MT outputs", "start_pos": 115, "end_pos": 125, "type": "TASK", "confidence": 0.9368180930614471}]}, {"text": "The word-embedding-based distance measure for document () and the word-alignment-based automatic evaluation metric using word embedding ( are effective to address word meanings.", "labels": [], "entities": []}, {"text": "Nevertheless, they can only ineffectively accommodate word order differences between the translation and reference.", "labels": [], "entities": []}, {"text": "Given those circumstances, anew metric with word embedding-based automatic MT evaluation metric using word position information is proposed in which the evaluation score is obtained by adjusting the Earth Mover's Distance (EMD) () to the evaluation task.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.8828113079071045}, {"text": "Earth Mover's Distance (EMD)", "start_pos": 199, "end_pos": 227, "type": "METRIC", "confidence": 0.6475287803581783}]}, {"text": "The EMD measure represents the distance between two probability distributions.", "labels": [], "entities": [{"text": "EMD measure", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9706363379955292}]}, {"text": "Moreover, the EMD distance is obtained based on a signature consisting of the feature and the weight, and the distance between two features.", "labels": [], "entities": [{"text": "EMD distance", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.9522198736667633}]}, {"text": "The feature, weight, and distance must therefore be defined to adjust EMD to the evaluation task.", "labels": [], "entities": []}, {"text": "In our proposed metric, the word embeddings and the sentence-level tf \u00b7 idf respectively denote the feature and the weight.", "labels": [], "entities": []}, {"text": "Consequently, our proposed metric can produce an evaluation based on the word meaning.", "labels": [], "entities": []}, {"text": "Moreover, our proposed metric uses word position information in the distance between two word embeddings.", "labels": [], "entities": []}, {"text": "The distance is obtained using cosine similarity and the difference of word position between the translation and reference.", "labels": [], "entities": []}, {"text": "Results demonstrate that our proposed metric can evaluate translations also considering word order differences.", "labels": [], "entities": [{"text": "translations", "start_pos": 58, "end_pos": 70, "type": "TASK", "confidence": 0.9737803936004639}]}, {"text": "We designate this new metric as Word Embedding-based automatic MT evaluation using Word Position Information (WE WPI).", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9015873968601227}]}, {"text": "The experimentally obtained results based on the WMT16 metrics shared task () demonstrated that our WE WPI achieves the highest correlation with human judgment among several metrics: BLEU, METEOR), IM-PACT, and RIBES (.", "labels": [], "entities": [{"text": "WMT16 metrics shared task", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.7711304277181625}, {"text": "WE WPI", "start_pos": 100, "end_pos": 106, "type": "DATASET", "confidence": 0.5582736432552338}, {"text": "BLEU", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.9982189536094666}, {"text": "METEOR", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.8993965983390808}, {"text": "IM-PACT", "start_pos": 198, "end_pos": 205, "type": "METRIC", "confidence": 0.6770053505897522}, {"text": "RIBES", "start_pos": 211, "end_pos": 216, "type": "METRIC", "confidence": 0.9594653844833374}]}, {"text": "Moreover, the correlation of WE WPI is better than that of WE WPI without word position information.", "labels": [], "entities": [{"text": "correlation", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.9712939262390137}, {"text": "WE WPI", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.5541435778141022}, {"text": "WE WPI", "start_pos": 59, "end_pos": 65, "type": "DATASET", "confidence": 0.7854667603969574}]}, {"text": "Results therefore confirmed the effectiveness of WE WPI using word position information.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 49, "end_pos": 55, "type": "TASK", "confidence": 0.7474077641963959}]}, {"text": "proposed the Word Mover's Distance (WMD) as a distance measure using word embedding and word alignment.", "labels": [], "entities": [{"text": "Word Mover's Distance (WMD)", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.5466422651495252}, {"text": "word alignment", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.7529357671737671}]}, {"text": "This measure obtains the distance between two documents adjusting EMD to a document.", "labels": [], "entities": [{"text": "EMD", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.8366960287094116}]}, {"text": "However, it cannot accommodate differences of word order between the translation and reference.", "labels": [], "entities": []}, {"text": "also proposed a word-alignment-based automatic evaluation metric using word embeddings for segment-level evaluation.", "labels": [], "entities": []}, {"text": "As described in that paper, Maximum Alignment Similarity (MAS) was found to have higher correlation with human evaluation than BLEU for European-to-English, which has similar grammar structures.", "labels": [], "entities": [{"text": "Maximum Alignment Similarity (MAS)", "start_pos": 28, "end_pos": 62, "type": "METRIC", "confidence": 0.8684251209100088}, {"text": "BLEU", "start_pos": 127, "end_pos": 131, "type": "METRIC", "confidence": 0.9976893663406372}]}, {"text": "For Japanese-toEnglish, which has different grammar structures, Average Alignment Similarity (AAS) showed better correlation with human evaluation than other metrics.", "labels": [], "entities": [{"text": "Average Alignment Similarity (AAS)", "start_pos": 64, "end_pos": 98, "type": "METRIC", "confidence": 0.9412158032258352}]}, {"text": "However, neither MAS nor AAS uses word position information.", "labels": [], "entities": [{"text": "MAS", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.6192434430122375}, {"text": "AAS", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.5859389305114746}]}, {"text": "Therefore, neither can sufficiently accommodate word order differences.", "labels": [], "entities": []}, {"text": "Actually, WE WPI uses not only the word alignment but also word position information.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.8232981562614441}, {"text": "word alignment", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.6414800137281418}]}], "datasetContent": [{"text": "WE WPI  We obtain WE WPI as new automatic MT evaluation metrics by adjusting EMD to the automatic MT evaluation task.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.8732762038707733}, {"text": "MT evaluation", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.9151700139045715}, {"text": "EMD", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9592944383621216}, {"text": "MT evaluation task", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9053182403246561}]}, {"text": "In WE WPI, the variables P and Q in respectively correspond to a translation T and reference R.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.7557432353496552}]}, {"text": "Moreover, the features (i.e., pi and q j in, the weight (i.e., w pi and w q j in, and distance (i.e., d ij in) are required as parameters to adjust EMD to the automatic MT evaluation task.", "labels": [], "entities": [{"text": "MT evaluation task", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.9262848496437073}]}, {"text": "As described herein, we use the word embeddings as features and the sentence-level tf \u00b7 idf as the weight.", "labels": [], "entities": []}, {"text": "The weight definition is presented in Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 38, "end_pos": 40, "type": "DATASET", "confidence": 0.925317645072937}]}, {"text": "In Eq., tf denotes the appearance frequency of a word in a translation or reference.", "labels": [], "entities": []}, {"text": "In addition, df represents the number of sentences in which the word appears in all translations or references.", "labels": [], "entities": []}, {"text": "In addition, N is the total number of translations or references.", "labels": [], "entities": []}, {"text": "Actually, WE WPI distinguishes the function word and the content word using Eq.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.6921443939208984}]}, {"text": "Furthermore, wt i of the word in the translation and w r i of the word in the reference by Eq.", "labels": [], "entities": []}, {"text": "(9) are normalized respectively using the following Eqs.", "labels": [], "entities": [{"text": "Eqs", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9075407385826111}]}, {"text": "(10) and (11).", "labels": [], "entities": []}, {"text": "The dependence of win Eq.", "labels": [], "entities": []}, {"text": "(9) by difference of dataset can be kept to the minimum by normalizing Eqs.", "labels": [], "entities": [{"text": "Eqs", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.8706815838813782}]}, {"text": "(10) and (11).", "labels": [], "entities": []}, {"text": "Moreover, we define distance d ij , which is ascertained from the result of the word alignment described in 3.2.1.", "labels": [], "entities": []}, {"text": "The d ij is obtained using the following Eq.: presents the distance matrix between the translation \"Are there topics that you think should discuss world?\" and the reference \"Are there topics you want to get the world talking about?\" in.", "labels": [], "entities": [{"text": "Eq.", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9477529525756836}]}, {"text": "In, the bold typeface represents the distance between the two aligned words.", "labels": [], "entities": []}, {"text": "The distance matrix using Eq. is effective because it is not influenced by the words which are not aligned between the translation and reference.", "labels": [], "entities": []}, {"text": "The WE WPI obtains the evaluation score byword embedding, sentence-level tf \u00b7 idf , and the distance matrix based on Eq.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.7345775067806244}]}, {"text": "The evaluation score of WE WPI is obtained as Eq..", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 24, "end_pos": 30, "type": "TASK", "confidence": 0.42385628819465637}, {"text": "Eq.", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9915539622306824}]}, {"text": "f ij becomes 0.0-1.0 using the weights normalized by Eqs. and.", "labels": [], "entities": [{"text": "Eqs.", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9566287994384766}]}, {"text": "Near 0.0, the distance between T and R is small.", "labels": [], "entities": []}, {"text": "However, in the automatic MT evaluation metrics, the score is close to 1.0 when the evaluation for the translation is generally high.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.9078269302845001}]}, {"text": "Therefore, we obtain W E WP I by taking the value of f ij from 1.0.", "labels": [], "entities": []}, {"text": "As a result, in between the translation \"Are there topics that you think should discuss world?\" and the reference \"Are there topics you want to get the world talking about?\", 0.608 is obtained as the score using Eq.", "labels": [], "entities": []}, {"text": "The WE WPI can evaluate the translation based on the meanings of words using word embedding.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.8092092275619507}]}, {"text": "Moreover, it can deal with the word order using the relative difference between the positions of words in the translation and the reference.", "labels": [], "entities": []}, {"text": "We conducted evaluation experiments to confirm the effectiveness of WE WPI.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 68, "end_pos": 74, "type": "TASK", "confidence": 0.5245585888624191}]}, {"text": "The \"newstest2016\" set, which is the main test set in WMT16 metrics shared task (, was used.", "labels": [], "entities": [{"text": "newstest2016\" set", "start_pos": 5, "end_pos": 22, "type": "DATASET", "confidence": 0.7934411962827047}, {"text": "WMT16 metrics shared task", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.6209319084882736}]}, {"text": "The script is available at http://www.statmt.org/wmt16/results.html.", "labels": [], "entities": []}, {"text": "Therefore, we can readily obtain the correlation coefficient between the metrics and human judgments in WMT16 metrics shared task.", "labels": [], "entities": [{"text": "WMT16 metrics shared task", "start_pos": 104, "end_pos": 129, "type": "DATASET", "confidence": 0.8288164138793945}]}, {"text": "The WMT16 metrics task includes English paired with Czech, German, Finnish, Romanian, Russian, and Turkish.", "labels": [], "entities": [{"text": "WMT16 metrics task", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.3790970842043559}]}, {"text": "For all translations, references and scores by human judgment in these language pairs are obtained from the url described above.", "labels": [], "entities": []}, {"text": "For these experiments, we used different automatic MT evaluation metrics for comparison with our WE WPI: BLEU, METEOR, IMPACT, RIBES, and WE.", "labels": [], "entities": [{"text": "MT", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9804518818855286}, {"text": "WE WPI", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.7296740710735321}, {"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9903424978256226}, {"text": "METEOR", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9792124032974243}, {"text": "IMPACT", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9525496959686279}, {"text": "RIBES", "start_pos": 127, "end_pos": 132, "type": "METRIC", "confidence": 0.9785168766975403}, {"text": "WE", "start_pos": 138, "end_pos": 140, "type": "METRIC", "confidence": 0.8345924615859985}]}, {"text": "Here, IMPACT and RIBES, which are surface-based metrics, are effective for language pairs with greatly different word order, such as English and Japanese.", "labels": [], "entities": [{"text": "IMPACT", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9203829765319824}, {"text": "RIBES", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9738563895225525}]}, {"text": "In addition, WE is an automatic MT evaluation metric that does not perform word alignment.", "labels": [], "entities": [{"text": "WE", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.6646038889884949}, {"text": "MT evaluation", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.9268019199371338}, {"text": "word alignment", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7510274052619934}]}, {"text": "It uses only d ij = 1.0 \u2212 cos sim(t i , r j ) as the d ij of Eq. in the WE WPI.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 72, "end_pos": 78, "type": "DATASET", "confidence": 0.9426295459270477}]}, {"text": "In both WE and WE WPI, the word vectors for seven languages (i.e., English, Czech, German, Finnish, Romanian, Russian, and Turkish) were obtained using fastText ().", "labels": [], "entities": [{"text": "WE", "start_pos": 8, "end_pos": 10, "type": "DATASET", "confidence": 0.8006889224052429}, {"text": "WE WPI", "start_pos": 15, "end_pos": 21, "type": "DATASET", "confidence": 0.835724264383316}]}, {"text": "respectively present the correlation coefficient of to-English and out-of-English at the system level.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 25, "end_pos": 48, "type": "METRIC", "confidence": 0.9682838618755341}]}, {"text": "respectively present the correlation coefficients of to-English and outof-English at the segment level.", "labels": [], "entities": []}, {"text": "In, RR represents the correlation based on the relative ranking by human judgment to 5 translations at a time.", "labels": [], "entities": [{"text": "RR", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.974886953830719}]}, {"text": "The bold typeface shows the highest correlation coefficient among all correlation coefficients of metrics.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 36, "end_pos": 59, "type": "METRIC", "confidence": 0.9755329489707947}]}, {"text": "Moreover, the coefficients of MEANT 2.0 described in are added to.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9072695374488831}]}, {"text": "Here, WE WPI achieves the highest correlation with human judgment in, DA in Table 6, and.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 6, "end_pos": 12, "type": "TASK", "confidence": 0.44694794714450836}, {"text": "DA", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9976118803024292}]}, {"text": "Especially, the correlation coefficients of WE WPI are high with language pairs for which the grammar differs (i.e., Englishto-German (en-de), German-to-English (de-en),: To-English system-level metric significance test of results for human assessment variants, where DA denotes the direct assessment of translation adequacy.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 44, "end_pos": 50, "type": "TASK", "confidence": 0.4340308904647827}, {"text": "DA", "start_pos": 268, "end_pos": 270, "type": "METRIC", "confidence": 0.9854834079742432}]}, {"text": "Green cells show a significant increase in correlation with human assessment for the metric in a given row over the metric in a given column according to the Williams test.", "labels": [], "entities": []}, {"text": "Figure 5: To-English system-level metric significance test of results for human assessment variants, where RR denotes the standard WMT relative ranking for the translation task system only.", "labels": [], "entities": [{"text": "RR", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9929118752479553}]}, {"text": "Green cells show a significant increase in correlation with human assessment for the metric in a given row over the metric in a given column according to the Williams test.: English-to-Russian system-level metric significance test of results for human assessment variants, where DA denotes direct assessment of translation adequacy.", "labels": [], "entities": [{"text": "DA", "start_pos": 279, "end_pos": 281, "type": "METRIC", "confidence": 0.9807248115539551}]}, {"text": "Green cells show a significant increase in correlation with human assessment for the metric in a given row over the metric in a given column according to the Williams test.", "labels": [], "entities": []}, {"text": "English-to-Turkish (en-tr), and Turkish-to-English (tr-en)).", "labels": [], "entities": []}, {"text": "Therefore, the WE WPI is effective with such language pairs because it uses word position information.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 15, "end_pos": 21, "type": "TASK", "confidence": 0.5619567334651947}]}, {"text": "Moreover, we investigated the significance of WE WPI results and those of other metrics except those of MEANT 2.0 and MEANT 2.0 -nosrl.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.47836731374263763}, {"text": "MEANT", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.5481178760528564}, {"text": "MEANT 2.0 -nosrl", "start_pos": 118, "end_pos": 134, "type": "METRIC", "confidence": 0.5515265911817551}]}, {"text": "As described herein, Williams significance test was used to assess differences in dependent correlations.", "labels": [], "entities": [{"text": "Williams significance test", "start_pos": 21, "end_pos": 47, "type": "METRIC", "confidence": 0.9334190885225931}]}, {"text": "present significance test results for every competing pair of metrics, including those of our WE WPI.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 94, "end_pos": 100, "type": "DATASET", "confidence": 0.9080367088317871}]}, {"text": "However, the language pairs for which significant differences could not be obtained in any competing pair of metrics are excluded from Figures 4-9 (i.e., cs-en and fi-en in, cs-en, fi-en and ro-en in, en-cs in).", "labels": [], "entities": []}, {"text": "In, green cells signify that the metric shows significant difference from other metrics with 95% or greater confidence.", "labels": [], "entities": []}, {"text": "Results demonstrated that our WE WPI yielded significantly different results among metrics.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.606573686003685}]}, {"text": "Particularly, WE WPI was found to have significantly better results than those of WE at the segment level, as shown in.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 14, "end_pos": 20, "type": "TASK", "confidence": 0.4354405999183655}]}, {"text": "This particular result demonstrates that the word position information in WE WPI is effective for segment-level evaluation.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 74, "end_pos": 80, "type": "DATASET", "confidence": 0.6714937388896942}]}, {"text": "Moreover, WE WPI does not need much time to calculate the scores described in 3.2.2.", "labels": [], "entities": [{"text": "WE WPI", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.8141706585884094}]}, {"text": "However, it takes time to calculate tf \u00b7 idf of words and to change the surface-level words to the word vectors.", "labels": [], "entities": []}, {"text": "It is efficient to calculate tf \u00b7 idf of all words in the translations and references, and to extract the word vectors, which correspond to the words in the translations and references, from the fastText models in advance.: Out-of-English system-level metric significance test of results for human assessment variants, where RR denotes the standard WMT relative ranking for translation task system only.", "labels": [], "entities": [{"text": "RR", "start_pos": 325, "end_pos": 327, "type": "METRIC", "confidence": 0.9872181415557861}]}, {"text": "Green cells show a significant increase in correlation with human assessment for the metric in a given row over the metric in a given column according to the Williams test.: To-English segment-level metric significance test of results for human assessment variants, where DA denotes direct assessment of translation adequacy.", "labels": [], "entities": [{"text": "DA", "start_pos": 272, "end_pos": 274, "type": "METRIC", "confidence": 0.9731506109237671}]}, {"text": "Green cells show marked benefits obtained with the metric in a given row over the metric in a given column according to the Williams test.: English-to-Russian segment-level metric significance test of results for human assessment variants, where DA denotes direct assessment of translation adequacy: green cells show marked benefits obtained with the metric in a given row over the metric in a given column according to the Williams test.", "labels": [], "entities": [{"text": "Williams test", "start_pos": 424, "end_pos": 437, "type": "DATASET", "confidence": 0.9065233767032623}]}], "tableCaptions": [{"text": " Table 1: Examples of signatures of P .", "labels": [], "entities": []}, {"text": " Table 2: Examples of signatures of Q.", "labels": [], "entities": []}, {"text": " Table 3: Distance matrix incorporating translation and reference.", "labels": [], "entities": [{"text": "translation", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.9644811749458313}]}, {"text": " Table 4: Absolute Pearson correlation of to-English system-level metric with human assessment variants: RR,  standard WMT relative ranking; DA, direct assessment of translation adequacy.", "labels": [], "entities": [{"text": "Absolute Pearson correlation", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.8207839926083883}, {"text": "RR", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9535164833068848}, {"text": "DA", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.9453761577606201}]}, {"text": " Table 5: Absolute Pearson correlation of out-of-English system-level metric with human assessment variants: RR,  standard WMT relative ranking; DA, direct assessment of translation adequacy.", "labels": [], "entities": [{"text": "Absolute Pearson correlation", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.8147862752278646}, {"text": "RR", "start_pos": 109, "end_pos": 111, "type": "METRIC", "confidence": 0.9547534584999084}, {"text": "DA", "start_pos": 145, "end_pos": 147, "type": "METRIC", "confidence": 0.9288617372512817}]}, {"text": " Table 6: Segment-level metric results for to-English language pairs with absolute values of correlation coefficients  reported for all metrics: correlation of segment-level metric scores with human assessment variants, where \u03c4 are  official results computed similarly to Kendall's \u03c4 and over standard WMT relative ranking (RR) human assess- ments; r are Pearson correlation coefficients of metric scores with direct assessment (DA) of absolute translation  adequacy.", "labels": [], "entities": []}]}