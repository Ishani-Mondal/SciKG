{"title": [{"text": "Simple Attention-Based Representation Learning for Ranking Short Social Media Posts", "labels": [], "entities": [{"text": "Simple Attention-Based Representation Learning", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7015638425946236}, {"text": "Ranking Short Social Media Posts", "start_pos": 51, "end_pos": 83, "type": "TASK", "confidence": 0.633157205581665}]}], "abstractContent": [{"text": "This paper explores the problem of ranking short social media posts with respect to user queries using neural networks.", "labels": [], "entities": []}, {"text": "Instead of starting with a complex architecture, we proceed from the bottom up and examine the effectiveness of a simple, word-level Siamese architecture augmented with attention-based mechanisms for capturing semantic \"soft\" matches between query and post tokens.", "labels": [], "entities": []}, {"text": "Extensive experiments on datasets from the TREC Mi-croblog Tracks show that our simple models not only achieve better effectiveness than existing approaches that are far more complex or exploit a more diverse set of relevance signals , but are also much faster.", "labels": [], "entities": [{"text": "TREC Mi-croblog Tracks", "start_pos": 43, "end_pos": 65, "type": "DATASET", "confidence": 0.8917118708292643}]}, {"text": "Implementations of our samCNN (Simple Attention-based Matching CNN) models are shared with the community to support future work.", "labels": [], "entities": [{"text": "Simple Attention-based Matching CNN)", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.5926150798797607}]}], "introductionContent": [{"text": "Despite a large body of work on neural ranking models for \"traditional\" ad hoc retrieval over web pages and newswire documents, there has been surprisingly little work () on applying neural networks to searching short social media posts such as tweets on Twitter.", "labels": [], "entities": []}, {"text": "identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling, and proposed the first neural model specifically designed to handle these characteristics.", "labels": [], "entities": [{"text": "relevance modeling", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.9339317977428436}]}, {"text": "Evaluation on a number of datasets from the TREC Microblog Tracks demonstrates state-of-the-art effectiveness as  \u00ed \u00b5\u00ed\u00b1\u009c Figure 1: Our model architecture: a general sentence encoder is applied on query and post embeddings to generate g q and g p ; an attention encoder is applied on post embeddings to generate variable-length queryaware features hi . These features are further aggregated to yield v, which feeds into the final prediction.", "labels": [], "entities": [{"text": "TREC Microblog Tracks", "start_pos": 44, "end_pos": 65, "type": "DATASET", "confidence": 0.9450032711029053}]}, {"text": "In this paper, we also examine the problem of modeling relevance for ranking short social media posts, but from a complementary perspective.", "labels": [], "entities": []}, {"text": "As notes, most systems are builtin a top-down process: authors propose a complex architecture and then validate design decisions with ablation experiments.", "labels": [], "entities": []}, {"text": "However, such experiments often lack comparisons to strong baselines, which raises the question as to whether model complexity is empirically justified.", "labels": [], "entities": []}, {"text": "As an alternative, they advocate a bottom-up approach where architectural complexity is gradually increased.", "labels": [], "entities": []}, {"text": "We adopt exactly such an approach, focused exclusively on word-level modeling.", "labels": [], "entities": []}, {"text": "As shown in, we examine variants of a simple, generic architecture that has emerged as \"best practices\" in the NLP community for tackling modeling problems on two input sequences: a Siamese CNN architecture for learning representations over both inputs (a query and asocial media post in our case), followed by fully-connected layers that produce a final relevance prediction; Rao architecture on the right.", "labels": [], "entities": []}, {"text": "In both, we construct F convolutional kernels for each query token (here, one kernel for the query token 'Evernote' is visualized).", "labels": [], "entities": []}, {"text": "In QAtt, the query token embedding is directly \"injected\" into the kernel via element-wise product (blue dotted arrows).", "labels": [], "entities": []}, {"text": "In PAtt, cosine similarity between the query token and tokens in the post within the convolution window are used as attention weights in the kernel.", "labels": [], "entities": []}, {"text": "et al., 2016), which we refer to as a General Sentence Encoder in Section 2.1.", "labels": [], "entities": []}, {"text": "Further adopting best practices, we incorporate query-aware convolutions with an average aggregation layer in the representation learning process.", "labels": [], "entities": []}, {"text": "Recently, a number of researchers () have started to reexamine simple baselines and found them to be highly competitive with the state of the art, especially with proper tuning.", "labels": [], "entities": []}, {"text": "For example, the InferSent approach () uses a simple BiLSTM with max pooling that achieves quite impressive accuracy on several classification benchmarks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.998863697052002}]}, {"text": "Our contribution is along similar lines, where we explore simple yet highly effective models for ranking social media posts, to gain insights into query-post relevance matching using standard neural architectures.", "labels": [], "entities": [{"text": "query-post relevance matching", "start_pos": 147, "end_pos": 176, "type": "TASK", "confidence": 0.6079986989498138}]}, {"text": "Experiments with TREC Microblog datasets show that our best model not only achieves better effectiveness than existing approaches that leverage more signals, but also demonstrates 4\u00d7 speedup in model training and inference compared to a recently-proposed neural model.", "labels": [], "entities": [{"text": "TREC Microblog datasets", "start_pos": 17, "end_pos": 40, "type": "DATASET", "confidence": 0.9481152693430582}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of TREC MB 2011-2014 datasets.", "labels": [], "entities": [{"text": "TREC MB 2011-2014 datasets", "start_pos": 24, "end_pos": 50, "type": "DATASET", "confidence": 0.8914502859115601}]}, {"text": " Table 2: Hyperparameters for our models. GloVe (Pen- nington et al., 2014) embeddings are used and fine- tuned during training. Unknown words are initialized  from a uniform distribution [\u2212k, k].", "labels": [], "entities": [{"text": "GloVe", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.7564800381660461}]}, {"text": " Table 3: Results of various models on the TREC Microblog Tracks datasets. Models 5-8 are copied from Rao  et al. (2019); note that MP-HCNN exploits URL information (+URL). Models with +QL include interpolation  with the QL baseline. BiCNN denotes our general sentence encoder architecture, with either query-aware attention  (QAtt) or position-aware attention (PAtt). Superscripts and subscripts indicate the row indexes for which a metric  difference is statistically significant at p < 0.05.", "labels": [], "entities": [{"text": "TREC Microblog Tracks datasets", "start_pos": 43, "end_pos": 73, "type": "DATASET", "confidence": 0.9475969672203064}, {"text": "position-aware attention (PAtt)", "start_pos": 336, "end_pos": 367, "type": "METRIC", "confidence": 0.7271392345428467}]}, {"text": " Table 4: Matching patterns for the worst-performing  query 127 \"Oscars snub Affleck\".", "labels": [], "entities": []}, {"text": " Table 4. The PAtt model indeed captures matching  patterns, mostly on Oscars and Affleck. However,  from the relevance judgments we see that snub is  the dominant term in most relevant posts, while  Oscars is often expressed implicitly. For example,  QL assigns more weight to the term snub in the  relevant post \"argo wins retributions for the snub", "labels": [], "entities": []}]}