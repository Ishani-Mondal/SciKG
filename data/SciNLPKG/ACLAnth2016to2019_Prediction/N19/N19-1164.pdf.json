{"title": [{"text": "Microblog Hashtag Generation via Encoding Conversation Contexts", "labels": [], "entities": [{"text": "Microblog Hashtag Generation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7767102718353271}]}], "abstractContent": [{"text": "Automatic hashtag annotation plays an important role in content understanding for mi-croblog posts.", "labels": [], "entities": [{"text": "content understanding", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.743281900882721}]}, {"text": "To date, progress made in this field has been restricted to phrase selection from limited candidates, or word-level hash-tag discovery using topic models.", "labels": [], "entities": [{"text": "phrase selection", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.8690509796142578}, {"text": "word-level hash-tag discovery", "start_pos": 105, "end_pos": 134, "type": "TASK", "confidence": 0.6249950528144836}]}, {"text": "Different from previous work considering hashtags to be inseparable, our work is the first effort to annotate hashtags with a novel sequence generation framework via viewing the hashtag as a short sequence of words.", "labels": [], "entities": []}, {"text": "Moreover, to address the data sparsity issue in processing short mi-croblog posts, we propose to jointly model the target posts and the conversation contexts initiated by them with bidirectional attention.", "labels": [], "entities": []}, {"text": "Extensive experimental results on two large-scale datasets, newly collected from English Twit-ter and Chinese Weibo, show that our model significantly outperforms state-of-the-art models based on classification.", "labels": [], "entities": [{"text": "English Twit-ter", "start_pos": 81, "end_pos": 97, "type": "DATASET", "confidence": 0.9300655424594879}, {"text": "Chinese Weibo", "start_pos": 102, "end_pos": 115, "type": "DATASET", "confidence": 0.5834500789642334}]}, {"text": "1 Further studies demonstrate our ability to effectively generate rare and even unseen hashtags, which is however not possible for most existing methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Microblogs have become an essential outlet for individuals to voice opinions and exchange information.", "labels": [], "entities": []}, {"text": "Millions of user-generated messages are produced everyday, far outpacing the human being's reading and understanding capacity.", "labels": [], "entities": []}, {"text": "As a result, the current decade has witnessed the increasing demand for effectively discovering gist information from large microblog texts.", "labels": [], "entities": []}, {"text": "To identify the key content of a microblog post, hashtags, user-generated labels prefixed with a \"#\" (such as \"#NAACL\" and \"#DeepLearning\"), have been", "labels": [], "entities": []}], "datasetContent": [{"text": "Here we describe how we setup our experiments.", "labels": [], "entities": []}, {"text": "Two largescale experiment datasets are newly collected from popular microblog platforms: an English Twitter dataset and a Chinese Weibo dataset.", "labels": [], "entities": [{"text": "English Twitter dataset", "start_pos": 92, "end_pos": 115, "type": "DATASET", "confidence": 0.7215550343195597}, {"text": "Chinese Weibo dataset", "start_pos": 122, "end_pos": 143, "type": "DATASET", "confidence": 0.7164889971415201}]}, {"text": "The Twitter dataset was built based on the TREC 2011 microblog track.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8144729137420654}, {"text": "TREC 2011 microblog track", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.9448617398738861}]}, {"text": "To recover the conversations, we used Tweet Search API to fetch \"in-reply-to\" relations in a recursive way.", "labels": [], "entities": []}, {"text": "The Weibo dataset was collected from January to August 2014 using Weibo Search API via searching messages with the trending queries 4 as keywords.", "labels": [], "entities": [{"text": "Weibo dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9875753819942474}, {"text": "Weibo Search API", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.9394173423449198}]}, {"text": "For goldstandard hashtags, we take the user-annotated hashtags, appearing before or after a post, as the reference.", "labels": [], "entities": []}, {"text": "The statistics of our datasets are shown in.", "labels": [], "entities": []}, {"text": "We randomly split both datasets into three subsets, where 80%, 10%, and 10% of the data corresponds to training, development, and test sets, respectively.", "labels": [], "entities": []}, {"text": "To further investigate how challenging our problem is, we show some statistics of the hashtags in and the distributions of hashtag frequency in.", "labels": [], "entities": []}, {"text": "In  the large size of hashtags in both datasets.", "labels": [], "entities": []}, {"text": "Moreover, indicates that most hashtags only appear a few times.", "labels": [], "entities": []}, {"text": "Given such a large and imbalanced hashtag space, hashtag selection from a candidate list, as many existing methods do, might not perform well.", "labels": [], "entities": [{"text": "hashtag selection", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.8109839856624603}]}, {"text": "also shows that only a small proportion of hashtags appearing in their posts, conversations, and either of them, making it inappropriate to directly extract words from the two sources to form hashtags.", "labels": [], "entities": []}, {"text": "For tokenization and word segmentation, we employed the tweet preprocessing toolkit released by for Twitter, and the Jieba toolkit 6 for Weibo.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9700049757957458}, {"text": "word segmentation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7459190785884857}, {"text": "Weibo", "start_pos": 137, "end_pos": 142, "type": "DATASET", "confidence": 0.6944500207901001}]}, {"text": "Then, for both Twitter and Weibo, we further take the following preprocessing steps: First, single-character hashtags were filtered out for not being meaningful.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 27, "end_pos": 32, "type": "DATASET", "confidence": 0.9488876461982727}]}, {"text": "Second, generic tags, i.e., links, mentions (@username), and numbers, were replaced with \"URL\" \"MENTION\", and \"DIGIT\", respectively.", "labels": [], "entities": [{"text": "MENTION", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9692386388778687}, {"text": "DIGIT", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9789777994155884}]}, {"text": "Third, inappropriate replies (e.g., retweetonly messages) were removed, and the remainder were chronologically ordered to form a sequence as conversation contexts.", "labels": [], "entities": []}, {"text": "Last, a vocabulary was maintained with the 30K and 50K most frequent words, for Twitter and Weibo, respectively.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.9619483351707458}]}, {"text": "For experiment comparisons, we first consider a weak baseline RANDOM that randomly ranks hashtags seen from training data.", "labels": [], "entities": []}, {"text": "Two unsupervised baselines are also considered, where words are ranked by latent topics induced with the latent Dirichlet allocation topic model (henceforth LDA), and by their TF-IDF scores (henceforth TF-IDF).", "labels": [], "entities": []}, {"text": "Here for TF-IDF scores, we consider the N -gram TF-IDF (N \u2264 5).", "labels": [], "entities": []}, {"text": "Besides, we compare with supervised models below: \u2022 EXTRACTOR: Following Zhang et al.", "labels": [], "entities": [{"text": "EXTRACTOR", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9486011266708374}]}, {"text": "(2018), we extract phrases from target posts as hashtags https://pypi.python.org/pypi/jieba/ via sequence tagging and encode conversations with memory networks ().", "labels": [], "entities": []}, {"text": "\u2022 CLASSIFIER: We compare with the state-ofthe-art model based on classification , where hashtags are selected from candidates seen in training data.", "labels": [], "entities": [{"text": "CLASSIFIER", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9024724960327148}]}, {"text": "Here two versions of their classifier are considered, one only taking a target post as input (henceforth CLASSIFIER (post only)) and the other taking the concatenation of a target post and its conversation as input (henceforth CLASSIFIER (post+conv)).", "labels": [], "entities": []}, {"text": "\u2022 GENERATOR: A seq2seq generator (henceforth SEQ2SEQ) () is applied to generate hashtags given a target post.", "labels": [], "entities": [{"text": "GENERATOR", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9229126572608948}]}, {"text": "We also consider its variant augmented with copy mechanism () (henceforth SEQ2SEQ-COPY), which has proven effective in keyphrase generation ( and also takes the post as input.", "labels": [], "entities": [{"text": "keyphrase generation", "start_pos": 119, "end_pos": 139, "type": "TASK", "confidence": 0.8035283088684082}]}, {"text": "The proposed seq2seq with the biattention to encode both the post and its conversation is denoted as OUR MODEL for simplicity.", "labels": [], "entities": [{"text": "OUR", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9940493106842041}, {"text": "MODEL", "start_pos": 105, "end_pos": 110, "type": "METRIC", "confidence": 0.4951525926589966}]}, {"text": "We conduct model tunings on the development set based on grid search, where the hyper-parameters that give the lowest objective loss are selected.", "labels": [], "entities": []}, {"text": "For the sequence generation models, the implementations are based on the OpenNMT framework ().", "labels": [], "entities": [{"text": "sequence generation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7052136361598969}, {"text": "OpenNMT framework", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.933898538351059}]}, {"text": "The word embeddings, with dimension set to 200, are randomly initialized.", "labels": [], "entities": []}, {"text": "For encoders, we employ two layers of Bi-GRU cells, and for decoders, one layer of GRU cell is used.", "labels": [], "entities": []}, {"text": "The hidden size of all GRUs is set to 300.", "labels": [], "entities": []}, {"text": "In learning, we use the Adam optimizer () with the learning rate initialized to 0.001.", "labels": [], "entities": []}, {"text": "We adopt the earlystop strategy: the learning rate decreases by a decay rate of 0.5 till either it is below 1e \u22126 or the validation loss stops decreasing.", "labels": [], "entities": []}, {"text": "The norm of gradients is rescaled to 1 if the L2-norm > 1 is observed.", "labels": [], "entities": []}, {"text": "The dropout rate is 0.1 and the batch size is 64.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9364784359931946}]}, {"text": "In inference, we set the beam-size to 20 and the maximum sequence length of a hashtag to 10.", "labels": [], "entities": []}, {"text": "For CLASSIFIER and EXTRACTOR, lacking publicly available codes, we reimplement the models using Keras.", "labels": [], "entities": [{"text": "CLASSIFIER", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8393535017967224}, {"text": "EXTRACTOR", "start_pos": 19, "end_pos": 28, "type": "DATASET", "confidence": 0.926764190196991}]}, {"text": "In this section, we first report the main comparison results in Section 4.1, followed by an in-depth comparative study between classification and sequence generation models in Section 4.2.", "labels": [], "entities": [{"text": "classification and sequence generation", "start_pos": 127, "end_pos": 165, "type": "TASK", "confidence": 0.7100250497460365}]}, {"text": "Further discussions are then presented to analyze our superiority and errors in Section 4.3.", "labels": [], "entities": [{"text": "superiority", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.961493968963623}, {"text": "errors", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9188349843025208}]}, {"text": "\u2022 Hashtag annotation is more challenging for Twitter than Weibo.", "labels": [], "entities": [{"text": "Hashtag annotation", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.8582760095596313}]}, {"text": "Generally, all models perform worse on Twitter measured by different metrics.", "labels": [], "entities": []}, {"text": "The intrinsic reason is the essential language difference between English and Chinese microblogs.", "labels": [], "entities": []}, {"text": "English allows higher freedom in writing, resulting in more variety in Twitter hashtags (e.g., abbreviations are prominent like \"aus\" in \"#AusOpen\").", "labels": [], "entities": []}, {"text": "For statistical reasons, Twitter hashtags are more likely to be absent in either posts or conversations, and have a more severe imbalanced distribution.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of our datasets. Avg len of posts,  convs, tags refer to the average number of words in  posts, conversations, and hashtags, respectively.", "labels": [], "entities": [{"text": "Avg", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9964806437492371}]}, {"text": " Table 3: Statistics of the hashtags. |Tagset|: the number  of distinct hashtags. P, C, and P \u222a C: the percentage of  hashtags appearing in their corresponding posts, con- versations, and the union set of them, respectively.", "labels": [], "entities": []}, {"text": " Table 4: Comparison results on Twitter and Weibo datasets (in %). RG-1 and RG-4 refer to ROUGE-1 and  ROUGE-SU4 respectively. The best results in each column are in bold. The \"*\" after numbers indicates signifi- cantly better results than all the other models (p < 0.05, paired t-test). Higher values indicate better performance.", "labels": [], "entities": [{"text": "Weibo datasets", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.978613555431366}, {"text": "RG-1", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.8064430952072144}]}, {"text": " Table 5: ROUGE-1 F1 scores (%) in producing unseen  hashtags. Best results are in bold.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.993898868560791}, {"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.8908696174621582}]}, {"text": " Table 6: F1@1 scores (%) for our variants.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.999136745929718}]}]}