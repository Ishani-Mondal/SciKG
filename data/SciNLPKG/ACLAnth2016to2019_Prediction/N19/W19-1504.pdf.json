{"title": [{"text": "Lightly-supervised Representation Learning with Global Interpretability", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a lightly-supervised approach for information extraction, in particular named entity classification, which combines the benefits of traditional bootstrapping, i.e., use of limited annotations and interpretability of extraction patterns, with the robust learning approaches proposed in representation learning.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.8045667111873627}, {"text": "named entity classification", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.5998845001061758}, {"text": "representation learning", "start_pos": 296, "end_pos": 319, "type": "TASK", "confidence": 0.8363180756568909}]}, {"text": "Our algorithm iteratively learns custom em-beddings for both the multi-word entities to be extracted and the patterns that match them from a few example entities per category.", "labels": [], "entities": []}, {"text": "We demonstrate that this representation-based approach outperforms three other state-of-the-art bootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes.", "labels": [], "entities": [{"text": "CoNLL-2003", "start_pos": 138, "end_pos": 148, "type": "DATASET", "confidence": 0.9299757480621338}]}, {"text": "Additionally, using these embeddings, our approach outputs a globally-interpretable model consisting of a decision list, by ranking patterns based on their proximity to the average entity embedding in a given class.", "labels": [], "entities": []}, {"text": "We show that this interpretable model performs close to our complete boot-strapping model, proving that representation learning can be used to produce interpretable models with small loss in performance.", "labels": [], "entities": []}, {"text": "This decision list can be edited by human experts to mitigate some of that loss and in some cases outperform the original model.", "labels": [], "entities": []}], "introductionContent": [{"text": "One strategy for mitigating the cost of supervised learning in information extraction (IE) is to bootstrap extractors with light supervision from a few provided examples (or seeds).", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.8799359202384949}]}, {"text": "Traditionally, bootstrapping approaches iterate between learning extraction patterns such as word ngrams, e.g., the pattern \"@ENTITY , former president\" could be used to extract person names, and applying these patterns to extract the desired structures (entities, relations, etc.).", "labels": [], "entities": []}, {"text": "One advantage of this direction is that these patterns are interpretable, which mitigates the maintenance cost associated with machine learning systems ().", "labels": [], "entities": []}, {"text": "On the other hand, representation learning has proven to be useful for natural language processing (NLP) applications.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.9737736880779266}]}, {"text": "Representation learning approaches often include a component that is trained in an unsupervised manner, e.g., predicting words based on their context from large amounts of data, mitigating the brittle statistics affecting traditional bootstrapping approaches.", "labels": [], "entities": [{"text": "Representation learning", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9402972757816315}, {"text": "predicting words based on their context", "start_pos": 110, "end_pos": 149, "type": "TASK", "confidence": 0.7964734733104706}]}, {"text": "However, the resulting realvalued embedding vectors are hard to interpret.", "labels": [], "entities": []}, {"text": "Here we argue that these two directions are complementary, and should be combined.", "labels": [], "entities": []}, {"text": "We propose such a bootstrapping approach for information extraction (IE), which blends the advantages of both directions.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.8565540611743927}]}, {"text": "As a use case, we instantiate our idea for named entity classification (NEC), i.e., classifying a given set of unknown entities into a predefined set of categories).", "labels": [], "entities": [{"text": "named entity classification (NEC)", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.8267684976259867}]}, {"text": "The contributions of this work are: (1) We propose an approach for bootstrapping NEC that iteratively learns custom embeddings for both the multi-word entities to be extracted and the patterns that match them from a few example entities per category.", "labels": [], "entities": []}, {"text": "Our approach changes the objective function of a neural network language models (NNLM) to include a semi-supervised component that models the known examples, i.e., by attracting entities and patterns in the same category to each other and repelling them from elements in different categories, and it adds an external iterative process that \"cautiously\" augments the pools of known examples).", "labels": [], "entities": []}, {"text": "In other words, our contribution is an example of combining representation learning and bootstrapping.", "labels": [], "entities": []}, {"text": "(2) We demonstrate that our representation learn-ing approach is suitable for semi-supervised NEC.", "labels": [], "entities": [{"text": "NEC", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.8394932746887207}]}, {"text": "We compare our approach against several stateof-the-art semi-supervised approaches on two datasets: and.", "labels": [], "entities": []}, {"text": "We show that, despite its simplicity, our method outperforms all other approaches.", "labels": [], "entities": []}, {"text": "(3) Our approach also outputs an interpretation of the learned model, consisting of a decision list of patterns, where each pattern gets a score per class based on the proximity of its embedding to the average entity embedding in the given class.", "labels": [], "entities": []}, {"text": "This interpretation is global, i.e., it explains the entire model rather than local predictions.", "labels": [], "entities": []}, {"text": "We show that this decision-list model performs comparably to the complete model on the two datasets.", "labels": [], "entities": []}, {"text": "(4) We also demonstrate that the resulting system can be understood, debugged, and maintained by non-machine learning experts.", "labels": [], "entities": []}, {"text": "We compare the decision-list model edited by human domain experts with the unedited decision-list model and see a modest improvement in overall performance, with some categories getting a bigger boost.", "labels": [], "entities": []}, {"text": "This improvement shows that, for non-ambiguous categories that are well-defined by the local contexts captured by our patterns, these patterns truly are interpretable to end users.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the above algorithms on the task of named entity classification from free text.", "labels": [], "entities": [{"text": "named entity classification", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.6299095153808594}]}, {"text": "Datasets: We used two datasets, the CoNLL-2003 shared task dataset, which contains 4 entity types, and the OntoNotes dataset (, which contains 11.", "labels": [], "entities": [{"text": "CoNLL-2003 shared task dataset", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.8403027206659317}, {"text": "OntoNotes dataset", "start_pos": 107, "end_pos": 124, "type": "DATASET", "confidence": 0.8640151023864746}]}, {"text": "These datasets contain marked entity boundaries with labels for each marked entity.", "labels": [], "entities": []}, {"text": "Here we only use the entity boundaries but not the labels of these entities during the training of our bootstrapping systems.", "labels": [], "entities": []}, {"text": "To simulate learning from large texts, we tuned hyper parameters on development, but ran the actual experiments on the train partitions.", "labels": [], "entities": []}, {"text": "Baselines: In addition to the EPB algorithm, we compare against the approach proposed by . This algorithm is a simpler version of the EPB system, where entities are promoted with a PMI-based formula rather than an entity classifier.", "labels": [], "entities": []}, {"text": "Further, we compare against label propagation (LP) (), with the implementation available in the scikit-learn package.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6577993929386139}]}, {"text": "In each bootstrapping epoch, we run LP, select the entities with the lowest entropy, and add them to their top category.", "labels": [], "entities": []}, {"text": "Each entity is represented by a feature vector that contains the co-occurrence counts of the entity and each of the patterns that matches it in text.", "labels": [], "entities": []}, {"text": "8 Settings: For all baselines and proposed models, we used the same set of 10 seeds/category, which were manually chosen from the most frequent entities in the dataset.", "labels": [], "entities": []}, {"text": "For the custom embedding  features, we used randomly initialized 15d embeddings.", "labels": [], "entities": []}, {"text": "Here we consider patterns to be ngrams of size up to 4 tokens on either side of an entity.", "labels": [], "entities": []}, {"text": "For instance, \"@ENTITY , former President\" is one of the patterns learned for the class person.", "labels": [], "entities": [{"text": "ENTITY", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9021702408790588}]}, {"text": "We ran all algorithms for 20 bootstrapping epochs, and the embedding learning component for 100 epochs in each bootstrapping epoch.", "labels": [], "entities": []}, {"text": "We add 10 entities and 10 patterns to each category during every bootstrapping epoch.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of patterns and experts' decisions and rationales from the CoNLL dataset.", "labels": [], "entities": [{"text": "CoNLL dataset", "start_pos": 78, "end_pos": 91, "type": "DATASET", "confidence": 0.9703822135925293}]}]}