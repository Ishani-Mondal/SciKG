{"title": [{"text": "Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory", "labels": [], "entities": [{"text": "Dialogue Generation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7195757925510406}]}], "abstractContent": [{"text": "Traditional generative dialogue models generate responses solely from input queries.", "labels": [], "entities": [{"text": "generative dialogue", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.9701701402664185}]}, {"text": "Such information is insufficient for generating a specific response since a certain query could be answered in multiple ways.", "labels": [], "entities": []}, {"text": "Recently, researchers have attempted to fill the information gap by exploiting information retrieval techniques.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.7244088351726532}]}, {"text": "For a given query, similar dialogues are retrieved from the entire training data and considered as an additional knowledge source.", "labels": [], "entities": []}, {"text": "While the use of retrieval may harvest extensive information, the generative models could be overwhelmed, leading to unsatisfactory performance.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew framework which exploits retrieval results via a skeleton-to-response paradigm.", "labels": [], "entities": []}, {"text": "At first, a skeleton is extracted from the retrieved dialogues.", "labels": [], "entities": []}, {"text": "Then, both the generated skeleton and the original query are used for response generation via a novel response generator.", "labels": [], "entities": [{"text": "response generation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.831037849187851}]}, {"text": "Experimental results show that our approach significantly improves the informativeness of the generated responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper focuses on tackling the challenges to develop a chit-chat style dialogue system (also known as chatbot).", "labels": [], "entities": []}, {"text": "Chit-chat style dialogue system aims at giving meaningful and coherent responses given a dialogue query in the open domain.", "labels": [], "entities": []}, {"text": "Most modern chit-chat systems can be categorized into two categories, namely, information retrieval-based (IR) models and generative models.", "labels": [], "entities": [{"text": "information retrieval-based (IR)", "start_pos": 78, "end_pos": 110, "type": "TASK", "confidence": 0.7825957298278808}]}, {"text": "The IR-based models () directly copy an existing response from a training corpus when receiving a response request.", "labels": [], "entities": []}, {"text": "Since the training corpus is usually collected from real-world conversations and possibly post-edited * Work done while DC was interning at Tencent AI Lab.", "labels": [], "entities": []}, {"text": "\u2020 Corresponding author. by a human, the retrieved responses are informative and grammatical.", "labels": [], "entities": []}, {"text": "However, the performance of such systems drops when a given dialogue history is substantially different from those in the training corpus.", "labels": [], "entities": []}, {"text": "The generative models), on the other hand, generate anew utterance from scratch.", "labels": [], "entities": []}, {"text": "While those generative models have better generalization capacity in rare dialogue contexts, the generated responses tend to be universal and noninformative (e.g., \"I don't know\", \"I think so\" etc.)", "labels": [], "entities": []}, {"text": "(. It is partly due to the diversity of possible responses to a single query (i.e., the one-to-many problem).", "labels": [], "entities": []}, {"text": "The dialogue query alone cannot decide a meaningful and specific response.", "labels": [], "entities": []}, {"text": "Thus a well-trained model tends to generate the most frequent (safe but boring) responses instead.", "labels": [], "entities": []}, {"text": "To summarize, IR-based models may give informative but inappropriate responses while generative models often do the opposite.", "labels": [], "entities": []}, {"text": "It is desirable to combine both merits.", "labels": [], "entities": []}, {"text": "used an extra encoder for the retrieved response.", "labels": [], "entities": []}, {"text": "The resulted dense representation, together with the original query, is used to feed the decoder in a standard SEQ2SEQ model ().", "labels": [], "entities": []}, {"text": "used a single encoder that takes the concatenation of the original query and the retrieved as input.", "labels": [], "entities": []}, {"text": "noted that the retrieved information should be used in awareness of the context difference, and further proposed to construct an edit vector by explicitly encoding the lexical differences between the input query and the retrieved query.", "labels": [], "entities": []}, {"text": "However, in our preliminary experiments, we found that the IR-guided models are inclined to degenerate into a copy mechanism, in which the generative models simply repeat the retrieved response without necessary modifications.", "labels": [], "entities": []}, {"text": "Sharp performance drop is caused when the retrieved re-sponse is irrelevant to the input query.", "labels": [], "entities": [{"text": "Sharp performance drop", "start_pos": 0, "end_pos": 22, "type": "METRIC", "confidence": 0.9473313689231873}]}, {"text": "A possible reason is that both useful and useless information is mixed in the dense vector space, which is uninterpretable and uncontrollable.", "labels": [], "entities": []}, {"text": "To address the above issue, we propose anew framework, skeleton-to-response, for response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.9126661419868469}]}, {"text": "Our motivations are two folds: The guidance from IR results should only specify a response aspect or pattern, but leave the queryspecific details to be elaborated by the generative model itself; (2) The retrieval results typically contain excessive information, such as inappropriate words or entities.", "labels": [], "entities": []}, {"text": "It is necessary to filter out irrelevant words and derive a useful skeleton before use.", "labels": [], "entities": []}, {"text": "Our approach consists of two components: a skeleton generator and a response generator.", "labels": [], "entities": []}, {"text": "The skeleton generator extracts a response skeleton by detecting and removing unwanted words in a retrieved response.", "labels": [], "entities": []}, {"text": "The response generator is responsible for adding query-specific details to the generated skeleton for query-to-response generation.", "labels": [], "entities": [{"text": "query-to-response generation", "start_pos": 102, "end_pos": 130, "type": "TASK", "confidence": 0.7645061016082764}]}, {"text": "A dialogue example illustrating our idea is shown in.", "labels": [], "entities": []}, {"text": "Due to the discrete choice of skeleton words, the gradient in the training process is no longer differentiable from the response to the skeleton generator.", "labels": [], "entities": []}, {"text": "Two techniques are proposed to solve this issue.", "labels": [], "entities": []}, {"text": "The first technique is to employ the policy gradient method for rewarding the output of the skeleton generator based on the feedback from a pre-trained critic.", "labels": [], "entities": []}, {"text": "An alternative technique is to solve both the skeleton generation and the response generation in a multi-task learning fashion.", "labels": [], "entities": []}, {"text": "Our contributions are summarized as below: (1) We develop a novel framework to inject the power of IR results into generative response models by introducing the idea of skeleton generation; (2) Our approach generates response skeletons by detecting and removing unnecessary words, which facilitates the generation of specific responses while not spoiling the generalization ability of the underlying generative models; (3) Experimental results show that our approach significantly outperforms other compared methods, resulting in more informative and specific responses.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our method is designed to improve the informativeness of the generative model and alleviate the inappropriateness problem of the retrieval model.", "labels": [], "entities": []}, {"text": "To measure the performance effectively, we use \u2022 Human evaluation We asked three experienced annotators to score the group of responses (the best output of each model) for 300 test queries.", "labels": [], "entities": []}, {"text": "The responses are rated on a five-point scale.", "labels": [], "entities": []}, {"text": "A response should be scored 1 if it can hardly be considered a valid response, 3 if it is a valid but not informative response, 5 if it is an informative response, which can deepen the discussion of the current topic or lead to anew topic.", "labels": [], "entities": []}, {"text": "2 and 4 are for decision dilemmas.", "labels": [], "entities": [{"text": "decision dilemmas", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.9396457970142365}]}, {"text": "\u2022 dist-1 & dist-2 It is defined as the number of unique uni-grams (dist-1) or bi-grams (dist-2) dividing by the total number of tokens, measuring the diversity of the generated responses ().", "labels": [], "entities": []}, {"text": "Note the two metrics do not necessarily reflect the response quality as the target queries are not taken into consideration.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Response performance of different models.  Sign tests on human score show that the CAS is sig- nificantly better than all other methods with p-value <  0.05, and the p-value < 0.01 except for those marked  by  \u2020.", "labels": [], "entities": []}, {"text": " Table 2: Performance of skeleton generator.", "labels": [], "entities": []}, {"text": " Table 1. Overall, both  of our models surpass all other methods, and our  cascaded model (CAS) gives the best performance  according to human evaluation. The contrast with  the SKP model illustrates that the use of skeletons  brings a significant performance gain.  According to the dist-1&2 metrics, the gener- ative models achieve significantly better diversity  by the use of retrieval results. The retrieval method  yields the highest diversity, which is consistent  with our intuition that the retrieval responses typi- cally contain a large amount of information though  they are not necessarily appropriate. The model of  MMI also gives strong diversity, yet we find that", "labels": [], "entities": []}, {"text": " Table 3: Upper: Skeleton-to-response examples of the CAS model. Lower: Responses from different models are  for comparison.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the usages of the retrieval set.", "labels": [], "entities": []}]}