{"title": [{"text": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems", "labels": [], "entities": [{"text": "Solving and Reasoning Math Word Problems", "start_pos": 45, "end_pos": 85, "type": "TASK", "confidence": 0.8414758046468099}]}], "abstractContent": [{"text": "Solving math word problems is a challenging task that requires accurate natural language understanding to bridge natural language texts and math expressions.", "labels": [], "entities": [{"text": "Solving math word problems", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8904707282781601}]}, {"text": "Motivated by the intuition about how human generates the equations given the problem texts, this paper presents a neural approach to automatically solve math word problems by operating symbols according to their semantic meanings in texts.", "labels": [], "entities": []}, {"text": "This paper views the process of generating equations as abridge between the semantic world and the symbolic world, where the proposed neural math solver is based on an encoder-decoder framework.", "labels": [], "entities": [{"text": "neural math solver", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.6879813075065613}]}, {"text": "In the proposed model, the encoder is designed to understand the semantics of problems, and the decoder focuses on tracking semantic meanings of the generated symbols and then deciding which symbol to generate next.", "labels": [], "entities": []}, {"text": "The preliminary experiments are conducted in a benchmark dataset Math23K, and our model significantly outper-forms both the state-of-the-art single model and the best non-retrieval-based model over about 10% accuracy, demonstrating the effectiveness of bridging the symbolic and semantic worlds from math word problems.", "labels": [], "entities": [{"text": "Math23K", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.5368092656135559}, {"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9975653886795044}]}], "introductionContent": [{"text": "Automatically solving math word problems has been an interesting research topic and also been viewed as away of evaluating machines' ability (.", "labels": [], "entities": [{"text": "Automatically solving math word problems", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.811740517616272}]}, {"text": "For human, writing down an equation that solves a math word problem requires the ability of reading comprehension, reasoning, and sometimes real world understanding.", "labels": [], "entities": []}, {"text": "Specifically, to solve a math word problem, we first need to know the goal of the given problem, then understand the semantic meaning of each numerical number in the problem, perform reasoning based on the comprehension in the previous step, and finally decide what to write in the equation.", "labels": [], "entities": []}, {"text": "Most prior work about solving math word problems relied on hand-crafted features, which required more human knowledge.", "labels": [], "entities": [{"text": "solving math word problems", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.8670898973941803}]}, {"text": "Because those features are often in the lexical level, it is not clear whether machines really understand the math problems.", "labels": [], "entities": []}, {"text": "Also, most prior work evaluated their approaches on relatively small datasets, and the capability of generalization is concerned.", "labels": [], "entities": [{"text": "generalization", "start_pos": 101, "end_pos": 115, "type": "TASK", "confidence": 0.9597890377044678}]}, {"text": "This paper considers the reasoning procedure when writing down the associated equation given a problem.", "labels": [], "entities": []}, {"text": "illustrates the problem solving process.", "labels": [], "entities": [{"text": "problem solving process", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.9247498909632365}]}, {"text": "The illustration shows that human actually assigns the semantic meaning to each number when manipulating symbols, including operands (numbers) and operators (+ \u2212 \u00d7\u00f7).", "labels": [], "entities": []}, {"text": "Also, we believe that the semantic meaning of operands can help us decide which operator to use.", "labels": [], "entities": []}, {"text": "For example, the summation of \"price of one pen\" and \"number of pens Tom bought\" is meaningless; therefore the addition would not be chosen.", "labels": [], "entities": []}, {"text": "Following the observation above, this paper proposes a novel encoder decoder model, where the encoder extracts semantic meanings of numbers in the problem, and the decoder is equipped with a stack that facilitates tracking the semantic meanings of operands.", "labels": [], "entities": []}, {"text": "The contributions of this paper are 4-fold: \u2022 This paper is the first work that models semantic meanings of operands and operators for math word problems.", "labels": [], "entities": []}, {"text": "\u2022 This paper proposes an end-to-end neural math solver with a novel decoding process that utilizes the stack to generate associated equations.", "labels": [], "entities": [{"text": "end-to-end neural math solver", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.687980443239212}]}, {"text": "\u2022 This paper achieves the state-of-the-art performance on the large benchmark dataset Math23K.", "labels": [], "entities": [{"text": "benchmark dataset Math23K", "start_pos": 68, "end_pos": 93, "type": "DATASET", "confidence": 0.7711572647094727}]}, {"text": "\u2022 This paper is capable of providing interpretation and reasoning for the math word problem solving procedure.", "labels": [], "entities": [{"text": "math word problem solving", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7088312953710556}]}], "datasetContent": [{"text": "To evaluate the performance of the proposed model, we conduct the experiments on the benchmark dataset and analyze the learned semantics.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 5-fold cross validation results on Math23K.", "labels": [], "entities": [{"text": "Math23K", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.9833515286445618}]}, {"text": " Table 2: 5-fold cross validation results of ablation tests.", "labels": [], "entities": []}, {"text": " Table 3: Randomly sampled incorrect predictions.", "labels": [], "entities": []}]}