{"title": [{"text": "Cooperative Learning of Disjoint Syntax and Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "There has been considerable attention devoted to models that learn to jointly infer an ex-pression's syntactic structure and its semantics.", "labels": [], "entities": []}, {"text": "Yet, Nangia and Bowman (2018) has recently shown that the current best systems fail to learn the correct parsing strategy on mathematical expressions generated from a simple context-free grammar.", "labels": [], "entities": []}, {"text": "In this work, we present a recursive model inspired by Choi et al.", "labels": [], "entities": []}, {"text": "(2018) that reaches near perfect accuracy on this task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9975606203079224}]}, {"text": "Our model is composed of two separated modules for syntax and semantics.", "labels": [], "entities": []}, {"text": "They are cooperatively trained with standard continuous and discrete optimisation schemes.", "labels": [], "entities": []}, {"text": "Our model does not require any linguistic structure for supervision, and its re-cursive nature allows for out-of-domain gen-eralisation.", "labels": [], "entities": []}, {"text": "Additionally, our approach performs competitively on several natural language tasks, such as Natural Language Inference and Sentiment Analysis.", "labels": [], "entities": [{"text": "Natural Language Inference", "start_pos": 93, "end_pos": 119, "type": "TASK", "confidence": 0.6429747045040131}, {"text": "Sentiment Analysis", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.9063773155212402}]}], "introductionContent": [{"text": "Standard linguistic theories propose that natural language is structured as nested constituents organised in the form of a tree ().", "labels": [], "entities": []}, {"text": "However, most popular models, such as the Long Sort-Term Memory network (LSTM), process text without imposing a grammatical structure.", "labels": [], "entities": []}, {"text": "To bridge this gap between theory and practice models that process linguistic expressions in a tree-structured manner have been considered in recent work ().", "labels": [], "entities": []}, {"text": "These tree-based models explicitly require access to the syntactic structure for the text, which is not entirely satisfactory.", "labels": [], "entities": []}, {"text": "Indeed, parse tree level supervision requires a significant amount of annotations from expert lin- * Work done while the author was an intern at Facebook AI guists.", "labels": [], "entities": []}, {"text": "These trees have been annotated with different goals in mind than the tasks we are using them for.", "labels": [], "entities": []}, {"text": "Such discrepancy may result in a deterioration of the performance of models relying on them.", "labels": [], "entities": []}, {"text": "Recently, several attempts were made to learn these models without explicit supervision for the parser ().", "labels": [], "entities": []}, {"text": "However, has recently shown that the structures learned by these models cannot be ascribed to discovering meaningful syntactic structure.", "labels": [], "entities": []}, {"text": "These models even fail to learn the simple context-free grammar of nested mathematical operations (.", "labels": [], "entities": []}, {"text": "In this work, we present an extension of, that successfully learns these simple grammars while preserving competitive performance on several standard linguistic tasks.", "labels": [], "entities": []}, {"text": "Contrary to previous work, our model makes a clear distinction between the parser and the compositional function.", "labels": [], "entities": []}, {"text": "These two modules are trained with different algorithms, cooperating to build a semantic representation that optimises the objective function.", "labels": [], "entities": []}, {"text": "The parser's goal is to generate a tree structure for the sentence.", "labels": [], "entities": []}, {"text": "The compositional function follows this structure to produce the sentence representation.", "labels": [], "entities": []}, {"text": "Our model contains a continuous component, the compositional function, and a discrete one, the parser.", "labels": [], "entities": []}, {"text": "The whole system is trained end-to-end with a mix of reinforcement learning and gradient descent. has noticed the difficulty of mixing these two optimisation schemes without one dominating the other.", "labels": [], "entities": []}, {"text": "This typically leads to the \"coadaptation problem\" where the parser simply follows the compositional function and fails to produce meaningful syntactic structures.", "labels": [], "entities": []}, {"text": "In this work, we show that this pitfall can be avoided by synchronising the learning paces of the two optimisation schemes.", "labels": [], "entities": []}, {"text": "This is achieved by com-bining several recent advances in reinforcement learning.", "labels": [], "entities": []}, {"text": "First, we use input-dependent control variates to reduce the variance of our gradient estimates.", "labels": [], "entities": []}, {"text": "Then, we apply multiple gradient steps to the parser's policy while controlling for its learning pace using the Proximal Policy Optimization (PPO) of.", "labels": [], "entities": []}, {"text": "The code for our model is publicly available 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on three different tasks: evaluating mathematical expressions on the ListOps dataset (, sentiment analysis on the SST dataset) and natural language inference task on the SNLI () and MultiNLI () datasets.", "labels": [], "entities": [{"text": "ListOps dataset", "start_pos": 94, "end_pos": 109, "type": "DATASET", "confidence": 0.9690378606319427}, {"text": "SST dataset", "start_pos": 139, "end_pos": 150, "type": "DATASET", "confidence": 0.8632664978504181}, {"text": "MultiNLI () datasets", "start_pos": 207, "end_pos": 227, "type": "DATASET", "confidence": 0.7482831279436747}]}, {"text": "For ListOps, we follow the experimental protocol of, i.e., a 128 dimensional model and a tenway softmax classifier.", "labels": [], "entities": []}, {"text": "However, we replace their multi-layer perceptron (MLP) by a linear classifier.", "labels": [], "entities": []}, {"text": "The validation set is composed of 1k examples randomly selected from the training set.", "labels": [], "entities": []}, {"text": "For SST and NLI, we follow the setup of: we initialise the word vectors with GloVe300D () and train an MLP classifier on the sentence representations.", "labels": [], "entities": [{"text": "SST", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9640538096427917}]}, {"text": "The hyperparameters are selected on the validation set using 5 random seeds for each configuration.", "labels": [], "entities": []}, {"text": "Our hyperparameters are the learning rate, weight decay, the regularisation parameter \u03bb, the leaf transformations, variance reduction hyperpa-  rameters and the number of updates K in PPO.", "labels": [], "entities": [{"text": "weight decay", "start_pos": 43, "end_pos": 55, "type": "METRIC", "confidence": 0.8390134871006012}, {"text": "variance reduction hyperpa-  rameters", "start_pos": 115, "end_pos": 152, "type": "METRIC", "confidence": 0.9054601073265076}]}, {"text": "We use an adadelta optimizer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy on ListOps test set for our model with three different baselines, with and without PPO. We use  K = 15 for PPO.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9976105690002441}]}, {"text": " Table 3: Results on SNLI. *: publicly available code  and hyperparameter optimization was used to obtain re- sults.  \u2020: results are taken from Williams et al. (2018a)", "labels": [], "entities": [{"text": "SNLI", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.658390462398529}]}, {"text": " Table 4: Results on MultiNLI.  \u2020: results are taken from  Williams et al. (2018a).", "labels": [], "entities": [{"text": "MultiNLI", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.9193947315216064}]}, {"text": " Table 5: Accuracy results of models on the SST. All  the numbers are from Choi et al. (2018) but  *  where  we used their publicly available code and performed  hyperparameter optimization.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9895812273025513}, {"text": "SST", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.7994816899299622}]}]}