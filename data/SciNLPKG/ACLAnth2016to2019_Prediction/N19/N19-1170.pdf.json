{"title": [{"text": "What makes a good conversation? How controllable attributes affect human judgments", "labels": [], "entities": []}], "abstractContent": [{"text": "A good conversation requires balance-between simplicity and detail; staying on topic and changing it; asking questions and answering them.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9765491485595703}]}, {"text": "Although dialogue agents are commonly evaluated via human judgments of overall quality, the relationship between quality and these individual factors is less well-studied.", "labels": [], "entities": []}, {"text": "In this work, we examine two controllable neural text generation methods, conditional training and weighted decoding, in order to control four important attributes for chitchat dialogue: repetition, specificity, response-relatedness and question-asking.", "labels": [], "entities": []}, {"text": "We conduct a large-scale human evaluation to measure the effect of these control parameters on multi-turn interactive conversations on the PersonaChat task.", "labels": [], "entities": []}, {"text": "We provide a detailed analysis of their relationship to high-level aspects of conversation, and show that by controlling combinations of these variables our models obtain clear improvements inhuman quality judgments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural generation models for dialogue, despite their ubiquity in current research, are still poorly understood.", "labels": [], "entities": [{"text": "Neural generation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8073917925357819}]}, {"text": "Well known problems, such as the genericness and repetitiveness of responses), remain without a de facto solution.", "labels": [], "entities": []}, {"text": "Strikingly, the factors that determine human judgments of overall conversation quality are almost entirely unexplored.", "labels": [], "entities": []}, {"text": "Most works have been limited to the next utterance prediction problem, whereas a multi-turn evaluation is necessary to evaluate the quality of a full conversation.", "labels": [], "entities": [{"text": "utterance prediction", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.829073041677475}]}, {"text": "In this work we both (i) conduct a large-scale study to identify the fine-grained factors governing human judgments of full conversations, and (ii) develop models that apply our findings in practice, * A.S. completed most of this work at Facebook (FAIR).", "labels": [], "entities": [{"text": "A.S.", "start_pos": 202, "end_pos": 206, "type": "METRIC", "confidence": 0.8483102321624756}, {"text": "FAIR", "start_pos": 248, "end_pos": 252, "type": "METRIC", "confidence": 0.48560449481010437}]}, {"text": "Specifically, we identify and study eight aspects of conversation that can be measured by human judgments, while varying four types of low-level attributes that can be algorithmically controlled in neural models; see.", "labels": [], "entities": []}, {"text": "To control the lowlevel model attributes, we consider two simple but general algorithms: conditional training, in which the neural model is conditioned on additional control features, and weighted decoding, in which control features are added to the decoding scoring function attest time only.", "labels": [], "entities": []}, {"text": "One major result of our findings is that existing work has ignored the importance of conversational flow, as standard models (i) repeat or contradict previous statements, (ii) fail to balance specificity with genericness, and (iii) fail to balance asking questions with other dialogue acts.", "labels": [], "entities": []}, {"text": "Conducting experiments on the PersonaChat task (), we obtain significantly higher engagingness scores than the baseline by optimizing control of repetition, specificity and question-asking over multiple turns.", "labels": [], "entities": [{"text": "repetition", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.9719462990760803}]}, {"text": "Using these findings, our best model matches the performance of the winning entry in the recent NeurIPS ConvAI2 competition (, which was trained on much more data but had no control (see Section 8.1).", "labels": [], "entities": []}, {"text": "Our code, pretrained models, and full chatlogs, are available at https://parl.ai/projects/ controllable_dialogue.", "labels": [], "entities": []}], "datasetContent": [{"text": "PersonaChat () is a chitchat dialogue task involving two participants (two humans or a human and a bot).", "labels": [], "entities": []}, {"text": "Each participant is given a persona -a short collection of personal traits such as I'm left handed or My favorite season is spring -and are instructed to get to know each other by chatting naturally using their designated personas, for 6-8 turns.", "labels": [], "entities": []}, {"text": "The training set contains 8939 conversations and 955 personas, collected via crowdworkers, plus 1000 conversations and 100 personas for validation, and a similar number in the hidden test set.", "labels": [], "entities": []}, {"text": "The PersonaChat task was the subject of the NeurIPS 2018 ConvAI2 Challenge (, in which competitors were first evaluated with respect to automatic met-rics (perplexity, hits@1 and F1 score), and then with respect to human judgment via the question \"How much did you enjoy talking to this user?\" on a scale of 1-4.", "labels": [], "entities": [{"text": "NeurIPS 2018 ConvAI2 Challenge", "start_pos": 44, "end_pos": 74, "type": "DATASET", "confidence": 0.7102153301239014}, {"text": "F1 score", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.983594685792923}]}, {"text": "In order to study the effect of our controllable attributes, we conduct a large-scale human evalua-tion of 28 model configurations (see Appendix E), plus human-human conversations for comparison.", "labels": [], "entities": []}, {"text": "Approach In our evaluation, a crowdworker chats with a model (or in the human-human case, another crowdworker) for six conversational turns, then answers eight multiple-choice questions which each capture different aspects of conversational quality: avoiding repetition, interestingness, making sense, fluency, listening, inquisitiveness, humanness and engagingness.", "labels": [], "entities": [{"text": "Approach", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9794210195541382}]}, {"text": "The eight questions are Likert questions on a 1-4 scale, where higher is better.", "labels": [], "entities": []}, {"text": "To match the ConvAI2 Challenge, we also add a persona retrieval question, in which the crowdworker is asked to select which of two possible personas was the model's persona.", "labels": [], "entities": []}, {"text": "For full details of the evaluation design, see Appendix B. Our evaluation is the same as the ConvAI2 Challenge evaluation, but more detailed -ConvAI2 includes only engagingness and persona retrieval.", "labels": [], "entities": [{"text": "persona retrieval", "start_pos": 181, "end_pos": 198, "type": "TASK", "confidence": 0.7448241412639618}]}, {"text": "As in the ConvAI2 challenge, each of our 28 model configurations was evaluated by over 100 crowdworkers, and the results were adjusted for annotator variance via a Bayesian calibration (.", "labels": [], "entities": []}, {"text": "In designing our evaluation, we aimed to capture the four aspects we expected to directly improve via control (avoiding repetition, interestingness, listening, inquisitiveness), two important error classes we thought would be affected by our controls (fluency, making sense), and two overall quality measures (engagingness, humanness).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Middle: Example of controlling specificity  (NIDF) via weighted decoding. At the extremes, the  model produces only the most rare or the most com- mon tokens. Bottom: Example of controlling speci- ficity via conditional training. This gives a narrower  NIDF range, but all the responses are appropriate.", "labels": [], "entities": []}, {"text": " Table 2: Example of controlling response-relatedness  (cosine similarity to input) via weighted decoding. Pos- itive weights (e.g. 5.0) can yield more on-topic re- sponses, but higher weights (e.g. 11.0) can result in  nonsensical lists of topically related words.", "labels": [], "entities": []}, {"text": " Table 6: Automatic metrics (computed over validation set) for all model configurations that were human-evaluated.", "labels": [], "entities": []}]}