{"title": [{"text": "Customizing Grapheme-to-Phoneme System for Non-Trivial Transcription Problems in Bangla Language", "labels": [], "entities": []}], "abstractContent": [{"text": "Grapheme to phoneme (G2P) conversion is an integral part in various text and speech processing systems, such as: Text to Speech system, Speech Recognition system, etc.", "labels": [], "entities": [{"text": "Grapheme to phoneme (G2P) conversion", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5480508889470782}, {"text": "Speech Recognition", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.7669104635715485}]}, {"text": "The existing methodologies for G2P conversion in Bangla language are mostly rule-based.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.8934058547019958}]}, {"text": "However, data-driven approaches have proved their superiority over rule-based approaches for large-scale G2P conversion in other languages, such as: English, German, etc.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.6925548762083054}]}, {"text": "As the performance of data-driven approaches for G2P conversion depend largely on pronunciation lexicon on which the system is trained, in this paper, we investigate on developing an improved training lexicon by identifying and categorizing the critical cases in Bangla language and include those critical cases in training lexicon for developing a robust G2P conversion system in Bangla language.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.8874556124210358}, {"text": "G2P conversion", "start_pos": 356, "end_pos": 370, "type": "TASK", "confidence": 0.8412023186683655}]}, {"text": "Additionally, we have incorporated nasal vowels in our proposed phoneme list.", "labels": [], "entities": []}, {"text": "Our methodology outperforms other state-of-the-art approaches for G2P conversion in Bangla language.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.7794492542743683}]}], "introductionContent": [{"text": "Grapheme to phoneme (G2P) conversion provides a mapping between a word and its pronunciation.", "labels": [], "entities": [{"text": "Grapheme to phoneme (G2P) conversion", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.546553909778595}]}, {"text": "Such mapping provides opportunity fora nonnative person to learn the correct pronunciation of words of a foreign language.", "labels": [], "entities": []}, {"text": "Moreover, in modern Text to Speech (TTS) and Automatic Speech Recognition (ASR) systems, G2P conversion is an integral task.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 45, "end_pos": 79, "type": "TASK", "confidence": 0.7426981826623281}, {"text": "G2P conversion", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.7100677043199539}]}, {"text": "The task of G2P conversion is generally language specific due to language specific conventions, rules, pronunciation constraints, etc.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.8698853850364685}]}, {"text": "In this paper, we focus on Modern Standard Bangla.", "labels": [], "entities": [{"text": "Modern Standard Bangla", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.9347118933995565}]}, {"text": "An example of G2P conversion in Bangla language: phonetic transcription of \u0985\u09a8\u09c1 \u09b6\u09c0\u09b2\u09a8 (practice) is /o nu sh i l O n/.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7577370405197144}]}, {"text": "(Please refer to for our phoneme symbols.)", "labels": [], "entities": []}, {"text": "The simplest means of G2P conversion is to buildup a lexicon or dictionary containing the mapping from words to their corresponding pronunciations.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.8195313513278961}]}, {"text": "However, it fails to provide pronunciations for unknown words and inclusion of newer words increases memory requirement.", "labels": [], "entities": [{"text": "memory", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9921882152557373}]}, {"text": "In another approach (), there are predefined rules for the conversion of a word to its pronunciation.", "labels": [], "entities": []}, {"text": "Though such rule-based approach can work for any word, the system becomes complex when it tries to formulate rules for incorporating all irregularities of pronunciation in a language.", "labels": [], "entities": []}, {"text": "Clearly, these approaches are not feasible for large-scale G2P conversion which is necessary in any modern TTS or ASR system.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.7184541523456573}, {"text": "TTS or ASR", "start_pos": 107, "end_pos": 117, "type": "TASK", "confidence": 0.6734078129132589}]}, {"text": "Data-driven machine learning approaches have great potential in such large-scale G2P conversion (.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.6501268446445465}]}, {"text": "In such an approach, a machine learning model predicts the phoneme conversion of a grapheme, being trained on a lexicon.", "labels": [], "entities": []}, {"text": "A predominant work following such approach in Bangla language is by), where they train their system using 37K words and achieve word-level accuracy of 81.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9530949592590332}]}, {"text": "However, a system trained on their lexicon will face several shortcomings, such as: \u0995\u09be\u09a6\u09be(mud) and \u0995\u09be\u0981 \u09a6\u09be(to cry) are pronounced differently but will have same phoneme representation in their system as: /k ad a/.", "labels": [], "entities": []}, {"text": "Similarly, \u09aa\u09b0\u09c0(fairy) and \u09aa\u09bf\u09bf(to read) are pronounced differently but will have same phoneme representation in their system as: /p or i/.", "labels": [], "entities": [{"text": "\u09aa\u09b0\u09c0(", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9840865731239319}]}, {"text": "Moreover, G2P system trained on their lexicon performs poorly on our identified critical cases from the most frequent 100K words.", "labels": [], "entities": []}, {"text": "Being motivated to increase the accuracy of grapheme to phoneme conversion in Bangla language, which will also perform well for critical inputs, we have developed a customized and robust G2P system for Bangla language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9992839694023132}, {"text": "grapheme to phoneme conversion", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6496783643960953}]}, {"text": "Our major contributions are as follows: (i) We identify and categorize the critical cases for grapheme to phoneme (G2P) conversion in Bangla language by analyzing the most frequent 100K words.", "labels": [], "entities": [{"text": "grapheme to phoneme (G2P) conversion", "start_pos": 94, "end_pos": 130, "type": "TASK", "confidence": 0.6625991591385433}]}, {"text": "(ii) We enrich the training lexicon for developing a robust G2P conversion system in Bangla language that performs much better for critical cases compared to other state-of-the-art G2P systems.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.7399481236934662}]}, {"text": "(iii) We perform phonetic transcriptions considering nasal vowels as separate phonemes.", "labels": [], "entities": []}, {"text": "(iv) We perform extensive simulations on largescale dataset and show that our methodology outperforms other state-of-the-art approaches for G2P conversion in Bangla language by providing word-level accuracy of 90.2%.", "labels": [], "entities": [{"text": "G2P conversion", "start_pos": 140, "end_pos": 154, "type": "TASK", "confidence": 0.7877860963344574}, {"text": "accuracy", "start_pos": 198, "end_pos": 206, "type": "METRIC", "confidence": 0.9662514925003052}]}, {"text": "The rest of the paper is organized as follows: we discuss the previous works in Section 2, our phoneme list in Section 3, identification of critical cases and categorization of errors in Section 4, development of our system in Section 5, experimental results in Section 6, and conclusion and future works in Section 7.", "labels": [], "entities": [{"text": "identification of critical cases", "start_pos": 122, "end_pos": 154, "type": "TASK", "confidence": 0.8746912032365799}]}], "datasetContent": [{"text": "We run extensive simulations and use two measures for evaluating the performances of the systems: Word Error Rate (WER): For calculating Word Error Rate (WER), we use the following formula: where E denotes the number of words that have disagreement in their generated phoneme sequence and reference phoneme sequence, and T denotes the total number of words.", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 98, "end_pos": 119, "type": "METRIC", "confidence": 0.8780417541662852}, {"text": "Word Error Rate (WER)", "start_pos": 137, "end_pos": 158, "type": "METRIC", "confidence": 0.7994357446829478}]}, {"text": "Phoneme Error Rate (PER): For calculating Phoneme Error Rate (PER), we use the following formula: PER = I + S + D T where I, S, D denote respectively the total number of insertion, substitution, and deletion operations needed for all the words to align the generated phoneme sequence with the reference phoneme sequence for each word.", "labels": [], "entities": [{"text": "Phoneme Error Rate (PER)", "start_pos": 42, "end_pos": 66, "type": "METRIC", "confidence": 0.7654646188020706}, {"text": "PER", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9601583480834961}]}, {"text": "T denotes the total number of phonemes present in all the words.", "labels": [], "entities": [{"text": "T", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9700214862823486}]}, {"text": "Our best performing model is Transformer Model.", "labels": [], "entities": []}, {"text": "We use batch size of 4096.", "labels": [], "entities": []}, {"text": "Our neural network has 3 hidden layers, each containing 256 nodes.", "labels": [], "entities": []}, {"text": "We use a computer having 8GB RAM, Intel Core i7 CPU, and Nvidia Geforce 1050 GPU for running all of the simulations.", "labels": [], "entities": [{"text": "Nvidia Geforce 1050 GPU", "start_pos": 57, "end_pos": 80, "type": "DATASET", "confidence": 0.8216284215450287}]}, {"text": "For each model, we run the simulations for around 110K iterations taking around 5 hours.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Error classification of 30K critical cases, here  each of the four rightmost columns denotes the model  trained on that particular lexicon.", "labels": [], "entities": [{"text": "Error classification of 30K critical cases", "start_pos": 10, "end_pos": 52, "type": "TASK", "confidence": 0.7531202137470245}]}, {"text": " Table 3: Performance on Critical Cases", "labels": [], "entities": []}, {"text": " Table 4: Performance Comparison In General", "labels": [], "entities": []}, {"text": " Table 5: Performance comparison on different error  categories. Here each of the three rightmost columns  denotes the model trained on that particular lexicon.", "labels": [], "entities": []}, {"text": " Table 6: Effectiveness of critical cases. Both lexicons  are of size 60K. New Lexicon consists of 21K critical  cases and 39K entries from Google lexicon.", "labels": [], "entities": [{"text": "New Lexicon", "start_pos": 75, "end_pos": 86, "type": "DATASET", "confidence": 0.9104818999767303}]}]}