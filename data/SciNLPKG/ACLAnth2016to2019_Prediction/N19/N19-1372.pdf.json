{"title": [{"text": "Decay-Function-Free Time-Aware Attention to Context and Speaker Indicator for Spoken Language Understanding", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 78, "end_pos": 107, "type": "TASK", "confidence": 0.7915310064951578}]}], "abstractContent": [{"text": "To capture salient contextual information for spoken language understanding (SLU) of a dialogue , we propose time-aware models that automatically learn the latent time-decay function of the history without a manual time-decay function.", "labels": [], "entities": [{"text": "spoken language understanding (SLU) of a dialogue", "start_pos": 46, "end_pos": 95, "type": "TASK", "confidence": 0.8625341521369086}]}, {"text": "We also propose a method to identify and label the current speaker to improve the SLU accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9182425141334534}]}, {"text": "In experiments on the benchmark dataset used in Dialog State Tracking Challenge 4, the proposed models achieved significantly higher F1 scores than the state-of-the-art contextual models.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge 4", "start_pos": 48, "end_pos": 81, "type": "TASK", "confidence": 0.7857073724269867}, {"text": "F1 scores", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9829412996768951}]}, {"text": "Finally, we analyze the effectiveness of the introduced models in detail.", "labels": [], "entities": []}, {"text": "The analysis demonstrates that the proposed methods were effective to improve SLU accuracy individually.", "labels": [], "entities": [{"text": "SLU", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9441084861755371}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9485191702842712}]}], "introductionContent": [{"text": "Spoken language understanding (SLU) is a component that understands the user's utterance of a dialogue system.", "labels": [], "entities": [{"text": "Spoken language understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8449859321117401}]}, {"text": "Given an utterance, SLU generates a structured meaning representation of the utterance; i.e., a semantic frame.", "labels": [], "entities": []}, {"text": "SLU can be decomposed into several subtasks such as domain identification, intent prediction and slot filling; these subtasks can be jointly assigned using a single model).", "labels": [], "entities": [{"text": "domain identification", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.7897924482822418}, {"text": "intent prediction", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7456291913986206}, {"text": "slot filling", "start_pos": 97, "end_pos": 109, "type": "TASK", "confidence": 0.8326363861560822}]}, {"text": "The accuracy of SLU is important for the dialogue system to generate an appropriate response to a user.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999526858329773}]}, {"text": "To improve the accuracy of SLU, much work has used contextual information of dialogues to alleviate the ambiguity of recognition of the given utterance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9974570870399475}, {"text": "SLU", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9363977909088135}]}, {"text": "In SLU, selecting important history information is crucial, and it directly influences the improvement of SLU accuracy.", "labels": [], "entities": [{"text": "SLU", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9182415008544922}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9240739345550537}]}, {"text": "To summarize this history, content-aware models) similar to attention models in machine translation () have been proposed.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7613250017166138}]}, {"text": "However, content-aware models are likely to select the wrong history when the histories are similar in content.", "labels": [], "entities": []}, {"text": "To alleviate this problem, time-aware models ( which pay attention to recent previous utterances by using the temporal distance between a previous utterance and a current utterance are being considered; the models are based on mathematical formulas, time-decay functions, which are formulated by human, and decomposed into trainable parameters.", "labels": [], "entities": []}, {"text": "However, the previous time-aware models may not be sufficiently accurate.", "labels": [], "entities": []}, {"text": "In the models, either a single time-decay function is used or a limited number of time-decay functions are linearly combined; these manual functions may not be sufficiently flexible to learn an optimal time-decay function.", "labels": [], "entities": []}, {"text": "In this paper, we propose flexible and effective time-aware attention models to improve SLU accuracy.", "labels": [], "entities": [{"text": "SLU", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9458343982696533}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.8913260102272034}]}, {"text": "The proposed models do not need any manual time-decay function, but learn a timedecay tendency directly by introducing a trainable distance vector, and therefore have good SLU accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9739644527435303}]}, {"text": "The proposed models do not use long short-term memory (LSTM) to summarize histories, and therefore use fewer parameters than previous time-aware models.", "labels": [], "entities": []}, {"text": "We also propose current-speaker modeling by using a speaker indicator that identifies the current speaker.", "labels": [], "entities": [{"text": "current-speaker modeling", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7148870080709457}]}, {"text": "To the best of our knowledge, this is the first method that shows improvement by considering the identity of the current speaker.", "labels": [], "entities": []}, {"text": "This information maybe helpful for modeling multi-party conversations in addition to human-human conversations.", "labels": [], "entities": []}, {"text": "Prediction of the semantic label of the current utterance even using a conventional time-aware model can be difficult.).", "labels": [], "entities": []}, {"text": "The nearest utterance is \"Right.\", but it is not the most rele- vant utterance to the current utterance; the most relevant utterance is \"What are the places that I can have some memorable experiences there?\".", "labels": [], "entities": []}, {"text": "If we do not know the current speaker is Guide, we cannot easily assess the relative importance of the nearest histories of the two speakers.", "labels": [], "entities": []}, {"text": "We believe that the proposed 'speaker indicator' can help our model to identify such information.", "labels": [], "entities": []}, {"text": "In experiments on the Dialog State Tracking Challenge 4 (DSTC 4) dataset, the proposed models achieved significantly higher accuracy than the state-of-the-art contextual models for SLU.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge 4 (DSTC 4) dataset", "start_pos": 22, "end_pos": 72, "type": "DATASET", "confidence": 0.7915900856256485}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9985783100128174}, {"text": "SLU", "start_pos": 181, "end_pos": 184, "type": "TASK", "confidence": 0.8847116827964783}]}, {"text": "Also, we examine how the proposed methods affect the SLU accuracy in detail.", "labels": [], "entities": [{"text": "SLU", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.8212838768959045}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9715352058410645}]}, {"text": "This result shows that the proposed methods were effective to improve SLU accuracy individually.", "labels": [], "entities": [{"text": "SLU", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9443104267120361}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.946648895740509}]}, {"text": "Our contributions are as follows: \u2022 We propose a decay-function-free timeaware attention model that automatically learn the latent time-decay function of the history without a manual time-decay function.", "labels": [], "entities": []}, {"text": "The proposed model achieves anew state-of-the-art F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9851792454719543}]}, {"text": "\u2022 We propose a current-speaker modeling method that uses a speaker indicator to identify the current speaker.", "labels": [], "entities": []}, {"text": "We present how to incorporate speaker indicator in the proposed attention model for further improvement of SLU accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.914070725440979}]}, {"text": "\u2022 We propose a model that is aware of content as well as time, which also achieved a higher F1 score than the state-of-the-art contextual models.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9907386004924774}]}, {"text": "\u2022 We analyze the effectiveness of proposed methods in detail.", "labels": [], "entities": []}, {"text": "Our source code to reproduce the experimental results is available at https://github.com/jgkimi/ Decay-Function-Free-Time-Aware.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test the proposed models, we conducted language-understanding experiments on a dataset of human-human conversations.", "labels": [], "entities": []}, {"text": "We conducted experiments on the DSTC 4 dataset which consists of 35 dialogue sessions on touristic information for Singapore; they were collected from Skype calls of three tour guides with 35 tourists.", "labels": [], "entities": [{"text": "DSTC 4 dataset", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9537863930066427}]}, {"text": "The 35 dialogue sessions total 21 h, and include 31,034 utterances and 273,580 words (.", "labels": [], "entities": []}, {"text": "DSTC 4 is a suitable benchmark dataset for evaluation, because all of the dialogues have been manually transcribed and annotated with speech acts and semantic labels at each turn level.", "labels": [], "entities": [{"text": "DSTC 4", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9441339075565338}]}, {"text": "a semantic label consists of a speech act and associated attribute(s).", "labels": [], "entities": []}, {"text": "The speaker information (guide and tourist) is also provided.", "labels": [], "entities": []}, {"text": "Humanhuman dialogues contain rich and complex human behaviors and bring much difficulty to all tasks that are involved in SLU.", "labels": [], "entities": [{"text": "SLU", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9044533967971802}]}, {"text": "We used the same training dataset, the same test dataset and the same validation set as in the DSTC 4 competition: 14 dialogues as the training dataset, 6 dialogues as the validation dataset, and 9 dialogues as the test dataset.", "labels": [], "entities": [{"text": "DSTC 4 competition", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.8294644157091776}]}, {"text": "We used Adam ( as the optimizer in training the model.", "labels": [], "entities": []}, {"text": "We set the batch size to 256, and used pretrained 200-dimensional word embeddings GloVe ().", "labels": [], "entities": []}, {"text": "We applied 30 training epochs with early stopping.", "labels": [], "entities": []}, {"text": "We set the size dim of every hidden layer to 128, and the context length to 7.", "labels": [], "entities": []}, {"text": "We used the ground truth intents (semantic labels) to form an intentdense vector like previous work.", "labels": [], "entities": []}, {"text": "To evaluate SLU accuracy, we used the F1 score, which is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "SLU", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9000879526138306}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9693175554275513}, {"text": "F1 score", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9895740747451782}, {"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9994760155677795}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.995404839515686}]}, {"text": "To validate the significance of improvements, we used a onetailed t-test.", "labels": [], "entities": []}, {"text": "We ran each model ten times, and report their average scores.", "labels": [], "entities": []}, {"text": "As baseline models, we used the state-of-the-art contextual models, and most accurate participant of DSTC 4 (DSTC 4 -Best) (  reported in the papers 1 . We ran three additional baseline models in which the prediction stage is the same: (1) 'No Context' uses no context summary; (2) 'LSTM-Used Context Summary without Attention' uses the context summary of bidirectional LSTM without an attention mechanism, and (3) 'LSTM-Used Content-Aware Attention' uses context summary of bidirectional LSTM after content-aware attention is applied to histories, as in previous approaches.", "labels": [], "entities": [{"text": "DSTC 4 (DSTC 4 -Best)", "start_pos": 101, "end_pos": 122, "type": "DATASET", "confidence": 0.8696394264698029}, {"text": "LSTM-Used Context Summary without Attention", "start_pos": 283, "end_pos": 326, "type": "TASK", "confidence": 0.7616564452648162}]}], "tableCaptions": [{"text": " Table 1: SLU accuracy on DSTC 4.  *  : p < 0.05;  *  *  , p < 0.01 compared to all the baseline models. Italicized  scores are reported in the references. Model names are described in the text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9795153737068176}, {"text": "DSTC 4", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.8809593617916107}]}, {"text": " Table 2: SLU accuracy of possible combinations of the  proposed methods. \"no attention\": sum of all history  vectors without calculating \u03b1, \"Content\" is content- aware attention (Decay-Function-Free Content-Aware  Attention), \"Time\" is the proposed time-aware at- tention (Decay-Function-Free Time-Aware Attention),  \"Content + Time\" is the proposed content-and-time- aware attention (Decay-Function-Free Content-and- Time-Aware Attention), \"Content x Time\" is variant  content-and-time-aware attention (Decay-Function- Free Inseparate Content-and-Time-Aware Attention).   *  : p < 0.05;  *  *  , p < 0.01 compared to the same at- tention without speaker indicator. An attention type in  bold is the speaker-involved part.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9767487049102783}]}, {"text": " Table 3: SLU accuracy of possible combinations of the  proposed methods in role-level attention with different  history representations. Int. used intent vector; Dist.  used distance vector.  *  : p < 0.05;  *  *  , p < 0.01 com- pared to using intent only. Other codes are as in Table  2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9486392140388489}]}]}