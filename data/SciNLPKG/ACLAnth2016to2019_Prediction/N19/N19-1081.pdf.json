{"title": [{"text": "Sub-Event Detection from Twitter Streams as a Sequence Labeling Problem", "labels": [], "entities": [{"text": "Sub-Event Detection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.745544046163559}, {"text": "Sequence Labeling", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.8400900363922119}]}], "abstractContent": [{"text": "This paper introduces improved methods for sub-event detection in social media streams, by applying neural sequence models not only on the level of individual posts, but also directly on the stream level.", "labels": [], "entities": [{"text": "sub-event detection", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7488072216510773}]}, {"text": "Current approaches to identify sub-events within a given event, such as a goal during a soccer match, essentially do not exploit the sequential nature of social media streams.", "labels": [], "entities": []}, {"text": "We address this shortcoming by framing the sub-event detection problem in social media streams as a sequence labeling task and adopt a neural sequence architecture that explicitly accounts for the chronological order of posts.", "labels": [], "entities": [{"text": "sub-event detection", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7649886608123779}]}, {"text": "Specifically, we (i) establish a neural baseline that outperforms a graph-based state-of-the-art method for binary sub-event detection (2.7% micro-F 1 improvement), as well as (ii) demonstrate superiority of a recurrent neural network model on the posts sequence level for labeled sub-events (2.4% bin-level F 1 improvement over non-sequential models).", "labels": [], "entities": [{"text": "binary sub-event detection", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.7584841052691141}, {"text": "bin-level F 1", "start_pos": 298, "end_pos": 311, "type": "METRIC", "confidence": 0.6740501125653585}]}], "introductionContent": [{"text": "Social media allow users to communicate via realtime postings and interactions, with Twitter as a notable example.", "labels": [], "entities": []}, {"text": "Twitter user posts, i.e., tweets, are often related to events.", "labels": [], "entities": []}, {"text": "These can be social events (concerts, research conferences, sports events, etc.), emergency situations (e.g., terrorist attacks), etc.", "labels": [], "entities": []}, {"text": "For a single event, multiple tweets are posted, by people with various personalities and social behavior.", "labels": [], "entities": []}, {"text": "Hence, even more so than (typically more neutral) traditional media, this implies many different perspectives, offering an interesting aggregated description.", "labels": [], "entities": []}, {"text": "Given this continuous and large stream of (likely duplicated) information in Twitter streams, and their noisy nature, it is challenging to keep track of the main parts of an event, such as a soccer match.", "labels": [], "entities": []}, {"text": "Automating such extraction of different sub-events within an evolving event is known as sub-event detection ().", "labels": [], "entities": [{"text": "sub-event detection", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7179020047187805}]}, {"text": "For tracking each of the sub-events, the timing aspect is an important concept (i.e., consecutive tweets in time).", "labels": [], "entities": [{"text": "timing", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9371397495269775}]}, {"text": "Thus, a sequential model could successfully exploit chronological relations between the tweets in a Twitter stream as an informative feature for sub-event detection.", "labels": [], "entities": [{"text": "sub-event detection", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.7426903247833252}]}, {"text": "Several methods have been proposed for subevent detection: clustering methods (, graph-based approaches (), topic models () and neural network architectures (.", "labels": [], "entities": [{"text": "subevent detection", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.83878955245018}]}, {"text": "None of these studies exploits the chronological relation between consecutive tweets.", "labels": [], "entities": []}, {"text": "In contrast, our work does take into account that chronological order and we predict the presence and the type of a sub-event exploiting information from previous tweets.", "labels": [], "entities": []}, {"text": "Specifically, we (i) propose anew neural baseline model that outperforms the state-of-the-art performance on the binary classification problem of detecting the presence/absence of sub-events in a sports stream, (ii) establish anew reasonable baseline for predicting also the sub-event types, (iii) explicitly take into account chronological information, i.e., the relation among consecutive tweets, by framing sub-event detection as a sequence labeling problem on top of our baseline model, and (iv) perform an experimental study, indicating the benefit of sequence labeling for sub-event detection in sports Twitter streams.", "labels": [], "entities": [{"text": "sub-event detection", "start_pos": 410, "end_pos": 429, "type": "TASK", "confidence": 0.7563277781009674}, {"text": "sub-event detection", "start_pos": 579, "end_pos": 598, "type": "TASK", "confidence": 0.737267255783081}]}], "datasetContent": [{"text": "We evaluated our system 1 on the dataset from, with tweets on 20 soccer matches from the 2010 and 2014 FIFA World Cups, totalling over 2M pre-processed tweets filtered from 6.1M collected ones, comprising 185 events.", "labels": [], "entities": []}, {"text": "The dataset includes a set of sub-events, such as goal, kick-off, half-time, etc.", "labels": [], "entities": []}, {"text": "To compare our binary classification baseline system to previous methods, we use the same train/test splits as, where 3 matches are used for training and 17 matches as test set.", "labels": [], "entities": []}, {"text": "In this setting, we predict only the presence/absence of a sub-event.", "labels": [], "entities": []}, {"text": "Similar to previous work, we count a sub-event as correct if at least one of its comprising bins has been classified as a subevent.", "labels": [], "entities": []}, {"text": "For the experimental study of our proposed sequence labeling approach for sub-event detection, where sub-event types are predicted, we have randomly split the test set into test (10 matches) and development (7 matches) sets.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.6672099232673645}, {"text": "sub-event detection", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7413976341485977}]}, {"text": "We use the development set to optimize the F 1 score for tuning of the model parameters, i.e., the word/tweet embedding representation size, LSTM hidden state size, dropout probability.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9774899284044901}, {"text": "LSTM hidden state size", "start_pos": 141, "end_pos": 163, "type": "METRIC", "confidence": 0.5623139888048172}]}, {"text": "We adopt 2 evaluation strategies.", "labels": [], "entities": []}, {"text": "The first one, referred to as relaxed evaluation, is commonly used in entity classification tasks,c) and similar to the binary classification baseline system evaluation: score a multibin sub-event as correct if at least one of its comprising bin types (e.g., goal) is correct, assuming that the boundaries are given.", "labels": [], "entities": [{"text": "entity classification tasks,c", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.7905378739039103}]}, {"text": "The second evaluation strategy, bin-level, is stricter: we count each bin individually, and check whether its sub-event type has been predicted correctly, similar to the token-based evaluation followed in. shows the experimental results of our baseline model.", "labels": [], "entities": []}, {"text": "The Burst baseline system is based on the tweeting rate in a specific time window (i.e., bin) and if a threshold is exceed, the system identifies that a sub-event has occurred.", "labels": [], "entities": [{"text": "Burst", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8476126790046692}]}, {"text": "We report evaluation scores as presented in.", "labels": [], "entities": []}, {"text": "The second approach is the graph-based method of.", "labels": [], "entities": []}, {"text": "We observe that our baseline system (Section 3.3) has a 1.2% improvement in terms of macro-F 1 and 2.7% improvement in terms of micro-F 1 , compared to the graph-based model from, mainly due to increased precision, and despite the recall loss.", "labels": [], "entities": [{"text": "precision", "start_pos": 204, "end_pos": 213, "type": "METRIC", "confidence": 0.999371349811554}, {"text": "recall", "start_pos": 231, "end_pos": 237, "type": "METRIC", "confidence": 0.9993595480918884}]}, {"text": "illustrates the predictive performance of our proposed model (i.e., using the chronological LSTM) compared to models making independent predictions per bin.", "labels": [], "entities": []}, {"text": "The upper part of contains models without the chronological LSTM.", "labels": [], "entities": []}, {"text": "Our experiments study both word-level and tweetlevel bin representations (see), as reflected in the 'Word' vs. 'Tweet' prefix, respectively, in the Model column of.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparing our neural network binary classifi- cation baseline model to state-of-the-art (P = precision,  R = recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9471864700317383}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.8744775652885437}]}, {"text": " Table 2: Comparison of our baseline methods in terms  of micro bin-level and relaxed F 1 score with and with- out chronological LSTM (see", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9588687022527059}]}]}