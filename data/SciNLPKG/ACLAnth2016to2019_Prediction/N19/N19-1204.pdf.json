{"title": [{"text": "A Robust Abstractive System for Cross-Lingual Summarization", "labels": [], "entities": [{"text": "Cross-Lingual Summarization", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.8199598491191864}]}], "abstractContent": [{"text": "We present a robust neural abstractive summa-rization system for cross-lingual summariza-tion.", "labels": [], "entities": []}, {"text": "We construct summarization corpora for documents automatically translated from three low-resource languages, Somali, Swahili, and Tagalog, using machine translation and the New York Times summarization corpus.", "labels": [], "entities": [{"text": "New York Times summarization corpus", "start_pos": 173, "end_pos": 208, "type": "DATASET", "confidence": 0.6408738553524017}]}, {"text": "We train three language-specific abstractive sum-marizers and evaluate on documents originally written in the source languages, as well as on a fourth, unseen language: Arabic.", "labels": [], "entities": []}, {"text": "Our systems achieve significantly higher fluency than a standard copy-attention summarizer on automatically translated input documents, as well as comparable content selection.", "labels": [], "entities": [{"text": "copy-attention summarizer", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.8164961040019989}]}], "introductionContent": [{"text": "Cross-lingual summarization is a little-explored task combining the difficulties of automatic summarization with those of machine translation.", "labels": [], "entities": [{"text": "Cross-lingual summarization", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6108734011650085}, {"text": "summarization", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.8506507277488708}, {"text": "machine translation", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7397184371948242}]}, {"text": "The goal is to summarize in one language a document available only in another language.", "labels": [], "entities": [{"text": "summarize", "start_pos": 15, "end_pos": 24, "type": "TASK", "confidence": 0.9703932404518127}]}, {"text": "describe two approaches: summarize then translate, and translate then summarize.", "labels": [], "entities": []}, {"text": "They argue that summarize-then-translate is preferable to avoid both the computational expense of translating more sentences and sentence extraction errors caused by incorrect translations.", "labels": [], "entities": [{"text": "summarize-then-translate", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.9662072062492371}, {"text": "sentence extraction", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.6954838782548904}]}, {"text": "However, summarize-then-translate can only be used when the source language is high-resource ( English as the source, for example); if the source language is one of the thousands of low-resource languages in the world, there are no summarization corpora available.", "labels": [], "entities": []}, {"text": "Languageindependent techniques, such as TextRank (Mihalcea), might be used, but there maybe serious difficulties in their application, such as morphologically rich languages that render token-based similarity measures useless.", "labels": [], "entities": [{"text": "TextRank (Mihalcea)", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.8241006433963776}]}, {"text": "In such a case, translatethen-summarize is the only possible approach.", "labels": [], "entities": []}, {"text": "We address this scenario through the development of a neural abstractive summarization system that fluently summarizes potentially disfluent, automatically-translated documents by generating short, simple phrases to replace awkward input phrases resulting from difficult to translate source documents.", "labels": [], "entities": [{"text": "neural abstractive summarization", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.6416332920392355}]}, {"text": "Our novel combination of existing building block systems results in a summarization solution that can be easily applied to new lowresource languages.", "labels": [], "entities": []}, {"text": "We use machine translation on the New York Times annotated corpus of document/summary pairs to create summarization corpora for documents automatically translated from three low-resource languages, Somali, Swahili, and Tagalog.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7103831022977829}]}, {"text": "We use these corpora to train crosslingual summarizers for these source languages, with English as the target.", "labels": [], "entities": []}, {"text": "We also evaluate our systems on a fourth source language, Arabic.", "labels": [], "entities": []}, {"text": "Our experiments show that our abstractive summarizers produce more fluent English summaries from automatically-translated documents, and that this improvement generalizes across source languages.", "labels": [], "entities": []}, {"text": "Our main contributions are as follows: \u2022 We create summarization corpora for automatically translated Somali, Swahili, and Tagalog documents: noisy English input documents paired with clean English reference summaries.", "labels": [], "entities": [{"text": "summarization corpora", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.8827040493488312}]}, {"text": "\u2022 We present a method for producing crosslingual summarization systems for low resource languages where no summarization corpora currently exist, providing a potential summarization solution for thousands of such languages.", "labels": [], "entities": [{"text": "summarization", "start_pos": 168, "end_pos": 181, "type": "TASK", "confidence": 0.9812814593315125}]}, {"text": "\u2022 Our novel approach of training on noisy input with clean references outperforms a standard copy-attention abstractive summarizer on realworld Somali, Swahili, and Tagalog documents.", "labels": [], "entities": [{"text": "copy-attention abstractive summarizer", "start_pos": 93, "end_pos": 130, "type": "TASK", "confidence": 0.8102733691533407}]}, {"text": "\u2022 Our evaluation on Arabic documents demonstrates that our robust abstractive summarizers in the editor: why did president clinton continue to praise a program on welfare-to-work that failed in half of those assigned?", "labels": [], "entities": []}, {"text": "in his comments, he praised the consultation of the community of kansas city, but was advised by gary j. stangler, director of the department of social service of missouri, which half of the participants failed.", "labels": [], "entities": []}, {"text": "where are these people helping each other when the government cut them?", "labels": [], "entities": []}, {"text": "back to the pantry of food.", "labels": [], "entities": []}, {"text": "bad news, mr. president.", "labels": [], "entities": []}, {"text": "the charity of the community will not help everyone who will come to us for help.", "labels": [], "entities": []}, {"text": "glenn classic valley park, mo. generalize to unseen languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "shows the performance of our abstractors on the Somali, Swahili, and Tagalog NYT test sets.", "labels": [], "entities": [{"text": "Somali, Swahili, and Tagalog NYT test sets", "start_pos": 48, "end_pos": 90, "type": "DATASET", "confidence": 0.6058733264605204}]}, {"text": "Differences among the language-specific systems are not statistically significant, and the more general mixed model achieved the best scores 1 . However, we found that abstractors trained solely on one language and tested on another significantly (p < 0.05) underperformed the mixed model, which was trained on all three languages, suggesting that training on some same-language data is still important.", "labels": [], "entities": []}, {"text": "We also trained a bigram language model on the entire set of NYT reference summaries and Document: mange kimambi 'i pray for the parliamentary seat for kinondoni constituency for ticket of ccm.", "labels": [], "entities": [{"text": "NYT reference summaries", "start_pos": 61, "end_pos": 84, "type": "DATASET", "confidence": 0.9283119638760885}]}, {"text": "not special seats' kinondoni without drugs is possible i pray for the parliamentary seat for kinondoni constituency on the ticket of ccm.", "labels": [], "entities": []}, {"text": "yes, it's not a special seats, khuini kinondoni, what will i do for kinondoni?", "labels": [], "entities": []}, {"text": "tension is many i get but we must remember no good that is available easily.", "labels": [], "entities": []}, {"text": "kinondoni without drugs is possible.", "labels": [], "entities": []}, {"text": "as a friend, fan or patriotism i urge you to grant your contribution to the situation and propert.", "labels": [], "entities": [{"text": "propert", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9883052110671997}]}, {"text": "you can use western union or money to go to mange john kimambi.", "labels": [], "entities": []}, {"text": "account of crdb bank is on blog.", "labels": [], "entities": [{"text": "crdb bank", "start_pos": 11, "end_pos": 20, "type": "DATASET", "confidence": 0.9378159940242767}]}, {"text": "reduce my profile in my blog understand why i have decided to vie for kinondoni constituency.", "labels": [], "entities": []}, {"text": "NYT-base: mange kimambi, who pray for parliamentary seat for kinondoni constituency for ticket of ccm in 0 , is on blog, and not special seats' kinondoni without drugs.", "labels": [], "entities": [{"text": "NYT-base", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.969651460647583}]}, {"text": "Abs-mix: mange kimambi, who pray for parliamentary seat for kinondoni constituency for ticket of ccm, comments on his plans to vie for 'kinondoni' without drugs.", "labels": [], "entities": [{"text": "Abs-mix", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9147404432296753}]}, {"text": "calculated the average perplexity of our abstractors' output as a proxy for fluency.", "labels": [], "entities": []}, {"text": "We see that Somali is the most difficult overall, but all three language-specific systems and the mixed model produce more fluent English across source languages than does the base model.", "labels": [], "entities": []}, {"text": "We perform a human evaluation on 20 Somali, 20 Swahili, and 20 Tagalog weblog entries that we automatically translate into English using the same neural machine translation systems we used to create our noisy NYT corpora.", "labels": [], "entities": []}, {"text": "Unlike our NYT data, which we translated from English into the low-resource languages, these weblogs are realworld Somali, Swahili, and Tagalog documentsthis evaluation demonstrates the performance of our system in areal use-case.", "labels": [], "entities": [{"text": "NYT data", "start_pos": 11, "end_pos": 19, "type": "DATASET", "confidence": 0.8520969450473785}]}, {"text": "shows a Swahili weblog entry and its summaries 2 . This example shows the advantage of our approach: unlike a machine translation system, which must translate every part of its input, our abstractor is able to delete most of the long, rambling, and disfluent blog entry, instead summing it up fluently with the generated phrase \"comments on his plans\" and the repurposed phrase \"to vie for\".", "labels": [], "entities": []}, {"text": "We use five human judges, all native English speakers and none of whom are the authors.", "labels": [], "entities": []}, {"text": "The 2 All four abstractors produced very similar summaries.", "labels": [], "entities": []}, {"text": "judges were shown a translated document and a summary and asked to rate the content and fluency of the summary on a scale of 1-3).", "labels": [], "entities": []}, {"text": "Our human judges rated our abstractors higher in both fluency and content, and we see again that while the language-specific systems are more fluent on their own languages than are the language-specific systems for the other languages, the mixed model still performs the best.", "labels": [], "entities": []}, {"text": "We also see that, while our improvement in content is more modest, our improvement in fluency -the goal of this work -is significant.", "labels": [], "entities": []}, {"text": "The judges achieved substantial agreement (Fleiss's \u03ba = 0.72).", "labels": [], "entities": [{"text": "Fleiss's \u03ba", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9587945342063904}]}, {"text": "Finally, we evaluate our system on anew language: Arabic.", "labels": [], "entities": []}, {"text": "We use the DUC 2004 Task 3 test set, which consists of real-world Arabic news articles translated into English, each paired with four human-written summaries.", "labels": [], "entities": [{"text": "DUC 2004 Task 3 test set", "start_pos": 11, "end_pos": 35, "type": "DATASET", "confidence": 0.9616644382476807}]}, {"text": "shows the performance of our abstractors on the Arabic data, demonstrating their ability to generalize and improve the fluency of input documents automatically translated from a previously unseen language, yielding a significant improvement in ROUGE.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 244, "end_pos": 249, "type": "METRIC", "confidence": 0.9304521679878235}]}, {"text": "Compared to the 28 DUC 2004 systems, our performance would have ranked 1 st on summarizing the machine-translated documents; despite our use of these lower-quality, au-Document: washington 10-23 (afp) was signed by benjamin netanyahu and yasser arafat on friday at the white house agreed on the israeli military withdrawal from the west bank in return for palestinian additional security guarantees.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.8278533220291138}]}, {"text": "NYT-base: washington 10-23, signed by benjamin netanyahu and yasser arafat, agrees on israeli military withdrawal from west bank in return for palestinian additional security guarantees.", "labels": [], "entities": [{"text": "NYT-base", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9174210429191589}, {"text": "washington 10-23", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.7458930611610413}]}, {"text": "Abs-mix: benjamin netanyahu and yasser arafat agree on israeli military withdrawal from west bank in return for palestinian security guarantees.: An Arabic article, automatically translated into English, and its baseline and mixed model summaries.", "labels": [], "entities": [{"text": "Abs-mix", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9840781688690186}]}, {"text": "tomatically-translated documents, we performed extremely well even in comparison with the DUC 2004 systems on high-quality, human-translated documents: we would have ranked 1 st , 4 th , and 5 th on ROUGE-1, -2, and -L, respectively.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.9388091266155243}, {"text": "ROUGE-1", "start_pos": 199, "end_pos": 206, "type": "METRIC", "confidence": 0.9288234710693359}]}, {"text": "compares the baseline system and our abstractors on the Arabic data 3 .", "labels": [], "entities": [{"text": "Arabic data", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.7588500678539276}]}], "tableCaptions": [{"text": " Table 1: Neural machine translation performance.", "labels": [], "entities": [{"text": "Neural machine translation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8105971217155457}]}, {"text": " Table 2: Baseline summarizer performance.", "labels": [], "entities": [{"text": "summarizer", "start_pos": 19, "end_pos": 29, "type": "TASK", "confidence": 0.6987036466598511}]}, {"text": " Table 3: Abs-so, -sw, and -tl are the Somali, Swahili,  and Tagalog systems, respectively. * indicates signifi- cant improvement over NYT-base (p < 1.16 \u00d7 10 \u221219 ).", "labels": [], "entities": [{"text": "Abs-so", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9977043271064758}, {"text": "NYT-base", "start_pos": 135, "end_pos": 143, "type": "DATASET", "confidence": 0.7675358653068542}]}, {"text": " Table 4: Language model perplexity of generated sum- maries on noisy Somali, Swahili, and Tagalog NYT.", "labels": [], "entities": []}, {"text": " Table 5: Average human-rated content and fluency scores on Somali, Swahili, and Tagalog weblog entries.", "labels": [], "entities": []}, {"text": " Table 6: DUC 2004 with ISI translations. * indi- cates significant improvement over NYT-base (p <  2.09\u00d710 \u22126 );  \u2020 indicates significant difference between  systems (p < 0.05).", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.9560205042362213}, {"text": "NYT-base", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.804705798625946}]}]}