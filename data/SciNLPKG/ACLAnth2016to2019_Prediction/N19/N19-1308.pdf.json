{"title": [{"text": "A General Framework for Information Extraction using Dynamic Span Graphs", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7726954519748688}]}], "abstractContent": [{"text": "We introduce a general framework for several information extraction tasks that share span representations using dynamically constructed span graphs.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.8155544201532999}]}, {"text": "The graphs are constructed by selecting the most confident entity spans and linking these nodes with confidence-weighted relation types and coreferences.", "labels": [], "entities": []}, {"text": "The dynamic span graph allows coreference and relation type confidences to propagate through the graph to iteratively refine the span representations.", "labels": [], "entities": []}, {"text": "This is unlike previous multi-task frameworks for information extraction in which the only interaction between tasks is in the shared first-layer LSTM.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.8102996051311493}]}, {"text": "Our framework significantly outperforms the state-of-the-art on multiple information extraction tasks across multiple datasets reflecting different domains.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7442170083522797}]}, {"text": "We further observe that the span enumeration approach is good at detecting nested span entities , with significant F1 score improvement on the ACE dataset.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9850068092346191}, {"text": "ACE dataset", "start_pos": 143, "end_pos": 154, "type": "DATASET", "confidence": 0.9809275269508362}]}], "introductionContent": [{"text": "Most Information Extraction (IE) tasks require identifying and categorizing phrase spans, some of which might be nested.", "labels": [], "entities": [{"text": "Information Extraction (IE) tasks", "start_pos": 5, "end_pos": 38, "type": "TASK", "confidence": 0.868938018878301}]}, {"text": "For example, entity recognition involves assigning an entity label to a phrase span.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.8337833285331726}]}, {"text": "Relation Extraction (RE) involves assigning a relation type between pairs of spans.", "labels": [], "entities": [{"text": "Relation Extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8935703873634339}]}, {"text": "Coreference resolution groups spans referring to the same entity into one cluster.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8547069430351257}]}, {"text": "Thus, we might expect that knowledge learned from one task might benefit another.", "labels": [], "entities": []}, {"text": "Most previous work in IE (e.g.,) employs a pipeline approach, first detecting entities and then using the detected entity spans for relation extraction and coreference resolution.", "labels": [], "entities": [{"text": "IE", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9815457463264465}, {"text": "relation extraction", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.7972233295440674}, {"text": "coreference resolution", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.954721987247467}]}, {"text": "To avoid cascading errors introduced by pipeline-style systems, recent work has focused on coupling different IE tasks as in joint modeling of entities and relations, entities and coreferences (), joint inference ( or multi-task (entity/relation/coreference) learning ().", "labels": [], "entities": []}, {"text": "These models mostly rely on the first layer LSTM to share span representations between different tasks and are usually designed for specific domains.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a general framework Dynamic Graph IE (DYGIE) for coupling multiple information extraction tasks through shared span representations which are refined leveraging contextualized information from relations and coreferences.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.8075135747591654}]}, {"text": "Our framework is effective in several domains, demonstrating a benefit from incorporating broader context learned from relation and coreference annotations.", "labels": [], "entities": []}, {"text": "shows an example illustrating the potential benefits of entity, relation, and coreference contexts.", "labels": [], "entities": []}, {"text": "It is impossible to predict the entity labels for This thing and it from within-sentence context alone.", "labels": [], "entities": []}, {"text": "However, the antecedent car strongly suggests that these two entities have a VEH type.", "labels": [], "entities": []}, {"text": "Similarly, the fact that Tom is located at Starbucks and Mike has a relation to Tom provides support for the fact that Mike is located at Starbucks.", "labels": [], "entities": []}, {"text": "DYGIE uses multi-task learning to identify entities, relations, and coreferences through shared span representations using dynamically constructed span graphs.", "labels": [], "entities": [{"text": "DYGIE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9190225601196289}]}, {"text": "The nodes in the graph are dynamically selected from abeam of highly-confident mentions, and the edges are weighted according to the confidence scores of relation types or coreferences.", "labels": [], "entities": []}, {"text": "Unlike the multi-task method that only shares span representations from the local context (), our framework leverages rich contextual span representations by propagating information through coreference and relation links.", "labels": [], "entities": []}, {"text": "Unlike previous BIO-based entity recognition systems) that assign a text span to at most one entity, our framework enumerates and represents all possible spans to recognize arbitrarily overlapping entities.", "labels": [], "entities": [{"text": "BIO-based entity recognition", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.5730444689591726}]}, {"text": "We evaluate DYGIE on several datasets spanning many domains (including news, scientific articles, and wet lab experimental protocols), achieving state-of-the-art performance across all tasks and domains and demonstrating the value of coupling related tasks to learn richer span representations.", "labels": [], "entities": []}, {"text": "For example, DYGIE achieves relative improvements of 5.7% and 9.9% overstate of the art on the ACE05 entity and relation extraction tasks, and an 11.3% relative improvement on the ACE05 overlapping entity extraction task.", "labels": [], "entities": [{"text": "ACE05 entity and relation extraction", "start_pos": 95, "end_pos": 131, "type": "TASK", "confidence": 0.5911399543285369}, {"text": "ACE05 overlapping entity extraction task", "start_pos": 180, "end_pos": 220, "type": "TASK", "confidence": 0.8075434327125549}]}, {"text": "The contributions of this paper are threefold.", "labels": [], "entities": []}, {"text": "1) We introduce the dynamic span graph framework as a method to propagate global contextual information, making the code publicly available.", "labels": [], "entities": []}, {"text": "2) We demonstrate that our framework significantly outperforms the state-of-the-art on joint entity and relation detection tasks across four datasets: ACE 2004, ACE 2005, SciERC and the Wet Lab Protocol Corpus.", "labels": [], "entities": [{"text": "joint entity and relation detection", "start_pos": 87, "end_pos": 122, "type": "TASK", "confidence": 0.6250212848186493}, {"text": "ACE 2004", "start_pos": 151, "end_pos": 159, "type": "DATASET", "confidence": 0.9260275363922119}, {"text": "ACE 2005", "start_pos": 161, "end_pos": 169, "type": "DATASET", "confidence": 0.8139021396636963}, {"text": "Wet Lab Protocol Corpus", "start_pos": 186, "end_pos": 209, "type": "DATASET", "confidence": 0.7414014488458633}]}, {"text": "3) We further show that our approach excels at detecting entities with overlapping spans, achieving an improvement of up to 8 F1 points on three benchmarks annotated with overlapped spans: ACE 2004, ACE 2005 and GENIA.", "labels": [], "entities": [{"text": "F1", "start_pos": 126, "end_pos": 128, "type": "METRIC", "confidence": 0.9960446357727051}, {"text": "ACE 2004", "start_pos": 189, "end_pos": 197, "type": "DATASET", "confidence": 0.8930180668830872}, {"text": "ACE 2005", "start_pos": 199, "end_pos": 207, "type": "DATASET", "confidence": 0.8330826759338379}, {"text": "GENIA", "start_pos": 212, "end_pos": 217, "type": "DATASET", "confidence": 0.9198269248008728}]}], "datasetContent": [{"text": "DYGIE is a general IE framework that can be applied to multiple tasks.", "labels": [], "entities": [{"text": "DYGIE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9283643960952759}]}, {"text": "We evaluate the performance of DYGIE against models from two lines of work: combined entity and relation extraction, and overlapping entity extraction.", "labels": [], "entities": [{"text": "combined entity and relation extraction", "start_pos": 76, "end_pos": 115, "type": "TASK", "confidence": 0.6530141294002533}, {"text": "overlapping entity extraction", "start_pos": 121, "end_pos": 150, "type": "TASK", "confidence": 0.6432652274767557}]}], "tableCaptions": [{"text": " Table 1: Datasets for joint entity and relation extraction  and their statistics. Ent: Number of entity categories.  Rel: Number of relation categories.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.725612223148346}, {"text": "Ent", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.8666096329689026}, {"text": "Rel", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.9489596486091614}]}, {"text": " Table 2: F1 scores on the joint entity and relation ex- traction task on each test set, compared against the pre- vious best systems. * indicates relation extraction sys- tem that takes gold entity boundary as input.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995027780532837}]}, {"text": " Table 3: Datasets for overlapping entity extraction and  their statistics. Ent: Number of entity categories. Over- lap: Percentage of sentences that contain overlapping  entities.", "labels": [], "entities": [{"text": "overlapping entity extraction", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.6735268533229828}, {"text": "Ent", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9260769486427307}, {"text": "Over- lap", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.8599019050598145}]}, {"text": " Table 4: Performance on the overlapping entity extrac- tion task, compared to previous best systems. We re- port F1 of extracted entities on the test sets.", "labels": [], "entities": []}, {"text": " Table 5: Ablations on the ACE05 development set with  different graph propagation setups. \u2212CorefProp  ablates the coreference propagation layers, while  \u2212RelProp ablates the relation propagation layers.  Base is the system without any propagation.", "labels": [], "entities": [{"text": "ACE05 development set", "start_pos": 27, "end_pos": 48, "type": "DATASET", "confidence": 0.9711280663808187}]}, {"text": " Table 6: Ablations on the SciERC development set on  different graph progation setups. CorefProp has a  much smaller effect on entity F1 compared to ACE05.", "labels": [], "entities": [{"text": "F1", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.8879337906837463}]}, {"text": " Table 7: Entity extraction performance on pronouns in  ACE05. CorefProp significantly increases entity ex- traction F1 on hard-to-disambiguate pronouns by allow- ing the model to leverage cross-sentence contexts.", "labels": [], "entities": [{"text": "Entity extraction", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6897642314434052}, {"text": "ACE05", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.936741292476654}, {"text": "entity ex- traction F1", "start_pos": 97, "end_pos": 119, "type": "METRIC", "confidence": 0.6585746109485626}]}, {"text": " Table 8: Difference in the confusion matrix counts  for ACE05 entity extraction associated with adding  CorefProp.", "labels": [], "entities": [{"text": "ACE05 entity extraction", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.6833676894505819}]}]}