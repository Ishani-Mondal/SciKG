{"title": [{"text": "A Framework for Decoding Event-Related Potentials from Text", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel framework for modeling event-related potentials (ERPs) collected during reading that couples pre-trained convolu-tional decoders with a language model.", "labels": [], "entities": []}, {"text": "Using this framework, we compare the abilities of a variety of existing and novel sentence processing models to reconstruct ERPs.", "labels": [], "entities": []}, {"text": "We find that modern contextual word embeddings under-perform surprisal-based models but that, combined , the two outperform either on its own.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding the mechanisms by which comprehenders incrementally process linguistic input in real time has been a key endeavor of cognitive scientists and psycholinguists.", "labels": [], "entities": []}, {"text": "Due to its fine time resolution, event-related potentials (ERPs) are an effective tool in probing the rapid, online cognitive processes underlying language comprehension.", "labels": [], "entities": []}, {"text": "Traditionally, ERP research has focused on how the properties of the language input affect different ERP components (see, for reviews).", "labels": [], "entities": []}, {"text": "While this approach has been fruitful, researchers have also long been aware of the potential drawbacks to this component-centric approach: a predictor's effects can be too transient to detect when averaging ERP amplitudes over a wide time window-as is typical in componentbased approaches (see, for discussion).", "labels": [], "entities": []}, {"text": "Different predictors can affect ERP in the same time window as an established component but have slightly different temporal) or spatial (DeLong et al., Examples of such components include the N1/P2 (); N250 (); N400 (; and P600 Figure 1: An instance of our framework using a bidirectional language model as the text encoder. 2005) profiles.", "labels": [], "entities": []}, {"text": "This means that the definition of a component strongly affects interpretation.", "labels": [], "entities": []}, {"text": "There are two typical approaches to resolving these issues.", "labels": [], "entities": []}, {"text": "The first is to plot the data and use visual inspection to select an analysis plan, introducing uncontrollable researcher degrees of freedom.", "labels": [], "entities": []}, {"text": "Another approach is to run separate models for each time point (or even each electrode) to look for the emergence of an effect.", "labels": [], "entities": []}, {"text": "This necessitates complex statistical tests to monitor for inflated Type I error (see, e.g.,, for discussion) and to control for autocorrelation across time points.", "labels": [], "entities": [{"text": "inflated Type I error", "start_pos": 59, "end_pos": 80, "type": "METRIC", "confidence": 0.7797156199812889}]}, {"text": "We explore an alternative approach to the analysis of ERP data in language studies that substantially reduces such researcher degrees of freedom: directly decoding the raw electroencephalography (EEG) measurements by which ERPs are collected.", "labels": [], "entities": []}, {"text": "Inspired by multimodal tasks like image captioning (see, fora review) and visual question answering (, we propose to model EEG using standard convolutional neural networks (CNNs) pre-trained under an autoencoding objective.", "labels": [], "entities": [{"text": "image captioning", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7190203070640564}, {"text": "question answering", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7108192592859268}]}, {"text": "The decoder CNN can then be decoupled from its encoder and recoupled with any language processing model, thus enabling explicit quantitative comparison of such models.", "labels": [], "entities": []}, {"text": "We demonstrate the efficacy of this framework by using it to compare existing sentence processing models based on surprisal and/or static word embeddings with novel models based on contextual word embeddings.", "labels": [], "entities": []}, {"text": "We find that surprisal-based models actually outperform contextual word embeddings on their own, but when combined, the two outperform either model alone.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the EEG recordings collected and modeled by.", "labels": [], "entities": []}, {"text": "In their study, 24 subjects read sentences drawn from natural text.", "labels": [], "entities": []}, {"text": "Sentences were presented word-by-word using a rapid serial visual presentation paradigm.", "labels": [], "entities": []}, {"text": "We use the ERPs of each word epoched from -100 to 700ms and time-locked to word onset from all the 32 recorded scalp channels.", "labels": [], "entities": []}, {"text": "After artifact rejection (provided by Frank and Willems with the data), this dataset contains 41,009 training instances.", "labels": [], "entities": [{"text": "artifact rejection", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.8068818747997284}]}, {"text": "Pre-training To select which decoder to use, we compare the performance of two CNN architectures motivated by well-known properties of EEG.", "labels": [], "entities": []}, {"text": "The first architecture has 5 latent channels and 9 time steps.", "labels": [], "entities": []}, {"text": "Given the sampling rate and size of the input (250Hz, 200 time steps), this roughly corresponds to filtering the EEG data with alpha band frequency (\u223c 10Hz).", "labels": [], "entities": [{"text": "EEG data", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.7974122762680054}]}, {"text": "The other has 10 latent channels and 20 time steps, thus lying within the range of beta band activity (\u223c 25Hz).", "labels": [], "entities": []}, {"text": "In addition to these two architectures, we also examine whether including subject-and electrode-specific random intercepts improves model performance.", "labels": [], "entities": []}, {"text": "We conduct a 5-fold cross-validation for each architecture to find the one that has the best performance in reconstructing ERP data.", "labels": [], "entities": []}, {"text": "As shown in, the beta models perform better overall than alpha models, since they likely capture both alpha and beta band activities.", "labels": [], "entities": []}, {"text": "Adding subjectspecific intercept, on the other hand, did not greatly improve the model performance.", "labels": [], "entities": [{"text": "intercept", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.8047077655792236}]}], "tableCaptions": [{"text": " Table 3: Model estimates and t statistics from mixed- effects model.  *  *  : p < 0.01;  *  : p < 0.05; + : p < 0.1", "labels": [], "entities": []}]}