{"title": [{"text": "An Analysis of Attention over Clinical Notes for Predictive Tasks", "labels": [], "entities": []}], "abstractContent": [{"text": "The shift to electronic medical records (EMRs) has engendered research into machine learning and natural language technologies to analyze patient records, and to predict from these clinical outcomes of interest.", "labels": [], "entities": []}, {"text": "Two observations motivate our aims here.", "labels": [], "entities": []}, {"text": "First, un-structured notes contained within EMR often contain key information, and hence should be exploited by models.", "labels": [], "entities": []}, {"text": "Second, while strong predictive performance is important, inter-pretability of models is perhaps equally so for applications in this domain.", "labels": [], "entities": []}, {"text": "Together, these points suggest that neural models for EMR may benefit from incorporation of attention over notes, which one may hope will both yield performance gains and afford transparency in predictions.", "labels": [], "entities": [{"text": "EMR", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9634169340133667}]}, {"text": "In this work we perform experiments to explore this question using two EMR corpora and four different pre-dictive tasks, that: (i) inclusion of attention mechanisms is critical for neural encoder modules that operate over notes fields in order to yield competitive performance, but, (ii) unfortunately , while these boost predictive performance , it is decidedly less clear whether they provide meaningful support for predictions.", "labels": [], "entities": []}, {"text": "Code to reproduce all experiments is available at https://github.com/successar/ AttentionExplanation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The adoption of electronic medical records (EMRs) has spurred development of machine learning (ML) and natural language processing methods that analyze the data these records contain; fora recent survey of such efforts, see.", "labels": [], "entities": []}, {"text": "Key information for downstream predictive tasks (e.g., forecasting whether a patient will need to be readmitted within 30 days) maybe contained within unstructured notes fields (.", "labels": [], "entities": []}, {"text": "In this work we focus on the modules within neural network architectures responsible for encoding text (notes) into a fixed-size representation for consumption by downstream layers.", "labels": [], "entities": []}, {"text": "Patient histories are often long and may contain information mostly irrelevant to a given target.", "labels": [], "entities": []}, {"text": "Encoding this may thus be difficult, and text encoder modules may benefit from attention mechanisms), which maybe imposed to emphasize relevant tokens.", "labels": [], "entities": []}, {"text": "In addition to mitigating noise introduced by irrelevant tokens, attention mechanisms are often seen as providing interpretability, or insight into model behavior.", "labels": [], "entities": []}, {"text": "However, recent work (Jain and has argued that treating attention as explanation may, at least in some cases, be misguided.", "labels": [], "entities": []}, {"text": "Interpretability is especially important for clinical tasks, but incorrect or misleading rationales supporting predictions maybe particularly harmful in this domain; this motivates our focused study in this space.", "labels": [], "entities": []}, {"text": "To summarize, our contributions are as follows.", "labels": [], "entities": []}, {"text": "First, we empirically investigate whether incorporating standard attention mechanisms into RNN-based text encoders improves the performance of predictive models learned over EMR.", "labels": [], "entities": []}, {"text": "We find that they do; inclusion of standard additive attention mechanism in LSTMs consistently yields absolute gains of \u223c10 points in AUC, compared to an LSTM without attention.", "labels": [], "entities": [{"text": "AUC", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9954119324684143}]}, {"text": "1 Second, we evaluate the induced attention distributions with respect to their ability to 'explain' model predictions.", "labels": [], "entities": []}, {"text": "We find mixed results here, similar to (Jain and Wallace, 2019): attention distributions correlate only weakly (though almost always significantly) with gradient measures of feature importance, and we are often able to identify very different attention distributions that nonetheless yield equivalent predictions.", "labels": [], "entities": []}, {"text": "Thus, one should not in general treat attention weights as meaningful explanation of predictions made using clinical notes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We consider five tasks over two independent EMR datasets.", "labels": [], "entities": [{"text": "EMR datasets", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.7292070686817169}]}, {"text": "The first EMR corpus is MIMIC-III (), a publicly available set of records from patients in the Intensive Care Unit (ICU).", "labels": [], "entities": []}, {"text": "We follow prior work in modeling aims and setup on this dataset.", "labels": [], "entities": []}, {"text": "Specifically we consider the following predictive tasks on MIMIC.", "labels": [], "entities": []}, {"text": "The task here is to predict patient readmission within 30 days of discharge or transfer from the ICU.", "labels": [], "entities": [{"text": "patient readmission", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.6041466593742371}]}, {"text": "We follow the cohort selection of (.", "labels": [], "entities": []}, {"text": "We assume the model has access to all notes from patient admission up until the discharge or transfer from the ICU (the point of prediction).", "labels": [], "entities": []}, {"text": "We aim to predict patient mortality within one year.", "labels": [], "entities": []}, {"text": "In this we follow the experimental setup of ().", "labels": [], "entities": []}, {"text": "The model is provided all notes up until patient discharge (excluding the discharge summary).", "labels": [], "entities": []}, {"text": "Here we aim to predict the top 25 acute care phenotypes for patients (associated at discharge with the admission).", "labels": [], "entities": []}, {"text": "For this we again rely on the framing established in prior work).", "labels": [], "entities": []}, {"text": "The model has access to all notes from admission up until the end of the ICU stay.", "labels": [], "entities": []}, {"text": "Note that this maybe viewed as a multilabel classification task, similar to ().", "labels": [], "entities": [{"text": "multilabel classification task", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.702564517656962}]}, {"text": "The second EMR dataset we use comprises records for 7174 patients from Mass General Hospital who underwent hip or knee arthroplasty procedures.", "labels": [], "entities": [{"text": "EMR dataset", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.7429051995277405}, {"text": "Mass General Hospital", "start_pos": 71, "end_pos": 92, "type": "DATASET", "confidence": 0.9610461393992106}]}, {"text": "Use of this data was approved by an Institutional Review Board (IRB protocol number 2016P002062) at Partners Healthcare.", "labels": [], "entities": [{"text": "Institutional Review Board (IRB protocol number 2016P002062)", "start_pos": 36, "end_pos": 96, "type": "DATASET", "confidence": 0.6700824962721931}, {"text": "Partners Healthcare", "start_pos": 100, "end_pos": 119, "type": "DATASET", "confidence": 0.8450700640678406}]}, {"text": "1. Predicting Hip and Knee Surgery Complications.", "labels": [], "entities": [{"text": "Predicting Hip and Knee Surgery Complications", "start_pos": 3, "end_pos": 48, "type": "TASK", "confidence": 0.8922667702039083}]}, {"text": "We consider patients who underwent hip or knee arthroplasty procedure; we aim to classify these patients with respect to whether or not they will be readmitted within 30 days due to surgery-related complications.", "labels": [], "entities": []}, {"text": "We run experiments over hip and knee surgery patients separately.", "labels": [], "entities": []}, {"text": "Following the analysis of (Jain and Wallace, 2019) but focusing on clinical tasks, we perform a set of experiments on these corpora that aim to assess the degree to which attention mechanisms aid (or hamper) predictive performance, and the degree to which the induced attention weights might be viewed as providing explanations for predictions.", "labels": [], "entities": []}, {"text": "The latter can be assessed in many ways, depending on one's view of interpretability.", "labels": [], "entities": []}, {"text": "To address the question of whether it is reasonable to treat attention as providing interpretability broadly, we perform experiments that interrogate multiple properties we might expect these weights to exhibit if so.", "labels": [], "entities": []}, {"text": "Specifically, we: probe the degree to which attention weights correlate with alternative gradient-based feature importance measures, which have a more straight-forward interpretation (; evaluate whether we are able to identify 'counterfactual' attention distributions that change the attention weights (focus) but not the prediction; and, in an exercise novel to the present work, we consider replacing attention weights with log odds scores from a logistic regression (linear) model.", "labels": [], "entities": []}, {"text": "We provide a web interface to interactively browse the plots for all datasets, model variants, and experiment types: https://successar.github.", "labels": [], "entities": []}, {"text": "io/AttentionExplanation/docs/.", "labels": [], "entities": []}, {"text": "To evaluate correlations between attention weights and gradient based feature importance scores, we compute Kendall-\u03c4 measure between attention scores and gradients with respect to the tokens comprising documents.", "labels": [], "entities": []}, {"text": "Across both corpora and all tasks we observe only a modest correlation between the two for BiLSTM model (the projection based model have higher correspondence, which is expected for such simple architectures).", "labels": [], "entities": []}, {"text": "This maybe problematic for attention as an explanatory mechanism, given the explicit relationship between gradients and model outputs.", "labels": [], "entities": []}, {"text": "(Although we note that gradient based methods themselves pose difficulty with respect to interpretation).", "labels": [], "entities": []}, {"text": "We investigate if model predictions would have differed, had the model attended to different words (i.e., under counterfactual attention distributions).", "labels": [], "entities": []}, {"text": "We follow the two strategies from (Jain and Wallace, 2019) for constructing counterfactual attention distributions.", "labels": [], "entities": []}, {"text": "In the first we randomly permute the empirical weights obtained from the attention module prior to inducing the weighted representation h \u03b1 . We repeat this process 100 times and record the median change in output.", "labels": [], "entities": []}, {"text": "The second strategy is adversarial; we explicitly aim to identify attention weights that are maximally different from the observed weights, with  the constraint that this does not change the model output by more some small value . In both cases, all other model parameters are held constant.", "labels": [], "entities": []}, {"text": "In, we observe that predictions are unchanged under alternative attention configurations in a significant majority of cases across all architectures.", "labels": [], "entities": []}, {"text": "Thus, attention cannot be viewed casually in the sense of 'the model made these predictions because these words were attended to'.", "labels": [], "entities": []}, {"text": "Alternative attention distributions that yield equivalent predictions would seem to be equally plausible under the view of attention as explanation.", "labels": [], "entities": []}, {"text": "As a novel exercise, we also consider swapping log-odds scores for features (from an LR model operating over BoW) in for attention weights in BiLSTM model.", "labels": [], "entities": [{"text": "BoW", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.9544705748558044}]}, {"text": "Specifically, we induce a 'log odds attention' over an input by substituting the absolute value of log odds (as estimated via LR) of: Heatmaps showing difference in Original and counterfactual attention distributions over clinical notes from MIMIC, where we have replaced text with lorem ipsum for all but the most relevant tokens in order to preserve privacy (red implies counterfactual attention is higher and blue vice-versa).", "labels": [], "entities": [{"text": "MIMIC", "start_pos": 242, "end_pos": 247, "type": "DATASET", "confidence": 0.9086882472038269}]}, {"text": "These show different cases where we can significantly change the attention distribution (either adversarial (Top) or using Log Odds (Bottom) while barely affecting the prediction.", "labels": [], "entities": []}, {"text": "the word present at each position and passing this through a softmax: \u03b1 LO = softmax t ({\u03b2 wt } T t=1 ) where wt is the word at position t and \u03b2 are logodds estimates.", "labels": [], "entities": []}, {"text": "These scores enjoy a clear interpretation under a linear regime.", "labels": [], "entities": []}, {"text": "We thus explore two ways of using them with attentive neural models: (1) Swapping in these in as attention weights place of h \u03b1 attest (prediction) time; (2) Use the (fixed) 'log-odds attention' during training, in place of learning the attention distribution end-to-end.", "labels": [], "entities": []}, {"text": "shows that using log odds attention attest time does not degrade the performance significantly inmost datasets (and actually improves performance for the Knee Surgery Complications task).", "labels": [], "entities": [{"text": "log odds attention attest time", "start_pos": 17, "end_pos": 47, "type": "METRIC", "confidence": 0.7028272747993469}, {"text": "Knee Surgery Complications task", "start_pos": 154, "end_pos": 185, "type": "TASK", "confidence": 0.8974112868309021}]}, {"text": "Similarly, using log odds attention during training also yields similar performance to standard attention variants.", "labels": [], "entities": []}, {"text": "But as we see in, log odds attention distributions can differ considerably from learned attention distributions, again highlighting the difficulty of interpreting attention weights.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Mean and std. dev. of correlations between  gradient importance measures and attention weights.  Sig. Frac. columns report the fraction of instances for  which this correlation is statistically significant.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9975444674491882}, {"text": "Sig. Frac.", "start_pos": 107, "end_pos": 117, "type": "DATASET", "confidence": 0.866265282034874}]}, {"text": " Table 2: Predictive results across all datasets and tasks  using different models and attention variants.", "labels": [], "entities": [{"text": "Predictive", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9572137594223022}]}]}