{"title": [{"text": "Language Discrimination and Transfer Learning for Similar Languages: Experiments with Feature Combinations and Adaptation", "labels": [], "entities": [{"text": "Language Discrimination and Transfer Learning", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6592292964458466}]}], "abstractContent": [{"text": "This paper describes the work done by team tearsofjoy participating in the VarDial 2019 Evaluation Campaign.", "labels": [], "entities": [{"text": "VarDial 2019 Evaluation Campaign", "start_pos": 75, "end_pos": 107, "type": "DATASET", "confidence": 0.8346704691648483}]}, {"text": "We developed two systems based on Support Vector Machines: SVM with a flat combination of features and SVM ensembles.", "labels": [], "entities": []}, {"text": "We participated in all language/dialect identification tasks, as well as the Moldavian vs. Romanian cross-dialect topic identification (MRC) task.", "labels": [], "entities": [{"text": "language/dialect identification tasks", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.6914287984371186}, {"text": "Moldavian vs. Romanian cross-dialect topic identification (MRC) task", "start_pos": 77, "end_pos": 145, "type": "TASK", "confidence": 0.6828269124031067}]}, {"text": "Our team achieved first place in German Dialect identification (GDI) and MRC subtasks 2 and 3, second place in the simplified variant of Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT) as well as Cuneiform Language Identification (CLI), and third and fifth place in DMT traditional and MRC subtask 1 respectively.", "labels": [], "entities": [{"text": "German Dialect identification (GDI)", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.7502111494541168}, {"text": "Cuneiform Language Identification (CLI)", "start_pos": 227, "end_pos": 266, "type": "TASK", "confidence": 0.7365414698918661}]}, {"text": "In most cases, the SVM with a flat combination of features performed better than SVM ensembles.", "labels": [], "entities": []}, {"text": "Besides describing the systems and the results obtained by them, we provide a tentative comparison between the feature combination methods, and present additional experiments with a method of adaptation to the test set, which may indicate potential pitfalls with some of the data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language identification is a text classification task that has been studied extensively in the field of Natural Language Processing.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7226425409317017}, {"text": "text classification task", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7818851967652639}]}, {"text": "The general concept and common implementations are described in the recent survey by.", "labels": [], "entities": []}, {"text": "A more challenging task is discerning closely related languages or dialects of the same language.", "labels": [], "entities": []}, {"text": "In recent years, the VarDial Evaluation Campaign has organized a multitude of shared tasks on classifying these with textual and spoken data (.", "labels": [], "entities": []}, {"text": "This year's VarDial evaluation campaign () featured one rerun (Swiss German dialect identification) and three new closely-related language identification tasks (Mainland vs. Taiwan varieties of Mandarin, Romanian vs. Moldavian, and cuneiform language identification, with the latter covering seven related languages within a wide historical time frame).", "labels": [], "entities": [{"text": "VarDial evaluation", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.5900323688983917}, {"text": "Swiss German dialect identification", "start_pos": 63, "end_pos": 98, "type": "TASK", "confidence": 0.7743168324232101}, {"text": "cuneiform language identification", "start_pos": 232, "end_pos": 265, "type": "TASK", "confidence": 0.8003602822621664}]}, {"text": "Our focus has been German dialect identification (GDI) and discriminating between mainland and Taiwan varieties of Mandarin (DMT).", "labels": [], "entities": [{"text": "German dialect identification (GDI)", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.7241447667280833}]}, {"text": "However, we submitted predictions for all language identification tasks.", "labels": [], "entities": [{"text": "language identification tasks", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.8411497871081034}]}, {"text": "While closely-related languages (or dialects) pose a challenge for language identification, they also provide opportunities for cross-lingual transfer where available resource and tools in one language is adapted to another, similar language variety.", "labels": [], "entities": [{"text": "language identification", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.728397935628891}, {"text": "cross-lingual transfer", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.7406395971775055}]}, {"text": "This year's evaluation campaign also features two cross-lingual transfer tasks.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7430371940135956}]}, {"text": "Namely, cross-lingual morphological analysis (CMA), and cross-lingual topic identification between Romanian and Moldavian (MRC).", "labels": [], "entities": [{"text": "cross-lingual morphological analysis (CMA)", "start_pos": 8, "end_pos": 50, "type": "TASK", "confidence": 0.7703970869382223}, {"text": "cross-lingual topic identification between Romanian and Moldavian (MRC)", "start_pos": 56, "end_pos": 127, "type": "TASK", "confidence": 0.6687542945146561}]}, {"text": "The CMA is a substantially different task than language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.8015599548816681}]}, {"text": "However, the MRC subtasks on cross-lingual topic identification can be solved by the very same text classification models used for language identification.", "labels": [], "entities": [{"text": "MRC", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.933440625667572}, {"text": "cross-lingual topic identification", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.7162636518478394}, {"text": "language identification", "start_pos": 131, "end_pos": 154, "type": "TASK", "confidence": 0.713083803653717}]}, {"text": "Hence, we also participated in the crosslingual classification subtasks of the MRC.", "labels": [], "entities": [{"text": "crosslingual classification", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.6973591148853302}, {"text": "MRC", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.61448073387146}]}, {"text": "Our base model is a linear support vector machine (SVM) classifier with sparse character and word n-gram features.", "labels": [], "entities": []}, {"text": "These models have been found to be successful in earlier instances of VarDial language identification tasks; in fact, they were found to be more effective than more recent neural classifiers (C \u00b8 \u00a8 oltekin and.", "labels": [], "entities": [{"text": "VarDial language identification tasks", "start_pos": 70, "end_pos": 107, "type": "TASK", "confidence": 0.7741673737764359}]}, {"text": "A successful variation of these linear classifiers is an ensemble of classifiers with different n-gram orders used both for language discrimination (, and native language identification.", "labels": [], "entities": [{"text": "language discrimination", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.7561818659305573}, {"text": "native language identification", "start_pos": 155, "end_pos": 185, "type": "TASK", "confidence": 0.6755036115646362}]}, {"text": "Besides the simple, 'flat' concatenation of the overlapping n-gram features, we also used an ensemble approach in some of the tasks, providing a tentative comparison between these two related methods.", "labels": [], "entities": []}, {"text": "An interesting result of last year's VarDial evaluation campaign was SUKI team's success on Indo-Aryan language identification (Jauhiainen et al., 2018b) and GDI () tasks with a rather large margin, which was likely because of the adaptation mechanism they used at prediction time.", "labels": [], "entities": [{"text": "VarDial evaluation", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.6628516614437103}, {"text": "Indo-Aryan language identification", "start_pos": 92, "end_pos": 126, "type": "TASK", "confidence": 0.608187327782313}, {"text": "GDI", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.6693305969238281}]}, {"text": "We adopted a similar adaptation approach to our SVM systems.", "labels": [], "entities": []}, {"text": "Besides the curious difference in the GDI data set last year, the adaptation idea is also a good fit for the crosslingual topic identification task (MRC).", "labels": [], "entities": [{"text": "GDI data set", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.9141983191172282}, {"text": "crosslingual topic identification task (MRC)", "start_pos": 109, "end_pos": 153, "type": "TASK", "confidence": 0.7896560217653003}]}, {"text": "The remainder of this paper introduces the tasks and data sets, describes our systems, and presents the results obtained followed by a brief discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our main submissions were based on two SVM systems that differ in the way they combine the n-gram features: SVM with flat feature combinations and SVM ensembles.", "labels": [], "entities": []}, {"text": "We employed both character and word n-gram features.", "labels": [], "entities": []}, {"text": "Depending on the task, the character n-grams varied between 1 to 9 and the word n-grams varied from 1 to 3.", "labels": [], "entities": []}, {"text": "The features were weighted with either tf-idf or BM25 () weighting schemes.", "labels": [], "entities": [{"text": "BM25", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.8871033191680908}]}, {"text": "The flat combination is similar to C \u00b8 \u00a8 oltekin and Rama (2016) and the ensemble approach is similar to.", "labels": [], "entities": []}, {"text": "Both methods were implemented in Python using the scikit-learn library).", "labels": [], "entities": []}, {"text": "We also experimented with recurrent neural classifiers and considered a system similar to HeLi, which was also used in earlier VarDial evaluation campaigns.", "labels": [], "entities": [{"text": "VarDial evaluation", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.5571051239967346}]}, {"text": "However, we only submitted results with the SVM classifiers described in more detail below, and we will limit our discussion to the results obtained by the SVM classifiers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Official results obtained by our models on  all tasks we participated. The column F1-diff indicates  the macro F1-score difference from the top score if the  result is not the top score, or the difference from the  second best scores otherwise. Our submissions in the  MRC task had an error, causing a shift of labels after  a certain index. The scores marked with  *  are post- evaluation results with the gold labels released by the  organizers after the evaluation period.", "labels": [], "entities": [{"text": "F1-diff", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9971380233764648}, {"text": "F1-score", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.7457662224769592}, {"text": "MRC task", "start_pos": 279, "end_pos": 287, "type": "TASK", "confidence": 0.9288677871227264}]}, {"text": " Table 2: F1 scores achieved by SVM with single fea- tures, tested on development set (Simplified Chinese)", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9983243346214294}, {"text": "SVM", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.7285180687904358}, {"text": "Simplified Chinese)", "start_pos": 87, "end_pos": 106, "type": "DATASET", "confidence": 0.7039931118488312}]}]}