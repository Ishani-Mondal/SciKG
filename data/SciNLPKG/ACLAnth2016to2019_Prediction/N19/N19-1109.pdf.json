{"title": [{"text": "Word-Node2Vec: Improving Word Embedding with Document-Level Non-Local Word Co-occurrences", "labels": [], "entities": [{"text": "Improving Word Embedding", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7459144989649454}]}], "abstractContent": [{"text": "Standard word embedding algorithms, such as word2vec and Glove, make a restrictive assumption that words are likely to be semantically related only if they co-occur locally within a window of fixed size.", "labels": [], "entities": []}, {"text": "However , this restrictive assumption may not capture the semantic association between words that co-occur frequently but non-locally within documents.", "labels": [], "entities": []}, {"text": "To alleviate this restriction, in this paper, we propose a graph-based word embedding method, named 'word-node2vec'.", "labels": [], "entities": []}, {"text": "By relaxing the strong constraint of locality , our method is able to capture both local and non-local co-occurrences.", "labels": [], "entities": []}, {"text": "Word-node2vec constructs a weighted graph, where each node represents a word and the weight of an edge between two nodes represents a combination of both local (e.g. word2vec) and document-level co-occurrences.", "labels": [], "entities": []}, {"text": "Our experiments show that word-node2vec outperforms word2vec and glove on a range of different tasks, such as word-pair similarity prediction, word analogy and concept categorization.", "labels": [], "entities": [{"text": "word-pair similarity prediction", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.6832773685455322}, {"text": "word analogy", "start_pos": 143, "end_pos": 155, "type": "TASK", "confidence": 0.8364045023918152}]}], "introductionContent": [{"text": "Word embedding, the process of obtaining vector representations of words, is a first step towards addressing language semantics, in which discrete entities, such as words, are embedded as vectors over a continuous space of reals.", "labels": [], "entities": [{"text": "Word embedding", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.660287007689476}]}, {"text": "This not only facilitates to obtain semantic similarities between words to improve tasks such as semantic search (, but is also useful in a number of down-stream NLP tasks including concept categorization (, information retrieval (, sentence similarity prediction, sentiment analysis ( and POS tagging ( etc.", "labels": [], "entities": [{"text": "semantic search", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.7928576171398163}, {"text": "information retrieval", "start_pos": 208, "end_pos": 229, "type": "TASK", "confidence": 0.7573556005954742}, {"text": "sentence similarity prediction", "start_pos": 233, "end_pos": 263, "type": "TASK", "confidence": 0.7880415717760721}, {"text": "sentiment analysis", "start_pos": 265, "end_pos": 283, "type": "TASK", "confidence": 0.9427584111690521}, {"text": "POS tagging", "start_pos": 290, "end_pos": 301, "type": "TASK", "confidence": 0.8325699865818024}]}, {"text": "Word embedding approaches such as word2vec () and Glove () rely on a large corpus to learn the association between words.", "labels": [], "entities": []}, {"text": "The architecture of existing word embedding approaches mimics the process of human cognition of word association by learning the representation of each word with an objective of maximizing the likelihood of predicting the words around its local context (defined by a fixed length word window).", "labels": [], "entities": []}, {"text": "A limitation of existing word embedding approaches, such as word2vec and glove, is that they use a strong constraint that words are likely to be semantically related to each other only if one occurs within a local context of the another, where the local context is given by a word window of specified length.", "labels": [], "entities": []}, {"text": "On the other hand, non-local or document-level co-occurrences between words have been widely used to estimate semantic similarities between words.", "labels": [], "entities": []}, {"text": "More specifically, the latent semantic analysis (LSA) method proposed by uses a spectral analysis (method of principal component analysis) of the term-document matrix of a collection to obtain the most informative concepts (word classes), and then expresses each document as a linear combination of these principal components.", "labels": [], "entities": [{"text": "latent semantic analysis (LSA)", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.7999731649955114}]}, {"text": "estimate a generative model from a given collection by assuming that documents are mixtures of a preset number of topics, where each topic represents a word distribution over the vocabulary.", "labels": [], "entities": []}, {"text": "This is largely similar to decomposing a term-document matrix as a product of matrices with non-negative components, a process commonly known as non-negative matrix factorization (NMF) ().", "labels": [], "entities": []}, {"text": "The underlying common idea among all these approaches is to make use of the frequent document-level word cooccurrences to identify likely semantic association between words.", "labels": [], "entities": []}, {"text": "Despite the presence of avast volume of lit-erature on document-level (non-local) word cooccurrences, word embedding approaches do not utilize this information to derive the word representations.", "labels": [], "entities": []}, {"text": "In this paper, we propose to augment the document-level non-local word co-occurrence information with the local co-occurrence information that methods such as word2vec and glove use.", "labels": [], "entities": []}, {"text": "More specifically, we propose a graph-based word embedding method, named word-node2vec, that by relaxing the strong constraint of locality, is able to capture both the local and non-local co-occurrences.", "labels": [], "entities": []}, {"text": "To represent the local dependencies, each node, representative of a word (hence the name 'word-node'), is initialized with a vector representation obtained with a standard method, e.g. word2vec.", "labels": [], "entities": []}, {"text": "We then define the weight of the edge between a pair of word-nodes to reflect their likelihood of non-local co-occurrence, computed with the help of the global term-document matrix for the whole collection.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we survey existing literature on word embedding.", "labels": [], "entities": []}, {"text": "In Section 3, we revisit the skip-gram approach and propose a graph-based view of the skip-gram objective as a pre-cursor to developing our model.", "labels": [], "entities": []}, {"text": "In Section 4, we extend the skip-gram graph model with non-local document-level cooccurrence information.", "labels": [], "entities": []}, {"text": "Section 5 describes our experimental setup.", "labels": [], "entities": []}, {"text": "Section 6 reports the results of our new embedding approach against a number of baselines.", "labels": [], "entities": []}, {"text": "Finally, Section 7 concludes the paper with directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe our experimental setup to evaluate our new word embedding method.", "labels": [], "entities": []}, {"text": "A word embedding algorithm requires a collection to learn word representations.", "labels": [], "entities": []}, {"text": "To compare the various word embedding approaches (i.e. our method and the baselines), we use the DBPedia (2014) corpus, which is a collection of abstracts of Wikipedia pages crawled in 2014 . Dataset characteristics are outlined in.", "labels": [], "entities": [{"text": "DBPedia (2014) corpus", "start_pos": 97, "end_pos": 118, "type": "DATASET", "confidence": 0.92996586561203}]}, {"text": "As part of preprocessing, we removed words with collection frequency less than 10 and also removed stopwords 2 .  To compare the relative performance of wordnode2vec with the baselines, we use a number of  datasets, each corresponding to one of the following three evaluation tasks.", "labels": [], "entities": []}, {"text": "A standard way to measure the effectiveness of embedded words is to measure how well the similarity between a pair of words correlates with human judgments.", "labels": [], "entities": []}, {"text": "Two such standard datasets that we use for our experiments are the WSIM-353 () and the MEN () datasets.", "labels": [], "entities": [{"text": "WSIM-353", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.8502846956253052}, {"text": "MEN () datasets", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.7521173159281412}]}, {"text": "Both comprise a list of word pairs, with an associated human judged similarity value.", "labels": [], "entities": []}, {"text": "This similarity value is expected to be high for semantically similar words, such as 'morning' and 'sunrise' (human assigned score of 49 out of 50), and low for semantically unrelated words, such as 'angel' and 'gasoline' (score of 1 out of 50), both examples being taken from the MEN dataset.", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 281, "end_pos": 292, "type": "DATASET", "confidence": 0.9798495769500732}]}, {"text": "The word analogy task consists of templates of the form \"A:B as C:X\", where A, B, and C are given words, whereas X is unknown.", "labels": [], "entities": [{"text": "word analogy task", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8085083961486816}]}, {"text": "Using a vector representation of words this analogy task is solved by retrieving the vector most similar to that of B + C \u2212 A.", "labels": [], "entities": []}, {"text": "A word embedding is considered effective if it finds a greater number of correct answers (resulting in higher accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9976807832717896}]}, {"text": "We employed three different analogy datasets, namely, the Google Analogy (), the MSR Analogy () and the SemEval-2012 task 2 (Jurgens et al., 2012) datasets.", "labels": [], "entities": [{"text": "MSR Analogy", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.9158307909965515}, {"text": "SemEval-2012 task 2 (Jurgens et al., 2012) datasets", "start_pos": 104, "end_pos": 155, "type": "DATASET", "confidence": 0.5531244332140143}]}, {"text": "The MSR dataset contains syntactic questions only involving morphological variations.", "labels": [], "entities": [{"text": "MSR dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7853557467460632}]}, {"text": "The Google dataset on the other hand contains both syntactic and semantic questions.", "labels": [], "entities": [{"text": "Google dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.969712644815445}]}, {"text": "Given an analogy 'A:B as C:D', the Semeval-2012 task requires prediction of the degree to which the semantic relations between A and B are similar to those between C and D.", "labels": [], "entities": []}, {"text": "In our experiments, we treat the given entity D as unknown and seek to predict D, similar to the MSR and Google analogy datasets.", "labels": [], "entities": [{"text": "MSR and Google analogy datasets", "start_pos": 97, "end_pos": 128, "type": "DATASET", "confidence": 0.6846931457519532}]}, {"text": "provides an overview of examples from these datasets.", "labels": [], "entities": []}, {"text": "The concept categorization task requires classifying nouns into a concept type derived from an ontology.", "labels": [], "entities": []}, {"text": "For this task, we employ the AP (), BLESS (Baroni and Lenci, 2011) and ESSL 2b (Marco) datasets.", "labels": [], "entities": [{"text": "AP", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9752325415611267}, {"text": "BLESS", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9984473586082458}, {"text": "ESSL 2b (Marco) datasets", "start_pos": 71, "end_pos": 95, "type": "DATASET", "confidence": 0.7466736932595571}]}, {"text": "The AP dataset contains 402 nouns from 21 WordNet classes, e.g., nouns such as 'ceremony', 'feast', and 'graduation' belong to the class 'Social Occasion'.", "labels": [], "entities": [{"text": "AP dataset", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8836131691932678}]}, {"text": "The BLESS dataset, designed for the evaluation of distributional semantic models, contains 200 distinct English concrete nouns as target concepts.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9388369619846344}]}, {"text": "These nouns are categorized into 17 broad classes.", "labels": [], "entities": []}, {"text": "The word similarity prediction effectiveness is measured with the help of Spearman's rank correlation coefficient \u03c1.", "labels": [], "entities": [{"text": "word similarity prediction", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6232999861240387}, {"text": "Spearman's rank correlation coefficient \u03c1", "start_pos": 74, "end_pos": 115, "type": "METRIC", "confidence": 0.6347949256499609}]}, {"text": "This measures the rank correlation (higher is better) between the list of word pairs sorted in decreasing order of inter-similarity values as predicted by a word embedding algorithm and the reference list of human judged word pairs.", "labels": [], "entities": [{"text": "rank correlation", "start_pos": 18, "end_pos": 34, "type": "METRIC", "confidence": 0.8509404957294464}]}, {"text": "For the analogy and the concept categorization tasks, we report the accuracy in predicting the reference word and that of the class, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.999622106552124}]}, {"text": "In our experiments, for all the methods, except ELMO, we set the number of dimensions to 200.", "labels": [], "entities": [{"text": "ELMO", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.4747198820114136}]}, {"text": "To find optimal settings for each method (except ELMO), we use the MEN dataset as a development set for tuning the parameters of each method.", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.9640424251556396}]}, {"text": "Each method with the optimal parameter settings is then applied for the rest of the datasets and tasks.", "labels": [], "entities": []}, {"text": "Since we used a pre-trained model for ELMO, the number of dimensions corresponds to the size of the output layer of the network, the value of which in the default configuration of the Python implementation 3 is 1024.", "labels": [], "entities": []}, {"text": "The parameters of SGNS are window size (k) and the number of negative samples (NS).", "labels": [], "entities": [{"text": "SGNS", "start_pos": 18, "end_pos": 22, "type": "TASK", "confidence": 0.9448585510253906}]}, {"text": "For the baseline approach SGNS, we varied k from 5 to 40 in steps of 5 and found that the best results are obtained when k = 10 and NS = 5.", "labels": [], "entities": [{"text": "SGNS", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.8603231310844421}]}, {"text": "Similarly, for Glove we chose the optimal settings by varying k within the same range of and found that the optimal \u03c1 for the MEN dataset is obtained fork = 20.", "labels": [], "entities": [{"text": "Glove", "start_pos": 15, "end_pos": 20, "type": "DATASET", "confidence": 0.8352658152580261}, {"text": "MEN dataset", "start_pos": 126, "end_pos": 137, "type": "DATASET", "confidence": 0.9218593537807465}, {"text": "fork", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.9860219359397888}]}, {"text": "We obtain the LDA results by setting the number of topics to 200 (so as to match with the dimensionality).", "labels": [], "entities": []}, {"text": "As LDA hyper-parameters, we use settings as prescribed in  (), i.e., \u03b2 = 0.1 and \u03b1 = 0.25 (50/(#topics = 200)).", "labels": [], "entities": []}, {"text": "Since we found that SGNS performed significantly better than Glove, we use SGNS vectors for the linear combination method (Equation 1), which we call SGNS-LDA from hereon.", "labels": [], "entities": []}, {"text": "The parameter \u03bb was varied within a range of [0.1, 0.9] in steps of 0.1 (\u03bb = 0 and \u03bb = 1 degenerate to that of LDA and SGNS respectively).", "labels": [], "entities": []}, {"text": "We found that the best results are obtained for \u03bb = 0.9.", "labels": [], "entities": []}, {"text": "For node2vec baseline approach of word-node embedding, we varied the parameters p and q (BFS and DFS parameters) within a range of [0.1, 5] and found that the best results on the MEN dataset are given for p = 1 and q = 1 (Grover and.", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 179, "end_pos": 190, "type": "DATASET", "confidence": 0.9306261241436005}]}, {"text": "Another parameter in node2vec is the random walk length, l, for which the optimal value was found to be 80.", "labels": [], "entities": []}, {"text": "For word-node2vec, in addition to window size (k) and number of negative samples (N S), three more parameters are: i) \u03b1, i.e., the importance of the presence of a term relative to its informativeness (Equation 12, ii) \u03b2, the prior assigned to sampling from the 1-adjacent neighborhood, and iii) the size of the context sampled from the neighborhood, l (this is analogous to the random walk length parameter of node2vec).", "labels": [], "entities": []}, {"text": "Instead of separately optimizing the parameters common to SGNS, we directly use the optimal values of k = 10 and NS = 5 for word-node2vec.", "labels": [], "entities": []}, {"text": "The optimal results of the additional parameters, tuned on the MEN dataset, are shown in.", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.9673352837562561}]}], "tableCaptions": [{"text": " Table 3: Word similarity prediction results.", "labels": [], "entities": [{"text": "Word similarity prediction", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7762949665387472}]}, {"text": " Table 4: Word analogy results.", "labels": [], "entities": [{"text": "Word analogy", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.7682713568210602}]}, {"text": " Table 5: Concept categorization results.", "labels": [], "entities": []}, {"text": " Table 6: Nearest neighbors of the word 'album' ob- tained by SGNS and word-node2vec.", "labels": [], "entities": []}]}