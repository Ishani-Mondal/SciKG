{"title": [], "abstractContent": [{"text": "Recent work has shown that visual context improves cross-lingual sense disambiguation for nouns.", "labels": [], "entities": [{"text": "cross-lingual sense disambiguation", "start_pos": 51, "end_pos": 85, "type": "TASK", "confidence": 0.6936994194984436}]}, {"text": "We extend this line of work to the more challenging task of cross-lingual verb sense disambiguation, introducing the Multi-Sense dataset of 9,504 images annotated with English, German, and Spanish verbs.", "labels": [], "entities": [{"text": "cross-lingual verb sense disambiguation", "start_pos": 60, "end_pos": 99, "type": "TASK", "confidence": 0.7146359756588936}, {"text": "Multi-Sense dataset", "start_pos": 117, "end_pos": 136, "type": "DATASET", "confidence": 0.673648327589035}]}, {"text": "Each image in MultiSense is annotated with an English verb and its translation in German or Span-ish.", "labels": [], "entities": []}, {"text": "We show that cross-lingual verb sense dis-ambiguation models benefit from visual context , compared to unimodal baselines.", "labels": [], "entities": []}, {"text": "We also show that the verb sense predicted by our best disambiguation model can improve the results of a text-only machine translation system when used fora multimodal translation task.", "labels": [], "entities": [{"text": "text-only machine translation", "start_pos": 105, "end_pos": 134, "type": "TASK", "confidence": 0.6741231679916382}, {"text": "multimodal translation task", "start_pos": 157, "end_pos": 184, "type": "TASK", "confidence": 0.783950408299764}]}], "introductionContent": [{"text": "Resolving lexical ambiguity remains one of the most challenging problems in natural language processing.", "labels": [], "entities": [{"text": "Resolving lexical ambiguity", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9201871554056803}, {"text": "natural language processing", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.6410648922125498}]}, {"text": "It is often studied as a word sense disambiguation (WSD) problem, which is the task of assigning the correct sense to a word in a given context.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8081614673137665}]}, {"text": "Word sense disambiguation is typically tackled using only textual context; however, in a multimodal setting, visual context is also available and can be used for disambiguation.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6517983178297678}]}, {"text": "Most prior work on visual word sense disambiguation has targeted noun senses (, but the task has recently been extended to verb senses (.", "labels": [], "entities": [{"text": "visual word sense disambiguation", "start_pos": 19, "end_pos": 51, "type": "TASK", "confidence": 0.657457210123539}]}, {"text": "Resolving sense ambiguity is particularly crucial for translation tasks, as words can have more than one translation, and these translations often correspond to word senses.", "labels": [], "entities": [{"text": "Resolving sense ambiguity", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7885538538297018}, {"text": "translation tasks", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.9092720448970795}]}, {"text": "As an example consider the verb ride, which can translate into German as fahren (ride a bike) or reiten (ride a horse).", "labels": [], "entities": []}, {"text": "Recent work on multimodal machine translation has partly addressed Source: Three guys riding on an elephant.", "labels": [], "entities": [{"text": "multimodal machine translation", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.6367184023062388}]}, {"text": "Target: Drei M\u00e4nner reiten auf einem Elefanten.", "labels": [], "entities": []}, {"text": "Output: Drei Jungs fahren auf einem Elefanten.", "labels": [], "entities": []}, {"text": "lexical ambiguity by using visual information, but it still remains unresolved especially for the part-ofspeech categories such as verbs (.", "labels": [], "entities": []}, {"text": "Prior work on cross-lingual WSD has been limited in scale and has only employed textual context), even though the task should benefit from visual context, just like monolingual WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.6478612422943115}]}, {"text": "Visual information has been shown to be useful to map words across languages for bilingual lexicon induction.", "labels": [], "entities": [{"text": "bilingual lexicon induction", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6999027927716573}]}, {"text": "For this, images are used as a pivot between languages or visual information is combined with cross-lingual vector spaces to learn word translations across languages (Bergsma and Van Durme, 2011;.", "labels": [], "entities": [{"text": "learn word translations across languages", "start_pos": 125, "end_pos": 165, "type": "TASK", "confidence": 0.7527534782886505}]}, {"text": "However, as with other grounding or word similarity tasks, bilingual lexicon induction has so far mainly targeted nouns and these approaches was shown to perform poorly for other word categories such as verbs.", "labels": [], "entities": [{"text": "grounding or word similarity", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.614475429058075}, {"text": "bilingual lexicon induction", "start_pos": 59, "end_pos": 86, "type": "TASK", "confidence": 0.7774393757184347}]}, {"text": "Recent work by and has shown using image as pivot between languages can lead to better multilingual multimodal representations and can have successful applications in crosslingual retrieval and multilingual image retrieval.", "labels": [], "entities": [{"text": "crosslingual retrieval", "start_pos": 167, "end_pos": 189, "type": "TASK", "confidence": 0.8067601025104523}, {"text": "multilingual image retrieval", "start_pos": 194, "end_pos": 222, "type": "TASK", "confidence": 0.626676470041275}]}, {"text": "In this paper, we introduce the MultiSense dataset of 9,504 images annotated with English verbs and their translations in German and Spanish.", "labels": [], "entities": [{"text": "MultiSense dataset", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.8176740109920502}]}, {"text": "For each image in MultiSense, the English verb is translation-ambiguous, i.e., it has more than one possible translation in German or Spanish.", "labels": [], "entities": []}, {"text": "We propose a series of disambiguation models that, given an image and an English verb, select the correct translation of the verb.", "labels": [], "entities": []}, {"text": "We apply our models on MultiSense and find that multimodal models that fuse textual context with visual features outperform unimodal models, confirming our hypothesis that cross-lingual WSD benefits from visual context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 186, "end_pos": 189, "type": "TASK", "confidence": 0.7511435747146606}]}, {"text": "Cross-lingual WSD also has a clear application in machine translation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8438491225242615}, {"text": "machine translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8054419755935669}]}, {"text": "Determining the correct sense of a verb is important for high quality translation output, and sometimes text-only translation systems fail when the correct translation would be obvious from visual information (see).", "labels": [], "entities": []}, {"text": "To show that cross-lingual visual sense disambiguation can improve the performance of translation systems, we annotate apart of our MultiSense dataset with English image descriptions and their German translations.", "labels": [], "entities": [{"text": "MultiSense dataset", "start_pos": 132, "end_pos": 150, "type": "DATASET", "confidence": 0.9125233888626099}]}, {"text": "There are two existing multimodal translation evaluation sets with ambiguous words: the Ambiguous COCO dataset contains sentences that are \"possibly ambiguous\", and the Multimodal Lexical Translation dataset is restricted to predicting single words instead of full sentences.", "labels": [], "entities": [{"text": "Ambiguous COCO dataset", "start_pos": 88, "end_pos": 110, "type": "DATASET", "confidence": 0.6904459595680237}, {"text": "Multimodal Lexical Translation", "start_pos": 169, "end_pos": 199, "type": "TASK", "confidence": 0.5829995175202688}]}, {"text": "This type of resource is important for multimodal translation because it is known that humans use visual context to resolve ambiguities for nouns and gender-neutral words.", "labels": [], "entities": [{"text": "multimodal translation", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.748497486114502}]}, {"text": "MultiSense contains sentences that are known to have ambiguities, and it allows for sentence-level and verb prediction evaluation.", "labels": [], "entities": [{"text": "verb prediction evaluation", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.7935758133729299}]}, {"text": "Here, we use the verbs predicted by our visual sense disambiguation model to constrain the output of a neural translation system and demonstrate a clear improvement in Meteor, BLEU, and verb accuracy over a text-only baseline.", "labels": [], "entities": [{"text": "Meteor", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.939005434513092}, {"text": "BLEU", "start_pos": 176, "end_pos": 180, "type": "METRIC", "confidence": 0.9871883392333984}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9305927753448486}]}], "datasetContent": [{"text": "Images Paired with Verb Translations The MultiSense dataset pairs sense-ambiguous English verbs with images as visual context and contextually appropriate German and Spanish translations.", "labels": [], "entities": []}, {"text": "shows examples of images taken from MultiSense with their Spanish and German translations.", "labels": [], "entities": []}, {"text": "To compile the dataset, we first chose a set of English verbs which had multiple translations into German and Spanish in Wiktionary, an online dictionary.", "labels": [], "entities": []}, {"text": "Then we retrieved 150 candidate images from Google Images using queries that included the target English verb.", "labels": [], "entities": []}, {"text": "We constructed the verb phrases by extracting the 100 most frequent phrases for each verb from the English Google syntactic n-grams dataset (), which we then manually filtered to remove redundancies, resulting in 10 phrases per verb.", "labels": [], "entities": [{"text": "Google syntactic n-grams dataset", "start_pos": 107, "end_pos": 139, "type": "DATASET", "confidence": 0.602246604859829}]}, {"text": "Examples of verb phrases for blow include blowing hair, blowing a balloon, and blowing up a bomb.", "labels": [], "entities": []}, {"text": "We filtered the candidate images using crowdworkers on Amazon Mechanical Turk, who were asked to remove images that were irrelevant to the verb phrase query.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.9306914607683817}]}, {"text": "Overall pairwise agreement for this image filtering task was 0.763.", "labels": [], "entities": [{"text": "agreement", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9441871643066406}, {"text": "image filtering task", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.8284761706988016}]}, {"text": "Finally, we employed native German and Spanish speakers to translate the verbs into their language, given the additional visual context.", "labels": [], "entities": []}, {"text": "This resulted in a dataset of 9,504 images, covering 55 English verbs with 154 and 136 unique translations in German and Spanish, respectively.", "labels": [], "entities": []}, {"text": "We divided the dataset into 75% training, 10% validation and 15% test splits.", "labels": [], "entities": []}, {"text": "Sentence-level Translations We also annotated a subset of MultiSense with sentence-level translations for English and German.", "labels": [], "entities": [{"text": "Sentence-level Translations", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7996649444103241}]}, {"text": "This subset contains 995 image-English description-German translation tuples that can be used to evaluate the verb sense disambiguation capabilities of multimodal translation models.", "labels": [], "entities": [{"text": "verb sense disambiguation", "start_pos": 110, "end_pos": 135, "type": "TASK", "confidence": 0.6472019453843435}]}, {"text": "We collected the data in foursteps: (1) crowdsource English descriptions of the images using the gold-standard MultiSense verb as a prompt; (2) manually post-edit the English descriptions to ensure they contain the correct verb; (3) crowdsource German translations, given the English descriptions, the German gold-standard MultiSense verb, and the image; (4) manually postedit the German translations to ensure they contain the correct verb.", "labels": [], "entities": []}, {"text": "shows an example of an image paired with its English description and German translation.", "labels": [], "entities": []}, {"text": "Spanish mandar hinchar explotar German zublasen aufblasen detonieren: Images for the English verb blow annotated with translations in Spanish and German.", "labels": [], "entities": []}, {"text": "The images correspond to the uses of blowing with a hairdryer and blowing a balloon, and blowing up a bomb.", "labels": [], "entities": []}, {"text": "Our experiments are designed to determine whether the integration of textual and visual features yields better cross-lingual verb sense disambiguation than unimodal models.", "labels": [], "entities": [{"text": "cross-lingual verb sense disambiguation", "start_pos": 111, "end_pos": 150, "type": "TASK", "confidence": 0.6437298282980919}]}, {"text": "We embed the textual queries using pre-trained d = 300 dimension word2vec embeddings ().", "labels": [], "entities": []}, {"text": "We represent images in the visual model using the features extracted from the 512D pool5 layer of a pre-trained ResNet-34.", "labels": [], "entities": []}, {"text": "All our models have ah = 128 dimension hidden layer.", "labels": [], "entities": []}, {"text": "The German models have an output vocabulary of v = 154 verbs, and the Spanish models have a vocabulary of v = 136 verbs.", "labels": [], "entities": []}, {"text": "All of our models are trained using SGD with minibatches of 16 samples and a learning rate of 0.0001.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 77, "end_pos": 90, "type": "METRIC", "confidence": 0.9776178002357483}]}, {"text": "We evaluate the performance of our models by measuring the accuracy of the predicted verb against the gold standard.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9992619156837463}]}, {"text": "We also compare against chance and majority label baselines.", "labels": [], "entities": [{"text": "chance", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9701412916183472}]}, {"text": "Our preliminary experiments show that with better visual representation we achieve better acccuracy scores similar to others who observed better visual representation contributes to better downstream tasks such as image description, multimodal machine translation ( ) and representation learning).", "labels": [], "entities": [{"text": "acccuracy", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9966187477111816}, {"text": "image description", "start_pos": 214, "end_pos": 231, "type": "TASK", "confidence": 0.7649805843830109}, {"text": "multimodal machine translation", "start_pos": 233, "end_pos": 263, "type": "TASK", "confidence": 0.6080120305220286}, {"text": "representation learning", "start_pos": 272, "end_pos": 295, "type": "TASK", "confidence": 0.830363392829895}]}, {"text": "We also evaluate our verb sense disambiguation model in the challenging downstream task of multimodal machine translation ( ).", "labels": [], "entities": [{"text": "verb sense disambiguation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.6208569804827372}, {"text": "multimodal machine translation", "start_pos": 91, "end_pos": 121, "type": "TASK", "confidence": 0.6225812137126923}]}, {"text": "We conduct this evaluation on the sentence-level translation subset of MultiSense.", "labels": [], "entities": [{"text": "sentence-level translation", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.6580616235733032}]}, {"text": "We evaluate model performance using BLEU () and Meteor scores between the MultiSense reference description and the translation model output.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9988300204277039}]}, {"text": "We also evaluate the verb prediction accuracy of the output against the gold standard verb annotation.", "labels": [], "entities": [{"text": "verb prediction", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.6468379646539688}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.8712456226348877}]}], "tableCaptions": [{"text": " Table 2: Cross-lingual verb sense disambiguation ac- curacy of our unimodal models and the multimodal  model. We also show the performance of a random  chance baseline and a majority label baseline.", "labels": [], "entities": [{"text": "Cross-lingual verb sense disambiguation", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.5980276241898537}]}, {"text": " Table 3: The visual verb sense predictions (\"blockieren\", \"b\u00fcrsten\") successfully constrains the decoder to predict  the correct sense of the verb (\"block\", \"brush\") in the German translation (+WSD). The incorrect verb in the  baseline translation is shown in bold red.", "labels": [], "entities": []}]}