{"title": [{"text": "Positional Encoding to Control Output Sequence Length", "labels": [], "entities": []}], "abstractContent": [{"text": "Neural encoder-decoder models have been successful in natural language generation tasks.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.647962341705958}]}, {"text": "However, real applications of abstractive sum-marization must consider additional constraint that a generated summary should not exceed a desired length.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple but effective extension of a sinusoidal positional encoding (Vaswani et al., 2017) to enable neural encoder-decoder model to preserves the length constraint.", "labels": [], "entities": []}, {"text": "Unlike in previous studies where that learn embeddings representing each length, the proposed method can generate a text of any length even if the target length is not present in training data.", "labels": [], "entities": []}, {"text": "The experimental results show that the proposed method cannot only control the generation length but also improve the ROUGE scores.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 118, "end_pos": 123, "type": "METRIC", "confidence": 0.996152937412262}]}], "introductionContent": [{"text": "Neural encoder-decoder models have been successfully applied to various natural language generation tasks including machine translation), summarization, and caption generation (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7764945924282074}, {"text": "summarization", "start_pos": 138, "end_pos": 151, "type": "TASK", "confidence": 0.9898205995559692}, {"text": "caption generation", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.9406231939792633}]}, {"text": "Still, it is necessary to control the output length for abstractive summarization, which generates a summary fora given text while satisfying a space constraint.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.5385884344577789}]}, {"text": "In fact, shows a large variance in output sequences produced by a widely used encoder-decoder model (, which has no mechanism for controlling the length of the output sequences.", "labels": [], "entities": []}, {"text": "trained embeddings that correspond to each output length to control the output sequence length.", "labels": [], "entities": []}, {"text": "Since the embeddings for different lengths are independent, it is hard to generate a sequence of the length that is infrequent in training data.", "labels": [], "entities": []}, {"text": "Thus, a method that can model any lengths continuously is required.: Difference in number of characters between correct headlines and outputs of a widely used LSTM encoder-decoder ( which is trained on sentence-headline pairs created by from the annotated English Gigaword corpus.", "labels": [], "entities": [{"text": "Difference", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.927962064743042}, {"text": "English Gigaword corpus", "start_pos": 256, "end_pos": 279, "type": "DATASET", "confidence": 0.8331897060076395}]}, {"text": "The difference was investigated for 3,000 sentence-headline pairs randomly sampled from the test splits.", "labels": [], "entities": []}, {"text": "proposed two learning based methods for an LSTM encoder-decoder: LenEmb and LenInit.", "labels": [], "entities": []}, {"text": "LenEmb inputs an embedding representing the remaining length in each decoding step.", "labels": [], "entities": []}, {"text": "Since this approach also prepares embeddings for each length independently, it suffers from the same problem as that in.", "labels": [], "entities": []}, {"text": "On the other hand, LenInit can handle arbitrary lengths because it combines the scalar value of a desired length with a trainable embedding.", "labels": [], "entities": []}, {"text": "LenInit initializes the LSTM cell of the decoder with the embedding depending on the scalar value of the desired length.", "labels": [], "entities": []}, {"text": "incorporated such scalar values into the initial state of the decoder in a CNN encoder-decoder.", "labels": [], "entities": []}, {"text": "These approaches deal with any length but it is reasonable to incorporate the distance to the desired terminal position into each decoding step such as in In this study, we focused on Transformer (, which recently achieved the state-of-the-art score on the machine translation task.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 257, "end_pos": 281, "type": "TASK", "confidence": 0.8589338660240173}]}, {"text": "We extend the sinusoidal positional encoding, which represents a position of each token in Transformer (, to represent a distance from a terminal position on the decoder side.", "labels": [], "entities": [{"text": "Transformer", "start_pos": 91, "end_pos": 102, "type": "DATASET", "confidence": 0.8965319395065308}]}, {"text": "In this way, the proposed method considers the remaining length explicitly at each decoding step.", "labels": [], "entities": []}, {"text": "Moreover, the proposed method can handle any desired length regardless of its appearance in a training corpus because it uses the same continuous space for any length.", "labels": [], "entities": []}, {"text": "We conduct experiments on the headline generation task.", "labels": [], "entities": [{"text": "headline generation task", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.8784226179122925}]}, {"text": "The experimental results show that our proposed method is able to not only control the output length but also improve the ROUGE scores from the baselines.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 122, "end_pos": 134, "type": "METRIC", "confidence": 0.9748547673225403}]}, {"text": "Our code and constructed test data are publicly available at: https://github.com/takase/control-length.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on the headline generation task on Japanese and English datasets.", "labels": [], "entities": [{"text": "headline generation task", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.8865033785502116}, {"text": "Japanese and English datasets", "start_pos": 58, "end_pos": 87, "type": "DATASET", "confidence": 0.5249147489666939}]}, {"text": "The purpose of the experiments is to evaluate the ability of the proposed method to generate a summary of good quality within a specified length.", "labels": [], "entities": []}, {"text": "We used JAMUL corpus as the Japanese test set (.", "labels": [], "entities": [{"text": "JAMUL corpus", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.9403634071350098}, {"text": "Japanese test set", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.8779585361480713}]}, {"text": "This test set contains three kinds of headlines for 1,181 1 news articles written by professional editors under the different upper bounds of headline lengths.", "labels": [], "entities": []}, {"text": "The upper bounds are 10, 13, and 26 characters (len = 10, 13, 26).", "labels": [], "entities": []}, {"text": "This test set is suitable for simulating the real process of news production because it is constructed by a Japanese media company.", "labels": [], "entities": [{"text": "news production", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.686941996216774}]}, {"text": "In contrast, we have no English test sets that contain headlines of multiple lengths.", "labels": [], "entities": [{"text": "English test sets", "start_pos": 24, "end_pos": 41, "type": "DATASET", "confidence": 0.7136269509792328}]}, {"text": "Thus, we randomly extracted 3,000 sentence-headline pairs that satisfy a length constraint from the test set constructed from annotated English Gigaword () by pre-processing scripts of . We set three configurations for the number of characters as the length constraint: 0 to 30 characters (len = 30), 30 to 50 characters (len = 50), and 50 to 75 characters (len = 75).", "labels": [], "entities": []}, {"text": "Moreover, we also evaluate the proposed method on the DUC-2004 task 1 ( for comparison with published scores in previous studies.", "labels": [], "entities": [{"text": "DUC-2004 task 1", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8967284560203552}]}, {"text": "Unfortunately, we have no large supervision data with multiple headlines of different lengths associated with each news article in both languages.", "labels": [], "entities": []}, {"text": "Thus, we trained the proposed method on pairs with a one-to-one correspondences between the source articles and headlines.", "labels": [], "entities": []}, {"text": "In the training step, we regarded the length of the target headline as the desired length len.", "labels": [], "entities": [{"text": "length", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9639059901237488}]}, {"text": "For Japanese, we used the JNC corpus, which contains a pair of the lead three sentences of a news article and its headline (.", "labels": [], "entities": [{"text": "JNC corpus", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.9481151103973389}]}, {"text": "The training set contains about 1.6M pairs 3 . For English, we used sentence-headline pairs extracted from the annotated English Gigaword with the same pre-processing script used in the construction of the test set.", "labels": [], "entities": []}, {"text": "The training set contains about 3.8M pairs.", "labels": [], "entities": []}, {"text": "In this paper, we used a character-level decoder to control the number of characters.", "labels": [], "entities": []}, {"text": "On the encoder side, we used subword units to construct the vocabulary (.", "labels": [], "entities": []}, {"text": "We set the hyper-parameter to fit the vocabulary size to about 8k for Japanese and 16k for English.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Recall-oriented ROUGE scores for each length on Japanese test set. This test set contains three kinds of  headlines, i.e., len = 10, 13, 26, tied to a single article.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.7498078346252441}, {"text": "Japanese test set", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.9627997477849325}]}, {"text": " Table 2: Recall-oriented ROUGE scores for each length on test data extracted from annotated English Gigaword.", "labels": [], "entities": [{"text": "Recall-oriented ROUGE scores", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.8246108889579773}]}, {"text": " Table 3: Recall-oriented ROUGE scores in DUC-2004.", "labels": [], "entities": [{"text": "Recall-oriented ROUGE scores", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.768031895160675}, {"text": "DUC-2004", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9316916465759277}]}, {"text": " Table 4: Variances of generated headlines.", "labels": [], "entities": []}]}