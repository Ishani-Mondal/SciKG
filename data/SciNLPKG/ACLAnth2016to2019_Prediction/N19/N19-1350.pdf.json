{"title": [{"text": "Learning to Describe Unknown Phrases with Local and Global Contexts", "labels": [], "entities": [{"text": "Describe Unknown Phrases with Local and Global Contexts", "start_pos": 12, "end_pos": 67, "type": "TASK", "confidence": 0.7548839151859283}]}], "abstractContent": [{"text": "When reading a text, it is common to become stuck on unfamiliar words and phrases, such as polysemous words with novel senses, rarely used idioms, internet slang, or emerging entities.", "labels": [], "entities": []}, {"text": "If we humans cannot figure out the meaning of those expressions from the immediate local context, we consult dictionaries for definitions or search documents or the web to find other global context to help in interpretation.", "labels": [], "entities": []}, {"text": "Can machines help us do this work?", "labels": [], "entities": []}, {"text": "Which type of context is more important for machines to solve the problem?", "labels": [], "entities": []}, {"text": "To answer these questions, we undertake a task of describing a given phrase in natural language based on its local and global contexts.", "labels": [], "entities": []}, {"text": "To solve this task, we propose a neural description model that consists of two context encoders and a description decoder.", "labels": [], "entities": []}, {"text": "In contrast to the existing methods for non-standard English explanation (Ni and Wang, 2017) and definition generation (Noraset et al., 2017; Gadetsky et al., 2018), our model appropriately takes important clues from both local and global contexts.", "labels": [], "entities": [{"text": "definition generation", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.9674867391586304}]}, {"text": "Experimental results on three existing datasets (including WordNet, Oxford and Urban Dictionaries) and a dataset newly created from Wikipedia demonstrate the effectiveness of our method over previous work.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9671614170074463}, {"text": "Oxford and Urban Dictionaries", "start_pos": 68, "end_pos": 97, "type": "DATASET", "confidence": 0.831339880824089}]}], "introductionContent": [{"text": "When we read news text with emerging entities, text in unfamiliar domains, or text in foreign languages, we often encounter expressions (words or phrases) whose senses we do not understand.", "labels": [], "entities": []}, {"text": "In such cases, we may first try to figure out the meanings of those expressions by reading the surrounding words (local context) carefully.", "labels": [], "entities": []}, {"text": "Failing to do so, we may consult dictionaries, and in the case of polysemous words, choose an appropriate meaning based on the context.", "labels": [], "entities": []}, {"text": "Learning novel word senses via dictionary definitions is known to be more effective than contextual guessing.", "labels": [], "entities": [{"text": "contextual guessing", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.6709935665130615}]}, {"text": "However, very often, handcrafted dictionaries do not contain definitions of expressions that are rarely used or newly created.", "labels": [], "entities": []}, {"text": "Ultimately, we may need to read through the entire document or even search the web to find other occurances of the expression (global context) so that we can guess its meaning.", "labels": [], "entities": []}, {"text": "Can machines help us do this work?", "labels": [], "entities": []}, {"text": "have proposed a task of generating a definition fora phrase given its local context.", "labels": [], "entities": []}, {"text": "However, they follow the strict assumption that the target phrase is newly emerged and there is only a single local context available for the phrase, which makes the task of generating an accurate and coherent definition difficult (perhaps as difficult as a human comprehending the phrase itself).", "labels": [], "entities": []}, {"text": "On the other hand, attempted to generate a definition of a word from an embedding induced from massive text (which can be seen as global context).", "labels": [], "entities": []}, {"text": "This is followed by that refers to a local context to disambiguate polysemous words by choosing relevant dimensions of their word embeddings.", "labels": [], "entities": []}, {"text": "Al-though these research efforts revealed that both local and global contexts are useful in generating definitions, none of these studies exploited both contexts directly to describe unknown phrases.", "labels": [], "entities": []}, {"text": "In this study, we tackle the task of describing (defining) a phrase when given its local and global contexts.", "labels": [], "entities": [{"text": "describing (defining) a phrase", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.7738354106744131}]}, {"text": "We present LOG-CaD, a neural description generator) to directly solve this task.", "labels": [], "entities": [{"text": "LOG-CaD", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.8925384879112244}]}, {"text": "Given an unknown phrase without sense definitions, our model obtains a phrase embedding as its global context by composing word embeddings while also encoding the local context.", "labels": [], "entities": []}, {"text": "The model therefore combines both pieces of information to generate a natural language description.", "labels": [], "entities": []}, {"text": "Considering various applications where we need definitions of expressions, we evaluated our method with four datasets including WordNet () for general words, the Oxford dictionary () for polysemous words, Urban Dictionary (Ni and Wang, 2017) for rare idioms or slang, and a newlycreated Wikipedia dataset for entities.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.941960334777832}, {"text": "Oxford dictionary", "start_pos": 162, "end_pos": 179, "type": "DATASET", "confidence": 0.9730324149131775}, {"text": "Wikipedia dataset", "start_pos": 287, "end_pos": 304, "type": "DATASET", "confidence": 0.9221189618110657}]}, {"text": "Our contributions are as follows: \u2022 We propose a general task of defining unknown phrases given their contexts.", "labels": [], "entities": []}, {"text": "This task is a generalization of three related tasks () and involves various situations where we need definitions of unknown phrases ( \u00a7 2).", "labels": [], "entities": []}, {"text": "\u2022 We propose a method for generating natural language descriptions for unknown phrases with local and global contexts ( \u00a7 3).", "labels": [], "entities": []}, {"text": "\u2022 As a benchmark to evaluate the ability of the models to describe entities, we build a largescale dataset from Wikipedia and Wikidata for the proposed task.", "labels": [], "entities": []}, {"text": "We release our dataset and the code 1 to promote the reproducibility of the experiments ( \u00a7 4).", "labels": [], "entities": []}, {"text": "\u2022 The proposed method achieves the state-ofthe-art performance on our new dataset and the three existing datasets used in the related studies) ( \u00a7 5).", "labels": [], "entities": []}, {"text": "In this section, we define our task of describing a phrase in a specific context.", "labels": [], "entities": []}, {"text": "Given an undefined phrase Here, X trg can be a word or a short phrase and is included in X.", "labels": [], "entities": []}, {"text": "Y is a definition-like concrete and concise sentence that describes the X trg . For example, given a phrase \"sonic boom\" with its context \"the shock wave maybe caused by sonic boom or by explosion,\" the task is to generate a description such as \"sound created by an object moving fast.\"", "labels": [], "entities": []}, {"text": "If the given context has been changed to \"this is the first official tour to support the band's latest studio effort, 2009's Sonic Boom,\" then the appropriate output would be \"album by Kiss.\"", "labels": [], "entities": [{"text": "Sonic Boom", "start_pos": 125, "end_pos": 135, "type": "DATASET", "confidence": 0.8661972284317017}]}, {"text": "The process of description generation can be modeled with a conditional language model as", "labels": [], "entities": [{"text": "description generation", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.8172214329242706}]}], "datasetContent": [{"text": "Our goal is to let machines describe unfamiliar words and phrases, such as polysemous words, rarely used idioms, or emerging entities.", "labels": [], "entities": []}, {"text": "Among the three existing datasets, WordNet and Oxford dictionary mainly target the words but not phrases, thus are not perfect test beds for this goal.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9682361483573914}, {"text": "Oxford dictionary", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.9679568111896515}]}, {"text": "On the other hand, although the Urban Dictionary dataset contains descriptions of rarely-used phrases, the domain of its targeted words and phrases is limited to Internet slang.", "labels": [], "entities": [{"text": "Urban Dictionary dataset", "start_pos": 32, "end_pos": 56, "type": "DATASET", "confidence": 0.8605267008145651}]}, {"text": "In order to confirm that our model can generate the description of entities as well as polysemous words and slang, we constructed anew dataset for context-aware phrase description generation from Wikipedia 2 and Wikidata 3 which contain a wide variety of entity descriptions with contexts.", "labels": [], "entities": [{"text": "phrase description generation", "start_pos": 161, "end_pos": 190, "type": "TASK", "confidence": 0.7392067313194275}]}, {"text": "The overview of the data extraction process is shown in.", "labels": [], "entities": [{"text": "data extraction", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7734949588775635}]}, {"text": "Each entry in the dataset consists of (1) a phrase, (2) its description, and (3) context (a sentence).", "labels": [], "entities": []}, {"text": "For preprocessing, we applied Stanford Tokenizer to the descriptions of Wikidata items and the articles in Wikipedia.", "labels": [], "entities": []}, {"text": "Next, we removed phrases in parentheses from the Wikipedia articles, since they tend to be paraphrasing in other languages and work as noise.", "labels": [], "entities": []}, {"text": "To obtain the contexts of each item in Wikidata, we extracted the sentence which has a link referring to the item through all the first paragraphs of Wikipedia articles and replaced the phrase of the links with a special token.", "labels": [], "entities": []}, {"text": "Wikidata items with no description or no contexts are ignored.", "labels": [], "entities": []}, {"text": "This utilization of links makes it possible to resolve the ambiguity of words and phrases in a sentence without human annotations, which is a major advantage of using Wikipedia.", "labels": [], "entities": [{"text": "resolve the ambiguity of words and phrases in a sentence", "start_pos": 47, "end_pos": 103, "type": "TASK", "confidence": 0.757479339838028}]}, {"text": "Note that we used only links whose anchor texts are identical to the title of the Wikipedia articles, since the users of Wikipedia sometimes link mentions to related articles.", "labels": [], "entities": []}, {"text": "We evaluate our method by applying it to describe words in WordNet 5 and Oxford Dictionary, 6 phrases in Urban Dictionary and Wikipedia/Wikidata.", "labels": [], "entities": [{"text": "WordNet 5", "start_pos": 59, "end_pos": 68, "type": "DATASET", "confidence": 0.9476271271705627}, {"text": "Oxford Dictionary", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.9580740332603455}]}, {"text": "8 For all of these datasets, a given word or phrase has an inventory of senses with corresponding definitions and usage examples.", "labels": [], "entities": []}, {"text": "These definitions are regarded as groundtruth descriptions.", "labels": [], "entities": []}, {"text": "Datasets To evaluate our model on the word description task on WordNet, we followed and extracted data from WordNet using the dict-definition 9 toolkit.", "labels": [], "entities": [{"text": "word description task", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8203500906626383}, {"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9249394536018372}, {"text": "WordNet", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.9715380072593689}]}, {"text": "Each entry in the data consists of three elements: (1) a word, (2) its definition, and, the Urban Dictionary following Ni and Wang (2017) and our Wikipedia dataset described in the previous section.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 146, "end_pos": 163, "type": "DATASET", "confidence": 0.9373445808887482}]}, {"text": "show the properties and statistics of the four datasets, respectively.", "labels": [], "entities": []}, {"text": "To simulate a situation in areal application where we might not have access to global context for the target phrases, we did not train domainspecific word embeddings on each dataset.", "labels": [], "entities": []}, {"text": "Instead, for all of the four datasets, we use the same  If the expression to be described consists of multiple words, its phrase embedding is calculated by simply summing up all the CBOW vectors of words in the phrase, such as \"sonic\" and \"boom.\"", "labels": [], "entities": []}, {"text": "If pre-trained CBOW embeddings are unavailable, we instead use a special vector (which is randomly initialized with a uniform distribution) as word embeddings.", "labels": [], "entities": []}, {"text": "Note that our pre-trained embeddings only cover 26.79% of the words in the expressions to be described in our Wikipedia dataset, while it covers all words in WordNet dataset (See).", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 110, "end_pos": 127, "type": "DATASET", "confidence": 0.9530000388622284}, {"text": "WordNet dataset", "start_pos": 158, "end_pos": 173, "type": "DATASET", "confidence": 0.9821361899375916}]}, {"text": "Even if no reliable word embeddings are available, all models can capture the character information through character-level CNNs (See.", "labels": [], "entities": []}, {"text": "Models We implemented four methods: (1) Global (Noraset et al., 2017), (2) Local (Ni and Wang, 2017) with CNN, (3) I-Attention (, and our proposed model, (4) LOGCaD.", "labels": [], "entities": [{"text": "LOGCaD", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.8309128880500793}]}, {"text": "The Global model is our reimplementation of the best model (S + G + CH) in.", "labels": [], "entities": []}, {"text": "It can access the global context of a phrase to be described, but has no ability to read the local context.", "labels": [], "entities": []}, {"text": "The Local model is the reimplementation of the best model (dual encoder) in Ni and.", "labels": [], "entities": []}, {"text": "In order to make a fair comparison of the effectiveness of local and global contexts, we slightly modify the original implementation by; as the character-level encoder in the Local model, we adopt CNNs that are exactly the same as the other two models instead of the original LSTMs.", "labels": [], "entities": []}, {"text": "The I-Attention is our reimplementation of the best model (S + I-Attention) in Gadetsky   et al..", "labels": [], "entities": []}, {"text": "Similar to our model, it uses both local and global contexts.", "labels": [], "entities": []}, {"text": "Unlike our model, however, it does not use character information to predict descriptions.", "labels": [], "entities": []}, {"text": "Also, it cannot directly use the local context to predict the words in descriptions.", "labels": [], "entities": []}, {"text": "This is because the I-Attention model indirectly uses the local context only to disambiguate the phrase embedding x trg as Here, the FFNN(\u00b7) function is a feed-forward neural network that maps the encoded local contexts hi to another space.", "labels": [], "entities": []}, {"text": "The mapped local contexts are then averaged over the length of the sentence X to obtain a representation of the local context.", "labels": [], "entities": []}, {"text": "This is followed by a linear layer and a sigmoid function to obtain the soft binary mask m which can filter out the unrelated information included in global context.", "labels": [], "entities": []}, {"text": "Finally, the disambiguated phrase embedding x trg is then used to update the decoder hidden state as All four models are implemented with the PyTorch framework (Ver. 1.0.0).", "labels": [], "entities": []}, {"text": "11   I-Attention model also uses local and global contexts, its performance was always lower than the LOG-CaD model.", "labels": [], "entities": []}, {"text": "This result shows that using local context to predict description is more effective than using it to disambiguate the meanings in global context.", "labels": [], "entities": [{"text": "predict description", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7929947376251221}]}, {"text": "In particular, the low BLEU scores of Global and I-Attention models on Wikipedia dataset suggest that it is necessary to learn to ignore the noisy information in global context if the coverage of pre-trained word embeddings is extremely low (see the third and fourth rows in).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.9992737174034119}, {"text": "Wikipedia dataset", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.9579352140426636}]}, {"text": "We suspect that the Urban Dictionary task is too difficult and the results are unreliable considering its extremely low BLEU scores and high ratio of unknown tokens in generated descriptions.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 120, "end_pos": 131, "type": "METRIC", "confidence": 0.9729070663452148}]}, {"text": "q-lets and co. is a filipino and english informative children 's show on q in the philippines . she was a founding producer of the cbc radio one show \" q \" . the q awards are the uk 's annual music awards run by the music magazine \" q \" . charles fraser-smith was an author and one-time missionary who is widely credited as being the inspiration for ian fleming 's james bond quartermaster q . Reference: philippine tv network canadian radio show british music magazine fictional character from james bond  Manual Evaluation To compare the proposed model and the strongest baseline in (i.e., the Local model), we performed a human evaluation on our dataset.", "labels": [], "entities": [{"text": "uk", "start_pos": 179, "end_pos": 181, "type": "DATASET", "confidence": 0.9642523527145386}]}, {"text": "We randomly selected 100 samples from the test set of the Wikipedia dataset and asked three native English speakers to rate the output descriptions from 1 to 5 points as: 1) completely wrong or self-definition, 2) correct topic with wrong information, 3) correct but incomplete, 4) small details missing, 5) correct.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.937555193901062}]}, {"text": "The averaged scores are reported in.", "labels": [], "entities": []}, {"text": "Pair-wise bootstrap resampling test) for the annotated scores has shown that the superiority of LOG-CaD over the Local model is statistically significant (p < 0.01).", "labels": [], "entities": [{"text": "LOG-CaD", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9360524415969849}]}, {"text": "Qualitative Analysis shows a word in the WordNet, while show the examples of the entities in Wikipedia as examples.", "labels": [], "entities": [{"text": "Qualitative Analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6455171406269073}, {"text": "WordNet", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9635188579559326}]}, {"text": "When comparing the two datasets, the quality of generated descriptions of Wikipedia dataset is significantly better than that of WordNet dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 74, "end_pos": 91, "type": "DATASET", "confidence": 0.9600261449813843}, {"text": "WordNet dataset", "start_pos": 129, "end_pos": 144, "type": "DATASET", "confidence": 0.9743203222751617}]}, {"text": "The main reason for this result is that the size of training data of the Wikipedia dataset is 64x larger than the WordNet dataset (See).", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.9723884463310242}, {"text": "WordNet dataset", "start_pos": 114, "end_pos": 129, "type": "DATASET", "confidence": 0.9875706732273102}]}, {"text": "For all examples in the three tables, the Global model can only generate a single description for each input word/phrase because it cannot access any local context.", "labels": [], "entities": []}, {"text": "In the Wordnet dataset, only the I-Attention and LOG-CaD models can successfully generate the concept of \"remove\" given the context #2.", "labels": [], "entities": [{"text": "Wordnet dataset", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.9845225214958191}, {"text": "LOG-CaD", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9255580306053162}]}, {"text": "This result suggests that considering both local and global contexts are essential to generate correct descriptions.", "labels": [], "entities": []}, {"text": "In our Wikipedia dataset, both the Local and LOG-CaD models can describe the word/phrase considering its local context.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.8916508853435516}]}, {"text": "For example, both the Local and LOG-CaD models could generate \"american\" in the description for \"daniel o'neill\" given \"united states\" in context #1, while they could generate \"british\" given \"belfast\" in context #2.", "labels": [], "entities": []}, {"text": "A similar trend can also be observed in, where LOG-CaD could generate the locational expressions such as \"philippines\" and \"british\" given the different contexts.", "labels": [], "entities": []}, {"text": "On the other hand, the I-Attention model could not describe the two phrases, taking into account the local contexts.", "labels": [], "entities": []}, {"text": "We will present an analysis of this phenomenon in the next section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the word/phrase description  datasets.", "labels": [], "entities": [{"text": "word/phrase description", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.6079413965344429}]}, {"text": " Table 3: Hyperparameters of the models", "labels": [], "entities": [{"text": "Hyperparameters", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.952586829662323}]}, {"text": " Table 4: BLEU scores on four datasets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9982810020446777}]}, {"text": " Table 5: Averaged human annotated scores on  Wikipedia dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.9849935472011566}]}]}