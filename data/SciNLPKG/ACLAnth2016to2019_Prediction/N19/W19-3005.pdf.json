{"title": [{"text": "Suicide Risk Assessment with Multi-level Dual-Context Language and BERT", "labels": [], "entities": [{"text": "Suicide Risk Assessment", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7113960882027944}, {"text": "BERT", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.997317373752594}]}], "abstractContent": [{"text": "Mental health predictive systems typically model language as if from a single context (e.g. Twitter posts, status updates, or forum posts) and often limited to a single level of analysis (e.g. either the message-level or user-level).", "labels": [], "entities": [{"text": "Mental health predictive", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.672374407450358}]}, {"text": "Here, we bring these pieces together to explore the use of open-vocabulary (BERT embeddings, topics) and theoretical features (emotional expression lexica, personality) for the task of suicide risk assessment on support forums (the CLPsych-2019 Shared Task).", "labels": [], "entities": [{"text": "BERT", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9825092554092407}, {"text": "suicide risk assessment", "start_pos": 185, "end_pos": 208, "type": "TASK", "confidence": 0.738447348276774}, {"text": "CLPsych-2019 Shared Task)", "start_pos": 232, "end_pos": 257, "type": "DATASET", "confidence": 0.8523011803627014}]}, {"text": "We used dual context based approaches (model-ing content from suicide forums separate from other content), built over both traditional ML models as well as a novel dual RNN architecture with user-factor adaptation.", "labels": [], "entities": []}, {"text": "We find that while affect from the suicide context distinguishes with no-risk from those with \"any-risk\", personality factors from the non-suicide contexts provide distinction of the levels of risk: low, medium, and high risk.", "labels": [], "entities": []}, {"text": "Within the shared task, our dual-context approach (listed as SBU-HLAB in the official results) achieved state-of-the-art performance predicting suicide risk using a combination of suicide-context and non-suicide posts (Task B), achieving an F1 score of 0.50 over hidden test set labels.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.9848364293575287}]}], "introductionContent": [{"text": "Suicidal behavior is conceptualized by the thoughts, plans, and acts an individual makes toward intentionally ending their own life.", "labels": [], "entities": [{"text": "Suicidal behavior", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9260911345481873}]}, {"text": "With deaths by suicide increasing substantially, researchers are turning to automated analysis of user generated content to potentially provide methods for early detection of suicide risk severity.", "labels": [], "entities": [{"text": "early detection of suicide risk severity", "start_pos": 156, "end_pos": 196, "type": "TASK", "confidence": 0.626607229312261}]}, {"text": "If an automated process could detect elevated risk in a person, personalized (potentially digital and early) interventions could be provided to the individual to alleviate the risk.", "labels": [], "entities": []}, {"text": "Importantly, suicide risk assessment follows a growing body of work which has provided language-based models for measuring theoretically related psychological constructs: valence and arousal), depression (, and stress (.", "labels": [], "entities": [{"text": "suicide risk assessment", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.9091890255610148}]}, {"text": "However, few have evaluated the role of such theoretical models alongside standard openvocbaulary features (e.g. ngrams, embeddings, topics), or integrated both message-level assessment (e.g. emotional valence) along with userlevel assessment (e.g., personality).", "labels": [], "entities": []}, {"text": "In this study, we investigate a series of dual context (treating suicide forum posts separate from other forum posts) and multi-level approaches (user-level assessments of demographics and personality as well as aggregates of message-level features) for suicide risk prediction.", "labels": [], "entities": [{"text": "suicide risk prediction", "start_pos": 254, "end_pos": 277, "type": "TASK", "confidence": 0.8227622310320536}]}, {"text": "Our contributions include: (1) proposal and evaluation of a dual-context modeling approach where language in a suicide-specific context is treated separate from language from other forums, (2) a novel deep learning architecture (DualDeepAtt) that both (a) applies dual-context modeling to GRU cells and attention layers and (b) adds a user-factor adaptation layer, (3) comparison of individual theoretically related linguistic assessments, (4) evaluation of models based on theoretically-motivated features versus models based on open-vocabulary features with multiple approaches to aggregating message-level features.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Pearson correlations (r) between theoretical  linguistic dimensions and suicide risk level over the  training data. Gender was continuously coded (larger  indicating more likely female). Correlations are signif- icant at p < .01 multi-test corrected.", "labels": [], "entities": [{"text": "Pearson correlations (r)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.9418157458305358}]}, {"text": " Table 2: Task A: Suicide Risk Prediction Performance  (measured by Accuracy and F1-scores). Best perform- ing models are highlighted. Meta features for Task A  only contains post statistics as all posts come from Sui- cideWatch.", "labels": [], "entities": [{"text": "Suicide Risk Prediction", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.5047790904839834}, {"text": "Accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9993939399719238}, {"text": "F1-scores", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.989953875541687}]}, {"text": " Table 3: Task B: Suicide Risk Prediction Performance  (measured by Accuracy and F1-scores). Best perform- ing models are highlighted.", "labels": [], "entities": [{"text": "Suicide Risk Prediction", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.5119661291440328}, {"text": "Accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9994695782661438}, {"text": "F1-scores", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9891780614852905}]}]}