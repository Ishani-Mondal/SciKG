{"title": [{"text": "Dialogue Act Classification with Context-Aware Self-Attention", "labels": [], "entities": [{"text": "Dialogue Act Classification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6338603496551514}]}], "abstractContent": [{"text": "Recent work in Dialogue Act classification has treated the task as a sequence labeling problem using hierarchical deep neural networks.", "labels": [], "entities": [{"text": "Dialogue Act classification", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7139845490455627}, {"text": "sequence labeling", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.6655918061733246}]}, {"text": "We build on this prior work by lever-aging the effectiveness of a context-aware self-attention mechanism coupled with a hierarchical recurrent neural network.", "labels": [], "entities": []}, {"text": "We conduct extensive evaluations on standard Dialogue Act classification datasets and show significant improvement over state-of-the-art results on the Switchboard Dialogue Act (SwDA) Corpus.", "labels": [], "entities": [{"text": "Dialogue Act classification datasets", "start_pos": 45, "end_pos": 81, "type": "DATASET", "confidence": 0.5803762897849083}, {"text": "Switchboard Dialogue Act (SwDA) Corpus", "start_pos": 152, "end_pos": 190, "type": "DATASET", "confidence": 0.620607601744788}]}, {"text": "We also investigate the impact of different utterance-level representation learning methods and show that our method is effective at capturing utterance-level semantic text representations while maintaining high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9940938353538513}]}], "introductionContent": [{"text": "Dialogue Acts (DAs) are the functions of utterances in dialogue-based interaction.", "labels": [], "entities": [{"text": "Dialogue Acts (DAs)", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.5529718816280365}]}, {"text": "A DA represents the meaning of an utterance at the level of illocutionary force, and hence, constitutes the basic unit of linguistic communication.", "labels": [], "entities": []}, {"text": "DA classification is an important task in Natural Language Understanding, with applications in question answering, conversational agents, speech recognition, etc.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9659565389156342}, {"text": "Natural Language Understanding", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6398337682088217}, {"text": "question answering", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.8274807929992676}, {"text": "speech recognition", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7444348931312561}]}, {"text": "Examples of DAs can be found in.", "labels": [], "entities": []}, {"text": "Here we have a conversation of 7 utterances between two speakers.", "labels": [], "entities": []}, {"text": "Each utterance has a corresponding label such as Question or Backchannel.", "labels": [], "entities": [{"text": "Backchannel", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.3853653371334076}]}, {"text": "Early work in this field made use of statistical machine learning methods and approached the task as either a structured prediction or text classification problem ().", "labels": [], "entities": [{"text": "structured prediction or text classification", "start_pos": 110, "end_pos": 154, "type": "TASK", "confidence": 0.6219531536102295}]}, {"text": "Many recent studies have proposed deep learning models for the DA classification task with promising results ( Vu, 2017).", "labels": [], "entities": [{"text": "DA classification task", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.9726327657699585}]}, {"text": "However, most of these approaches treat the task as a text classification problem, treating each utterance in isolation, rendering them unable to leverage the conversation-level contextual dependence among utterances.", "labels": [], "entities": [{"text": "text classification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7283602505922318}]}, {"text": "Knowing the text and/or the DA labels of the previous utterances can assist in predicting the current DA state.", "labels": [], "entities": []}, {"text": "For instance, in, the Answer or Statement dialog acts often follow Question type utterances.", "labels": [], "entities": [{"text": "Answer or Statement dialog", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.8380824029445648}]}, {"text": "This work draws from recent advances in NLP such as self-attention, hierarchical deep learning models, and contextual dependencies to produce a dialogue act classification model that is effective across multiple domains.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 144, "end_pos": 171, "type": "TASK", "confidence": 0.631284256776174}]}, {"text": "Specifically, we propose a hierarchical deep neural network to model different levels of utterance and dialogue act semantics, achieving state-of-the-art performance on the Switchboard Dialogue Act Corpus.", "labels": [], "entities": [{"text": "Switchboard Dialogue Act Corpus", "start_pos": 173, "end_pos": 204, "type": "DATASET", "confidence": 0.5797624737024307}]}, {"text": "We demonstrate how performance can improve by leveraging context at different levels of the model: previous labels for sequence prediction (using a CRF), conversation-level context with self-attention for utterance representation learning, and character embeddings at the word-level.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.6893932968378067}, {"text": "utterance representation learning", "start_pos": 205, "end_pos": 238, "type": "TASK", "confidence": 0.8097010056177775}]}, {"text": "Finally, we explore different ways to learn effective utterance repre-sentations, which serve as the building blocks of our hierarchical architecture for DA classification.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 154, "end_pos": 171, "type": "TASK", "confidence": 0.97702756524086}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Number of utterances by dataset. |C| denotes  number of classes and |V| is the vocabulary size.", "labels": [], "entities": []}, {"text": " Table 3: DA Classification Accuracy", "labels": [], "entities": [{"text": "DA Classification", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6534755229949951}, {"text": "Accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9234377145767212}]}, {"text": " Table 4: Performance of utterance representation  methods when integrated with the hierarchical model", "labels": [], "entities": [{"text": "utterance representation", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.8308552503585815}]}]}