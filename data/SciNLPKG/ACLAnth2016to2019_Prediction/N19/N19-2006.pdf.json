{"title": [{"text": "Diversifying Reply Suggestions using a Matching-Conditional Variational Autoencoder", "labels": [], "entities": [{"text": "Diversifying Reply Suggestions", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8794038693110148}]}], "abstractContent": [{"text": "We consider the problem of diversifying automated reply suggestions fora commercial instant-messaging (IM) system (Skype).", "labels": [], "entities": []}, {"text": "Our conversation model is a standard matching based information retrieval architecture, which consists of two parallel encoders to project messages and replies into a common feature representation.", "labels": [], "entities": []}, {"text": "During inference, we select replies from a fixed response set using nearest neighbors in the feature space.", "labels": [], "entities": []}, {"text": "To diversify responses, we formulate the model as a generative latent variable model with Conditional Variational Auto-Encoder (M-CVAE).", "labels": [], "entities": []}, {"text": "We propose a constrained-sampling approach to make the variational inference in M-CVAE efficient for our production system.", "labels": [], "entities": []}, {"text": "In offline experiments, M-CVAE consistently increased diversity by \u223c 30 \u2212 40% without significant impact on relevance.", "labels": [], "entities": [{"text": "diversity", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9543272256851196}]}, {"text": "This translated to a 5% gain in click-rate in our online production system .", "labels": [], "entities": [{"text": "click-rate", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9509056210517883}]}], "introductionContent": [{"text": "Automated reply suggestions or smart-replies (SR) are increasingly becoming common in many popular applications such as,,,, and Facebook Messenger.", "labels": [], "entities": [{"text": "Automated reply suggestions or smart-replies (SR)", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.5473160669207573}]}, {"text": "Given a message, the problem that SR solves is to suggest short and relevant responses that a person may select with a click to avoid any typing.", "labels": [], "entities": [{"text": "SR", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9811990261077881}]}, {"text": "For example, fora message such as Want to meetup for lunch?", "labels": [], "entities": []}, {"text": "an SR system may suggest the following three responses {Sure; No problem!; Ok}.", "labels": [], "entities": []}, {"text": "While these are all relevant suggestions, they are semantically equivalent.", "labels": [], "entities": []}, {"text": "In this paper, we consider how we can diversify the suggestions such as with {Sure; Sorry I can't; What time?} without losing any relevance.", "labels": [], "entities": []}, {"text": "Our hypothesis is that encompassing greater semantic variability and intrinsic diversity will lead to higher click-rates for suggestions.", "labels": [], "entities": []}, {"text": "Smart-reply has been modeled as an sequenceto-sequence (S2S) process ( inspired by their success in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.7047552019357681}]}, {"text": "It has also been modeled as an Information Retrieval (IR) task.", "labels": [], "entities": [{"text": "Information Retrieval (IR) task", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.8496122260888418}]}, {"text": "Here, replies are selected from a fixed list of responses, using two parallel Matching networks to encode messages and replies in a common representation.", "labels": [], "entities": []}, {"text": "Our production system uses such a Matching architecture.", "labels": [], "entities": [{"text": "Matching", "start_pos": 34, "end_pos": 42, "type": "TASK", "confidence": 0.9331256151199341}]}, {"text": "There are several practical factors in favor of the Matching-IR approach.", "labels": [], "entities": [{"text": "Matching-IR", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.9579099416732788}]}, {"text": "Production systems typically maintain a curated response-set (to have better control on the feature and to prevent inappropriate responses) due to which they rarely require a generative model.", "labels": [], "entities": []}, {"text": "Moreover, inference is efficient in the matching architecture as vectors for the fixed response set can be pre-computed and hashed for fast lookup.", "labels": [], "entities": []}, {"text": "Qualitatively, S2S also tends to generate generic, and sometimes incorrect responses due to label and exposure bias.", "labels": [], "entities": []}, {"text": "Solutions for S2S during training) and inference () have high overhead.", "labels": [], "entities": []}, {"text": "Matching architectures on the other hand, can incorporate a global normalization factor during training to mitigate this issue.", "labels": [], "entities": []}, {"text": "In practice we found that the Matching model retrieves responses which are semantically very similar in lexical content and underlying intent as shown in.", "labels": [], "entities": []}, {"text": "This behavior is not surprising and even expected since we optimize the model as a point estimation on golden message-reply (mr) pairs.", "labels": [], "entities": []}, {"text": "In fact, it illustrates the effectiveness of encoding similar intents in the common feature space.", "labels": [], "entities": []}, {"text": "While this leads to individual responses being highly relevant, the model needs to diversify the responses to improve the overall relevance of the set by covering a wider variety of intents.", "labels": [], "entities": []}, {"text": "We hypothesize that diversity would improve the click rates in our production system.", "labels": [], "entities": []}, {"text": "This is the main focus of this paper.", "labels": [], "entities": []}, {"text": "We provide two baselines approaches using lexical clustering and maximal marginal relevance (MMR) for diversification in the Matching model.", "labels": [], "entities": [{"text": "maximal marginal relevance (MMR)", "start_pos": 65, "end_pos": 97, "type": "METRIC", "confidence": 0.8677692910035452}]}, {"text": "Since we typically do not have multiple responses in one-on-one conversational data (and thus cannot train for multiple-intents), we consider a generative Latent Variable Model (LVM) to learn the hidden intents from individual m-r pairs.", "labels": [], "entities": []}, {"text": "Our key hypothesis is that intents can be encoded through a latent variable, which can be then be utilized to generate diverse responses.", "labels": [], "entities": []}, {"text": "To this end, we propose the Matching-CVAE (M-CVAE) architecture, which introduces a generative LVM on the Matching-IR model using the neural variational autoencoder (VAE) framework (.", "labels": [], "entities": []}, {"text": "M-CVAE is trained to generate the vector representation of the response conditioned on the input message and a stochastic latent variable.", "labels": [], "entities": []}, {"text": "During inference we sample responses fora message and use voting to rank candidates.", "labels": [], "entities": []}, {"text": "To reduce latency, we propose a constrained sampling strategy for M-CVAE which makes variational inference feasible for production systems.", "labels": [], "entities": []}, {"text": "We show that the Matching architecture maintains the relevance advantages and inference-efficiency required fora production system while CVAE allows diversification of responses.", "labels": [], "entities": [{"text": "Matching", "start_pos": 17, "end_pos": 25, "type": "TASK", "confidence": 0.961841344833374}]}, {"text": "We first describe our current production model and diversification approaches.", "labels": [], "entities": []}, {"text": "Next, we present our key contribution: Matching-CVAE.", "labels": [], "entities": [{"text": "Matching-CVAE", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.8861525654792786}]}, {"text": "Finally we report on our results from offline and online experiments, including production system performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our current production model in Skype is a parallel Matching stack) with embedding size of 320 and 2 Bi-LSTM layers with hidden size of 300 for both messages and replies.", "labels": [], "entities": []}, {"text": "The token vocabulary is\u02dc100kis\u02dc100k (tokens with a minimum frequency of 50 in the training set), and the response set size is\u02dc30kis\u02dc30k.", "labels": [], "entities": []}, {"text": "It selects top 15 candidates and deduplicates using lexical clustering to suggest three responses.", "labels": [], "entities": []}, {"text": "The entire system is implemented on the Cognitive Toolkit (CNTK) which provides efficient training and run-time libraries, particularly suited to RNN based architectures.", "labels": [], "entities": []}, {"text": "We analyze the M-CVAE model in comparison to this production model . The production model is also used as the control for online A/B testing, so it is natural to use the same model for offline analysis.", "labels": [], "entities": []}, {"text": "To train the M-CVAE, we use the base Matching model, freeze its parameters, and then train the CVAE layers on top.", "labels": [], "entities": []}, {"text": "We apply a dropout rate of 0.2 after the initial embedding layer (for both Matching and M-CVAE) and use the Adadelta learner for training.", "labels": [], "entities": [{"text": "Adadelta learner", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9227873980998993}]}, {"text": "We use the loss on a held out validation set for model selection.", "labels": [], "entities": [{"text": "model selection", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7054117619991302}]}, {"text": "Training data: We sample\u02dc100sample\u02dc100 million pairs of m-r pairs from one-on-one IM conversations.", "labels": [], "entities": []}, {"text": "We filter out multi-user and multi-turn conversations since they were difficult to align reliably.", "labels": [], "entities": []}, {"text": "We set aside 10% of the data to compute validation losses for model selection.", "labels": [], "entities": [{"text": "model selection", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7299932241439819}]}, {"text": "The data is completely eyesoff i.e., neither the training nor the validation set is accessible for eyes-on analysis.", "labels": [], "entities": []}, {"text": "Response set: To generate the response set, we filter replies from the m-r pairs with spam, offensive, and English vocabulary filters and clean them of personally identifiable information.", "labels": [], "entities": []}, {"text": "Next, we select top 100k responses based on frequency and then top 30k based on lm-scores.", "labels": [], "entities": []}, {"text": "We pre-compute the lm-scores, lexical-clusters and encodings for the response set and embed them inside the inference graphs as shown in and 2.", "labels": [], "entities": []}, {"text": "Evaluation metrics and set: The model predicts three responses per message for which we compute two metrics: Defects (a response is deemed incorrect) and Duplicates (at least 2 out of 3 responses are semantically similar).", "labels": [], "entities": [{"text": "Duplicates", "start_pos": 154, "end_pos": 164, "type": "METRIC", "confidence": 0.9830867052078247}]}, {"text": "We use crowd sourced human judgments with at least 5 judges per sample.", "labels": [], "entities": []}, {"text": "Judges are asked to provide a binary Yes/No answer on defects and duplicates.", "labels": [], "entities": []}, {"text": "Judge consensus (inter annotator agreement) of 4 and above is considered for metrics, with 3 deemed as no-consensus (around 5%).", "labels": [], "entities": [{"text": "Judge consensus (inter annotator agreement)", "start_pos": 0, "end_pos": 43, "type": "METRIC", "confidence": 0.7809375694819859}]}, {"text": "Since training/validation sets are not accessible for analysis, we created an evaluation set of 2000 messages using crowd sourcing for reporting our metrics.", "labels": [], "entities": []}, {"text": "M-CVAE parameters: We consider three parameters for ablation studies in M-CVAE: size of latent vector z, number of samples sand the response pruning size k for constrained sampling.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The M-CVAE numbers (row 2 onwards) are relative to the base Matching model in row 1.", "labels": [], "entities": []}, {"text": "First, row 2 shows that latent vector size of 256 provides a suitable balance between defects and duplicates, but in general, the size of the latent variable is not a significant factor in performance.", "labels": [], "entities": []}, {"text": "Next, in row 3, we see that the response-pruning size k, is an effective  control to trade-off defects and duplicates.", "labels": [], "entities": []}, {"text": "Thus, constrained sampling not only reduces the latency but also provides quality control required in a production system.", "labels": [], "entities": []}, {"text": "In row 4, we see that more samples lead to better metrics but the improvements are marginal beyond 300 samples.", "labels": [], "entities": []}, {"text": "In all cases, M-CVAE significantly reduces duplicates (by as much as 40%) without any major increase in defects.", "labels": [], "entities": []}, {"text": "We select the model with hyper-parameters [k = 15, z = 256, s = 300] for further analysis.", "labels": [], "entities": []}, {"text": "Diversification with LC: The first two rows of analyzes the impact of LC based deduplication.", "labels": [], "entities": []}, {"text": "LC can significantly reduce the duplicates in the base matching model.", "labels": [], "entities": []}, {"text": "However, M-CVAE (even without LC) reduces the rates by almost 50% as shown in column 4 in row 1.", "labels": [], "entities": []}, {"text": "Using LC as a post processing step after M-CVAE, can give further boosts in diversity (row 2).", "labels": [], "entities": []}, {"text": "Diversification with MMR: also reports the impact of MMR re-ranking.", "labels": [], "entities": []}, {"text": "For Matching+MMR, duplicates can reduce significantly as we increase the \u03b2 parameter, but at the cost of  increased defects.", "labels": [], "entities": [{"text": "Matching+MMR", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.846500813961029}]}, {"text": "With MMR+M-CVAE, further diversification can be achieved, and typically at a lower defect rate.", "labels": [], "entities": []}, {"text": "This shows the advantage of using M-CVAE which conditions the responses on the message and hence has stronger controls on the relevance than MMR.", "labels": [], "entities": []}, {"text": "Comparison with other architectures: We have considered two other architectures for our SR system.", "labels": [], "entities": []}, {"text": "First is a standard S2S with attention () with equivalent parameters for embedding and LSTMs as our base model, and inference using beam search decoding with width 15.", "labels": [], "entities": []}, {"text": "Second, is a feed-forward (instead of an LSTM) based Matching encoder architecture which is equivalent to the one in ().", "labels": [], "entities": []}, {"text": "All models use LC for de-duplication after 15 candidate responses are selected.", "labels": [], "entities": []}, {"text": "validates our architectural preference towards Matching/Bi-LSTM which has a superior performance in terms of defects.", "labels": [], "entities": []}, {"text": "Inference latency: Architecture choices were also driven by latency requirements in our production system.", "labels": [], "entities": []}, {"text": "The results are summarized in for different architectures.", "labels": [], "entities": []}, {"text": "S2S and unconstrained sampling in M-CVAE were unsuitable for production due to their high latencies.", "labels": [], "entities": []}, {"text": "With constrained sampling (including MMR), the latency increases marginally compared to the base model, and allows us to put the model in production.", "labels": [], "entities": [{"text": "latency", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9612553119659424}]}, {"text": "Online experiments: Offline metrics were used principally for selecting the best candidate models for online A/B experiments.", "labels": [], "entities": []}, {"text": "We selected M-CVAE model with parameters [z=256, k=15, s=300] from.", "labels": [], "entities": []}, {"text": "Using our existing production model as the control, and a treatment group consisting of 10% of our IM client users (with: Click rates for the M-CVAE flighted model.", "labels": [], "entities": [{"text": "Click", "start_pos": 122, "end_pos": 127, "type": "METRIC", "confidence": 0.9717352986335754}]}, {"text": "The control is the Matching model in production.", "labels": [], "entities": [{"text": "Matching", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.8703944683074951}]}, {"text": "the same population properties as the control), we conducted an online A/B test for two weeks.", "labels": [], "entities": [{"text": "A/B test", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.8503665179014206}]}, {"text": "shows that the click-rate for M-CVAE compared to the Matching model increased by\u02dc5%by\u02dc5% overall.", "labels": [], "entities": [{"text": "click-rate", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.981947660446167}]}, {"text": "Gains were driven by the increase in the 2nd (10.3%) and 3rd (6.7%) suggested reply positions with virtually no impact in the 1st position.", "labels": [], "entities": []}, {"text": "This correlates with our offline analysis since M-CVAE typically differs from the base model at these two positions.", "labels": [], "entities": []}, {"text": "Intuitively, the three positions point to the head, torso and tail intents of responses 6 . Gains at these positions show that M-CVAE extracts diverse responses without sacrificing the relevance of these tail intents.", "labels": [], "entities": []}, {"text": "Driven by these gains, we have switched our production system in Skype to use M-CVAE for 100% of users.", "labels": [], "entities": []}], "tableCaptions": []}