{"title": [{"text": "Extraction of Message Sequence Charts from Narrative History Text", "labels": [], "entities": [{"text": "Extraction of Message Sequence", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8276567310094833}]}], "abstractContent": [{"text": "In this paper, we advocate the use of Message Sequence Chart (MSC) as a knowledge representation to capture and visualize multi-actor interactions and their temporal ordering.", "labels": [], "entities": []}, {"text": "We propose algorithms to automatically extract an MSC from a history narrative.", "labels": [], "entities": [{"text": "MSC from a history narrative", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.7418808341026306}]}, {"text": "For a given narrative, we first identify verbs which indicate interactions and then use dependency parsing and Semantic Role Labelling based approaches to identify senders (initiating actors) and receivers (other actors involved) for these interaction verbs.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7122286409139633}]}, {"text": "As a final step in MSC extraction, we employ a state-of-the art algorithm to temporally reorder these interactions.", "labels": [], "entities": [{"text": "MSC extraction", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9853267669677734}]}, {"text": "Our evaluation on multiple publicly available narratives shows improvements over four baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Narrative texts, particularly in history, contain rich knowledge about actors and interactions among them along with their temporal and spatial details.", "labels": [], "entities": []}, {"text": "For such texts, it is often useful to extract and visualize these interactions through a set of inter-related timelines, one for each actor, where the timeline of an actor specifies the temporal order of interactions in which that actor has participated.", "labels": [], "entities": []}, {"text": "Message Sequence Chart (MSC) is an intuitive visual notation with rigorous mathematical semantics that can help to precisely represent and analyze) such scenarios., and propose techniques to convert software requirements to MSC.", "labels": [], "entities": [{"text": "Message Sequence Chart (MSC)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6975100139776865}]}, {"text": "Event timeline construction is a related task about inferring the temporal ordering among events, but where events are not necessarily interactions among actors ().", "labels": [], "entities": [{"text": "Event timeline construction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.760866622130076}]}, {"text": "Another related line of research is storyline or plot generation from narrative texts such as news stories or fiction, which uses different narratological output representations (not MSC), such as event sequences or story curves.", "labels": [], "entities": [{"text": "storyline or plot generation from narrative texts such as news stories or fiction", "start_pos": 36, "end_pos": 117, "type": "TASK", "confidence": 0.8405008636988126}]}, {"text": "In this paper, we extract actors and their interactions from the given input history narrative text, and map them to actors and messages in the basic MSC notation.", "labels": [], "entities": []}, {"text": "We generalize the previous work along several dimensions, and propose an unsupervised approach enriched with linguistic knowledge.", "labels": [], "entities": []}, {"text": "MSC extracted from the given history text can be analyzed for consistency, similarity, causality and used for applications such as question-answering.", "labels": [], "entities": [{"text": "consistency", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.9744061231613159}]}, {"text": "For example, from the example in we extract the MSC as shown in, which can be used to answer questions like \"Whom did Napoleon defend the National Convention from?\".", "labels": [], "entities": [{"text": "Napoleon defend the National Convention", "start_pos": 118, "end_pos": 157, "type": "DATASET", "confidence": 0.5310359358787536}]}, {"text": "To the best of our knowledge, this is the first work that uses MSC to represent knowledge about actors and their interactions in narrative history text.", "labels": [], "entities": []}, {"text": "Our approach is general, and can represent interactions among actors in any narrative text (e.g., news, fiction and screenplays).", "labels": [], "entities": []}, {"text": "We propose unsupervised approaches using dependency parsing and Semantic Role Labelling for extracting interactions and corresponding senders/receivers.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8446065783500671}, {"text": "Semantic Role Labelling", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.6426413158575693}]}, {"text": "We use a state-ofthe-art tense based technique ( to temporally order the interactions to create the MSC.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach on history narratives as they are replete with multiple actors, spatiotemporal details and have varied forms of interactions.", "labels": [], "entities": []}, {"text": "We choose public narratives of varying linguistic complexity to cover a spectrum of history: (i) famous personalities: Napoleon (Nap), and Mao Zedong (Mao), (ii) a key event: Battle of Haldighati (BoH), and (iii) a major phenomenon: Fascism (Fas).", "labels": [], "entities": [{"text": "Fascism (Fas)", "start_pos": 233, "end_pos": 246, "type": "DATASET", "confidence": 0.7433045208454132}]}, {"text": "We also use a subset of the Facebook's bAbI QA dataset () which is a text understanding and reasoning benchmark.", "labels": [], "entities": [{"text": "Facebook's bAbI QA dataset", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.8672271847724915}, {"text": "text understanding", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7327153384685516}]}, {"text": "Our bAbI dataset includes 10 instances from the timereasoning subset of the bAbI QA dataset.", "labels": [], "entities": [{"text": "bAbI dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9052528738975525}, {"text": "bAbI QA dataset", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.8976389765739441}]}, {"text": "Each instance consists of two interleaved sets of information: a set of sentences describing an event and its time for e.g. Mary went to the cinema yesterday., and a set of temporal reasoning questions which need to be answered based on the sentences seen till that instant.", "labels": [], "entities": []}, {"text": "We remove the questions from each instance keeping only the event description sentences as input to the approach.", "labels": [], "entities": []}, {"text": "We manually annotated these datasets for independent actor mentions, their aliases (canonical mentions), interaction verbs, complete messages and temporal ordering of the messages.", "labels": [], "entities": []}, {"text": "Number of sentences and messages for the datasets are: Nap (106, 99), Fas (117, 115), BoH (77, 133), Mao (58, 135) and bAbI (118, 118).", "labels": [], "entities": [{"text": "Nap", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8308022618293762}, {"text": "Fas", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.6745840311050415}, {"text": "BoH", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.6881232857704163}, {"text": "bAbI", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.8348405957221985}]}, {"text": "We give highest priority to the message label and hence senders / receivers of a message are deemed to be correct only if the corresponding message label has been identified correctly.", "labels": [], "entities": []}, {"text": "As one of the evaluation measures, we report the F-measure for identifying only the message labels, ignoring the corresponding senders / receivers.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9985902905464172}]}, {"text": "We further evaluate message identification performance of the proposed approaches at two levels: i) complete messages with actor mentions (denoted as L 1 level) and ii) complete messages with canonical mentions of the actors (L 2 level).", "labels": [], "entities": [{"text": "message identification", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7860422730445862}]}, {"text": "As described in Section 3.1, each actor mention has a canonical mention associated with it, which represents a group of corefering actor mentions.", "labels": [], "entities": []}, {"text": "At L 1 level, a predicted message is counted as a true positive if the combination of the predicted sender mention, receiver mention and message label (i.e., the complete message) is present in the gold-standard messages for the same sentence.", "labels": [], "entities": []}, {"text": "False positives and false negatives are computed on similar lines and overall F-measures are computed for identifying complete messages, at the actor mention level.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9973227381706238}]}, {"text": "Similarly, the corresponding Fmeasures at L 2 (canonical mention) level are also computed by considering canonical senders / receivers instead of their mentions.", "labels": [], "entities": [{"text": "Fmeasures", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.7799822092056274}]}, {"text": "We conduct the experiments in two different settings: i) Setting S 1 : using gold-standard information about actor mentions, canonical mentions and interaction verbs ii) Setting S 2 : using predicted actors and interaction verbs.", "labels": [], "entities": []}, {"text": "We use the approach proposed by for predicting actor mentions and identifying canonical mentions; and a simple algorithm for predicting interaction verbs.", "labels": [], "entities": [{"text": "predicting interaction verbs", "start_pos": 125, "end_pos": 153, "type": "TASK", "confidence": 0.8573106726010641}]}, {"text": "For evaluating our temporal ordering approach, we use Kendall's \u03c4 rank correlation coefficient to compare predicted and gold time-lines of a key actor in each dataset (e.g., Mao Zedong in the Mao dataset).", "labels": [], "entities": [{"text": "\u03c4 rank correlation coefficient", "start_pos": 64, "end_pos": 94, "type": "METRIC", "confidence": 0.8106409758329391}, {"text": "Mao dataset", "start_pos": 192, "end_pos": 203, "type": "DATASET", "confidence": 0.8179992437362671}]}, {"text": "As goal of Kof's work) is same as our work on message extraction, we use it as one of the baselines (B-Kof).", "labels": [], "entities": [{"text": "message extraction", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.841806024312973}]}, {"text": "We also use OpenIE () as another baseline (B-OIE).", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 12, "end_pos": 18, "type": "DATASET", "confidence": 0.8743266463279724}, {"text": "B-OIE", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.9795947670936584}]}, {"text": "To avoid unnecessarily penalizing B-OIE, we consider only those extractions where relations fit our definition of interaction verbs and arguments fit our definition of actors.", "labels": [], "entities": []}, {"text": "We compare our temporal ordering approach with the default text order based baseline (Text-Order).", "labels": [], "entities": []}, {"text": "shows comparative performance of the proposed approaches for message extraction and temporal ordering.", "labels": [], "entities": [{"text": "message extraction", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.841187983751297}, {"text": "temporal ordering", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7285413593053818}]}], "tableCaptions": [{"text": " Table 2: F1-measures for following approaches-B-OIE: OpenIE baseline, B-Kof:", "labels": [], "entities": [{"text": "F1-measures", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9986953139305115}, {"text": "OpenIE baseline", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.895555168390274}]}]}