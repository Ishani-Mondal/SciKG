{"title": [{"text": "Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions", "labels": [], "entities": [{"text": "Distant Supervision Relation Extraction", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.9215601980686188}]}], "abstractContent": [{"text": "This paper presents a neural relation extraction method to deal with the noisy training data generated by distant supervision.", "labels": [], "entities": [{"text": "neural relation extraction", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6390198965867361}]}, {"text": "Previous studies mainly focus on sentence-level de-noising by designing neural networks with intra-bag attentions.", "labels": [], "entities": []}, {"text": "In this paper, both intra-bag and inter-bag attentions are considered in order to deal with the noise at sentence-level and bag-level respectively.", "labels": [], "entities": []}, {"text": "First, relation-aware bag representations are calculated by weighting sentence embeddings using intra-bag attentions.", "labels": [], "entities": []}, {"text": "Here, each possible relation is utilized as the query for attention calculation instead of only using the target relation in conventional methods.", "labels": [], "entities": [{"text": "attention calculation", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.8664374947547913}]}, {"text": "Furthermore, the representation of a group of bags in the training set which share the same relation label is calculated by weighting bag representations using a similarity-based inter-bag attention module.", "labels": [], "entities": []}, {"text": "Finally, a bag group is utilized as a training sample when building our relation extrac-tor.", "labels": [], "entities": []}, {"text": "Experimental results on the New York Times dataset demonstrate the effectiveness of our proposed intra-bag and inter-bag attention modules.", "labels": [], "entities": [{"text": "New York Times dataset", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.7396270185709}]}, {"text": "Our method also achieves better relation extraction accuracy than state-of-the-art methods on this dataset 1 .", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8135859370231628}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9669701457023621}]}], "introductionContent": [{"text": "Relation Extraction is a fundamental task in natural language processing (NLP), which aims to extract semantic relations between entities.", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9421918392181396}, {"text": "natural language processing (NLP)", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.8057508369286855}]}, {"text": "For example, sentence \"[Barack Obama] e1 was born in e2 \" expresses the relation BornIn between entity pair Barack Obama and Hawaii.", "labels": [], "entities": []}, {"text": "Conventional relation extraction methods, such as (), adopted supervised training and suffered from the lack of The code is available at https://github.com/ZhixiuYe/ Intra-Bag-and-Inter-Bag-Attentions.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.76108717918396}]}, {"text": "Kyle Busch , a Las Vegas resident who ran second to Johnson last year, finished third, followed by Kasey Kahne, Jeff Gordon and mark martin .", "labels": [], "entities": []}], "datasetContent": [{"text": "The New York Times (NYT) dataset was adopted in our experiments.", "labels": [], "entities": [{"text": "The New York Times (NYT) dataset", "start_pos": 0, "end_pos": 32, "type": "DATASET", "confidence": 0.7170088514685631}]}, {"text": "This dataset was first released by ( and has been widely used by previous research on distant supervision relation extraction (.", "labels": [], "entities": [{"text": "distant supervision relation extraction", "start_pos": 86, "end_pos": 125, "type": "TASK", "confidence": 0.6121618449687958}]}, {"text": "This dataset was generated by aligning Freebase with the New York Times (NYT) corpus automatically.", "labels": [], "entities": [{"text": "Freebase with the New York Times (NYT) corpus", "start_pos": 39, "end_pos": 84, "type": "DATASET", "confidence": 0.7614501565694809}]}, {"text": "There were 52 actual relations and a special relation N A which indicated there was no relation between two entities.", "labels": [], "entities": []}, {"text": "Following previous studies, we evaluated our models on the held-out test set of the NYT dataset.", "labels": [], "entities": [{"text": "NYT dataset", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.9569675326347351}]}, {"text": "Precisionrecall (PR) curves, area under curve (AUC) values and Precision@N (P@N) values () were adopted as evaluation metrics in our experiments.", "labels": [], "entities": [{"text": "Precisionrecall (PR) curves", "start_pos": 0, "end_pos": 27, "type": "METRIC", "confidence": 0.8706750512123108}, {"text": "area under curve (AUC) values", "start_pos": 29, "end_pos": 58, "type": "METRIC", "confidence": 0.8502016918999808}, {"text": "Precision@N (P@N) values", "start_pos": 63, "end_pos": 87, "type": "METRIC", "confidence": 0.8838028444184197}]}, {"text": "All of the numerical results given by our experiments were the mean values of 10 repetitive trainings, and the PR curves were randomly selected from the repetitions because there was no significant visual difference among them.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Hyper-parameters of the models built in our  experiments.", "labels": [], "entities": [{"text": "Hyper-parameters", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9818759560585022}]}, {"text": " Table 3: AUC values of different models.", "labels": [], "entities": [{"text": "AUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8989437818527222}]}, {"text": " Table 4: P@N values of the entity pairs with different number of test sentences.", "labels": [], "entities": []}, {"text": " Table 6: A test set example of relation /location/location/contains from the NYT corpus.", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 78, "end_pos": 88, "type": "DATASET", "confidence": 0.9673584997653961}]}, {"text": " Table 7: The distributions of inter-bag attention  weights for the bags with different number of sen- tences.", "labels": [], "entities": []}, {"text": " Table  7. From this table, we can see that the bag with", "labels": [], "entities": []}]}