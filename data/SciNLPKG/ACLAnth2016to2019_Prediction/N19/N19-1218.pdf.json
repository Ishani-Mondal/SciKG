{"title": [{"text": "Harry Potter and the Action Prediction Challenge from Natural Language", "labels": [], "entities": [{"text": "Action Prediction Challenge from Natural Language", "start_pos": 21, "end_pos": 70, "type": "TASK", "confidence": 0.8226724366346995}]}], "abstractContent": [{"text": "We explore the challenge of action prediction from textual descriptions of scenes, a testbed to approximate whether text inference can be used to predict upcoming actions.", "labels": [], "entities": [{"text": "action prediction", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7208081781864166}]}, {"text": "As a case of study, we consider the world of the Harry Potter fantasy novels and inferring what spell will be cast next given a fragment of a story.", "labels": [], "entities": []}, {"text": "Spells act as keywords that abstract actions (e.g. 'Alohomora' to open a door) and denote a response to the environment.", "labels": [], "entities": []}, {"text": "This idea is used to automatically build HPAC, a corpus containing 82 836 samples and 85 actions.", "labels": [], "entities": []}, {"text": "We then evaluate different baselines.", "labels": [], "entities": []}, {"text": "Among the tested models, an LSTM-based approach obtains the best performance for frequent actions and large scene descriptions, but approaches such as logistic regression behave well on infrequent actions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language processing (NLP) has achieved significant advances in reading comprehension tasks.", "labels": [], "entities": [{"text": "Natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7618406961361567}]}, {"text": "These are partially due to embedding methods ( and neural networks, but also to the availability of new resources and challenges.", "labels": [], "entities": []}, {"text": "For instance, in cloze-form tasks (, the goal is to predict the missing word given a short context.", "labels": [], "entities": []}, {"text": "presented baBI, a set of proxy tasks for reading comprenhension.", "labels": [], "entities": []}, {"text": "In the SQuAD corpus (, the aim is to answer questions given a Wikipedia passage.", "labels": [], "entities": [{"text": "SQuAD corpus", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.7150702774524689}]}, {"text": "introduce NarrativeQA, where answering the questions requires to process entire stories.", "labels": [], "entities": []}, {"text": "Ina related line, use fictional crime scene investigation data, from the CSI series, to define a task where the models try to answer the question: 'who committed the crime?'.", "labels": [], "entities": []}, {"text": "In an alternative line of work, script induction ( has been also a useful approach to evaluate inference and semantic capabilities of NLP systems.", "labels": [], "entities": [{"text": "script induction", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.8174415826797485}]}, {"text": "Here, a model processes a document to infer new sequences that reflect events that are statistically probable (e.g. go to a restaurant, be seated, check the menu, . .", "labels": [], "entities": []}, {"text": "). For example, introduce narrative event chains, a representation of structured knowledge of a set of events occurring around a protagonist.", "labels": [], "entities": []}, {"text": "They then propose a method to learn statistical scripts, and also introduce two different evaluation strategies.", "labels": [], "entities": []}, {"text": "With a related aim, propose a multi-event representation of statistical scripts to be able to consider multiple entities.", "labels": [], "entities": []}, {"text": "These same authors have also studied the abilities of recurrent neural networks for learning scripts, generating upcoming events given a raw sequence of tokens, using BLEU) for evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 167, "end_pos": 171, "type": "METRIC", "confidence": 0.9944804906845093}]}, {"text": "This paper explores instead anew task: action prediction from natural language descriptions of scenes.", "labels": [], "entities": [{"text": "action prediction from natural language descriptions of scenes", "start_pos": 39, "end_pos": 101, "type": "TASK", "confidence": 0.8026306480169296}]}, {"text": "The challenge is addressed as follows: given a natural language input sequence describing the scene, such as apiece of a story coming from a transcript, the goal is to infer which action is most likely to happen next.", "labels": [], "entities": []}, {"text": "Contribution We introduce a fictional-domain English corpus set in the world of Harry Potter novels.", "labels": [], "entities": []}, {"text": "The domain is motivated by the existence of a variety of spells in these literary books, associated with keywords that can be seen as unambiguous markers for actions that potentially relate to the previous context.", "labels": [], "entities": []}, {"text": "This is used to automatically create a natural language corpus coming from hundreds of users, with different styles, interests and writing skills.", "labels": [], "entities": []}, {"text": "We then train a number of standard baselines to predict upcoming actions, a task that requires to be aware of the context.", "labels": [], "entities": []}, {"text": "In particular, we test a number of generic models, from a simple logistic regression to neural models.", "labels": [], "entities": []}, {"text": "Experiments shed some light about their strengths and weaknesses and how these are related to the frequency of each action, the existence of other semantically related actions and the length of the input story.", "labels": [], "entities": []}], "datasetContent": [{"text": "Setup All MLP \u03b8 's have 128 input neurons and 1 hidden layer.", "labels": [], "entities": []}, {"text": "We trained up to 15 epochs using mini-batches (size=16), Adam (lr=0.001) ( and early stopping.", "labels": [], "entities": []}, {"text": "shows the macro and weighted F-scores for the models considering different snippet sizes.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9134511351585388}]}, {"text": "To diminish the impact of random seeds and local minima in neural networks, results are averaged across 5 runs.", "labels": [], "entities": []}, {"text": "8 'Base' is a majority-class model that maps everything to 'Avada Kedavra', the most common action in the training set.", "labels": [], "entities": []}, {"text": "This helps test whether the models predict above chance performance.", "labels": [], "entities": []}, {"text": "When using short snippets (size=32), disparate models such as our MLR, MLP and LSTMs achieve a similar performance.", "labels": [], "entities": []}, {"text": "As the snippet size is increased, the LSTM-based approach shows a clear improvement on the weighted scores 9 , something that happens only marginally for the rest.", "labels": [], "entities": []}, {"text": "However, from  To shed some light, shows their performance according to a ranking metric, recall at k.", "labels": [], "entities": [{"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9986273050308228}]}, {"text": "The results show that the LSTM-based approach is the top performing model, but the MLP obtains just slightly worse results.", "labels": [], "entities": [{"text": "MLP", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.48252037167549133}]}, {"text": "Recall at 1 is in both cases low, which suggests that the task is indeed complex and that using just LSTMs is not enough.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9964739680290222}]}, {"text": "It is also possible to observe that even if the models have difficulties to correctly predict the action as a first option, they develop certain sense of the scene and consider the right one among their top choices.", "labels": [], "entities": []}, {"text": "delves into this by splitting the performance of the model into infrequent and frequent actions (above the average, i.e. those that occur more than 98 times in the training set, a total of 20 actions).", "labels": [], "entities": []}, {"text": "There is a clear gap between the performance on these two groups of actions, with a \u223c50 points difference in recall at 5.", "labels": [], "entities": [{"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9994739890098572}]}, {"text": "Also, a simple logistic regression performs similar to the LSTM on the infrequent actions.", "labels": [], "entities": []}, {"text": "Error analysis 10 Some of the misclassifications made by the LSTM approach were semantically related actions and counter-actions.", "labels": [], "entities": []}, {"text": "For example, 'Colloportus' (to close a door) was never predicted.", "labels": [], "entities": [{"text": "'Colloportus' (to close a door)", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.5825676955282688}]}, {"text": "The most common mis-classification (14 out of 41) was 'Alohomora' (to unlock a door), which was 5 times more frequent in the training corpus.", "labels": [], "entities": []}, {"text": "Similarly, 'Nox' (to extinguish the light from a wand) was correctly predicted 6 times, meanwhile 36 mis-classifications corre-spond to 'Lumos' (to light a place using a wand), which was 6 times more frequent in the training set.", "labels": [], "entities": []}, {"text": "Other less frequent spells that denote vision and guidance actions, such as 'Point me' (the wand acts a a compass pointing North) and 'Homenum revelio' (to revel a human presence) were also mainly misclassified as 'Lumos'.", "labels": [], "entities": []}, {"text": "This is an indicator that the LSTM approach has difficulties to disambiguate among semantically related actions, especially if their occurrence was unbalanced in the training set.", "labels": [], "entities": []}, {"text": "This issue is inline with the tendency observed for recall at k.", "labels": [], "entities": [{"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.997426450252533}]}, {"text": "Spells intended for much more specific purposes, according to the books, obtained a performance significantly higher than the average, e.g. Fscore('Riddikulus')=63.54, F-score('Expecto Patronum')=55.49 and F-score('Obliviate')=47.45.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.9991703033447266}, {"text": "F-score", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9808090925216675}, {"text": "F-score", "start_pos": 206, "end_pos": 213, "type": "METRIC", "confidence": 0.993907630443573}]}, {"text": "As said before, the model is significantly biased towards frequent actions.", "labels": [], "entities": []}, {"text": "For 79 out of 84 gold actions in the test set, we found that the samples tagged with such actions were mainly classified into one of the top 20 most frequent actions.", "labels": [], "entities": []}, {"text": "approach obtained a similar performance, but the lower macro F-score by the LSTM could bean indicator that humans can distinguish within a wider spectrum of actions.", "labels": [], "entities": [{"text": "F-score", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9539753794670105}]}, {"text": "As aside note, super-human performance it is not strange in other NLP tasks, such as sentiment analysis).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.9714154005050659}]}], "tableCaptions": [{"text": " Table 1: Examples from the Harry Potter books showing how spells map to reactions to the environment.", "labels": [], "entities": []}, {"text": " Table 2: Corpus statistics: s is the length of the snippet.", "labels": [], "entities": []}, {"text": " Table 3: Macro and weighted F-scores over 5 runs.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9240520000457764}]}, {"text": " Table 4: Averaged recall at k over 5 runs.", "labels": [], "entities": [{"text": "Averaged", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9964064955711365}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9435696601867676}]}, {"text": " Table 5: Performance on frequent (those that occur  above the average) and infrequent actions.", "labels": [], "entities": []}]}