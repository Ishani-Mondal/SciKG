{"title": [{"text": "Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce a novel method for multilingual transfer that utilizes deep contextual embeddings, pretrained in an unsupervised fashion.", "labels": [], "entities": [{"text": "multilingual transfer", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7608414590358734}]}, {"text": "While contextual embeddings have been shown to yield richer representations of meaning compared to their static counterparts , aligning them poses a challenge due to their dynamic nature.", "labels": [], "entities": []}, {"text": "To this end, we construct context-independent variants of the original monolingual spaces and utilize their mapping to derive an alignment for the context-dependent spaces.", "labels": [], "entities": []}, {"text": "This mapping readily supports processing of a target language, improving transfer by context-aware embeddings.", "labels": [], "entities": []}, {"text": "Our experimental results demonstrate the effectiveness of this approach for zero-shot and few-shot learning of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.8142172396183014}]}, {"text": "Specifically, our method consistently outper-forms the previous state-of-the-art on 6 tested languages, yielding an improvement of 6.8 LAS points on average.", "labels": [], "entities": [{"text": "LAS", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.9903535842895508}]}], "introductionContent": [{"text": "Multilingual embedding spaces have been demonstrated to be a promising means for enabling crosslingual transfer in many natural language processing tasks (e.g.;).", "labels": [], "entities": [{"text": "crosslingual transfer", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.7775214314460754}]}, {"text": "Similar to how universal part-ofspeech tags enabled parsing transfer across languages (, multilingual word embeddings further improve transfer capacity by enriching models with lexical information.", "labels": [], "entities": [{"text": "parsing transfer across languages", "start_pos": 52, "end_pos": 85, "type": "TASK", "confidence": 0.9237123876810074}]}, {"text": "Since this lexical representation is learned in an unsupervised fashion and thus can leverage large amounts of raw data, it can capture a more nuanced representation of meaning than unlexicalized transfer.", "labels": [], "entities": []}, {"text": "Naturally, this enrichment is trans-lated into improved transfer accuracy, especially in low-resource scenarios (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9651462435722351}]}, {"text": "In this paper, we are moving further along this line and exploring the use of contextual word embeddings for multilingual transfer.", "labels": [], "entities": [{"text": "multilingual transfer", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7487325370311737}]}, {"text": "By dynamically linking words to their various contexts, these embeddings provide a richer semantic and syntactic representation than traditional context-independent word embeddings.", "labels": [], "entities": []}, {"text": "A straightforward way to utilize this richer representation is to directly apply existing transfer algorithms on the contextual embeddings instead of their static counterparts.", "labels": [], "entities": []}, {"text": "In this case, however, each token pair is represented by many different vectors corresponding to its specific context.", "labels": [], "entities": []}, {"text": "Even when supervision is available in the form of a dictionary, it is still unclear how to utilize this information for multiple contextual embeddings that correspond to a word translation pair.", "labels": [], "entities": [{"text": "word translation", "start_pos": 172, "end_pos": 188, "type": "TASK", "confidence": 0.7025392800569534}]}, {"text": "In this paper, we propose a simple but effective mechanism for constructing a multilingual space of contextual embeddings.", "labels": [], "entities": []}, {"text": "Instead of learning the alignment in the original, complex contextual space, we drive the mapping process using context-independent embedding anchors.", "labels": [], "entities": []}, {"text": "We obtain these anchors by factorizing the contextual embedding space into context-independent and context-dependent parts.", "labels": [], "entities": []}, {"text": "Operating at the anchor level not only compresses the space, but also enables us to utilize a word-level bilingual dictionary as a source of supervision, if available.", "labels": [], "entities": []}, {"text": "Once the anchor-level alignment is learned, it can be readily applied to map the original spaces with contextual embeddings.", "labels": [], "entities": []}, {"text": "Clearly, the value of word embeddings depends on their quality, which is determined by the amount of raw data available for their training.", "labels": [], "entities": []}, {"text": "We are interested in expanding the above approach to the truly low-resource scenario, where a language not only lacks annotations, but also has limited amounts of raw data.", "labels": [], "entities": []}, {"text": "In this case, we can also rely on a data rich language to stabilize monolingual embeddings of the resource-limited language.", "labels": [], "entities": []}, {"text": "As above, contextindependent anchors are informing this process.", "labels": [], "entities": []}, {"text": "Specifically, we introduce an alignment component to the loss function of the language model, pushing the anchors to be closer in the joint space.", "labels": [], "entities": []}, {"text": "While this augmentation is performed on the static anchors, the benefit extends to the contextual embeddings space in which we operate.", "labels": [], "entities": []}, {"text": "We evaluate our aligned contextual embeddings on the task of zero-shot cross-lingual dependency parsing.", "labels": [], "entities": [{"text": "cross-lingual dependency parsing", "start_pos": 71, "end_pos": 103, "type": "TASK", "confidence": 0.5932530661424001}]}, {"text": "Our model consistently outperforms previous transfer methods, yielding absolute improvement of 6.8 LAS points over the prior stateof-the-art ().", "labels": [], "entities": [{"text": "LAS", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9938628673553467}]}, {"text": "We also perform comprehensive studies of simplified variants of our model.", "labels": [], "entities": []}, {"text": "Even without POS tag labeling or a dictionary, our model performs on par with context-independent models that douse such information.", "labels": [], "entities": [{"text": "POS tag labeling", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.6988617380460104}]}, {"text": "Our results also demonstrate the benefits of this approach for few-shot learning, i.e. processing languages with limited data.", "labels": [], "entities": []}, {"text": "Specifically, on the Kazakh tree-bank from the recent CoNLL 2018 shared task with only 38 trees for training, the model yields 5 LAS points gain over the top result ().", "labels": [], "entities": [{"text": "CoNLL 2018 shared task", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.7484098672866821}, {"text": "LAS", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.9960176348686218}]}], "datasetContent": [{"text": "Contextual Embeddings We use the ELMo model () with its default parameters to generate embeddings of dimension 1024 for all languages.", "labels": [], "entities": []}, {"text": "For each language, training data comprises Wikipedia dumps 5 that were tokenized using UDpipe.", "labels": [], "entities": [{"text": "UDpipe", "start_pos": 87, "end_pos": 93, "type": "DATASET", "confidence": 0.9428468942642212}]}, {"text": "We randomly shuffle the sentences and, following the setting of ELMO, use 95% of them for training and 5% for evaluation.", "labels": [], "entities": [{"text": "ELMO", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.6085754036903381}]}, {"text": "Alignment We utilize the MUSE framework 6 () and the dictionary tables provided by them.", "labels": [], "entities": [{"text": "MUSE framework 6", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.8698920210202535}]}, {"text": "The \u00af e i (anchor) vectors for the alignment are generated by computing the average of representations on the evaluation set (except for the limited unlabeled data case).", "labels": [], "entities": []}, {"text": "To evaluate our alignment, we use the anchors to produce word translations.", "labels": [], "entities": [{"text": "word translations", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7036610841751099}]}, {"text": "For all experiments we use the 50k most common words in each language.", "labels": [], "entities": []}, {"text": "Dependency Parsing We used the biaffine parser implemented in AllenNLP (, refactored to handle our modifications as described in Section 4.", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7648904323577881}, {"text": "AllenNLP", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9783141016960144}]}, {"text": "The parser is trained on trees from a single or multiple languages, as described in each setting (Section 6).", "labels": [], "entities": []}, {"text": "For the multiple case, we randomly alternate between the available languages, i.e. at each iteration we randomly choose one language and sample a corresponding batch.", "labels": [], "entities": []}, {"text": "Dropout () is applied on ELMo representations, Bi-LSTM representations and outputs of MLP layers.", "labels": [], "entities": []}, {"text": "We also apply early stopping, where validation accuracy is measured as average LAS score on the development set across all training languages.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7721557021141052}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9473123550415039}, {"text": "LAS score", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9742732346057892}]}, {"text": "The parser hyperparameters are the same as except we reduce the POS tag embedding size from 100 to 50 and increase the head/dependent MLP dimension from 400 to 500.", "labels": [], "entities": [{"text": "head/dependent MLP dimension", "start_pos": 119, "end_pos": 147, "type": "METRIC", "confidence": 0.6756640076637268}]}, {"text": "All hyperparameter values used are listed in App.", "labels": [], "entities": [{"text": "App", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.9545947313308716}]}, {"text": "C. From experiments on the English tree-bank, we found that using the outputs of the first LSTM layer is as good as learning a combination.", "labels": [], "entities": [{"text": "English tree-bank", "start_pos": 27, "end_pos": 44, "type": "DATASET", "confidence": 0.8984598815441132}]}, {"text": "agrees with, showing that lower layers capture more syntactic information.", "labels": [], "entities": []}, {"text": "Therefore, we fix the weights over ELMo layers to, i.e. using only representations from the first LSTM layer.", "labels": [], "entities": []}, {"text": "For a fair comparison, we use the same setting as used by previous models for each scenario.", "labels": [], "entities": []}, {"text": "Our main model (which we refer to as OURS) is using a SUPERVISED ANCHORED ALIGNMENT (Section 3.3) to align the multilingual pretrained ELMo embeddings which are used by the parser.", "labels": [], "entities": [{"text": "OURS", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.918428897857666}, {"text": "ANCHORED ALIGNMENT", "start_pos": 65, "end_pos": 83, "type": "METRIC", "confidence": 0.6921374797821045}]}, {"text": "We compare against several variants of our model: \u2022 ALIGNED FASTTEXT: instead of ELMo, we use FASTTEXT pretrained embeddings (), aligned to English using MUSE.", "labels": [], "entities": [{"text": "ALIGNED", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9895089864730835}, {"text": "FASTTEXT", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.4589989483356476}, {"text": "ELMo", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.867222011089325}]}, {"text": "\u2022 ALIGNED \u00af e: instead of contextualized embeddings, we use the anchors themselves as fixed embeddings, aligned to English.", "labels": [], "entities": [{"text": "ALIGNED", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9932258725166321}]}, {"text": "\u2022 NO DICTIONARY: we assume the absence of a dictionary and use UNSUPERVISED AN-CHORED ALIGNMENT.", "labels": [], "entities": [{"text": "NO DICTIONARY", "start_pos": 2, "end_pos": 15, "type": "METRIC", "confidence": 0.8358795046806335}, {"text": "UNSUPERVISED AN-CHORED ALIGNMENT", "start_pos": 63, "end_pos": 95, "type": "METRIC", "confidence": 0.7868052919705709}]}, {"text": "\u2022 NO POS: no use of part of speech tags.", "labels": [], "entities": [{"text": "NO", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9875051975250244}, {"text": "POS", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.6625102162361145}]}], "tableCaptions": [{"text": " Table 2: Word translation to English precision @5 using CSLS (Conneau et al., 2018a) with a dictionary (su- pervised) and without (unsupervised) for German (DE), Spanish (ES), French (FR), Italian (IT), Portuguese (PT)  and Swedish (SV). Each of the unsupervised results is followed by a line with the results post the anchor-based  refinement steps.  * stands for 'Failed to converge'.", "labels": [], "entities": [{"text": "Word translation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7509006857872009}, {"text": "Failed", "start_pos": 367, "end_pos": 373, "type": "METRIC", "confidence": 0.9646705389022827}]}, {"text": " Table 3: Zero-shot cross lingual LAS scores compared to previous methods, for German (DE), Spanish (ES), French  (", "labels": [], "entities": []}, {"text": " Table 4: Zero-shot, single-source results for the Spanish limited unlabeled data experiments. The parsing results  are UAS/LAS scores, the perplexity is of the ELMo model, and the alignment scores are precision@5 on the  held-out set, based on CSLS. All embeddings were aligned to English using supervised anchored alignment.", "labels": [], "entities": [{"text": "Spanish limited unlabeled data experiments", "start_pos": 51, "end_pos": 93, "type": "DATASET", "confidence": 0.6189947724342346}, {"text": "UAS/LAS scores", "start_pos": 120, "end_pos": 134, "type": "METRIC", "confidence": 0.5486655533313751}, {"text": "ELMo", "start_pos": 161, "end_pos": 165, "type": "METRIC", "confidence": 0.8380475044250488}, {"text": "precision", "start_pos": 202, "end_pos": 211, "type": "METRIC", "confidence": 0.992053747177124}]}, {"text": " Table 5: Results for the Kazakh dataset from CoNLL  2018 Shared Task on Multilingual Parsing, compared  to the two leading models w.r.t. this treebank.", "labels": [], "entities": [{"text": "Kazakh dataset from CoNLL  2018 Shared Task", "start_pos": 26, "end_pos": 69, "type": "DATASET", "confidence": 0.7811734335763114}, {"text": "Multilingual Parsing", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.6369273066520691}]}, {"text": " Table 6: Per ELMo layer word translation to English precision @1 / @5 using CSLS (Conneau et al., 2018a)  with a dictionary (supervised) for German (DE), Spanish (ES), French (FR), Italian (IT), Portuguese (PT) and  Swedish (SV). Layer 0 representations are the result of the character-level word embeddings (which are context  independent). Layer 1 and 2 alignments are based on anchors from the first and second LSTM layer output  respectively.", "labels": [], "entities": [{"text": "ELMo layer word translation", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.469891756772995}]}, {"text": " Table 7: Zero-shot cross lingual results compared to previous methods, measured in UAS. Aligned fastText and \u00af  e  context-independent models are also presented as baselines. The bottom three rows are models that don't use POS  tags at all and/or use an unsupervised anchored alignment.  Note that Ammar et al. (2016) did not publish UAS results.", "labels": [], "entities": [{"text": "UAS", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.6313489079475403}, {"text": "UAS", "start_pos": 335, "end_pos": 338, "type": "DATASET", "confidence": 0.657076358795166}]}, {"text": " Table 8: Hyper-parameters used in parsing experi- ments, shared across different settings.", "labels": [], "entities": [{"text": "parsing experi- ments", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.8356674611568451}]}]}