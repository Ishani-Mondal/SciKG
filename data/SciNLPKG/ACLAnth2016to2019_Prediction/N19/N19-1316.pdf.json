{"title": [], "abstractContent": [{"text": "The uncertainty measurement of classifiers' predictions is especially important in applications such as medical diagnoses that need to ensure limited human resources can focus on the most uncertain predictions returned by machine learning models.", "labels": [], "entities": []}, {"text": "However, few existing uncertainty models attempt to improve overall prediction accuracy where human resources are involved in the text classification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.895051121711731}, {"text": "text classification task", "start_pos": 130, "end_pos": 154, "type": "TASK", "confidence": 0.8565434018770853}]}, {"text": "In this paper, we propose a novel neural-network-based model that applies anew dropout-entropy method for uncertainty measurement.", "labels": [], "entities": []}, {"text": "We also design a metric learning method on feature representations, which can boost the performance of dropout-based uncertainty methods with smaller prediction variance in accurate prediction trials.", "labels": [], "entities": []}, {"text": "Extensive experiments on real-world data sets demonstrate that our method can achieve a considerable improvement in overall prediction accuracy compared to existing approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.8998462557792664}]}, {"text": "In particular, our model improved the accuracy from 0.78 to 0.92 when 30% of the most uncertain predictions were handed over to human experts in \"20NewsGroup\" data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9997203946113586}, {"text": "20NewsGroup\" data", "start_pos": 146, "end_pos": 163, "type": "DATASET", "confidence": 0.8757185339927673}]}], "introductionContent": [{"text": "Machine learning algorithms are gradually taking over from the human operators in tasks such as machine translation (), optical character recognition (, and face recognition (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.8166898488998413}, {"text": "optical character recognition", "start_pos": 120, "end_pos": 149, "type": "TASK", "confidence": 0.6827751795450846}, {"text": "face recognition", "start_pos": 157, "end_pos": 173, "type": "TASK", "confidence": 0.8888474404811859}]}, {"text": "However, some real-world applications require higher accuracy than the results achieved by state-of-the-art algorithms, which makes it difficult to directly apply these algorithms in certain scenarios.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9964479207992554}]}, {"text": "For example, a medical diagnosis system (van der) is expected to have a very high accuracy to support correct decisionmaking for medical practitioners.", "labels": [], "entities": [{"text": "medical diagnosis system (van der)", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.7894066572189331}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9989781379699707}]}, {"text": "Although domain experts can achieve a high performance in these challenging tasks, it is not always feasible to rely on limited and expensive human input for large-scale data sets.", "labels": [], "entities": []}, {"text": "Therefore, if we have a model with 70% prediction accuracy, it is intuitive to ask what percentage of the data should be handed to domain experts to achieve an overall accuracy rate above 90%?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9510775804519653}, {"text": "accuracy rate", "start_pos": 168, "end_pos": 181, "type": "METRIC", "confidence": 0.982886791229248}]}, {"text": "To maximize the value of limited human resources while achieving desirable results, modeling uncertainty accurately is extremely important to ensure that domain experts can focus on the most uncertain results returned by machine learning models.", "labels": [], "entities": []}, {"text": "Most existing uncertainty models are based on Bayesian models, which are not only timeconsuming but also unable to handle large-scale data sets.", "labels": [], "entities": []}, {"text": "Deep Neural networks (DNNs) have attracted increasing attention in recent years and have been reported to achieve state-of-the-art performance in various machine learning tasks).", "labels": [], "entities": []}, {"text": "However, unlike probabilistic models, DNNs are still at the early development stage in regards to providing the model uncertainty in their predictions.", "labels": [], "entities": []}, {"text": "For those seeking to address the prediction uncertainty in DNNs, it is common to suffer from the following issues on the text classification task.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 121, "end_pos": 145, "type": "TASK", "confidence": 0.857485850652059}]}, {"text": "Firstly, few researchers have sought to improve overall prediction performance when only limited human resources are available.", "labels": [], "entities": []}, {"text": "Different from existing methods which focus on the value of uncertainty, this problem needs to get domain experts involved in emphasis on the order of the uncertain predictions.", "labels": [], "entities": []}, {"text": "For example, the importance of distance between feature representations is neglected by the majority of existing models, but actually this is crucial for improving the order of uncertain predictions, especially during the pre-training of embedding vectors.", "labels": [], "entities": []}, {"text": "Moreover, the methods proposed for continuous feature space cannot be applied to discrete text data.", "labels": [], "entities": []}, {"text": "For example, adversarial train-ing is used in some uncertainty models.", "labels": [], "entities": []}, {"text": "However, due to its dependence on gradient-based methods to generate adversarial examples, the method is not applicable to discrete text data.", "labels": [], "entities": []}, {"text": "In order to simultaneously address all these problems in existing methods, the work presented in this paper adopts a DNN-based approach that incorporates a novel dropout-entropy uncertainty measurement method along with metric learning in the feature representation to handle the uncertainty problem in the document classification task.", "labels": [], "entities": [{"text": "document classification task", "start_pos": 307, "end_pos": 335, "type": "TASK", "confidence": 0.8279669682184855}]}, {"text": "The study's main contributions can be summarized as follows: \u2022 A novel DNN-based text classification model is proposed to achieve higher model accuracy with limited human input.", "labels": [], "entities": [{"text": "DNN-based text classification", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.6433221797148386}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9930324554443359}]}, {"text": "In this new approach, a reliable uncertainty model learns to identify the accurate predictions with smaller estimated uncertainty.", "labels": [], "entities": []}, {"text": "\u2022 Metric learning in feature representation is designed to boost the performance of the dropout-based uncertainty methods in the text classification task.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 129, "end_pos": 153, "type": "TASK", "confidence": 0.8664876619974772}]}, {"text": "Specifically, the shortened intra-class distance and enlarged inter-class distance can reduce the prediction variance and increase the confidence for the accurate predictions.", "labels": [], "entities": []}, {"text": "\u2022 A new dropout-entropy method based on the Bayesian approximation property of Dropout in DNNs is presented.", "labels": [], "entities": []}, {"text": "Specifically, we measure the model uncertainty in terms of the information entropy of multiple dropout-based evaluations combined with the de-noising mask operations.", "labels": [], "entities": []}, {"text": "\u2022 Extensive experiments on real-world data sets demonstrate that the effectiveness of our proposed approach consistently outperforms existing methods.", "labels": [], "entities": []}, {"text": "In particular, the macro-F1 score can be increased from 0.78 to 0.92 by assigning 25% of the labeling work to human experts in a 20-class text classification task.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 138, "end_pos": 162, "type": "TASK", "confidence": 0.7541082998116811}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work, and Section 3 provides a detailed description of our proposed model.", "labels": [], "entities": []}, {"text": "The experiments on multiple real-world data sets are presented in Section 4.", "labels": [], "entities": []}, {"text": "The paper concludes with a summary of the research in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, the performance of the proposed model uncertainty approach is evaluated on multiple real-world document classification data sets.", "labels": [], "entities": []}, {"text": "After an introduction of the experiment settings in Section 4.1, we compare the performance achieved by the proposed method against those of existing state-of-the-art methods, along with an analysis of the parameter settings and metric learning in Section 4.2.", "labels": [], "entities": []}, {"text": "Due to space limitation, the detailed experiment results on different sequence models can be accessed in the full version here 1 . The source code can be downloaded here 2 .  In our experiments, all word vectors are initialized by pre-trained Glove ( word vectors, by default.", "labels": [], "entities": []}, {"text": "The word embedding vectors are pre-trained in Wikipedia 2014 with a word vector dimension of 200.", "labels": [], "entities": [{"text": "Wikipedia 2014", "start_pos": 46, "end_pos": 60, "type": "DATASET", "confidence": 0.9338313937187195}]}, {"text": "We trained all the DNN-based models with a batch size of 32 samples with a momentum of 0.9 and an initial learning rate of 0.001 using the Adam () optimization algorithm.", "labels": [], "entities": []}, {"text": "We conducted experiments on three publicly available datasets: 1) 20 Newsgroups 3 (Lang, 1995): The data set is a collection of 20,000 documents, partitioned evenly across 20 different news groups; 2) IMDb Reviews (Maas et al., 2011): The data set contains 50,000 popular movie reviews with binary positive or negative labels from the IMDb website; and 3) Amazon Reviews (: The dataset is a collection of reviews from Amazon spanning the time period from May 1996 to July 2013.", "labels": [], "entities": []}, {"text": "We used review data from the Sports and outdoors category, with 272,630 data samples and rating labels from 1 to 5.", "labels": [], "entities": []}, {"text": "For all three data sets, we randomly selected 70% of the data samples as the training set, 10% as the validation set and 20% as the test set.", "labels": [], "entities": []}, {"text": "In order to answer the question \"What percentage of data should be transferred to domain experts to achieve an overall accuracy rate above 90%?\", we measure the classification performance in terms of various uncertainty ratios.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 119, "end_pos": 132, "type": "METRIC", "confidence": 0.9854550361633301}]}, {"text": "Specifically, assuming the entire testing set S has size n and an uncertainty ratio r, we can remove the most uncertain samples Sr from S based on the uncertainty ratio r, where the size of the uncertainty set Sr is r \u00b7 n.", "labels": [], "entities": []}, {"text": "We assume the uncertain samples Sr handed to domain experts achieve 100% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9989211559295654}]}, {"text": "If the uncertainty ratio r equals to 0, the model performs   without uncertainty measurement concerns.", "labels": [], "entities": [{"text": "uncertainty ratio r", "start_pos": 7, "end_pos": 26, "type": "METRIC", "confidence": 0.8699434995651245}]}, {"text": "For the binary classification task, we use the accuracy and F1-score to measure the classification performance based on the testing set S \\ Sr for different uncertainty ratios r.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 8, "end_pos": 34, "type": "TASK", "confidence": 0.7494966089725494}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9998030066490173}, {"text": "F1-score", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9991631507873535}]}, {"text": "Similarly, for multiclass tasks, we use the micro-F1 and macro-F1 scores utilizing the same settings as for the binary classification.", "labels": [], "entities": []}, {"text": "This subsection presents the results of the uncertainty performance comparison and the analysis of the metric learning and parameter settings.", "labels": [], "entities": []}, {"text": "shows the Micro-F1 and Macro-F1 scores for ratios of uncertain predictions eliminated ranging from 10 to 40% for the 20NewsGroup data set.", "labels": [], "entities": [{"text": "Micro-F1", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.755618691444397}, {"text": "20NewsGroup data set", "start_pos": 117, "end_pos": 137, "type": "DATASET", "confidence": 0.9560407996177673}]}, {"text": "To demonstrate its effect, metric learning was also applied to the baseline method Dropout, and our proposed method DE.", "labels": [], "entities": [{"text": "DE", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.8106072545051575}]}, {"text": "The improvement ratio compared to the results with no uncertainty elimination, shown in the 0% column, are presented after the F1 scores.", "labels": [], "entities": [{"text": "improvement ratio", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.970174252986908}, {"text": "F1", "start_pos": 127, "end_pos": 129, "type": "METRIC", "confidence": 0.9994518160820007}]}, {"text": "Based on these result, we can conclude that: 1) Our proposed method, DE+Metric, significantly improves both the Micro-and Macro-F1 scores when a portion of uncertain predictions are eliminated.", "labels": [], "entities": [{"text": "DE+Metric", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9336459835370382}]}, {"text": "For example, the Micro-F1 improves from 0.78 to 0.92 when 30% of the uncertain predictions are eliminated.", "labels": [], "entities": [{"text": "Micro-F1", "start_pos": 17, "end_pos": 25, "type": "DATASET", "confidence": 0.8641821146011353}]}, {"text": "2) Comparing the results obtained by DE and DE+Metric, metric learning significantly improves the results obtained for different uncertainty ratio settings.", "labels": [], "entities": [{"text": "DE", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9240773916244507}]}, {"text": "Similar results can be observed when comparing the Dropout and Dropout+Metric.", "labels": [], "entities": [{"text": "Dropout", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9503316879272461}, {"text": "Dropout+Metric", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.8243305881818136}]}, {"text": "For example, the Micro-F1 scores for Dropout+Metric are around 5% better than the Dropout method alone, boosting them from 0.851 to 0.892, with a 30% uncertainty ratio.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Uncertainty Scores for the 20 NewsGroup Dataset (20 Categories)", "labels": [], "entities": [{"text": "20 NewsGroup Dataset", "start_pos": 37, "end_pos": 57, "type": "DATASET", "confidence": 0.7994831999142965}]}, {"text": " Table 2: Uncertainty Scores for the IMDb Dataset (2 Categories)", "labels": [], "entities": [{"text": "IMDb Dataset", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.974686861038208}]}, {"text": " Table 3: Uncertainty Scores for the Amazon Dataset (5 Categories)", "labels": [], "entities": [{"text": "Amazon Dataset", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9807946681976318}]}, {"text": " Table 4: Embedding vs. No Pre-trained Embedding", "labels": [], "entities": []}]}