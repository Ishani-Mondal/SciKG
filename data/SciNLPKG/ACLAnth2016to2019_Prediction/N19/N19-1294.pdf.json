{"title": [{"text": "Improving Distantly-supervised Entity Typing with Compact Latent Space Clustering", "labels": [], "entities": [{"text": "Improving Distantly-supervised Entity Typing", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8883721232414246}]}], "abstractContent": [{"text": "Recently, distant supervision has gained great success on Fine-grained Entity Typing (FET).", "labels": [], "entities": [{"text": "Fine-grained Entity Typing (FET)", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.7180178910493851}]}, {"text": "Despite its efficiency in reducing manual labeling efforts, it also brings the challenge of dealing with false entity type labels, as distant supervision assigns labels in a context-agnostic manner.", "labels": [], "entities": []}, {"text": "Existing works alleviated this issue with partial-label loss, but usually suffer from confirmation bias, which means the classifier fit a pseudo data distribution given by itself.", "labels": [], "entities": []}, {"text": "In this work, we propose to regularize distantly supervised models with Compact Latent Space Clustering (CLSC) to bypass this problem and effectively utilize noisy data yet.", "labels": [], "entities": []}, {"text": "Our proposed method first dynamically constructs a similarity graph of different entity mentions; infer the labels of noisy instances via label propagation.", "labels": [], "entities": []}, {"text": "Based on the inferred labels, mention embeddings are updated accordingly to encourage entity mentions with close semantics to form a compact cluster in the embedding space, thus leading to better classification performance.", "labels": [], "entities": []}, {"text": "Extensive experiments on standard benchmarks show that our CLSC model consistently out-performs state-of-the-art distantly supervised entity typing systems by a significant margin.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have seen a surge of interests in fine-grained entity typing (FET) as it serves as an important cornerstone of several nature language processing tasks including relation extraction (, entity linking, and knowledge base completion ().", "labels": [], "entities": [{"text": "entity typing (FET)", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8325282573699951}, {"text": "relation extraction", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.8175946474075317}, {"text": "entity linking", "start_pos": 198, "end_pos": 212, "type": "TASK", "confidence": 0.7816367149353027}, {"text": "knowledge base completion", "start_pos": 218, "end_pos": 243, "type": "TASK", "confidence": 0.6373067200183868}]}, {"text": "To reduce manual efforts in labelling training data, distant supervision () has been widely adopted by recent FET systems.", "labels": [], "entities": [{"text": "labelling training", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.8851853013038635}, {"text": "FET", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.6187980771064758}]}, {"text": "With the help of an external knowledge base (KB), an entity mention is first * Corresponding Author.", "labels": [], "entities": []}, {"text": "linked to an existing entity in KB, and then labeled with all possible types of the KB entity as supervision.", "labels": [], "entities": []}, {"text": "However, despite its efficiency, distant supervision also brings the challenge of outof-context noise, as it assigns labels in a context agnostic manner.", "labels": [], "entities": []}, {"text": "Early works usually ignore such noise in supervision (, which dampens the performance of distantly supervised models.", "labels": [], "entities": []}, {"text": "Towards overcoming out-of-context noise, two lines of work have been proposed to distantly supervised FET.", "labels": [], "entities": [{"text": "FET", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.8480272889137268}]}, {"text": "The first kind of work try to filter out noisy labels using heuristic rules).", "labels": [], "entities": []}, {"text": "However, such heuristic pruning significantly reduces the amount of training data, and thus cannot make full use of distantly annotated data.", "labels": [], "entities": []}, {"text": "In contrast, the other thread of works try to incorporate such imperfect annotation by partiallabel loss (PLL).", "labels": [], "entities": [{"text": "partiallabel loss (PLL)", "start_pos": 87, "end_pos": 110, "type": "METRIC", "confidence": 0.9183465480804444}]}, {"text": "The basic assumption is that, fora noisy mention, the maximum score associated with its candidate types should be greater than the scores associated with any other non-candidate types.", "labels": [], "entities": []}, {"text": "Despite their success, PLLbased models still suffer from Confirmation Bias by taking its own prediction as optimization objective in the next step.", "labels": [], "entities": [{"text": "Confirmation Bias", "start_pos": 57, "end_pos": 74, "type": "METRIC", "confidence": 0.9174073934555054}]}, {"text": "Specifically, given an entity mention, if the typing system selected a wrong: The overall framework of CLSC.", "labels": [], "entities": []}, {"text": "We calculate classification loss only on clean data, while regularize the feature extractor with CLSC using both clean and noisy data.", "labels": [], "entities": [{"text": "classification", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9574259519577026}]}, {"text": "type with the maximum score among all candidates, it will try to further maximize the score of the wrong type in following optimization epoches (in order to minimize PLL), thus amplifying the confirmation bias.", "labels": [], "entities": [{"text": "PLL", "start_pos": 166, "end_pos": 169, "type": "METRIC", "confidence": 0.9661707878112793}]}, {"text": "Such bias starts from the early stage of training, when the typing model is still very suboptimal, and can accumulate in training process.", "labels": [], "entities": []}, {"text": "Related discussion can be also found in the setting of semi-supervised learning (.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew method for distantly supervised fine-grained entity typing.", "labels": [], "entities": [{"text": "distantly supervised fine-grained entity typing", "start_pos": 42, "end_pos": 89, "type": "TASK", "confidence": 0.6069390416145325}]}, {"text": "Enlightened by, we propose to effectively utilize imperfect annotation as model regularization via Compact Latent Space Clustering (CLSC).", "labels": [], "entities": []}, {"text": "More specifically, our model encourages the feature extractor to group mentions of the same type as a compact cluster (dense region) in the representation space, which leads to better classification performance.", "labels": [], "entities": []}, {"text": "For training data with noisy labels, instead of generating pseudo supervision by the typing model itself, we dynamically construct a similarity-weighted graph between clean and noisy mentions, and apply label propagation on the graph to help the formation of compact clusters.", "labels": [], "entities": []}, {"text": "demonstrates the effectiveness of our method in clustering mentions of different types into dense regions.", "labels": [], "entities": []}, {"text": "In contrast to PLL-based models, we do not force the model to fit pseudo supervision generated by itself, but only use noisy data as part of regularization for our feature extractor layer, thus avoiding bias accumulation.", "labels": [], "entities": []}, {"text": "Extensive experiments on standard benchmarks show that our method consistently outperforms state-of-the-art models.", "labels": [], "entities": []}, {"text": "Further study reveals that, the advantage of our model over the competitors gets even more significant as the portion of noisy data rises.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method on two standard benchmarks: OntoNotes and BBN: \u2022 OntoNotes: The OntoNotes dataset is composed of sentences from the Newswire part of OntoNotes corpus.", "labels": [], "entities": [{"text": "BBN", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.7009075880050659}, {"text": "OntoNotes dataset", "start_pos": 87, "end_pos": 104, "type": "DATASET", "confidence": 0.8358272910118103}, {"text": "Newswire part of OntoNotes corpus", "start_pos": 139, "end_pos": 172, "type": "DATASET", "confidence": 0.8089223861694336}]}, {"text": "In this work we use the preprocessed datasets provided by. shows detailed statistics of the datasets.", "labels": [], "entities": []}, {"text": "For evaluation metrics, we adopt strict accuracy, loose macro, and loose micro F-scores widely used in the FET task (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9989311099052429}, {"text": "FET task", "start_pos": 107, "end_pos": 115, "type": "TASK", "confidence": 0.6126581430435181}]}, {"text": "To fine tuning the hyper-parameters, we randomly sampled 10% of the test set as a development set for both datasets.", "labels": [], "entities": []}, {"text": "With the fine-tuned hyperparameter as mentioned in 4.4, we run the model five times and report the average strict accuracy, macro F1 and micro F1 on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9583011269569397}, {"text": "F1", "start_pos": 130, "end_pos": 132, "type": "METRIC", "confidence": 0.5767200589179993}, {"text": "F1", "start_pos": 143, "end_pos": 145, "type": "METRIC", "confidence": 0.6267648339271545}]}], "tableCaptions": [{"text": " Table 1: Performance comparision of FET systems on the two datasets.", "labels": [], "entities": [{"text": "FET", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.406560480594635}]}, {"text": " Table 2: Detailed statistics of the two datasets.", "labels": [], "entities": []}]}