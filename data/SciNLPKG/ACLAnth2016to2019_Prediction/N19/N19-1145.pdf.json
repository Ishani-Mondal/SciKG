{"title": [{"text": "Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM", "labels": [], "entities": [{"text": "Biomedical Event Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7355388005574545}]}], "abstractContent": [{"text": "Event extraction for the biomedical domain is more challenging than that in the general news domain since it requires broader acquisition of domain-specific knowledge and deeper understanding of complex contexts.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8075879812240601}]}, {"text": "To better encode contextual information and external background knowledge, we propose a novel knowledge base (KB)-driven tree-structured long short-term memory networks (Tree-LSTM) framework, incorporating two new types of features: (1) dependency structures to capture wide contexts; (2) entity properties (types and category descriptions) from external ontologies via entity linking.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the BioNLP shared task with Genia dataset and achieve anew state-of-the-art result.", "labels": [], "entities": [{"text": "Genia dataset", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.8869242966175079}]}, {"text": "In addition, both quantitative and qualitative studies demonstrate the advancement of the Tree-LSTM and the external knowledge representation for biomedical event extraction.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 146, "end_pos": 173, "type": "TASK", "confidence": 0.7553966244061788}]}], "introductionContent": [{"text": "Biomedical information extraction is widely used to assist the biology community on knowledge acquisition and ontology construction.", "labels": [], "entities": [{"text": "Biomedical information extraction", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8323250015576681}, {"text": "knowledge acquisition", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.7235384732484818}, {"text": "ontology construction", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.8912994265556335}]}, {"text": "Biomedical events generally refer to a change of status, particularly on proteins or genes.", "labels": [], "entities": []}, {"text": "The goal of event extraction is to identify triggers and their arguments from biomedical text, and then assign an event type to each trigger and a role to each argument.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7396857589483261}]}, {"text": "For example, in the sentence shown in, it includes a gene expression and a positive regulation event mention, both triggered by the word transduced.", "labels": [], "entities": []}, {"text": "Tax is the Theme argument of the gene expression event.", "labels": [], "entities": []}, {"text": "An event could also serve as an argument of another event, leading to a nested structure.", "labels": [], "entities": []}, {"text": "For instance, the gene expression event triggered by transduced is also a Theme argument of the positive regulation event as shown in.", "labels": [], "entities": []}, {"text": "Earlier studies on biomedical event extraction rely on kernel classification methods like the support vector machines (SVMs)) using hand-crafted features, which require high engineering effort and domain-specific knowledge.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6627071599165598}]}, {"text": "Recent distributional representation based approaches ( explore deep neural networks which only require distributed semantic features.", "labels": [], "entities": []}, {"text": "However, different from event extraction in the general news domain, biomedical event extraction requires broad acquisition of domain-specific knowledge and deep understanding of complex contexts.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.7950592041015625}, {"text": "biomedical event extraction", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.7031663060188293}]}, {"text": "For example, in Genia event extracton of BioNLP shared task 2011), about 80% of entity mentions are abbreviations of genes, proteins and diseases while more than 36% of event triggers and arguments are separated with more than 10 words.", "labels": [], "entities": [{"text": "Genia event extracton of BioNLP shared task 2011", "start_pos": 16, "end_pos": 64, "type": "DATASET", "confidence": 0.7499081902205944}]}, {"text": "In order to efficiently capture indicative information from broad contexts, we first adopt tree structure based long short-term memory (Tree-LSTM) networks.", "labels": [], "entities": []}, {"text": "Compared to the linear chain structured LSTM, the Tree-LSTM takes treestructured network topology into consideration.", "labels": [], "entities": []}, {"text": "As shown in the top frame of, Tree-LSTM takes the dependency tree structure of each sentence as input and gradually incorporates the information from the whole subtree into each node.", "labels": [], "entities": []}, {"text": "Dependency tree structure can connect semantically related concepts, and thus shorten the distance between a trigger and its arguments significantly.", "labels": [], "entities": []}, {"text": "For instance, in the following sentence \"...", "labels": [], "entities": []}, {"text": ", which binds to the enhancer A located in the promoter of the mouse MHC class I gene H2Kb, ...\", when determining the trigger type of binds, we need to carefully select its contextual words, such as H-2Kb, which indicates the object of binds.", "labels": [], "entities": [{"text": "MHC class I gene H2Kb", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7830840706825256}]}, {"text": "However, binds and H-2Kb are sepa-    The framework of the KB-driven Tree-LSTM model.", "labels": [], "entities": []}, {"text": "The upper frame shows the dependency tree structure and event annotations of a sentence; the middle frame demonstrates the knowledge base information obtained from the Gene Ontology for Tax; the bottom frame describes the KB-driven Tree-LSTM which takes the KB concept embedding and word embedding as input.", "labels": [], "entities": []}, {"text": "rated with 16 words which is difficult fora chainstructured LSTM to capture their long distance dependency, while within dependency tree structure, their distance is significantly shortened to 7.", "labels": [], "entities": []}, {"text": "Moreover, to better capture domain-specific knowledge, we further propose to leverage the external knowledge bases (KBs) to acquire properties of all the biomedical entities.", "labels": [], "entities": []}, {"text": "The KB properties are extremely beneficial for our model to learn patterns more explicitly.", "labels": [], "entities": []}, {"text": "Take the entity Tax in as an example, it's a protein often involved in the biological process of positive regulation of transcription referred to Gene Ontology ().", "labels": [], "entities": []}, {"text": "This function description provides crucial clues to determine the type of transduced as positive regulation.", "labels": [], "entities": []}, {"text": "Therefore, to capture such knowledge from external KBs, for each entity, we first learn a KB concept embedding from its properties, and then automatically incorporate the KB representation into its Tree-LSTM hidden state with agate function.", "labels": [], "entities": []}, {"text": "Our contributions are twofold: First, to the best of our knowledge, it's the first time to adopt Tree-LSTM for biomedical event extraction to effectively capture the wide contexts.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.6930691301822662}]}, {"text": "Second, we further incorporate external knowledge from domainspecific KBs into the Tree-LSTM, which yields state-of-the-art performance on Genia event extraction shared task.", "labels": [], "entities": [{"text": "Genia event extraction shared task", "start_pos": 139, "end_pos": 173, "type": "TASK", "confidence": 0.8250672340393066}]}], "datasetContent": [{"text": "We apply our KB-driven Tree-LSTM model on Genia 2011 data set.", "labels": [], "entities": [{"text": "Genia 2011 data set", "start_pos": 42, "end_pos": 61, "type": "DATASET", "confidence": 0.9503215700387955}]}, {"text": "The entities in Genia data set are manually annotated and given as part of the input.", "labels": [], "entities": [{"text": "Genia data set", "start_pos": 16, "end_pos": 30, "type": "DATASET", "confidence": 0.8398864070574442}]}, {"text": "We evaluate our results on the test set using the official online tool provided by the Genia task organizers.", "labels": [], "entities": []}, {"text": "1 Following previous studies, we report scores obtained by the approximate span (allowing trigger spans to differ from gold spans by single words).", "labels": [], "entities": []}, {"text": "As we only focus on matching core arguments, we use recursive matching criterion for evaluation which not requires matching of additional arguments for events referred from other events).", "labels": [], "entities": []}, {"text": "We use the word embedding pretrained on PubMed and PMC texts) for word and type embeddings.", "labels": [], "entities": [{"text": "PubMed and PMC texts", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.8253174275159836}]}, {"text": "The hyperparameters are tuned on the development set and listed in shows the final event extraction results of applying our KB-driven Tree-LSTM model on Genia 2011 dataset with the comparison of only using Tree-LSTM and a standard BiLSTM model.", "labels": [], "entities": [{"text": "Genia 2011 dataset", "start_pos": 153, "end_pos": 171, "type": "DATASET", "confidence": 0.9305052757263184}]}, {"text": "Tree-LSTM outperforms the BiLSTM baseline which indicates the power of Tree-LSTM in dealing with long-distance dependency structure in biomedical literature.", "labels": [], "entities": [{"text": "BiLSTM baseline", "start_pos": 26, "end_pos": 41, "type": "DATASET", "confidence": 0.6869124174118042}]}, {"text": "By incorporating external KB information, our approach achieves about 2.12% F-score gain comparing to Tree-LSTM, which demonstrates the effectiveness of the KB properties for biomedical event extraction.", "labels": [], "entities": [{"text": "F-score gain", "start_pos": 76, "end_pos": 88, "type": "METRIC", "confidence": 0.9869662821292877}, {"text": "biomedical event extraction", "start_pos": 175, "end_pos": 202, "type": "TASK", "confidence": 0.7462340990702311}]}, {"text": "We will show detailed analysis in Section 3.4.", "labels": [], "entities": []}, {"text": "presents the previous event extraction results from the BioNLP shared task using the same corpus.", "labels": [], "entities": []}, {"text": "Our approach outperforms all previous methods.", "labels": [], "entities": []}, {"text": "Among them, the systems TEES (), EventMine-CR ( and Stacked Generalization () are based on SVMs with well designed features. FAUST () and) use jointed inference models.", "labels": [], "entities": [{"text": "TEES", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9183570146560669}, {"text": "FAUST", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.5168883800506592}]}, {"text": "adopts a convolutional neural networks (CNNs) with abundant features derived from TEES system.", "labels": [], "entities": []}, {"text": "In our work, instead of using high-dimensional features with manual effort as in these previous models, our approach only requires pretrained distributed word representations as input features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Predefined event types with accepted argu- ment roles in Genia event extraction task, and data  statistics of Genia event extraction 2011 dataset. P:  protein; E: event.", "labels": [], "entities": [{"text": "Genia event extraction task", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.8309768587350845}, {"text": "Genia event extraction 2011 dataset", "start_pos": 120, "end_pos": 155, "type": "DATASET", "confidence": 0.6912708640098572}]}, {"text": " Table 1. Note that a Binding event may take  more than one protein as its Theme arguments. A  Regulation event may take one protein or event as  its Theme argument and also optionally take one", "labels": [], "entities": []}, {"text": " Table 2. Word representations are updated  during training with an initial learning rate of 0.1.", "labels": [], "entities": []}, {"text": " Table 3: Precision (Prec), recall (Rec) and F-score (F1)  results achieved by the KB-driven Tree-LSTM model  on the test set of BioNLP Genia 2011, evaluated on  approximate span and recursive criteria.", "labels": [], "entities": [{"text": "Precision (Prec)", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8724460005760193}, {"text": "recall (Rec)", "start_pos": 28, "end_pos": 40, "type": "METRIC", "confidence": 0.9371148198843002}, {"text": "F-score (F1)", "start_pos": 45, "end_pos": 57, "type": "METRIC", "confidence": 0.888082355260849}, {"text": "KB-driven Tree-LSTM model  on the test set of BioNLP Genia 2011", "start_pos": 83, "end_pos": 146, "type": "DATASET", "confidence": 0.8475170839916576}]}, {"text": " Table 4: State-of-the-art system results evaluated on  BioNLP Genia 2011 test dataset with approximate span  and recursive criteria.", "labels": [], "entities": [{"text": "BioNLP Genia 2011 test dataset", "start_pos": 56, "end_pos": 86, "type": "DATASET", "confidence": 0.966214120388031}]}]}