{"title": [{"text": "Cross-lingual Multi-Level Adversarial Transfer to Enhance Low-Resource Name Tagging", "labels": [], "entities": [{"text": "Multi-Level Adversarial Transfer", "start_pos": 14, "end_pos": 46, "type": "TASK", "confidence": 0.6151642004648844}, {"text": "Low-Resource Name Tagging", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.6136932075023651}]}], "abstractContent": [{"text": "We focus on improving name tagging for low-resource languages using annotations from related languages.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.8252377212047577}]}, {"text": "Previous studies either directly project annotations from a source language to a target language using cross-lingual representations or use a shared encoder in a multitask network to transfer knowledge.", "labels": [], "entities": []}, {"text": "These approaches inevitably introduce noise to the target language annotation due to mis-matched source-target sentence structures.", "labels": [], "entities": []}, {"text": "To effectively transfer the resources, we develop anew neural architecture that leverages multi-level adversarial transfer: (1) word-level ad-versarial training, which projects source language words into the same semantic space as those of the target language without using any parallel corpora or bilingual gazetteers, and (2) sentence-level adversarial training, which yields language-agnostic sequential features.", "labels": [], "entities": []}, {"text": "Our neural architecture outperforms previous approaches on CoNLL data sets.", "labels": [], "entities": [{"text": "CoNLL data sets", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.9087288975715637}]}, {"text": "Moreover, on 10 low-resource languages, our approach achieves up to 16% absolute F-score gain overall high-performing baselines on cross-lingual transfer without using any target-language resources.", "labels": [], "entities": [{"text": "F-score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.9507086277008057}, {"text": "cross-lingual transfer", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.7352865636348724}]}], "introductionContent": [{"text": "Low-resource language name tagging is an important but challenging task.", "labels": [], "entities": [{"text": "Low-resource language name tagging", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6101188808679581}]}, {"text": "An effective solution is to perform cross-lingual transfer, by leveraging the annotations from high-resource languages.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7840200960636139}]}, {"text": "Most of these efforts achieve cross-lingual annotation projection based on bilingual parallel corpora combining with automatic word alignment (;, bilingual gazetteers, cross-lingual word embedding, or cross-lingual Wikification (, but these resources are still only available for dozens of languages.", "labels": [], "entities": [{"text": "cross-lingual annotation projection", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.726858933766683}, {"text": "word alignment", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.7373437285423279}]}, {"text": "Recent efforts on multi-task learning model each language as one single task while all the tasks share the same encoding layer ().", "labels": [], "entities": []}, {"text": "These methods can transfer knowledge via the shared encoder without using bilingual resources.", "labels": [], "entities": []}, {"text": "However, different languages usually have different underlying sequence structures, as shown in.", "labels": [], "entities": []}, {"text": "Without an explicit constraint, the encoder is not guaranteed to extract language-independent sequential features.", "labels": [], "entities": []}, {"text": "Moreover, when the size of annotated resources is not balanced, the encoder is likely to be biased toward the resource-dominant language.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our methods from multiple settings.", "labels": [], "entities": []}, {"text": "We first evaluate our architecture on 10 lowresource languages from the DARPA LORELEI project.", "labels": [], "entities": [{"text": "DARPA LORELEI project", "start_pos": 72, "end_pos": 93, "type": "DATASET", "confidence": 0.7321147620677948}]}, {"text": "The annotations are released by the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 36, "end_pos": 68, "type": "DATASET", "confidence": 0.8535383343696594}]}, {"text": "Each dataset has four predefined name types: person (PER), organization (ORG), location (LOC) and geo-political entity (GPE).", "labels": [], "entities": []}, {"text": "For each target low-resource language, we choose a source language if they are from the same language family or use the same script.", "labels": [], "entities": []}, {"text": "To show the impact of resource transfer between distinct languages, we also use English as a source language for each target low-resource language.", "labels": [], "entities": []}, {"text": "We create the English annotated resource by combining the TAC-KBP 2015 English Entity Discovery and Linking () data set and the Automatic Content Extraction (ACE2005) data set.", "labels": [], "entities": [{"text": "TAC-KBP 2015 English Entity Discovery and Linking () data set", "start_pos": 58, "end_pos": 119, "type": "TASK", "confidence": 0.8368743360042572}, {"text": "Automatic Content Extraction (ACE2005) data set", "start_pos": 128, "end_pos": 175, "type": "DATASET", "confidence": 0.6955300234258175}]}, {"text": "To avoid the impact of parameter initialization, we perform 5-fold cross validation.", "labels": [], "entities": [{"text": "parameter initialization", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.6213987171649933}]}, {"text": "For each experiment, we run twice and get the averaged Fscore.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9866524338722229}]}, {"text": "shows the statistics of each data set.", "labels": [], "entities": []}, {"text": "We also evaluate our approach on high-resource languages.", "labels": [], "entities": []}, {"text": "We use Dutch (nl) and Spanish (es) data sets from the CoNLL 2002) shared task as target languages, and use English (en) data from the CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) shared task as The annotations are from: am (LDC2016E87), ti (LDC2017E39), ar (LDC2016E89), fa (LDC2016E93), om (LDC2017E27), so (LDC2016E91), sw (LDC2017E64), yo (LDC2016E105), ug (LDC2016E70), uz (LDC2016E29) The data sets are LDC2015E103 and LDC2006T06 the source language.", "labels": [], "entities": [{"text": "CoNLL 2002) shared task", "start_pos": 54, "end_pos": 77, "type": "DATASET", "confidence": 0.9300317645072937}, {"text": "CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) shared task", "start_pos": 134, "end_pos": 194, "type": "DATASET", "confidence": 0.9346980835710254}]}, {"text": "All the data sets have four pre-defined name types: PER, ORG, LOC and miscellaneous (MISC).", "labels": [], "entities": [{"text": "PER", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9764112830162048}, {"text": "ORG", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9815270304679871}, {"text": "LOC", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9515764713287354}]}, {"text": "shows the statistics of these data sets.", "labels": [], "entities": []}, {"text": "For fair comparison, we use the same pretrained word embeddings of English, Dutch and Spanish as, while for each lowresource language we train their word embeddings using the documents from their LDC packages with FastText.", "labels": [], "entities": []}, {"text": "lists the key hyperparameters we used in our experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data set statistics for each low-resource lan- guage.", "labels": [], "entities": []}, {"text": " Table 4: Cross-lingual transfer when the target lan- guage has no resources (F-score %).", "labels": [], "entities": [{"text": "Cross-lingual transfer", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8324678540229797}, {"text": "F-score", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9978334307670593}]}, {"text": " Table 5: Cross-lingual transfer when the target language has resources (F-score %).", "labels": [], "entities": [{"text": "Cross-lingual transfer", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8076970875263214}, {"text": "F-score", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.9973335266113281}]}]}