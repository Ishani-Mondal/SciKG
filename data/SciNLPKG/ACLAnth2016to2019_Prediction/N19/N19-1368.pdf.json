{"title": [{"text": "Ranking and Selecting Multi-Hop Knowledge Paths to Better Predict Human Needs", "labels": [], "entities": [{"text": "Predict Human Needs", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.813757598400116}]}], "abstractContent": [{"text": "To make machines better understand sentiments , research needs to move from polarity identification to understanding the reasons that underlie the expression of sentiment.", "labels": [], "entities": [{"text": "polarity identification", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.7829309403896332}]}, {"text": "Categorizing the goals or needs of humans is one way to explain the expression of sentiment in text.", "labels": [], "entities": []}, {"text": "Humans are good at understanding situations described in natural language and can easily connect them to the character's psychological needs using commonsense knowledge.", "labels": [], "entities": []}, {"text": "We present a novel method to extract, rank, filter and select multi-hop relation paths from a commonsense knowledge resource to interpret the expression of sentiment in terms of their underlying human needs.", "labels": [], "entities": []}, {"text": "We efficiently integrate the acquired knowledge paths in a neural model that interfaces context representations with knowledge using a gated attention mechanism.", "labels": [], "entities": []}, {"text": "We assess the model's performance on a recently published dataset for categorizing human needs.", "labels": [], "entities": []}, {"text": "Selectively integrating knowledge paths boosts performance and establishes anew state-of-the-art.", "labels": [], "entities": []}, {"text": "Our model offers inter-pretability through the learned attention map over commonsense knowledge paths.", "labels": [], "entities": []}, {"text": "Human evaluation highlights the relevance of the encoded knowledge.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis and emotion detection are essential tasks in human-computer interaction.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9631814062595367}, {"text": "emotion detection", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.781806617975235}]}, {"text": "Due to its broad practical applications, there has been rapid growth in the field of sentiment analysis (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.967327892780304}]}, {"text": "Although state-of-the-art sentiment analysis can detect the polarity of text units (, there has been limited work towards explaining the reasons for the expression of sentiment and emotions in texts (.", "labels": [], "entities": [{"text": "state-of-the-art sentiment analysis", "start_pos": 9, "end_pos": 44, "type": "TASK", "confidence": 0.6791424055894216}]}, {"text": "In our work, we aim to go beyond the detection of sentiment, toward explaining sentiments.", "labels": [], "entities": []}, {"text": "Such explanations can range from detecting overtly expressed explanations or reasons for sentiments towards specific aspects of, e.g., products or films, as in user reviews to the explanation of the underlying reasons for emotional reactions of characters in a narrative story.", "labels": [], "entities": [{"text": "detecting overtly expressed explanations or reasons for sentiments towards specific aspects of, e.g., products or films, as in user reviews to the explanation of the underlying reasons for emotional reactions of characters in a narrative story", "start_pos": 33, "end_pos": 276, "type": "Description", "confidence": 0.7809117421125754}]}, {"text": "The latter requires understanding of stories and modeling the mental state of characters.", "labels": [], "entities": []}, {"text": "Recently, proposed to categorize affective events with categories based on human needs, to provide explanations of people's attitudes towards such events.", "labels": [], "entities": []}, {"text": "Given an expression such as I broke my leg, they categorize the reason for the expressed negative sentiment as being related to a need concerning 'health'.", "labels": [], "entities": []}, {"text": "In this paper we focus on the Modelling Naive Psychology of Characters in Simple Commonsense Stories dataset of, which contains annotations of a fully-specified chain of motivations and emotional reactions of characters fora collection of narrative stories.", "labels": [], "entities": [{"text": "Simple Commonsense Stories dataset", "start_pos": 74, "end_pos": 108, "type": "DATASET", "confidence": 0.7121666446328163}]}, {"text": "The stories are annotated with labels from multiple theories of psychology to provide explanations for the emotional reactions of characters.", "labels": [], "entities": []}, {"text": "Similar to, we hypothesize that emotional reactions (joy, trust, fear, etc.) of characters can be explained by (dis)satisfaction of their psychological needs.", "labels": [], "entities": []}, {"text": "However, predicting categories of human needs that underlie the expression of sentiment is a difficult task fora computational model.", "labels": [], "entities": [{"text": "predicting categories of human needs that underlie the expression of sentiment", "start_pos": 9, "end_pos": 87, "type": "TASK", "confidence": 0.772689017382535}]}, {"text": "It requires not only detecting surface patterns from the text, but also requires commonsense knowledge about how a given situation mayor may not satisfy specific human needs of a character.", "labels": [], "entities": []}, {"text": "Such knowledge can be diverse and complex, and will typically be implicit in the text.", "labels": [], "entities": []}, {"text": "In contrast, human readers can make use of relevant information from the story and associate it with their knowledge about human interaction, desires and human needs, and thus will be able to infer underlying reasons for emotions indicated in the text.", "labels": [], "entities": []}, {"text": "In this work, we propose a computational model that aims to categorize human needs of story characters by integrating commonsense knowledge from ConceptNet (.", "labels": [], "entities": []}, {"text": "Our model aims to imitate human understanding of a story, by (i) learning to select relevant words from the text, (ii) extracting pieces of knowledge from the commonsense inventory and (iii) associating them with human need categories put forth by psychological theories.", "labels": [], "entities": []}, {"text": "Our assumption is that by integrating commonsense knowledge in our model we will be able to overcome the lack of textual evidence in establishing relations between expressed emotions in specific situations and the inferable human needs of story characters.", "labels": [], "entities": []}, {"text": "In order to provide such missing associations, we leverage the graph structure of the knowledge source.", "labels": [], "entities": []}, {"text": "Since these connections can be diverse and complex, we develop a novel approach to extract and rank multi-hop relation paths from ConceptNet using graph-based methods.", "labels": [], "entities": []}, {"text": "Our contributions are: (i) We propose a novel approach to extract and rank multi-hop relation paths from a commonsense knowledge resource using graph-based features and algorithms.", "labels": [], "entities": []}, {"text": "(ii) We present an end-to-end model enhanced with attention and a gated knowledge integration component to predict human needs in a given context.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our model is the first to advance commonsense knowledge for this task.", "labels": [], "entities": []}, {"text": "(iii) We conduct experiments that demonstrate the effectiveness of the extracted knowledge paths and show significant performance improvements over the prior state-of-the-art.", "labels": [], "entities": []}, {"text": "(iv) Our model provides interpretability in two ways: by selecting relevant words from the input text and by choosing relevant knowledge paths from the imported knowledge.", "labels": [], "entities": []}, {"text": "In both cases, the degree of relevance is indicated via an attention map.", "labels": [], "entities": []}, {"text": "(v) A small-scale human evaluation demonstrates that the extracted multi-hop knowledge paths are indeed relevant.", "labels": [], "entities": []}, {"text": "Our code is made publicly available.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset: We evaluate our model on the Modeling Naive Psychology of Characters in Simple Commonsense Stories (MNPCSCS) dataset (.", "labels": [], "entities": [{"text": "Modeling Naive Psychology of Characters in Simple Commonsense Stories (MNPCSCS) dataset", "start_pos": 38, "end_pos": 125, "type": "TASK", "confidence": 0.7154644750631772}]}, {"text": "It contains narrative stories where each sentence is annotated with a character and a set of human need categories from two inventories: Maslow's (with five coarsegrained) and Reiss's (with 19 fine-grained) categories (Reiss's labels are considered as subcategories of Maslow's).", "labels": [], "entities": []}, {"text": "The data contains the original worker annotations.", "labels": [], "entities": []}, {"text": "Following prior work we select the annotations that display the \"majority label\" i.e., categories voted on by \ud97b\udf59 2 workers.", "labels": [], "entities": []}, {"text": "Since no training data is available, similar to prior work we use a portion of the devset as training data, by performing a random split, using 80% of the data to train the classifier, and 20% to tune parameters.", "labels": [], "entities": []}, {"text": "Data statistics is reported in. report that there is low annotator agreement i.a. between the belonging and the approval class.", "labels": [], "entities": []}, {"text": "We also find high cooccurrence of the belonging, approval and social contact classes, where belonging and social contact both pertain to the Maslow class Love/belonging while approval belongs to the Maslow class Esteem.", "labels": [], "entities": []}, {"text": "This indicates that belonging interacts with Love/belonging and Esteem in relation to social contact.", "labels": [], "entities": [{"text": "Esteem", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9957488775253296}]}, {"text": "We further observed during our study that in the Reiss dataset the number of instances annotated with the belonging class is very low (no. of instances in training is 24, and in dev 5).", "labels": [], "entities": [{"text": "Reiss dataset", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.8249299824237823}]}, {"text": "The performance for this class is thus severely hampered, with 4.7 F 1 score for BiLSTM+Self-Attention and 7.1 F 1 score for BiLSTM+Self-Attention+Knowledge.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9765776793162028}, {"text": "BiLSTM", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.6769098043441772}, {"text": "F 1 score", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9826421538988749}, {"text": "BiLSTM+Self-Attention+Knowledge", "start_pos": 125, "end_pos": 156, "type": "DATASET", "confidence": 0.7179208159446716}]}, {"text": "After establishing benchmark results with prior work (cf., including belonging), we perform all further experiments with a reduced Reiss dataset, by eliminating the belonging class from all instances.", "labels": [], "entities": [{"text": "Reiss dataset", "start_pos": 131, "end_pos": 144, "type": "DATASET", "confidence": 0.737477719783783}]}, {"text": "This impacts the overall number of instances only slightly: by one instance for training and two instances for test, as shown in.", "labels": [], "entities": []}, {"text": "Training: During training we minimize the weighted binary cross entropy loss, where Z is the number of class labels in the classification tasks and w z is the weight.", "labels": [], "entities": []}, {"text": "P (y z ) is the marginal class probability of a positive label for z in the training set.", "labels": [], "entities": [{"text": "P (y z )", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9162557601928711}]}, {"text": "Embeddings: To compare our model with prior work we experiment with pretrained GloVe (100d) embeddings).", "labels": [], "entities": []}, {"text": "Otherwise we used GloVe (300d) and pretrained ELMo embeddings () to train our model.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9068377017974854}]}, {"text": "Hyperparameters for Knowledge Inclusion: We compute ranked lists of knowledge paths of two types: p c\ud97b\udf59z and p c\ud97b\udf59c . We use the top-3 p c\ud97b\udf59z paths for each z using our best ranking strategy (Closeness Centrality + Personalized PageRank) in our best system results, and also considered paths p c\ud97b\udf59c (top-3 per pair) when evaluating different path selection strategies.", "labels": [], "entities": [{"text": "Knowledge Inclusion", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7071717232465744}]}, {"text": "Evaluation Metrics: We predict a binary label for each class using a binary classifier so the prediction of each label is conditionally independent of the other classes given a context representation of the sentence.", "labels": [], "entities": []}, {"text": "In all prediction tasks we report the micro-averaged Precision (P), Recall (R) and F 1 scores by counting the number of positive instances across all of the categories.", "labels": [], "entities": [{"text": "micro-averaged Precision (P)", "start_pos": 38, "end_pos": 66, "type": "METRIC", "confidence": 0.8675212740898133}, {"text": "Recall (R) and F 1 scores", "start_pos": 68, "end_pos": 93, "type": "METRIC", "confidence": 0.8853270560503006}]}, {"text": "All reported results are averaged over five runs.", "labels": [], "entities": []}, {"text": "More informa-  tion on the dataset, metrics and all other training details are given in the Supplement.", "labels": [], "entities": [{"text": "Supplement", "start_pos": 92, "end_pos": 102, "type": "DATASET", "confidence": 0.7971903085708618}]}, {"text": "We conduct human evaluation to test the effectiveness and relevance of the extracted commonsense knowledge paths.", "labels": [], "entities": []}, {"text": "We randomly selected 50 sentence-context pairs with their gold labels from the devset and extracted knowledge paths that contain the gold label (using CC+PPR for ranking).", "labels": [], "entities": []}, {"text": "We asked three expert evaluators to decide whether the paths are relevant to provide information about the missing links between the concepts in the sentence and the human need (gold label).", "labels": [], "entities": []}, {"text": "The inter-annotator agreement had a Fleiss' \uf8ff= 0.76.", "labels": [], "entities": [{"text": "Fleiss'", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9942014813423157}]}, {"text": "The result for this evaluation shows that in 34% of the cases computed on the basis of majority agreement, our algorithm was able to select a relevant commonsense path.", "labels": [], "entities": []}, {"text": "More details about the human evaluation are given in the Supplement.", "labels": [], "entities": [{"text": "Supplement", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.565009593963623}]}], "tableCaptions": [{"text": " Table 1: Dataset Statistics: nb. of instances (sentences  with annotated characters and human need labels).", "labels": [], "entities": []}, {"text": " Table 2: Multi-label Classification Results: \u21e7 : results in  Rashkin et al.; ? : w/o belonging; BM: BiLSTM+Self- Att.; +K:w/ knowledge, | :ranking method CC+PPR.", "labels": [], "entities": [{"text": "BM", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9855871200561523}]}, {"text": " Table 3: Model ablations for Reiss Classification on  MNPCSCS dataset w/o belonging.", "labels": [], "entities": [{"text": "Reiss Classification", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.9840554893016815}, {"text": "MNPCSCS dataset", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9564164280891418}]}, {"text": " Table 4: Results for different path selection strategies  on MNPCSCS w/o belonging; S+M:Single+Multi hop.", "labels": [], "entities": [{"text": "MNPCSCS", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.7776404619216919}]}, {"text": " Table 5: Multi-label classification on MNPCSCS w/o  belonging class and w/o context (1 st sentence only)", "labels": [], "entities": [{"text": "MNPCSCS", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.7631850242614746}]}]}