{"title": [{"text": "Scalable Methods for Annotating Legal-Decision Corpora", "labels": [], "entities": [{"text": "Annotating Legal-Decision Corpora", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.762028435866038}]}], "abstractContent": [{"text": "Recent research has demonstrated that judicial and administrative decisions can be predicted by machine-learning models trained on prior decisions.", "labels": [], "entities": []}, {"text": "However, to have any practical application, these predictions must be explainable, which in turn requires modeling a rich set of features.", "labels": [], "entities": []}, {"text": "Such approaches face a roadblock if the knowledge engineering required to create these features is not scalable.", "labels": [], "entities": []}, {"text": "We present an approach to developing a feature-rich corpus of administrative rulings about domain name disputes, an approach which leverages a small amount of manual annotation and prototypical patterns present in the case documents to automatically extend feature labels to the entire corpus.", "labels": [], "entities": []}, {"text": "To demonstrate the feasibility of this approach, we report results from systems trained on this dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent research has demonstrated that judicial and administrative decisions can be predicted by machine-learning models trained on prior decisions (.", "labels": [], "entities": []}, {"text": "Predictive legal models have the potential to improve both the delivery of services to citizens and the efficiency of agency decision processes, e.g., by making benefits adjudications faster and more transparent, and by enabling decision-support tools for evaluating benefits claims.", "labels": [], "entities": []}, {"text": "The accuracy of predictive legal models is highest, and explanatory capability greatest, when the prior decisions are represented in terms of features manually engineered to express exactly the most relevant aspects of the prior case (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994288086891174}, {"text": "predictive legal", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.8752475082874298}]}, {"text": "However, this approach is not scalable.", "labels": [], "entities": []}, {"text": "Alternatively, decisions can be predicted from case text alone, but these models typically lack explanatory capability ().", "labels": [], "entities": []}, {"text": "Development of approaches for explaining decision predictions in terms of relevant case facts while minimizing manual feature engineering is critical for broad adoption of systems for legal case prediction.", "labels": [], "entities": [{"text": "explaining decision predictions", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.755736509958903}, {"text": "legal case prediction", "start_pos": 184, "end_pos": 205, "type": "TASK", "confidence": 0.6810646255811056}]}, {"text": "Our approach to explainable legal prediction focuses on annotating the portions of written decisions that set forth the justification for the decision.", "labels": [], "entities": [{"text": "explainable legal prediction", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.6422422826290131}]}, {"text": "We hypothesize that tag sets for these justifications can be used as features for explainable prediction.", "labels": [], "entities": []}, {"text": "Ina separate paper ( we propose an approach that uses models trained on an annotated corpus to extract features that can be used for both outcome prediction and explanation in new cases.", "labels": [], "entities": [{"text": "outcome prediction and explanation", "start_pos": 138, "end_pos": 172, "type": "TASK", "confidence": 0.7209050804376602}]}, {"text": "This paper focuses on development of the annotated corpus itself.", "labels": [], "entities": []}, {"text": "Our feature set makes use of two common elements in legal argumentation: issues and factors.", "labels": [], "entities": []}, {"text": "In our usage, an \"issue\" is a formal element of a legal claim corresponding to a term, or \"predicate,\" that occurs in an authoritative legal source, such as a statute, regulation, or policy, and that is cited in the decision portion of cases.", "labels": [], "entities": [{"text": "an \"issue\" is a formal element of a legal claim corresponding to a term, or \"predicate,\" that occurs in an authoritative legal source, such as a statute, regulation, or policy", "start_pos": 14, "end_pos": 189, "type": "Description", "confidence": 0.7950782219046041}]}, {"text": "For example, in jurisdictions in which the term \"intoxication\" occurs in a statute forbidding driving under the influence of alcohol or drugs (DUI), the predicate \"intoxication\" is an issue, and legal liability depends on whether this predicate is established at trial.", "labels": [], "entities": []}, {"text": "\"Slurred speech,\" by contrast, is a \"factor\" if the decision portion of one or more cases contains findings about \"slurred speech\" that justify conclusions about the issue of intoxication.", "labels": [], "entities": []}, {"text": "This usage differs from and others in that our factors are not features developed by domain experts, but rather are classes of factual findings in case decisions denoted by common annotation tags.", "labels": [], "entities": []}, {"text": "We surmise that these decision-derived factors are amenable both to HYPO/CATO-like argumentation) and to alternative machinelearning and inferential techniques.", "labels": [], "entities": [{"text": "HYPO/CATO-like argumentation", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.5259747579693794}]}, {"text": "This paper describes several approaches to lightweight and expedited corpus creation in support of explainable legal decision prediction.", "labels": [], "entities": [{"text": "explainable legal decision prediction", "start_pos": 99, "end_pos": 136, "type": "TASK", "confidence": 0.6264945194125175}]}, {"text": "The methods are tested on formal written decisions about domain name disputes which are published by the World Intellectual Property Organization (WIPO).", "labels": [], "entities": [{"text": "World Intellectual Property Organization (WIPO)", "start_pos": 105, "end_pos": 152, "type": "DATASET", "confidence": 0.605883892093386}]}, {"text": "The first approach involves human annotators applying a three-layer schema for labeling argument elements, issues, and factors in the panel's findings and decisions on the case.", "labels": [], "entities": []}, {"text": "This method is applied to a very small corpus of 25 documents.", "labels": [], "entities": []}, {"text": "The second approach is applied to the entire corpus of over 16000 documents and employs a combination of automated preprocessing and human annotation for labeling the outcome for three principal issues in each WIPO case.", "labels": [], "entities": [{"text": "WIPO case", "start_pos": 210, "end_pos": 219, "type": "TASK", "confidence": 0.610159695148468}]}, {"text": "A third layer of annotation is added by automatically projecting the argument element, issue, and factor annotations onto each sentence in each document of the entire corpus.", "labels": [], "entities": []}, {"text": "We are making this a richly annotated corpus available to the research community via MITRE's GitHub space (https://github.com/mitre).", "labels": [], "entities": [{"text": "MITRE's GitHub space", "start_pos": 85, "end_pos": 105, "type": "DATASET", "confidence": 0.8626455515623093}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Issue-Level Outcome Annotations", "labels": [], "entities": []}, {"text": " Table 4: Issue-Level Prediction Scores", "labels": [], "entities": [{"text": "Issue-Level Prediction Scores", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.7478195230166117}]}]}