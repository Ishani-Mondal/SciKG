{"title": [{"text": "Gender Bias in Contextualized Word Embeddings", "labels": [], "entities": [{"text": "Gender Bias in Contextualized Word Embeddings", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6438593020041784}]}], "abstractContent": [{"text": "In this paper, we quantify, analyze and mitigate gender bias exhibited in ELMo's contex-tualized word vectors.", "labels": [], "entities": []}, {"text": "First, we conduct several intrinsic analyses and find that (1) training data for ELMo contains significantly more male than female entities, (2) the trained ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities.", "labels": [], "entities": []}, {"text": "Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus.", "labels": [], "entities": [{"text": "WinoBias probing corpus", "start_pos": 137, "end_pos": 160, "type": "DATASET", "confidence": 0.8245946764945984}]}, {"text": "Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributed representations of words in the form of word embeddings () and contextualized word embeddings () have led to huge performance improvement on many NLP tasks.", "labels": [], "entities": []}, {"text": "However, several recent studies show that training word embeddings in large corpora could lead to encoding societal biases present in these human-produced data (.", "labels": [], "entities": []}, {"text": "In this work, we extend these analyses to the ELMo contextualized word embeddings.", "labels": [], "entities": []}, {"text": "Our work provides anew intrinsic analysis of how ELMo represents gender in biased ways.", "labels": [], "entities": []}, {"text": "First, the corpus used for training ELMo has a significant gender skew: male entities are nearly three times more common than female entities, which leads to gender bias in the downloadable pre-trained contextualized embeddings.", "labels": [], "entities": []}, {"text": "Then, we apply principal component analysis (PCA) to show that after training on such biased corpora, there exists a lowdimensional subspace that captures much of the gender information in the contextualized embeddings.", "labels": [], "entities": []}, {"text": "Finally, we evaluate how faithfully ELMo preserves gender information in sentences by measuring how predictable gender is from ELMo representations of occupation words that co-occur with gender revealing pronouns.", "labels": [], "entities": []}, {"text": "Our results show that ELMo embeddings perform unequally on male and female pronouns: male entities can be predicted from occupation words 14% more accurately than female entities.", "labels": [], "entities": []}, {"text": "In addition, we examine how gender bias in ELMo propagates to the downstream applications.", "labels": [], "entities": []}, {"text": "Specifically, we evaluate a state-of-the-art coreference resolution system ( ) that makes use of ELMo's contextual embeddings on WinoBias (), a coreference diagnostic dataset that evaluates whether systems behave differently on decisions involving male and female entities of stereotyped or anti-stereotyped occupations.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.8820824325084686}]}, {"text": "We find that in the most challenging setting, the ELMo-based system has a disparity inaccuracy between pro-and anti-stereotypical predictions, which is nearly 30% higher than a similar system based on GloVe (.", "labels": [], "entities": []}, {"text": "Finally, we investigate approaches for mitigating the bias which propagates from the contextualized word embeddings to a coreference resolution system.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.9164071679115295}]}, {"text": "We explore two different strategies: (1) a training-time data augmentation technique (), where we augment the corpus for training the coreference system with its genderswapped variant (female entities are swapped to male entities and vice versa) and, afterwards, retrain the coreference system; and (2) a test-time embedding neutralization technique, where input contextualized word representations are averaged with word representations of a sentence with entities of the opposite gender.", "labels": [], "entities": []}, {"text": "Results show that testtime embedding neutralization is only partially effective, while data augmentation largely mitigates bias demonstrated on WinoBias by the coreference system.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: F1 on OntoNotes and WinoBias development sets. WinoBias dataset is split Semantics Only and w/  Syntactic Cues subsets. ELMo improves the performance on the OntoNotes dataset by 5% but shows stronger bias  on the WinoBias dataset. Avg. stands for averaged F1 score on the pro-and anti-stereotype subsets while \"Diff.\"  is the absolute difference between these two subsets. * indicates the difference between pro/anti stereotypical  conditions is significant (p < .05) under an approximate randomized test", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9985394477844238}, {"text": "WinoBias dataset", "start_pos": 57, "end_pos": 73, "type": "DATASET", "confidence": 0.7348720133304596}, {"text": "ELMo", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9212645292282104}, {"text": "OntoNotes dataset", "start_pos": 167, "end_pos": 184, "type": "DATASET", "confidence": 0.8881547152996063}, {"text": "WinoBias dataset", "start_pos": 223, "end_pos": 239, "type": "DATASET", "confidence": 0.741403341293335}, {"text": "Avg.", "start_pos": 241, "end_pos": 245, "type": "METRIC", "confidence": 0.9779930412769318}, {"text": "F1 score", "start_pos": 266, "end_pos": 274, "type": "METRIC", "confidence": 0.9714926183223724}, {"text": "Diff.", "start_pos": 321, "end_pos": 326, "type": "METRIC", "confidence": 0.995457649230957}]}]}