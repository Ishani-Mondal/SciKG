{"title": [{"text": "Disentangling Language and Knowledge in Task-Oriented Dialogs", "labels": [], "entities": [{"text": "Disentangling Language and Knowledge in Task-Oriented Dialogs", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.8050602844783238}]}], "abstractContent": [{"text": "The Knowledge Base (KB) used for real-world applications, such as booking a movie or restaurant reservation, keeps changing overtime.", "labels": [], "entities": [{"text": "booking a movie or restaurant reservation", "start_pos": 66, "end_pos": 107, "type": "TASK", "confidence": 0.6445315480232239}]}, {"text": "End-to-end neural networks trained for these task-oriented dialogs are expected to be immune to any changes in the KB.", "labels": [], "entities": []}, {"text": "However, existing approaches breakdown when asked to handle such changes.", "labels": [], "entities": []}, {"text": "We propose an encoder-decoder architecture (BOSSNET) with a novel Bag-of-Sequences (BOSS) memory, which facilitates the disentangled learning of the re-sponse's language model and its knowledge incorporation.", "labels": [], "entities": [{"text": "knowledge incorporation", "start_pos": 184, "end_pos": 207, "type": "TASK", "confidence": 0.7200720757246017}]}, {"text": "Consequently, the KB can be modified with new knowledge without a drop in interpretability.", "labels": [], "entities": []}, {"text": "We find that BOSSNET out-performs state-of-the-art models, with considerable improvements (>10%) on bAbI OOV test sets and other human-human datasets.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.6127741932868958}, {"text": "bAbI OOV test sets", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.8497022390365601}]}, {"text": "We also systematically modify existing datasets to measure disentanglement and show BOSSNET to be robust to KB modifications.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9687771201133728}]}], "introductionContent": [{"text": "Task-oriented dialog agents converse with a user with the goal of accomplishing a specific task and often interact with a knowledge-base (KB).", "labels": [], "entities": []}, {"text": "For example, a restaurant reservation agent) will be grounded to a KB that contains the names of restaurants, and their details.", "labels": [], "entities": [{"text": "restaurant reservation agent", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.7678578694661459}]}, {"text": "In real-world applications, the KB information could changeover time.", "labels": [], "entities": []}, {"text": "For example, (1) a KB associated with a movie ticket booking system gets updated every week based on new film releases, and (2) a restaurant reservation agent, trained with the knowledge of eateries in one city, maybe deployed in other cities with an entirely different range of establishments.", "labels": [], "entities": []}, {"text": "In such situations, the system should have the ability to conform to new-found knowledge unseen during its training.", "labels": [], "entities": []}, {"text": "Ideally, the training algorithm must learn to disentangle the language * D.", "labels": [], "entities": []}, {"text": "Raghu is an employee at IBM Research.", "labels": [], "entities": [{"text": "IBM Research", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.8912710249423981}]}, {"text": "This work was carried out as part of PhD research at IIT Delhi.", "labels": [], "entities": [{"text": "IIT Delhi", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.628481388092041}]}, {"text": "model from the knowledge interface model.", "labels": [], "entities": []}, {"text": "This separation will enable the system to generalize to KB modifications, without a loss in performance.", "labels": [], "entities": []}, {"text": "Moreover, for achieving good progress towards the user's task, the agent must also retain the ability to draw inferences based on past utterances and the KB.", "labels": [], "entities": []}, {"text": "Notably, we find that existing approaches either achieve this disentanglement or effective progress towards the task, but not both.", "labels": [], "entities": []}, {"text": "For instance,) exhibits satisfactory performance when tested on the training KB.", "labels": [], "entities": [{"text": "training KB", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.6437195837497711}]}, {"text": "It represents the dialog history and the KB knowledge as a bag of words in a flat memory arrangement.", "labels": [], "entities": []}, {"text": "This enables Mem2Seq to revisit each word several times, as needed, obtaining good performance.", "labels": [], "entities": []}, {"text": "But at the same time, flat memory prevents it from capturing any surrounding context -this deteriorates its performance rapidly when the amount of new unseen information in the KB increases, as shown in.", "labels": [], "entities": []}, {"text": "On the other hand, the performance of copy augmented sequence-tosequence network (Seq2Seq+Copy), is robust to changes in the KB, but fails to achieve acceptable task-oriented performance.", "labels": [], "entities": []}, {"text": "It captures context by representing the entire dialog history as one continuous sequence.", "labels": [], "entities": []}, {"text": "However, it can be difficult fora sequence encoder to reason overlong dialogs found in real-world datasets and its ability to learn the task gets hampered.", "labels": [], "entities": []}, {"text": "We propose BOSSNET, a novel network that effectively disentangles the language and knowledge models, and also achieves state-of-the-art performance on three existing datasets.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.660738468170166}]}, {"text": "To achieve this, BOSSNET makes two design choices.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.7647405862808228}]}, {"text": "First, it encodes the conversational input as a bag of sequences (BOSS) memory, in which the input representation is built at two levels of abstraction.", "labels": [], "entities": []}, {"text": "The higher level flat memory encodes the KB tuples and utterances to facilitate effective inferencing over them.", "labels": [], "entities": []}, {"text": "The lower level encoding of each individual utterance and tuple is constructed via a sequence encoder.", "labels": [], "entities": []}, {"text": "This enables the model to maintain the sequential context surrounding each token, aiding in better interpretation of unseen tokens attest time.", "labels": [], "entities": []}, {"text": "Second, we augment the standard cross-entropy loss used in dialog systems with an additional loss term to encourage the model to only copy KB tokens in a response, instead of generating them via the language model.", "labels": [], "entities": []}, {"text": "This combination of sequence encoding and additional loss (along with dropout) helps in effective disentangling between language and knowledge.", "labels": [], "entities": [{"text": "sequence encoding", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.6616575121879578}]}, {"text": "We perform evaluations over three datasetsbAbI (,, and Stanford Multi-Domain Dataset ( . Of these, the last two are realworld datasets.", "labels": [], "entities": [{"text": "Stanford Multi-Domain Dataset", "start_pos": 55, "end_pos": 84, "type": "DATASET", "confidence": 0.8711864550908407}]}, {"text": "We find that BOSSNET is competitive or significantly better on standard metrics in all datasets as compared to state-of-the-art baselines.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.952378511428833}]}, {"text": "We also introduce a knowledge adaptability (KA) evaluation, in which we systematically increase the percentage of previously unseen entities in the KB.", "labels": [], "entities": [{"text": "knowledge adaptability (KA) evaluation", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.6777485261360804}]}, {"text": "We find that BOSSNET is highly robust across all percentage levels.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9376742243766785}]}, {"text": "Finally, we also report a humanbased evaluation and find that BOSSNET responses are frequently rated higher than other baselines.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9489216804504395}]}, {"text": "Overall, our contributions are: 1.", "labels": [], "entities": []}, {"text": "We propose BOSSNET, a novel architecture to disentangle the language model from knowledge incorporation in task-oriented dialogs.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.7163958549499512}, {"text": "knowledge incorporation", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.7461819350719452}]}, {"text": "2. We introduce a knowledge adaptability evaluation to measure the ability of dialog systems to scale performance to unseen KB entities.", "labels": [], "entities": []}, {"text": "3. Our experiments show that BOSSNET is competitive or significantly better, measured via standard metrics, than the existing baselines on three datasets.: The dialog history and KB tuples stored in the memory have memory cell representations and token representations.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.924549400806427}]}, {"text": "The encoder understands the last user utterance using only the memory cell representations.", "labels": [], "entities": []}, {"text": "The decoder generates the next response using both representations.", "labels": [], "entities": []}, {"text": "We release our code and knowledge adaptability (KA) test sets for further use by the research community.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments on three task-oriented dialog datasets: bAbI Dialog (,, and Stanford Multi-Domain Dataset ( . bAbI Dialog consists of synthetically generated dialogs with the goal of restaurant reservation.", "labels": [], "entities": [{"text": "Stanford Multi-Domain Dataset", "start_pos": 83, "end_pos": 112, "type": "DATASET", "confidence": 0.8403106331825256}, {"text": "restaurant reservation", "start_pos": 190, "end_pos": 212, "type": "TASK", "confidence": 0.6956833600997925}]}, {"text": "The dataset consists of five different tasks, all grounded to a KB.", "labels": [], "entities": []}, {"text": "This KB is split into two mutually exclusive halves.", "labels": [], "entities": []}, {"text": "One half is used to generate the train, validation, and test sets, while the other half is used to create a second test set called the OOV test set.", "labels": [], "entities": [{"text": "OOV test set", "start_pos": 135, "end_pos": 147, "type": "DATASET", "confidence": 0.8413055340449015}]}, {"text": "CamRest is a human-human dialog dataset, collected using the Wiz-of-Oz framework, also aimed at restaurant reservation.", "labels": [], "entities": [{"text": "CamRest", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9140615463256836}, {"text": "restaurant reservation", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.693382665514946}]}, {"text": "It is typically used to evaluate traditional slot filling systems.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.8504290580749512}]}, {"text": "In order to make it suitable for end-to-end learning, we stripped the handcrafted state representations and annotations in each dialog, and divided the 676 available dialogs into train, validation, and test sets (406, 135, and 135 dialogs, respectively).", "labels": [], "entities": []}, {"text": "Stanford Multi-Domain Dataset (SMD) is another human-human dialog dataset collected using the Wiz-of-Oz framework.", "labels": [], "entities": [{"text": "Stanford Multi-Domain Dataset (SMD)", "start_pos": 0, "end_pos": 35, "type": "DATASET", "confidence": 0.8512443800767263}]}, {"text": "Each conversation is between a driver and an in-car assistant.", "labels": [], "entities": []}, {"text": "The other datasets consist of dialogs from just one domain (restaurant reservation), whereas SMD consists of dialogs from multiple domains (calendar scheduling, weather information retrieval, and navigation).", "labels": [], "entities": [{"text": "SMD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9680123329162598}, {"text": "weather information retrieval", "start_pos": 161, "end_pos": 190, "type": "TASK", "confidence": 0.7136537432670593}]}, {"text": "We evaluate BOSSNET and other models based on their ability to generate valid responses.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.4889054298400879}]}, {"text": "The per-response accuracy is the percentage of generated responses that exactly match their respective gold response.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9030118584632874}]}, {"text": "The per-dialog accuracy is the percentage of dialogs with all correctly generated responses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.8554022908210754}]}, {"text": "These accuracy metrics area good measure for evaluating datasets with boilerplate responses such as bAbI.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9984563589096069}]}, {"text": "To quantify performance on other datasets, we use BLEU () and Entity F1 (Eric and Manning, 2017) scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9986993074417114}, {"text": "Entity F1", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.8876483738422394}]}, {"text": "BLEU measures the overlap of n-grams between the generated response and its gold response and has become a popular measure to compare task-oriented dialog systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.983026921749115}, {"text": "overlap", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9546694755554199}]}, {"text": "Entity F1 is computed by micro-F1 over KB entities in the entire set of gold responses.", "labels": [], "entities": [{"text": "Entity F1", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9220542311668396}]}, {"text": "We use two human evaluation experiments to compare (1) the usefulness of a generated response with respect to solving the given task, and (2) the grammatical correctness and fluency of the responses on a 0-3 scale.", "labels": [], "entities": []}, {"text": "We obtain human annotations by creating Human Intelligence Tasks (HITs) on Amazon Mechanical Turk (AMT).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 75, "end_pos": 103, "type": "DATASET", "confidence": 0.9396553933620453}]}, {"text": "For each test condition (percentage of unseen entities), we sampled 50 dialogs from Camrest and SMD each, and two AMT workers labeled each system response for both experiments, resulting in 200 labels per condition per dataset per system.", "labels": [], "entities": [{"text": "Camrest", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.9713313579559326}, {"text": "SMD", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.7156020998954773}]}, {"text": "We evaluate four systems in this study, leading to a total of 1600 labels per condition.", "labels": [], "entities": []}, {"text": "The detailed setup is given in the Appendix.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.674684464931488}]}, {"text": "Our experiments evaluate three research questions.", "labels": [], "entities": []}, {"text": "1. Performance Study: How well is BOSSNET able to perform the tasks of our three datasets as compared to the baseline models?", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.5039901733398438}]}, {"text": "2. Disentanglement Study: How robust are the models in generalizing on the KA test sets?", "labels": [], "entities": [{"text": "KA test sets", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.8262322942415873}]}, {"text": "3. Ablation Study: What is the performance gain from each novel feature in BOSSNET?", "labels": [], "entities": [{"text": "Ablation", "start_pos": 3, "end_pos": 11, "type": "METRIC", "confidence": 0.9898871779441833}, {"text": "BOSSNET", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.739822506904602}]}, {"text": "reports the per-response and per-dialog (in parentheses) accuracies on the bAbI dialog tasks.", "labels": [], "entities": []}, {"text": "The multi-hop retrieval-based models such as QRN, MN and GMN perform well on the non-OOV test sets for tasks 1, 2, and 5, but fail to exhibit similar performance on the corresponding OOV test sets.", "labels": [], "entities": [{"text": "OOV test sets", "start_pos": 183, "end_pos": 196, "type": "DATASET", "confidence": 0.7860219577948252}]}, {"text": "This result is expected as these models are trained to retrieve from a pre-defined set of responses.", "labels": [], "entities": []}, {"text": "Their poor non-OOV performance on tasks 3 and 4 is attributed to an error in the bAbI dataset construction, due to which, the non-OOV and OOV test conditions are the same for these tasks (see.", "labels": [], "entities": [{"text": "bAbI dataset construction", "start_pos": 81, "end_pos": 106, "type": "DATASET", "confidence": 0.7958645125230154}]}, {"text": "A simple generative model (Seq2Seq) achieves accuracies comparable to the multi-hop retrieval models.", "labels": [], "entities": []}, {"text": "Enabling it with the ability to copy from the context (Seq2Seq+Copy) shows a considerable increase in performance, especially on the OOV test sets (and non-OOV tests for tasks 3 and 4).", "labels": [], "entities": [{"text": "OOV test sets", "start_pos": 133, "end_pos": 146, "type": "DATASET", "confidence": 0.9086247086524963}]}, {"text": "We qualitatively compare the performance of BOSSNET with other baselines using examples., demonstrates the ability of BOSSNET to copy entities (restaurant name and address) in its response.", "labels": [], "entities": []}, {"text": "The other baselines either generate unwanted or irrelevant entities in their response, or fail to copy altogether.", "labels": [], "entities": []}, {"text": "BOSSNET also best captures the language model effectively with a slight paraphrasing of the gold response.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6995025873184204}]}, {"text": "This example highlights the shortcomings of the Seq2Seq model as it ends up predicting a restaurant encountered during training.", "labels": [], "entities": []}, {"text": "Mem2Seq copies a restaurant name without learning to sort the restaurants based on rating.", "labels": [], "entities": [{"text": "Mem2Seq", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9210178852081299}]}, {"text": "BOSSNET, with its efficient memory addressing, is seen to be able to solve both issues.", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7588691711425781}]}, {"text": "The KB entities present in validation and non-OOV test sets for task 3 and 4 do not overlap with those in the train set.", "labels": [], "entities": []}, {"text": "This effectively means that non-OOV and OOV test conditions are the same for tasks 3 and 4.", "labels": [], "entities": [{"text": "OOV", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.8764747381210327}]}, {"text": "This explains the low performance of baseline models on task 3 and 4 non-OOV test sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Per-response and per-dialog accuracies (in brackets) on bAbI dialog tasks of BOSSNET and baselines", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.866303026676178}]}, {"text": " Table 2: Performance of BOSSNET and baselines on  the CamRest and SMD datasets", "labels": [], "entities": [{"text": "BOSSNET", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9693236351013184}, {"text": "CamRest and SMD datasets", "start_pos": 55, "end_pos": 79, "type": "DATASET", "confidence": 0.7637314349412918}]}, {"text": " Table 3: AMT Evaluations on CamRest and SMD", "labels": [], "entities": [{"text": "AMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7982235550880432}, {"text": "CamRest", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9244629144668579}, {"text": "SMD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9537414312362671}]}, {"text": " Table 5: AMT Evaluations on CamRest and SMD (50%  unseen) KA datasets", "labels": [], "entities": [{"text": "AMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7155478596687317}, {"text": "CamRest", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9251478314399719}, {"text": "SMD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.929402232170105}, {"text": "KA datasets", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.754563182592392}]}, {"text": " Table 6: Ablation study: impact of each model element on BOSSNET", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9961516261100769}, {"text": "BOSSNET", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.6238470077514648}]}, {"text": " Table 9: The hyperparameters used to train BOSSNET on the different datasets", "labels": [], "entities": []}, {"text": " Table 13: Example from SMD with 50% OOV. The OOV entity present in the dialog is {pittsburgh}", "labels": [], "entities": [{"text": "SMD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.973099946975708}, {"text": "OOV", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9542778134346008}]}, {"text": " Table 14: Ablation study: impact of hops in BOSSNET encoder", "labels": [], "entities": [{"text": "Ablation", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9962013363838196}, {"text": "BOSSNET encoder", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.8948939144611359}]}]}