{"title": [{"text": "Understanding Learning Dynamics Of Language Models with SVCCA", "labels": [], "entities": [{"text": "SVCCA", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.9319925904273987}]}], "abstractContent": [{"text": "Research has shown that neural models implicitly encode linguistic features, but there has been no research showing how these en-codings arise as the models are trained.", "labels": [], "entities": []}, {"text": "We present the first study on the learning dynamics of neural language models, using a simple and flexible analysis method called Singular Vector Canonical Correlation Analysis (SVCCA), which enables us to compare learned representations across time and across models, without the need to evaluate directly on annotated data.", "labels": [], "entities": []}, {"text": "We probe the evolution of syntactic, semantic, and topic representations and find that part-of-speech is learned earlier than topic; that recurrent layers become more similar to those of a tagger during training; and embedding layers less similar.", "labels": [], "entities": []}, {"text": "Our results and methods could inform better learning algorithms for NLP models, possibly to incorporate linguistic information more effectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "Large neural networks have a notorious capacity to memorize training data (, but their high accuracy on many NLP tasks shows that they nonetheless generalize.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9972202777862549}]}, {"text": "One apparent explanation for their performance is that they learn linguistic generalizations even without explicit supervision for those generalizations-for example, that subject and verb number agree in English (; that derivational suffixes attach to only specific parts of speech; and that short segments of speech form natural clusters corresponding to phonemes.", "labels": [], "entities": []}, {"text": "These studies tell us that neural models learn to implicitly represent linguistic categories and their interactions.", "labels": [], "entities": []}, {"text": "But how do they learn these representations?", "labels": [], "entities": []}, {"text": "One clue comes from the inspection of multilayer models, which seem to encode lexical categories in lower layers, and more contextual categories in higher layers.", "labels": [], "entities": []}, {"text": "For example, found that a word's part of speech (POS) is encoded by lower layers, and the POS of its syntactic parent is encoded by higher layers; while found that POS is encoded by lower layers and semantic category is encoded by higher layers.", "labels": [], "entities": []}, {"text": "More generally, the most useful layer for an arbitrary NLP task seems to depend on how \"high-level\" the task is ().", "labels": [], "entities": []}, {"text": "Since we know that lower layers in a multi-layer model converge to their final representations more quickly than higher layers (, it is likely that models learn local lexical categories like POS earlier than they learn higher-level linguistic categories like semantic class.", "labels": [], "entities": []}, {"text": "How and when do neural representations come to encode specific linguistic categories?", "labels": [], "entities": []}, {"text": "Answers could explain why neural models work and help us improve learning algorithms.", "labels": [], "entities": []}, {"text": "We investigate how representations of linguistic structure are learned overtime in neural language models (LMs), which are central to NLP: on their own, they are used to produce contextual representations of words for many tasks (e.g.); while conditional LMs power machine translation, speech recognition, and dialogue systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 286, "end_pos": 304, "type": "TASK", "confidence": 0.7166351974010468}]}, {"text": "We use a simple and flexible method, Singular Vector Canonical Correlation Analysis (SVCCA;, which allows us to compare representations from our LM at each epoch of training with representations of other models trained to predict specific linguistic categories.", "labels": [], "entities": [{"text": "Singular Vector Canonical Correlation Analysis", "start_pos": 37, "end_pos": 83, "type": "TASK", "confidence": 0.6220681309700012}]}, {"text": "We discover that lower layers initially discover features shared by all predictive models, but lose these features as the LM explores more specific clusters.", "labels": [], "entities": []}, {"text": "We demonstrate that different aspects of linguistic structure are learned at different rates within a single recurrent layer, acquiring POS tags early but continuing to learn global topic information later in training.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained our LM on a corpus of tokenized, lowercased English Wikipedia (70/10/20 train/dev/test split).", "labels": [], "entities": []}, {"text": "To reduce the number of unique words in the corpus, we excluded any sentence with a word type appearing fewer than 100 times.", "labels": [], "entities": []}, {"text": "Words appearing fewer than 100 times in the resulting training set are replaced with an unknown token.", "labels": [], "entities": []}, {"text": "The resulting training set has over 227 million tokens of 20K types.", "labels": [], "entities": []}, {"text": "We train for 50 epochs to maximize crossentropy, using a batch size of 40, dropout ratio of 0.2, and sequence length of 35.", "labels": [], "entities": [{"text": "sequence length", "start_pos": 101, "end_pos": 116, "type": "METRIC", "confidence": 0.873263031244278}]}, {"text": "The optimizer is standard SGD with clipped gradients at 0.25, Language model  A benefit of SVCCA is its flexibility: it can compute the correlation of a hidden representation to any other vector.", "labels": [], "entities": []}, {"text": "used it to understand learning dynamics by comparing a learned representation to snapshots of the same representation at different epochs during training.", "labels": [], "entities": []}, {"text": "We use a similar experiment to establish the basic learning dynamics of our model.", "labels": [], "entities": []}, {"text": "In our shallow 2-level model, activations at h 1 converge slightly after h 2).", "labels": [], "entities": []}, {"text": "This differs from the results of, who found that a 5-layer stacked LSTM LM exhibits faster convergence at lower layers, but this difference maybe attributed to our much larger training data, which gives our model sufficient training data at early epochs.", "labels": [], "entities": []}, {"text": "Our main experiments will test the rate at which different linguistic categories are learned by different layers, but to interpret the results, we need to understand the behaviour of SVCCA for these models.", "labels": [], "entities": []}, {"text": "In theory, SVCCA scores can vary from 0 for no correlation to 1 for perfect correlation.", "labels": [], "entities": []}, {"text": "But in practice, these extreme cases will not occur.", "labels": [], "entities": []}, {"text": "To establish an empirical upper bound on correlation, we compared the similarity at each epoch of training to the frozen final state of a LM with identical architecture but different initialization, trained on the same data ().", "labels": [], "entities": []}, {"text": "The correlations increase overtime as expected, but to a maximum near 0.64; we don't expect correlations between our LM and other models to exceed this value.", "labels": [], "entities": []}, {"text": "We explore corresponding lower bounds in our main experiments below.", "labels": [], "entities": []}, {"text": "Next we examine the correlation between different layers of the same model overtime ().", "labels": [], "entities": []}, {"text": "We observe that, while overtime correlation increases, in general closer layers are more similar, and they are less correlated than they are with the same layer of a differently initialized model.", "labels": [], "entities": [{"text": "overtime correlation", "start_pos": 23, "end_pos": 43, "type": "METRIC", "confidence": 0.9169830977916718}]}, {"text": "This supports the idea that we should compare recurrent layers with recurrent layers because their representations play similar roles within their respective architectures.: Tag predictor and tagger statistics.", "labels": [], "entities": [{"text": "Tag predictor", "start_pos": 174, "end_pos": 187, "type": "TASK", "confidence": 0.7655158340930939}]}, {"text": "Accuracy and perplexity on t + 1 are from the target tag predictor, on tare from the input tagger.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9633949995040894}]}, {"text": "Metrics obtained when training on randomly shuffled labels are provided as a low baseline.", "labels": [], "entities": [{"text": "Metrics", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.967125654220581}]}, {"text": "Accuracy is on the test set from the training domain (GMB or Wikipedia).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9833706617355347}, {"text": "GMB or Wikipedia)", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.8281495273113251}]}, {"text": "But if a diagnostic classifier is trained on enough examples, then random embeddings as input representations often outperform any pretrained intermediate representation.", "labels": [], "entities": []}, {"text": "This suggests that diagnostic classifiers may work simply by memorizing the association between an embedding and the most frequent output category associated with that embedding; since for many words their category is (empirically) unambiguous, this may give an inflated view of just how much a model \"understands\" about that category.", "labels": [], "entities": []}, {"text": "Our use of SVCCA below will differ from the use of diagnostic classifiers in an important way.", "labels": [], "entities": []}, {"text": "Diagnostic classifiers use the intermediate representations of the LM as inputs to a tagger.", "labels": [], "entities": []}, {"text": "A representation is claimed to encode, for example, POS if the classifier accurately predicts it-in other words, whether it can decode it from the representation.", "labels": [], "entities": []}, {"text": "We will instead evaluate the similarity between the representations in an LM and in an independently-trained tagger.", "labels": [], "entities": []}, {"text": "The intuition behind this is that, if the representation of our LM encodes a particular category, then it must be similar to the representation of model that is specifically trained to predict that category.", "labels": [], "entities": []}, {"text": "A benefit of the approach is that similarity can be evaluated on any dataset, not only one that has been labeled with the linguis- tic categories of interest.", "labels": [], "entities": [{"text": "similarity", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9427167773246765}]}, {"text": "Another distinction from the typical use of diagnostic classifiers is that probes are usually used to decode tag information about the context or most recent input from the hidden state at the current step.", "labels": [], "entities": []}, {"text": "Because the hidden representation at time t is meant to encode predictive information about the target word at time t+1, we treat it as encoding a prediction about the tag of the target word.", "labels": [], "entities": []}, {"text": "To understand the empirical strengths and weaknesses of these approaches, we compare the use of SVCCA and diagnostic classifiers in understanding learning dynamics.", "labels": [], "entities": []}, {"text": "In other words, we ask: is our first conceptual shift (to SVCCA) necessary?", "labels": [], "entities": []}, {"text": "To test this, we use the same model as, which classifies an arbitrary representation using a ReLU followed by a softmax layer.", "labels": [], "entities": []}, {"text": "To be consistent with, we use y t as their target label.", "labels": [], "entities": []}, {"text": "We repeat their method in this manner () as well as applying our second modification, in which we instead target the label y t+1.", "labels": [], "entities": []}, {"text": "We found the correlations to be relatively stable over the course of training.", "labels": [], "entities": []}, {"text": "This is at odds with the results in, which suggest that representations change substantially during training in ways that materially affect the accuracy of the LM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9989216327667236}]}, {"text": "This suggests that diagnostic classifiers are not illustrating improvements in word representations throughout training, and we conclude that they are ineffective for understanding learning dynamics.", "labels": [], "entities": []}, {"text": "Our remaining experiments use only SVCCA.", "labels": [], "entities": [{"text": "SVCCA", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.9344748854637146}]}], "tableCaptions": [{"text": " Table 2: Tag predictor and tagger statistics. Accuracy and perplexity on t + 1 are from the target tag predictor,  on t are from the input tagger. Metrics obtained when training on randomly shuffled labels are provided as a low  baseline. Accuracy is on the test set from the training domain (GMB or Wikipedia).", "labels": [], "entities": [{"text": "Tag predictor", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.6934812963008881}, {"text": "Accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9946704506874084}, {"text": "Accuracy", "start_pos": 240, "end_pos": 248, "type": "METRIC", "confidence": 0.9988137483596802}, {"text": "GMB or Wikipedia)", "start_pos": 294, "end_pos": 311, "type": "DATASET", "confidence": 0.8445286154747009}]}]}