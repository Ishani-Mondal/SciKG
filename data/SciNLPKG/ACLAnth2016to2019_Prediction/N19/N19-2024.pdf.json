{"title": [{"text": "Neural Text Normalization with Subword Units", "labels": [], "entities": [{"text": "Neural Text Normalization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8122142752011617}]}], "abstractContent": [{"text": "Text normalization (TN) is an important step in conversational systems.", "labels": [], "entities": [{"text": "Text normalization (TN)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.849286288022995}]}, {"text": "It converts written text to its spoken form to facilitate speech recognition, natural language understanding and text-to-speech synthesis.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7373334467411041}, {"text": "natural language understanding", "start_pos": 78, "end_pos": 108, "type": "TASK", "confidence": 0.6695138911406199}, {"text": "text-to-speech synthesis", "start_pos": 113, "end_pos": 137, "type": "TASK", "confidence": 0.7223458141088486}]}, {"text": "Finite state transducers (FSTs) are commonly used to build grammars that handle text normalization (Sproat, 1996; Roark et al., 2012).", "labels": [], "entities": [{"text": "Finite state transducers (FSTs)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6936598271131516}, {"text": "text normalization", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7266075164079666}]}, {"text": "However, translating linguistic knowledge into grammars requires extensive effort.", "labels": [], "entities": [{"text": "translating linguistic knowledge", "start_pos": 9, "end_pos": 41, "type": "TASK", "confidence": 0.883401095867157}]}, {"text": "In this paper, we frame TN as a machine translation task and tackle it with sequence-to-sequence (seq2seq) models.", "labels": [], "entities": [{"text": "TN", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9784755706787109}, {"text": "machine translation task", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.7257059812545776}]}, {"text": "Previous research focuses on normalizing a word (or phrase) with the help of limited word-level context, while our approach directly normalizes full sentences.", "labels": [], "entities": [{"text": "normalizing a word (or phrase)", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.8129919937678746}]}, {"text": "We find subword models with additional linguistic features yield the best performance (with a word error rate of 0.17%).", "labels": [], "entities": [{"text": "word error rate", "start_pos": 94, "end_pos": 109, "type": "METRIC", "confidence": 0.8249578873316447}]}], "introductionContent": [{"text": "Non-standard words (NSWs) include expressions such as time or date (e.g., 4:58AM, 08-02, 8/2/2018), abbreviations (e.g., ft.) and letter sequences (e.g., IBM, DL) ().", "labels": [], "entities": []}, {"text": "They commonly appear in written texts such as websites, books and movie scripts.", "labels": [], "entities": []}, {"text": "Written form of non-standard words can be normalized/verbalized to a spoken form, e.g., \"August second\".", "labels": [], "entities": []}, {"text": "Although there is no incentive for human users to transcribe NSWs into spoken form, it plays an integral role in spoken dialog systems.", "labels": [], "entities": []}, {"text": "As shown in, automatic speech recognition (ASR), natural language understanding (NLU) and textto-speech synthesis (TTS) components all involve written-to-spoken form normalization or its inverse process, spoken-to-written text normalization (ITN).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.8124233782291412}, {"text": "natural language understanding (NLU)", "start_pos": 49, "end_pos": 85, "type": "TASK", "confidence": 0.812887837489446}, {"text": "textto-speech synthesis (TTS)", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.8085231244564056}, {"text": "spoken-to-written text normalization (ITN)", "start_pos": 204, "end_pos": 246, "type": "TASK", "confidence": 0.787977953751882}]}, {"text": "ASR normalizes the training corpus before building its language model.", "labels": [], "entities": [{"text": "ASR normalizes", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.929812490940094}]}, {"text": "Among many benefits, such a model can reduce the size of the required vocabulary and address data sparsity issues.", "labels": [], "entities": []}, {"text": "NLU might adopt ITN to recover the written text from ASR in run-time (e.g., \"five pm \" \u2192 \"5:00PM\").", "labels": [], "entities": [{"text": "NLU", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9680678248405457}]}, {"text": "In text-to-speech synthesis, for example, in order to pronounce \"221B Baker St\", TTS needs to first convert the text to \"two twenty one b baker street\" and then generate the audio signal.", "labels": [], "entities": [{"text": "text-to-speech synthesis", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.7299684137105942}, {"text": "221B Baker St\"", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.6943157389760017}]}, {"text": "Normalizing the written form text to its spoken form is difficult due to the following bottlenecks: 1.", "labels": [], "entities": []}, {"text": "Lack of supervision -there is no incentive for people to produce spoken form text.", "labels": [], "entities": []}, {"text": "Thus, it is hard to obtain a supervised dataset for training machine learning models; 2.", "labels": [], "entities": []}, {"text": "Ambiguity -for written text, a change in context may require a different normalization.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9545013308525085}]}, {"text": "For example, \"2/3\" can be verbalized as a date or fraction depending on the meaning of the sentence.", "labels": [], "entities": []}, {"text": "Traditionally, the task of NSW normalization has been approached by manually authoring grammars in the form of finite-state transducers) such as integer grammars (e.g., \"26\" \u2192 \"twenty six\") or time grammars (e.g., \"5:26\" \u2192 \"five twenty six\").", "labels": [], "entities": [{"text": "NSW normalization", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.9688394367694855}]}, {"text": "Constructing such grammars is time consuming and error-prone and requires extensive linguistic knowledge and programming proficiency.", "labels": [], "entities": []}, {"text": "Recently, with the rise of machine learning and especially deep learning techniques, researchers are starting to bring more data-driven approaches to this field.", "labels": [], "entities": []}, {"text": "In this paper, we present our approach to nonstandard text normalization via machine translation techniques, where the source and target are written and spoken form text, respectively.", "labels": [], "entities": [{"text": "nonstandard text normalization", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6542446613311768}, {"text": "machine translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7150940299034119}]}], "datasetContent": [{"text": "The data for the window-based seq2seq model and full sentence seq2seq were generated from the publicly available release of parallel written/speech formatted text from Sproat and Jaitly.", "labels": [], "entities": []}, {"text": "The set consists of Wikipedia text which was processed through Google TTS's Kestrel text normalization system relying primarily on handcrafted rules to produce speech-formatted text.", "labels": [], "entities": [{"text": "Kestrel text normalization", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.6560390194257101}]}, {"text": "Although a large parallel dataset is available for English, we consider the feasibility of developing neural models for other languages which may not have text normalization systems in place.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.6933188289403915}]}, {"text": "Therefore, we choose to scale the training data size to a limited set of text which could be generated by annotators in a reasonable time frame.", "labels": [], "entities": []}, {"text": "As summarized in, both window-based and sentencebased models are trained with 500K training instances.", "labels": [], "entities": []}, {"text": "Our datasets were randomly sampled from a set of 4.9M sentences in the training data portion of the Sproat and Jaitly (2016) data release and split into training, validation, and test data.", "labels": [], "entities": [{"text": "Sproat and Jaitly (2016) data release", "start_pos": 100, "end_pos": 137, "type": "DATASET", "confidence": 0.8363601788878441}]}, {"text": "However, the training data for window-based and sentencebased models are not identical due to differences in input configurations.", "labels": [], "entities": []}, {"text": "While the window-based model uses 500K randomly sampled windows, the sentence-based models use 500K sentences.", "labels": [], "entities": []}, {"text": "For testing, 62.5K identical test sentences are used across all models.", "labels": [], "entities": []}, {"text": "In order to decode sentences with the window-based model, sentences are first segmented into windows before inference.", "labels": [], "entities": []}, {"text": "Among 16 edit labels available in the dataset release, we found the normalization target for: Size of training, validation, and test datasets.", "labels": [], "entities": []}, {"text": "For the window-baseline, the data are pairs of windows and the normalization of the central piece of the window.", "labels": [], "entities": []}, {"text": "For the sent-baseline and subword models, the data are pairs of sentences but in different formats -sent-baseline: (character sequence, word sequence); subword: (subword sequence, subword sequence).", "labels": [], "entities": []}, {"text": "All models are evaluated on the same set of 62.5K sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performance of different subword inventory  sizes on validation set.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of models on test set.", "labels": [], "entities": []}, {"text": " Table 5. Severe errors are shown in the first two  rows. While these types of errors are infrequent,  they change or obscure the meaning of the utter-", "labels": [], "entities": []}]}