{"title": [{"text": "What a neural language model tells us about spatial relations", "labels": [], "entities": []}], "abstractContent": [{"text": "Understanding and generating spatial descriptions requires knowledge about what objects are related, their functional interactions, and where the objects are geometrically located.", "labels": [], "entities": []}, {"text": "Different spatial relations have different functional and geometric bias.", "labels": [], "entities": []}, {"text": "The wide usage of neural language models in different areas including generation of image description motivates the study of what kind of knowledge is encoded in neural language models about individual spatial relations.", "labels": [], "entities": [{"text": "generation of image description", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.7446810752153397}]}, {"text": "With the premise that the functional bias of relations is expressed in their word distributions, we construct multi-word distributional vector representations and show that these representations perform well on intrinsic semantic reasoning tasks, thus confirming our premise.", "labels": [], "entities": []}, {"text": "A comparison of our vector representations to human semantic judgments indicates that different bias (functional or geometric) is captured in different data collection tasks which suggests that the contribution of the two meaning modalities is dynamic, related to the context of the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spatial descriptions such as \"the chair is to the left of the table\" contain spatial relations \"to the left of\" the semantic representations of which must be grounded in visual representations in terms of geometry.", "labels": [], "entities": []}, {"text": "The apprehension of spatial relations in terms of scene geometry has been investigated through acceptability scores of human judges over possible locations of objects (.", "labels": [], "entities": []}, {"text": "In addition, other research has pointed out that there is an interplay between geometry and object-specific function in the apprehension of spatial relations).", "labels": [], "entities": []}, {"text": "Therefore, spatial descriptions must be grounded in two kinds of knowledge (.", "labels": [], "entities": []}, {"text": "One kind of knowledge is referential meaning, expressed in the geometry of scenes (geometric knowledge or where objects are) while the other kind of knowledge is higher-level conceptual world knowledge about interactions between objects which is not directly grounded in perceivable situations but is learned through our experience of situations in the world (functional knowledge or what objects are related).", "labels": [], "entities": []}, {"text": "Furthermore, argue that individual relations have a particular geometric and functional bias and \"under\" and \"over\" are more functionally-biased than \"below\" and \"above\".", "labels": [], "entities": []}, {"text": "For instance, when describing the relation between a person and an umbrella in a scene with a textual context such as \"an umbrella a person\", \"above\" is associated with stricter geometric properties compared to \"over\" which covers a more object-specific extra-geometric sense between the target and the landmark (i.e. covering or protecting in this case).", "labels": [], "entities": []}, {"text": "Of course, there will be several configurations of objects that could be described either with \"over\" or \"above\" which indicates that the choice of a description is determined by the speaker, in particular what aspect of meaning they want to emphasise.", "labels": [], "entities": []}, {"text": "consider this bias for prepositions that are geometrically similar and therefore the functional knowledge is reflected in different preferences for objects that are related.", "labels": [], "entities": []}, {"text": "However, such functional differences also exist between geometrically different relations.", "labels": [], "entities": []}, {"text": "This poses two interesting research questions for computational modelling of spatial language.", "labels": [], "entities": []}, {"text": "The first one is how both kinds of knowledge interact with individual spatial relations and how models of spatial language can be constructed and learned within end-to-end deep learning paradigm.", "labels": [], "entities": []}, {"text": "compare the performance of classifiers using different multi-modal features (visual, geometric and textual) to predict a spatial preposition.", "labels": [], "entities": []}, {"text": "applies semantic similarity metrics of spatial relations on geo-graphical data retrieval.", "labels": [], "entities": []}, {"text": "show that word embeddings can be used as predictive features for commonsense knowledge about location of objects in 2D images.", "labels": [], "entities": []}, {"text": "The second question is related to the extraction of functional knowledge for applications such as generation of spatial descriptions in a robot scenario.", "labels": [], "entities": [{"text": "generation of spatial descriptions in a robot scenario", "start_pos": 98, "end_pos": 152, "type": "TASK", "confidence": 0.784740723669529}]}, {"text": "Typically, a robot will not be able to observe all object interactions as in ) to learn about the interaction of objects and choose the appropriate relation.", "labels": [], "entities": []}, {"text": "Following the intuition that the functional bias of spatial relations is reflected in a greater selectivity for their target and landmark objects,) propose that the degree of association between relations and objects in the corpus of image descriptions can be used as filters for selecting the most applicable relation fora pair of objects.", "labels": [], "entities": []}, {"text": "They also demonstrate that entropy-based analysis of the targets and landmarks can identify the functional and geometric bias of spatial relations.", "labels": [], "entities": []}, {"text": "They use descriptions from a corpus of image descriptions because here the prepositions in spatial relations are used mainly in the spatial sense.", "labels": [], "entities": []}, {"text": "The same investigation of textual corpora such as BNC does not yield such results as there prepositions are used mainly in their nonspatial sense.", "labels": [], "entities": [{"text": "BNC", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.7322059869766235}]}, {"text": "1 Similarly, inspect the perplexity of recurrent language models for different descriptions containing spatial relations in the Visual Genome dataset of image captions () in order to investigate their bias for objects.", "labels": [], "entities": [{"text": "Visual Genome dataset", "start_pos": 128, "end_pos": 149, "type": "DATASET", "confidence": 0.6401281257470449}]}, {"text": "In this paper, we follow this line of work and (i) further investigate what semantics about spatial relations are captured from descriptions of images by generative recurrent neural language models, and (ii) whether such knowledge can be extracted, for example as vector representations, and evaluated in tests.", "labels": [], "entities": []}, {"text": "The neural embeddings are opaque to interpretations per se.", "labels": [], "entities": []}, {"text": "The benefit of using recurrent language models is that they allow us to (i) deal with spatial relations as multi-word expressions and (ii) they learn their representations within their contexts: (a) a cat on a mat (b) a cat on the top of a mat (c) a mat under a cat We may call this metaphoric or highly functional usage which is completely absent of the geometric dimension.", "labels": [], "entities": []}, {"text": "In (a) and (b), the textual contexts are the same \"a cat a mat\" but the meaning of the spatial relations, one of which is a multi-word expression, are slightly different.", "labels": [], "entities": []}, {"text": "In (c) the context is made different through word order.", "labels": [], "entities": []}, {"text": "The question of what knowledge (functional or geometric) should be represented in the models can be explained in information-theoretic terms.", "labels": [], "entities": []}, {"text": "The low surprisal of a textual language model on anew text corpora is an indication that the model has encoded the same information content as the text.", "labels": [], "entities": []}, {"text": "In the absence of the geometric knowledge during the training of the model, this means that a language model encodes the relevant functional knowledge.", "labels": [], "entities": []}, {"text": "We will show that the degree to which each spatial description containing a spatial relation encodes functional knowledge in different contexts can be used as source for building distributional representations.", "labels": [], "entities": []}, {"text": "We evaluate these representations intrinsically in reasoning tests and extrinsically against human performance and human judgment.", "labels": [], "entities": []}, {"text": "The contributions of this paper are: This paper is organised as follows: in Section 2 we describe how we create distributional representations with recurrent neural language models, in Section 3 we describe our computational implementations that build these representations, and in Section 4 we provide their evaluation.", "labels": [], "entities": []}, {"text": "In Section 5 we give our final remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "As stated in Section 2 the P-vectors we have built are intended to capture the discriminatory power of a generative language model to encode and discriminate different spatial relations, their functional bias.", "labels": [], "entities": []}, {"text": "In this section we evaluate the Pvectors on several common intrinsic and extrinsic tests for vectors.", "labels": [], "entities": [{"text": "Pvectors", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.964661180973053}]}, {"text": "If successful, this demonstrates that such knowledge has indeed been captured by the language model.", "labels": [], "entities": []}, {"text": "We evaluate both single-and multi-word relations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The accuracies of different representations on  the word analogy test.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.7124201357364655}]}, {"text": " Table 4: The accuracies in odd-one-out tests.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9950716495513916}]}, {"text": " Table 5: Spearman's \u03c1 between pairwise lists of simi- larities. WA are similarities based on word associations  and WS are direct word similarities from human judg- ments.", "labels": [], "entities": [{"text": "WA", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9915059208869934}]}]}