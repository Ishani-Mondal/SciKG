{"title": [{"text": "Understanding language-elicited EEG data by predicting it from a fine-tuned language model", "labels": [], "entities": []}], "abstractContent": [{"text": "Electroencephalography (EEG) recordings of brain activity taken while participants read or listen to language are widely used within the cognitive neuroscience and psycholinguistics communities as a tool to study language comprehension.", "labels": [], "entities": []}, {"text": "Several time-locked stereotyped EEG responses to word-presentations-known collectively as event-related potentials (ERPs)-are thought to be markers for semantic or syntactic processes that take place during comprehension.", "labels": [], "entities": []}, {"text": "However, the characterization of each individual ERP in terms of what features of a stream of language trigger the response remains controversial.", "labels": [], "entities": []}, {"text": "Improving this characterization would make ERPs a more useful tool for studying language comprehension.", "labels": [], "entities": []}, {"text": "We take a step towards better understanding the ERPs by fine-tuning a language model to predict them.", "labels": [], "entities": []}, {"text": "This new approach to analysis shows for the first time that all of the ERPs are predictable from embeddings of a stream of language.", "labels": [], "entities": []}, {"text": "Prior work has only found two of the ERPs to be predictable.", "labels": [], "entities": []}, {"text": "In addition to this analysis, we examine which ERPs benefit from sharing parameters during joint training.", "labels": [], "entities": []}, {"text": "We find that two pairs of ERPs previously identified in the literature as being related to each other benefit from joint training, while several other pairs of ERPs that benefit from joint training are suggestive of potential relationships.", "labels": [], "entities": []}, {"text": "Extensions of this analysis that further examine what kinds of information in the model embeddings relate to each ERP have the potential to elucidate the processes involved inhuman language comprehension.", "labels": [], "entities": []}], "introductionContent": [{"text": "The cognitive processes involved inhuman language comprehension are complex and only partially identified.", "labels": [], "entities": []}, {"text": "According to the dual-stream model of speech comprehension, sound waves are first converted to).", "labels": [], "entities": []}, {"text": "The bottom portion of the figure shows a top-down schematic of the electrode locations with the nose facing towards the top of the page.", "labels": [], "entities": []}, {"text": "Each ERP is the mean potential from all of the indicated electrodes during a specific time-window, creating a single scalar value per ERP per word.", "labels": [], "entities": []}, {"text": "Overlapping circles indicate multiple ERPs recorded from the same electrode.", "labels": [], "entities": []}, {"text": "The ELAN is measured from 125-175ms after stimulus onset, the LAN from 300-400ms, the N400 from 300ms-500ms, the EPNP from 400-600ms, the P600 from 500-700ms, and the PNP from 600-700ms.", "labels": [], "entities": [{"text": "ELAN", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9399696588516235}]}, {"text": "phoneme-like features and further processed by a ventral stream that maps those features onto words and semantic structures, and a dorsal stream that (among other things) supports audio-short term memory.", "labels": [], "entities": []}, {"text": "The mapping of words onto meaning is thought to be subserved by widely distributed regions of the brain that specialize in particular modalities -for example visual aspects of the word banana reside in the occipital lobe of the brain and are activated when the word banana is heard) -and the different representation modalities are thought to be integrated into a single coherent latent representation in the anterior temporal lobe (.", "labels": [], "entities": []}, {"text": "While this part of meaning representation inhuman language comprehension is somewhat understood, much less is known about how the meanings of words are integrated together to form the meaning of sentences and discourses.", "labels": [], "entities": []}, {"text": "One tool researchers use to study the integration of meaning across words is electroencephelography (EEG), which measures the electrical activity of large numbers of neurons acting in concert.", "labels": [], "entities": [{"text": "integration of meaning across words", "start_pos": 38, "end_pos": 73, "type": "TASK", "confidence": 0.8506968259811402}]}, {"text": "EEG has the temporal resolution necessary to study the processes involved in meaning integration, and certain stereotyped electrical responses to word presentations, known as event-related potentials (ERPs), have been identified with some of the processes thought to contribute to comprehension.", "labels": [], "entities": [{"text": "meaning integration", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7706125676631927}]}, {"text": "In this work, we consider six ERP components that have been associated in the cognitive neuroscience and psycholinguistics literature with language processing and which we analyze in the data from (see for spatial and temporal definitions of these ERP components).", "labels": [], "entities": []}, {"text": "Three of these -the N400, EPNP, and PNP responses -are primarily considered markers for semantic processing, while the other three -the P600, ELAN, and LAN responses -are primarily considered markers for syntactic processing.", "labels": [], "entities": []}, {"text": "However, the neat division of the ERP responses into either semantic or syntactic categories is controversial.", "labels": [], "entities": []}, {"text": "The N400 response has been very well studied (for an overview see) and it is well established that it is associated with semantic complexity, but the features of language that trigger the other ERP responses we consider here are poorly understood.", "labels": [], "entities": []}, {"text": "We propose to use a neural network pretrained as a language model to probe what features of language drive these ERP responses, and in turn to probe what features of language mediate the cognitive processes that underlie human language comprehension, and especially the integration of meaning across words.", "labels": [], "entities": [{"text": "integration of meaning across words", "start_pos": 270, "end_pos": 305, "type": "TASK", "confidence": 0.8005111694335938}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Proportion of variance explained (POVE) for each of the ERP components (mean of 100 training runs).  The second column in each cell shows which ERP components in addition to the target ERP component were  included in training. All combinations of training signals were explored. Shown is the best combination for each  ERP target as well as every combination which is (i) significantly different from training on the target component  alone, (ii) not significantly different from the best training combination, and (iii) uses no more than the number  of signals used by the best combination. The N400 is predicted best when only the N400 signal is included in  training. All values are significantly different from 0. GROUP A refers to (PNP, ELAN, LAN, P600) and GROUP  B refers to (EPNP, ELAN, LAN, P600).", "labels": [], "entities": [{"text": "POVE)", "start_pos": 44, "end_pos": 49, "type": "METRIC", "confidence": 0.9779064953327179}, {"text": "GROUP A", "start_pos": 728, "end_pos": 735, "type": "METRIC", "confidence": 0.9808771014213562}, {"text": "GROUP  B", "start_pos": 773, "end_pos": 781, "type": "METRIC", "confidence": 0.9870966076850891}]}, {"text": " Table 2: Proportion of variance explained (POVE) for each of the ERP components (mean of 100 training runs).  +ERP indicates the best combination of ERP training signals for the target ERP component, + READ indicates the  inclusion of self-paced reading times, +EYE indicates the inclusion of eye-tracking data, and bold font indicates a  significant difference from training on the target component alone.", "labels": [], "entities": [{"text": "Proportion of variance explained (POVE)", "start_pos": 10, "end_pos": 49, "type": "METRIC", "confidence": 0.8540782758167812}, {"text": "READ", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.9964382648468018}, {"text": "EYE", "start_pos": 263, "end_pos": 266, "type": "METRIC", "confidence": 0.9936825037002563}]}, {"text": " Table 3: Proportion of variance explained for each of the ERP components when using only the forward direction  of the encoder (mean of 100 training runs). +ERP indicates the best combination of ERP training signals for the  target ERP component, + READ indicates the inclusion of self-paced reading times, +EYE indicates the inclusion  of eye-tracking data, and bold font indicates a significant difference from training on the target component alone.", "labels": [], "entities": [{"text": "READ", "start_pos": 250, "end_pos": 254, "type": "METRIC", "confidence": 0.9966078996658325}, {"text": "EYE", "start_pos": 309, "end_pos": 312, "type": "METRIC", "confidence": 0.9945989847183228}]}, {"text": " Table 4: Proportion of variance explained for each of the ERP components when using only the word embeddings  as input to the decoder and bypassing the LSTM entirely (mean of 100 training runs). +ERP indicates the best  combination of ERP training signals for the target ERP component, + READ indicates the inclusion of self-paced  reading times, +EYE indicates the inclusion of eye-tracking data, and bold font indicates a significant difference  from training on the target component alone.", "labels": [], "entities": [{"text": "READ", "start_pos": 289, "end_pos": 293, "type": "METRIC", "confidence": 0.9959906935691833}, {"text": "EYE", "start_pos": 349, "end_pos": 352, "type": "METRIC", "confidence": 0.9938610792160034}]}, {"text": " Table 5: Raw Pearson's correlation coefficients (computed on content words after the standardization and  participant-averaging) between each neural and behavioral measure and each other measure. FIX indicates first- fixation time, PASS indicates first-pass time, GO indicates go-past time, RIGHT indicates right-bounded reading  time, and READ indicates self-paced reading. Many of the measures are highly correlated, but the pattern of cor- relations is different from the pattern of benefits that we find during joint-training. In particular we note that the  N400 is correlated with the other ERP signals, and yet we do not see benefit in prediction of the N400 when jointly  training a model to predict it and other signals.", "labels": [], "entities": [{"text": "FIX", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.9979221224784851}, {"text": "first- fixation time", "start_pos": 211, "end_pos": 231, "type": "METRIC", "confidence": 0.8513796478509903}, {"text": "PASS indicates first-pass time", "start_pos": 233, "end_pos": 263, "type": "METRIC", "confidence": 0.8086977899074554}, {"text": "GO indicates go-past time", "start_pos": 265, "end_pos": 290, "type": "METRIC", "confidence": 0.8816514164209366}, {"text": "RIGHT indicates right-bounded reading  time", "start_pos": 292, "end_pos": 335, "type": "METRIC", "confidence": 0.7633195042610168}, {"text": "READ", "start_pos": 341, "end_pos": 345, "type": "METRIC", "confidence": 0.9937688112258911}]}]}