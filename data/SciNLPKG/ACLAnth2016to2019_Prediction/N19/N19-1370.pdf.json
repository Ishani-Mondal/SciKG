{"title": [{"text": "Document-Level N -ary Relation Extraction with Multiscale Representation Learning", "labels": [], "entities": [{"text": "Document-Level N -ary Relation Extraction", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5701720068852106}]}], "abstractContent": [{"text": "Most information extraction methods focus on binary relations expressed within single sentences.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.8215588331222534}]}, {"text": "In high-value domains, however, n-ary relations are of great demand (e.g., drug-gene-mutation interactions in precision oncology).", "labels": [], "entities": []}, {"text": "Such relations often involve entity mentions that are far apart in the document, yet existing work on cross-sentence relation extraction is generally confined to small text spans (e.g., three consecutive sentences), which severely limits recall.", "labels": [], "entities": [{"text": "cross-sentence relation extraction", "start_pos": 102, "end_pos": 136, "type": "TASK", "confidence": 0.7864300608634949}, {"text": "recall", "start_pos": 238, "end_pos": 244, "type": "METRIC", "confidence": 0.9850837588310242}]}, {"text": "In this paper, we propose a novel multiscale neural architecture for document-level n-ary relation extraction.", "labels": [], "entities": [{"text": "document-level n-ary relation extraction", "start_pos": 69, "end_pos": 109, "type": "TASK", "confidence": 0.6206620559096336}]}, {"text": "Our system combines representations learned over various text spans throughout the document and across the subrelation hierarchy.", "labels": [], "entities": []}, {"text": "Widening the sys-tem's purview to the entire document maximizes potential recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9983044862747192}]}, {"text": "Moreover, by integrating weak signals across the document, multi-scale modeling increases precision, even in the presence of noisy labels from distant supervision.", "labels": [], "entities": [{"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9988728165626526}]}, {"text": "Experiments on biomedical machine reading show that our approach substantially outperforms previous n-ary relation extraction methods.", "labels": [], "entities": [{"text": "biomedical machine reading", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.6301943063735962}, {"text": "n-ary relation extraction", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.7125606536865234}]}], "introductionContent": [{"text": "Knowledge acquisition is a perennial challenge in AI.", "labels": [], "entities": [{"text": "Knowledge acquisition", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8104662001132965}]}, {"text": "In high-value domains, it has acquired new urgency in recent years due to the advent of big data.", "labels": [], "entities": []}, {"text": "For example, the dramatic drop in genome sequencing cost has created unprecedented opportunities for tailoring cancer treatment to a tumor's genetic composition.", "labels": [], "entities": [{"text": "genome sequencing", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.6381804496049881}]}, {"text": "Despite this potential, operationalizing personalized medicine is difficult, in part because it requires painstaking curation of precision oncology knowledge from biomedical literature.", "labels": [], "entities": [{"text": "operationalizing personalized medicine", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.8682013948758444}]}, {"text": "With tens of millions of papers on PubMed, and thousands more added every * Work done as an intern at Microsoft Research.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.9617213606834412}]}, {"text": "\"We next expressed ALK F1174L, ALK F1174L/L1198P, ALK F1174L/G1123S, and ALK F1174L/G1123D in the original SH-SY5Y cell line.\"", "labels": [], "entities": [{"text": "SH-SY5Y cell line", "start_pos": 107, "end_pos": 124, "type": "DATASET", "confidence": 0.7727658748626709}]}, {"text": "15 sentences spanning 3 paragraphs . .", "labels": [], "entities": []}, {"text": ") \"The 2 mutations that were only found in the neuroblastoma resistance screen (G1123S/D) are located in the glycine-rich loop, which is known to be crucial for ATP and ligand binding and are the first mutations described that induce resistance to TAE684, but not to PF02341066.\" day, we are sorely in need of automated methods to accelerate manual curation.", "labels": [], "entities": [{"text": "neuroblastoma resistance", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.6739214360713959}]}, {"text": "Prior work in machine reading has made great strides in sentence-level binary relation extraction.", "labels": [], "entities": [{"text": "machine reading", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7613042891025543}, {"text": "sentence-level binary relation extraction", "start_pos": 56, "end_pos": 97, "type": "TASK", "confidence": 0.6624957174062729}]}, {"text": "However, generalizing extraction to n-ary relations poses new challenges.", "labels": [], "entities": []}, {"text": "Higher-order relations often involve entity mentions that are faraway in the document.", "labels": [], "entities": []}, {"text": "Recent work on n-ary relation extraction has begun to explore cross-sentence extraction (, but the scope is still confined to short text spans (e.g., three consecutive sentences), even though a document may contain hundreds of sentences and tens of thousands of words.", "labels": [], "entities": [{"text": "n-ary relation extraction", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6160852213700613}, {"text": "cross-sentence extraction", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.8551844358444214}]}, {"text": "While this already increases the yield compared to sentencelevel extraction, it still misses many relations.", "labels": [], "entities": [{"text": "sentencelevel extraction", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.8022469282150269}]}, {"text": "For example, in, the drug-gene-mutation relations between PF02341066, ALK, G1123S(D) (PF02341066 can treat cancers with mutation G1123S(D) in gene ALK) can only be extracted by substantially expanding the scope.", "labels": [], "entities": []}, {"text": "High-value information, such as latest medical findings, might only be mentioned once in the corpus.", "labels": [], "entities": []}, {"text": "Maximiz-ing recall is thus of paramount importance.", "labels": [], "entities": [{"text": "Maximiz-ing", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9562642574310303}, {"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9038115739822388}]}, {"text": "In this paper, we propose a novel multiscale neural architecture for document-level n-ary relation extraction.", "labels": [], "entities": [{"text": "document-level n-ary relation extraction", "start_pos": 69, "end_pos": 109, "type": "TASK", "confidence": 0.6206620559096336}]}, {"text": "By expanding extraction scope to the entire document, rather than restricting relation candidates to co-occurring entities in a short text span, we ensure maximum potential recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9964795708656311}]}, {"text": "To combat the ensuing difficulties in document-level extraction, such as low precision, we introduce multiscale learning, which combines representations learned over text spans of varying scales and for various subrelations).", "labels": [], "entities": [{"text": "document-level extraction", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.7772352695465088}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9936886429786682}]}, {"text": "This approach deviates from past methods in several key regards.", "labels": [], "entities": []}, {"text": "First, we adopt an entity-centric formulation by making a single prediction for each entity tuple occurring in a document.", "labels": [], "entities": []}, {"text": "Previous n-ary relation extraction methods typically classify individual mention tuples, but this approach scales poorly to whole documents.", "labels": [], "entities": [{"text": "n-ary relation extraction", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.6497705479462942}]}, {"text": "Since each entity can be mentioned many times in the same document, applying mention-level methods leads to a combinatorial explosion of mention tuples.", "labels": [], "entities": []}, {"text": "This creates not only computational challenges but also learning challenges, as the vast majority of these tuples do not express the relation.", "labels": [], "entities": []}, {"text": "Our entity-centric formulation alleviates both of these problems.", "labels": [], "entities": []}, {"text": "Second, for each candidate tuple, prior methods typically take as input the contiguous text span encompassing the mentions.", "labels": [], "entities": []}, {"text": "For document-level extraction, the resulting text span could become untenably large, even though most of it is unrelated to the relation of interest.", "labels": [], "entities": [{"text": "document-level extraction", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7595825791358948}]}, {"text": "Instead, we allow discontiguous input formed by multiple discourse units (e.g., sentence or paragraph) containing the given entity mentions.", "labels": [], "entities": []}, {"text": "Finally, while an n-ary relation might not reside within a discourse unit, its subrelations might.", "labels": [], "entities": []}, {"text": "In, the paper first mentions a gene-mutation subrelation, then discusses a drug-mutation subrelation in a later paragraph.", "labels": [], "entities": []}, {"text": "By including subrelations in our modeling, we can predict n-ary relations even when all n entities never co-occur in the same discourse unit.", "labels": [], "entities": []}, {"text": "With multiscale learning, we turn the document view from a challenge into an advantage by combining weak signals across text spans and subrelations.", "labels": [], "entities": []}, {"text": "Following recent work in cross-sentence relation extraction, we conduct thorough evaluation in biomedical machine reading.", "labels": [], "entities": [{"text": "cross-sentence relation extraction", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.8375539580980936}, {"text": "biomedical machine reading", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.7049299279848734}]}, {"text": "Our approach substantially outperforms prior n-ary relation extraction methods, attaining state-of-the-art results on a large benchmark dataset recently released by a major cancer center.", "labels": [], "entities": [{"text": "n-ary relation extraction", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6623238126436869}]}, {"text": "Ablation studies show that multiscale modeling is the key to these gains.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of our training corpus using PMC- OA articles and distant supervision from CIVIC,  GDKD, and OncoKB. \"Text Units\" refers to the num- ber of distinct sentences, paragraphs, and documents  that contain a candidate triple of drug, gene, mutation.", "labels": [], "entities": [{"text": "PMC- OA articles", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.6886720657348633}, {"text": "CIVIC", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.9691222906112671}, {"text": "GDKD", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.8580175638198853}]}, {"text": " Table 2: Statistics of the CKB evaluation corpus.", "labels": [], "entities": [{"text": "CKB evaluation corpus", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.8813695112864176}]}, {"text": " Table 3: Comparison of our multiscale system with restricted variants and DPL (Wang and Poon, 2018) on CKB.", "labels": [], "entities": [{"text": "DPL", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.957313597202301}, {"text": "CKB", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.9726961851119995}]}, {"text": " Table 4: Results on CKB when removing either  SENTLEVEL, PARALEVEL, or DOCLEVEL from the  ensemble computed by MULTISCALE. MR=max re- call, P=precision, R=recall.", "labels": [], "entities": [{"text": "SENTLEVEL", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9962432384490967}, {"text": "PARALEVEL", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9818666577339172}, {"text": "MULTISCALE", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.6432036757469177}, {"text": "MR", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9984356760978699}, {"text": "max re- call", "start_pos": 127, "end_pos": 139, "type": "METRIC", "confidence": 0.9041618853807449}, {"text": "precision", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.9949144124984741}, {"text": "R", "start_pos": 154, "end_pos": 155, "type": "METRIC", "confidence": 0.9615914225578308}, {"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.9810001850128174}]}, {"text": " Table 5: Results on CKB after replacing logsumexp  with max (with noisy-or and gene-mutation filter).  P=precision, R=recall. Max recall same as in", "labels": [], "entities": [{"text": "CKB", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.8447672724723816}, {"text": "P", "start_pos": 104, "end_pos": 105, "type": "METRIC", "confidence": 0.9657992720603943}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9853696823120117}, {"text": "R", "start_pos": 117, "end_pos": 118, "type": "METRIC", "confidence": 0.9598818421363831}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9882965683937073}, {"text": "Max", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.953665554523468}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.8225982189178467}]}]}