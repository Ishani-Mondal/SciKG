{"title": [{"text": "Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data", "labels": [], "entities": [{"text": "Improving Grammatical Error Correction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.9197008013725281}]}], "abstractContent": [{"text": "Neural machine translation systems have become state-of-the-art approaches for Grammatical Error Correction (GEC) task.", "labels": [], "entities": [{"text": "Neural machine translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7246374289194742}, {"text": "Grammatical Error Correction (GEC) task", "start_pos": 79, "end_pos": 118, "type": "TASK", "confidence": 0.7300544508865902}]}, {"text": "In this paper, we propose a copy-augmented architecture for the GEC task by copying the unchanged words from the source sentence to the target sentence.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 64, "end_pos": 72, "type": "TASK", "confidence": 0.8640588819980621}]}, {"text": "Since the GEC suffers from not having enough labeled training data to achieve high accuracy.", "labels": [], "entities": [{"text": "GEC", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.8838961124420166}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9978471994400024}]}, {"text": "We pre-train the copy-augmented architecture with a denoising auto-encoder using the unlabeled One Billion Benchmark and make comparisons between the fully pre-trained model and a partially pre-trained model.", "labels": [], "entities": []}, {"text": "It is the first time copying words from the source context and fully pre-training a sequence to sequence model are experimented on the GEC task.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 135, "end_pos": 143, "type": "TASK", "confidence": 0.5795059502124786}]}, {"text": "Moreover, We add token-level and sentence-level multi-task learning for the GEC task.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 76, "end_pos": 84, "type": "TASK", "confidence": 0.5954038500785828}]}, {"text": "The evaluation results on the CoNLL-2014 test set show that our approach outperforms all recently published state-of-the-art results by a large margin.", "labels": [], "entities": [{"text": "CoNLL-2014 test set", "start_pos": 30, "end_pos": 49, "type": "DATASET", "confidence": 0.9595940510431925}]}, {"text": "The code and pre-trained models are released at https://github.com/zhawe01/fairseq-gec.", "labels": [], "entities": []}], "introductionContent": [{"text": "Grammatical Error Correction (GEC) is a task of detecting and correcting grammatical errors in text.", "labels": [], "entities": [{"text": "Grammatical Error Correction (GEC)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8109580278396606}, {"text": "detecting and correcting grammatical errors in text", "start_pos": 48, "end_pos": 99, "type": "TASK", "confidence": 0.7264063613755363}]}, {"text": "Due to the growing number of language learners of English, there has been increasing attention to the English GEC, in the past decade.", "labels": [], "entities": [{"text": "English GEC", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.6664671301841736}]}, {"text": "The following sentence is an example of the GEC task, where the word in bold needs to be corrected to its adverb form.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 44, "end_pos": 52, "type": "TASK", "confidence": 0.8561911880970001}]}, {"text": "Nothing is [absolute \u2192 absolutely] right or wrong.", "labels": [], "entities": []}, {"text": "Although machine translation systems have become state-of-the-art approaches for GEC, GEC is different from translation since it only changes several words of the source sentence.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7252135723829269}, {"text": "GEC", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9404795169830322}]}, {"text": "In we list the ratio of unchanged words of the target sentence to the source sentence in three different datasets.", "labels": [], "entities": []}, {"text": "We can observe that more than 80% of the words can be copied from the source sentence.", "labels": [], "entities": []}, {"text": "Considering the percentage of unchanged words is high in the GEC task, a more proper neural architecture is needed for it.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 61, "end_pos": 69, "type": "TASK", "confidence": 0.8739002048969269}]}, {"text": "We enhance the current neural architecture by enabling it to copy the unchanged words and the out-of-vocabulary words directly from the source sentence, just as what humans do when they correct sentences.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first time that neural copying mechanism is used on GEC.", "labels": [], "entities": [{"text": "GEC", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.8545095920562744}]}, {"text": "Progresses have been made thanks to largescale training corpus, including NUS Corpus of Learner English (NUCLE) ( and the large-scale Lang-8 corpus().", "labels": [], "entities": [{"text": "NUS Corpus of Learner English (NUCLE)", "start_pos": 74, "end_pos": 111, "type": "DATASET", "confidence": 0.9537617787718773}, {"text": "Lang-8 corpus", "start_pos": 134, "end_pos": 147, "type": "DATASET", "confidence": 0.9177599847316742}]}, {"text": "However, even with millions of labeled sentences, automatic GEC is challenging due to the lack of enough labeled training data to achieve high accuracy.", "labels": [], "entities": [{"text": "GEC", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.8345069289207458}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9912911653518677}]}, {"text": "To alleviate the problem of insufficient labeled data, we propose a method to leverage the unlabeled data.", "labels": [], "entities": []}, {"text": "The concrete way is to pre-train our copy-augmented model with the unlabeled One Billion Benchmark () by leveraging denoising auto-encoders.", "labels": [], "entities": []}, {"text": "We also add two multi-tasks for the copyaugmented architecture, including a token-level labeling task and a sentence-level copying task, to further improve the performance of the GEC task.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 179, "end_pos": 187, "type": "TASK", "confidence": 0.6418407559394836}]}, {"text": "The copying mechanism is for the first time used on the GEC task, which was used on text summarization tasks.", "labels": [], "entities": [{"text": "copying", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9753130674362183}, {"text": "GEC task", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.7877444326877594}, {"text": "text summarization tasks", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8522069652875265}]}, {"text": "On the GEC task, copying mechanism enables training a model with a small vocabulary since it can straightly copy the unchanged and out-of-vocabulary words from the source input tokens.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 7, "end_pos": 15, "type": "TASK", "confidence": 0.4884178787469864}, {"text": "copying", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9606906771659851}]}, {"text": "Besides, by separating the constant part of the work from the GEC task, copying makes the generating portion of the architecture more powerful.", "labels": [], "entities": [{"text": "GEC", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8080856800079346}, {"text": "copying", "start_pos": 72, "end_pos": 79, "type": "TASK", "confidence": 0.9566271305084229}]}, {"text": "In the experiment section of this paper, we show that copying does more than just solving the \"UNK problem\", and it can also recall more edits for the GEC problem.", "labels": [], "entities": [{"text": "copying", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9811288118362427}, {"text": "UNK", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.7187181711196899}, {"text": "GEC problem", "start_pos": 151, "end_pos": 162, "type": "TASK", "confidence": 0.5969258546829224}]}, {"text": "The copy-augmented architecture outperforms all the other architectures on the GEC task, by achieving a 56.42 F 0.5 score on the CoNLL 2014 test data set.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.83393794298172}, {"text": "F 0.5 score", "start_pos": 110, "end_pos": 121, "type": "METRIC", "confidence": 0.9337781071662903}, {"text": "CoNLL 2014 test data set", "start_pos": 129, "end_pos": 153, "type": "DATASET", "confidence": 0.9667230844497681}]}, {"text": "Combined with denoising auto-encoders and multi-tasks, our architecture achieves 61.15 F 0.5 on the CoNLL-2014 test data set, improving +4.9 F 0.5 score than state-of-the-art systems.", "labels": [], "entities": [{"text": "F 0.5", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.9360944628715515}, {"text": "CoNLL-2014 test data set", "start_pos": 100, "end_pos": 124, "type": "DATASET", "confidence": 0.9814677387475967}, {"text": "F 0.5 score", "start_pos": 141, "end_pos": 152, "type": "METRIC", "confidence": 0.9478393991788229}]}, {"text": "In summary, our main contributions are as follows.", "labels": [], "entities": []}, {"text": "We propose a more proper neural architecture for the GEC problem, which enables copying the unchanged words and out-ofvocabulary words directly from the source input tokens.", "labels": [], "entities": [{"text": "GEC problem", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.8364110589027405}]}, {"text": "(2) We pre-train the copy-augmented model with large-scale unlabeled data using denoising auto-encoders, alleviating the problem of the insufficient labeled training corpus.", "labels": [], "entities": []}, {"text": "(3) We evaluate the architecture on the CoNLL-2014 test set, which shows that our approach outperforms all recently published state-of-the-art approaches by a large margin.", "labels": [], "entities": [{"text": "CoNLL-2014 test set", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.9770475625991821}]}], "datasetContent": [{"text": "As previous studies, we use the public NUCLE (   To make our results comparable to state-of-theart results in the field of GEC, we limit our training data strictly to public resources.", "labels": [], "entities": []}, {"text": "list all the data sets that we use in this paper.", "labels": [], "entities": []}, {"text": "We build a statistical-based spell error correction system and correct the spell errors in our training data. and etc., we apply spell correction before evaluation for our dev/test datasets.", "labels": [], "entities": [{"text": "spell error correction", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.5799509684244791}]}, {"text": "A 50,000-word dictionary is extracted from the spell-corrected Lang-8 data corpus.", "labels": [], "entities": [{"text": "Lang-8 data corpus", "start_pos": 63, "end_pos": 81, "type": "DATASET", "confidence": 0.8969172040621439}]}, {"text": "Like previous works, we remove the unchanged sentence pairs in the Lang-8 corpus before training.", "labels": [], "entities": [{"text": "Lang-8 corpus", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.9001734852790833}]}, {"text": "We compare our results with the well-known GEC systems, as shown in.", "labels": [], "entities": [{"text": "GEC", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.899689257144928}]}, {"text": "Rule, classification, statistical machine translation (SMT), and neural machine translation (NMT) based systems were built for the GEC task.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.7794529348611832}, {"text": "GEC task", "start_pos": 131, "end_pos": 139, "type": "TASK", "confidence": 0.7752127945423126}]}, {"text": "We list the well-known models on the top section of and our results in the middle.", "labels": [], "entities": []}, {"text": "Almost all the previous systems reranked their top 12 results using a big language model and some of them used partially pretrained parameters, which improve their results by 1.5 to 5 F 0.5 score.", "labels": [], "entities": []}, {"text": "Our copy-augmented architecture achieve a 56.42 F 0.5 score on the CoNLL-2014 dataset and outperforms all the previous architectures even without reranking or pre-training.", "labels": [], "entities": [{"text": "CoNLL-2014 dataset", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.9747481942176819}]}, {"text": "Combined with denoising auto-encoders and multi-tasks, our model achieve a 61.15 F 0.5 score on the CoNLL-2014 data set.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9233997464179993}, {"text": "CoNLL-2014 data set", "start_pos": 100, "end_pos": 119, "type": "DATASET", "confidence": 0.9772068460782369}]}, {"text": "This result exceeds the previous state-of-the-art system +4.9 F 0.5 points.", "labels": [], "entities": []}, {"text": "In the bottom section of, we list the results of.", "labels": [], "entities": []}, {"text": "No direct comparison can be made between us, because they used the non-public Cambridge Learner Corpus (CLC) and their own collected nonpublic Lang-8 corpus, making their labeled training data set 3.6 times larger than ours.", "labels": [], "entities": [{"text": "Cambridge Learner Corpus (CLC)", "start_pos": 78, "end_pos": 108, "type": "DATASET", "confidence": 0.9530659218629202}, {"text": "Lang-8 corpus", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.8495848774909973}]}, {"text": "Even so, our results on the CoNLL 2014 test data set and JFLEG test data set are very close to theirs.", "labels": [], "entities": [{"text": "CoNLL 2014 test data set", "start_pos": 28, "end_pos": 52, "type": "DATASET", "confidence": 0.9749426007270813}, {"text": "JFLEG test data set", "start_pos": 57, "end_pos": 76, "type": "DATASET", "confidence": 0.9671262353658676}]}, {"text": "In, \"SMT (with LM)\" refers to  \"SMT Rule-Based Hybird\" refers to); \"SMT Classification Hybird\" refers to; \"Neural Hybird MT\" refers to (; \"CNN + EO\" refers to and \"EO\" means rerank with edit-operation features; \"Transformer + MIMs\" refers to  and \"MIMs\" means model indepent methods; \"NMT SMT Hybrid\" refers to (Grundkiewicz and Junczys-Dowmunt, 2018); \"CNN + FB Learning\" refers to (Ge et al., 2018).", "labels": [], "entities": [{"text": "SMT", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9518156051635742}, {"text": "SMT Rule-Based Hybird", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.8129143913586935}, {"text": "NMT SMT", "start_pos": 285, "end_pos": 292, "type": "TASK", "confidence": 0.4314735680818558}, {"text": "CNN + FB Learning", "start_pos": 354, "end_pos": 371, "type": "DATASET", "confidence": 0.7973800450563431}]}], "tableCaptions": [{"text": " Table 1: The ratio of unchanged words in the target  sentence to the source sentence. \"Sent.\" means the  sentence number. \"Tok.\" means the token number of  the target sentence. \"Same %\" means the same word  percentage.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of GEC systems on CoNLL-2014 and JFLEG test set. The M 2 score for CoNLL-2014 test  dataset and the GLEU for the JFLEG test set are reported. DA refers to the \"Denoising Auto-encoder\". (with LM)  refers to the usage of an extra language model. (4 ens.) refers to the ensemble decoding of 4 independently trained  models. We re-rank the results of the top 12 hypothesizes for the JFLEG test set with an extra language model and  marked them with  *  .", "labels": [], "entities": [{"text": "JFLEG test set", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.9396057724952698}, {"text": "M 2 score", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9286009669303894}, {"text": "CoNLL-2014 test  dataset", "start_pos": 88, "end_pos": 112, "type": "DATASET", "confidence": 0.930294911066691}, {"text": "GLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9983474016189575}, {"text": "JFLEG test set", "start_pos": 134, "end_pos": 148, "type": "DATASET", "confidence": 0.9282235304514567}, {"text": "JFLEG test set", "start_pos": 400, "end_pos": 414, "type": "DATASET", "confidence": 0.8762402931849161}]}, {"text": " Table 5: Single Model Ablation Study on CoNLL 2014 Test Data Set.", "labels": [], "entities": [{"text": "CoNLL 2014 Test Data Set", "start_pos": 41, "end_pos": 65, "type": "DATASET", "confidence": 0.961880362033844}]}, {"text": " Table 6:  Denoising Auto-encoder's Results on  CoNLL-2014 Test Data Set.", "labels": [], "entities": [{"text": "CoNLL-2014 Test Data Set", "start_pos": 48, "end_pos": 72, "type": "DATASET", "confidence": 0.9630770236253738}]}, {"text": " Table 7: Recall on Different Error Types. % is the  percentage of this error type in the test data set. Recall  is the percentage of the fixed errors in each error type.", "labels": [], "entities": [{"text": "Recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9991329312324524}]}]}