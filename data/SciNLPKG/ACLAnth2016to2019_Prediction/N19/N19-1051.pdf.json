{"title": [{"text": "Outlier Detection for Improved Data Quality and Diversity in Dialog Systems", "labels": [], "entities": [{"text": "Outlier Detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7751527428627014}]}], "abstractContent": [{"text": "Ina corpus of data, outliers are either errors: mistakes in the data that are counterproduc-tive, or are unique: informative samples that improve model robustness.", "labels": [], "entities": []}, {"text": "Identifying out-liers can lead to better datasets by (1) removing noise in datasets and (2) guiding collection of additional data to fill gaps.", "labels": [], "entities": []}, {"text": "However, the problem of detecting both outlier types has received relatively little attention in NLP, particularly for dialog systems.", "labels": [], "entities": []}, {"text": "We introduce a simple and effective technique for detecting both erroneous and unique samples in a corpus of short texts using neural sentence embeddings combined with distance-based outlier detection.", "labels": [], "entities": []}, {"text": "We also present a novel data collection pipeline built atop our detection technique to automatically and iteratively mine unique data samples while discarding erroneous samples.", "labels": [], "entities": []}, {"text": "Experiments show that our outlier detection technique is effective at finding errors while our data collection pipeline yields highly diverse corpora that in turn produce more robust intent classification and slot-filling models.", "labels": [], "entities": [{"text": "outlier detection", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7709093689918518}, {"text": "intent classification", "start_pos": 183, "end_pos": 204, "type": "TASK", "confidence": 0.7031811773777008}]}], "introductionContent": [{"text": "High-quality annotated data is one of the fundamental drivers of progress in Natural Language Processing (e.g..", "labels": [], "entities": []}, {"text": "In order to be effective at producing an accurate and robust model, a dataset needs to be correct while also diverse enough to cover the full range of ways in which the phenomena it targets occur.", "labels": [], "entities": []}, {"text": "Substantial research effort has considered dataset correctness, particularly for crowdsourcing (, but addressing diversity in data has received less attention, with the exception of using data from diverse domains ().", "labels": [], "entities": [{"text": "dataset correctness", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7618829905986786}]}, {"text": "Outlier detection, the task of finding examples in a dataset that are atypical, provides a means of approaching the questions of correctness and diversity, but has mainly been studied at the document level (, whereas texts in dialog systems are often no more than a few sentences in length.", "labels": [], "entities": [{"text": "Outlier detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8127195239067078}]}, {"text": "We propose a novel approach that uses sentence embeddings to detect outliers in a corpus of short texts.", "labels": [], "entities": []}, {"text": "We rank samples based on their distance from the mean embedding of the corpus and consider samples farthest from the mean outliers.", "labels": [], "entities": []}, {"text": "Outliers come in two varieties: (1) errors, sentences that have been mislabeled whose inclusion in the dataset would be detrimental to model performance, and (2) unique samples, sentences that differ in structure or content from most in the data and whose inclusion would be helpful for model robustness.", "labels": [], "entities": []}, {"text": "Building upon this approach, we propose a novel crowdsourcing pipeline that distinguishes errors from unique samples and uses the unique samples to guide workers to give more diverse samples.", "labels": [], "entities": []}, {"text": "Experimentally, we find that our outlier detection technique leads to efficient detection of both artificial and real errors in our datasets.", "labels": [], "entities": []}, {"text": "We also use the proposed crowdsourcing pipeline to collect new datasets and build models for the dialog system tasks of intent classification and slot-filling.", "labels": [], "entities": [{"text": "intent classification", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.7660549879074097}]}, {"text": "We find that the proposed pipeline produces more diverse data, which in turn results in models that are more robust.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform two sets of experiments to probe the effectiveness of our outlier detection method.", "labels": [], "entities": [{"text": "outlier detection", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7443469762802124}]}, {"text": "First, we consider error detection, comparing various ranking methods in artificial and real data scenarios.", "labels": [], "entities": [{"text": "error detection", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.6753250062465668}]}, {"text": "Second, we use our uniqueness-driven pipeline to collect data, measuring the impact on data diversity and model robustness.", "labels": [], "entities": []}, {"text": "All experiments were conducted on English language data.", "labels": [], "entities": []}, {"text": "We consider several different metrics to probe how effectively our proposed pipeline improves data quality.", "labels": [], "entities": []}, {"text": "In all cases, higher values are better.", "labels": [], "entities": []}, {"text": "Intrinsic We measure the diversity and coverage of each dataset using the metrics introduced in () and shown in.", "labels": [], "entities": []}, {"text": "Extrinsic The main reason to increase dataset diversity is to construct more robust models.", "labels": [], "entities": []}, {"text": "To directly evaluate that objective, we randomly divided the datasets collected by each pipeline into training and test sets (85-15 split).", "labels": [], "entities": []}, {"text": "Our intuition is that a robust model should perform fairly well across all test sets.", "labels": [], "entities": []}, {"text": "Training on a dataset that is not diverse will lead to a brittle model that only does well on data collected with the same seed sentences.", "labels": [], "entities": []}, {"text": "For intent classification, we measure accuracy of two models: an SVM () using bag of words feature representation, and FastText (), a neural network that averages across sentence embeddings and passes the result through feedforward layers.", "labels": [], "entities": [{"text": "intent classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8542642891407013}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9992942810058594}]}, {"text": "For slot-filling, we measure the F 1 -score of a bi-directional LSTM with word vectors that are trained, but initialized with GloVe 300-dimensional embeddings.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9867981374263763}]}, {"text": "For all models, we average results across 10 runs.: Classifier accuracy when training on one dataset and testing on another (top and middle), and coverage of the test set for each training set (bottom).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9952213168144226}, {"text": "coverage", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9938697814941406}]}, {"text": "As expected, the highest scores are when we train and test on the same data, but off the diagonal the unique test set (gray column) is considerably harder for models trained on other data while a model trained on unique performs consistently well.", "labels": [], "entities": []}, {"text": "This accuracy trend is matched in coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9995573163032532}, {"text": "coverage", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9922310709953308}]}], "tableCaptions": [{"text": " Table 1: Outlier detection effectiveness for error detection in an artificial setting (constructed by randomly adding  content from other intents) and a real setting (manually checked utterances from a crowdsourced set). The artificial  results are represented by different values of p (1%, 2%, 4%, and 8%), where p represents different amounts of  errors injected into each intent class. Our proposed neural methods are consistently more effective, reducing the  manual effort required to identify errors.", "labels": [], "entities": [{"text": "Outlier detection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7985679507255554}, {"text": "error detection", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7685242593288422}]}, {"text": " Table 3: Classification: Diversity scores for data col- lected in each round (top), and the number of samples  collected (bottom). The data for the All column com- bines the previous two sets in the row and the data from  (same round 1). The unique approach produces data  that is considerably higher diversity.", "labels": [], "entities": []}, {"text": " Table 4: Classifier accuracy when training on one  dataset and testing on another (top and middle), and  coverage of the test set for each training set (bottom).  As expected, the highest scores are when we train and  test on the same data, but off the diagonal the unique  test set (gray column) is considerably harder for mod- els trained on other data while a model trained on  unique performs consistently well. This accuracy  trend is matched in coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9914884567260742}, {"text": "coverage", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9882504940032959}, {"text": "accuracy", "start_pos": 422, "end_pos": 430, "type": "METRIC", "confidence": 0.9985888600349426}, {"text": "coverage", "start_pos": 452, "end_pos": 460, "type": "METRIC", "confidence": 0.9955158829689026}]}, {"text": " Table 5: Slot-filling: Diversity scores for data col- lected in each round (top), and the number of samples  collected (bottom). The data for the All column com- bines the previous two sets in the row and the data from  (same Round 1). As seen for intent classification, the  unique approach produces data that is of consider- ably higher diversity.", "labels": [], "entities": [{"text": "intent classification", "start_pos": 249, "end_pos": 270, "type": "TASK", "confidence": 0.8310954868793488}]}, {"text": " Table 6: F 1 -scores and coverage scores for each train- test pair for the slot-filling experiment. Training on the  unique data produces a more robust model, with con- sistently high performance across test sets.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9890038073062897}, {"text": "coverage", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9937561750411987}]}]}