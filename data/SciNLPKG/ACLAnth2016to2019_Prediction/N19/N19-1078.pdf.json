{"title": [{"text": "Pooled Contextualized Embeddings for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7808198730150858}]}], "abstractContent": [{"text": "Contextual string embeddings area recent type of contextualized word embedding that were shown to yield state-of-the-art results when utilized in a range of sequence labeling tasks.", "labels": [], "entities": []}, {"text": "They are based on character-level language models which treat text as distributions over characters and are capable of generating em-beddings for any string of characters within any textual context.", "labels": [], "entities": []}, {"text": "However, such purely character-based approaches struggle to produce meaningful embeddings if a rare string is used in a underspecified context.", "labels": [], "entities": []}, {"text": "To address this drawback, we propose a method in which we dynamically aggregate contextual-ized embeddings of each unique string that we encounter.", "labels": [], "entities": []}, {"text": "We then use a pooling operation to distill a global word representation from all contextualized instances.", "labels": [], "entities": []}, {"text": "We evaluate these pooled contextualized embeddings on common named entity recognition (NER) tasks such as CoNLL-03 and WNUT and show that our approach significantly improves the state-of-the-art for NER.", "labels": [], "entities": [{"text": "common named entity recognition (NER) tasks", "start_pos": 54, "end_pos": 97, "type": "TASK", "confidence": 0.8416809439659119}, {"text": "CoNLL-03", "start_pos": 106, "end_pos": 114, "type": "DATASET", "confidence": 0.8465256094932556}, {"text": "WNUT", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.6868667602539062}]}, {"text": "We make all code and pre-trained models available to the research community for use and reproduction.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings area crucial component in many NLP approaches) since they capture latent semantics of words and thus allow models to better train and generalize.", "labels": [], "entities": []}, {"text": "Recent work has moved away from the original \"one word, one embedding\" paradigm to investigate contextualized embedding models (.", "labels": [], "entities": []}, {"text": "Such approaches produce different embeddings for the same word depending on its context and are thus capable of capturing latent contextualized semantics of ambiguous words.", "labels": [], "entities": []}, {"text": "Recently, proposed a character-level contextualized embeddings ap- context.", "labels": [], "entities": []}, {"text": "This leads to an underspecified contextual word embedding for the string \"Indra\" that ultimately causes a misclassification of \"Indra\" as an organization (ORG) instead of person (PER) in a downstream NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 200, "end_pos": 208, "type": "TASK", "confidence": 0.8917460739612579}]}, {"text": "proach they refer to as contextual string embeddings.", "labels": [], "entities": []}, {"text": "They leverage pre-trained character-level language models from which they extract hidden states at the beginning and end character positions of each word to produce embeddings for any string of characters in a sentential context.", "labels": [], "entities": []}, {"text": "They showed these embeddings to yield state-of-the-art results when utilized in sequence labeling tasks such as named entity recognition (NER) or part-of-speech (PoS) tagging.", "labels": [], "entities": [{"text": "named entity recognition (NER) or part-of-speech (PoS) tagging", "start_pos": 112, "end_pos": 174, "type": "TASK", "confidence": 0.673782783250014}]}, {"text": "However, such contextualized character-level models suffer from an inherent weakness when encountering rare words in an underspecified context.", "labels": [], "entities": []}, {"text": "Consider the example text segment shown in: \"Fung Permadi (Taiwan) v Indra\", from the English CONLL-03 test data split.", "labels": [], "entities": [{"text": "Fung Permadi (Taiwan) v Indra", "start_pos": 45, "end_pos": 74, "type": "DATASET", "confidence": 0.8429334163665771}, {"text": "CONLL-03 test data split", "start_pos": 94, "end_pos": 118, "type": "DATASET", "confidence": 0.8993636071681976}]}, {"text": "If we consider the word \"Indra\" to be rare (meaning no prior occurrence in the corpus used to generate word embeddings), the underspecified context allows this word to be interpreted as either a person or an organization.", "labels": [], "entities": []}, {"text": "This leads to an underspecified embedding that ultimately causes an incorrect classification of \"Indra\" as an organization in a downstream NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 139, "end_pos": 147, "type": "TASK", "confidence": 0.9219875633716583}]}, {"text": "In this paper, we present a simple but effective approach to address this issue.", "labels": [], "entities": []}, {"text": "We intuit that entities are normally only used in underspecified contexts if they are expected to be known to the reader.", "labels": [], "entities": []}, {"text": "That is, they are either more clearly introduced in an earlier sentence, or part of general in-domain knowl-figure2-crop.pdf edge a reader is expected to have.", "labels": [], "entities": []}, {"text": "Indeed, the string \"Indra\" in the CONLL-03 data also occurs in the earlier sentence \"Indra Wijaya (Indonesia) beat Ong Ewe Hock\".", "labels": [], "entities": [{"text": "CONLL-03 data", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9717305898666382}]}, {"text": "Based on this, we propose an approach in which we dynamically aggregate contextualized embeddings of each unique string that we encounter as we process a dataset.", "labels": [], "entities": []}, {"text": "We then use a pooling operation to distill a global word representation from all contextualized instances that we use in combination with the current contextualized representation as new word embedding.", "labels": [], "entities": []}, {"text": "We evaluate our proposed embedding approach on the task of named entity recognition on the CONLL-03 (English, German and Dutch) and WNUT datasets.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.6363001863161722}, {"text": "CONLL-03 (English, German and Dutch) and WNUT datasets", "start_pos": 91, "end_pos": 145, "type": "DATASET", "confidence": 0.8492337465286255}]}, {"text": "In all cases, we find that our approach outperforms previous approaches and yields new state-of-the-art scores.", "labels": [], "entities": []}, {"text": "We contribute our approach and all pre-trained models to the open source FLAIR 1 framework, to ensure reproducibility of these results.", "labels": [], "entities": [{"text": "FLAIR 1 framework", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.8849859436353048}]}], "datasetContent": [{"text": "We verify our proposed approach in four named entity recognition (NER) tasks: We use the English, German and Dutch evaluation setups of the CONLL-03 shared task) to evaluate our approach on classic newswire data, and the WNUT-17 task on emerging entity detection to evaluate our approach in a noisy user-generated data setting with few repeated entity mentions.", "labels": [], "entities": [{"text": "entity recognition (NER)", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.8634940624237061}, {"text": "CONLL-03 shared task", "start_pos": 140, "end_pos": 160, "type": "DATASET", "confidence": 0.824138879776001}, {"text": "emerging entity detection", "start_pos": 237, "end_pos": 262, "type": "TASK", "confidence": 0.6074676513671875}]}, {"text": "We use the open source FLAIR framework in all our experiments.", "labels": [], "entities": [{"text": "FLAIR framework", "start_pos": 23, "end_pos": 38, "type": "DATASET", "confidence": 0.7440492808818817}]}, {"text": "It implements the standard BiLSTM-CRF sequence labeling architecture ( and includes pre-trained contextual string embeddings for many languages.", "labels": [], "entities": [{"text": "BiLSTM-CRF sequence labeling", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.6096527477105459}]}, {"text": "To FLAIR, we add an implementation of our proposed pooled contextualized embeddings.", "labels": [], "entities": [{"text": "FLAIR", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.7012182474136353}]}, {"text": "For our experiments, we follow the training and evaluation procedure outlined in and follow most hyperparameter suggestions as given by the in-depth study presented in.", "labels": [], "entities": []}, {"text": "That is, we use an LSTM with 256 hidden states and one layer), a locked dropout value of 0.5, a word dropout of 0.05, and train using SGD with an annealing rate of 0.5 and a patience of 3.", "labels": [], "entities": [{"text": "patience", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9899194240570068}]}, {"text": "We perform model selection over the learning rate \u2208 {0.01, 0.05, 0.1} and mini-batch size \u2208 {8, 16, 32}, choosing the model with the best F-measure on the validation set.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9620155096054077}]}, {"text": "Following, we then repeat the experiment 5 times with different random seeds, and train using both train and development set, reporting both average performance and standard deviation over these runs on the test set as final performance.", "labels": [], "entities": []}, {"text": "The default setup of recommends contextual string embeddings to be used in combination with standard word embeddings.", "labels": [], "entities": []}, {"text": "We use GLOVE embeddings () for the English tasks and FASTTEXT embeddings () for all newswire tasks.", "labels": [], "entities": [{"text": "GLOVE", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.8693314790725708}, {"text": "FASTTEXT", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.8249852657318115}]}, {"text": "Our baseline are contextual string embeddings without pooling, i.e. the original setup proposed in Akbik et al.", "labels": [], "entities": []}, {"text": "In addition, we list the best reported numbers for the four tasks.", "labels": [], "entities": []}, {"text": "This includes the recent BERT approach using bidirectional transformers by, the semi-supervised multitask learning approach by , the ELMo word-level language modeling approach by, and the best published numbers for WNUT-17 () and German and Dutch CONLL-03 (Lample et al., 2016).", "labels": [], "entities": [{"text": "BERT", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9815752506256104}, {"text": "ELMo word-level language modeling", "start_pos": 133, "end_pos": 166, "type": "TASK", "confidence": 0.5080751031637192}, {"text": "WNUT-17", "start_pos": 215, "end_pos": 222, "type": "DATASET", "confidence": 0.9335108399391174}]}], "tableCaptions": [{"text": " Table 1: Comparative evaluation of proposed approach with different pooling operations (min, max, mean) against current", "labels": [], "entities": []}, {"text": " Table 2: Ablation experiment using contextual string embeddings without word embeddings. We find a more significant", "labels": [], "entities": []}]}