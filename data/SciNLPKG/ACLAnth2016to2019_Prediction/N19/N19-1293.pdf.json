{"title": [{"text": "Predicting Malware Attributes from Cybersecurity Texts", "labels": [], "entities": [{"text": "Predicting Malware Attributes from Cybersecurity Texts", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8832230567932129}]}], "abstractContent": [{"text": "Text analytics is a useful tool for studying mal-ware behavior and tracking emerging threats.", "labels": [], "entities": [{"text": "Text analytics", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7073173820972443}]}, {"text": "The task of automated malware attribute identification based on cybersecurity texts is very challenging due to a large number of malware attribute labels and a small number of training instances.", "labels": [], "entities": [{"text": "automated malware attribute identification", "start_pos": 12, "end_pos": 54, "type": "TASK", "confidence": 0.6329139396548271}]}, {"text": "In this paper, we propose a novel feature learning method to leverage diverse knowledge sources such as small amount of human annotations, unlabeled text and specifications about malware attribute labels.", "labels": [], "entities": []}, {"text": "Our evaluation has demonstrated the effectiveness of our method over the state-of-the-art mal-ware attribute prediction systems.", "labels": [], "entities": [{"text": "mal-ware attribute prediction", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.6656276981035868}]}], "introductionContent": [{"text": "Securing computer systems has become a necessity for both organizations and individuals, as many cyber attacks result in devastating consequences.", "labels": [], "entities": []}, {"text": "An outbreak of the WannaCry ransomware in 2017 affected more than 200,000 computers across 150 countries, with total damages ranging from hundreds of millions to billions of dollars.", "labels": [], "entities": [{"text": "WannaCry ransomware", "start_pos": 19, "end_pos": 38, "type": "DATASET", "confidence": 0.8251996636390686}]}, {"text": "Detection of malware often relies on an understanding of the characteristics of malware behavior.", "labels": [], "entities": [{"text": "Detection of malware", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8768588304519653}]}, {"text": "To establish a standard for unambiguously characterizing malware, MAEC (Malware Attribute Enumeration and Characterization), a community-based project organized by MITRE, has specified a set of standard malware attributes ().", "labels": [], "entities": [{"text": "Malware Attribute Enumeration and Characterization)", "start_pos": 72, "end_pos": 123, "type": "TASK", "confidence": 0.5620746165513992}]}, {"text": "Based on MAEC, the actions of a malware can be categorized by four attributes: ActionName, Capability, StrategicObjectives and TacticalObjectives.", "labels": [], "entities": []}, {"text": "ActionName specifies the actions taken by a malware.", "labels": [], "entities": []}, {"text": "For example, \"delete file\" is a malware action that deletes existing files from affected systems.", "labels": [], "entities": [{"text": "delete file\"", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.769921620686849}]}, {"text": "Capability defines the general capabilities of a malware.", "labels": [], "entities": []}, {"text": "For example, \"anti-removal\" is a malware capability that prevents itself from being removed from a system.", "labels": [], "entities": []}, {"text": "StrategicObjectives and TacticalObjectives are subcategories of Capability to capture more details.", "labels": [], "entities": []}, {"text": "For example, a malware can have a StrategicObjective of \"staging data for exfiltration\" and a TacticalObjective of \"moving data to a staging server\".", "labels": [], "entities": []}, {"text": "In total, MAEC specified TacticalObjectives.", "labels": [], "entities": [{"text": "MAEC", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.7362160682678223}]}, {"text": "The goal of this research is to automatically assign malware attribute labels based on cybersecurity texts.", "labels": [], "entities": []}, {"text": "The system needs to assign a large number of labels (444 in total).", "labels": [], "entities": []}, {"text": "However, it is difficult to obtain sufficient training examples for each label since malware attribute labeling requires extensive cybersecurity knowledge and only domain experts can do this reliably.", "labels": [], "entities": [{"text": "malware attribute labeling", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.685265044371287}]}, {"text": "Given a large number of possible labels and a small number of training examples, typical supervised text classification techniques do notwork well.", "labels": [], "entities": [{"text": "text classification", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.6935610920190811}]}, {"text": "In this work, we focus on incorporating additional knowledge sources to improve feature learning.", "labels": [], "entities": []}, {"text": "The main contributions of this work include 1.", "labels": [], "entities": []}, {"text": "Develop a novel malware attribute prediction system with the state of the art performance to automatically characterize malware behavior based on cybersecurity text.", "labels": [], "entities": [{"text": "malware attribute prediction", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.6607029338677725}]}, {"text": "2. Propose a novel Word Annotation Embedding (WAE) algorithm to encode diverse information from heterogeneous knowledge sources such as human annotations, raw texts and MAEC specifications.", "labels": [], "entities": []}, {"text": "3. Since WAE generates embeddings for both words and malware attribute labels, we construct high-quality predicting features based on both types of embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "For classification, we tried both SVM and neural network-based models such as multilayer perceptron.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9719669222831726}]}, {"text": "After experimenting with different model parameters, we found that the best SVM model with a linear kernel performed slightly better than the best neural network models.", "labels": [], "entities": []}, {"text": "We speculate that this might be because SVM is less likely to overfit when the training data are sparse.", "labels": [], "entities": [{"text": "SVM", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.8922440409660339}]}, {"text": "shows the average F-scores over 5 runs by the SVM models on the test data.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9966183304786682}]}, {"text": "We compare our models with three baseline systems: (B1) (, (B2) word2vec and (B3) word2vec + cap.", "labels": [], "entities": []}, {"text": "Among them, (B1) represents the best published results on the same dataset.", "labels": [], "entities": [{"text": "B1)", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9674390852451324}]}, {"text": "(B2) and (B3) are all the comparable models with embeddings learned by word2vec.", "labels": [], "entities": []}, {"text": "As shown in, all our models outperformed all the baseline systems.", "labels": [], "entities": []}, {"text": "The improve-ment over the word2vec model is 15%, 11%, 15% and 25% respectively, and, the improvement over (), a previous state of the art, is 39%, 54%, 74% and 105% respectively.", "labels": [], "entities": []}, {"text": "The improvement over W ord2vec + Cap is 15% and 15% respectively for StrategicObjective and TechnicalObjective.", "labels": [], "entities": []}, {"text": "We also conducted t-tests to verify the significance of the improvements.", "labels": [], "entities": []}, {"text": "The t-test results confirmed that our models significantly outperformed the baseline models with p<0.05.", "labels": [], "entities": []}, {"text": "Moreover, the value of \"Capability\" seems to help the prediction of StrategicObjective and TechnicalObjective.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation Results. B1-B3 are the three baselines. S1-S6 are our models with six different sets of  predicting features. \u22061-\u22063 are the improvements of our best models over the three baselines.", "labels": [], "entities": []}]}