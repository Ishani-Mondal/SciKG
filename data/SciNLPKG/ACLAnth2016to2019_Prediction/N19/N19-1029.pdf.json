{"title": [{"text": "Simple Question Answering with Subgraph Ranking and Joint-Scoring", "labels": [], "entities": [{"text": "Simple Question Answering", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6633577148119608}, {"text": "Joint-Scoring", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9681183695793152}]}], "abstractContent": [{"text": "Knowledge graph based simple question answering (KBSQA) is a major area of research within question answering.", "labels": [], "entities": [{"text": "Knowledge graph based simple question answering (KBSQA)", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6449427041742537}, {"text": "question answering", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.8984073996543884}]}, {"text": "Although only dealing with simple questions, i.e., questions that can be answered through a single knowledge base (KB) fact, this task is neither simple nor close to being solved.", "labels": [], "entities": []}, {"text": "Targeting on the two main steps, subgraph selection and fact selection, the research community has developed sophisticated approaches.", "labels": [], "entities": [{"text": "subgraph selection", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.8931471407413483}, {"text": "fact selection", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7874078452587128}]}, {"text": "However, the importance of subgraph ranking and leverag-ing the subject-relation dependency of a KB fact have not been sufficiently explored.", "labels": [], "entities": [{"text": "subgraph ranking", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.8378034234046936}]}, {"text": "Motivated by this, we present a unified framework to describe and analyze existing approaches.", "labels": [], "entities": []}, {"text": "Using this framework as a starting point, we focus on two aspects: improving subgraph selection through a novel ranking method and leveraging the subject-relation dependency by proposing a joint scoring CNN model with a novel loss function that enforces the well-order of scores.", "labels": [], "entities": [{"text": "subgraph selection", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.8451805710792542}]}, {"text": "Our methods achieve anew state of the art (85.44% in accuracy) on the SimpleQuestions dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9994403719902039}, {"text": "SimpleQuestions dataset", "start_pos": 70, "end_pos": 93, "type": "DATASET", "confidence": 0.9310688376426697}]}], "introductionContent": [{"text": "Knowledge graph based simple question answering (KBSQA) is an important area of research within question answering, which is one of the core areas of interest in natural language processing (.", "labels": [], "entities": [{"text": "Knowledge graph based simple question answering (KBSQA)", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6817026502556272}, {"text": "question answering", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.8761504590511322}]}, {"text": "It can be used for many applications such as virtual home assistants, customer service, and chat-bots.", "labels": [], "entities": []}, {"text": "A knowledge graph is a multi-entity and multi-relation directed graph containing the information needed to answer the questions.", "labels": [], "entities": []}, {"text": "The graph can be represented as collection of triples {(subject, relation, * Work conducted during an internship at Alexa AI, CA. object)}.", "labels": [], "entities": []}, {"text": "Each triple is called a fact, where a directed relational arrow points from subject node to object node.", "labels": [], "entities": []}, {"text": "A simple question means that the question can be answered by extracting a single fact from the knowledge graph, i.e., the question has a single subject and a single relation, hence a single answer.", "labels": [], "entities": []}, {"text": "For example, the question \"Which Harry Potter series did Rufus Scrimgeour appear in?\" can be answered by a single fact (Rufus Scrimgeour, book.book-characters.appears-inbook, Harry Potter and the Deathly Hallows).", "labels": [], "entities": []}, {"text": "Given the simplicity of the questions, one would think this task is trivial.", "labels": [], "entities": []}, {"text": "Yet it is far from being easy or close to being solved.", "labels": [], "entities": []}, {"text": "The complexity lies in two aspects.", "labels": [], "entities": []}, {"text": "One is the massive size of the knowledge graph, usually in the order of billions of facts.", "labels": [], "entities": []}, {"text": "The other is the variability of the questions in natural language.", "labels": [], "entities": []}, {"text": "Based on this anatomy of the problem, the solutions also consist of two steps: (1) selecting a relatively small subgraph from the knowledge graph given a question and (2) selecting the correct fact from the subgraph.", "labels": [], "entities": []}, {"text": "Different approaches have been studied to tackle the KBSQA problems.", "labels": [], "entities": [{"text": "KBSQA", "start_pos": 53, "end_pos": 58, "type": "TASK", "confidence": 0.7746053338050842}]}, {"text": "The common solution for the first step, subgraph selection (which is also known as entity linking), is to label the question with subject part (mention) and nonsubject part (pattern) and then use the mention to retrieve related facts from the knowledge graph, constituting the subgraph.", "labels": [], "entities": [{"text": "subgraph selection", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.817513644695282}, {"text": "entity linking", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.7717263698577881}]}, {"text": "Sequence labeling models, such as a BiLSTM-CRF tagger , are commonly employed to label the mention and the pattern.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7796342968940735}]}, {"text": "To retrieve the subgraph, it is common to search all possible n-grams of the mention against the knowledge graph and collect the facts with matched subjects as the subgraph.", "labels": [], "entities": []}, {"text": "The candidate facts in the subgraph may contain incorrect subjects and relations.", "labels": [], "entities": []}, {"text": "In our running example, we first identify the mention in the question, i.e.,\"Rufus Scrimgeour\", and then retrieve the subgraph which could contain the following facts: {(Rufus Scrimgeour, book.book-characters.appears-in-book, Harry Potter and the Deathly Hallows), (Rufus Wainwright, music.singer.singer-of, I Don't Know What That Is)}.", "labels": [], "entities": []}, {"text": "For the second step, fact selection, a common approach is to construct models to match the mention with candidate subjects and match the pattern with candidate relations in the subgraph from the first step.", "labels": [], "entities": [{"text": "fact selection", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8184932768344879}]}, {"text": "For example, the correct fact is identified by matching the mention \"Rufus Scrimgeour\" with candidate subjects {Rufus Scrimgeour, Rufus Wainwright} and matching the pattern \"Which Harry Potter series did m appear in\" with candidate relations {book.book-characters.appears-inbook, music.singer.singer-of}.", "labels": [], "entities": []}, {"text": "Different neural network models can be employed).", "labels": [], "entities": []}, {"text": "Effective as these existing approaches are, there are three major drawbacks.", "labels": [], "entities": []}, {"text": "(1) First, in subgraph selection, there is no effective way to deal with inexact matches and the facts in subgraph are not ranked by relevance to the mention; however, we will later show that effective ranking can substantially improve the subgraph recall.", "labels": [], "entities": [{"text": "subgraph selection", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.8967283964157104}, {"text": "recall", "start_pos": 249, "end_pos": 255, "type": "METRIC", "confidence": 0.9458342790603638}]}, {"text": "(2) Second, the existing approaches do not leverage the dependency between mention-subjects and pattern-relations; however, mismatches of mention-subject can lead to incorrect relations and hence incorrect answers.", "labels": [], "entities": []}, {"text": "We will later show that leveraging such dependency contributes to the overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9988742470741272}]}, {"text": "(3) Third, the existing approaches minimize the ranking loss (; however, we will later show that the ranking loss is suboptimal.", "labels": [], "entities": []}, {"text": "Addressing these points, the contributions of this paper are three-fold: (1) We propose a subgraph ranking method with combined literal and semantic score to improve the recall of the subgraph selection.", "labels": [], "entities": [{"text": "subgraph ranking", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.8076572120189667}, {"text": "recall", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.9962848424911499}]}, {"text": "It can deal with inexact match, and achieves better performance compared to the previous state of the art.", "labels": [], "entities": []}, {"text": "(2) We propose a lowcomplexity joint-scoring CNN model and a wellorder loss to improve fact selection.", "labels": [], "entities": [{"text": "fact selection", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.7663327753543854}]}, {"text": "It couples the subject matching and the relation matching by learning order-preserving scores and dynamically adjusting the weights of scores.", "labels": [], "entities": [{"text": "relation matching", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.6972525268793106}]}, {"text": "(3) We achieve better performance (85.44% in accuracy) than the previous state of the art on the SimpleQuestions dataset, surpassing the best baseline by a large margin 1 .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9984145164489746}, {"text": "SimpleQuestions dataset", "start_pos": 97, "end_pos": 120, "type": "DATASET", "confidence": 0.8839032053947449}]}], "datasetContent": [{"text": "Here, we evaluate our proposed approach for the KBSQA problem on the SimpleQuestions benchmark dataset and compare with baseline approaches.", "labels": [], "entities": [{"text": "KBSQA problem", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.5582101047039032}, {"text": "SimpleQuestions benchmark dataset", "start_pos": 69, "end_pos": 102, "type": "DATASET", "confidence": 0.9426551858584086}]}], "tableCaptions": [{"text": " Table 1: Sequence Tagger Configurations", "labels": [], "entities": [{"text": "Sequence Tagger Configurations", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.9569814403851827}]}, {"text": " Table 2: Matching Model Configurations", "labels": [], "entities": [{"text": "Matching Model Configurations", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7614863912264506}]}, {"text": " Table 4: Subgraph Selection Results", "labels": [], "entities": [{"text": "Subgraph Selection", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9602134525775909}]}, {"text": " Table 5: Fact Selection Accuracy (%). The object accuracy is the end-to-end question answer accuracy, while  subject and relation accuracies refer to separately computed subject accuracy and relation accuracy.", "labels": [], "entities": [{"text": "Fact Selection Accuracy", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.7070690294106802}, {"text": "object accuracy", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.5127427130937576}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.5072703957557678}]}]}