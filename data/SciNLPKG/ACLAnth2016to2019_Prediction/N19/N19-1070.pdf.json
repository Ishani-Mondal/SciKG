{"title": [], "abstractContent": [{"text": "Authors' keyphrases assigned to scientific articles are essential for recognizing content and topic aspects.", "labels": [], "entities": []}, {"text": "Most of the proposed supervised and unsupervised methods for keyphrase generation are unable to produce terms that are valuable but do not appear in the text.", "labels": [], "entities": [{"text": "keyphrase generation", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.8702605962753296}]}, {"text": "In this paper, we explore the possibility of considering the keyphrase string as an abstractive summary of the title and the abstract.", "labels": [], "entities": []}, {"text": "First, we collect, process and release a large dataset of scientific paper metadata that contains 2.2 million records.", "labels": [], "entities": []}, {"text": "Then we experiment with popular text summarization neural architectures.", "labels": [], "entities": [{"text": "text summarization neural", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.7857205470403036}]}, {"text": "Despite using advanced deep learning models, large quantities of data and many days of computation , our systematic evaluation on four test datasets reveals that the explored text sum-marization methods could not produce better keyphrases than the simpler unsupervised methods, or the existing supervised ones.", "labels": [], "entities": []}], "introductionContent": [{"text": "A valuable concept for searching and categorizing scientific papers in digital libraries is the keyphrase (we use keyphrase and keyword interchangeably), a short set of one or few words that represent concepts.", "labels": [], "entities": []}, {"text": "Scientific articles are commonly annotated with keyphrases based on taxonomies of concepts and the authors' judgment.", "labels": [], "entities": []}, {"text": "Finding keyphrases that best describe the contents of a document is thus essential and rewarding.", "labels": [], "entities": []}, {"text": "Most of the proposed keyphrase extraction solutions tend to be unsupervised ( and generate terms by selecting the most appropriate candidates, ranking the candidates based on several features and finally returning the top N . Another way is to utilize datasets of texts and keywords for training supervised models with linguistic or other features to predict if candidates are keywords or not (.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.851606160402298}]}, {"text": "All above methods propose N keyphrases for each article which are joined together with \",\" (or other separator like \";\") to form the keyphrase string of that article.", "labels": [], "entities": []}, {"text": "They suffer from various problems or discrepancies.", "labels": [], "entities": []}, {"text": "First, they are unable to find an optimal value for N and require it as a preset parameter.", "labels": [], "entities": []}, {"text": "Furthermore, semantic and syntactic properties of article phrases are analyzed separately.", "labels": [], "entities": []}, {"text": "The meaning of paragraphs, sections or entire document is thus missed.", "labels": [], "entities": []}, {"text": "Lastly, only phrases that do appear in the article are returned.", "labels": [], "entities": []}, {"text": "recently proposed a deep supervised keyphrase generation solution trained on a big dataset.", "labels": [], "entities": [{"text": "keyphrase generation", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7379471808671951}]}, {"text": "It successfully solves the last two problems above, but not the first one.", "labels": [], "entities": []}, {"text": "Motivated by recent advances in neural machine translation and abstractive text summarization (, in this paper, we explore the possibility of considering keyphrase generation as an abstractive text summarization task.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7211650808652242}, {"text": "abstractive text summarization", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.6151408553123474}, {"text": "keyphrase generation", "start_pos": 154, "end_pos": 174, "type": "TASK", "confidence": 0.7513774931430817}, {"text": "abstractive text summarization", "start_pos": 181, "end_pos": 211, "type": "TASK", "confidence": 0.6607168217500051}]}, {"text": "Instead of generating keywords one by one and linking them to form the keyphrase string, we consider the later as an abstractive summary of the concatenated paper title and abstract.", "labels": [], "entities": []}, {"text": "Different recently-proposed text summarization architectures are tried on four test datasets of article keyphrases (.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7495124042034149}]}, {"text": "We trained them with a newly created dataset of 2.2 million article titles, abstracts and keyphrase strings that we processed and released.", "labels": [], "entities": []}, {"text": "The selected text summarization models are compared with popular unsupervised and supervised methods using ROUGE) and fullmatch F 1 metrics.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.5657714754343033}]}, {"text": "The results show that though trained with large data quantities for many days, the tried text summarization methods could not produce better keywords than the existing supervised or deep supervised predictive models.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.6940959692001343}]}, {"text": "In our opinion, a possible explanation for this is the fact that the title and the abstract may not carry sufficient topical information about the article, even when joined together.", "labels": [], "entities": []}, {"text": "In contrast, when assigning keywords annotations of their paper, authors are highly influenced by the topic aspects of it.", "labels": [], "entities": []}, {"text": "This paper carries several contributions, despite the fact that no progressive result scores were reached.", "labels": [], "entities": []}, {"text": "It is the first work that considers keyphrase generation as an abstractive text summarization task.", "labels": [], "entities": [{"text": "keyphrase generation", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.8939069211483002}, {"text": "abstractive text summarization", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.6342030167579651}]}, {"text": "We produced a large dataset of article titles, abstracts, and keywords that can be used for keyword generation, text summarization or similar purposes.", "labels": [], "entities": [{"text": "keyword generation", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7241745144128799}, {"text": "text summarization", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7100507467985153}]}, {"text": "Finally, we evaluated the performance of different neural network architectures on summarization of article keyword strings, comparing them with popular unsupervised methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "Because of the open source and open data initiatives, many public datasets from various domains can be found online.", "labels": [], "entities": []}, {"text": "Among the several collections of scientific articles, some of them have gained considerable popularity in research literature.", "labels": [], "entities": []}, {"text": "In, we found a recent and big collection of 20K paper abstracts and keyphrases.", "labels": [], "entities": []}, {"text": "These metadata belong to articles of computer science from ACM Digital Library, ScienceDirect, and Web of Science.", "labels": [], "entities": [{"text": "ACM Digital Library", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.9372703631718954}]}, {"text": "In Hulth (2003), we found a collection of 2000 (1500 for train/val and 500 for testing) abstracts in English, together with titles and authors' keywords.", "labels": [], "entities": [{"text": "Hulth (2003)", "start_pos": 3, "end_pos": 15, "type": "DATASET", "confidence": 0.7437092512845993}]}, {"text": "The corresponding articles were published from 1998 to 2002 and belong to the discipline of Information Technology.", "labels": [], "entities": []}, {"text": "Furthermore, released a dataset of 2000 (1600 for train/val and 400 for testing) full articles published by ACM from 2003 to 2005 in Computer Science domain.", "labels": [], "entities": [{"text": "ACM", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.9280053377151489}]}, {"text": "More information about similar keyphrase data collections or other available resources can be found in and in online repositories.", "labels": [], "entities": []}, {"text": "Regarding text summarization, some of the most popular datasets are:  ) and Newsroom, a heterogeneous bundle of news articles described in.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6921065896749496}, {"text": "Newsroom", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9719094634056091}]}, {"text": "These datasets are frequently used for the task of predicting titles from abstracts or short stories.", "labels": [], "entities": [{"text": "predicting titles from abstracts or short stories", "start_pos": 51, "end_pos": 100, "type": "TASK", "confidence": 0.8988254496029445}]}, {"text": "However, no keyphrases are provided; they do not serve to our purpose.", "labels": [], "entities": []}, {"text": "ArnetMiner is a recent attempt to crawl scientific paper data from academic networks ().", "labels": [], "entities": [{"text": "ArnetMiner", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8241143226623535}]}, {"text": "The system extracts profiles of researchers from digital resources and integrates their data in a common network.", "labels": [], "entities": []}, {"text": "A spin-off is the Open Academic Graph (OAG) data collection (.", "labels": [], "entities": [{"text": "Open Academic Graph (OAG) data collection", "start_pos": 18, "end_pos": 59, "type": "DATASET", "confidence": 0.5461808480322361}]}, {"text": "To produce a usable collection for our purpose, we started from OAG.", "labels": [], "entities": [{"text": "OAG", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.8746204376220703}]}, {"text": "We extracted title, abstract and keywords.", "labels": [], "entities": []}, {"text": "The list of keywords was transformed into a comma-separated string and a language identifier was used to remove records that were not in English.", "labels": [], "entities": []}, {"text": "Abstracts and titles were lowercased, and Stanford CoreNLP tokenizer was used for tokenizing.", "labels": [], "entities": [{"text": "Stanford CoreNLP tokenizer", "start_pos": 42, "end_pos": 68, "type": "DATASET", "confidence": 0.9041731158892313}, {"text": "tokenizing", "start_pos": 82, "end_pos": 92, "type": "TASK", "confidence": 0.965961217880249}]}, {"text": "Short records of fewer than 20 tokens in the abstract, 2 tokens in the title and 2 tokens in the keywords were removed.", "labels": [], "entities": []}, {"text": "For the test portion, we selected documents of at least 27, 3 and 2 tokens in each field.", "labels": [], "entities": []}, {"text": "Data preprocessing stopped here for the release version (no symbol filtering), given that many researchers want to filter text in their own way.", "labels": [], "entities": [{"text": "symbol filtering", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.7222079932689667}]}, {"text": "This new dataset named OAGK can be used for both text summarization (predicting title from abstract) and keyphrase extraction (unsupervised, supervised or deep supervised) tasks.", "labels": [], "entities": [{"text": "OAGK", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.47272589802742004}, {"text": "text summarization", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7287631332874298}, {"text": "predicting title from abstract)", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.8101416826248169}, {"text": "keyphrase extraction", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.7483416497707367}]}, {"text": "Some rounded measures about each set of released data are presented in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of OAGK dataset", "labels": [], "entities": [{"text": "OAGK dataset", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.8179591298103333}]}, {"text": " Table 2: Full-match scores of predicted keyphrases by various methods", "labels": [], "entities": []}, {"text": " Table 3: Rouge scores of predicted keyphrases by various methods", "labels": [], "entities": []}]}