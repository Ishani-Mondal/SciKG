{"title": [{"text": "Multi-Channel Convolutional Neural Network for Twitter Emotion and Sentiment Recognition", "labels": [], "entities": [{"text": "Emotion and Sentiment Recognition", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.6885427981615067}]}], "abstractContent": [{"text": "The advent of micro-blogging sites has paved the way for researchers to collect and analyze huge volumes of data in recent years.", "labels": [], "entities": []}, {"text": "Twit-ter, being one of the leading social networking sites worldwide, provides a great opportunity to its users for expressing their states of mind via short messages which are called tweets.", "labels": [], "entities": [{"text": "Twit-ter", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9405672550201416}]}, {"text": "The urgency of identifying emotions and sentiments conveyed through tweets has led to several research works.", "labels": [], "entities": [{"text": "identifying emotions and sentiments conveyed through tweets", "start_pos": 15, "end_pos": 74, "type": "TASK", "confidence": 0.7355843612125942}]}, {"text": "It provides a great way to understand human psychology and impose a challenge to researchers to analyze their content easily.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel use of a multi-channel convolu-tional neural architecture which can effectively use different emotion and sentiment indicators such as hashtags, emoticons and emojis that are present in the tweets and improve the performance of emotion and sentiment identification.", "labels": [], "entities": [{"text": "emotion and sentiment identification", "start_pos": 262, "end_pos": 298, "type": "TASK", "confidence": 0.6906644254922867}]}, {"text": "We also investigate the incorporation of different lexical features in the neural network model and its effect on the emotion and sentiment identification task.", "labels": [], "entities": [{"text": "emotion and sentiment identification task", "start_pos": 118, "end_pos": 159, "type": "TASK", "confidence": 0.7039581775665283}]}, {"text": "We analyze our model on some standard datasets and compare its effectiveness with existing techniques.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social networking sites (e.g., Twitter) have become immensely popular in the last decade.", "labels": [], "entities": []}, {"text": "User generated content (e.g., blog posts, statuses, tweets etc.) in social media provides a wide range of opinionated, emotional and sentimental content which gives researchers a massive data source to explore.", "labels": [], "entities": []}, {"text": "For example, Twitter, being one of the leading social networking giants, provides an online environment that allows people of various backgrounds and locations to share their opinions and views on different matters.", "labels": [], "entities": []}, {"text": "As of July 2018, over 500 million tweets are sent per day having over 300 million monthly active users.", "labels": [], "entities": []}, {"text": "1 http://www.internetlivestats.com/twitter-statistics/ There is often a misconception about sentiments and emotions as these subjectivity terms have been used interchangeably ().", "labels": [], "entities": []}, {"text": "differentiate these two terms along with other subjectivity terms and provide the computational linguistics community with clear concepts for effective analysis of text.", "labels": [], "entities": []}, {"text": "While sentiment classification tasks deal with the polarity of a given text (whether apiece of text expresses positive, negative or neutral sentiment) and the intensity of the sentiment expressed, emotion mining tasks naturally deal with human emotions which in some end purposes are more desirable.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.8761427402496338}, {"text": "emotion mining", "start_pos": 197, "end_pos": 211, "type": "TASK", "confidence": 0.7405674606561661}]}, {"text": "Detecting emotion and sentiment from noisy twitter data is really challenging due to its nature.", "labels": [], "entities": [{"text": "Detecting emotion and sentiment from noisy twitter", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8744762454714093}]}, {"text": "Tweets tend to be short in length and have a diverse vocabulary making them harder to analyze due to the limited contextual information they contain.", "labels": [], "entities": []}, {"text": "In this study, we are interested in tackling these two tasks with a novel use of a single neural network architecture.", "labels": [], "entities": []}, {"text": "A number of emotion theories are available which suggest different sets of basic emotions.", "labels": [], "entities": []}, {"text": "Interestingly, joy, sadness, anger, fear and surprise are common to all.", "labels": [], "entities": [{"text": "surprise", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9435679912567139}]}, {"text": "To the best of our knowledge, the model suggested by is the most broadly used emotion model.", "labels": [], "entities": []}, {"text": "In this study, we use Ekman's basic emotions together with other sets of emotions.", "labels": [], "entities": []}, {"text": "In early textual emotion mining and sentiment analysis research, the usefulness of using external lexicons along with predefined rules has been demonstrated).", "labels": [], "entities": [{"text": "textual emotion mining", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.63896311322848}, {"text": "sentiment analysis", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.9141258895397186}]}, {"text": "Aman and used Roget's Thesaurus along with WordNet-Affect for fine-grained emotion prediction from blog data.", "labels": [], "entities": [{"text": "WordNet-Affect", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.9707880020141602}, {"text": "fine-grained emotion prediction", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6708850165208181}]}, {"text": "propose a unigram mixture model (UMM) to create a domain-specific lexicon which performs better in extracting features than Point-wise Mutual Information and supervised Latent Dirichlet Allocation methods.", "labels": [], "entities": []}, {"text": "propose a rule-based system which can handle informal texts in particular.", "labels": [], "entities": []}, {"text": "They built a database of abbreviations, emoticons, affect words, etc., in which each entry is labeled with an emotion and its intensity.", "labels": [], "entities": []}, {"text": "propose an algorithm, SentiStrength, which utilizes a dictionary of sentiment words associated with strength measures to deal with short informal texts from social media.", "labels": [], "entities": []}, {"text": "propose VADER, a rule-based model for sentiment analysis.", "labels": [], "entities": [{"text": "VADER", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.9250937700271606}, {"text": "sentiment analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.9576152861118317}]}, {"text": "They built a lexicon which is specially attuned to microblog-like contexts and their model outperforms individual human raters.", "labels": [], "entities": []}, {"text": "More recently, deep learning models have proven to be very successful when applied on various text-related tasks.", "labels": [], "entities": []}, {"text": "showed the effectiveness of a simple CNN model that leverages pretrained word vectors fora sentence classification task.", "labels": [], "entities": [{"text": "sentence classification task", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.7763067384560903}]}, {"text": "propose a dynamic CNN model using a dynamic k-max pooling mechanism which is able to generate a feature graph which captures a variety of word relations.", "labels": [], "entities": []}, {"text": "They showed the efficacy of their model by achieving high performances on binary and multiclass sentiment classification tasks without any feature engineering.", "labels": [], "entities": [{"text": "multiclass sentiment classification tasks", "start_pos": 85, "end_pos": 126, "type": "TASK", "confidence": 0.7001118659973145}]}, {"text": "dos propose a deep CNN model that uses both character and word-level information allowing them to achieve state-of-the-art performance on both binary and fine-grained multi-class sentiment classification for one of the twitter datasets.", "labels": [], "entities": [{"text": "multi-class sentiment classification", "start_pos": 167, "end_pos": 203, "type": "TASK", "confidence": 0.6567214727401733}]}, {"text": "propose a Tree-LSTM model which captures syntactic properties in text.", "labels": [], "entities": []}, {"text": "Their model performs particularly well on sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.9661559462547302}]}, {"text": "propose a regional CNN-LSTM model for dimensional sentiment analysis.", "labels": [], "entities": [{"text": "dimensional sentiment analysis", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.7747847437858582}]}, {"text": "Their proposed model computes valence-arousal ratings from texts and outperforms several regressionbased methods.", "labels": [], "entities": []}, {"text": "propose a bidirectional LSTM model with attention showing that their model learns better representations when distant supervision is expanded to a set of noisy labels.", "labels": [], "entities": []}, {"text": "Abdul-Mageed and Ungar (2017) also used distant supervision to build a large twitter dataset and proposed a Gated Recurrent Neural Network model for fine-grained emotion detection.", "labels": [], "entities": [{"text": "fine-grained emotion detection", "start_pos": 149, "end_pos": 179, "type": "TASK", "confidence": 0.6511595745881399}]}, {"text": "The recent success of neural based models motivated us to take a different look at the sentiment and emotion prediction from the noisy twitter data task.", "labels": [], "entities": [{"text": "sentiment and emotion prediction", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.7738766372203827}]}, {"text": "Compared with sequential models, CNN models train relatively faster and seem to work very well on noisy data such as tweets which are grammatically error-prone.", "labels": [], "entities": []}, {"text": "We decided to work with CNN models after our initial experiments suggested that they perform comparatively better than a simple BiLSTM model on twitter dataset.", "labels": [], "entities": []}, {"text": "We address the following questions in this paper: \u2022 Can CNN models be used in away that can improve the performance of detecting emotion and sentiment from noisy Twitter data?", "labels": [], "entities": [{"text": "detecting emotion and sentiment from noisy Twitter", "start_pos": 119, "end_pos": 169, "type": "TASK", "confidence": 0.8396276916776385}]}, {"text": "\u2022 How important are hashtag words, emoticons and emojis as predictors of emotion and sentiment in micro-blogging sites?", "labels": [], "entities": []}, {"text": "How can we encode them in a multi-channel convolutional neural network?", "labels": [], "entities": []}, {"text": "\u2022 How can we add external features to a CNN model effectively?", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: We describe our model architecture in detail in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the datasets and lexicons used in our experiments.", "labels": [], "entities": []}, {"text": "As well, we describe the experimental setup required for working with Twitter data.", "labels": [], "entities": []}, {"text": "In Section 4, we discuss the results from our experiments.", "labels": [], "entities": []}, {"text": "In Section 5, we discuss our findings with particular attention paid to answering the above questions.", "labels": [], "entities": []}, {"text": "Finally, in Section 6, we give a summary of our work followed by our remarks on future studies.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe in detail the datasets and experimental procedures used in our study.", "labels": [], "entities": []}, {"text": "We used a number of emotion and sentiment datasets for our experiments.", "labels": [], "entities": []}, {"text": "A description of each dataset is given below: BTD.", "labels": [], "entities": [{"text": "BTD", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.4773317575454712}]}, {"text": "Big Twitter Data is an emotion-labeled Twitter dataset provided by.", "labels": [], "entities": [{"text": "Big Twitter Data", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.8327652017275492}]}, {"text": "The dataset had been automatically annotated based on the seven emotion category seed words being a hashtag and the quality of the data was verified by two annotators as described in ().", "labels": [], "entities": []}, {"text": "We were only able to retrieve a portion of the original dataset as many tweets were either removed or not available at the time we fetched the data using the Twitter API.", "labels": [], "entities": []}, {"text": "We applied the heuristics from () to remove any hashtags from the tweets which belong to the list of emotion seed words.", "labels": [], "entities": []}, {"text": "Twitter Emotion Corpus has been published by Mohammad (2012) for research purposes.", "labels": [], "entities": [{"text": "Twitter Emotion Corpus", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.7787017027537028}]}, {"text": "About 21,000 tweets were collected based on hashtags corresponding to Ekman's (1999) six basic emotions.", "labels": [], "entities": []}, {"text": "The dataset has been used in related works.", "labels": [], "entities": []}, {"text": "The Cleaned Balanced Emotional Tweet dataset is provided by.", "labels": [], "entities": [{"text": "Cleaned Balanced Emotional Tweet dataset", "start_pos": 4, "end_pos": 44, "type": "DATASET", "confidence": 0.5466495394706726}]}, {"text": "To the best of our knowledge, this is one of the largest publically available balanced datasets for twitter emotion detection research.", "labels": [], "entities": [{"text": "twitter emotion detection research", "start_pos": 100, "end_pos": 134, "type": "TASK", "confidence": 0.8421669453382492}]}, {"text": "The dataset contains 80,937 tweets with nine emotion categories including Ekman's six basic emotions.", "labels": [], "entities": []}, {"text": "The SemEval-2018 Task 1 -Affect dataset was provided by.", "labels": [], "entities": [{"text": "SemEval-2018 Task 1 -Affect dataset", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.6119510928789774}]}, {"text": "The SemEval task was to estimate the intensity of a given tweet and its corresponding emotion.", "labels": [], "entities": [{"text": "SemEval", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9422974586486816}]}, {"text": "However, in this study, we utilize the labeled dataset only to classify the tweets into four emotion categories and use the training, development and test sets provided in this dataset in our experiments.", "labels": [], "entities": []}, {"text": "This dataset was constructed by STS.", "labels": [], "entities": []}, {"text": "The Stanford Twitter Sentiment dataset was introduced by.", "labels": [], "entities": [{"text": "Stanford Twitter Sentiment dataset", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.9351710379123688}]}, {"text": "It consists of a training set and a test set.", "labels": [], "entities": []}, {"text": "The training set contains around 1.6 million tweets, whereas the test set contains 498 tweets.", "labels": [], "entities": []}, {"text": "The training set was built automatically based on several emoticons as potential identifiers of sentiment.", "labels": [], "entities": []}, {"text": "However, the test set was manually annotated and heavily used for model evaluation in related research.", "labels": [], "entities": [{"text": "model evaluation", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.6799656897783279}]}, {"text": "We perform one experiment with all three labels (positive/negative/neutral) to compare the performance of different variants of our model and another one with two labels (positive/negative) to make comparison with related works (.", "labels": [], "entities": []}, {"text": "The Sentiment Strength Twitter dataset was constructed by to evaluate SentiStrength.", "labels": [], "entities": [{"text": "Sentiment Strength Twitter dataset", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.6534908190369606}]}, {"text": "The tweets were manually labeled by multiple persons.", "labels": [], "entities": []}, {"text": "Each tweet is assigned a number between 1 and 5 for both positive and negative sentiments, 1 represents weak sentiment strength and 5 represents strong sentiment strength.", "labels": [], "entities": []}, {"text": "We followed the heuristics used by to obtain a single sentiment label for each tweet, giving us a total of 4, 242 positive, negative and neutral tweets.", "labels": [], "entities": []}, {"text": "The transformed dataset has been used in other literature (.", "labels": [], "entities": []}, {"text": "We provide basic statistics of the datasets used in our experiments in.", "labels": [], "entities": []}, {"text": "Twitter data is unstructured and highly informal ( and thus it requires a great deal of effort to make it suitable for any model.", "labels": [], "entities": []}, {"text": "NLTK () provides a regular-expression based tokenizer for Twitter, TweetTokenizer, which preserves user mentions, hashtags, urls, emoticons and emojis in particular.", "labels": [], "entities": [{"text": "NLTK", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8583791255950928}]}, {"text": "It also reduces the length of repeated characters to three (i.e. \"Haaaaaapy\" will become \"Haaapy\")\".", "labels": [], "entities": [{"text": "length", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9666159152984619}]}, {"text": "In our experiments, we utilized the TweetTokenizer to tokenize tweets.", "labels": [], "entities": [{"text": "tokenize tweets", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.8712756633758545}]}, {"text": "To accommodate the pretrained word vectors from (Pennington et al., 2014b), we pre-processed each tweet in a number of ways.", "labels": [], "entities": []}, {"text": "We lowercased all the letters in the tweet.", "labels": [], "entities": []}, {"text": "User mentions have been replaced with <user> token (i.e. @user-name1 will become <user>).", "labels": [], "entities": []}, {"text": "In addition, we also removed urls from the tweets as urls do not provide any emotional value.", "labels": [], "entities": []}, {"text": "We also normalized certain negative words (e.g., \"won't\" will become \"will not\").", "labels": [], "entities": []}, {"text": "Using slang words is a very common practice in social media.", "labels": [], "entities": []}, {"text": "We compiled a list of the most common slang words from various online resources 2 and replaced all of the occurrences with their full form (e.g., \"nvm\" will become \"never mind\").", "labels": [], "entities": []}, {"text": "Our list of slang words doesn't contain any word which has multiple meanings.", "labels": [], "entities": []}, {"text": "Usage of certain punctuation is often crucial in social media posts as it helps the user to emphasize certain things.", "labels": [], "entities": []}, {"text": "We found that two punctuation symbols (! and ?) are common among social media users to express certain emotional states.", "labels": [], "entities": []}, {"text": "We kept these symbols in our text and normalized the repetitions (e.g., \"!!!\" will become \"! <repeat>\").", "labels": [], "entities": [{"text": "repetitions", "start_pos": 53, "end_pos": 64, "type": "METRIC", "confidence": 0.9624165892601013}]}, {"text": "The use of emojis and emoticons has increased significantly with the advent of various social media sites.", "labels": [], "entities": []}, {"text": "Emoticons (e.g., :-D) are essentially a combination of punctuation marks, letters and numbers used to create pictorial icons which generally display an emotion or sentiment.", "labels": [], "entities": []}, {"text": "On the other hand, emojis are pictographs of faces, objects and symbols.", "labels": [], "entities": []}, {"text": "The primary purpose of using emojis and emoticons is to convey certain emotions and sentiments.", "labels": [], "entities": []}, {"text": "One advantage of using the TweetTokenizer is that it gives us emoticons and emojis as tokens.", "labels": [], "entities": []}, {"text": "Though we use the emoticons as is in our experiment, we utilize a python library called \"emoji\" to get descriptive details about the pictorial image.", "labels": [], "entities": []}, {"text": "For example, \"\" represents \"smiling face\".", "labels": [], "entities": []}, {"text": "In our experiments, we removed stop-words and replaced numbers occurring in the tweets with the token <number>.", "labels": [], "entities": []}, {"text": "We also stripped off \"#\" symbols from all the hashtags within the tweets (e.g.,  \"#depressed\" will become \"depressed\") and used the stripped version of hashtags on the second channel of our model.", "labels": [], "entities": []}, {"text": "We only kept tokens with more than one character.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: (a) Basic statistics of the emotion datasets used  in our experiments. (b) Basic statistics of sentiment  labeled datasets used in our experiments.", "labels": [], "entities": []}, {"text": " Table 2: Results (in %) of our model (MC-CNN) for four emotion-labeled datasets.", "labels": [], "entities": []}, {"text": " Table 3: Ranges of different hyper-parameters searched  during tuning and the final configurations selected for  our experiments", "labels": [], "entities": []}, {"text": " Table 5: Results (in %) of three variants of our model from 10-fold cross-validation for sentiment labeled datasets  (3-class). Bold text indicates the best performance in a column. \u2020 represents the inclusion of Hash-Emo embedding  into the network.  \u2021 represents the inclusion of external features into the network.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of results (accuracy in %) of  three variants of our model.  \u2020 represents the inclusion  of Hash-Emo embedding into the network.  \u2021 represents  the inclusion of external features into the network.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9990383386611938}]}]}