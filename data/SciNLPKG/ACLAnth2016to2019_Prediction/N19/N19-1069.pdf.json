{"title": [{"text": "Adversarial Training for Satire Detection: Controlling for Confounding Variables", "labels": [], "entities": [{"text": "Satire Detection", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.9807227253913879}]}], "abstractContent": [{"text": "The automatic detection of satire vs. regular news is relevant for downstream applications (for instance, knowledge base population) and to improve the understanding of linguistic characteristics of satire.", "labels": [], "entities": [{"text": "automatic detection of satire vs. regular news", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.6984606044633048}]}, {"text": "Recent approaches build upon corpora which have been labeled automatically based on article sources.", "labels": [], "entities": []}, {"text": "We hypothesize that this encourages the models to learn characteristics for different publication sources (e.g., \"The Onion\" vs. \"The Guardian\") rather than characteristics of satire, leading to poor generalization performance to unseen publication sources.", "labels": [], "entities": [{"text": "The Onion\" vs. \"The Guardian\")", "start_pos": 114, "end_pos": 144, "type": "DATASET", "confidence": 0.8846874535083771}]}, {"text": "We therefore propose a novel model for satire detection with an adversarial component to control for the confounding variable of publication source.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.8515052497386932}]}, {"text": "On a large novel data set collected from German news (which we make available to the research community), we observe comparable satire classification performance and, as desired, a considerable drop in publication classification performance with adversarial training.", "labels": [], "entities": [{"text": "data set collected from German news", "start_pos": 17, "end_pos": 52, "type": "DATASET", "confidence": 0.7205576300621033}, {"text": "satire classification", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.8899677991867065}, {"text": "publication classification", "start_pos": 202, "end_pos": 228, "type": "TASK", "confidence": 0.6315458416938782}]}, {"text": "Our analysis shows that the adversarial component is crucial for the model to learn to pay attention to linguistic properties of satire.", "labels": [], "entities": []}], "introductionContent": [{"text": "Satire is a form of art used to criticize in an entertaining manner (cf. Sulzer, 1771, p. 995ff.).", "labels": [], "entities": []}, {"text": "It makes use of different stylistic devices, e.g., humor, irony, sarcasm, exaggerations, parody or caricature.", "labels": [], "entities": []}, {"text": "The occurrence of harsh, offensive or banal and funny words is typical.", "labels": [], "entities": []}, {"text": "Satirical news are written with the aim of mimicking regular news in diction.", "labels": [], "entities": []}, {"text": "In contrast to misinformation and disinformation, it does not have the intention of fooling the readers into actually believing something wrong in order to manipulate their opinion.", "labels": [], "entities": []}, {"text": "* Work was done at University of Stuttgart.", "labels": [], "entities": []}, {"text": "The task of satire detection is to automatically distinguish satirical news from regular news.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7750192284584045}, {"text": "distinguish satirical news from regular news", "start_pos": 49, "end_pos": 93, "type": "TASK", "confidence": 0.7288101315498352}]}, {"text": "This is relevant, for instance, for downstream applications, such that satirical articles can be ignored in knowledge base population.", "labels": [], "entities": []}, {"text": "Solving this problem computationally is challenging.", "labels": [], "entities": []}, {"text": "Even human readers are sometimes notable to precisely recognize satire.", "labels": [], "entities": []}, {"text": "Thus, an automatic system for satire detection is both relevant for downstream applications and could help humans to better understand the characteristics of satire.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8474730849266052}]}, {"text": "Previous work mostly builds on top of corpora of news articles which have been labeled automatically based on the publication source (e.g., \"The New York Times\" articles would be labeled as regular while \"The Onion\" articles as satire 1 ).", "labels": [], "entities": []}, {"text": "We hypothesize that such distant labeling approach leads to the model mostly representing characteristics of the publishers instead of actual satire.", "labels": [], "entities": []}, {"text": "This has two main issues: First, interpretation of the model to obtain a better understanding of concepts of satire would be misleading, and second, generalization of the model to unseen publication sources would be harmed.", "labels": [], "entities": []}, {"text": "We propose anew model with adversarial training to control for the confounding variable of publication sources, i.e., we debias the model.", "labels": [], "entities": []}, {"text": "Our experiments and analysis show that (1) the satire detection performance stays comparable when the adversarial component is included, and (2) that adversarial training is crucial for the model to pay attention to satire instead of publication characteristics.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7290734052658081}]}, {"text": "(3), we publish a large German data set for satire detection which is a) the first data set in German, b) the first data set including publication sources, enabling the experiments at hand, and c) the largest resource for satire detection so far.", "labels": [], "entities": [{"text": "German data set", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.8829638163248698}, {"text": "satire detection", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7705104947090149}, {"text": "satire detection", "start_pos": 222, "end_pos": 238, "type": "TASK", "confidence": 0.7656433284282684}]}], "datasetContent": [{"text": "We consider German regular news collected from 4 websites and German satirical news from 11 websites.", "labels": [], "entities": []}, {"text": "shows statistics and sources of the corpus, consisting of almost 330k articles.", "labels": [], "entities": []}, {"text": "The corpus contains articles published between January 1st, 2000 and May 1st, 2018.", "labels": [], "entities": []}, {"text": "Each publication has individual typical phrases and different most common words.", "labels": [], "entities": []}, {"text": "Among the most common words is typically the name of each publication, e.g., \"Der Spiegel\" has \"SPIEGEL\" as fifth and \"Der Postillon\" \"Postillon\" as third most common word.", "labels": [], "entities": [{"text": "SPIEGEL", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9537444710731506}]}, {"text": "We did not delete those words to keep the dataset as realistic as possible.", "labels": [], "entities": []}, {"text": "We randomly split the data set into training, development (dev) and test (80/10/10 %) with the same label distributions in all sets.", "labels": [], "entities": []}, {"text": "Given the comparable large size of the corpus, we opt for using a well-defined test set for reproducability of our experiments in contrast to a crossvalidation setting.", "labels": [], "entities": []}, {"text": "RQ1: How does a decrease in publication classification performance through adversarial training affect the satire classification performance?", "labels": [], "entities": [{"text": "RQ1", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5643346309661865}, {"text": "publication classification", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.6540483981370926}, {"text": "satire classification", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.8596302568912506}]}, {"text": "RQ2: Is adversarial training effective for avoiding that the model pays most attention to the characteristics of publication source rather than actual satire?", "labels": [], "entities": [{"text": "RQ2", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7622182369232178}]}, {"text": "As a baseline model, we train the satire detector part (gray area in on the satire task.", "labels": [], "entities": [{"text": "satire detector", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7024792581796646}]}, {"text": "Then, we freeze the weights of the feature extractor and train the publication classifier on top of it.", "labels": [], "entities": []}, {"text": "In addition, we use a majority baseline model which predicts the most common class.", "labels": [], "entities": []}, {"text": "We cut the input sentences to a maximum length of 500 words.", "labels": [], "entities": []}, {"text": "This enables us to fully represent almost all satire articles and  capture most of the content of the regular articles while keeping the training time low.", "labels": [], "entities": []}, {"text": "As mentioned before, we represent the input words with 300 dimensional embeddings.", "labels": [], "entities": []}, {"text": "The feature extractor consists of a biLSTM layer with 300 hidden units in each direction and a self-attention layer with an internal hidden representation of 600.", "labels": [], "entities": []}, {"text": "For training, we use Adam () with an initial learning rate of 0.0001 and a decay rate of 10 \u22126 . We use mini-batch gradient descent training with a batch size of 32 and alternating batches of the two branches of our model.", "labels": [], "entities": []}, {"text": "We avoid overfitting by early stopping based on the satire F1 score on the development set.", "labels": [], "entities": [{"text": "F1 score on the development set", "start_pos": 59, "end_pos": 90, "type": "DATASET", "confidence": 0.8265021046002706}]}, {"text": "For evaluating satire detection, we use precision, recall and F1 score of the satire class.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.8803666234016418}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9997782111167908}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9996476173400879}, {"text": "F1 score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9891677498817444}]}, {"text": "For publication identification, we calculate a weighted macro precision, recall and F1 score, i.e., a weighted sum of class-specific scores with weights determined by the class distribution.", "labels": [], "entities": [{"text": "publication identification", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8477508723735809}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.8617504239082336}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9980069994926453}, {"text": "F1 score", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9875226616859436}]}, {"text": "shows results for different values of \u03bb, the hyperparameter of adversarial training, on dev.", "labels": [], "entities": []}, {"text": "For \u03bb \u2208 {0.2, 0.3, 0.5}, the results are comparably, with \u03bb = 0.2 performing best for satire detection.", "labels": [], "entities": [{"text": "satire detection", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.9113422632217407}]}, {"text": "Setting \u03bb = 0.7 leads to a performance drop for satire but also to F 1 = 0 for publication classification.", "labels": [], "entities": [{"text": "F 1", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9852327406406403}, {"text": "publication classification", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.8076008260250092}]}, {"text": "Hence, we chose \u03bb = 0.2 (the best performing model on satire classification) and \u03bb = 0.7 (the worst performing model on publication identification) to investigate RQ1.", "labels": [], "entities": [{"text": "satire classification", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.9063156247138977}, {"text": "publication identification", "start_pos": 120, "end_pos": 146, "type": "TASK", "confidence": 0.8240686357021332}, {"text": "RQ1", "start_pos": 163, "end_pos": 166, "type": "DATASET", "confidence": 0.7121062278747559}]}], "tableCaptions": [{"text": " Table 1: Corpus statistics (average length in words)", "labels": [], "entities": []}, {"text": " Table 2: Results on dev and independent test data.", "labels": [], "entities": []}]}