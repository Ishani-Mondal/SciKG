{"title": [{"text": "Issue Framing in Online Discussion Fora", "labels": [], "entities": []}], "abstractContent": [{"text": "In online discussion fora, speakers often make arguments for or against something, say birth control, by highlighting certain aspects of the topic.", "labels": [], "entities": []}, {"text": "In social science, this is referred to as issue framing.", "labels": [], "entities": [{"text": "issue framing", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.790046900510788}]}, {"text": "In this paper, we introduce anew issue frame annotated corpus of online discussions.", "labels": [], "entities": []}, {"text": "We explore to what extent models trained to detect issue frames in newswire and social media can be transferred to the domain of discussion fora, using a combination of multi-task and adversarial training, assuming only unlabeled training data in the target domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "The framing of an issue refers to a choice of perspective, often motivated by an attempt to influence its perception and interpretation.", "labels": [], "entities": []}, {"text": "The way issues are framed can change the evolution of policy as well as public opinion (.", "labels": [], "entities": []}, {"text": "As an illustration, contrast the statement Illegal workers depress wages with This country is abusing and terrorizing undocumented immigrant workers.", "labels": [], "entities": []}, {"text": "The first statement puts focus on the economic consequences of immigration, whereas the second one evokes amorality frame by pointing out the inhumane conditions under which immigrants may have to work.", "labels": [], "entities": []}, {"text": "Being exposed to primarily one of those perspectives might affect the publics attitude towards immigration.", "labels": [], "entities": []}, {"text": "Computational methods for frame classification have previously been studied in news articles) and social media posts.", "labels": [], "entities": [{"text": "frame classification", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.901468425989151}]}, {"text": "In this work, we introduce anew benchmark dataset, based on a subset of the 15 generic frames in the Policy Frames Codebook by.", "labels": [], "entities": [{"text": "Policy Frames Codebook", "start_pos": 101, "end_pos": 123, "type": "DATASET", "confidence": 0.6903650561968485}]}, {"text": "We focus on frame classification in online discussion fora, which have be- come crucial platforms for public dialogue on social and political issues.", "labels": [], "entities": [{"text": "frame classification", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.8580136895179749}]}, {"text": "shows example annotations, compared to previous annotations for news articles and social media.", "labels": [], "entities": []}, {"text": "Dialogue data is substantially different from news articles and social media, and we therefore explore ways to transfer information from these domains, using multitask and adversarial learning, providing non-trivial baselines for future work in this area.", "labels": [], "entities": []}, {"text": "Contributions We present anew issue-frame annotated dataset that is used to evaluate issue frame classification in online discussion fora.", "labels": [], "entities": [{"text": "issue frame classification", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.625374992688497}]}, {"text": "Issue frame classification was previously limited to news and social media.", "labels": [], "entities": [{"text": "Issue frame classification", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6023968060811361}]}, {"text": "As manual annotation is expensive, we explore ways to overcome the lack of labeled training data in the target domain with: Class distribution in the online discussion test set.", "labels": [], "entities": [{"text": "online discussion test set", "start_pos": 150, "end_pos": 176, "type": "DATASET", "confidence": 0.7879117429256439}]}, {"text": "The frame labels correspond to the classes Economic (1), Political (13), Legality, Jurisprudence and Constitutionality (5), Policy prescription and evaluation (6) and Crime and Punishment (7).", "labels": [], "entities": [{"text": "Policy prescription and evaluation", "start_pos": 124, "end_pos": 158, "type": "TASK", "confidence": 0.7808140218257904}]}, {"text": "multi-task and adversarial learning, leading to improved results in the target domain.", "labels": [], "entities": []}, {"text": "1 Related Work Previous work on automatic frame classification focused on news articles and social media.", "labels": [], "entities": [{"text": "automatic frame classification", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.635374387105306}]}, {"text": "predict frames in news articles at the document level, using clusters of latent dimensions and word-based features in a logistic regression model.", "labels": [], "entities": []}, {"text": "improve on previous work integrating discourse structure into a recursive neural network.", "labels": [], "entities": []}, {"text": "use the same resource, but make predictions at the sentence level, using topic models and recurrent neural networks.", "labels": [], "entities": []}, {"text": "predict frames in social media data at the micro-post level, using probabilistic soft logic based on lists of keywords, as well as temporal similarity and network structure.", "labels": [], "entities": []}, {"text": "All the work mentioned above uses the generic frames of's Policy Frames Codebook.", "labels": [], "entities": [{"text": "'s Policy Frames Codebook", "start_pos": 55, "end_pos": 80, "type": "DATASET", "confidence": 0.7976062744855881}]}, {"text": "predict words perceived as frame-evoking in political news articles with hand-crafted features.", "labels": [], "entities": []}, {"text": "analyse how Russian news articles frame the U.S. using a keyword-based cross-lingual projection setup.", "labels": [], "entities": []}, {"text": "use topic models to analyze issue ownership and framing in public statements released by the US congress.", "labels": [], "entities": [{"text": "issue ownership and framing in public statements released by the US congress", "start_pos": 28, "end_pos": 104, "type": "TASK", "confidence": 0.7833240975936254}]}, {"text": "Besides work on frame classification, there has recently been a lot of work on aspects closely related to framing, such as subjectivity detection), detection of biased language) and stance detection (.", "labels": [], "entities": [{"text": "frame classification", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8511658608913422}, {"text": "subjectivity detection", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.6819377541542053}, {"text": "stance detection", "start_pos": 182, "end_pos": 198, "type": "TASK", "confidence": 0.9314005374908447}]}, {"text": "Corpus is a collection of argumentative dialogues across topics and platforms.", "labels": [], "entities": []}, {"text": "The corpus contains posts on the following topics: gay marriage, gun control, death penalty and evolution.", "labels": [], "entities": [{"text": "gay marriage", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.6982031017541885}, {"text": "gun control", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.7675369083881378}]}, {"text": "A subset of the corpus was annotated with argument quality scores by, which we exploit in our multi-task setup (see \u00a73).", "labels": [], "entities": []}, {"text": "We collect new issue frame annotations for each argument in the argument-quality annotated data.", "labels": [], "entities": []}, {"text": "We refer to this new issue-frame annotated corpus as online discussion corpus henceforth.", "labels": [], "entities": []}, {"text": "Each argument can have one or multiple frames.", "labels": [], "entities": []}, {"text": "Following, we focus on the five most frequent issue frames: Economic, constitutionality and jurisprudence, policy prescription and evaluation, law and order/crime and justice, and political.", "labels": [], "entities": [{"text": "policy prescription and evaluation", "start_pos": 107, "end_pos": 141, "type": "TASK", "confidence": 0.8681527972221375}]}, {"text": "See for the class distribution in the resulting online discussions test set.", "labels": [], "entities": []}, {"text": "Phrases which do not match the five categories are labeled as Other, but we do not consider this class in our experiments.", "labels": [], "entities": []}, {"text": "The annotations were done by a single annotator.", "labels": [], "entities": []}, {"text": "A second annotator labeled a subset of 200 instances that we use to compute agreement as macro-averaged F-score, assuming one of the annotations as gold standard.", "labels": [], "entities": [{"text": "F-score", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9283740520477295}]}, {"text": "Results are 0.73 and 0.7, respectively.", "labels": [], "entities": []}, {"text": "The averaged Cohen's Kappa is 0.71.", "labels": [], "entities": [{"text": "Cohen's Kappa", "start_pos": 13, "end_pos": 26, "type": "METRIC", "confidence": 0.5267450014750162}]}], "datasetContent": [{"text": "We compare the multi-task learning and the adversarial setup with two baseline models: (a) a Random Forest classifier using tf-idf weighted bagof-words-representations, and (b) the LSTM baseline model.", "labels": [], "entities": []}, {"text": "For the multi-task model, we use both the Twitter dataset and the argument quality dataset as auxiliary tasks.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.9316740334033966}]}, {"text": "For all models, we report results on the test set using the optimal hyperparameters that we found averaged over 3 runs on the validation set.", "labels": [], "entities": []}, {"text": "For the neural models, we use 100-dimensional GloVe embeddings (), pre-trained on Wikipedia and Gigaword.", "labels": [], "entities": []}, {"text": "Details about hyper-parameter tuning and optimal settings can be found in Appendix B.", "labels": [], "entities": [{"text": "hyper-parameter tuning", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7861633002758026}]}], "tableCaptions": [{"text": " Table 2: Class distribution in the online discussion test  set. The frame labels correspond to the classes Eco- nomic (1), Political (13), Legality, Jurisprudence and  Constitutionality (5), Policy prescription and evalua- tion (6) and Crime and Punishment (7).", "labels": [], "entities": [{"text": "online discussion test  set", "start_pos": 36, "end_pos": 63, "type": "DATASET", "confidence": 0.7566819787025452}, {"text": "Policy prescription", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.7349476963281631}]}, {"text": " Table 3: Overview over the data and labelsets for the different tasks. The baseline model trains on the main task  and predicts the target task. The multi-task model uses one or both auxiliary tasks in addition to the main task. The  adversarial model uses the adversarial task in addition to the main task. All models use the online disc. dev set for  model selection.", "labels": [], "entities": []}, {"text": " Table 4: Examples for model predictions on the online discussion dev set. The first column shows the gold label  and the following columns the prediction made by the adversarial model (Adv), the Multi-Task model (MTL) and  the LSTM baseline (LSTM).", "labels": [], "entities": [{"text": "online discussion dev set", "start_pos": 48, "end_pos": 73, "type": "DATASET", "confidence": 0.7412824034690857}]}, {"text": " Table 5: Macro-(ma) and micro-averaged (mi) scores  for the online discussion test data averaged over 3 runs.  The multi-task model uses the Twitter and argument  quality datasets as auxiliary tasks. The micro-average  F of a baseline that predicts the majority class is 0.307.", "labels": [], "entities": [{"text": "Macro-(ma) and micro-averaged (mi) scores", "start_pos": 10, "end_pos": 51, "type": "METRIC", "confidence": 0.7951504826545716}, {"text": "F", "start_pos": 220, "end_pos": 221, "type": "METRIC", "confidence": 0.740218997001648}]}]}