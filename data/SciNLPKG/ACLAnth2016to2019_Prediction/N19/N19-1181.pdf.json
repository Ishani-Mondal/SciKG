{"title": [{"text": "Text Similarity Estimation Based on Word Embeddings and Matrix Norms for Targeted Marketing", "labels": [], "entities": [{"text": "Text Similarity Estimation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.74482594927152}]}], "abstractContent": [{"text": "The prevalent way to estimate the similarity of two documents based on word embeddings is to apply the cosine similarity measure to the two centroids obtained from the embedding vectors associated with the words in each document.", "labels": [], "entities": [{"text": "cosine similarity measure", "start_pos": 103, "end_pos": 128, "type": "METRIC", "confidence": 0.7447519898414612}]}, {"text": "Motivated by an industrial application from the domain of youth marketing, where this approach produced only mediocre results, we propose an alternative way of combining the word vectors using matrix norms.", "labels": [], "entities": []}, {"text": "The evaluation shows superior results for most of the investigated matrix norms in comparison to both the classical cosine measure and several other document similarity estimates.", "labels": [], "entities": []}], "introductionContent": [{"text": "Estimating semantic document similarity is of utmost importance in a lot of different areas, like plagiarism detection, information retrieval, or text summarization.", "labels": [], "entities": [{"text": "plagiarism detection", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.7912950813770294}, {"text": "information retrieval", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.8104765117168427}, {"text": "text summarization", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.7542475759983063}]}, {"text": "We will focus hereon an NLP application that has been less researched, i.e., the assignment of people to the best matching target group to allow for running precise and customeroriented marketing campaigns.", "labels": [], "entities": []}, {"text": "Until recently, similarity estimates were predominantly based either on deep semantic approaches or on typical information retrieval techniques like Latent Semantic Analysis.", "labels": [], "entities": [{"text": "Latent Semantic Analysis", "start_pos": 149, "end_pos": 173, "type": "TASK", "confidence": 0.5983213682969412}]}, {"text": "In the last couple of years, however, so-called word and sentence embeddings became state-of-the-art.", "labels": [], "entities": []}, {"text": "The prevalent approach to document similarity estimation based on word embeddings consists in measuring the similarity between the vector representations of the two documents derived as follows: 1.", "labels": [], "entities": [{"text": "document similarity estimation", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.6395448545614878}]}, {"text": "The word embeddings (often weighted by the tf-idf coefficients of the associated words () are looked up in a hashtable for all the words in the two documents to compare.", "labels": [], "entities": []}, {"text": "These embeddings are determined beforehand on a very large corpus typically using either the skip gram or the continuous bag of words variant of the Word2Vec model ().", "labels": [], "entities": []}, {"text": "2. The centroid overall word embeddings belonging to the same document is calculated to obtain its vector representation.", "labels": [], "entities": []}, {"text": "If vector representations of the two documents to compare were successfully established, a similarity estimate can be obtained by applying the cosine measure to the two vectors.", "labels": [], "entities": []}, {"text": "Let x 1 , . .", "labels": [], "entities": []}, {"text": ", x m and y 1 , . .", "labels": [], "entities": []}, {"text": ", y n be the word vectors of two documents.", "labels": [], "entities": []}, {"text": "The cosine similarity value between the two document centroids C 1 und C 2 is given by: n j=1 xi , y j mnC 1 C 2 (1) Hence, potentially small values of xi , y j can have in aggregate a considerable influence on the total similarity estimate, which makes this estimate vulnerable to noise in the data.", "labels": [], "entities": []}, {"text": "We propose an alternative approach that is based on matrix norms and which proved to be more noise-robust by focusing primarily on high word similarities.", "labels": [], "entities": []}, {"text": "Finally, we conducted an evaluation where we achieved with our method superior accuracy in target group assignments than several traditional word embedding based methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9981707334518433}]}], "datasetContent": [{"text": "For evaluation, we selected three online contests (language: German), where people elaborated on their favorite travel destination for an example, speculated about potential experiences with a pair of fancy sneakers (contest 2) and explained why they emotionally prefer a certain product out of   four available candidates.", "labels": [], "entities": []}, {"text": "We experimented with different keyword list sizes but obtained the best results with rather few and therefore precise keywords.", "labels": [], "entities": []}, {"text": "In particular, we used the following number of keywords for the individual milieus: \u2022 Action Sportsman: 3 \u2022 Young Performer: 4 \u2022 Hedonist: 7 \u2022 Conservative Youth: 4 \u2022 Progressive Postmodern Youth: 6 In order to provide a gold standard, three professional marketers from different youth marketing companies annotated independently the best matching youth milieus for every contest answer.", "labels": [], "entities": []}, {"text": "We determined for each annotator individually his/her average inter-annotator agreement with the others (Cohen's kappa).", "labels": [], "entities": []}, {"text": "The minimum and maximum of these average agreement values are given in.", "labels": [], "entities": []}, {"text": "Since for contest 2 and contest 3, some of the annotators annotated only the first 50 entries (last 50 entries respectively), we specified min/max average kappa values for both parts.", "labels": [], "entities": [{"text": "min/max average kappa", "start_pos": 139, "end_pos": 160, "type": "METRIC", "confidence": 0.7073406338691711}]}, {"text": "We further compared the youth milieus proposed by our unsupervised matching algorithm with the majority votes over the human experts' answers (see) . Moreover, we computed its average inter-annotator agreement with the human annotators (see), quasi treating the predictions like additional annotations.", "labels": [], "entities": []}, {"text": "The Word2Vec word embeddings were trained on the German Wikipedia (dump originating from 20 February 2017) merged with a Frankfurter Rundschau newspaper Corpus and 34 249 articles of the news journal 20 minutes 2 , where the latter is targeted to the Swiss market and freely available at various Swiss train stations (see fora comparison of corpus sizes).", "labels": [], "entities": [{"text": "Frankfurter Rundschau newspaper Corpus", "start_pos": 121, "end_pos": 159, "type": "DATASET", "confidence": 0.8393317610025406}]}, {"text": "By employing articles from 20 minutes, we want to ensure the reliability of word vectors for certain Switzerland specific expressions like Velo or Glace, which are underrepresented in the German Wikipedia and the Frankfurter Rundschau corpus.", "labels": [], "entities": [{"text": "reliability", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.9917362332344055}, {"text": "Velo", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.8781705498695374}, {"text": "Glace", "start_pos": 147, "end_pos": 152, "type": "METRIC", "confidence": 0.9190784096717834}, {"text": "Frankfurter Rundschau corpus", "start_pos": 213, "end_pos": 241, "type": "DATASET", "confidence": 0.9480490883191427}]}, {"text": "ESA is usually trained on Wikipedia, since the authors of the original ESA paper suggest that the articles of the training corpus should represent disjoint concepts, which is only guaranteed for encyclopedias.", "labels": [], "entities": []}, {"text": "However, challenged this hypothesis and demonstrated that promising results can be obtained by applying ESA on other types of corpora like the popular Reuters newspaper corpus as well.", "labels": [], "entities": [{"text": "Reuters newspaper corpus", "start_pos": 151, "end_pos": 175, "type": "DATASET", "confidence": 0.9627845287322998}]}, {"text": "Unfortunately, the implementation we use (Wikiprep-ESA 3 ) expects its training data to be a Wikipedia Dump.", "labels": [], "entities": []}, {"text": "Furthermore, Wikiprep-ESA only indexes words that are connected by hyperlinks, which are usually lacking in ordinary newspaper articles.", "labels": [], "entities": [{"text": "Wikiprep-ESA", "start_pos": 13, "end_pos": 25, "type": "DATASET", "confidence": 0.91534823179245}]}, {"text": "So we could train Wikiprep-ESA on Wikipedia only but additionally have developed aversion of ESA that can be applied on arbitrary corpora (in the following referred to as ESA2) and which was trained on the full corpus (Wikipedia+Frankfurter Rundschau+20 minutes).", "labels": [], "entities": []}, {"text": "The STVs were also trained on the same corpus as our matrix norms based estimates and Word2Vec embedding centroids.", "labels": [], "entities": []}, {"text": "The actual document similarity estimation is accomplished by the usual centroid approach (we did not evaluate matrix norms here).", "labels": [], "entities": [{"text": "document similarity estimation", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.5864556133747101}]}, {"text": "An issue we were faced with is that STVs are not bag of word models but actually take the sequence of the words into account and therefore the obtained similar-: Accuracy value otbained for matching a sentence of the first to the associated sentence of the second translation.", "labels": [], "entities": []}, {"text": "ity estimate between milieu keyword list and contest answer would be dependent on the keyword ordering.", "labels": [], "entities": []}, {"text": "However, this order could have arbitrarily been chosen by the marketers and might be completely random.", "labels": [], "entities": []}, {"text": "A possible solution is to compare the contest answers with all possible permutation of keywords and determine the maximum value overall those comparisons.", "labels": [], "entities": []}, {"text": "However, such an approach would be infeasible already for medium keyword list sizes.", "labels": [], "entities": []}, {"text": "Therefore, we use abeam search approach instead, which extends the keyword list iteratively and keeps only the n-best performing permutations.", "labels": [], "entities": []}, {"text": "Finally, to verify the general applicability of our approach, we conducted a second experiment, where a novel from Edgar Allen Poe (The purloined letter) was independently translated by two translators into German.", "labels": [], "entities": []}, {"text": "We aim to match a sentence from the first translation to the associated sentence of the second by looking for the assignment with the highest semantic relatedness disregarding the sentence order.", "labels": [], "entities": []}, {"text": "The obtained accuracy values based on the first 200 sentences of both translations are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9994502663612366}]}, {"text": "To guarantee an 1:1 sentence mapping, periods were partly replaced by semicolons.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus sizes measured by number of words.", "labels": [], "entities": []}, {"text": " Table 3: Obtained accuracy values for similarity mea- sures induced by different matrix norms and for four  baseline methods. GM = Geometric Mean of sn 1 and  sn \u221e . (W)W2VC=(tf-idf-weighted) Word2Vec Em- bedding Centroids.", "labels": [], "entities": [{"text": "Obtained", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9548758268356323}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9161497354507446}, {"text": "similarity mea- sures", "start_pos": 39, "end_pos": 60, "type": "METRIC", "confidence": 0.7396752908825874}, {"text": "GM", "start_pos": 127, "end_pos": 129, "type": "METRIC", "confidence": 0.9774467349052429}, {"text": "Geometric Mean", "start_pos": 132, "end_pos": 146, "type": "METRIC", "confidence": 0.9455560147762299}, {"text": "Word2Vec Em- bedding Centroids", "start_pos": 193, "end_pos": 223, "type": "DATASET", "confidence": 0.8675527453422547}]}, {"text": " Table 4: Minimum and maximum average inter- annotator agreements (Cohen's kappa) / average inter- annotator agreement values for our automated match- ing method, FN=Frobenius norm.", "labels": [], "entities": [{"text": "Minimum", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9762200117111206}, {"text": "automated match- ing", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.5889437645673752}, {"text": "FN", "start_pos": 163, "end_pos": 165, "type": "METRIC", "confidence": 0.9891148805618286}]}]}