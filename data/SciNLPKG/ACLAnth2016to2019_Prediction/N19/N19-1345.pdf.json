{"title": [{"text": "Domain adaptation for part-of-speech tagging of noisy user-generated text", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7181396633386612}, {"text": "part-of-speech tagging of noisy user-generated text", "start_pos": 22, "end_pos": 73, "type": "TASK", "confidence": 0.8360874950885773}]}], "abstractContent": [{"text": "The performance of a Part-of-speech (POS) tagger is highly dependent on the domain of the processed text, and for many domains there is no or only very little training data available.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagger", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.6080934643745423}]}, {"text": "This work addresses the problem of POS tagging noisy user-generated text using a neural network.", "labels": [], "entities": [{"text": "POS tagging noisy user-generated text", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.9026877164840699}]}, {"text": "We propose an architecture that trains an out-of-domain model on a large newswire corpus, and transfers those weights by using them as a prior fora model trained on the target domain (a data-set of Ger-man Tweets) for which there is very little annotations available.", "labels": [], "entities": []}, {"text": "The neural network has two standard bidirectional LSTMs at its core.", "labels": [], "entities": []}, {"text": "However, we find it crucial to also encode a set of task-specific features, and to obtain reliable (source-domain and target-domain) word representations.", "labels": [], "entities": []}, {"text": "Experiments with different reg-ularization techniques such as early stopping, dropout and fine-tuning the domain adaptation prior weights are conducted.", "labels": [], "entities": []}, {"text": "Our best model uses external weights from the out-of-domain model, as well as feature embeddings, pre-trained word and sub-word embeddings and achieves a tagging accuracy of slightly over 90%, improving on the previous state of the art for this task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9514309763908386}]}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is a prerequisite for many applications and necessary fora wide range of tools for computational linguists.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5809185266494751}]}, {"text": "The stateof-the art method to implement a tagger is to use neural networks.", "labels": [], "entities": []}, {"text": "The performance of a POS tagger is highly dependent on the domain of the processed text and the availability of sufficient training data).", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 21, "end_pos": 31, "type": "TASK", "confidence": 0.8263270854949951}]}, {"text": "Existing POS taggers for canonical German text already achieve very good results around 97% accuracy, e.g..", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.7870824038982391}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9993914365768433}]}, {"text": "When applying these trained models to out-of-domain data the performance decreases drastically.", "labels": [], "entities": []}, {"text": "One of the domains where there is not enough data is online conversational text in platforms such as Twitter, where the very informal language exhibits many phenomena that differ significantly from canonical written language.", "labels": [], "entities": []}, {"text": "In this work, we propose a neural network that combines a character-based encoder and embeddings of features from previous non-neural approaches (that can be interpreted as an inductive bias to guide the learning task).", "labels": [], "entities": []}, {"text": "We further show that the performance of this already effective tagger can be improved significantly by incorporating external weights using a mechanism of domainspecific L2-regularization during the training on in-domain data.", "labels": [], "entities": []}, {"text": "This approach establishes stateof-the-art results of 90.3% accuracy on the German Twitter corpus of Rehbein (2013).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.998044490814209}, {"text": "German Twitter corpus of Rehbein (2013)", "start_pos": 75, "end_pos": 114, "type": "DATASET", "confidence": 0.9411951303482056}]}], "datasetContent": [{"text": "This section describes the proposed architecture of the neural network and the conditional random field used in the experiments.", "labels": [], "entities": []}, {"text": "For comparison of the results we also experiment with jointly training on a merged training set, which contains the Twitter and the TIGER training sets.", "labels": [], "entities": [{"text": "TIGER training sets", "start_pos": 132, "end_pos": 151, "type": "DATASET", "confidence": 0.8385393619537354}]}, {"text": "The model's performance increases by another 3 percentage points if the character level layer is used.", "labels": [], "entities": []}, {"text": "Including the pretrained embeddings, FastText and Word2Vec vectors, the accuracy is 84.5%, which outperforms the CRF baseline.", "labels": [], "entities": [{"text": "FastText", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.8731168508529663}, {"text": "Word2Vec", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.8627280592918396}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9997469782829285}]}, {"text": "shows the impact of domain adaptation and fine-tuning the prior weight.", "labels": [], "entities": []}, {"text": "The value of the \u03bb parameter in the regularization formula 1 can control the degree of impact of the weights on the training.", "labels": [], "entities": []}, {"text": "Excluding the pretrained weights means that \u03bb is 0.", "labels": [], "entities": []}, {"text": "We observe an optimal benefit from the out-of-domain weights by using a \u03bb value Overall the addition of the L2 fine-tuning can improve the tagging outcome by 5 percentage points, compared to not doing domain adaptation.", "labels": [], "entities": [{"text": "tagging", "start_pos": 139, "end_pos": 146, "type": "TASK", "confidence": 0.9546293616294861}, {"text": "domain adaptation", "start_pos": 201, "end_pos": 218, "type": "TASK", "confidence": 0.7269799113273621}]}, {"text": "A binomial test shows that this improvement is significant.", "labels": [], "entities": []}, {"text": "This result confirms the intuition that the tagger can benefit from the pretrained weights.", "labels": [], "entities": []}, {"text": "On top of fine-tuning different dropout rates were added to both directions of the LSTMs for the character level layer and the joint embeddings.", "labels": [], "entities": []}, {"text": "A dropout rate of 75% is optimal in our scenario, and it increases the accuracy by 0.7 percentage points.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 2, "end_pos": 14, "type": "METRIC", "confidence": 0.9089730083942413}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9998036026954651}]}, {"text": "The final 90.3% on the test set outperform the results of Rehbein (2013) by 1.5 percentage points.Our best score also outperforms the accuracy obtained with the NCRF++ model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9994365572929382}, {"text": "NCRF++ model", "start_pos": 161, "end_pos": 173, "type": "DATASET", "confidence": 0.9255762696266174}]}, {"text": "This shows that for classifying noisy user-generated text, explicit feature engineering is beneficial, and that the usage of domain adaptation is expedient in this context.", "labels": [], "entities": [{"text": "classifying noisy user-generated text", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.8634195625782013}]}, {"text": "Joint training, using all data (out-of-domain and target domain), can obtain an accuracy score of 89.4%, which is about 1 percentage point worse than using the same data with domain adaptation.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 80, "end_pos": 94, "type": "METRIC", "confidence": 0.983049213886261}]}, {"text": "The training setup for the joint training is the same as for the other experiments and includes all extensions except for the domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.728114515542984}]}], "tableCaptions": [{"text": " Table 1: Results on the test set using the time- distributed layer.", "labels": [], "entities": []}]}