{"title": [{"text": "Improving Lemmatization of Non-Standard Languages with Joint Learning", "labels": [], "entities": [{"text": "Improving Lemmatization of Non-Standard Languages", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.8654620766639709}]}], "abstractContent": [{"text": "Lemmatization of standard languages is concerned with (i) abstracting over morphological differences and (ii) resolving token-lemma ambiguities of inflected words in order to map them to a dictionary headword.", "labels": [], "entities": []}, {"text": "In the present paper we aim to improve lemmatization performance on a set of non-standard historical languages in which the difficulty is increased by an additional aspect (iii): spelling variation due to lacking orthographic standards.", "labels": [], "entities": []}, {"text": "We approach lemmatization as a string-transduction task with an encoder-decoder architecture which we enrich with sentence context information using a hierarchical sentence encoder.", "labels": [], "entities": []}, {"text": "We show significant improvements over the state-of-the-art when training the sentence encoder jointly for lemmatization and language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.7458024621009827}]}, {"text": "Crucially, our architecture does not require POS or morphological annotations, which are not always available for historical corpora.", "labels": [], "entities": []}, {"text": "Additionally, we also test the proposed model on a set of typolog-ically diverse standard languages showing results on par or better than a model without enhanced sentence representations and previous state-of-the-art systems.", "labels": [], "entities": []}, {"text": "Finally, to encourage future work on processing of non-standard varieties , we release the dataset of non-standard languages underlying the present study, based on openly accessible sources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lemmatization is the task of mapping a token to its corresponding dictionary head-form to allow downstream applications to abstract away from orthographic and inflectional variation).", "labels": [], "entities": []}, {"text": "While lemmatization is considered to be solved for analytic and resourcerich languages such as English, it remains an open challenge for morphologically complex (e.g. Estonian, Latvian) and low-resource languages with unstable orthography (e.g. historical languages).", "labels": [], "entities": []}, {"text": "Especially for languages with higher surface variation, lemmatization plays a crucial role as a preprocessing step for downstream tasks such as topic modeling, stylometry and information retrieval.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 144, "end_pos": 158, "type": "TASK", "confidence": 0.8325525522232056}, {"text": "information retrieval", "start_pos": 175, "end_pos": 196, "type": "TASK", "confidence": 0.8198918998241425}]}, {"text": "In the case of standard languages, lemmatization complexity arises primarily from two sources: (i) morphological complexity affecting the number of inflectional patterns a lemmatizer has to model and (ii) token-lemma ambiguities (e.g. \"living\" can refer to lemmas \"living\" or \"live\") which require modeling sentence context information.", "labels": [], "entities": []}, {"text": "In the case of historical languages, however, the aforementioned spelling variation introduces further complications.", "labels": [], "entities": []}, {"text": "For instance, the regularity of the morphological system is drastically reduced since the evidence supporting token-lemma mappings becomes more sparse.", "labels": [], "entities": []}, {"text": "As an example, while the modern Dutch lemma \"jaar\" (en.", "labels": [], "entities": []}, {"text": "\"year\") can be inflected in 2 different ways (\"jaar\", \"jaren\"), in a Middle Dutch corpus used in this study it is found in combination with 70 different forms (\"iare\", \"ior\", \"jaer\", etc.).", "labels": [], "entities": []}, {"text": "Moreover, spelling variation increases token-lemma ambiguities by conflating surface realizations of otherwise unambiguous tokens-e.g. Middle Low German \"bath\" can refer to lemmas \"bat\" (en. \"bad\") and \"bidden\" (en.", "labels": [], "entities": []}, {"text": "\"bet\") due to different spellings of the dental occlusive in final position.", "labels": [], "entities": []}, {"text": "Spelling variation is not exclusive of historical languages and it can be found in contemporary forms of on communication, such as microblogs, with loose orthographic conventions).", "labels": [], "entities": [{"text": "Spelling variation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9228927791118622}]}, {"text": "An important difference, however, is that while for modern languages normalization is feasible (, for many historic languages such is not possible, because one is dealing with an amalgam of regional dialects that lacked any sort of supra-regional variant functioning as target domain (.", "labels": [], "entities": []}, {"text": "In the present paper, we apply representation learning to lemmatization of historical languages.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.9264959990978241}]}, {"text": "Our method shows improvements over a plain encoder-decoder framework, which reportedly achieves state-of-the-art performance on lemmatization and morphological analysis.", "labels": [], "entities": []}, {"text": "In particular, we make the following contributions: 1.", "labels": [], "entities": []}, {"text": "We introduce a simple joint learning approach based on a bidirectional Language Model (LM) loss and achieve relative improvements in overall accuracy of 7.9% over an encoder-decoder trained without joint loss and 30.72% over edit-tree based approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9983426332473755}]}, {"text": "2. We provide a detailed analysis of the linguistic and corpus characteristics that explain the amount of improvement we can expect from LM joint training.", "labels": [], "entities": [{"text": "LM joint training", "start_pos": 137, "end_pos": 154, "type": "TASK", "confidence": 0.8556983272234598}]}, {"text": "3. We probe the hidden representations learned with the joint loss and find them significantly better predictors of POS-tags and other morphological categories than the representations of the simple model, confirming the efficiency of the joint loss for feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 254, "end_pos": 272, "type": "TASK", "confidence": 0.7349723875522614}]}, {"text": "Additionally, we test our approach on a typologically varied set of modern standard languages and find that the joint LM loss significantly improves lemmatization accuracy of ambiguous tokens over the encoder-decoder baseline (with a relative increase of 15.1%), but that, in contrast to previous literature, the overall performance of encoder-decoder models is not significantly higher than that of edit-tree based approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9086948037147522}]}, {"text": "Taking into account the type of inflectional morphology dominating in a particular language, we show that the benefit of encoder-decoder approaches is highly dependent on typological morphology.", "labels": [], "entities": []}, {"text": "Finally, to assure reproducibility, all corpus preprocessing pipelines and train-dev-test splits are released.", "labels": [], "entities": []}, {"text": "With this release, we hope to encourage future work on processing of lesser studied nonstandard varieties.", "labels": [], "entities": []}, {"text": "1 1 Datasets and training splits are available at https: //www.github.com/emanjavacas/pie-data.", "labels": [], "entities": []}, {"text": "Experiments are conducted with our framework pie available at: https://www.github.com/emanjavacas/ pie.", "labels": [], "entities": []}, {"text": "All our experiments are implemented using PyTorch ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Section 4.1 first introduces the datasets, both the newly introduced dataset of historical languages, and the dataset of modern standard languages sampled from Universal Dependencies (v2.2) corpus ().", "labels": [], "entities": [{"text": "Universal Dependencies (v2.2) corpus", "start_pos": 160, "end_pos": 196, "type": "DATASET", "confidence": 0.716557095448176}]}, {"text": "Finally, Section 4.2 describes model training and settings in detail.", "labels": [], "entities": []}, {"text": "Historical Languages In recent years, a number of historical corpora have appeared thanks to an increasing number of digitization initiatives  French, Historical Slovene and Medieval Latin, which we take from the following sources.", "labels": [], "entities": []}, {"text": "Both cga and cgl contain medieval Dutch material from the Gysseling corpus curated by the Institute for Dutch Lexicology 5 cga is a charter collection (administrative documents), whereas cgl concerns a variety of literary texts that greatly vary in length.", "labels": [], "entities": [{"text": "Gysseling corpus curated", "start_pos": 58, "end_pos": 82, "type": "DATASET", "confidence": 0.8932459950447083}]}, {"text": "crm is another Middle Dutch charter collection from the 14th century with wide geographic coverage.", "labels": [], "entities": [{"text": "crm", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8820505738258362}, {"text": "Middle Dutch charter collection", "start_pos": 15, "end_pos": 46, "type": "DATASET", "confidence": 0.5998271107673645}]}, {"text": "cgr, finally, is a smaller collection of samples from Middle Dutch religious writings that include later medieval texts (.", "labels": [], "entities": []}, {"text": "fro offers a corpus of Old French heroic epics, known as chansons de geste.", "labels": [], "entities": []}, {"text": "llat dataset is taken from the Late Latin Charter Treebank, consisting of early medieval Latin documentary texts.", "labels": [], "entities": [{"text": "llat dataset", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9647478461265564}, {"text": "Late Latin Charter Treebank", "start_pos": 31, "end_pos": 58, "type": "DATASET", "confidence": 0.7497866675257683}]}, {"text": "goo comes from the reference corpus of historical Slovene, sampled from 89 texts from the period 1584-1899.", "labels": [], "entities": [{"text": "reference corpus of historical Slovene", "start_pos": 19, "end_pos": 57, "type": "DATASET", "confidence": 0.8495339512825012}]}, {"text": "gml refers to the reference corpus of Middle Low German and Low Rhenish texts, found in manuscripts, prints and inscriptions (.", "labels": [], "entities": []}, {"text": "Finally, cap is a corpus of early medieval Latin ordinances decreed by Carolingian rulers.", "labels": [], "entities": []}, {"text": "Standard Languages For a more thorough comparison between systems across domains and a better examination of the effect of the LM loss, we evaluate our systems on a set of 20 standard languages sampled from the UD corpus, trying to guarantee typological diversity while selecting datasets with at least 20k words.", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 211, "end_pos": 220, "type": "DATASET", "confidence": 0.892209529876709}]}, {"text": "We use the pre-defined splits from the original UD corpus (v2.2).", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.8960072100162506}]}, {"text": "visualizes the test set sizes in terms of total, ambiguous and unknown tokens for both historical and standard languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average accuracy across historical languages.  Lemming and Morfette are shown aggregated by  taking the best performing model per dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9637570381164551}]}, {"text": " Table 2: Accuracy for the Gysseling subcorpora.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9978209733963013}, {"text": "Gysseling subcorpora", "start_pos": 27, "end_pos": 47, "type": "DATASET", "confidence": 0.8016338348388672}]}, {"text": " Table 3: Average accuracy across morphologically related standard languages. Type 1 encloses bg, cs, lv, ru  and sl. Type 2 comprises et, fi, hu, tr. Finally, Type 3 encompasses de, en, es, fr, it and nb.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9853421449661255}]}, {"text": " Table 4: Average accuracy across all 20 standard lan- guages. Lemming and Morfette are shown aggre- gated by taking the best performing model per dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9587210416793823}]}, {"text": " Table 5: Overall accuracy of Sent and Sent-LM  models and a Majority baseline on 5 probing tasks  and actual number of languages per morphological cat- egory. All differences over Sent except for Case are  significant at p < 0.05. Support is shown in terms of  number of languages exhibiting such grammatical dis- tinctions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9997147917747498}]}]}