{"title": [{"text": "Neural Models of the Psychosemantics of 'Most'", "labels": [], "entities": []}], "abstractContent": [{"text": "How are the meanings of linguistic expressions related to their use in concrete cognitive tasks?", "labels": [], "entities": []}, {"text": "Visual identification tasks show human speakers can exhibit considerable variation in their understanding, representation and verification of certain quantifiers.", "labels": [], "entities": [{"text": "Visual identification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7024487853050232}]}, {"text": "This paper initiates an investigation into neural models of these psycho-semantic tasks.", "labels": [], "entities": []}, {"text": "We trained two types of network-a convolutional neural network (CNN) model and a recurrent model of visual attention (RAM)-on the \"most\" verification task from Pietroski et al.", "labels": [], "entities": []}, {"text": "(2009), manipulating the visual scene and novel notions of task duration.", "labels": [], "entities": []}, {"text": "Our results qualitatively mirror certain features of human performance (such as sensitivity to the ratio of set sizes, indicating a reliance on approximate number) while differing in interesting ways (such as exhibiting a subtly different pattern for the effect of image type).", "labels": [], "entities": []}, {"text": "We conclude by discussing the prospects for using neural models as cognitive models of this and other psychosemantic tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantics -the scientific study of meaning -has traditionally studied the truth-conditions of sentences and how the meanings of sub-sentential expressions combine to generate them.", "labels": [], "entities": []}, {"text": "How exactly truth-conditions are represented and then deployed in concrete acts of production and comprehension has often not been seen as belonging to the purview of semantics properly.", "labels": [], "entities": []}, {"text": "A recent line of work, however, has argued that the mental representation of the meanings of expressions bias behavior in cognitive tasks in ways that allow us to adjudicate between truth-conditionally equivalent but representationally distinct semantic theories.", "labels": [], "entities": []}, {"text": "In particular, considered the verification of the sentence \"Most of the dots are yellow\".", "labels": [], "entities": []}, {"text": "The meaning of 'most' can be expressed in distinct, but truth-conditionally equivalent ways.", "labels": [], "entities": []}, {"text": "For instance (where, in the running example, A is the set of dots, and B the set of yellow things): \u2022 most(A)(B) = 1 iff |A \u2229 B| > |A \\ B| \u2022 most(A)(B) = 1 iff there is f : A \\ B \u2192 A \u2229 B that is one-to-one, but not onto The former says that the number of dots which are yellow is larger than the number of non-yellow dots, while the latter says that the former can be paired off with the latter, with some yellow dots remaining.", "labels": [], "entities": []}, {"text": "Whilst these representations are truth conditionally equivalent, each is associated with a distinct verification strategy to evaluate those truth conditions.", "labels": [], "entities": []}, {"text": "When deciding whether most of the dots are yellow: the former representation is associated with an algorithm for computing and comparing two cardinalities, while the latter representation is associated with an algorithm for checking whether a certain correspondence between yellow and non-yellow dots exists.", "labels": [], "entities": []}, {"text": "Whilst a speaker maybe capable of implementing many possible strategies,'s claim is that, all other things being equal, speakers are biased towards using the default strategy associated with their representation.", "labels": [], "entities": []}, {"text": "sought to determine whether speakers prefer one of the above representations by testing which verification strategy they typically use.", "labels": [], "entities": []}, {"text": "By manipulating the arrangement of the dots in images against which 'most' was verified, they created conditions which should ease the implementation of one of the strategies (e.g. dots arranged in pairs should favour correspondence).", "labels": [], "entities": []}, {"text": "They found no difference in verification accuracy between three of the four image types used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9702915549278259}]}, {"text": "Participants were significantly more accurate on the remaining image type, which consisted of two paired columns of colour sorted dots.", "labels": [], "entities": [{"text": "accurate", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9777451157569885}]}, {"text": "Their analysis suggested that the participants used the columns' lengths as a proxy for set cardinality, rather than using a correspondence strategy.", "labels": [], "entities": []}, {"text": "The results of the remaining three image types were explaind very well by a psychophyiscal model of approximate number.", "labels": [], "entities": []}, {"text": "Given that this system cannot be used to implement a correspondence strategy, they concluded that the meaning of 'most' is best represented in the former way.", "labels": [], "entities": []}, {"text": "In this paper, we begin to develop robust mechanistic cognitive models of their sentence verification task to help elucidate the factors underlying the psychosemantics of 'most'.", "labels": [], "entities": [{"text": "sentence verification task", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.7893499930699667}]}, {"text": "In particular, we are interested in the following question: do various neural models show the potential to be developed into good cognitive models of the meaning of 'most'?", "labels": [], "entities": []}, {"text": "A good cognitive model does at least two things: (i) fits human data well and (ii) has movable parameters that enable new predictions to be made.", "labels": [], "entities": []}, {"text": "To address this question, we subjected two different classes of models -convolutional networks and recurrent models of visual attention -to the experimental design from, together with an additional and novel manipulation for 'task duration' (inspired by).", "labels": [], "entities": []}, {"text": "This allows us to assess the models along both dimensions (i) and (ii).", "labels": [], "entities": []}, {"text": "Our key contributions are: \u2022 Subjecting neural models to prominent tasks from the psychosemantics literature.", "labels": [], "entities": []}, {"text": "\u2022 Operationalizing 'task duration' in two distinct ways: depth of a convolutional network, and the number of glimpses in a model of visual attention.", "labels": [], "entities": [{"text": "Operationalizing 'task duration'", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.8469830989837647}]}, {"text": "The key findings from our experiments are: \u2022 Both models exhibit patterns of behavior qualitatively similar to humans, including sensitivity to dot ratio.", "labels": [], "entities": [{"text": "sensitivity to dot ratio", "start_pos": 129, "end_pos": 153, "type": "METRIC", "confidence": 0.7238394692540169}]}, {"text": "\u2022 The psychophysical model of approximate number fits model data well, with parameters not too far from human participants.", "labels": [], "entities": []}, {"text": "\u2022 Model performance is effected by the image type in a subtly different way than human performance.", "labels": [], "entities": []}, {"text": "\u2022 The effect of task duration is more robust for the convolutional networks than for visual attention.", "labels": [], "entities": []}, {"text": "After discussing related work in the next section, we outline the hypotheses of our experiment, before a full explanation of our methods and results.", "labels": [], "entities": []}, {"text": "We conclude by discussing the results and outlining future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Multiple logistic regression of the CNN trials.  Significance: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1.", "labels": [], "entities": []}, {"text": " Table 1. The model shows that the  log-odds of the VGG7-11 networks correctly pre- dicting a stimulus' label are significantly reduced  as the stimulus' dot set ratio becomes more bal- anced. We found no significant effect for either of  our control variables (absolute difference and to- tal number). These findings strongly support Hy- pothesis 1. Holding all other variables constant,  VGG7-11 were significantly less likely to predict  the correct label of scattered random images than  scattered pairs images. Given that the lack of dif- ference between the images types that could not  be included in the analysis appears to be due to  ceiling effects, we interpret these findings as sup- porting Hypothesis 2. Holding all other variables  constant, VGG7 was significantly less likely than  VGG11 to make a correct classification. No dif- ference was found between VGG9 and 11. Again,  as the lack of difference between the VGG9+ net- works appears to be best explained by response  invariance due to ceiling effects, we cautiously in- terpret these findings as supporting Hypothesis 3.  Finally, we found a significant positive interaction", "labels": [], "entities": []}, {"text": " Table 2: Multiple logistic regression on RAM trials.", "labels": [], "entities": []}, {"text": " Table 2. According to the model, the log  odds of a RAM network correctly labelling stimuli  is significantly reduced as set ratios become more  balanced. We also found a small but significant ef- fect of total dots, indicating that the likelihood of a  correct prediction increases with total dots. This is  unsurprising, as increasing total dots reduces im- age sparseness, increasing the odds that glimpses  will contain dots. This can be especially important  for the initial glimpse, which has a random loca- tion. This does not invalidate the dot ratio finding,  given their comparative effect sizes. No significant  effect was found for absolute difference. These  findings support Hypothesis 1. The log odds of  a RAM network predicting the correct labels for  column pairs mixed, scattered pairs or scattered  random images was significantly lower (by vary- ing degrees) than for column sorted pairs images.  This strongly supports Hypothesis 2. We found no  significant difference in the likelihood of the 4-16  glimpse RAM networks correctly labelling stimuli  than their comparison class, the 24 glimpse RAM  network. These findings do not support Hypoth- esis 3. Finally, we found a small but significant  positive interaction between dot ratio and RAM8,  suggesting that the increase in log-odds of correct  prediction per unit increase in dot ratio is stronger  for RAM8 than for RAM24. Because the effect  size is small, we caution against over-interpreting", "labels": [], "entities": []}, {"text": " Table 3: Weber fractions and R 2 for the ANS model.", "labels": [], "entities": [{"text": "R 2", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9772903025150299}, {"text": "ANS", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.6211414933204651}]}, {"text": " Table 4: Weber fractions (w) and correlations (R 2 ) for all models and all trial types.", "labels": [], "entities": [{"text": "correlations (R 2 )", "start_pos": 34, "end_pos": 53, "type": "METRIC", "confidence": 0.9033012866973877}]}]}