{"title": [{"text": "Neural and Linear Pipeline Approaches to Cross-lingual Morphological Analysis", "labels": [], "entities": [{"text": "Neural and Linear Pipeline Approaches", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.568489384651184}, {"text": "Cross-lingual Morphological Analysis", "start_pos": 41, "end_pos": 77, "type": "TASK", "confidence": 0.6645487646261851}]}], "abstractContent": [{"text": "This paper describes T\u00fcbingen-Oslo team's participation in the cross-lingual morphological analysis task in the VarDial 2019 evaluation campaign.", "labels": [], "entities": [{"text": "cross-lingual morphological analysis task", "start_pos": 63, "end_pos": 104, "type": "TASK", "confidence": 0.7625907957553864}, {"text": "VarDial 2019 evaluation campaign", "start_pos": 112, "end_pos": 144, "type": "DATASET", "confidence": 0.80469910800457}]}, {"text": "We participated in the shared task with a standard neural network model.", "labels": [], "entities": []}, {"text": "Our model achieved analysis F1-scores of 31.48 and 23.67 on test languages Karachay-Balkar (Turkic) and Sardinian (Romance) respectively.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9185724854469299}]}, {"text": "The scores are comparable to the scores obtained by the other participants in both language families, and the analysis score on the Romance data set was also the best result obtained in the shared task.", "labels": [], "entities": [{"text": "Romance data set", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.7916786173979441}]}, {"text": "Besides describing the system used in our shared task participation , we describe another, simpler, model based on linear classifiers, and present further analyses using both models.", "labels": [], "entities": []}, {"text": "Our analyses, besides revealing some of the difficult cases, also confirm that the usefulness of a source language in this task is highly correlated with the similarity of source and target languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological analysis is one of the basic tasks in natural language processing (NLP).", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.92293781042099}, {"text": "natural language processing (NLP)", "start_pos": 52, "end_pos": 85, "type": "TASK", "confidence": 0.809059351682663}]}, {"text": "The need for morphological analysis becomes particularly important in processing morphologically rich languages, where analysis of words can both be challenging and fruitful.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7380378842353821}]}, {"text": "Morphological analysis can be useful in downstream NLP tasks as well as being useful for (linguistic) research.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9172954261302948}]}, {"text": "Traditionally, morphological analyzers have been developed using finite state transducers (FSTs).", "labels": [], "entities": [{"text": "morphological analyzers", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.7970674932003021}]}, {"text": "Finite-state morphological analyzers define a lexicon and a set of rules to specify both morphotactics and morpho-phonological (or orthographic) alternations.", "labels": [], "entities": [{"text": "Finite-state morphological analyzers", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6112696429093679}]}, {"text": "The resulting rule-based system is compiled into a finite state transducer which is capable of analyzing a given word to an underlying linguistic representation.", "labels": [], "entities": []}, {"text": "The resulting FSTs are fast, and can be used fora range of tasks from stemming/lemmatization to full morphological analysis.", "labels": [], "entities": [{"text": "FSTs", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.7956245541572571}, {"text": "stemming/lemmatization", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.8431040445963541}]}, {"text": "As well as transducing word forms to a linguistic analysis, they can also be used in reverse to generate the word form(s) of a given linguistic representation.", "labels": [], "entities": []}, {"text": "Finite-state morphological analyzers have been used successfully fora broad range of NLP tasks, and are available for most of the world's major languages.", "labels": [], "entities": [{"text": "Finite-state morphological analyzers", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6069939434528351}]}, {"text": "Finite-state analyzers also exist for all of the languages that are featured in this shared task (examples of such analyzers include,.", "labels": [], "entities": []}, {"text": "On the downside, developing these analyzers requires substantial expert effort, 1 which in some cases may not even exist, e.g., for languages with few speakers where experts are also hard to find.", "labels": [], "entities": []}, {"text": "A potential solution to aid developing morphological analysis tools is to use unsupervised methods.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8154374063014984}]}, {"text": "Earlier attempts to develop unsupervised morphological analysis tools, mostly within Morpho Challenge shared tasks (, returned rather mixed, often sub-optimal results (see, fora survey).", "labels": [], "entities": [{"text": "Morpho Challenge shared tasks", "start_pos": 85, "end_pos": 114, "type": "DATASET", "confidence": 0.8361005038022995}]}, {"text": "Another approach for obtaining morphological analyses for languages without a morphological analyzer is based on transfer learning, which has become a widespread approach in NLP and related disciplines rather recently (.", "labels": [], "entities": []}, {"text": "The general idea is to train a supervised machine learning model that predicts analyses of word forms in a target language using gold-standard analyses that exist in other related languages.", "labels": [], "entities": []}, {"text": "The present shared task, cross-lingual morphological analysis, takes the second approach.", "labels": [], "entities": [{"text": "cross-lingual morphological analysis", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.79513019323349}]}, {"text": "Track 1 of the task that we participated in aims to analyze words in a 'surprise' language, given goldstandard analyses of words in languages in the same language family.", "labels": [], "entities": []}, {"text": "The second track included some additional resources (see for further details about the task).", "labels": [], "entities": []}, {"text": "The present task is also strongly related to the series of SIGMORPHON (re)inflection tasks, where the emphasis is in generation of the inflected forms rather than producing an analysis.", "labels": [], "entities": []}, {"text": "Another difference between the present task and the inflection tasks is also the level of ambiguity.", "labels": [], "entities": []}, {"text": "In inflection tasks, especially in context, ambiguity level is rather low, making it less pressing to produce multiple results, while dealing with ambiguity is more important in morphological analysis.", "labels": [], "entities": [{"text": "ambiguity level", "start_pos": 44, "end_pos": 59, "type": "METRIC", "confidence": 0.915518194437027}]}, {"text": "We developed multiple systems for the task.", "labels": [], "entities": []}, {"text": "Our main system was a neural encoder-decoder architecture, where we used a recurrent network as encoder and lemma decoder, but unlike many earlier examples, we do not consider POS tags and morphological features as part of the output sequence.", "labels": [], "entities": []}, {"text": "Although they share the encoder, the tags are predicted by multi-layer feed-forward neural classifiers.", "labels": [], "entities": []}, {"text": "The second, simpler method is a set of linear SVM classifiers.", "labels": [], "entities": []}, {"text": "Besides describing both models, we report further experiments and analyses, including a comparison of the models, a detailed error analysis, and a set of experiments investigating the roles of individual source languages in transfer learning.", "labels": [], "entities": []}], "datasetContent": [{"text": "The CMA task included data from two language families, Romance (ROA) and Turkic (TRK).", "labels": [], "entities": []}, {"text": "Since we participate only on track 1, we only make use of morphological analyses released by the shared task organizers.", "labels": [], "entities": []}, {"text": "The reader is referred to for detailed description of the data set.", "labels": [], "entities": []}, {"text": "We give a brief description of the data set here.", "labels": [], "entities": []}, {"text": "The Turkic (TRK) data consisted of training samples from Bashkir (bak), Kazakh (kaz), Kyrgyz (kir), Tatar (tat) and Turkish (tur), Turkic development data came from Crimean Tatar (crh), and test data was from Karachay-Balkar (krc).", "labels": [], "entities": []}, {"text": "The Romance (ROA) data consisted of training samples from Catalan (cat), French (fra), Italian (ita), Portuguese (por) and Spanish (spa).", "labels": [], "entities": [{"text": "Romance (ROA)", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.844056561589241}]}, {"text": "Romance development and test data were from Asturian (ast) and Sardinian (srd) respectively.", "labels": [], "entities": []}, {"text": "The number of word forms along with the number of lemmas, tags (POS and morphological feature combinations) and analyses per word form for each language is presented in.", "labels": [], "entities": []}, {"text": "For both language families, the task involves predicting possibly multiple analyses consisting of a lemma, a POS tag, and a set of morphological feature-value pairs for each word form (examples    shown in).", "labels": [], "entities": []}, {"text": "The POS tag set used for both languages consist of nouns, adjectives, adverbs, and verbs.", "labels": [], "entities": [{"text": "POS tag set", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.6904565294583639}]}, {"text": "The number of unique morphological feature-value combinations is 89 in the ROA training set, and 1 013 in the TRK training set.", "labels": [], "entities": [{"text": "ROA training set", "start_pos": 75, "end_pos": 91, "type": "DATASET", "confidence": 0.8932038346926371}, {"text": "TRK training set", "start_pos": 110, "end_pos": 126, "type": "DATASET", "confidence": 0.9347654382387797}]}, {"text": "Following the official evaluation script, we report precision, recall and F1-scores, for lemmas, tags (combination of POS tags and morphological features) and full analysis (combination of all) for each word form.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9995833039283752}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9993877410888672}, {"text": "F1-scores", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9975711703300476}]}, {"text": "In some experiments we also report separate scores for POS tags and morphological features.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 55, "end_pos": 63, "type": "TASK", "confidence": 0.5867545306682587}]}, {"text": "We compare our models against the competition baseline, which is a neural machine translation model (Silfverberg and Tyers, 2019).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples taken from Spanish (ROA track) and Turkish (TRK track) training data for the morphological  prediction task.", "labels": [], "entities": [{"text": "morphological  prediction task", "start_pos": 96, "end_pos": 126, "type": "TASK", "confidence": 0.9087425867716471}]}, {"text": " Table 2: Statistics on individual languages of CMA  analysis data. The column 'words' is the number of  word forms, the other columns indicate the ambiguity,  e.g., 'pos' indicates number of part-of-speech tags per  word form. 'analysis' indicate the full-analysis ambi- guity, 'tag' indicates ambiguity of full morphological  tag (combination of the POS and morphological fea- tures).", "labels": [], "entities": [{"text": "CMA  analysis data", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.7056381702423096}]}, {"text": " Table 4: Official results obtained by our neural model  in comparison to the shared-task baseline. The scores  are F1-scores.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9983513355255127}]}, {"text": " Table 5: Detailed results on the development set in comparison to the our linear baseline (Linear) as well as the  competition baseline (Baseline). Besides the F1 scores (F) we also present precision and recall. Last two groups,  'POS' and 'Morphology' columns are a breakdown of the 'Tag' scores to part of speech tags and morphological  features, respectively.", "labels": [], "entities": [{"text": "F1 scores (F)", "start_pos": 161, "end_pos": 174, "type": "METRIC", "confidence": 0.955385959148407}, {"text": "precision", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.999505877494812}, {"text": "recall", "start_pos": 205, "end_pos": 211, "type": "METRIC", "confidence": 0.9990247488021851}, {"text": "POS", "start_pos": 232, "end_pos": 235, "type": "METRIC", "confidence": 0.8990685343742371}]}, {"text": " Table 6: False positive (FP) and false negative (FN) er- ror rates on feature-value pairs on Turkic development  set. The rates are aggregated over the feature label.", "labels": [], "entities": [{"text": "False positive (FP) and false negative (FN) er- ror", "start_pos": 10, "end_pos": 61, "type": "METRIC", "confidence": 0.8588431434971946}, {"text": "Turkic development  set", "start_pos": 94, "end_pos": 117, "type": "DATASET", "confidence": 0.694592277208964}]}, {"text": " Table 7: False positive (FP) and false negative (FN)  error rates on feature-value pairs on Romance devel- opment set. The rates are aggregated over the feature  label.", "labels": [], "entities": [{"text": "False positive (FP) and false negative (FN)  error rates", "start_pos": 10, "end_pos": 66, "type": "METRIC", "confidence": 0.8539456908519452}, {"text": "Romance devel- opment set", "start_pos": 93, "end_pos": 118, "type": "DATASET", "confidence": 0.8947664499282837}]}]}