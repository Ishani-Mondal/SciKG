{"title": [{"text": "Recursive Routing Networks: Learning to Compose Modules for Language Understanding", "labels": [], "entities": [{"text": "Recursive Routing Networks", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8756818175315857}, {"text": "Language Understanding", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7324319183826447}]}], "abstractContent": [{"text": "We introduce Recursive Routing Networks (RRNs), which are modular, adaptable models that learn effectively in diverse environments.", "labels": [], "entities": []}, {"text": "RRNs consist of a set of functions, typically organized into a grid, and a meta-learner decision-making component called the router.", "labels": [], "entities": []}, {"text": "The model jointly optimizes the parameters of the functions and the meta-learner's policy for routing inputs through those functions.", "labels": [], "entities": []}, {"text": "RRNs can be incorporated into existing ar-chitectures in a number of ways; we explore adding them to word representation layers, recurrent network hidden layers, and classifier layers.", "labels": [], "entities": []}, {"text": "Our evaluation task is natural language inference (NLI).", "labels": [], "entities": [{"text": "natural language inference (NLI)", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.6682011584440867}]}, {"text": "Using the MULTINLI corpus, we show that an RRN's routing decisions reflect the high-level genre structure of that corpus.", "labels": [], "entities": [{"text": "MULTINLI corpus", "start_pos": 10, "end_pos": 25, "type": "DATASET", "confidence": 0.8800179362297058}]}, {"text": "To show that RRNs can learn to specialize to more fine-grained semantic distinctions, we introduce anew corpus of NLI examples involving implicative predicates, and show that the model components become fine-tuned to the inferential signatures that are characteristic of these predicates.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human cognition has an extraordinary ability to modularize, decomposing problems and solving them by re-composing elements from prior solutions, and this ability is nowhere more evident than in language understanding).", "labels": [], "entities": []}, {"text": "Most machine learning architectures lack this modularity, which limits their ability to generalize and leaves them susceptible to catastrophic interference) -forgetting past skills when acquiring new ones.", "labels": [], "entities": []}, {"text": "We propose to address this need for modularity by applying Routing Networks () to natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.6527258555094401}]}, {"text": "Routing Networks are self-organizing networks with two components (): a set of function blocks Figure 1: Given a premise-hypothesis pair x, e.g., t managed to do sand t did s (1), the model needs to learn to predict entails (6).", "labels": [], "entities": []}, {"text": "The router (2) estimates the value of applying each of the available sub-functions to the input.", "labels": [], "entities": []}, {"text": "Given that manage has certain semantic properties, the router may select (3) a function f1 specialized to them.", "labels": [], "entities": []}, {"text": "The module is then applied (4), yielding f1(x).", "labels": [], "entities": []}, {"text": "This process repeats (5), now using f1(x), selecting and applying another sub-function, and soon, until the router is confident in its prediction (6).", "labels": [], "entities": []}, {"text": "which can be applied to transform the input, and a router which makes decisions about which function block to apply next.", "labels": [], "entities": []}, {"text": "Here we introduce Recursive Routing Networks (RRNs), in which there is a single set of composable functions, recursively chosen by the router.", "labels": [], "entities": [{"text": "Recursive Routing Networks (RRNs)", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.6681268662214279}]}, {"text": "RRNs can be applied to different components of modern language understanding architectures with full end-to-end training.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7235930263996124}]}, {"text": "The model jointly optimizes the parameters of selected sub-functions and the meta-learner's policy for how to route inputs through those functions.", "labels": [], "entities": []}, {"text": "As a result, individual sub-functions specialize to specific inputs, and paths through the grid of sub-functions can similarly be trained to reflect specific concepts and capabilities.", "labels": [], "entities": []}, {"text": "RRNs share many intuitions with other modular methods like: Neural Module Networks (, which learn to construct a neural network from pre-defined modules; the Compositional Recursive Learner (, a closely related approach that uti-  When examples are learned using largely separate weights, there is a thin possible distribution of gradient dot products that limits interference, which unfortunately also limits transfer.", "labels": [], "entities": []}, {"text": "This is beneficial for unrelated examples, but frustrates the learning of related ones.", "labels": [], "entities": []}, {"text": "Conversely, when examples are learned using largely shared weights, there is a wide possible distribution of gradient dot products that allows for both high magnitude transfer and interference.", "labels": [], "entities": []}, {"text": "This is beneficial for related examples, but maximizes interference when examples are unrelated.", "labels": [], "entities": []}, {"text": "With RRNs, we provide our network with an unprecedented degree of leverage to learn to navigate this trade-off.", "labels": [], "entities": []}], "datasetContent": [{"text": "The MULTINLI corpus contains 392,702 training examples, 10K dev examples, and 10K test examples.", "labels": [], "entities": [{"text": "MULTINLI corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9234673082828522}]}, {"text": "The examples come from 5 genres: fiction, government reports, the Slate website, the Switchboard corpus, and Berlitz travel guides.", "labels": [], "entities": [{"text": "Slate website", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.8656424582004547}, {"text": "Switchboard corpus", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.881540834903717}]}, {"text": "We treat these genre labels as meta-information for the model (Section 3.1).", "labels": [], "entities": []}, {"text": "Our MULTINLI results are given in, and the learning dynamics in.", "labels": [], "entities": [{"text": "MULTINLI", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9391147494316101}]}, {"text": "The best model combines the Transformer base model with routing in the attentional layers.", "labels": [], "entities": []}, {"text": "Our methods for routing the RNN seem to be less successful, but wordrepresentation routing offers clear benefits with the CBOW base model.", "labels": [], "entities": [{"text": "routing the RNN", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7024941047032675}, {"text": "wordrepresentation routing", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.774643212556839}]}, {"text": "Interestingly, the baseline (non-routed) models perform at the same level as the very similar models without genre labels evaluated by.", "labels": [], "entities": []}, {"text": "It seems that these models are notable to take advantage of the metainformation.", "labels": [], "entities": []}, {"text": "In contrast, RRNs seem to provide the space needed to condition linguistic senses on these labels.", "labels": [], "entities": []}, {"text": "Our hypothesis is that routing will not only lead to better performance on diverse tasks like MULTINLI, but also that the paths -i.e., the sequence of functions selected by the router -followed by the network will reflect high-level task structure.", "labels": [], "entities": [{"text": "MULTINLI", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.7014816403388977}]}, {"text": "suggests that this is the case for MULTINLI.", "labels": [], "entities": [{"text": "MULTINLI", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.707206130027771}]}, {"text": "Here we show the degree of pathoverlap for all pairs of genres.", "labels": [], "entities": []}, {"text": "As we might expect, government (the 9/11 report), Slate (current affairs), and travel cluster together, as distinct from the two more isolated genres (Switchboard; spoken language) and fiction (mostly from the 20th century).", "labels": [], "entities": [{"text": "Slate (current affairs)", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.553619921207428}]}, {"text": "Karttunen (1971) discovered that implicative constructions, such as manage and waste chance (e.g. They wasted their chance to win), have signatures, which characterize the inferences they support in positive and negative contexts.", "labels": [], "entities": []}, {"text": "This makes them the order compelled him to appear as a witness entails he appeared as a witness we have missed an opportunity to examine the art market today contradicts we have examined the art market today Mr Odinga had not been forced to change his plans permits Mr Odinga had changed his plans: Examples from SCI randomly chosen from the validation set.", "labels": [], "entities": []}, {"text": "Each row contains a triplet formed by a premise (left column), a hypothesis (right column), and a label specifying one of the three possible relations (entails, contradicts, permits) holding between premise and hypothesis.", "labels": [], "entities": []}, {"text": "The last row contains an example of a probabilistic implicative (see the main text).", "labels": [], "entities": []}, {"text": "particularly informative for NLI predictions.", "labels": [], "entities": [{"text": "NLI predictions", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.7654416561126709}]}, {"text": "For instance, the positive sentence Joan managed to solve the problem entails Joan solved the problem, and the negative sentence Joan didn't manage to solve the problem contradicts Joan solved the problem, so we say that the verb manage has the signature +|-(.", "labels": [], "entities": []}, {"text": "In contrast, waste chance has the opposite signature, since they wasted the chance to befriend him contradicts they befriended him, and they didn't waste the chance to befriend him entails they befriended him.", "labels": [], "entities": []}, {"text": "There are seven implicative signatures: six were previously known, and we found an additional one (+|+; e.g. take no time to).", "labels": [], "entities": []}, {"text": "See Appendix C for additional details.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.7852800488471985}]}, {"text": "Signatures are compositional: when two or more implicative constructions are composed in a sentence, they create a nested implicative construction whose signature is determined by the signatures of the individual verbs ().", "labels": [], "entities": []}, {"text": "For example, John managed to remember to get the keys entails John got the keys, where the nested implicative manage to remember has the overall signature +|-.", "labels": [], "entities": []}, {"text": "We also see a more limited form of compositionality inside phrasal implicatures; their signatures are often largely determined by the lexical semantic family of their constituent words.", "labels": [], "entities": []}, {"text": "Therefore, signatures make implicatives ideal for evaluating different degrees of compositional generalization with RRNs, as they provide valuable meta-information (Section 3.1  Routed models that achieve good performance on SCI show a strong indication of proper learning of entailment and contradiction, and some difficulties with neutral cases, as indicated by the confusion matrix in.", "labels": [], "entities": []}, {"text": "An inspection of common errors of the CBOW WP model shows a number of cases related to the probabilistic component of the signature.", "labels": [], "entities": [{"text": "CBOW WP model", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.8318796753883362}]}, {"text": "For example, Jerry got a chance to pitch was marked as contradicting Jerry did not manage to pitch, when the gold label is indeed permits.", "labels": [], "entities": []}, {"text": "In this case, if the premise is true then there is a small chance that the author would regard the hypothesis as false and therefore predict contradicts as the model did.", "labels": [], "entities": []}, {"text": "Other errors involve coreference, such as the prediction of entailment between you took the time to review my presentation and you reviewed his presentation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for MULTINLI and SCI with different baselines and their routed versions. We report average accuracy with", "labels": [], "entities": [{"text": "MULTINLI", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.43911927938461304}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9924639463424683}]}, {"text": " Table 3: SCI statistics. Top: Percentage of validated pairs", "labels": [], "entities": []}]}