{"title": [{"text": "Cross-domain Text Classification with Multiple Domains and Disparate Label Sets", "labels": [], "entities": [{"text": "Cross-domain Text Classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6636197765668234}]}], "abstractContent": [{"text": "Advances in transfer learning have let go the limitations of traditional supervised machine learning algorithms for being dependent on annotated training data for training new models for every new domain.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.9688360095024109}]}, {"text": "However, several applications encounter scenarios where models need to transfer/adapt across domains when the label sets vary both in terms of count of labels as well as their connotations.", "labels": [], "entities": []}, {"text": "This paper presents first-of-its-kind transfer learning algorithm for cross-domain classification with multiple source domains and dis-parate label sets.", "labels": [], "entities": [{"text": "cross-domain classification", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.7354072630405426}]}, {"text": "It starts with identifying transferable knowledge from across multiple domains that can be useful for learning the target domain task.", "labels": [], "entities": []}, {"text": "This knowledge in the form of selective labeled instances from different domains is congregated to form an auxiliary training set which is used for learning the target domain task.", "labels": [], "entities": []}, {"text": "Experimental results validate the efficacy of the proposed algorithm against strong baselines on areal world social media and the 20 Newsgroups datasets.", "labels": [], "entities": [{"text": "20 Newsgroups datasets", "start_pos": 130, "end_pos": 152, "type": "DATASET", "confidence": 0.7531780997912089}]}], "introductionContent": [{"text": "A fundamental assumption in supervised statistical learning is that training and test data are independently and identically distributed (i.i.d.) samples drawn from a distribution.", "labels": [], "entities": []}, {"text": "Otherwise, good performance on test data cannot be guaranteed even if the training error is low.", "labels": [], "entities": []}, {"text": "On the other hand, transfer learning techniques allow domains, tasks, and distributions used in training and testing to be different, but related.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.9056738018989563}]}, {"text": "It works in contrast to traditional supervised techniques on the principle of transferring learned knowledge across domains.", "labels": [], "entities": []}, {"text": "Pan and Yang, in their survey paper (2010), de- scribed different transfer learning settings depending on if domains and tasks vary as well as labeled data is available in one/more/none of the domains.", "labels": [], "entities": []}, {"text": "In this paper, we propose a generic solution for multi-source transfer learning where domains and tasks are different and no labeled data is available in the target domain.", "labels": [], "entities": [{"text": "multi-source transfer learning", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.7515634099642435}]}, {"text": "This is a relatively less chartered territory and arguably a more generic setting of transfer learning.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.9238042831420898}]}, {"text": "Motivating example: Consider asocial media consulting company helping brands to monitor their social media channels.", "labels": [], "entities": []}, {"text": "Two problems typically of interest are: (i) sentiment classification (is a post positive/negative/neutral?) and (ii) subject classification (what was the subject of a post?).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.8851037621498108}, {"text": "subject classification", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.6789052188396454}]}, {"text": "While sentiment classification attempts to classify a post based on its polarity, subject classification is towards identifying the subject (or topic) of the post, as illustrated in.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.884676992893219}, {"text": "subject classification", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.7152290791273117}]}, {"text": "The company has been using standard classification techniques from an off-the-shelf machine learning toolbox.", "labels": [], "entities": []}, {"text": "While machine learning toolkit helps them to create and apply statistical models efficiently, the same model cannot be applied on anew collection due to variations in data distributions across collections . It requires a few hundreds of manually labeled posts for every task on every collec-tion.", "labels": [], "entities": []}, {"text": "As social media are extremely high velocity and low retention channels, human labeling efforts act like that proverbial narrow bottleneck.", "labels": [], "entities": []}, {"text": "Need of the hour was to reduce, if not eliminate, the human-intensive labeling stage while continue to use machine learning models for new collections.", "labels": [], "entities": [{"text": "labeling", "start_pos": 70, "end_pos": 78, "type": "TASK", "confidence": 0.8831273913383484}]}, {"text": "Several transfer learning techniques exist in the literature which can reduce labeling efforts required for performing tasks in new collections.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.889240175485611}]}, {"text": "Tasks such as sentiment classification, named entity recognition (NER), part of speech (POS) tagging that have invariant label sets across domains, have shown to be greatly benefited from these works.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.9652512967586517}, {"text": "named entity recognition (NER)", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.8121874630451202}, {"text": "part of speech (POS) tagging", "start_pos": 72, "end_pos": 100, "type": "TASK", "confidence": 0.612188058240073}]}, {"text": "On the other hand, tasks like subject classification that have disparate label sets across domains have not been able to gain at pace with the advances in transfer learning.", "labels": [], "entities": [{"text": "subject classification", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7061571329832077}]}, {"text": "Towards that we formulate the problem of Cross-domain classification with disparate label sets as learning an accurate model for the new unlabeled target domain given labeled data from multiple source domains where all domains have (possibly) different label sets.", "labels": [], "entities": [{"text": "Cross-domain classification", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.8668664395809174}]}, {"text": "Our contributions: To the best of our knowledge, this is the first work to explore the problem of cross-domain text classification with multiple source domains and disparate label sets.", "labels": [], "entities": [{"text": "cross-domain text classification", "start_pos": 98, "end_pos": 130, "type": "TASK", "confidence": 0.6771263380845388}]}, {"text": "The other contributions of this work includes a simple yet efficient algorithm which starts with identifying transferable knowledge from across multiple source domains useful for learning the target domain task.", "labels": [], "entities": []}, {"text": "Specifically, it identifies relevant class-labels from the source domains such that the instances in those classes can induce classseparability in the target domain.", "labels": [], "entities": []}, {"text": "This transferable knowledge is accumulated as an auxiliary training set for an algorithm to learn the target domain classification task followed by suitable transformation of the auxiliary training instances.", "labels": [], "entities": []}, {"text": "Organization of the paper is as follows: Section 2 presents the preliminaries and notation, Section 3 summarizes the related work.", "labels": [], "entities": [{"text": "preliminaries", "start_pos": 64, "end_pos": 77, "type": "METRIC", "confidence": 0.9655820727348328}]}, {"text": "Section 4 and 5 present the proposed algorithm and experimental results respectively.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Comprehensive experiments are performed to evaluate the efficacy of the proposed algorithm for cross-domain classification with disparate label sets across domains on two datasets.", "labels": [], "entities": [{"text": "cross-domain classification", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.7354910373687744}]}, {"text": "The first dataset is a real-world Online Social Media (OSM) dataset which consists of 74 collections.", "labels": [], "entities": []}, {"text": "Each collection comprises comments/tweets that are collected based on user-defined keywords.", "labels": [], "entities": []}, {"text": "These keywords are fed to a listening engine which crawls the social media (i.e. Twitter.com) and fetches comments matching the keywords.", "labels": [], "entities": []}, {"text": "The task is to classify the comments in a collection  into user-defined categories.", "labels": [], "entities": []}, {"text": "These user-defined categories may vary across collections in terms of count as well as their connotations.", "labels": [], "entities": []}, {"text": "shows an example of the user-defined categories fora few collections related to \"Apple\" products.", "labels": [], "entities": []}, {"text": "In the experiments, one collection is used as unlabeled target collection and the remaining collections are used as the labeled source collections.", "labels": [], "entities": []}, {"text": "We randomly selected 5 target collections to report the performance, as described in.", "labels": [], "entities": []}, {"text": "The second dataset is the 20 Newsgroups (NG)) dataset which comprises 20, 000 news articles organized into 6 groups with different sub-groups both in terms of count as well as connotations, as shown in.", "labels": [], "entities": [{"text": "Newsgroups (NG)) dataset", "start_pos": 29, "end_pos": 53, "type": "DATASET", "confidence": 0.6212142527103424}]}, {"text": "Two different experiments are performed on this dataset.", "labels": [], "entities": []}, {"text": "In the first experiment (\"Exp-1\"), one group is considered as the target domain and the remaining 5 groups as the source domains.", "labels": [], "entities": []}, {"text": "In the second experiment (\"Exp-2\"), one sub-group from each of the first five groups 5 is randomly selected to synthesize a target domain while all the groups (with the remaining sub-groups) are used as source domains.", "labels": [], "entities": []}, {"text": "shows an example on how to synthesize target domains in \"Exp-2\".", "labels": [], "entities": []}, {"text": "There are 720 possible target domains in this experiment and we report the average performance across all possible target domains, referred to as \"Grp 7\".", "labels": [], "entities": []}, {"text": "The task in both the experiments is to categorize the target domain into its K categories (sub-groups) using labeled data from multiple source domains.", "labels": [], "entities": []}, {"text": "The performance is reported in terms of classification accuracy on the target domain.", "labels": [], "entities": [{"text": "classification", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.9300450086593628}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9242624640464783}]}, {"text": "There is no definite mapping between the actual class-labels in the target domain and the K categories (i.e. induced categories) in the auxiliary training set.", "labels": [], "entities": []}, {"text": "Therefore, we sequentially evaluate all possible one-to-one mappings between the K categories in the auxiliary training set and target domain to report results for the best performing mapping.", "labels": [], "entities": []}, {"text": "The performance of the proposed algorithm is skylined by the in-domain performance (Gold), i.e. a classifier trained and tested on the labeled target domain data.", "labels": [], "entities": [{"text": "in-domain performance (Gold)", "start_pos": 61, "end_pos": 89, "type": "METRIC", "confidence": 0.6909798741340637}]}, {"text": "We also compared the performance with spherical K-means clustering) used to group the target domain data into K categories against the ground truth, referred to CL.", "labels": [], "entities": []}, {"text": "Spherical K-means clustering is based on cosine similarity and performs better for high-dimensional sparse data such as text.", "labels": [], "entities": []}, {"text": "To compare with a baseline and an existing adaptation algorithm, we selected the most similar source domain with exactly K number of classlabels and report the performance on the best possible mapping, as described in Section 5.2.", "labels": [], "entities": []}, {"text": "To compute the baseline (BL), a classifier trained on the source domain is used to categorize the target domain.", "labels": [], "entities": [{"text": "baseline (BL)", "start_pos": 15, "end_pos": 28, "type": "METRIC", "confidence": 0.6443024501204491}]}, {"text": "A widely used domain adaptation algorithm, namely structural correspondence learning (SCL) () is also applied using the selected source domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7277063429355621}, {"text": "structural correspondence learning (SCL)", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.7859886487325033}]}, {"text": "Results in and show the efficacy of the proposed algorithm for cross-domain classification with disparate label sets as it outperforms other approaches by at least 15%.", "labels": [], "entities": [{"text": "cross-domain classification", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.7601557672023773}]}, {"text": "Coll ID(#) refers to the target collection and the corresponding count of class-labels.", "labels": [], "entities": [{"text": "Coll ID(#)", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8158833781878153}]}, {"text": "Results in also compare the performance of the proposed technique without the distributional normalization of the auxiliary training set, referred to as \"W/O\".", "labels": [], "entities": []}, {"text": "Results suggest that suitably weighing instances from the auxiliary training set mitigates the distributional variations and enhances the cross-domain performance by at least 3.3%.", "labels": [], "entities": []}, {"text": "Results in show that the proposed algorithm outperforms other techniques for both the experiments by at least 15 % and 18% respectively on the 20 Newsgroups dataset.", "labels": [], "entities": [{"text": "20 Newsgroups dataset", "start_pos": 143, "end_pos": 164, "type": "DATASET", "confidence": 0.9128828644752502}]}, {"text": "In, \"-\" refers to the cases where a single source domain with the same number of class-labels as in the target domain is not available.", "labels": [], "entities": []}, {"text": "In \"Exp-1\" where the source and target categories vary in terms of counts as well as their connotations, the proposed algorithm efficiently induces the classes in the unlabeled target domain using the partial transferable knowledge from multiple sources.", "labels": [], "entities": []}, {"text": "For \"Exp-2\", it is observed that the performance of the proposed algorithm is better than the performance in \"Exp-1\" as the target categories have closely related categories (from the same group) in the source do-  mains.", "labels": [], "entities": []}, {"text": "reports the average performance across all the 720 possible combinations of target domains with a standard deviation of 2.6.", "labels": [], "entities": []}, {"text": "validates our assertion that multiple sources are necessary to induce class-separability in the target domain as a single source is not sufficient to cater to the heterogeneity of class-labels across domains.", "labels": [], "entities": []}, {"text": "It also suggests that the proposed algorithm can learn class-separability in the target domain by using arbitrary diverse class-labels from different sources and does not necessarily require class-labels to follow any sort of coarse-tofine mapping across domains.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Table illustrates the collections from the  EMPATH database used in this research.", "labels": [], "entities": [{"text": "EMPATH database", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9335809350013733}]}, {"text": " Table 4: Summarizes the performance of the pro- posed algorithm on the OSM dataset.", "labels": [], "entities": [{"text": "OSM dataset", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.8389185667037964}]}, {"text": " Table 5: Summarizes the performance of the pro- posed algorithm on the 20Newsgroups dataset.", "labels": [], "entities": [{"text": "20Newsgroups dataset", "start_pos": 72, "end_pos": 92, "type": "DATASET", "confidence": 0.9641262292861938}]}, {"text": " Table 7: Comparing the proposed algorithm with  existing domain adaptation algorithms.", "labels": [], "entities": []}, {"text": " Table 8: Comparing different representations.", "labels": [], "entities": []}]}