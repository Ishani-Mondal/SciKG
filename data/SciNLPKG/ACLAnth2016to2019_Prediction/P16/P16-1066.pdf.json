{"title": [{"text": "AraSenTi: Large-Scale Twitter-Specific Arabic Sentiment Lexicons", "labels": [], "entities": []}], "abstractContent": [{"text": "Sentiment Analysis (SA) is an active research area nowadays due to the tremendous interest in aggregating and evaluating opinions being disseminated by users on the Web.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9134621739387512}]}, {"text": "SA of English has been thoroughly researched; however research on SA of Arabic has just flourished.", "labels": [], "entities": [{"text": "SA of English", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8767261107762655}, {"text": "SA of Arabic", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.8370808561642965}]}, {"text": "Twitter is considered a powerful tool for disseminating information and a rich resource for opinionated text containing views on many different topics.", "labels": [], "entities": []}, {"text": "In this paper we attempt to bridge a gap in Arabic SA of Twitter which is the lack of sentiment lexicons that are tailored for the informal language of Twitter.", "labels": [], "entities": []}, {"text": "We generate two lexicons extracted from a large dataset of tweets using two approaches and evaluate their use in a simple lexicon based method.", "labels": [], "entities": []}, {"text": "The evaluation is performed on internal and external da-tasets.", "labels": [], "entities": []}, {"text": "The performance of these automatically generated lexicons was very promising, al-beit the simple method used for classification.", "labels": [], "entities": []}, {"text": "The best F-score obtained was 89.58% on the internal dataset and 63.1-64.7% on the external datasets.", "labels": [], "entities": [{"text": "F-score", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9994833469390869}]}], "introductionContent": [{"text": "The past decade has witnessed the proliferation of social media websites which has led to the production of vast amounts of unstructured text on the Web.", "labels": [], "entities": []}, {"text": "This text can be characterized as objective, i.e. containing facts, or subjective i.e. containing opinions and sentiments about entities.", "labels": [], "entities": []}, {"text": "Sentiment Analysis (SA) is the research field that is concerned with identifying opinions in text and classifying them as positive, negative or neutral.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9204666137695312}]}, {"text": "SA of English has been thoroughly researched; however research on SA of Arabic has just flourished.", "labels": [], "entities": [{"text": "SA of English", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8767261107762655}, {"text": "SA of Arabic", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.8370808561642965}]}, {"text": "Arabic is ranked fourth among languages on the web although it is the fastest growing language on the web among other languages.", "labels": [], "entities": []}, {"text": "Arabic is a morphologically rich language where one lemma can have hundreds of surface forms; this complicates the tasks of SA.", "labels": [], "entities": []}, {"text": "Moreover, the Arabic language has many variants.", "labels": [], "entities": []}, {"text": "The formal language is called Modern Standard Arabic (MSA) and the spoken language differs in different Arabic countries producing numerous Arabic dialects sometimes called informal Arabic or colloquial Arabic.", "labels": [], "entities": []}, {"text": "The language used in social media is known to be highly dialectal).", "labels": [], "entities": []}, {"text": "Dialects differ from MSA phonologically, morphologically and syntactically and they do not have standard orthographies.", "labels": [], "entities": []}, {"text": "Consequently, resources built for MSA cannot be adapted to dialects very well.", "labels": [], "entities": []}, {"text": "The informal language used in social media and in Twitter in particular makes the SA of tweets a challenging task.", "labels": [], "entities": [{"text": "SA of tweets", "start_pos": 82, "end_pos": 94, "type": "TASK", "confidence": 0.8380574584007263}]}, {"text": "The language on social media is known to contain slang, nonstandard spellings and evolves by time.", "labels": [], "entities": []}, {"text": "As such sentiment lexicons that are built from standard dictionaries cannot adequately capture the informal language in social media text.", "labels": [], "entities": []}, {"text": "Therefore, in this paper we propose to generate Arabic sentiment lexicons that are tweet-specific i.e. generated from tweets.", "labels": [], "entities": []}, {"text": "We present two approaches to generating Arabic sentiment lexicons from a large dataset of 2.2 million tweets.", "labels": [], "entities": [{"text": "generating Arabic sentiment lexicons", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.7418259158730507}]}, {"text": "The lexicons are evaluated on three datasets, one internal dataset extracted from the larger dataset of tweets and two external datasets from the literature on Arabic SA.", "labels": [], "entities": [{"text": "Arabic SA", "start_pos": 160, "end_pos": 169, "type": "TASK", "confidence": 0.6015495359897614}]}, {"text": "Moreover, the lexicons are compared to an external Arabic lexicon generated also from tweets.", "labels": [], "entities": []}, {"text": "A simple lexicon-based method is used to evaluate the lexicons.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 reviews the related work on sentiment lexicon generation.", "labels": [], "entities": [{"text": "sentiment lexicon generation", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.9017376104990641}]}, {"text": "Section 3 describes the details of the datasets used to generate the lexicons and how they were collected.", "labels": [], "entities": []}, {"text": "Section 4 presents the approaches used to generate the lexicons.", "labels": [], "entities": []}, {"text": "Section 5 details the experimental setup while Section 6 presents and analyzes the results.", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper and present potential future work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We followed the approaches in previous work on SA of English Twitter to collect the datasets.", "labels": [], "entities": [{"text": "SA of English Twitter", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.7153323963284492}]}, {"text": "As in ( we utilized emoticons as noisy labels to construct the first dataset EMO-TWEET.", "labels": [], "entities": [{"text": "EMO-TWEET", "start_pos": 77, "end_pos": 86, "type": "DATASET", "confidence": 0.7128769159317017}]}, {"text": "Tweets containing the emoticons: \":)\" and \":(\" and the rule \"lang:ar\" (to retrieve Arabic tweets only) were collected during November and December 2015.", "labels": [], "entities": []}, {"text": "The total number of Tweets collected is shown in. and used hashtags of sentiment words such as #good and #bad to create corpora of positive and negative tweets, we adopted a similar method to theirs.", "labels": [], "entities": []}, {"text": "Initially, we tried collecting tweets that contain Arabic sentiment words with hashtags but the search results were too low.", "labels": [], "entities": []}, {"text": "We designated this result to a cultural difference in using hashtags between the western and eastern societies.", "labels": [], "entities": []}, {"text": "Arabs do not use hashtags in this way.", "labels": [], "entities": []}, {"text": "Accordingly we opted to use the sentiment words as keywords without the hashtag sign and the number of search results was substantial.", "labels": [], "entities": []}, {"text": "Tweets containing 10 Arabic words having positive polarity and 10 Arabic words having negative polarity were collected during January 2016.", "labels": [], "entities": []}, {"text": "The keywords are in and the number of tweets collected in Table1.", "labels": [], "entities": []}, {"text": "These results constitute our second dataset KEY-TWEET.", "labels": [], "entities": [{"text": "KEY-TWEET", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.41500619053840637}]}, {"text": "Retweets, tweets containing URLs or media and tweets containing non-Arabic words were all excluded from the dataset.", "labels": [], "entities": []}, {"text": "The reason for excluding tweets with URLs and media is that we found that most of the tweets that contain URLS and media were spam.", "labels": [], "entities": []}, {"text": "We also noticed that although we had specified in the search query that the fetched tweets should be in Arabic \"lang:ar\" some of the tweets were in English and other languages.", "labels": [], "entities": []}, {"text": "So we had to add a filter to eliminate tweets with non-Arabic characters.", "labels": [], "entities": []}, {"text": "In total, the number of collected tweets was around 6.3 million Arabic tweets in a time span of three months.", "labels": [], "entities": []}, {"text": "After filtration and cleaning of the tweets, the remaining were 2.2 million tweets.", "labels": [], "entities": []}, {"text": "To evaluate the performance of the tweetspecific lexicons, we performed a set of experiments using a simple lexicon-based approach, hence no training and/or tuning is required.", "labels": [], "entities": []}, {"text": "We performed a two-way classification on the datasets (positive or negative).", "labels": [], "entities": []}, {"text": "We leave the problem of three and four way classification (positive, negative, neutral, mixed) for future work.", "labels": [], "entities": []}, {"text": "We evaluated the generated lexicons on a dataset of 10,133 tweets extracted from the larger datasets of tweets EMO-TWEET and KEY-TWEET.", "labels": [], "entities": [{"text": "EMO-TWEET", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.7853541970252991}, {"text": "KEY-TWEET", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.5793355703353882}]}, {"text": "The tweets were manually annotated by three annotators that are Arabic native speakers.", "labels": [], "entities": []}, {"text": "The conflict between annotators was resolved by majority voting.", "labels": [], "entities": []}, {"text": "We will call this dataset AraSenTi-Tweet.", "labels": [], "entities": [{"text": "AraSenTi-Tweet", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.907696008682251}]}, {"text": "We also evaluated the generated lexicons on two external datasets of tweets: ASTD by (Nabil et al., 2015) and RR by).", "labels": [], "entities": [{"text": "ASTD", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9648638963699341}, {"text": "RR", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9517718553543091}]}, {"text": "We extracted only the tweets that were labeled as positive or negative from these datasets.", "labels": [], "entities": []}, {"text": "The details of all the datasets used in the experiments are illustrated in.", "labels": [], "entities": []}, {"text": "We plan to release the dataset and the generated lexicons for the public.", "labels": [], "entities": []}, {"text": "Negation significantly affects the sentiment of its scope and consequently affects the evaluation of the lexicons.", "labels": [], "entities": [{"text": "Negation", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.8479587435722351}]}, {"text": "Accordingly, we propose to evaluate the generated lexicons in two settings: with and without negation handling.", "labels": [], "entities": []}, {"text": "We also compare the performance of the generated lexicons with a lexicon that was generated in a very similar approach to one of the lexicons.", "labels": [], "entities": []}, {"text": "Since the datasets are unbalanced, we will report the performance measures of the macroaveraged F-score (F avg ), precision (P) and recall (R) of the positive and negative classes as follows: wherein the case of the positive class: TP is the number of positive tweets classified correctly as positive (true positive), FP is the number of negative tweets falsely classified as positive (false positive), and FN is the number of positive tweets falsely classified as negative (false negatives).", "labels": [], "entities": [{"text": "macroaveraged F-score (F avg )", "start_pos": 82, "end_pos": 112, "type": "METRIC", "confidence": 0.864722470442454}, {"text": "precision (P)", "start_pos": 114, "end_pos": 127, "type": "METRIC", "confidence": 0.955514132976532}, {"text": "recall (R)", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.9707000851631165}, {"text": "FP", "start_pos": 318, "end_pos": 320, "type": "METRIC", "confidence": 0.9830575585365295}, {"text": "FN", "start_pos": 407, "end_pos": 409, "type": "METRIC", "confidence": 0.9885038733482361}]}, {"text": "The same holds for the negative class.", "labels": [], "entities": []}, {"text": "Then the F-score is calculated as: \u00ed \u00b5\u00ed\u00b0\u00b9 \u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u00a3\u00ed \u00b5\u00ed\u00b1\u0094 = \u00ed \u00b5\u00ed\u00b0\u00b9 \u00ed \u00b5\u00ed\u00b1\u009d\u00ed \u00b5\u00ed\u00b1\u009c\u00ed \u00b5\u00ed\u00b1 +\u00ed \u00b5\u00ed\u00b0\u00b9 \u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u0092\u00ed \u00b5\u00ed\u00b1\u0094 2 (6)  AraSenti: Results of the second experimental setup with negation handling on the generated lexicons AraSenti-Trans and AraSenti-PMI and on the external lexicon DAHL", "labels": [], "entities": [{"text": "F-score", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.996320366859436}, {"text": "DAHL", "start_pos": 282, "end_pos": 286, "type": "DATASET", "confidence": 0.8522136807441711}]}], "tableCaptions": [{"text": " Table 1: Number of collected tweets, number of  tweets in datasets after cleaning and filtering and  number of tokens in each dataset.", "labels": [], "entities": []}, {"text": " Table 3: Details of the generated lexicons and the  lexicon they will be compared to.", "labels": [], "entities": []}, {"text": " Table 4. We  plan to release the dataset and the generated lexi- cons for the public.", "labels": [], "entities": []}, {"text": " Table 4: Datasets used in the evaluation of the  generated lexicons.", "labels": [], "entities": []}, {"text": " Table 5: Results of the first experimental setup without negation handling on the generated lexicons  AraSenti-Trans and AraSenti-PMI.", "labels": [], "entities": []}, {"text": " Table 6: Results of the second experimental setup with negation handling on the generated lexicons  AraSenti-Trans and AraSenti-PMI and on the external lexicon DAHL", "labels": [], "entities": [{"text": "DAHL", "start_pos": 161, "end_pos": 165, "type": "DATASET", "confidence": 0.8152137398719788}]}]}