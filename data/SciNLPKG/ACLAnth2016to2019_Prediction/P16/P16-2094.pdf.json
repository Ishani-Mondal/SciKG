{"title": [{"text": "Weakly Supervised Part-of-speech Tagging Using Eye-tracking Data", "labels": [], "entities": [{"text": "Part-of-speech Tagging", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7387504875659943}]}], "abstractContent": [{"text": "For many of the world's languages, there are no or very few linguistically annotated resources.", "labels": [], "entities": []}, {"text": "On the other hand, raw text, and often also dictionaries, can be harvested from the web for many of these languages, and part-of-speech taggers can be trained with these resources.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7376631796360016}]}, {"text": "At the same time, previous research shows that eye-tracking data, which can be obtained without explicit annotation, contains clues to part-of-speech information.", "labels": [], "entities": []}, {"text": "In this work, we bring these two ideas together and show that given raw text, a dictionary, and eye-tracking data obtained from naive participants reading text, we can train a weakly supervised PoS tagger using a second-order HMM with maximum entropy emissions.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 194, "end_pos": 204, "type": "TASK", "confidence": 0.7559987008571625}]}, {"text": "The best model use type-level aggregates of eye-tracking data and significantly outperforms a baseline that does not have access to eye-tracking data.", "labels": [], "entities": []}], "introductionContent": [{"text": "According to Ethnologue, there are around 7,000 languages in the world.", "labels": [], "entities": [{"text": "Ethnologue", "start_pos": 13, "end_pos": 23, "type": "DATASET", "confidence": 0.8676990270614624}]}, {"text": "For most of these languages, no or very little linguistically annotated resources are available.", "labels": [], "entities": []}, {"text": "This is why over the past decade or so, NLP researchers have focused on developing unsupervised algorithms that learn from raw text, which for many languages is widely available on the web.", "labels": [], "entities": []}, {"text": "An example is part-ofspeech (PoS) tagging, in which unsupervised approaches have been increasingly successful (see for an overview).", "labels": [], "entities": [{"text": "part-ofspeech (PoS) tagging", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.5885490417480469}]}, {"text": "The performance of unsupervised PoS taggers can be improved further if dictionary information is available, making it possible to constrain the PoS 1 http://www.ethnologue.com/world tagging process.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.8846971988677979}, {"text": "world tagging", "start_pos": 176, "end_pos": 189, "type": "TASK", "confidence": 0.6064249873161316}]}, {"text": "Again, dictionary information can be harvested readily from the web for many languages (.", "labels": [], "entities": []}, {"text": "In this paper, we show that PoS tagging performance can be improved further by using a weakly supervised model which exploits eye-tracking data in addition to raw text and dictionary information.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9053559303283691}]}, {"text": "Eye-tracking data can be obtained by getting native speakers of the target language to read text while their gaze behavior is recorded.", "labels": [], "entities": []}, {"text": "Reading is substantially faster than manual annotation, and competent readers are available for languages where trained annotators are hard to find or non-existent.", "labels": [], "entities": []}, {"text": "While high quality eye-tracking equipment is still expensive, $100 eye-trackers such as the EyeTribe are already on the market, and cheap eye-tracking equipment is likely to be widely available in the near future, including eyetracking by smartphone or webcam (.", "labels": [], "entities": [{"text": "EyeTribe", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.9575363397598267}]}, {"text": "Gaze patterns during reading are strongly influenced by the parts of speech of the words being read.", "labels": [], "entities": [{"text": "Gaze", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8859193325042725}]}, {"text": "Psycholinguistic experiments show that readers are less likely to fixate on closed-class words that are predictable from context.", "labels": [], "entities": []}, {"text": "Readers also fixate longer on rare words, on words that are semantically ambiguous, and on words that are morphologically complex).", "labels": [], "entities": []}, {"text": "These findings indicate that eye-tracking data should be useful for classifying words by part of speech, and indeed  show that word-type-level aggregate statistics collected from eye-tracking corpora can be used as features for supervised PoS tagging, leading to substantial gains inaccuracy across domains.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 239, "end_pos": 250, "type": "TASK", "confidence": 0.8744455277919769}]}, {"text": "This leads us to hypothesize that gaze data should also improve weakly supervised PoS tagging.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.8696651756763458}]}, {"text": "In this paper, we test this hypothesis by experimenting with a PoS tagging model that uses raw text, dictionary information, and eye-tracking data, but requires no explicit annotation.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.7129683792591095}]}, {"text": "We start with a state-of-the-art unsupervised PoS tagging model, the second-order hidden Markov model with maximum entropy emissions of, which uses only textual features.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.7031899243593216}]}, {"text": "We augment this model with a wide range of features derived from an eye-tracking corpus at training time (type-level gaze features).", "labels": [], "entities": []}, {"text": "We also experiment with token-level gaze features; the use of these features implies that eye-tracking is available both at training time and attest time.", "labels": [], "entities": []}, {"text": "We find that eyetracking features lead to a significant increase in PoS tagging accuracy, and that type-level aggregates work better than token-level features.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.9065324366092682}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9663125872612}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Features in feature selection groups.", "labels": [], "entities": []}, {"text": " Table 3: Tagging accuracy for the baseline, for  models with no text features and for our gaze- enriched models using type and token gaze fea- tures. Significant improvements over the baseline  marked by * (p < 10 \u22123 , McNemar's test).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9810780882835388}]}]}