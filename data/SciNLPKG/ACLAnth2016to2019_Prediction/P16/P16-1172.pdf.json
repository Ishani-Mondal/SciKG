{"title": [{"text": "Optimizing an Approximation of ROUGE -a Problem-Reduction Approach to Extractive Multi-Document Summarization", "labels": [], "entities": [{"text": "Extractive Multi-Document Summarization", "start_pos": 70, "end_pos": 109, "type": "TASK", "confidence": 0.6179685791333517}]}], "abstractContent": [{"text": "This paper presents a problem-reduction approach to extractive multi-document summarization: we propose a reduction to the problem of scoring individual sentences with their ROUGE scores based on supervised learning.", "labels": [], "entities": [{"text": "extractive multi-document summarization", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.5812410215536753}, {"text": "ROUGE scores", "start_pos": 174, "end_pos": 186, "type": "METRIC", "confidence": 0.948234349489212}]}, {"text": "For the summariza-tion, we solve an optimization problem where the ROUGE score of the selected summary sentences is maximized.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.9819718897342682}]}, {"text": "To this end, we derive an approximation of the ROUGE-N score of a set of sentences, and define a principled discrete optimization problem for sentence selection.", "labels": [], "entities": [{"text": "ROUGE-N score", "start_pos": 47, "end_pos": 60, "type": "METRIC", "confidence": 0.9855502247810364}, {"text": "sentence selection", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.7330077588558197}]}, {"text": "Mathematical and empirical evidence suggests that the sentence selection step is solved almost exactly, thus reducing the problem to the sentence scoring task.", "labels": [], "entities": [{"text": "sentence selection step", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.8160157998402914}, {"text": "sentence scoring", "start_pos": 137, "end_pos": 153, "type": "TASK", "confidence": 0.7534188032150269}]}, {"text": "We perform a detailed experimental evaluation on two DUC datasets to demonstrate the validity of our approach.", "labels": [], "entities": [{"text": "DUC datasets", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.9592889547348022}]}], "introductionContent": [{"text": "Multi-document summarization (MDS) is the task of constructing a summary from a topically related document collection.", "labels": [], "entities": [{"text": "Multi-document summarization (MDS)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8893249988555908}]}, {"text": "This paper focuses on the variant of extractive and generic MDS, which has been studied in detail for the news domain using available benchmark datasets from the Document Understanding Conference (DUC).", "labels": [], "entities": [{"text": "Document Understanding Conference (DUC)", "start_pos": 162, "end_pos": 201, "type": "TASK", "confidence": 0.6204986373583475}]}, {"text": "Extractive MDS can be cast as a budgeted subset selection problem) where the document collection is considered as a set of sentences and the task is to select a subset of the sentences under a length constraint.", "labels": [], "entities": [{"text": "Extractive MDS", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.819791167974472}]}, {"text": "State-of-the-art and recent works in extractive MDS solve this discrete optimization problem using integer linear programming or submodular function maximization).", "labels": [], "entities": [{"text": "extractive MDS", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7438937723636627}]}, {"text": "The objective function that is maximized in the optimization step varies considerably in previous work.", "labels": [], "entities": []}, {"text": "For instance, maximize the number of informative words, the coverage of particular concepts, and others maximize a notion of \"summary worthiness\", while minimizing summary redundancy (.", "labels": [], "entities": []}, {"text": "There are also multiple approaches which maximize the evaluation metric for system summaries itself based on supervised Machine Learning (ML).", "labels": [], "entities": []}, {"text": "System summaries are commonly evaluated using ROUGE), a recall oriented metric that measures the n-gram overlap between a system summary and a set of human-written reference summaries.", "labels": [], "entities": [{"text": "System summaries", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.636394590139389}, {"text": "ROUGE", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9831944108009338}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.94915372133255}]}, {"text": "The benchmark datasets for MDS can be employed in two different ways for supervised learning of ROUGE scores: either by training a model that assigns ROUGE scores to individual textual units (e.g., sentences), or by performing structured output learning and directly maximizing the ROUGE scores of the created summaries ().", "labels": [], "entities": []}, {"text": "The latter approach suffers both from the limited amount of training data and from the higher complexity of the machine learning models.", "labels": [], "entities": []}, {"text": "In contrast, supervised learning of ROUGE scores for individual sentences can be performed with simple regression models using hundreds of sentences as training instances, taken from a single pair of documents and reference summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.8058212399482727}]}, {"text": "Extractive MDS can leverage the ROUGE scores of individual sentences in various ways, in particular, as part of an optimization step.", "labels": [], "entities": [{"text": "Extractive MDS", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8343645334243774}, {"text": "ROUGE", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.979943573474884}]}, {"text": "In our work, we follow the previously successful approaches to extractive MDS using discrete optimization, and make the following contributions: We provide a theoretical justification and empirical validation for using ROUGE scores of individual sentences as an optimization objective.", "labels": [], "entities": [{"text": "extractive MDS", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.7549967765808105}]}, {"text": "Assuming that ROUGE scores of individual sentences have been estimated by a supervised learner, we derive an approximation of the ROUGE-N score fora set of sentences from the ROUGE-N scores of the individual sentences in the general case of N >= 1.", "labels": [], "entities": [{"text": "ROUGE-N score", "start_pos": 130, "end_pos": 143, "type": "METRIC", "confidence": 0.9531242251396179}]}, {"text": "We use our approximation to define a mathematically principled discrete optimization problem for sentence selection.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.8056821823120117}]}, {"text": "We empirically evaluate our framework on two DUC datasets, demonstrating the validity of our approximation, as well as its ability to achieve competitive ROUGE scores in comparison to several strong baselines.", "labels": [], "entities": [{"text": "DUC datasets", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.8862110078334808}, {"text": "ROUGE", "start_pos": 154, "end_pos": 159, "type": "METRIC", "confidence": 0.9851822257041931}]}, {"text": "Most importantly, the resulting framework reduces the MDS task to the problem of scoring individual sentences with their ROUGE scores.", "labels": [], "entities": [{"text": "MDS task", "start_pos": 54, "end_pos": 62, "type": "TASK", "confidence": 0.8941167593002319}, {"text": "ROUGE", "start_pos": 121, "end_pos": 126, "type": "METRIC", "confidence": 0.9834676384925842}]}, {"text": "The overall summarization task is converted to two sequential tasks: (i) scoring single sentences, and (ii) selecting summary sentences by solving an optimization problem where the ROUGE score of the selected sentences is maximized.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.889932245016098}, {"text": "ROUGE score", "start_pos": 181, "end_pos": 192, "type": "METRIC", "confidence": 0.9712251424789429}]}, {"text": "The optimization objective we propose almost exactly solves (ii), which we justify by providing both mathematical and empirical evidence.", "labels": [], "entities": []}, {"text": "Hence, solving the whole problem of MDS is reduced to solving (i).", "labels": [], "entities": [{"text": "MDS", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8307157754898071}]}, {"text": "The rest of this paper is structured as follows: in Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "Section 3 presents our subset selection framework consisting of an approximation of the ROUGE score of a set of sentences, and a mathematically principled discrete optimization problem for sentence selection.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 88, "end_pos": 99, "type": "METRIC", "confidence": 0.9773049354553223}, {"text": "sentence selection", "start_pos": 189, "end_pos": 207, "type": "TASK", "confidence": 0.7815225422382355}]}, {"text": "We evaluate our framework in Section 4 and discuss the results in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform three kinds of experiments in order to empirically evaluate our framework: first, we show that our proposed approximation is valid, then we analyze a basic supervised sentence scoring component, and finally we perform an extrinsic evaluation on end-to-end extractive MDS.", "labels": [], "entities": []}, {"text": "In our experiments, we use the DUC datasets from.", "labels": [], "entities": [{"text": "DUC datasets", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9698343276977539}]}, {"text": "We use the variants of ROUGE identified by as strongly correlating with human evaluation methods: ROUGE-2 recall with stemming and stopwords not removed (giving the best agreement with human evaluation), and ROUGE-1 recall (as the measure with the highest ability to identify the better summary in a pair of system summaries).", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.9631059765815735}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.5363146066665649}, {"text": "ROUGE-1", "start_pos": 208, "end_pos": 215, "type": "METRIC", "confidence": 0.9719812273979187}, {"text": "recall", "start_pos": 216, "end_pos": 222, "type": "METRIC", "confidence": 0.6176740527153015}]}, {"text": "For DUC-03, summaries are truncated to 100 words, and to 200 words for DUC-02.", "labels": [], "entities": [{"text": "DUC-03", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.932072639465332}, {"text": "DUC-02", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.9719015955924988}]}, {"text": "The truncation is done automatically by ROUGE.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9902946949005127}]}, {"text": "In our end-to-end evaluation on extractive MDS, we use the following baselines for comparison: \u2022 TF*IDF weighting: This simple heuristic was introduced by.", "labels": [], "entities": [{"text": "TF", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9738239645957947}, {"text": "IDF weighting", "start_pos": 100, "end_pos": 113, "type": "METRIC", "confidence": 0.8482752740383148}]}, {"text": "Each sentence receives a score from the TF*IDF of its terms.", "labels": [], "entities": [{"text": "TF*IDF", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.6498846610387167}]}, {"text": "We trained IDFs (Inverse Document Frequencies) on a background corpus 4 to improve the original algorithm.", "labels": [], "entities": []}, {"text": "\u2022 LexRank: Among other graph-based approaches to summarization (Mani and Bloedorn, 1997;,) has become the most popular one.", "labels": [], "entities": [{"text": "LexRank", "start_pos": 2, "end_pos": 9, "type": "DATASET", "confidence": 0.934333860874176}, {"text": "summarization", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9840929508209229}]}, {"text": "A similarity graph G(V, E) is constructed where V is the set of sentences and an edge e ij is drawn between sentences vi and v j if and only if We used DBpedia long abstract: http://wiki.dbpedia.org/Downloads2015-04.", "labels": [], "entities": [{"text": "DBpedia long abstract", "start_pos": 152, "end_pos": 173, "type": "DATASET", "confidence": 0.9114465912183126}]}, {"text": "the cosine similarity between them is above a given threshold.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.7121394872665405}]}, {"text": "Sentences are scored according to their PageRank score in G.", "labels": [], "entities": []}, {"text": "For our experiments, we use the implementation available in the sumy package.", "labels": [], "entities": []}, {"text": "\u2022 ICSI: ICSI is a recent system that has been identified as one of the state-of-the-art systems by . It is a global linear optimization framework that extracts a summary by solving a maximum coverage problem considering the most important concepts in the source documents.", "labels": [], "entities": []}, {"text": "Concepts are identified as bi-grams and their importance is estimated via their frequency in the source documents.", "labels": [], "entities": []}, {"text": "released a Python implementation (ICSI sume) that we use in our experiments.", "labels": [], "entities": []}, {"text": "\u2022 SFOUR: SFOUR is a structured prediction approach that trains an end-to-end system with a large-margin method to optimize a convex relaxation of ROUGE ().", "labels": [], "entities": [{"text": "SFOUR", "start_pos": 2, "end_pos": 7, "type": "DATASET", "confidence": 0.5261126756668091}, {"text": "ROUGE", "start_pos": 146, "end_pos": 151, "type": "METRIC", "confidence": 0.9519156217575073}]}, {"text": "We use the publicly available implementation.", "labels": [], "entities": []}, {"text": "As described in the previous section, two models are trained: R1 and R2.", "labels": [], "entities": []}, {"text": "We evaluate both of them in the end-to-end setup with and without our optimization.", "labels": [], "entities": []}, {"text": "In the greedy version, sentences are added as long as the summary length is valid.", "labels": [], "entities": []}, {"text": "We apply the optimization for sentence scoring models trained on ROUGE-1 and ROUGE-2 as well.", "labels": [], "entities": []}, {"text": "The scoring models are trained on one dataset and evaluated on the other.", "labels": [], "entities": []}, {"text": "For the ILP optimization, the damping factor can vary and leads to different performance.", "labels": [], "entities": [{"text": "ILP optimization", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.9299076795578003}]}, {"text": "We report the best results among few variations.", "labels": [], "entities": []}, {"text": "In order to speed-up the ILP step, we propose to limit the search space by only looking at the top K sentences: Impact of the optimization step on sentence subset selection.", "labels": [], "entities": [{"text": "sentence subset selection", "start_pos": 147, "end_pos": 172, "type": "TASK", "confidence": 0.6556960741678873}]}, {"text": "The proposed optimization significantly and systematically improves TF*IDF performance as we expected from our analysis in the previous section.", "labels": [], "entities": [{"text": "TF*IDF", "start_pos": 68, "end_pos": 74, "type": "TASK", "confidence": 0.6579203406969706}]}, {"text": "This result suggests that using only a frequency signal in source documents is enough to get high scoring summaries, which supports the common belief that frequency is one of the most useful features for generic news summarization.", "labels": [], "entities": [{"text": "generic news summarization", "start_pos": 204, "end_pos": 230, "type": "TASK", "confidence": 0.8875269293785095}]}, {"text": "It also aligns well with the strong performance of ICSI, which combines an ILP step with frequency information as well.", "labels": [], "entities": [{"text": "ICSI", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.5741366147994995}]}, {"text": "The optimization also significantly and systematically improves upon the greedy approach combined with our scoring models.", "labels": [], "entities": []}, {"text": "Combining a SVR learner (SVR-1 and SVR-2) and our ILP-R produces results on par with ICSI and sometimes significantly better.", "labels": [], "entities": [{"text": "ICSI", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.768886923789978}]}, {"text": "SFOUR maximizes ROUGE in an end-to-end fashion, but is outperformed by our framework when using the same training data.", "labels": [], "entities": [{"text": "SFOUR", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7172386050224304}, {"text": "ROUGE", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9652723073959351}]}, {"text": "The framework is able to reach a competitive performance even with a basic learner.", "labels": [], "entities": []}, {"text": "These results again suggest that investigating better learners for sentence scoring might be promising in order to improve the quality of the summaries.", "labels": [], "entities": [{"text": "sentence scoring", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.7993040978908539}]}, {"text": "We observe that the model trained on ROUGE-2 is performing better than the model trained on ROUGE-1, although learning the ROUGE-2 scores seems to be harder than learning ROUGE-1 The symbol * indicates that the difference compared to the previous best baseline is significant with p \u2264 0.05.", "labels": [], "entities": []}, {"text": "scores (as shown in table 2).", "labels": [], "entities": []}, {"text": "However, errors and approximations propagate less easily in ROUGE-2, because the number of bi-grams in the intersection of two given sentences is far less.", "labels": [], "entities": []}, {"text": "Hence we conclude that learning ROUGE-2 scores should be put into the focus of future work on improving sentence scoring.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.8541905879974365}, {"text": "sentence scoring", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.785289466381073}]}], "tableCaptions": [{"text": " Table 1: Upper bound of our framework compared  to extractive upper bound.", "labels": [], "entities": []}, {"text": " Table 2: Correlation of different kinds of sentence scores and their true ROUGE-1 and ROUGE-2 scores.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9828134775161743}, {"text": "ROUGE-2 scores", "start_pos": 87, "end_pos": 101, "type": "METRIC", "confidence": 0.9565072059631348}]}, {"text": " Table 3: Impact of the optimization step on sen- tence subset selection.", "labels": [], "entities": [{"text": "sen- tence subset selection", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.6692317247390747}]}]}