{"title": [{"text": "A Domain Adaptation Regularization for Denoising Autoencoders", "labels": [], "entities": [{"text": "Domain Adaptation Regularization", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.7583033442497253}]}], "abstractContent": [{"text": "Finding domain invariant features is critical for successful domain adaptation and transfer learning.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7463354170322418}, {"text": "transfer learning", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.9300882518291473}]}, {"text": "However, in the case of unsupervised adaptation, there is a significant risk of overfitting on source training data.", "labels": [], "entities": []}, {"text": "Recently, a regularization for domain adaptation was proposed for deep models by (Ganin and Lempitsky, 2015).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7329344004392624}]}, {"text": "We build on their work by suggesting a more appropriate regularization for denoising autoen-coders.", "labels": [], "entities": []}, {"text": "Our model remains unsupervised and can be computed in a closed form.", "labels": [], "entities": []}, {"text": "On standard text classification adaptation tasks, our approach yields the state of the art results, with an important reduction of the learning cost.", "labels": [], "entities": [{"text": "text classification adaptation tasks", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.8399984017014503}]}], "introductionContent": [{"text": "Domain Adaptation problem arises each time when we need to leverage labeled data in one or more related source domains, to learn a classifier for unseen data in a target domain.", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7806749939918518}]}, {"text": "It has been studied for more than a decade, with applications in statistical machine translation, opinion mining, part of speech tagging, named entity recognition and document ranking.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7480394641558329}, {"text": "opinion mining", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.855472207069397}, {"text": "part of speech tagging", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.6355803161859512}, {"text": "named entity recognition", "start_pos": 138, "end_pos": 162, "type": "TASK", "confidence": 0.7091869910558065}, {"text": "document ranking", "start_pos": 167, "end_pos": 183, "type": "TASK", "confidence": 0.7601759433746338}]}, {"text": "The idea of finding domain invariant features underpins numerous works in domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7635295391082764}]}, {"text": "A shared representation eases prediction tasks, and theoretical analyses uphold such hypotheses).", "labels": [], "entities": [{"text": "prediction tasks", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8994813859462738}]}, {"text": "For instance, have shown that replicating features in three main subspaces (source, common and target) yields improved accuracy as the classifier can subsequently pick the most relevant common features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9986503720283508}]}, {"text": "With the pivoting technique (, the bag of words features are projected on a subspace that captures the relations between some central pivot features and the remaining words.", "labels": [], "entities": []}, {"text": "Similarly, there are several extensions of topic models and matrix factorization techniques where the latent factors are shared by source and target collections).", "labels": [], "entities": []}, {"text": "More recently, deep learning has been proposed as a generic solution to domain adaptation and transfer learning problems by demonstrating their ability to learn invariant features.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7242897003889084}]}, {"text": "On one hand, unsupervised models such as denoising autoencoders (Glorot et al., 2011) or models built on word embeddings () are shown to be effective for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 154, "end_pos": 171, "type": "TASK", "confidence": 0.7680247724056244}]}, {"text": "On the other hand, supervised deep models ( can be designed to select an appropriate feature space for classification.", "labels": [], "entities": []}, {"text": "Adaptation to anew domain can also be performed by fine tuning the neural network on the target task (.", "labels": [], "entities": [{"text": "Adaptation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9698136448860168}]}, {"text": "While such solutions perform relatively well, the refinement may require a significant amount of new labeled data.", "labels": [], "entities": []}, {"text": "Recent work by  has proposed a better strategy; they proposed to regularize intermediate layers with a domain prediction task, i.e. deciding whether an object comes from the source or target domain.", "labels": [], "entities": [{"text": "domain prediction", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.725697711110115}]}, {"text": "This paper proposes to combine the domain prediction regularization idea of (Ganin and Lempitsky, 2015) with the denoising autoencoders.", "labels": [], "entities": [{"text": "domain prediction regularization", "start_pos": 35, "end_pos": 67, "type": "TASK", "confidence": 0.8584010799725851}]}, {"text": "More precisely, we build on stacked Marginalized Denoising Autoencoders (sMDA)), which can be learned efficiently with a closed form solution.", "labels": [], "entities": []}, {"text": "We show that such domain adaptation regularization keeps the benefits of the sMDA and yields results competitive to the state of the art results of ( .", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct unsupervised domain adaptation experiments on two standard collections: the Amazon reviews) and the 20News-group () datasets.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7253732830286026}, {"text": "Amazon reviews", "start_pos": 87, "end_pos": 101, "type": "DATASET", "confidence": 0.882786750793457}, {"text": "20News-group () datasets", "start_pos": 111, "end_pos": 135, "type": "DATASET", "confidence": 0.8407504558563232}]}, {"text": "From the Amazon dataset we consider the four most used domains: dvd (D), books (B), electronics (E) and kitchen (K), and adopt the settings of ( ) with the 5000 most frequent common features selected for each adaptation task and a tf-idf weighting.", "labels": [], "entities": [{"text": "Amazon dataset", "start_pos": 9, "end_pos": 23, "type": "DATASET", "confidence": 0.9296417832374573}]}, {"text": "We then use the Logistic Regression (LR) to classify the reviews.", "labels": [], "entities": [{"text": "Logistic Regression (LR)", "start_pos": 16, "end_pos": 40, "type": "METRIC", "confidence": 0.7952191829681396}]}, {"text": "Our previous experiments with MDA revealed that the MDA noise probability p needs to beset to high values (e.g. 0.9).", "labels": [], "entities": [{"text": "MDA noise probability p", "start_pos": 52, "end_pos": 75, "type": "METRIC", "confidence": 0.628609798848629}]}, {"text": "A possible explanation is that document representations are already sparse and adding low noise has no effect on the features already equal to zero.", "labels": [], "entities": []}, {"text": "shows the average accuracy for the twelve Amazon tasks, when we vary the noise probability p.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9996434450149536}]}, {"text": "In addition, we observed that a single layer with a tanh activation function is sufficient to achieve top performance; stacking several layers and/or concatenating the outputs with the original features yields no improvement but increases the computational time.", "labels": [], "entities": []}, {"text": "The dropout probability p is fixed to 0.9 in all experiments, for both the MDA baseline and our model; we test the performance with a single layer and a tanh activation function.", "labels": [], "entities": [{"text": "dropout probability p", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.9464412728945414}, {"text": "MDA baseline", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.8891203999519348}]}, {"text": "Stacking several layers is left for future experiments.", "labels": [], "entities": []}, {"text": "select the LR parameters and the parameters \u03b1, \u03bb by cross validating the classification results using only the \"reconstructed\" source data; for estimating W we used the source with an unlabeled target set (excluded attest time).", "labels": [], "entities": []}, {"text": "This corresponds to the setting used in ( ), with the difference that they use SVM and reverse crossvalidation . shows the results for twelve adaptation tasks on the Amazon review dataset for the four following methods.", "labels": [], "entities": [{"text": "Amazon review dataset", "start_pos": 166, "end_pos": 187, "type": "DATASET", "confidence": 0.9193644126256307}]}, {"text": "Columns 1 and 2 show the LR classification results on the target set for the single layer MDA and the proposed target regularized MDA (MDA+TR).", "labels": [], "entities": [{"text": "LR classification", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.6413495093584061}]}, {"text": "Column 3 reports the SVM result on the target from ( . They used a 5 layers sMDA where the 5 outputs are concatenated with input to generate 30,000 features, on which the SVM is then trained and tested (G-sMDA).", "labels": [], "entities": [{"text": "SVM", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9406189322471619}]}, {"text": "Finally, column 4 shows the current state of the art results obtained with Domain-Adversarial Training of Neural Networks (DA NN) instead of SVM ( . Despite a single layer and LR trained on the source only, the MDA baseline (80.15% on average) is very close to the G-sMDA results obtained with 5 layer sMDA and 6 times larger feature set (80.18%).", "labels": [], "entities": []}, {"text": "Furthermore, adding the target regularization allows to significantly outperform in many It consists in using self training on the target validation set and calibrating parameters on a validation set from the source labeled data.", "labels": [], "entities": []}, {"text": "cases the baseline and the state of the art DA NN.", "labels": [], "entities": [{"text": "DA NN", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.7157662510871887}]}, {"text": "We note that our method has a much lower cost, as it uses the closed form solution for the reconstruction and a simple LR on the reconstructed source data, instead of domain-adversarial training of deep neural networks.", "labels": [], "entities": [{"text": "LR", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9799372553825378}]}, {"text": "We also look at the difference between the previously introduced expansion mass for the MDA and MDA+TR.", "labels": [], "entities": []}, {"text": "In the adaptation task from dvd (D) to electronics (E), the words for which the mass changed the most are the following : worked, to use, speakers, i have, work, mouse, bought, cable, works, quality, unit, ipod, price, number , sound, card, phone, use, product, my.", "labels": [], "entities": []}, {"text": "These words are mostly target specific and the results confirm that they get promoted by the new model.", "labels": [], "entities": []}, {"text": "Our model favors features which are more likely to appear in target examples, while DA NN seeks domain invariant features.", "labels": [], "entities": []}, {"text": "Despite this difference, the two approaches achieve similar results.", "labels": [], "entities": []}, {"text": "It is surprising, and we argue that eventually both approaches penalize source specific features.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we use MDA with R = [0; 1] (case 3) that penalizes source specific features and we obtain again similar performances.", "labels": [], "entities": []}, {"text": "Finally, we test our approach on the 20News-group adaptation tasks described in.", "labels": [], "entities": [{"text": "20News-group adaptation", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7582684755325317}]}, {"text": "We first filter out rare words and keep at most 10,000 features.", "labels": [], "entities": []}, {"text": "Then, we apply both MDA and MDA+TR as above.", "labels": [], "entities": [{"text": "MDA", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.8641771078109741}, {"text": "MDA+TR", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.5251686573028564}]}, {"text": "shows results for ten adaptation tasks.", "labels": [], "entities": []}, {"text": "As we can see, in all cases the target regularization (MDA+TR) helps improve the classification accuracy.", "labels": [], "entities": [{"text": "MDA+TR)", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.829227015376091}, {"text": "classification", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.9518842101097107}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9472575783729553}]}, {"text": "In ascending order of the differences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracies of MDA, MDA+TR, G- sMDA and DA NN on the Amazon review dataset.  Underline indicates improvement over the base- line MDA, bold indicates the highest value.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9972580671310425}, {"text": "MDA+TR", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.5216519037882487}, {"text": "G- sMDA", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.927586038907369}, {"text": "DA", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.921938955783844}, {"text": "Amazon review dataset", "start_pos": 62, "end_pos": 83, "type": "DATASET", "confidence": 0.9436012903849283}]}, {"text": " Table 2: Accuracies of MDA and MDA+TR on  20Newsgroup adaptation tasks.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9932477474212646}, {"text": "MDA", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.7991827130317688}, {"text": "MDA+TR", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.606129785378774}, {"text": "20Newsgroup adaptation tasks", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.7265291810035706}]}]}