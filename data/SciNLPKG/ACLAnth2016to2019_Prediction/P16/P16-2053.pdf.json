{"title": [{"text": "Transductive Adaptation of Black Box Predictions", "labels": [], "entities": [{"text": "Transductive Adaptation of Black Box Predictions", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.888562927643458}]}], "abstractContent": [{"text": "Access to data is critical to any machine learning component aimed at training an accurate predictive model.", "labels": [], "entities": []}, {"text": "In reality, data is often a subject of technical and legal constraints.", "labels": [], "entities": []}, {"text": "Data may contain sensitive topics and data owners are often reluctant to share them.", "labels": [], "entities": []}, {"text": "Instead of access to data, they make available decision making procedures to enable predictions on new data.", "labels": [], "entities": []}, {"text": "Under the black box classifier constraint, we build an effective domain adaptation technique which adapts classi-fier predictions in a transductive setting.", "labels": [], "entities": []}, {"text": "We run experiments on text categorization datasets and show that significant gains can be achieved, especially in the unsuper-vised case where no labels are available in the target domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "While huge volumes of unlabeled data are generated and made available in various domains, the cost of acquiring data labels remains high.", "labels": [], "entities": []}, {"text": "Domain Adaptation problems arise each time when one leverage labeled data in one or more related source domains, to learn a classifier for unseen data in a target domain which is related, but not identical.", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7695303857326508}]}, {"text": "The majority of domain adaptation methods makes an assumption of largely available source collections; this allows to measure the discrepancy between distributions and either build representations common to both target and sources, or directly reuse source instances fora better target classification (.", "labels": [], "entities": []}, {"text": "Numerous approaches have been proposed to address domain adaptation for statistical machine translation (, opinion mining, part of speech tagging and document ranking, , ().", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7651096880435944}, {"text": "statistical machine translation", "start_pos": 72, "end_pos": 103, "type": "TASK", "confidence": 0.7400124867757162}, {"text": "opinion mining", "start_pos": 107, "end_pos": 121, "type": "TASK", "confidence": 0.7487766742706299}, {"text": "part of speech tagging", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.6328274756669998}, {"text": "document ranking", "start_pos": 150, "end_pos": 166, "type": "TASK", "confidence": 0.7355816960334778}]}, {"text": "Most effective techniques include feature replication, pivot features (), (  and finding topic models shared by source and target collections).", "labels": [], "entities": [{"text": "feature replication", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7724699079990387}]}, {"text": "Domain adaptation has equally received a lot of attention in computer vision ( where domain shift is a consequence of changing conditions, such as background, location and pose, etc.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8159738481044769}]}, {"text": "More recently, domain adaptation has been tackled with word embedding techniques or deep learning.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8267799317836761}]}, {"text": "( proposed an unsupervised method for learning domain-specific word embedding while) relied on word2vec models () to compute feature embedding.", "labels": [], "entities": []}, {"text": "Deep learning has been considered as a generic solution to domain adaptation ( and transfer learning problems (.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7114623337984085}]}, {"text": "For instance, denoising autoencoders are successful models which find common features between source and target collection.", "labels": [], "entities": []}, {"text": "They are trained to reconstruct input data from partial random corruption and can be stacked into a multi-layered network where the weights are fine-tuned with backpropagation () or marginalized out (.", "labels": [], "entities": []}, {"text": "Domain adaptation is also very attractive for service companies operating customer business processes as it can reduce annotation costs.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8072181940078735}]}, {"text": "For instance, opinion mining components deployed in a service solution can be customized to anew customer and adapted with few annotations in order to achieve a contractual performance.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.8198513090610504}]}, {"text": "But, in reality, the simplifying assumption of having access to source data rarely holds and limits therefore the application of existing domain adaptation methods.", "labels": [], "entities": []}, {"text": "Source data are often a subject of legal, technical and contractual constraints between data owners and data customers.", "labels": [], "entities": []}, {"text": "Often, customers are reluctant to share their data.", "labels": [], "entities": []}, {"text": "Instead, they often put in place decision making procedures.", "labels": [], "entities": [{"text": "decision making", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.8580076396465302}]}, {"text": "This allows to obtain predictions for new data under a black box scenario.", "labels": [], "entities": []}, {"text": "Note that this scenario is different from the differential privacy setting) in the sense that no queries to the raw source database are allowed whereas, in our case, only requests for predicting labels of target documents are permitted.", "labels": [], "entities": [{"text": "predicting labels of target documents", "start_pos": 184, "end_pos": 221, "type": "TASK", "confidence": 0.8392939805984497}]}, {"text": "This makes privacy preserving machine learning methods inapplicable here,).", "labels": [], "entities": []}, {"text": "In addition, black boxes systems are frequent in natural language processing applications.", "labels": [], "entities": []}, {"text": "For instance, Statistical Machine Translation (SMT) systems are often used as black box to extract features (.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 14, "end_pos": 51, "type": "TASK", "confidence": 0.8591747184594473}]}, {"text": "Similarly, the problem of adapting SMT systems for cross lingual retrieval has been addressed in () where target document collections cannot be accessed and the retrieval engine works as a black box.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9915779829025269}]}, {"text": "In this paper we address the problem of adapting classifiers trained on the source data and available as black boxes.", "labels": [], "entities": []}, {"text": "The case of available source classifiers has been studied by to regularize supervised target classifiers, but we consider here a transductive setting, where the source classifiers are used to predict class scores fora set of available target instances.", "labels": [], "entities": []}, {"text": "We then apply the denoising principle and consider these predictions on target instances as corrupted by the domain shift from the source to target.", "labels": [], "entities": []}, {"text": "More precisely, we use the stacked Marginalized Denoising Autoencoders () to reconstruct the predictions by exploiting the correlation between the target features and the predicted scores.", "labels": [], "entities": []}, {"text": "This method has the advantage of coping with unsupervised cases where no labels in the target domain is available.", "labels": [], "entities": []}, {"text": "We test the prediction denoising method on two benchmark text classification datasets and demonstrate its capacity to significantly improve the classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.915554940700531}]}], "datasetContent": [{"text": "We test our approach on two standard domain adaptation datasets: the Amazon reviews (AMT) and the 20Newsgroups (NG).", "labels": [], "entities": [{"text": "Amazon reviews (AMT)", "start_pos": 69, "end_pos": 89, "type": "DATASET", "confidence": 0.9173144578933716}]}, {"text": "The AMT dataset consists of products reviews with 2 classes (positive and negative) represented by tf-idf normalized Algorithm 1 Transductive prediction adaptation.", "labels": [], "entities": [{"text": "AMT dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7437377423048019}, {"text": "Transductive prediction adaptation", "start_pos": 129, "end_pos": 163, "type": "TASK", "confidence": 0.8393550713857015}]}, {"text": "bag-of-words, used in previous studies on domain adaptation).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7229364067316055}]}, {"text": "We consider the 10,000 most frequent features and four domains used in the studies: kitchen (k), dvd (d), books (b) and electronics (e) with roughly 5,000 documents per domain.", "labels": [], "entities": []}, {"text": "We use all the source dataset as training and test on the whole target dataset.", "labels": [], "entities": []}, {"text": "We set the MDA noise level p to high values (e.g. 0.9), as document representations are sparse and adding low noise have no effect on the features already equal to zero.", "labels": [], "entities": [{"text": "MDA noise level p", "start_pos": 11, "end_pos": 28, "type": "METRIC", "confidence": 0.6977247968316078}]}, {"text": "In, we show the performance of the Transductive Prediction Adaptation (TPA) on 12 adaptation tasks in the AMT dataset.", "labels": [], "entities": [{"text": "Transductive Prediction Adaptation (TPA)", "start_pos": 35, "end_pos": 75, "type": "TASK", "confidence": 0.8261793653170267}, {"text": "AMT dataset", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.7679760158061981}]}, {"text": "The first column shows the accuracies for the dream case where the standard MDA is applied to both source and target data.", "labels": [], "entities": []}, {"text": "The second column shows the baseline results (f s (X t )) obtained directly as class predictions by the source classifier.", "labels": [], "entities": []}, {"text": "The classification model is an l 2 regularized Logistic Regression 3 cross-validated with regularized parameter C \u2208 [0.0001, 0.001, 0.1, 1, 10, 50, 100].", "labels": [], "entities": []}, {"text": "The two last columns show the results obtained with two versions of TPA (results are underlined when improving over the baseline and in bold when yielding the highest values).", "labels": [], "entities": [{"text": "TPA", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.429536372423172}]}, {"text": "In the first version, target instances x tn contains only features (words and bigrams) appearing in the source documents and used to make the predictions f (x tn ).", "labels": [], "entities": []}, {"text": "In the second version, denoted as TPAe, we extend TPA with words unseen in the source documents.", "labels": [], "entities": []}, {"text": "If the extension part is denoted v tn , we obtain an augmented representation u tn = [x tn ; v tn ; f (x tn )] as input to MDA.", "labels": [], "entities": [{"text": "MDA", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.926590085029602}]}, {"text": "As we can see, both TPA and TPAe significantly outperform the baseline f s (X t ) obtained with no adaptation.", "labels": [], "entities": [{"text": "TPA", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.8397432565689087}, {"text": "TPAe", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.8821889758110046}]}, {"text": "Furthermore, extending TPA with words present in target documents only allows to further improve the classification accuracy inmost cases.", "labels": [], "entities": [{"text": "TPA", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.5262680649757385}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9247863292694092}]}, {"text": "Finally, TPAe often outperforms the dream case and also on average (note however that MDA * uses the features common to source and target documents as input).", "labels": [], "entities": [{"text": "TPAe", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.8384338021278381}]}, {"text": "To understand the effect of prediction adaptation we analyze the book \u2192 electronics adaptation task.", "labels": [], "entities": [{"text": "prediction adaptation", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.9665588736534119}, {"text": "book \u2192 electronics adaptation", "start_pos": 65, "end_pos": 94, "type": "TASK", "confidence": 0.6344980746507645}]}, {"text": "In the mapping W, we sort the weights corresponding to the correlation between the positive class and the target features.", "labels": [], "entities": []}, {"text": "Features with the highest weights (up-weighted by TPA) are great, my, sound, easy, excellent, good, easy to, best, yo, a great, when, well, the best.", "labels": [], "entities": [{"text": "TPA", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.60554438829422}]}, {"text": "On contrary, the words that got the smallest weight (down-weighted by TPA) are no, was, number, don't, after, money, if, work, bad, get, buy.", "labels": [], "entities": [{"text": "TPA", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.8224349021911621}]}, {"text": "As TPA is totally unsupervised, we run additional experiments to understand its practical usefulness.", "labels": [], "entities": [{"text": "TPA", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.514185905456543}]}, {"text": "We compare TPA to the case of weakly annotated target data, where few target examples are labelled and used for training a target classifier.", "labels": [], "entities": [{"text": "TPA", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.8521307110786438}]}, {"text": "Trained with 40, 100 and 200 target examples, a logistic regression yields an average accuracy of 64.63%, 68.01% and 75.13% over 12 tasks and a Multinomial Naives Bayes reports 65.82%, 71.49% and 76%, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.999460756778717}]}, {"text": "Even with 200 labeled target documents, the target versus target classification results are significantly below the 79.8% average accuracy of the baseline source classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9979565143585205}]}, {"text": "All these values are therefore significantly below the 83.73% obtained with TPAe.", "labels": [], "entities": [{"text": "TPAe", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.4877493679523468}]}, {"text": "This strongly supports the domain adaptation scenario, when a sentiment analysis classifier trained on a larger source set and adapted to target documents can do better than a classifier trained on a small set of labeled target documents.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7875068485736847}, {"text": "sentiment analysis classifier", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.835839847723643}]}, {"text": "Furthermore, we have seen that the baseline can be significantly improved by TPA and even more by TPAe without the need of even a small amount of manual labeling of the target set.", "labels": [], "entities": []}, {"text": "The second group of evaluation tests is on the 20Newsgroup dataset.", "labels": [], "entities": [{"text": "20Newsgroup dataset", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.9893951714038849}]}, {"text": "It contains around 20,000 documents of 20 classes and represents a standard testbed for text categorization.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7432436048984528}]}, {"text": "For the domain adaptation, we follow the setting described in ().", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7529442012310028}]}, {"text": "We filter out rare words (appearing less than 3 times) and keep at most 10,000 features for each task with a tf-idf termweighting.", "labels": [], "entities": []}, {"text": "As all documents are organized as a hierarchy, the domain adaptation tasks are defined on category pairs with sources and targets corresponding to subcategories.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7614872455596924}]}, {"text": "For example, for the 'comp vs sci' task, subcategories such as comp.sys.ibm.pc.hardware and sci.crypt are set as source domains and comp.sys.ibm.mac.hardware and sci.med as targets, respectively.", "labels": [], "entities": []}, {"text": "In our experiments we consider 5 adaptation tasks on category pairs ( 'comp vs sci','rec vs talk', 'rec vs sci', 'sci vs talk' and 'comp vs rec' as in ), and run the baseline, TPA and TPAe methods.", "labels": [], "entities": [{"text": "TPA", "start_pos": 176, "end_pos": 179, "type": "METRIC", "confidence": 0.5928597450256348}]}, {"text": "For each category pair, we additionally inverse the source and target roles; this explains two sets of experimental results for each pair.", "labels": [], "entities": []}, {"text": "We show the evaluation results in.", "labels": [], "entities": []}, {"text": "It is easy to observe again the significant improvement over the baseline f s (x tn ) and the positive effect of including the unseen words in the TPA.", "labels": [], "entities": [{"text": "TPA", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.7704213261604309}]}], "tableCaptions": [{"text": " Table 1: TPA results on the AMT dataset.", "labels": [], "entities": [{"text": "TPA", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5734560489654541}, {"text": "AMT dataset", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.8914019763469696}]}, {"text": " Table 2. It  is easy to observe again the significant improve- ment over the baseline f s (x t  n ) and the positive ef- fect of including the unseen words in the TPA.", "labels": [], "entities": [{"text": "improve- ment", "start_pos": 55, "end_pos": 68, "type": "METRIC", "confidence": 0.8480916420618693}, {"text": "TPA", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.873595654964447}]}, {"text": " Table 2: TPA results on the 20Newsgroup dataset.", "labels": [], "entities": [{"text": "TPA", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6107601523399353}, {"text": "20Newsgroup dataset", "start_pos": 29, "end_pos": 48, "type": "DATASET", "confidence": 0.9829291701316833}]}]}