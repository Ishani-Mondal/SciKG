{"title": [{"text": "The Value of Semantic Parse Labeling for Knowledge Base Question Answering", "labels": [], "entities": [{"text": "Semantic Parse Labeling", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.6994621058305105}, {"text": "Knowledge Base Question Answering", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.5008920058608055}]}], "abstractContent": [{"text": "We demonstrate the value of collecting semantic parse labels for knowledge base question answering.", "labels": [], "entities": [{"text": "collecting semantic parse labels", "start_pos": 28, "end_pos": 60, "type": "TASK", "confidence": 0.7374052852392197}, {"text": "knowledge base question answering", "start_pos": 65, "end_pos": 98, "type": "TASK", "confidence": 0.5969151630997658}]}, {"text": "In particular, (1) unlike previous studies on small-scale datasets, we show that learning from labeled semantic parses significantly improves overall performance, resulting in absolute 5 point gain compared to learning from answers, (2) we show that with an appropriate user interface, one can obtain semantic parses with high accuracy and at a cost comparable or lower than obtaining just answers, and (3) we have created and shared the largest semantic-parse labeled dataset to date in order to advance research in question answering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 327, "end_pos": 335, "type": "METRIC", "confidence": 0.9857631921768188}, {"text": "question answering", "start_pos": 517, "end_pos": 535, "type": "TASK", "confidence": 0.815238893032074}]}], "introductionContent": [{"text": "Semantic parsing is the mapping of text to a meaning representation.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8242096602916718}]}, {"text": "Early work on learning to build semantic parsers made use of datasets of questions and their associated semantic parses.", "labels": [], "entities": []}, {"text": "Recent work on semantic parsing for knowledge base questionanswering (KBQA) has called into question the value of collecting such semantic parse labels, with most recent KBQA semantic parsing systems being trained using only question-answer pairs instead of question-parse pairs.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7332361340522766}, {"text": "KBQA semantic parsing", "start_pos": 170, "end_pos": 191, "type": "TASK", "confidence": 0.5692107876141866}]}, {"text": "In fact, there is evidence that using only question-answer pairs can yield improved performance as compared with approaches based on semantic parse labels ( . It is also widely believed that collecting semantic parse labels can be a \"difficult, time consuming task\" ( even for domain experts.", "labels": [], "entities": []}, {"text": "Furthermore, recent focus has been more on the final task-specific performance of a system (i.e., did it get the right answer fora question) as opposed to agreement on intermediate representations (, which allows for KBQA datasets to be built with only the answers to each question.", "labels": [], "entities": [{"text": "KBQA datasets", "start_pos": 217, "end_pos": 230, "type": "DATASET", "confidence": 0.8395705819129944}]}, {"text": "In this work, we re-examine the value of semantic parse labeling and demonstrate that semantic parse labels can provide substantial value for knowledge base question-answering.", "labels": [], "entities": [{"text": "semantic parse labeling", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.7941655218601227}]}, {"text": "We focus on the task of question-answering on Freebase, using the WEBQUESTIONS dataset.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.97765052318573}, {"text": "WEBQUESTIONS dataset", "start_pos": 66, "end_pos": 86, "type": "DATASET", "confidence": 0.9663542211055756}]}, {"text": "Our first contribution is the construction of the largest semantic parse dataset for KB questionanswering to date.", "labels": [], "entities": []}, {"text": "In order to evaluate the costs and benefits of gathering semantic parse labels, we created the WEBQUESTIONSSP dataset 1 , which contains semantic parses for the questions from WEBQUESTIONS that are answerable using Freebase.", "labels": [], "entities": [{"text": "WEBQUESTIONSSP dataset 1", "start_pos": 95, "end_pos": 119, "type": "DATASET", "confidence": 0.9572788874308268}, {"text": "WEBQUESTIONS", "start_pos": 176, "end_pos": 188, "type": "DATASET", "confidence": 0.9053082466125488}]}, {"text": "In particular, we provide SPARQL queries for 4,737 questions.", "labels": [], "entities": []}, {"text": "The remaining 18.5% of the original WEBQUESTIONS questions are labeled as \"not answerable\".", "labels": [], "entities": [{"text": "WEBQUESTIONS questions", "start_pos": 36, "end_pos": 58, "type": "DATASET", "confidence": 0.7885911464691162}]}, {"text": "This is due to a number of factors including the use of a more stringent assessment of \"answerable\", namely that the question be answerable via SPARQL rather than by returning or extracting information from textual descriptions.", "labels": [], "entities": []}, {"text": "Compared to the previous semantic parse dataset on Freebase,, our WEBQUESTIONSSP is not only substantially larger, but also provides the semantic parses in SPARQL with standard Freebase entity identifiers, which are directly executable on Freebase.", "labels": [], "entities": [{"text": "WEBQUESTIONSSP", "start_pos": 66, "end_pos": 80, "type": "METRIC", "confidence": 0.5494371652603149}, {"text": "Freebase", "start_pos": 239, "end_pos": 247, "type": "DATASET", "confidence": 0.957436740398407}]}, {"text": "Our second contribution is a demonstration that semantic parses can be collected at low cost.", "labels": [], "entities": [{"text": "semantic parses", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7655667662620544}]}, {"text": "We employ a staged labeling paradigm that enables efficient labeling of semantic parses and improves the accuracy, consistency and efficiency of ob-1 Available at http://aka.ms/WebQSP.", "labels": [], "entities": [{"text": "labeling of semantic parses", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.7893569618463516}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9988730549812317}, {"text": "consistency", "start_pos": 115, "end_pos": 126, "type": "METRIC", "confidence": 0.9844462275505066}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The results of two different model train- ing settings: answers only vs. semantic parses.", "labels": [], "entities": []}, {"text": " Table 2: Comparing labeling methods on 50 sampled ques-", "labels": [], "entities": [{"text": "Comparing labeling", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6514308154582977}]}]}