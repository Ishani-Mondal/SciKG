{"title": [{"text": "Joint Word Segmentation and Phonetic Category Induction", "labels": [], "entities": [{"text": "Joint Word Segmentation and Phonetic Category Induction", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6424292283398765}]}], "abstractContent": [{"text": "We describe a model which jointly performs word segmentation and induces vowel categories from formant values.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7166589647531509}]}, {"text": "Vowel induction performance improves slightly over a baseline model which does not segment; segmentation performance decreases slightly from a baseline using entirely symbolic input.", "labels": [], "entities": []}, {"text": "Our high joint performance in this idealized setting implies that problems in unsupervised speech recognition reflect the phonetic variability of real speech sounds in context.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7610267698764801}]}], "introductionContent": [{"text": "In learning to speak their native language, a developing infant must acquire two related pieces of information: a set of lexical items (along with the contexts in which they are likely to occur), and a set of phonetic categories.", "labels": [], "entities": []}, {"text": "For instance, an Englishlearning infant must learn that and are different segments, differentiating between words like beat and bit, while fora Spanish-learning infant, and-like tokens represent realizations of the same category.", "labels": [], "entities": []}, {"text": "It is clear that these two tasks are intimately related, and that models of language acquisition must solve both together-but how?", "labels": [], "entities": []}, {"text": "This problem has inspired much recent work in low-resource speech recognition (, with impressive results.", "labels": [], "entities": [{"text": "low-resource speech recognition", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6315165559450785}]}, {"text": "Nonetheless, many of these researchers conclude that their systems learn too many phonetic categories, a problem they attribute to the presence of contextual variants (allophones) of the different sounds.", "labels": [], "entities": []}, {"text": "For instance, the in dog is likely longer than the in dock (), but this difference is not phonologically meaningful in English-it cannot differentiate any pair of words on its own.", "labels": [], "entities": []}, {"text": "Many unsupervised systems are claimed to erroneously learn these kinds of differences as categorical ones.", "labels": [], "entities": []}, {"text": "Here, we attempt to model the problem in a more controlled setting by extending work in cognitive modeling of language acquisition.", "labels": [], "entities": [{"text": "cognitive modeling of language acquisition", "start_pos": 88, "end_pos": 130, "type": "TASK", "confidence": 0.6273872911930084}]}, {"text": "We present a system which jointly acquires vowel categories and lexical items from a mixed symbolic/acoustic representation of the input.", "labels": [], "entities": []}, {"text": "As is traditional in cognitive models of vowel acquisition, it uses a singlepoint formant representation of the vowel acoustics, and is tested on a simulated corpus in which vowel acoustics are unaffected by context.", "labels": [], "entities": [{"text": "vowel acquisition", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7327466458082199}]}, {"text": "We find that, under these circumstances, vowel categories and lexical items can be learned jointly with relatively little decrease inaccuracy from learning either alone.", "labels": [], "entities": []}, {"text": "Thus, our results support the hypothesis that the more realistic problem is hard because of contextual variability.", "labels": [], "entities": []}, {"text": "As a secondary point, we show that the results reflect problems with local minima in the popular framework of hierarchical Bayesian modeling.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset replicates the previous idealized setting for vowel category induction in cognitive modeling, but in a corpus of unsegmented utterances rather than a wordlist.", "labels": [], "entities": [{"text": "vowel category induction", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.7425226966540018}]}, {"text": "We adapt a standard word segmentation corpus of child-directed speech, which consists of 8000 utterances from, orthographically transcribed and then phonetically transcribed using a pronunciation dictionary.", "labels": [], "entities": []}, {"text": "We add simulated acoustics (without contextual variation) to each vowel in the Brent corpus.", "labels": [], "entities": [{"text": "Brent corpus", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.9231915473937988}]}, {"text": "Following previous cognitive models of category induction), we use the vowel dataset given by, which gives formants for English vowels read in the context h d.", "labels": [], "entities": [{"text": "category induction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8205876350402832}]}, {"text": "We estimate a multivariate Gaussian distribution for each vowel, and, whenever a monophthongal vowel occurs in the Brent corpus, we replace it with a pair of formants (f 1 , f 2 ) drawn from the appropriate Gaussian.", "labels": [], "entities": [{"text": "Brent corpus", "start_pos": 115, "end_pos": 127, "type": "DATASET", "confidence": 0.8773066699504852}]}, {"text": "The ARPABET diphthongs \"oy, aw, ay, em, en\", and all the consonants, retain their discrete values.", "labels": [], "entities": [{"text": "ARPABET", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.6808852553367615}]}, {"text": "The first three words of the dataset, orthographically \"you want to\", are rendered:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Segmentation and vowel clustering scores.", "labels": [], "entities": [{"text": "vowel clustering", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.6412883996963501}]}]}