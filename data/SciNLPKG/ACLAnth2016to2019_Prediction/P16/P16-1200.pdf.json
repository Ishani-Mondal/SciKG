{"title": [{"text": "Neural Relation Extraction with Selective Attention over Instances", "labels": [], "entities": [{"text": "Neural Relation Extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9044592181841532}]}], "abstractContent": [{"text": "Distant supervised relation extraction has been widely used to find novel relational facts from text.", "labels": [], "entities": [{"text": "Distant supervised relation extraction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6056146547198296}]}, {"text": "However, distant supervision inevitably accompanies with the wrong labelling problem, and these noisy data will substantially hurt the performance of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8744758069515228}]}, {"text": "To alleviate this issue, we propose a sentence-level attention-based model for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.9500776827335358}]}, {"text": "In this model, we employ convolu-tional neural networks to embed the semantics of sentences.", "labels": [], "entities": []}, {"text": "Afterwards, we build sentence-level attention over multiple instances, which is expected to dynamically reduce the weights of those noisy instances.", "labels": [], "entities": []}, {"text": "Experimental results on real-world datasets show that, our model can make full use of all informative sentences and effectively reduce the influence of wrong labelled instances.", "labels": [], "entities": []}, {"text": "Our model achieves significant and consistent improvements on relation extraction as compared with baselines.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.8576111793518066}]}, {"text": "The source code of this paper can be obtained from https: //github.com/thunlp/NRE.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, various large-scale knowledge bases (KBs) such as Freebase (,) and YAGO () have been built and widely used in many natural language processing (NLP) tasks, including web search and question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 198, "end_pos": 216, "type": "TASK", "confidence": 0.9146368503570557}]}, {"text": "These KBs mostly compose of relational facts with triple format, e.g.,.", "labels": [], "entities": []}, {"text": "Although existing KBs contain a massive amount of facts, they are still far from complete compared to the infinite real-world facts.", "labels": [], "entities": []}, {"text": "To enrich KBs, many efforts have been invested in automatically finding unknown relational facts.", "labels": [], "entities": [{"text": "KBs", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8842023611068726}]}, {"text": "Therefore, relation extraction (RE), the process of generating relational data from plain text, is a crucial task in NLP.", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.9240884184837341}]}, {"text": "Most existing supervised RE systems require a large amount of labelled relation-specific training data, which is very time consuming and labor intensive.", "labels": [], "entities": [{"text": "RE", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9448251128196716}]}, {"text": "( proposes distant supervision to automatically generate training data via aligning KBs and texts.", "labels": [], "entities": []}, {"text": "They assume that if two entities have a relation in KBs, then all sentences that contain these two entities will express this relation.", "labels": [], "entities": []}, {"text": "For example, (Microsoft, founder, Bill Gates) is a relational fact in KB.", "labels": [], "entities": []}, {"text": "Distant supervision will regard all sentences that contain these two entities as active instances for relation founder.", "labels": [], "entities": [{"text": "relation founder", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.8636713027954102}]}, {"text": "Although distant supervision is an effective strategy to automatically label training data, it always suffers from wrong labelling problem.", "labels": [], "entities": []}, {"text": "For example, the sentence \"Bill Gates 's turn to philanthropy was linked to the antitrust problems Microsoft had in the U.S. and the European union.\" does not express the relation founder but will still be regarded as an active instance.", "labels": [], "entities": []}, {"text": "Hence, () adopt multi-instance learning to alleviate the wrong labelling problem.", "labels": [], "entities": []}, {"text": "The main weakness of these conventional methods is that most features are explicitly derived from NLP tools such as POS tagging and the errors generated by NLP tools will propagate in these methods.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 116, "end_pos": 127, "type": "TASK", "confidence": 0.7125633358955383}]}, {"text": "Some recent works) attempt to use deep neural networks in relation classification without handcrafted features.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.9268772602081299}]}, {"text": "These methods build classifier based on sentence-level annotated data, which cannot be applied in large-scale: The architecture of sentence-level attention-based CNN, where xi and xi indicate the original sentence for an entity pair and its corresponding sentence representation, \u03b1 i is the weight given by sentence-level attention, and s indicates the representation of the sentence set.", "labels": [], "entities": []}, {"text": "KBs due to the lack of human-annotated training data.", "labels": [], "entities": [{"text": "KBs", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.4879763424396515}]}, {"text": "Therefore, () incorporates multi-instance learning with neural network model, which can build relation extractor based on distant supervision data.", "labels": [], "entities": [{"text": "relation extractor", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7061207145452499}]}, {"text": "Although the method achieves significant improvement in relation extraction, it is still far from satisfactory.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.9372386336326599}]}, {"text": "The method assumes that at least one sentence that mentions these two entities will express their relation, and only selects the most likely sentence for each entity pair in training and prediction.", "labels": [], "entities": []}, {"text": "It's apparent that the method will lose a large amount of rich information containing in neglected sentences.", "labels": [], "entities": []}, {"text": "In this paper, we propose a sentence-level attention-based convolutional neural network (CNN) for distant supervised relation extraction.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 98, "end_pos": 136, "type": "TASK", "confidence": 0.6189253553748131}]}, {"text": "As illustrated in, we employ a CNN to embed the semantics of sentences.", "labels": [], "entities": []}, {"text": "Afterwards, to utilize all informative sentences, we represent the relation as semantic composition of sentence embeddings.", "labels": [], "entities": []}, {"text": "To address the wrong labelling problem, we build sentence-level attention over multiple instances, which is expected to dynamically reduce the weights of those noisy instances.", "labels": [], "entities": []}, {"text": "Finally, we extract relation with the relation vector weighted by sentence-level attention.", "labels": [], "entities": []}, {"text": "We evaluate our model on a real-world dataset in the task of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8331283330917358}]}, {"text": "The experimental results show that our model achieves significant and consistent improvements in relation extraction as compared with the state-of-the-art methods.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.9160861968994141}]}, {"text": "The contributions of this paper can be summarized as follows: \u2022 As compared to existing neural relation extraction model, our model can make full use of all informative sentences of each entity pair.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7693974375724792}]}, {"text": "\u2022 To address the wrong labelling problem in distant supervision, we propose selective attention to de-emphasize those noisy instances.", "labels": [], "entities": []}, {"text": "\u2022 In the experiments, we show that selective attention is beneficial to two kinds of CNN models in the task of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.8685168325901031}]}], "datasetContent": [{"text": "Our experiments are intended to demonstrate that our neural models with sentence-level selective attention can alleviate the wrong labelling problem and take full advantage of informative sentences for distant supervised relation extraction.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 202, "end_pos": 240, "type": "TASK", "confidence": 0.6342509463429451}]}, {"text": "To this end, we first introduce the dataset and evaluation metrics used in the experiments.", "labels": [], "entities": []}, {"text": "Next, we use cross-validation to determine the parameters of our model.", "labels": [], "entities": []}, {"text": "And then we evaluate the effects of our selective attention and show its performance on the data with different set size.", "labels": [], "entities": []}, {"text": "Finally, we compare the performance of our method to several state-of-the-art feature-based methods.", "labels": [], "entities": []}, {"text": "We evaluate our model on a widely used dataset 1 which is developed by ( and has also been used by.", "labels": [], "entities": []}, {"text": "This dataset was generated by aligning Freebase relations with the New York Times corpus (NYT).", "labels": [], "entities": [{"text": "New York Times corpus (NYT)", "start_pos": 67, "end_pos": 94, "type": "DATASET", "confidence": 0.7506557532719204}]}, {"text": "Entity mentions are found using the Stanford named entity tagger (), and are further matched to the names of Freebase entities.", "labels": [], "entities": []}, {"text": "The Freebase relations are divided into two parts, one for training and one for testing.", "labels": [], "entities": [{"text": "Freebase relations", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9427742660045624}]}, {"text": "It aligns the the sentences from the corpus of the years and regards them as training instances.", "labels": [], "entities": []}, {"text": "And the testing instances are the aligned sentences from 2007.", "labels": [], "entities": []}, {"text": "There are 53 possible relationships including a special relation NA which indicates there is no relation between head and tail entities.", "labels": [], "entities": []}, {"text": "The training data contains 522,611 sentences, 281,270 entity pairs and 18,252 relational facts.", "labels": [], "entities": []}, {"text": "The testing set contains 172,448 sentences, 96,678 entity pairs and 1,950 relational facts.", "labels": [], "entities": []}, {"text": "Similar to previous work (, we evaluate our model in the held-out evaluation.", "labels": [], "entities": []}, {"text": "It evaluates our model by comparing the relation facts discovered from the test articles with those in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 103, "end_pos": 111, "type": "DATASET", "confidence": 0.9609599709510803}]}, {"text": "It assumes that the testing systems have similar performances in relation facts inside and outside Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 99, "end_pos": 107, "type": "DATASET", "confidence": 0.9729424715042114}]}, {"text": "Hence, the held-out evaluation provides an approximate measure of precision without time consumed human evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9994640946388245}]}, {"text": "We report both the aggregate curves precision/recall curves and Precision@N (P@N) in our experiments.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9908005595207214}, {"text": "recall curves", "start_pos": 46, "end_pos": 59, "type": "METRIC", "confidence": 0.9145435094833374}, {"text": "Precision@N (P@N)", "start_pos": 64, "end_pos": 81, "type": "METRIC", "confidence": 0.9452636614441872}]}], "tableCaptions": [{"text": " Table 2: P@N for relation extraction in the entity pairs with different number of sentences", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7902059257030487}]}]}