{"title": [{"text": "Cross-lingual projection for class-based language models", "labels": [], "entities": [{"text": "Cross-lingual projection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7098947018384933}]}], "abstractContent": [{"text": "This paper presents a cross-lingual projection technique for training class-based language models.", "labels": [], "entities": [{"text": "cross-lingual projection", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.7262498140335083}]}, {"text": "We borrow from previous success in projecting POS tags and NER mentions to that of a trained class-based language model.", "labels": [], "entities": []}, {"text": "We use a CRF to train a model to predict when a sequence of words is a member of a given class and use this to label our language model training data.", "labels": [], "entities": []}, {"text": "We show that we can successfully project the contextual cues for these classes across pairs of languages and retain a high quality class model in languages with no supervised class data.", "labels": [], "entities": []}, {"text": "We present empirical results that show the quality of the projected models as well as their effect on the downstream speech recognition objective.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.703634724020958}]}, {"text": "We are able to achieve over 70% of the WER reduction when using the projected class models as compared to models trained on human annotations .", "labels": [], "entities": [{"text": "WER reduction", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.9528966546058655}]}], "introductionContent": [{"text": "Class-based language modeling has along history of being used to improve the quality of speech recognition systems (.", "labels": [], "entities": [{"text": "Class-based language modeling", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6001614332199097}, {"text": "speech recognition", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7418356239795685}]}, {"text": "Recent work on class-based models has exploited named entity recognition (NER) approaches to label language model training data with class labels (, providing a means to assign words and phrases to classes based on their context.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.8194328745206197}]}, {"text": "These contextually assigned classes have been shown to improve speech recognition significantly over grammar-based, deterministic class assignments.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7134041488170624}]}, {"text": "In this work, we address the problem of labeling training data in order to build a class sequence tagger.", "labels": [], "entities": []}, {"text": "We borrow from the successes of previous cross-lingual projection experiments for labeling tasks (.", "labels": [], "entities": [{"text": "labeling tasks", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.9052649140357971}]}, {"text": "We focus on numeric classes (e.g., address numbers, dates, currencies, times, etc.) as the sequence-based labeling approach has been shown to be effective for identifying them.", "labels": [], "entities": []}, {"text": "Given a model trained from human-labeled data in one language (we refer to this as the highresource language), we label translations of sentences from another language (referred to as the low-resource language).", "labels": [], "entities": []}, {"text": "We show that we can project the numeric entity boundaries and labels across the aligned translations with a phrase-based translation model.", "labels": [], "entities": []}, {"text": "Furthermore, we show that if we train a class labeling model on the projected low-resource language and then use that to build a class-based speech recognition system, we achieve between 70% and 85% of the error reduction as we would have achieved with human-labeled examples in the low-resource language.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.7140282690525055}, {"text": "error reduction", "start_pos": 206, "end_pos": 221, "type": "METRIC", "confidence": 0.9777252674102783}]}, {"text": "We present empirical results projecting numeric entity labels from English to Russian, Indonesian, and Italian.", "labels": [], "entities": []}, {"text": "We present full speech recognition results for using human annotated data (the ideal performance) and projected data with various sizes of training data.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7070593684911728}]}], "datasetContent": [{"text": "We trained an English conditional random field (CRF) () tagger to be used in all experiments in order to provide labels for the sentences produced by translation.", "labels": [], "entities": []}, {"text": "To train this tagger we obtained a data set of 24,503 manually labeled sentences (150K tokens) sampled from a corpus of British English language model training material.", "labels": [], "entities": [{"text": "British English language model training material", "start_pos": 120, "end_pos": 168, "type": "DATASET", "confidence": 0.8007423579692841}]}, {"text": "Each token is labeled with one of 17 possible tags.", "labels": [], "entities": []}, {"text": "About 95% of the tokens are labeled with a 'none' tag, meaning that the token is not in any of the pre-determined non-lexical classes.", "labels": [], "entities": []}, {"text": "Separately, we obtained similar training sets to create Italian, Indonesian and Russian taggers.", "labels": [], "entities": [{"text": "Indonesian and Russian taggers", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.6066351532936096}]}, {"text": "The models trained from these labeled data sets were used only to create baseline systems for comparison with the cross-lingual systems.", "labels": [], "entities": []}, {"text": "To provide input into our cross-lingual projection procedure, we also sampled datasets of unlabeled sentences of varying sizes for each evaluation language, using the same sampling procedure as used for the human-labeled sets.", "labels": [], "entities": [{"text": "cross-lingual projection", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.7462490499019623}]}, {"text": "Note that these tagger training sets have inconsistent sizes across languages (see) due to the nature of the sampling procedure: Each training source is searched for sentences matching an extensive list of patterns of numeric entities.", "labels": [], "entities": []}, {"text": "Sentences from each training source are collected up to a source-specific maximum number (which may not always be reached).", "labels": [], "entities": []}, {"text": "We also apply a flattening step to increase diversity of the sample.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: NUM refers to the NUMERIC entities test  set and VS refers to the VOICE-SEARCH test set.", "labels": [], "entities": [{"text": "NUMERIC entities test  set", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.6383329257369041}, {"text": "VS", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9789551496505737}, {"text": "VOICE-SEARCH test set", "start_pos": 76, "end_pos": 97, "type": "DATASET", "confidence": 0.8697113792101542}]}, {"text": " Table 2: NUM refers to the NUMERIC entities test  set and VS refers to the VOICE-SEARCH test set.  All NUM WER results are statistically significant  (p < 0.1%) using a paired random permutation  significance test.", "labels": [], "entities": [{"text": "NUMERIC entities test  set", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.6815278828144073}, {"text": "VS", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9818124175071716}, {"text": "VOICE-SEARCH test set", "start_pos": 76, "end_pos": 97, "type": "DATASET", "confidence": 0.8779925306638082}]}]}