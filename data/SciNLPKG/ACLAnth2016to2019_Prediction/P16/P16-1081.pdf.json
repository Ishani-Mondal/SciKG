{"title": [{"text": "Modeling Social Norms Evolution for Personalized Sentiment Classification", "labels": [], "entities": [{"text": "Modeling Social Norms Evolution", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8737256526947021}, {"text": "Personalized Sentiment Classification", "start_pos": 36, "end_pos": 73, "type": "TASK", "confidence": 0.7922809918721517}]}], "abstractContent": [{"text": "Motivated by the findings in social science that people's opinions are diverse and variable while together they are shaped by evolving social norms, we perform person-alized sentiment classification via shared model adaptation overtime.", "labels": [], "entities": [{"text": "person-alized sentiment classification", "start_pos": 160, "end_pos": 198, "type": "TASK", "confidence": 0.6678767402966818}]}, {"text": "In our proposed solution, a global sentiment model is constantly updated to capture the ho-mogeneity in which users express opinions , while personalized models are simultaneously adapted from the global model to recognize the heterogeneity of opinions from individuals.", "labels": [], "entities": []}, {"text": "Global model sharing alleviates data sparsity issue, and individualized model adaptation enables efficient online model learning.", "labels": [], "entities": [{"text": "individualized model adaptation", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.6425644357999166}]}, {"text": "Extensive experimentations are performed on two large review collections from Amazon and Yelp, and encouraging performance gain is achieved against several state-of-the-art transfer learning and multi-task learning based sentiment classification solutions.", "labels": [], "entities": [{"text": "Yelp", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.8329309225082397}, {"text": "sentiment classification", "start_pos": 221, "end_pos": 245, "type": "TASK", "confidence": 0.7366639077663422}]}], "introductionContent": [{"text": "Sentiment is personal; the same sentiment can be expressed in various ways and the same expression might carry distinct polarities across different individuals ().", "labels": [], "entities": []}, {"text": "Current mainstream solutions of sentiment analysis overlook this fact by focusing on population-level models.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9702284336090088}]}, {"text": "But the idiosyncratic and variable ways in which individuals communicate their opinions make a global sentiment classifier incompetent and consequently lead to suboptimal opinion mining results.", "labels": [], "entities": []}, {"text": "For instance, a shared statistical classifier can hardly recognize that in restaurant reviews, the word \"expensive\" may indicate some users' satisfaction with a restaurant's quality, although it is generally associated with negative attitudes.", "labels": [], "entities": []}, {"text": "Hence, a personalized sentiment classification solution is required to achieve fine-grained understanding of individuals' distinctive and dynamic opinions and benefit downstream opinion mining applications.", "labels": [], "entities": [{"text": "personalized sentiment classification", "start_pos": 9, "end_pos": 46, "type": "TASK", "confidence": 0.6315144598484039}, {"text": "opinion mining", "start_pos": 178, "end_pos": 192, "type": "TASK", "confidence": 0.7280847728252411}]}, {"text": "Sparse observations of individuals' opinionated data) prevent straightforward solutions from building personalized sentiment classification models, such as estimating supervised classifiers on a per-user basis.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.7345479130744934}]}, {"text": "Semi-supervised methods are developed to address the data sparsity issue.", "labels": [], "entities": []}, {"text": "For example, leveraging auxiliary information from user-user and user-document relations in transductive learning ().", "labels": [], "entities": []}, {"text": "However, only one global model is estimated there, and the details of how individual users express diverse opinions cannot be captured.", "labels": [], "entities": []}, {"text": "More importantly, existing solutions build static sentiment models on historic data; but the means in which a user expresses his/her opinion is changing overtime.", "labels": [], "entities": []}, {"text": "To capture temporal dynamics in a user's opinions with existing solutions, repeated model reconstruction is unavoidable, albeit it is prohibitively expensive.", "labels": [], "entities": [{"text": "model reconstruction", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7869217693805695}]}, {"text": "As a result, personalized sentiment analysis requires effective exploitation of users' own opinionated data and efficient execution of model updates across all users.", "labels": [], "entities": [{"text": "personalized sentiment analysis", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.7593084573745728}]}, {"text": "To address these challenges, we propose to build personalized sentiment classification models via shared model adaptation.", "labels": [], "entities": [{"text": "personalized sentiment classification", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.6382843454678854}, {"text": "shared model adaptation", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.7240219116210938}]}, {"text": "Our solution roots in the social psychology theories about humans' dispositional tendencies ().", "labels": [], "entities": []}, {"text": "Humans' behaviors are shaped by social norms, a set of socially shared \"feelings\" and \"display rules\" about how one should feel and express opinions.", "labels": [], "entities": []}, {"text": "In the context of content-based sentiment classification, we interpret social norms as global model sharing and adaptation across users.", "labels": [], "entities": [{"text": "content-based sentiment classification", "start_pos": 18, "end_pos": 56, "type": "TASK", "confidence": 0.7253279089927673}]}, {"text": "Formally, we assume a global sentiment model serves as the basis to capture self-enforcing sentimental regulari-ties across users, and each individual user tailors the shared model to realize his/her personal preference.", "labels": [], "entities": []}, {"text": "In addition, social norms also evolve overtime, which leads to shifts in individuals' behaviors.", "labels": [], "entities": []}, {"text": "This can again be interpreted as model adaptation: anew global model is adapted from an existing one to reflect the newly adopted sentimental norms.", "labels": [], "entities": []}, {"text": "The temporal changes in individuals' opinions can be efficiently captured via online model adaptation at the levels of both global and personalized models.", "labels": [], "entities": []}, {"text": "Our proposed solution can also be understood from the perspective of multi-task learning).", "labels": [], "entities": []}, {"text": "Intuitively, personalized model adaptations can be considered as a set of related tasks in individual users, which contribute to a shared global model adaptation.", "labels": [], "entities": []}, {"text": "In particular, we assume the distinct ways in which users express their opinions can be characterized by a linear classifier's parameters, i.e., the weights of textual features.", "labels": [], "entities": []}, {"text": "Personalized models are thus achieved via a series of linear transformations over a globally shared classifier's parameters (), e.g., shifting and scaling the weight vector.", "labels": [], "entities": []}, {"text": "This globally shared classifier itself is obtained via another set of linear transformations over a given base classifier, which can be estimated from an isolated collection beforehand and serves as a prior for shared sentiment classification.", "labels": [], "entities": [{"text": "shared sentiment classification", "start_pos": 211, "end_pos": 242, "type": "TASK", "confidence": 0.690148651599884}]}, {"text": "The shared global model adaptation makes personalized model estimation no longer independent, such that regularity is formed across individualized learning tasks.", "labels": [], "entities": [{"text": "personalized model estimation", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.6471181114514669}]}, {"text": "We empirically evaluated the proposed solution on two large collections of reviews, i.e., Amazon and Yelp reviews.", "labels": [], "entities": [{"text": "Amazon and Yelp reviews", "start_pos": 90, "end_pos": 113, "type": "DATASET", "confidence": 0.7364389598369598}]}, {"text": "Extensive experiment results confirm its effectiveness: the proposed method outperformed user-independent classification methods, several state-of-the-art model adaption methods, and multi-task learning algorithms.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we perform empirical evaluations of the proposed MT-LinAdapt model.", "labels": [], "entities": []}, {"text": "We verified the effectiveness of different feature groupings in individual users' and shared global model adaptation by comparing our solution with several stateof-the-art transfer learning and multi-task learning solutions for personalized sentiment classification, together with some qualitative studies to demonstrate how our model recognizes users' distinct expressions of sentiment.", "labels": [], "entities": [{"text": "personalized sentiment classification", "start_pos": 228, "end_pos": 265, "type": "TASK", "confidence": 0.7377603650093079}]}, {"text": "We evaluated the proposed model on two large collections of review documents, i.e., Amazon product reviews ( and Yelp restaurant reviews.", "labels": [], "entities": []}, {"text": "Each review document contains a set of attributes such as author ID, review ID, timestamp, textual content, and an opinion rating in discrete five-star range.", "labels": [], "entities": []}, {"text": "We applied the following pre-processing stepson both datasets: 1) filtered duplicated reviews; 2) labeled reviews with overall rating above 3 stars as positive, below 3 stars as negative, and removed the rest; 3) removed reviewers who posted more than 1,000 reviews and those whose positive review ratio is more than 90% or less than 10% (little variance in their opinions and thus easy to classify).", "labels": [], "entities": []}, {"text": "Since such users can be easily captured by the base model, the removal emphasizes comparisons on adapted models; 4) sorted each user's reviews in chronological order.", "labels": [], "entities": []}, {"text": "Then, we performed feature selection by taking the union of top unigrams and bigrams ranked by Chi-square and information gain metrics, after removing a standard list of stopwords and porter stemming.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7988433539867401}]}, {"text": "The final controlled vocabulary consists of 5,000 and 3,071 textual features for Amazon and Yelp datasets respectively; and we adopted TF-IDF as the feature weighting scheme.", "labels": [], "entities": [{"text": "Yelp datasets", "start_pos": 92, "end_pos": 105, "type": "DATASET", "confidence": 0.8773262798786163}]}, {"text": "From the resulting data sets, we randomly sampled 9,760 Amazon reviewers and 11,733 Yelp reviewers for testing purpose.", "labels": [], "entities": []}, {"text": "There are 105,472 positive reviews and 37,674 negative reviews in the selected Amazon dataset; 108,105 positive reviews and 32,352 negative reviews in the selected Yelp dataset.", "labels": [], "entities": [{"text": "Amazon dataset", "start_pos": 79, "end_pos": 93, "type": "DATASET", "confidence": 0.9374925494194031}, {"text": "Yelp dataset", "start_pos": 164, "end_pos": 176, "type": "DATASET", "confidence": 0.9904910326004028}]}, {"text": "We compared the performance of MT-LinAdapt against seven different baselines, ranging from user-independent classifiers to several state-of-the-art model adaption methods and multi-task learning algorithms.", "labels": [], "entities": []}, {"text": "Due to space limit, we will briefly discuss the baseline models below.", "labels": [], "entities": []}, {"text": "Our solution requires a user-independent classifier as base sentiment model for adaptation.", "labels": [], "entities": []}, {"text": "We estimated logistic regression models from a separated collection of reviewers outside the preserved testing data on Amazon and Yelp datasets accordingly.", "labels": [], "entities": [{"text": "Amazon and Yelp datasets", "start_pos": 119, "end_pos": 143, "type": "DATASET", "confidence": 0.7671816051006317}]}, {"text": "We also included these isolated base models in our comparison and name them as Base.", "labels": [], "entities": [{"text": "Base", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.7893268465995789}]}, {"text": "In order to verify the necessity of personalized sentiment models, we trained a global SVM based on the pooled adaptation data from all testing reviewers, and name it as Global SVM.", "labels": [], "entities": [{"text": "Global SVM", "start_pos": 170, "end_pos": 180, "type": "DATASET", "confidence": 0.9410909414291382}]}, {"text": "We also estimated an independent SVM model for each single user only based on his/her adaptation reviews, and name it as Individual SVM.", "labels": [], "entities": []}, {"text": "We included an instance-based transfer learning method), which considers the k-nearest neighbors of each testing review document from the isolated training set for personalized model training.", "labels": [], "entities": []}, {"text": "As a result, for each testing case, we estimated an independent classification model, which is denoted as ReTrain.) used L2 regularization to enforce the adapted models to be close to the global model.", "labels": [], "entities": []}, {"text": "We applied this method to get personalized logistic regression models and refer to it as RegLR.", "labels": [], "entities": [{"text": "RegLR", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.7662321329116821}]}, {"text": "LinAdapt developed in) also performs groupwise linear model adaptation to build personalization classifiers.", "labels": [], "entities": [{"text": "groupwise linear model adaptation", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.5867624208331108}]}, {"text": "But it isolates model adaptation in individual users.", "labels": [], "entities": []}, {"text": "MT-SVM is a multi-task learning method, which encodes task relatedness via a shared linear kernel ().", "labels": [], "entities": [{"text": "MT-SVM", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7050542831420898}]}, {"text": "We evaluated all the models with both synchronized (batch) and asynchronized (online) model update.", "labels": [], "entities": []}, {"text": "We should note MT-SVM can only be tested in batch mode, because it is prohibitively expensive to retrain SVM repeatedly.", "labels": [], "entities": [{"text": "MT-SVM", "start_pos": 15, "end_pos": 21, "type": "TASK", "confidence": 0.7183129191398621}]}, {"text": "In batch evaluation, we split each user's reviews into two sets: the first 50% for adaptation and the rest 50% for testing.", "labels": [], "entities": []}, {"text": "In online evaluation, once we get anew testing instance, we first evaluate the up-to-date personalized classifier against the ground-truth; then use the instance to update the personalized model.", "labels": [], "entities": []}, {"text": "To simulate the real-world situation where user reviews arrive sequentially and asynchronously, we ordered all reviews chronologically and accessed them one at a time for online model update.", "labels": [], "entities": []}, {"text": "In particular, we utilized stochastic gradient descent for this online optimization).", "labels": [], "entities": []}, {"text": "Because of the biased class distribution in both datasets, we computed F1 measure for both positive and negative class in each user, and took macro average among users to compare the different models' performance.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9808589518070221}]}], "tableCaptions": [{"text": " Table 1: Effect of different feature groupings in  MT-LinAdapt.", "labels": [], "entities": [{"text": "MT-LinAdapt", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.7794361710548401}]}, {"text": " Table 2: Classification results in batch mode.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9769315123558044}]}, {"text": " Table 3: Shared model adaptation for cold start on Amazon and Yelp.", "labels": [], "entities": [{"text": "Yelp", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.5306220054626465}]}]}