{"title": [{"text": "Prediction of Prospective User Engagement with Intelligent Assistants", "labels": [], "entities": []}], "abstractContent": [{"text": "Intelligent assistants on mobile devices, such as Siri, have recently gained considerable attention as novel applications of dialogue technologies.", "labels": [], "entities": []}, {"text": "A tremendous amount of real users of intelligent assistants provide us with an opportunity to explore a novel task of predicting whether users will continually use their intelligent assistants in the future.", "labels": [], "entities": []}, {"text": "We developed prediction models of prospective user engagement by using large-scale user logs obtained from a commercial intelligent assistant.", "labels": [], "entities": []}, {"text": "Experiments demonstrated that our models can predict prospective user engagement reasonably well, and outper-forms a strong baseline that makes prediction based past utterance frequency.", "labels": [], "entities": []}], "introductionContent": [{"text": "Intelligent assistants on mobile devices, such as Siri, have recently gained considerable attention as novel applications of dialogue technologies (.", "labels": [], "entities": []}, {"text": "They receive instructions from users via voice control to execute a wide range of tasks (e.g., searching the Web, setting alarms, making phone calls, and so on).", "labels": [], "entities": []}, {"text": "Some are able to even chat or play games with users (.", "labels": [], "entities": []}, {"text": "Intelligent assistants possess a unique characteristic as an object of dialogue study.", "labels": [], "entities": []}, {"text": "Popular intelligent assistants have thousands or even millions of real users, thanks to the prevalence of mobile devices.", "labels": [], "entities": []}, {"text": "Some of those users continually use intelligent assistants fora long period of time, while others stop using them after a few trials.", "labels": [], "entities": []}, {"text": "Such user behaviors are rarely observed in conventional experimental environments, where dialogue systems 1 http://www.apple.com/ios/siri have only a small number of experimental participants who almost always continue to use the systems for the whole duration of the experiment.", "labels": [], "entities": []}, {"text": "This paper explores a novel task of predicting whether a user will continue to use intelligent assistants in the future (This task is referred to as prospective user engagement prediction and its definition is given in Section 3).", "labels": [], "entities": [{"text": "prospective user engagement prediction", "start_pos": 149, "end_pos": 187, "type": "TASK", "confidence": 0.6299375593662262}]}, {"text": "We attempt to develop such a prediction model, which would contribute to enhancing intelligent assistants in many ways.", "labels": [], "entities": []}, {"text": "For example, if users who are likely to stop using systems can be identified, intelligent assistants can take actions to gain or maintain their interest (e.g., by sending push notifications).", "labels": [], "entities": []}, {"text": "This task is related to, but is significantly different from, user engagement detection, which has been extensively explored in prior dialogue studies (.", "labels": [], "entities": [{"text": "user engagement detection", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.7987593412399292}]}, {"text": "The prior studies attempt to predict how strongly users are currently engaged in dialogues with systems.", "labels": [], "entities": []}, {"text": "On the other hand, the goal of this study is to predict how strongly users will be engaged with intelligent assistants in the future.", "labels": [], "entities": []}, {"text": "The largest difference lies in whether the prediction target is user engagement at present or in the future.", "labels": [], "entities": []}, {"text": "Also, our definition of engagement is slightly different from the prior ones.", "labels": [], "entities": []}, {"text": "In this study, engagement is considered as a sentiment as to whether users like intelligent assistants and feel like they want to use them continually.", "labels": [], "entities": []}, {"text": "To develop and evaluate models of prospective user engagement prediction, we exploit large-scale user logs obtained from a commercial intelligent assistant.", "labels": [], "entities": [{"text": "user engagement prediction", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.6163598597049713}]}, {"text": "Since monitoring users' long-term behaviors is considered crucial for precise prediction of their prospective engagement, we tailor various features by extracting usage patterns from along history of user dialogues.", "labels": [], "entities": []}, {"text": "The resulting features are contrastive to those previously used for user engagement detection, in which features are basically extracted from a single user utterance.", "labels": [], "entities": [{"text": "user engagement detection", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.7099886536598206}]}, {"text": "Experimental results demonstrated that our models are able to predict prospective user engagement reasonably well and are overwhelmingly better than a strong baseline that makes predictions based on past utterance frequency.", "labels": [], "entities": []}, {"text": "We also discuss the trade-off between prediction accuracy and instancy.", "labels": [], "entities": [{"text": "prediction", "start_pos": 38, "end_pos": 48, "type": "TASK", "confidence": 0.9345417022705078}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9092937707901001}]}, {"text": "Specifically, we investigate how the prediction performance improves as we wait for more user dialogues to be collected.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe our experimental results and discuss them.", "labels": [], "entities": []}, {"text": "We randomly divided the log data into training, development, and test sets with the ratio of 8:1:1.", "labels": [], "entities": []}, {"text": "Note that we confirmed that the users in different data sets do not overlap with each other.", "labels": [], "entities": []}, {"text": "We trained the model with the training set and optimized hyperparameters with the development set.: Precisions and Recalls in the dropout prediction task.", "labels": [], "entities": [{"text": "Precisions", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9914645552635193}, {"text": "Recalls", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9892884492874146}, {"text": "dropout prediction task", "start_pos": 130, "end_pos": 153, "type": "TASK", "confidence": 0.8163663148880005}]}, {"text": "the SVR for the engagement level prediction task.", "labels": [], "entities": [{"text": "SVR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8714155554771423}, {"text": "engagement level prediction task", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.7403156906366348}]}, {"text": "We optimized the C parameter on the development set.", "labels": [], "entities": []}, {"text": "In the dropout prediction task, we used the -w option to weigh the C parameter of each class with the inverse ratio of the number of users in that class.", "labels": [], "entities": [{"text": "dropout prediction task", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8538666566212972}]}, {"text": "We also used the -B option to introduce the bias term.", "labels": [], "entities": []}, {"text": "Next, we describe the evaluation metrics.", "labels": [], "entities": []}, {"text": "We used accuracy and F 1 -measure in the dropout prediction task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9997047781944275}, {"text": "F 1 -measure", "start_pos": 21, "end_pos": 33, "type": "METRIC", "confidence": 0.9908464401960373}, {"text": "dropout prediction task", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.8410584131876627}]}, {"text": "Mean squared error (MSE) and Spearman rank correlation coefficient were used in the engagement level prediction task.", "labels": [], "entities": [{"text": "Mean squared error (MSE)", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.9663661817709605}, {"text": "Spearman rank correlation coefficient", "start_pos": 29, "end_pos": 66, "type": "METRIC", "confidence": 0.7170184105634689}, {"text": "engagement level prediction task", "start_pos": 84, "end_pos": 116, "type": "TASK", "confidence": 0.7936496138572693}]}, {"text": "These evaluation metrics are commonly used in classification and regression tasks.", "labels": [], "entities": []}, {"text": "We compare the proposed models with baseline method.", "labels": [], "entities": []}, {"text": "Because we have no previous work on both tasks, we defined baseline method of our own.", "labels": [], "entities": []}, {"text": "The baseline method was trained in the same framework as the proposed methods except that they used only Session feature.", "labels": [], "entities": []}, {"text": "We chose Session for baseline because frequency of use features such as Session were shown predictive to similar tasks () to prospective user engagement.", "labels": [], "entities": []}, {"text": "illustrates the result of dropout prediction task.", "labels": [], "entities": [{"text": "dropout prediction", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7587940394878387}]}, {"text": "The first row compares the proposed method with the baseline.", "labels": [], "entities": []}, {"text": "We can see that the proposed: Accuracies per the number of sessions in the observation period of the proposed method and the baseline.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9953319430351257}]}, {"text": "The rightmost points represent the accuracy of the users whose number of sessions in the observation period are equal to or more than 40.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9994432330131531}]}, {"text": "This indicates the effectiveness of our feature set.", "labels": [], "entities": []}, {"text": "The second row illustrates the performances of the proposed method when only one feature type is used.", "labels": [], "entities": []}, {"text": "This result suggests that the utterance frequency and time interval features are especially useful, while the combination of all types of features performs the best.", "labels": [], "entities": []}, {"text": "We conducted McNemar test to investigate the significance of these improvements, and confirmed that all improvements are statistically significant (p < 0.01).", "labels": [], "entities": [{"text": "McNemar test", "start_pos": 13, "end_pos": 25, "type": "METRIC", "confidence": 0.9238891005516052}]}, {"text": "shows the precisions and the recalls of dropout prediction task.", "labels": [], "entities": [{"text": "precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9995657801628113}, {"text": "recalls", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.998842179775238}, {"text": "dropout prediction", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7075401991605759}]}, {"text": "As shown in, the precision of the proposed method performs the best while the recall is worst.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9994207620620728}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9992382526397705}]}, {"text": "We consider that the performance of the precision is more important for our model because taking proactive actions against users who are likely to stop using the system is one of the assumed applications.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.997955322265625}]}, {"text": "Taking proactive actions (e.g., push notifications) against users continually using the system might irritate them and de- crease their user engagement.", "labels": [], "entities": []}, {"text": "Therefore, the rate of the users who actually intend to stop using the system in the users predicted as dropout affects the effectiveness of these proactive actions.", "labels": [], "entities": []}, {"text": "The result that the precision of the proposed method is 0.553 and that of the baseline is 0.350 is, in other words, using the proposed model improves the effectiveness by 20% absolute in taking these actions.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9994890689849854}]}, {"text": "shows the accuracies per the number of sessions in the observation period of the proposed method and the baseline.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9919742941856384}]}, {"text": "The proposed method consistently outperforms the baseline throughout the number of sessions in the observation period.", "labels": [], "entities": []}, {"text": "In particular, the proposed method predicts well the dropout of users whose number of sessions is around five compared to the baseline.", "labels": [], "entities": []}, {"text": "These results again indicate the effectiveness of the combination of our feature set.", "labels": [], "entities": []}, {"text": "shows the result of engagement level prediction task.", "labels": [], "entities": [{"text": "engagement level prediction", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.5813173154989878}]}, {"text": "We again observe similar trends to the dropout prediction task.", "labels": [], "entities": [{"text": "dropout prediction task", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.8081340193748474}]}, {"text": "The proposed method outperforms the baseline.", "labels": [], "entities": []}, {"text": "The utterance frequency and time interval features are the most effective, while the combination of all four feature types achieves the best performance in both evaluation metrics.", "labels": [], "entities": []}, {"text": "visualizes the correlation between the oracle engagement levels and the ones predicted by the baseline (left) and by the proposed method (right).", "labels": [], "entities": []}, {"text": "We can intuitively reconfirm that the proposed method is able to predict the engagement levels reasonably well.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: User log examples. The dashed line represents the session boundary.", "labels": [], "entities": []}, {"text": " Table 3: User distribution over the four engage- ment levels. The second column represents inter- vals of the number of sessions corresponding to  the four levels.", "labels": [], "entities": []}, {"text": " Table 4: List of features. The utterance frequency features, response frequency features, and time interval  features are all scaled.", "labels": [], "entities": []}, {"text": " Table 6: Classification accuracies and F-measures  in the dropout prediction task.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9986190795898438}, {"text": "dropout prediction task", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.8303128878275553}]}, {"text": " Table 7: Precisions and Recalls in the dropout pre- diction task.", "labels": [], "entities": [{"text": "Precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9927600622177124}, {"text": "Recalls", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9772342443466187}]}, {"text": " Table 8: MSE and Spearman's \u03c1 in the engage- ment level prediction task.", "labels": [], "entities": [{"text": "MSE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5104058384895325}, {"text": "engage- ment level prediction task", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.640859658519427}]}, {"text": " Table 9: Feature weights learned by the SVR.", "labels": [], "entities": [{"text": "SVR", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.8122442364692688}]}]}