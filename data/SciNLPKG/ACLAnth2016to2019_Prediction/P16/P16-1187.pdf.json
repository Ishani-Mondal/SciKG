{"title": [{"text": "Predicting the Compositionality of Nominal Compounds: Giving Word Embeddings a Hard Time", "labels": [], "entities": []}], "abstractContent": [{"text": "Distributional semantic models (DSMs) are often evaluated on artificial similarity datasets containing single words or fully compositional phrases.", "labels": [], "entities": [{"text": "Distributional semantic models (DSMs)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7059269150098165}]}, {"text": "We present a large-scale multilingual evaluation of DSMs for predicting the degree of semantic compositionality of nominal compounds on 4 datasets for En-glish and French.", "labels": [], "entities": []}, {"text": "We build a total of 816 DSMs and perform 2,856 evaluations using word2vec, GloVe, and PPMI-based models.", "labels": [], "entities": []}, {"text": "In addition to the DSMs, we compare the impact of different parameters, such as level of corpus preprocessing, context window size and number of dimensions.", "labels": [], "entities": []}, {"text": "The results obtained have a high correlation with human judgments, being comparable to or outperforming the state of the art for some datasets (Spearman's \u03c1=.82 for the Reddy dataset).", "labels": [], "entities": [{"text": "Reddy dataset", "start_pos": 169, "end_pos": 182, "type": "DATASET", "confidence": 0.9390708804130554}]}], "introductionContent": [{"text": "Distributional semantic models (DSMs) use context information to represent the meaning of lexical units as vectors.", "labels": [], "entities": []}, {"text": "They normally focus on the accurate semantic representation of single words.", "labels": [], "entities": [{"text": "accurate semantic representation of single words", "start_pos": 27, "end_pos": 75, "type": "TASK", "confidence": 0.7036816676457723}]}, {"text": "It is based on single words that many optimizations for these models have been proposed.", "labels": [], "entities": []}, {"text": "This is particularly true for word embeddings, that is, a type of DSM where distributional vectors are obtained as a by-product of training a neural network to learn a function between words and their contexts ().", "labels": [], "entities": []}, {"text": "Simultaneously, there has been intensive research on models to compose individual word vectors in order to create representations for larger units such as phrases, sentences and even whole documents ().", "labels": [], "entities": []}, {"text": "Larger units can often be assumed to have their meanings derived from their parts according to the language's grammar, but this is not always the case ().", "labels": [], "entities": []}, {"text": "Many multiword units are associated with idiomatic interpretations, unrelated to the meaning of the component words (e.g. silver bullet, eager beaver).", "labels": [], "entities": []}, {"text": "Precision-oriented NLP applications need to be able to identify partly-compositional and idiomatic cases and ensure meaning preservation during processing.", "labels": [], "entities": [{"text": "meaning preservation", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.6892126351594925}]}, {"text": "Compositionality identification is a first step towards complete semantic interpretation in tasks such as machine translation (to translate non-compositional compounds as a unit), word sense disambiguation (to avoid assigning a sense to parts of non-compositional compounds), and semantic parsing (to identify complex predicates and their arguments).", "labels": [], "entities": [{"text": "Compositionality identification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8641238808631897}, {"text": "semantic interpretation", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7636958360671997}, {"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7443272173404694}, {"text": "word sense disambiguation", "start_pos": 180, "end_pos": 205, "type": "TASK", "confidence": 0.6899442871411642}, {"text": "semantic parsing", "start_pos": 280, "end_pos": 296, "type": "TASK", "confidence": 0.7124281078577042}]}, {"text": "Even when larger units are explicitly represented in DSMs (), it is not clear whether the quality of these representations is comparable to the representations of single words.", "labels": [], "entities": []}, {"text": "In particular, when building vectors for larger units, their generally lower frequencies in corpora) may combine with morphosyntactic phenomena to increase sparsity even further, often requiring non-trivial preprocessing (lemmatization and word reordering) to conflate variants.", "labels": [], "entities": []}, {"text": "This paper presents a large-scale multilingual evaluation of DSMs and their parameters for the task of compositionality prediction of nominal compounds in French and English.", "labels": [], "entities": [{"text": "compositionality prediction of nominal compounds", "start_pos": 103, "end_pos": 151, "type": "TASK", "confidence": 0.8361846804618835}]}, {"text": "We examine parameters like the level of corpus preprocessing, the size of the context window and the number of dimensions for context representation.", "labels": [], "entities": [{"text": "context representation", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.7209547758102417}]}, {"text": "Additionally, we compare standard DSMs based on positive pointwise mutual information (PPMI) against widely used word embedding tools such as word2vec, henceforth, and GloVe ().", "labels": [], "entities": []}, {"text": "We start with a discussion of related work ( \u00a72) and the materials and methods used ( \u00a73).", "labels": [], "entities": []}, {"text": "We report on the evaluations performed ( \u00a74) and finish with conclusions and future work ( \u00a75).", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, we use nominal compound compositionality datasets for English and for French (FR-comp).", "labels": [], "entities": [{"text": "FR-comp", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9584136009216309}]}, {"text": "They provide annotations as to whether a given compound is more idiomatic or more compositional.", "labels": [], "entities": []}, {"text": "Reddy contains compositionality judgments for 90 compounds and their individual word components, in a scale of literality from 0 (idiomatic) to 5 (literal), collected with Mechanical Turk (Reddy et al., 2011).", "labels": [], "entities": []}, {"text": "For each compound, compositionality scores are averaged over its annotators.", "labels": [], "entities": []}, {"text": "Compounds included in the dataset were selected to balance frequency range and degree of compositionality (low, middle and high).", "labels": [], "entities": []}, {"text": "We use only the global compositionality score, ignoring individual word judgments.", "labels": [], "entities": []}, {"text": "With a few exceptions (e.g. sacred cow), most compounds are formed exclusively by nouns.", "labels": [], "entities": []}, {"text": "Reddy++ is anew resource created for this evaluation (.", "labels": [], "entities": [{"text": "Reddy++", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9377747774124146}]}, {"text": "It extends the Reddy set with an additional 90 English nominal compounds, in a total of 180 entries.", "labels": [], "entities": [{"text": "Reddy set", "start_pos": 15, "end_pos": 24, "type": "DATASET", "confidence": 0.9256528913974762}]}, {"text": "Scores also range from 0 to 5 and were collected through Mechanical Turk and averaged over the annotators.", "labels": [], "entities": [{"text": "Mechanical Turk", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9576704502105713}]}, {"text": "The extra 90 entries include some adjective-noun compounds and are balanced with respect to frequency and compositionality.", "labels": [], "entities": []}, {"text": "We focus our evaluation on this combined dataset, since it includes Reddy.", "labels": [], "entities": [{"text": "Reddy", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9484391808509827}]}, {"text": "However, to allow comparison with state of the art, we also report results individually for Reddy.", "labels": [], "entities": []}, {"text": "Farahmand contains 1042 English compounds extracted from Wikipedia with binary noncompositionality judgments by four experts ).", "labels": [], "entities": []}, {"text": "We consider a compound as non-compositional if at least two judges agree that it is non-compositional, following.", "labels": [], "entities": []}, {"text": "In our evaluations, we use the sum of all judgments in order to have a single numeral compositionality score, ranging from 0 (compositional) to 4 (idiomatic).", "labels": [], "entities": []}, {"text": "FR-comp is also anew resource created for this evaluation.", "labels": [], "entities": [{"text": "FR-comp", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.48762714862823486}]}, {"text": "It contains 180 adjective-noun and noun-adjective compounds in French, such as belle-m` ere (mother-in-law, lit. beautiful-mother) and carte bleue (credit card, lit. blue card).", "labels": [], "entities": []}, {"text": "This dataset was constructed in the same manner as the extension to Reddy, that is, using crowdsourcing and average numerical scores.", "labels": [], "entities": [{"text": "Reddy", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9673053026199341}]}, {"text": "Special care was taken to guarantee that annotators were native speakers by asking them to provide paraphrases along with compositionality scores.", "labels": [], "entities": []}, {"text": "The new datasets Reddy++ and FR-comp are similar to Reddy.", "labels": [], "entities": [{"text": "Reddy++", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.9159683883190155}, {"text": "FR-comp", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9689115881919861}, {"text": "Reddy", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.9611521363258362}]}, {"text": "For instance, the average standard deviation of compound scores given by different annotators is \u03c3 = 1.17 for the new compounds in Reddy++, \u03c3 = 1.15 for FR-comp and \u03c3 = 0.99 for Reddy.", "labels": [], "entities": [{"text": "standard deviation of compound scores", "start_pos": 26, "end_pos": 63, "type": "METRIC", "confidence": 0.8365322589874268}, {"text": "FR-comp", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.5992406010627747}, {"text": "Reddy", "start_pos": 178, "end_pos": 183, "type": "DATASET", "confidence": 0.9088578224182129}]}, {"text": "Their detailed evaluation is presented by.", "labels": [], "entities": []}, {"text": "We evaluate the compositionality models and their parameters on the datasets described in Section 3.2.", "labels": [], "entities": []}, {"text": "For Reddy, Reddy++ and FR-comp, we report Spearman's \u03c1 correlation between the ranking provided by humans and those calculated from the models.", "labels": [], "entities": [{"text": "FR-comp", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9750994443893433}, {"text": "Spearman's \u03c1 correlation", "start_pos": 42, "end_pos": 66, "type": "METRIC", "confidence": 0.8601071089506149}]}, {"text": "We follow and report the best F1 score (BF1) obtained for the Farahmand dataset, by calculating the F1 score for the top k compounds classified as positive (noncompositional), for all possible values of k.", "labels": [], "entities": [{"text": "F1 score (BF1)", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.9020159244537354}, {"text": "Farahmand dataset", "start_pos": 62, "end_pos": 79, "type": "DATASET", "confidence": 0.9698155224323273}, {"text": "F1 score", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9854286313056946}]}, {"text": "Given the high number of experiments we performed, we report the best performance of each model type.", "labels": [], "entities": []}, {"text": "For instance, the performances reported for w2v-cbow using different values of WINDOWSIZE are the best configurations across all possible values of other parameters such as DIMENSION and WORDFORM.", "labels": [], "entities": []}, {"text": "This avoids reporting local maxima that can arise if one fixes all other parameters when evaluating a given one.", "labels": [], "entities": []}, {"text": "For Reddy++ and Farahmand, we distinguish between strict evaluation, reported in the form of wider bars in the figures, and loose evaluation, shown as narrow blue bars in the figures.", "labels": [], "entities": []}, {"text": "Strict evaluation corresponds to the performance of the model only on those compounds that have a vector representation in all underlying DSMs, 175 out of 180 for Reddy++ and 913 out of 1042 for Farahmand.", "labels": [], "entities": [{"text": "Reddy++", "start_pos": 163, "end_pos": 170, "type": "DATASET", "confidence": 0.87148317694664}]}, {"text": "Loose evaluation considers the full dataset, using a fallback strategy for the imputation of missing values, assigning the average compositionality score to absent compounds (.", "labels": [], "entities": []}, {"text": "This is particularly important for Farahmand, which contains more rare compounds such as universe human and mankind instruction so that 129 compounds are missing in the corpus.", "labels": [], "entities": []}, {"text": "Only strict evaluation is reported for FR-comp, as all compounds are frequent enough in FRWaC.", "labels": [], "entities": [{"text": "FR-comp", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.6515017747879028}, {"text": "FRWaC", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.9270293712615967}]}, {"text": "The vectors generated by and glove have some non-determinism due to random initialization.", "labels": [], "entities": []}, {"text": "To assess its impact on results, we report the average of 3 runs using identical configurations and use error bars in the graphics.", "labels": [], "entities": []}, {"text": "The results for context vector dimensionality,, show, as expected, that the best results are obtained with larger dimensions (DIMENSION=750) for all models, except for glove, which displays very similar results independently of the number of dimensions.", "labels": [], "entities": [{"text": "DIMENSION", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9978281855583191}]}, {"text": "Examining the Reddy dataset alone, the same trends for all parameters were found, but with higher results.", "labels": [], "entities": [{"text": "Reddy dataset", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.976238489151001}]}, {"text": "The overall best performances on Reddy were quite similar: w2v-cbow (\u03c1 = 0.82),-sg (\u03c1 = 0.81), PPMI-SVD (\u03c1 = 0.80) and PPMI-thresh (\u03c1 = 0.79), and the differences are significant except for the two best w2v models.", "labels": [], "entities": [{"text": "Reddy", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9738373756408691}]}, {"text": "The 90 compounds added to Reddy++ seem to be more difficult to assess than the original ones, probably because they include many adjectives, which have been found harder to judge for compositionality than nouns (Ramisch et al., 2016).", "labels": [], "entities": []}, {"text": "shows the overall best model for the Farahmand dataset.", "labels": [], "entities": [{"text": "Farahmand dataset", "start_pos": 37, "end_pos": 54, "type": "DATASET", "confidence": 0.9643098711967468}]}, {"text": "PPMI-SVD reached a BF1 score of 0.52, with DIMENSION=750, WINDOW-SIZE=4, using lemma, and both w2v (BF1=0.51) obtain comparable results with similar configurations.", "labels": [], "entities": [{"text": "PPMI-SVD", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8049958944320679}, {"text": "BF1", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9980165958404541}, {"text": "DIMENSION", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9977686405181885}, {"text": "WINDOW-SIZE", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9925676584243774}, {"text": "BF1", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9810081720352173}]}, {"text": "These results show a marked difference between the loose (the narrower bars in the figures) and the strict evaluation (wider bars).", "labels": [], "entities": []}, {"text": "The former uses a fallback strategy for the imputation of missing values that does not accurately reflect how the compositionality scores vary.", "labels": [], "entities": []}, {"text": "Indeed, we observed that compounds that do not appear very often in our corpora tend to be non-compositional, whereas most of the compound occurrences are compositional, increasing average compositionality.", "labels": [], "entities": []}, {"text": "For instance, the 10 most compositional compounds in Reddy++ occur an average of 26551  times in the UKWaC vs 1096 times for the 10 least compositional ones.", "labels": [], "entities": [{"text": "UKWaC", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.979316771030426}]}, {"text": "Spearman rank correlation between frequency and compositionality in Reddy++ is \u03c1 = 0.43.", "labels": [], "entities": [{"text": "Spearman rank correlation", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.8197037180264791}, {"text": "Reddy++", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.917451947927475}]}, {"text": "12 In short, even if a fallback strategy is adopted as the means to obtain a lowerbound for performance, it maybe unrelated to the real performance for the missing compounds.", "labels": [], "entities": []}, {"text": "For most models, corpus preprocessing resulted in better scores, with WORDFORM=lemma outperforming all other forms of preprocessing, especially for French.", "labels": [], "entities": [{"text": "WORDFORM", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9924495220184326}]}, {"text": "Concatenating lemmas and POS tags does not seem to help, probably due to decreasing word frequencies without substantial gain in informativeness).", "labels": [], "entities": []}, {"text": "The impact of WINDOWSIZE has a similar trend to the one found for the Reddy++ and Reddy datasets).", "labels": [], "entities": [{"text": "Reddy++", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.9254665374755859}, {"text": "Reddy datasets", "start_pos": 82, "end_pos": 96, "type": "DATASET", "confidence": 0.8263958096504211}]}, {"text": "That is, the larger window was preferred by most models, but the average difference between the best and the worst size for each DSM is only 0.01.", "labels": [], "entities": []}, {"text": "For DIMENSION, a larger number resulted in better scores, as expected, with 750 being the best for all models in.", "labels": [], "entities": [{"text": "DIMENSION", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.49972763657569885}]}, {"text": "Nonetheless, here too the average difference in scores between DIMENSION=750 and 250 is 0.01.", "labels": [], "entities": [{"text": "DIMENSION", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9890086054801941}]}, {"text": "Globally, for the FR-comp dataset, PPMI-thresh (\u03c1 = 0.70) outperforms glove (\u03c1 = 0.68) and w2v (\u03c1 = 0.66), as can be seen in.", "labels": [], "entities": [{"text": "FR-comp dataset", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.9122032225131989}]}, {"text": "For morphologically rich languages like French,(b) indicates that working on lemmatized data often yields better results than working on surface forms.", "labels": [], "entities": []}, {"text": "Lemmas conflate the frequencies for all the many morphologically inflected variants which would otherwise be dispersed in different surface forms.", "labels": [], "entities": []}, {"text": "Therefore, it is not surprising that the best results concerning WORDFORM are achieved by lemma.", "labels": [], "entities": [{"text": "WORDFORM", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.4872182011604309}]}, {"text": "These results differ from English, where a corpus without any preprocess-  ing yields more accurate results.", "labels": [], "entities": []}, {"text": "Moreover, a smaller WINDOWSIZE leads to better results for most models, as shown in.", "labels": [], "entities": [{"text": "WINDOWSIZE", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9889076352119446}]}, {"text": "But just as in English, all models except glove benefit from an increase in dimension, as shown in.", "labels": [], "entities": [{"text": "dimension", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9882245063781738}]}], "tableCaptions": []}