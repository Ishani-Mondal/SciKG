{"title": [{"text": "An Unsupervised Method for Automatic Translation Memory Cleaning", "labels": [], "entities": [{"text": "Automatic Translation Memory Cleaning", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.7688952684402466}]}], "abstractContent": [{"text": "We address the problem of automatically cleaning a large-scale Translation Memory (TM) in a fully unsupervised fashion , i.e. without human-labelled data.", "labels": [], "entities": [{"text": "automatically cleaning a large-scale Translation Memory (TM)", "start_pos": 26, "end_pos": 86, "type": "TASK", "confidence": 0.7271037002404531}]}, {"text": "We approach the task by: i) designing a set of features that capture the similarity between two text segments in different languages, ii) use them to induce reliable training labels fora subset of the translation units (TUs) contained in the TM, and iii) use the automatically labelled data to train an ensemble of binary clas-sifiers.", "labels": [], "entities": []}, {"text": "We apply our method to clean a test set composed of 1,000 TUs randomly extracted from the English-Italian version of MyMemory, the world's largest public TM.", "labels": [], "entities": [{"text": "MyMemory", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.7985647916793823}]}, {"text": "Our results show competitive performance not only against a strong baseline that exploits machine translation, but also against a state-of-the-art method that relies on human-labelled data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7145291268825531}]}], "introductionContent": [{"text": "Translation Memories (TMs) are one of the main sources of knowledge supporting human translation with the so-called Computer-assisted Translation (CAT) tools.", "labels": [], "entities": [{"text": "Translation Memories (TMs)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9113924503326416}, {"text": "human translation", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.6939796805381775}, {"text": "Computer-assisted Translation (CAT)", "start_pos": 116, "end_pos": 151, "type": "TASK", "confidence": 0.8567415952682496}]}, {"text": "ATM is a database that stores (source, target) segments called translation units (TUs).", "labels": [], "entities": []}, {"text": "These segments can be sub-sentential fragments, full sentences or even paragraphs in two languages and, ideally, they are perfect translations of each other.", "labels": [], "entities": []}, {"text": "Their use in a CAT framework is based on computing a \"fuzzy match\" score between an input sentence to be translated and the left-hand side (the source) of each TU stored in the TM.", "labels": [], "entities": []}, {"text": "If the score is above a certain threshold, the right-hand side (the target) is presented to the user as a translation suggestion.", "labels": [], "entities": []}, {"text": "When translating a document with a CAT tool, the user can store each translated (source, target) pair in the TM for future use.", "labels": [], "entities": []}, {"text": "Each newly added TU contributes to the growth of the TM which, as time goes by, will become more and more useful to the user.", "labels": [], "entities": []}, {"text": "Due to such constant growth, in which they evolve incorporating users style and terminology, the socalled private TMs represent an invaluable asset for individual translators and translation companies.", "labels": [], "entities": []}, {"text": "Collaboratively-created public TMs grow in a less controlled way (e.g. incorporating potentially noisy TUs supplied by anonymous contributors or automatically extracted from the Web) but still remain a practical resource for the translators' community at large.", "labels": [], "entities": []}, {"text": "Together with the quantity, the quality of the stored material is a crucial factor that determines the usefulness of the TM and, all in all, its value.", "labels": [], "entities": []}, {"text": "For this reason, the growth of the TM should go hand in hand with its continuous maintenance.", "labels": [], "entities": [{"text": "TM", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.7267704606056213}]}, {"text": "This problem is usually addressed through manual (hence costly) revision, or by applying simple (hence approximate) automatic filtering routines.", "labels": [], "entities": []}, {"text": "Advanced automatic methods for tidying up an existing TM would contribute to reduce management costs, increase its quality, speed-up and simplify the daily work of human translators.", "labels": [], "entities": []}, {"text": "Focusing on TM maintenance, we explore an automatic method to clean a large-scale TM by identifying the TUs in which the target is a poor translation of the source.", "labels": [], "entities": [{"text": "TM maintenance", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.9786898493766785}]}, {"text": "Its main strength is the reliance on a fully unsupervised approach, which makes it independent from the availability of human-labelled data.", "labels": [], "entities": []}, {"text": "As it allows us to avoid the burden of acquiring a (possibly large) set of annotated TUs, our method is cost-effective and highly portable across languages and TMs.", "labels": [], "entities": []}, {"text": "This contrasts with supervised strategies like the one presented in ( or those applied in closely-related tasks such as cross-lingual seman- tic textual similarity, 1 cross-lingual textual entailment ( ), and quality estimation (QE) for MT (.", "labels": [], "entities": [{"text": "quality estimation (QE)", "start_pos": 209, "end_pos": 232, "type": "METRIC", "confidence": 0.8240152835845947}, {"text": "MT", "start_pos": 237, "end_pos": 239, "type": "TASK", "confidence": 0.9722160696983337}]}, {"text": "Also most of the previous approaches to bilingual data mining/cleaning for statistical MT rely on supervised learning.", "labels": [], "entities": [{"text": "bilingual data mining/cleaning", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.6832609415054322}, {"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.7106375694274902}]}, {"text": "Unsupervised solutions, like the one proposed by usually rely on redundancy-based approaches that reward parallel segments containing phrase pairs that are frequent in a training corpus.", "labels": [], "entities": []}, {"text": "This idea is wellmotivated in the SMT framework but scarcely applicable in the CAT scenario, in which it is crucial to manage and reward rare phrases as a source of useful suggestions for difficult translations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9841635823249817}, {"text": "CAT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9421137571334839}]}], "datasetContent": [{"text": "We experiment with the English-Italian version of MyMemory, 6 the world's largest public TM.", "labels": [], "entities": [{"text": "MyMemory", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9251634478569031}]}, {"text": "This collaboratively built TM contains about 11M TUs coming from heterogeneous sources: aggregated private TMs or automatically extracted from the web/corpora, and anonymous contributions of (source, target) bi-segments.", "labels": [], "entities": []}, {"text": "Being large and free, the TM is of great utility for professional translators.", "labels": [], "entities": []}, {"text": "Its uncontrolled sources, however, call for accurate cleaning methods (e.g. to make it more accurate, smaller and manageable).", "labels": [], "entities": []}, {"text": "From the TM we randomly extracted: i) subsets of variable size to automatically obtain training data for the base classifiers and ii) a collection of 2,500 TUs manually annotated with binary labels.", "labels": [], "entities": []}, {"text": "Data annotation was done by two Italian native speakers properly trained with the same guidelines prepared by the TM owner for periodic manual revisions.", "labels": [], "entities": [{"text": "Data annotation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6145167946815491}, {"text": "TM owner", "start_pos": 114, "end_pos": 122, "type": "DATASET", "confidence": 0.8238069415092468}]}, {"text": "After agreement computation (Cohen's kappa is 0.7838), a reconciliation ended up with about 65% positive and 35% negative examples.", "labels": [], "entities": []}, {"text": "This pool is randomly split in two parts.", "labels": [], "entities": []}, {"text": "One (1,000 instances) is used as test set for our evaluation.", "labels": [], "entities": []}, {"text": "The other (1,500 instances) is used to replicate the approach of used as term of comparison.", "labels": [], "entities": []}, {"text": "Our base classifiers are trained with the Extremely Randomized Trees algorithm), optimized using 10-fold cross-validation in a randomized search process and combined in a majority voting schema.", "labels": [], "entities": []}, {"text": "To handle the imbalanced (65%-35%) data distribution, and equally reward the correct classification on both classes, we evaluate performance in terms of balanced accuracy https://mymemory.translated.net/ (BA), computed as the average of the accuracies on the two classes ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9891630411148071}, {"text": "BA)", "start_pos": 205, "end_pos": 208, "type": "METRIC", "confidence": 0.984644740819931}, {"text": "accuracies", "start_pos": 241, "end_pos": 251, "type": "METRIC", "confidence": 0.9884933829307556}]}, {"text": "We evaluate our approach against two terms of comparison, both stronger than the trivial random baseline achieving a BA of 50.0%.", "labels": [], "entities": [{"text": "BA", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.9991974234580994}]}, {"text": "The first competitor (MT-based) is a translation-based solution that exploits Bing translator to render the source segment of a TU in the same language of the target.", "labels": [], "entities": []}, {"text": "Then, the similarity between the translated source and the target segment is measured in terms of Translation Edit Rate (TER).", "labels": [], "entities": [{"text": "Translation Edit Rate (TER)", "start_pos": 98, "end_pos": 125, "type": "METRIC", "confidence": 0.9304126501083374}]}, {"text": "The TU is marked as \"good\" if the TER is smaller than 0.4 (\"bad\" otherwise).", "labels": [], "entities": [{"text": "TU", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9797688126564026}, {"text": "TER", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9972135424613953}]}, {"text": "This value is chosen based on the findings of , which suggests that only for TER values lower than 0.4 human translators consider MT suggestions as good enough for being post-editable.", "labels": [], "entities": [{"text": "TER", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9719523787498474}, {"text": "MT", "start_pos": 130, "end_pos": 132, "type": "TASK", "confidence": 0.9333460330963135}]}, {"text": "In our scenario we hence assume that \"good\" TUs are those featuring a small TER distance between the target and an automatic translation of the source.", "labels": [], "entities": [{"text": "TER distance", "start_pos": 76, "end_pos": 88, "type": "METRIC", "confidence": 0.9791995584964752}]}, {"text": "The second competitor (Barbu15) is the supervised approach proposed by, which leverages human-labelled data to train an SVM binary classifier.", "labels": [], "entities": [{"text": "Barbu15", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.9181351661682129}, {"text": "SVM binary classifier", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.7566431562105814}]}, {"text": "To the best of our knowledge, it represents the state-of-the-art in this task.", "labels": [], "entities": []}], "tableCaptions": []}