{"title": [{"text": "Unsupervised morph segmentation and statistical language models for vocabulary expansion", "labels": [], "entities": [{"text": "Unsupervised morph segmentation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6247801582018534}]}], "abstractContent": [{"text": "This work explores the use of unsu-pervised morph segmentation along with statistical language models for the task of vocabulary expansion.", "labels": [], "entities": [{"text": "vocabulary expansion", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.7486487627029419}]}, {"text": "Unsupervised vocabulary expansion has large potential for improving vocabulary coverage and performance in different natural language processing tasks, especially in less-resourced settings on morphologically rich languages.", "labels": [], "entities": [{"text": "vocabulary expansion", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7539067566394806}]}, {"text": "We propose a combination of unsupervised morph segmentation and statistical language models and evaluate on languages from the Babel corpus.", "labels": [], "entities": [{"text": "Babel corpus", "start_pos": 127, "end_pos": 139, "type": "DATASET", "confidence": 0.84879469871521}]}, {"text": "The method is shown to perform well for all the evaluated languages when compared to the previous work on the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language modelling for different natural language processing tasks like speech recognition, machine translation or optical character recognition require large training corpora to achieve good language model estimates and high enough vocabulary coverage.", "labels": [], "entities": [{"text": "Language modelling", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.710042804479599}, {"text": "speech recognition", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.7469075918197632}, {"text": "machine translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8039658069610596}, {"text": "optical character recognition", "start_pos": 115, "end_pos": 144, "type": "TASK", "confidence": 0.6214581529299418}]}, {"text": "Sometimes such resources are not readily available or easily acquirable.", "labels": [], "entities": []}, {"text": "This is especially the case for the many less-resourced languages.", "labels": [], "entities": []}, {"text": "In the case of morphologically rich languages, these issues are emphasized, as words appear in many forms, thus increasing the required vocabulary size and the data sparsity.", "labels": [], "entities": []}, {"text": "Automatic speech recognition of spontaneous speech is a task with some special characteristics, as speech transcriptions are expensive to acquire.", "labels": [], "entities": [{"text": "Automatic speech recognition of spontaneous speech", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7488816032807032}]}, {"text": "Taking all these factors into account, the importance of making the most out of the available resources becomes evident.", "labels": [], "entities": []}, {"text": "This work was done while the author was visiting the Saarland University Spoken Language Systems group Previous work on handling out-of-vocabulary (OOV) words in automatic speech recognition have included explicit OOV word modelling and confidence measures) and hybrid word-subword language modelling for OOV word detection (.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 162, "end_pos": 190, "type": "TASK", "confidence": 0.6955776413281759}, {"text": "OOV word modelling", "start_pos": 214, "end_pos": 232, "type": "TASK", "confidence": 0.619238922993342}, {"text": "OOV word detection", "start_pos": 305, "end_pos": 323, "type": "TASK", "confidence": 0.7206830978393555}]}, {"text": "Speech recognition by directly using optimized subword units has also) proven a good approach for speech recognition of a morphologically rich language.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.849702388048172}, {"text": "speech recognition", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7901137173175812}]}, {"text": "In this work, we study unsupervised vocabulary expansion for conversational speech recognition of morphologically rich languages in a lessresourced setting.", "labels": [], "entities": [{"text": "vocabulary expansion", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7616860866546631}, {"text": "conversational speech recognition", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.6731962561607361}]}, {"text": "We expand the recognition vocabulary, and thus lower the OOV rate, by generating new word forms.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.989275187253952}]}, {"text": "Two recent works also target the unsupervised vocabulary expansion.", "labels": [], "entities": [{"text": "vocabulary expansion", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.6810413300991058}]}, {"text": "In (), an unsupervised morphological segmentation was inferred from the training corpus using the Morfessor Categories-MAP ( method.", "labels": [], "entities": []}, {"text": "The prefix-stem-suffix structure estimated by the model was then represented as a finite-statetransducer for sampling new word forms.", "labels": [], "entities": []}, {"text": "Different reranking schemes using a bigram language model and a letter trigraph language model were evaluated.", "labels": [], "entities": []}, {"text": "The Kaldi speech recognition package) includes an approach () for vocabulary expansion.", "labels": [], "entities": [{"text": "Kaldi speech recognition", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.5594241420427958}, {"text": "vocabulary expansion", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.7651932239532471}]}, {"text": "In this approach, the provided syllable segmented pronunciation lexicon is used as the basis for the expansion.", "labels": [], "entities": []}, {"text": "An n-gram model is trained over the syllable segmentation and syllabic words are generated from the model.", "labels": [], "entities": [{"text": "syllable segmentation", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.7771618664264679}]}, {"text": "Finally a phoneme-to-grapheme mapping is performed to obtain the grapheme form for the words.", "labels": [], "entities": []}, {"text": "In our approach, statistical language models are trained over a morph segmentation, which is learned unsupervisedly from the data.", "labels": [], "entities": []}, {"text": "Words are sampled from the language models and ordered according to the probabilities given by the language models.", "labels": [], "entities": []}, {"text": "We evaluate the method on seven morphologically rich languages from the Babel corpus and compare to the previously suggested approaches.", "labels": [], "entities": [{"text": "Babel corpus", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.8987032771110535}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of the datasets used in the experiments. The scripted training corpus is included.", "labels": [], "entities": []}, {"text": " Table 2: Type-based OOV reduction rates for the  50k best words", "labels": [], "entities": [{"text": "Type-based OOV reduction", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.826075553894043}]}, {"text": " Table 3: Token-based OOV reduction rates for the  50k best words", "labels": [], "entities": [{"text": "OOV reduction", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.7553836703300476}]}, {"text": " Table 4: Type-based OOV rate comparison to  Kaldi", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.7557002007961273}, {"text": "Kaldi", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.5973465442657471}]}, {"text": " Table 5: Token-based OOV rate comparison to  Kaldi", "labels": [], "entities": [{"text": "Kaldi", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.6086466908454895}]}]}