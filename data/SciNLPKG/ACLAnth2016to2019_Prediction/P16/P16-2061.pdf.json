{"title": [{"text": "IBC-C: A Dataset for Armed Conflict Event Analysis", "labels": [], "entities": [{"text": "Armed Conflict Event Analysis", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.598008044064045}]}], "abstractContent": [{"text": "We describe the Iraq Body Count Corpus (IBC-C) dataset, the first substantial armed conflict-related dataset which can be used for conflict analysis.", "labels": [], "entities": [{"text": "Iraq Body Count Corpus (IBC-C) dataset", "start_pos": 16, "end_pos": 54, "type": "DATASET", "confidence": 0.8750231266021729}, {"text": "conflict analysis", "start_pos": 131, "end_pos": 148, "type": "TASK", "confidence": 0.7823761999607086}]}, {"text": "IBC-C provides a ground-truth dataset for conflict specific named entity recognition, slot filling, and event de-duplication.", "labels": [], "entities": [{"text": "IBC-C", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8528296947479248}, {"text": "conflict specific named entity recognition", "start_pos": 42, "end_pos": 84, "type": "TASK", "confidence": 0.5781758010387421}, {"text": "slot filling", "start_pos": 86, "end_pos": 98, "type": "TASK", "confidence": 0.8162069022655487}]}, {"text": "IBC-C is constructed using data collected by the Iraq Body Count project which has been recording incidents from the ongoing war in Iraq since 2003.", "labels": [], "entities": [{"text": "IBC-C", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7718545198440552}, {"text": "Iraq Body Count project", "start_pos": 49, "end_pos": 72, "type": "DATASET", "confidence": 0.9422230869531631}]}, {"text": "We describe the dataset's creation, how it can be used for the above three tasks and provide initial baseline results for the first task (named entity recognition) using Hidden Markov Models, Conditional Random Fields, and Recursive Neural Networks.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7777409553527832}]}], "introductionContent": [{"text": "Many reports about armed conflict related incidents are published everyday.", "labels": [], "entities": []}, {"text": "However, these reports on the deaths and injuries of civilians and combatants often get forgotten or go unnoticed for long periods of time.", "labels": [], "entities": []}, {"text": "Automatically extracting casualty counts from such reports would help better track ongoing conflicts and understand past ones.", "labels": [], "entities": []}, {"text": "One popular approach of discovering incidents is to identify them from textual reports and extract casualty, and other, information from them.", "labels": [], "entities": []}, {"text": "This can either be done by hand or automatically.", "labels": [], "entities": []}, {"text": "The Iraq Body Count (IBC) project has been directly recording casualties since 2003 for the ongoing conflict in Iraq).", "labels": [], "entities": [{"text": "Iraq Body Count (IBC)", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.7522391776243845}]}, {"text": "IBC staff collect reports, link them to unique incidents, extract casualty information, and save the information on a per incident basis as can be seen in.", "labels": [], "entities": [{"text": "IBC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7610604166984558}]}, {"text": "Direct recording by hand is a slow process and notable efforts to do so have tended to lag behind the present.", "labels": [], "entities": [{"text": "Direct recording", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8379873633384705}]}, {"text": "Information extraction systems capable of automating this process must explicitly or implicitly successfully solve three tasks: (1) find and extract casualty information in reports (2) detect events mentioned in reports (3) deduplicate detected events into unique events which we call incidents.", "labels": [], "entities": [{"text": "Information extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7506043314933777}]}, {"text": "The three tasks correspond to named entity recognition, slot filling, and In this work we introduce the report based IBC-C dataset.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.5947737793127695}, {"text": "slot filling", "start_pos": 56, "end_pos": 68, "type": "TASK", "confidence": 0.9100847840309143}, {"text": "IBC-C dataset", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.8529459834098816}]}, {"text": "Each report can contain one or more sections; each section, one or more sentences; each sentence, one or more words.", "labels": [], "entities": []}, {"text": "Each word is tagged with one of nine entity tags in the insideoutside-beginning (IOB) style.", "labels": [], "entities": []}, {"text": "A visual representation of the dataset can be seen in and its statistics in.", "labels": [], "entities": []}, {"text": "To the best of our knowledge apart from the significantly smaller MUC-3 and MUC-4 datasets (which aren't casualty-specific) there are no other publicly available datasets made specifically for tasks (1), (2) or (3).", "labels": [], "entities": [{"text": "MUC-3", "start_pos": 66, "end_pos": 71, "type": "DATASET", "confidence": 0.9127094149589539}, {"text": "MUC-4 datasets", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.9014648199081421}]}, {"text": "The IBC-C dataset can be used to train supervised models for all three tasks.", "labels": [], "entities": [{"text": "IBC-C dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9429373741149902}]}, {"text": "We provide baseline results for task (1) which we posit as a sequence-classification problem and solve using an HMM, a CRF, and an RNN.", "labels": [], "entities": []}, {"text": "Since the 1990s the conflict analysis and NLP/IE communities have diverged.", "labels": [], "entities": [{"text": "conflict analysis", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8235207200050354}]}, {"text": "With the IBC-C dataset we hope to bring the two communities closer again.", "labels": [], "entities": [{"text": "IBC-C dataset", "start_pos": 9, "end_pos": 22, "type": "DATASET", "confidence": 0.9686964154243469}]}], "datasetContent": [{"text": "Baseline results were computed for the named entity recognition task using an 80:20 tag split across sentences (we ignore report or section boundaries).", "labels": [], "entities": [{"text": "named entity recognition task", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.6910556256771088}]}, {"text": "We compare three different sequenceclassification models as seen in: a Hidden Markov Model (), a Conditional Random Field, and a Elman-style Recursive Neural Network similar to the one used in.", "labels": [], "entities": []}, {"text": "For the HMM we use bigram features in combination with the current word and the current base named entity features 2 . We trained the HMM in CRF form using LBFGS.", "labels": [], "entities": [{"text": "LBFGS", "start_pos": 156, "end_pos": 161, "type": "DATASET", "confidence": 0.8554710745811462}]}, {"text": "For the CRF we find that using bigram features and a 13-word window, across words and base named entities, gives us the best result.", "labels": [], "entities": []}, {"text": "We train the CRF using LBFGS.", "labels": [], "entities": [{"text": "LBFGS", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.7964158058166504}]}, {"text": "All CRF training, including the HMM, was done using CRFSuite.", "labels": [], "entities": [{"text": "HMM", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.6311542987823486}, {"text": "CRFSuite", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.9085428714752197}]}, {"text": "For the Elman-style recurrent network we use randomly initialised 100 dimensional word vectors as input, the network has 100 hidden units, and we use a 13-word context window again.", "labels": [], "entities": []}, {"text": "The RNN was implemented using Theano ().", "labels": [], "entities": [{"text": "RNN", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.603180468082428}, {"text": "Theano", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.9438743591308594}]}, {"text": "We train the RNN using stochastic gradient descent on a single GPU.", "labels": [], "entities": [{"text": "RNN", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.9221224784851074}]}, {"text": "The first thing which strikes us is how low the ISUB scores are.", "labels": [], "entities": [{"text": "ISUB scores", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.638845756649971}]}, {"text": "The CRF returns a recall score of 0.24.", "labels": [], "entities": [{"text": "CRF", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.5038392543792725}, {"text": "recall score", "start_pos": 18, "end_pos": 30, "type": "METRIC", "confidence": 0.9849576950073242}]}, {"text": "At the same time, the precision is relatively high at 0.89.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9997606873512268}]}, {"text": "Low recall indicates a lot of false negative classifications -i.e. there were many injured people who were mistakingly tagged as uninjured.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9995923638343811}]}, {"text": "A high precision rate means a low false Base named entities such as PERSON and LOCATION were found using Stanford's named entity recogniser ( positive rate -i.e. most uninjured people were correctly tagged as uninjured.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 7, "end_pos": 21, "type": "METRIC", "confidence": 0.980402410030365}, {"text": "false Base", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.8246655166149139}, {"text": "PERSON", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.8440616726875305}, {"text": "LOCATION", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.877788245677948}]}, {"text": "In short, the classifier was too generous with tagging people as having been injured.", "labels": [], "entities": []}, {"text": "Looking at the dataset we realise that in contrast to KSUBS, words which we associate with injury such as \"wounded\" or \"injured\" are often very faraway from an ISUB.", "labels": [], "entities": [{"text": "KSUBS", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.8462233543395996}]}, {"text": "Increasing the window size with the CRF didn't help (such large features are often never expressed during the test phase).", "labels": [], "entities": []}, {"text": "Low recall scores across multiple tags indicate that long-distance dependencies determine a word's classification.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9988172650337219}]}, {"text": "K/INUM recall is exceptionally high because K/INUMs are usually surrounded by words such as \"killed\".", "labels": [], "entities": [{"text": "INUM", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.6097145080566406}, {"text": "recall", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.8230569362640381}]}, {"text": "We were surprised to seethe RNN perform relatively poorly and expected it to be able to factor in long-distance dependencies.", "labels": [], "entities": []}, {"text": "We believe this has more to do with our hyper-parameter settings than deficiencies in the actual model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: An example of an incident hand coded  by IBC staff. Min and max values represent the  minimum and maximum figures quoted in report  sections linked to the incident.", "labels": [], "entities": [{"text": "IBC", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.9105338454246521}, {"text": "Min", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9551282525062561}, {"text": "max", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.6030632853507996}]}, {"text": " Table 4: Results for various models", "labels": [], "entities": []}]}