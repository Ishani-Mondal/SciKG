{"title": [{"text": "Investigating LSTMs for Joint Extraction of Opinion Entities and Relations", "labels": [], "entities": [{"text": "Joint Extraction of Opinion Entities and Relations", "start_pos": 24, "end_pos": 74, "type": "TASK", "confidence": 0.8248549997806549}]}], "abstractContent": [{"text": "We investigate the use of deep bi-directional LSTMs for joint extraction of opinion entities and the IS-FROM and IS-ABOUT relations that connect them-the first such attempt using a deep learning approach.", "labels": [], "entities": []}, {"text": "Perhaps surprisingly, we find that standard LSTMs are not competitive with a state-of-the-art CRF+ILP joint inference approach (Yang and Cardie, 2013) to opinion entities extraction, performing below even the standalone sequence-tagging CRF.", "labels": [], "entities": [{"text": "opinion entities extraction", "start_pos": 154, "end_pos": 181, "type": "TASK", "confidence": 0.6733462611834208}]}, {"text": "Incorporating sentence-level and a novel relation-level optimization, however, allows the LSTM to identify opinion relations and to perform within 1-3% of the state-of-the-art joint model for opinion entities and the IS-FROM relation; and to perform as well as the state-of-the-art for the IS-ABOUT relation-all without access to opinion lexicons, parsers and other preprocessing components required for the feature-rich CRF+ILP approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has been much research in recent years in the area of fine-grained opinion analysis where the goal is to identify subjective expressions in text along with their associated sources and targets.", "labels": [], "entities": [{"text": "fine-grained opinion analysis", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.6417210300763448}]}, {"text": "More specifically, fine-grained opinion analysis aims to identify three types of opinion entities: \u2022 opinion expressions, O, which are direct subjective expressions (i.e., explicit mentions of otherwise private states or speech events expressing private states); \u2022 opinion targets, T , which are the entities or topics that the opinion is about; and \u2022 opinion holders, H, which are the entities expressing the opinion.", "labels": [], "entities": [{"text": "fine-grained opinion analysis", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.7184080481529236}]}, {"text": "In addition, the task involves identifying the IS-FROM and IS-ABOUT relations between an opinion expression and its holder and target, respectively.", "labels": [], "entities": []}, {"text": "In the sample sentences, numerical subscripts indicate an IS-FROM or IS-ABOUT relation.", "labels": [], "entities": []}, {"text": "S1 In S1, for example, \"infuriated\" indicates that there is an (negative) opinion from \"Beijing\" regarding \"the sale.\"", "labels": [], "entities": []}, {"text": "1 Traditionally, the task of extracting opinion entities and opinion relations was handled in a pipelined manner, i.e., extracting the opinion expressions first and then extracting opinion targets and opinion holders based on their syntactic and semantic associations with the opinion expressions (.", "labels": [], "entities": []}, {"text": "More recently, methods that jointly infer the opinion entity and relation extraction tasks (e.g., using Integer Linear Programming (ILP)) have been introduced ( and show that the existence of opinion relations provides clues for the identification of opinion entities and vice-versa, and thus results in better performance than a pipelined approach.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7171773910522461}]}, {"text": "However, the success of these methods depends critically on the availability of opinion lexicons, dependency parsers, named-entity taggers, etc.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.714354082942009}]}, {"text": "Alternatively, neural network-based methods have been employed.", "labels": [], "entities": []}, {"text": "In these approaches, the required latent features are automatically learned as dense vectors of the hidden layers., for example, compare several variations of recurrent neural network methods and find that long short-term memory networks (LSTMs) perform the best in identifying opinion expressions and opinion targets for the specific case of product/service reviews.", "labels": [], "entities": []}, {"text": "Motivated by the recent success of LSTMs on this and other problems in NLP, we investigate here the use of deep bi-directional LSTMs for joint extraction of opinion expressions, holders, targets and the relations that connect them.", "labels": [], "entities": []}, {"text": "This is the first attempt to handle the full opinion entity and relation extraction task using a deep learning approach.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.8095841805140177}]}, {"text": "In experiments on the MPQA dataset for opinion entities, we find that standard LSTMs are not competitive with the state-of-the-art CRF+ILP joint inference approach of, performing below even the standalone sequencetagging CRF.", "labels": [], "entities": [{"text": "MPQA dataset", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.9291270077228546}]}, {"text": "Inspired by, we show that incorporating sentence-level, and our newly proposed relation-level optimization, allows the LSTM to perform within 1-3% of the ILP joint model for all three opinion entity types and to do so without access to opinion lexicons, parsers or other preprocessing components.", "labels": [], "entities": []}, {"text": "For the primary task of identifying opinion entities together with their IS-FROM and IS-ABOUT relations, we show that the LSTM with sentenceand relation-level optimizations outperforms an LSTM baseline that does not employ joint inference.", "labels": [], "entities": []}, {"text": "When compared to the CRF+ILP-based joint inference approach, the optimized LSTM performs slightly better for the IS-ABOUT 2 relation and within 3% for the IS-FROM relation.", "labels": [], "entities": []}, {"text": "In the sections that follow, we describe: related work (Section 2) and the multi-layer bi-directional LSTM (Section 3); the LSTM extensions (Section 4); the experiments on the MPQA corpus (Sections 5 and 6) and error analysis (Section 7).", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 176, "end_pos": 187, "type": "DATASET", "confidence": 0.9381489455699921}, {"text": "error analysis", "start_pos": 211, "end_pos": 225, "type": "TASK", "confidence": 0.7978840172290802}]}], "datasetContent": [{"text": "We use precision, recall and F-measure (as in) as evaluation metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9994970560073853}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9991652965545654}, {"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9972397089004517}]}, {"text": "Since the identification of exact boundaries for opinion entities is hard even for humans), soft evaluation methods such as Binary Overlap and Proportional Overlap are reported.", "labels": [], "entities": [{"text": "identification of exact boundaries for opinion entities", "start_pos": 10, "end_pos": 65, "type": "TASK", "confidence": 0.8096138834953308}]}, {"text": "Binary Overlap counts every overlapping predicted and gold entity as correct, while Proportional Overlap assigns a partial score proportional to the ratio of overlap span and the correct span (Recall) or the ratio of overlap span and the predicted span (Precision).", "labels": [], "entities": [{"text": "Recall)", "start_pos": 193, "end_pos": 200, "type": "METRIC", "confidence": 0.8587027490139008}]}, {"text": "For the case of opinion relations, we report precision, recall and F-measure according to the Binary Overlap.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9997134804725647}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9996719360351562}, {"text": "F-measure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.999434769153595}]}, {"text": "It considers a relation correct if there is an overlap between the predicted opin- ion expression and the gold opinion expression as well as an overlap between the predicted entity (holder/target) and the gold entity (holder/target).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on opinion entity extraction. Top table shows Binary Overlap performance; bottom  table shows Proportional Overlap performance. Superscripts designate one standard deviation.", "labels": [], "entities": [{"text": "opinion entity extraction", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.6809508403142294}, {"text": "Proportional Overlap performance", "start_pos": 116, "end_pos": 148, "type": "METRIC", "confidence": 0.8936758041381836}]}, {"text": " Table 2: Performance on opinion relation extraction using Binary Overlap on the opinion entities. Su- perscripts designate one standard deviation.", "labels": [], "entities": [{"text": "opinion relation extraction", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.7616411050160726}]}]}