{"title": [{"text": "Putting Sarcasm Detection into Context: The Effects of Class Imbalance and Manual Labelling on Supervised Machine Classification of Twitter Conversations", "labels": [], "entities": [{"text": "Sarcasm Detection into Context", "start_pos": 8, "end_pos": 38, "type": "TASK", "confidence": 0.8764966875314713}, {"text": "Supervised Machine Classification of Twitter Conversations", "start_pos": 95, "end_pos": 153, "type": "TASK", "confidence": 0.7747360467910767}]}], "abstractContent": [{"text": "Sarcasm can radically alter or invert a phrase's meaning.", "labels": [], "entities": []}, {"text": "Sarcasm detection can therefore help improve natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "Sarcasm detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9512868523597717}]}, {"text": "The majority of prior research has modeled sarcasm detection as classification, with two important limitations: 1.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9884369373321533}]}, {"text": "Balanced datasets, when sarcasm is actually rather rare.", "labels": [], "entities": []}, {"text": "2. Using Twitter users' self-declarations in the form of hashtags to label data, when sarcasm can take many forms.", "labels": [], "entities": []}, {"text": "To address these issues, we create an unbalanced corpus of manually annotated Twitter conversations.", "labels": [], "entities": []}, {"text": "We compare human and machine ability to recognize sarcasm on this data under varying amounts of context.", "labels": [], "entities": []}, {"text": "Our results indicate that both class imbalance and labelling method affect performance, and should both be considered when designing automatic sarcasm detection systems.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.8036295473575592}]}, {"text": "We conclude that for progress to be made in real-world sarcasm detection, we will require anew class labelling scheme that is able to access the 'common ground' held between conversational parties.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.8852628469467163}]}], "introductionContent": [{"text": "Sarcasm, or verbal irony, is prevalent both in spoken and written communication, and can radically alter or invert a phrase's meaning.", "labels": [], "entities": []}, {"text": "Automatic sarcasm detection can therefore help improve natural language processing (NLP) tasks, such as sentiment analysis, where failure to take ironic intent into account has been recognised as a major cause of errors.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.81964972615242}, {"text": "sentiment analysis", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.9747956991195679}]}, {"text": "However, automatic sarcasm detection is a nontrivial problem, and research into this subject is in its infancy.", "labels": [], "entities": [{"text": "automatic sarcasm detection", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.6901853481928507}]}, {"text": "The majority of prior research has treated sarcasm detection as a classification task, with two important limitations: 1.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9883299171924591}]}, {"text": "It focuses on balanced datasets, when sarcasm is actually rather rare.", "labels": [], "entities": []}, {"text": "2. In order to obtain labelled data for supervised learning, many studies relied on Twitter users' supposed self-declarations of sarcasm in the form of hashtags such as #sarcasm, but sarcasm can take many forms.", "labels": [], "entities": []}, {"text": "Although reporting impressive results for sarcasm detection, even state-of-the-art systems fail to address the above issues.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.9688990414142609}]}, {"text": "Research suggesting that verbal irony occurs in less than a fifth of conversations () implies that, rather than using balanced datasets, a more realistic approach maybe to view sarcasm recognition as a problem of anomaly detection, in which positive examples are scarce.", "labels": [], "entities": [{"text": "sarcasm recognition", "start_pos": 177, "end_pos": 196, "type": "TASK", "confidence": 0.7861502468585968}, {"text": "anomaly detection", "start_pos": 213, "end_pos": 230, "type": "TASK", "confidence": 0.794654905796051}]}, {"text": "While convenient, obtaining labelled data from hashtags has been found to introduce both noise, in the form of incorrectly labelled examples, and bias to the datasets usedanalysis suggests that only certain forms of sarcasm are likely to be tagged in this way ( , and predominantly by certain types of Twitter users.", "labels": [], "entities": []}, {"text": "To address these issues, we create a novel corpus of manually annotated Twitter conversations and, using the feature classes of, perform sarcasm classification experiments on both balanced and unbalanced datasets.", "labels": [], "entities": [{"text": "sarcasm classification", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.8453099429607391}]}, {"text": "We also compare model performance to a dataset of conversations automatically retrieved using hashtags.", "labels": [], "entities": []}, {"text": "Our contributions In this paper, we present a novel corpus of manually annotated two-part Twitter conversations for use in supervised classification of sarcastic and non-sarcastic text.", "labels": [], "entities": [{"text": "supervised classification of sarcastic and non-sarcastic text", "start_pos": 123, "end_pos": 184, "type": "TASK", "confidence": 0.6992367846625192}]}, {"text": "We compare human vs. machine learning classification performance under varying amounts of contextual information, and evaluate machine perfor-mance on balanced and unbalanced, and manually labelled and automatically retrieved datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "To compare human to machine performance, we fit binary classification models on both balanced and unbalanced splits of the two datasets.", "labels": [], "entities": []}, {"text": "Experimental setup We evaluate performance using a standard logistic regression model with 2 regularization, evaluated via five-fold crossvalidation.", "labels": [], "entities": []}, {"text": "Normalisation We convert all features to binary or numeric values and normalize them to the range between zero and one.", "labels": [], "entities": [{"text": "Normalisation", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9094541668891907}]}, {"text": "Procedure Following, we evaluate classification performance on the above feature sets in the following combinations: tweet features only, tweet + author features, tweet + audience features, tweet + environment features, and tweet + author + audience + environment.", "labels": [], "entities": []}], "tableCaptions": []}