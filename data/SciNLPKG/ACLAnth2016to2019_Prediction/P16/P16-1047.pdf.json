{"title": [{"text": "Neural Networks For Negation Scope Detection", "labels": [], "entities": [{"text": "Negation Scope Detection", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.7643778522809347}]}], "abstractContent": [{"text": "Automatic negation scope detection is a task that has been tackled using different classifiers and heuristics.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8891400297482809}]}, {"text": "Most systems are however 1) highly-engineered, 2) English-specific, and 3) only tested on the same genre they were trained on.", "labels": [], "entities": []}, {"text": "We start by addressing 1) and 2) using a neural network architecture.", "labels": [], "entities": []}, {"text": "Results obtained on data from the *SEM2012 shared task on negation scope detection show that even a simple feed-forward neural network using word-embedding features alone, performs on par with earlier classifiers, with a bi-directional LSTM outperforming all of them.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.9654225508371989}]}, {"text": "We then address 3) by means of a specially-designed synthetic test set; in doing so, we explore the problem of detecting the negation scope more in depth and show that performance suffers from genre effects and differs with the type of negation considered.", "labels": [], "entities": []}], "introductionContent": [{"text": "Amongst different extra-propositional aspects of meaning, negation is one that has received a lot of attention in the NLP community.", "labels": [], "entities": [{"text": "negation", "start_pos": 58, "end_pos": 66, "type": "TASK", "confidence": 0.9691568613052368}]}, {"text": "Previous work have focused in particular on automatically detecting the scope of negation, that is, given a negative instance, to identify which tokens are affected by negation ( \u00a72).", "labels": [], "entities": []}, {"text": "As shown in (1), only the first clause is negated and therefore we mark he and the car, along with the predicate was driving as inside the scope, while leaving the other tokens outside.", "labels": [], "entities": []}, {"text": "(1) He was not driving the car and she left to go home.", "labels": [], "entities": []}, {"text": "In the BioMedical domain there is along line of research around the topic (e.g.  and), given the importance of recognizing negation for information extraction from medical records.", "labels": [], "entities": [{"text": "information extraction from medical records", "start_pos": 136, "end_pos": 179, "type": "TASK", "confidence": 0.8449867248535157}]}, {"text": "In more general domains, efforts have been more limited and most of the work centered around the *SEM2012 shared task on automatically detecting negation ( \u00a73), despite the recent interest (e.g. machine translation).", "labels": [], "entities": [{"text": "automatically detecting negation", "start_pos": 121, "end_pos": 153, "type": "TASK", "confidence": 0.5777445435523987}, {"text": "machine translation", "start_pos": 195, "end_pos": 214, "type": "TASK", "confidence": 0.7979215085506439}]}, {"text": "The systems submitted for this shared task, although reaching good overall performance are highly feature-engineered, with some relying on heuristics based on English ( ) or on tools that are available fora limited number of languages (e.g.,), which do not make them easily portable across languages.", "labels": [], "entities": []}, {"text": "Moreover, the performance of these systems was only assessed on data of the same genre (stories from Conan Doyle's Sherlock Holmes) but there was no attempt to test the approach on data of different genre.", "labels": [], "entities": []}, {"text": "Given these shortcomings, we investigate whether neural network based sequence-tosequence models ( \u00a7 4) area valid alternative.", "labels": [], "entities": []}, {"text": "The first advantage of neural networks-based methods for NLP is that we could perform classification by means of unsupervised word-embeddings features only, under the assumption that they also encode structural information previous system had to explicitly represent as features.", "labels": [], "entities": []}, {"text": "If this assumption holds, another advantage of continuous representations is that, by using a bilingual word-embedding space, we would be able to transfer the model cross-lingually, obviating the problem of the lack of annotated data in other languages.", "labels": [], "entities": []}, {"text": "The paper makes the following contributions: 1.", "labels": [], "entities": []}, {"text": "Comparable or better performance: We show that neural networks perform on par with previously developed classifiers, with a bi-directional LSTM outperforming them 495 when tested on data from the same genre.", "labels": [], "entities": []}, {"text": "2. Better understanding of the problem: We analyze in more detail the difficulty of detecting negation scope by testing on data of different genre and find that the performance of wordembedding features is comparable to that of more fine-grained syntactic features.", "labels": [], "entities": [{"text": "detecting negation scope", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.7363851269086202}]}, {"text": "3. Creation of additional resources: We create a synthetic test set of negative sentences extracted from Simple English Wikipedia ( \u00a7 5) and annotated according to the guidelines released during the *SEM2012 shared task), that we hope will guide future work in the field.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 105, "end_pos": 129, "type": "DATASET", "confidence": 0.7811144987742106}, {"text": "SEM2012 shared task", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.4850781460603078}]}], "datasetContent": [{"text": "Training, development and test set area collection of stories from Conan Doyle's Sherlock Holmes annotated for cue and scope of negation and released in concomitance with the *SEM2012 shared task.", "labels": [], "entities": [{"text": "cue", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9554951190948486}]}, {"text": "For each word, the correspondent lemma, POS tag and the constituent subtree it belongs to are also annotated.", "labels": [], "entities": []}, {"text": "If a sentence contains multiple instances of negation, each is annotated separately.", "labels": [], "entities": []}, {"text": "Both training and testing is done on negative sentences only, i.e. those sentences with at least one cue annotated.", "labels": [], "entities": []}, {"text": "Training and test size are of 848 and 235 sentences respectively.", "labels": [], "entities": []}, {"text": "If a sentence contains multiple negation instances, we create as many copies as the number of instances.", "labels": [], "entities": []}, {"text": "If the sentence contains a morphological cue (e.g. impatient) we split it into affix (im-) and root (patient), and consider the former as cue and the latter as part of the scope.", "labels": [], "entities": []}, {"text": "Both neural network architectures are implemented using TensorFlow () with a 200-units hidden layer (400 in total for two concatenated hidden layers in the BiLSTM), the Adam optimizer () with a starting learning rate of 0.0001, learning rate decay after 10 iterations without improvement and early stopping.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 156, "end_pos": 162, "type": "DATASET", "confidence": 0.8410966992378235}, {"text": "learning rate decay", "start_pos": 228, "end_pos": 247, "type": "METRIC", "confidence": 0.8643213907877604}]}, {"text": "In both cases we experimented with different settings: 1.", "labels": [], "entities": []}, {"text": "Simple baseline: In order to understand how hard the task of negation scope detection is, we created a simple baseline by tagging as part of the scope all the tokens 4 words to the left and 6 to the right of the cue; these values were found to be the average span of the scope in either direction in the training data.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.9253385265668234}]}, {"text": "2. Cue info (C): The word-embedding matrix is randomly initialised and updated relying on the training data only.", "labels": [], "entities": []}, {"text": "Information about the cue is fed through another set of embedding vectors, as shown in 4.", "labels": [], "entities": []}, {"text": "This resembles the 'Closed track' of the *SEM2012 shared task since no external resource is used.", "labels": [], "entities": []}, {"text": "3. Cue info + external embeddings (E): This is the same as setting except that the embeddings are pre-trained using external data.", "labels": [], "entities": []}, {"text": "We experimented with both keeping the wordembedding matrix fixed and updating it during training but we found small or no difference between the two settings.", "labels": [], "entities": []}, {"text": "To do this, we train a word-embedding matrix using Word2Vec () on 770 million tokens (for a total of 30 million sentences and 791028 types) from the 'One Billion Words Language Modelling' dataset 6 and the Sherlock Holmes data (5520 sentences) combined.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9333966970443726}, {"text": "One Billion Words Language Modelling' dataset 6", "start_pos": 150, "end_pos": 197, "type": "DATASET", "confidence": 0.6623883657157421}, {"text": "Sherlock Holmes data", "start_pos": 206, "end_pos": 226, "type": "DATASET", "confidence": 0.5674973626931509}]}, {"text": "The dataset was tokenized and morphological cues split into negation affix and root to match the Conan Doyle's data.", "labels": [], "entities": [{"text": "Conan Doyle's data", "start_pos": 97, "end_pos": 115, "type": "DATASET", "confidence": 0.7601220980286598}]}, {"text": "In order to perform this split, we matched each word against an hand-crafted list of words containing affixal negation ; this method have an accuracy of 0.93 on the Conan Doyle test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9987055063247681}, {"text": "Doyle test data", "start_pos": 171, "end_pos": 186, "type": "DATASET", "confidence": 0.8668940862019857}]}], "tableCaptions": [{"text": " Table 1: Summary of previous work on automatic detection of negation scope.", "labels": [], "entities": [{"text": "automatic detection of negation scope", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.7140735983848572}]}, {"text": " Table 3: Results for the scope detection task on the synthetic test set.", "labels": [], "entities": [{"text": "scope detection task", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.9228170116742452}]}]}