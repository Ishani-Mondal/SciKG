{"title": [{"text": "Vector-space topic models for detecting Alzheimer's disease", "labels": [], "entities": [{"text": "detecting Alzheimer's disease", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.8814235478639603}]}], "abstractContent": [{"text": "Semantic deficit is a symptom of language impairment in Alzheimer's disease (AD).", "labels": [], "entities": [{"text": "Alzheimer's disease (AD)", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.6374964465697607}]}, {"text": "We present a generalizable method for automatic generation of information content units (ICUs) fora picture used in a standard clinical task, achieving high recall, 96.8%, of human-supplied ICUs.", "labels": [], "entities": [{"text": "automatic generation of information content units (ICUs)", "start_pos": 38, "end_pos": 94, "type": "TASK", "confidence": 0.7342415054639181}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9993740916252136}]}, {"text": "We use the automatically generated topic model to extract semantic features, and train a random forest classifier to achieve an F-score of 0.74 in binary classification of controls versus people with AD using a set of only 12 features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.9989820122718811}]}, {"text": "This is comparable to results (0.72 F-score) with a set of 85 manual features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9948112964630127}]}, {"text": "Adding semantic information to a set of standard lexicosyntactic and acoustic features improves F-score to 0.80.", "labels": [], "entities": [{"text": "F-score", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9993189573287964}]}, {"text": "While control and dementia subjects discuss the same topics in the same contexts, controls are more informative per second of speech.", "labels": [], "entities": []}], "introductionContent": [{"text": "Alzheimer's disease (AD) is the most common cause of neurodegenerative dementia, and affects more than 24.3 million people worldwide ().", "labels": [], "entities": [{"text": "Alzheimer's disease (AD)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7093552947044373}]}, {"text": "Importantly, early detection enables some therapeutic intervention and diseasemodifying treatment).", "labels": [], "entities": [{"text": "early detection", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.6692416816949844}]}, {"text": "Longitudinal studies of people with autopsyconfirmed AD indicate that linguistic changes are detectable in the prodromal stages of the disease; these include a decline in grammatical complexity, word-finding difficulties, and semantic content deficiencies, such as low idea density (i.e., the ratio of semantic units to the total number of words in a speech sample), and low efficiency (i.e., the rate of semantic units over the duration of the speech sample) ().", "labels": [], "entities": []}, {"text": "In the present study, we investigate methods of automatically assessing the semantic content of speech, and use it to distinguish people with AD from healthy older adults.", "labels": [], "entities": []}, {"text": "A standard clinical task for eliciting spontaneous speech, with high sensitivity to language in early AD, is picture description.", "labels": [], "entities": [{"text": "picture description", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.8327375054359436}]}, {"text": "In it, a participant is asked to provide a free-form verbal description of a visual stimulus (.", "labels": [], "entities": []}, {"text": "The picture is associated with a set of human-supplied information content units (hsICUs) representing components of the image, such as subjects, objects, locations, and actions ().", "labels": [], "entities": []}, {"text": "The semantic content of the elicited speech can then be scored by counting the hsICUs present in the description.", "labels": [], "entities": []}, {"text": "Previous studies found that, even in the earliest stages, descriptions by those with AD are less informative compared to those of healthy older adults, producing fewer information units out of a pre-defined list of units, and having less relevant content and lower efficiency).", "labels": [], "entities": []}, {"text": "Using a pre-defined list of annotated hsICUs is subject to several limitations: (i) it is subjectivedifferent authors use a different number of hsICUs for the same picture (e.g., from 7 to 25 for Cookie Theft in the Boston Diagnostic Aphasia Examination (BDAE)); (ii) it may not be optimal for detecting linguistic impairment -the manually-annotated hsICUs are neither exhaustive of all details present in the picture, nor necessarily reflective of the content units which differ most across groups; (iii) it is not generalizable -hsICUs are specific to a particular picture, and new visual stimuli (e.g., required for longitudinal assessments) need to be annotated manually.", "labels": [], "entities": [{"text": "Cookie Theft in the Boston Diagnostic Aphasia Examination (BDAE))", "start_pos": 196, "end_pos": 261, "type": "TASK", "confidence": 0.6611865352500569}, {"text": "detecting linguistic impairment", "start_pos": 294, "end_pos": 325, "type": "TASK", "confidence": 0.8502548336982727}]}, {"text": "In addition to requiring time and effort, this may result in inconsistencies, since the methodology for identifying hsICUs was never clearly defined in previous work.", "labels": [], "entities": []}, {"text": "Automatic scoring of semantic content in speech to detect cognitive impairment has so far required manual hsICUs.", "labels": [], "entities": []}, {"text": "used unigram recall among hsICUs in the Western Aphasia Battery's Picnic picture ( and obtained a correlation of 0.93 with manual hsICU counts.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9386898279190063}, {"text": "Western Aphasia Battery's Picnic picture", "start_pos": 40, "end_pos": 80, "type": "DATASET", "confidence": 0.9790312846501669}]}, {"text": "counted N -grams (N = 1, 2, 3, 4) extracted from a list of hsICUs for the Cookie Theft picture to assess semantic content in the speech of patients with frontotemporal lobar degeneration.", "labels": [], "entities": [{"text": "Cookie Theft picture", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.7189749280611674}]}, {"text": "counted instances of lexical tokens extracted from a list of hsICUs, using dependency parses of Cookie Theft picture descriptions, and combined them with other lexicosyntactic and acoustic features to obtain classification accuracy of 81.9% in identifying people with AD from controls.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.9909693598747253}, {"text": "identifying people with AD", "start_pos": 244, "end_pos": 270, "type": "TASK", "confidence": 0.7122098803520203}]}, {"text": "While those automated methods for scoring the information content in speech used manual hsICUs, we have found none that attempted to produce ICUs automatically.", "labels": [], "entities": []}, {"text": "In this paper, we present a generalizable method for automatically generating information content units for any given picture (or spontaneous speech task), using reference speech.", "labels": [], "entities": []}, {"text": "Since clinical data can be sparse, we present a method for building word vector representations using a large general corpus, then augment it with local context windows from a smaller clinical corpus.", "labels": [], "entities": []}, {"text": "We evaluate the generated ICUs by computing recall of hsICUs and use the constructed topic models to compare the speech of participants with and without dementia, and compute topic alignment.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9980669617652893}, {"text": "topic alignment", "start_pos": 175, "end_pos": 190, "type": "TASK", "confidence": 0.7921250760555267}]}, {"text": "Second, we automatically score new picture descriptions by learning semantic features extracted from these generated ICU models, using a random forest classifier; we assess performance with recall, precision, and F-score.", "labels": [], "entities": [{"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9995406866073608}, {"text": "precision", "start_pos": 198, "end_pos": 207, "type": "METRIC", "confidence": 0.9989210367202759}, {"text": "F-score", "start_pos": 213, "end_pos": 220, "type": "METRIC", "confidence": 0.9986653327941895}]}, {"text": "Third, we propose a set of clinically-relevant features for identifying AD based on differences in topic, topic context, idea density and idea efficiency.", "labels": [], "entities": [{"text": "identifying AD", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.8697730004787445}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of dataset transcriptions.", "labels": [], "entities": [{"text": "Distribution of dataset transcriptions", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.6437551975250244}]}, {"text": " Table 2: Information units above the double line are human-supplied ICUs (hsICUs) found in previous  work, except those marked with  \u2020 which were annotated by an SLP for this study; those below are ad- ditionally analyzed. Over 1,000 clustering configurations based on word vectors extracted from Control  and Dementia reference transcriptions, \u00b5 is the mean of the scaled distance (Eq. 1) of each hsICU to its  closest cluster centroid, \u03c3 is the standard deviation, and \u03b4 = (\u00b5 dementia \u2212 \u00b5 control ). Statistical signifi- cance of \u03b4 was tested using an independent two-sample, two-tailed t-test; *** = p < .001, ** = p < .01,  * = p < .05, ns = not significant.", "labels": [], "entities": [{"text": "Statistical signifi- cance of \u03b4", "start_pos": 503, "end_pos": 534, "type": "METRIC", "confidence": 0.9265404343605042}]}, {"text": " Table 3: Cluster statistics for control (C*) and dementia (D*) models, with computed cluster alignment.  Cluster words are the 5 most frequently occurring words. f vec is the fraction of all vectors which belong  to the given cluster. \u00b5 cl and \u03c3 cl are the mean and standard deviation of the cluster distortion. f n is the  fraction of nouns among cluster vectors; (1 \u2212 f n ) is the fraction of verbs. TTR is the type-to-token ratio.  a is the ID of the aligned cluster, and \u00b5 a is the mean scaled distance to the aligned cluster centroid.", "labels": [], "entities": [{"text": "TTR", "start_pos": 403, "end_pos": 406, "type": "METRIC", "confidence": 0.9904634356498718}]}, {"text": " Table 4: Binary classification (AD:CT) using a random forest classifier, with 10-fold cross-validation.  All cluster models are trained on vectors with no local context. LS&A are lexicosyntactic and acoustic  features as described by", "labels": [], "entities": [{"text": "Binary classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7189247310161591}]}]}