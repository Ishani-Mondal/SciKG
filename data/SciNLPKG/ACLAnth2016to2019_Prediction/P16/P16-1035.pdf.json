{"title": [{"text": "Query Expansion with Locally-Trained Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Continuous space word embeddings have received a great deal of attention in the natural language processing and machine learning communities for their ability to model term similarity and other relationships.", "labels": [], "entities": []}, {"text": "We study the use of term relatedness in the context of query expansion for ad hoc information retrieval.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.7749516069889069}, {"text": "ad hoc information retrieval", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.6733295246958733}]}, {"text": "We demonstrate that word embeddings such as word2vec and GloVe, when trained globally, under-perform corpus and query specific em-beddings for retrieval tasks.", "labels": [], "entities": []}, {"text": "These results suggest that other tasks benefiting from global embeddings may also benefit from local embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Continuous space embeddings such as word2vec () or GloVe () project terms in a vocabulary to a dense, lower dimensional space.", "labels": [], "entities": []}, {"text": "Recent results in the natural language processing community demonstrate the effectiveness of these methods for analogy and word similarity tasks.", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.7546632985273997}]}, {"text": "In general, these approaches provide global representations of words; each word has a fixed representation, regardless of any discourse context.", "labels": [], "entities": []}, {"text": "While a global representation provides some advantages, language use can vary dramatically by topic.", "labels": [], "entities": []}, {"text": "For example, ambiguous terms can easily be disambiguated given local information in immediately surrounding words.", "labels": [], "entities": []}, {"text": "The window-based training of word2vec style algorithms exploits this distributional property.", "labels": [], "entities": []}, {"text": "A global word embedding, even when trained using local windows, risks capturing only coarse representations of those topics dominant in the corpus.", "labels": [], "entities": []}, {"text": "While a particular embedding maybe appropriate fora specific word within a sentence-length context globally, it maybe entirely inappropriate within a specific topic.", "labels": [], "entities": []}, {"text": "refer to this as the 'one sense per discourse' property (.", "labels": [], "entities": []}, {"text": "Previous work by Yarowsky demonstrates that this property can be successfully combined with information from nearby terms for word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 126, "end_pos": 151, "type": "TASK", "confidence": 0.731196661790212}]}, {"text": "Our work extends this approach to word2vec-style training in the context word similarity.", "labels": [], "entities": [{"text": "context word similarity", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.6647148827711741}]}, {"text": "For many tasks that require topic-specific linguistic analysis, we argue that topic-specific representations should outperform global representations.", "labels": [], "entities": []}, {"text": "Indeed, it is difficult to imagine a natural language processing task that would not benefit from an understanding of the local topical structure.", "labels": [], "entities": [{"text": "natural language processing task", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.7562040835618973}]}, {"text": "Our work focuses on a query expansion, an information retrieval task where we can study different lexical similarity methods with an extrinsic evaluation metric (i.e. retrieval metrics).", "labels": [], "entities": [{"text": "query expansion", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.747082531452179}, {"text": "information retrieval task", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.8012110789616903}]}, {"text": "Recent work has demonstrated that similarity based on global word embeddings can be used to outperform classic pseudo-relevance feedback techniques.", "labels": [], "entities": []}, {"text": "We propose that embeddings be learned on topically-constrained corpora, instead of large topically-unconstrained corpora.", "labels": [], "entities": []}, {"text": "Ina retrieval scenario, this amounts to retraining an embedding on documents related to the topic of the query.", "labels": [], "entities": []}, {"text": "We present local embeddings which capture the nuances of topic-specific language better than global embeddings.", "labels": [], "entities": []}, {"text": "There is substantial evidence that global methods underperform local methods for information re-trieval tasks such as query expansion, latent semantic analysis), cluster-based retrieval, and term clustering.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 118, "end_pos": 133, "type": "TASK", "confidence": 0.71482053399086}, {"text": "latent semantic analysis", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.6396088798840841}, {"text": "term clustering", "start_pos": 191, "end_pos": 206, "type": "TASK", "confidence": 0.7204766869544983}]}, {"text": "We demonstrate that the same holds true when using word embeddings for text retrieval.", "labels": [], "entities": [{"text": "text retrieval", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.754537433385849}]}], "datasetContent": [{"text": "We consider several standard retrieval evaluation metrics, including NDCG@10 and interpolated precision at standard recall points).", "labels": [], "entities": [{"text": "NDCG@10", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.9342462420463562}, {"text": "interpolated precision", "start_pos": 81, "end_pos": 103, "type": "METRIC", "confidence": 0.7038872539997101}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.7978618144989014}]}, {"text": "NDCG@10 provides insight into performance specifically at higher ranks.", "labels": [], "entities": [{"text": "NDCG@10", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8964919447898865}]}, {"text": "An interpolated precision recall graph describes system performance throughout the entire ranked list.", "labels": [], "entities": [{"text": "precision recall graph", "start_pos": 16, "end_pos": 38, "type": "METRIC", "confidence": 0.7910143136978149}]}], "tableCaptions": [{"text": " Table 1: Corpora used for retrieval and local  embedding training.", "labels": [], "entities": []}, {"text": " Table 2: Retrieval results comparing query expansion based on various global and local embed- dings. Bolded numbers indicate the best expansion in that class of embeddings. Wilcoxon signed  rank test between bolded numbers indicates statistically significant improvements (p < 0.05) for  all collections.", "labels": [], "entities": [{"text": "Retrieval", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9462243318557739}]}, {"text": " Table 3: Kendall's \u03c4 and Spearman's \u03c1 be- tween improvement in NDCG@10 and lo- cal KL divergence with the corpus language  model. The improvement is measured for the  best local embedding over the best global em- bedding.", "labels": [], "entities": []}]}