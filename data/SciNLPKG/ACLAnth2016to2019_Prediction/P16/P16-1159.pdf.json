{"title": [{"text": "Minimum Risk Training for Neural Machine Translation", "labels": [], "entities": [{"text": "Minimum Risk", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.698828786611557}, {"text": "Neural Machine Translation", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.8379140098889669}]}], "abstractContent": [{"text": "We propose minimum risk training for end-to-end neural machine translation.", "labels": [], "entities": [{"text": "end-to-end neural machine translation", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.651263527572155}]}, {"text": "Unlike conventional maximum likelihood estimation, minimum risk training is capable of optimizing model parameters directly with respect to arbitrary evaluation metrics, which are not necessarily differ-entiable.", "labels": [], "entities": [{"text": "maximum likelihood estimation", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.660545547803243}]}, {"text": "Experiments show that our approach achieves significant improvements over maximum likelihood estimation on a state-of-the-art neural machine translation system across various languages pairs.", "labels": [], "entities": []}, {"text": "Transparent to architectures, our approach can be applied to more neural networks and potentially benefit more NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, end-to-end neural machine translation (NMT) has attracted increasing attention from the community.", "labels": [], "entities": [{"text": "end-to-end neural machine translation (NMT)", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.7312135313238416}]}, {"text": "Providing anew paradigm for machine translation, NMT aims at training a single, large neural network that directly transforms a sourcelanguage sentence to a target-language sentence without explicitly modeling latent structures (e.g., word alignment, phrase segmentation, phrase reordering, and SCFG derivation) that are vital in conventional statistical machine translation (SMT) (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7657864689826965}, {"text": "word alignment", "start_pos": 235, "end_pos": 249, "type": "TASK", "confidence": 0.7369187921285629}, {"text": "phrase segmentation", "start_pos": 251, "end_pos": 270, "type": "TASK", "confidence": 0.7206020802259445}, {"text": "phrase reordering", "start_pos": 272, "end_pos": 289, "type": "TASK", "confidence": 0.720929428935051}, {"text": "statistical machine translation (SMT)", "start_pos": 343, "end_pos": 380, "type": "TASK", "confidence": 0.7906079689661661}]}, {"text": "Current NMT models are based on the encoderdecoder framework (, with an encoder to read and encode a source-language sentence into a vector, from which a decoder generates a target-language sentence.", "labels": [], "entities": []}, {"text": "While early efforts encode the input into a * Corresponding author: Yang Liu.", "labels": [], "entities": []}, {"text": "fixed-length vector, advocate the attention mechanism to dynamically generate a context vector fora target word being generated.", "labels": [], "entities": []}, {"text": "Although NMT models have achieved results on par with or better than conventional SMT, they still suffer from a major drawback: the models are optimized to maximize the likelihood of training data instead of evaluation metrics that actually quantify translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9883976578712463}]}, {"text": "indicate two drawbacks of maximum likelihood estimation (MLE) for NMT.", "labels": [], "entities": [{"text": "maximum likelihood estimation (MLE)", "start_pos": 26, "end_pos": 61, "type": "METRIC", "confidence": 0.7855555266141891}]}, {"text": "First, the models are only exposed to the training distribution instead of model predictions.", "labels": [], "entities": []}, {"text": "Second, the loss function is defined at the word level instead of the sentence level.", "labels": [], "entities": []}, {"text": "In this work, we introduce minimum risk training (MRT) for neural machine translation.", "labels": [], "entities": [{"text": "minimum risk training (MRT", "start_pos": 27, "end_pos": 53, "type": "METRIC", "confidence": 0.7876103520393372}, {"text": "neural machine translation", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.6077255109945933}]}, {"text": "The new training objective is to minimize the expected loss (i.e., risk) on the training data.", "labels": [], "entities": []}, {"text": "MRT has the following advantages over MLE: 1.", "labels": [], "entities": [{"text": "MRT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5858165621757507}, {"text": "MLE", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.8805144429206848}]}, {"text": "Direct optimization with respect to evaluation metrics: MRT introduces evaluation metrics as loss functions and aims to minimize expected loss on the training data.", "labels": [], "entities": [{"text": "MRT", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9611471891403198}]}, {"text": "2. Applicable to arbitrary loss functions: our approach allows arbitrary sentence-level loss functions, which are not necessarily differentiable.", "labels": [], "entities": []}, {"text": "3. Transparent to architectures: MRT does not assume the specific architectures of NMT and can be applied to any end-to-end NMT systems.", "labels": [], "entities": [{"text": "MRT", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9698800444602966}]}, {"text": "While MRT has been widely used in conventional SMT) and deep learning based MT (, to the best of our knowledge, this work is the first effort to introduce MRT into end-to-end NMT.", "labels": [], "entities": [{"text": "MRT", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9198924899101257}, {"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.993924081325531}, {"text": "MT", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.8522744178771973}, {"text": "MRT", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9904769659042358}]}, {"text": "Experiments on a variety of language pairs show that MRT leads to significant improvements over MLE on a state-ofthe-art NMT system ().", "labels": [], "entities": [{"text": "MRT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9704918265342712}]}], "datasetContent": [{"text": "We also conducted a subjective evaluation to validate the benefit of replacing MLE with MRT.", "labels": [], "entities": [{"text": "MLE", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.6316297054290771}, {"text": "MRT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.5550824403762817}]}, {"text": "Two human evaluators were asked to compare MLE and MRT translations of 100 source sentences randomly sampled from the test sets without knowing from which system a candidate translation was generated.", "labels": [], "entities": [{"text": "MRT translations of 100 source sentences", "start_pos": 51, "end_pos": 91, "type": "TASK", "confidence": 0.8164756298065186}]}, {"text": "shows the results of subjective evaluation.", "labels": [], "entities": []}, {"text": "The two human evaluators made close judgements: around 54% of MLE translations are worse than MRE, 23% are equal, and 23% are better.", "labels": [], "entities": [{"text": "MLE translations", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.901790201663971}, {"text": "MRE", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.8787811994552612}]}, {"text": "We find that MOSES translates a Chinese string \"yi wei fuze yu pingrang dangju da jiaodao de qian guowuyuan guanyuan\" that requires long-distance reordering in a wrong way, which is a notorious challenge for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 208, "end_pos": 239, "type": "TASK", "confidence": 0.6772672136624655}]}, {"text": "In contrast, RNNSEARCH-MLE seems to overcome this problem in this example thanks to the capability of gated RNNs to capture long-distance dependencies.", "labels": [], "entities": []}, {"text": "However, as MLE uses a loss function defined only at the word level, its translation lacks sentence-level consistency: \"chinese\" occurs twice while \"two senate\" is missing.", "labels": [], "entities": []}, {"text": "By optimizing model parameters directly with respect to sentence-level BLEU, RNNSEARCH-MRT seems to be able to generate translations more consistently at the sentence level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9822491407394409}]}, {"text": "shows the results on English-French translation.", "labels": [], "entities": [{"text": "English-French translation", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.5832266062498093}]}, {"text": "We list existing end-to-end NMT systems that are comparable to our system.", "labels": [], "entities": []}, {"text": "All these systems use the same subset of the WMT 2014 training corpus and adopt MLE as the training criterion.", "labels": [], "entities": [{"text": "WMT 2014 training corpus", "start_pos": 45, "end_pos": 69, "type": "DATASET", "confidence": 0.9046538323163986}, {"text": "MLE", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9855241179466248}]}, {"text": "They differ in network architectures and vocabulary sizes.", "labels": [], "entities": []}, {"text": "Our RNNSEARCH-MLE system achieves a BLEU score comparable to that of.", "labels": [], "entities": [{"text": "RNNSEARCH-MLE", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.8431020975112915}, {"text": "BLEU score", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9799812138080597}]}, {"text": "RNNSEARCH-MRT achieves the highest BLEU score in this setting even with a vocabulary size smaller than and.", "labels": [], "entities": [{"text": "RNNSEARCH-MRT", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.4285240173339844}, {"text": "BLEU score", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9856099784374237}]}, {"text": "Note that our approach does not assume specific architectures and can in principle be applied to any NMT systems.", "labels": [], "entities": []}, {"text": "shows the results on English-German translation.", "labels": [], "entities": [{"text": "English-German translation", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.5210243165493011}]}, {"text": "Our approach still significantly out-Source meiguo daibiao tuan baokuo laizi shidanfu daxue de yi wei zhongguo zhuanjia , liang ming canyuan waijiao zhengce zhuli yiji yi wei fuze yu pingrang dangju da jiaodao de qian guowuyuan guanyuan . Reference the us delegation consists of a chinese expert from the stanford university , two senate foreign affairs policy assistants and a former state department official who was in charge of dealing with pyongyang authority . MOSES the united states to members of the delegation include representatives from the stanford university , a chinese expert , two assistant senate foreign policy and a responsible for dealing with pyongyang before the officials of the state council . RNNSEARCH-MLE the us delegation comprises a chinese expert from stanford university , a chinese foreign office assistant policy assistant and a former official who is responsible for dealing with the pyongyang authorities . RNNSEARCH-MRT the us delegation included a chinese expert from the stanford university , two senate foreign policy assistants , and a former state department official who had dealings with the pyongyang authorities .: Example Chinese-English translations.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 467, "end_pos": 472, "type": "METRIC", "confidence": 0.9160858392715454}, {"text": "RNNSEARCH-MRT", "start_pos": 943, "end_pos": 956, "type": "DATASET", "confidence": 0.9256898760795593}]}, {"text": "\"Source\" is a romanized Chinese sentence, \"Reference\" is a gold-standard translation.", "labels": [], "entities": []}, {"text": "\"MOSES\" and \"RNNSEARCH-MLE\" are baseline SMT and NMT systems.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 1, "end_pos": 6, "type": "METRIC", "confidence": 0.6066939234733582}, {"text": "RNNSEARCH-MLE", "start_pos": 13, "end_pos": 26, "type": "METRIC", "confidence": 0.8389695286750793}, {"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9693976640701294}]}, {"text": "\"RNNSEARCH-MRT\" is our system.", "labels": [], "entities": [{"text": "RNNSEARCH-MRT", "start_pos": 1, "end_pos": 14, "type": "METRIC", "confidence": 0.7871464490890503}]}, {"text": "We believe that our work can be applied to their architecture easily.", "labels": [], "entities": []}, {"text": "Despite these significant improvements, the margins on English-German and English-French datasets are much smaller than Chinese-English.", "labels": [], "entities": [{"text": "English-French datasets", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.7113133817911148}]}, {"text": "We conjecture that there are two possible reasons.", "labels": [], "entities": []}, {"text": "First, the Chinese-English datasets contain four reference translations for each sentence while both English-French and English-German datasets only have single references.", "labels": [], "entities": []}, {"text": "Second, Chinese and English are more distantly related than English, French and German and thus benefit more from MRT that incorporates evaluation metrics into optimization to capture structural divergence.", "labels": [], "entities": [{"text": "MRT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.98188316822052}]}], "tableCaptions": [{"text": " Table 2: Effect of loss function on the Chinese- English validation set.", "labels": [], "entities": [{"text": "Chinese- English validation set", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.6537489116191864}]}, {"text": " Table 3: Case-insensitive BLEU scores on Chinese-English translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9379091858863831}]}, {"text": " Table 4: Case-insensitive TER scores on Chinese-English translation.", "labels": [], "entities": [{"text": "TER", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.8523480892181396}]}, {"text": " Table 7: Comparison with previous work on English-French translation. The BLEU scores are case- sensitive. \"PosUnk\" denotes Luong et al. (2015b)'s technique of handling rare words.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.998593270778656}]}, {"text": " Table 8: Comparison with previous work on English-German translation. The BLEU scores are case- sensitive.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9974775910377502}]}]}