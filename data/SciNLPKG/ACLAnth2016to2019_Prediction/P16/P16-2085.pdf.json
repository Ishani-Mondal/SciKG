{"title": [], "abstractContent": [{"text": "Computational Argumentation has two main goals-the detection and analysis of arguments on the one hand, and the synthesis of arguments on the other.", "labels": [], "entities": [{"text": "Computational Argumentation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8337419927120209}]}, {"text": "Much attention has been given to the former, but considerably less to the latter.", "labels": [], "entities": []}, {"text": "A key component in synthesizing arguments is the synthesis of claims.", "labels": [], "entities": []}, {"text": "One way to do so is by employing argumentation mining to detect claims within an appropriate corpus.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8846445977687836}]}, {"text": "In general, this appears to be a hard problem.", "labels": [], "entities": []}, {"text": "Thus, it is interesting to explore if-for the sake of synthesis-there maybe other ways to generate claims.", "labels": [], "entities": []}, {"text": "Here we explore such a method: we extract the predicate of simple, manually-detected, claims, and attempt to generate novel claims from them.", "labels": [], "entities": []}, {"text": "Surprisingly, this simple method yields fairly good results.", "labels": [], "entities": []}], "introductionContent": [{"text": "When people argue, how do they come up with the arguments they present, and can a machine emulate this?", "labels": [], "entities": []}, {"text": "The motivation for this work comes from this second question, for which the relevant field of study is Computational Argumentation, an emerging field with roots in Computer Science, Mathematics, Philosophy and Rhetorics.", "labels": [], "entities": []}, {"text": "However, while much attention is given in the field to the modeling and analysis of arguments, automatic synthesis of arguments receives considerably less.", "labels": [], "entities": [{"text": "automatic synthesis of arguments", "start_pos": 95, "end_pos": 127, "type": "TASK", "confidence": 0.7722381949424744}]}, {"text": "So, how do people come up with arguments?", "labels": [], "entities": []}, {"text": "One way is to read-up on the topic and present the arguments you find in the literature.", "labels": [], "entities": []}, {"text": "Another -if the topic at hand is within your field of expertise -is to communicate your opinion.", "labels": [], "entities": []}, {"text": "Yet a third way is to \"recycle\" arguments you are familiar with and apply them to new domains.", "labels": [], "entities": []}, {"text": "For example, someone who's concerned about the free speech might use an argument like \"it's a violation of free speech\" when discussing anyone of these topics: whether violent video games should be banned, whether some Internet content should be censored, or whether certain types of advertisement should be restricted.", "labels": [], "entities": []}, {"text": "Argumentation Mining (Mochales) is analogous to the first option: Given a corpus, it aims to detect arguments therein (and the relations among them).", "labels": [], "entities": [{"text": "Argumentation Mining (Mochales)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8576847791671753}]}, {"text": "Thus, it can be used to suggest claims when a relevant corpus is available.", "labels": [], "entities": []}, {"text": "The second option is analogous to Natural Language Generation (NLG;), where applications such as recommender systems synthesize arguments to explain their recommendations, as done for example in) . These approaches yield good results when applied to specific domains.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.7788063883781433}]}, {"text": "In an NLG application, there is commonly a specific knowledge base which the system communicates.", "labels": [], "entities": []}, {"text": "The form and content of arguments are derived and determined by it and are thus limited to the knowledge therein.", "labels": [], "entities": []}, {"text": "Similarly, argument mining works well when an argument-rich and topic-related corpus is available -e.g. () -but in general seems to be hard ().", "labels": [], "entities": [{"text": "argument mining", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.9172912240028381}]}, {"text": "Thus, it is interesting and challenging to synthesize arguments in an open domain.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that directly attempts to address this task.", "labels": [], "entities": []}, {"text": "Modeling of arguments goes back to the ancient Greeks and Aristotle, and more modern work starting perhaps most famously with the Toulmin argument model.", "labels": [], "entities": [{"text": "Modeling of arguments", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8669783473014832}]}, {"text": "A common element in all such models is the claim (or conclusion) being forwarded by the argument.", "labels": [], "entities": []}, {"text": "Thus, a natural first step in synthesizing arguments in a general setting is being able to synthesize claims in such a setting.", "labels": [], "entities": []}, {"text": "We suggest here a simple way for doing so, based on the aforementioned notion of argument \"recycling\".", "labels": [], "entities": []}, {"text": "Specifically, that the predicate of a claim -what it says on the topic at hand -may be applicable to other topics as well.", "labels": [], "entities": []}, {"text": "For example, if we are familiar with the claim \"banning violent video games is a violation of free speech\" in the context of the topic \"banning violent video games\", we could synthesize the claim \"Internet censorship is a violation of free speech\" when presented with the topic \"Internet Censorship\".", "labels": [], "entities": [{"text": "Internet Censorship\"", "start_pos": 279, "end_pos": 299, "type": "TASK", "confidence": 0.7085415720939636}]}, {"text": "The challenge is then to determine whether the synthesized claim is actually coherent and relevant to the new topic, which we do using statistical Machine Learning techniques, as described in Section 2.1.", "labels": [], "entities": []}, {"text": "This two-stages framework -generating text and then selecting whether or not it is appropriateis reminiscent of Statistical NLG (SNLG;).", "labels": [], "entities": [{"text": "Statistical NLG (SNLG", "start_pos": 112, "end_pos": 133, "type": "DATASET", "confidence": 0.8895697444677353}]}, {"text": "In an SNLG system, after the macro-planning and micro-planning stages (see) are executed, and the message to be communicated is determined, multiple candidate realizations are produced, and then statistical methods are used to determine which of these realizations is the best (based on a reference corpus).", "labels": [], "entities": []}, {"text": "Our work differs from SNLG in that there are no pre-determined messages.", "labels": [], "entities": [{"text": "SNLG", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.6353051066398621}]}, {"text": "The generation stage produces candidate content.", "labels": [], "entities": []}, {"text": "Each candidate claim is a different message, and the selection stage attempts to identify those which are coherent and relevant, rather than best realized.", "labels": [], "entities": []}, {"text": "In other words, while the classical NLG paradigm is to first select the content and then realize it in a natural language, here our building blocks from the onset are natural language elements, and statistical methods are used to determine which content selectionsimplied by combining them -are valid.", "labels": [], "entities": []}, {"text": "Finally, the notion that predicates of claims regarding one topic maybe applicable to another is reminiscent of the motivation for the work of, who observe that there are commonalities (so called \"framing dimensions\") among the way different topics are framed in news articles.", "labels": [], "entities": []}], "datasetContent": [{"text": "We generated claims for 67 topics, extracted from debatabase motions (http://idebate.org) for which we have previously annotated relevant Wikipedia articles (for the benefit of the n-TLs construction; see Section 2.1).", "labels": [], "entities": []}, {"text": "Importantly, when generating candidate claims fora topic, predicates which originated from this topic were not used.", "labels": [], "entities": []}, {"text": "For each topic 28 candidate claims were generated, and in addition one manually-detected claim (as per () and one mock claim were included for control.", "labels": [], "entities": []}, {"text": "The mock claim was constructed by setting the topic as the subject of a sentence, and selecting a mock predicate at random from a hand-crafted list.", "labels": [], "entities": []}, {"text": "These 67 \u00d7 30 candidate claims were annotated using Amazon's Mechanical Turk (AMT).", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk (AMT)", "start_pos": 52, "end_pos": 82, "type": "DATASET", "confidence": 0.9249290823936462}]}, {"text": "In each HIT (Human Intelligence Task) we presented the annotators with a debatabase motion and 10 candidate claims, and asked which of the claims is appropriate for the motion (10 annotators per HIT).", "labels": [], "entities": []}, {"text": "After filtering out the less reliable annotators based on mutual agreement and control questions, a reasonable agreement was apparent (average \u03ba = 0.73).", "labels": [], "entities": []}, {"text": "After this filtering 45 of the initial 82 annotators remained, as well as 955 of the initial 2010 annotated candidate claims (discard-  Initially we thought to label a candidate claim as either positive or negative examples, based on the majority vote of the annotators.", "labels": [], "entities": []}, {"text": "This lead to a seemingly 52% of the candidates being \"good\".", "labels": [], "entities": []}, {"text": "However, anecdotal examination of this majority labeling suggested that the many annotators were biased toward answering \"good\" -even on some of the control questions which contained nonsensical sentences.", "labels": [], "entities": []}, {"text": "This, alongside relatively low mean agreement, raised the need for filtering mentioned above.", "labels": [], "entities": [{"text": "agreement", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.6177191138267517}]}, {"text": "After filtering, 40% of the candidate claims were taken to be positive examples.", "labels": [], "entities": []}, {"text": "The accuracy of the Selection Component was assessed using a leave-one-out methodology, leaving out one topic at each iteration.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993047714233398}]}, {"text": "The overall accuracy achieved by the classifier was 0.75 depicts the confusion matrix).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995892643928528}]}, {"text": "We also examined the trade-off between the number of selected candidate claims and the fraction of them which are valid.", "labels": [], "entities": []}, {"text": "average precision when varying the two Selection Component parameters, \u03ba and \u03c4 . For example, at the most conservative setting, where the component outputs at most one claim per topic, and only fora topic for which at least half the candidate claims were predicted to be valid (31 of the 67 topics), the precision is 0.94.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9989575147628784}, {"text": "precision", "start_pos": 304, "end_pos": 313, "type": "METRIC", "confidence": 0.9984959363937378}]}, {"text": "Recall that in the entire dataset, 40% of the examples are positive.", "labels": [], "entities": []}, {"text": "We note that this precision is significantly higher than reported for claim detection (, where, for example, mean precision at 5 is 0.28 (in our case it is 0.7 \u2212 0.8).", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9988923668861389}, {"text": "claim detection", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.8191626369953156}, {"text": "mean", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9393579363822937}, {"text": "precision", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.5109803080558777}]}, {"text": "One should note, however, that this is not a fair comparison.", "labels": [], "entities": []}, {"text": "First, we permit the algorithm to discard some topics.", "labels": [], "entities": []}, {"text": "Second, here the definition of a valid claim is less strict than in (.", "labels": [], "entities": []}, {"text": "Examining the impact of individual features, we first looked which of them, on their own, are most correlated with the labels.", "labels": [], "entities": []}, {"text": "These turned out to be the number of times p appears in a claim candidate labeled positive and negative (Pearson's correlation 0.33 and -0.34 resp.).", "labels": [], "entities": [{"text": "Pearson's correlation 0.33", "start_pos": 105, "end_pos": 131, "type": "METRIC", "confidence": 0.9107442796230316}]}, {"text": "We then examined which features received the most weight in the logistic regression classifier (trained overall data; features were scaled to a).", "labels": [], "entities": []}, {"text": "The top feature was the number of sentences in which all words appear, and following it were the aforementioned appearance counts in negative and positive examples.", "labels": [], "entities": []}], "tableCaptions": []}