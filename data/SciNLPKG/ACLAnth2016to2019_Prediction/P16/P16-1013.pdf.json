{"title": [{"text": "Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning", "labels": [], "entities": [{"text": "Word Representation Learning", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.7866050402323405}]}], "abstractContent": [{"text": "We use Bayesian optimization to learn curricula for word representation learning, optimizing performance on downstream tasks that depend on the learned representations as features.", "labels": [], "entities": [{"text": "word representation learning", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.8069003025690714}]}, {"text": "The curricula are mod-eled by a linear ranking function which is the scalar product of a learned weight vector and an engineered feature vector that characterizes the different aspects of the complexity of each instance in the training corpus.", "labels": [], "entities": []}, {"text": "We show that learning the curriculum improves performance on a variety of downstream tasks over random orders and in comparison to the natural corpus order.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is well established that in language acquisition, there are robust patterns in the order by which phenomena are acquired.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7073827832937241}]}, {"text": "For example, prototypical concepts are acquired earlier; concrete words tend to be learned before abstract ones.", "labels": [], "entities": []}, {"text": "The acquisition of lexical knowledge in artificial systems proceeds differently.", "labels": [], "entities": []}, {"text": "In general, models will improve during the course of parameter learning, but the time course of acquisition is not generally studied beyond generalization error as a function of training time or data size.", "labels": [], "entities": []}, {"text": "We revisit this issue of choosing the order of learning-curriculum learning-framing it as an optimization problem so that a rich array of factors-including nuanced measures of difficulty, as well as prototypicality and diversity-can be exploited.", "labels": [], "entities": []}, {"text": "Prior research focusing on curriculum strategies in NLP is scarce, and has conventionally been following a paradigm of \"starting small\", i.e., initializing the learner with \"simple\" examples first, and then gradually increasing data complexity (.", "labels": [], "entities": []}, {"text": "In language modeling, this preference for increasing complexity has been realized by curricula that increase the entropy of training data by growing the size of the training vocabulary from frequent to less frequent words.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.6988036781549454}]}, {"text": "In unsupervised grammar induction, an effective curriculum comes from increasing length of training sentences as training progresses (.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.6995724588632584}]}, {"text": "These case studies have demonstrated that carefully designed curricula can lead to better results.", "labels": [], "entities": []}, {"text": "However, they have relied on heuristics in selecting curricula or have followed the intuitions of human and animal learning.", "labels": [], "entities": []}, {"text": "Had different heuristics been chosen, the results would have been different.", "labels": [], "entities": []}, {"text": "In this paper, we use curriculum learning to create improved word representations.", "labels": [], "entities": []}, {"text": "However, rather than testing a small number of curricula, we search for an optimal curriculum using Bayesian optimization.", "labels": [], "entities": []}, {"text": "A curriculum is defined to be the ordering of the training instances, in our case it is the ordering of paragraphs in which the representation learning model reads the corpus.", "labels": [], "entities": []}, {"text": "We use a linear ranking function to conduct a systematic exploration of interacting factors that affect curricula of representation learning models.", "labels": [], "entities": []}, {"text": "We then analyze our findings, and compare them to human intuitions and learning principles.", "labels": [], "entities": []}, {"text": "We treat curriculum learning as an outer loop in the process of learning and evaluation of vectorspace representations of words; the iterative procedure is (1) predict a curriculum; (2) train word embeddings; (3) evaluate the embeddings on tasks that use word embeddings as the sole features.", "labels": [], "entities": []}, {"text": "Through this model we analyze the impact of curriculum on word representation models and on extrinsic tasks.", "labels": [], "entities": [{"text": "word representation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7602428197860718}]}, {"text": "To quantify curriculum properties, we define three groups of features aimed at analyzing statistical and linguistic content and structure of training data: (1) diversity, (2) simplicity, and (3) prototypicality.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 175, "end_pos": 185, "type": "METRIC", "confidence": 0.998439610004425}]}, {"text": "A function of these features is computed to score each paragraph in the training data, and the curriculum is determined by sorting corpus paragraphs by the paragraph scores.", "labels": [], "entities": []}, {"text": "We detail the model in \u00a72.", "labels": [], "entities": []}, {"text": "Word vectors are learned from the sorted corpus, and then evaluated on partof-speech tagging, parsing, named entity recognition, and sentiment analysis ( \u00a73).", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7426806092262268}, {"text": "parsing", "start_pos": 94, "end_pos": 101, "type": "TASK", "confidence": 0.9499783515930176}, {"text": "named entity recognition", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.5987534125645956}, {"text": "sentiment analysis", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.9281264841556549}]}, {"text": "Our experiments confirm that training data curriculum affects model performance, and that models with optimized curriculum consistently outperform baselines trained on shuffled corpora ( \u00a74).", "labels": [], "entities": []}, {"text": "We analyze our findings in \u00a75.", "labels": [], "entities": []}, {"text": "The contributions of this work are twofold.", "labels": [], "entities": []}, {"text": "First, this is the first framework that formulates curriculum learning as an optimization problem, rather then shuffling data or relying on human intuitions.", "labels": [], "entities": [{"text": "formulates curriculum learning", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.8053199251492819}]}, {"text": "We experiment with optimizing the curriculum of word embeddings, but in principle the curriculum of other models can be optimized in a similar way.", "labels": [], "entities": []}, {"text": "Second, to the best of our knowledge, this study is the first to analyze the impact of distributional and linguistic properties of training texts on the quality of task-specific word embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the utility of the pretrained word embeddings as features in downstream NLP tasks.", "labels": [], "entities": []}, {"text": "We choose the following off-the-shelf models that utilize pretrained word embeddings as features:  Data.", "labels": [], "entities": []}, {"text": "All models were trained on Wikipedia articles, split to paragraph-per-line.", "labels": [], "entities": []}, {"text": "Texts were cleaned, tokenized, numbers were normalized by replacing each digit with \"DG\", all types that occur less than 10 times were replaces by the \"UNK\" token, the data was not lowercased.", "labels": [], "entities": []}, {"text": "We list data sizes in Experiments.", "labels": [], "entities": []}, {"text": "In all the experiments we first train word embedding models, then the word embeddings are used as features in four extrinsic tasks ( \u00a73).", "labels": [], "entities": []}, {"text": "We tune the tasks on development data, and report results on the test data.", "labels": [], "entities": []}, {"text": "The only component that varies across the experiments is order of paragraphs in the training corpus-the curriculum.", "labels": [], "entities": []}, {"text": "We compare the following experimental setups: \u2022 Shuffled baselines: the curriculum is defined by random shuffling the training data.", "labels": [], "entities": []}, {"text": "We shuffled the data 10 times, and trained 10 word embeddings models, each model was then evaluated on downstream tasks.", "labels": [], "entities": []}, {"text": "Following, we report test results for the system that is closest to the median in dev scores.", "labels": [], "entities": []}, {"text": "To evaluate variability and a range of scores that can be obtained from shuffling the data, we also report test results for systems that obtained the highest dev scores.", "labels": [], "entities": []}, {"text": "\u2022 Sorted baselines: the curriculum is defined by sorting the training data by sentence length in increasing/decreasing order, similarly to ().", "labels": [], "entities": []}, {"text": "\u2022 Coherent baselines: the curriculum is defined by just concatenating Wikipedia articles.", "labels": [], "entities": []}, {"text": "The goal of this experiment is to evaluate the importance of semantic coherence in training data.", "labels": [], "entities": []}, {"text": "Our intuition is that a coherent curriculum can improve models, since words with similar meanings and similar contexts are grouped when presented to the learner.", "labels": [], "entities": []}, {"text": "\u2022 Optimized curriculum models: the curriculum is optimized using the BayesOpt.", "labels": [], "entities": [{"text": "BayesOpt", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.9012892246246338}]}, {"text": "We evaluate and compare models optimized using features from one of the three feature groups ( \u00a72.2).", "labels": [], "entities": []}, {"text": "As in the shuffled baselines, we fix the number of trials (here, BayesOpt iterations) to 10, and we report test results of systems that obtained best dev scores.", "labels": [], "entities": []}, {"text": "Experimental results are listed in table 2.", "labels": [], "entities": []}, {"text": "Most systems trained with curriculum substantially outperform the strongest of all baselines.", "labels": [], "entities": []}, {"text": "These results are encouraging, given that all word embedding models were trained on the same set of examples, only in different order, and display the indirect influence of the data curriculum on downstream tasks.", "labels": [], "entities": []}, {"text": "These results support our assumption that curriculum matters.", "labels": [], "entities": []}, {"text": "Albeit not as pronounced as with optimized curriculum, sorting paragraphs by length can also lead to substantial improvements over random baselines, but there is no clear recipe on whether the models prefer curricula sorted in an increasing or decreasing order.", "labels": [], "entities": []}, {"text": "These results also support the advantage of a taskspecific optimization framework over a general, intuition-guided recipe.", "labels": [], "entities": []}, {"text": "An interesting result, also, that shuffling is not essential: systems trained on coherent data are on par (or better) than the shuffled systems.", "labels": [], "entities": []}, {"text": "In the next section, we analyze these results qualitatively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Training data sizes.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of the impact of the curriculum of word embeddings on the downstream tasks.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of the impact of curriculum  integrated in the cbow objective.", "labels": [], "entities": []}, {"text": " Table 4: Curricula correlations across feature  groups.", "labels": [], "entities": []}, {"text": " Table 5: Data selection results.", "labels": [], "entities": [{"text": "Data selection", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7336648404598236}]}]}