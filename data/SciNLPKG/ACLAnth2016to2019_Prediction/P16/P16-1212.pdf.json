{"title": [{"text": "Knowledge-Based Semantic Embedding for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7321385741233826}]}], "abstractContent": [{"text": "In this paper, with the help of knowledge base, we build and formulate a semantic space to connect the source and target languages, and apply it to the sequence-to-sequence framework to propose a Knowledge-Based Semantic Embedding (KBSE) method.", "labels": [], "entities": []}, {"text": "In our KB-SE method, the source sentence is firstly mapped into a knowledge based semantic space, and the target sentence is generated using a recurrent neural network with the internal meaning preserved.", "labels": [], "entities": []}, {"text": "Experiments are conducted on two translation tasks, the electric business data and movie data, and the results show that our proposed method can achieve outstanding performance, compared with both the traditional SMT methods and the existing encoder-decoder models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 213, "end_pos": 216, "type": "TASK", "confidence": 0.9875524044036865}]}], "introductionContent": [{"text": "Deep neural network based machine translation, such as sequence-to-sequence (S2S) model), try to learn translation relation in a continuous vector space.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7853116989135742}]}, {"text": "As shown in, the S2S framework contains two parts: an encoder and a decoder.", "labels": [], "entities": []}, {"text": "To compress a variable-length source sentence into a fixed-size vector, with a recurrent neural network (RNN), an encoder reads words one by one and generates a sequence of hidden vectors.", "labels": [], "entities": []}, {"text": "By reading all the source words, the final hidden vector should contain the information of source sentence, and it is called the context vector.", "labels": [], "entities": []}, {"text": "Based on the context vector, another RNN-based neural network is used to generate the target sentence.", "labels": [], "entities": []}, {"text": "* This work was done while the first author was visiting Microsoft Research.", "labels": [], "entities": []}, {"text": "The context vector plays a key role in the connection of source and target language spaces, and it should contain all the internal meaning extracted from source sentence, based on which, the decoder can generate the target sentence keeping the meaning unchanged.", "labels": [], "entities": []}, {"text": "To extract the internal meaning and generate the target sentence, S2S framework usually needs large number of parameters, and a big bilingual corpus is acquired to train them.", "labels": [], "entities": []}, {"text": "In many cases, the internal meaning is not easy to learn, especially when the language is informal.", "labels": [], "entities": []}, {"text": "For the same intention, there are various expressions with very different surface string, which aggravates the difficulty of internal meaning extraction.", "labels": [], "entities": [{"text": "internal meaning extraction", "start_pos": 125, "end_pos": 152, "type": "TASK", "confidence": 0.7042761842409769}]}, {"text": "As shown in, there are three different expressions fora same intention, a customer wants a white 4G cellphone with a big screen.", "labels": [], "entities": []}, {"text": "The first and second expressions (Source1 and Source2) are wordy and contain lots of verbiage.", "labels": [], "entities": []}, {"text": "To extract the internal meaning, the encoder should ignore these verbiage and focus on key information.", "labels": [], "entities": []}, {"text": "This is hard for the encoder-decoder mechanism, since it is not defined or formulated that what kind of information is key information.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our proposed KBSE model, in this section, we conduct experiments on two Chineseto-English translation tasks.", "labels": [], "entities": [{"text": "Chineseto-English translation tasks", "start_pos": 84, "end_pos": 119, "type": "TASK", "confidence": 0.7253642578919729}]}, {"text": "One is from electric business domain, and the other is from movie domain.", "labels": [], "entities": []}, {"text": "To train our KBSE system, we only need two kinds of pairs: the pair of source sentence and semantic tuples to train our Source Grounding, the pair of semantic tuples and target sentence to train our Target Generation.", "labels": [], "entities": []}, {"text": "Examples of our training data in the electric business and movie domains are shown in  Our electric business corpus contains 50,169 source-KB-target triplets.", "labels": [], "entities": []}, {"text": "For this data, we divide the intention of electric business into 11 classes, which are Category, Function, Network, People, Price, Appearance, Carrier, Others, Performance, OS and Brand.", "labels": [], "entities": [{"text": "OS", "start_pos": 173, "end_pos": 175, "type": "METRIC", "confidence": 0.9367339611053467}]}, {"text": "Each class above also has subclasses, for example Category class has subclass computer and cellphone, and computer class can be divided into laptop, tablet PC, desktop and AIO.", "labels": [], "entities": []}, {"text": "Our movie corpus contains 44,826 source-KBtarget triplets, together with 76,134 source-KB pairs and 85,923 KB-target pairs.", "labels": [], "entities": []}, {"text": "The data is crawling from English Wikipedia 5 and the parallel web page in Chinese Wikipedia . Simple rule method is used to extract sentences and KB pairs by matching the information in the infobox and the sentences in the page content.", "labels": [], "entities": [{"text": "English Wikipedia 5", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.8643030722935995}]}, {"text": "Since not all the entities from Chinese wikipedia has english name, we have an extra entity translator to translate them.", "labels": [], "entities": []}, {"text": "For a fair comparison, this entity translator are also used in other systems.", "labels": [], "entities": []}, {"text": "Due to the whole process is semi-automatic, there maybe a few irregular results within.", "labels": [], "entities": []}, {"text": "We divided the intention of movie data into 14 classes, which are BasedOn, Budget, Country, Director, Distributor, Genre, Language, Name, Producer, Released, Starring, Studio, Theme and Writer.", "labels": [], "entities": []}, {"text": "We use BLEU () as the automatical evaluation matrix, significant testing is carried out using bootstrap re-sampling method) with a 95% confidence level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9986942410469055}]}, {"text": "As an addition, we also do human evaluation for all the comparison systems.", "labels": [], "entities": []}, {"text": "Since the first part Source Grounding of our KBSE is separately trained, the F-score of KB tuples is also evaluated.", "labels": [], "entities": [{"text": "KBSE", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.8720698952674866}, {"text": "F-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9977818131446838}]}, {"text": "5 https://en.wikipedia.org 6 https://zh.wikipedia.org lists evaluation results for the electric business and movie data sets.", "labels": [], "entities": [{"text": "movie data sets", "start_pos": 109, "end_pos": 124, "type": "DATASET", "confidence": 0.845270832379659}]}, {"text": "From, we can find that our proposed method can achieve much higher BLEU than SMT system, and we can also achieve 1.9 and 3.6 BLEU points improvement compared with the raw encoder-decoder system on both eletric business and movies data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9991588592529297}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.8889890909194946}, {"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9985826015472412}]}, {"text": "For the Enc-Dec+KBSE method, with the same training data on electric business domain, introducing knowledge semantic information can achieve about 4 BLEU points compared with the encoder-decoder and more than 2 BLEU points compared with our KBSE.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.9980125427246094}, {"text": "BLEU", "start_pos": 211, "end_pos": 215, "type": "METRIC", "confidence": 0.9977244734764099}, {"text": "KBSE", "start_pos": 241, "end_pos": 245, "type": "DATASET", "confidence": 0.9097206592559814}]}, {"text": "Compared with encoder-decoder, Enc-Dec+KBSE method leverages the constrained semantic space, so that key semantic information can be extracted.", "labels": [], "entities": []}, {"text": "Compared with KBSE, which relies on the knowledge base, Enc-Dec+KBSE method can reserve the information which is not formulated in the knowledge base, and also may fix errors generated in the source grounding part.", "labels": [], "entities": []}, {"text": "Since Enc-Dec+KBSE can only be trained with source-KB-target triplets, for the movie dataset, the performance is not as good as our KBSE, but still achieves again of more than 2 BLEU point compared with the raw Enc-Dec system.", "labels": [], "entities": [{"text": "movie dataset", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.6892779767513275}, {"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.9991437196731567}]}, {"text": "On movie data, our KBSE can achieve significant improvement compared with the models (SMT, EncDec, Enc-Dec+KBSE ) only using bilingual data.", "labels": [], "entities": []}, {"text": "This shows the advantage of our proposed method, which is our model can leverage monolingual data to learn Source Grounding and Target Generation separately.", "labels": [], "entities": [{"text": "Target Generation", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.7640013992786407}]}, {"text": "We also separately evaluate the Source Grounding and Target Generation parts.", "labels": [], "entities": [{"text": "Target Generation", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7377240657806396}]}, {"text": "We evaluate the F-score of generated KB tuples compared with the golden KB tuples.", "labels": [], "entities": [{"text": "F-score", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.9986095428466797}]}, {"text": "The result shows that our semantic grounding performance is quite high (92.6%), which means the first part can extract the semantic information in high coverage and accuracy.", "labels": [], "entities": [{"text": "coverage", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9569385051727295}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.981991708278656}]}, {"text": "We evaluate the translation result by feeding the Target Generation network with human labeled KB tuples.", "labels": [], "entities": []}, {"text": "The translation result (shown as KBSE upperbound in) with golden KB tuples can achieve about 1.1 and 1.8 BLEU scores improvement compared with KBSE with generated KB tuples in both dataset.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9989149570465088}]}, {"text": "For the human evaluation, we do not need the whole sentence to be totally right.", "labels": [], "entities": []}, {"text": "We focus on the key information, and if a translation is right by main information and grammar correction, we label it as correct translation, no matter how different of the translation compared with the reference on surface strings.", "labels": [], "entities": []}, {"text": "Examples of correct and incorrect translations are shown in.", "labels": [], "entities": []}, {"text": "As shown in, the human evaluation result shares the same trend as in BLEU evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.920013427734375}]}, {"text": "Our proposed method achieves the best results compared with SMT and raw encoder-decoder.", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9669627547264099}]}, {"text": "In our method, important information are extracted and normalized by encoding the source sentence into the semantic space, and the correct translation of important information is key for human evaluation, thus our method can generate better translation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The BLEU scores, human evaluation accuracy, tuple F-score for the proposed KBSE model and  other benchmark models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9989321827888489}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9401839375495911}, {"text": "tuple F-score", "start_pos": 54, "end_pos": 67, "type": "METRIC", "confidence": 0.877956360578537}, {"text": "KBSE model", "start_pos": 85, "end_pos": 95, "type": "DATASET", "confidence": 0.8639162480831146}]}]}