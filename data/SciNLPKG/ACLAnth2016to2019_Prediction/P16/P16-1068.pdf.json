{"title": [{"text": "Automatic Text Scoring Using Neural Networks", "labels": [], "entities": [{"text": "Automatic Text Scoring", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5994577805201212}]}], "abstractContent": [{"text": "Automated Text Scoring (ATS) provides a cost-effective and consistent alternative to human marking.", "labels": [], "entities": [{"text": "Automated Text Scoring (ATS)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7531116455793381}, {"text": "human marking", "start_pos": 85, "end_pos": 98, "type": "TASK", "confidence": 0.6750136613845825}]}, {"text": "However, in order to achieve good performance, the pre-dictive features of the system need to be manually engineered by human experts.", "labels": [], "entities": []}, {"text": "We introduce a model that forms word representations by learning the extent to which specific words contribute to the text's score.", "labels": [], "entities": []}, {"text": "Using Long-Short Term Memory networks to represent the meaning of texts, we demonstrate that a fully automated framework is able to achieve excellent results over similar approaches.", "labels": [], "entities": []}, {"text": "In an attempt to make our results more interpretable, and inspired by recent advances in visualizing neural networks, we introduce a novel method for identifying the regions of the text that the model has found more discriminative.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated Text Scoring (ATS) refers to the set of statistical and natural language processing techniques used to automatically score a text on a marking scale.", "labels": [], "entities": [{"text": "Automated Text Scoring (ATS)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7496801515420278}]}, {"text": "The advantages of ATS systems have been established since Project Essay Grade (PEG), one of the earliest systems whose development was largely motivated by the prospect of reducing labour-intensive marking activities.", "labels": [], "entities": [{"text": "ATS", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9500516057014465}]}, {"text": "In addition to providing a cost-effective and efficient approach to large-scale grading of (extended) text, such systems ensure a consistent application of marking criteria, therefore facilitating equity in scoring.", "labels": [], "entities": []}, {"text": "There is a large body of literature with regards to ATS systems of text produced by nonnative English-language learners, among others), overviews of which can be found in various studies).", "labels": [], "entities": [{"text": "ATS systems of text produced by nonnative English-language learners", "start_pos": 52, "end_pos": 119, "type": "TASK", "confidence": 0.8114980128076341}]}, {"text": "Implicitly or explicitly, previous work has primarily treated text scoring as a supervised text classification task, and has utilized a large selection of techniques, ranging from the use of syntactic parsers, via vectorial semantics combined with dimensionality reduction, to generative and discriminative machine learning.", "labels": [], "entities": [{"text": "text scoring", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.7989603579044342}, {"text": "text classification task", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.8015219370524088}, {"text": "generative and discriminative machine learning", "start_pos": 277, "end_pos": 323, "type": "TASK", "confidence": 0.7883321523666382}]}, {"text": "As multiple factors influence the quality of texts, ATS systems typically exploit a large range of textual features that correspond to different properties of text, such as grammar, vocabulary, style, topic relevance, and discourse coherence and cohesion.", "labels": [], "entities": []}, {"text": "In addition to lexical and part-ofspeech (POS) ngrams, linguistically deeper features such as types of syntactic constructions, grammatical relations and measures of sentence complexity are among some of the properties that form an ATS system's internal marking criteria.", "labels": [], "entities": []}, {"text": "The final representation of a text typically consists of a vector of features that have been manually selected and tuned to predict a score on a marking scale.", "labels": [], "entities": []}, {"text": "Although current approaches to scoring, such as regression and ranking, have been shown to achieve performance that is indistinguishable from that of human examiners, there is substantial manual effort involved in reaching these results on different domains, genres, prompts and so forth.", "labels": [], "entities": []}, {"text": "Linguistic features intended to capture the aspects of writing to be assessed are hand-selected and tuned for specific domains.", "labels": [], "entities": []}, {"text": "In order to perform well on different data, separate models with distinct feature sets are typically tuned.", "labels": [], "entities": []}, {"text": "Prompted by recent advances in deep learning and the ability of such systems to surpass state-ofthe-art models in similar areas, we propose the use of recurrent neural network models for ATS.", "labels": [], "entities": [{"text": "ATS", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.9551243782043457}]}, {"text": "Multi-layer neural networks are known for automatically learning useful features from data, with lower layers learning basic feature detectors and upper levels learning more high-level abstract features (.", "labels": [], "entities": []}, {"text": "Additionally, recurrent neural networks are well-suited for modeling the compositionality of language and have been shown to perform very well on the task of language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.7155568301677704}]}, {"text": "We therefore propose to apply these network structures to the task of scoring, in order to both improve the performance of ATS systems and learn the required feature representations for each dataset automatically, without the need for manual tuning.", "labels": [], "entities": []}, {"text": "More specifically, we focus on predicting a holistic score for extended-response writing items.", "labels": [], "entities": []}, {"text": "However, automated models are not a panacea, and their deployment depends largely on the ability to examine their characteristics, whether they measure what is intended to be measured, and whether their internal marking criteria can be interpreted in a meaningful and useful way.", "labels": [], "entities": []}, {"text": "The deep architecture of neural network models, however, makes it rather difficult to identify and extract those properties of text that the network has identified as discriminative.", "labels": [], "entities": []}, {"text": "Therefore, we also describe a preliminary method for visualizing the information the model is exploiting when assigning a specific score to an input text.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Kaggle dataset contains 12.976 essays ranging from 150 to 550 words each, marked by two raters (Cohen's \u03ba = 0.86).", "labels": [], "entities": [{"text": "Kaggle dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9431404173374176}]}, {"text": "The essays were written by students ranging from Grade 7 to Grade 10, comprising eight distinct sets elicited by eight different prompts, each with distinct marking criteria and score range.", "labels": [], "entities": []}, {"text": "For our experiments, we use the resolved combined score between the two raters, which is calculated as the average between the two raters' scores (if the scores are close), or is determined by a third expert (if the scores are far apart).", "labels": [], "entities": []}, {"text": "Currently, the state-of-the-art on this dataset has achieved a Cohen's \u03ba = 0.81 (using quadratic weights).", "labels": [], "entities": []}, {"text": "However, the test set was released without the gold score annotations, rendering any comparisons futile, and we are therefore restricted in splitting the given training set to create anew test set.", "labels": [], "entities": []}, {"text": "The sets where divided as follows: 80% of the entire dataset was reserved for training/validation, and 20% for testing.", "labels": [], "entities": []}, {"text": "80% of the training/validation subset was used for actual training, while the remaining 20% for validation (in absolute terms for the entire dataset: 64% training, 16% validation, 20% testing).", "labels": [], "entities": []}, {"text": "To facilitate future work, we release the ids of the validation and test set essays we used in our experiments, in addition to our source code and various hyperparameter values.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the different models on the Kaggle dataset. All resulting vectors were trained  using linear regression. We optimized the parameters using a separate validation set (see text)  and report the results on the test set.", "labels": [], "entities": [{"text": "Kaggle dataset", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.966529130935669}]}]}