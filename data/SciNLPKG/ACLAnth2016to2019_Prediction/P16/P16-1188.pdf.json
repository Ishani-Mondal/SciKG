{"title": [{"text": "Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints", "labels": [], "entities": [{"text": "Single-Document Summarization", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.5268946886062622}]}], "abstractContent": [{"text": "We present a discriminative model for single-document summarization that integrally combines compression and anaphoricity constraints.", "labels": [], "entities": [{"text": "single-document summarization", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.5418830215930939}]}, {"text": "Our model selects textual units to include in the summary based on a rich set of sparse features whose weights are learned on a large corpus.", "labels": [], "entities": []}, {"text": "We allow for the deletion of content within a sentence when that deletion is licensed by compression rules; in our framework, these are implemented as dependencies between subsentential units of text.", "labels": [], "entities": []}, {"text": "Anaphoricity constraints then improve cross-sentence coherence by guaranteeing that, for each pronoun included in the summary, the pronoun's antecedent is included as well or the pronoun is rewritten as a full mention.", "labels": [], "entities": []}, {"text": "When trained end-to-end, our final system 1 outperforms prior work on both ROUGE as well as on human judgments of linguistic quality.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.808422863483429}]}], "introductionContent": [{"text": "While multi-document summarization is wellstudied in the NLP literature), single-document summarization) has received less attention in recent years and is generally viewed as more difficult.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.564632922410965}, {"text": "NLP literature", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.7767132222652435}, {"text": "single-document summarization", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.5157401710748672}]}, {"text": "Content selection is tricky without redundancy across multiple input documents as a guide and simple positional information is often hard to beat.", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8120624721050262}]}, {"text": "In this work, we tackle the single-document problem by training an expressive summarization model on a large nat-1 Available at http://nlp.cs.berkeley.edu urally occurring corpus-the New York Times Annotated Corpus which contains around 100,000 news articles with abstractive summaries-learning to select important content with lexical features.", "labels": [], "entities": [{"text": "urally occurring corpus-the New York Times Annotated Corpus", "start_pos": 155, "end_pos": 214, "type": "DATASET", "confidence": 0.6939372830092907}]}, {"text": "This corpus has been explored in related contexts (), but to our knowledge it has not been directly used for singledocument summarization.", "labels": [], "entities": [{"text": "singledocument summarization", "start_pos": 109, "end_pos": 137, "type": "TASK", "confidence": 0.5740643441677094}]}, {"text": "To increase the expressive capacity of our model we allow more aggressive compression of individual sentences by combining two different formalisms-one syntactic and the other discursive.", "labels": [], "entities": []}, {"text": "Additionally, we incorporate a model of anaphora resolution and give our system the ability rewrite pronominal mentions, further increasing expressivity.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7169013321399689}]}, {"text": "In order to guide the model, we incorporate (1) constraints from coreference ensuring that critical pronoun references are clear in the final summary and (2) constraints from syntactic and discourse parsers ensuring that sentence realizations are well-formed.", "labels": [], "entities": []}, {"text": "Despite the complexity of these additional constraints, we demonstrate an efficient inference procedure using an ILPbased approach.", "labels": [], "entities": []}, {"text": "By training our full system endto-end on a large-scale dataset, we are able to learn a high-capacity structured model of the summarization process, contrasting with past approaches to the single-document task which have typically been heuristic in nature.", "labels": [], "entities": [{"text": "summarization process", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.9205298125743866}]}, {"text": "We focus our evaluation on the New York Times Annotated corpus.", "labels": [], "entities": [{"text": "New York Times Annotated corpus", "start_pos": 31, "end_pos": 62, "type": "DATASET", "confidence": 0.7556486248970031}]}, {"text": "According to ROUGE, our system outperforms a document prefix baseline, a bigram coverage baseline adapted from a strong multi-document system, and a discourse-informed method from prior work ().", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 13, "end_pos": 18, "type": "DATASET", "confidence": 0.6738569736480713}]}, {"text": "Imposing discursive and referential constraints improves human judgments of linguistic clarity and referential structure-outperforming the method of 8i, k x unit i \uf8ff x unit k if 9j with xref ij = 0 where the antecedent of r ij is in u k 8j xref ij = 1 i\u21b5 no prior included textual unit mentions the entity that r ij refers to 8i, k x unit i \uf8ff x unit k if u i requires u k on the basis of pronoun anaphora: ILP formulation of our single-document summarization model.", "labels": [], "entities": []}, {"text": "The basic model extracts a set of textual units with binary variables x UNIT subject to a length constraint.", "labels": [], "entities": [{"text": "UNIT", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9642746448516846}]}, {"text": "These textual units u are scored with weights wand features f . Next, we add constraints derived from both syntactic parses and Rhetorical Structure Theory (RST) to enforce grammaticality.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 128, "end_pos": 161, "type": "TASK", "confidence": 0.7227544089158376}]}, {"text": "Finally, we add anaphora constraints derived from coreference in order to improve summary coherence.", "labels": [], "entities": []}, {"text": "We introduce additional binary variables x REF that control whether each pronoun is replaced with its antecedent using a candidate replacement rij.", "labels": [], "entities": [{"text": "REF", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.987449049949646}]}, {"text": "These are also scored in the objective and are incorporated into the length constraint. and approaching the clarity of a sentence-extractive baseline-and still achieves substantially higher ROUGE score than either method.", "labels": [], "entities": [{"text": "clarity", "start_pos": 108, "end_pos": 115, "type": "METRIC", "confidence": 0.9902212619781494}, {"text": "ROUGE score", "start_pos": 190, "end_pos": 201, "type": "METRIC", "confidence": 0.986810028553009}]}, {"text": "These results indicate that our model has the expressive capacity to extract important content, but is sufficiently constrained to ensure fluency is not sacrificed as a result.", "labels": [], "entities": []}, {"text": "Past work has explored various kinds of structure for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.9906084537506104}]}, {"text": "Some work has focused on improving content selection using discourse structure (), topical structure (), or related techniques ().", "labels": [], "entities": [{"text": "content selection", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7160691171884537}]}, {"text": "Other work has used structure primarily to reorder summaries and ensure coherence () or to represent content for sentence fusion or abstraction ().", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 113, "end_pos": 128, "type": "TASK", "confidence": 0.7327908128499985}]}, {"text": "Similar to these approaches, we appeal to structures from upstream NLP tasks (syntactic parsing, RST parsing, and coreference) to restrict our model's capacity to generate.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7554439604282379}, {"text": "RST parsing", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9269707798957825}]}, {"text": "However, we go further by optimizing for ROUGE subject to these constraints with end-to-end learning.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9111541509628296}]}], "datasetContent": [{"text": "We primarily evaluate our model on a roughly 3000-document evaluation set from the New York Times Annotated Corpus.", "labels": [], "entities": [{"text": "3000-document evaluation set from the New York Times Annotated Corpus", "start_pos": 45, "end_pos": 114, "type": "DATASET", "confidence": 0.7337348818778991}]}, {"text": "We also investigate its performance on the RST Discourse), but because this dataset is only 30 documents it provides much less robust estimates of performance.", "labels": [], "entities": [{"text": "RST Discourse", "start_pos": 43, "end_pos": 56, "type": "DATASET", "confidence": 0.8368348181247711}]}, {"text": "8 Throughout this section, when we decode a document, we set the word budget for our summarizer to be the same as the number of words in the corresponding reference summary, following previous work ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the NYT50 test set (documents with sum- maries of at least 50 tokens) from the New York Times Anno- tated Corpus (Sandhaus", "labels": [], "entities": [{"text": "NYT50 test set", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.949748714764913}, {"text": "New York Times Anno- tated Corpus", "start_pos": 100, "end_pos": 133, "type": "DATASET", "confidence": 0.5315392868859428}, {"text": "Sandhaus", "start_pos": 135, "end_pos": 143, "type": "DATASET", "confidence": 0.6120166182518005}]}, {"text": " Table 2: Results for RST Discourse Treebank (", "labels": [], "entities": [{"text": "RST Discourse Treebank", "start_pos": 22, "end_pos": 44, "type": "DATASET", "confidence": 0.7977938254674276}]}]}