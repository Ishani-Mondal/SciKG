{"title": [{"text": "Models and Inference for Prefix-Constrained Machine Translation", "labels": [], "entities": [{"text": "Prefix-Constrained Machine Translation", "start_pos": 25, "end_pos": 63, "type": "TASK", "confidence": 0.642456591129303}]}], "abstractContent": [{"text": "We apply phrase-based and neural models to a core task in interactive machine translation: suggesting how to complete a partial translation.", "labels": [], "entities": [{"text": "interactive machine translation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.651111364364624}]}, {"text": "For the phrase-based system , we demonstrate improvements in suggestion quality using novel objective functions , learning techniques, and inference algorithms tailored to this task.", "labels": [], "entities": []}, {"text": "Our contributions include new tunable metrics, an improved beam search strategy, an n-best extraction method that increases suggestion diversity, and a tuning procedure fora hierarchical joint model of alignment and translation.", "labels": [], "entities": [{"text": "beam search", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.8988582491874695}, {"text": "alignment and translation", "start_pos": 202, "end_pos": 227, "type": "TASK", "confidence": 0.7108961741129557}]}, {"text": "The combination of these techniques improves next-word suggestion accuracy dramatically from 28.5% to 41.2% in a large-scale English-German experiment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9622535705566406}]}, {"text": "Our recurrent neural translation system increases accuracy yet further to 53.0%, but inference is two orders of magnitude slower.", "labels": [], "entities": [{"text": "recurrent neural translation", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6403831342856089}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9994261264801025}]}, {"text": "Manual error analysis shows the strengths and weaknesses of both approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "A core prediction task in interactive machine translation (MT) is to complete a partial translation).", "labels": [], "entities": [{"text": "interactive machine translation (MT)", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.8023091952006022}]}, {"text": "Sentence completion enables interfaces that are richer than basic post-editing of MT output.", "labels": [], "entities": [{"text": "Sentence completion", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9388129413127899}, {"text": "MT output", "start_pos": 82, "end_pos": 91, "type": "TASK", "confidence": 0.9048981666564941}]}, {"text": "For example, the translator can receive updated suggestions after each word typed ().", "labels": [], "entities": []}, {"text": "However, we show that completing partial translations by na\u00efve constrained decoding-the standard in prior work-yields poor suggestion quality.", "labels": [], "entities": []}, {"text": "We describe new phrase-based objective functions, learning techniques, and inference algorithms for the sentence completion task.", "labels": [], "entities": [{"text": "sentence completion task", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7907036244869232}]}, {"text": "We then compare this improved phrase-based system to a state-of-theart recurrent neural translation system in large-scale English-German experiments.", "labels": [], "entities": [{"text": "state-of-theart recurrent neural translation", "start_pos": 55, "end_pos": 99, "type": "TASK", "confidence": 0.725242480635643}]}, {"text": "A system for completing partial translations takes as input a source sentence and a prefix of the target sentence.", "labels": [], "entities": [{"text": "completing partial translations", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.6063796083132426}]}, {"text": "It predicts a suffix: a sequence of tokens that extends the prefix to form a full sentence.", "labels": [], "entities": []}, {"text": "In an interactive setting, the first words of the suffix are critical; these words are the focus of the user's attention and can typically be appended to the translation with a single keystroke.", "labels": [], "entities": []}, {"text": "We introduce a tuning metric that scores correctness of the whole suffix, but is particularly sensitive to these first words.", "labels": [], "entities": [{"text": "correctness", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.9720600247383118}]}, {"text": "Phrase-based inference for this task involves aligning the prefix to the source, then generating the suffix by translating the unaligned words.", "labels": [], "entities": []}, {"text": "We describe abeam search strategy and a hierarchical joint model of alignment and translation that together improve suggestions dramatically.", "labels": [], "entities": []}, {"text": "For English-German news, next-word accuracy increases from 28.5% to 41.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9838154911994934}]}, {"text": "An interactive MT system could also display multiple suggestions to the user.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9812983274459839}]}, {"text": "We describe an algorithm for efficiently finding the n-best next words directly following a prefix and their corresponding best suffixes.", "labels": [], "entities": []}, {"text": "Our experiments show that this approach to n-best list extraction, combined with our other improvements, increased next-word suggestion accuracy of 10-best lists from 33.4% to 55.5%.", "labels": [], "entities": [{"text": "n-best list extraction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.6095532476902008}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9532411694526672}]}, {"text": "We also train a recurrent neural translation system to maximize the conditional likelihood of the next word following a translation prefix, which is both a standard training objective in neural translation and an ideal fit for our task.", "labels": [], "entities": [{"text": "recurrent neural translation", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.7224119901657104}, {"text": "neural translation", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.748108297586441}]}, {"text": "This neural system provides even more accurate predictions than our improved phrase-based system.", "labels": [], "entities": []}, {"text": "However, inference is two orders of magnitude slower, which is prob-lematic for an interactive setting.", "labels": [], "entities": []}, {"text": "We conclude with a manual error analysis that reveals the strengths and weaknesses of both the phrase-based and neural approaches to suffix prediction.", "labels": [], "entities": [{"text": "suffix prediction", "start_pos": 133, "end_pos": 150, "type": "TASK", "confidence": 0.8394290506839752}]}], "datasetContent": [{"text": "We evaluate our models and methods for EnglishFrench and English-German on two domains: software and news.", "labels": [], "entities": []}, {"text": "The phrase-based systems are built with Phrasal (), an open source toolkit.", "labels": [], "entities": []}, {"text": "We use a dynamic phrase table () and tune parameters with AdaGrad.", "labels": [], "entities": [{"text": "AdaGrad", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9217376708984375}]}, {"text": "All systems have 42 dense baseline features.", "labels": [], "entities": []}, {"text": "We align the bitexts with mgiza () and estimate 5-gram language models (LMs) with.", "labels": [], "entities": []}, {"text": "The English-French bilingual training data consists of 4.9M sentence pairs from the Common Crawl and Europarl corpora from WMT 2015).", "labels": [], "entities": [{"text": "Common Crawl", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.9132472574710846}, {"text": "Europarl corpora from WMT 2015", "start_pos": 101, "end_pos": 131, "type": "DATASET", "confidence": 0.9098390698432922}]}, {"text": "The LM was estimated from the target side of the bitext.", "labels": [], "entities": [{"text": "LM", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9815951585769653}]}, {"text": "For English-German we run large-scale experiments.", "labels": [], "entities": []}, {"text": "The bitext contains 19.9M parallel segments collected from WMT 2015 and the OPUS collection).", "labels": [], "entities": [{"text": "WMT 2015", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9380299746990204}, {"text": "OPUS collection", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.9612144231796265}]}, {"text": "The LM was estimated from the target side of the bitext and the monolingual Common Crawl corpus), altogether 37.2B running words.", "labels": [], "entities": [{"text": "LM", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9739022850990295}, {"text": "Common Crawl corpus", "start_pos": 76, "end_pos": 95, "type": "DATASET", "confidence": 0.9247941374778748}]}, {"text": "The software test set includes 10k sentence pairs from the Autodesk post editing corpus . For the news domain we chose the English-French newstest2014 and English-German newstest2015 sets provided for the WMT 2016 5 shared task.", "labels": [], "entities": [{"text": "Autodesk post editing corpus", "start_pos": 59, "end_pos": 87, "type": "DATASET", "confidence": 0.7707864493131638}, {"text": "WMT 2016 5 shared task", "start_pos": 205, "end_pos": 227, "type": "DATASET", "confidence": 0.8994067788124085}]}, {"text": "The translation systems were tuned towards the specific domain, using another 10k segments from the Autodesk data or the newstest2013 data set, respectively.", "labels": [], "entities": [{"text": "Autodesk data", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.9879280626773834}, {"text": "newstest2013 data set", "start_pos": 121, "end_pos": 142, "type": "DATASET", "confidence": 0.9489964644114176}]}, {"text": "On the English-French tune set we randomly select one target prefix from each sentence pair for rapid experimentation.", "labels": [], "entities": [{"text": "English-French tune set", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.8036355376243591}]}, {"text": "On all other test and tune sets we select two target prefixes at random.", "labels": [], "entities": []}, {"text": "The selected prefixes remain fixed throughout all experiments.", "labels": [], "entities": []}, {"text": "For NMT, we report results both using a single network and an ensemble of eight models using various attention mechanisms ().", "labels": [], "entities": [{"text": "NMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8906159996986389}]}, {"text": "show the main phrase-based results.", "labels": [], "entities": []}, {"text": "The baseline system corresponds to constrained beam search, which performed best in (Ortiz-Mart\u00ednez et al., 2009) and (, where it was referred to as phrase-based (PB) and phrase-based model (PBM), respectively.", "labels": [], "entities": []}, {"text": "Our target beam search strategy improves all metrics on both test sets.", "labels": [], "entities": [{"text": "target beam search", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.6594605247179667}]}], "tableCaptions": [{"text": " Table 1: Phrase-based results on the English-French task. We compare the baseline with the target beam  search proposed in this work. Prefix tuning is evaluated with four different tuning criteria.", "labels": [], "entities": []}, {"text": " Table 2: Phrase-based results on English-German, tuned to the linear combination of pxBBBB and WPA.", "labels": [], "entities": [{"text": "WPA", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.8326432704925537}]}, {"text": " Table 3: Translation examples from the English-German newstest2015 test set. We compare the prefix  decoding output of the baseline against target beam search both with and without prefix tuning. The prefix  is printed in italics.", "labels": [], "entities": [{"text": "English-German newstest2015 test set", "start_pos": 40, "end_pos": 76, "type": "DATASET", "confidence": 0.7676822990179062}]}, {"text": " Table 5: English-German results for the phrase-based system with target beam search and tuned to a  combined metric, compared with the recurrent neural translation system. The 10-best diverse line contains  oracle scores from a 10-best list; all other scores are computed for a single suffix prediction per example.  We also report unconstrained full-sentence BBBB scores. The phrase-based timing results include prefix  alignment and synthetic phrase extraction.", "labels": [], "entities": [{"text": "recurrent neural translation", "start_pos": 136, "end_pos": 164, "type": "TASK", "confidence": 0.7183646559715271}, {"text": "BBBB", "start_pos": 361, "end_pos": 365, "type": "METRIC", "confidence": 0.831843376159668}, {"text": "prefix  alignment", "start_pos": 414, "end_pos": 431, "type": "TASK", "confidence": 0.7419223785400391}, {"text": "phrase extraction", "start_pos": 446, "end_pos": 463, "type": "TASK", "confidence": 0.7413900196552277}]}, {"text": " Table 6: Example sentences from the English-German newstest2015 test set. We compare the prefix  decoding output of phrase-based target beam search against the single network neural machine translation  (NMT) engine, printing the prefix in italics. The examples illustrate the four error categories missing verb  (Ex. 1 and 2), grammar / morphology (Ex. 3 and 4), missing content words (Ex. 5) and alignment (Ex. 6).", "labels": [], "entities": [{"text": "English-German newstest2015 test set", "start_pos": 37, "end_pos": 73, "type": "DATASET", "confidence": 0.7458571121096611}]}, {"text": " Table 7: Result of the manual analysis on the first  100 segments of the English-German newstest2015  test set. For each of the four error categories we  count how many times one of the systems produced  a better output.", "labels": [], "entities": [{"text": "English-German newstest2015  test set", "start_pos": 74, "end_pos": 111, "type": "DATASET", "confidence": 0.7878360897302628}]}]}