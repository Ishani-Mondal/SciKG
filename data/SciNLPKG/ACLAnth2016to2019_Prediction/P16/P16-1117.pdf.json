{"title": [{"text": "Neural Network-Based Model for Japanese Predicate Argument Structure Analysis", "labels": [], "entities": [{"text": "Predicate Argument Structure Analysis", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.8630337566137314}]}], "abstractContent": [{"text": "This paper presents a novel model for Japanese predicate argument structure (PAS) analysis based on a neural network framework.", "labels": [], "entities": [{"text": "Japanese predicate argument structure (PAS) analysis", "start_pos": 38, "end_pos": 90, "type": "TASK", "confidence": 0.8176163174211979}]}, {"text": "Japanese PAS analysis is challenging due to the tangled characteristics of the Japanese language, such as case disappearance and argument omission.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.8495883047580719}, {"text": "case disappearance", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7194657474756241}, {"text": "argument omission", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.7178437113761902}]}, {"text": "To unravel this problem, we learn selectional preferences from a large raw corpus, and incorporate them into a SOTA PAS analysis model, which considers the consistency of all PASs in a given sentence.", "labels": [], "entities": [{"text": "SOTA PAS analysis", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.5876974860827128}]}, {"text": "We demonstrate that the proposed PAS analysis model significantly outperforms the base SOTA system.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.8656306862831116}]}], "introductionContent": [{"text": "Research on predicate argument structure (PAS) analysis has been conducted actively these days.", "labels": [], "entities": [{"text": "predicate argument structure (PAS) analysis", "start_pos": 12, "end_pos": 55, "type": "TASK", "confidence": 0.8667280673980713}]}, {"text": "The improvement of PAS analysis would benefit many natural language processing (NLP) applications, such as information extraction, summarization, and machine translation.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.9737596809864044}, {"text": "information extraction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8654170334339142}, {"text": "summarization", "start_pos": 131, "end_pos": 144, "type": "TASK", "confidence": 0.9826746582984924}, {"text": "machine translation", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.804845541715622}]}, {"text": "The target of this work is Japanese PAS analysis.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.8102463781833649}]}, {"text": "The Japanese language has the following characteristics: \u2022 head final, \u2022 free word order (among arguments), and \u2022 postpositions function as (surface) case markers.", "labels": [], "entities": []}, {"text": "Japanese major surface cases are (ga), (wo), and (ni), which correspond to Japanese postpositions (case markers).", "labels": [], "entities": []}, {"text": "We call them nominative case, accusative case, and dative case, respectively.", "labels": [], "entities": []}, {"text": "In this paper, we limit our target cases to these three cases.", "labels": [], "entities": []}, {"text": "Note that though they are surface cases, they roughly correspond to Arg1, Arg2, and Arg3 of English semantic role labeling based on PropBank.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9922991394996643}, {"text": "Arg2", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9668632745742798}, {"text": "Arg3", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9872543215751648}, {"text": "English semantic role labeling", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.5543772950768471}, {"text": "PropBank", "start_pos": 132, "end_pos": 140, "type": "DATASET", "confidence": 0.9552854299545288}]}, {"text": "Japanese PAS analysis has been considered as one of the most difficult basic NLP tasks, due to the following two phenomena.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.8314357399940491}]}, {"text": "Case disappearance When a topic marker (wa) is used or a noun is modified by a relative clause, their case markings disappear as in the following examples.", "labels": [], "entities": [{"text": "Case disappearance", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.830339640378952}]}, {"text": "In the example sentences (1a) and (1b), since a topic marker is used, the NOM and ACC case markers disappear.", "labels": [], "entities": [{"text": "NOM and ACC case markers", "start_pos": 74, "end_pos": 98, "type": "METRIC", "confidence": 0.7623106956481933}]}, {"text": "In the example sentences (2a) and (2b), since a noun is modified by a relative clause, the NOM case of \"\" (John) for \" \" (eat) and ACC case of \"\" (bread) for \"\" disappear.", "labels": [], "entities": [{"text": "NOM", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.7580426931381226}]}], "datasetContent": [{"text": "The KWDLC (Kyoto University Web Document Leads Corpus) evaluation set ( was used for our experiments, because it contains a wide variety of Web documents, such as news articles and blogs.", "labels": [], "entities": [{"text": "KWDLC (Kyoto University Web Document Leads Corpus) evaluation set", "start_pos": 4, "end_pos": 69, "type": "DATASET", "confidence": 0.8352340188893405}]}, {"text": "This evaluation set consists of the first three sentences of 5,000 Web documents.", "labels": [], "entities": []}, {"text": "Morphology, named entities, dependencies, PASs, and coreferences were manually annotated.", "labels": [], "entities": []}, {"text": "This evaluation set was divided into 3,694 documents (11,558 sents.) for training, 512 documents (1,585 sents.) for development, and 700 documents (2,195 sents.) for testing.", "labels": [], "entities": []}, {"text": "shows the statistics of the number of arguments in the test set.", "labels": [], "entities": []}, {"text": "While \"dep argument\" means that the argument and a predicate have a dependency relation, but a specified case marking postposition is hidden (corresponds to \"dashed line\" in Section 3.1), \"zero argument\" means that the argument and a predicate do not have a dependency relation (corresponds to \"dotted line\" in Section 3.1).", "labels": [], "entities": []}, {"text": "Since we want to focus on the accuracy of case analysis and zero anaphora resolution, gold morphological analysis, dependency analysis, and named entities were used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9993816614151001}, {"text": "case analysis", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7751232981681824}]}, {"text": "The sentences having a predicate that takes multiple arguments in the same case role were excluded from training and test examples, since the base model cannot handle this phenomena (it assumes that each predicate has only one argument with one case role).", "labels": [], "entities": []}, {"text": "For example, the following sentence, where the predicate \"\" (report) takes both \"\" (daily life) and \"\" (picture) as ACC case arguments, was excluded from training and testing.", "labels": [], "entities": []}, {"text": "About 200 sentences (corresponding to about 1.5% of the whole evaluation set) were excluded.", "labels": [], "entities": []}, {"text": "In this evaluation set, zero exophora, which is a phenomenon that a referent does not appear in a document, is annotated.", "labels": [], "entities": []}, {"text": "Among five types of zero exophora, the two major types, \"author\" and \"reader,\" are adopted, and the others are discarded.", "labels": [], "entities": []}, {"text": "To consider \"author\" and \"reader\" as a referent, the two special nodes, AUTHOR and READER, are added as well as a NULL node in a PA graph of the base model.", "labels": [], "entities": [{"text": "AUTHOR", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9866657853126526}, {"text": "READER", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9901671409606934}]}, {"text": "When the argument predication score is calculated for \"author\" or \"reader,\" because its lemma does not appear in a document, for each noun in the following noun list of \"author\"/\"reader\" (, the argument prediction score is calculated, and the maximum score is used as a feature.", "labels": [], "entities": []}, {"text": "\u2022 author: \"\" (I), \"\" (we), \"\" (I), \" \" (our company), \u00b7 \u00b7 \u00b7 \u2022 reader: \"\" (you), \"\" (customer), \" \" (you), \"\"(you all), \u00b7 \u00b7 \u00b7 In the argument prediction model training described in Section 4.1, a Japanese Web corpus consisting of 10M sentences was used.", "labels": [], "entities": [{"text": "argument prediction model training", "start_pos": 132, "end_pos": 166, "type": "TASK", "confidence": 0.8985413908958435}]}, {"text": "We preformed syntactic parsing with a publicly available Japanese parser, KNP 4 . The number of negative samples was 5, and the number of epochs was 10.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7495290637016296}]}, {"text": "In the model training described in Section 4.3, the dimensions of both embeddings for predicates/arguments and hidden layer were set to 100.", "labels": [], "entities": []}, {"text": "The number of epochs was set to 20, following the base model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test set statistics of the number of argu- ments.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results on the KWDLC corpus.", "labels": [], "entities": [{"text": "KWDLC corpus", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.8887175917625427}]}]}