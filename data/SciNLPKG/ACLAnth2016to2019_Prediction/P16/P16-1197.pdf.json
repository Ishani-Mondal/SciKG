{"title": [{"text": "Evaluating Sentiment Analysis in the Context of Securities Trading", "labels": [], "entities": [{"text": "Evaluating Sentiment Analysis in the Context of Securities Trading", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.680597679482566}]}], "abstractContent": [{"text": "There are numerous studies suggesting that published news stories have an important effect on the direction of the stock market, its volatility, the volume of trades, and the value of individual stocks mentioned in the news.", "labels": [], "entities": []}, {"text": "There is even some published research suggesting that automated sentiment analysis of news documents , quarterly reports, blogs and/or twit-ter data can be productively used as part of a trading strategy.", "labels": [], "entities": [{"text": "sentiment analysis of news documents", "start_pos": 64, "end_pos": 100, "type": "TASK", "confidence": 0.8957309722900391}]}, {"text": "This paper presents just such a family of trading strategies, and then uses this application to reexamine some of the tacit assumptions behind how sentiment analyzers are generally evaluated , in spite of the contexts of their application.", "labels": [], "entities": [{"text": "sentiment analyzers", "start_pos": 147, "end_pos": 166, "type": "TASK", "confidence": 0.8460899889469147}]}, {"text": "This discrepancy comes at a cost.", "labels": [], "entities": []}], "introductionContent": [{"text": "The proliferation of opinion-rich text on the World Wide Web, which includes anything from product reviews to political blog posts, led to the growth of sentiment analysis as a research field more than a decade ago.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.94435915350914}]}, {"text": "The market need to quantify opinions expressed in social media and the blogosphere has provided a great opportunity for sentiment analysis technology to make an impact in many sectors, including the financial industry, in which interest in automatically detecting news sentiment in order to inform trading strategies extends back at least 10 years.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7953004240989685}]}, {"text": "In this case, sentiment takes on a slightly different meaning; positive sentiment is not the emotional and subjective use of laudatory language.", "labels": [], "entities": []}, {"text": "Rather, a news article that contains positive sentiment is optimistic about the future financial prospects of a company.", "labels": [], "entities": []}, {"text": "experimented with news sentiment to inform simple market neutral trading algorithms, and produced an impressive maximum yearly return of around 30% -even more when using sentiment from blogs and twitter data.", "labels": [], "entities": []}, {"text": "They did so, however, without an appropriate baseline, making it very difficult to appreciate the significance of this number.", "labels": [], "entities": []}, {"text": "Using a very standard, and in fact somewhat dated sentiment analyzer, we are regularly able to garner annualized returns over twice that percentage, and in a manner that highlights two of the better design decisions that made, viz., (1) their decision to trade based upon numerical SVM scores rather than upon discrete positive or negative sentiment classes, and (2) their decision to go long (resp., short) in then best-(worst-) ranking securities rather than to treat all positive (negative) securities equally.", "labels": [], "entities": []}, {"text": "On the other hand, we trade based upon the raw SVM score itself, rather than its relative rank within a basket of other securities as did, and we experimentally tune a threshold for that score that determines whether to go long, neutral or short.", "labels": [], "entities": []}, {"text": "We sampled our stocks for both training and evaluation in two runs, one without survivor bias, the tendency for long positions in stocks that are publicly traded as of the date of the experiment to pay better using historical trading data than long positions in random stocks sampled on the trading days themselves.", "labels": [], "entities": [{"text": "survivor", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9725372195243835}]}, {"text": "Most of the evaluations of sentiment-based trading either unwittingly adopt this bias, or do not need to address it because their returns are computed over very brief historical periods.", "labels": [], "entities": []}, {"text": "We also provide appropriate trading baselines as well as Sharpe ratios to attempt to quantify the relative risk inherent to our experimental strategies.", "labels": [], "entities": [{"text": "Sharpe ratios", "start_pos": 57, "end_pos": 70, "type": "METRIC", "confidence": 0.9783864617347717}]}, {"text": "As tacitly assumed by most of the work on this subject, our trading strategy is not portfolio-limited, and our returns are calculated on a percentage basis with theoretical, commission-free trades.", "labels": [], "entities": []}, {"text": "It is important to understand at the outset, however, that the purpose of this research was not to beat returns (although we have), nor merely to conduct the first properly controlled, sufficiently explicit, scientific test of the descriptive hypothesis that sentiment analysis is of benefit to securities trading (although, to our knowledge, we did).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 259, "end_pos": 277, "type": "TASK", "confidence": 0.8845798671245575}, {"text": "securities trading", "start_pos": 295, "end_pos": 313, "type": "TASK", "confidence": 0.7071790993213654}]}, {"text": "The main purpose of this study was in fact to reappraise the evaluation standards used by the sentiment analysis community.", "labels": [], "entities": [{"text": "sentiment analysis community", "start_pos": 94, "end_pos": 122, "type": "TASK", "confidence": 0.9260046680768331}]}, {"text": "It is not at all uncommon within this community to evaluate a sentiment analyzer with a variety of classification accuracy or hypothesis testing scores such as F-measures, SARs, kappas or Krippendorf alphas derived from human-subject annotationseven when more extensional measures are available, such as actual market returns from historical data in the case of securities trading.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8752878904342651}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.5530828237533569}, {"text": "F-measures", "start_pos": 160, "end_pos": 170, "type": "METRIC", "confidence": 0.99179607629776}, {"text": "SARs", "start_pos": 172, "end_pos": 176, "type": "METRIC", "confidence": 0.8661506175994873}]}, {"text": "With Hollywood films, another popular domain for automatic sentiment analysis, one might refer to box-office returns or the number of award nominations that a film receives rather than to its star-rankings on review websites where pile-on and confirmation biases are widely known to be rampant.", "labels": [], "entities": [{"text": "automatic sentiment analysis", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.6826028525829315}]}, {"text": "Are the opinions of human judges, paid or unpaid, a sufficient proxy for the business cases that actually drive the demand for sentiment analyzers?", "labels": [], "entities": [{"text": "sentiment analyzers", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.9028778672218323}]}, {"text": "We regret to report that they do not seem to be.", "labels": [], "entities": []}, {"text": "As a case study to demonstrate this point (Section 4.3), we exhibit one particular modification to our experimental financial sentiment analyzer that, when evaluated against an evaluation test set sampled from the same pool of human-subject annotations as the analyzer's training data, returns poorer performance, but when evaluated against actual market returns, yields better performance.", "labels": [], "entities": []}, {"text": "This should worry any researcher who relies on classification accuracies, because the improvements that they report, whether due to better feature selection or different pattern recognition algorithms, may in fact not be improvements at all.", "labels": [], "entities": []}, {"text": "Differences in the amount or degree of improvement might arguably be rescalable, but Section 4.3 shows that such intrinsic measures are not even accurate up to a determination of the delta's sign.", "labels": [], "entities": []}, {"text": "On the other hand, the results reported here should not be construed as an indictment of sentiment analysis as a technology or its potential application.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.937254399061203}]}, {"text": "In fact, one of our baselines alternatively attempts to train the same classifier directly on market returns, and the experimental approach handily beats that, too.", "labels": [], "entities": []}, {"text": "It is important to train on human-annotated sentiments, but then it is equally important to tune, and eventually evaluate, on an empirically grounded task-specific measure, such as market returns.", "labels": [], "entities": []}, {"text": "This paper thus presents, to our knowledge, the first real proof that sentiment is worth analyzing in this or any other domain.", "labels": [], "entities": []}, {"text": "A likely machine-learning explanation for this experimental result is that whenever two unbiased estimators are pitted against each other, they often result in an improved combined performance because each acts as a regularizer against the other.", "labels": [], "entities": []}, {"text": "If true, this merely attests to the relative independence of task-based and human-annotated knowledge sources.", "labels": [], "entities": []}, {"text": "A more HCI-oriented view, however, would argue that direct human-subject annotations are highly problematic unless the annotations have been elicited in manner that is ecologically valid.", "labels": [], "entities": []}, {"text": "When human subjects are paid to annotate quarterly reports or business news, they are paid regardless of the quality of their annotations, the quality of their training, or even their degree of comprehension of what they are supposed to be doing.", "labels": [], "entities": []}, {"text": "When human subjects post film reviews on web-sites, they are participating in a cultural activity in which the quality of the film under consideration is only one factor.", "labels": [], "entities": []}, {"text": "These sources of annotation have not been properly controlled in previous experiments on sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.9412727355957031}]}, {"text": "Regardless of the explanation, this is a lesson that applies to many more areas of NLP than just sentiment analysis, and to far more recent instances of sentiment analysis than the one that we based our experiments on here.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.905377596616745}, {"text": "sentiment analysis", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.9062886238098145}]}, {"text": "Indeed, we chose sentiment analysis because this is an area that can set a higher standard; it has the rightsize for an NLP component to be embedded in real applications and to be evaluated properly.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9660213887691498}]}, {"text": "This is noteworthy because it is challenging to explain why recent publications in sentiment analysis research would so dramatically increase the value that they assign to sentence-level sentiment scoring algorithms based on syntactically compositional derivations of \"good-for/ bad-for\" annotation, when statistical parsing itself has spent the last twenty-five years staggering through a linguistically induced delirium as it attempts to document any of its putative advances without recourse to clear empirical evidence that PTB-style syntactic derivations area reliable approximation of seman-tic content or structure.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.9304253160953522}, {"text": "sentence-level sentiment scoring", "start_pos": 172, "end_pos": 204, "type": "TASK", "confidence": 0.648095945517222}, {"text": "statistical parsing", "start_pos": 305, "end_pos": 324, "type": "TASK", "confidence": 0.7058568894863129}]}, {"text": "We submit, in light of our experience with the present study, that the most crucial obstacle facing the state of the art in sentiment analysis is not a granularity problem, nor a pattern recognition problem, but an evaluation problem.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.9700874388217926}, {"text": "pattern recognition", "start_pos": 179, "end_pos": 198, "type": "TASK", "confidence": 0.7939023375511169}]}, {"text": "Those evaluations must be task-specific to be reliable, and sentiment analysis, in spite of our careless use of the term in the NLP community, is not a task.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.9377042651176453}]}, {"text": "Stock trading is a task -one of many in which a sentiment analyzer is a potentially useful component.", "labels": [], "entities": [{"text": "Stock trading", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6978619545698166}, {"text": "sentiment analyzer", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8707061409950256}]}, {"text": "This paper provides an example of how to test that utility.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments of this section, we will evaluate an entire trading strategy, which includes the sentiment analyzer and the particulars of the trading algorithm itself.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.7400263249874115}]}, {"text": "The purpose of these experiments is to refine the trading strategy itself and so the sentiment analyzer will beheld constant.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8547340929508209}]}, {"text": "In Section 4.3, we will hold the trading strategy constant, and instead vary the document representation features in the underlying sentiment analyzer.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.7249386608600616}]}, {"text": "In all three experiments, we compare the perposition returns of the following four standard strategies, where the number of days for which a position is held remains constant: 1.", "labels": [], "entities": []}, {"text": "The momentum strategy computes the price of the stock h days ago, where h is the holding period.", "labels": [], "entities": []}, {"text": "Then, it goes long for h days if the previous price is lower than the current price.", "labels": [], "entities": []}, {"text": "2. The S&P strategy simply goes long on the S&P 500 for the holding period.", "labels": [], "entities": [{"text": "S&P", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.6687830289204916}, {"text": "S&P 500", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9382797181606293}]}, {"text": "This strategy completely ignores the stock in question and the news about it.", "labels": [], "entities": []}, {"text": "3. The oracle S&P strategy computes the value of the S&P 500 index h days into the future.", "labels": [], "entities": [{"text": "S&P 500 index h", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.8324361344178518}]}, {"text": "If the future value is greater than the current day's value, then it goes long on the S&P 500 index.", "labels": [], "entities": [{"text": "S&P 500 index", "start_pos": 86, "end_pos": 99, "type": "DATASET", "confidence": 0.907174801826477}]}, {"text": "Otherwise, it goes short.", "labels": [], "entities": []}, {"text": "4. The oracle strategy computes the value of the stock h days into the future.", "labels": [], "entities": []}, {"text": "If the future value is greater than the current day's value, then it goes long on the stock.", "labels": [], "entities": []}, {"text": "Otherwise, it goes short.", "labels": [], "entities": []}, {"text": "The oracle and oracle S&P strategies are included as toplines to determine how close the experimental strategies come to ones with perfect knowledge of the future.", "labels": [], "entities": []}, {"text": "\"Market-trained\" is the same as \"experimental\" attest time, but trains the sentiment analyzer on the market return of the stock in question for h days following a training article's publication, rather than the article's annotation.", "labels": [], "entities": []}, {"text": "Given a news document fora publicly traded company, the trading agent first computes the sentiment class of the document.", "labels": [], "entities": []}, {"text": "If the sentiment is positive, the agent goes long on the stock on the date the news is released; if negative, it goes short.: Returns and Sharpe ratios for the Experimental, baseline and topline trading strategies over 30, 5, 3, and 1 day(s) holding periods.", "labels": [], "entities": [{"text": "Returns", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.9892153143882751}, {"text": "Sharpe", "start_pos": 138, "end_pos": 144, "type": "METRIC", "confidence": 0.8006694316864014}]}, {"text": "All trades are made based on the adjusted closing price on this date.", "labels": [], "entities": []}, {"text": "We evaluate the performance of this strategy using four different holding periods: 30, 5, 3, and 1 day(s).", "labels": [], "entities": []}, {"text": "The returns and Sharpe ratios are presented in for the four different holding periods and the five different trading strategies.", "labels": [], "entities": [{"text": "returns", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9720699787139893}, {"text": "Sharpe ratios", "start_pos": 16, "end_pos": 29, "type": "METRIC", "confidence": 0.8725929260253906}]}, {"text": "The Sharpe ratio is a return-to-risk ratio, with a high value indicating good return for relatively low risk.", "labels": [], "entities": [{"text": "Sharpe ratio", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9863970875740051}]}, {"text": "The Sharpe ratio is calculated as: where Ra is the return of a single asset and Rb is the risk-free return of a 10-year U.S. Treasury note.", "labels": [], "entities": [{"text": "Sharpe ratio", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9842576682567596}, {"text": "Ra", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9780722856521606}, {"text": "Rb", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9594040513038635}]}, {"text": "The returns from this experimental trading system are fairly low, although they do beat the baselines.", "labels": [], "entities": []}, {"text": "A one-way ANOVA test among the experimental, momentum and S&P strategies using the percent returns from the individual trades yields p values of 0.06493, 0.08162, 0.1792, and 0.4164, respectively, thus failing to reject the null hypothesis that the returns are not significantly higher.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.6422340869903564}]}, {"text": "3: Percent returns for 1 day holding period versus market capitalization of the traded stocks.", "labels": [], "entities": []}, {"text": "Furthermore, the means and medians of all three trading strategies are approximately the same and centred around 0.", "labels": [], "entities": []}, {"text": "The standard deviations of the experimental strategy and the momentum strategy are nearly identical, differing only in the thousandths digit.", "labels": [], "entities": []}, {"text": "The standard deviations for the S&P strategy differ from the other two strategies due to the fact that the strategy buys and sells the entire S&P 500 index and not the individual stocks described in the news articles.", "labels": [], "entities": [{"text": "S&P strategy", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.7382613644003868}, {"text": "S&P 500 index", "start_pos": 142, "end_pos": 155, "type": "DATASET", "confidence": 0.8450603723526001}]}, {"text": "There is, in fact, no convincing evidence that discrete sentiment class leads to an improved trading strategy from this or any other study with which we are familiar, based on their published details.", "labels": [], "entities": []}, {"text": "One may note, however, that the returns from the experimental strategy have slightly higher Sharpe ratios than either of the baselines.", "labels": [], "entities": [{"text": "Sharpe", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9914761185646057}]}, {"text": "One may also note that using a sentiment analyzer mostly beats training directly on market data.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8966439962387085}]}, {"text": "This vindicates using sentiment annotation as an information source.", "labels": [], "entities": []}, {"text": "shows the market capitalizations of each individual trade's companies plotted against their percent return with a 1 day holding period.", "labels": [], "entities": []}, {"text": "The correlation between the two variables is not significant.", "labels": [], "entities": []}, {"text": "Returns for the other holding periods are similarly dispersed.", "labels": [], "entities": []}, {"text": "The importance of having good baselines is demonstrated by the fact that when we annualize our returns for the 3-day holding period, we get 70.086%.", "labels": [], "entities": []}, {"text": "This number appears very high, but the annualized return from the momentum strategy is were unlikely to have been generated by chance from a normal distribution centred at zero.", "labels": [], "entities": []}, {"text": "70.066% 4 , which is not significantly lower.", "labels": [], "entities": [{"text": "4", "start_pos": 8, "end_pos": 9, "type": "METRIC", "confidence": 0.9720463156700134}]}, {"text": "shows the percent change in share value plotted against the raw SVM score for the different holding periods.", "labels": [], "entities": []}, {"text": "We can see a weak correlation between the two.", "labels": [], "entities": []}, {"text": "For the 30 days, 5 days, 3 days, and 1 day holding periods, the correlations are 0.017, 0.16, 0.16, and 0.16, respectively.", "labels": [], "entities": []}, {"text": "The line of best fit is shown.", "labels": [], "entities": [{"text": "fit", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9399973750114441}]}, {"text": "This prompts our next experiment.", "labels": [], "entities": []}, {"text": "Before, we labelled documents as positive (negative) when the score was above (below) 0, because 0 was the decision boundary.", "labels": [], "entities": []}, {"text": "But 0 might not be the best threshold, \u03b8, for high returns.", "labels": [], "entities": []}, {"text": "To determine \u03b8, we divided the evaluation dataset, i.e. the dataset with news articles dated on or after March 10, 2005, into two folds having an equal number of documents with positive and negative sentiment.", "labels": [], "entities": []}, {"text": "We used the first fold to determine \u03b8 and traded using the data from the second fold and \u03b8.", "labels": [], "entities": []}, {"text": "For every news article, if the SVM score for that article is above (below) \u03b8, then we go long (short) on the appropriate stock on the day the article was released.", "labels": [], "entities": []}, {"text": "A separate theta was determined for each holding period.", "labels": [], "entities": []}, {"text": "We varied \u03b8 from \u22121 to 1 in increments of 0.1.", "labels": [], "entities": []}, {"text": "Using this method, we were able to obtain significantly higher returns.", "labels": [], "entities": []}, {"text": "In order of 30, 5, 3, and 1 day holding periods, the returns were 0.057%, 1.107%, 1.238%, and 0.745% (p < 0.001 in every case).", "labels": [], "entities": []}, {"text": "This is a large improvement over the previous returns, as they are average per-position figures.", "labels": [], "entities": []}, {"text": "For every news item classified, SVM outputs a score.", "labels": [], "entities": []}, {"text": "For a binary SVM with a linear kernel function f , given some feature vector x, f (x) can be viewed as the signed distance of x from the decision boundary.", "labels": [], "entities": []}, {"text": "It is then possibly justified to interpret raw SVM scores as degrees to which an article is positive or negative.", "labels": [], "entities": []}, {"text": "As in the previous section, we separate the evaluation set into the same two folds, only now we The momentum strategy has a different number of possible trades in any actual calendar year because it is a function of the holding period.", "labels": [], "entities": []}, {"text": "Training directly on market data, by comparison, yields -0.258%, -0.282%, -0.036% and -0.388%, respectively.", "labels": [], "entities": []}, {"text": "use two thresholds, \u03b8 \u2265 \u03b6.", "labels": [], "entities": []}, {"text": "We will go long when the SVM score is above \u03b8, abstain when the SVM score is between \u03b8 and \u03b6, and go short when the SVM score is below \u03b6.", "labels": [], "entities": []}, {"text": "This is a strict generalization of the above experiment, in which \u03b6 = \u03b8.", "labels": [], "entities": []}, {"text": "For convenience, we will assume in this section that \u03b6 = \u2212\u03b8, leaving us again with one parameter to estimate.", "labels": [], "entities": []}, {"text": "We again vary \u03b8 from 0 to 1 in increments of 0.1.", "labels": [], "entities": [{"text": "\u03b8", "start_pos": 14, "end_pos": 15, "type": "METRIC", "confidence": 0.957342267036438}]}, {"text": "shows the returns as a function of \u03b8 for each holding period on the development dataset.", "labels": [], "entities": [{"text": "development dataset", "start_pos": 68, "end_pos": 87, "type": "DATASET", "confidence": 0.7360330522060394}]}, {"text": "If we increased the upper bound on \u03b8 to be greater than 1, then there would be too few trading examples (less than 10) to reliably calculate the Sharpe ratio.", "labels": [], "entities": [{"text": "Sharpe ratio", "start_pos": 145, "end_pos": 157, "type": "METRIC", "confidence": 0.9836290180683136}]}, {"text": "Using this method with \u03b8 = 1, we were able to obtain even higher returns: 3.843%, 1.851%, 1.691, and 2.251% for the 30, 5, 3, and 1 day holding periods, versus 0.057%, 1.107%, 1.238%, and 0.745% in the second taskbased experiment.", "labels": [], "entities": []}, {"text": "In our final experiment, let us now hold the trading strategy fixed (at the third one, with safety zones) and turn to the underlying sentiment analyzer.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.7769559025764465}]}, {"text": "With a good trading strategy in place, it is clearly possible to vary some aspect of the sentiment analyzer in order to determine its best setting in this context.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.8330114483833313}]}, {"text": "We will measure both market return and classifier accuracy to determine whether they agree.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9733032584190369}]}, {"text": "Is the latter a suitable proxy for the former?", "labels": [], "entities": []}, {"text": "Indeed, we may hope that classifier accuracy will be more portable to other possible tasks, but then it must at least correlate well with task-based performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9588392972946167}]}, {"text": "In addition to evaluating those feature sets attempted in Section 3.2, we now hypothesize that the passive voice maybe useful to emphasize in our representations, as the existential passive can be used to evade responsibility.", "labels": [], "entities": []}, {"text": "So we add to the  BM25 weighted vector the counts of word tokens ending in \"n\" or \"d\" as well as the total count of every conjugated form of the copular verb: \"be\", \"is\", \"am\", \"are\", \"were\", \"was\", and \"been\".", "labels": [], "entities": [{"text": "BM25", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.8747203946113586}]}, {"text": "These three features are superficial indicators of the passive voice.", "labels": [], "entities": []}, {"text": "Clearly, we could have used a part-of-speech tagger to detect the passive voice more reliably, but we are more interested herein how well our task-based evaluation will correspond to a more customary classifier-accuracy evaluation, rather than finding the world's best indicators of the passive voice.", "labels": [], "entities": []}, {"text": "presents returns obtained from these 6 feature sets.", "labels": [], "entities": []}, {"text": "The feature set with BM25-weighted term frequencies plus the number of copulars and tokens ending in \"n\", \"d\" (bm25 freq dnc) yields higher returns than any other representation attempted on the 5, 3, and 1 day holding periods, and the second-highest on the 30 days holding period.", "labels": [], "entities": []}, {"text": "But it has the worst classification accuracy by far: a full 18 percentage points below term presence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9599144458770752}]}, {"text": "This is a very compelling illustration of how misleading an intrinsic evaluation can be.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average 10-fold cross validation ac- curacy of the sentiment classifier using different  term-frequency weighting schemes. The same  folds were used in all feature sets.", "labels": [], "entities": []}, {"text": " Table 2: Returns and Sharpe ratios for the Experi- mental, baseline and topline trading strategies over  30, 5, 3, and 1 day(s) holding periods.", "labels": [], "entities": [{"text": "Returns and Sharpe ratios", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.7733167931437492}]}, {"text": " Table 3: Sentiment classification accuracy (aver- age 10-fold cross-validation) and trade returns of  different feature sets and term frequency weight- ing schemes in Exp. 3. The same folds were  used for the different representations. The non- annualized returns are presented in columns 3-6.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8871257603168488}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.8606584668159485}, {"text": "Exp", "start_pos": 168, "end_pos": 171, "type": "DATASET", "confidence": 0.9096221327781677}]}]}