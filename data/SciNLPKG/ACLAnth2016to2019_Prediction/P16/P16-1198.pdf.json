{"title": [{"text": "Edge-Linear First-Order Dependency Parsing with Undirected Minimum Spanning Tree Inference", "labels": [], "entities": [{"text": "Edge-Linear First-Order Dependency Parsing", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.4488614797592163}]}], "abstractContent": [{"text": "The run time complexity of state-of-the-art inference algorithms in graph-based dependency parsing is super-linear in the number of input words (n).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7241238057613373}]}, {"text": "Recently, pruning algorithms for these models have shown to cut a large portion of the graph edges, with minimal damage to the resulting parse trees.", "labels": [], "entities": []}, {"text": "Solving the inference problem in run time complexity determined solely by the number of edges (m) is hence of obvious importance.", "labels": [], "entities": []}, {"text": "We propose such an inference algorithm for first-order models, which encodes the problem as a minimum spanning tree (MST) problem in an undirected graph.", "labels": [], "entities": []}, {"text": "This allows us to utilize state-of-the-art undirected MST algorithms whose run time is O(m) at expectation and with a very high probability.", "labels": [], "entities": [{"text": "MST", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9547303318977356}, {"text": "O", "start_pos": 87, "end_pos": 88, "type": "METRIC", "confidence": 0.9916885495185852}]}, {"text": "A directed parse tree is then inferred from the undirected MST and is subsequently improved with respect to the directed parsing model through local greedy updates, both steps running in O(n) time.", "labels": [], "entities": []}, {"text": "In experiments with 18 languages, a variant of the first-order MSTParser (McDonald et al., 2005b) that employs our algorithm performs very similarly to the original parser that runs an O(n 2) directed MST inference.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsers are major components of a large number of NLP applications.", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8126718401908875}]}, {"text": "As application models are applied to constantly growing amounts of data, efficiency becomes a major consideration.", "labels": [], "entities": []}, {"text": "In graph-based dependency parsing models, given an n word sentence and a model order k, the run time of exact inference is O(n 3 ) fork = 1 and O(n k+1 ) fork > 1 in the projective case).", "labels": [], "entities": [{"text": "graph-based dependency parsing", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.7190850973129272}]}, {"text": "In the non-projective case it is O(n 2 ) fork = 1 and NP-hard fork \u2265 2 (.", "labels": [], "entities": [{"text": "O", "start_pos": 33, "end_pos": 34, "type": "METRIC", "confidence": 0.9570293426513672}]}, {"text": "Consequently, a number of approximated parsers have been introduced, utilizing a variety of techniques: the Eisner algorithm), belief propagation (, dual decomposition () and multi-commodity flows).", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.8478772938251495}]}, {"text": "The run time of all these approximations is superlinear inn.", "labels": [], "entities": []}, {"text": "Recent pruning algorithms for graph-based dependency parsing) have shown to cut a very large portion of the graph edges, with minimal damage to the resulting parse trees.", "labels": [], "entities": [{"text": "graph-based dependency parsing", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6756998797257742}]}, {"text": "For example, demonstrated that a single O(n) pass of vinepruning (Eisner and) can preserve > 98% of the correct edges, while ruling out > 86% of all possible edges.", "labels": [], "entities": []}, {"text": "Such results give strong motivation to solving the inference problem in a run time complexity that is determined solely by the number of edges (m).", "labels": [], "entities": []}, {"text": "In this paper we propose to formulate the inference problem in first-order (arc-factored) dependency parsing as a minimum spanning tree (MST) problem in an undirected graph.", "labels": [], "entities": [{"text": "arc-factored) dependency parsing", "start_pos": 76, "end_pos": 108, "type": "TASK", "confidence": 0.7449193000793457}]}, {"text": "Our formulation allows us to employ state-of-the-art algorithms for the MST problem in undirected graphs, whose run time depends solely on the number of edges in the graph.", "labels": [], "entities": [{"text": "MST problem", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.9507391154766083}]}, {"text": "Importantly, a parser that employs our undirected inference algorithm can generate all possible trees, projective and non-projective.", "labels": [], "entities": []}, {"text": "Particularly, the undirected MST problem ( \u00a7 2) has a randomized algorithm which is O(m) at expectation and with a very high probability), as well as an O(m \u00b7 \u03b1(m, n)) worst-case deterministic algorithm, where \u03b1(m, n) is a certain natural inverse of Ackermann's function.", "labels": [], "entities": [{"text": "MST problem", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.9044602811336517}, {"text": "O", "start_pos": 84, "end_pos": 85, "type": "METRIC", "confidence": 0.9732455611228943}, {"text": "O", "start_pos": 153, "end_pos": 154, "type": "METRIC", "confidence": 0.9432654976844788}]}, {"text": "As the inverse of Ackermann's function grows extremely slowly 3 the deterministic algorithm is in practice linear in m ( \u00a7 3).", "labels": [], "entities": []}, {"text": "In the rest of the paper we hence refer to the run time of these two algorithms as practically linear in the number of edges m.", "labels": [], "entities": []}, {"text": "Our algorithm has four steps ( \u00a7 4).", "labels": [], "entities": []}, {"text": "First, it encodes the first-order dependency parsing inference problem as an undirected MST problem, in up to O(m) time.", "labels": [], "entities": [{"text": "dependency parsing inference problem", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.819024384021759}, {"text": "O", "start_pos": 110, "end_pos": 111, "type": "METRIC", "confidence": 0.9543648958206177}]}, {"text": "Then, it computes the MST of the resulting undirected graph.", "labels": [], "entities": [{"text": "MST", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.5897566080093384}]}, {"text": "Next, it infers a unique directed parse tree from the undirected MST.", "labels": [], "entities": []}, {"text": "Finally, the resulting directed tree is greedily improved with respect to the directed parsing model.", "labels": [], "entities": []}, {"text": "Importantly, the last two steps take O(n) time, which makes the total run time of our algorithm O(m) at expectation and with very high probability.", "labels": [], "entities": [{"text": "O(n) time", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9126564264297485}]}, {"text": "We integrated our inference algorithm into the first-order parser of) and compared the resulting parser to the original parser which employs the Chu-Liu-Edmonds algorithm) for inference.", "labels": [], "entities": []}, {"text": "CLE is the most efficient exact inference algorithm for graph-based first-order nonprojective parsers, running at O(n 2 ) time.", "labels": [], "entities": []}, {"text": "jointly performed in O(n) steps.", "labels": [], "entities": [{"text": "O", "start_pos": 21, "end_pos": 22, "type": "METRIC", "confidence": 0.9682004451751709}]}, {"text": "We therefore do not include initial graph construction and pruning in our complexity computations.", "labels": [], "entities": [{"text": "initial graph construction", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.7097471753756205}]}, {"text": "3 \u03b1(m, n) is less than 5 for any practical input sizes (m, n).", "labels": [], "entities": []}, {"text": "The output dependency tree contains exactly n\u22121 edges, therefore m \u2265 n \u2212 1, which makes O(m) + O(n) = O(m).", "labels": [], "entities": []}, {"text": "5 CLE has faster implementations: O(m+nlogn) ( as well as O(mlogn) for sparse graphs, both are super-linear inn for connected graphs.", "labels": [], "entities": [{"text": "O", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9617432951927185}, {"text": "O", "start_pos": 58, "end_pos": 59, "type": "METRIC", "confidence": 0.9721273183822632}]}, {"text": "We reWe experimented ( \u00a7 5) with 17 languages from the CoNLL 2006 and 2007 shared tasks on multilingual dependency parsing ( and in three English setups.", "labels": [], "entities": [{"text": "CoNLL 2006", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.9683670103549957}, {"text": "multilingual dependency parsing", "start_pos": 91, "end_pos": 122, "type": "TASK", "confidence": 0.6089923481146494}]}, {"text": "Our results reveal that the two algorithms perform very similarly.", "labels": [], "entities": []}, {"text": "While the averaged unlabeled attachment accuracy score (UAS) of the original parser is 0.97% higher than ours, in 11 of 20 test setups the number of sentences that are better parsed by our parser is larger than the number of sentences that are better parsed by the original parser.", "labels": [], "entities": [{"text": "unlabeled attachment accuracy score (UAS)", "start_pos": 19, "end_pos": 60, "type": "METRIC", "confidence": 0.755114517041615}]}, {"text": "Importantly, in this work we present an edge-linear first-order dependency parser which achieves similar accuracy to the existing one, making it an excellent candidate to be used for efficient MST computation in k-best trees methods, or to be utilized as an inference/initialization subroutine as apart of more complex approximation frameworks such as belief propagation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9957239627838135}, {"text": "MST computation", "start_pos": 193, "end_pos": 208, "type": "TASK", "confidence": 0.9469297528266907}, {"text": "belief propagation", "start_pos": 352, "end_pos": 370, "type": "TASK", "confidence": 0.7742464542388916}]}, {"text": "In addition, our model produces a different solution compared to the existing one (see), paving the way for using methods such as dual decomposition to combine these two models into a superior one.", "labels": [], "entities": [{"text": "dual decomposition", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.7768545746803284}]}, {"text": "Undirected inference has been recently explored in the context of transition based parsing, with the motivation of preventing the propagation of erroneous early edge directionality decisions to subsequent parsing decisions.", "labels": [], "entities": [{"text": "transition based parsing", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.5649316509564718}]}, {"text": "Yet, to the best of our knowledge this is the first paper to address undirected inference for graph based dependency parsing.", "labels": [], "entities": [{"text": "graph based dependency parsing", "start_pos": 94, "end_pos": 124, "type": "TASK", "confidence": 0.6327021047472954}]}, {"text": "Our motivation and algorithmic challenges are substantially different from those of the earlier transition based work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experimental setup We evaluate four models: (a) The original directed parser (D-MST,); (b) Our undirected MST parser with undirected features and with the local enhancement procedure (U-MST-uf-lep); 11 (c) Our undirected MST parser with undirected features but without the local enhancement procedure (U-MST-uf); and (d) Our undirected MST parser with directed features (U-MST-df).", "labels": [], "entities": []}, {"text": "All models are implemented within the MSTParser code . The MSTParser does not prune its input graphs.", "labels": [], "entities": [{"text": "MSTParser code", "start_pos": 38, "end_pos": 52, "type": "DATASET", "confidence": 0.9444236159324646}, {"text": "MSTParser", "start_pos": 59, "end_pos": 68, "type": "DATASET", "confidence": 0.9442939758300781}]}, {"text": "To demonstrate the value of undirected parsing for sparse input graphs, we implemented the lengthdictionary pruning strategy which eliminates all edges longer than the maximum length observed for each directed head-modifier POS pair in the training data.", "labels": [], "entities": []}, {"text": "An undirected edg\u00ea (u, v) is pruned if f both directed edges (u, v) and (v, u) are to be pruned according to the pruning method.", "labels": [], "entities": []}, {"text": "To estimate the accuracy/graph-size tradeoff provided by undirected parsing (models (b)-(d)), we apply the pruning strategy only to these models leaving the the D-MST model (model (a)) untouched.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9989569187164307}]}, {"text": "This way D-MST runs on a complete directed graph with n 2 edges.", "labels": [], "entities": []}, {"text": "Our models were developed in a monolingual setup: training on sections 2-21 of WSJ PTB () and testing on section 22.", "labels": [], "entities": [{"text": "WSJ PTB", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.925870954990387}]}, {"text": "The development phase was devoted to the various decisions detailed throughout this paper and to the tuning of the single hyperparameter: the number of times the local enhancement procedure is executed.", "labels": [], "entities": []}, {"text": "We tested the models in 3 English and 17 multilingual setups.", "labels": [], "entities": []}, {"text": "The English setups are: (a) PTB: training on sections 2-21 of the WSJ PTB and testing on its section 23; (b) GENIA: training with a random sample of 90% of the 4661 GENIA corpus () sentences and testing on the other 10%; and (c) QBank: a setup identical to (b) for the 3987 QuestionBank () sentences.", "labels": [], "entities": [{"text": "WSJ PTB", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9707189500331879}, {"text": "GENIA corpus", "start_pos": 165, "end_pos": 177, "type": "DATASET", "confidence": 0.8487829864025116}, {"text": "QuestionBank", "start_pos": 274, "end_pos": 286, "type": "DATASET", "confidence": 0.9124200344085693}]}, {"text": "Multilingual parsing was performed with the multilingual datasets of the CoNLL 2006 () and) shared tasks on multilingual dependency parsing, following their standard train/test split.", "labels": [], "entities": [{"text": "Multilingual parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7185207605361938}, {"text": "CoNLL 2006", "start_pos": 73, "end_pos": 83, "type": "DATASET", "confidence": 0.9589595794677734}, {"text": "multilingual dependency parsing", "start_pos": 108, "end_pos": 139, "type": "TASK", "confidence": 0.6133186221122742}]}, {"text": "Following previous work, punctuation was excluded from the evaluation.", "labels": [], "entities": []}, {"text": "Length-dictionary pruning reduces the number of undirected edges by 27.02% on average across our 20 setups (std = 11.02%, median = 23.85%), leaving an average of 73.98% of the edges in the undirected graph.", "labels": [], "entities": []}, {"text": "In 17 of 20 setups the reduction is above 20%.", "labels": [], "entities": [{"text": "reduction", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9631129503250122}]}, {"text": "Note that the number of edges in a complete directed graph is twice the number in its undirected counterpart.", "labels": [], "entities": []}, {"text": "Therefore, on average, the number of input edges in the pruned undirected models amounts to 73.98% 2 = 36.49% of the number of edges in the complete directed graphs.", "labels": [], "entities": []}, {"text": "In fact, every edge-related operation (such as feature extraction) in the undirected model is actually performed on half of the number of edges compared to the directed model, saving run-time not only in the MST-inference stage but in every stage involving these operations.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7518862187862396}]}, {"text": "In addition, some pruning methods, such as length-dictionary pruning (used  in this work) perform feature extraction only for existing (un-pruned) edges, meaning that any reduction in the number of edges also reduces feature extraction operations.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7418731153011322}, {"text": "feature extraction", "start_pos": 217, "end_pos": 235, "type": "TASK", "confidence": 0.7619144916534424}]}, {"text": "For each model we report the standard directed unlabeled attachment accuracy score (D-UAS).", "labels": [], "entities": [{"text": "accuracy score (D-UAS)", "start_pos": 68, "end_pos": 90, "type": "METRIC", "confidence": 0.8927153944969177}]}, {"text": "In addition, since this paper explores the value of undirected inference fora problem that is directed in nature, we also report the undirected unlabeled attachment accuracy score (U-UAS), hoping that these results will shed light on the differences between the trees generated by the different models.", "labels": [], "entities": [{"text": "undirected unlabeled attachment accuracy score (U-UAS)", "start_pos": 133, "end_pos": 187, "type": "METRIC", "confidence": 0.7231374382972717}]}, {"text": "While the directed MST parser (D-MST) is the best performing model across almost all test sets and evaluation measures, it outperforms our best model, U-MST-uf-lep, by a very small margin.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Directed/undirected UAS for the various parsing models of this paper.", "labels": [], "entities": []}, {"text": " Table 2: Top two lines (per language): percentage of sentences for which each of the models performs better than the other  according to the directed UAS. Bottom line (Oracle): Directed UAS of an oracle model that selects the parse tree of the best  performing model for each sentence. Improvement over the directed UAS score of D-MST is given in parenthesis.", "labels": [], "entities": []}]}