{"title": [{"text": "Bi-Transferring Deep Neural Networks for Domain Adaptation", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7414787709712982}]}], "abstractContent": [{"text": "Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs).", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9124583899974823}]}, {"text": "Due to the mismatch among different domains, a sentiment classifier trained in one domain may notwork well when directly applied to other domains.", "labels": [], "entities": []}, {"text": "Thus, domain adaptation for sentiment classification algorithms are highly desirable to reduce the domain discrepancy and manual labeling costs.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.9508706629276276}]}, {"text": "To address the above challenge, we propose a novel domain adaptation method, called Bi-Transferring Deep Neu-ral Networks (BTDNNs).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7348989844322205}]}, {"text": "The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also transfer the target domain examples to the source domain.", "labels": [], "entities": [{"text": "BTDNNs", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.8214015960693359}]}, {"text": "The linear transformation of BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner.", "labels": [], "entities": [{"text": "BTDNNs", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.7600188851356506}]}, {"text": "As a result, the transferred source domain is supervised and follows similar distribution as the target domain.", "labels": [], "entities": []}, {"text": "Therefore, any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in a target domain.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.9144625663757324}]}, {"text": "We conduct experiments on a benchmark composed of reviews of 4 types of Amazon products.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed approach significantly outperforms the several baseline methods, and achieves an accuracy which is competitive with the state-of-the-art method for domain adaptation .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9994747042655945}, {"text": "domain adaptation", "start_pos": 192, "end_pos": 209, "type": "TASK", "confidence": 0.7735775113105774}]}], "introductionContent": [{"text": "With the rise of social media (e.g., blogs and social networks etc.), more and more user generated sentiment data have been shared on the Web ().", "labels": [], "entities": []}, {"text": "They exist in the form of user reviews on shopping or opinion sites, in posts of blogs/questions or customer feedbacks.", "labels": [], "entities": []}, {"text": "This has created a surge of research in sentiment classification (or sentiment analysis), which aims to automatically determine the sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs, questions).", "labels": [], "entities": [{"text": "sentiment classification (or sentiment analysis)", "start_pos": 40, "end_pos": 88, "type": "TASK", "confidence": 0.8087710312434605}]}, {"text": "Machine learning algorithms have been proved promising and widely used for sentiment classification (.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.9763738811016083}]}, {"text": "However, the performance of these models relies on manually labeled training data.", "labels": [], "entities": []}, {"text": "In many practical cases, we may have plentiful labeled data in the source domain, but very few or no labeled data in the target domain with a different data distribution.", "labels": [], "entities": []}, {"text": "For example, we may have many labeled books reviews, but we are interested in detecting the polarity of electronics reviews.", "labels": [], "entities": []}, {"text": "Reviews for different products might have different vocabularies, thus classifiers trained on one domain often fail to produce satisfactory results when transferring to another domain.", "labels": [], "entities": []}, {"text": "This has motivated much research on cross-domain (domain adaptation) sentiment classification which transfers the knowledge from the source domain to the target domain (.", "labels": [], "entities": [{"text": "cross-domain (domain adaptation) sentiment classification", "start_pos": 36, "end_pos": 93, "type": "TASK", "confidence": 0.7506119566304343}]}, {"text": "Depending on whether the labeled data are available for the target domain, cross-domain sen-timent classification can be divided into two categories: supervised domain adaptation and unsupervised domain adaptation.", "labels": [], "entities": [{"text": "cross-domain sen-timent classification", "start_pos": 75, "end_pos": 113, "type": "TASK", "confidence": 0.6167044242223104}]}, {"text": "In scenario of supervised domain adaptation, labeled data is available in the target domain but the number is usually too small to train a good sentiment classifier, while in unsupervised domain adaptation only unlabeled data is available in the target domain, which is more challenging.", "labels": [], "entities": [{"text": "supervised domain adaptation", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.7295351624488831}]}, {"text": "This work focuses on the unsupervised domain adaptation problem of which the essence is how to employ the unlabeled data of target domain to guide the model learning from the labeled source domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7383045554161072}]}, {"text": "The fundamental challenge of cross-domain sentiment classification lies in that the source domain and the target domain have different data distribution.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.802506705125173}]}, {"text": "Recent work has investigated several techniques for alleviating the domain discrepancy: instance-weight adaptation) and feature representation adaptation (.", "labels": [], "entities": [{"text": "instance-weight adaptation", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.7065563052892685}, {"text": "feature representation adaptation", "start_pos": 120, "end_pos": 153, "type": "TASK", "confidence": 0.7983353932698568}]}, {"text": "The first kind of methods assume that some training data in the source domain are very useful for the target domain and these data can be used to train models for the target domain after re-weighting.", "labels": [], "entities": []}, {"text": "In contrast, feature representation approaches attempt to develop an adaptive feature representation that is effective in reducing the difference between domains.", "labels": [], "entities": [{"text": "feature representation", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7234114110469818}]}, {"text": "Recently, some efforts have been initiated on learning robust feature representations with deep neural networks (DNNs) in the context of crossdomain sentiment classification).", "labels": [], "entities": [{"text": "crossdomain sentiment classification", "start_pos": 137, "end_pos": 173, "type": "TASK", "confidence": 0.7306169271469116}]}, {"text": "proposed to learn robust feature representations with stacked denoising auto-encoders (SDAs).", "labels": [], "entities": []}, {"text": "Denoising auto-encoders are onelayer neural networks that are optimized to reconstruct input data from partial and random corruption.", "labels": [], "entities": []}, {"text": "These denoisers can be stacked into deep learning architectures.", "labels": [], "entities": []}, {"text": "The outputs of their intermediate layers are then used as input features for SVMs.", "labels": [], "entities": []}, {"text": "proposed a marginalized SDA (mSDA) that addressed the two crucial limitations of SDAs: high computational cost and lack of scalability to highdimensional features.", "labels": [], "entities": []}, {"text": "However, these methods learn the unified domain-invariable feature representations by combining the source domain data and that of the target domain data together, which cannot well characterize the domain-specific features as well as the commonality of domains.", "labels": [], "entities": []}, {"text": "To this end, we propose a Bi-Transferring Deep Neural Networks (BTDNNs) which can transfer the source domain examples to the target domain and also transfer the target domain examples to the source domain, as shown in.", "labels": [], "entities": []}, {"text": "In BTDNNs, the linear transformation makes the feasibility of transferring between domains, and the linear data reconstruction manner ensures the distribution consistency between the transferred domain and the desirable domain.", "labels": [], "entities": [{"text": "BTDNNs", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.7369237542152405}]}, {"text": "Specifically, our BTDNNs has one common encoder f c , two decoders g sand gt which can map an example to the source domain and the target domain respectively.", "labels": [], "entities": [{"text": "BTDNNs", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.8817547559738159}]}, {"text": "As a result, the source domain can be transferred to the target domain along with its sentiment label, and any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in the target domain, as the transferred source domain data share the similar distribution as the target domain.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 200, "end_pos": 224, "type": "TASK", "confidence": 0.9021929502487183}]}, {"text": "Experimental results show that the proposed approach significantly outperforms several baselines, and achieves an accuracy which is competitive with the state-of-the-art method for cross-domain sentiment classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.999434769153595}, {"text": "cross-domain sentiment classification", "start_pos": 181, "end_pos": 218, "type": "TASK", "confidence": 0.7755003770192465}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our proposed bi-transferring deep neural networks (BTDNNs).", "labels": [], "entities": []}, {"text": "Section 4 presents the experimental results.", "labels": [], "entities": []}, {"text": "In Section 5, we conclude with ideas for future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Amazon review statistics. This table de- picts the number of training, testing and unlabeled  reviews for each domain, as well as the portion of  negative training reviews of the data set.", "labels": [], "entities": []}]}