{"title": [{"text": "Easy Things First: Installments Improve Referring Expression Generation for Objects in Photographs", "labels": [], "entities": [{"text": "Installments Improve Referring Expression Generation", "start_pos": 19, "end_pos": 71, "type": "TASK", "confidence": 0.7482706785202027}]}], "abstractContent": [{"text": "Research on generating referring expressions has so far mostly focussed on \"one-shot reference\", where the aim is to generate a single, discriminating expression.", "labels": [], "entities": []}, {"text": "In interactive settings, however, it is not uncommon for reference to be established in \"installments\", where referring information is offered piecewise until success has been confirmed.", "labels": [], "entities": []}, {"text": "We show that this strategy can also be advantageous in technical systems that only have uncertain access to object attributes and categories.", "labels": [], "entities": []}, {"text": "We train a recently introduced model of grounded word meaning on a data set of REs for objects in images and learn to predict semantically appropriate expressions.", "labels": [], "entities": []}, {"text": "Ina human evaluation, we observe that users are sensitive to inadequate object names-which unfortunately are not unlikely to be generated from low-level visual input.", "labels": [], "entities": []}, {"text": "We propose a solution inspired from human task-oriented interaction and implement strategies for avoiding and repairing semantically inaccurate words.", "labels": [], "entities": []}, {"text": "We enhance a word-based REG with context-aware, referential installments and find that they substantially improve the refer-ential success of the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "A speaker who wants to refer to an object in a visual scene will try to produce a referring expression (RE) that (i) is semantically adequate, i.e. accurately describes the visual properties of the target referent, and (ii) is pragmatically and contextually appropriate, i.e. distinguishes the target from girl in front man on right anywhere brown: Example images and REs from the ReferIt corpus ( other objects in the scene but does not overload the listener with unnecessary information.", "labels": [], "entities": [{"text": "ReferIt corpus", "start_pos": 381, "end_pos": 395, "type": "DATASET", "confidence": 0.835442066192627}]}, {"text": "illustrates this with two examples from a corpus of REs collected from human subjects for objects in images ().", "labels": [], "entities": []}, {"text": "Research on referring expression generation (REG) has mostly focussed on (ii), modeling pragmatic adequacy in attribute selection tasks, using as input a fully specified, symbolic representation of the visual attributes of an object and its distractors in a scene ().", "labels": [], "entities": [{"text": "referring expression generation (REG)", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.8687161803245544}]}, {"text": "In this paper, we follow a more recent trend ( and investigate REG on real-world images.", "labels": [], "entities": [{"text": "REG", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.8963232040405273}]}, {"text": "In this setting, a low-level visual representation of an image (a scene) segmented into regions (objects), including the region of the target referent, constitutes the input.", "labels": [], "entities": []}, {"text": "This task is closely related to the recently very active field of image-to-text generation, where deep learning approaches have been used to directly map low-level visual input to natural language sentences, e.g. (. Similarly, we propose to cast REG on images as a word selection task.", "labels": [], "entities": [{"text": "image-to-text generation", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.7720893025398254}, {"text": "word selection task", "start_pos": 265, "end_pos": 284, "type": "TASK", "confidence": 0.7810621460278829}]}, {"text": "Thus, we base this work on a model of perceptually grounded word meaning, which associates words with classifiers that predict their semantic appropriateness given the low-level visual features of an object.", "labels": [], "entities": []}, {"text": "As our first contribution, we train this model on the ReferIt corpus () and define decoding mechanisms tailored to REG.", "labels": [], "entities": [{"text": "ReferIt corpus", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.8675118088722229}]}, {"text": "Large-scale recognition of objects and their attributes in images is still a non-trivial task.", "labels": [], "entities": [{"text": "Large-scale recognition of objects and their attributes in images", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.8292596009042528}]}, {"text": "Consequently, REG systems now face the challenge of dealing with semantically inadequate expressions.", "labels": [], "entities": []}, {"text": "For instance, in, the system might not precisely distinguish between manor woman and generate an inadequate, confusing RE like man in the middle.", "labels": [], "entities": [{"text": "RE", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9875352382659912}]}, {"text": "Therefore, we focus on evaluating our system in an object identification task with users, in contrast to previous approaches to REG on images (.", "labels": [], "entities": [{"text": "object identification task", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7804902096589407}]}, {"text": "In order to assess possible sources of misunderstanding more precisely, our set-up also introduces a restricted form of interaction: instead of measuring \"one-shot\" performance only, users have three trials for identifying a referent.", "labels": [], "entities": []}, {"text": "In this set-up, we find that different parameter settings of the systems (e.g. their visual inputs) have a clear effect on the referential success rates, while automatic evaluation measures reflect the interactive effectiveness rather poorly.", "labels": [], "entities": []}, {"text": "Research on reference inhuman interaction has noticed that conversation partners try to minimize their joint effort and often prefer to present simple expressions that can be expanded on or repaired, if necessary.", "labels": [], "entities": []}, {"text": "This strategy, called \"referring in installments\" is very effective for achieving common ground in taskoriented interaction) and is attested in dialogue data ().", "labels": [], "entities": []}, {"text": "The connection between reference in installments on the one and the status of distractors and distinguishing expressions on the other hand is relatively unexplored, though it seems natural to combine the two perspectives).", "labels": [], "entities": []}, {"text": "shows an example for very a simple but highly effective expression -it mentions color as a salient and distinguishing property while avoiding a potentially unclear object name.", "labels": [], "entities": []}, {"text": "As our second contribution, we extend our probabilistic word selection model to work in a simple interactive installment component that tries to avoid semantically inadequate words as much as possible and only expands the expression in case of misunderstanding.", "labels": [], "entities": [{"text": "word selection", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.6995949149131775}]}, {"text": "We present an algorithm that generates these installments depending on the context, based on ideas from traditional REG algorithms like.", "labels": [], "entities": []}, {"text": "We find that a context-aware installment strategy greatly improves referential success as it helps to avoid and repair misunderstandings and offers a combined treatment of semantic and pragmatic adequacy.", "labels": [], "entities": [{"text": "context-aware installment", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6865985095500946}]}], "datasetContent": [{"text": "To the best of our knowledge, end-to-end REG performance has not been reported on the ReferIt data set before.", "labels": [], "entities": [{"text": "REG", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8977157473564148}, {"text": "ReferIt data set", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.9509665966033936}]}, {"text": "shows corpus-based BLEU and NIST measures calculated on the test set (using 3 references for each RE).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9806361794471741}]}, {"text": "The results indicate a minor gain of the GoogLeNet features.", "labels": [], "entities": []}, {"text": "We also evaluate aversion of the GoogLeNetbased system that instantiates the beam search with the gold length of the RE from the corpus (GoogLeNet glen ).", "labels": [], "entities": [{"text": "GoogLeNet glen", "start_pos": 137, "end_pos": 151, "type": "DATASET", "confidence": 0.8795072138309479}]}, {"text": "This leads to a small improvement in BLEU and NIST, indicating that the length prediction is not a critical factor.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9976517558097839}, {"text": "NIST", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.7608653903007507}, {"text": "length prediction", "start_pos": 72, "end_pos": 89, "type": "METRIC", "confidence": 0.9116044044494629}]}, {"text": "Set-up In parallel to the reference game in (), we setup a game between a computer that generates REs and a human player who clicks on the location of the described object that he identifies based on the RE.", "labels": [], "entities": []}, {"text": "After each click, the GUI presents some canned feedback and informs the player whether he clicked on the intended object.", "labels": [], "entities": []}, {"text": "In case of an unsuccessful click, the player has two more trials.", "labels": [], "entities": []}, {"text": "In the following, we report the success rates with respect to each trial and the different test sets.", "labels": [], "entities": []}, {"text": "This setup will trigger a certain amount of user guesses such that the success rates do not correspond perfectly to semantic accuracies.", "labels": [], "entities": []}, {"text": "But it accounts for the increased difficulty as well as the interactive nature of the task.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9659449458122253}]}, {"text": "See Section 4.4 for an analysis of learning effects in this set-up and () for general discussion on REG and NLG evaluation.", "labels": [], "entities": [{"text": "REG", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.8565257787704468}]}, {"text": "For each player, we randomly sampled the games from the entire test set, but balanced the items so that they were equally distributed across the 3 test subsets A, B, C (see above) and the three systems.", "labels": [], "entities": []}, {"text": "We also included human REs from the corpus.", "labels": [], "entities": []}, {"text": "In total, we collected 1201 games played by 8 participants.", "labels": [], "entities": []}, {"text": "Results In, we report the cumulative success rates for the different systems across the different trials, i.e. the success rate in the 3rd trial corresponds to the overall proportion of successfully identified referents.", "labels": [], "entities": []}, {"text": "First of all, this suggests that the differences in performance between the systems is much bigger in terms of their communicative effectiveness as in terms of the corpusbased measures.", "labels": [], "entities": []}, {"text": "Thus, on the one hand, the GoogLeNet features are clearly superior to SA-IAPR, whereas differences between GoogLeNet and GoogLeNet glen are minor.", "labels": [], "entities": []}, {"text": "Interestingly, the GoogLeNet features improve 1st trial as well as overall success, leading to a much better error reduction rate 3 in object identification between the first and third trial.", "labels": [], "entities": [{"text": "error reduction rate", "start_pos": 109, "end_pos": 129, "type": "METRIC", "confidence": 0.973737875620524}, {"text": "object identification", "start_pos": 135, "end_pos": 156, "type": "TASK", "confidence": 0.8747671246528625}]}, {"text": "This means that, here, humans are more likely to recover from misunderstandings and indicates that REs generated by the SAIAPR system are more semantically inadequate.", "labels": [], "entities": []}, {"text": "In, we report the overall success rates for the different test sets.", "labels": [], "entities": []}, {"text": "All systems have a clearly higher performance on the B Set which contains the most frequent object types.", "labels": [], "entities": []}, {"text": "Surprisingly, all systems have a largely comparable performance on Set A and C whereas only C contains images with distractors in the sense of traditional REG.", "labels": [], "entities": []}, {"text": "This shows that describing objects which belong to an infrequent type in a semantically adequate way, which is necessary in Set A, is equally challenging as reaching pragmatic adequacy which is called for in Set C.  Set-up We use the task-oriented setup from Section 3.4 with 3 trials per image.", "labels": [], "entities": []}, {"text": "But instead of presenting the same RE in each trial, the system now updates the phrases according to the RE triples described above.", "labels": [], "entities": [{"text": "RE", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9102700352668762}]}, {"text": "We have recruited 5 players and collected 1200 games, split equally between (a) Start with Location: re1: \"in front\" re2: \"hat guy in front\" re3: \"hat or mountain in front\" (b) Start with Location, Object Type: re1: \"building on left side\" re2: \"house or bus on left side\" re3: \"yellow house or bus on top left side\" (c) Start with Location, Object Type,Other: re1: \"green plants on far right side\" re2: \"shrub or stand on right side\" re3: \"on right\" Results shows that even the simple, pattern-based installment system improves the 1st trial success rate compared to the non-interactive baseline (the GoogLeNet-based system from Section 3) and is clearly superior with respect to its overall success and error reduction rate over trials.", "labels": [], "entities": [{"text": "error reduction rate", "start_pos": 705, "end_pos": 725, "type": "METRIC", "confidence": 0.942339559396108}]}, {"text": "This suggests that a fair amount of target objects can be identified by users based on very simple, locative REs as semantically inadequate object names are avoided.", "labels": [], "entities": []}, {"text": "Another important finding here is the high rate of error reduction during the 2nd and 3rd trial achieved by the installmentbased system.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.8153000473976135}]}, {"text": "In the non-interactive system, users did not have additional cues for repairing their misunderstanding and probably guessed other possible targets in individual, more or less systematic ways.", "labels": [], "entities": []}, {"text": "Apparently, even simple strategies for extending and hedging the initially presented RE provide very helpful cues for repairing initial misunderstandings.", "labels": [], "entities": [{"text": "extending and hedging the initially presented RE", "start_pos": 39, "end_pos": 87, "type": "TASK", "confidence": 0.7944634471620832}, {"text": "repairing initial misunderstandings", "start_pos": 118, "end_pos": 153, "type": "TASK", "confidence": 0.8487369418144226}]}, {"text": "As we expected, the pattern-based installment system is clearly improved by our contextdependent approach to generating installments.", "labels": [], "entities": []}, {"text": "This systems seems to strike a much better balance between generating simple expressions that avoid  The finding that installment strategies should be combined with insights from traditional distractororiented REG is further corroborated when we compare the success rates on the different subsets of our test set, see.", "labels": [], "entities": []}, {"text": "Thus, the performance of the context-dependent installment system is much more stable on the different subsets than the pattern-based system which has a clear dip in success rate on Set C, which contains target referents with distractors of the same object type.", "labels": [], "entities": []}, {"text": "This result suggests that our approach to determine distinguishing REs based purely on predictions of word-based REG (Section 4.3) presents a viable solution for REG on images, where information on distractors is not directly assessable in the lowlevel representation of the scene.", "labels": [], "entities": [{"text": "determine distinguishing REs", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.5898661216100057}, {"text": "REG", "start_pos": 162, "end_pos": 165, "type": "TASK", "confidence": 0.9629957675933838}]}, {"text": "Finally, the graph in shows the average success rates overtime and provides more evidence for the effectiveness of installments.", "labels": [], "entities": []}, {"text": "We observe a clear learning effect in the non-interactive system, meaning that users faced unexpected interpretation problems due to inaccurate expressions, but adapted to the situation to some extent.", "labels": [], "entities": []}, {"text": "In contrast, both installment systems have stable performance overtime, which indicates that system behaviour is immediately understandable and predictable for human users.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatic evaluation for word-based  REG systems", "labels": [], "entities": []}, {"text": " Table 2: Human success and error reduction rates  in object identification task, for different sets of  visual features", "labels": [], "entities": [{"text": "object identification task", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.8588815132776896}]}, {"text": " Table 3: Human success rates for baseline REG  systems trained on different visual feature sets", "labels": [], "entities": []}, {"text": " Table 4: Human evaluation for installment-based  REG systems", "labels": [], "entities": [{"text": "REG", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.8596107959747314}]}, {"text": " Table 5. Thus, the perfor- mance of the context-dependent installment sys- tem is much more stable on the different subsets  than the pattern-based system which has a clear  dip in success rate on Set C, which contains target  referents with distractors of the same object type.  This result suggests that our approach to determine  distinguishing REs based purely on predictions of  word-based REG (Section 4.3) presents a viable  solution for REG on images, where information  on distractors is not directly assessable in the low- level representation of the scene.", "labels": [], "entities": []}, {"text": " Table 5: Human evaluation on different test sets  for installment-based REG systems", "labels": [], "entities": []}]}