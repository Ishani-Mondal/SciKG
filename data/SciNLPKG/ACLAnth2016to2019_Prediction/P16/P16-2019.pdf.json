{"title": [{"text": "Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent work in learning vector-space em-beddings for multi-relational data has fo-cused on combining relational information derived from knowledge bases with dis-tributional information derived from large text corpora.", "labels": [], "entities": []}, {"text": "We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources , in conjunction with distributional semantics, in order to derive a better ini-tialization for training relational models.", "labels": [], "entities": []}, {"text": "Applying this initialization to the TransE model results in significant new state-of-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51.", "labels": [], "entities": [{"text": "WordNet dataset", "start_pos": 113, "end_pos": 128, "type": "DATASET", "confidence": 0.985439270734787}]}, {"text": "It also results in faster convergence of the entity representations.", "labels": [], "entities": []}, {"text": "We find that there is a trade-off between improving the mean rank and the hits@10 with this approach.", "labels": [], "entities": [{"text": "mean rank", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.941663384437561}]}, {"text": "This illustrates that much remains to be understood regarding performance improvements in relational models.", "labels": [], "entities": []}], "introductionContent": [{"text": "A surprising result of work on vector-space word embeddings is that word representations that are learned from a large training corpus display semantic regularities in the form of linear vector translations.", "labels": [], "entities": []}, {"text": "For example, show that using their induced word vector representations, king \u2212 man + woman \u2248 queen.", "labels": [], "entities": []}, {"text": "Such a structure is appealing because it provides an interpretation to the distributional vector space through lexical-semantic analogical inferences.", "labels": [], "entities": []}, {"text": "Concurrent to that work, proposed translating embeddings (TransE), which takes a pre-existing semantic hierarchy as in-", "labels": [], "entities": [{"text": "translating embeddings", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8556614220142365}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Comparison between random initialization and using the entity descriptions. 'NS' tag indicates  stopword removal from the entity descriptions'TransE Freebase W2V init' model uses word2vec pre- trained with the Freebase vocabulary, and thus was not tested on WN.", "labels": [], "entities": []}]}