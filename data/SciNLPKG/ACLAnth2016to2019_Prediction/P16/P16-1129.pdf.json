{"title": [{"text": "Towards Constructing Sports News from Live Text Commentary", "labels": [], "entities": [{"text": "Constructing Sports News from Live Text Commentary", "start_pos": 8, "end_pos": 58, "type": "TASK", "confidence": 0.6624312954289573}]}], "abstractContent": [{"text": "In this paper, we investigate the possibility to automatically generate sports news from live text commentary scripts.", "labels": [], "entities": [{"text": "generate sports news from live text commentary scripts", "start_pos": 63, "end_pos": 117, "type": "TASK", "confidence": 0.713689424097538}]}, {"text": "As a preliminary study, we treat this task as a special kind of document summarization based on sentence extraction.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7142494916915894}]}, {"text": "We formulate the task in a supervised learning to rank framework, utilizing both traditional sentence features for generic document summarization and novelly designed task-specific features.", "labels": [], "entities": [{"text": "generic document summarization", "start_pos": 115, "end_pos": 145, "type": "TASK", "confidence": 0.6313452819983164}]}, {"text": "To tackle the problem of local redundancy, we also propose a probabilistic sentence selection algorithm.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.6997999250888824}]}, {"text": "Experiments on our collected data from football live commentary scripts and corresponding sports news demonstrate the feasibility of this task.", "labels": [], "entities": []}, {"text": "Evaluation results show that our methods are indeed appropriate for this task, outperforming several baseline methods in different aspects.", "labels": [], "entities": []}], "introductionContent": [{"text": "There area huge number of sports games played each day.", "labels": [], "entities": []}, {"text": "It is demanding and challenging to write corresponding news reports instantly after various games.", "labels": [], "entities": []}, {"text": "Meanwhile, live text commentary services are available on the web and becoming increasingly popular for sports fans who do not have access to live video streams due to copyright reasons.", "labels": [], "entities": []}, {"text": "Some people may also prefer live texts on portable devices.", "labels": [], "entities": []}, {"text": "The emergence of live texts has produced huge amount of text commentary data.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there exists few studies about utilizing this rich data source.", "labels": [], "entities": []}, {"text": "Manually written sports news for match report usually share the same information and vocabulary as live texts for the corresponding sports game.", "labels": [], "entities": []}, {"text": "Sports news and commentary texts can be treated as two different sources of descriptions for the same sports events.", "labels": [], "entities": []}, {"text": "It is tempting to investigate whether we can utilize the huge amount of live texts to automatically construct sports news, typically in a form of match report.", "labels": [], "entities": []}, {"text": "Building such a system will largely relax the burden of sports news editors, making them free from repetitive tedious efforts for writing while producing sports news more efficiently.", "labels": [], "entities": [{"text": "sports news editors", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.6804140011469523}]}, {"text": "In this work, we study the possibility to construct sports news in the form of match reports from given live text commentary scripts.", "labels": [], "entities": []}, {"text": "As a concrete example we collect live text data and corresponding news reports for football (called soccer more often in the United States) games and conduct our study thereby.", "labels": [], "entities": []}, {"text": "However, our methods and discussions made in this paper can be trivially adapted to other types of sports games as well.", "labels": [], "entities": []}, {"text": "As a preliminary study, we treat this task as a special kind of document summarization: extracting sentences from live texts to form a match report as generated news.", "labels": [], "entities": []}, {"text": "However, generating sports news from live texts is still challenging due to some unique properties of live text commentary scripts.", "labels": [], "entities": [{"text": "generating sports news from live texts", "start_pos": 9, "end_pos": 47, "type": "TASK", "confidence": 0.7908710539340973}]}, {"text": "For almost every minute of the game there are usually several sentences describing various kinds of events.", "labels": [], "entities": []}, {"text": "Texts are ordered and organized by the timeline, without apparent highlights for many important events . Descriptions are usually in short sentences, which is not helpful for sentence scoring and selection in general.", "labels": [], "entities": [{"text": "sentence scoring", "start_pos": 175, "end_pos": 191, "type": "TASK", "confidence": 0.7853325605392456}]}, {"text": "The commentators may tend to use similar, repeated words describing the same type of key events, which may bring additional challenges to traditional summarization methods that are designed to avoid literal repetitions in nature.", "labels": [], "entities": [{"text": "summarization", "start_pos": 150, "end_pos": 163, "type": "TASK", "confidence": 0.9771290421485901}]}, {"text": "As a result, naively treating the task as an ordinary document summarization problem can hardly lead to the construction of reasonable sports news reports.", "labels": [], "entities": []}, {"text": "To overcome these difficulties, we explore some specific features of live text commentary scripts and formulate a system based on supervised learning to rank models for this task.", "labels": [], "entities": []}, {"text": "In order to tackle the local redundancy issue, we also propose a probabilistic sentence selection strategy.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7074078619480133}]}, {"text": "We summarize our contributions as follows: \u2022 We originally study the task of sports news construction from live text commentary and we build datasets for supervised learning and evaluation for this task.", "labels": [], "entities": [{"text": "sports news construction from live text commentary", "start_pos": 77, "end_pos": 127, "type": "TASK", "confidence": 0.7320225366524288}]}, {"text": "\u2022 We formulate the task in a learning to rank framework, utilizing both traditional features for document summarization and novel taskspecific features during supervised learning.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.6585094332695007}]}, {"text": "\u2022 We propose a probabilistic sentence selection algorithm to address the issue of local redundancy in description.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7169717699289322}]}, {"text": "\u2022 We conduct a series of experiments on areal dataset and the evaluation results verify the performance of our system.", "labels": [], "entities": []}, {"text": "Results suggest that constructing sports news from live texts is feasible and our proposed methods can outperform a few strong baselines.", "labels": [], "entities": [{"text": "constructing sports news from live texts", "start_pos": 21, "end_pos": 61, "type": "TASK", "confidence": 0.8174725472927094}]}], "datasetContent": [{"text": "Similar to the evaluation for traditional summarization tasks, we use the ROUGE metrics ( to automatically evaluate the quality of produced summaries given the goldstandard reference news.", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.9314483106136322}, {"text": "ROUGE", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9896283149719238}]}, {"text": "The ROUGE metrics measure summary quality by counting the precision, recall and F-score of overlapping units, such as n-grams and skip grams, between a candidate summary and the reference summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.7925663590431213}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9994787573814392}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9963489770889282}, {"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9943925738334656}]}, {"text": "We use the ROUGE-1.5.5 toolkit to perform the evaluation.", "labels": [], "entities": [{"text": "ROUGE-1.5.5", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.8579389452934265}]}, {"text": "In this paper we report the F-scores of the following metrics in the experimental results: ROUGE-1 (unigram-based), ROUGE-2 (bigrambased) and ROUGE-SU4 (based on skip bigrams with a maximum skip distance of 4).", "labels": [], "entities": [{"text": "F-scores", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9957625269889832}, {"text": "ROUGE-1", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.9847003221511841}, {"text": "ROUGE-2", "start_pos": 116, "end_pos": 123, "type": "METRIC", "confidence": 0.9576842188835144}, {"text": "ROUGE-SU4", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.8987457752227783}]}, {"text": "We also conduct manual pyramid evaluation in this study.", "labels": [], "entities": [{"text": "pyramid evaluation", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.8567163646221161}]}, {"text": "Specifically, we use the modified pyramid scores as described in () to manually evaluate the summaries generated by different methods.", "labels": [], "entities": []}, {"text": "We randomly sample 20 games from the data set and manually annotate facts on the gold-standard news.", "labels": [], "entities": []}, {"text": "The annotated facts are mostly describing specific events happened during the game, e.g. \"\u4f0a\u4e07\u88ab\u9ec4\u724c\u8b66\u544a\" (Ivanovic is shown the yellow card) and \"\u5185\u9a6c\u5c14 \u5f00\u51fa\u89d2\u7403\" (Neymar takes the corner).", "labels": [], "entities": []}, {"text": "Each fact is treated as a Summarization Content Unit, (SCU) ().", "labels": [], "entities": []}, {"text": "The number of occurrences for each SCU in the gold-standard news is regarded as the weight of this SCU.", "labels": [], "entities": [{"text": "gold-standard news", "start_pos": 46, "end_pos": 64, "type": "DATASET", "confidence": 0.7479878962039948}]}], "tableCaptions": [{"text": " Table 1.  Method  R-1  R-2  R-SU4  HeadTail 0.30147 0.07779 0.10336  Centroid 0.32508 0.08113 0.11245  LexRank 0.31284 0.06159 0.09376  ILP  0.32552 0.07285 0.10378  Highlight 0.34687 0.08748 0.11924  RF  0.38559 0.11887 0.14907  RF+DPP 0.39391 0.11986 0.15097  Table 1: Comparison results of different methods", "labels": [], "entities": [{"text": "HeadTail 0.30147 0.07779 0.10336  Centroid 0.32508 0.08113 0.11245  LexRank 0.31284 0.06159 0.09376  ILP  0.32552", "start_pos": 36, "end_pos": 149, "type": "DATASET", "confidence": 0.886984361069543}, {"text": "RF  0.38559 0.11887 0.14907  RF+DPP 0.39391", "start_pos": 202, "end_pos": 245, "type": "METRIC", "confidence": 0.6709799915552139}]}, {"text": " Table 2: Average Pyramid scores  Overall, the experimental results indicate that  our system can generate much better news than  the baselines in both automatic and manual eval- uations. We include examples of our constructed  news reports in the supplementary materials.", "labels": [], "entities": []}, {"text": " Table 3: Results of feature validation", "labels": [], "entities": [{"text": "feature validation", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.6861237734556198}]}, {"text": " Table 4.  We observe numerically superior scores compared  with reference. This is not strange since we are in- tentionally optimizing ROUGE scores. And also  this suggests that the sentence extraction approach  for sports news construction is rather reasonable,  in terms of information overlap.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 136, "end_pos": 141, "type": "METRIC", "confidence": 0.9500018954277039}, {"text": "sentence extraction", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.7635894417762756}, {"text": "sports news construction", "start_pos": 217, "end_pos": 241, "type": "TASK", "confidence": 0.6687814394632975}]}, {"text": " Table 5: Manual readability ratings", "labels": [], "entities": []}]}