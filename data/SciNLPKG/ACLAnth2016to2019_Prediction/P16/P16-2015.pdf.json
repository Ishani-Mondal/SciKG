{"title": [{"text": "A Fast Approach for Semantic Similar Short Texts Retrieval", "labels": [], "entities": [{"text": "Semantic Similar Short Texts Retrieval", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.7983165979385376}]}], "abstractContent": [{"text": "Retrieving semantic similar short texts is a crucial issue to many applications, e.g., web search, ads matching, question-answer system, and so forth.", "labels": [], "entities": [{"text": "Retrieving semantic similar short texts", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.902310597896576}, {"text": "ads matching", "start_pos": 99, "end_pos": 111, "type": "TASK", "confidence": 0.7256594151258469}]}, {"text": "Most of the traditional methods concentrate on how to improve the precision of the similarity measurement, while current real applications need to efficiently explore the top similar short texts semantically related to the query one.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9980809688568115}]}, {"text": "We address the efficiency issue in this paper by investigating the similarity strategies and incorporating them into the FAST framework (efficient FrAmework for semantic similar Short Texts retrieval).", "labels": [], "entities": [{"text": "FAST framework", "start_pos": 121, "end_pos": 135, "type": "DATASET", "confidence": 0.7079079151153564}]}, {"text": "We conduct comprehensive performance evaluation on real-life data which shows that our proposed method outperforms the state-of-the-art techniques.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we investigate the fast approach of short texts retrieval, which is important to many applications, e.g., web search, ads matching, question-answer system, etc.", "labels": [], "entities": [{"text": "short texts retrieval", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.6901768247286478}, {"text": "ads matching", "start_pos": 133, "end_pos": 145, "type": "TASK", "confidence": 0.7426919639110565}]}, {"text": "(. The setting of the problem is that users always ask for those most semantically related to their queries from a huge text collection.", "labels": [], "entities": []}, {"text": "A common solution is applying the state-of-the-art short texts similarity measurement techniques;, and then return the top-k ones * Corresponding author. by sorting them with regard to the similarity score.", "labels": [], "entities": []}, {"text": "After surveying the previous approaches, we find that almost all the methods concentrate on how to improve the precision, i.e., effectiveness issue.", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9995110034942627}, {"text": "effectiveness", "start_pos": 128, "end_pos": 141, "type": "METRIC", "confidence": 0.9514840841293335}]}, {"text": "In addition, the data collections which they conducted are rather small.", "labels": [], "entities": []}, {"text": "However, the scale of the problem has dramatically increased and the current short texts similarity measurement techniques could not handle when the data collection size becomes enormous.", "labels": [], "entities": []}, {"text": "In this paper, we aim to address the efficiency issue in the literature while keeping their high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9985955357551575}]}, {"text": "Moreover, we focus on the top-k issue because users commonly do not care about the individual similarity score but only the sorted results.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 94, "end_pos": 110, "type": "METRIC", "confidence": 0.8756058812141418}]}, {"text": "Furthermore, most of the previous studies) need to set predefined threshold to filter out those dissimilar texts which is rather difficult to determine by users.", "labels": [], "entities": []}, {"text": "Different from long texts, short texts cannot always observe the syntax of a written language and usually do not possess sufficient information to support statistical based text processing techniques, e.g., TF-IDF.", "labels": [], "entities": []}, {"text": "This indicates that the traditional NLP techniques for long texts may not be always appropriate to apply to short texts.", "labels": [], "entities": []}, {"text": "The related works on short texts similarity measurement can be classified into the following major categories, i.e., (1) inner resource based strategy (; (2) outer resource based strategy (; and (3) hybrid based strategy.", "labels": [], "entities": [{"text": "short texts similarity measurement", "start_pos": 21, "end_pos": 55, "type": "TASK", "confidence": 0.6307145729660988}]}, {"text": "Naively testing the candidate short texts for topk similar short texts retrieval is inefficient when directly using these strategies.", "labels": [], "entities": []}, {"text": "To tackle the efficiency problem, we propose an efficient strategy to evaluate as few candidates as possible.", "labels": [], "entities": []}, {"text": "Moreover, our fast algorithm aims to output the results progressively, i.e., the top-1 should be obtained instantly.", "labels": [], "entities": []}, {"text": "This scheme meets the demand of the real world applications, especially for big data environment.", "labels": [], "entities": []}, {"text": "We list our contribution of this paper as follows: we propose a fast approach to tackle the efficiency problem for retrieving top-k semantic similar short texts; we present the optimized techniques and improve the efficiency which minimizes the candidate number to be evaluated in our framework.", "labels": [], "entities": []}, {"text": "The results of four different settings demonstrate that the efficiency of our fast approach outperforms the state-of-the-art methods while keeping effectiveness.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conduct on three different datasets to evaluate the performance of our approach.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness, we test the dataset which was used in ().", "labels": [], "entities": []}, {"text": "For efficiency evaluation, we apply the BNC and MSC datasets which are extracted from British National Corpus and Microsoft Research Paraphrase Corpus respectively.", "labels": [], "entities": [{"text": "BNC", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.6939411163330078}, {"text": "MSC datasets", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.8905384838581085}, {"text": "British National Corpus", "start_pos": 86, "end_pos": 109, "type": "DATASET", "confidence": 0.8873131275177002}, {"text": "Microsoft Research Paraphrase Corpus", "start_pos": 114, "end_pos": 150, "type": "DATASET", "confidence": 0.9152116477489471}]}, {"text": "The baseline strategy is implemented according to the state-of-the-art (linear assembling strategy as).", "labels": [], "entities": []}, {"text": "In our proposed strategy, we take four different settings: (1) FAST E is the one that we apply the ESA topic strategy; (2) FAST L employs the LDA topic strategy in corpus based similarity with equal weight; and (3) FAST Ew and FAST Lw are implemented based on the former two ones, respectively, with the tuned combinational weights.", "labels": [], "entities": [{"text": "FAST E", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.688601553440094}]}, {"text": "We evaluate the efficiency by using two real-life datasets which have been denoted as BNC and MSC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9609444737434387}]}, {"text": "To test the effect of size of data collection, we select different size of these two datasets.", "labels": [], "entities": []}, {"text": "Firstly, we conducted experiments on the fixed size of data collection by using 4 settings of our proposed approach.", "labels": [], "entities": []}, {"text": "The results show that comparing with the baseline strategy, FAST E , FAST L , FAST Ew and FAST Lw have promotion at 75.34%, 74.68%, 75.31% and 74.59% respectively.", "labels": [], "entities": [{"text": "FAST E", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.8291831016540527}, {"text": "FAST L", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.766683042049408}, {"text": "FAST Ew", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.6489082276821136}, {"text": "FAST Lw", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.7531137466430664}, {"text": "promotion", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9959555864334106}]}, {"text": "The four settings have similar results which indicates that the weight is not the crucial factor in our proposed strategy.", "labels": [], "entities": []}, {"text": "1 tells us the number of candidates accessed.", "labels": [], "entities": []}, {"text": "Our evaluation has been conducted on different data collection size to test the scalability of our proposed strategy.", "labels": [], "entities": []}, {"text": "Since the baseline strategy should access all the short texts in each size of data collection, which means in 1k size of BNC data collection, the baseline strategy access all these 1k candidates.", "labels": [], "entities": [{"text": "BNC data collection", "start_pos": 121, "end_pos": 140, "type": "DATASET", "confidence": 0.950038472811381}]}, {"text": "However, our proposed strategies under different settings only access small size candidates to obtain the results.", "labels": [], "entities": []}, {"text": "From the table, we can see that, our proposed strategy can largely reduce the number of candidates accessed in both data collections.", "labels": [], "entities": []}, {"text": "In addition, the number of candidates accessed has increases not quickly which indicate our proposed approach scales well.", "labels": [], "entities": []}, {"text": "Therefore, the proposed strategy is efficient than the baseline strategy.", "labels": [], "entities": []}, {"text": "We also evaluate the effect of k which is an important factor for evaluating the efficiency of an algorithm.", "labels": [], "entities": []}, {"text": "The experiments conducted on a fixed size of data collection which show that the top-1 value has been outputted instantly by apply our proposed strategy while baseline strategy should access all candidates.", "labels": [], "entities": []}, {"text": "For the query time of FAST E setting costs only 19.12s while baseline strategy costs 897.5s for obtaining the top-1 value.", "labels": [], "entities": [{"text": "FAST E setting", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7124423782030741}]}, {"text": "FAST L , FAST Es and FAST Lw cost 20.13s, 21.21s and 20.32s respectively which confirms that combinational weight is not an important factor in our proposed strategy.", "labels": [], "entities": [{"text": "FAST L", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.5850358605384827}, {"text": "FAST Es", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.6547450125217438}, {"text": "FAST Lw", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.6090668737888336}]}, {"text": "We illustrate the results of the correlation coefficient with human ratings in 2.", "labels": [], "entities": [{"text": "correlation", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9503294229507446}]}, {"text": "Note here, the baseline strategy is composed by knowledge based strategy and corpus based strategy (ESA method) with equal weight.", "labels": [], "entities": []}, {"text": "From the table we can see that, the FAST E has the same precision as the baseline because our proposed strategy only changes the order of the evaluated short texts but not the similarity strategy.", "labels": [], "entities": [{"text": "FAST E", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.8706464171409607}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9990211725234985}]}, {"text": "FAST L has better precision than FAST E because we select the best LDA topic size to form Wiki topic.", "labels": [], "entities": [{"text": "FAST L", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.5369073152542114}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.998784601688385}]}, {"text": "FAST Ew and FAST Lw have dynamically changed the combinational weights and therefore, the performance of them has been improved.", "labels": [], "entities": [{"text": "FAST Ew", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6830734014511108}]}], "tableCaptions": [{"text": " Table 1: Number of candidates accessed in effi- ciency evaluation", "labels": [], "entities": []}, {"text": " Table 2: Effectiveness evaluation on different  strategies", "labels": [], "entities": []}]}