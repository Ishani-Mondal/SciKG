{"title": [{"text": "A Personalized Markov Clustering and Deep Learning Approach for Arabic Text Categorization", "labels": [], "entities": [{"text": "Arabic Text Categorization", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.5485040744145712}]}], "abstractContent": [{"text": "Text categorization has become a key research field in the NLP community.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8371733725070953}]}, {"text": "However , most works in this area are focused on Western languages ignoring other Semitic languages like Arabic.", "labels": [], "entities": []}, {"text": "These languages are of immense political and social importance necessitating robust cate-gorization techniques.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel three-stage technique to efficiently classify Arabic documents into different categories based on the words they contain.", "labels": [], "entities": []}, {"text": "We leverage the significance of root-words in Arabic and incorporate a combination of Markov clustering and Deep Belief Networks to classify Arabic words into separate groups (clusters).", "labels": [], "entities": []}, {"text": "Our approach is tested on two public datasets giving a F-Measure of 91.02%.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.999677300453186}]}], "introductionContent": [{"text": "In the emerging era of big data technology, there has been a widespread increase in information obtained from text documents.", "labels": [], "entities": []}, {"text": "Furthermore, with the rapid availability of machine-readable documents, text classification techniques have gained tremendous interest during the recent years.", "labels": [], "entities": [{"text": "text classification", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.8710356056690216}]}, {"text": "Consequently, automatic categorization of numerous new documents to different categories has become critical for political, social and for news research purposes.", "labels": [], "entities": []}, {"text": "Text categorization techniques have been widely investigated by researchers around the world.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7873822450637817}]}, {"text": "However, most of the recent developments in this field are focused on popular Western languages, ignoring Semitic and Middle-Eastern languages like Arabic, Hebrew, Urdu and Persian.", "labels": [], "entities": []}, {"text": "As discussed further in related works in Section 2.1, most classification algorithms utilized English and Chinese to validate their methods while works on Arabic are extremely rare.", "labels": [], "entities": []}, {"text": "This is primarily due to significant dialect differences between these languages and their complex morphology.", "labels": [], "entities": []}, {"text": "Additionally, the presence of various inflections in Arabic as opposed to English makes it difficult for the NLP community to validate techniques on the popular Middle Eastern languages.", "labels": [], "entities": []}, {"text": "According to the US Department of Cultural Affairs, Arabic and Urdu are categorized as critical languages and United Nations heavily emphasizes on the social and political importance of these languages.", "labels": [], "entities": []}, {"text": "Arabic is listed as one of the six official languages of the United Nations.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel three stage approach to classify Arabic text documents into different categories combining Markov Clustering, Fuzzy-C-means and Deep Learning.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that leverages the heavy influence of root-words in Arabic to extract features for both clustering and deep learning to perform classification of Arabic documents.", "labels": [], "entities": [{"text": "classification of Arabic documents", "start_pos": 181, "end_pos": 215, "type": "TASK", "confidence": 0.8463038951158524}]}, {"text": "First, we segment each document and extract root-word information.", "labels": [], "entities": []}, {"text": "Then we perform clustering with root-word based features using Fuzzy-C-Means and Markov clustering.", "labels": [], "entities": []}, {"text": "This allows us to separate documents into unsupervised groups (clusters).", "labels": [], "entities": []}, {"text": "We then train a deep belief network (DBN) for each cluster using Restricted Boltzmann Machines.", "labels": [], "entities": []}, {"text": "This personalization which is essentially training DBN for each cluster improves the classification accuracy and features extraction.", "labels": [], "entities": [{"text": "classification", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.9403939247131348}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.972459077835083}, {"text": "features extraction", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.6818973273038864}]}, {"text": "Finally, we generate network graphs of these clusters which can be used for similarity relatedness or summarization in future works.", "labels": [], "entities": [{"text": "summarization", "start_pos": 102, "end_pos": 115, "type": "TASK", "confidence": 0.9796999096870422}]}, {"text": "This is the first work to use a modified combination of Markov clustering and personalized deep learning to classify documents into different categories.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 discusses the literature review and Arabic morphology.", "labels": [], "entities": [{"text": "Arabic morphology", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.6048057973384857}]}, {"text": "Section 3 focuses on methodology for Markov clustering and deep learning.", "labels": [], "entities": [{"text": "Markov clustering", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.6516767144203186}]}, {"text": "Section 4 discusses our experimental results and finally, Section 5 summarizes the paper and presents conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our three-stage technique using two popular datasets previously used in Arabic text categorization: 10,000 documents from AlJazeera news website (http://www.aljazeera.net) and 6,000 Saudi Press Agency ( documents.", "labels": [], "entities": [{"text": "AlJazeera news website", "start_pos": 134, "end_pos": 156, "type": "DATASET", "confidence": 0.9307248195012411}, {"text": "Saudi Press Agency", "start_pos": 194, "end_pos": 212, "type": "DATASET", "confidence": 0.7909713586171468}]}, {"text": "The results are reported using 10-fold cross validation.", "labels": [], "entities": []}, {"text": "Our proposed method achieves a precision of 91.2% and recall of 90.9% giving F-measure of 91.02%.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9996103644371033}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9998433589935303}, {"text": "F-measure", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9995119571685791}]}, {"text": "Clustering is performed on a set consisting of the total 12,000 documents, randomly sampled from separately from Al-Jazeera and Saudi Press Agency.", "labels": [], "entities": [{"text": "Saudi Press Agency", "start_pos": 128, "end_pos": 146, "type": "DATASET", "confidence": 0.8776947259902954}]}, {"text": "We further ran deep learning on each of these clusters and extracted network graphs.", "labels": [], "entities": []}, {"text": "Two example networks are presented in and 4.", "labels": [], "entities": []}, {"text": "We compare our results with existing approaches in.", "labels": [], "entities": []}, {"text": "We can see that our technique improves substantially on the previous published works.", "labels": [], "entities": []}, {"text": "Furthermore, it is capable to categorize different diacritics by using clusters based on root-words.", "labels": [], "entities": []}, {"text": "Most misclassified cases in our algorithm due to random outliers and/or mix categories in a document.", "labels": [], "entities": []}, {"text": "An example of a random outlier are some recent words which are not influenced by root-words.", "labels": [], "entities": []}, {"text": "This can be further improved by using a larger dataset and using new discriminative features for clustering and deep learning.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of our algorithm on Al-Jazeera Dataset", "labels": [], "entities": [{"text": "Al-Jazeera Dataset", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.9216931760311127}]}]}