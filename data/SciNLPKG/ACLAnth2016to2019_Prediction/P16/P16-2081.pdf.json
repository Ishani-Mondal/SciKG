{"title": [{"text": "Semantics-Driven Recognition of Collocations Using Word Embeddings", "labels": [], "entities": [{"text": "Semantics-Driven Recognition of Collocations", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8835682719945908}]}], "abstractContent": [{"text": "L2 learners often produce \"ungrammat-ical\" word combinations such as, e.g., *give a suggestion or *make a walk.", "labels": [], "entities": []}, {"text": "This is because of the \"collocationality\" of one of their items (the base) that limits the acceptance of collocates to express a specific meaning ('perform' above).", "labels": [], "entities": []}, {"text": "We propose an algorithm that delivers, fora given base and the intended meaning of a collo-cate, the actual collocate lexeme(s) (make / take above).", "labels": [], "entities": []}, {"text": "The algorithm exploits the linear mapping between bases and collo-cates from examples and generates a collo-cation transformation matrix which is then applied to novel unseen cases.", "labels": [], "entities": []}, {"text": "The evaluation shows a promising line of research in collocation discovery.", "labels": [], "entities": [{"text": "collocation discovery", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.7704282999038696}]}], "introductionContent": [{"text": "Collocations of the kind make [a] suggestion, attend [a] lecture, heavy rain, deep thought, strong tea, etc., are restricted lexical co-occurrences of two syntactically bound lexical elements).", "labels": [], "entities": []}, {"text": "The central role of collocations for second language (henceforth, L2) learning has been discussed in a series of theoretical and empirical studies and is widely reflected in (especially English) learner dictionaries.", "labels": [], "entities": []}, {"text": "In computational lexicography, several statistical measures have been used to retrieve collocations from corpora, among them, mutual information (, entropy), pointwise mutual information, and weighted pointwise mutual information).", "labels": [], "entities": []}, {"text": "However, the needs of language learners go beyond mere lists of collocations: the cited studies reveal that language learners often build \"miscollocations\" (as, e.g., *give a suggestion or *have the curiosity) to express the intended meaning.", "labels": [], "entities": []}, {"text": "In other words, they fail to observe, in Kilgarriff's terms, the \"collocationality\" restrictions of L2, which imply that in language production, one of the elements of a collocation (the base) is freely chosen, while the choice of the other (the collocate) depends on the base.", "labels": [], "entities": []}, {"text": "For instance, to express the meaning of 'do' or 'perform', the base suggestion prompts for the choice of make as collocate: make [a] suggestion, while advice prompts for give: give advice; to express the meaning of 'participate in', lecture prompts for attend: attend [a] lecture, while operation prompts for assist: assist operation; to express the meaning of 'intense' in connection with rain, the right collocate is heavy, while 'intense wind' is strong wind.", "labels": [], "entities": []}, {"text": "The idiosyncrasy of collocations makes them also language-specific.", "labels": [], "entities": []}, {"text": "Thus, in English, you take walk, in Spanish you 'give' it (dar paseo), and in German and French you 'make' it ( Spaziergang machen, faire [une] promenade); in English, rain is heavy, while in Spanish and German it is 'strong' (fuerte lluvia/starker Regen).", "labels": [], "entities": []}, {"text": "In order to effectively support L2 learners, techniques are thus needed that are able not only to retrieve collocations, but also provide fora given base (or headword) and a given semantic gloss of a collocate meaning, the actual collocate lexeme.", "labels": [], "entities": []}, {"text": "In what follows, we present such a technique, which is grounded in's word embeddings, and which leverages the fact that semantically related words in two different vector representations are related by linear transformation ().", "labels": [], "entities": []}, {"text": "This property has been exploited for word-based translation, learning semantic hierarchies (hyponym-hypernym relations) in Chinese (, and modeling linguistic similarities between standard (Wikipedia) and nonstandard language (Twitter) (.", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.667986661195755}]}, {"text": "In our task, we learn a transition matrix over a small number of collocation examples, where collocates share the same semantic gloss, to apply then this matrix to discover new collocates for any previously unseen collocation base.", "labels": [], "entities": []}, {"text": "We discuss the outcome of the experiments with ten different collocate glosses (including 'do' / 'perform', 'increase', 'decrease', etc.), and show that for most glosses, an approach that combines a stage of the application of a gloss-specific transition matrix with a pruning stage that is based on statistical evidence outperforms approaches that exploit only one of these stages as well as a baseline that is based on collocation retrieval exploiting the embeddings property for drawing analogies, such as, e.g., x \u223c applause \u2261 heavy \u223c rain (implying x=thunderous)).", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out experiments with 10 of the most frequent semantic collocate glosses (listed in the first column of: Semantic glosses and size of training set randomly selected nouns from the Macmillan Dictionary and manually classified their corresponding collocates with respect to the glosses.", "labels": [], "entities": [{"text": "Macmillan Dictionary", "start_pos": 190, "end_pos": 210, "type": "DATASET", "confidence": 0.9879999458789825}]}, {"text": "Note that there maybe more than one collocate for each base.", "labels": [], "entities": []}, {"text": "Since collocations with different collocate meanings are not evenly distributed in language (e.g., speakers use more often collocations conveying the idea of 'intense' and 'perform' than 'stop performing'), the number of instances per gloss in our training data also varies significantly (see).", "labels": [], "entities": []}, {"text": "Due to the asymmetric nature of collocations, not all corpora maybe equally suitable for the derivation of word embedding representations for both bases and collocates.", "labels": [], "entities": []}, {"text": "Thus, we may hypothesize that for modeling (nominal) bases, which keep in collocations their literal meaning, a standard register corpus with a small percentage of figurative meanings will be more adequate, while for modeling collocates, a corpus which is potentially rich in collocations is likely to be more appropriate.", "labels": [], "entities": []}, {"text": "In order to verify this hypothesis, we carried out two different experiments.", "labels": [], "entities": []}, {"text": "In the first experiment, we used for both bases and collocates vectors pre-trained on the Google News corpus (GoogleVecs), which is available at word2vec's website.", "labels": [], "entities": [{"text": "Google News corpus (GoogleVecs)", "start_pos": 90, "end_pos": 121, "type": "DATASET", "confidence": 0.8819282452265421}]}, {"text": "In the second experiment, the bases were modeled by training their word vectors over a 2014 dump of the English Wikipedia, while for modeling collocates, again, GoogleVecs has been used.", "labels": [], "entities": []}, {"text": "In other words, we assumed that Wikipedia is a standard register corpus and thus better for modeling B, while GoogleVecs is more suitable for modeling C.", "labels": [], "entities": []}, {"text": "The figures in Section 3.2 below will give us a hint whether this assumption is correct.", "labels": [], "entities": []}, {"text": "3 At this stage of our work, we considered only collocations that involve single word tokens for both the base and the collocate.", "labels": [], "entities": []}, {"text": "In other words, we did not take into account, e.g., phrasal verb collocates such as stand up, give up or calm down.", "labels": [], "entities": []}, {"text": "We also left aside the problem of subcategorization in collocations; cf., e.g., into in take [into] consideration.", "labels": [], "entities": []}, {"text": "For the calculation of NP MI during postprocessing, the British National Corpus (BNC) was used.", "labels": [], "entities": [{"text": "calculation of NP MI", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7073058858513832}, {"text": "British National Corpus (BNC)", "start_pos": 56, "end_pos": 85, "type": "DATASET", "confidence": 0.9687631527582804}]}, {"text": "The outcome of each experiment was assessed by verifying the correctness of each retrieved candidate from the top-10 candidates obtained for each test base.", "labels": [], "entities": []}, {"text": "A total of 10 bases was evaluated for each gloss.", "labels": [], "entities": []}, {"text": "The ground truth test set was created in a similar fashion as the training set: nouns from the Macmillan Dictionary were randomly chosen, and their collocates manually classified in terms of the different glosses, until a set often unseen base-collocate pairs was obtained for each gloss.", "labels": [], "entities": [{"text": "Macmillan Dictionary", "start_pos": 95, "end_pos": 115, "type": "DATASET", "confidence": 0.9858464598655701}]}, {"text": "For the outcome of each experiment, we computed both precision (p) as the ratio of retrieved collocates that match the targeted glosses to the overall number of obtained collocates for each base, and Mean Reciprocal Rank (MRR), which rewards the position of the first correct result in a ranked list of outcomes: where Q is a sample of experiment runs and rank i refers to the rank position of the first relevant outcome for the ith run.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9986660480499268}, {"text": "Mean Reciprocal Rank (MRR)", "start_pos": 200, "end_pos": 226, "type": "METRIC", "confidence": 0.9677405456701914}]}, {"text": "MRR is commonly used in Information Retrieval and Question Answering, but has also shown to be well suited for collocation discovery; see, e.g., (.", "labels": [], "entities": [{"text": "MRR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.424823522567749}, {"text": "Information Retrieval", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.8309884369373322}, {"text": "Question Answering", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8154410421848297}, {"text": "collocation discovery", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7814260423183441}]}, {"text": "We evaluated four different configurations of our technique against two baselines.", "labels": [], "entities": []}, {"text": "The first baseline (S1) is based on the regularities in word embeddings, with the vec(king) \u2212 vec(man) + vec(woman) = vec(queen) example as paramount case.", "labels": [], "entities": []}, {"text": "In this context, we manually selected one representative example for each semantic gloss to discover collocates for novel bases following the same schema; cf., e.g., for the gloss 'perform' vec(take) \u2212 vec(walk) + vec(suggestion) = vec(make) (where make is the collocate to be discovered); see () for details.", "labels": [], "entities": []}, {"text": "The second baseline (S2) is an extension of S1 in that its output Mean Reciprocal Rank   is filtered with respect to the valid POS-patterns of targeted collocations and NP MI.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank", "start_pos": 66, "end_pos": 86, "type": "METRIC", "confidence": 0.8580013314882914}]}, {"text": "The four configurations of our technique that we tested were: S3, which is based on the transition matrix for which GoogleVecs is used as reference vector space representation for both bases and collocates; S4, which applies POS-pattern and NP MI filters to the output of S3; S5, which is equivalent to S3, but relies on a vector space representation derived from Wikipedia for learning bases projections and on a vector space representation from GoogleVecs for collocate projections; and, finally, S6, where the S5 output is, again, filtered by POS collocation patterns and NP MI.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Semantic glosses and size of training set", "labels": [], "entities": []}, {"text": " Table 2: Precision and MRR", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9420816898345947}, {"text": "MRR", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.5565416216850281}]}, {"text": " Table 4: Precision of the coarse-grained evaluation  of the S6 configuration", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9834188222885132}]}]}