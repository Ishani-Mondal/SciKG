{"title": [{"text": "A Fast Unified Model for Parsing and Sentence Understanding", "labels": [], "entities": [{"text": "Parsing and Sentence", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.8691879113515218}]}], "abstractContent": [{"text": "Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences.", "labels": [], "entities": []}, {"text": "However, they suffer from two key technical problems that make them slow and unwieldy for large-scale NLP tasks: they usually operate on parsed sentences and they do not directly support batched computation.", "labels": [], "entities": []}, {"text": "We address these issues by introducing the Stack-augmented Parser-Interpreter Neural Network (SPINN), which combines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shift-reduce parser.", "labels": [], "entities": []}, {"text": "Our model supports batched computation fora speedup of up to 25\u00d7 over other tree-structured models, and its integrated parser can operate on unparsed data with little loss inaccuracy.", "labels": [], "entities": []}, {"text": "We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models.", "labels": [], "entities": [{"text": "Stanford NLI entailment task", "start_pos": 22, "end_pos": 50, "type": "DATASET", "confidence": 0.880145251750946}]}], "introductionContent": [{"text": "A wide range of current models in NLP are built around a neural network component that produces vector representations of sentence meaning (e.g.,.", "labels": [], "entities": []}, {"text": "This component, the sentence encoder, is generally formulated as a learned parametric function from a sequence of word vectors to a sentence vector, and this function can take a range of different forms.", "labels": [], "entities": []}, {"text": "Common sentence encoders include sequencebased recurrent neural network models (RNNs, see) with Long Short-Term Memory (LSTM, * The first two authors contributed equally.", "labels": [], "entities": [{"text": "Long Short-Term Memory", "start_pos": 96, "end_pos": 118, "type": "METRIC", "confidence": 0.693787415822347}]}, {"text": "Figure 1: An illustration of two standard designs for sentence encoders.", "labels": [], "entities": []}, {"text": "The TreeRNN, unlike the sequence-based RNN, requires a substantially different connection structure for each sentence, making batched computation impractical., which accumulate information over the sentence sequentially; convolutional neural networks, which accumulate information using filters over short local sequences of words or characters; and tree-structured recursive neural networks, see), which propagate information up a binary parse tree.", "labels": [], "entities": []}, {"text": "Of these, the TreeRNN appears to be the principled choice, since meaning in natural language sentences is known to be constructed recursively according to a tree structure.", "labels": [], "entities": []}, {"text": "TreeRNNs have shown promise), but have  largely been overlooked in favor of sequencebased RNNs because of their incompatibility with batched computation and their reliance on external parsers.", "labels": [], "entities": []}, {"text": "Batched computation-performing synchronized computation across many examples at once-yields order-of-magnitude improvements in model run time, and is crucial in enabling neural networks to be trained efficiently on large datasets.", "labels": [], "entities": []}, {"text": "Because TreeRNNs use a different model structure for each sentence, as in, efficient batching is impossible in standard implementations.", "labels": [], "entities": []}, {"text": "Partly to address efficiency problems, standard TreeRNN models commonly only operate on sentences that have already been processed by a syntactic parser, which slows and complicates the use of these models attest time for most applications.", "labels": [], "entities": []}, {"text": "This paper introduces anew model to address both these issues: the Stack-augmented ParserInterpreter Neural Network, or SPINN, shown in.", "labels": [], "entities": []}, {"text": "SPINN executes the computations of a tree-structured model in a linearized sequence, and can incorporate a neural network parser that produces the required parse structure on the fly.", "labels": [], "entities": []}, {"text": "This design improves upon the TreeRNN architecture in three ways: At test time, it can simultaneously parse and interpret unparsed sentences, removing the dependence on an external parser at nearly no additional computational cost.", "labels": [], "entities": []}, {"text": "Secondly, it supports batched computation for both parsed and unparsed sentences, yielding dramatic speedups over standard TreeRNNs.", "labels": [], "entities": []}, {"text": "Finally, it supports a novel tree-sequence hybrid architecture for handling local linear context in sentence interpretation.", "labels": [], "entities": [{"text": "sentence interpretation", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7469292879104614}]}, {"text": "This model is a basically plausible model of human sentence processing and yields substantial accuracy gains over pure sequence-or tree-based models.", "labels": [], "entities": [{"text": "human sentence processing", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6614226599534353}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.998496413230896}]}, {"text": "We evaluate SPINN on the Stanford Natural Language Inference entailment task, and find that it significantly outperforms other sentence-encoding-based models, even with a relatively simple and underpowered implementation of the built-in parser.", "labels": [], "entities": [{"text": "Stanford Natural Language Inference entailment task", "start_pos": 25, "end_pos": 76, "type": "TASK", "confidence": 0.7327053348223368}]}, {"text": "We also find that SPINN yields speed increases of up to 25\u00d7 over a standard TreeRNN implementation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate SPINN on the task of natural language inference (NLI, a.k.a. recognizing textual entailment, or RTE;).", "labels": [], "entities": []}, {"text": "NLI is a sentence pair classification task, in which a model reads two sentences (a premise and a hypothesis), and outputs a judgment of entailment, contradiction, or neutral, reflecting the relationship between the meanings of the two sentences.", "labels": [], "entities": [{"text": "sentence pair classification task", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.7622733563184738}]}, {"text": "Below is an example sentence pair and judgment from the SNLI corpus which we use in our experiments: Premise: Girl in a redcoat, blue head wrap and jeans is making a snow angel.", "labels": [], "entities": [{"text": "SNLI corpus", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.7436516582965851}, {"text": "Premise", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9827921986579895}]}, {"text": "Hypothesis: A girl outside plays in the snow.", "labels": [], "entities": []}, {"text": "Label: entailment SNLI is a corpus of 570k human-labeled pairs of scene descriptions like this one.", "labels": [], "entities": []}, {"text": "We use the standard train-test split and ignore unlabeled examples, which leaves about 549k examples for training, 9,842 for development, and 9,824 for testing.", "labels": [], "entities": []}, {"text": "SNLI labels are roughly balanced, with the most frequent label, entailment, making up 34.2% of the test set.", "labels": [], "entities": []}, {"text": "Although NLI is framed as a simple three-way classification task, it is nonetheless an effective way of evaluating the ability of a model to extract broadly informative representations of sentence meaning.", "labels": [], "entities": []}, {"text": "In order fora model to perform reliably well on NLI, it must be able to represent and reason with the core phenomena of natural language semantics, including quantification, coreference, scope, and several types of ambiguity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Hyperparameter ranges and values. Range shows the hyperparameter ranges explored during  random search. Strategy indicates whether sampling from the range was uniform, or log-uniform. Dropout  parameters are expressed as keep rates rather than drop rates.", "labels": [], "entities": []}, {"text": " Table 3: Results on SNLI 3-way inference classification. Params. is the approximate number of trained  parameters (excluding word embeddings for all models). Trans. acc. is the model's accuracy in predicting  parsing transitions at test time. Train and test are SNLI classification accuracy.", "labels": [], "entities": [{"text": "SNLI 3-way inference classification", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.8959832936525345}, {"text": "Params.", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9892928600311279}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9981854557991028}, {"text": "predicting  parsing transitions", "start_pos": 198, "end_pos": 229, "type": "TASK", "confidence": 0.7306919495264689}, {"text": "SNLI classification", "start_pos": 263, "end_pos": 282, "type": "TASK", "confidence": 0.8395338952541351}, {"text": "accuracy", "start_pos": 283, "end_pos": 291, "type": "METRIC", "confidence": 0.6496862769126892}]}]}