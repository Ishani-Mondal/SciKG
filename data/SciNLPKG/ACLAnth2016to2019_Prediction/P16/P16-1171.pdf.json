{"title": [{"text": "Physical Causality of Action Verbs in Grounded Language Understanding", "labels": [], "entities": [{"text": "Physical Causality of Action Verbs in Grounded Language Understanding", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.593726764122645}]}], "abstractContent": [{"text": "Linguistics studies have shown that action verbs often denote some Change of State (CoS) as the result of an action.", "labels": [], "entities": []}, {"text": "However, the causality of action verbs and its potential connection with the physical world has not been systematically explored.", "labels": [], "entities": []}, {"text": "To address this limitation, this paper presents a study on physical causality of action verbs and their implied changes in the physical world.", "labels": [], "entities": []}, {"text": "We first conducted a crowd-sourcing experiment and identified eighteen categories of physical causality for action verbs.", "labels": [], "entities": []}, {"text": "For a subset of these categories , we then defined a set of detectors that detect the corresponding change from visual perception of the physical environment.", "labels": [], "entities": []}, {"text": "We further incorporated physical causality modeling and state detection in grounded language understanding.", "labels": [], "entities": [{"text": "state detection", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.7374995797872543}]}, {"text": "Our empirical studies have demonstrated the effectiveness of causality modeling in grounding language to perception.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistics studies have shown that action verbs often denote some change of state (CoS) as the result of an action, where the change of state often involves an attribute of the direct object of the verb . For example, the result of \"slice a pizza\" is that the state of the object (pizza) changes from one big piece to several smaller pieces.", "labels": [], "entities": []}, {"text": "This change of state can be perceived from the physical world.", "labels": [], "entities": []}, {"text": "In Artificial Intelligence (, decades of research on planning, for example, back to the early days of the STRIPS planner (Fikes and Nilsson, * This work was conducted at Michigan State University where the author received his MS degree.", "labels": [], "entities": [{"text": "STRIPS planner", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.6587733626365662}]}, {"text": "1971), have defined action schemas to capture the change of state caused by a given action.", "labels": [], "entities": []}, {"text": "Based on action schemas, planning algorithms can be applied to find a sequence of actions to achieve a goal state ().", "labels": [], "entities": []}, {"text": "The state of the physical world is a very important notion and changing the state becomes a driving force for agents' actions.", "labels": [], "entities": []}, {"text": "Thus, motivated by linguistic literature on action verbs and AI literature on action representations, in our view, modeling change of physical state for action verbs, in other words, physical causality, can better connect language to the physical world.", "labels": [], "entities": []}, {"text": "Although this kind of physical causality has been described in linguistic studies , a detailed account of potential causality that could be denoted by an action verb is lacking.", "labels": [], "entities": []}, {"text": "For example, in VerbNet () the semantic representation for various verbs may indicate that a change of state is involved, but it does not provide the specifics associated with the verb's meaning (e.g., to what attribute of its patient the changes might occur).", "labels": [], "entities": []}, {"text": "To address this limitation, we have conducted an empirical investigation on verb semantics from anew angle of how they may change the state of the physical world.", "labels": [], "entities": []}, {"text": "As the first step in this investigation, we selected a set of action verbs from a cooking domain and conducted a crowd-sourcing study to examine the potential types of causality associated with these verbs.", "labels": [], "entities": []}, {"text": "Motivated by linguistics studies on typology for gradable adjectives, which also have a notion of change along a scale (), we developed a set of eighteen main categories to characterize physical causality.", "labels": [], "entities": []}, {"text": "We then defined a set of change-of-state detectors focusing on visual perception.", "labels": [], "entities": []}, {"text": "We further applied two approaches, a knowledge-driven approach and a learning-based approach, to incorporate causality modeling in grounded language understanding.", "labels": [], "entities": []}, {"text": "Our empirical results have demonstrated that both of these approaches achieve significantly better performance in grounding language to perception compared to previous approaches ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted our experiments using the dataset from (.", "labels": [], "entities": []}, {"text": "This dataset was developed from a subset of the TACoS corpus.", "labels": [], "entities": [{"text": "TACoS corpus", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.9018819630146027}]}, {"text": "It contains a set of video clips paired with natural language descriptions related to two cooking tasks \"cutting cucumber\" and \"cutting bread\".", "labels": [], "entities": []}, {"text": "Each task has 5 videos showing how different people perform the same task, and each of these videos was split into pairs of video clips and corresponding sentences.", "labels": [], "entities": []}, {"text": "For each video clip, objects are annotated with bounding boxes, tracks,: Grounding accuracy on four semantic roles and labels (e.g. \"cucumber, cutting board\" etc).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9874838590621948}]}, {"text": "For each sentence, the semantic roles of a verb are extracted using Propbank) definitions and each of them is annotated with the ground truth groundings in terms of the object tracks in the corresponding video clip.", "labels": [], "entities": []}, {"text": "We selected the 11 most frequent verbs (get, take, wash, cut, rinse, slice, place, peel, put, remove, open) and the 4 most frequent explicit semantic roles (agent, patient, source, destination) in this evaluation.", "labels": [], "entities": []}, {"text": "In total, this dataset includes 977 pairs of video clips and corresponding sentences, and 1096 verb-patient occurrences.", "labels": [], "entities": []}, {"text": "We compare our knowledge-driven approach (VC-Knowledge) and learning-based approach (VC-Learning) with the following two baselines.", "labels": [], "entities": []}, {"text": "This method simply grounds the semantic role to the track whose label matches the word phrase.", "labels": [], "entities": []}, {"text": "If there are multiple matching tracks, it will randomly choose one of them.", "labels": [], "entities": []}, {"text": "If there is no matching track, it will randomly select one from all the tracks..", "labels": [], "entities": []}, {"text": "This work studies grounded semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.6208883623282114}]}, {"text": "The evaluation data from this work is used in this paper.", "labels": [], "entities": []}, {"text": "It is a natural baseline for comparison.", "labels": [], "entities": []}, {"text": "To evaluate the learning-based approaches such as VC-Learning and), 75% of video clips with corresponding sentences were randomly sampled as the training set.", "labels": [], "entities": []}, {"text": "The remaining 25% were used as the test set.", "labels": [], "entities": []}, {"text": "For approaches which do not need training such as Label Matching and VC-Knowledge, we used the same test set to report their results.", "labels": [], "entities": [{"text": "Label Matching", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.7693285644054413}]}, {"text": "The results of the patient role grounding for each verb are shown in.", "labels": [], "entities": []}, {"text": "The results of grounding all four semantic roles are shown in Table 5.", "labels": [], "entities": []}, {"text": "The scores in bold are statistically significant (p < 0.05) compared to the Label Matching method.", "labels": [], "entities": [{"text": "Label Matching", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.7000341415405273}]}, {"text": "The scores with an asterisk ( * ) are statistically significant (p < 0.05) compared to (.", "labels": [], "entities": []}, {"text": "As it can be difficult to obtain labels for the track, especially when the vision system encounters novel objects, we further conducted several experiments assuming we do not know the labels for the object tracks.", "labels": [], "entities": []}, {"text": "In this case, only geometric information of tracked objects is available. and also include these results.", "labels": [], "entities": []}, {"text": "From the grounding results, we can see that the causality modeling has shown to be very effective in grounding semantic roles.", "labels": [], "entities": []}, {"text": "First of all, both the knowledge-driven approach and the learningbased approach outperform the two baselines.", "labels": [], "entities": []}, {"text": "In: Grounding accuracy on patient role using predicted causality knowledge.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9911608695983887}]}, {"text": "particular, our knowledge-driven approach (VCKnowledge) even outperforms the trained model (.", "labels": [], "entities": []}, {"text": "Our learning-based approach (VC-Learning) achieves the best overall performance.", "labels": [], "entities": []}, {"text": "In the learning-based approach, causality detection results can be seen as a set of intermediate visual features.", "labels": [], "entities": [{"text": "causality detection", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7431391179561615}]}, {"text": "The reason that our learning-based approach significantly outperforms the similar model in ( is that the causality categorization provides a good guideline for designing intermediate visual features.", "labels": [], "entities": []}, {"text": "These causality detectors focus on the changes of state of objects, which are more robust than the geometric features used in ().", "labels": [], "entities": []}, {"text": "In the setting of no object recognition labels, VC-Knowledge and VC-Learning also generate significantly better grounding accuracy than the two baselines.", "labels": [], "entities": [{"text": "object recognition labels", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7816407481829325}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9858549237251282}]}, {"text": "This once again demonstrates the advantage of using causality detection results as intermediate visual features.", "labels": [], "entities": []}, {"text": "All these results illustrate the potential of causality modeling for grounded language understanding.", "labels": [], "entities": [{"text": "grounded language understanding", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.6240868965784708}]}, {"text": "The results in also indicate that grounding source or destination is more difficult than grounding patient or agent.", "labels": [], "entities": []}, {"text": "One reason could be that source and destination do not exhibit obvious change of state as a result of action, so their groundings usually depend on the correct grounding of other roles such as patient.", "labels": [], "entities": []}, {"text": "Since automated tracking for this TACoS dataset is notably difficult due to the complexity of the scene and the lack of depth information, our current results are based on annotated tracks.", "labels": [], "entities": [{"text": "TACoS dataset", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.7323329746723175}]}, {"text": "But object tracking algorithms have made significant progress in recent years ().", "labels": [], "entities": [{"text": "object tracking", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9056840240955353}]}, {"text": "We intend to apply our algorithms with automated tracking on real scenes in the future.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Grounding accuracy on patient role", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9871331453323364}]}, {"text": " Table 5: Grounding accuracy on four semantic roles", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9701067209243774}]}, {"text": " Table 6: Grounding accuracy on patient role using predicted causality knowledge.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9945675134658813}]}]}