{"title": [{"text": "Dimensional Sentiment Analysis Using a Regional CNN-LSTM Model", "labels": [], "entities": [{"text": "Dimensional Sentiment Analysis", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8152799208958944}]}], "abstractContent": [{"text": "Dimensional sentiment analysis aims to recognize continuous numerical values in multiple dimensions such as the valence-arousal (VA) space.", "labels": [], "entities": [{"text": "Dimensional sentiment analysis", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9174460967381796}]}, {"text": "Compared to the categorical approach that focuses on sentiment classification such as binary classification (i.e., positive and negative), the dimensional approach can provide more fine-grained sentiment analysis.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.8912907540798187}, {"text": "sentiment analysis", "start_pos": 194, "end_pos": 212, "type": "TASK", "confidence": 0.8007604777812958}]}, {"text": "This study proposes a regional CNN-LSTM model consisting of two parts: regional CNN and LSTM to predict the VA ratings of texts.", "labels": [], "entities": []}, {"text": "Unlike a conventional CNN which considers a whole text as input, the proposed regional CNN uses an individual sentence as a region, dividing an input text into several regions such that the useful affective information in each region can be extracted and weighted according to their contribution to the VA prediction.", "labels": [], "entities": [{"text": "VA", "start_pos": 303, "end_pos": 305, "type": "METRIC", "confidence": 0.8622682690620422}]}, {"text": "Such regional information is sequentially integrated across regions using LSTM for VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.9277649819850922}]}, {"text": "By combining the regional CNN and LSTM, both local (re-gional) information within sentences and long-distance dependency across sentences can be considered in the prediction process.", "labels": [], "entities": []}, {"text": "Experimental results show that the proposed method outperforms lexicon-based, regression based , and NN-based methods proposed in previous studies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis has been useful in the development of online applications for customer reviews and public opinion analysis (.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.951683908700943}, {"text": "public opinion analysis", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.6406725148359934}]}, {"text": "In sentiment representation, the categorical approach represents emotional states as several discrete classes such as binary (i.e., positive and negative) or as multiple categories such as six basic emotions (anger, happiness, fear, sadness, disgust, and surprise).", "labels": [], "entities": [{"text": "sentiment representation", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.9379359185695648}]}, {"text": "Classification algorithms can then be used to identify sentiment categories from texts.", "labels": [], "entities": [{"text": "identify sentiment categories from texts", "start_pos": 46, "end_pos": 86, "type": "TASK", "confidence": 0.7487780690193176}]}, {"text": "The dimensional approach represents emotional states as continuous numerical values in multiple dimensions such as the valence-arousal (VA) space.", "labels": [], "entities": []}, {"text": "The dimension of valence refers to the degree of positive and negative sentiment, whereas the dimension of arousal refers to the degree of calm and excitement.", "labels": [], "entities": []}, {"text": "Both dimensions range from 1 (highly negative or calm) to 9 (highly positive or excited) based on the self-assessment manikin (SAM) annotation scheme (.", "labels": [], "entities": []}, {"text": "For example, the following passage consisting of three sentences is associated with a valence-arousal rating of (2.5, 7.8), which displays a high degree of negativity and arousal.", "labels": [], "entities": []}, {"text": "(r1) A few days ago I checked into a franchise hotel.", "labels": [], "entities": []}, {"text": "(r2) The front desk service was terrible, and they didn't know much about local attractions.", "labels": [], "entities": []}, {"text": "(r3) I would not recommend this hotel to a friend.", "labels": [], "entities": []}, {"text": "Such high-arousal negative (or high-arousal positive) texts are usually of interest and could prioritized in product review systems.", "labels": [], "entities": []}, {"text": "Dimensional sentiment analysis can accomplish this by recognizing the VA ratings of texts and rank them accordingly, thus providing more intelligent and fine-grained sentiment applications.), recurrent neural networks (RNN) and long shortterm memory (LSTM) ( ) have been successfully employed for categorical sentiment analysis.", "labels": [], "entities": [{"text": "Dimensional sentiment analysis", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7369989355405172}, {"text": "categorical sentiment analysis", "start_pos": 297, "end_pos": 327, "type": "TASK", "confidence": 0.8677946925163269}]}, {"text": "In general, CNN is capable of extracting local information but may fail to capture long-distance dependency.", "labels": [], "entities": []}, {"text": "LSTM can address this limitation by sequentially modeling texts across sentences.", "labels": [], "entities": []}, {"text": "Such NN-based and word embedding methods have not been well explored for dimensional sentiment analysis.", "labels": [], "entities": [{"text": "dimensional sentiment analysis", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.8766970634460449}]}, {"text": "This study proposes a regional CNN-LSTM model consisting of two parts, regional CNN and LSTM, to predict the VA ratings of texts.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.7962967753410339}]}, {"text": "We first construct word vectors for vocabulary words using word embedding.", "labels": [], "entities": []}, {"text": "The regional CNN is then used to build text vectors for the given texts being predicted based on the word vectors.", "labels": [], "entities": []}, {"text": "Unlike a conventional CNN which considers a whole text as input, the proposed regional CNN uses individual sentences as regions, dividing an input text into several regions such that the useful affective information in different regions can be extracted and weighted according to their contribution to the VA prediction.", "labels": [], "entities": [{"text": "VA", "start_pos": 306, "end_pos": 308, "type": "METRIC", "confidence": 0.8444827198982239}]}, {"text": "For example, in the aforementioned example text, it would be useful for the system to emphasize the two sentences/regions (r2) and (r3) containing negative affective information.", "labels": [], "entities": []}, {"text": "Finally, such regional information is sequentially integrated across regions using LSTM for VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.9458055198192596}]}, {"text": "By combining the regional CNN and LSTM, both local (regional) information within sentences and longdistance dependency across sentences can be considered in the prediction process.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the proposed regional CNN-LSTM model.", "labels": [], "entities": []}, {"text": "Section 3 reports the evaluation results of the proposed method against lexiconbased, regression-based, and NN-based methods.", "labels": [], "entities": []}, {"text": "Conclusions are finally drawn in Section 4.", "labels": [], "entities": []}, {"text": "shows the overall framework of the proposed regional CNN-LSTM model.", "labels": [], "entities": []}, {"text": "First, the word vectors of vocabulary words are trained from a large corpus using the word2vec toolkit.", "labels": [], "entities": []}, {"text": "For each given text, the regional CNN model uses a sentence as a region to divide the given text into R regions, i.e. r1,\u2026, ri, rj, rk,\u2026, rR.", "labels": [], "entities": []}, {"text": "In each region, useful affective features can be extracted once the word vectors sequentially pass through a convolutional layer and max pooling layer.", "labels": [], "entities": []}, {"text": "Such local (regional) features are then sequentially integrated across regions using LSTM to build a text vector for VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 117, "end_pos": 130, "type": "TASK", "confidence": 0.9713141322135925}]}], "datasetContent": [{"text": "This section evaluates the performance of the proposed regional CNN-LSTM model against lexicon-based, regression-based, and NN-based methods.", "labels": [], "entities": []}, {"text": "This experiment used two affective corpora.", "labels": [], "entities": []}, {"text": "i) Stanford Sentiment Treebank (SST)) contains 8,544 training texts, 2,210 test texts, and 1,101 validation texts.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank (SST))", "start_pos": 3, "end_pos": 37, "type": "DATASET", "confidence": 0.8780661424001058}]}, {"text": "Each text was rated with a single dimension (valence) in the range of (0, 1).", "labels": [], "entities": [{"text": "valence", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.951047956943512}]}, {"text": "ii) Chinese ValenceArousal Texts (CVAT) ( consists of 2,009 texts collected from social forums, manually rated with both valence and arousal dimensions in the range of (1, 9) using the SAM annotation scheme ().", "labels": [], "entities": [{"text": "Chinese ValenceArousal Texts (CVAT)", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.7905993362267812}]}, {"text": "The word vectors for English and Chinese were respectively trained using the Google News and Chinese wiki dumps (zhwiki) datasets.", "labels": [], "entities": [{"text": "Google News and Chinese wiki dumps (zhwiki) datasets", "start_pos": 77, "end_pos": 129, "type": "DATASET", "confidence": 0.7273183524608612}]}, {"text": "The dimensionality for both word vectors are 300.", "labels": [], "entities": []}, {"text": "where Ai is the actual value, Pi is the predicted value, n is the number of test samples, A and P respectively denote the arithmetic mean of A and P, and \u03c3 is the standard deviation.", "labels": [], "entities": [{"text": "Ai", "start_pos": 6, "end_pos": 8, "type": "METRIC", "confidence": 0.968062162399292}]}, {"text": "A lower RMSE or MAE and a higher r value indicates better prediction performance.", "labels": [], "entities": [{"text": "RMSE", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9873350858688354}, {"text": "MAE", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9868026375770569}]}, {"text": "A t-test was used to determine whether the performance difference was statistically significant.", "labels": [], "entities": []}, {"text": "respectively present the comparative results of the regional CNN-LSTM against several methods for VA prediction of texts in both English and Chinese corpora.", "labels": [], "entities": [{"text": "CNN-LSTM", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.8408013582229614}, {"text": "VA prediction", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.8324641585350037}]}, {"text": "For the lexicon-based methods, wGM outperformed wAM, which is consistent with the results presented in (.", "labels": [], "entities": []}, {"text": "Instead of using the VA ratings of words to directly measure those of texts, the regressionbased methods learned the correlations between the VA ratings of words and texts, thus yielding better performance.", "labels": [], "entities": []}, {"text": "Once the word embedding and deep learning techniques were introduced, the performance of NN-based methods (except RNN) jumped dramatically.", "labels": [], "entities": []}, {"text": "In addition, the proposed regional CNN-LSTM outperformed the other NN-based methods, indicating the effectiveness of sequentially integrating the regional information across regions.", "labels": [], "entities": []}, {"text": "Another observation is that the Pearson correlation coefficient of prediction in arousal is lower than that for the valence prediction, indicating that arousal is more difficult to predict.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 32, "end_pos": 63, "type": "METRIC", "confidence": 0.9648261268933614}, {"text": "valence prediction", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.654870793223381}]}], "tableCaptions": [{"text": " Table 1: Comparative results of different methods in SST.", "labels": [], "entities": [{"text": "SST", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9899982810020447}]}, {"text": " Table 2. Comparative results of different methods in CVAT.", "labels": [], "entities": []}]}