{"title": [{"text": "One model, two languages: training bilingual parsers with harmonized treebanks", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce an approach to train lexical-ized parsers using bilingual corpora obtained by merging harmonized treebanks of different languages, producing parsers that can analyze sentences in either of the learned languages, or even sentences that mix both.", "labels": [], "entities": []}, {"text": "We test the approach on the Universal Dependency Treebanks, training with MaltParser and MaltOpti-mizer.", "labels": [], "entities": [{"text": "Universal Dependency Treebanks", "start_pos": 28, "end_pos": 58, "type": "DATASET", "confidence": 0.6485534012317657}]}, {"text": "The results show that these bilingual parsers are more than competitive, as most combinations not only preserve accuracy , but some even achieve significant improvements over the corresponding mono-lingual parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9987674951553345}]}, {"text": "Preliminary experiments also show the approach to be promising on texts with code-switching and when more languages are added.", "labels": [], "entities": []}], "introductionContent": [{"text": "The need of frameworks for analyzing content in different languages has been discussed recently (, and multilingual dependency parsing is no stranger to this challenge.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.6178912619749705}]}, {"text": "Datadriven parsing models) can be trained for any language, given enough annotated data.", "labels": [], "entities": [{"text": "Datadriven parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6717126071453094}]}, {"text": "On languages where treebanks are not available, cross-lingual transfer can be used to train parsers fora target language with data from one or more source languages.", "labels": [], "entities": []}, {"text": "Data transfer approaches (e.g.,) map linguistic annotations across languages through parallel corpora.", "labels": [], "entities": [{"text": "Data transfer", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7362740933895111}]}, {"text": "Instead, model transfer approaches (e.g.) rely on crosslinguistic syntactic regularities to learn aspects of the source language that help parse an unseen language, without parallel corpora.", "labels": [], "entities": [{"text": "model transfer", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7906533479690552}]}, {"text": "Model transfer approaches have benefitted from the development of multilingual resources that harmonize annotations.", "labels": [], "entities": [{"text": "Model transfer", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7187079340219498}]}, {"text": "proposed a universal tagset, and  employed it to transfer delexicalized parsers.", "labels": [], "entities": []}, {"text": "More recently, several projects have presented treebank collections of multiple languages with their annotations standardized at the syntactic level, including HamleDT () and the Universal Dependency.", "labels": [], "entities": [{"text": "HamleDT", "start_pos": 160, "end_pos": 167, "type": "DATASET", "confidence": 0.9066100716590881}]}, {"text": "In this paper we also rely on these resources, but with a different goal: we use universal annotations to train bilingual dependency parsers that effectively analyze unseen sentences in any of the learned languages.", "labels": [], "entities": []}, {"text": "Unlike delexicalized approaches for model transfer, our parsers exploit lexical features.", "labels": [], "entities": [{"text": "model transfer", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.764254629611969}]}, {"text": "The results are encouraging: our experiments show that, starting with a monolingual parser, we can \"teach\" it an additional language for free in terms of accuracy (i.e., without significant accuracy loss on the original language, in spite of learning a more complex task) in the vast majority of cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9971954822540283}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9900060296058655}]}], "datasetContent": [{"text": "To ensure a fair comparison between monolingual and bilingual models, we chose to optimize the models from scratch with MaltOptimizer, expecting it to choose the parsing algorithm and feature model which is most likely to obtain good results.", "labels": [], "entities": []}, {"text": "We observed that the selection of a bilingual parsing algorithm was not necessarily related with the algorithms selected for the monolingual models.", "labels": [], "entities": []}, {"text": "The system sometimes chose an algorithm fora bilingual model that was not selected for any of 1 http://grupolys.org/software/PARSERS/ the corresponding monolingual models.", "labels": [], "entities": []}, {"text": "In view of this, and as it is known that different parsing algorithms can be more or less competitive depending on the language, we ran a control experiment to evaluate the models setting the same parsing algorithm for all cases, executing only phase 3 of MaltOptimizer.", "labels": [], "entities": []}, {"text": "We chose the arc-eager parser for this experiment, as it was the algorithm that MaltOptimizer chose most frequently for the monolingual models in the previous configuration.", "labels": [], "entities": []}, {"text": "The aim was to compare the accuracy of the bilingual models with respect to the monolingual ones, when there is no variation on the parsing algorithm between them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9993230104446411}]}, {"text": "The results of this control experiment are not shown for space reasons, but they were very similar to those of the original experiment.", "labels": [], "entities": []}, {"text": "compares the accuracy of bilingual models to that of monolingual ones, under the treebankdependent tags configuration.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9993937015533447}]}, {"text": "Each table cell shows the accuracy of a model, in terms of LAS and UAS.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995212554931641}, {"text": "LAS", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9966819882392883}, {"text": "UAS", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9612852931022644}]}, {"text": "Cells in the diagonal correspond to monolingual models (the baseline), with the cell located at row i and column i representing the result obtained by training a monolingual parser on the training set of language Li , and evaluating it on the test set of the same language Li . Each cell outside the diagonal (at row i and column j, with j \ud97b\udf59 = i) shows the results of training a bilingual model on the training set for Li \u222a L j , evaluated on the test set of Li .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on the Universal Dependency Treebanks test sets using the gold POSTAG information. For each cell,", "labels": [], "entities": [{"text": "Universal Dependency Treebanks test sets", "start_pos": 29, "end_pos": 69, "type": "DATASET", "confidence": 0.765719723701477}, {"text": "POSTAG information", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.7661385536193848}]}, {"text": " Table 2: Performance on the Universal Dependency Treebanks test sets using the gold CPOSTAG information. The table is", "labels": [], "entities": [{"text": "Universal Dependency Treebanks test sets", "start_pos": 29, "end_pos": 69, "type": "DATASET", "confidence": 0.7730944871902465}, {"text": "CPOSTAG information", "start_pos": 85, "end_pos": 104, "type": "DATASET", "confidence": 0.9188776910305023}]}, {"text": " Table 3: Shared language-specific tags between pairs of", "labels": [], "entities": []}, {"text": " Table 4: Performance on a code-switching treebank com-", "labels": [], "entities": []}]}