{"title": [{"text": "Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change", "labels": [], "entities": []}], "abstractContent": [{"text": "Understanding how words change their meanings overtime is key to models of language and cultural evolution, but historical data on meaning is scarce, making theories hard to develop and test.", "labels": [], "entities": []}, {"text": "Word embeddings show promise as a di-achronic tool, but have not been carefully evaluated.", "labels": [], "entities": []}, {"text": "We develop a robust methodology for quantifying semantic change by evaluating word embeddings (PPMI, SVD, word2vec) against known historical changes.", "labels": [], "entities": []}, {"text": "We then use this methodology to reveal statistical laws of semantic evolution.", "labels": [], "entities": [{"text": "semantic evolution", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.8432464599609375}]}, {"text": "Using six historical corpora spanning four languages and two centuries, we propose two quantitative laws of semantic change: (i) the law of conformity-the rate of semantic change scales with an inverse power-law of word frequency; (ii) the law of innovation-independent of frequency , words that are more polysemous have higher rates of semantic change.", "labels": [], "entities": []}], "introductionContent": [{"text": "Shifts in word meaning exhibit systematic regularities.", "labels": [], "entities": []}, {"text": "The rate of semantic change, for example, is higher in some words than others) -compare the stable semantic history of cat (from ProtoGermanic kattuz, \"cat\") to the varied meanings of English cast: \"to mould\", \"a collection of actors', \"a hardened bandage\", etc.", "labels": [], "entities": []}, {"text": "(all from Old Norse kasta, \"to throw\",.", "labels": [], "entities": []}, {"text": "Various hypotheses have been offered about such regularities in semantic change, such as an increasing subjectification of meaning, or the grammaticalization of inferences (e.g.,).", "labels": [], "entities": []}, {"text": "But many core questions about semantic change remain unanswered.", "labels": [], "entities": [{"text": "semantic change", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.8905401825904846}]}, {"text": "One is the role of frequency.", "labels": [], "entities": []}, {"text": "Frequency plays a key role in other linguistic changes, associated sometimes with faster change-sound changes like lenition occur in more frequent words-and sometimes with slower change-high frequency words are more resistant to morphological regularization.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9018456935882568}]}, {"text": "What is the role of word frequency in meaning change?", "labels": [], "entities": [{"text": "meaning change", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.6986984461545944}]}, {"text": "Another unanswered question is the relationship between semantic change and polysemy.", "labels": [], "entities": []}, {"text": "Words gain senses overtime as they semantically drift, and polysemous words 1 occur in more diverse contexts, affecting lexical access speed) and rates of L2 learning).", "labels": [], "entities": []}, {"text": "But we don't know whether the diverse contextual use of polysemous words makes them more or less likely to undergo change.", "labels": [], "entities": []}, {"text": "Furthermore, polysemy is strongly correlated with frequency-high frequency words have more senses-so understanding how polysemy relates to semantic change requires controling for word frequency.", "labels": [], "entities": []}, {"text": "Answering these questions requires new methods that can go beyond the case-studies of a few words (often followed over widely different timeperiods) that are our most common diachronic data.", "labels": [], "entities": []}, {"text": "One promising avenue is the use of distributional semantics, in which words are embedded in vector spaces according to their co-occurrence relationships, and the embeddings of words: Two-dimensional visualization of semantic change in English using SGNS vectors.", "labels": [], "entities": []}, {"text": "a, The word gay shifted from meaning \"cheerful\" or \"frolicsome\" to referring to homosexuality.", "labels": [], "entities": []}, {"text": "b, In the early 20th century broadcast referred to \"casting out seeds\"; with the rise of television and radio its meaning shifted to \"transmitting signals\".", "labels": [], "entities": []}, {"text": "c, Awful underwent a process of pejoration, as it shifted from meaning \"full of awe\" to meaning \"terrible or appalling\" ( are then compared across time-periods.", "labels": [], "entities": [{"text": "Awful", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.49302956461906433}]}, {"text": "This new direction has been effectively demonstrated in a number of case-studies) and used to perform largescale linguistic change-point detection () as well as to test a few specific hypotheses, such as whether English synonyms tend to change meaning in similar ways (.", "labels": [], "entities": [{"text": "largescale linguistic change-point detection", "start_pos": 102, "end_pos": 146, "type": "TASK", "confidence": 0.5785793662071228}]}, {"text": "However, these works employ widely different embedding approaches and test their approaches only on English.", "labels": [], "entities": []}, {"text": "In this work, we develop a robust methodology for quantifying semantic change using embeddings by comparing state-of-the-art approaches (PPMI, SVD, word2vec) on novel benchmarks.", "labels": [], "entities": []}, {"text": "We then apply this methodology in a large-scale cross-linguistic analysis using 6 corpora spanning 200 years and 4 languages.", "labels": [], "entities": []}, {"text": "Based on this analysis, we propose two statistical laws relating frequency and polysemy to semantic change: \u2022 The law of conformity: Rates of semantic change scale with a negative power of word frequency.", "labels": [], "entities": []}, {"text": "\u2022 The law of innovation: After controlling for frequency, polysemous words have significantly higher rates of semantic change.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained models on the 6 datasets described in, taken from Google N-Grams () and the COHA corpus.", "labels": [], "entities": [{"text": "Google N-Grams", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.9049565494060516}, {"text": "COHA corpus", "start_pos": 87, "end_pos": 98, "type": "DATASET", "confidence": 0.9552766382694244}]}, {"text": "The Google N-Gram datasets are extremely large (comprising \u22486% of all books ever published), but they also contain many corpus artifacts due, e.g., to shifting sampling biases overtime.", "labels": [], "entities": [{"text": "Google N-Gram datasets", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7716799974441528}]}, {"text": "In contrast, the COHA corpus was carefully selected to be genre-balanced and representative of American English over the last 200 years, though as a result it is two orders of magnitude smaller.", "labels": [], "entities": [{"text": "COHA corpus", "start_pos": 17, "end_pos": 28, "type": "DATASET", "confidence": 0.9269841611385345}]}, {"text": "The COHA corpus also contains pre-extracted word lemmas, which we used to validate that our results hold at both the lemma and raw token levels.", "labels": [], "entities": [{"text": "COHA corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9517198204994202}]}, {"text": "All the datasets were aggregated to the granularity of decades.", "labels": [], "entities": []}, {"text": "We follow the recommendations of insetting the hyperparameters for the embedding methods, though preliminary experiments were used to tune key settings.", "labels": [], "entities": []}, {"text": "For all methods, we used symmetric context windows of size 4 (on each side).", "labels": [], "entities": []}, {"text": "For SGNS and SVD, we use embeddings of size 300.", "labels": [], "entities": []}, {"text": "See Appendix A for further implementation and pre-processing details.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Six large historical datasets from various languages and sources are used.", "labels": [], "entities": []}, {"text": " Table 2: Set of attested historical shifts used to evaluate the methods. The examples are taken from previous works on semantic  change and from the Oxford English Dictionary (OED), e.g. using 'obsolete' tags. The shift start points were estimated using  attestation dates in the OED. The first six examples are words that shifted dramatically in meaning while the remaining four are  words that acquired new meanings (while potentially also keeping their old ones).", "labels": [], "entities": [{"text": "Oxford English Dictionary (OED)", "start_pos": 150, "end_pos": 181, "type": "DATASET", "confidence": 0.8106155196825663}, {"text": "OED", "start_pos": 281, "end_pos": 284, "type": "DATASET", "confidence": 0.9546162486076355}]}, {"text": " Table 3: Performance on detection task, i.e. ability to cap- ture the attested shifts from", "labels": [], "entities": []}, {"text": " Table 2. SGNS and SVD capture  the correct directionality of the shifts in all cases (%Correct),  e.g., gay becomes more similar to homosexual, but there are  differences in whether the methods deem the shifts to be sta- tistically significant at the p < 0.05 level (%Sig).", "labels": [], "entities": [{"text": "Correct", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9858993887901306}]}]}