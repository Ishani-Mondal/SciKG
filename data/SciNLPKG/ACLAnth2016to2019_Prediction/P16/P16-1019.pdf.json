{"title": [{"text": "Idiom Token Classification using Sentential Distributed Semantics", "labels": [], "entities": [{"text": "Idiom Token Classification", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8342766364415487}]}], "abstractContent": [{"text": "Idiom token classification is the task of deciding fora set of potentially idiomatic phrases whether each occurrence of a phrase is a literal or idiomatic usage of the phrase.", "labels": [], "entities": [{"text": "Idiom token classification is the task of deciding fora set of potentially idiomatic phrases whether each occurrence of a phrase is a literal or idiomatic usage of the phrase", "start_pos": 0, "end_pos": 174, "type": "Description", "confidence": 0.7954780921853822}]}, {"text": "In this work we explore the use of Skip-Thought Vectors to create distributed representations that encode features that are predictive with respect to idiom token classification.", "labels": [], "entities": [{"text": "idiom token classification", "start_pos": 151, "end_pos": 177, "type": "TASK", "confidence": 0.6446369091669718}]}, {"text": "We show that classifiers using these representations have competitive performance compared with the state of the art in idiom token classification.", "labels": [], "entities": [{"text": "idiom token classification", "start_pos": 120, "end_pos": 146, "type": "TASK", "confidence": 0.7152052521705627}]}, {"text": "Importantly, however, our models use only the sentence containing the target phrase as input and are thus less dependent on a potentially inaccurate or incomplete model of discourse context.", "labels": [], "entities": []}, {"text": "We further demonstrate the feasibility of using these representations to train a competitive general idiom token classifier.", "labels": [], "entities": []}], "introductionContent": [{"text": "Idioms area class of multiword expressions (MWEs) whose meaning cannot be derived from their individual constituents.", "labels": [], "entities": []}, {"text": "Idioms often present idiosyncratic behaviour such as violating selection restrictions or changing the default semantic roles of syntactic categories.", "labels": [], "entities": []}, {"text": "Consequently, they present many challenges for Natural Language Processing (NLP) systems.", "labels": [], "entities": []}, {"text": "For example, in Statistical Machine Translation (SMT) it has been shown that translations of sentences containing idioms receive lower scores than translations of sentences that do not contain idioms).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.8528185288111368}]}, {"text": "Idioms are pervasive across almost all languages and text genres and as a result broad coverage NLP systems must explicitly handle idioms (.", "labels": [], "entities": []}, {"text": "A complicating factor, however, is that many idiomatic expressions can be used both literally or figuratively.", "labels": [], "entities": []}, {"text": "In general, idiomatic usages are more frequent, but for some expressions the literal meaning maybe more common (.", "labels": [], "entities": []}, {"text": "As a result, there are two fundamental tasks in NLP idiom processing: idiom type classification is the task of identifying expressions that have possible idiomatic interpretations and idiom token classification is the task of distinguishing between idiomatic and literal usages of potentially idiomatic phrases.", "labels": [], "entities": [{"text": "NLP idiom processing", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.787260631720225}, {"text": "idiom type classification", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6261161466439565}, {"text": "idiom token classification", "start_pos": 184, "end_pos": 210, "type": "TASK", "confidence": 0.6154763400554657}]}, {"text": "In this paper we focus on this second task, idiom token classification.", "labels": [], "entities": [{"text": "idiom token classification", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.7609659234682719}]}, {"text": "Previous work on idiom token classification, such as and), often frame the problem in terms of modelling the global lexical context.", "labels": [], "entities": [{"text": "idiom token classification", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.6441067059834799}]}, {"text": "For example, these models try to capture the fact that the idiomatic expression break the ice is likely to have a literal meaning in a context containing words such as cold, frozen or water and an idiomatic meaning in a context containing words such as meet or discuss (.", "labels": [], "entities": []}, {"text": "Frequently these global lexical models create a different idiom token classifier for each phrase.", "labels": [], "entities": []}, {"text": "However, a number of papers on idiom type and token classification have pointed to a range of other features that could be useful for idiom token classification; including local syntactic and lexical patterns) and cue words ().", "labels": [], "entities": [{"text": "token classification", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.8681893944740295}, {"text": "idiom token classification", "start_pos": 134, "end_pos": 160, "type": "TASK", "confidence": 0.7600143551826477}]}, {"text": "However, inmost cases these non-global features are specific to a particular phrase.", "labels": [], "entities": []}, {"text": "So a key challenge is to identify from a range of features which features are the correct features to use for idiom token classification fora specific expression.", "labels": [], "entities": [{"text": "idiom token classification", "start_pos": 110, "end_pos": 136, "type": "TASK", "confidence": 0.6208685537179311}]}, {"text": "Meanwhile, in recent years there has been an explosion in the use of neural networks for learning distributed representations for language (e.g.,, and).", "labels": [], "entities": []}, {"text": "These representations are automatically trained from data and can simultaneously encode multiple linguistics features.", "labels": [], "entities": []}, {"text": "For example, word embeddings can encode gender distinctions and plural-singular distinctions) and the representations generated in sequence to sequence mappings have been shown to be sensitive to word order ().", "labels": [], "entities": []}, {"text": "The recent development of Skip-Thought Vectors (or Sent2Vec) ( ) has provided an approach to learn distributed representations of sentences in an unsupervised manner.", "labels": [], "entities": []}, {"text": "In this paper we explore whether the representations generated by Sent2Vec encodes features that are useful for idiom token classification.", "labels": [], "entities": [{"text": "idiom token classification", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.7111508448918661}]}, {"text": "This question is particularly interesting because the Sent2Vec based models only use the sentence containing the phrase as input whereas the baselines systems use full the paragraph surrounding the sentence.", "labels": [], "entities": []}, {"text": "We further investigate the construction of a \"general\" classifier that can predict if a sentence contains literal or idiomatic language (independent of the expression) using just the distributed representation of the sentence.", "labels": [], "entities": []}, {"text": "This approach contrasts with previous work that has primarily adopted a \"per expression\" classifier approach and has been based on more elaborate context features, such as discourse and lexical cohesion between and sentence and the larger context.", "labels": [], "entities": []}, {"text": "We show that our method needs less contextual information than the state-of-the-art method and achieves competitive results, making it an important contribution to a range of applications that do not have access to a full discourse context.", "labels": [], "entities": []}, {"text": "We proceed by introducing that previous work in more detail.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following we describe a study that evaluates the predictiveness of the distributed representations generated by Sent2Vec for idiom token classifier.", "labels": [], "entities": []}, {"text": "We first evaluate these representations using a \"per expression\" study design (i.e., one classifier per expression) and compare our results to those of who applied multiparagraphs contexts to generate best results.", "labels": [], "entities": []}, {"text": "We also experiment with a \"general\" classifier trained and tested on a set of mixed expressions.", "labels": [], "entities": []}, {"text": "In order to make our results comparable with () we used the same VNC-Tokens dataset) that they used in their experiments.", "labels": [], "entities": [{"text": "VNC-Tokens dataset", "start_pos": 65, "end_pos": 83, "type": "DATASET", "confidence": 0.9290264248847961}]}, {"text": "The dataset used is a collection of sentences containing 53 different Verb Noun Constructions 2 (VNCs) extracted from the British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 122, "end_pos": 151, "type": "DATASET", "confidence": 0.9720291594664255}]}, {"text": "In total, the VNC-Token dataset has 2984 sentences where each sample sentence is labelled with one of three labels: I (idiomatic); L (literal); or Q (unknown).", "labels": [], "entities": [{"text": "VNC-Token dataset", "start_pos": 14, "end_pos": 31, "type": "DATASET", "confidence": 0.9571480751037598}]}, {"text": "Of the 56 VNCs in the dataset 28 of these expressions have a reasonably balanced representation (with similar numbers of idiomatic and literal occurrences in the corpus) and the other 28 expressions have a skewed representation (with one class much more common then the other).", "labels": [], "entities": []}, {"text": "Following the approach taken by, in this study we use the \"balanced\" part of the dataset and considered only those sentences labelled as \"I\" and \"L\" (1205 sentences -749 labelled as \"I\" and 456 labelled as \"L\").", "labels": [], "entities": []}, {"text": "reported the precision, recall and f1-score of their models on 4 of the expressions from the balanced section of dataset: BlowWhistle; MakeScene; LoseHead; and TakeHeart.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9997054934501648}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9989445805549622}, {"text": "f1-score", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9723620414733887}, {"text": "BlowWhistle", "start_pos": 122, "end_pos": 133, "type": "DATASET", "confidence": 0.6734240651130676}, {"text": "MakeScene", "start_pos": 135, "end_pos": 144, "type": "DATASET", "confidence": 0.7075105905532837}, {"text": "TakeHeart", "start_pos": 160, "end_pos": 169, "type": "DATASET", "confidence": 0.9286419153213501}]}, {"text": "So, our first experiment is designed to compare our models with these baseline systems on a \"per-expression\" basis.", "labels": [], "entities": []}, {"text": "For this experiment we built a training and test set for each of these expressions by randomly sampling expressions following the same distributions presented in.", "labels": [], "entities": []}, {"text": "In we present those distribution and the split into training and test sets.", "labels": [], "entities": []}, {"text": "The numbers in parentheses denote the number of samples labelled as \"I\".", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results in terms of precision (P.), recall (R.) and f1-score (F1) on the four chosen expressions.", "labels": [], "entities": [{"text": "precision (P.)", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.9297832101583481}, {"text": "recall (R.)", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.940170094370842}, {"text": "f1-score (F1)", "start_pos": 62, "end_pos": 75, "type": "METRIC", "confidence": 0.9028118252754211}]}]}