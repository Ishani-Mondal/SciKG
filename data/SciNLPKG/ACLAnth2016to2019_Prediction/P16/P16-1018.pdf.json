{"title": [{"text": "Literal and Metaphorical Senses in Compositional Distributional Semantic Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Metaphorical expressions are pervasive in natural language and pose a substantial challenge for computational semantics.", "labels": [], "entities": []}, {"text": "The inherent compositionality of metaphor makes it an important test case for compositional distributional semantic models (CDSMs).", "labels": [], "entities": []}, {"text": "This paper is the first to investigate whether metaphorical composition warrants a distinct treatment in the CDSM framework.", "labels": [], "entities": [{"text": "metaphorical composition", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.815579354763031}]}, {"text": "We propose a method to learn metaphors as linear transformations in a vector space and find that, across a variety of semantic domains, explicitly modeling metaphor improves the resulting semantic representations.", "labels": [], "entities": []}, {"text": "We then use these representations in a metaphor identification task, achieving a high performance of 0.82 in terms of F-score.", "labels": [], "entities": [{"text": "metaphor identification task", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.879558781782786}, {"text": "F-score", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.9963845014572144}]}], "introductionContent": [{"text": "An extensive body of behavioral and corpuslinguistic studies suggests that metaphors are pervasive in everyday language and play an important role in how humans define and understand the world.", "labels": [], "entities": []}, {"text": "According to Conceptual Metaphor Theory (CMT), individual metaphorical expressions, or linguistic metaphors (LMs), are instantiations of broader generalizations referred to as conceptual metaphors (CMs).", "labels": [], "entities": [{"text": "Conceptual Metaphor Theory (CMT)", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.7494099934895834}]}, {"text": "For example, the phrases half-baked idea, food for thought, and spoon-fed information are LMs that instantiate the CM IDEAS ARE FOOD.", "labels": [], "entities": [{"text": "CM IDEAS", "start_pos": 115, "end_pos": 123, "type": "TASK", "confidence": 0.42334333062171936}, {"text": "ARE", "start_pos": 124, "end_pos": 127, "type": "METRIC", "confidence": 0.4558863639831543}, {"text": "FOOD", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.49170416593551636}]}, {"text": "These phrases reflect a mapping from the source domain of FOOD to the target domain of IDEAS.", "labels": [], "entities": [{"text": "FOOD", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.8891116976737976}, {"text": "IDEAS", "start_pos": 87, "end_pos": 92, "type": "DATASET", "confidence": 0.9578419327735901}]}, {"text": "Two central claims of the CMT are that this mapping is systematic, in the sense that it consists of a fixed set of ontological correspondences, such as thinking is preparing, communication is feeding, understanding is digestion; and that this mapping can be productively extended to produce novel LMs that obey these correspondences.", "labels": [], "entities": []}, {"text": "Recent years have seen the rise of statistical techniques for metaphor detection.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9786570966243744}]}, {"text": "Several of these techniques leverage distributional statistics and vector-space models of meaning to classify utterances as literal or metaphorical).", "labels": [], "entities": []}, {"text": "An important insight of these studies is that metaphorical meaning is not merely a property of individual words, but rather arises through cross-domain composition.", "labels": [], "entities": []}, {"text": "The meaning of sweet, for instance, is not intrinsically metaphorical.", "labels": [], "entities": []}, {"text": "Yet this word may exhibit a range of metaphorical meanings-e.g., sweet dreams, sweet person, sweet victory-that are created through the interplay of source and target domains.", "labels": [], "entities": []}, {"text": "If metaphor is compositional, how do we represent it, and how can we use it in a compositional framework for meaning?", "labels": [], "entities": []}, {"text": "Compositional distributional semantic models (CDSMs) provide a compact model of compositionality that produces vector representations of phrases while avoiding the sparsity and storage issues associated with storing vectors for each phrase in a language explicitly.", "labels": [], "entities": []}, {"text": "One of the most popular CDSM frameworks represents nouns as vectors, adjectives as matrices that act on the noun vectors, and transitive verbs as third-order tensors that act on noun or noun phrase vectors.", "labels": [], "entities": []}, {"text": "The meaning of a phrase is then derived by composing these lexical representations.", "labels": [], "entities": []}, {"text": "The vast majority of such models build a single representation for all senses of a word, collapsing distinct senses together.", "labels": [], "entities": []}, {"text": "One exception is the work of, who investigated homonymy, in which lexical items have identical form but unrelated meanings (e.g., bank).", "labels": [], "entities": []}, {"text": "They found that deriving verb tensors from all instances of a homonymous form (as compared to training a separate tensor for each distinct sense) loses information and degrades the resultant phrase vector representations.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there has not yet been a study of regular polysemy (i.e. metaphorical or metonymic sense distinctions) in the context of compositional distributional semantics.", "labels": [], "entities": []}, {"text": "Yet, due to systematicity in metaphorical cross-domain mappings, there are likely to be systematic contextual sense distinctions that can be captured by a CDSM, improving the resulting semantic representations.", "labels": [], "entities": []}, {"text": "In this paper, we investigate whether metaphor, as a case of regular polysemy, warrants distinct treatment under a compositional distributional semantic framework.", "labels": [], "entities": []}, {"text": "We propose anew approach to CDSMs, in which metaphorical meanings are distinct but structurally related to literal meanings.", "labels": [], "entities": []}, {"text": "We then extend the generalizability of our approach by proposing a method to automatically learn metaphorical mappings as linear transformations in a CDSM.", "labels": [], "entities": []}, {"text": "We focus on modeling adjective senses and evaluate our methods on anew data set of 8592 adjective-noun pairs annotated for metaphoricity, which we will make publicly available.", "labels": [], "entities": []}, {"text": "Finally, we apply our models to classify unseen adjective-noun (AN) phrases as literal or metaphorical and obtain state-of-the-art performance in the metaphor identification task.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 150, "end_pos": 173, "type": "TASK", "confidence": 0.7208640873432159}]}], "datasetContent": [{"text": "We trained our DSMs from a corpus of 4.58 billion tokens.", "labels": [], "entities": []}, {"text": "Our corpus construction procedure is modeled on that of.", "labels": [], "entities": [{"text": "corpus construction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7085729837417603}]}, {"text": "The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (, the BNC (, and the English Gigaword corpus ().", "labels": [], "entities": [{"text": "UKWaC", "start_pos": 62, "end_pos": 67, "type": "DATASET", "confidence": 0.9881288409233093}, {"text": "BNC", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8109179735183716}, {"text": "English Gigaword corpus", "start_pos": 90, "end_pos": 113, "type": "DATASET", "confidence": 0.8215924104054769}]}, {"text": "The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit () for Python.", "labels": [], "entities": []}, {"text": "We created an annotated dataset of 8592 AN phrases (3991 literal, 4601 metaphorical).", "labels": [], "entities": []}, {"text": "Our choice of adjectives was inspired by the test set of, though our annotated dataset is considerably larger.", "labels": [], "entities": []}, {"text": "We focused on 23 adjectives that can have both metaphorical and literal senses, and which function as source-domain words in relatively productive CMs: TEMPERATURE (cold, heated, icy, warm), LIGHT (bright, brilliant, dim), TEXTURE (rough, smooth, soft); SUBSTANCE (dense, heavy, solid), CLARITY (clean, clear, murky), TASTE (bitter, sour, sweet), STRENGTH (strong, weak), and DEPTH (deep, shallow).", "labels": [], "entities": [{"text": "TEMPERATURE", "start_pos": 152, "end_pos": 163, "type": "METRIC", "confidence": 0.9904630780220032}, {"text": "LIGHT", "start_pos": 191, "end_pos": 196, "type": "METRIC", "confidence": 0.9943660497665405}, {"text": "TEXTURE", "start_pos": 223, "end_pos": 230, "type": "METRIC", "confidence": 0.9902674555778503}, {"text": "TASTE", "start_pos": 318, "end_pos": 323, "type": "METRIC", "confidence": 0.9959023594856262}, {"text": "STRENGTH", "start_pos": 347, "end_pos": 355, "type": "METRIC", "confidence": 0.9960721731185913}, {"text": "DEPTH", "start_pos": 376, "end_pos": 381, "type": "METRIC", "confidence": 0.9975630044937134}]}, {"text": "We extracted all AN phrases involving these adjectives that occur in our corpus at least 10 times.", "labels": [], "entities": []}, {"text": "We filtered out all phrases that require wider context to establish their meaning or metaphoricity-e.g., bright side, weak point.", "labels": [], "entities": []}, {"text": "The remaining phrases were annotated using a procedure based on.", "labels": [], "entities": []}, {"text": "Annotators were encouraged to rely on their own intuition of metaphor, but were provided with the following guidance: \u2022 For each phrase, establish the meaning of the adjective in the context of the phrase.", "labels": [], "entities": []}, {"text": "\u2022 Try to imagine a more basic meaning of this adjective in other contexts.", "labels": [], "entities": []}, {"text": "Basic meanings tend to be: more concrete; related to embodied actions/perceptions/sensations; more precise; historically older/more \"original\".", "labels": [], "entities": []}, {"text": "\u2022 If you can establish a basic meaning distinct from the meaning of the adjective in this context, it is likely to be used metaphorically.", "labels": [], "entities": []}, {"text": "If requested, a randomly sampled sentence from the corpus that contained the phrase in question was also provided.", "labels": [], "entities": []}, {"text": "The annotation was performed by one of the authors.", "labels": [], "entities": []}, {"text": "The author's annotations were compared against those of a university graduate native English-speaking volunteer who was not involved in the research, on a sample of 500 phrases.", "labels": [], "entities": []}, {"text": "Interannotator reliability) was \u03ba = 0.80 (SE = .02).", "labels": [], "entities": [{"text": "Interannotator reliability", "start_pos": 0, "end_pos": 26, "type": "METRIC", "confidence": 0.8048354685306549}, {"text": "SE", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9984771609306335}]}, {"text": "Our annotated data set is publicly available at http: //bit.ly/1TQ5czN  We used a cross-validation scheme where we treated each adjective in a source domain as a fold in training the domain's metaphor transformation matrix.", "labels": [], "entities": []}, {"text": "The nested cross-validation procedure we use to set regularization parameters \u03bb and evaluate performance requires at least 3 adjectives in a source domain, so we evaluate on the 6 source domain classes containing at least 3 adjectives.", "labels": [], "entities": []}, {"text": "The total number of phrases for these 19 adjectives is 6987 (3659 metaphorical, 3328 literal).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the method of  \u00a74.4 (MET- LIT) against various baselines.", "labels": [], "entities": [{"text": "MET- LIT)", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.8705206513404846}]}, {"text": " Table 2: Performance of method of  \u00a75.4 (TRANS- LIT) against method of  \u00a74.4 (MET-LIT) and vari- ous baselines.", "labels": [], "entities": [{"text": "TRANS- LIT)", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.9506390690803528}]}]}