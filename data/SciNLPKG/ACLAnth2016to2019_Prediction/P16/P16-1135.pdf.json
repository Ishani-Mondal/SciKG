{"title": [{"text": "Identifying Causal Relations Using Parallel Wikipedia Articles", "labels": [], "entities": [{"text": "Identifying Causal Relations", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9019460479418436}]}], "abstractContent": [{"text": "The automatic detection of causal relationships in text is important for natural language understanding.", "labels": [], "entities": [{"text": "automatic detection of causal relationships in text", "start_pos": 4, "end_pos": 55, "type": "TASK", "confidence": 0.8004494479724339}, {"text": "natural language understanding", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.6618773937225342}]}, {"text": "This task has proven to be difficult, however, due to the need for world knowledge and inference.", "labels": [], "entities": []}, {"text": "We focus on a sub-task of this problem where an open class set of linguistic markers can provide clues towards understanding causality.", "labels": [], "entities": []}, {"text": "Unlike the explicit markers, a closed class, these markers vary significantly in their linguistic forms.", "labels": [], "entities": []}, {"text": "We leverage parallel Wikipedia corpora to identify new markers that are variations on known causal phrases, creating a training set via distant supervision.", "labels": [], "entities": []}, {"text": "We also train a causal classifier using features from the open class markers and semantic features providing contextual information.", "labels": [], "entities": []}, {"text": "The results show that our features provide an 11.05 point absolute increase over the baseline on the task of identifying causality in text.", "labels": [], "entities": []}], "introductionContent": [{"text": "The automatic detection of causal relationships in text is an important but difficult problem.", "labels": [], "entities": [{"text": "automatic detection of causal relationships in text", "start_pos": 4, "end_pos": 55, "type": "TASK", "confidence": 0.8197806307247707}]}, {"text": "The identification of causality is useful for the understanding and description of events.", "labels": [], "entities": []}, {"text": "Causal inference may also aid upstream applications such as question answering and text summarization.", "labels": [], "entities": [{"text": "question answering", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.9384745657444}, {"text": "text summarization", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7655363082885742}]}, {"text": "Knowledge of causal relationships can improve performance in question answering for \"why\" questions.", "labels": [], "entities": [{"text": "question answering for \"why\" questions", "start_pos": 61, "end_pos": 99, "type": "TASK", "confidence": 0.7908797860145569}]}, {"text": "Summarization of event descriptions can be improved by selecting causally motivated sentences.", "labels": [], "entities": []}, {"text": "However, causality is frequently expressed implicitly, which requires world knowledge and inference.", "labels": [], "entities": []}, {"text": "Even when causality is explicit, there is a wide variety in how it is expressed.", "labels": [], "entities": []}, {"text": "Causality is one type of relation in the Penn Discourse Tree Bank (PDTB) ().", "labels": [], "entities": [{"text": "Penn Discourse Tree Bank (PDTB)", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.9584237166813442}]}, {"text": "In general, discourse relations indicate how two text spans are logically connected.", "labels": [], "entities": []}, {"text": "In PDTB theory, these discourse relations can be marked explicitly or conveyed implicitly.", "labels": [], "entities": []}, {"text": "In the PDTB, there are 102 known explicit discourse markers such as \"and\", \"but\", \"after\", \"in contrast\", or \"in addition\".", "labels": [], "entities": []}, {"text": "Of these, 28 explicitly mark causal relations (e.g., \"because\", \"as a result\", \"consequently\").", "labels": [], "entities": []}, {"text": "In addition to explicit markers, PDTB researchers recognize the existence of an open class of markers, which they call AltLex.", "labels": [], "entities": []}, {"text": "There is a tremendous amount of variation in how AltLexes are expressed and so the set of AltLexes is arguably infinite in size.", "labels": [], "entities": []}, {"text": "In the PDTB, non-causal AltLexes include \"That compares with\" and \"In any event.\"", "labels": [], "entities": [{"text": "PDTB", "start_pos": 7, "end_pos": 11, "type": "DATASET", "confidence": 0.8887152075767517}]}, {"text": "Causal AltLexes include \"This may help explain why\" and \"This activity produced.\"", "labels": [], "entities": []}, {"text": "Discourse relations with explicit discourse markers can be identified with high precision ) but they are also relatively rare.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9970935583114624}]}, {"text": "Implicit relations are much more common but very difficult to identify.", "labels": [], "entities": []}, {"text": "AltLexes fall in the middle; their linguistic variety makes them difficult to identify but their presence improves the identification of causality.", "labels": [], "entities": []}, {"text": "One issue with causality identification is the lack of data.", "labels": [], "entities": [{"text": "causality identification", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.8680749237537384}]}, {"text": "Unsupervised identification on open domain data yields low precision () and while supervised methods on the PDTB have improved (, creating enough labeled data is difficult.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9970120191574097}, {"text": "PDTB", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.9312949776649475}]}, {"text": "Here, we present a distant supervision method for causality identification that uses parallel data to identify new causal connectives given a seed set.", "labels": [], "entities": [{"text": "causality identification", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.8422658145427704}]}, {"text": "We train a classifier on this data and self-train to obtain new data.", "labels": [], "entities": []}, {"text": "Our novel approach uses AltLexes that were automatically identified using semi-supervised learning over a parallel corpus.", "labels": [], "entities": []}, {"text": "Since we do not know a priori what these phrases are, we used a monolingual parallel corpus to identify new phrases that are aligned with known causal connectives.", "labels": [], "entities": []}, {"text": "As large corpora of this type are rare, we used Simple and English Wikipedia to create one.", "labels": [], "entities": [{"text": "Simple and English Wikipedia", "start_pos": 48, "end_pos": 76, "type": "DATASET", "confidence": 0.6896428093314171}]}, {"text": "Section 2 discusses prior research in causality and discourse.", "labels": [], "entities": []}, {"text": "Section 4 describes how we created anew corpus from Wikipedia for causality and extracted a subset of relations with AltLexes.", "labels": [], "entities": []}, {"text": "In section 5, we recount the semantic and marker features and how they were incorporated into a classifier for causality.", "labels": [], "entities": []}, {"text": "We show that these features improve causal inference by an 11.05 point increase in F-measure over a naive baseline in 6.", "labels": [], "entities": [{"text": "causal inference", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.8806644380092621}, {"text": "F-measure", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9984493255615234}]}, {"text": "Finally, we discuss the results and future work in 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}