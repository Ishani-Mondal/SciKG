{"title": [{"text": "A New Psychometric-inspired Evaluation Metric for Chinese Word Segmentation", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.5672523279984792}]}], "abstractContent": [{"text": "Word segmentation is a fundamental task for Chinese language processing.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7050560116767883}, {"text": "Chinese language processing", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.7231979171435038}]}, {"text": "However , with the successive improvements, the standard metric is becoming hard to distinguish state-of-the-art word segmentation systems.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7763513326644897}]}, {"text": "In this paper, we propose anew psychometric-inspired evaluation metric for Chinese word segmentation, which addresses to balance the very skewed word distribution at different levels of difficulty 1.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.5810527503490448}]}, {"text": "The performance on areal evaluation shows that the proposed metric gives more reasonable and distinguishable scores and correlates well with human judgement.", "labels": [], "entities": []}, {"text": "In addition, the proposed metric can be easily extended to evaluate other sequence labelling based NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word segmentation is a fundamental task for Chinese language processing.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7050560116767883}, {"text": "Chinese language processing", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.7231979171435038}]}, {"text": "In recent years, Chinese word segmentation (CWS) has undergone great development, which is, to some degree, driven by evaluation conferences of CWS, such as SIGHAN Bakeoffs.", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7857828438282013}]}, {"text": "The current state-of-the-art methods regard word segmentation as a sequence labeling problem).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7608412504196167}]}, {"text": "The goal of sequence labeling is to assign labels to all elements in a sequence, which can be handled with supervised learning algorithms, such as maximum entropy (ME) (, conditional random fields (CRF) () and Perceptron).", "labels": [], "entities": [{"text": "maximum entropy (ME)", "start_pos": 147, "end_pos": 167, "type": "METRIC", "confidence": 0.7174005210399628}]}, {"text": "Benefiting from the public datasets and feature engineering, Chinese word segmentation achieves quite high precision after years of intensive research.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.5594508151213328}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9951044321060181}]}, {"text": "To evaluate a word segmenter, the standard metric consists of precision p, recall r, and an evenly-weighted F-score f 1 . However, with the successive improvement of performance, state-of-the-art segmenters are hard to be distinguished under the standard metric.", "labels": [], "entities": [{"text": "word segmenter", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7136694043874741}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9954315423965454}, {"text": "recall r", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9884266555309296}, {"text": "F-score f 1", "start_pos": 108, "end_pos": 119, "type": "METRIC", "confidence": 0.9610404769579569}]}, {"text": "Therefore, researchers also report results with some other measures, such as out-of-vocabulary (OOV) recall, to show their strengths besides p, rand f 1 . Furthermore, although state-of-the-art methods have achieved high performances on p, rand f 1 , there exists inconsistence between the evaluation ranking and the intuitive feelings towards the segmentation results of these methods.", "labels": [], "entities": [{"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.832241952419281}]}, {"text": "The inconsistence is caused by two reasons: (1) The high performance is due to the fact that the distribution of difficulties of words is unbalanced.", "labels": [], "entities": []}, {"text": "The proportion of trivial cases is very high, such as '\u7684 ('s)'\uff0c'\u6211\u4eec (we)', which results in that the non-trivial cases are relatively despised.", "labels": [], "entities": []}, {"text": "Therefore, a good measure should have a capability to balance the skewed distribution by weighting the test cases.", "labels": [], "entities": []}, {"text": "(2) Human judgement depends on difficulties of segmentations.", "labels": [], "entities": []}, {"text": "A segmenter can earn extra credits when correctly segmenting a difficult word than an easy word.", "labels": [], "entities": []}, {"text": "Conversely, a segmenter can take extra penalties when wrongly segmenting an easy word than a difficult word.", "labels": [], "entities": []}, {"text": "Taking a sentence and two predicted segmentations as an example: S : \u767d\u85dc\u82a6\u9187 \u662f \u4e00 \u79cd \u915a\u7c7b \u7269\u8d28 (Trans: Resveratrol is a kind of phenols material.)", "labels": [], "entities": []}, {"text": "P1: \u767d \u85dc\u82a6 \u9187 \u662f \u4e00\u79cd \u915a\u7c7b \u7269\u8d28 P2: \u767d\u85dc \u82a6\u9187 \u662f \u4e00 \u79cd \u915a\u7c7b\u7269 \u8d28 We can see that the two segmentations have the same scores in p, rand f 1 . But intuitively, P1 should be better than P2, since P2 is worse even on the trivial cases, such as '\u915a\u7c7b (phenols)' and '\u7269\u8d28 (material)'.", "labels": [], "entities": []}, {"text": "Therefore, we think that an appropriate evaluation metric should not only provide an all-around quantitative analysis of system performances, but also explicitly reveal the strengths and potential weaknesses of a model.", "labels": [], "entities": []}, {"text": "Inspired by psychometrics, we propose anew evaluation metric for Chinese word segmentation in this paper.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.627459704875946}]}, {"text": "Given a labeled dataset, not all words have the same contribution to judge the performance of a segmenter.", "labels": [], "entities": []}, {"text": "Based on psychometric research (, we assign a difficulty value to each word.", "labels": [], "entities": []}, {"text": "The difficulty of a word is automatically rated by a committee of segmenters, which are diversified by training on different datasets and features.", "labels": [], "entities": []}, {"text": "We design a balanced precision, recall to pay different attentions to words according to their difficulties.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9983106851577759}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9940034747123718}]}, {"text": "We also give detailed analysis on areal evaluation of Chinese word segmentation with our proposed metric.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.6318478882312775}]}, {"text": "The analysis result shows that the new metric gives a more balanced evaluation result towards the human intuition of the segmentation quality.", "labels": [], "entities": []}, {"text": "We will release the weighted datasets focused this paper to the academic community.", "labels": [], "entities": []}, {"text": "Although our proposed metric is applied to Chinese word segmentation fora case study, it can be easily extended to other sequence labelling based NLP tasks.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.606046199798584}]}], "datasetContent": [{"text": "The standard evaluation usually uses three measures: precision, recall and balanced F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9997394680976868}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9992344379425049}, {"text": "F-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9803282618522644}]}, {"text": "Precision p is defined as the number of correctly segmented words divided by the total number of words in the automatically segmented corpus.", "labels": [], "entities": [{"text": "Precision p", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9622638821601868}]}, {"text": "Recall r is defined as the number of correctly segmented words divided by the total number of words in the gold standard, which is the manually annotated corpus.", "labels": [], "entities": [{"text": "Recall r", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9636066854000092}]}, {"text": "F-score f 1 the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score f 1", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9607815941174825}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9946796298027039}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9989448189735413}]}, {"text": "Given a sentence, the gold-standard segmentation of a sentence is w 1 , \u00b7 \u00b7 \u00b7 , W N , N is the number of words.", "labels": [], "entities": []}, {"text": "The predicted segmentation is w \u2032 1 , \u00b7 \u00b7 \u00b7 , w \u2032 N \u2032 , N \u2032 is the number of words.", "labels": [], "entities": []}, {"text": "Among that, the number of words correctly identified by the predicted segmentation is c, and the number of incorrectly predicted words is e. p, rand f 1 are defined as follows: As a complement to these metrics, researchers also use the recall of out-of-vocabulary (OOV) words to measure the segmenter's performance in detecting unknown words.", "labels": [], "entities": [{"text": "recall", "start_pos": 236, "end_pos": 242, "type": "METRIC", "confidence": 0.9897944331169128}]}, {"text": "We involve the basic idea from psychometrics and improve the evaluation metric by assigning weights to test cases.", "labels": [], "entities": []}, {"text": "Since the distribution of the difficulties of words is very skew, we design anew metric to balance the weights of different words according to their difficulties.", "labels": [], "entities": []}, {"text": "In addition, we also should keep strictly a fair rule for rewards and punishments.", "labels": [], "entities": []}, {"text": "Intuitively, if the difficulty of a word is high, a correct segmentation should be given an extra rewards; otherwise, if the difficulty of a word is low, it is reasonable to give an extra punishment to a wrong segmentation.", "labels": [], "entities": []}, {"text": "Our new metric of precision, recall and balanced F-score is designed as follows.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9996821880340576}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9997263550758362}, {"text": "F-score", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9751030802726746}]}, {"text": "Balanced Recall Given anew predicted segmentation, the mark mi \u2208 {0, 1} indicates whether word w i is correctly segmented.", "labels": [], "entities": [{"text": "Balanced Recall", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9092881679534912}]}, {"text": "d i is the degree of difficulty of word w i . According to the difficulties of each word, we can calculated the reward recall r reward which biased for the difficult cases.", "labels": [], "entities": [{"text": "reward recall r reward", "start_pos": 112, "end_pos": 134, "type": "METRIC", "confidence": 0.7457643747329712}]}, {"text": "where r \u2032 reward \u2208 [0, 1] is biased recall, which places more attention on the difficult cases and less attention on the easy cases.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9929925203323364}]}, {"text": "Conversely, we can calculated another punishment recall r punishment which biased for the easy cases.", "labels": [], "entities": []}, {"text": "where r punishment \u2208 [0, 1] is biased recall, which places more attention on the easy cases and less attention on the difficult cases.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9944990873336792}]}, {"text": "r punishment can be interpreted as a punishment as bellows.", "labels": [], "entities": []}, {"text": "From Eq (9), we can see that an extra punishment is given to wrong segmentation for low difficult word.", "labels": [], "entities": []}, {"text": "In detailed, fora word w i that is easy to segment, its weights will be larger, which results to a smaller final score.", "labels": [], "entities": []}, {"text": "To balance the reward and punishment, a balanced recall r b is used, which is the harmonic mean of r reward and r punishment . is the degree of difficulty of segment s \u2032 i , which is an average difficulty of the corresponding gold words.", "labels": [], "entities": [{"text": "recall r b", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.8854124148686727}]}, {"text": "Similar to balanced recall, we use the same way to calculate balance precision p b . Here N \u2032 is the number of words in the predicted segmentation.", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.8728784322738647}, {"text": "balance precision p b", "start_pos": 61, "end_pos": 82, "type": "METRIC", "confidence": 0.7819706201553345}]}, {"text": "d \u2032 i is the weight for the predicted segmentation unit w \u2032 i . It equals to the word difficulty of the corresponding word w that cover the right boundary of w \u2032 i in the gold segmentation.", "labels": [], "entities": [{"text": "word difficulty", "start_pos": 81, "end_pos": 96, "type": "METRIC", "confidence": 0.9095631241798401}]}, {"text": "Balanced F-score The final balanced F-score is  Here we demonstrate the effectiveness of the proposed method in areal evaluation by reanalyzing the submission results from NLPCC 2015 Shared Task 2 of Chinese word segmentation.", "labels": [], "entities": [{"text": "F-score", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.8263925909996033}, {"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9675201773643494}, {"text": "NLPCC 2015 Shared Task 2", "start_pos": 172, "end_pos": 196, "type": "DATASET", "confidence": 0.884093165397644}, {"text": "Chinese word segmentation", "start_pos": 200, "end_pos": 225, "type": "TASK", "confidence": 0.7552301287651062}]}, {"text": "The dataset of this shared task is collected from micro-blog text.", "labels": [], "entities": []}, {"text": "For convenience, we use WB to represent this dataset in the following discussions.", "labels": [], "entities": []}, {"text": "We select the submissions of all 7 participants from the closed track and the submissions of all We compare the standard precision, recall and F-score with our new metric.", "labels": [], "entities": [{"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9994341731071472}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9995324611663818}, {"text": "F-score", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.9979275465011597}]}, {"text": "The result is displayed in.", "labels": [], "entities": []}, {"text": "Considering the related privacy issues, we will refer to the participants as P1, P2, etc.", "labels": [], "entities": []}, {"text": "The order of these participants in the sub-figures is sorted according to the original ranking given by the standard metric in each track.", "labels": [], "entities": []}, {"text": "The same ID number refers to the same participants.", "labels": [], "entities": []}, {"text": "It is interesting to see that the proposed metric gives out significantly different rankings for the participants, compared to the original rankings.", "labels": [], "entities": []}, {"text": "Based on the standard metric, Participant 1 (P1) ranks the top in closed track while P7 is ranked as the worst in both tracks.", "labels": [], "entities": []}, {"text": "However, P2 ranks first under the evaluation of the new metric in the Closed track.", "labels": [], "entities": [{"text": "Closed track", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.7996133863925934}]}, {"text": "P7 also get higher ranking than its original one.", "labels": [], "entities": [{"text": "P7", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.9440195560455322}]}, {"text": "In this section, we give comparisons on SIGHAN datasets.", "labels": [], "entities": [{"text": "SIGHAN datasets", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.8407424688339233}]}, {"text": "We use four simplified Chinese datasets: PKU and MSR) as well as NCC and SXU.", "labels": [], "entities": []}, {"text": "For each dataset, we train four segmenters with varying abilities, based on 20%, 50%, 80% and 100% of training data respectively.", "labels": [], "entities": []}, {"text": "The used feature template is F2 in shows the different evaluation results with standard metric and our balanced metric.", "labels": [], "entities": [{"text": "F2", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9667832255363464}]}, {"text": "We can see that the proposed evaluation metric generally gives lower and more distinguishable score, compared with the standard metric.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Model evaluation with standard metric and our new metric. Models vary in the amount of  training data and feature types.", "labels": [], "entities": []}]}