{"title": [{"text": "Embeddings for Word Sense Disambiguation: An Evaluation Study", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.7635594805081686}]}], "abstractContent": [{"text": "Recent years have seen a dramatic growth in the popularity of word embeddings mainly owing to their ability to capture semantic information from massive amounts of textual content.", "labels": [], "entities": []}, {"text": "As a result, many tasks in Natural Language Processing have tried to take advantage of the potential of these distributional models.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.6487573087215424}]}, {"text": "In this work, we study how word embeddings can be used in Word Sense Disambiguation, one of the oldest tasks in Natural Language Processing and Artificial Intelligence.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.743698259194692}]}, {"text": "We propose different methods through which word embeddings can be leveraged in a state-of-the-art supervised WSD system architecture, and perform a deep analysis of how different parameters affect performance.", "labels": [], "entities": [{"text": "WSD system", "start_pos": 109, "end_pos": 119, "type": "TASK", "confidence": 0.8697158396244049}]}, {"text": "We show how a WSD system that makes use of word embeddings alone, if designed properly, can provide significant performance improvement over a state-of-the-art WSD system that incorporates several standard WSD features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Embeddings represent words, or concepts in a low-dimensional continuous space.", "labels": [], "entities": []}, {"text": "These vectors capture useful syntactic and semantic information, such as regularities in language, where relationships are characterized by a relation-specific vector offset.", "labels": [], "entities": []}, {"text": "The ability of embeddings to capture knowledge has been exploited in several tasks, such as Machine Translation (, Sentiment Analysis (, Word Sense Disambiguation ( and Language Understanding.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.881912112236023}, {"text": "Sentiment Analysis", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.7752284407615662}, {"text": "Word Sense Disambiguation", "start_pos": 137, "end_pos": 162, "type": "TASK", "confidence": 0.5958652098973592}, {"text": "Language Understanding", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.7601925730705261}]}, {"text": "Supervised WSD is based on the hypothesis that contextual information provides a good approximation to word meaning, as suggested by: semantically similar words tend to have similar contextual distributions.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9463565945625305}]}, {"text": "Recently, there have been efforts on leveraging embeddings for improving supervised WSD systems.", "labels": [], "entities": [{"text": "WSD", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9697409272193909}]}, {"text": "showed that the performance of conventional supervised WSD systems can be increased by taking advantage of embeddings as new features.", "labels": [], "entities": [{"text": "WSD", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9570107460021973}]}, {"text": "In the same direction, trained embeddings by mixing words, lexemes and synsets, and introducing a set of features based on calculations on the resulting representations.", "labels": [], "entities": []}, {"text": "However, none of these techniques takes full advantage of the semantic information contained in embeddings.", "labels": [], "entities": []}, {"text": "As a result, they generally fail in providing substantial improvements in WSD performance.", "labels": [], "entities": [{"text": "WSD", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9402072429656982}]}, {"text": "In this paper, we provide for the first time a study of different techniques for taking advantage of the combination of embeddings with standard WSD features.", "labels": [], "entities": []}, {"text": "We also propose an effective approach for leveraging embeddings in WSD, and show that this can provide significant improvement on multiple standard benchmarks.", "labels": [], "entities": [{"text": "WSD", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.6305513978004456}]}], "datasetContent": [{"text": "We evaluated the performance of our embeddingbased WSD system on two standard WSD tasks: lexical sample and all-words.", "labels": [], "entities": []}, {"text": "In all the experiments in this section we used the exponential decay strategy (cf. Section 3.6) and a window size often words on each side of the target word.", "labels": [], "entities": []}, {"text": "The lexical sample WSD tasks provide training datasets in which different occurrences of a small set of words are sense annotated.", "labels": [], "entities": []}, {"text": "The goal is fora WSD system to analyze the contexts of the individual senses of these words and to capture clues that can be used for distinguishing different senses of a word from each other at the test phase.  only.", "labels": [], "entities": []}, {"text": "shows the number of sentences per part of speech for the training and test datasets of each of these tasks.", "labels": [], "entities": []}, {"text": "In addition to the vanilla IMS system in its default setting we compared our system against two recent approaches that also modify the IMS system so that it can benefit from the additional knowledge derived from word embeddings for improved WSD performance: (1) the system of, which combines word embeddings of Collobert and Weston (2008) using the concatenation strategy (cf. Section 3.6) and introduces the combined embeddings as anew feature in addition to the standard WSD features in IMS; and (2) AutoExtend (Rothe and Sch\u00fctze, 2015), which constructs a whole new set of features based on vectors made from words, senses and synsets of WordNet and incorporates them in IMS.", "labels": [], "entities": [{"text": "WSD", "start_pos": 241, "end_pos": 244, "type": "TASK", "confidence": 0.9697815179824829}]}, {"text": "shows the F1 performance of the different systems on the three lexical sample datasets.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9992161989212036}]}, {"text": "As can be seen, the IMS + Word2vec system improves overall comparison systems including those that combine standard WSD and embedding features (i.e., the system of Taghipour and Ng (2015) and AutoExtend) across all the datasets.", "labels": [], "entities": []}, {"text": "This shows that our proposed strategy for introducing word embeddings into the IMS system on the basis of exponential decay was beneficial.", "labels": [], "entities": []}, {"text": "In the last three rows of the table, we also report the performance of the WSD systems that leverage only word embeddings as their features and do not incorporate any standard WSD feature.", "labels": [], "entities": []}, {"text": "It can be seen that word embeddings, in isolation, provide competitive performance, which proves their capability in obtaining the information captured by standard WSD features.", "labels": [], "entities": []}, {"text": "Among different embeddings, the retrofitted vectors provide the best performance when used in isolation.", "labels": [], "entities": []}, {"text": "The goal in this task is to disambiguate all the content words in a given text.", "labels": [], "entities": []}, {"text": "In order to learn models for disambiguating a large set of content words, a high-coverage sense-annotated corpus is required.", "labels": [], "entities": []}, {"text": "Since all-words tasks do not usually provide any training data, the challenge here is not only to learn accurate disambiguation models from the training data, as is the casein the lexical sample task, but also to gather high-coverage training data and to learn disambiguation models for as many words as possible.).", "labels": [], "entities": []}, {"text": "We benchmarked the performance of our system against five other systems.", "labels": [], "entities": []}, {"text": "Similarly to our lexical sample experiment, we compared against the vanilla IMS system and the work of.", "labels": [], "entities": []}, {"text": "In addition, we performed experiments on the nouns subsets of the datasets in order to be able to provide comparisons against two other WSD approaches: Babelfy () and Muffin).", "labels": [], "entities": [{"text": "WSD", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.836344301700592}, {"text": "Muffin", "start_pos": 167, "end_pos": 173, "type": "DATASET", "confidence": 0.8080193400382996}]}, {"text": "Babelfy is a multilingual knowledge-based WSD and Entity Linking algorithm based on the semantic network of BabelNet.", "labels": [], "entities": [{"text": "Babelfy", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8546050190925598}]}, {"text": "Muffin is a multilingual sense representation technique that combines the structural knowledge derived from semantic networks with the distributional statistics obtained from text corpora.", "labels": [], "entities": [{"text": "multilingual sense representation", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.6686621606349945}]}, {"text": "The system uses sense-based representations for performing WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9466838240623474}]}, {"text": "(2015a) also proposed a hybrid system that averages the disambiguation scores of IMS with theirs (shown as \"Muffin + IMS\" in our tables).", "labels": [], "entities": []}, {"text": "We also report the results for UKB, another knowledge-based WSD approach based on Personalized PageRank).", "labels": [], "entities": [{"text": "UKB", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.8777937889099121}]}, {"text": "Finally, we also carried out experiments with the pre-trained models 6 that are pro-   vided with the IMS toolkit, as well as IMS trained on our two training corpora, i.e., SemCor and OM-STI.", "labels": [], "entities": [{"text": "IMS toolkit", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.8306544423103333}, {"text": "OM-STI", "start_pos": 184, "end_pos": 190, "type": "DATASET", "confidence": 0.8406073451042175}]}, {"text": "list the performance of different systems on, respectively, the whole and the nounsubset datasets of the three all-words WSD tasks.", "labels": [], "entities": [{"text": "nounsubset datasets", "start_pos": 78, "end_pos": 97, "type": "DATASET", "confidence": 0.85108682513237}, {"text": "WSD tasks", "start_pos": 121, "end_pos": 130, "type": "TASK", "confidence": 0.6253095865249634}]}, {"text": "Similarly to our lexical sample experiment, the IMS + Word2vec system provided the best performance across datasets and benchmarks.", "labels": [], "entities": [{"text": "IMS + Word2vec", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.7273932695388794}]}, {"text": "The coupling of Word2vec embeddings to the IMS system proved to be consistently helpful.", "labels": [], "entities": []}, {"text": "Among the two training corpora, as expected, OMSTI provided a better performance owing to its considerably larger size and higher coverage.", "labels": [], "entities": [{"text": "OMSTI", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.7525516748428345}, {"text": "coverage", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9668157696723938}]}, {"text": "Another point to be noted here is the difference between results of the IMS with the pre-trained models and those trained on the OMSTI corpus.", "labels": [], "entities": [{"text": "IMS", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9485106468200684}, {"text": "OMSTI corpus", "start_pos": 129, "end_pos": 141, "type": "DATASET", "confidence": 0.8573994636535645}]}, {"text": "Since we used the same system configuration across the two runs, we conclude that the OMSTI corpus is either substantially smaller or less representative than the corpus used by for building the pre-trained models of IMS.", "labels": [], "entities": [{"text": "OMSTI corpus", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.8823804557323456}, {"text": "IMS", "start_pos": 217, "end_pos": 220, "type": "TASK", "confidence": 0.9393823146820068}]}, {"text": "Despite this fact, the IMS + Word2vec system can consistently improve the performance of IMS (pre-trained models) across the three datasets.", "labels": [], "entities": []}, {"text": "This shows that a proper introduction of word embeddings into a supervised WSD system can compensate the negative effect of using lower quality training data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9405810832977295}]}], "tableCaptions": [{"text": " Table 1: The number of sentences per part of speech in the datasets of the English lexical sample tasks  we considered for our experiments.", "labels": [], "entities": []}, {"text": " Table 2: F1 performance on the three English lexical sam-", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9948047995567322}]}, {"text": " Table 3: F1 performance on different English all- words WSD datasets.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9969556331634521}, {"text": "WSD datasets", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.6923277974128723}]}, {"text": " Table 4: F1 performance in the nouns subsets of  different all-words WSD datasets.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9990755319595337}, {"text": "WSD datasets", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.8416589498519897}]}, {"text": " Table 5: F1 performance of different models on the Senseval-2 English Lexical Sample task. We show  results for varied dimensionality (200, 400, and 800), window size (5, 10 and 20 words) and combination  strategy, i.e., Concatenation (Con), Averaging (Avg), Fractional decay (Frac), and Exponential decay  (Exp). To make the table easier to read, we highlight each cell according to the relative performance gain  in comparison to the IMS baseline (top row in the table).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9960961937904358}, {"text": "Senseval-2 English Lexical Sample task", "start_pos": 52, "end_pos": 90, "type": "TASK", "confidence": 0.47038525342941284}, {"text": "Averaging (Avg)", "start_pos": 243, "end_pos": 258, "type": "METRIC", "confidence": 0.913885697722435}, {"text": "Exponential decay  (Exp)", "start_pos": 289, "end_pos": 313, "type": "METRIC", "confidence": 0.9303192734718323}, {"text": "IMS baseline", "start_pos": 437, "end_pos": 449, "type": "DATASET", "confidence": 0.7835933566093445}]}, {"text": " Table 6: F1 percentage performance on the Senseval-2 English Lexical Sample dataset with different  word representations models, vector dimensionalities (Dim.) and combination strategies.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9989558458328247}, {"text": "Senseval-2 English Lexical Sample dataset", "start_pos": 43, "end_pos": 84, "type": "DATASET", "confidence": 0.855749249458313}]}]}