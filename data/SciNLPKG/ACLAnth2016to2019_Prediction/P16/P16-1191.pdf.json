{"title": [{"text": "Supersense Embeddings: A Unified Model for Supersense Interpretation, Prediction, and Utilization", "labels": [], "entities": [{"text": "Supersense Embeddings", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.877275139093399}, {"text": "Supersense Interpretation, Prediction", "start_pos": 43, "end_pos": 80, "type": "TASK", "confidence": 0.7810320258140564}]}], "abstractContent": [{"text": "Coarse-grained semantic categories such as supersenses have proven useful fora range of downstream tasks such as question answering or machine translation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.9008706212043762}, {"text": "machine translation", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.7582968771457672}]}, {"text": "To date, no effort has been put into integrating the supersenses into distributional word representations.", "labels": [], "entities": []}, {"text": "We present a novel joint embedding model of words and supersenses, providing insights into the relationship between words and supersenses in the same vector space.", "labels": [], "entities": []}, {"text": "Using these embeddings in a deep neural network model, we demonstrate that the supersense enrichment leads to a significant improvement in a range of downstream classification tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "The effort of understanding the meaning of words is central to the NLP community.", "labels": [], "entities": [{"text": "understanding the meaning of words", "start_pos": 14, "end_pos": 48, "type": "TASK", "confidence": 0.8226481437683105}]}, {"text": "The word sense disambiguation (WSD) task has therefore received a substantial amount of attention (see or for an overview).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD) task", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.8261001876422337}]}, {"text": "Words in training and evaluation data are usually annotated with senses taken from a particular lexical semantic resource, most commonly WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 137, "end_pos": 144, "type": "DATASET", "confidence": 0.9578145742416382}]}, {"text": "However, WordNet has been criticized to provide too fine-grained distinctions for end level applications.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.9285851716995239}]}, {"text": "e.g. in machine translation or information retrieval (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.8069575428962708}, {"text": "information retrieval", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.7429375946521759}]}, {"text": "Although some researchers report an improvement in sentiment prediction using WSD (, the publication bias toward positive results () impedes the comparison to experiments with the opposite conclusion, and the contribution of WSD to downstream document classification tasks remains \"mostly speculative\"(), which can be attributed to the too subtle sense distinctions.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.9695923626422882}, {"text": "document classification tasks", "start_pos": 243, "end_pos": 272, "type": "TASK", "confidence": 0.7697974145412445}]}, {"text": "This is why supersenses, the coarse-grained word labels based on WordNet's  Usage of supersense labels has been shown to improve dependency parsing), named entity recognition (, non-factoid question answering (), question generation, semantic role labeling (, personality profiling (, semantic similarity () and metaphor detection ().", "labels": [], "entities": [{"text": "WordNet", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.9446030855178833}, {"text": "dependency parsing", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.7823436856269836}, {"text": "named entity recognition", "start_pos": 150, "end_pos": 174, "type": "TASK", "confidence": 0.6440330644448599}, {"text": "question answering", "start_pos": 190, "end_pos": 208, "type": "TASK", "confidence": 0.7363462150096893}, {"text": "question generation", "start_pos": 213, "end_pos": 232, "type": "TASK", "confidence": 0.8829472959041595}, {"text": "semantic role labeling", "start_pos": 234, "end_pos": 256, "type": "TASK", "confidence": 0.7193732261657715}, {"text": "metaphor detection", "start_pos": 312, "end_pos": 330, "type": "TASK", "confidence": 0.8537065386772156}]}, {"text": "An alternative path to semantic interpretation follows the distributional hypothesis.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.8748661279678345}]}, {"text": "Recently, word vector representations learned with neural-network based language models have contributed to state-of-the-art results on various linguistic tasks.", "labels": [], "entities": []}, {"text": "In this work, we present a novel approach for incorporating the supersense information into the word embedding space and propose anew methodology for utilizing these to label the text with supersenses and to exploit these joint word and supersense embeddings in a range of applied text classification tasks.", "labels": [], "entities": [{"text": "text classification", "start_pos": 281, "end_pos": 300, "type": "TASK", "confidence": 0.7175949960947037}]}, {"text": "Our contributions in this work include the following: \u2022 We are the first to provide a joint wordand supersense-embedding model, which we make publicly available 1 for the research community.", "labels": [], "entities": []}, {"text": "This provides an insight into the word and supersense positions in the vector space through similarity queries and visualizations, and can be readily used in any word embedding application.", "labels": [], "entities": []}, {"text": "\u2022 Using this information, we propose a supersense tagging model which achieves competitive performance on recently published social media datasets.", "labels": [], "entities": [{"text": "supersense tagging", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6399685889482498}]}, {"text": "\u2022 We demonstrate how these predicted supersenses and their embeddings can be used in a range of text classification tasks.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 96, "end_pos": 121, "type": "TASK", "confidence": 0.846238374710083}]}, {"text": "Using a deep neural network architecture, we achieve an improvement of 2-6% inaccuracy for the tasks of sentiment polarity classification, subjectivity classification and metaphor prediction.", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 104, "end_pos": 137, "type": "TASK", "confidence": 0.8896519740422567}, {"text": "subjectivity classification", "start_pos": 139, "end_pos": 166, "type": "TASK", "confidence": 0.7112946510314941}, {"text": "metaphor prediction", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.9010023772716522}]}], "datasetContent": [{"text": "Both Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM)) are state-of-the-art semantic composition models fora variety of text classification tasks LSTM LSTM LSTM LSTM: Network architecture.", "labels": [], "entities": [{"text": "text classification tasks LSTM LSTM LSTM LSTM", "start_pos": 142, "end_pos": 187, "type": "TASK", "confidence": 0.8269064852169582}]}, {"text": "Each of the four different embedding channels serves as input to its CNN layer, followed by an LSTM layer.", "labels": [], "entities": []}, {"text": "Afterwards, the outputs are concatenated and fed into a dense layer.", "labels": [], "entities": []}, {"text": "Keras demo 7 , into which we incorporate the supersense information.", "labels": [], "entities": [{"text": "Keras demo 7", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9190188050270081}]}, {"text": "First, we use three channels of word embeddings on the plain textual input.", "labels": [], "entities": []}, {"text": "The first channel are the 300-dimensional word embeddings obtained from our enriched Wikipedia corpus.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.8172453045845032}]}, {"text": "The second embedding channel consists of 41-dimensional vectors capturing the cosine similarity of the word to each supersense embedding.", "labels": [], "entities": []}, {"text": "The third channel contains the vector of relative frequencies of the word occurring in the enriched Wikipedia together with its supersense, i.e. providing the background supersense distribution for the word.", "labels": [], "entities": []}, {"text": "Each of the document embeddings is then convoluted with the filter size of 3, followed by a pooling layer of length 2 and fed into a longshort-term-memory (LSTM) layer.", "labels": [], "entities": []}, {"text": "In parallel, we feed as input a processed document text, where the words are replaced by their predicted supersenses.", "labels": [], "entities": []}, {"text": "Given that we have the Wikipedia-based supersense embeddings in the same vector space as the word embeddings, we can now proceed to creating the 300-dimensional embedding channel also for the supersense text.", "labels": [], "entities": []}, {"text": "As in the plain text channels, we feed also these embeddings into the convolutional and LSTM layers in a similar fashion.", "labels": [], "entities": []}, {"text": "Afterwards, we concatenate all LSTM outputs and feed them into a standard fully connected neural network layer, followed by the sigmoid for the binary output.", "labels": [], "entities": []}, {"text": "The following subsections discuss our results on a range of classification tasks: subjectivity prediction, sentiment polarity classification and metaphor detection.", "labels": [], "entities": [{"text": "subjectivity prediction", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.7243740409612656}, {"text": "sentiment polarity classification", "start_pos": 107, "end_pos": 140, "type": "TASK", "confidence": 0.890889843304952}, {"text": "metaphor detection", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.927905797958374}]}], "tableCaptions": [{"text": " Table 4: Accuracy and standard error on analogy  tasks. Tasks related to noun supersense distinctions  show the tendency to improve, while syntax-related  information is pushed to the background. In most  cases, however, the difference is not significant.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9959000945091248}, {"text": "standard error", "start_pos": 23, "end_pos": 37, "type": "METRIC", "confidence": 0.9066958427429199}, {"text": "noun supersense distinctions", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.6885854601860046}]}, {"text": " Table 5: Performance of our vectors (Spearman's \u03c1)  on five similarity datasets. Results indicate a trend  of better performance of vectors trained jointly with  supersenses.", "labels": [], "entities": []}, {"text": " Table 6: Weighted F-score performance on super- sense prediction for the development set and two  test sets provided by", "labels": [], "entities": [{"text": "F-score", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9424952268600464}, {"text": "super- sense prediction", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.5329037755727768}]}, {"text": " Table 7: 10-fold cross-validation accuracy and stan- dard error of our system and as reported in previous  work for the sentiment classification task on Pang  and Lee (2005) movie review data", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9834312796592712}, {"text": "stan- dard error", "start_pos": 48, "end_pos": 64, "type": "METRIC", "confidence": 0.920035794377327}, {"text": "sentiment classification task", "start_pos": 121, "end_pos": 150, "type": "TASK", "confidence": 0.9554735620816549}, {"text": "Pang  and Lee (2005) movie review", "start_pos": 154, "end_pos": 187, "type": "DATASET", "confidence": 0.8442788794636726}]}, {"text": " Table 9. The  supersenses (SUPER) provide an additional infor- mation, improving the model performance by up  to 2% over word embeddings (WORDS). The dif- ference between both systems is significant. Based  on a manual error analysis, the supersense informa- tion contributes here in a similar manner as in the  previous case. Subjective sentences contain more  verbs of supersense PERCEPTION, while objective  ones more frequently feature the supersenses POS- SESSION and SOCIAL. Nouns in the subjective cat- egory are characterized by supersenses COMMUNI- CATION and ATTRIBUTE, while in objective ones  the", "labels": [], "entities": [{"text": "ATTRIBUTE", "start_pos": 570, "end_pos": 579, "type": "METRIC", "confidence": 0.9831050038337708}]}, {"text": " Table 9: 10-fold cross-validation accuracy and stan- dard error of our system and as reported in previous  work for binary classification on the subjectivity  dataset of", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9840400815010071}, {"text": "stan- dard error", "start_pos": 48, "end_pos": 64, "type": "METRIC", "confidence": 0.9437084645032883}, {"text": "binary classification", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.6907891035079956}]}]}