{"title": [{"text": "A Transition-Based System for Joint Lexical and Syntactic Analysis", "labels": [], "entities": [{"text": "Joint Lexical and Syntactic Analysis", "start_pos": 30, "end_pos": 66, "type": "TASK", "confidence": 0.6735155463218689}]}], "abstractContent": [{"text": "We present a transition-based system that jointly predicts the syntactic structure and lexical units of a sentence by building two structures over the input words: a syntactic dependency tree and a forest of lexical units including multiword expressions (MWEs).", "labels": [], "entities": []}, {"text": "This combined representation allows us to capture both the syntactic and semantic structure of MWEs, which in turn enables deeper downstream semantic analysis, especially for semi-compositional MWEs.", "labels": [], "entities": []}, {"text": "The proposed system extends the arc-standard transition system for dependency parsing with transitions for building complex lexical units.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.819532960653305}]}, {"text": "Experiments on two different data sets show that the approach significantly improves MWE identification accuracy (and sometimes syntactic accuracy) compared to existing joint approaches.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.9636374711990356}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.8856070637702942}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9213334321975708}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) are sequences of words that form non-compositional semantic units.", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7163928985595703}]}, {"text": "Their identification is crucial for semantic analysis, which is traditionally based on the principle of compositionality.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.9314894676208496}]}, {"text": "For instance, the meaning of cut the mustard cannot be compositionally derived from the meaning of its elements and the expression therefore has to be treated as a single unit.", "labels": [], "entities": []}, {"text": "Since, MWEs have attracted growing attention in the NLP community.", "labels": [], "entities": []}, {"text": "Identifying MWEs in running text is challenging for several reasons (.", "labels": [], "entities": [{"text": "Identifying MWEs in running text", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.866108751296997}]}, {"text": "First, MWEs encompass very diverse linguistic phenomena, such as complex grammatical words (in spite of, because of), nominal compounds (light house), noncanonical prepositional phrases (above board), verbal idiomatic expressions (burn the midnight oil), light verb constructions (have a bath), multiword names, and soon.", "labels": [], "entities": []}, {"text": "They can also be discontiguous in the sense that the sequence can include intervening elements (John pulled Mary's leg).", "labels": [], "entities": []}, {"text": "They may also vary in their morphological forms (hot dog, hot dogs), in their lexical elements (lose one's mind/head), and in their syntactic structure (he took a step, the step he took).", "labels": [], "entities": []}, {"text": "The semantic processing of MWEs is further complicated by the fact that there exists a continuum between entirely non-compositional expressions (piece of cake) and almost free expressions (traffic light).", "labels": [], "entities": [{"text": "semantic processing of MWEs", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.5615440756082535}]}, {"text": "Many MWEs are indeed semicompositional.", "labels": [], "entities": []}, {"text": "For example, the compound white wine denotes a type of wine, but the color of the wine is not white, so the expression is only partially transparent.", "labels": [], "entities": []}, {"text": "In the light verb construction take a nap, nap keeps its usual meaning but the meaning of the verb take is bleached.", "labels": [], "entities": []}, {"text": "In addition, the noun can be compositionally modified as in take along nap.", "labels": [], "entities": []}, {"text": "Such cases show that MWEs maybe decomposable and partially analyzable, which implies the need for predicting their internal structure in order to compute their meaning.", "labels": [], "entities": []}, {"text": "From a syntactic point of view, MWEs often have a regular structure and do not need special syntactic annotation.", "labels": [], "entities": []}, {"text": "Some MWEs have an irregular structure, such as by and large which on the surface is a coordination of a preposition and an adjective.", "labels": [], "entities": []}, {"text": "They are syntactically as well as semantically non-compositional and cannot be represented with standard syntactic structures, as stated in.", "labels": [], "entities": []}, {"text": "Many of these irregular MWEs are complex grammatical words like because of, in spite of and in order to -fixed (grammatical) MWEs in the sense of.", "labels": [], "entities": []}, {"text": "In some treebanks, these are annotated using special structures and labels because they can-not be modified or decomposed.", "labels": [], "entities": []}, {"text": "We hereafter use the term fixed MWE to refer to either fixed or irregular MWEs.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel representation that allows both regular and irregular MWEs to be adequately represented without compromising the syntactic representation.", "labels": [], "entities": []}, {"text": "We then show how this representation can be processed using a transitionbased system that is a mild extension of a standard dependency parser.", "labels": [], "entities": []}, {"text": "This system takes as input a sentence consisting of a sequence of tokens and predicts its syntactic dependency structure as well as its lexical units (including MWEs).", "labels": [], "entities": []}, {"text": "The resulting structure combines two factorized substructures: (i) a standard tree representing the syntactic dependencies between the lexical elements of the sentence and (ii) a forest of lexical trees including MWEs identified in the sentence.", "labels": [], "entities": []}, {"text": "Each MWE is represented by a constituency-like tree, which permits complex lexical units like MWE embeddings . The syntactic and lexical structures are factorized in the sense that they share lexical elements: both tokens and fixed MWEs.", "labels": [], "entities": []}, {"text": "The proposed parsing model is an extension of a classical arc-standard parser, integrating specific transitions for MWE detection.", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9661464095115662}, {"text": "MWE detection", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.9692970514297485}]}, {"text": "In order to deal with the two linguistic dimensions separately, it uses two stacks (instead of one).", "labels": [], "entities": []}, {"text": "It is synchronized by using a single buffer, in order to handle the factorization of the two structures.", "labels": [], "entities": []}, {"text": "It also includes different hard constraints on the system in order to reduce ambiguities artificially created by the addition of new transitions.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this system is the first transition-based parser that includes a specific mechanism for handling MWEs in two dimensions.", "labels": [], "entities": []}, {"text": "Previous related research has usually proposed either pipeline approaches with MWE identification performed either before or after dependency parsing () or workaround joint solutions using off-the-shelf parsers trained on dependency treebanks where MWEs are annotated by specific subtrees ().", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.9838210940361023}, {"text": "dependency parsing", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.759276419878006}]}], "datasetContent": [{"text": "This section provides experimental results obtained with a simple implementation of our system using a greedy search parsing algorithm and a linear model trained with an averaged perceptron with shuffled examples and a static oracle.", "labels": [], "entities": []}, {"text": "More precisely, the static oracle is defined using the following transition priorities: Merge F > Merge N > Complete > LeftArc > RightArc > Shift.", "labels": [], "entities": []}, {"text": "At each state of the training phase, the static oracle selects the valid transition that has the higher priority.", "labels": [], "entities": []}, {"text": "We evaluated the two variants of the system, namely Explicit and Implicit, with explicit and implicit completion, respectively.", "labels": [], "entities": []}, {"text": "They were compared against the joint approach proposed in Candito and Constant (2014) that we applied to an arcstandard parser, instead of a graph-based parser.", "labels": [], "entities": []}, {"text": "The parser is trained on a treebank where MWE status and grammatical function are concatenated in arc labels.", "labels": [], "entities": []}, {"text": "We consider it as the Baseline.", "labels": [], "entities": []}, {"text": "We used classical transition-based parsing features consisting of patterns combining linguistic attributes of nodes on the stacks and the buffer, as well as processed subtrees and transition history.", "labels": [], "entities": []}, {"text": "We can note that the joint systems do not contain features sharing elements of both stacks.", "labels": [], "entities": []}, {"text": "Preliminary tuning experiments did not show gains when using such features.", "labels": [], "entities": []}, {"text": "We also compared these systems against weaker ones, obtained by disabling some transitions and using one stack only.", "labels": [], "entities": []}, {"text": "Two systems, namely Syntactic-baseline and Syntactic only predict the syntactic nodes and the dependency structure by using respectively a baseline parser and our system where neither the lexical stack nor the Merge N and Complete transitions are used.", "labels": [], "entities": []}, {"text": "The latter one is an implementation of the proposal in Nivre (2014).", "labels": [], "entities": [{"text": "Nivre (2014)", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9365868121385574}]}, {"text": "Two systems are devoted only to the lexical layer: Lexical only recognizes the lexical units (only the lexical stack and the Merge N and Complete transitions are activated); Fixed only identifies the fixed expressions.", "labels": [], "entities": []}, {"text": "We also implemented pipeline systems where: (i) fixed MWEs are identified by applying only the Fixed system; (ii) elements of predicted MWEs are merged into single tokens; (iii) the retokenized text is parsed using the Baseline or Implicit systems trained on a dataset where fixed MWEs consist of single tokens.", "labels": [], "entities": []}, {"text": "We carried out our experiments on two different datasets annotating both the syntactic structure and the MWEs: the French Treebank () and the STREUSLE corpus () combined with the English Web Treebank [EWT] ().", "labels": [], "entities": [{"text": "French Treebank", "start_pos": 115, "end_pos": 130, "type": "DATASET", "confidence": 0.9901785552501678}, {"text": "STREUSLE corpus", "start_pos": 142, "end_pos": 157, "type": "DATASET", "confidence": 0.8099599778652191}, {"text": "English Web Treebank [EWT]", "start_pos": 179, "end_pos": 205, "type": "DATASET", "confidence": 0.9291121164957682}]}, {"text": "They are commonly used for evaluating the most recent MWE-aware dependency parsers and supervised MWE identification systems.", "labels": [], "entities": [{"text": "MWE-aware dependency parsers", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.8979089061419169}, {"text": "MWE identification", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9193312525749207}]}, {"text": "Concerning the FTB, we used the dependency version developed in derived from the SPMRL shared task version ).", "labels": [], "entities": [{"text": "FTB", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.7742007970809937}]}, {"text": "Fixed and non-fixed MWEs are distinguished, but are limited to contiguous ones only.", "labels": [], "entities": []}, {"text": "The STREUSLE corpus () corresponds to a subpart of the English Web Treebank (EWT).", "labels": [], "entities": [{"text": "STREUSLE corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8048390746116638}, {"text": "English Web Treebank (EWT)", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9408636689186096}]}, {"text": "It consists of reviews and is comprehensively annotated in contiguous and discontiguous MWEs.", "labels": [], "entities": []}, {"text": "Fixed and non-fixed expressions are not distinguished though the distinction between non-compositional and collocational MWEs is made.", "labels": [], "entities": []}, {"text": "This implies that the Merge F transition is not used on this dataset.", "labels": [], "entities": [{"text": "Merge F transition", "start_pos": 22, "end_pos": 40, "type": "METRIC", "confidence": 0.8062534133593241}]}, {"text": "Practically, we used the LTH converter to obtain the dependency version of the EWT constituent version.", "labels": [], "entities": [{"text": "EWT", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.8666108250617981}]}, {"text": "We also used the predicted linguistic attributes used in Constant and Le and in.", "labels": [], "entities": []}, {"text": "Both datasets include predicted POS tags, lemmas and morphology, as well as features computed from compound dictionary lookup.", "labels": [], "entities": []}, {"text": "None of them is entirely satisfying with respect to our model, but they allow us to evaluate the feasibility of the approach.", "labels": [], "entities": []}, {"text": "Statistics on the two datasets are provided in.", "labels": [], "entities": []}, {"text": "Results are provided in for French and in for English.", "labels": [], "entities": []}, {"text": "In order to evaluate the syntactic layer, we used classical UAS and LAS metrics.", "labels": [], "entities": [{"text": "UAS", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.7433260679244995}]}, {"text": "Before evaluation, merged units were automatically decomposed in the form of flat subtrees using specific arcs as in , so all systems can be evaluated and compared at the token level.", "labels": [], "entities": []}, {"text": "MWE identification is evaluated with the F-score of the MWE segmentation, namely MWE for all MWEs and FMWE for fixed MWEs only.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8454475700855255}, {"text": "F-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.995305597782135}, {"text": "MWE segmentation", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.6405328512191772}, {"text": "FMWE", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.49391210079193115}]}, {"text": "An MWE segment corresponds to the set of its component positions in the input token sequence.", "labels": [], "entities": []}, {"text": "First, results show that our joint system consistently and significantly outperforms the baseline in terms of MWE identification on both datasets.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.9635838568210602}]}, {"text": "The merge transitions play a key role.", "labels": [], "entities": []}, {"text": "In terms of syntax, the Explicit system does not have any positive impact (on par or degraded scores), whereas the Implicit system allows us to obtain slightly better results on French and a significant improvement on English.", "labels": [], "entities": [{"text": "par", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9659830927848816}]}, {"text": "The very good performances on English might be explained by the fact that it contains a non-negligeable set of discontiguous MWEs which complicates the prediction of explicit Complete transitions.", "labels": [], "entities": []}, {"text": "When compared with weaker systems, we can see that the addition of the lexical layer helps improve the prediction of the syntactic layer, which confirms results on symbolic parsing.", "labels": [], "entities": [{"text": "symbolic parsing", "start_pos": 164, "end_pos": 180, "type": "TASK", "confidence": 0.6659242510795593}]}, {"text": "The syntactic layer does not seem to impact the lexical layer prediction: we observe comparable results.", "labels": [], "entities": []}, {"text": "This might be due to the fact that syntax is helpful for long-distance discontiguity only, which does not appear in our datasets (the English dataset contains MWEs with small gaps).", "labels": [], "entities": [{"text": "English dataset", "start_pos": 134, "end_pos": 149, "type": "DATASET", "confidence": 0.7614956200122833}]}, {"text": "Another explanation could also be that syntactic parsing accuracy is rather low due to the use of a simple greedy algorithm.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7187791168689728}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9731251001358032}]}, {"text": "Developing more advanced transition-based parsing methods like beam-search may help improve both syntactic parsing accuracy and MWE identification.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.6463867276906967}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9355724453926086}, {"text": "MWE identification", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.9774330854415894}]}, {"text": "When comparing joint systems with pipeline ones, we can see that preidentifying fixed MWEs seems to help MWE identification whereas syntactic parsing accuracy tends to be slightly lower.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.9721823036670685}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.8486753702163696}]}, {"text": "One hypothesis could be that Merge F transitions may confuse the prediction of Merge N transitions.", "labels": [], "entities": []}, {"text": "When compared with existing state-of-the-art systems, we can see that the proposed systems achieve MWE identification scores that are comparable with the pipeline and joint approaches used in.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.9056854546070099}]}, {"text": "These scores are obtained on the SPMRL shared task version, though they are not entirely comparable with our system as they do not distinguish fixed from non-fixed MWEs.", "labels": [], "entities": [{"text": "SPMRL shared task", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.50341068704923}]}], "tableCaptions": [{"text": " Table 2: Results on the FTB. To reduce bias due to training with shuffled examples, scores are averages  of 3 different training/parsing runs.", "labels": [], "entities": [{"text": "FTB", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.8480114340782166}]}, {"text": " Table 3: Results on the reviews part of the English Web Treebank, via cross-validation on the training  set with 8 splits, and simple validation on the test set.", "labels": [], "entities": [{"text": "English Web Treebank", "start_pos": 45, "end_pos": 65, "type": "DATASET", "confidence": 0.9872592290242513}]}]}