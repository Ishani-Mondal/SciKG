{"title": [{"text": "The More Antecedents, the Merrier: Resolving Multi-Antecedent Anaphors", "labels": [], "entities": [{"text": "Merrier", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.8641533851623535}, {"text": "Resolving Multi-Antecedent Anaphors", "start_pos": 35, "end_pos": 70, "type": "TASK", "confidence": 0.6185136834780375}]}], "abstractContent": [{"text": "Anaphor resolution is an important task in NLP with many applications.", "labels": [], "entities": [{"text": "Anaphor resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.747841477394104}]}, {"text": "Despite much research effort, it remains an open problem.", "labels": [], "entities": []}, {"text": "The difficulty of the problem varies substantially across different sub-problems.", "labels": [], "entities": []}, {"text": "One sub-problem, in particular , has been largely untouched by prior work despite occurring frequently throughout corpora: the anaphor that has multiple antecedents, which here we call multi-antecedent anaphors or m-anaphors.", "labels": [], "entities": []}, {"text": "Current coreference resolvers restrict anaphors to at most a single antecedent.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.9581917822360992}]}, {"text": "As we show in this paper, relaxing this constraint poses serious problems in coreference chain-building, where each chain is intended to refer to a single entity.", "labels": [], "entities": []}, {"text": "This work provides a formaliza-tion of the new task with preliminary insights into multi-antecedent noun-phrase anaphors, and offers a method for resolving such cases that outperforms a number of baseline methods by a significant margin.", "labels": [], "entities": []}, {"text": "Our system uses local agglomerative clustering on candidate antecedents and an existing coreference system to score clusters to determine which cluster of mentions is antecedent fora given anaphor.", "labels": [], "entities": []}, {"text": "When we augment an existing coreference system with our proposed method, we observe a substantial increase in performance (0.6 absolute CoNLL F1) on an annotated corpus.", "labels": [], "entities": [{"text": "CoNLL F1)", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9235533873240153}]}], "introductionContent": [{"text": "Anaphor resolution is a very difficult task in Natural Language Understanding, involving the complex interaction of discourse cues, syntactic rules, and semantic phenomena.", "labels": [], "entities": [{"text": "Anaphor resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.814426451921463}, {"text": "Natural Language Understanding", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6500417689482371}]}, {"text": "It is closely related to the task of coreference resolution), for which a myriad of solutions have been proposed).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.9578127861022949}]}, {"text": "However, given the complexity of the problem, a comprehensive approach remains elusive.", "labels": [], "entities": []}, {"text": "The difficulty varies drastically across different cases (proper nouns, pronouns, gerunds, etc.), each of which involves different assumptions about and models of various linguistic phenomena (e.g., vocabulary, syntax, and semantics).", "labels": [], "entities": []}, {"text": "As a result, state-of-theart systems yield varying performance across subproblems.", "labels": [], "entities": []}, {"text": "To avoid the complexity of the overarching resolution task, many current systems -whether learning-based) or rule-based () -focus on a restricted version of the problem, where candidate anaphors are linked to at most one antecedent, from which coreference chains are built by propagating the induced equivalence relation, with each chain corresponding to an entity (.", "labels": [], "entities": []}, {"text": "While this single-antecedent inference task does resolve a very large number of anaphors in any given text, it leaves one quite common subproblem virtually untouched: anaphors that link to multiple antecedents.", "labels": [], "entities": []}, {"text": "These have sometimes been called split-antecedent anaphors; here we use the term multi-antecedent anaphors or m-anaphors in order to emphasize the existence of more than one (possibly more than two) antecedents fora given anaphor.", "labels": [], "entities": []}, {"text": "Consider the following examples: (1) 1 met 2 at the park and [they] 1,2 began their stroll to the river.", "labels": [], "entities": []}, {"text": "(2) Mrs. Dashwood, having moved to another country, saw her 1 and [sister-inlaw] 2 demoted to occasional visitors.", "labels": [], "entities": [{"text": "Mrs. Dashwood", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7645923495292664}]}, {"text": "As such, however, her old [kin] 1,2 were treated by her new family with quiet civility.", "labels": [], "entities": []}, {"text": "Such cases present a challenge to state-of-theart methods: certain features well-suited for the single-antecedent case do not apply (e.g. gender and pluarity)), and strong long-distance effects cannot be ignored.", "labels": [], "entities": []}, {"text": "Moreover, the presence of multiple antecedents fora single anaphor violates the separation between coreference chains.", "labels": [], "entities": []}, {"text": "In this paper, we address the multi-antecedent case of noun-phrase (NP) anaphor resolution in English, the most widely understood and studied form of coreference resolution.", "labels": [], "entities": [{"text": "noun-phrase (NP) anaphor resolution", "start_pos": 55, "end_pos": 90, "type": "TASK", "confidence": 0.6449039926131567}, {"text": "coreference resolution", "start_pos": 150, "end_pos": 172, "type": "TASK", "confidence": 0.9441527128219604}]}, {"text": "While we frame the general question of multi-antecedent inference, we restrict our analyses to one particular sub-problem: resolving the antecedents of the pronouns they and them.", "labels": [], "entities": [{"text": "multi-antecedent inference", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.7152760624885559}]}, {"text": "These pronouns best isolate the characteristics of manaphors (see Section 2 for more on the motivation of this choice).", "labels": [], "entities": []}, {"text": "We propose a system for resolving they and them that models grouping compatibility of mentions through a maximum entropy pairwise model, independently from coreference of groupings, which is handled through an existing coreference resolution system leveraging corpus knowledge.", "labels": [], "entities": []}, {"text": "This paper makes four core contributions.", "labels": [], "entities": []}, {"text": "First, it provides a generalization of the anaphor resolution problem to permit linking to multiple antecedents.", "labels": [], "entities": [{"text": "anaphor resolution problem", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.7773124972979227}]}, {"text": "Second, we characterize core properties of m-anaphors and their linguistic environments in a large, annotated corpus.", "labels": [], "entities": []}, {"text": "Third, we provide a entity-centric system for specifically resolving multi-antecedent cases that outperforms a number of baselines.", "labels": [], "entities": []}, {"text": "And, finally, we show how to pair our system with an existing coreference system and show again of 0.6 points (CoNLL F1) on the complete coreference resolution task (resolving all anaphors, single-and multi-antecedent).", "labels": [], "entities": [{"text": "CoNLL F1)", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.932638426621755}, {"text": "coreference resolution", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.8767116069793701}]}, {"text": "The rest of the paper is organized as follows: We introduce the terminology and problem statement for split-antecedent resolution in Section 2.", "labels": [], "entities": [{"text": "split-antecedent resolution", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.886945903301239}]}, {"text": "A summary of the data is given in Section 3 and the behaviour of split-antecedent anaphors is analyzed in Section 4.", "labels": [], "entities": []}, {"text": "Our approach to antecedent prediction is presented in Section 5 and the results and analysis are reported in Section 6.", "labels": [], "entities": [{"text": "antecedent prediction", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7170795500278473}]}, {"text": "Finally, we review related work in Section 7 and conclude and discuss future work in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to assess the performance of our method, we conduct two experiments.", "labels": [], "entities": []}, {"text": "In the first, we assess performance of our system on the specific they-them m-anaphor resolution sub-task.", "labels": [], "entities": []}, {"text": "Our system, and its variants, are compared against a number of baseline methods based on performance on the test set.", "labels": [], "entities": []}, {"text": "In the second experiment, we consider how our system improves the performance of a coreference resolution system when all anaphors (both 1-anaphors and m-anaphors) are considered.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.9099001884460449}]}, {"text": "Accuracy is measured in terms of the number of mention pairs correctly grouped as mantecedents fora given m-anaphor -similar to previous works in anaphor resolution (.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9956188797950745}, {"text": "anaphor resolution", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.7460587918758392}]}, {"text": "We use the standard classification metrics for precision, recall, and F1-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9997662901878357}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9995905756950378}, {"text": "F1-score", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9989023208618164}]}, {"text": "If n 1 , n 2 , . .", "labels": [], "entities": []}, {"text": ", n N represent the number of gold m-antecedents for m-anaphors g 1 , g 2 , . .", "labels": [], "entities": []}, {"text": ", g N in a document, and m 1 , m 2 , . .", "labels": [], "entities": []}, {"text": ", m N are predicted, of which k 1 , k 2 , . .", "labels": [], "entities": []}, {"text": ", k N are correct, then precision is defined as i k i / i mi and recall as i k i / in i , where i ranges from 1 to N . In order to align ourselves with the gold labels, we adjust the predicted mention corresponding to an entity to the closest one preceding the given m-anaphor.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9996803998947144}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9994694590568542}]}, {"text": "Because a given entity may appear multiple times in a candidate mention window, the most recent one, relative to the m-anaphor, is not always the one carrying the strongest signal and hence is not always predicted as an antecedent.", "labels": [], "entities": []}, {"text": "For the purposes of evaluation, such cases are considered correct.", "labels": [], "entities": []}, {"text": "Automatic handling would involve a separate, single-antecedent coreference resolver, but given the thesis of this work is the multi-antecedent case, this choice is justified.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.8467643558979034}]}], "tableCaptions": [{"text": " Table 1: Counts of the most frequent m-anaphoric  pronouns in P&P.", "labels": [], "entities": []}, {"text": " Table 2: Number of m-anaphoric they and them  mentions and % of all they and them mentions that  are m-anaphors.", "labels": [], "entities": []}, {"text": " Table 3: Average and standard deviations of the  word distance, sentence distance, and number of  intermediate mentions between the first and sec- ond most recent mentions to an m-anaphor.", "labels": [], "entities": []}, {"text": " Table 3. The usual  presence of intermediate mentions between m- anaphors and their m-antecedents makes the res- olution task non-trivial. Moreover, the large dis- tances between m-anaphors and their antecedents  attenuates any signal for coreference, introducing  greater noise to the problem.", "labels": [], "entities": []}, {"text": " Table 6: Test set performance of each system on  the m-anaphor resolution task.", "labels": [], "entities": [{"text": "m-anaphor resolution task", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.7837014396985372}]}, {"text": " Table 7: Performance results of the M-TREE sys- tem on the different classes of m-anaphors.", "labels": [], "entities": []}, {"text": " Table 8: CoNLL metric scores for coreference res- olution on the test portion of P&P for the Clark  and Manning", "labels": [], "entities": [{"text": "CoNLL metric", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.7895922064781189}, {"text": "coreference res- olution", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.7803661823272705}]}]}