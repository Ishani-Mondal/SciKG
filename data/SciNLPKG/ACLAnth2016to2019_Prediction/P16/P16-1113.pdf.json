{"title": [{"text": "Neural Semantic Role Labeling with Dependency Path Embeddings", "labels": [], "entities": [{"text": "Neural Semantic Role Labeling", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7310099899768829}]}], "abstractContent": [{"text": "This paper introduces a novel model for semantic role labeling that makes use of neural sequence modeling techniques.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7453811367352804}]}, {"text": "Our approach is motivated by the observation that complex syntactic structures and related phenomena, such as nested subordinations and nominal predicates, are not handled well by existing models.", "labels": [], "entities": []}, {"text": "Our model treats such instances as sub-sequences of lexicalized dependency paths and learns suitable embedding representations.", "labels": [], "entities": []}, {"text": "We experimentally demonstrate that such embeddings can improve results over previous state-of-the-art semantic role la-belers, and showcase qualitative improvements obtained by our method.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of semantic role labeling (SRL) is to identify and label the arguments of semantic predicates in a sentence according to a set of predefined relations (e.g., \"who\" did \"what\" to \"whom\").", "labels": [], "entities": [{"text": "semantic role labeling (SRL) is to identify and label the arguments of semantic predicates in a sentence according to a set of predefined relations (e.g., \"who\" did \"what\" to \"whom\")", "start_pos": 12, "end_pos": 194, "type": "Description", "confidence": 0.772594902664423}]}, {"text": "Semantic roles provide a layer of abstraction beyond syntactic dependency relations, such as subject and object, in that the provided labels are insensitive to syntactic alternations and can also be applied to nominal predicates.", "labels": [], "entities": []}, {"text": "Previous work has shown that semantic roles are useful fora wide range of natural language processing tasks, with recent applications including statistical machine translation), plagiarism detection (, and multi-document abstractive summarization (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 144, "end_pos": 175, "type": "TASK", "confidence": 0.7169396877288818}, {"text": "plagiarism detection", "start_pos": 178, "end_pos": 198, "type": "TASK", "confidence": 0.717579796910286}, {"text": "multi-document abstractive summarization", "start_pos": 206, "end_pos": 246, "type": "TASK", "confidence": 0.6915855010350546}]}, {"text": "The task of semantic role labeling (SRL) was pioneered by: Outputs of SRL systems for the sentence He had trouble raising funds.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.8229393362998962}]}, {"text": "Arguments of raise are shown with predicted roles as defined in PropBank (A0: getter of money; A1: money).", "labels": [], "entities": [{"text": "PropBank", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8240268230438232}]}, {"text": "Asterisks mark flawed analyses that miss the argument He. their work, features based on syntactic constituent trees were identified as most valuable for labeling predicate-argument relationships.", "labels": [], "entities": []}, {"text": "Later work confirmed the importance of syntactic parse features ( and found that dependency parse trees provide a better form of representation to assign role labels to arguments.", "labels": [], "entities": [{"text": "syntactic parse", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7032181322574615}, {"text": "dependency parse trees", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7665015955766042}]}, {"text": "Most semantic role labeling approaches to date rely heavily on lexical and syntactic indicator features.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.6199544966220856}]}, {"text": "Through the availability of large annotated resources, such as PropBank (), statistical models based on such features achieve high accuracy.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9634496569633484}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9942281246185303}]}, {"text": "However, results often fall short when the input to be labeled involves instances of linguistic phenomena that are relevant for the labeling decision but appear infrequently at training time.", "labels": [], "entities": []}, {"text": "Examples include control and raising verbs, nested conjunctions or other recursive structures, as well as rare nominal predicates.", "labels": [], "entities": []}, {"text": "The difficulty lies in that simple lexical and syntactic indicator features are notable to model interactions triggered by such phenomena.", "labels": [], "entities": []}, {"text": "For instance, con-sider the sentence He had trouble raising funds and the analyses provided by four publicly available tools in (mate-tools,; mateplus,; TensorSRL,; and easySRL,).", "labels": [], "entities": [{"text": "easySRL", "start_pos": 169, "end_pos": 176, "type": "METRIC", "confidence": 0.8860782384872437}]}, {"text": "Despite all systems claiming stateof-the-art or competitive performance, none of them is able to correctly identify He as the agent argument of the predicate raise.", "labels": [], "entities": []}, {"text": "Given the complex dependency path relation between the predicate and its argument, none of the systems actually identifies He as an argument at all.", "labels": [], "entities": []}, {"text": "In this paper, we develop anew neural network model that can be applied to the task of semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.7990699609120687}]}, {"text": "The goal of this model is to better handle control predicates and other phenomena that can be observed from the dependency structure of a sentence.", "labels": [], "entities": []}, {"text": "In particular, we aim to model the semantic relationships between a predicate and its arguments by analyzing the dependency path between the predicate word and each argument headword.", "labels": [], "entities": []}, {"text": "We consider lexicalized paths, which we decompose into sequences of individual items, namely the words and dependency relations on a path.", "labels": [], "entities": []}, {"text": "We then apply long-short term memory networks) to find a recurrent composition function that can reconstruct an appropriate representation of the full path from its individual parts (Section 2).", "labels": [], "entities": []}, {"text": "To ensure that representations are indicative of semantic relationships, we use semantic roles as target labels in a supervised setting (Section 3).", "labels": [], "entities": []}, {"text": "By modeling dependency paths as sequences of words and dependencies, we implicitly address the data sparsity problem.", "labels": [], "entities": []}, {"text": "This is the case because we use single words and individual dependency relations as the basic units of our model.", "labels": [], "entities": []}, {"text": "In contrast, previous SRL work only considered full syntactic paths.", "labels": [], "entities": [{"text": "SRL", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9757340550422668}]}, {"text": "Experiments on the CoNLL-2009 benchmark dataset show that our model is able to outperform the state-of-the-art in English (Section 4), and that it improves SRL performance in other languages, including Chinese, German and Spanish (Section 5).", "labels": [], "entities": [{"text": "CoNLL-2009 benchmark dataset", "start_pos": 19, "end_pos": 47, "type": "DATASET", "confidence": 0.9684678514798483}, {"text": "SRL", "start_pos": 156, "end_pos": 159, "type": "TASK", "confidence": 0.9825389385223389}]}], "datasetContent": [{"text": "In this section, we demonstrate the usefulness of dependency path embeddings for semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7438390254974365}]}, {"text": "Our hypotheses are that (1) modeling dependency paths as sequences will lead to better representations for the SRL task, thus increasing labeling precision overall, and that (2) embeddings will address the problem of data sparsity, leading to higher recall.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 111, "end_pos": 119, "type": "TASK", "confidence": 0.9327666461467743}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9516106843948364}, {"text": "recall", "start_pos": 250, "end_pos": 256, "type": "METRIC", "confidence": 0.9985499978065491}]}, {"text": "To test both hypotheses, we experiment on the in-domain and out-of-domain test sets provided in the CoNLL-2009 shared task) and compare results of our system, henceforth PathLSTM, with systems that do not involve path embeddings.", "labels": [], "entities": [{"text": "CoNLL-2009 shared task", "start_pos": 100, "end_pos": 122, "type": "DATASET", "confidence": 0.8631423314412435}]}, {"text": "We compute precision, recall and F 1 -score using the official CoNLL-2009 scorer.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9996161460876465}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.999670147895813}, {"text": "F 1 -score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9848665595054626}, {"text": "CoNLL-2009 scorer", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.904534637928009}]}, {"text": "The code is available at https://github.com/microth/PathLSTM..", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Hyperparameters selected for best models and training procedures", "labels": [], "entities": []}, {"text": " Table 3: Results on the CoNLL-2009 in-domain  test set. All numbers are in percent.", "labels": [], "entities": [{"text": "CoNLL-2009 in-domain  test set", "start_pos": 25, "end_pos": 55, "type": "DATASET", "confidence": 0.8762742877006531}]}, {"text": " Table 4: Ablation tests in the in-domain setting.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9858048558235168}]}, {"text": " Table 5: Results on the CoNLL-2009 out-of- domain test set. All numbers are in percent.", "labels": [], "entities": [{"text": "CoNLL-2009 out-of- domain test set", "start_pos": 25, "end_pos": 59, "type": "DATASET", "confidence": 0.7993627587954203}]}, {"text": " Table 6: Results by word category and role label.", "labels": [], "entities": []}]}