{"title": [{"text": "A Neural Network based Approach to Automatic Post-Editing", "labels": [], "entities": [{"text": "Approach", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9413400888442993}]}], "abstractContent": [{"text": "We present a neural network based automatic post-editing (APE) system to improve raw machine translation (MT) output.", "labels": [], "entities": [{"text": "machine translation (MT) output", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.7931199669837952}]}, {"text": "Our neural model of APE (NNAPE) is based on a bidirectional recurrent neu-ral network (RNN) model and consists of an encoder that encodes an MT output into a fixed-length vector from which a de-coder provides a post-edited (PE) translation.", "labels": [], "entities": []}, {"text": "APE translations produced by NNAPE show statistically significant improvements of 3.96, 2.68 and 1.35 BLEU points absolute over the original MT, phrase-based APE and hierarchical APE outputs, respectively.", "labels": [], "entities": [{"text": "APE translations", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8716183304786682}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9962856769561768}]}, {"text": "Furthermore, human evaluation shows that the NNAPE generated PE translations are much better than the original MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9454485774040222}]}], "introductionContent": [{"text": "For many applications the performance of stateof-the-art MT systems is useful but often far from perfect.", "labels": [], "entities": [{"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9813014268875122}]}, {"text": "MT technologies have gained wide acceptance in the localization industry.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9828260540962219}]}, {"text": "Computer aided translation (CAT) has become the de-facto standard in large parts of the translation industry which has resulted in a surge of demand for professional post-editors.", "labels": [], "entities": [{"text": "Computer aided translation (CAT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.771931196252505}]}, {"text": "This, in turn, has resulted in substantial quantities of PE data which can be used to develop APE systems.", "labels": [], "entities": [{"text": "PE", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.8817049860954285}, {"text": "APE", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9635182023048401}]}, {"text": "In the context of MT, \"post-editing\" (PE) is defined as the correction performed by humans over the translations produced by an MT system, often with minimal amount of manual effort and as a process of modification rather than revision.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9883804321289062}, {"text": "post-editing\" (PE)", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.6129240453243255}]}, {"text": "MT systems primarily make two types of errors -lexical and reordering errors.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9776491522789001}]}, {"text": "However, due to the statistical and probabilistic nature of modelling in statistical MT (SMT), the currently dominant MT technology, it is non-trivial to rectify these errors in the SMT models.", "labels": [], "entities": [{"text": "MT (SMT)", "start_pos": 85, "end_pos": 93, "type": "TASK", "confidence": 0.7769821286201477}, {"text": "MT", "start_pos": 118, "end_pos": 120, "type": "TASK", "confidence": 0.9608734846115112}, {"text": "SMT", "start_pos": 182, "end_pos": 185, "type": "TASK", "confidence": 0.9785364866256714}]}, {"text": "Post-edited data are often used in incremental MT frameworks as additional training material.", "labels": [], "entities": [{"text": "MT frameworks", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.9088321626186371}]}, {"text": "However, often this does not fully exploit the potential of these rich PE data: e.g., PE data may just be drowned out by a large SMT model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9641704559326172}]}, {"text": "An APE system trained on human post-edited data can serve as a MT post-processing module which can improve overall performance.", "labels": [], "entities": [{"text": "MT post-processing", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.8811068832874298}]}, {"text": "An APE system can be considered as an MT system, translating predictable error patterns in MT output into their corresponding corrections.", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.972701370716095}]}, {"text": "APE systems assume the availability of source language input text (SL IP ), target language MT output (T L MT ) and target language PE data (T LP E ).", "labels": [], "entities": []}, {"text": "An APE system can be modelled as an MT system between SL IP T L MT and T LP E . However, if we do not have access to SL IP , but have sufficiently large amounts of parallel T L MT -T LP E data, we can still build an APE model between T L MT and T LP E . Translations provided by state-of-the-art MT systems suffer from a number of errors including incorrect lexical choice, word ordering, word insertion, word deletion, etc.", "labels": [], "entities": [{"text": "APE", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9453833699226379}, {"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9775412678718567}, {"text": "word ordering", "start_pos": 374, "end_pos": 387, "type": "TASK", "confidence": 0.7280822843313217}, {"text": "word insertion", "start_pos": 389, "end_pos": 403, "type": "TASK", "confidence": 0.7373303174972534}]}, {"text": "The APE work presented in this paper is an effort to improve the MT output by rectifying some of these errors.", "labels": [], "entities": [{"text": "APE work", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.6490625292062759}, {"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9863134622573853}]}, {"text": "For this purpose we use a deep neural network (DNN) based approach.", "labels": [], "entities": []}, {"text": "Neural MT (NMT)) is a newly emerging approach to MT.", "labels": [], "entities": [{"text": "Neural MT (NMT))", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8110243380069733}, {"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.9957565665245056}]}, {"text": "On the one hand DNNs represent language in a continuous vector space which eases the modelling of semantic similarities (or distance) between phrases or sentences, and on the other hand it can also consider contextual information, e.g., utilizing all available history information in deciding the next target word, which is not an easy task to model with standard APE systems.", "labels": [], "entities": []}, {"text": "Unlike phrase-based APE systems (), our NNAPE system builds and trains a single, large neural network that accepts a 'draft' translation (T L MT ) and outputs an improved translation (T LP E ).", "labels": [], "entities": [{"text": "T LP E )", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.880823627114296}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of relevant related work.", "labels": [], "entities": []}, {"text": "The proposed NNAPE system is described in detail in Section 3.", "labels": [], "entities": []}, {"text": "We present the experimental setup in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 presents the results of automatic and human evaluation together with some analysis.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper and provides avenues for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the model on an English-Italian APE task, which is detailed in the following subsections.", "labels": [], "entities": [{"text": "APE task", "start_pos": 44, "end_pos": 52, "type": "TASK", "confidence": 0.5326751321554184}]}, {"text": "Our bidirectional RNN Encoder-Decoder contains 1000 hidden units for the forward backward RNN encoder and 1000 hidden units for the decoder.", "labels": [], "entities": []}, {"text": "The network is basically a multilateral neural network with a single maxout unit as hidden layer () to compute the conditional probability of each target word.", "labels": [], "entities": []}, {"text": "The word embedding vector dimension is 620 and the size of the maxout hidden layer in the deep output is 500.", "labels": [], "entities": []}, {"text": "The number of hidden units in the alignment model is 1000.", "labels": [], "entities": []}, {"text": "The model has been trained on a mini-batched stochastic gradient descent (SGD) with 'Adadelta'.", "labels": [], "entities": [{"text": "stochastic gradient descent (SGD)", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.7161554197470347}]}, {"text": "The main reason behind the use of 'Adadelta' is to automatically adapt the learning rate of each parameter ( = 10 \u22126 and \u03c1 = 0.95).", "labels": [], "entities": []}, {"text": "Each SGD update direction is computed using a mini-batch of 80 sentences.", "labels": [], "entities": [{"text": "SGD update direction", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.8846465547879537}]}, {"text": "We compare our NNAPE system with state-ofthe-art phrase-based () as well as hierarchical phrase-based APE (Pal, 2015) systems.", "labels": [], "entities": [{"text": "phrase-based APE (Pal, 2015)", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.6482944871698108}]}, {"text": "We also compare the output provided by our system against the original GT output.", "labels": [], "entities": []}, {"text": "For building the phrase-based and hierarchical phrasebased APE systems, we set maximum phrase length to 7.", "labels": [], "entities": []}, {"text": "A 5-gram language model built using KenLM (Heafield, 2011) was used for decoding.", "labels": [], "entities": [{"text": "KenLM (Heafield, 2011)", "start_pos": 36, "end_pos": 58, "type": "DATASET", "confidence": 0.8208398520946503}]}, {"text": "System tuning was carried out using both k-best MIRA (Cherry and Foster, 2012) and Minimum Error Rate Training (MERT) on the held-out development set (devset).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.8869194388389587}, {"text": "Minimum Error Rate Training (MERT)", "start_pos": 83, "end_pos": 117, "type": "METRIC", "confidence": 0.9177636504173279}]}, {"text": "After parameters were tuned, decoding was carried out on the held out test set.", "labels": [], "entities": []}, {"text": "The performance of the NNAPE system was evaluated using both automatic and human evaluation methods, as described below.", "labels": [], "entities": []}, {"text": "The output of the NNAPE system on the 1000 sentences testset was evaluated using three MT evaluation metrics: BLEU), TER () and.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.998673677444458}, {"text": "TER", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9969319105148315}]}, {"text": "provides a comparison of our neural system performance against the baseline phrase-based APE (S 1 ), baseline hierarchical phrase-based APE (S 2 ) and the original GT output.", "labels": [], "entities": []}, {"text": "We use a, b, c, and d to indicate statistical significance over GT, S 1 , S 2 and our NNAPE system (NN), respectively.", "labels": [], "entities": []}, {"text": "For example, the S 2 BLEU score 63.87 a,b in means that the improvement provided by S 2 in BLEU is statistically significant over Google Translator and phrase-based APE.", "labels": [], "entities": [{"text": "BLEU score 63.87 a,b", "start_pos": 21, "end_pos": 41, "type": "METRIC", "confidence": 0.9420161843299866}, {"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.8894355297088623}]}, {"text": "shows that S 1 provides statistically significant (0.01 < p < 0.04) improvements over GT across all metrics.", "labels": [], "entities": []}, {"text": "Similarly S 2 yields statistically significant (p < 0.01) improvements over both GT and S 1 across all metrics.", "labels": [], "entities": []}, {"text": "The NN system performs best and results in statistically significant (p < 0.01) improvements overall other systems across all metrics.", "labels": [], "entities": []}, {"text": "A systematic trend (N N > S 2 > S 1 > GT ) can be observed in  Human evaluation was carried out by four professional translators, native speakers of Italian, with professional translation experience between one and two years.", "labels": [], "entities": []}, {"text": "Since human evaluation is very costly and time consuming, it was carried out on a small portion of the test set consisting of 145 randomly sampled sentences and only compared NN with the original GT output.", "labels": [], "entities": []}, {"text": "We used a polling scheme with three different options.", "labels": [], "entities": []}, {"text": "Translators choose which of the two (GT or NN) outputs is the better translation or whether there is a tie ('uncertain').", "labels": [], "entities": []}, {"text": "To avoid any bias towards any particular system, the order in which two system outputs are presented is randomized so that the translators do not know which system they are contributing their votes to.", "labels": [], "entities": []}, {"text": "We analyzed the outcome of the voting process (4 translators each giving 145 votes) and found that the winning NN system received 285 (49.13%) votes compared to 99 (17.07%) votes received by the GT system, while the rest of the votes.79%) go to the 'uncertain' option.", "labels": [], "entities": [{"text": "NN system", "start_pos": 111, "end_pos": 120, "type": "DATASET", "confidence": 0.9214300811290741}]}, {"text": "We measured pairwise inter-annotator agreement between the translators by computing Cohen's \u03ba coefficient reported in.", "labels": [], "entities": []}, {"text": "The overall \u03ba coefficient is 0.330.", "labels": [], "entities": [{"text": "\u03ba coefficient", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.9627442955970764}]}, {"text": "According to this correlation coefficient can be interpreted as fair.", "labels": [], "entities": [{"text": "correlation", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9664439558982849}]}, {"text": "Cohen's \u03ba: Pairwise correlation between translators in the evaluation process.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Pairwise correlation between translators  in the evaluation process.", "labels": [], "entities": []}]}