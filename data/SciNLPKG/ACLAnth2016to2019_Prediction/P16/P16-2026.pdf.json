{"title": [{"text": "How Naked is the Naked Truth? A Multilingual Lexicon of Nominal Compound Compositionality", "labels": [], "entities": [{"text": "Nominal Compound Compositionality", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.7844676574071249}]}], "abstractContent": [{"text": "We introduce anew multilingual resource containing judgments about nominal compound compositionality in English, French and Por-tuguese.", "labels": [], "entities": []}, {"text": "It covers 3 \u00d7 180 noun-noun and adjective-noun compounds for which we provide numerical compositionality scores for the headword, for the modifier and for the compound as a whole, along with possible paraphrases.", "labels": [], "entities": []}, {"text": "This resource was constructed by native speakers via crowdsourcing.", "labels": [], "entities": []}, {"text": "It can serve as basis for evaluating tasks such as lexical substitution and compositionality prediction.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.7136792838573456}, {"text": "compositionality prediction", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.8917793333530426}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) are notoriously challenging for NLP, due to their many potential levels of idiosyncrasy, from lexical to semantic and pragmatic to statistical.", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7408259391784668}]}, {"text": "One widely known problem is the semantic interpretation of noun compounds, which in English are noun phrases composed by a sequence of nouns.", "labels": [], "entities": [{"text": "semantic interpretation of noun compounds", "start_pos": 32, "end_pos": 73, "type": "TASK", "confidence": 0.8630446553230285}]}, {"text": "These MWEs often lack a structure from which to identify implicit semantic relations unambiguously.", "labels": [], "entities": []}, {"text": "For instance, there is no indication that a brick wall is a wall made of bricks, while a cheese knife is not a knife made of cheese, but rather a knife for cutting cheese ().", "labels": [], "entities": []}, {"text": "Noun compounds are often idiomatic or noncompositional.", "labels": [], "entities": []}, {"text": "That is, the meaning of the whole does not come directly from the meaning of the parts.", "labels": [], "entities": []}, {"text": "For instance, a black Friday is not any Friday that is somehow black, but is the day following Thanksgiving Day in the United States.", "labels": [], "entities": []}, {"text": "Moreover, the contribution of the semantics of each element for the meaning of the compound may vary considerably (e.g. police car vs. crocodile tears).", "labels": [], "entities": []}, {"text": "Any NLP application that intends to deal with phrasal semantics adequately must be able to distinguish fairly compositional from fully idiomatic compounds.", "labels": [], "entities": []}, {"text": "For example, automatically translating dead end literally into French (?fin morte) or Portuguese (?fim morto) would drastically alter the meaning of the original expression.", "labels": [], "entities": [{"text": "translating dead end literally", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.669205792248249}]}, {"text": "In this paper we introduce a resource with human judgments about the semantics of compounds and their individual elements.", "labels": [], "entities": []}, {"text": "Eliciting quantitative judgments about compositionality from non-linguists maybe too abstract, even with accompanying guidelines and training.", "labels": [], "entities": []}, {"text": "We propose a more constrained way of obtaining these judgments, with the participation of non-experts through crowdsourcing.", "labels": [], "entities": []}, {"text": "We first focus the participants' attention on compound interpretation in context, by requesting paraphrases in example sentences.", "labels": [], "entities": [{"text": "compound interpretation", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.7609477937221527}]}, {"text": "Then, we inquire about the degree to which the meaning of a given compound arises from each of its elements.", "labels": [], "entities": []}, {"text": "The assumption is that if the interpretation of the compound comes from both nouns (e.g. access road), then it is fully compositional, whereas if it is unrelated to both nouns (e.g. nut case), then it is fully idiomatic.", "labels": [], "entities": []}, {"text": "This indirect annotation does not require expert knowledge and provides reliable and stable data.", "labels": [], "entities": []}, {"text": "This paper presents a multilingual resource that models compounds compositionality, including both numerical scores and free paraphrases.", "labels": [], "entities": []}, {"text": "Data is currently available for 180 compounds in 3 different languages: English, French and Portuguese.", "labels": [], "entities": []}, {"text": "Such resources are extremely valuable, as they enable the development and evaluation of techniques for automatic compositionality prediction and lexical substitution.", "labels": [], "entities": [{"text": "compositionality prediction", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.7695609331130981}, {"text": "lexical substitution", "start_pos": 145, "end_pos": 165, "type": "TASK", "confidence": 0.7257272303104401}]}, {"text": "This paper is structured as follows: \u00a72 discusses related work; \u00a73 discusses the target compounds, the annotation schema and interface; \u00a74 presents the results and \u00a75 the conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Although noun-noun compounds are rare in some languages mainly due to syntactic reasons, these languages present alternatives to this type of configuration.", "labels": [], "entities": []}, {"text": "In French (FR) and Brazilian Portuguese (PT), the equivalents of English (EN) compounds of the form N 1 N 2 are usually: 1.", "labels": [], "entities": []}, {"text": "N 2 PREP N 1 , connecting the nouns through a preposition and optional determiner; e.g. lung cancer (EN) \u2192 cancer du poumon (FR), c\u00e2ncer de pulm\u00e3o (PT).", "labels": [], "entities": []}, {"text": "2. N 2 ADJ 1 , using a denominal adjective which is derived from N 1 ; e.g. cell death (EN) \u2192 mort cellulaire (FR), morte celular (PT).", "labels": [], "entities": []}, {"text": "We describe the construction of datasets for English, French and Brazilian Portuguese.", "labels": [], "entities": []}, {"text": "Given the two syntactic forms above, we focus on N 2 ADJ 1 for French and Portuguese, as its simpler structure resembles more closely the English noun-noun compound structure, and also because we have some ADJ 1 N 2 compounds in English as well (e.g. sacred cow).", "labels": [], "entities": []}, {"text": "We collectively call our target constructions nominal compounds, as they have nouns as head of the phrase.", "labels": [], "entities": []}, {"text": "For each language, data collection involves the following steps: (1) compound selection; (2) sentence selection; and (3) questionnaire design.", "labels": [], "entities": [{"text": "compound selection", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.6971112191677094}, {"text": "sentence selection", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7709124684333801}, {"text": "questionnaire design", "start_pos": 121, "end_pos": 141, "type": "TASK", "confidence": 0.7162732481956482}]}, {"text": "Compound selection The initial set of idiomatic and partially compositional candidates was constructed by introspection, independently for each language, since these maybe harder to find in corpora because of lower frequency.", "labels": [], "entities": [{"text": "Compound selection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7317945063114166}]}, {"text": "This list of compounds was complemented by selecting entries from lists of frequent adjective+noun and noun+noun pairs.", "labels": [], "entities": []}, {"text": "These were automatically extracted through POS-sequence queries using the mwetoolkit (Ramisch, 2015) from ukWaC (), frWaC and brWaC ().", "labels": [], "entities": []}, {"text": "We removed all compounds in which the complement is not an adjective in Portuguese/French (e.g. PT noun-noun abelha rainha), those in which the head is not necessarily a noun (e.g. FR aller simple, as aller is also a verb) and those in which the literal sense is very common in the corpus (e.g. EN low blow).", "labels": [], "entities": []}, {"text": "For each language, we attempted to select a balanced set of 60 idiomatic, 60 partially compositional and 60 fully compositional compounds by rough manual preannotation.", "labels": [], "entities": []}, {"text": "Sentence selection For each compound, we selected 3 sentences from a WaC corpus where the compound is used with the same meaning.", "labels": [], "entities": [{"text": "WaC corpus", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.8924272060394287}]}, {"text": "These sentences are used during the data collection process (described later) as disambiguating context for the annotators.", "labels": [], "entities": [{"text": "data collection process", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7503725091616312}]}, {"text": "We sort them by sentence length, in order to favor shorter sentences, and manually select 3 examples that satisfy these criteria: \u2022 The occurrence of the compound must have the same meaning in all sentences.", "labels": [], "entities": []}, {"text": "\u2022 A sentence must contain enough context to enable mental disambiguation of the compound.", "labels": [], "entities": []}, {"text": "\u2022 Inter-sentence variability can be used to provide more information to the reader.", "labels": [], "entities": []}, {"text": "Questionnaire design We collect data for each compound through a separate HIT (Human Intelligence Task).", "labels": [], "entities": []}, {"text": "Each HIT page contains a list of instructions followed by the questionnaire associated with that compound.", "labels": [], "entities": []}, {"text": "In the instructions, we briefly describe the task and require that the users fill in an external identification form, following.", "labels": [], "entities": []}, {"text": "This form provides us with demographics about the annotators, ensuring that they are native speakers of the target language.", "labels": [], "entities": []}, {"text": "At the end of the form, they are also given extra example questions with annotated answers for training.", "labels": [], "entities": []}, {"text": "After filling in the identification form, users can start working on the task.", "labels": [], "entities": []}, {"text": "This section of the HIT is structured in 5 subtasks: 1.", "labels": [], "entities": []}, {"text": "2. Read 3 sentences containing the compound.", "labels": [], "entities": []}, {"text": "3. Provide 2 to 3 synonym expressions for the target compound seen in the sentences.", "labels": [], "entities": []}, {"text": "4. Using a Likert scale from 0 to 5, judge how much of the meaning of the compound comes from word 1 (mod) and word 2 (head) separately, as shown in.", "labels": [], "entities": []}, {"text": "5. Using a Likert scale from 0 to 5, judge how much of the meaning of the compound (comp) comes from its components.", "labels": [], "entities": []}, {"text": "We have been consciously careful about requiring answers in an even-numbered scale (0-5 makes for 6 reply categories), as otherwise, undecided annotators would be biased towards the middle score.", "labels": [], "entities": []}, {"text": "As an additional help for the annotators, when the mouse hovers over a reply to a multiple-choice question, we present a guiding tooltip, as in.", "labels": [], "entities": []}, {"text": "We avoid incomplete HITs by making Subtasks 3-5 mandatory.", "labels": [], "entities": []}, {"text": "The order of subtasks has also been taken into account.", "labels": [], "entities": []}, {"text": "During a pilot test, we found that presenting the multiple-choice questions (Subtasks 4-5) before asking for synonyms (Subtask 3) yielded lower agreement, as users were often less self-consistent in the multiplechoice questions (e.g. replying \"non-compositional\" for Subtask 4 but \"compositional\" for Subtask 5), even if they carefully selected their synonyms in response to Subtask 3.", "labels": [], "entities": [{"text": "agreement", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9782724380493164}]}, {"text": "Asking for synonyms prior to the multiplechoice questions helps the user focus on the target meaning for the compound and also have more examples (the synonyms) when considering the semantic contribution of each element of the compound.", "labels": [], "entities": []}, {"text": "For EN and FR, annotators were recruited and paid via Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "EN and FR", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.42239434520403546}, {"text": "Amazon Mechanical Turk", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.949147641658783}]}, {"text": "The quality of FR results was manually controlled by only accepting HITs with reasonable paraphrases.", "labels": [], "entities": [{"text": "FR", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.985363781452179}, {"text": "HITs", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.7797691822052002}]}, {"text": "During a pilot, we noticed the lack of qualified PT native speakers on the platform.", "labels": [], "entities": []}, {"text": "For PT only, judgments were provided by volunteers through a standalone web interface that simulated the HIT page.", "labels": [], "entities": [{"text": "PT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9372631311416626}]}], "tableCaptions": [{"text": " Table 1: Pearson correlation r and number of cases of  high standard deviation \u03c3.  Out of all human judges, 3 of them annotated a large  subset of 119 compounds in PT. For this subset, we re- port inter-annotator agreement. Pairwise weighted \u03ba  values range from .28 to .58 depending on the ques- tion (head, mod or comp) and on the annotator pair.  Multi-rater \u03b1 agreement (", "labels": [], "entities": [{"text": "Pearson correlation r", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.9049733678499857}, {"text": "Multi-rater \u03b1 agreement", "start_pos": 351, "end_pos": 374, "type": "METRIC", "confidence": 0.7589126626650492}]}, {"text": " Table 2: Most polemic and consensual compounds in  each language (average\u00b1\u03c3 score).", "labels": [], "entities": []}]}