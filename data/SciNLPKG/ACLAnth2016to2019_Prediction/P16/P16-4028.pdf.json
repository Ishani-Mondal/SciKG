{"title": [{"text": "new/s/leak -Information Extraction and Visualization for Investigative Data Journalists", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.667618066072464}]}], "abstractContent": [{"text": "We present new/s/leak, a novel tool developed for and with the help of journalists , which enables the automatic analysis and discovery of newsworthy stories from large textual datasets.", "labels": [], "entities": [{"text": "automatic analysis and discovery of newsworthy stories from large textual", "start_pos": 103, "end_pos": 176, "type": "TASK", "confidence": 0.7532503545284271}]}, {"text": "We rely on different NLP preprocessing steps such named entity tagging, extraction of time expressions , entity networks, relations and meta-data.", "labels": [], "entities": [{"text": "entity tagging", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7135710418224335}]}, {"text": "The system features an intuitive web-based user interface based on network visualization combined with data exploring methods and various search and faceting mechanisms.", "labels": [], "entities": []}, {"text": "We report the current state of the software and exemplify it with the WikiLeaks PlusD (Cablegate) data.", "labels": [], "entities": [{"text": "WikiLeaks PlusD (Cablegate) data", "start_pos": 70, "end_pos": 102, "type": "DATASET", "confidence": 0.8888294200102488}]}], "introductionContent": [{"text": "This paper presents new/s/leak 1 , the network of searchable leaks, a journalistic software for investigating and visualizing large textual datasets (see live demo here 2 ).", "labels": [], "entities": []}, {"text": "Investigation of unstructured document collections is a laborious task: The sheer amount of content can be vast, for instance, the WikiLeaks PlusD 3 dataset contains around 250 thousand cables.", "labels": [], "entities": [{"text": "WikiLeaks PlusD 3 dataset", "start_pos": 131, "end_pos": 156, "type": "DATASET", "confidence": 0.8380121141672134}]}, {"text": "Typically, these collections largely consist of unstructured text with additional metadata such as date, location or sender and receiver of messages.", "labels": [], "entities": []}, {"text": "The largest part of these documents are irrelevant for journalistic investigations, concealing the crucial storylines.", "labels": [], "entities": []}, {"text": "For instance, war crime stories in WikiLeaks were hid-1 http://newsleak.io 2 http://bev.lt.informatik.tu-darmstadt.de/ newsleak/ 3 https://wikileaks.org/plusd/about den and scattered among hundreds of thousands of routine conversations between officials.", "labels": [], "entities": []}, {"text": "Therefore, if journalists do not know in advance what to look for in the document collections, they can only vaguely target all people and organizations (named entities) of public interest.", "labels": [], "entities": []}, {"text": "Currently, the discovery of novel and relevant stories in large data leaks requires many people and a large time budget, both of which are typically not available to journalists: If the documents are confidential like datasets from an informer, only a few selected journalists will have access to the classified data, and those few will have to carry the whole workload.", "labels": [], "entities": []}, {"text": "On the other hand, if the documents are publicly available (e.g. a leak posted on the web), the texts have to be analyzed under enormous time pressure, because the journalistic value of each story decreases rapidly if other media publish it before.", "labels": [], "entities": []}, {"text": "There is a plethora of tools (see Section 2) for data journalist that automatically reveal and visualize interesting correlations hidden within large number-centric datasets ().", "labels": [], "entities": [{"text": "data journalist", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.781839907169342}]}, {"text": "However, these tools provide very limited automatic support with visual guidance through plain text collections.", "labels": [], "entities": []}, {"text": "Some tools include shallow natural language processing, but mostly restricted to English.", "labels": [], "entities": []}, {"text": "There is no tool that works for multiple languages, handles a large number of text collections, analyzes and visualizes named entities along with the relations between them and allows editing what is considered as an entity.", "labels": [], "entities": []}, {"text": "Moreover, available software is usually not open source but rather expensive and often requires substantial training, which is unsuitable fora journalist under time pressure and no prior experience with such software.", "labels": [], "entities": []}, {"text": "The goal of new/s/leak is to provide journalists with a novel visual interactive data analysis support that combines the latest advances from natural language processing approaches and information visualization.", "labels": [], "entities": []}, {"text": "It enables journalists to swiftly process large collections of text documents in order to find interesting pieces of information.", "labels": [], "entities": []}, {"text": "This paper presents the core concepts and architecture behind the new/s/leak.", "labels": [], "entities": []}, {"text": "We also show an in-depth analysis of user requirements and how we implement and address these.", "labels": [], "entities": []}, {"text": "Finally, we discuss our prototype, which will be made available in open source 4 under a lenient license.", "labels": [], "entities": []}, {"text": "states that investigative journalist should look at the facts, identify what is wrong with the situation, uncover the truth, and write a story that places the facts in context.", "labels": [], "entities": []}, {"text": "This work explains traditional story discovery engine components which, on the technical side, consist of a knowledge base, an inference engine and an easy to use user interface for visualization.", "labels": [], "entities": [{"text": "story discovery engine", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.817384680112203}]}], "datasetContent": [{"text": "We demonstrate capabilities of our system on two well-known cases: 1) The well-investigated WikiLeaks PlusD \"Cablegate\" collection, a collection of diplomatic notes from over 45 years originating from US embassies allover the world.", "labels": [], "entities": [{"text": "WikiLeaks PlusD \"Cablegate\" collection", "start_pos": 92, "end_pos": 130, "type": "DATASET", "confidence": 0.8369360963503519}]}, {"text": "2) The Enron email dataset () is a collection of email messages which is available publicly from the Enron Corporation.", "labels": [], "entities": [{"text": "Enron email dataset", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.8465858300526937}]}, {"text": "The dataset comprises over 600,000 messages between 158 employees.", "labels": [], "entities": []}, {"text": "This example shows the tools' general applicability to email leaks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on WikiLeaks PlusD and Enron", "labels": [], "entities": [{"text": "WikiLeaks PlusD", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.8003444671630859}, {"text": "Enron", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.6166195273399353}]}]}