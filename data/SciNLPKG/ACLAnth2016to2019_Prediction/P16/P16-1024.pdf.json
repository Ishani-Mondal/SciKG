{"title": [{"text": "On the Role of Seed Lexicons in Learning Bilingual Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "A shared bilingual word embedding space (SBWES) is an indispensable resource in a variety of cross-language NLP and IR tasks.", "labels": [], "entities": []}, {"text": "A common approach to the SB-WES induction is to learn a mapping function between monolingual semantic spaces, where the mapping critically relies on a seed word lexicon used in the learning process.", "labels": [], "entities": [{"text": "SB-WES induction", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.9621188044548035}]}, {"text": "In this work, we analyze the importance and properties of seed lexicons for the SBWES induction across different dimensions (i.e., lexicon source, lexicon size, translation method, translation pair reliability).", "labels": [], "entities": [{"text": "SBWES induction", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.9018375873565674}]}, {"text": "On the basis of our analysis, we propose a simple but effective hybrid bilingual word embedding (BWE) model.", "labels": [], "entities": []}, {"text": "This model (HYBWE) learns the mapping between two monolingual embedding spaces using only highly reliable symmetric translation pairs from a seed document-level embedding space.", "labels": [], "entities": []}, {"text": "We perform bilingual lexicon learning (BLL) with 3 language pairs and show that by carefully selecting reliable translation pairs our new HYBWE model outperforms benchmarking BWE learning models, all of which use more expensive bilingual signals.", "labels": [], "entities": [{"text": "bilingual lexicon learning (BLL)", "start_pos": 11, "end_pos": 43, "type": "TASK", "confidence": 0.7734872102737427}]}, {"text": "Effectively, we demonstrate that a SBWES maybe induced by leveraging only a very weak bilingual signal (document alignments) along with monolingual data.", "labels": [], "entities": [{"text": "SBWES", "start_pos": 35, "end_pos": 40, "type": "TASK", "confidence": 0.9697120785713196}]}], "introductionContent": [{"text": "Dense real-valued vector representations of words or word embeddings (WEs) have recently gained increasing popularity in natural language processing (NLP), serving as invaluable features in abroad range of NLP tasks, e.g.,.", "labels": [], "entities": [{"text": "Dense real-valued vector representations of words or word embeddings (WEs)", "start_pos": 0, "end_pos": 74, "type": "TASK", "confidence": 0.6405757268269857}, {"text": "natural language processing (NLP)", "start_pos": 121, "end_pos": 154, "type": "TASK", "confidence": 0.7573630412419637}]}, {"text": "Several studies have showcased a direct link and comparable performance to \"more traditional\" distributional models).", "labels": [], "entities": []}, {"text": "Yet the widely used skip-gram model with negative sampling (SGNS) () is considered as the state-of-the-art word representation model, due to its simplicity, fast training, as well as its solid and robust performance across a wide variety of semantic tasks (.", "labels": [], "entities": [{"text": "word representation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7201983332633972}]}, {"text": "Research interest has recently extended to bilingual word embeddings.", "labels": [], "entities": []}, {"text": "BWE learning models focus on the induction of a shared bilingual word embedding space (SBWES) where words from both languages are represented in a uniform language-independent manner such that similar words (regardless of the actual language) have similar representations (see).", "labels": [], "entities": []}, {"text": "A variety of BWE learning models have been proposed, differing in the essential requirement of a bilingual signal necessary to construct such a SBWES (discussed later in Sect. 2).", "labels": [], "entities": []}, {"text": "SBWES maybe used to support many tasks, e.g., computing cross-lingual/multilingual semantic word similarity, learning bilingual word lexicons (, cross-lingual entity linking), parsing (, machine translation (, or crosslingual information retrieval.", "labels": [], "entities": [{"text": "computing cross-lingual/multilingual semantic word similarity", "start_pos": 46, "end_pos": 107, "type": "TASK", "confidence": 0.6257025684629168}, {"text": "cross-lingual entity linking)", "start_pos": 145, "end_pos": 174, "type": "TASK", "confidence": 0.7045761346817017}, {"text": "parsing", "start_pos": 176, "end_pos": 183, "type": "TASK", "confidence": 0.9636881947517395}, {"text": "machine translation", "start_pos": 187, "end_pos": 206, "type": "TASK", "confidence": 0.8036347925662994}, {"text": "crosslingual information retrieval", "start_pos": 213, "end_pos": 247, "type": "TASK", "confidence": 0.6271545390288035}]}, {"text": "BWE models should have two desirable properties: (P1) leverage (large) monolingual training sets tied together through a bilingual signal, (P2) use as inexpensive bilingual signal as possible in order to learn a SBWES in a scalable and widely applicable manner across languages and domains.", "labels": [], "entities": []}, {"text": "While we provide a classification of related work, that is, different BWE models according to these properties in Sect.", "labels": [], "entities": []}, {"text": "2.1, the focus of this work is on a popular class of models labeled Post-Hoc Mapping with Seed Lexicons.", "labels": [], "entities": [{"text": "Post-Hoc Mapping", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.6097459495067596}]}, {"text": "These models operate as follows (: (1) two separate non-aligned monolingual embedding spaces are induced using any monolingual WE learning model (SGNS is the typical choice), given a seed lexicon of word translation pairs as the bilingual signal for training, a mapping function is learned which ties the two monolingual spaces together into a SBWES.", "labels": [], "entities": []}, {"text": "All existing work on this class of models assumes that high-quality training seed lexicons are readily available.", "labels": [], "entities": []}, {"text": "In reality, little is understood regarding what constitutes a high quality seed lexicon, even with \"traditional\" distributional models (.", "labels": [], "entities": []}, {"text": "Therefore, in this work we ask whether BWE learning could be improved by making more intelligent choices when deciding over seed lexicon entries.", "labels": [], "entities": [{"text": "BWE learning", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.6796260178089142}]}, {"text": "In order to do this we delve deeper into the cross-lingual mapping problem by analyzing a spectrum of seed lexicons with respect to controllable parameters such as lexicon source, its size, translation method, and translation pair reliability.", "labels": [], "entities": [{"text": "cross-lingual mapping", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.7427471280097961}]}, {"text": "The contributions of this paper are as follows: (C1) We present a systematic study on the importance of seed lexicons for learning mapping functions between monolingual WE spaces.", "labels": [], "entities": []}, {"text": "(C2) Given the insights gained, we propose a simple yet effective hybrid BWE model HYBWE that removes the need for readily available seed lexicons, and satisfies properties P1 and P2.", "labels": [], "entities": []}, {"text": "HYBWE relies on an inexpensive seed lexicon of highly reliable word translation pairs obtained by a documentlevel BWE model ) from document-aligned comparable data.", "labels": [], "entities": [{"text": "HYBWE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9304934740066528}]}, {"text": "(C3) Using a careful pair selection process when constructing a seed lexicon, we show that in the BLL task HYBWE outperforms a BWE model of which relies on readily available seed lexicons.", "labels": [], "entities": []}, {"text": "HYBWE also outperforms state-of-the-art models of () which require sentencealigned parallel data.", "labels": [], "entities": [{"text": "HYBWE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8630703687667847}]}], "datasetContent": [{"text": "Task: Bilingual Lexicon Learning (BLL) After the final SBWES is induced, given a list of n source language words x u1 , . .", "labels": [], "entities": []}, {"text": ", x un , the task is to find a target language word t for each x u in the list using the SBWES.", "labels": [], "entities": [{"text": "SBWES", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.8792078495025635}]}, {"text": "t is the target language word closest to the source language word x u in the induced SBWES, also known as the cross-lingual nearest neighbor.", "labels": [], "entities": []}, {"text": "Baseline Models To induce SBWES-1, we resort to document-level embeddings of Vuli\u00b4cVuli\u00b4c and Moens (2016) (Type 3).", "labels": [], "entities": [{"text": "SBWES-1", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9142307043075562}]}, {"text": "We also compare to results obtained directly by their model (BWESG) to measure the performance gains with HYBWE.", "labels": [], "entities": [{"text": "BWESG", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.908745527267456}, {"text": "HYBWE", "start_pos": 106, "end_pos": 111, "type": "DATASET", "confidence": 0.9200806617736816}]}, {"text": "To compare with a representative Type 2 model, we opt for the BilBOWA model of due to its solid performance and robustness in the BLL task when trained on general-domain corpora such as Wikipedia (, its reduced complexity reflected in fast computations on massive datasets, as well as its public availabilliterature (), but we do not observe any significant gains when resorting to the more complex reliability estimates.", "labels": [], "entities": [{"text": "BilBOWA", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9691529273986816}]}, {"text": "http://people.cs.kuleuven.be/~ivan.vulic/ 5 Similar trends are observed within a more lenient setting with Acc5 and Acc10 scores, but we omit these results for clarity and the fact that the actual BLL performance is best reflected in Acc1 scores (i.e., best translation only). ity.", "labels": [], "entities": [{"text": "Acc5", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9241907000541687}, {"text": "Acc10", "start_pos": 116, "end_pos": 121, "type": "METRIC", "confidence": 0.8160088062286377}, {"text": "clarity", "start_pos": 160, "end_pos": 167, "type": "METRIC", "confidence": 0.9602460861206055}, {"text": "BLL", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.924712061882019}, {"text": "Acc1", "start_pos": 234, "end_pos": 238, "type": "METRIC", "confidence": 0.8791645169258118}]}, {"text": "6 In short, BilBOWA combines the adapted SGNS for monolingual objectives together with a cross-lingual objective that minimizes the L 2 -loss between the bag-of-word vectors of parallel sentences.", "labels": [], "entities": [{"text": "BilBOWA", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9601187109947205}, {"text": "L 2 -loss", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9250870198011398}]}, {"text": "BilBOWA uses the same training setup as HYBWE (monolingual datasets plus a bilingual signal), but relies on a stronger bilingual signal (sentence alignments as opposed to HYBWE's document alignments).", "labels": [], "entities": [{"text": "BilBOWA", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.5654619932174683}, {"text": "HYBWE", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.9344452023506165}]}, {"text": "We also compare with a benchmarking Type 1 model from sentence-aligned parallel data called BiCVM ().", "labels": [], "entities": []}, {"text": "Finally, a SGNS-based BWE model with the BNC+GT seed lexicon is taken as a baseline Type 4 model ().", "labels": [], "entities": [{"text": "BNC+GT seed lexicon", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.6672089397907257}]}, {"text": "Training Data and Setup We use standard training data and suggested settings to obtain BWEs for all models involved in comparison.", "labels": [], "entities": [{"text": "Training Data", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.7663723826408386}, {"text": "BWEs", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9605574607849121}]}, {"text": "We retain the 100K most frequent words in each language for all models.", "labels": [], "entities": []}, {"text": "To induce monolingual WE spaces, two monolingual SGNS models were trained on the cleaned and tokenized Wikipedias from the Polyglot website (Al-Rfou et al., 2013) using SGD with a global learning rate of 0.025.", "labels": [], "entities": [{"text": "WE spaces", "start_pos": 22, "end_pos": 31, "type": "TASK", "confidence": 0.8990015983581543}, {"text": "Polyglot website", "start_pos": 123, "end_pos": 139, "type": "DATASET", "confidence": 0.9636206328868866}]}, {"text": "For BilBOWA, as in the original work (), the bilingual signal for the cross-lingual regularization is provided by the first 500K sentences from Europarl.v7.", "labels": [], "entities": [{"text": "BilBOWA", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.7234859466552734}, {"text": "Europarl.v7", "start_pos": 144, "end_pos": 155, "type": "DATASET", "confidence": 0.8979673385620117}]}, {"text": "We use SGD with a global rate of 0.15.", "labels": [], "entities": []}, {"text": "The window size is varied from 2 to 16 in steps of 2, and the best scoring model is always reported in all comparisons.", "labels": [], "entities": []}, {"text": "BWESG was trained on the cleaned and tokenized document-aligned Wikipedias available online 9 , SGD on pseudo-bilingual documents with a global rate 0.025.", "labels": [], "entities": [{"text": "BWESG", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7904954552650452}]}, {"text": "For BiCVM, we use the tool released by its authors 10 and train on the whole Europarl.v7 for each language pair: we train an additive model, with hinge loss margin set to d (i.e., dimensionality) as in the original paper, batch size of 50, and noise parameter of 10.", "labels": [], "entities": [{"text": "Europarl.v7", "start_pos": 77, "end_pos": 88, "type": "DATASET", "confidence": 0.9918248057365417}, {"text": "hinge loss margin", "start_pos": 146, "end_pos": 163, "type": "METRIC", "confidence": 0.9172947605450948}]}, {"text": "All BiCVM models are trained with 200 iterations.", "labels": [], "entities": []}, {"text": "For all models, we obtain BWEs with d = 40, 64, 300, 500, but we report only results with 300-dimensional BWEs as similar trends were observed with other d-s.", "labels": [], "entities": [{"text": "BWEs", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9675940871238708}]}, {"text": "This first batch of quantitative results already shows that Type 4 models with inexpensive automatically induced lexicons (i.e., HYBWE) are on a par with or even better than Type 4 models relying on external resources or translation systems.", "labels": [], "entities": []}, {"text": "In addition, the best reported scores using the more constrained symmetric BNC/HFQ+HYB+SYM lexicon variants are higher than those for three baseline models (of Type 1, Type 2, and Type 3) that previously held highest scores on the BLL test sets . These improvements over the baseline models and BNC+GT are statistically significant (using McNemar's statistical significance test, p < 0.05).", "labels": [], "entities": [{"text": "BLL test sets", "start_pos": 231, "end_pos": 244, "type": "DATASET", "confidence": 0.9037256042162577}]}, {"text": "also suggests that a careful selection of reliable pairs can lead to peak performances even with a lower number of pairs, i.e., seethe results of BNC+HYB+SYM.", "labels": [], "entities": [{"text": "BNC+HYB+SYM", "start_pos": 146, "end_pos": 157, "type": "METRIC", "confidence": 0.7985403537750244}]}, {"text": "II: Lexicon Size BLL results for ES-EN and NL-EN obtained by varying the seed lexicon sizes are displayed in.", "labels": [], "entities": [{"text": "BLL", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.8707290291786194}]}, {"text": "Results for IT-EN closely follow the patterns observed with ES-EN.", "labels": [], "entities": []}, {"text": "BNC+HYB+SYM and HFQ+HYB+ASYM -the two models that do not blindly use all potential training pairs, but rely on sets of symmetric pairs (i.e., they include the simple measure of translation pair reliability) -display the best performance across all lexicon sizes.", "labels": [], "entities": []}, {"text": "The finding confirms the intuition that a more intelligent pair selection strategy is essential for Type 4 BWE models.", "labels": [], "entities": [{"text": "pair selection", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.6917095333337784}]}, {"text": "HFQ+HYB+SYM -a simple hybrid BWE model (HYBWE) combining a document-level Type 3 model with a Type 4 model and translation reliability detection -is the strongest BWE model overall (see also again).", "labels": [], "entities": [{"text": "HFQ", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8339471817016602}, {"text": "translation reliability detection", "start_pos": 111, "end_pos": 144, "type": "TASK", "confidence": 0.7991122404734293}]}, {"text": "HYBWE-based models which do not perform any pair selection (i.e., BNC/HFQ+HYB+ASYM) closely follow the behaviour of the GT-based model.", "labels": [], "entities": []}, {"text": "This demonstrates that an external lexicon or translation system maybe safely replaced by a document-level embedding model without any significant performance loss in the BLL task.", "labels": [], "entities": []}, {"text": "The ORTHO-based model falls short of its competitors.", "labels": [], "entities": [{"text": "ORTHO-based", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.6725001931190491}]}, {"text": "However, we observe that even this model with the learning setting relying on the cheapest bilingual signal may lead to reasonable BLL scores, especially for the more related NL-EN pair.", "labels": [], "entities": [{"text": "BLL", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.995100200176239}]}, {"text": "The two models with the symmetry constraint display a particularly strong performance with settings relying on scarce resources (i.e., only a small portion of training pairs is available).", "labels": [], "entities": []}, {"text": "For instance, HFQ+HYB+SYM scores 0.129 for ES-EN with only 200 training pairs (vs 0.002 with BNC+GT), and 0.529 with 500 pairs (vs 0.145 with BNC+GT).", "labels": [], "entities": [{"text": "HFQ+HYB+SYM", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.7199829936027526}]}, {"text": "On the other hand, adding more pairs does not lead to an improved BLL performance.", "labels": [], "entities": [{"text": "BLL", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9976092576980591}]}, {"text": "In fact, we observe a slow and steady decrease in performance with lexicons containing 10, 000 and more training pairs for all HYBWE variants.", "labels": [], "entities": [{"text": "HYBWE", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.8762872815132141}]}, {"text": "The phenomenon maybe attributed to the fact that highly frequent words receive more accurate representations in SBWES-1, and adding less frequent and, consequently, less accurate training pairs to the SBWES-2 learning process brings in additional noise.", "labels": [], "entities": []}, {"text": "In plain language, when it comes to seed lexicons Type 4 models prefer quality over quantity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Nearest EN neighbours of the Spanish word casamiento (marriage) with different seed lexicons.", "labels": [], "entities": []}, {"text": " Table 2: Acc 1 scores in a standard BLL setup  (for Type 4 models): all seed lexicons contain 5K  translation pairs, except for BNC+HYB+SYM (its  sizes provided in parentheses). * denotes a statisti- cally significant improvement over baselines and  BNC+GT using McNemar's statistical significance  test with the Bonferroni correction, p < 0.05.", "labels": [], "entities": [{"text": "Acc 1", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9812735021114349}]}, {"text": " Table 3: Acc 1 scores in the SWTC task. All seed  lexicons contain 6K translation pairs, except for  BNC+HYB+SYM (its sizes provided in parenthe- ses). * denotes a statistically significant improve- ment over baselines and BNC+GT using McNe- mar's statistical significance test with the Bonfer- roni correction, p < 0.05.", "labels": [], "entities": [{"text": "Acc 1", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9782839119434357}, {"text": "SWTC task", "start_pos": 30, "end_pos": 39, "type": "TASK", "confidence": 0.9093013107776642}]}]}