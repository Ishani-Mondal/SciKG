{"title": [], "abstractContent": [{"text": "Essay stance classification, the task of determining how much an essay's author agrees with a given proposition, is an important yet under-investigated subtask in understanding an argumentative essay's overall content.", "labels": [], "entities": [{"text": "Essay stance classification, the task of determining how much an essay's author agrees with a given proposition", "start_pos": 0, "end_pos": 111, "type": "Description", "confidence": 0.8139563265599703}]}, {"text": "We introduce anew corpus of argumentative student essays annotated with stance information and propose a computational model for automatically predicting essay stance.", "labels": [], "entities": [{"text": "predicting essay stance", "start_pos": 143, "end_pos": 166, "type": "TASK", "confidence": 0.7998515367507935}]}, {"text": "In an evaluation on 826 essays, our approach significantly outperforms four baselines, one of which relies on features previously developed specifically for stance classification in student essays, yielding relative error reductions of at least 11.3% and 5.3%, in micro and macro F-score, respectively.", "labels": [], "entities": [{"text": "stance classification in student essays", "start_pos": 157, "end_pos": 196, "type": "TASK", "confidence": 0.8818563222885132}, {"text": "F-score", "start_pos": 280, "end_pos": 287, "type": "METRIC", "confidence": 0.9471832513809204}]}], "introductionContent": [{"text": "State-of-the-art automated essay scoring engines such as E-rater () do not grade essay content, focusing instead on providing diagnostic trait feedback on categories such as grammar, usage, mechanics, style and organization.", "labels": [], "entities": []}, {"text": "Hence, persuasiveness and other content-dependent dimensions of argumentative essay quality are largely ignored in existing automated essay scoring research.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 134, "end_pos": 147, "type": "TASK", "confidence": 0.6880026757717133}]}, {"text": "While full-fledged content-based essay scoring is still beyond the reach of state-of-the-art essay scoring engines, recent work has enabled us to move one step closer to this ambitious goal by analyzing essay content, attempting to determine the argumentative structure of student essays and the persuasiveness of the arguments made in these essays.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.7071130573749542}]}, {"text": "Stance classification is an important first step in determining how persuasive an argumentative student essay is because persuasiveness depends on how well the author argues w.r.t. the stance she takes using the supporting evidence she provides.", "labels": [], "entities": [{"text": "Stance classification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9283977150917053}]}, {"text": "For instance, if her stance is Agree Somewhat, a persuasive argument would involve explaining what reservations she has about the given proposition.", "labels": [], "entities": []}, {"text": "As another example, an argumentative essay in which the author takes a neutral stance or the author presents evidence that does not support the stance she claims to take should receive a low persuasiveness score.", "labels": [], "entities": []}, {"text": "Given the important role played by stance classification in determining an essay's persuasiveness, our goal in this paper is to examine stance classification in argumentative student essays.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.8862024545669556}, {"text": "stance classification", "start_pos": 136, "end_pos": 157, "type": "TASK", "confidence": 0.8760747909545898}]}, {"text": "While there is a large body of work on stance classification 1 , stance classification in argumentative essays is largely under-investigated and is different from previous work in several respects.", "labels": [], "entities": [{"text": "stance classification 1", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.9379205306371053}, {"text": "stance classification", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.9520543813705444}]}, {"text": "First, in automated essay grading, the majority of the essays to be assessed are written by students who are learners of English.", "labels": [], "entities": []}, {"text": "Hence our stance classification task could be complicated by the authors' lack of fluency in English.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9521297812461853}]}, {"text": "Second, essays are longer and more formally written than the text typically used in previous stance classification research (e.g., debate posts).", "labels": [], "entities": [{"text": "stance classification", "start_pos": 93, "end_pos": 114, "type": "TASK", "confidence": 0.9301015436649323}]}, {"text": "In particular, a student essay writer typically expresses her stance on the essay's topic in a thesis sentence/clause, while a debate post's author may never even explicitly express her stance.", "labels": [], "entities": []}, {"text": "Although the explicit expression of stance in essays seems to make our task easier, Prompt Prompt Parts Most university degrees are theoretical and do not prepare students for the real world.", "labels": [], "entities": []}, {"text": "They are therefore of very little value.", "labels": [], "entities": []}, {"text": "1) Most university degrees are theoretical.", "labels": [], "entities": []}, {"text": "2) Most university degrees do not prepare students for the real world.", "labels": [], "entities": []}, {"text": "3) Most university degrees are of very little value.", "labels": [], "entities": []}, {"text": "The prison system is outdated.", "labels": [], "entities": []}, {"text": "No civilized society should punish its criminals: it should rehabilitate them.", "labels": [], "entities": []}, {"text": "1) The prison system is outdated.", "labels": [], "entities": []}, {"text": "2) No civilized society should punish its criminals.", "labels": [], "entities": []}, {"text": "3) Civilized societies should rehabilitate criminals.: Some examples of essay prompts and their associated parts.", "labels": [], "entities": []}, {"text": "identifying stancetaking text in the midst of nonstancetaking sentences in a potentially long essay, as we will see, is by no means a trivial task.", "labels": [], "entities": []}, {"text": "To our knowledge, the essay stance classification task has only been attempted by.", "labels": [], "entities": [{"text": "essay stance classification task", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8116260170936584}]}, {"text": "However, the version of the task we address is different from his.", "labels": [], "entities": []}, {"text": "First, Faulkner only performed two-class stance classification: while his corpus contains essays labeled with For (Agree), Against (Disagree), and Neither, he simplified the task by leaving out the arguably most difficult-to-identify stance, Neither.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7572642266750336}]}, {"text": "In contrast, we perform fine-grained stance classification, where we allow essay stance to take one of six values: Agree Strongly, Agree Somewhat, Neutral, Disagree Somewhat, Disagree Strongly, and Never Addressed, given the practical need to perform fine-grained stance classification in student essays, as discussed above.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7394756972789764}, {"text": "Agree", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.9439653754234314}, {"text": "Never", "start_pos": 198, "end_pos": 203, "type": "METRIC", "confidence": 0.9739845991134644}, {"text": "fine-grained stance classification in student essays", "start_pos": 251, "end_pos": 303, "type": "TASK", "confidence": 0.8284993668397268}]}, {"text": "Second, given that many essay prompts are composed of multiple simpler propositions (e.g., the prompt \"Most university degrees are theoretical and do not prepare students for the real world\" has two parts, \"Most university degrees are theoretical\" and \"Most university degrees do not prepare students for the real world.\"), we manually split such prompts into prompt parts and determine the stance of the author w.r.t. each part, whereas Faulkner assigned an overall stance to a given prompt regardless of whether it is composed of multiple propositions.", "labels": [], "entities": []}, {"text": "The distinction is important because an analysis of our annotations described in Section 2 shows that essay authors take different stances w.r.t. different prompt parts in 49% of essays, and in 39% of essays, authors even take stances with different polarities w.r.t. different prompt parts.", "labels": [], "entities": []}, {"text": "In sum, our contributions in this paper are twofold.", "labels": [], "entities": []}, {"text": "First, we propose a computational model for essay stance classification that outperforms four baselines, including our re-implementation of Faulkner's approach.", "labels": [], "entities": [{"text": "essay stance classification", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.8894328276316324}]}, {"text": "Second, in order to stimulate further research on this task, we make our annotations publicly available.", "labels": [], "entities": []}, {"text": "Since progress on this task is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource for the NLP community.", "labels": [], "entities": []}], "datasetContent": [{"text": "All our results are obtained via leave-one-prompt-out cross-validation experiments.", "labels": [], "entities": []}, {"text": "So, in each fold experiment, we partition the instances from our 11 prompts into a training set (10 prompts) and a test set (1 prompt).", "labels": [], "entities": []}, {"text": "We employ two metrics to evaluate our systems: (1) micro F-score, which treats each instance as having equal weight; and (2) macro F-score, which treats each class as having equal weight.", "labels": [], "entities": [{"text": "F-score", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.5698674321174622}]}, {"text": "To gain insights into how different systems perform on different classes, we additionally report per-class F-scores.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9076000452041626}]}, {"text": "We train the baselines and our approach using two learning algorithms, MAL-LET's) implementation of maximum entropy (MaxEnt) classification and our own implementation of the one nearest neighbor (1NN) algorithm using the cosine similarity metric.", "labels": [], "entities": []}, {"text": "Note that these two learners have their own strengths and weaknesses: in comparison to 1NN, MaxEnt is better at exploiting high-dimensional features but less robust to skewed class distributions.", "labels": [], "entities": []}, {"text": "For the baseline systems, we select the learner by performing cross validation on the training folds to maximize the average of micro and macro F-scores in each fold experiment.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.8815038800239563}]}, {"text": "When training our approach, we perform exhaustive feature selection to determine which sub- Since stance classification is a multiclass, single-label task, micro F-score, precision, recall, and accuracy are all equivalent.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.8659835159778595}, {"text": "F-score", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.7877309918403625}, {"text": "precision", "start_pos": 171, "end_pos": 180, "type": "METRIC", "confidence": 0.9995701909065247}, {"text": "recall", "start_pos": 182, "end_pos": 188, "type": "METRIC", "confidence": 0.9995155334472656}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9996187686920166}]}, {"text": "set of the four sets of features (i.e., n-gram, duplicated Faulkner, path-based, and knowledge-based features) should be used.", "labels": [], "entities": []}, {"text": "Specifically, we select the feature groups and learner jointly by performing cross validation on the training folds, choosing the combination yielding the highest average of micro and macro F-scores in each fold experiment.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.8449225425720215}]}, {"text": "To prevent any feature type from dominating the others, to each feature we apply a weight of one divided by the number of features having its type.", "labels": [], "entities": []}, {"text": "In case of a tie when applying 1NN, the tie is broken by selecting the class appearing higher in.", "labels": [], "entities": []}, {"text": "Since all the systems we examined fared poorly on identifying Somewhat classes, one may wonder how these systems would perform if we considered a simplified version of the task where we merged each Somewhat class with the corresponding Strongly class.", "labels": [], "entities": []}, {"text": "In particular, since Faulkner's approach was originally not designed to distinguish between Strongly and Somewhat classes, it may seem fairer to compare our approach against Duplicated Faulkner on the four-class essay stance classification task, where stance can take one of four values: Agree (created by merging Agree All significance tests are approximate randomization tests with p < 0.01.", "labels": [], "entities": [{"text": "four-class essay stance classification task", "start_pos": 201, "end_pos": 244, "type": "TASK", "confidence": 0.6956457674503327}, {"text": "Agree", "start_pos": 288, "end_pos": 293, "type": "METRIC", "confidence": 0.9890227317810059}]}, {"text": "Boldfaced results are significant w.r.t. micro F-score for the Always Agree Strongly baseline, and macro F-score w.r.t. the Duplicated Faulkner baseline.", "labels": [], "entities": [{"text": "F-score", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9400462508201599}, {"text": "F-score", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.8316181302070618}, {"text": "Duplicated Faulkner baseline", "start_pos": 124, "end_pos": 152, "type": "DATASET", "confidence": 0.7851333419481913}]}, {"text": "Strongly and Agree Somewhat), Disagree (created by merging Disagree Strongly and Disagree Somewhat), Neutral, and Never Addressed.", "labels": [], "entities": []}, {"text": "In the results for the different systems on this four-class stance classification task, shown in Table 4, we see that the same patterns we noticed in the six-class version of the task persist.", "labels": [], "entities": [{"text": "four-class stance classification task", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.7079653143882751}]}, {"text": "The approaches' relative order w.r.t. micro and macro Fscore remains the same, though they are adjusted upwards due to the problem's increased simplicity.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.7852522730827332}]}, {"text": "Our approach's performance on Agree increases (compared to Agree Strongly) because Agree is a bigger class, making predictions of the class safer.", "labels": [], "entities": []}, {"text": "Our approach's performance decreases on Disagree (compared to Disagree Strongly) since it is not good at predicting Disagree Somewhat instances which are part of the class.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Cross-validation results for four-class essay stance classification for Agree (A), Neutral (Neu),  Disagree (D), and Never Addressed (Nev).", "labels": [], "entities": [{"text": "four-class essay stance classification", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.5865214169025421}, {"text": "Agree (A)", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9231221973896027}]}]}