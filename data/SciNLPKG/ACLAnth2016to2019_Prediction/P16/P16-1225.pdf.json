{"title": [{"text": "Finding Non-Arbitrary Form-Meaning Systematicity Using String-Metric Learning for Kernel Regression", "labels": [], "entities": [{"text": "Kernel Regression", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7685048878192902}]}], "abstractContent": [{"text": "Arbitrariness of the sign-the notion that the forms of words are unrelated to their meanings-is an underlying assumption of many linguistic theories.", "labels": [], "entities": []}, {"text": "Two lines of research have recently challenged this assumption , but they produce differing characterizations of non-arbitrariness in language.", "labels": [], "entities": []}, {"text": "Behavioral and corpus studies have confirmed the validity of localized form-meaning patterns manifested in limited subsets of the lexicon.", "labels": [], "entities": []}, {"text": "Meanwhile, global (lexicon-wide) statistical analyses instead find diffuse form-meaning system-aticity across the lexicon as a whole.", "labels": [], "entities": []}, {"text": "We bridge the gap with an approach that can detect both local and global form-meaning systematicity in language.", "labels": [], "entities": []}, {"text": "In the kernel regression formulation we introduce , form-meaning relationships can be used to predict words' distributional semantic vectors from their forms.", "labels": [], "entities": []}, {"text": "Furthermore , we introduce a novel metric learning algorithm that can learn weighted edit distances that minimize kernel regression error.", "labels": [], "entities": []}, {"text": "Our results suggest that the English lexicon exhibits far more global form-meaning systematicity than previously discovered, and that much of this systematicity is focused in localized form-meaning patterns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Arbitrariness of the sign refers to the notion that the phonetic/orthographic forms of words have no relationship to their meanings (.", "labels": [], "entities": [{"text": "Arbitrariness", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9688100814819336}]}, {"text": "It is a foundational assumption of many theories of language comprehension, production, acquisition, and evolution.", "labels": [], "entities": []}, {"text": "For instance, influential enumeration of the design features of human language ascribes a central role to arbitrariness in enabling the combination and recombination of phonemic units to create new words.", "labels": [], "entities": []}, {"text": "uses simulations to show that for large vocabularies, arbitrary form-meaning mappings may provide an advantage in acquisition.", "labels": [], "entities": []}, {"text": "Meanwhile, modular theories of language comprehension rely upon the duality of patterning to support the independence of the phonetic and semantic aspects of language comprehension ().", "labels": [], "entities": []}, {"text": "Quantifying the extent to which the arbitrariness principle actually holds is important for understanding how language works.", "labels": [], "entities": []}, {"text": "Language researchers have long noted exceptions to arbitrariness.", "labels": [], "entities": []}, {"text": "Most of these are patterns that occur in some relatively localized subset of the lexicon.", "labels": [], "entities": []}, {"text": "These patterns are sub-morphemic because, unlike conventional morphemes, they cannot combine reliably to produce new words. are one example.", "labels": [], "entities": []}, {"text": "A phonaestheme is a phonetic cluster that recurs in many words that have related meanings.", "labels": [], "entities": []}, {"text": "One notable phonaestheme is the onset gl-, which occurs at the beginning of at least 38 English words relating to vision: glow, glint, glaze, gleam, etc..", "labels": [], "entities": [{"text": "onset gl-", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.8396421273549398}]}, {"text": "At least 46 candidate phonaesthemes have been posited in the linguistics literature, according to a list compiled by.", "labels": [], "entities": []}, {"text": "Iconicity is another violation of arbitrariness that can lead to non-arbitrary local regularities.", "labels": [], "entities": []}, {"text": "Iconicity occurs when the form of a word is transparently motivated by some perceptual aspect of its referent.", "labels": [], "entities": []}, {"text": "Consequently, when several referents share perceptual features, their associated word-forms would tend to be similar as well (to the extent that they are iconic).", "labels": [], "entities": []}, {"text": "For instance, conjectures that vowels with high acoustic frequency tend to associate with smaller items while vowels with low acoustic frequency tend to associate with larger items, due to the experiential link between vocalizer size and frequency.", "labels": [], "entities": []}, {"text": "Systematic iconicity is also manifested in sets of onomatopoeic words that echo similar sounds (e.g., clink, clank).", "labels": [], "entities": [{"text": "Systematic iconicity", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7908297777175903}]}, {"text": "Although these exceptions to non-arbitrariness differ, in each case, specific form-meaning relationships emerge in a subset of the lexicon.", "labels": [], "entities": []}, {"text": "We will refer to all such specific localized form-meaning patterns as phonosemantic sets.", "labels": [], "entities": []}, {"text": "In recent decades, behavioral and corpus studies have empirically confirmed the psychological reality and statistical reliability of many phonosemantic sets that had previously been identified by intuition and observation.", "labels": [], "entities": []}, {"text": "Various candidate phonaesthemes have significant effects on reaction times during language processing tasks.", "labels": [], "entities": []}, {"text": "test the statistical significance of the 46 candidates in list, and find that 27 of them exhibit more within-category distributional semantic coherence than expected by chance.", "labels": [], "entities": []}, {"text": "These results have been replicated using other corpora and distributional semantic models (.", "labels": [], "entities": []}, {"text": "shows that sound-symbolic attributes such as those proposed by are associated with human judgments about nonwords' semantic attributes, such as smallness or beauty.", "labels": [], "entities": []}, {"text": "Using a statistical corpus analysis and WordNet semantic features, Monaghan et al.", "labels": [], "entities": []}, {"text": "(2014a) examine a similar hypothesis space of sound-symbolic phonological and semantic attributes, and reach similar conclusions.", "labels": [], "entities": []}, {"text": "While these localized studies support the existence of some islands of non-arbitrariness in language, their results do not address how pervasive non-arbitrariness is at the global level-that is, in the lexicon of a language as a whole.", "labels": [], "entities": []}, {"text": "After all, some seemingly non-arbitrary local patterns can be expected to emerge merely by chance.", "labels": [], "entities": []}, {"text": "How can we measure whether local phonosemantic patterning translates into global phonosemantic systematicity-that is, strong, non-negligible lexiconwide non-arbitrariness?", "labels": [], "entities": []}, {"text": "introduce the idea of measuring phonosemantic systematicity by analyzing the correlation between phonological edit distances and distributional semantic distances.", "labels": [], "entities": []}, {"text": "Ina lexicon of monomorphemic and monosyllabic English words, they find a small but statistically significant correlation between these two distance measures.", "labels": [], "entities": []}, {"text": "elaborate on this methodology, showing that the statistical effect is robust to different choices of form-distance and semantic-distance metrics.", "labels": [], "entities": []}, {"text": "They also look at the effect of leaving out each word in the lexicon on the overall correlation measure; from this, they derive a phonosemantic systematicity measure for each word.", "labels": [], "entities": []}, {"text": "Interestingly, they find that systematicity is diffusely distributed across the words in English in a pattern indistinguishable from random chance.", "labels": [], "entities": []}, {"text": "Hence, they conclude that \"systematicity in the vocabulary is not a consequence of small clusters of sound symbolism.\"", "labels": [], "entities": []}, {"text": "This line of work provides a proof-of-concept that it is possible to detect the phonosemantic systematicity of a language, and confirms that English exhibits significant phonosemantic systematicity.", "labels": [], "entities": []}, {"text": "Broadly speaking, both the localized tests of individual phonosemantic sets and the global analyses of phonosemantic systematicity challenge the arbitrariness of the sign.", "labels": [], "entities": []}, {"text": "However, they attribute responsibility for non-arbitrariness differently.", "labels": [], "entities": []}, {"text": "The local methods reveal dozens of specific phonosemantic sets that have strong, measurable behavioral effects and statistical signatures in corpora.", "labels": [], "entities": []}, {"text": "Meanwhile, the global methods find small and diffuse systematicity.", "labels": [], "entities": []}, {"text": "How can we reconcile this discrepancy?", "labels": [], "entities": []}, {"text": "We attempt to bridge the gap with anew approach that builds off of previous lexicon-wide analyses, making two innovations.", "labels": [], "entities": []}, {"text": "The first addresses the concern that the lexicon-wide methods currently in use may not be well suited to finding local regularities such as phonosemantic sets, because they make the assumption that systematicity exists only in the form of a global correlation between distances in formspace and distances in meaning-space.", "labels": [], "entities": []}, {"text": "Instead, we model the problem using kernel regression, a nonparametric regression model.", "labels": [], "entities": []}, {"text": "Crucially, in kernel regression the prediction fora point is based on the predictions of neighboring points; this enables us to conduct a global analysis while still capturing local, neighborhood effects.", "labels": [], "entities": []}, {"text": "As in previous work, we represent word-forms by their orthographic strings, and word-meanings by their semantic vector representations as produced by a distributional semantic vector space model.", "labels": [], "entities": []}, {"text": "The goal of the regression is then to learn a mapping from string-valued predictor variables to vectorvalued target variables that minimizes regression error in the vector space.", "labels": [], "entities": []}, {"text": "Conveniently, our model allows us to produce predictions of the semantic vectors associated with both words and nonwords.", "labels": [], "entities": []}, {"text": "Previous work may also underestimate systematicity in that it weights all edits (substitutions, insertions, and deletions) equally in determining edit distance.", "labels": [], "entities": []}, {"text": "A priori, there is no reason to believe this is the case-indeed, the work on individual phonosemantic sets suggests that some orthographic/phonetic attributes are more important than others for non-arbitrariness.", "labels": [], "entities": []}, {"text": "To address this, we introduce String-Metric Learning for Kernel Regression (SMLKR), a metric-learning algorithm that is able to learn a weighted edit distance metric that minimizes the prediction error in kernel regression.", "labels": [], "entities": []}, {"text": "We find that SMLKR enables us to recover more systematicity from a lexicon of monomorphemic English words than reported in previous global analyses.", "labels": [], "entities": [{"text": "SMLKR", "start_pos": 13, "end_pos": 18, "type": "TASK", "confidence": 0.9433383345603943}]}, {"text": "Using SMLKR, we propose anew measure of per-word phonosemantic systematicity.", "labels": [], "entities": []}, {"text": "Our analyses using this systematicity measure indicate that specific phonosemantic sets do contribute significantly to the global phonosemantic systematicity of English, in keeping with previous local-level analyses.", "labels": [], "entities": []}, {"text": "Finally, we evaluate our systematicity measure against human judgments, and find that it accords with raters' intuitions about what makes a word's form well suited to its meaning.", "labels": [], "entities": []}], "datasetContent": [{"text": "We empirically tested whether the systematicity measure based on SMLKR regression error accords with na\u00a8\u0131vena\u00a8\u0131ve human judgments about how well-suited a word's form is to its meaning (its \"phonosemantic feeling\")).", "labels": [], "entities": [{"text": "systematicity", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.9254851937294006}, {"text": "SMLKR", "start_pos": 65, "end_pos": 70, "type": "TASK", "confidence": 0.7667880654335022}]}, {"text": "We recruited 60 native English-speaking participants through Mechanical Turk, and asked them to judge the phonosemantic feeling of the 60 words in on a sliding scale from 1 to 5.", "labels": [], "entities": [{"text": "Mechanical Turk", "start_pos": 61, "end_pos": 76, "type": "DATASET", "confidence": 0.8479471206665039}]}, {"text": "We used Cronbach's \u03b1 to measure inter-annotator reliability at \u03b1 = 0.96, indicating a high degree of interannotator reliability).", "labels": [], "entities": []}, {"text": "The results showed that the words in the SMLKR list were rated higher for phonosemantic feeling than the words in the Correlation and Random lists.", "labels": [], "entities": [{"text": "SMLKR list", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.7789679765701294}]}, {"text": "We fit a parametric linear mixedeffects model to the phonosemantic feeling judgments (, as implemented in the lme4 library for R.", "labels": [], "entities": []}, {"text": "As fixed effects, we entered the list identity (SMLKR, Correlation, Random), the word length, and the log frequency of the word in our corpus.", "labels": [], "entities": [{"text": "SMLKR", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.757086992263794}]}, {"text": "Our random effects structure included a random intercept for word, and random subject slopes for all fixed effects, with all correlations allowed (a \"maximal\" randomeffects structure ().", "labels": [], "entities": []}, {"text": "Including list identity in the maximal mixed-effects model significantly improved model fit (\u03c7 2 11 = 126.08, p < 10 \u22126 ).", "labels": [], "entities": []}, {"text": "Post-hoc analysis revealed that the SMLKR list elicited average suitability judgments that were 0.49 points higher than the Random list (p < 10 \u22126 ) and 0.59 points higher than the Correlation list (p < 10 \u22126 ).", "labels": [], "entities": [{"text": "SMLKR", "start_pos": 36, "end_pos": 41, "type": "TASK", "confidence": 0.8801394104957581}]}, {"text": "Post-hoc analysis did not find a significant difference in suitability judgments between the Random and Correlation lists (p > .16).", "labels": [], "entities": []}], "tableCaptions": []}