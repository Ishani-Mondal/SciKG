{"title": [{"text": "Discovery of Treatments from Text Corpora", "labels": [], "entities": [{"text": "Discovery of Treatments from Text Corpora", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6438207676013311}]}], "abstractContent": [{"text": "An extensive literature in computational social science examines how features of messages, advertisements, and other corpora affect individuals' decisions, but these analyses must specify the relevant features of the text before the experiment.", "labels": [], "entities": []}, {"text": "Automated text analysis methods are able to discover features of text, but these methods cannot be used to obtain the estimates of causal effects-the quantity of interest for applied researchers.", "labels": [], "entities": []}, {"text": "We introduce anew experimental design and statistical model to simultaneously discover treatments in a corpora and estimate causal effects for these discovered treatments.", "labels": [], "entities": []}, {"text": "We prove the conditions to identify the treatment effects of texts and introduce the supervised Indian Buffet process to discover those treatments.", "labels": [], "entities": [{"text": "Indian Buffet process", "start_pos": 96, "end_pos": 117, "type": "DATASET", "confidence": 0.8994473814964294}]}, {"text": "Our method enables us to discover treatments in a training set using a collection of texts and individuals' responses to those texts, and then estimate the effects of these interventions in a test set of new texts and survey respondents.", "labels": [], "entities": []}, {"text": "We apply the model to an experiment about candidate biographies, recovering intuitive features of voters' decisions and revealing a penalty for lawyers and a bonus for military service.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computational social scientists are often interested in inferring how blocks of text, such as messages from political candidates or advertising content, affect individuals' decisions (.", "labels": [], "entities": []}, {"text": "To do so, they typically attempt to estimate the causal effect of the text: they model the outcome of interest, Y , as a function of the block of text presented to the respondent, t, and define the treatment effect oft relative to some other block of text t as Y (t) \u2212 Y (t ).", "labels": [], "entities": []}, {"text": "For example, in industrial contexts researchers design A/B tests to compare two potential texts fora use case.", "labels": [], "entities": [{"text": "A/B", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.7956202824910482}]}, {"text": "Academic researchers often design one text that has a feature of interest and another text that lacks that feature but is otherwise identical (for example,).", "labels": [], "entities": []}, {"text": "Both kinds of experiments assume researchers already know the features of text to vary and offer little help to researchers who would like to discover the features to vary.", "labels": [], "entities": []}, {"text": "Topic models and related methods can discover important features in corpora of text data, but they are constructed in away that makes it difficult to use the discovered features to estimate causal effects (.", "labels": [], "entities": []}, {"text": "Consider, for example, supervised latent Dirichlet allocation (sLDA).", "labels": [], "entities": [{"text": "supervised latent Dirichlet allocation", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.5604415908455849}]}, {"text": "It associates a topicprevalence vector, \u03b8, with each document where the estimated topics depend upon both the content of documents and a label associated with each document.", "labels": [], "entities": []}, {"text": "If K topics are included in the model, then \u03b8 is defined on the K \u2212 1-dimensional unit simplex.", "labels": [], "entities": []}, {"text": "It is straightforward to define a treatment effect as the difference between two treatments \u03b8 and \u03b8 (or points on the simplex) Y (\u03b8) \u2212 Y (\u03b8 ).", "labels": [], "entities": []}, {"text": "It is less clear how to define the marginal effect of anyone dimension.", "labels": [], "entities": []}, {"text": "This is because bigger values on some dimensions implies smaller values on other dimensions, making the effect of anyone topic necessarily a combination of the differences obtained when averaging across all the dimensions).", "labels": [], "entities": []}, {"text": "This problem will befall all topic models because the zero-sum nature of the topic-prevalence vector implies that increasing the prevalence of anyone topic necessarily decreases the prevalence of some other topic.", "labels": [], "entities": []}, {"text": "The result is that it is difficult (or impossible) to interpret the effect of anyone topic marginalizing over the other topics.", "labels": [], "entities": []}, {"text": "Other applications of topic models to estimate causal effects treat text as the response, rather than the treatment (.", "labels": [], "entities": []}, {"text": "And still other methods require a difficult to interpret assumption of how text might affect individuals' responses.", "labels": [], "entities": []}, {"text": "To facilitate the discovery of treatments and to address the limitation of existing unsupervised learning methods, we introduce anew experimental design, framework, and statistical model for discovering treatments within blocks of text and then reliably inferring the effects of those treatments.", "labels": [], "entities": []}, {"text": "By doing so, we combine the utility of discovering important features in a topic model with the scientific value of causal treatment effects estimated in a potential outcomes framework.", "labels": [], "entities": []}, {"text": "We present anew statistical model-the supervised Indian Buffet Process-to both discover treatments in a training set and infer the effects treatments in a test set ().", "labels": [], "entities": [{"text": "Indian Buffet Process-to", "start_pos": 49, "end_pos": 73, "type": "DATASET", "confidence": 0.8712996244430542}]}, {"text": "We prove that randomly assigning blocks of text to respondents in an experiment is sufficient to identify the effects of latent treatments that comprise blocks of text.", "labels": [], "entities": []}, {"text": "Our framework provides the first of its kind approach to automatically discover treatment effects in text, building on literatures in both social science and machine learning (.", "labels": [], "entities": []}, {"text": "The use of the training and test set ensures that this discovery does not come at the expense of credibly inferring causal effects, insulating the research design from concerns about \"p-hacking\" and overfitting).", "labels": [], "entities": []}, {"text": "Critically, we use a theoretical justification for our methodology: we select our particular approach because it enables us to estimate causal effect of interest.", "labels": [], "entities": []}, {"text": "Rather than demonstrating that our method performs better at some predictive task, we prove that our method is able to estimate useful causal effects from the data.", "labels": [], "entities": []}, {"text": "We apply our framework to study how features of apolitical candidate's background affect voters' decisions.", "labels": [], "entities": []}, {"text": "We use a collection of candidate biographies collected from Wikipedia to automatically discover treatments in the biographies and then infer their effects.", "labels": [], "entities": []}, {"text": "This reveals a penalty for lawyers and career politicians and a bonus for military service and advanced degrees.", "labels": [], "entities": []}, {"text": "While we describe our procedure throughout the paper, we summarize our experimental protocol and strategy for discovering treatment effects in.", "labels": [], "entities": []}], "datasetContent": [{"text": "We demonstrate our method in an experiment to assess how features of a candidate's background affect respondents evaluations of the candidates.", "labels": [], "entities": []}, {"text": "There is a rich literature in political science about the ideal attributes of political candidates).", "labels": [], "entities": []}, {"text": "We build on this literature and use a collection of candidate biographies to discover features of candidates' backgrounds that voters find appealing.", "labels": [], "entities": []}, {"text": "To uncover the features of candidate biographies that voters are responsive to we acquired a collection of 1,246 Congressional candidate biographies from Wikipedia.", "labels": [], "entities": []}, {"text": "We then anonymize the biographies-replacing names and removing other identifiable information-to ensure that the only information available to the respondent was explicitly present in the text.", "labels": [], "entities": []}, {"text": "In Section 2.1 we show that a necessary condition for this experiment to uncover latent treatments is that each vector of treatments has nonzero probability of occuring.", "labels": [], "entities": []}, {"text": "This is equivalent to assuming that none of the treatments are aliased, or perfectly correlated ().", "labels": [], "entities": []}, {"text": "Aliasing would be more likely if there are only a few distinct texts that are provided to participants in our experiment.", "labels": [], "entities": [{"text": "Aliasing", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9823144674301147}]}, {"text": "Therefore, we assign each respondent in each evaluation round a distinct candidate biography.", "labels": [], "entities": []}, {"text": "To bolster our statistical power, we ask our respondents to evaluate up to four distinct candidate biographies, resulting in each respondent evaluating 2.8 biographies on average.", "labels": [], "entities": []}, {"text": "After presenting the respondents with a candidate's biography, we ask each respondent to rate the candidate using a feeling thermometer: a well-established social science scale that goes from 0 when a respodent is \"cold\" to a candidate to 100 when a respondent is \"warm\" to the candidate.", "labels": [], "entities": []}, {"text": "We recruited a sample of 1,886 participants using Survey Sampling International (SSI), an online survey platform.", "labels": [], "entities": []}, {"text": "Our sample is census matched to reflect US demographics on sex, age, race, and education.", "labels": [], "entities": []}, {"text": "Using the sample we obtain 5,303 total observations.", "labels": [], "entities": []}, {"text": "We assign 2,651 responses to the training set and 2,652 to the test set.", "labels": [], "entities": []}, {"text": "We then apply the sIBP process to the training data.", "labels": [], "entities": []}, {"text": "To apply the model, we standardize the feeling thermometer to have mean zero and standard deviation 1.", "labels": [], "entities": []}, {"text": "We set K to a relatively low value (K = 10) reflecting a quantitative and qualitative search over K.", "labels": [], "entities": []}, {"text": "We then select the final model varying the parameters and evaluating the CE score.", "labels": [], "entities": [{"text": "CE score", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9828849136829376}]}, {"text": "provides the top words for each of the ten treatments the sIBP discovered in the training set.", "labels": [], "entities": []}, {"text": "We selected ten treatments using a combination of guidance from the sIBP, assessment using CE scores, and our own qualitative assessment of the models.", "labels": [], "entities": [{"text": "sIBP", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.9133150577545166}]}, {"text": "While it is true that our final selection depends on human input, some reliance on human judgment at this stage is appropriate.", "labels": [], "entities": []}, {"text": "If one set includes a treatment about military service but not legal training and another set includes a treatment about legal training but not military service, then model selection is tantamount to deciding which hypotheses are most worthy of investigation.", "labels": [], "entities": []}, {"text": "Our CE scores identify sets of treatments that are most likely to be interesting, but the human analyst should make the final decision about which hypotheses he would like to test.", "labels": [], "entities": [{"text": "CE", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.913321316242218}]}, {"text": "However, it is extremely important for the analyst to select a set of treatments first and only afterwards estimate the effects of those treatments.", "labels": [], "entities": []}, {"text": "If the analyst observes the effects of some treatments and then decides he would like to test other sets, then the integrity of any p-values he might calculate are undermined by the multiple testing problem.", "labels": [], "entities": []}, {"text": "A key feature of our procedure is that it draws a clear line between the selection of hypotheses to test (which leverages human judgment) and the estimation of effects (which is purely mechanical).", "labels": [], "entities": []}, {"text": "The estimated treatments cover salient features of Congressional biographies from the time period that we analyze.", "labels": [], "entities": []}, {"text": "For example, treatments 6 and 10 capture a candidate's military experience.", "labels": [], "entities": []}, {"text": "Treatment 5 and 7 are about previous political experience and Treatment 3 and 9 refer to a candidate's education experience.", "labels": [], "entities": []}, {"text": "Clearly, there are many features of a candidate's background missing, but the treatments discovered provide a useful set of dimensions to assess how voters respond to a candidate's background.", "labels": [], "entities": []}, {"text": "Further, the discovered treatments area combination of those that are both prevalent in the biographies and have an effect on the thermometer rating.", "labels": [], "entities": [{"text": "thermometer rating", "start_pos": 130, "end_pos": 148, "type": "METRIC", "confidence": 0.9758599102497101}]}, {"text": "The absence of biographical features that we might think matters for candidate evaluation could be because there are few of those biographies in our data set, or because the respondents were unresponive to those features.", "labels": [], "entities": []}, {"text": "After training the model on the training set, we apply it to the test set to infer the treatments in the biographies.", "labels": [], "entities": []}, {"text": "We assume there are no interactions   between the discovered treatments in order to estimate their effects.", "labels": [], "entities": []}, {"text": "6 shows the point estimate and 95-percent confidence intervals, which take into account uncertainty in inferring the treatments from the texts and the relationship between those treatments and the response.", "labels": [], "entities": [{"text": "point", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.9537990093231201}]}, {"text": "The treatment effects reveal intuitive, though interesting, features of candidate biographies that affect respondent's evaluations.", "labels": [], "entities": []}, {"text": "For example, Figure 2 reveals a distaste for political and legal experience-even though a large share of Congressional candidates have previous political ex-perience and a law degree.", "labels": [], "entities": []}, {"text": "Treatment 5, which describes a candidate's previous political experience, causes an 2.26 point reduction in feeling thermometer evaluation (95 percent confidence interval,).", "labels": [], "entities": [{"text": "feeling thermometer evaluation (95 percent confidence interval", "start_pos": 108, "end_pos": 170, "type": "METRIC", "confidence": 0.641275767236948}]}, {"text": "Likewise, Treatment 9 shows that respondents dislike lawyers, with the presence of legal experience causing a 2.34 point reduction in feeling thermometer (95-percent confidence interval,).", "labels": [], "entities": []}, {"text": "The aversion to lawyers is not, however, an aversion to education.", "labels": [], "entities": []}, {"text": "Treatment 3, a treatment that describes advanced degrees, causes a 2.43 point increase in feeling thermometer evaluations (95-percent confidence interval,).", "labels": [], "entities": [{"text": "feeling thermometer evaluations (95-percent confidence interval", "start_pos": 90, "end_pos": 153, "type": "METRIC", "confidence": 0.6681059386048999}]}, {"text": "In contrast, shows that there is a consistent bonus for military experience.", "labels": [], "entities": []}, {"text": "This is consistent with intuition from political observers that the public supports veterans.", "labels": [], "entities": []}, {"text": "For example, treatment 6, which describes a candidate's military record, causes a 3.21 point increase in feeling thermometer rating (95-percent confidence interval,) and treatment 10 causes a 4.00 point increase (95-percent confidence interval,).", "labels": [], "entities": [{"text": "feeling thermometer rating (95-percent confidence interval", "start_pos": 105, "end_pos": 163, "type": "METRIC", "confidence": 0.7586266824177333}]}, {"text": "Because simultaneously discovering treatments from labeled data and estimating their average marginal component effects is a novel task, we cannot compare the performance of our framework against any benchmark.", "labels": [], "entities": []}, {"text": "Even so, one natural question is whether the user could obtain much more coherent topics by foresaking the estimation of causal effects and using a more traditional topic modeling method.", "labels": [], "entities": []}, {"text": "We provide the topics discovered by sLDA in.", "labels": [], "entities": []}, {"text": "sIBP discovered most of the same features sLDA did.", "labels": [], "entities": []}, {"text": "Both find military service, legal training, political background, and higher education.", "labels": [], "entities": []}, {"text": "The Greek life feature is less coherent in sIBP than it is in sLDA, and sLDA finds business and ancestry features that sIBP does not.", "labels": [], "entities": []}, {"text": "Both have a few incoherent treatments.", "labels": [], "entities": []}, {"text": "This comparison suggests that sIBP does almost as well as sLDA at identifying coherent latent features, while also facilitating the estimation of marginal treatment effects.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Top Words for 10 Treatments sIBP Discovered", "labels": [], "entities": [{"text": "10 Treatments sIBP Discovered", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.5138233378529549}]}]}