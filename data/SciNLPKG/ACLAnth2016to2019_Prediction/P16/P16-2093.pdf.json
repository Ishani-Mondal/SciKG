{"title": [{"text": "Deep Neural Networks for Syntactic Parsing of Morphologically Rich Languages", "labels": [], "entities": [{"text": "Syntactic Parsing of Morphologically Rich Languages", "start_pos": 25, "end_pos": 76, "type": "TASK", "confidence": 0.8743419647216797}]}], "abstractContent": [{"text": "Morphologically rich languages (MRL) are languages in which much of the structural information is contained at the word-level, leading to high level word-form variation.", "labels": [], "entities": [{"text": "Morphologically rich languages (MRL)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6216092507044474}]}, {"text": "Historically, syntactic parsing has been mainly tackled using genera-tive models.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.9349623322486877}]}, {"text": "These models assume input features to be conditionally independent, making difficult to incorporate arbitrary features.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the greedy discriminative parser described in (Legrand and Collobert, 2015), which relies on word embeddings, in the context of MRL.", "labels": [], "entities": [{"text": "MRL", "start_pos": 158, "end_pos": 161, "type": "TASK", "confidence": 0.8198408484458923}]}, {"text": "We propose to learn morphological embeddings and propagate morphological information through the tree using a recur-sive composition procedure.", "labels": [], "entities": []}, {"text": "Experiments show that such embeddings can dramatically improve the average performance on different languages.", "labels": [], "entities": []}, {"text": "Moreover, it yields state-of-the art performance fora majority of languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphologically rich languages (MRL) are languages for which important information concerning the syntactic structure is expressed through word formation, rather than constituent-order patterns.", "labels": [], "entities": [{"text": "Morphologically rich languages (MRL)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6270092527071635}]}, {"text": "Unlike English, they can have complex word structure as well as flexible word order.", "labels": [], "entities": []}, {"text": "A common practice when dealing with such languages is to incorporate morphological information explicitly (.", "labels": [], "entities": []}, {"text": "However this poses two problems to the classical generative models: they assume input features to be conditionally independent which makes the incorpora- * All research was conducted at the Idiap Research Institute, before Ronan Collobert joined Facebook AI Research tion of arbitrary features difficult.", "labels": [], "entities": [{"text": "Idiap Research Institute", "start_pos": 190, "end_pos": 214, "type": "DATASET", "confidence": 0.9547484914461771}]}, {"text": "Moreover, refining input features leads to a data sparsity issue.", "labels": [], "entities": []}, {"text": "In the other hand, neural network-based models using continuous word representations as input have been able to overcome the data sparsity problem inherent in NLP (.", "labels": [], "entities": []}, {"text": "Furthermore, neural networks allow to incorporate arbitrary features and learn complex non-linear relations between them.", "labels": [], "entities": []}, {"text": "introduced a greedy syntactic parser, based on neural networks which relies on word embeddings.", "labels": [], "entities": []}, {"text": "This model maintains a history of the previous node predictions, in the form of vector representations, by leveraging a recursive composition procedure.", "labels": [], "entities": []}, {"text": "In this paper, we propose to enhance this model for syntactic parsing of MRL, by learning morphological embeddings.", "labels": [], "entities": [{"text": "syntactic parsing of MRL", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7927931845188141}]}, {"text": "We take advantage of a recursive composition procedure similar to the one used in ( to propagate morphological information during the parsing process.", "labels": [], "entities": [{"text": "parsing", "start_pos": 134, "end_pos": 141, "type": "TASK", "confidence": 0.9679105877876282}]}, {"text": "We evaluate our approach on the SPMRL (Syntactic Parsing of MRL) Shared Task 2014 () on nine different languages.", "labels": [], "entities": [{"text": "SPMRL (Syntactic Parsing of MRL) Shared Task 2014", "start_pos": 32, "end_pos": 81, "type": "TASK", "confidence": 0.7743139237165451}]}, {"text": "Each of them comes with a set of morphological features allowing to augment words with information such as their grammatical functions, relation with other words in the sentence, prefixes, affixes and lemmas.", "labels": [], "entities": []}, {"text": "We show that integrating morphological features allows to increase dramatically the average performance and yields state-of-theart performance fora majority of languages.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for all languages in terms of F1-score, using gold POS and morphological tags. Berke- ley+POS and Berkeley RAW are the two baseline system results provided by the organizers of the shared  task. Our experiments used an ensemble of 5 models, trained starting from different random initializa- tions.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9986091256141663}, {"text": "Berke- ley+POS", "start_pos": 97, "end_pos": 111, "type": "METRIC", "confidence": 0.6886179447174072}, {"text": "Berkeley RAW", "start_pos": 116, "end_pos": 128, "type": "DATASET", "confidence": 0.7805677950382233}]}, {"text": " Table 2: Influence of the additional morphological  embeddings in terms of F1-score", "labels": [], "entities": [{"text": "F1-score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9953746199607849}]}, {"text": " Table 3: Results for all languages in terms of F1-score using predicted POS and morphological tags.  Berkeley+POS and Berkeley RAW are the two baseline system results provided by the organizers of  the shared task. Our experiments used an ensemble of 5 models, trained starting from different random  initializations.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9984720349311829}, {"text": "Berkeley RAW", "start_pos": 119, "end_pos": 131, "type": "DATASET", "confidence": 0.7506056725978851}]}]}