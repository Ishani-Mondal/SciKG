{"title": [{"text": "An Open Web Platform for Rule-Based Speech-to-Sign Translation", "labels": [], "entities": [{"text": "Rule-Based Speech-to-Sign Translation", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.5984293719132742}]}], "abstractContent": [{"text": "We present an open web platform for developing , compiling, and running rule-based speech to sign language translation applications.", "labels": [], "entities": [{"text": "rule-based speech to sign language translation", "start_pos": 72, "end_pos": 118, "type": "TASK", "confidence": 0.5503583004077276}]}, {"text": "Speech recognition is performed using the Nuance Recognizer 10.2 toolkit, and signed output, including both manual and non-manual components, is rendered using the JASigning avatar system.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8052861988544464}]}, {"text": "The platform is designed to make the component technologies readily accessible to sign language experts who are not necessarily computer scientists.", "labels": [], "entities": []}, {"text": "Translation grammars are written in aversion of Synchronous Context-Free Grammar adapted to the peculiarities of sign language.", "labels": [], "entities": [{"text": "Translation grammars", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9246810078620911}]}, {"text": "All processing is carried out on a remote server, with content uploaded and accessed through a web interface.", "labels": [], "entities": []}, {"text": "Initial experiences show that simple translation grammars can be implemented on a timescale of a few hours to a few days and produce signed output readily com-prehensible to Deaf informants.", "labels": [], "entities": [{"text": "translation grammars", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.9413609504699707}]}, {"text": "Overall, the platform drastically lowers the barrier to entry for researchers interested in building applications that generate high-quality signed language.", "labels": [], "entities": []}], "introductionContent": [{"text": "While a considerable amount of linguistic research has been carried out on sign languages to date, work in automatic sign language processing is still in its infancy.", "labels": [], "entities": [{"text": "automatic sign language processing", "start_pos": 107, "end_pos": 141, "type": "TASK", "confidence": 0.6492350399494171}]}, {"text": "Automatic sign language processing comprises applications such assign language recognition, sign language synthesis, and sign language translation.", "labels": [], "entities": [{"text": "Automatic sign language processing", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6761194616556168}, {"text": "assign language recognition", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.7483508189519247}, {"text": "sign language synthesis", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.7864466309547424}, {"text": "sign language translation", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.8050740758577982}]}, {"text": "For all of these applications, drawing on the expertise of native signers, sign language linguists and sign language interpreters is crucial.", "labels": [], "entities": [{"text": "sign language interpreters", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.6133949160575867}]}, {"text": "These different types of sign language experts may exhibit varying degrees of computer literacy.", "labels": [], "entities": []}, {"text": "In the past, their contribution to the development of systems that automatically translate into sign language has been restricted mostly to the provision of transcribed and/or annotated sign language data.", "labels": [], "entities": []}, {"text": "In this paper, we report on the development and evaluation of a platform that allows sign language experts with modest computational skills to play a more active role in sign language machine translation.", "labels": [], "entities": [{"text": "sign language machine translation", "start_pos": 170, "end_pos": 203, "type": "TASK", "confidence": 0.64054174721241}]}, {"text": "The platform enables these users to independently develop and run applications translating speech into synthesized sign language through a web interface.", "labels": [], "entities": []}, {"text": "Synthesized sign language is presented by means of a signing avatar.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our platform is the first to facilitate low-threshold speech-to-sign translation, opening up various possible use cases, e.g. that of communicating with a Deaf customer in a public service setting like a hospital, train station or bank.", "labels": [], "entities": [{"text": "speech-to-sign translation", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.715444803237915}]}, {"text": "By pursuing a rule-based translation approach, the platform also offers new possibilities for empirical investigation of sign language linguistics: the linguist can concretely implement a fragment of a hypothesized sign language grammar, sign a range of generated utterances through the avatar, and obtain judgements from Deaf informants.", "labels": [], "entities": [{"text": "sign language linguistics", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.6780778169631958}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents background and related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the architecture of the speech-to-sign platform.", "labels": [], "entities": []}, {"text": "Section 4 reports on a preliminary evaluation of the usability of the platform and of translations produced by the platform.", "labels": [], "entities": []}, {"text": "Section 5 offers a conclusion and an outlook on future research questions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}