{"title": [{"text": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", "labels": [], "entities": [{"text": "CNN/Daily Mail Reading Comprehension", "start_pos": 30, "end_pos": 66, "type": "DATASET", "confidence": 0.8695405324300131}]}], "abstractContent": [{"text": "Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP.", "labels": [], "entities": []}, {"text": "A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data.", "labels": [], "entities": []}, {"text": "(2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task.", "labels": [], "entities": []}, {"text": "In this paper, we conduct a thorough examination of this new reading comprehension task.", "labels": [], "entities": []}, {"text": "Our primary aim is to understand what depth of language understanding is required to do well on this task.", "labels": [], "entities": []}, {"text": "We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 72.4% and 75.8% on these two datasets, exceeding current state-of-the-art results by over 5% and approaching what we believe is the ceiling for performance on this task.1", "labels": [], "entities": [{"text": "accuracies", "start_pos": 179, "end_pos": 189, "type": "METRIC", "confidence": 0.9927132725715637}]}], "introductionContent": [{"text": "Reading comprehension (RC) is the ability to read text, process it, and understand its meaning.2 How to endow computers with this capacity has been an elusive challenge and a long-standing goal of Artificial Intelligence (e.g.,).", "labels": [], "entities": [{"text": "Reading comprehension (RC)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6205300569534302}]}, {"text": "Genuine reading comprehension involves interpretation of 1Our code is available at https://github.com/danqi/ rc-cnn-dailymail.", "labels": [], "entities": []}, {"text": "2https://en.wikipedia.org/wiki/Reading_ comprehension the text and making complex inferences.", "labels": [], "entities": []}, {"text": "Human reading comprehension is often tested by asking questions that require interpretive understanding of a passage, and the same approach has been suggested for testing computers . In recent years, there have been several strands of work which attempt to collect human-labeled data for this task -in the form of document, question and answer triples -and to learn machine learning models directly from it (.", "labels": [], "entities": []}, {"text": "However, these datasets consist of only hundreds of documents, as the labeled examples usually require considerable expertise and neat design, making the annotation process quite expensive.", "labels": [], "entities": []}, {"text": "The subsequent scarcity of labeled examples prevents us from training powerful statistical models, such as deep learning models, and would seem to prevent a system from learning complex textual reasoning capacities.", "labels": [], "entities": []}, {"text": "Recently, researchers at DeepMind ( had the appealing, original idea of exploiting the fact that the abundant news articles of CNN and Daily Mail are accompanied by bullet point summaries in order to heuristically create large-scale supervised training data for the reading comprehension task.", "labels": [], "entities": []}, {"text": "Their idea is that a bullet point usually summarizes one or several aspects of the article.", "labels": [], "entities": []}, {"text": "If the computer understands the content of the article, it should be able to infer the missing entity in the bullet point.", "labels": [], "entities": []}, {"text": "This is a clever way of creating supervised data cheaply and holds promise for making progress on training RC models; however, it is unclear what level of reading comprehension is actually needed to solve this somewhat artificial task and, indeed, what statistical models that do reasonably well on this task have actually learned.", "labels": [], "entities": []}, {"text": "In this paper, our aim is to provide an in-depth and thoughtful analysis of this dataset and what level of natural language understanding is needed to ( @entity4 ) if you feel a ripple in the force today , it maybe the news that the official @entity6 is getting its first gay character . according to the sci-fi website @entity9 , the upcoming novel \" @entity11 \" will feature a capable but flawed @entity13 official named @entity14 who \" also happens to be a lesbian . \" the character is the first gay figure in the official @entity6 --the movies , television shows , comics and books approved by @entity6 franchise owner @entity22 --according to @entity24 , editor of \" @entity6 \" books at @entity28 imprint @entity26 . do well on it.", "labels": [], "entities": []}, {"text": "We demonstrate that simple, carefully designed systems can obtain high, state-of-the-art accuracies of 72.4% and 75.8% on CNN and Daily Mail respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.996401309967041}, {"text": "CNN", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.9560074806213379}, {"text": "Daily Mail", "start_pos": 130, "end_pos": 140, "type": "DATASET", "confidence": 0.9274438321590424}]}, {"text": "We do a careful hand-analysis of a small subset of the problems to provide data on their difficulty and what kinds of language understanding are needed to be successful and we try to diagnose what is learned by the systems that we have built.", "labels": [], "entities": []}, {"text": "We conclude that: (i) this dataset is easier than previously realized, (ii) straightforward, conventional NLP systems can do much better on it than previously suggested, (iii) the distributed representations of deep learning systems are very effective at recognizing paraphrases, (iv) partly because of the nature of the questions, current systems much more have the nature of single-sentence relation extraction systems than larger-discoursecontext text understanding systems, (v) the systems that we present here are close to the ceiling of performance for single-sentence and unambiguous cases of this dataset, and (vi) the prospects forgetting the final 20% of questions correct appear poor, since most of them involve issues in the data preparation which undermine the chances of answering the question (coreference errors or anonymization of entities making understanding too difficult).", "labels": [], "entities": [{"text": "single-sentence relation extraction", "start_pos": 377, "end_pos": 412, "type": "TASK", "confidence": 0.7402660051981608}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data statistics of the CNN and Daily  Mail datasets. The avg. tokens and sentences in  the passage, the avg. tokens in the query, and the  number of entities are based on statistics from the  training set, but they are similar on the development  and test sets.", "labels": [], "entities": [{"text": "CNN and Daily  Mail datasets", "start_pos": 33, "end_pos": 61, "type": "DATASET", "confidence": 0.8109069347381592}]}, {"text": " Table 2: Accuracy of all models on the CNN and Daily Mail datasets. Results marked  \u2020 are from (Hermann  et al., 2015) and results marked  \u2021 are from (Hill et al., 2016). Classifier and Neural net denote our  entity-centric classifier and neural network systems respectively. The numbers marked with  *  indicate that  the results are from ensemble models.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9748740792274475}, {"text": "CNN and Daily Mail datasets", "start_pos": 40, "end_pos": 67, "type": "DATASET", "confidence": 0.8216889500617981}]}, {"text": " Table 3: Feature ablation analysis of our entity- centric classifier on the development portion of the  CNN dataset. The numbers denote the accuracy  after we exclude each feature from the full system,  so a low number indicates an important feature.", "labels": [], "entities": [{"text": "CNN dataset", "start_pos": 105, "end_pos": 116, "type": "DATASET", "confidence": 0.958312451839447}, {"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9993652701377869}]}, {"text": " Table 5: An estimate of the breakdown of the  dataset into classes, based on the analysis of our  sampled 100 examples from the CNN dataset.", "labels": [], "entities": [{"text": "CNN dataset", "start_pos": 129, "end_pos": 140, "type": "DATASET", "confidence": 0.981883704662323}]}]}