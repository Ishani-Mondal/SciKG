{"title": [{"text": "Unsupervised Multi-Author Document Decomposition Based on Hidden Markov Model", "labels": [], "entities": [{"text": "Multi-Author Document Decomposition", "start_pos": 13, "end_pos": 48, "type": "TASK", "confidence": 0.5726052522659302}]}], "abstractContent": [{"text": "This paper proposes an unsupervised approach for segmenting a multi-author document into authorial components.", "labels": [], "entities": []}, {"text": "The key novelty is that we utilize the sequential patterns hidden among document elements when determining their authorships.", "labels": [], "entities": []}, {"text": "For this purpose, we adopt Hidden Markov Model (HMM) and construct a sequential probabilistic model to capture the dependencies of sequential sentences and their authorships.", "labels": [], "entities": []}, {"text": "An unsuper-vised learning method is developed to initialize the HMM parameters.", "labels": [], "entities": []}, {"text": "Experimental results on benchmark datasets have demonstrated the significant benefit of our idea and our approach has outperformed the state-of-the-arts on all tests.", "labels": [], "entities": []}, {"text": "As an example of its applications , the proposed approach is applied for attributing authorship of a document and has also shown promising results .", "labels": [], "entities": []}], "introductionContent": [{"text": "Authorship analysis is a process of inspecting documents in order to extract authorial information about these documents.", "labels": [], "entities": [{"text": "Authorship analysis", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8423541784286499}]}, {"text": "It is considered as a general concept that embraces several types of authorship subjects, including authorship verification, plagiarism detection and author attribution.", "labels": [], "entities": [{"text": "authorship verification", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7959951460361481}, {"text": "plagiarism detection", "start_pos": 125, "end_pos": 145, "type": "TASK", "confidence": 0.7434279322624207}, {"text": "author attribution", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.6805537641048431}]}, {"text": "Authorship verification () decides whether a given document is written by a specific author.", "labels": [], "entities": []}, {"text": "Plagiarism detection) seeks to expose the similarity between two texts.", "labels": [], "entities": [{"text": "Plagiarism detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8713474273681641}]}, {"text": "However, it is unable to determine if they are written by the same author.", "labels": [], "entities": []}, {"text": "In author attribution, areal author of an anonymous document is predicted using labeled documents of a set of candidate authors.", "labels": [], "entities": []}, {"text": "Another significant subject in authorship analysis, which has received comparatively less attention from research community, is authorship-based document decomposition (ABDD).", "labels": [], "entities": [{"text": "authorship analysis", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.8855884969234467}, {"text": "authorship-based document decomposition (ABDD)", "start_pos": 128, "end_pos": 174, "type": "TASK", "confidence": 0.7312394579251608}]}, {"text": "This subject is to group the sentences of a multi-author document to different classes, of which each contains the sentences written by only one author.", "labels": [], "entities": []}, {"text": "Many applications can take advantage of such a subject, especially those in forensic investigation, which aim to determine the authorship of sentences in a multi-author document.", "labels": [], "entities": []}, {"text": "Furthermore, this kind of subject is beneficial for detecting plagiarism in a document and defining contributions of authors in a multi-author document for commercial purpose.", "labels": [], "entities": []}, {"text": "ABDD can also be applied to identify which source (regarded as an 'author' in this paper) apart of a document is copied from when the document is formed by taking contents from various sources.", "labels": [], "entities": [{"text": "ABDD", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.5399186611175537}]}, {"text": "In despite of the benefits of ABDD, there has been little research reported on this subject. are the first researchers who implemented an unsupervised approach for ABDD.", "labels": [], "entities": [{"text": "ABDD", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.5032719373703003}, {"text": "ABDD", "start_pos": 164, "end_pos": 168, "type": "TASK", "confidence": 0.7396010756492615}]}, {"text": "However, their approach is restricted to Hebrew documents only.", "labels": [], "entities": []}, {"text": "The authors of addressed the drawbacks of the above approach by proposing a generic unsupervised approach for ABDD.", "labels": [], "entities": []}, {"text": "Their approach utilized distance measurements to increase the precision and accuracy of clustering and classification phases, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9993719458580017}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.998782217502594}, {"text": "clustering and classification", "start_pos": 88, "end_pos": 117, "type": "TASK", "confidence": 0.6009787619113922}]}, {"text": "The accuracy of their approach is highly dependent on the number of au-thors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994598031044006}]}, {"text": "When the number of authors increases, the accuracy of the approach is significantly dropped.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9995911717414856}]}, {"text": "presented an improved approach for ABDD when the number of authors of the document is known or unknown.", "labels": [], "entities": [{"text": "ABDD", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.7960513830184937}]}, {"text": "In his approach, a Bayesian segmentation algorithm is applied, which is followed by a segment clustering algorithm.", "labels": [], "entities": [{"text": "Bayesian segmentation", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.5997023582458496}, {"text": "segment clustering", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7108160555362701}]}, {"text": "However, the author tested his approach by using only documents with a few transitions among authors.", "labels": [], "entities": []}, {"text": "Furthermore, the accuracy of the approach is very sensitive to the setting of its parameters.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9994433522224426}]}, {"text": "In, the authors presented an unsupervised approach ABDD by exploiting the differences in the posterior probabilities of a Naive-Bayesian model in order to increase the precision and the classification accuracy, and to be less dependent on the number of authors in comparing with the approach in.", "labels": [], "entities": [{"text": "ABDD", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.6854395270347595}, {"text": "precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.999416708946228}, {"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9733281135559082}]}, {"text": "Their work was tested on documents with up to 400 transitions among authors and the accuracy of their approach was not sensitive to the setting of parameters, in contrast with the approach in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.999350368976593}]}, {"text": "However, the performance of their approach greatly depends on a threshold, of which the optimal value for an individual document is not easy to find.", "labels": [], "entities": []}, {"text": "Some other works have focused on segmenting a document into components according to their topics.", "labels": [], "entities": []}, {"text": "For applications where the topics of documents are unavailable, these topicbased solutions will fail.", "labels": [], "entities": []}, {"text": "In this paper, the ABDD approach is independent of documents' topics.", "labels": [], "entities": []}, {"text": "All of the existing works have assumed that the observations (i.e., sentences) are independent and identically distributed (i.i.d.).", "labels": [], "entities": []}, {"text": "No consideration has been given to the contextual information between the observations.", "labels": [], "entities": []}, {"text": "However, in some cases, the i.i.d. assumption is deemed as a poor one (.", "labels": [], "entities": []}, {"text": "In this paper, we will relax this assumption and consider sentences of a document as a sequence of observations.", "labels": [], "entities": []}, {"text": "We make use of the contextual information hidden between sentences in order to identify the authorship of each sentence in a document.", "labels": [], "entities": []}, {"text": "In other words, the authorships of the \"previous\" and \"subsequent\" sentences have relationships with the authorship of the current sentence.", "labels": [], "entities": []}, {"text": "Therefore, in this paper, a well-known sequential model, Hidden Markov Model (HMM), is used for modelling the sequential patterns of the document in order to describe the authorship relationships.", "labels": [], "entities": []}, {"text": "The contributions of this article are summarized as follows.", "labels": [], "entities": []}, {"text": "1. We capture the dependencies between consecutive elements in a document to identify different authorial components and construct an HMM for classification.", "labels": [], "entities": []}, {"text": "It is for the first time the sequential patterns hidden among document elements is considered for such a problem.", "labels": [], "entities": []}, {"text": "2. To build and learn the HMM model, an unsupervised learning method is first proposed to estimate its initial parameters, and it does not require any information of authors or document's context other than how many authors have contributed to write the document.", "labels": [], "entities": []}, {"text": "3. Different from the approach in, the proposed unsupervised approach no longer relies on any predetermined threshold for ABDD.", "labels": [], "entities": [{"text": "ABDD", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.757887065410614}]}, {"text": "4. Comprehensive experiments are conducted to demonstrate the superior performance of our ideas on both widely-used artificial benchmark datasets and an authentic scientific document.", "labels": [], "entities": []}, {"text": "As an example of its applications, the proposed approach is also applied for attributing authorship on a popular dataset.", "labels": [], "entities": []}, {"text": "The proposed approach cannot only correctly determine the author of a disputed document but also provide away for measuring the confidence level of the authorship decision for the first time.", "labels": [], "entities": []}, {"text": "The rest of this article is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews the HMM.", "labels": [], "entities": [{"text": "HMM", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.6084277629852295}]}, {"text": "Section 3 presents the details of our proposed approach, including the processes for initialization and learning of HMM parameters, and the Viterbi decoding process for classification.", "labels": [], "entities": []}, {"text": "Experiments are conducted in Section 4, followed by the conclusion in Section 5.", "labels": [], "entities": []}, {"text": "model which describes the statistical dependency between a sequence of observations O = {o 1 , o 2 , \u00b7 \u00b7 \u00b7 , o T } and a sequence of hidden states Q = {q 1 , q 2 , \u00b7 \u00b7 \u00b7 , q T }.", "labels": [], "entities": []}, {"text": "The observations can either be discrete variables, where each oi takes a value from a set of M symbols W = {w 1 , \u00b7 \u00b7 \u00b7 , w M }, or be continuous variables.", "labels": [], "entities": []}, {"text": "On the other hand, each q i takes one possible value from a set of N symbols, The behaviour of the HMM can be determined by three parameters shown as follows.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we demonstrate the performance of our proposed approach by conducting experiments on benchmark datasets as well as one authentic document.", "labels": [], "entities": []}, {"text": "Furthermore, an application on authorship attribution is presented using another popular dataset.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.882531076669693}]}, {"text": "Three benchmark corpora widely used for authorship analysis are used to evaluate our approach.", "labels": [], "entities": [{"text": "authorship analysis", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.9377380013465881}]}, {"text": "Furthermore, an authentic document is also examined.", "labels": [], "entities": []}, {"text": "The first corpus consists of five Biblical books written by Ezekiel, Isaiah, Jeremiah, Proverbs and Job, respectively.", "labels": [], "entities": []}, {"text": "All of these books are written in Hebrew.", "labels": [], "entities": []}, {"text": "The five books belong to two types of literature genres.", "labels": [], "entities": []}, {"text": "The first three books are related to prophecy literature and the other two books are related to a wisdom literature.", "labels": [], "entities": []}, {"text": "The second corpus consists of blogs written by the Nobel Prize-winning economist Gary S. Becker and the renowned jurist and legal scholar Richard A. Posner.", "labels": [], "entities": []}, {"text": "This corpus, which is titled \"The Becker-Posner Blogs\" (www.becker-posner-blog.com), contains 690 blogs.", "labels": [], "entities": []}, {"text": "On average, each blog has 39 sentences talking about particular topic.", "labels": [], "entities": []}, {"text": "The Becker-Posner Blogs dataset, which is considered as a very important dataset for authorship analysis, provides a good benchmark for testing the proposed approach in a document where the topics of authors are not distinguishable.", "labels": [], "entities": [{"text": "Becker-Posner Blogs dataset", "start_pos": 4, "end_pos": 31, "type": "DATASET", "confidence": 0.6864171028137207}, {"text": "authorship analysis", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.9381038844585419}]}, {"text": "For more challenging documents, Giannella   cles are subjected to different topics.", "labels": [], "entities": []}, {"text": "In our experiments, all possible multi-author documents of articles of these columnists are created.", "labels": [], "entities": []}, {"text": "Therefore, this corpus permits us to examine the performance of our approach in documents written by more than two authors.", "labels": [], "entities": []}, {"text": "The fourth corpus is a very early draft of a scientific article co-authored by two PhD students each being assigned a task to write some full sections of the paper.", "labels": [], "entities": []}, {"text": "We employ this corpus in order to evaluate the performance of our approach on an authentic document.", "labels": [], "entities": []}, {"text": "For this purpose, we have disregarded its titles, author names, references, figures and tables.", "labels": [], "entities": []}, {"text": "After that, we get 313 sentences which are written by two authors, where Author 1 has written 131 sentences and Author 2 has written 182 sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The classification accuracies and pre- dicted contributions of the two authors of the  scientific paper using the proposed approach.", "labels": [], "entities": []}]}