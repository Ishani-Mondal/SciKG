{"title": [{"text": "Efficient techniques for parsing with tree automata", "labels": [], "entities": []}], "abstractContent": [{"text": "Parsing fora wide variety of grammar formalisms can be performed by intersecting finite tree automata.", "labels": [], "entities": []}, {"text": "However, naive implementations of parsing by intersection are very inefficient.", "labels": [], "entities": [{"text": "parsing by intersection", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.848186989625295}]}, {"text": "We present techniques that speedup tree-automata-based parsing , to the point that it becomes practically feasible on realistic data when applied to context-free, TAG, and graph parsing.", "labels": [], "entities": [{"text": "graph parsing", "start_pos": 172, "end_pos": 185, "type": "TASK", "confidence": 0.7305754721164703}]}, {"text": "For graph parsing, we obtain the best runtimes in the literature.", "labels": [], "entities": [{"text": "graph parsing", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.7202125191688538}]}], "introductionContent": [{"text": "Grammar formalisms that go beyond context-free grammars have recently enjoyed renewed attention throughout computational linguistics.", "labels": [], "entities": []}, {"text": "Classical grammar formalisms such as TAG) and CCG) have been equipped with expressive statistical models, and high-performance parsers have become available.", "labels": [], "entities": []}, {"text": "Synchronous grammar formalisms such as synchronous context-free grammars and tree-to-string transducers ( are being used as models that incorporate syntactic information in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 173, "end_pos": 204, "type": "TASK", "confidence": 0.6642641524473826}]}, {"text": "Synchronous string-to-tree () and string-to-graph grammars) have been applied to semantic parsing; and so forth.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.7659789621829987}]}, {"text": "Each of these grammar formalisms requires its users to develop new algorithms for parsing and training.", "labels": [], "entities": []}, {"text": "This comes with challenges that are both practical and theoretical.", "labels": [], "entities": []}, {"text": "From a theoretical perspective, many of these algorithms are basically the same, in that they rest upon a CKY-style parsing algorithm which recursively explores substructures of the input object and assigns them nonterminal symbols, but their exact relationship is rarely made explicit.", "labels": [], "entities": []}, {"text": "On the practical side, this parsing algorithm and its extensions (e.g. to EM training) have to be implemented and optimized from scratch for each new grammar formalism.", "labels": [], "entities": []}, {"text": "Thus, development time is spent on reinventing wheels that are slightly different from previous ones, and the resulting implementations still tend to underperform.", "labels": [], "entities": []}, {"text": "introduced Interpreted Regular Tree Grammars (IRTGs) in order to address this situation.", "labels": [], "entities": [{"text": "Interpreted Regular Tree Grammars (IRTGs)", "start_pos": 11, "end_pos": 52, "type": "TASK", "confidence": 0.587172623191561}]}, {"text": "An IRTG represents a language by describing a regular language of derivation trees, each of which is mapped to a term over some algebra and evaluated there.", "labels": [], "entities": []}, {"text": "Grammars from a wide range of monolingual and synchronous formalisms can be mapped into IRTGs by using different algebras: Context-free and treeadjoining grammars use string algebras of different kinds, graph grammars can be captured by using graph algebras, and soon.", "labels": [], "entities": []}, {"text": "In addition, IRTGs come with a universal parsing algorithm based on closure results for tree automata.", "labels": [], "entities": []}, {"text": "Implementing and optimizing this parsing algorithm once, one could apply it to all grammar formalisms that can be mapped to IRTG.", "labels": [], "entities": [{"text": "IRTG", "start_pos": 124, "end_pos": 128, "type": "DATASET", "confidence": 0.8233288526535034}]}, {"text": "However, while Koller and Kuhlmann show that asymptotically optimal parsing is possible in theory, it is non-trivial to implement their algorithm optimally.", "labels": [], "entities": []}, {"text": "In this paper, we introduce practical algorithms for the two key operations underlying IRTG parsing: computing the intersection of two tree automata and applying an inverse tree homomorphism to a tree automaton.", "labels": [], "entities": [{"text": "IRTG parsing", "start_pos": 87, "end_pos": 99, "type": "TASK", "confidence": 0.9225869178771973}]}, {"text": "After defining IRTGs (Section 2), we will first illustrate that a naive bottom-up implementation of the intersection algorithm yields asymptotic parsing complexities that are too high (Section 3).", "labels": [], "entities": []}, {"text": "We will then show how the parsing complexity can be improved by combining algebra-specific index data structures with a generic parsing algorithm (Section 4), and by replacing bottom-up with top-down queries (Section 5).", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9671279788017273}]}, {"text": "In contrast to the naive algorithm, both of these methods achieve the expected asymptotic complexities, e.g. O(n 3 ) for context-free parsing, O(n 6 ) for TAG parsing, etc.", "labels": [], "entities": [{"text": "O", "start_pos": 109, "end_pos": 110, "type": "METRIC", "confidence": 0.9873430728912354}, {"text": "TAG parsing", "start_pos": 155, "end_pos": 166, "type": "TASK", "confidence": 0.8002254366874695}]}, {"text": "Furthermore, an evaluation with realistic grammars shows that our algorithms improve practical parsing times with IRTG grammars encoding context-free grammars, tree-adjoining grammars, and graph grammars by orders of magnitude (Section 6).", "labels": [], "entities": []}, {"text": "Thus our algorithms make IRTG parsing practically feasible for the first time; for graph parsing, we obtain the fastest reported runtimes.", "labels": [], "entities": [{"text": "IRTG parsing", "start_pos": 25, "end_pos": 37, "type": "TASK", "confidence": 0.9288599193096161}, {"text": "graph parsing", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.7175207138061523}]}], "datasetContent": [{"text": "We compare the runtime performance of the proposed algorithms on practical grammars and inputs, from three very different grammar formalisms: context-free grammars, TAG, and HRG graph grammars.", "labels": [], "entities": []}, {"text": "In each setting, we measure the bottom-up top-down top-down cond.", "labels": [], "entities": []}, {"text": "sibling-finder GKT 15 . We measure the runtimes for computing the complete chart, and plot the geometric mean of runtimes for each input size on a log scale.", "labels": [], "entities": [{"text": "GKT", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.832551896572113}]}, {"text": "We measured all runtimes on an Intel Xeon E7-8857 CPU at 3 GHz using Java 8.", "labels": [], "entities": []}, {"text": "The JVM was warmed up before the measurements.", "labels": [], "entities": [{"text": "JVM", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8632918000221252}]}, {"text": "The parser filtered each grammar automatically, removing all rules whose homomorphic image contained a constant that could not be used fora given input (e.g., a word that did not occur in the sentence).", "labels": [], "entities": []}, {"text": "We extracted a binarized context-free grammar with 6929 rules from Section 00 of the Penn Treebank, and parsed the sentences of Section 00 with it.", "labels": [], "entities": [{"text": "Section 00 of the Penn Treebank", "start_pos": 67, "end_pos": 98, "type": "DATASET", "confidence": 0.7300939857959747}]}, {"text": "The homorphism in the corresponding IRTG assigns every terminal symbol a constant or the term * (x 1 , x 2 ), as in.", "labels": [], "entities": [{"text": "IRTG", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.6847298741340637}]}, {"text": "As a consequence, the condensed automaton optimization from Section 5 outperforms all other algo-rithms, achieving a 100x speedup over the naive bottom-up algorithm when it was cancelled.", "labels": [], "entities": []}, {"text": "We also extracted a tree-adjoining grammar from Section 00 of the PTB as described by, converted it to an IRTG as described by, and binarized it, yielding an IRTG with 26652 rules.", "labels": [], "entities": [{"text": "PTB", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.9136068224906921}]}, {"text": "Each term h(r) in this grammar represents an entire TAG elementary tree, which means the terms are much more complex than for the PCFG and there are much fewer terminal symbols with the same homomorphic term.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.9530096054077148}]}, {"text": "As a consequence, condensing the invhom is much less helpful.", "labels": [], "entities": []}, {"text": "However, the sibling-finder algorithm excels at maintaining state information within each elementary tree, yielding a 1000x speedup over the naive bottom-up algorithm when it was cancelled.", "labels": [], "entities": []}, {"text": "Finally, we parsed a corpus of graphs instead of strings, using the 13681-rule graph grammar of to parse the 1258 graphs with up to 10 nodes from the \"Little Prince\" AMR-Bank ().", "labels": [], "entities": [{"text": "AMR-Bank", "start_pos": 166, "end_pos": 174, "type": "DATASET", "confidence": 0.7073538303375244}]}, {"text": "The top-down algorithms are slow in this experiment, confirming Groschwitz et al.'s findings.", "labels": [], "entities": []}, {"text": "Again, the sibling-finder algorithm outperforms all other algorithms.", "labels": [], "entities": []}, {"text": "Note that Groschwitz et al.'s parser (\"GKT 15\" in) shares much code with our system.", "labels": [], "entities": [{"text": "GKT 15", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.848408043384552}]}, {"text": "It uses the same decomposition automata, but a less mature version of the sibling-finder method which fully computes the invhom automaton.", "labels": [], "entities": []}, {"text": "Our new system achieves a 9x speedup for parsing the whole corpus, compared to GKT 15.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9741069674491882}, {"text": "GKT", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.7923855185508728}]}], "tableCaptions": []}