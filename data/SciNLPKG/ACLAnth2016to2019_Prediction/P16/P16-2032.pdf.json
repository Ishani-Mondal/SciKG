{"title": [{"text": "Is This Post Persuasive? Ranking Argumentative Comments in the Online Forum", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we study how to identify persuasive posts in the online forum discussions , using data from Change My View sub-Reddit.", "labels": [], "entities": [{"text": "Change My View sub-Reddit", "start_pos": 106, "end_pos": 131, "type": "DATASET", "confidence": 0.7689695060253143}]}, {"text": "Our analysis confirms that the users' voting score fora comment is highly correlated with its metadata information such as published time and author reputation.", "labels": [], "entities": []}, {"text": "In this work, we propose and evaluate other features to rank comments for their persuasive scores, including tex-tual information in the comments and social interaction related features.", "labels": [], "entities": []}, {"text": "Our experiments show that the surface textual features do not perform well compared to the argumentation based features, and the social interaction based features are effective especially when more users participate in the discussion.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the popularity of online forums such as idebate and convinceme , researchers have been paying increasing attentions to analyzing persuasive content, including identification of arguing expressions in online debates), recognition of stance in ideological online debates, and debate summarization ().", "labels": [], "entities": [{"text": "identification of arguing expressions in online debates", "start_pos": 164, "end_pos": 219, "type": "TASK", "confidence": 0.8203325016157967}, {"text": "recognition of stance in ideological online debates", "start_pos": 222, "end_pos": 273, "type": "TASK", "confidence": 0.7997166684695652}, {"text": "debate summarization", "start_pos": 279, "end_pos": 299, "type": "TASK", "confidence": 0.702825516462326}]}, {"text": "However, how to automatically determine if a text is persuasive is still an unsolved problem.", "labels": [], "entities": []}, {"text": "Text quality and popularity evaluation has been studied in different domains in the past few years (.", "labels": [], "entities": [{"text": "Text quality and popularity evaluation", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5892199277877808}]}, {"text": "However, http://idebate.org/ 2 http://convinceme.net quality evaluation of argumentative text in the online forum has some unique characterisitcs.", "labels": [], "entities": []}, {"text": "First, persuasive text contains argument that is not common in other genres.", "labels": [], "entities": []}, {"text": "Second, beside the text itself, the interplay between a comment and what it responds to is crucial.", "labels": [], "entities": []}, {"text": "Third, the community reaction to the comment also needs to betaken into consideration.", "labels": [], "entities": [{"text": "betaken", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.6826154589653015}]}, {"text": "In this paper, we propose several sets of features to capture the above mentioned characteristics for persuasive comment identification in the online forum.", "labels": [], "entities": [{"text": "persuasive comment identification", "start_pos": 102, "end_pos": 135, "type": "TASK", "confidence": 0.6798880298932394}]}, {"text": "We constructed a dataset from a sub-forum of Reddit 3 , namely change my view . We first analyze the corpus and show the correlation between the human voting score for an argumentative comment and its entry order and author reputation.", "labels": [], "entities": []}, {"text": "Then for the comment ranking task, we propose three sets of features including surface text features, social interaction based features and argumentation based features.", "labels": [], "entities": []}, {"text": "Our experimental results show that the argumentation based features work the best in the early stage of the discussion and the effectiveness of social interaction features increases when the number of comments in the discussion grows.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use 5-fold cross-validation in our experiments.", "labels": [], "entities": []}, {"text": "Normalized discounted cumulative gain (NDCG) score) is used as the evaluation metric for our First-N comments ranking task.", "labels": [], "entities": [{"text": "discounted cumulative gain (NDCG) score", "start_pos": 11, "end_pos": 50, "type": "METRIC", "confidence": 0.8507803082466125}, {"text": "First-N comments ranking task", "start_pos": 93, "end_pos": 122, "type": "TASK", "confidence": 0.5678754895925522}]}, {"text": "In this study, N is10.", "labels": [], "entities": [{"text": "N", "start_pos": 15, "end_pos": 16, "type": "METRIC", "confidence": 0.9747193455696106}]}, {"text": "shows the results for first-10 comments ranking using information from only these 10 comments.", "labels": [], "entities": []}, {"text": "As shown in, metadata features, entry order and author's reputation are correlated with the karma score of a comment.", "labels": [], "entities": [{"text": "entry order", "start_pos": 32, "end_pos": 43, "type": "METRIC", "confidence": 0.8288777768611908}]}, {"text": "We We constructed a list of connective words including 55 entries (e.g., because, therefore etc.).", "labels": [], "entities": []}, {"text": "thus use these two values as baselines.", "labels": [], "entities": []}, {"text": "We also include the performance of the random baseline for comparison . For our ranking based models (LTR * ), we compare using the three sets of features described in Section.", "labels": [], "entities": []}, {"text": "3.2 (noted as text, social and arg respectively), individually or in combination.", "labels": [], "entities": [{"text": "arg", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9494092464447021}]}, {"text": "We report NDCG scores for position 1, 5 and 10 respectively.", "labels": [], "entities": [{"text": "NDCG", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.44857552647590637}]}, {"text": "The followings are some findings.", "labels": [], "entities": []}, {"text": "\u2022 Both metadata based baselines generate significantly better results compared to the random baseline.", "labels": [], "entities": []}, {"text": "Baseline entry-order performs much better than author, suggesting that the entry order is more indicative for the karma score of a comment.", "labels": [], "entities": []}, {"text": "\u2022 The surface text features are least effective among the three sets of features, and the performance using them is even worse than the two metadata baselines.", "labels": [], "entities": []}, {"text": "This might be because the general writing quality of the comments in CMV is high because of the policy of the forum.", "labels": [], "entities": [{"text": "CMV", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.9099521636962891}]}, {"text": "Therefore, the surface text features we used are not very discriminative for comment ranking.", "labels": [], "entities": [{"text": "comment ranking", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7263325750827789}]}, {"text": "A further analysis of features in this category shows that length is the most effective feature.", "labels": [], "entities": [{"text": "length", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9885746836662292}]}, {"text": "\u2022 Argumentation based features have the best performance among the three categories.", "labels": [], "entities": []}, {"text": "Its performance is significantly better than surface text features, consistent with our expectation that argumentation related features are useful for persuasiveness evaluation.", "labels": [], "entities": []}, {"text": "Our additional experiments show that interactive features are more effective than local features.", "labels": [], "entities": []}, {"text": "This might be because the argumentation features and models we use are not perfect.", "labels": [], "entities": []}, {"text": "Future research is still needed to better represent argumentation information in the text.", "labels": [], "entities": []}, {"text": "\u2022 When combining two categories of features, the performance of the ranker increases consistently.", "labels": [], "entities": []}, {"text": "The performance can be further improved by combining all the three categories of features we proposed (the improvement compared to using a single feature category is significant).", "labels": [], "entities": []}, {"text": "The best results are achieved by LTR all , i.e., combining two metadata features and features we proposed.", "labels": [], "entities": []}, {"text": "The performance of random baseline is high because of the tie of reference karma scores.", "labels": [], "entities": []}, {"text": "Significance is computed by two tailed t-test.", "labels": [], "entities": [{"text": "Significance", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.9771207571029663}]}, {"text": "With the evolving discussion, there will be more comments joining the thread providing more information for social interaction based features.", "labels": [], "entities": []}, {"text": "In order to show the impact of different features at different discussion stage, we conduct another experiment by ranking first-10 comments with varying numbers of comments in the test thread for feature computing.", "labels": [], "entities": []}, {"text": "The result of the experiment is shown in.", "labels": [], "entities": []}, {"text": "The performance of LTR text and LTR arg remain the same since their feature values are not affected by the new coming comments.", "labels": [], "entities": []}, {"text": "The performance of LTR social increases consistently when the number of comments grows, and it outperforms LTR arg when the number of comments is more than 20.", "labels": [], "entities": []}, {"text": "LTR T +S+A has always the best performance, benefiting from the combination of different types of features.", "labels": [], "entities": [{"text": "LTR T +S+A", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.7412648051977158}]}], "tableCaptions": [{"text": " Table 2: Feature list (c: the comment; rc: the root comment of c.)", "labels": [], "entities": []}, {"text": " Table 3: Performance of first-10 comments rank- ing (T+S+A: the combination of the three sets of  features we proposed; all: the combination of two  meta-data features and our features; bold: the best  performance in each column;  \u2020: the approach is  significantly better than both metadata baselines  (p <0.01);  \u2021: the approach is significantly better  than LTR approaches using a single category of  features (p <0.01).).", "labels": [], "entities": []}]}