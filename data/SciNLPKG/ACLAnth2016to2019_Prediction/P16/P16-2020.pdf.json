{"title": [{"text": "Multiplicative Representations for Unsupervised Semantic Role Induction", "labels": [], "entities": [{"text": "Semantic Role Induction", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.6228635013103485}]}], "abstractContent": [{"text": "In unsupervised semantic role labeling, identifying the role of an argument is usually informed by its dependency relation with the predicate.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.7009813189506531}]}, {"text": "In this work, we propose a neural model to learn argument embeddings from the context by explicitly incorporating dependency relations as multiplicative factors, which bias argument embeddings according to their dependency roles.", "labels": [], "entities": []}, {"text": "Our model outperforms existing state-of-the-art embeddings in un-supervised semantic role induction on the CoNLL 2008 dataset and the SimLex999 word similarity task.", "labels": [], "entities": [{"text": "CoNLL 2008 dataset", "start_pos": 107, "end_pos": 125, "type": "DATASET", "confidence": 0.9570448597272238}, {"text": "SimLex999 word similarity task", "start_pos": 134, "end_pos": 164, "type": "TASK", "confidence": 0.6903216317296028}]}, {"text": "Qualitative results demonstrate our model can effectively bias argument embeddings based on their dependency role.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic role labeling (SRL) aims to identify predicate-argument structures of a sentence.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8530762692292532}]}, {"text": "The following example shows the arguments labeled with the roles A0 (typically the agent of an action) and A1 (typically the patient of an action), as well as the predicate in bold.", "labels": [], "entities": [{"text": "A1", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9842809438705444}]}, {"text": "[Little Willy A0 ] broke [a window A1 ].", "labels": [], "entities": [{"text": "Little Willy A0 ]", "start_pos": 1, "end_pos": 18, "type": "DATASET", "confidence": 0.9405734986066818}]}, {"text": "As manual annotations are expensive and timeconsuming, supervised approaches () to this problem are held back by limited coverage of available gold annotations.", "labels": [], "entities": []}, {"text": "SRL performance decreases remarkably when applied to out-of-domain data (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8938866853713989}]}, {"text": "Unsupervised SRL offer a promising alternative (;.", "labels": [], "entities": [{"text": "SRL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.909281849861145}]}, {"text": "It is commonly formalized as a clustering problem, where each cluster represents an induced semantic role.", "labels": [], "entities": []}, {"text": "Such clustering is usually performed through manually defined semantic and syntactic features defined over argument instances.", "labels": [], "entities": []}, {"text": "However, the representation based on these features are usually sparse and difficult to generalize.", "labels": [], "entities": []}, {"text": "Inspired by the recent success of distributed word representations (), we introduce two unsupervised models that learn embeddings of arguments, predicates, and syntactic dependency relations between them.", "labels": [], "entities": []}, {"text": "The embeddings are learned by predicting each argument from its context, which includes the predicate and other arguments in the same sentence.", "labels": [], "entities": []}, {"text": "Driven by the importance of syntactic dependency relations in SRL, we explicitly model dependencies as multiplicative factors in neural networks, yielding more succinct models than existing representation learning methods employing dependencies ().", "labels": [], "entities": [{"text": "SRL", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9785959720611572}]}, {"text": "The learned argument embeddings are then clustered and are evaluated by the clusters' agreement with ground truth labels.", "labels": [], "entities": []}, {"text": "On unsupervised SRL, our models outperform the state of the art by on gold parses and on automatic parses.", "labels": [], "entities": [{"text": "SRL", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.7839254140853882}]}, {"text": "Qualitative results suggest our model is effective in biasing argument embeddings toward a specific dependency relation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our models in unsupervised SRL and compare the effectiveness our approach in modeling dependency relations with the previous work.", "labels": [], "entities": [{"text": "SRL", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9296082258224487}]}], "tableCaptions": [{"text": " Table 1: Purity, collocation and F1 measures for  the CoNLL-2008 data set.", "labels": [], "entities": [{"text": "Purity", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9834733605384827}, {"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9995261430740356}, {"text": "CoNLL-2008 data set", "start_pos": 55, "end_pos": 74, "type": "DATASET", "confidence": 0.9764830470085144}]}, {"text": " Table 2: The 8 most similar predicates to a given argument in a given dependency role.", "labels": [], "entities": []}, {"text": " Table 3: A POS-based analysis of the various em- beddings. Numbers are the Spearman's \u03c1 scores  of each model on nouns and verbs of SimLex999.", "labels": [], "entities": [{"text": "Spearman's \u03c1 scores", "start_pos": 76, "end_pos": 95, "type": "METRIC", "confidence": 0.6329153627157211}]}]}