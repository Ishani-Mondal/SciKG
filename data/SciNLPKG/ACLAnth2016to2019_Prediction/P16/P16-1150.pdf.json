{"title": [{"text": "Which argument is more convincing? Analyzing and predicting convincingness of Web arguments using bidirectional LSTM", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose anew task in the field of computational argumentation in which we investigate qualitative properties of Web arguments, namely their convincingness.", "labels": [], "entities": []}, {"text": "We cast the problem as relation classification , where a pair of arguments having the same stance to the same prompt is judged.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9525202214717865}]}, {"text": "We annotate a large datasets of 16k pairs of arguments over 32 topics and investigate whether the relation \"A is more convincing than B\" exhibits properties of total ordering; these findings are used as global constraints for cleaning the crowdsourced data.", "labels": [], "entities": []}, {"text": "We propose two tasks: (1) predicting which argument from an argument pair is more convincing and (2) ranking all arguments to the topic based on their convinc-ingness.", "labels": [], "entities": []}, {"text": "We experiment with feature-rich SVM and bidirectional LSTM and obtain 0.76-0.78 accuracy and 0.35-0.40 Spear-man's correlation in a cross-topic evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9986735582351685}, {"text": "Spear-man's correlation", "start_pos": 103, "end_pos": 126, "type": "METRIC", "confidence": 0.9416990280151367}]}, {"text": "We release the newly created corpus UKPConvArg1 and the experimental software under open licenses.", "labels": [], "entities": [{"text": "UKPConvArg1", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.9892500638961792}]}], "introductionContent": [{"text": "What makes a good argument?", "labels": [], "entities": []}, {"text": "Despite the recent achievements in computational argumentation, such as identifying argument components (, finding evidence for claims (, or predicting argument structure (, this question remains too hard to be answered.", "labels": [], "entities": [{"text": "predicting argument structure", "start_pos": 141, "end_pos": 170, "type": "TASK", "confidence": 0.8717975815137228}]}, {"text": "Even Aristotle claimed that perceiving an argument as a \"good\" one depends on multiple factors ( -not only the logical structure of the argument (logos), but also on the speaker (ethos), emotions (pathos), or context (cairos) (.", "labels": [], "entities": []}, {"text": "Experiments also show that different audiences perceive the very same arguments differently (.", "labels": [], "entities": []}, {"text": "A solid body of argumentation research has been devoted to the quality of arguments), giving more profound criteria that \"good\" arguments should fulfill.", "labels": [], "entities": []}, {"text": "However, the empirical evidence proving applicability of many theories falls short on everyday arguments (.", "labels": [], "entities": []}, {"text": "Since the main goal of argumentation is persuasion () we take a pragmatic perspective on qualitative properties of argumentation and investigate anew high-level task.", "labels": [], "entities": []}, {"text": "We asked whether we could quantify and predict how convincing an argument is.", "labels": [], "entities": []}, {"text": "If we take Argument 1 from, assigning a single \"convincingness score\" is highly subjective, given the lack of context, reader's prejudice, beliefs, etc.", "labels": [], "entities": [{"text": "Argument", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.6811522841453552}]}, {"text": "However, when comparing both arguments from the same example, one can decide that A1 is probably more convincing than A2, because it uses at least some statistics, addresses the health factor, and A2 is just harsh and attacks.", "labels": [], "entities": [{"text": "A1", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9779055714607239}, {"text": "A2", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9744554162025452}, {"text": "A2", "start_pos": 197, "end_pos": 199, "type": "METRIC", "confidence": 0.8922339677810669}]}, {"text": "We adapt pairwise comparison as our backbone approach.", "labels": [], "entities": []}, {"text": "We propose a novel task of predicting convincingness of arguments in an argument pair, as well as ranking arguments related to a certain topic.", "labels": [], "entities": [{"text": "predicting convincingness of arguments in an argument pair", "start_pos": 27, "end_pos": 85, "type": "TASK", "confidence": 0.8557007536292076}]}, {"text": "Since no data for such a task are available, we create anew annotated corpus.", "labels": [], "entities": []}, {"text": "We employ SVM model with rich linguistic features as well as bidirectional Long Short-Term Memory (BLSTM) neural networks because of their excellent performance across various end-to-end NLP tasks (.", "labels": [], "entities": [{"text": "Long Short-Term Memory (BLSTM", "start_pos": 75, "end_pos": 104, "type": "METRIC", "confidence": 0.7096680760383606}]}, {"text": "Main contributions of this article are (1) large annotated dataset consisting of 16k argument pairs with 56k reasons in natural language (700k tokens), (2) thorough investigation of the annotated data with respect to properties of convincingness as a measure, (3) a SVM model and end-to-end BLSTM model.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 291, "end_pos": 296, "type": "METRIC", "confidence": 0.6585274934768677}]}, {"text": "The annotated data, licensed under CC-BY-SA license, and the experimental code are publicly available at https://github.com/UKPLab/ acl2016-convincing-arguments.", "labels": [], "entities": [{"text": "UKPLab", "start_pos": 124, "end_pos": 130, "type": "DATASET", "confidence": 0.9758967161178589}]}, {"text": "We hope it will foster future research in computational argumentation and beyond.", "labels": [], "entities": []}], "datasetContent": [{"text": "The previous section shows a variety of reasons that makes one argument more convincing than other arguments.", "labels": [], "entities": []}, {"text": "Considering A1 is more convincing than A2 as a binary relation R, we thus asked the following research question: Is convincingness a measure with total strict order or strict weak order?", "labels": [], "entities": []}, {"text": "Namely, is relation R that compares convingcingness of two arguments transitive, antisymmetric, and total?", "labels": [], "entities": []}, {"text": "In particular, does is exhibit properties such that if A\u2265B and B\u2265C, then A\u2265C (total ordering)?", "labels": [], "entities": []}, {"text": "We can treat arguments as nodes in a graph and argument pairs as graph edges.", "labels": [], "entities": []}, {"text": "We will denote such graph as argument graph (and use nodes/arguments and edges/pairs interchangeably in this section).", "labels": [], "entities": []}, {"text": "As the sampled argument pairs Argument pair A>B becomes a directed edge A \u2192 B contained all argument pair combinations for each topic, we ended up with an almost fully connected argument graph for each topic (remember that we discarded 5% of argument pair annotations with lowest reliability).", "labels": [], "entities": []}, {"text": "We further investigate the properties of the argument graphs.", "labels": [], "entities": []}, {"text": "Transitivity is only guaranteed, if the argument graph is a DAG (directed acyclic graph).", "labels": [], "entities": []}, {"text": "Building argument graph from crowdsourced argument pairs We build the argument graph iteratively by sampling annotated argument pairs and adding them as graph edges (see Algorithm 1).", "labels": [], "entities": []}, {"text": "We consider two possible scenarios in the graph building algorithm.", "labels": [], "entities": [{"text": "graph building algorithm", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.8033289511998495}]}, {"text": "In the first scenario, we accept only argument pairs without equivalency (thus A>B is allowed but A=B is forbidden and discarded).", "labels": [], "entities": []}, {"text": "The second scenario accepts all pairs, but since the resulting graph must be DAG, equivalent arguments are merged into one node.", "labels": [], "entities": []}, {"text": "We use Johnson's algorithm for finding all elementary cycles in DAG.", "labels": [], "entities": []}, {"text": "Argument pair weights By building argument graph from all pairs, introducing cycles into the graph seems to be inevitable, given a certain amount of noise in the annotations.", "labels": [], "entities": []}, {"text": "We asked the following question: to which extent does occurrence of cycles in an argument graph depend on the quality of annotations?", "labels": [], "entities": []}, {"text": "We thus compute a weight for each argument pair.", "labels": [], "entities": []}, {"text": "Let e i be a particular annotation pair (edge).", "labels": [], "entities": []}, {"text": "Let G i be all labels in that pair that match the predicted gold label, and O i opposite labels (different from the gold label).", "labels": [], "entities": []}, {"text": "Let v be a single worker's vote and c v a global worker's competence score.", "labels": [], "entities": []}, {"text": "Then the weight w of edge e i is computed as follows: where \u03c3 is a sigmoid function \u03c3 = 1 1+e \u2212x to squeeze the weight into the (0, 1) interval and \u03bb is a penalty for opposite labels (we set empirically \u03bb to 10.0 to ensure strict penalization).", "labels": [], "entities": []}, {"text": "For example, if the predicted gold label from were A1>A2, then G i would contain four votes and O i one vote (the last one).", "labels": [], "entities": []}, {"text": "This weight allows us to sort argument pairs before sampling them for building the argument in the argument graph. graph.", "labels": [], "entities": []}, {"text": "We test three following strategies.", "labels": [], "entities": []}, {"text": "As a baseline, we use random shuffling (Rand), where no prior information about the weight of the pairs is given.", "labels": [], "entities": [{"text": "Rand)", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9430155158042908}]}, {"text": "The other two sorting algorithms use the argument pair weight computed by Equation 1.", "labels": [], "entities": [{"text": "Equation", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9826065897941589}]}, {"text": "As the worst case scenario, we sort the pairs in ascending order (Asc), which means that the \"worse\" pairs come first to the graph building algorithm.", "labels": [], "entities": []}, {"text": "We used this scenario to see how much the prior pair weight information actually matters, because building a graph preferably from bad pair label estimates should cause more harm.", "labels": [], "entities": []}, {"text": "Finally, the Desc algorithm sorts the pairs given their weight in descending order (the \"better\" estimates come first).", "labels": [], "entities": []}, {"text": "Measuring transitivity score We measure how \"good\" the graph is by a transitivity score.", "labels": [], "entities": []}, {"text": "Here we assume that the graph is a DAG.", "labels": [], "entities": []}, {"text": "Given two nodes A and Z, let P L be the longest path between these nodes and PS the shortest path, respectively.", "labels": [], "entities": []}, {"text": "For example, let P L = A \u2192 B \u2192 C \u2192 Z and Then the transitivity score is the ratio of longest and shortest path |P L | |P S | . (which is 1.5 is our example).", "labels": [], "entities": []}, {"text": "The average transitivity score is then an average of transitivity scores for each pair of nodes from the graph that are connected by two or more paths.", "labels": [], "entities": []}, {"text": "Analogically, the maximum transitivity score is the maximal value.", "labels": [], "entities": []}, {"text": "We restrict the shortest path to be a direct edge only.", "labels": [], "entities": []}, {"text": "The motivation for the transitivity score is the following.", "labels": [], "entities": []}, {"text": "If the longest path between A and Z (A \u2192 . .", "labels": [], "entities": []}, {"text": "\u2192 Z) consists of 10 other nodes, than the total ordering property requires that there also exists a direct edge A \u2192 Z.", "labels": [], "entities": []}, {"text": "This is indeed em- pirically confirmed by the presence of the shortest path between A and Z.", "labels": [], "entities": []}, {"text": "Thus the longer the longest path and the shorter the shortest path are on average, the bigger empirical evidence is given about the transitivity property.", "labels": [], "entities": []}, {"text": "shows an example of argument graph built using only non-equivalent pairs and desc prior sort or argument pairs.", "labels": [], "entities": []}, {"text": "There are few \"bad\" arguments in the middle (many incoming edges, none outcoming) and few very convincing arguments (large circles).", "labels": [], "entities": []}, {"text": "Notice the high maximum transitivity score even for medium-sized nodes.", "labels": [], "entities": []}, {"text": "Observations First, let us compare the different sorting algorithms for each sampling strategy.", "labels": [], "entities": []}, {"text": "As  The results show a tendency that, when sampling annotated argument pairs for building a DAG, sorting argument pairs by their weight based on workers' scores influences the number of pairs that break the DAG by introducing cycles.", "labels": [], "entities": []}, {"text": "In particular, starting with more confident argumentation pairs, the graph grows bigger while keeping its DAG consistency.", "labels": [], "entities": [{"text": "DAG consistency", "start_pos": 106, "end_pos": 121, "type": "METRIC", "confidence": 0.8701705932617188}]}, {"text": "The presence of the equal relation causes cycles to break the DAG sooner as compared to argument pairs in which one argument is more convincing than the other.", "labels": [], "entities": [{"text": "DAG", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.7604095935821533}]}, {"text": "We interpret this finding as that it is easier for humans to judge A>B than A=B consistently across all possible pairs of arguments from a given topic.", "labels": [], "entities": []}, {"text": "We experiment with two machine learning algorithms on two tasks using the two new benchmark corpora.", "labels": [], "entities": []}, {"text": "In both tasks, we perform 32-fold cross-topic cross-validation (one topic is test data, remaining 31 topics are training ones).", "labels": [], "entities": []}, {"text": "This rather  challenging setting ensures that no arguments are seen in both training and test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Values averaged over all 32 topics reported by different sampling strategies and scenarios for  argument graph building.", "labels": [], "entities": [{"text": "argument graph building", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.7033141652743021}]}, {"text": " Table 2: Properties of resulting gold data.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy results on UKPConvArgStrict  data. The difference between SVM and bi- directional LSTM is significant, p = 0.0414 using  two-tailed Wilcoxon signed-rank test.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990100860595703}, {"text": "UKPConvArgStrict  data", "start_pos": 30, "end_pos": 52, "type": "DATASET", "confidence": 0.9849799573421478}]}, {"text": " Table 4: Correlation results on UKPConvArg- Rank.", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9738969802856445}, {"text": "UKPConvArg- Rank", "start_pos": 33, "end_pos": 49, "type": "METRIC", "confidence": 0.6491673390070597}]}]}