{"title": [{"text": "Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction", "labels": [], "entities": [{"text": "Incremental Acquisition", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7519053518772125}, {"text": "Interaction", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.49214351177215576}]}], "abstractContent": [{"text": "As anew generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands and to learn new actions from human language instructions.", "labels": [], "entities": []}, {"text": "To address this issue, this paper presents an approach that explicitly represents verb semantics through hypothesis spaces of fluents and automatically acquires these hypothesis spaces by interacting with humans.", "labels": [], "entities": []}, {"text": "The learned hypothesis spaces can be used to automatically plan for lower-level primitive actions towards physical world interaction.", "labels": [], "entities": []}, {"text": "Our empirical results have shown that the representation of a hypothesis space of flu-ents, combined with the learned hypothesis selection algorithm, outperforms a previous baseline.", "labels": [], "entities": []}, {"text": "In addition, our approach applies incremental learning, which can contribute to lifelong learning from humans in the future.", "labels": [], "entities": []}], "introductionContent": [{"text": "As anew generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands and to learn new actions from human language instructions.", "labels": [], "entities": []}, {"text": "To achieve such a capability, one of the fundamental challenges is to link higher-level concepts expressed by human language to lower-level primitive actions the robot is familiar with.", "labels": [], "entities": []}, {"text": "While grounding language to perception; has received much attention in recent years, less work has addressed grounding language to robotic action.", "labels": [], "entities": []}, {"text": "Actions are often expressed by verbs or verb phrases.", "labels": [], "entities": []}, {"text": "Most semantic representations for verbs are based on argument frames (e.g., thematic roles which capture participants of an action).", "labels": [], "entities": []}, {"text": "For example, suppose a human directs a robot to \"fill the cup with milk\".", "labels": [], "entities": []}, {"text": "The robot will need to first create a semantic representation for the verb \"fill\" where \"the cup\" and \"milk\" are grounded to the respective objects in the environment ( . Suppose the robot is successful in this first step, it still may not be able to execute the action \"fill\" as it does not know how this higher-level action corresponds to its lower-level primitive actions.", "labels": [], "entities": []}, {"text": "In robotic systems, operations usually consist of multiple segments of lower-level primitive actions (e.g., move to, open gripper, and close gripper) which are executed both sequentially and concurrently.", "labels": [], "entities": []}, {"text": "Task scheduling provides the order or schedule for executions of different segments of actions and action planning provides the plan for executing each individual segment.", "labels": [], "entities": [{"text": "Task scheduling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7527557015419006}]}, {"text": "Primitive actions are often predefined in terms of how they change the state of the physical world.", "labels": [], "entities": []}, {"text": "Given a goal, task scheduling and action planning will derive a sequence of primitive actions that can change the initial environment to the goal state.", "labels": [], "entities": []}, {"text": "The goal state of the physical world becomes a driving force for robot actions.", "labels": [], "entities": []}, {"text": "Thus, beyond semantic frames, modeling verb semantics through their effects on the state of the world may provide a link to connect higher-level language and lowerlevel primitive actions.", "labels": [], "entities": []}, {"text": "Motivated by this perspective, we have developed an approach where each verb is explicitly represented by a hypothesis space of fluents (i.e., desired goal states) of the physical world, which is incrementally acquired and updated through interacting with humans.", "labels": [], "entities": []}, {"text": "More specifically, given a human command, if there is no knowledge about the corresponding verb (i.e., no existing hypothesis space for that verb), the robot will initiate a learning process by asking human partners to demonstrate the sequence of actions that is necessary to accomplish this command.", "labels": [], "entities": []}, {"text": "Based on this demonstration, a hypothesis space of fluents for that verb frame will be automatically acquired.", "labels": [], "entities": []}, {"text": "If there is an existing hypothesis space for the verb, the robot will select the best hypothesis that is most relevant to the current situation and plan for the sequence of lower-level actions.", "labels": [], "entities": []}, {"text": "Based on the outcome of the actions (e.g., whether it has successfully executed the command), the corresponding hypothesis space will be updated.", "labels": [], "entities": []}, {"text": "Through this fashion, a hypothesis space for each encountered verb frame is incrementally acquired and updated through continuous interactions with human partners.", "labels": [], "entities": []}, {"text": "In this paper, to focus our effort on representations and learning algorithms, we adopted an existing benchmark dataset ( to simulate the incremental learning process and interaction with humans.", "labels": [], "entities": []}, {"text": "Compared to previous works, our approach has three unique characteristics.", "labels": [], "entities": []}, {"text": "First, rather than a single goal state associated with a verb, our approach captures a space of hypotheses which can potentially account fora wider range of novel situations when the verb is applied.", "labels": [], "entities": []}, {"text": "Second, given anew situation, our approach can automatically identify the best hypothesis that fits the current situation and plan for lower-level actions accordingly.", "labels": [], "entities": []}, {"text": "Third, through incremental learning and acquisition, our approach has a potential to contribute to life-long learning from humans.", "labels": [], "entities": []}, {"text": "This paper provides details on the hypothesis space representation, the induction and inference algorithms, as well as experiments and evaluation results.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our approach, we applied the dataset made available by.", "labels": [], "entities": []}, {"text": "To support incremental learning, each utterance from every original paragraph is extracted so that each command/utterance only contains one verb and its arguments.", "labels": [], "entities": []}, {"text": "The corresponding initial environment and an action sequence Features on h k and current situation Ei 3.", "labels": [], "entities": []}, {"text": "Portion of fluents in h k that are already satisfied by Ei.", "labels": [], "entities": []}, {"text": "4. Portion of non-argument objects in h k . Examples of non-argument objects are o1 and o2 in.", "labels": [], "entities": []}, {"text": "Features on relations between a testing verb frame viand previous interaction experience 5.", "labels": [], "entities": []}, {"text": "Whether the same verb frame vi has been executed previously with the same argument objects.", "labels": [], "entities": []}, {"text": "6. Similarities between noun phrase descriptions used in current command and commands from interaction history.: Current features used for incremental learning of the regression model.", "labels": [], "entities": []}, {"text": "The first two are binary features and the rest are real-valued features.", "labels": [], "entities": []}, {"text": "taught by a human for each command are also extracted.", "labels": [], "entities": []}, {"text": "An example is shown in, where Li is a language command, E i is the initial working environment, and A i is a sequence of primitive actions to complete the command given by the human.", "labels": [], "entities": []}, {"text": "In the original data, some sentences are not aligned with any actions, and thus cannot be used for either the learning or the evaluation.", "labels": [], "entities": []}, {"text": "Removing these unaligned sentences resulted in a total of 991 data instances, including 165 different verb frames.", "labels": [], "entities": []}, {"text": "Among the 991 data instances, 793 were used for incremental learning (i.e., space induction and hypothesis selector learning).", "labels": [], "entities": []}, {"text": "Specifically, given a command, if the robot correctly predicts an action sequence 2 , this correct prediction is used to update the hypothesis selector.", "labels": [], "entities": []}, {"text": "Otherwise, the agent will require a correct action sequence from the human, which is used for hypothesis space induction as well as updating the hypothesis selector.", "labels": [], "entities": [{"text": "hypothesis space induction", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.6690223614374796}]}, {"text": "The hypothesis spaces and regression based selectors acquired at each run were evaluated on the other 20% (198) testing instances.", "labels": [], "entities": []}, {"text": "Specifically, for each testing instance, the induced space and the hypothesis selector were applied to identify a desired goal state.", "labels": [], "entities": []}, {"text": "Then a symbolic planner 3 was applied to predict an action sequence A (p) based on this predicted goal state.", "labels": [], "entities": []}, {"text": "We then compared A (p) with the ground truth action sequence A (g) using the following two metrics.", "labels": [], "entities": []}, {"text": "\u2022 IED (Instruction Edit Distance) measures similarity between the ground truth action sequence A (g) and the predicted sequence A (p) . Specifically, the edit distance d between two action sequences A (g) and ), such that IED ranges from 0 to 1 and a larger IED means the two sequences are more similar.", "labels": [], "entities": [{"text": "IED (Instruction Edit Distance)", "start_pos": 2, "end_pos": 33, "type": "METRIC", "confidence": 0.6976899107297262}, {"text": "IED", "start_pos": 222, "end_pos": 225, "type": "METRIC", "confidence": 0.9581013917922974}]}, {"text": "\u2022 SJI (State Jaccard Index).", "labels": [], "entities": [{"text": "State Jaccard Index)", "start_pos": 7, "end_pos": 27, "type": "DATASET", "confidence": 0.8239750117063522}]}, {"text": "Because different action sequences could lead to a same goal state, we also use Jaccard Index to check the overlap between the changed states.", "labels": [], "entities": [{"text": "Jaccard Index", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.6528948247432709}]}, {"text": "Specifically, executing the ground truth action sequence A (g) in the initial scene E i results in a final environment E i . Suppose the changed states between E i and E i is c (g) . For the predicted action sequence, we can calculate another set of changed states c (p) . The Jaccard Index between c (g) and c (p) is evaluated, which also ranges from 0 to 1 and a larger SJI means the predicted state changes are more similar to the ground truth.", "labels": [], "entities": [{"text": "SJI", "start_pos": 372, "end_pos": 375, "type": "METRIC", "confidence": 0.9906144142150879}]}, {"text": "We also compared the results of using the regression based selector to select a hypothesis (i.e., RegressionBased) with the following different strategies for selecting the hypothesis: \u2022 Misra2015: The state of the art system reported in () on the command/utterance level evaluation 4 . \u2022 MemoryBased: Given the induced space, only the base hypotheses h k s from each learning instances are used.", "labels": [], "entities": [{"text": "RegressionBased", "start_pos": 98, "end_pos": 113, "type": "METRIC", "confidence": 0.9474110007286072}]}, {"text": "Because these h k s don't have any relaxation, they represent purely learning from memorization.", "labels": [], "entities": []}, {"text": "\u2022 MostGeneral: In this case, only those hypotheses from the top level of the hypothesis space are used, which contain the least number of fluents.", "labels": [], "entities": [{"text": "MostGeneral", "start_pos": 2, "end_pos": 13, "type": "METRIC", "confidence": 0.9458482265472412}]}, {"text": "These nodes are the most relaxed hypotheses in the space.", "labels": [], "entities": []}, {"text": "\u2022 MostFrequent: In this setting, the hypotheses that are most frequently observed in the learning instances are used.", "labels": [], "entities": [{"text": "MostFrequent", "start_pos": 2, "end_pos": 14, "type": "METRIC", "confidence": 0.978434681892395}]}], "tableCaptions": []}