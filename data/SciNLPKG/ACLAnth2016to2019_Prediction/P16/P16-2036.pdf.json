{"title": [{"text": "Don't Count, Predict! An Automatic Approach to Learning Sentiment Lexicons for Short Text", "labels": [], "entities": [{"text": "Count", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.7128937840461731}]}], "abstractContent": [{"text": "We describe an efficient neural network method to automatically learn sentiment lexicons without relying on any manual resources.", "labels": [], "entities": [{"text": "learn sentiment lexicons", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.6216323375701904}]}, {"text": "The method takes inspiration from the NRC method, which gives the best results in SemEval13 by leveraging emoticons in large tweets, using the PMI between words and tweet sentiments to define the sentiment attributes of words.", "labels": [], "entities": [{"text": "NRC", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.8491814136505127}, {"text": "PMI", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.977362871170044}]}, {"text": "We show that better lexicons can be learned by using them to predict the tweet sentiment labels.", "labels": [], "entities": []}, {"text": "By using a very simple neu-ral network, our method is fast and can take advantage of the same data volume as the NRC method.", "labels": [], "entities": []}, {"text": "Experiments show that our lexicons give significantly better accuracies on multiple languages compared to the current best methods.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9579881429672241}]}], "introductionContent": [{"text": "Sentiment lexicons contain the sentiment polarity and/or the strength of words or phrases ().", "labels": [], "entities": []}, {"text": "They have been used for both rule-based) and unsupervised) or supervised () machine-learning-based sentiment analysis.", "labels": [], "entities": [{"text": "machine-learning-based sentiment analysis", "start_pos": 76, "end_pos": 117, "type": "TASK", "confidence": 0.699312150478363}]}, {"text": "As a result, constructing sentiment lexicons is one important research task in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.9450622200965881}]}, {"text": "Many approaches have been proposed to construct sentiment lexicons.", "labels": [], "entities": []}, {"text": "Traditional methods manually label the sentiment attributes of words (.", "labels": [], "entities": []}, {"text": "One benefit of such lexicons is high quality.", "labels": [], "entities": []}, {"text": "On the other hand, the methods are timeconsuming, requiring language and domain expertise.", "labels": [], "entities": []}, {"text": "Recently, statistical methods have been exploited to learn sentiment lexicons automatically (.", "labels": [], "entities": [{"text": "learn sentiment lexicons", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.6527446111043295}]}, {"text": "Such methods leverage knowledge resources or labeled sentiment data (), giving significantly better coverage compared to manual lexicons.", "labels": [], "entities": []}, {"text": "Among the automatic methods, proposed to use tweets with emoticons or hashtags as training data.", "labels": [], "entities": []}, {"text": "The main advantage is that such training data are abundant, and manual annotation can be avoided.", "labels": [], "entities": []}, {"text": "Despite that emoticons or hashtags can be noisy in indicating the sentiment of a tweet, existing research () has shown that effectiveness of such data when used to supervise sentiment classifiers.", "labels": [], "entities": [{"text": "supervise sentiment classifiers", "start_pos": 164, "end_pos": 195, "type": "TASK", "confidence": 0.6954989433288574}]}, {"text": "collect sentiment lexicons by calculating pointwise mutual information (PMI) between words and emoticons.", "labels": [], "entities": []}, {"text": "The resulting lexicons give the best results in a SemEval13 benchmark.", "labels": [], "entities": []}, {"text": "In this paper, we show that a better lexicon can be learned by directly optimizing the prediction accuracy, taking the lexicon as input and emoticon as the output.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9731901288032532}]}, {"text": "The correlation between our method and the method of is analogous to the \"predicting\" vs \"counting\" correlation between distributional and distributed word representations ().", "labels": [], "entities": []}, {"text": "We follow in using two simple attributes to represent each sentiment word, and take inspiration from in using a very simple neural network for sentiment prediction.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 143, "end_pos": 163, "type": "TASK", "confidence": 0.9522231817245483}]}, {"text": "The method can leverage the same data as and therefore benefits from both scale and annotation independence.", "labels": [], "entities": []}, {"text": "Experiments show that the neural model gives the best results on standard benchmarks across multiple languages.", "labels": [], "entities": []}, {"text": "Our code and lexicons are publicly available at https://github.com/duytinvo/acl2016.", "labels": [], "entities": []}], "datasetContent": [{"text": "Training data: To automatically obtain training data, we use the Twitter Developers API 1 to crawl emoticon tweets 2 of English and Arabic from February 2014 to September 2014.", "labels": [], "entities": []}, {"text": "We follow, removing all emoticons used to collect training data from the tweets, and, ignoring tweets which are less than 7 tokens.", "labels": [], "entities": []}, {"text": "A Twitter tokenizer) is applied to preprocess all tweets.", "labels": [], "entities": []}, {"text": "Rare words that occur less than 5 times in the vocabulary are removed.", "labels": [], "entities": []}, {"text": "HTTP links and username are replaced by http and user, respectively.", "labels": [], "entities": []}, {"text": "The statistics of training data is shown in.", "labels": [], "entities": []}, {"text": "Sentiment classifier: We use LibLinear as the supervised classifier on benchmark datasets.", "labels": [], "entities": [{"text": "Sentiment classifier", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8570205867290497}]}, {"text": "The parameter c is tuned by making a grid search () on the accuracy of development set on the English dataset and fivefold cross validation on the Arabic dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9993016719818115}, {"text": "English dataset", "start_pos": 94, "end_pos": 109, "type": "DATASET", "confidence": 0.9071621596813202}]}, {"text": "Evaluation: We follow  in employing precision (P), recall (R) and F1 score (F) to evaluate unsupervised classification.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.9579180181026459}, {"text": "recall (R)", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9591147601604462}, {"text": "F1 score (F)", "start_pos": 66, "end_pos": 78, "type": "METRIC", "confidence": 0.9832566738128662}]}, {"text": "We follow and use accuracy (acc), the tuning criterion, to evaluate supervised classification.", "labels": [], "entities": [{"text": "accuracy (acc)", "start_pos": 18, "end_pos": 32, "type": "METRIC", "confidence": 0.9255983084440231}, {"text": "supervised classification", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.6798074841499329}]}, {"text": "Code and lexicons: We make the Python implementation of our models and the resulting sentiment lexicons available at https://github.com/duytinvo/acl2016: Standard splits of ASTD.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the Semeval13.", "labels": [], "entities": []}, {"text": " Table 3: Results on SemEval13 (English).", "labels": [], "entities": []}, {"text": " Table 4: Standard splits of ASTD.", "labels": [], "entities": [{"text": "ASTD", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.7670777440071106}]}, {"text": " Table 4. We follow Nabil et al. (2015) by merg- ing training and validating data for learning model.  We compare our lexicon with only the lexicons of  NRC 7 (Salameh et al., 2015), because the meth- ods of Tang et al. (2014a) and Bravo-Marquez et  al. (2015) depend on manual resources, which are Lexicons  Balanced Unbalanced", "labels": [], "entities": [{"text": "NRC 7", "start_pos": 153, "end_pos": 158, "type": "DATASET", "confidence": 0.945916086435318}]}, {"text": " Table 6: Example sentiment scores, where  *  de- notes incorrect polarity.", "labels": [], "entities": []}]}