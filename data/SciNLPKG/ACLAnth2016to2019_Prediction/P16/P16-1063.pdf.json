{"title": [{"text": "Generative Topic Embedding: a Continuous Representation of Documents", "labels": [], "entities": [{"text": "Generative Topic Embedding", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6339979569117228}]}], "abstractContent": [{"text": "Word embedding maps words into a low-dimensional continuous embedding space by exploiting the local word collocation patterns in a small context window.", "labels": [], "entities": []}, {"text": "On the other hand, topic modeling maps documents onto a low-dimensional topic space, by utilizing the global word collocation patterns in the same document.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.922191709280014}]}, {"text": "These two types of patterns are complementary.", "labels": [], "entities": []}, {"text": "In this paper, we propose a generative topic embedding model to combine the two types of patterns.", "labels": [], "entities": [{"text": "generative topic embedding", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.8692991733551025}]}, {"text": "In our model, topics are represented by embedding vectors, and are shared across documents.", "labels": [], "entities": []}, {"text": "The probability of each word is influenced by both its local context and its topic.", "labels": [], "entities": []}, {"text": "A variational inference method yields the topic embed-dings as well as the topic mixing proportions for each document.", "labels": [], "entities": []}, {"text": "Jointly they represent the document in a low-dimensional continuous space.", "labels": [], "entities": []}, {"text": "In two document classification tasks, our method performs better than eight existing methods, with fewer features.", "labels": [], "entities": [{"text": "document classification", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.7741331160068512}]}, {"text": "In addition, we illustrate with an example that our method can generate coherent topics even based on only one document .", "labels": [], "entities": []}], "introductionContent": [{"text": "Representing documents as fixed-length feature vectors is important for many document processing algorithms.", "labels": [], "entities": []}, {"text": "Traditionally documents are represented as a bag-of-words (BOW) vectors.", "labels": [], "entities": []}, {"text": "However, this simple representation suffers from being high-dimensional and highly sparse, and loses semantic relatedness across the vector dimensions.", "labels": [], "entities": []}, {"text": "Word Embedding methods have been demonstrated to bean effective way to represent words as continuous vectors in a low-dimensional embedding space ().", "labels": [], "entities": []}, {"text": "The learned embedding fora word encodes its semantic/syntactic relatedness with other words, by utilizing local word collocation patterns.", "labels": [], "entities": []}, {"text": "In each method, one core component is the embedding link function, which predicts a word's distribution given its context words, parameterized by their embeddings.", "labels": [], "entities": []}, {"text": "When it comes to documents, we wish to find a method to encode their overall semantics.", "labels": [], "entities": []}, {"text": "Given the embeddings of each word in a document, we can imagine the document as a \"bag-of-vectors\".", "labels": [], "entities": []}, {"text": "Related words in the document point in similar directions, forming semantic clusters.", "labels": [], "entities": []}, {"text": "The centroid of a semantic cluster corresponds to the most representative embedding of this cluster of words, referred to as the semantic centroids.", "labels": [], "entities": []}, {"text": "We could use these semantic centroids and the number of words around them to represent a document.", "labels": [], "entities": []}, {"text": "In addition, fora set of documents in a particular domain, some semantic clusters may appear in many documents.", "labels": [], "entities": []}, {"text": "By learning collocation patterns across the documents, the derived semantic centroids could be more topical and less noisy.", "labels": [], "entities": []}, {"text": "Topic Models, represented by Latent Dirichlet Allocation (LDA) (, are able to group words into topics according to their collocation patterns across documents.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 29, "end_pos": 62, "type": "METRIC", "confidence": 0.825853705406189}]}, {"text": "When the corpus is large enough, such patterns reflect their semantic relatedness, hence topic models can discover coherent topics.", "labels": [], "entities": []}, {"text": "The probability of a word is governed by its latent topic, which is modeled as a categorical distribution in LDA.", "labels": [], "entities": []}, {"text": "Typically, only a small number of topics are present in each document, and only a small number of words have high probability in each topic.", "labels": [], "entities": []}, {"text": "This intuition motivated to regularize the topic distributions with Dirichlet priors.", "labels": [], "entities": []}, {"text": "Semantic centroids have the same nature as topics in LDA, except that the former exist in the embedding space.", "labels": [], "entities": []}, {"text": "This similarity drives us to seek the common semantic centroids with a model similar to LDA.", "labels": [], "entities": []}, {"text": "We extend a generative word embedding model PSDVec (, by incorporating topics into it.", "labels": [], "entities": []}, {"text": "The new model is named TopicVec.", "labels": [], "entities": []}, {"text": "In TopicVec, an embedding link function models the word distribution in a topic, in place of the categorical distribution in LDA.", "labels": [], "entities": []}, {"text": "The advantage of the link function is that the semantic relatedness is already encoded as the cosine distance in the embedding space.", "labels": [], "entities": []}, {"text": "Similar to LDA, we regularize the topic distributions with Dirichlet priors.", "labels": [], "entities": []}, {"text": "A variational inference algorithm is derived.", "labels": [], "entities": []}, {"text": "The learning process derives topic embeddings in the same embedding space of words.", "labels": [], "entities": []}, {"text": "These topic embeddings aim to approximate the underlying semantic centroids.", "labels": [], "entities": []}, {"text": "To evaluate how well TopicVec represents documents, we performed two document classification tasks against eight existing topic modeling or document representation methods.", "labels": [], "entities": [{"text": "document classification", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.7193953990936279}, {"text": "topic modeling or document representation", "start_pos": 122, "end_pos": 163, "type": "TASK", "confidence": 0.6513920187950134}]}, {"text": "Two setups of TopicVec outperformed all other methods on two tasks, respectively, with fewer features.", "labels": [], "entities": []}, {"text": "In addition, we demonstrate that TopicVec can derive coherent topics based only on one document, which is not possible for topic models.", "labels": [], "entities": []}, {"text": "The source code of our implementation is available at https://github.com/askerlee/topicvec.", "labels": [], "entities": []}, {"text": "proposed a generative word embedding method PSDVec, which is the precursor of TopicVec.", "labels": [], "entities": []}, {"text": "PSDVec assumes that the conditional distribution of a word given its context words can be factorized approximately into independent log-bilinear terms.", "labels": [], "entities": []}, {"text": "In addition, the word embeddings and regression residuals are regularized by Gaussian priors, reducing their chance of overfitting.", "labels": [], "entities": []}, {"text": "The model inference is approached by an efficient Eigendecomposition and blockwiseregression method ().", "labels": [], "entities": []}, {"text": "TopicVec differs from PSDVec in that in the conditional distribution of a word, it is not only influenced by its context words, but also by a topic, which is an embedding vector indexed by a latent variable drawn from a Dirichlet-Multinomial distribution.", "labels": [], "entities": []}, {"text": "proposed to model topics as a certain number of binary hidden variables, which interact with all words in the document through weighted connections.", "labels": [], "entities": []}, {"text": "Larochelle and Lauly (2012) assigned each word a unique topic vector, which is a summarization of the context of the current word.", "labels": [], "entities": []}, {"text": "proposed to incorporate global (document-level) semantic information to help the learning of word embeddings.", "labels": [], "entities": []}, {"text": "The global embedding is simply a weighted average of the embeddings of words in the document.", "labels": [], "entities": []}, {"text": "It assumes each piece of text has a latent paragraph vector, which influences the distributions of all words in this text, in the same way as a latent word.", "labels": [], "entities": []}, {"text": "It can be viewed as a special case of TopicVec, with the topic number set to 1.", "labels": [], "entities": []}, {"text": "Typically, however, a document consists of multiple semantic centroids, and the limitation of only one topic may lead to underfitting.", "labels": [], "entities": []}, {"text": "proposed Latent Feature Topic Modeling (LFTM), which extends LDA to incorporate word embeddings as latent features.", "labels": [], "entities": [{"text": "Latent Feature Topic Modeling (LFTM)", "start_pos": 9, "end_pos": 45, "type": "TASK", "confidence": 0.7321699133941105}]}, {"text": "The topic is modeled as a mixture of the conventional categorical distribution and an embedding link function.", "labels": [], "entities": []}, {"text": "The coupling between these two components makes the inference difficult.", "labels": [], "entities": []}, {"text": "They designed a Gibbs sampler for model inference.", "labels": [], "entities": [{"text": "model inference", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7554542720317841}]}, {"text": "Their implementation 1 is slow and infeasible when applied to a large corpous.", "labels": [], "entities": []}, {"text": "proposed Topical Word Embedding (TWE), which combines word embedding with LDA in a simple and effective way.", "labels": [], "entities": [{"text": "Topical Word Embedding (TWE)", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.740658238530159}]}, {"text": "They train word embeddings and a topic model separately on the same corpus, and then average the embeddings of words in the same topic to get the embedding of this topic.", "labels": [], "entities": []}, {"text": "The topic embedding is concatenated with the word embedding to form the topical word embedding of a word.", "labels": [], "entities": []}, {"text": "In the end, the topical word embeddings of all words in a document are averaged to be the embedding of the document.", "labels": [], "entities": []}, {"text": "This method performs well on our two classification tasks.", "labels": [], "entities": []}, {"text": "Weaknesses of TWE include: 1) the way to combine the results of word embedding and LDA lacks statistical foundations; 2) the LDA module requires a large corpus to derive semantically coherent topics.", "labels": [], "entities": []}], "datasetContent": [{"text": "To investigate the quality of document representation of our TopicVec model, we compared its performance against eight topic modeling or document representation methods in two document classification tasks.", "labels": [], "entities": [{"text": "document classification", "start_pos": 176, "end_pos": 199, "type": "TASK", "confidence": 0.7172458171844482}]}, {"text": "Moreover, to show the topic coherence of TopicVec on a single document, we present the top words in top topics learned on a news article.", "labels": [], "entities": []}, {"text": "Compared Methods Two setups of TopicVec were evaluated: \u2022 TopicVec: the topic proportions learned by TopicVec; \u2022 TV+WV: the topic proportions, concatenated with the mean word embedding of the document (same as the MeanWV below).", "labels": [], "entities": [{"text": "MeanWV", "start_pos": 214, "end_pos": 220, "type": "DATASET", "confidence": 0.9206207394599915}]}, {"text": "We compare the performance of our methods against eight methods, including three topic modeling methods, three continuous document representation methods, and the conventional bag-ofwords (BOW) method.", "labels": [], "entities": []}, {"text": "The count vector of BOW is unweighted.", "labels": [], "entities": [{"text": "count vector", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9689538776874542}, {"text": "BOW", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.8704291582107544}]}, {"text": "The topic modeling methods include: \u2022 LDA: the vanilla LDA () in the gensim library 3 ; \u2022 sLDA: Supervised Topic Model, which improves the predictive performance of LDA by modeling class labels; \u2022 LFTM: Latent Feature Topic Modeling ().", "labels": [], "entities": [{"text": "Latent Feature Topic Modeling", "start_pos": 203, "end_pos": 232, "type": "TASK", "confidence": 0.5496241003274918}]}, {"text": "The document-topic proportions of topic modeling methods were used as their document representation.", "labels": [], "entities": []}, {"text": "The document representation methods are: \u2022 Doc2Vec: Paragraph Vector () in the gensim library 6 . \u2022 TWE: Topical Word Embedding 7 (, which represents a document by concatenating average topic embedding and average word embedding, similar to our TV+WV; \u2022 GaussianLDA: Gaussian LDA 8 (, which assumes that words in a topic are random samples from a multivariate Gaussian distribution with the mean as the topic embedding.", "labels": [], "entities": [{"text": "TWE", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9413201212882996}]}, {"text": "Similar to TopicVec, we derived the posterior topic proportions as the features of each document; \u2022 MeanWV: The mean word embedding of the document.", "labels": [], "entities": [{"text": "MeanWV", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.937248170375824}]}, {"text": "Datasets We used two standard document classification corpora: the 20 Newsgroups 9 and the ApteMod version of the Reuters-21578 corpus . The two corpora are referred to as the 20News and Reuters in the following.", "labels": [], "entities": [{"text": "20 Newsgroups 9", "start_pos": 67, "end_pos": 82, "type": "DATASET", "confidence": 0.7514375249544779}, {"text": "Reuters-21578 corpus", "start_pos": 114, "end_pos": 134, "type": "DATASET", "confidence": 0.896369606256485}, {"text": "Reuters", "start_pos": 187, "end_pos": 194, "type": "DATASET", "confidence": 0.9386429786682129}]}, {"text": "20News contains about 20,000 newsgroup documents evenly partitioned into 20 different categories.", "labels": [], "entities": []}, {"text": "Reuters contains 10,788 documents, where each document is assigned to one or more categories.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9694599509239197}]}, {"text": "For the evaluation of document classification, documents appearing in two or more categories were removed.", "labels": [], "entities": [{"text": "document classification", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.6966331303119659}]}, {"text": "The numbers of documents in the categories of Reuters are highly imbalanced, and we only selected the largest 10 categories, leaving us with 8,025 documents in total.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.8469094038009644}]}, {"text": "The same preprocessing steps were applied to all methods: words were lowercased; stop words and words out of the word embedding vocabulary (which means that they are extremely rare) were removed.", "labels": [], "entities": []}, {"text": "Experimental Settings TopicVec used the word embeddings trained using PSDVec on a March 2015 Wikipedia snapshot.", "labels": [], "entities": []}, {"text": "It contains the most frequent 180,000 words.", "labels": [], "entities": []}, {"text": "The dimensionality of word embeddings and topic embeddings was 500.", "labels": [], "entities": []}, {"text": "The hyperparameters were \u03b1 = (0.1, \u00b7 \u00b7 \u00b7 , 0.1), \u03b3 = 5.", "labels": [], "entities": []}, {"text": "For 20news and Reuters, we specified 15 and 12 topics in each category on the training set, respectively.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.8255335688591003}]}, {"text": "The first topic in each category was always set to null.", "labels": [], "entities": []}, {"text": "The learned topic embeddings were combined to form the whole topic set, where redundant null topics in different categories were removed, leaving us with 281 topics for 20News and 111 topics for Reuters.", "labels": [], "entities": [{"text": "20News", "start_pos": 169, "end_pos": 175, "type": "DATASET", "confidence": 0.9758996367454529}, {"text": "Reuters", "start_pos": 195, "end_pos": 202, "type": "DATASET", "confidence": 0.969273567199707}]}, {"text": "The initial learning rate was set to 0.1.", "labels": [], "entities": []}, {"text": "After 100 GEM iterations on each dataset, the topic embeddings were obtained.", "labels": [], "entities": []}, {"text": "Then the posterior document-topic distributions of the test sets were derived by performing one E-step given the topic embeddings trained on the training set.", "labels": [], "entities": []}, {"text": "LFTM includes two models: LF-LDA and LF-DMM.", "labels": [], "entities": [{"text": "LFTM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9318149089813232}]}, {"text": "We chose the better performing LF-LDA to evaluate.", "labels": [], "entities": []}, {"text": "TWE includes three models, and we chose the best performing TWE-1 to compare.", "labels": [], "entities": [{"text": "TWE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9854441285133362}, {"text": "TWE-1", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.9693138599395752}]}, {"text": "LDA, sLDA, LFTM and TWE used the specified 50 topics on Reuters, as this is the optimal topic number according to).", "labels": [], "entities": [{"text": "LDA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9713070392608643}, {"text": "LFTM", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.8936336636543274}, {"text": "TWE", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.9251933693885803}, {"text": "Reuters", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.966433584690094}]}, {"text": "On the larger 20news dataset, they used the specified 100 topics.", "labels": [], "entities": [{"text": "20news dataset", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.968549907207489}]}, {"text": "Other hyperparameters of all compared methods were left at their default values.", "labels": [], "entities": []}, {"text": "GaussianLDA was specified 100 topics on 20news and 70 topics on Reuters.", "labels": [], "entities": [{"text": "GaussianLDA", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.82915198802948}, {"text": "20news", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.9695139527320862}, {"text": "Reuters", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9831821918487549}]}, {"text": "As each sampling iteration took over 2 hours, we only had time for 100 sampling iterations.", "labels": [], "entities": []}, {"text": "For each method, after obtaining the document representations of the training and test sets, we trained an -1 regularized linear SVM one-vs-all classifier on the training set using the scikit-learn library . We then evaluated its predictive performance on the test set.", "labels": [], "entities": []}, {"text": "Evaluation metrics Considering that the largest few categories dominate Reuters, we adopted macro-averaged precision, recall and F1 measures as the evaluation metrics, to avoid the average results being dominated by the performance of the 11 http://scikit-learn.org/stable/modules/svm.html   top categories.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.966042160987854}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9393409490585327}, {"text": "recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9981750249862671}, {"text": "F1", "start_pos": 129, "end_pos": 131, "type": "METRIC", "confidence": 0.9980321526527405}]}, {"text": "presents the performance of the different methods on the two classification tasks.", "labels": [], "entities": []}, {"text": "The highest scores were highlighted with boldface.", "labels": [], "entities": []}, {"text": "It can be seen that TV+WV and TopicVec obtained the best performance on the two tasks, respectively.", "labels": [], "entities": [{"text": "TV+WV", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.9336171746253967}]}, {"text": "With only topic proportions as features, TopicVec performed slightly better than BOW, MeanWV and TWE, and significantly outperformed four other methods.", "labels": [], "entities": [{"text": "BOW", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.938265860080719}, {"text": "MeanWV", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.5711858868598938}]}, {"text": "The number of features it used was much lower than BOW, MeanWV and TWE.", "labels": [], "entities": [{"text": "BOW", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8069241046905518}, {"text": "MeanWV", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.5346348285675049}, {"text": "TWE", "start_pos": 67, "end_pos": 70, "type": "DATASET", "confidence": 0.6646748185157776}]}, {"text": "GaussianLDA performed considerably inferior to all other methods.", "labels": [], "entities": []}, {"text": "After checking the generated topic embeddings manually, we found that the embeddings for different topics are highly similar to each other.", "labels": [], "entities": []}, {"text": "Hence the posterior topic proportions were almost uniform and non-discriminative.", "labels": [], "entities": []}, {"text": "In addition, on the two datasets, even the fastest Alias sampling in () took over 2 hours for one iteration and 10 days for the whole 100 iterations.", "labels": [], "entities": []}, {"text": "In contrast, our method finished the 100 EM iterations in 2 hours.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance on multi-class text classifi- cation. Best score is in boldface.", "labels": [], "entities": []}, {"text": " Table 3: Number of features of the five best per- forming methods.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9540929794311523}]}]}