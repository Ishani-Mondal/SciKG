{"title": [{"text": "A Novel Measure for Coherence in Statistical Topic Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Big data presents new challenges for understanding large text corpora.", "labels": [], "entities": []}, {"text": "Topic mod-eling algorithms help understand the underlying patterns, or \"topics\", in data.", "labels": [], "entities": []}, {"text": "Re-searchersauthor often read these topics in order to gain an understanding of the underlying corpus.", "labels": [], "entities": []}, {"text": "It is important to evaluate the interpretability of these automatically generated topics.", "labels": [], "entities": []}, {"text": "Methods have previously been designed to use crowdsourcing platforms to measure interpretability.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate the necessity of a key concept, coherence, when assessing the topics and propose an effective method for its measurement.", "labels": [], "entities": []}, {"text": "We show that the proposed measure of coherence captures a different aspect of the topics than existing measures.", "labels": [], "entities": []}, {"text": "We further study the automation of these topic measures for scalabil-ity and reproducibility, showing that these measures can be automated.", "labels": [], "entities": [{"text": "automation", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9717578291893005}]}], "introductionContent": [{"text": "Big data poses new challenges in analyzing text corpora.", "labels": [], "entities": []}, {"text": "Topic modeling algorithms have recently grown to popularity for their ability to help discover the underlying topics in a corpus.", "labels": [], "entities": [{"text": "Topic modeling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8039804995059967}]}, {"text": "Topic words are the words selected to represent a topic.", "labels": [], "entities": []}, {"text": "They have been shown to be useful in the areas of machine learning, text analysis, and social media analysis), among others.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 68, "end_pos": 81, "type": "TASK", "confidence": 0.8553410768508911}, {"text": "social media analysis", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.6954793135325114}]}, {"text": "Topic models can be used as predictive models to classify new documents in the context of the training corpus.", "labels": [], "entities": []}, {"text": "They are evaluated by measuring their predictive performance on a held-out set of documents.", "labels": [], "entities": []}, {"text": "Topic models can also be inspected manually by a human to understand the themes of the underlying corpus.", "labels": [], "entities": []}, {"text": "A widely adopted way is suggested by: it measures the quality of a topic by inspecting how far topic words are from some random words.", "labels": [], "entities": []}, {"text": "The idea is that the quality of a topic can be measured by how far topic words are from some random words.", "labels": [], "entities": []}, {"text": "In other words, if human evaluators can consistently separate random words from topic words, these topics are good, otherwise, they are not good.", "labels": [], "entities": []}, {"text": "An advantage of this measure is that it can be easily implemented to deploy on a crowd-sourcing platform like Amazon's Mechanical Turk.", "labels": [], "entities": []}, {"text": "Assuming that random words represent random topics, we can name the above method \"betweentopic\" measure.", "labels": [], "entities": []}, {"text": "In this paper, we hypothesize that this measure considers just one important aspect in assessing the quality of statistical topics.", "labels": [], "entities": []}, {"text": "Specifically, we investigate the topic interpretability by examining the \"coherence\" of a topic generated by topic modeling algorithms, i.e., how close topic words are within a topic.", "labels": [], "entities": []}, {"text": "Thus, this measure is a \"within-topic\" measure.", "labels": [], "entities": []}, {"text": "Two immediate challenging questions are: (1) without knowing ground truth of topic coherence, how can we design an equally effective method like \"betweentopic\" measure for crowd-sourcing evaluation? and (2) how different is this \"within-topic\" coherence measure from the existing \"between-topic\" measure?", "labels": [], "entities": []}, {"text": "We elaborate how we answer these two challenges by starting with some related work, showing how the \"between-topic\" measure faces difficulty in measuring coherence, and presenting our proposal of a coherence measure.", "labels": [], "entities": []}], "datasetContent": [{"text": "To perform this experiment, we inject one lowprobability word for each topic, and we ask the Turkers to select two words that do not fit within the group.", "labels": [], "entities": []}, {"text": "We show the six words to the Turker in random order with the following prompt: You will be shown six words.", "labels": [], "entities": []}, {"text": "Four words belong together, and two of them do not.", "labels": [], "entities": []}, {"text": "Choose two words that do not belong in the group.", "labels": [], "entities": []}, {"text": "Coherent topics will cause the Turkers' responses regarding the second intruded word to be unpredictable.", "labels": [], "entities": []}, {"text": "Thus, our measure of the goodness of the topic should be the predictability of the Turkers' second choice.", "labels": [], "entities": [{"text": "Turkers'", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8569755554199219}]}, {"text": "We propose anew measure called \"Model Precision Choose Two\" to measure this.", "labels": [], "entities": []}, {"text": "Model Precision Choose Two (MPCT) measures this spread as the peakedness of the probability distribution.", "labels": [], "entities": []}, {"text": "We define MP CT m k for topic k on model m as: The intuition behind choosing entropy is that it will measure the unpredictability in the Turker selections.", "labels": [], "entities": []}, {"text": "That is, if the Turkers are confused about which second word to choose, then their answers will be scattered amongst the remaining five words.", "labels": [], "entities": []}, {"text": "As a result, the entropy will be high.", "labels": [], "entities": [{"text": "entropy", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9240321516990662}]}, {"text": "Conversely, if the second word is obvious, the Turkers will begin to congregate around that second choice, meaning that their answers will be focused.", "labels": [], "entities": []}, {"text": "As a result, the entropy will below.", "labels": [], "entities": [{"text": "entropy", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.982377290725708}]}, {"text": "Because entropy is able to measure the confusion of the Turkers responses about the second word, we use it directly in the design of our measure.", "labels": [], "entities": []}, {"text": "The results of this experiment, aggregated by model, are shown in.", "labels": [], "entities": []}, {"text": "We see that as the value of K increases, the median score for MPCT stays roughly the same.", "labels": [], "entities": [{"text": "MPCT", "start_pos": 62, "end_pos": 66, "type": "TASK", "confidence": 0.7460862398147583}]}, {"text": "We compute the Spearman's \u03c1 correlation coefficient between the MP and MP CT measures, and find that the measures have \u03c1 = 0.09.", "labels": [], "entities": [{"text": "Spearman's \u03c1 correlation coefficient", "start_pos": 15, "end_pos": 51, "type": "METRIC", "confidence": 0.7618405640125274}]}, {"text": "This lack of correlation indicates that this measure is assessing a different dimension of the topics.", "labels": [], "entities": []}, {"text": "To help explain these results, we provide some examples of topics that received different MPCT scores with a perfect separateness (MP) score in.", "labels": [], "entities": [{"text": "perfect separateness (MP) score", "start_pos": 109, "end_pos": 140, "type": "METRIC", "confidence": 0.8804100354512533}]}, {"text": "We see that although all of the topics have perfect scores along this dimension, their cohesiveness score varies.", "labels": [], "entities": []}, {"text": "This is due to the Turkers' agreement about the second intruded word.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example topics showing the variance of  M P CT when M P = 1.0.", "labels": [], "entities": [{"text": "variance of  M P CT", "start_pos": 37, "end_pos": 56, "type": "METRIC", "confidence": 0.6315902888774871}]}, {"text": " Table 2: Performance of automated measures in  approximating the crowdsourced experiments. All  values are Spearman's \u03c1 correlation coefficients  with the crowdsourced measure.", "labels": [], "entities": []}]}