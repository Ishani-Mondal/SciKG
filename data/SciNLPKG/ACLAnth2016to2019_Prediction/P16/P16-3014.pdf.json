{"title": [], "abstractContent": [{"text": "The computing cost of many NLP tasks increases faster than linearly with the length of the representation of a sentence.", "labels": [], "entities": []}, {"text": "For parsing the representation is tokens, while for operations on syntax and semantics it will be more complex.", "labels": [], "entities": []}, {"text": "In this paper we propose anew task of sentence chunking: splitting sentence representations into coherent substructures.", "labels": [], "entities": [{"text": "sentence chunking", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7374455332756042}]}, {"text": "Its aim is to make further processing of long sentences more tractable.", "labels": [], "entities": []}, {"text": "We investigate this idea experimentally using the Dependency Minimal Recursion Semantics (DMRS) representation .", "labels": [], "entities": [{"text": "Dependency Minimal Recursion Semantics (DMRS)", "start_pos": 50, "end_pos": 95, "type": "TASK", "confidence": 0.7310618885925838}]}], "introductionContent": [{"text": "Long sentences pose a challenge in many Natural Language Processing (NLP) tasks, such as parsing or translation.", "labels": [], "entities": [{"text": "parsing or translation", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.6285976966222128}]}, {"text": "We propose chunking as away of making such sentences more tractable before further processing.", "labels": [], "entities": [{"text": "chunking", "start_pos": 11, "end_pos": 19, "type": "TASK", "confidence": 0.9678024649620056}]}, {"text": "Chunking a sentence means cutting a complex sentence into grammatical constituents that can be processed independently and then recombined without loss of information.", "labels": [], "entities": []}, {"text": "Such an operation can be defined both on the surface string of a sentence and on its semantic representation, and is applicable to a wide range of tasks.", "labels": [], "entities": []}, {"text": "Some approaches to parsing have space and time requirements which are much worse than linear in sentence length.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9699897170066833}]}, {"text": "This can lead to practical difficulties in processing.", "labels": [], "entities": []}, {"text": "For example, the ACE processor 1 running the English Resource Grammar (ERG)) requires roughly 530 MB of RAM to parse Sentence 1.", "labels": [], "entities": [{"text": "parse Sentence 1", "start_pos": 111, "end_pos": 127, "type": "TASK", "confidence": 0.8222058812777201}]}, {"text": "In fact, longer and more complicated sen-tences can cause the parser to timeout or run out of memory before a solution is found.", "labels": [], "entities": []}, {"text": "(1) Marcellina has hired Bartolo as her counsel, since Figaro had once promised to marry her if he should default on a loan she had made to him, and she intends to enforce that promise.", "labels": [], "entities": []}, {"text": "Chunking would make processing of long sentences more tractable.", "labels": [], "entities": [{"text": "processing of long sentences", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.818105012178421}]}, {"text": "For example, we aim to split sentences like Sentence 1 into chunks 2a-d. c. He should default on a loan she made to him. d. She intends to enforce that promise.", "labels": [], "entities": []}, {"text": "Each of these shorter sentences can be parsed with less than 20 MB, requiring in total less than a fifth of RAM needed to parse the full sentence.", "labels": [], "entities": [{"text": "RAM", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9731568098068237}]}, {"text": "What exactly constitutes a valid chunk has to be considered in the context of the task which we want to simplify by chunking.", "labels": [], "entities": []}, {"text": "In this sense a potentially useful analogy could be made to the use of factoids in summarisation ().", "labels": [], "entities": [{"text": "summarisation", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.9448370337486267}]}, {"text": "However, we can make some general assumptions about the nature of 'good' chunks.", "labels": [], "entities": []}, {"text": "They have to be semantically and grammatically self-contained parts of the larger sentence.", "labels": [], "entities": []}, {"text": "Sentence chunking resembles clause splitting as defined by the CoNLL-2001 shared task ().", "labels": [], "entities": [{"text": "Sentence chunking", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9360364973545074}, {"text": "clause splitting", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.8007548749446869}]}, {"text": "Each of the chunks a-d is a finite clause, although each consists of multiple smaller clauses.", "labels": [], "entities": []}, {"text": "This points to a crucial difference between sentence chunking and clause splitting which justifies treating them as separate tasks.", "labels": [], "entities": [{"text": "sentence chunking", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7305113077163696}, {"text": "clause splitting", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.7463889569044113}]}, {"text": "We define chunking in terms of its purpose as a pre-processing step and because of that it is more restrictive.", "labels": [], "entities": []}, {"text": "Not every clause boundary is a chunk boundary.", "labels": [], "entities": []}, {"text": "A key aspect of sentence chunking is deciding whereto place a chunk border so that the resulting chunks can be processed and recombined without loss of information.", "labels": [], "entities": [{"text": "sentence chunking", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7191160917282104}]}, {"text": "Another difference between sentence chunking and clause splitting is the domain of the task.", "labels": [], "entities": [{"text": "sentence chunking", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7363486588001251}, {"text": "clause splitting", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7399490773677826}]}, {"text": "Clause splitting is performed on the surface string of a sentence, while we can define chunking not only on the surface representation but also on more complex ones, such a graph-based semantic representation.", "labels": [], "entities": []}, {"text": "There are two reasons why chunking a semantic representation is a good idea: 1.", "labels": [], "entities": [{"text": "chunking a semantic representation", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.8483266234397888}]}, {"text": "Many operations on graphs have worse than linear complexity, some types of graph matching are NP-complete.", "labels": [], "entities": [{"text": "graph matching", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7850778102874756}]}, {"text": "Chunking semantic representations can make their manipulation more tractable (Section 1.1).", "labels": [], "entities": []}, {"text": "2. Such a form of chunking, apart from being useful in its own right, can also help chunking surface sentences (Section 1.2).", "labels": [], "entities": [{"text": "chunking surface sentences", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.8967700600624084}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the DMRS-based chunking algorithm and the baseline on the WikiWoods and  WeScience datasets. Precision is the percentage of attempted sentences which were chunked correctly,  while Correct and Incorrect columns give absolute numbers of correctly and incorrectly chunked sen- tences. Attempted column is the percentage of sentences for which a chunking opportunity was found  and attempted.", "labels": [], "entities": [{"text": "DMRS-based chunking", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.6211525052785873}, {"text": "WeScience datasets", "start_pos": 98, "end_pos": 116, "type": "DATASET", "confidence": 0.8998792171478271}, {"text": "Precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9938814640045166}]}]}