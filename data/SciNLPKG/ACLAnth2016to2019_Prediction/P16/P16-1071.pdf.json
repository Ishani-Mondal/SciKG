{"title": [{"text": "Extracting token-level signals of syntactic processing from fMRI -with an application to PoS induction", "labels": [], "entities": []}], "abstractContent": [{"text": "Neuro-imaging studies on reading different parts of speech (PoS) report somewhat mixed results, yet some of them indicate different activations with different PoS.", "labels": [], "entities": []}, {"text": "This paper addresses the difficulty of using fMRI to discriminate between linguistic tokens in reading of running text because of low temporal resolution.", "labels": [], "entities": []}, {"text": "We show that once we solve this problem, fMRI data contains a signal of PoS distinctions to the extent that it improves PoS induction with error reductions of more than 4%.", "labels": [], "entities": [{"text": "fMRI data", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.8300870656967163}, {"text": "PoS induction", "start_pos": 120, "end_pos": 133, "type": "TASK", "confidence": 0.46255674958229065}, {"text": "error reductions", "start_pos": 139, "end_pos": 155, "type": "METRIC", "confidence": 0.9484552443027496}]}], "introductionContent": [{"text": "A few recent studies have tried to extract morphosyntactic signals from measurements of human sentence processing and used this information to improve NLP models., for example, used eye-tracking recordings to regularize a sentence compression model.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 222, "end_pos": 242, "type": "TASK", "confidence": 0.7067371010780334}]}, {"text": "More related to this work, recently used eyetracking recordings to induce PoS models.", "labels": [], "entities": []}, {"text": "However, a weakness of eye-tracking data is that while eye movement surely does reflect the temporal aspect of cognitive processing, it is only a proxy of the latter and does not directly represent which processes take place in the brain.", "labels": [], "entities": []}, {"text": "A recent neuro-imaging study suggests that concrete nouns and verbs elicit different brain signatures in the frontocentral cortex, and that concrete and abstract nouns elicit different brain activation patterns).", "labels": [], "entities": []}, {"text": "Also, for example, concrete verbs activate motor and premotor cortex more strongly than concrete nouns, and concrete nouns activate inferior frontal areas more strongly than concrete verbs.", "labels": [], "entities": []}, {"text": "A decade earlier, showed that the left inferior frontal gyrus was more strongly activated in processing regularly inflected verbs compared to regularly inflected nouns.", "labels": [], "entities": []}, {"text": "Such studies suggest that different parts of our brains are activated when reading different parts of speech (PoS).", "labels": [], "entities": []}, {"text": "This would in turn mean that neuro-images of readers carry information about the grammatical structure of what they read.", "labels": [], "entities": []}, {"text": "In other words, neuro-imaging provides a partial, noisy annotation of the data with respect to morphosyntactic category.", "labels": [], "entities": []}, {"text": "Say neuro-imaging data of readers was readily available.", "labels": [], "entities": []}, {"text": "Would it be of any use to, for example, engineers interested in PoS taggers for lowresource languages?", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.7472962439060211}]}, {"text": "This is far from obvious.", "labels": [], "entities": []}, {"text": "In fact, it is well-known that neuro-imaging data from reading is noisy, in part because the reading signal is not always very distinguishable), and also because the content of what we read may elicit certain activation in brain regions e.g. related to sensory processing ().", "labels": [], "entities": []}, {"text": "Other researchers such as have also questioned that there are differences, claiming to show that the majority of activation is shared between nouns and verbs -including in regions suggested by previous researchers as unique to either nouns or verbs.", "labels": [], "entities": []}, {"text": "argue that only verbs could be associated with unique regions, not nouns.", "labels": [], "entities": []}, {"text": "In this paper we nevertheless explore this question.", "labels": [], "entities": []}, {"text": "The paper should be seen as a proof of concept that interesting linguistic signals can be extracted from brain imaging data, and an attempt to show that learning NLP models from such data could be away of pushing the boundaries of both fields.", "labels": [], "entities": []}, {"text": "Contributions (a) We present a novel technique for extracting syntactic processing signal at the token level from neuro-imaging data that is charac-: Neural activity by brain region and type of information processed, as measured and rendered by. terized by low temporal resolution.", "labels": [], "entities": []}, {"text": "(b) We demonstrate that the fMRI data improves performance of a type-constrained, second order hidden Markov model for PoS induction.", "labels": [], "entities": [{"text": "fMRI data", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8612253069877625}, {"text": "PoS induction", "start_pos": 119, "end_pos": 132, "type": "TASK", "confidence": 0.8583534955978394}]}, {"text": "Our model leads to an error reduction of more than 4% in tagging accuracy despite very little training data, which to the best of our knowledge is the first positive result on weakly supervised part-of-speech induction from fMRI data in the literature.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 22, "end_pos": 37, "type": "METRIC", "confidence": 0.9648792445659637}, {"text": "tagging", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.9556512236595154}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.94211745262146}, {"text": "part-of-speech induction", "start_pos": 194, "end_pos": 218, "type": "TASK", "confidence": 0.6879711896181107}]}], "datasetContent": [{"text": "Experimental setup From the neuro-imaging dataset described above, we use 41 sentences (720 tokens) as a development set and 41 sentences (529 tokens) as a test set, and the remaining 326 sentences (corresponding to 80%) for training our model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Tagging accuracy on test data for the dif- ferent models. The fMRI model is significantly  better than the baseline (p = 0.014, Bootstrap).", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9815292358398438}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9831404089927673}, {"text": "fMRI", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.7718546390533447}, {"text": "Bootstrap", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9799010157585144}]}, {"text": " Table 2: Test data tagging performance by part-of- speech class for the best fMRI model. The right- most column displays the difference in F 1 com- pared to the baseline model.", "labels": [], "entities": [{"text": "F 1 com- pared", "start_pos": 140, "end_pos": 154, "type": "METRIC", "confidence": 0.9342284440994263}]}]}