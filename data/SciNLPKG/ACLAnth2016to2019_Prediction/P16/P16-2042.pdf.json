{"title": [{"text": "Automatic Semantic Classification of German Preposition Types: Comparing Hard and Soft Clustering Approaches across Features", "labels": [], "entities": [{"text": "Semantic Classification of German Preposition Types", "start_pos": 10, "end_pos": 61, "type": "TASK", "confidence": 0.8194290300210317}, {"text": "Approaches", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.9751752018928528}]}], "abstractContent": [{"text": "This paper addresses an automatic classification of preposition types in Ger-man, comparing hard and soft clustering approaches and various window-and syntax-based co-occurrence features.", "labels": [], "entities": []}, {"text": "We show that (i) the semantically most salient preposition features (i.e., subcategor-ised nouns) are the most successful, and that (ii) soft clustering approaches are required for the task but reveal quite different attitudes towards predicting ambiguity.", "labels": [], "entities": [{"text": "predicting ambiguity", "start_pos": 235, "end_pos": 255, "type": "TASK", "confidence": 0.8835179507732391}]}], "introductionContent": [{"text": "In the last decades, an impressive number of semantic classifications has been developed, both regarding manual lexicographic and/or cognitive classifications such as WordNet, VerbNet (Kipper) and PrepNet/The Preposition Project (), as well as regarding computational classifications for nouns), verbs) and adjectives (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 167, "end_pos": 174, "type": "DATASET", "confidence": 0.9661130309104919}]}, {"text": "Semantic classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language.", "labels": [], "entities": [{"text": "Semantic classifications", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7878269255161285}]}, {"text": "Such classifications have been used in applications such as word sense disambiguation), parsing (), machine translation (, and information extraction ().", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6717640360196432}, {"text": "parsing", "start_pos": 88, "end_pos": 95, "type": "TASK", "confidence": 0.9739814400672913}, {"text": "machine translation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.8449650704860687}, {"text": "information extraction", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.8281510472297668}]}, {"text": "Regarding prepositions, comparably little effort in computational semantics has gone beyond a specific choice of prepositions (such as spatial prepositions), towards a systematic classification of preposition senses, as in The Preposition Project ().", "labels": [], "entities": []}, {"text": "Distributional approaches towards preposition meaning and sense distinction have only recently started to explore salient preposition features, but with few exceptions (such as Baldwin) these approaches focused on token-based classification of preposition senses.", "labels": [], "entities": [{"text": "sense distinction", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7190274745225906}, {"text": "token-based classification of preposition senses", "start_pos": 214, "end_pos": 262, "type": "TASK", "confidence": 0.7459690034389496}]}, {"text": "This paper addresses an automatic classification of preposition types in German, comparing various clustering approaches.", "labels": [], "entities": [{"text": "automatic classification of preposition types", "start_pos": 24, "end_pos": 69, "type": "TASK", "confidence": 0.6783931255340576}]}, {"text": "We aim for an unsupervised setting that does not require predefined expensive resources, such as a token-based annotation of preposition senses.", "labels": [], "entities": []}, {"text": "Our task is challenging, because (i) prepositions are notoriously ambiguous, (ii) the interpretation of out-of-context preposition type classification is more difficult than context-embedded token interpretation, (iii) there are no established lexical resources for type-based semantic classification other than for English, and (iv) there are no established evaluation measures for ambiguous linguistic classifications.", "labels": [], "entities": [{"text": "interpretation of out-of-context preposition type classification", "start_pos": 86, "end_pos": 150, "type": "TASK", "confidence": 0.7064865181843439}, {"text": "context-embedded token interpretation", "start_pos": 174, "end_pos": 211, "type": "TASK", "confidence": 0.6923673351605734}, {"text": "type-based semantic classification", "start_pos": 266, "end_pos": 300, "type": "TASK", "confidence": 0.6398974359035492}]}, {"text": "We accept the challenges, identify salient preposition features, and demonstrate the inevitability to apply soft (rather than hard) clustering in order to explore linguistic ambiguity.", "labels": [], "entities": []}], "datasetContent": [{"text": "We chose the fuzzy extension of B-Cubed (.", "labels": [], "entities": []}, {"text": "Pair-wise precision P determines the homogeneity of a cluster analysis, by calculating for each individual preposition p the amount of prepositions pin the same cluster c that also belong to the same gold-standard class g, cf. Equation (1).", "labels": [], "entities": [{"text": "Pair-wise precision P", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.7529386281967163}, {"text": "Equation", "start_pos": 227, "end_pos": 235, "type": "METRIC", "confidence": 0.9834873080253601}]}, {"text": "Pair-wise recall R determines the completeness of a cluster analysis, by calculating for each individual preposition p the amount of prepositions pin the same gold-standard class g that also belong to the same cluster c, cf. Equation (2).", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8193987607955933}, {"text": "Equation", "start_pos": 225, "end_pos": 233, "type": "METRIC", "confidence": 0.9307855367660522}]}, {"text": "The overall B-Cubed precision and recall scores are the averages overall preposition-wise scores.", "labels": [], "entities": [{"text": "B-Cubed", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9475694894790649}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.7473185658454895}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9993402361869812}]}, {"text": "We combined precision and recall by their harmonic mean, the f-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9995203018188477}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9992548823356628}]}], "tableCaptions": []}