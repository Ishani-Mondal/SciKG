{"title": [{"text": "User Modeling in Language Learning with Macaronic Texts", "labels": [], "entities": [{"text": "User Modeling", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8223379552364349}]}], "abstractContent": [{"text": "Foreign language learners can acquire new vocabulary by using cognate and context clues when reading.", "labels": [], "entities": []}, {"text": "To measure such incidental comprehension, we devise an experimental framework that involves reading mixed-language \"macaronic\" sentences.", "labels": [], "entities": []}, {"text": "Using data collected via Amazon Mechanical Turk, we train a graphi-cal model to simulate a human subject's comprehension of foreign words, based on cognate clues (edit distance to an English word), context clues (pointwise mutual information), and prior exposure.", "labels": [], "entities": []}, {"text": "Our model does a reasonable job at predicting which words a user will be able to understand, which should facilitate the automatic construction of comprehensible text for per-sonalized foreign language education.", "labels": [], "entities": []}], "introductionContent": [{"text": "Second language (L2) learning requires the acquisition of vocabulary as well as knowledge of the language's constructions.", "labels": [], "entities": [{"text": "Second language (L2) learning", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.5698962658643723}]}, {"text": "One of the ways in which learners become familiar with novel vocabulary and constructions is through reading.", "labels": [], "entities": []}, {"text": "According to, learners acquire language through incidental learning, which occurs when learners are exposed to comprehensible input.", "labels": [], "entities": []}, {"text": "What constitutes \"comprehensible input\" fora learner varies as their knowledge of the L2 increases.", "labels": [], "entities": []}, {"text": "For example, a student in their first month of German lessons would be hard-pressed to read German novels or even front-page news, but they might understand brief descriptions of daily routines.", "labels": [], "entities": []}, {"text": "Comprehensible input need not be completely familiar to the learner; it could include novel vocabulary items or structures (whose meanings they can glean from context).", "labels": [], "entities": []}, {"text": "Such input falls in the \"zone of proximal development\", just outside of the learner's comfort zone.", "labels": [], "entities": []}, {"text": "The related concept of \"scaffolding\" ( consists of providing assistance to the learner at a level that is just sufficient for them to complete their task, which in our case is understanding a sentence.", "labels": [], "entities": []}, {"text": "Automatic selection or construction of comprehensible input-perhaps online and personalized-would be a useful educational technology.", "labels": [], "entities": []}, {"text": "However, this requires modeling the student: what can an L2 learner understand in a given context?", "labels": [], "entities": []}, {"text": "In this paper, we develop a model and train its parameters on data that we collect.", "labels": [], "entities": []}, {"text": "For the remainder of the paper we focus on native English speakers learning German.", "labels": [], "entities": []}, {"text": "Our methodology is a novel solution to the problem of controlling for the learner's German skill level.", "labels": [], "entities": []}, {"text": "We use subjects with zero previous knowledge of German, but we translate portions of the sentence into English.", "labels": [], "entities": []}, {"text": "Thus, we can presume that they do already know the English words and do not already know the German words (except from seeing them in earlier trials within our experiment).", "labels": [], "entities": []}, {"text": "We are interested in whether they can jointly infer the meanings of the remaining German words in the sentence, so we ask them to guess.", "labels": [], "entities": []}, {"text": "The resulting stimuli are sentences like \"Der Polizist arrested the Bankr\u00e4uber.\"", "labels": [], "entities": [{"text": "Bankr\u00e4uber", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.8714279532432556}]}, {"text": "Even a reader with no knowledge of German is likely to be able to understand this sentence reasonably well by using cognate and context clues.", "labels": [], "entities": []}, {"text": "We refer to this as a macaronic sentence; so-called macaronic language is a pastiche of two or more languages (often intended for humorous effect).", "labels": [], "entities": []}, {"text": "Our experimental subjects are required to guess what \"Polizist\" and \"Bankr\u00e4uber\" mean in this sentence.", "labels": [], "entities": []}, {"text": "We train a featurized model to predict these guesses jointly within each sentence and thereby predict incidental comprehension on any macaronic sentence.", "labels": [], "entities": []}, {"text": "Indeed, we hope our model design will generalize from predicting incidental comprehension on macaronic sentences (for our beginner subjects, who need some context words to be in English) to predicting incidental comprehension on full German sentences (for more ad-vanced students, who understand some of the context words as if they were in English).", "labels": [], "entities": [{"text": "predicting incidental comprehension", "start_pos": 190, "end_pos": 225, "type": "TASK", "confidence": 0.8496263027191162}]}, {"text": "In addition, we are developing a user interface that uses macaronic sentences directly as a medium of language instruction: our companion paper (  gives an overview of that project.", "labels": [], "entities": []}, {"text": "We briefly review previous work, then describe our data collection setup and the data obtained.", "labels": [], "entities": []}, {"text": "Finally, we discuss our model of learner comprehension and validate our model's predictions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divided our data randomly into 5550 training instances, 1903 development instances, and 1939 test instances.", "labels": [], "entities": []}, {"text": "Each instance was a single submission from one user, consisting of a batch of \"simultaneous\" guesses on a macaronic sentence.", "labels": [], "entities": []}, {"text": "We noted qualitatively that when a large number of English words have been revealed, particularly content words, the users tend to make better guesses.", "labels": [], "entities": []}, {"text": "Conversely, when most context is German, we unsuprisingly seethe user leave many guesses blank and make other guesses based on string similarity triggers.", "labels": [], "entities": []}, {"text": "Such submissions are difficult to predict as different users will come up with a wide variety of guesses; our model therefore resorts to predicting similar-sounding words.", "labels": [], "entities": []}, {"text": "For detailed examples of this see Appendix A.: Percentage of foreign words for which the user's actual guess appears in our top-k list of predictions, for models with and without user-specific features (k \u2208 {1, 25, 50}).", "labels": [], "entities": []}, {"text": "For each foreign word f i in a submission with i / \u2208 Obs, our inference method (section 4.2) predicts a marginal probability distribution over a user's guesses\u00eaguesses\u02c6guesses\u00ea i . shows our ability to predict user guesses.", "labels": [], "entities": []}, {"text": "Recall that this task is essentially a structured prediction task that does joint 4919-way classification of each German word.", "labels": [], "entities": [{"text": "4919-way classification of each German word", "start_pos": 82, "end_pos": 125, "type": "TASK", "confidence": 0.6684935539960861}]}, {"text": "Roughly 1/3 of the time, our model's top 25 words include the user's exact guess.", "labels": [], "entities": []}, {"text": "However, the recall reported in is too stringent for our educational application.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9992470741271973}]}, {"text": "We could give the model partial credit for predicting a synonym of the learner's guess\u00eaguess\u02c6guess\u00ea.", "labels": [], "entities": []}, {"text": "More precisely, we would like to give the model partial credit for predicting when the learner will make a poor guess of the truth e * -even if the model does not predict the user's specific incorrect guess\u00eaguess\u02c6guess\u00ea.", "labels": [], "entities": []}, {"text": "To get at this question, we use English word embeddings (as in section 3.4) as a proxy for the semantics and morphology of the words.", "labels": [], "entities": []}, {"text": "We measure the actual quality of the learner's guess\u00eaguess\u02c6guess\u00ea as its cosine similarity to the truth, sim(\u02c6 e, e * ).", "labels": [], "entities": []}, {"text": "While quality of 1 is an exact match, and quality scores > 0.75 are consistently good matches, we found quality of \u2248 0.6 also reasonable.", "labels": [], "entities": [{"text": "quality", "start_pos": 6, "end_pos": 13, "type": "METRIC", "confidence": 0.9896906614303589}, {"text": "quality", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9788457155227661}]}, {"text": "Pairs such as (mosque, islamic) and (politics, government) are examples from the collected data with quality \u2248 0.6.", "labels": [], "entities": []}, {"text": "As quality becomes < 0.4, however, the relationship becomes tenuous, e.g., (refugee, soil).", "labels": [], "entities": []}, {"text": "Similarly, we measure the predicted quality as sim(e, e * ), where e is the model's 1-best prediction of the user's guess.", "labels": [], "entities": []}, {"text": "plots predicted vs. actual quality (each point represents one of the learner's guesses on development data), obtaining a correlation of 0.38, which we call the \"quality correlation\" or QC.", "labels": [], "entities": [{"text": "quality correlation\" or QC", "start_pos": 161, "end_pos": 187, "type": "METRIC", "confidence": 0.8301173925399781}]}, {"text": "A clear diagonal band can be seen, corresponding to the instances where Throughout this section, we ignore the 5.2% of tokens on which the user did not guess (i.e., the guess was <BLANK> after the normalization of section 3.5).", "labels": [], "entities": [{"text": "BLANK", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9824121594429016}]}, {"text": "Our present model simply treats <BLANK> as an ordinary and very bland word (section 4.2), rather than truly attempting to predict when the user will not guess.", "labels": [], "entities": [{"text": "BLANK", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9835996627807617}]}, {"text": "Indeed, the model's posterior probability of <BLANK> in these cases is a paltry 0.0000267 on average (versus 0.0000106 when the user does guess).", "labels": [], "entities": [{"text": "BLANK", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9303361177444458}]}, {"text": "the model exactly predicts the user's guess.", "labels": [], "entities": []}, {"text": "The cloud around the diagonal is formed by instances where the model's prediction was not identical to the user's guess but had similar quality.", "labels": [], "entities": []}, {"text": "We also consider the expected predicted quality, averaging over the model's predictions e of\u00ea of\u02c6of\u00ea (for all e \u2208 V e ) in proportion to the probabilities that it assigns them.", "labels": [], "entities": []}, {"text": "This allows the model to more smoothly assess whether the learner is likely to make a high-quality guess.", "labels": [], "entities": []}, {"text": "shows this version, where the points tend to shift upward and the quality correlation (QC) rises to 0.53.", "labels": [], "entities": [{"text": "quality correlation (QC)", "start_pos": 66, "end_pos": 90, "type": "METRIC", "confidence": 0.9605249881744384}]}, {"text": "All QC values are given in.", "labels": [], "entities": []}, {"text": "We used expected QC on the development set as the criterion for selecting the regularization coefficient \u03bb and as the early stopping criterion during training.).", "labels": [], "entities": [{"text": "early stopping criterion", "start_pos": 118, "end_pos": 142, "type": "METRIC", "confidence": 0.9228436549504598}]}], "tableCaptions": [{"text": " Table 1: Percentage of foreign words for which the user's ac- tual guess appears in our top-k list of predictions, for models  with and without user-specific features (k \u2208 {1, 25, 50}).", "labels": [], "entities": []}, {"text": " Table 2: Quality correlations: basic and user-adapted models.", "labels": [], "entities": []}, {"text": " Table 3: Impact on quality correlation (QC) of removing  features from the model. Ablated QC values marked with  asterisk  *  differ significantly from the full-model QC values  in the first row (p < 0.05, using the test of Preacher", "labels": [], "entities": [{"text": "quality correlation (QC)", "start_pos": 20, "end_pos": 44, "type": "METRIC", "confidence": 0.8696354031562805}, {"text": "Ablated QC", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9121144413948059}, {"text": "Preacher", "start_pos": 225, "end_pos": 233, "type": "DATASET", "confidence": 0.8938156962394714}]}]}