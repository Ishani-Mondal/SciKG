{"title": [{"text": "Domain Adaptation for Authorship Attribution: Improved Structural Correspondence Learning", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6449945122003555}, {"text": "Authorship Attribution", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8892349898815155}]}], "abstractContent": [{"text": "We present the first domain adaptation model for authorship attribution to leverage unlabeled data.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.8616849184036255}]}, {"text": "The model includes extensions to structural correspondence learning needed to make it appropriate for the task.", "labels": [], "entities": []}, {"text": "For example, we propose a median-based classification instead of the standard binary classification used in previous work.", "labels": [], "entities": []}, {"text": "Our results show that punctuation-based character n-grams form excellent pivot features.", "labels": [], "entities": []}, {"text": "We also show how singular value decomposition plays a critical role in achieving domain adaptation, and that replacing (in-stead of concatenating) non-pivot features with correspondence features yields better performance.", "labels": [], "entities": [{"text": "singular value decomposition", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.632069061199824}, {"text": "domain adaptation", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.729531779885292}]}], "introductionContent": [{"text": "Authorship Attribution (AA) can be used for historical purposes, such as disentangling the different authors contributing to a literary work.", "labels": [], "entities": [{"text": "Authorship Attribution (AA)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7893775045871735}]}, {"text": "It can also help in understanding language evolution and change at the individual level, revealing a writer's changes in linguistic patterns overtime.", "labels": [], "entities": []}, {"text": "Authorship attribution can also help to settle disputes over the original creators of a given piece of text.", "labels": [], "entities": [{"text": "Authorship attribution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7237258851528168}]}, {"text": "Or it can help build a prosecution case against an online abuser, an important application especially considering the rising trends in cyber-bullying and other electronic forms of teen violence . The absorbing social media networks, together with the ever increasing use of electronic communications will require robust approaches to authorship attribution that can help to determine with certainty the author of a text, determine the provenance of a written sample, and in sum, help us determine the trustworthiness of electronic data.", "labels": [], "entities": []}, {"text": "1 http://cyberbullying.org/ One of the scenarios that has received limited attention is cross-domain authorship attribution, when we need to identify the author of a text but all the text with known authors is from a different topic, genre, or modality.", "labels": [], "entities": [{"text": "cross-domain authorship attribution", "start_pos": 88, "end_pos": 123, "type": "TASK", "confidence": 0.6966764330863953}]}, {"text": "Here we propose to solve the problem of cross-domain authorship attribution by adapting the Structural Correspondence Learning (SCL) algorithm proposed by.", "labels": [], "entities": [{"text": "cross-domain authorship attribution", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.6812219818433126}]}, {"text": "We make the following contributions: \u2022 We introduce the first domain adaptation model for authorship attribution that combines labeled data in a source domain with unlabeled data from a target domain to improve performance on the target domain.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.85233473777771}]}, {"text": "\u2022 We examine two sets of features that have previously been successful in cross-domain authorship attribution, explain how these can be used to select the \"pivot\" features required by SCL, and show that typed n-gram features (which differentiate between the the in their and the the in breathe) produce simpler models that are just as accurate.", "labels": [], "entities": [{"text": "cross-domain authorship attribution", "start_pos": 74, "end_pos": 109, "type": "TASK", "confidence": 0.6349691351254781}]}, {"text": "\u2022 We propose anew approach for defining SCL's pivot feature classification task so that it is able to handle count-based features, and show that this median-based approach outperforms the standard SCL approach.", "labels": [], "entities": [{"text": "SCL's pivot feature classification task", "start_pos": 40, "end_pos": 79, "type": "TASK", "confidence": 0.8256097237269083}]}, {"text": "\u2022 We examine the importance of the dimensionality reduction step in SCL, and show that the singular value decomposition increases robustness even beyond the robustness achieved by SCL's learned feature transformations.", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.6467419415712357}, {"text": "SCL", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9385586380958557}]}, {"text": "\u2022 We propose an alternative approach to combining features within SCL, and show that excluding the non-pivot features from the final classifier generally improves performance.", "labels": [], "entities": []}, {"text": "Our experimental results show that using standard SCL for this domain adaptation authorship attribution task improves prediction accuracy by only 1% over a model without any domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation authorship attribution task", "start_pos": 63, "end_pos": 108, "type": "TASK", "confidence": 0.7478193938732147}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9478596448898315}]}, {"text": "In contrast, our proposed improvements to SCL reach an accuracy boost of more than 15% over the no domain adaptation model and of 14% over the standard SCL formulation.", "labels": [], "entities": [{"text": "SCL", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9683551788330078}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9995409250259399}, {"text": "no domain adaptation", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.6620769699414571}]}, {"text": "The extensions to SCL that we propose in this work are likely to yield performance improvements in other tasks where SCL has been successfully applied, such as part-of-speech tagging and sentiment analysis.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 160, "end_pos": 182, "type": "TASK", "confidence": 0.7983303368091583}, {"text": "sentiment analysis", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.9455024003982544}]}, {"text": "We plan to investigate this further in the future.", "labels": [], "entities": []}], "datasetContent": [{"text": "To explore cross-domain settings of authorship attribution, we need datasets containing documents from a number of authors from different domains (different topics, different genres).", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.6851615160703659}]}, {"text": "We use a corpus that consists of texts published in The Guardian daily newspaper that is actively used by the authorship attribution community in cross-domain studies.", "labels": [], "entities": [{"text": "The Guardian daily newspaper", "start_pos": 52, "end_pos": 80, "type": "DATASET", "confidence": 0.9588931500911713}]}, {"text": "The Guardian corpus contains opinion articles written by 13 authors in four different topics: World, U.K., Society, and Politics.", "labels": [], "entities": [{"text": "Guardian corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9160884916782379}]}, {"text": "Following prior work, to make the collection balanced across authors, we choose at most ten documents per author for each of the four topics.", "labels": [], "entities": []}, {"text": "presents some statistics about the datasets.", "labels": [], "entities": []}, {"text": "We trained support vector machine (SVM) classifiers using the Weka implementation) with default parameters.", "labels": [], "entities": []}, {"text": "For the untyped features, we used character 3-grams appearing at least 5 times in the training data, a list of 643 predefined stop-words, and the 3,500 most frequent non-stopword words as the lexical features.", "labels": [], "entities": []}, {"text": "For the typed features, we used the top 3,500 most frequent 3-grams occurring at least five times in the training data for each of the 10 character n-gram categories.", "labels": [], "entities": []}, {"text": "In both cases, we selected p = 100 pivot features as described in Section 3.2.", "labels": [], "entities": []}, {"text": "We measured performance in terms of accuracy across all possible topic pairings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9990928173065186}]}, {"text": "That is, we paired each of the 4 topics in the Guardian corpus with each of the 3 remaining topics: train on Politics, test on Society; train on Politics, test on UK; train on Politics, test on World; etc.", "labels": [], "entities": [{"text": "Guardian corpus", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.9773030877113342}, {"text": "UK", "start_pos": 163, "end_pos": 165, "type": "DATASET", "confidence": 0.9314148426055908}]}, {"text": "For each such model, we allowed SCL to learn feature correspondences from the labeled data of the 1 training topic and the unlabeled data of the 1 test topic.", "labels": [], "entities": [{"text": "SCL", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.888083815574646}]}, {"text": "This resulted in 12 pairings of training/testing topics.", "labels": [], "entities": []}, {"text": "We report both accuracy on the individual pairings and an overall average of the 12 accuracies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9997970461845398}, {"text": "accuracies", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9520605206489563}]}, {"text": "We compare performance against two state-ofthe-art baselines: and, as described in Section 3.2, and whose features are denoted as untyped and typed, respectively.", "labels": [], "entities": []}, {"text": "We replicate these models by using the pivot+nonpivot setting of C, i.e., not including any of the new SCL-based features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the Guardian dataset.", "labels": [], "entities": [{"text": "Guardian dataset", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9168637096881866}]}, {"text": " Table 3: Accuracy of untyped and typed feature  sets. The difference between the averages is not  statistically significant (p=0.927).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9792748093605042}]}, {"text": " Table 4: Accuracy of greater-than-zero and me- dian formulations of the B i (y) binarization func- tion. Median is significantly better than greater- than-zero in both untyped (p=0.0007) and typed  (p=0.003).", "labels": [], "entities": []}, {"text": " Table 5: Accuracy of different choices for dimen- sionality reduction with typed features. The pat- tern is similar for untyped. d = 50 is significantly  better than no SVD (p=0.0009), but not signifi- cantly different from d = 25 (p=0.291) or d = 100  (p=0.211).", "labels": [], "entities": [{"text": "dimen- sionality reduction", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.7744708210229874}]}, {"text": " Table 6: Accuracy of different untyped feature combinations. The best performance for each dataset is  in bold. The performance of pivot+new is not significantly different from pivot+nonpivot (p=0.258) or  pivot+nonpivot+new (p=0.305).", "labels": [], "entities": []}, {"text": " Table 7: Accuracy of different typed feature combinations. The best performance for each dataset is  in bold. The performance of pivot+new is significantly better than pivot+nonpivot (p=0.041) but not  significantly different from pivot+nonpivot+new (p=0.059).", "labels": [], "entities": []}]}