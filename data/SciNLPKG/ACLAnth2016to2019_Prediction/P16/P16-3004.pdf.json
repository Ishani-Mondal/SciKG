{"title": [{"text": "Generating Natural Language Descriptions for Semantic Representations of Human Brain Activity", "labels": [], "entities": [{"text": "Generating Natural Language Descriptions", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6239907890558243}, {"text": "Semantic Representations of Human Brain Activity", "start_pos": 45, "end_pos": 93, "type": "TASK", "confidence": 0.8227703173955282}]}], "abstractContent": [{"text": "Quantitative analysis of human brain activity based on language representations, such as the semantic categories of words, have been actively studied in the field of brain and neuroscience.", "labels": [], "entities": []}, {"text": "Our study aims to generate natural language descriptions for human brain activation phenomena caused by visual stimulus by employing deep learning methods, which have gained interest as an effective approach to automatically describe natural language expressions for various type of multi-modal information , such as images.", "labels": [], "entities": []}, {"text": "We employed an image-captioning system based on a deep learning framework as the basis for our method by learning the relationship between the brain activity data and the features of an intermediate expression of the deep neural network owing to lack of training brain data.", "labels": [], "entities": []}, {"text": "We conducted three experiments and were able to generate natural language sentences which enabled us to quantitatively interpret brain activity.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the field of brain and neuroscience, analyzing semantic activities occurring in the human brain is an area of active study.", "labels": [], "entities": [{"text": "analyzing semantic activities occurring in the human brain", "start_pos": 40, "end_pos": 98, "type": "TASK", "confidence": 0.8461439907550812}]}, {"text": "Meanwhile, in the field of computational linguistics, the recent evolution of deep learning methods has allowed methods of generating captions for images to be actively studied.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.7294739782810211}]}, {"text": "Combining these backgrounds, we propose a method to quantitatively interpret the states of the human brain with natural language descriptions, referring to prior methods developed in the fields of both brain and neuroscience and computational linguistics.", "labels": [], "entities": []}, {"text": "Because it is difficult to prepare a large-scale brain activity dataset to train a deep neural model of generating captions for brain activity from scratch, therefore, to handle this problem, we instead reuse a model trained to generate captions for images as the basis for our method.", "labels": [], "entities": []}, {"text": "We apply brain activity data, instead of images, to the image caption-generation frameworks proposed by and to generate natural language descriptions expressing the contents of the brain activity.", "labels": [], "entities": []}, {"text": "In this way, we aim to achieve a quantitative analysis of brain activities through language representation.", "labels": [], "entities": [{"text": "language representation", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.709527775645256}]}], "datasetContent": [{"text": "In this study, we conducted three experiments, under the conditions shown in, using the model of caption generation for images and the model to learn the corresponding relationships between the brain activity data and the features obtained from VGGNet.", "labels": [], "entities": [{"text": "caption generation", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.8392789959907532}, {"text": "VGGNet", "start_pos": 245, "end_pos": 251, "type": "DATASET", "confidence": 0.9763532876968384}]}, {"text": "The model for Exp.1 is illustrated in, and the models for both Exps.2 and 3 are illustrated in.", "labels": [], "entities": [{"text": "Exp.1", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.9606102705001831}, {"text": "Exps.2", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.9156367778778076}]}, {"text": "We employed Chainer 1 as the deep-learning framework.", "labels": [], "entities": []}, {"text": "We used Microsoft COCO 2 , which contains 414,113 pairs of data with still pictures and natural language descriptions of their contents, as the training data for the building captiongeneration model.", "labels": [], "entities": [{"text": "Microsoft COCO 2", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.8716809550921122}]}, {"text": "In this study, we have so far been able to train the network with 168,000 pairs of the total dataset in the below experiments.", "labels": [], "entities": []}, {"text": "We employed the brain activity data of a subject being stimulated by motion pictures (Nishimoto et al., 2011) as the data for training and evaluation.", "labels": [], "entities": []}, {"text": "In the experiments, we used BOLD signals observed every 2s via fMRI while the subject was watching motion pictures as the brain activity data, and the still pictures extracted from the motion pictures were synchronized with the brain data.", "labels": [], "entities": [{"text": "BOLD", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9960606694221497}]}, {"text": "The brain activity data were observed throughout the brain and were recorded in 100(x)\u00d7100(y)\u00d732(z) voxels.", "labels": [], "entities": []}, {"text": "We employed 30,662 voxels corresponding to only the cerebral cortex region, which is the area of the whole brain, in the above observed voxels as input brain data (see,).", "labels": [], "entities": []}, {"text": "In the Exp.1, the multi-layered perceptron learns the corresponding relationships between the input 30,662 dimensional brain data and the 14\u00d714\u00d7512=100,352 dimensional data of the intermediate layer of VGGNet.", "labels": [], "entities": [{"text": "VGGNet", "start_pos": 202, "end_pos": 208, "type": "DATASET", "confidence": 0.9673975706100464}]}, {"text": "In Exps.2 and 3, the 4,096 dimensional feature vector output by VGGNet is the target that needs to be correlated with the brain activity data.", "labels": [], "entities": [{"text": "VGGNet", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.9612654447555542}]}, {"text": "We have only 3,600 training brain activity data which are too small to train deep neural networks, so we have applied a pre-trained deep neural image caption generator to the task for describing brain activity caused by visual stimulation.", "labels": [], "entities": [{"text": "describing brain activity caused by visual stimulation", "start_pos": 184, "end_pos": 238, "type": "TASK", "confidence": 0.7644827621323722}]}], "tableCaptions": [{"text": " Table 2: Details of the experimental settings.", "labels": [], "entities": []}, {"text": " Table 3: Exp.1: Training evaluation.", "labels": [], "entities": [{"text": "Training evaluation", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8355115056037903}]}, {"text": " Table 4: Exp.2: Training evaluation.", "labels": [], "entities": [{"text": "Training evaluation", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8406500220298767}]}]}