{"title": [{"text": "Learning Multiview Embeddings of Twitter Users", "labels": [], "entities": []}], "abstractContent": [{"text": "Low-dimensional vector representations are widely used as stand-ins for the text of words, sentences, and entire documents.", "labels": [], "entities": []}, {"text": "These em-beddings are used to identify similar words or make predictions about documents.", "labels": [], "entities": []}, {"text": "In this work, we consider embeddings for social media users and demonstrate that these can be used to identify users who behave similarly or to predict attributes of users.", "labels": [], "entities": []}, {"text": "In order to capture information from all aspects of a user's online life, we take a multiview approach, applying a weighted variant of Generalized Canonical Correlation Analysis (GCCA) to a collection of over 100,000 Twitter users.", "labels": [], "entities": []}, {"text": "We demonstrate the utility of these multiview em-beddings on three downstream tasks: user engagement , friend selection, and demographic attribute prediction.", "labels": [], "entities": [{"text": "friend selection", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.7435701191425323}, {"text": "demographic attribute prediction", "start_pos": 125, "end_pos": 157, "type": "TASK", "confidence": 0.6342557668685913}]}], "introductionContent": [{"text": "Dense, low-dimensional vector representations (embeddings) have along history in NLP, and recent work on neural models have provided new and popular algorithms for training representations for word types, sentences (, and entire documents ().", "labels": [], "entities": []}, {"text": "These embeddings often have nice properties, such as capturing some aspects of syntax or semantics and outperforming their sparse counterparts at downstream tasks.", "labels": [], "entities": []}, {"text": "While there are many approaches to generating embeddings of text, it is not clear how to learn embeddings for social media users.", "labels": [], "entities": []}, {"text": "There are several different types of data (views) we can use to build user representations: the text of messages they post, neighbors in their local network, articles they link to, images they upload, etc.", "labels": [], "entities": []}, {"text": "We propose unsupervised learning of representations of users with a variant of Generalized Canonical Correlation Analysis (GCCA)), a multiview technique that learns a single, low-dimensional vector for each user best capturing information from each of their views.", "labels": [], "entities": []}, {"text": "We believe this is more appropriate for learning user embeddings than concatenating views into a single vector, since views may correspond to different modalities (image vs. text data) or have very different distributional properties.", "labels": [], "entities": []}, {"text": "Treating all features as equal in this concatenated vector is not appropriate.", "labels": [], "entities": []}, {"text": "We offer two main contributions: (1) an application of GCCA to learning vector representations of social media users that best accounts for all aspects of a user's online life, and (2) an evaluation of these vector representations fora set of Twitter users at three different tasks: user engagement, friend, and demographic attribute prediction.", "labels": [], "entities": [{"text": "demographic attribute prediction", "start_pos": 312, "end_pos": 344, "type": "TASK", "confidence": 0.6801469524701437}]}], "datasetContent": [{"text": "We selected three user prediction tasks to demonstrate the effectiveness of the multi-view embeddings: user engagement prediction, friend recommendation and demographic characteristics inference.", "labels": [], "entities": [{"text": "user engagement prediction", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.6764181156953176}]}, {"text": "Our focus is to show the performance of multiview embeddings compared to other representations, not on building the best system fora given task.", "labels": [], "entities": []}, {"text": "User Engagement Prediction The goal of user engagement prediction is to determine which topics a user will likely tweet about, using hashtag as a proxy.", "labels": [], "entities": [{"text": "User Engagement Prediction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6438818573951721}, {"text": "user engagement prediction", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.6124184827009836}]}, {"text": "This task is similar to hashtag recommendation fora tweet based on its contents ().", "labels": [], "entities": []}, {"text": "(2011) presented a supervised task to predict if a hashtag would appear in a tweet using features from the user's network, previous tweets, and the tweet's content.", "labels": [], "entities": []}, {"text": "We selected the 400 most frequently used hashtags in messages authored by our users and which first appeared in March 2015, randomly and evenly dividing them into dev and test sets.", "labels": [], "entities": []}, {"text": "We held out the first 10 users who tweeted each hashtag as exemplars of users that would use the hashtag in the future.", "labels": [], "entities": []}, {"text": "We ranked all other users by the cosine distance of their embedding to the average embedding of these 10 users.", "labels": [], "entities": []}, {"text": "Since embeddings are learned on data pre-March 2015, the hashtags cannot impact the learned representations.", "labels": [], "entities": []}, {"text": "Performance is measured using precision and recall at k, as well as mean reciprocal rank (MRR), where a user is marked as correct if they used the hashtag.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9995225667953491}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9992427825927734}, {"text": "mean reciprocal rank (MRR)", "start_pos": 68, "end_pos": 94, "type": "METRIC", "confidence": 0.9488936960697174}]}, {"text": "Note that this task is different than that reported in Purohit et al.", "labels": [], "entities": []}, {"text": "(2011), since we are making recommendations at the level of users, not tweets.", "labels": [], "entities": []}, {"text": "Friend Recommendation The goal of friend recommendation/link prediction is to recommend/predict other accounts fora user to follow.", "labels": [], "entities": [{"text": "friend recommendation/link prediction", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.567162299156189}]}, {"text": "We selected the 500 most popular accounts -which we call celebrities -followed by our users, randomly, and evenly divided them into dev and test sets.", "labels": [], "entities": []}, {"text": "We randomly select 10 users who follow each celebrity and rank all other users by cosine distance to the average of these 10 representations.", "labels": [], "entities": []}, {"text": "The tweets of selected celebrities are removed during embedding training so as not to influence the learned representations.", "labels": [], "entities": []}, {"text": "We use the same evaluation as user engagement prediction, where a user is marked as correct if they follow the given celebrity.", "labels": [], "entities": [{"text": "user engagement prediction", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7673300703366598}]}, {"text": "For both user engagement prediction and friend recommendation we z-score normalize each feature, subtracting off the mean and scaling each feature independently to have unit variance, before computing cosine similarity.", "labels": [], "entities": [{"text": "user engagement prediction", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.7710566520690918}]}, {"text": "We select the approach and whether to zscore normalize based on the development set performance.", "labels": [], "entities": []}, {"text": "Demographic Characteristics Inference Our final task is to infer the demographic characteristics of a user  We use the dataset from which annotates 383 users forage (old/young), 383 for gender (male/female), and 396 political affiliation (republican/democrat), with balanced classes.", "labels": [], "entities": []}, {"text": "Predicting each characteristic is a binary supervised prediction task.", "labels": [], "entities": []}, {"text": "Each set is partitioned into 10 folds, with two folds held out for test, and the other eight for tuning via cross-fold validation.", "labels": [], "entities": []}, {"text": "The provided dataset contained tweets from each user, mentioned users, friends and follower networks.", "labels": [], "entities": []}, {"text": "It did not contain the actual social networks for these users, so we did not evaluate NetSim, NetSim-PCA, or GCCA-net at these prediction tasks.", "labels": [], "entities": []}, {"text": "Each feature was z-score normalized before being passed to a linear-kernel SVM where we swept over 10 \u22124 , . .", "labels": [], "entities": []}, {"text": ", 10 4 for the penalty on the error term, C.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Macro performance at user engagement prediction  on dev/test. Ranking of model performance was consistent  across metrics. Precision is low since few users tweet a given  hashtag. Values bolded by best test performance per metric.  Baselines (bottom): NetSize: a ranking of users by the size of  their local network; Random randomly ranks users.", "labels": [], "entities": [{"text": "user engagement prediction", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6222118933995565}, {"text": "Precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9993855953216553}]}, {"text": " Table 2: Macro performance for friend recommendation.  Performance of NetSim-PCA and GCCA-sv are identical  since the view weighting for GCCA-sv only selected solely  the friend view. Thus, these methods learned identical user  embeddings.", "labels": [], "entities": [{"text": "GCCA-sv", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.8925283551216125}]}, {"text": " Table 3: Average CV/test accuracy for inferring demo- graphic characteristics.", "labels": [], "entities": [{"text": "Average CV/test accuracy", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.6888360023498535}]}]}