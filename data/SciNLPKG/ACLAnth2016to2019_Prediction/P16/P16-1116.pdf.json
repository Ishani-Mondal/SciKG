{"title": [{"text": "RBPB: Regularization-Based Pattern Balancing Method for Event Extraction", "labels": [], "entities": [{"text": "Regularization-Based Pattern Balancing", "start_pos": 6, "end_pos": 44, "type": "TASK", "confidence": 0.8967088460922241}, {"text": "Event Extraction", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7088676989078522}]}], "abstractContent": [{"text": "Event extraction is a particularly challenging information extraction task, which intends to identify and classify event triggers and arguments from raw text.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8024084568023682}, {"text": "information extraction", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.7436119168996811}]}, {"text": "In recent works, when determining event types (trigger classification), most of the works are either pattern-only or feature-only.", "labels": [], "entities": [{"text": "determining event types (trigger classification)", "start_pos": 22, "end_pos": 70, "type": "TASK", "confidence": 0.7197942946638379}]}, {"text": "However, although patterns cannot coverall representations of an event, it is still a very important feature.", "labels": [], "entities": []}, {"text": "In addition, when identifying and classifying arguments, previous works consider each candidate argument separately while ignoring the relationship between arguments.", "labels": [], "entities": []}, {"text": "This paper proposes a Regularization-Based Pattern Balancing Method (RBPB).", "labels": [], "entities": [{"text": "Regularization-Based Pattern Balancing", "start_pos": 22, "end_pos": 60, "type": "TASK", "confidence": 0.9219164450963339}]}, {"text": "Inspired by the progress in representation learning, we use trigger embedding, sentence-level embedding and pattern features together as our features for trigger classification so that the effect of patterns and other useful features can be balanced.", "labels": [], "entities": [{"text": "trigger classification", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.7427856922149658}]}, {"text": "In addition, RBPB uses a regularization method to take advantage of the relationship between arguments.", "labels": [], "entities": []}, {"text": "Experiments show that we achieve results better than current state-of-art equivalents.", "labels": [], "entities": []}], "introductionContent": [{"text": "Event extraction has become a popular research topic in the area of information extraction.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7928142249584198}, {"text": "information extraction", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.892794281244278}]}, {"text": "ACE 2005 defines event extraction task 1 as three sub-tasks: identifying the trigger of an event, identifying the arguments of the event, and distinguishing their corresponding roles.", "labels": [], "entities": [{"text": "ACE 2005", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9566334784030914}, {"text": "event extraction task 1", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.7880574837327003}]}, {"text": "As an example in, there is an \"Attack\" event http://www.itl.nist.gov/iad/mig/tests/ace/2005/ triggered by \"tear through\" with three arguments.", "labels": [], "entities": []}, {"text": "Each argument has one role.", "labels": [], "entities": []}, {"text": "In the trigger classification stage, some previous approaches () use patterns to decide the types of event triggers.", "labels": [], "entities": [{"text": "trigger classification", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.9058687388896942}]}, {"text": "However, pattern-based approaches suffer from low recall since real world events usually have a large variety of representations.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.999152660369873}]}, {"text": "Some other approaches identify and classify event triggers using a large set of features without using patterns.", "labels": [], "entities": []}, {"text": "Although these features can be very helpful, patterns are still indispensable in many cases because they can identify a trigger with the correct event type with more than 96% accuracy according to our data analysis on ACE 2005 data sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9977478384971619}, {"text": "ACE 2005 data sets", "start_pos": 218, "end_pos": 236, "type": "DATASET", "confidence": 0.98173588514328}]}, {"text": "In argument identification and classification, most approaches identify each candidate argument separately without considering the relation between arguments.", "labels": [], "entities": [{"text": "argument identification and classification", "start_pos": 3, "end_pos": 45, "type": "TASK", "confidence": 0.7724598124623299}]}, {"text": "We define two kinds of argument relations here: (1) Positive correlation: if one candidate argument belongs to one event, then the other is more likely to belong to the same event.", "labels": [], "entities": [{"text": "correlation", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.677269697189331}]}, {"text": "For example, in, the entity \"a waiting shed\" shares a common dependency head \"tore\" with \"a powerful bomb\", so when the latter entity is identified as an argument, the former is more likely to be identified.", "labels": [], "entities": []}, {"text": "(2) Negative correlation: if one candidate argument belongs to one event, then the other is less likely to belong to the same event.", "labels": [], "entities": [{"text": "Negative correlation", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.8545261919498444}]}, {"text": "For example, in, \"bus\" is irrelevant to other arguments, so if other entities are identified as arguments \"bus\" is less likely to be identified.", "labels": [], "entities": []}, {"text": "Note that although all the above relation examples have something to do with dependency analysis, the positive/negative relationship depends not only on dependency parsing, but many other aspects as well.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.8701297640800476}, {"text": "dependency parsing", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.7727610170841217}]}, {"text": "In this paper, we propose using both patterns and elaborately designed features simultaneously to identify and classify event triggers.", "labels": [], "entities": []}, {"text": "In addition, we propose using a regularization method to model the relationship between candidate arguments to improve the performance of argument identification.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.7251838594675064}]}, {"text": "Our method is called Regularization-Based Pattern Balancing Method method.", "labels": [], "entities": [{"text": "Regularization-Based Pattern Balancing", "start_pos": 21, "end_pos": 59, "type": "TASK", "confidence": 0.9309276342391968}]}, {"text": "The contributions of this paper are as follows: \u2022 Inspired by the progress of representation learning, we use trigger embedding, sentence-level embedding, and pattern features together as the our features for balancing.", "labels": [], "entities": []}, {"text": "\u2022 We proposed a regularization-based method in order to make use of the relationship between candidate arguments.", "labels": [], "entities": []}, {"text": "Our experiments on the ACE 2005 data set show that the regularization method does improve the performance of argument identification.", "labels": [], "entities": [{"text": "ACE 2005 data set", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.9826230853796005}, {"text": "argument identification", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.7450635731220245}]}], "datasetContent": [{"text": "We conduct experiments to answer the following questions.", "labels": [], "entities": []}, {"text": "(1) Can pattern balancing lead to a higher performance in trigger classification, argument identification, and classification while retaining the precision value?", "labels": [], "entities": [{"text": "pattern balancing", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7702732682228088}, {"text": "trigger classification", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.7869046926498413}, {"text": "argument identification", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.7347264587879181}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.998299777507782}]}, {"text": "(2) Can the regularization step improve the performance of argument identification and classification?", "labels": [], "entities": [{"text": "argument identification and classification", "start_pos": 59, "end_pos": 101, "type": "TASK", "confidence": 0.7283242121338844}]}, {"text": "shows the overall performance on the blind test set.", "labels": [], "entities": []}, {"text": "We compare our results with the JET baseline as well as the Cross-Event, CrossEntity, and joint methods.", "labels": [], "entities": [{"text": "JET baseline", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8830237090587616}]}, {"text": "When adding the event type classifier, in the line titled \"+ ET\", we see a significant increase in the three measures over the JET baseline in recall.", "labels": [], "entities": [{"text": "ET", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9864441752433777}, {"text": "JET baseline", "start_pos": 127, "end_pos": 139, "type": "DATASET", "confidence": 0.8583419322967529}, {"text": "recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9921244978904724}]}, {"text": "Although our trigger's precision is lower than RBPB(JET), it gains 5.2% improvement on the trigger's F 1 measure, 10.6% improvement on argument identification's F 1 measure and 9.7% improvement on argument classification's F 1 measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9991161227226257}, {"text": "RBPB", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9616010785102844}, {"text": "F 1 measure", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.9421506524085999}, {"text": "argument identification", "start_pos": 135, "end_pos": 158, "type": "TASK", "confidence": 0.7224556803703308}, {"text": "F 1 measure", "start_pos": 161, "end_pos": 172, "type": "METRIC", "confidence": 0.7131198445955912}, {"text": "F 1 measure", "start_pos": 223, "end_pos": 234, "type": "METRIC", "confidence": 0.8699068228403727}]}, {"text": "We also test the performance with argument candidates automatically extracted by JET in, our approach \"+ ET\" again significantly outperforms the JET baseline.", "labels": [], "entities": [{"text": "JET", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.8768057823181152}, {"text": "ET", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.969661295413971}, {"text": "JET baseline", "start_pos": 145, "end_pos": 157, "type": "DATASET", "confidence": 0.8821343779563904}]}, {"text": "Remarkably, our result is comparable with the Joint model although we only use lexical features.", "labels": [], "entities": []}, {"text": "The line titled \"+ Regu\" in represents the performance when we only use the regularization method.", "labels": [], "entities": []}, {"text": "In, the \"+ Regu\" again gains a higher F 1 measure than the JET, Cross-Document, joint model baseline and \"+ ET\".", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 38, "end_pos": 49, "type": "METRIC", "confidence": 0.9908592700958252}, {"text": "JET", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.8666104674339294}, {"text": "ET", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9025185108184814}]}, {"text": "The complete approach is denoted as \"RBPB\" in.", "labels": [], "entities": [{"text": "RBPB", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.8431037068367004}]}, {"text": "Remarkably, our approach performances comparable in trigger classification with the state-of art methods: Cross-Document, Cross-Event, Cross-Entity, Joint model, DMCNN and significantly higher than them in argument identification as well as classification although we did not use the cross-document, cross-event information or any global feature.", "labels": [], "entities": [{"text": "trigger classification", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7622378766536713}, {"text": "argument identification", "start_pos": 206, "end_pos": 229, "type": "TASK", "confidence": 0.7292233109474182}]}, {"text": "Therefore, the relationship between argument candidates can indeed contribute to argument identification performance.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.8385951519012451}]}, {"text": "The event type classifier also contributes a lot in trigger identification & classification.", "labels": [], "entities": [{"text": "trigger identification", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.8733420670032501}]}, {"text": "We do the Wilcoxon Signed Rank Test on trigger classification, argument identification and argument classification, all the three have p < 0.01.", "labels": [], "entities": [{"text": "Wilcoxon Signed Rank Test", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.6145501434803009}, {"text": "trigger classification", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7361752986907959}, {"text": "argument identification", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.829410582780838}, {"text": "argument classification", "start_pos": 91, "end_pos": 114, "type": "TASK", "confidence": 0.7643062472343445}]}, {"text": "A more detailed study of the pattern feature's effect is shown in: The effect (F 1 value) of pattern feature much better performance than with two kinds of features alone.", "labels": [], "entities": [{"text": "F 1 value", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9804361462593079}]}, {"text": "However, our approach is just a pipeline approach which suffers from error propagation and the argument performance may not affect the trigger too much.", "labels": [], "entities": []}, {"text": "We can see from that although we use gold argument candidates, the trigger performance is still lower than DMCNN.", "labels": [], "entities": [{"text": "DMCNN", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.917798638343811}]}, {"text": "Another limitation is that our regularization method does not improve the argument classification too much since it only uses constraints to affect roles.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7278439402580261}]}, {"text": "Future work maybe done to solve these two limitations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overall performance with gold-standard entities, timex, and values, the candidate arguments  are annotated in ACE 2005. \"ET\" means the pattern balancing event type classifier, \"Regu\" means the  regularization method", "labels": [], "entities": [{"text": "ACE 2005", "start_pos": 120, "end_pos": 128, "type": "DATASET", "confidence": 0.9552502632141113}, {"text": "ET", "start_pos": 131, "end_pos": 133, "type": "METRIC", "confidence": 0.9172884225845337}]}, {"text": " Table 1 and Table 2. Remarkably, our approach  performances comparable in trigger classification  with the state-of art methods: Cross-Document,  Cross-Event, Cross-Entity, Joint model, DMCNN  and significantly higher than them in argument  identification as well as classification although  we did not use the cross-document, cross-event  information or any global feature. Therefore,  the relationship between argument candidates  can indeed contribute to argument identification  performance.", "labels": [], "entities": [{"text": "trigger classification", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.6776386499404907}, {"text": "argument  identification", "start_pos": 232, "end_pos": 256, "type": "TASK", "confidence": 0.7147093415260315}, {"text": "argument identification", "start_pos": 459, "end_pos": 482, "type": "TASK", "confidence": 0.822956383228302}]}, {"text": " Table 3. We can see that RBPB  with both plain feature and pattern feature can gain", "labels": [], "entities": []}]}