{"title": [{"text": "Learning Structured Predictors from Bandit Feedback for Interactive NLP", "labels": [], "entities": []}], "abstractContent": [{"text": "Structured prediction from bandit feedback describes a learning scenario where instead of having access to a gold standard structure, a learner only receives partial feedback inform of the loss value of a predicted structure.", "labels": [], "entities": [{"text": "Structured prediction from bandit feedback", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8524972558021545}]}, {"text": "We present new learning objectives and algorithms for this interactive scenario, focusing on convergence speed and ease of elicitability of feedback.", "labels": [], "entities": []}, {"text": "We present supervised-to-bandit simulation experiments for several NLP tasks (machine translation, sequence labeling , text classification), showing that bandit learning from relative preferences eases feedback strength and yields improved empirical convergence.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.805685818195343}, {"text": "sequence labeling", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.667142853140831}, {"text": "text classification", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7885743081569672}]}], "introductionContent": [{"text": "Structured prediction from partial information can be described by the following learning protocol: On each of a sequence of rounds, the learning algorithm makes a prediction, and receives partial information in terms of feedback on the predicted point.", "labels": [], "entities": [{"text": "Structured prediction from partial information", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8464710950851441}]}, {"text": "This single-point feedback is used to construct a parameter update that is an unbiased estimate of the respective update rule for the full information objective.", "labels": [], "entities": []}, {"text": "In difference to the full information scenario, the learner does not know what the correct prediction looks like, nor what would have happened if it had predicted differently.", "labels": [], "entities": []}, {"text": "This learning scenario has been investigated under the names of learning from bandit feedback 1 or rein- * The work for this paper was done while the authors were at Heidelberg University.", "labels": [], "entities": []}, {"text": "The name is inherited from a model wherein each round a gambler pulls an arm of a different slot machine (\"onearmed bandit\"), with the goal of maximizing his reward relative to the maximal possible reward, without apriori knowledge of the optimal slot machine.", "labels": [], "entities": []}, {"text": "See Bubeck and CesaBianchi (2012) for an overview.", "labels": [], "entities": []}, {"text": "forcement learning 2 , and has (financially) important real world applications such as online advertising ().", "labels": [], "entities": [{"text": "forcement learning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8317916989326477}]}, {"text": "In this application, the probability that an ad will be clicked (and the advertiser has to pay) is estimated by trading off exploration (a new ad needs to be displayed in order to learn its click-through rate) and exploitation (displaying the ad with the current best estimate is better in the short term) in displaying ads to users.", "labels": [], "entities": []}, {"text": "Similar to the online advertising scenario, there are many potential applications to interactive learning in NLP.", "labels": [], "entities": []}, {"text": "For example, in interactive statistical machine translation (SMT), user feedback inform of post-edits of predicted translations is used for model adaptation).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7782096713781357}, {"text": "model adaptation", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.7258497774600983}]}, {"text": "Since post-editing feedback has a high cost and requires professional expertise of users, weaker forms of feedback are desirable.", "labels": [], "entities": []}, {"text": "showed in a simulation experiment that partial information inform of translation quality judgements on predicted translations is sufficient for model adaptation in SMT.", "labels": [], "entities": [{"text": "model adaptation", "start_pos": 144, "end_pos": 160, "type": "TASK", "confidence": 0.6999041438102722}, {"text": "SMT", "start_pos": 164, "end_pos": 167, "type": "TASK", "confidence": 0.9899938702583313}]}, {"text": "However, one drawback of their bandit expected loss minimization algorithm is the slow convergence speed, meaning that impractically many rounds of user feedback would be necessary for learning in real-world interactive SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 220, "end_pos": 223, "type": "TASK", "confidence": 0.9448059797286987}]}, {"text": "Furthermore, their algorithms requires feedback inform of numerical assessments of translation quality.", "labels": [], "entities": []}, {"text": "Such absolute feedback is arguably harder to elicit from human users than relative judgements.", "labels": [], "entities": []}, {"text": "The goal of this work is a preparatory study of different objectives and algorithms for structured prediction from partial information with real-world interactive scenarios in mind.", "labels": [], "entities": []}, {"text": "Since the algorithm of can be characterized as stochastic optimization of a non-convex objective, a possible avenue to address the problem of convergence speed is a (strong) convexification of the learning objective, which we formalize as bandit cross-entropy minimization.", "labels": [], "entities": []}, {"text": "To the aim of easing elicitability of feedback, we present a bandit pairwise preference learning algorithm that requires only relative feedback in the form of pairwise preference rankings.", "labels": [], "entities": []}, {"text": "The focus of this paper is on an experimental evaluation of the empirical performance and convergence speed of the different algorithms.", "labels": [], "entities": []}, {"text": "We follow the standard practice of early stopping by measuring performance on a development set, and present results of an extensive evaluation on several tasks with different loss functions, including BLEU for SMT, Hamming loss for optical character recognition, and F1 score for chunking.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.8183616101741791}, {"text": "BLEU", "start_pos": 202, "end_pos": 206, "type": "METRIC", "confidence": 0.9989091157913208}, {"text": "SMT", "start_pos": 211, "end_pos": 214, "type": "TASK", "confidence": 0.9951608777046204}, {"text": "optical character recognition", "start_pos": 233, "end_pos": 262, "type": "TASK", "confidence": 0.5964191059271494}, {"text": "F1 score", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.9888013303279877}, {"text": "chunking", "start_pos": 281, "end_pos": 289, "type": "TASK", "confidence": 0.940379798412323}]}, {"text": "In our experiments, we use a standard supervisedto-bandit transformation where a reward signal is simulated by evaluating a task loss against gold standard structures without revealing them to the learning algorithm ().", "labels": [], "entities": []}, {"text": "From the perspective of real-world interactive applications, bandit pairwise preference learning is the preferred algorithm since it only requires comparative judgements for learning.", "labels": [], "entities": [{"text": "bandit pairwise preference learning", "start_pos": 61, "end_pos": 96, "type": "TASK", "confidence": 0.5935708358883858}]}, {"text": "This type of relative feedback been shown to be advantageous for human decision making.", "labels": [], "entities": [{"text": "decision making", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.7922190427780151}]}, {"text": "However, in our simulation experiments we found that relative feedback also results in improved empirical convergence speed for bandit pairwise preference learning.", "labels": [], "entities": [{"text": "bandit pairwise preference learning", "start_pos": 128, "end_pos": 163, "type": "TASK", "confidence": 0.5811740681529045}]}, {"text": "The picture of fastest empirical convergence of bandit pairwise preference learning is consistent across different tasks, both compared to bandit expected loss minimization and bandit cross-entropy minimization.", "labels": [], "entities": []}, {"text": "Given the improved convergence and the ease of elicitability of relative feedback, the presented bandit pairwise preference learner is an attractive choice for interactive NLP tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments follow an online learning protocol whereon each of a sequence of rounds, an output structure is randomly sampled, and feedback to it is used to update the model).", "labels": [], "entities": []}, {"text": "We simulate bandit feedback by evaluating \u2206 against gold standard structures which are never revealed to the learner ().", "labels": [], "entities": []}, {"text": "Training is started from w 0 = 0 or from an out-of-domain model (for SMT).", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9876229763031006}]}, {"text": "Following the standard practice of early stopping by performance evaluation on a development set, we compute convergence speed as the number of iterations needed to find the point of optimal performance before overfitting on the development set occurs.", "labels": [], "entities": [{"text": "convergence speed", "start_pos": 109, "end_pos": 126, "type": "METRIC", "confidence": 0.8868253827095032}]}, {"text": "The convergence criterion is thus based on the respective task loss function \u2206(\u02c6 y wt (x)) under MAP prediction\u02c6yprediction\u02c6 prediction\u02c6y w (x) = arg max y\u2208Y(x) p w (y|x), microaveraged on the development data.", "labels": [], "entities": []}, {"text": "This lets us compare convergence across different objectives, and is justified by the standard practice of performing online-tobatch conversion by early stopping on a development set, or by tolerant training to avoid overfitting.", "labels": [], "entities": [{"text": "online-tobatch conversion", "start_pos": 118, "end_pos": 143, "type": "TASK", "confidence": 0.6093645095825195}]}, {"text": "As a further measure for comparability of convergence,), clipping constant k used to replace p wt (\u02dc y t |x t ) with max{p wt (\u02dc y t |x t ), k} inline 7 of Algorithm 3 (Ionides, 2008), 2 regularization constant \u03bb.", "labels": [], "entities": []}, {"text": "Unspecified parameters are set to zero.", "labels": [], "entities": []}, {"text": "speeds across algorithms, we employ small constant learning rates in all experiments.", "labels": [], "entities": []}, {"text": "The use of constant learning rates for Algorithms 1 and 2 is justified by the analysis of.", "labels": [], "entities": []}, {"text": "For Algorithm 3, the use of constant learning rates effectively compares convergence speed towards an area in close vicinity of a local minimum in the search phase of the algorithm).", "labels": [], "entities": []}, {"text": "The development data are also used for metaparameter search.", "labels": [], "entities": [{"text": "metaparameter search", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7444082796573639}]}, {"text": "Optimal configurations are listed in.", "labels": [], "entities": []}, {"text": "Final testing was done by computing \u2206 on a further unseen test set using the model found by online-to-batch conversion.", "labels": [], "entities": []}, {"text": "For bandit-type algorithms, final results are averaged over 3 runs with different random seeds.", "labels": [], "entities": []}, {"text": "For statistical significance testing of results against baselines we use Approximate Randomization testing.", "labels": [], "entities": [{"text": "Approximate", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9840982556343079}]}, {"text": "Multiclass text classification on the Reuters RCV1 dataset () is a standard benchmark for (simplified) structured prediction that has been used in a bandit setup by.", "labels": [], "entities": [{"text": "Multiclass text classification", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6904265284538269}, {"text": "Reuters RCV1 dataset", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.9692443013191223}]}, {"text": "The simplified problem uses a binary \u2206 function indicating incorrect assignment of one out of 4 classes.", "labels": [], "entities": []}, {"text": "Following, we used documents with exactly one label from the set of labels {CCAT, ECAT, GCAT, MCAT} and converted them to tfidf word vectors of dimension 244,805 in training.", "labels": [], "entities": [{"text": "GCAT", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.8163961172103882}, {"text": "MCAT", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.6301213502883911}]}, {"text": "The data were split into the sets train (509,381 documents from original test pt.dat files), dev (19,486 docs: every 8th entry from test pt3.dat and test (19,806 docs from train.dat).", "labels": [], "entities": []}, {"text": "As shown in (row 1), all loss results are small and comparable since the task is relatively easy.", "labels": [], "entities": []}, {"text": "For comparison, the partial information classification algorithm Banditron () (after adjusting the exploration/exploitation constant on the dev set) scored 0.047 on the test set.", "labels": [], "entities": [{"text": "information classification", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.6752427071332932}]}, {"text": "However, our main interest is in convergence speed.", "labels": [], "entities": [{"text": "convergence speed", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7896324396133423}]}, {"text": "(row 1) shows that pairwise ranking (Algorithm 2) yields fastest convergence by a factor of 2-4 compared to the other bandit algorithms.", "labels": [], "entities": []}, {"text": "confirms that this improvement is not attributable to larger learning rates (Algorithm 2 employs a similar or smaller learning rate than Algorithms 1 and 3, respectively.)", "labels": [], "entities": []}, {"text": "Sequence labeling for OCR and chunking.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.876597136259079}]}, {"text": "Handwritten optical character recognition (OCR) is a standard benchmark task for structured prediction (, where the Hamming distance between the predicted word and the gold standard labeling (normalized byword length) is assumed as the \u2206 function.", "labels": [], "entities": [{"text": "Handwritten optical character recognition (OCR)", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7687730618885585}, {"text": "structured prediction", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.7591893076896667}]}, {"text": "We used their dataset of 6,876 handwritten words, from 150 human subjects, under a split where 5,546 examples (folds 2-9) were used as train set, 704 examples (fold 1) as dev, and 626 (fold 0) as test set.", "labels": [], "entities": []}, {"text": "We assumed the classical linear-chain Conditional Random Field (CRF) () model with input images xi at every ith node, tabular state-transition probabilities between 28 possible labels of the (i \u2212 1)th and ith node (Latin letters plus two auxiliary start and stop states).", "labels": [], "entities": []}, {"text": "To test the CRF-based model also with sparse features, we followed Sha and Pereira in applying CRFs to the noun phrase chunking task: Test set evaluation for full information lower and upper bounds and partial information bandit learners (expected loss, pairwise loss, cross-entropy).", "labels": [], "entities": [{"text": "noun phrase chunking task", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.7260566204786301}]}, {"text": "\u2191 and \u2193 indicate the direction of improvement for the respective evaluation metric.", "labels": [], "entities": []}, {"text": "on the CoNLL-2000 dataset . We split the original training set into a dev set (top 1,000 sent.) and used the rest as train set (7,936 sent.); the test set was kept intact (2,012 sent.).", "labels": [], "entities": [{"text": "CoNLL-2000 dataset", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.9851428270339966}]}, {"text": "For an input sentence x, each CRF node xi carries an observable word and its part-of-speech tag, and has to be assigned a chunk tag c i out of 3 labels: Beginning, Inside, or Outside (of a noun phrase).", "labels": [], "entities": []}, {"text": "Chunk labels are not nested.", "labels": [], "entities": []}, {"text": "As in Sha and Pereira, we use second order Markov dependencies (bigram chunk tags), such that for sentence position i, the state is y i = c i\u22121 c i , increasing the label set size from 3 to 9.", "labels": [], "entities": []}, {"text": "Out of the full list of Sha and Pereira (2003)'s features we implemented all except two feature templates, y i = y and c(y i ) = c, to simplify implementation.", "labels": [], "entities": []}, {"text": "Impossible bigrams (OI) and label transitions of the pattern O \u2192 I were prohibited by setting the respective potentials to \u2212\u221e.", "labels": [], "entities": []}, {"text": "As the active feature count in the train set was just under 2M, we hashed all features and weights into a sparse array of 2M entries.", "labels": [], "entities": []}, {"text": "Despite the reduced train size and feature set, and hashing, our full information baseline trained with log-likelihood attained the test F1-score of 0.935, which is comparable to the original result of 0.9438.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9888789653778076}]}, {"text": "(rows 2-3) and (rows 2-3) show evaluation and convergence results for the OCR and chunking tasks.", "labels": [], "entities": []}, {"text": "For the chunking task, the F1-score results obtained for bandit learning are close to the full-information baseline.", "labels": [], "entities": [{"text": "chunking task", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.9273882508277893}, {"text": "F1-score", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9991651773452759}]}, {"text": "For the OCR task, bandit learning does decrease Hamming loss, but it does not quite achieve full-information performance.", "labels": [], "entities": [{"text": "OCR task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.9026022851467133}, {"text": "Hamming loss", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.8034031987190247}]}, {"text": "However, pairwise ranking (Algorithm 2) again converges faster than the alternative bandit algorithms by a factor of 2-4, despite similar learning rates for Algorithms 1 and 2 and a compensa-   Discriminative ranking for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 221, "end_pos": 224, "type": "TASK", "confidence": 0.9834743142127991}]}, {"text": "Following, we apply bandit learning to simulate personalized MT where a given SMT system is adapted to user style and domain based on feedback to predicted translations.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.8870567083358765}, {"text": "SMT", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9768953323364258}]}, {"text": "We perform French-to-English domain adaptation from Europarl to NewsCommentary domains using the data of.", "labels": [], "entities": [{"text": "French-to-English domain adaptation", "start_pos": 11, "end_pos": 46, "type": "TASK", "confidence": 0.564444343249003}, {"text": "Europarl", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.988578200340271}, {"text": "NewsCommentary domains", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.890330582857132}]}, {"text": "One difference of our experiment compared to is our use of the SCFG decoder cdec () (instead of the phrase-based Moses decoder).", "labels": [], "entities": [{"text": "SCFG decoder cdec", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.84641565879186}]}, {"text": "Furthermore, in addition to bandit learning for re-ranking on unique 5,000-best lists, we perform ranking on hypergraphs with redecoding after each update.", "labels": [], "entities": []}, {"text": "Sampling and computation of expectations on the hypergraph uses the Inside-Outside algorithm over the expectation semiring (.", "labels": [], "entities": [{"text": "Sampling", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.976702094078064}]}, {"text": "The re-ranking model used 15 dense features (6 lexicalized reordering features, two (out-of-and in-domain) language models, 5 translation model features, distortion and word penalty).", "labels": [], "entities": []}, {"text": "The hypergraph experiments used additionally lexicalized sparse features: rule-id features, rule source and target bigram features, and rule shape features.", "labels": [], "entities": []}, {"text": "For all SMT experiments we tokenized, lowercased and aligned words using cdec tools, trained 4-gram in-domain and out-of-domain language models (on the English sides of Europarl and in-domain NewsCommentary) For dense feature models, the out-of-domain baseline SMT model was trained on 1.6M parallel Europarl data and tuned with cdec's lattice MERT on out-of-domain Europarl dev2006 dev set (2,000 sent.).", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.993634819984436}, {"text": "Europarl", "start_pos": 169, "end_pos": 177, "type": "DATASET", "confidence": 0.8996427059173584}, {"text": "SMT", "start_pos": 261, "end_pos": 264, "type": "TASK", "confidence": 0.9719780683517456}, {"text": "Europarl data", "start_pos": 300, "end_pos": 313, "type": "DATASET", "confidence": 0.8856648206710815}, {"text": "MERT", "start_pos": 344, "end_pos": 348, "type": "METRIC", "confidence": 0.9779382944107056}, {"text": "Europarl dev2006 dev set", "start_pos": 366, "end_pos": 390, "type": "DATASET", "confidence": 0.8891631960868835}]}, {"text": "The full-information in-domain SMT model tuned by MERT on news in-domain sets (nc-dev2007, 1,057 sent.) gives the range of possible improvements by the difference of its BLEU score to the one of the out-of-domain model (2.5 BLEU points).", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8788763880729675}, {"text": "MERT", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.7191893458366394}, {"text": "BLEU", "start_pos": 170, "end_pos": 174, "type": "METRIC", "confidence": 0.9992038607597351}, {"text": "BLEU", "start_pos": 224, "end_pos": 228, "type": "METRIC", "confidence": 0.9984309077262878}]}, {"text": "For sparse feature models, in-domain and out-of-domain baselines were trained on the same data using MIRA).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.7986937761306763}]}, {"text": "The in-domain MIRA model contains 133,531 active features, the out-of-domain MIRA model 214,642.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.6096922159194946}, {"text": "MIRA", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.5863294005393982}]}, {"text": "MERT and MIRA runs for both settings were repeated 7 times and median results are reported.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8546320199966431}, {"text": "MIRA", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9471092224121094}]}, {"text": "Learning under bandit feedback starts at the learned weights of the out-of-domain median models.", "labels": [], "entities": []}, {"text": "It uses the parallel in-domain data (news-commentary, 40,444 sent.) to simulate bandit feedback, by evaluating the sampled translation against the reference using as loss function \u2206 a smoothed per-sentence 1 \u2212 BLEU (zero n-gram counts being replaced with 0.01).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 210, "end_pos": 214, "type": "METRIC", "confidence": 0.9972078204154968}]}, {"text": "For pairwise preference learning we use binary feedback resulting from the comparison of the BLEU scores of the sampled translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9988468885421753}]}, {"text": "To speedup training for hypergraph re-decoding, the training instances were reduced to those with at most 60 words (38,350 sent.).", "labels": [], "entities": [{"text": "hypergraph re-decoding", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.8759297430515289}]}, {"text": "Training is distributed across 38 shards using multitask-based feature selection for sparse models, where after each epoch of distributed training, the top 10k features across all shards are selected, all other features are set to zero.", "labels": [], "entities": []}, {"text": "The meta-parameters were adjusted on the in-domain dev sets (nc-devtest2007, 1,064 parallel sentences).", "labels": [], "entities": []}, {"text": "The final results are obtained on separate in-domain test sets (nc-test2007, 2,007 sentences) by averaging three independent runs for the optimal dev set meta-parameters.", "labels": [], "entities": []}, {"text": "The results for n-best re-ranking in (4th row) show statistically significant improvements of 1-2 BLEU points over the out-of-domain SMT model (that includes an in-domain language model) for all bandit learning methods, confirming the results of fora different decoder.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9984825253486633}, {"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.9687016010284424}]}, {"text": "Similarly, the results for hypergraph re-coding with sparse feature models (row 5 in) show significant improvements over the out-of-domain baseline for all bandit learners.", "labels": [], "entities": []}, {"text": "Table 3 (row 4) shows the convergence speed for nbest re-ranking, which is similar for Algorithms 2 and 3, and improved over Algorithm 1 by a factor of 3.", "labels": [], "entities": []}, {"text": "For hypergraph re-decoding, shows fastest convergence for Algorithm 2 com-pared to Algorithms 1 and 3 by a factor of 2-4.", "labels": [], "entities": [{"text": "convergence", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.977824866771698}]}, {"text": "Again, we note that for both n-best re-ranking and hypergraph re-decoding, learning rates are similar for Algorithms 1 and 2, and smaller learning rates in Algorithm 3 are compensated by variance reduction or regularization.", "labels": [], "entities": []}, {"text": "shows the learning curves of BLEU for SMT hypergraph re-decoding on the development set that were used to find the stopping points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9871101379394531}, {"text": "SMT hypergraph re-decoding", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.8646257519721985}]}, {"text": "For each algorithm, we show learning curves for three runs with different random seeds, together with an average learning curve.", "labels": [], "entities": []}, {"text": "We see that Algorithm 2, optimizing the pairwise preference ranking objective, reaches the stopping point of peak performance on development data fastest, followed by Algorithms 1 and 3.", "labels": [], "entities": []}, {"text": "Furthermore, the larger variance of the runs of Algorithm 3 is visible, despite the smallest learning rate used.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Test set evaluation for full information lower and upper bounds and partial information bandit  learners (expected loss, pairwise loss, cross-entropy). \u2191 and \u2193 indicate the direction of improvement for  the respective evaluation metric.", "labels": [], "entities": []}]}