{"title": [{"text": "Natural Language Inference by Tree-Based Convolution and Heuristic Matching", "labels": [], "entities": [{"text": "Natural Language Inference", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6922764182090759}]}], "abstractContent": [{"text": "In this paper, we propose the TBCNN-pair model to recognize entailment and contradiction between two sentences.", "labels": [], "entities": []}, {"text": "In our model, a tree-based convolutional neu-ral network (TBCNN) captures sentence-level semantics; then heuristic matching layers like concatenation, element-wise product/difference combine the information in individual sentences.", "labels": [], "entities": []}, {"text": "Experimental results show that our model outper-forms existing sentence encoding-based approaches by a large margin.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognizing entailment and contradiction between two sentences (called a premise and a hypothesis) is known as natural language inference (NLI) in.", "labels": [], "entities": []}, {"text": "Provided with a premise sentence, the task is to judge whether the hypothesis can be inferred (entailment), or the hypothesis cannot be true (contradiction).", "labels": [], "entities": []}, {"text": "Several examples are illustrated in NLI is in the core of natural language understanding and has wide applications in NLP, e.g., question answering ( ) and automatic summarization ().", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.6556641757488251}, {"text": "question answering", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.9146438241004944}, {"text": "automatic summarization", "start_pos": 156, "end_pos": 179, "type": "TASK", "confidence": 0.5165013670921326}]}, {"text": "Moreover, NLI is also related to other tasks of sentence pair modeling, including paraphrase detection (), relation recognition of discourse units (, etc.", "labels": [], "entities": [{"text": "sentence pair modeling", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7227028012275696}, {"text": "paraphrase detection", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.8488744497299194}, {"text": "relation recognition of discourse units", "start_pos": 107, "end_pos": 146, "type": "TASK", "confidence": 0.876149344444275}]}, {"text": "Traditional approaches to NLI mainly fall into two groups: feature-rich models and formal reasoning methods.", "labels": [], "entities": []}, {"text": "Feature-based approaches typically leverage machine learning models, but require intensive human engineering to represent lexical and syntactic information in two sentences * Equal contribution.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our TBCNN-pair model, we used the newly published Stanford Natural Language Inference (SNLI) dataset.", "labels": [], "entities": [{"text": "Stanford Natural Language Inference (SNLI) dataset", "start_pos": 62, "end_pos": 112, "type": "DATASET", "confidence": 0.7097322195768356}]}, {"text": "The dataset is constructed by crowdsourced efforts, each sentence written by humans.", "labels": [], "entities": []}, {"text": "Moreover, the SNLI dataset is magnitudes of larger than previous resources, and hence is particularly suitable for comparing neural models.", "labels": [], "entities": [{"text": "SNLI dataset", "start_pos": 14, "end_pos": 26, "type": "DATASET", "confidence": 0.7889517247676849}]}, {"text": "The target labels comprise three classes: Entailment, Contradiction, and Neutral (two irrelevant sentences).", "labels": [], "entities": [{"text": "Neutral", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.9412444829940796}]}, {"text": "We applied the standard train/validation/test split, contraining 550k, 10k, and 10k samples, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the Stanford Natural Lan- guage Inference dataset where each sentence is  parsed into a dependency parse tree.", "labels": [], "entities": [{"text": "Stanford Natural Lan- guage Inference dataset", "start_pos": 28, "end_pos": 73, "type": "DATASET", "confidence": 0.9078926614352635}]}, {"text": " Table 3: Accuracy of the TBCNN-pair model in  comparison with previous results ( b", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9989252686500549}]}, {"text": " Table 4: Validation and test accuracies of  TBCNN-pair variants (in percentage).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.8643662333488464}]}]}