{"title": [{"text": "Cross-Lingual Sentiment Classification with Bilingual Document Representation Learning", "labels": [], "entities": [{"text": "Cross-Lingual Sentiment Classification", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7305144270261129}, {"text": "Bilingual Document Representation", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.6625117262204488}]}], "abstractContent": [{"text": "Cross-lingual sentiment classification aims to adapt the sentiment resource in a resource-rich language to a resource-poor language.", "labels": [], "entities": [{"text": "Cross-lingual sentiment classification", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7695606549580892}]}, {"text": "In this study, we propose a representation learning approach which simultaneously learns vector representations for the texts in both the source and the target languages.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.9005182385444641}]}, {"text": "Different from previous research which only gets bilingual word embedding, our Bilingual Document Representation Learning model BiDRL directly learns document representations.", "labels": [], "entities": [{"text": "Bilingual Document Representation Learning", "start_pos": 79, "end_pos": 121, "type": "TASK", "confidence": 0.7376502752304077}]}, {"text": "Both semantic and sentiment correlations are utilized to map the bilingual texts into the same embedding space.", "labels": [], "entities": []}, {"text": "The experiments are based on the multilingual multi-domain Amazon review dataset.", "labels": [], "entities": [{"text": "Amazon review dataset", "start_pos": 59, "end_pos": 80, "type": "DATASET", "confidence": 0.6669934988021851}]}, {"text": "We use English as the source language and use Japanese, German and French as the target languages.", "labels": [], "entities": []}, {"text": "The experimental results show that BiDRL outperforms the state-of-the-art methods for all the target languages.", "labels": [], "entities": [{"text": "BiDRL", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.6612381935119629}]}], "introductionContent": [{"text": "Sentiment analysis for online user-generated contents has become a hot research topic during the last decades.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9544526934623718}]}, {"text": "Among all the sentiment analysis tasks, polarity classification is the most widely studied topic.", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.9501506090164185}, {"text": "polarity classification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.9396785497665405}]}, {"text": "It has been proved to be invaluable in many applications, such as opinion polling), customer feedback tracking), election prediction (, stock market prediction) and soon.", "labels": [], "entities": [{"text": "opinion polling", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.6939346790313721}, {"text": "customer feedback tracking", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.612083782752355}, {"text": "election prediction", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.7429588437080383}, {"text": "stock market prediction", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.6159725288550059}]}, {"text": "Most of the current sentiment classification systems are built on supervised machine learning algorithms which require manually labelled data.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.953253835439682}]}, {"text": "However, sentiment resources are usually unbalanced in different languages.", "labels": [], "entities": []}, {"text": "Cross-lingual sentiment classification aims to leverage the resources in a resource-rich language (such as English) to classify the sentiment polarity of texts in a resource-poor language (such as Japanese).", "labels": [], "entities": [{"text": "Cross-lingual sentiment classification", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7772716283798218}]}, {"text": "The biggest challenge for cross-lingual sentiment classification is the vocabulary gap between the source language and the target language.", "labels": [], "entities": [{"text": "cross-lingual sentiment classification", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.8852494955062866}]}, {"text": "This problem is addressed with different strategies in different approaches.", "labels": [], "entities": []}, {"text": "use machine translation tools to translate the training data directly into the target language. and exploit parallel unlabeled data to bridge the language barrier.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7072227597236633}]}, {"text": "use correspondence learning algorithm to learn a map between the source language and the target language.", "labels": [], "entities": []}, {"text": "Recently, representation learning methods has been proposed to solve the cross-lingual classification problem).", "labels": [], "entities": [{"text": "representation learning", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9432823359966278}, {"text": "cross-lingual classification", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.7548102140426636}]}, {"text": "These methods aim to learn common feature representations for different languages.", "labels": [], "entities": []}, {"text": "However, most of the current researches only focus on bilingual word embedding.", "labels": [], "entities": []}, {"text": "In addition, these models only use the semantic correlations between aligned words or sentences in different languages while the sentiment correlations are ignored.", "labels": [], "entities": []}, {"text": "In this study, we propose a cross-lingual representation learning model BiDRL which simultaneously learns both the word and document representations in both languages.", "labels": [], "entities": []}, {"text": "We propose a joint learning algorithm which exploits both monolingual and bilingual constraints.", "labels": [], "entities": []}, {"text": "The monolingual constraints help to model words and documents in each individual language while the bilingual constraints help to build a consistent embedding space across languages.", "labels": [], "entities": []}, {"text": "For each individual language, we extend the paragraph vector model ( to obtain word and document embeddings.", "labels": [], "entities": []}, {"text": "The traditional paragraph vector model is fully unsupervised without using the valuable sentiment labels.", "labels": [], "entities": []}, {"text": "We extend it into a semi-supervised manner by forcing the positive and negative documents to fall into different sides of a classification hyperplane.", "labels": [], "entities": []}, {"text": "Learning task-specific embedding has been proved to be effective in previous research.", "labels": [], "entities": []}, {"text": "To address the cross-language problem, different strategies are proposed to obtain a consistent embedding space across different languages.", "labels": [], "entities": []}, {"text": "Both sentiment and semantic relatedness are exploited while previous studies only use the semantic connection between parallel sentences or documents.", "labels": [], "entities": []}, {"text": "The performance of BiDRL is evaluated on a multilingual multi-domain Amazon review dataset.", "labels": [], "entities": [{"text": "Amazon review dataset", "start_pos": 69, "end_pos": 90, "type": "DATASET", "confidence": 0.6856515010197958}]}, {"text": "By selecting English as the source language, a total of nine tasks are evaluated with different combinations of three different target languages and three different domains.", "labels": [], "entities": []}, {"text": "The proposed method achieves the stateof-the-art performance on all the tasks.", "labels": [], "entities": []}, {"text": "The main contributions of this study are summarized as follows: 1) We propose a novel representation learning method BiDRL which directly learns bilingual document representations for cross-lingual sentiment classification.", "labels": [], "entities": [{"text": "cross-lingual sentiment classification", "start_pos": 184, "end_pos": 222, "type": "TASK", "confidence": 0.7931587894757589}]}, {"text": "Different from previous studies which only obtain word embeddings, our model can learn vector representations for both words and documents in bilingual texts.", "labels": [], "entities": []}, {"text": "2) Our model leverages both the semantic and sentiment correlations between bilingual documents.", "labels": [], "entities": []}, {"text": "Not only the parallel documents but also the documents with the same sentiment are required to get similar representations.", "labels": [], "entities": []}, {"text": "3) Our model achieves the state-of-the-art performances on nine benchmark cross-lingual sentiment classification tasks and it consistently outperforms the existing methods by a large margin.", "labels": [], "entities": [{"text": "cross-lingual sentiment classification", "start_pos": 74, "end_pos": 112, "type": "TASK", "confidence": 0.6802258690198263}]}], "datasetContent": [{"text": "We use the multilingual multi-domain Amazon review dataset 2 created by.", "labels": [], "entities": [{"text": "Amazon review dataset", "start_pos": 37, "end_pos": 58, "type": "DATASET", "confidence": 0.7559349735577902}]}, {"text": "It contains three different domains book, DVD and music.", "labels": [], "entities": []}, {"text": "Each domain has reviews in four different languages English, German, French and Japanese.", "labels": [], "entities": []}, {"text": "In our experiments, we use English as the source language and the rest three as target languages.", "labels": [], "entities": []}, {"text": "Therefore, we have a total of nine tasks with different combinations of three domains and three target languages.", "labels": [], "entities": []}, {"text": "For each task, the training and test datasets have 1000 positive reviews and 1000 negative reviews.", "labels": [], "entities": []}, {"text": "There are also several thousand of unlabeled reviews but the quantity of them varies significantly for different tasks.", "labels": [], "entities": []}, {"text": "Following, when there are more than 50000 unlabeled reviews we randomly selected 50000 of them, otherwise we use all the unlabeled reviews.", "labels": [], "entities": []}, {"text": "The detailed statistics of the dataset are shown in.", "labels": [], "entities": []}, {"text": "We translated the 2000 training reviews and 2000 test reviews into the other languages using Google Translate. has already provided the translation of the test data.", "labels": [], "entities": []}, {"text": "We only need to translate the English training data into the three target languages.", "labels": [], "entities": []}, {"text": "All the review texts are tokenized and converted into lowercase.", "labels": [], "entities": []}, {"text": "We use Mecab 3 to segment the Japanese reviews.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Cross-lingual sentiment classification accuracy for the nine tasks. For all the methods, we get  ten different runs of the algorithm and calculate the mean accuracy.", "labels": [], "entities": [{"text": "Cross-lingual sentiment classification", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.7594910264015198}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9652096629142761}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.6641296744346619}]}, {"text": " Table 1: The amount of unlabeled reviews used in  the experiments. There are also 1000 positive and  1000 negative reviews both for training and test in  each task, i.e. |S| = |T | = 2000.", "labels": [], "entities": []}, {"text": " Table 3: Influence of the sentiment information.  We only show the mean accuracy of the nine tasks  due to space limit.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.982337474822998}]}]}