{"title": [{"text": "Transition-based dependency parsing with topological fields", "labels": [], "entities": [{"text": "Transition-based dependency parsing", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5968095560868582}]}], "abstractContent": [{"text": "The topological field model is commonly used to describe the regularities in German word order.", "labels": [], "entities": []}, {"text": "In this work, we show that topological fields can be predicted reliably using sequence labeling and that the predicted field labels can inform a transition-based dependency parser.", "labels": [], "entities": []}], "introductionContent": [{"text": "The topological field model has traditionally been used to account for regularities in word order across different clause types of German.", "labels": [], "entities": []}, {"text": "This model assumes that each clause type contains a left bracket (LK) and aright bracket (RK), which appear to the left and the right of the middle field (MF).", "labels": [], "entities": [{"text": "aright bracket (RK)", "start_pos": 74, "end_pos": 93, "type": "METRIC", "confidence": 0.945837926864624}]}, {"text": "Additionally, in a verb-second declarative clause, the LK is preceded by the initial field (VF) with the RK optionally followed by the final field (NF).", "labels": [], "entities": []}, {"text": "gives examples of topological fields in verb-second declarative (MC) and verb-final relative (RC) clauses.", "labels": [], "entities": [{"text": "verb-second declarative (MC) and verb-final relative (RC) clauses", "start_pos": 40, "end_pos": 105, "type": "TASK", "confidence": 0.6466754029194514}]}, {"text": "Certain syntactic restrictions can be described in terms of topological fields.", "labels": [], "entities": []}, {"text": "For instance, only a single constituent is typically allowed in the VF, while multiple constituents are allowed in the MF and the NF.", "labels": [], "entities": []}, {"text": "Many ordering preferences can also be stated using the model.", "labels": [], "entities": []}, {"text": "For example, in a main clause, placing the subject in the VF and the direct object in the MF is preferred over the opposite order.", "labels": [], "entities": []}, {"text": "In parsing, topological field analysis is often seen as a task that is embedded in parsing itself.", "labels": [], "entities": [{"text": "parsing", "start_pos": 3, "end_pos": 10, "type": "TASK", "confidence": 0.9816826581954956}, {"text": "topological field analysis", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.6222540239493052}]}, {"text": "For instance,,, and train PCFG parsers on The abbreviations are derived from the German terms linke Klammer, rechte treebanks that annotate topological fields as interior nodes.", "labels": [], "entities": []}, {"text": "It is perhaps not surprising that this approach works effectively for phrase structure parsing, because topological fields favor annotations that do not rely on crossing or discontinuous dependencies ().", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.8165139357248942}]}, {"text": "However, the possible role of topological fields in statistical dependency parsing has not been explored much.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.7667398452758789}]}, {"text": "We will show that statistical dependency parsing of German can benefit from knowledge of clause structure as provided by the topological field model.", "labels": [], "entities": [{"text": "statistical dependency parsing of German", "start_pos": 18, "end_pos": 58, "type": "TASK", "confidence": 0.6901098668575287}]}], "datasetContent": [{"text": "To evaluate the proposed topological field model, we use the same partitioning of T\u00fcBa-D/Z and the word and tag embeddings as De.", "labels": [], "entities": []}, {"text": "For training, validation, and evaluation of the parser, we use these splits as-is.", "labels": [], "entities": []}, {"text": "Since we want to test the parser with non-gold topological field annotations as well, we swapped the training and validation data for training our topological field predictor.", "labels": [], "entities": []}, {"text": "The parser was trained using the same hyperparameters and embeddings as in De.", "labels": [], "entities": []}, {"text": "Our topological field predictor is trained using.", "labels": [], "entities": [{"text": "topological field predictor", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.6190339624881744}]}, {"text": "The hyperparameters that we use are summarized in Appendix A. The topological field predictor uses the same word and tag embeddings as the parser.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9114318490028381}]}, {"text": "In, we show the accuracy of the topological field labeler.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9996401071548462}]}, {"text": "The use of a bi-directional LSTM is clearly justified, since it outperforms the stacked unidirectional LSTM by a wide margin.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Parse results with topological fields and  gold topological fields. Parsers that use topolog- ical field information outperform parsers without  access to such information.", "labels": [], "entities": []}, {"text": " Table 8: The ten dependency relations with the  highest LAS \u2206 of the parser with access to gold  topological fields compared to the (de Kok, 2015)  parser.", "labels": [], "entities": [{"text": "LAS \u2206", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9703888893127441}]}]}