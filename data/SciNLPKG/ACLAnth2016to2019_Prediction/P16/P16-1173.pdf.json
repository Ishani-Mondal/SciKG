{"title": [{"text": "Phrase Structure Annotation and Parsing for Learner English", "labels": [], "entities": [{"text": "Phrase Structure Annotation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8641277352968851}]}], "abstractContent": [{"text": "There has been almost no work on phrase structure annotation and parsing specially designed for learner English despite the fact that they are useful for representing the structural characteristics of learner En-glish.", "labels": [], "entities": [{"text": "phrase structure annotation and parsing", "start_pos": 33, "end_pos": 72, "type": "TASK", "confidence": 0.7989121913909912}]}, {"text": "To address this problem, in this paper , we first propose a phrase structure annotation scheme for learner English and annotate two different learner corpora using it.", "labels": [], "entities": []}, {"text": "Second, we show their usefulness, reporting on (a) inter-annotator agreement rate, (b) characteristic CFG rules in the corpora, and (c) parsing performance on them.", "labels": [], "entities": []}, {"text": "In addition, we explore methods to improve phrase structure parsing for learner English (achieving an F-measure of 0.878).", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.7681266268094381}, {"text": "F-measure", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.999201238155365}]}, {"text": "Finally, we release the full annotation guidelines, the annotated data, and the improved parser model for learner English to the public.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learner corpora have been essential for NLP tasks related to learner language such as grammatical error correction.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.5750969250996908}]}, {"text": "They are normally annotated with linguistic properties.", "labels": [], "entities": []}, {"text": "In the beginning, attention was mainly focused on grammatical error annotation (.", "labels": [], "entities": [{"text": "grammatical error annotation", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.6052676737308502}]}, {"text": "Recently, it has been expanded to grammatical annotation -first, Part-Of-Speech (POS) tagging) and then syntactic annotation (; syntactic annotation for learner corpora is now intensively studied.", "labels": [], "entities": [{"text": "Part-Of-Speech (POS) tagging", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6463403582572937}]}, {"text": "Among a variety of studies, a series of work by) is important in that they proposed a dependency annotation scheme, theoretically and empirically evaluated it, and revealed its theoretical problems, which gives a good starting point to those who wish to develop anew annotation scheme for learner corpora.", "labels": [], "entities": []}, {"text": "Researchers including and have even started using dependencyannotated learner corpora to develop dependency parsers for learner language.", "labels": [], "entities": []}, {"text": "Although research on syntactic analysis for learner corpora has been making great progress as noted above, it is not yet complete.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7526054680347443}]}, {"text": "There are at least three limitations in the previous work: (i) as far as we are aware, there has been almost no work on phrase structure annotation specially designed for learner corpora; (ii) there are no publicly available learner corpora annotated with syntax; (iii) phrase structure parsing performance on learner English has not yet been reported.", "labels": [], "entities": [{"text": "phrase structure annotation", "start_pos": 120, "end_pos": 147, "type": "TASK", "confidence": 0.7695988019307455}, {"text": "phrase structure parsing", "start_pos": 270, "end_pos": 294, "type": "TASK", "confidence": 0.8010391394297282}]}, {"text": "The first limitation is that there exists no phrase structure annotation scheme specially designed for learner English.", "labels": [], "entities": []}, {"text": "As related work, and propose a method for creating a pseudo-learner corpus by artificially generating errors in a native corpus with phrase structures.", "labels": [], "entities": []}, {"text": "However, the resulting corpus does not capture various error patterns in learner English.", "labels": [], "entities": []}, {"text": "Concerning the second limitation, a corpus greatly increases in value when it is available to the public as has been seen in other domains.", "labels": [], "entities": []}, {"text": "Nevertheless, whether dependency or phrase structure, there seems to be no publicly available learner corpora annotated with syntax.", "labels": [], "entities": []}, {"text": "The above two limitations cause the third one that phrase structure parsing performance on leaner has not yet been reported.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7952075401941935}]}, {"text": "For this reason, Cahill (2015) demonstrates how ac-curately an existing parser performs on a pseudolearner corpus (section 23 of WSJ with errors artificially generated by's method).", "labels": [], "entities": [{"text": "WSJ", "start_pos": 129, "end_pos": 132, "type": "DATASET", "confidence": 0.9470875263214111}]}, {"text": "show the performance of a phrase structure parser augmented by self-training on students' essays, many of which are presumably written by native speakers of English.", "labels": [], "entities": [{"text": "phrase structure parser", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7535471320152283}]}, {"text": "partially show phrase structure parsing performance concerning preposition usage in learner English, concluding that it is effective in extracting features for preposition error correction.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.765925943851471}, {"text": "preposition error correction", "start_pos": 160, "end_pos": 188, "type": "TASK", "confidence": 0.7156206568082174}]}, {"text": "We need to reveal full parsing performance to be able to confirm that this is true for other syntactic categories and whether or not we should use phrase structure parsing to facilitate related tasks such as grammatical error correction and automated essay scoring.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 147, "end_pos": 171, "type": "TASK", "confidence": 0.7016839881738027}, {"text": "grammatical error correction", "start_pos": 208, "end_pos": 236, "type": "TASK", "confidence": 0.5972243944803873}, {"text": "essay scoring", "start_pos": 251, "end_pos": 264, "type": "TASK", "confidence": 0.6476239114999771}]}, {"text": "Here, we emphasize that phrase structure annotation has at least two advantages over dependency annotation . First of all, it can directly encode information about word order.", "labels": [], "entities": [{"text": "phrase structure annotation", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.7247834404309591}]}, {"text": "This is particularly important because learner corpora often contain errors in word order.", "labels": [], "entities": []}, {"text": "For example, phrase structure parsing will reveal in which phrases errors in word order tend to occur as we will partly do in Sect.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.8006068468093872}]}, {"text": "3. Second of all, phrase structure rather abstractly represents syntactic information in terms of phrase-to-phrase relations.", "labels": [], "entities": []}, {"text": "This means that the characteristics of learner English are represented by means of phrase-to-phrase relations (e.g., context free grammar (CFG) rules) or even as trees.", "labels": [], "entities": []}, {"text": "Take as an example, one of the characteristic trees we found in the corpora we have created: S NP VP \u03d5 ADJP As we will discuss in Sect.", "labels": [], "entities": []}, {"text": "3, this tree suggests the mother tongue interference that the copula is not necessary in adjective predicates in certain languages.", "labels": [], "entities": []}, {"text": "It would be linguistically interesting to reveal what CFG rules we need to add to, or subtract from, the native CFG rule set to be able to generate learner English.", "labels": [], "entities": [{"text": "CFG rule set", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.9211024045944214}]}, {"text": "This is our primary motivation for this work although our other motivations include developing a parser for learner English.", "labels": [], "entities": []}, {"text": "In view of this background, we address the above problems in this paper.", "labels": [], "entities": []}, {"text": "First, we present a phrase structure annotation scheme for dealing with learner English consistently and reliably.", "labels": [], "entities": []}, {"text": "For this, we propose five principles which can be applied to creating a novel annotation scheme for learner corpora.", "labels": [], "entities": []}, {"text": "Second, we evaluate the usefulness of the annotation scheme by annotating learner corpora using it.", "labels": [], "entities": []}, {"text": "To be precise, we report on inter-annotator agreement rate and characteristic CFG rules in the corpora, and take the first step to revealing phrase structure parsing performance on learner English.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 141, "end_pos": 165, "type": "TASK", "confidence": 0.7208947141965231}]}, {"text": "In addition, we explore methods to improve phrase structure parsing for learner English.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.7927567760149637}]}, {"text": "Finally, we release the full annotation guidelines, the annotated corpora, and the improved parser model to the public.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "2 describes the annotation scheme.", "labels": [], "entities": []}, {"text": "3 explores the annotated learner corpora.", "labels": [], "entities": []}, {"text": "4 evaluates parsing performance using it.", "labels": [], "entities": [{"text": "parsing", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.9599690437316895}]}], "datasetContent": [{"text": "We tested the following two state-of-the-art parsers on the annotated data: Stanford Statistical Natural Language Parser (ver.2.0.3) () and Charniak-Johnson parser).", "labels": [], "entities": [{"text": "Stanford Statistical Natural Language Parser", "start_pos": 76, "end_pos": 120, "type": "DATASET", "confidence": 0.8369925141334533}]}, {"text": "We gave the tokenized sentences to them as their inputs.", "labels": [], "entities": []}, {"text": "We used again the EVALB tool with the Collins (1997)'s evaluation parameter.", "labels": [], "entities": [{"text": "Collins (1997)'", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.8970446139574051}]}, {"text": "To our surprise, both parsers perform very well on the learner corpora despite the fact that it contains a number of grammatical errors and also syntactic tags that are not defined in PTB-II.", "labels": [], "entities": [{"text": "PTB-II", "start_pos": 184, "end_pos": 190, "type": "DATASET", "confidence": 0.9259704351425171}]}, {"text": "Their performance is comparable to, or even better than, that on the Penn Treebank (reported in).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.9910787642002106}]}, {"text": "To achieve further improvement, we augmented the Charniak-Johnson parser with the learner data.", "labels": [], "entities": []}, {"text": "We first retrained its parser model using the 2-21 sections of Penn Treebank Wall Street Journal (hereafter, WSJ) as training data and its 24 section as development data, following the settings shown in  each of which approximately consisted of 61 essays, used one sixth as test data, another one sixth as development data instead of the 24 section, and retrained the parser model using the development data and the training data consisting of the remaining four-sixths part of the learner data and the 2-21 sections of WSJ.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal", "start_pos": 63, "end_pos": 96, "type": "DATASET", "confidence": 0.9818935513496398}, {"text": "WSJ", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.8210276961326599}, {"text": "WSJ", "start_pos": 520, "end_pos": 523, "type": "DATASET", "confidence": 0.9881646633148193}]}, {"text": "We also conducted experiments where we copied the four sixths of the learner data n times (1 \u2264 n \u2264 50) and added them to the training data to increase its weight in retraining.", "labels": [], "entities": []}, {"text": "The simple addition of the learner data (n = 1) already outperforms the parser trained only on the 2-21 sections of WSJ (n = 0) in both recall and precision, achieving an F -measure of 0.866 and a complete match rate of 0.515.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.8700229525566101}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9990047812461853}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9965983033180237}, {"text": "F -measure", "start_pos": 171, "end_pos": 181, "type": "METRIC", "confidence": 0.9952954649925232}, {"text": "complete match rate", "start_pos": 197, "end_pos": 216, "type": "METRIC", "confidence": 0.788351039091746}]}, {"text": "The augmented parser model particularly works well on recognizing erroneous fragments in the learner data; F -measure improved to 0.796 (n = 1) from 0.683 (n = 0) in the sentences containing fragments (i.e., FRAG) (46 out of the 111 sentences that were originally erroneously parsed made even a complete match).", "labels": [], "entities": [{"text": "F -measure", "start_pos": 107, "end_pos": 117, "type": "METRIC", "confidence": 0.9943995674451193}, {"text": "FRAG", "start_pos": 208, "end_pos": 212, "type": "METRIC", "confidence": 0.9526240229606628}]}, {"text": "It was also robust against spelling errors.", "labels": [], "entities": []}, {"text": "The performance further improves as the weight n increases (up to F = 0.878 when n = 24), which shows the effectiveness of using learner corpus data as training data.", "labels": [], "entities": [{"text": "F", "start_pos": 66, "end_pos": 67, "type": "METRIC", "confidence": 0.9988580942153931}]}, {"text": "ICNALE (classified by country code 9 ).", "labels": [], "entities": [{"text": "ICNALE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8649762272834778}]}, {"text": "In most of the sub-corpora, the parser achieves an F -measure of 0.800 or better.", "labels": [], "entities": [{"text": "F -measure", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9961371024449667}]}, {"text": "By contrast, it performs much worse on the Korean sub-corpus.", "labels": [], "entities": []}, {"text": "The major reason for this is that it contains a number of word order errors (i.e., XP-ORD); to be precise, 27 instances compared to zero to two instances in the other sub-corpora.", "labels": [], "entities": [{"text": "XP-ORD", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9386469721794128}]}, {"text": "Similarly, FRAG is a source of parsing errors in the Thai sub-corpus.", "labels": [], "entities": [{"text": "FRAG", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.7518245577812195}, {"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9729382991790771}, {"text": "Thai sub-corpus", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.9005896151065826}]}, {"text": "We need further investigation to determine whether the differences in parsing performance are due to the writers' mother tongue or other factors (e.g., proficiency).", "labels": [], "entities": [{"text": "parsing", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.9760484099388123}]}, {"text": "We can summarize the findings as follows: (1) the state-of-the-art phrase structure parsers for native English are effective even in parsing learner English; (2) they are successfully augmented by learner corpus data; (3) the evaluation results support the previous report) that they are effective in extracting parse features for grammatical error correction (and probably for related NLP tasks such as automated essay scoring); (4) however, performance may vary depending on the writer's mother tongue and/or other factors, which we need further investigation to confirm.", "labels": [], "entities": [{"text": "phrase structure parsers", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.7058025201161703}, {"text": "parsing learner English", "start_pos": 133, "end_pos": 156, "type": "TASK", "confidence": 0.8279668887456259}, {"text": "extracting parse", "start_pos": 301, "end_pos": 317, "type": "TASK", "confidence": 0.8468599319458008}, {"text": "grammatical error correction", "start_pos": 331, "end_pos": 359, "type": "TASK", "confidence": 0.6100569466749827}, {"text": "essay scoring", "start_pos": 414, "end_pos": 427, "type": "TASK", "confidence": 0.6661577224731445}]}], "tableCaptions": [{"text": " Table 2: Statistics on annotated learner corpora.", "labels": [], "entities": []}, {"text": " Table 3: Inter-annotator agreement measured in Recall (R), Precision (P ), F -measure (F ), Complete  Match Rate (CMR), and Chance-Corrected Measure (CCM).", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9478470683097839}, {"text": "Precision (P )", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.9475954920053482}, {"text": "F -measure (F )", "start_pos": 76, "end_pos": 91, "type": "METRIC", "confidence": 0.9772209127744039}, {"text": "Complete  Match Rate (CMR)", "start_pos": 93, "end_pos": 119, "type": "METRIC", "confidence": 0.9066643317540487}, {"text": "Chance-Corrected Measure (CCM)", "start_pos": 125, "end_pos": 155, "type": "METRIC", "confidence": 0.8262791275978089}]}, {"text": " Table 4: Characteristic CFG rules.", "labels": [], "entities": [{"text": "Characteristic CFG", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6313219666481018}]}, {"text": " Table 5: Parsing performance on learner English.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9441239237785339}]}]}