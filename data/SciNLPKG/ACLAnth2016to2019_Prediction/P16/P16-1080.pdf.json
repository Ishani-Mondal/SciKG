{"title": [{"text": "Analyzing Biases in Human Perception of User Age and Gender from Text", "labels": [], "entities": [{"text": "Analyzing Biases in Human Perception of User Age and Gender from Text", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8211984758575758}]}], "abstractContent": [{"text": "User traits disclosed through written text, such as age and gender, can be used to per-sonalize applications such as recommender systems or conversational agents.", "labels": [], "entities": []}, {"text": "However, human perception of these traits is not perfectly aligned with reality.", "labels": [], "entities": []}, {"text": "In this paper, we conduct a large-scale crowdsourcing experiment on guessing age and gender from tweets.", "labels": [], "entities": []}, {"text": "We systematically analyze the quality and possible biases of these predictions.", "labels": [], "entities": []}, {"text": "We identify the textual cues which lead to miss-assessments of traits or make annota-tors more or less confident in their choice.", "labels": [], "entities": []}, {"text": "Our study demonstrates that differences between real and perceived traits are noteworthy and elucidates inaccurately used stereotypes inhuman perception.", "labels": [], "entities": []}], "introductionContent": [{"text": "There are notable differences between actual user traits and their perception by others).", "labels": [], "entities": []}, {"text": "Assessments of the perceived traits are dependent, for example, on the interpretation skills of a judge and the ability of users to deliberately adjust their behavior to the way they intend to be perceived e.g., for following asocial goal).", "labels": [], "entities": []}, {"text": "People typically use stereotypes -a set of beliefs, generalizations, and associations about asocial groupto make judgements about others.", "labels": [], "entities": []}, {"text": "The discrepancy between stereotypes and actual group differences is * Project carried out during a research stay at the University of Pennsylvania an important topic in psychological research).", "labels": [], "entities": []}, {"text": "Such differences are likely reflected through one's writing.", "labels": [], "entities": []}, {"text": "With the Internet a substantial part of daily life, users leave enough footprints which allow algorithms to learn a range of individual traits, some with even higher accuracy than the users' own family (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9951589703559875}]}, {"text": "With an increase in readily available user generated content, prediction of user attributes has become more popular than ever.", "labels": [], "entities": [{"text": "prediction of user attributes", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.864125445485115}]}, {"text": "Researchers built learning models to infer different user traits from text, such as age (), gender), location (, political orientation (), income (Preot\u00b8iucPreot\u00b8iuc-Pietro et al., 2015c), socio-economic status), popularity (), personality () or mental illnesses).", "labels": [], "entities": []}, {"text": "Prediction models are trained on large data sets with labels extracted either from user selfreports (Preot\u00b8iucPreot\u00b8iuc-Pietro et al., 2015b) or perceived from annotations ( . The former is useful in obtaining accurate prediction models for unknown users while the latter is more suitable in applications that interact with humans.", "labels": [], "entities": []}, {"text": "Previous studies showed the implications of perceived individual traits to the believability and likability of autonomous agents.", "labels": [], "entities": []}, {"text": "This study aims to emphasize the differences between real user traits and how these are perceived by humans from Twitter posts.", "labels": [], "entities": []}, {"text": "In this context, we address the following research questions: \u2022 How accurate are people at judging traits of other users?", "labels": [], "entities": []}, {"text": "\u2022 Are there systematic biases humans are subject to?", "labels": [], "entities": []}, {"text": "\u2022 What are the implications of using human perception as a proxy for truth?", "labels": [], "entities": []}, {"text": "\u2022 Which textual cues lead to a false perception of the truth?", "labels": [], "entities": []}, {"text": "\u2022 Which textual cues make people more or less confident in their ratings?", "labels": [], "entities": []}, {"text": "We use age and gender as target traits for our analysis, as these are considered basic categories in person assessment) and are highly studied by previous research.", "labels": [], "entities": []}, {"text": "Using a large-scale crowdsourcing experiment, we demonstrate that human annotators are generally accurate in assessing the traits of others.", "labels": [], "entities": []}, {"text": "However, they make systematically different types of errors compared to a prediction model trained using the bag-of-words assumption.", "labels": [], "entities": []}, {"text": "This hints at the fact that annotators over-emphasize some linguistic features based on their stereotypes.", "labels": [], "entities": []}, {"text": "We show how this phenomenon can be leveraged to improve prediction performance and demonstrate that by replacing selfreports with perceived annotations we introduce systematic biases into our models.", "labels": [], "entities": []}, {"text": "In our analysis section, we directly test the accuracy of these stereotypes, as the human predictions must rely on these theories of relative differences between groups if no explicit cues are mentioned.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9987120628356934}]}, {"text": "We uncover remarkable differences between actual and perceived traits by using multiple lexical features: unigrams, clusters of words built from word embeddings and emotions expressed through posts.", "labels": [], "entities": []}, {"text": "In our analysis of features that lead to wrong assessments we uncover that humans mostly rely on accurate stereotypes from textual cues, but sometimes over-emphasize them.", "labels": [], "entities": []}, {"text": "For example, annotators assume that males post more than they do about sports and business, females show more joy, older users more interest in politics and younger users use more slang and are more self-referential.", "labels": [], "entities": []}, {"text": "Similarly, we highlight the textual features which lead to higher self-reported confidence in guesses, such as the mentions of family and beauty products for gender or college and school related topics forage.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use Amazon Mechanical Turk to create crowdsourcing tasks for predicting age and gender from tweets.", "labels": [], "entities": []}, {"text": "Each HIT consists of 20 tweets randomly sampled from the pool of 100 tweets of a single user.", "labels": [], "entities": []}, {"text": "Each user was assessed independently by 9 different annotators.", "labels": [], "entities": []}, {"text": "Using only these tweets as cues, the annotators were asked to predict either age (integer value) or gender (forced choice binary male/female) and self-rate the confidence of their guess on a scale from 1 (not at all confident) to 5 (very confident).", "labels": [], "entities": []}, {"text": "Participants received a small compensation (.02$) for each rating and could repeat the task as many times as they wished, but never for the same author.", "labels": [], "entities": []}, {"text": "They were also presented with an initial bonus (.25$) and a similar one upon completing a number of guesses.", "labels": [], "entities": []}, {"text": "For quality control, we used a set of HITs where the user's age or gender was explicitly stated within the top 10 tweets displayed in the task.", "labels": [], "entities": [{"text": "HITs", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.8980278372764587}]}, {"text": "The control HIT appeared 10% of the time and all annotators missing the correct answer twice were excluded from annotation and all their HITs invalidated.", "labels": [], "entities": []}, {"text": "A total of 28 annotators were banned from the study.", "labels": [], "entities": []}, {"text": "Further, we limited annotator location to the US and they had to spend at least 10 seconds on each HIT before they were allowed to submit their guess.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Normalized confusion matrices of human annotations (Pred.H) to ground truth (Real), classifier  performance (Pred.C) to ground truth (Real), and human annotations (Pred.H) to classifier performance  (Pred.C) on the same data set.", "labels": [], "entities": []}, {"text": " Table 2: Normalized confusion matrices for system  comparison when using perceived or ground truth  labels.", "labels": [], "entities": []}, {"text": " Table 3: Textual features highlighting errors in human perception of gender compared to ground truth  labels. Table shows correlation to perceived gender expression (Perc), to ground truth (Real) and to  perceived gender expression controlled for ground truth (Cont). All correlations of gender unigrams,  topics and emotions are statistically significant at p < .001 (t-test)", "labels": [], "entities": []}, {"text": " Table 4: Textual features highlighting high and low confidence in human perception of gender.", "labels": [], "entities": []}, {"text": " Table 5: Textual features highlighting errors in human perception of age compared to ground truth labels.  Table shows correlation to perceived age expression (Perc), to ground truth (Real) and to perceived age  expression controlled for ground truth (Cont). All correlations of age unigrams, topics and emotions are  statistically significant at p < .001 (t-test), except of the values in brackets.", "labels": [], "entities": []}, {"text": " Table 6: Textual features highlighting high and low confidence in human perception of age. Table shows  correlation to average self-reported confidence (Conf), to ground truth (Real) and with self-reported  confidence controlled for ground truth (Cont). Correlation values of age unigrams, topics and emotions  statistically significant at p < .001 (t-test) unless in brackets.", "labels": [], "entities": []}]}