{"title": [{"text": "Bidirectional Recurrent Convolutional Neural Network for Relation Classification", "labels": [], "entities": [{"text": "Relation Classification", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7967127859592438}]}], "abstractContent": [{"text": "Relation classification is an important semantic processing task in the field of natural language processing (NLP).", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9673174023628235}, {"text": "natural language processing (NLP)", "start_pos": 81, "end_pos": 114, "type": "TASK", "confidence": 0.8197528123855591}]}, {"text": "In this paper , we present a novel model BRCNN to classify the relation of two entities in a sentence.", "labels": [], "entities": [{"text": "BRCNN", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.7248277068138123}]}, {"text": "Some state-of-the-art systems concentrate on modeling the shortest dependency path (SDP) between two entities leveraging convolutional or recurrent neu-ral networks.", "labels": [], "entities": []}, {"text": "We further explore how to make full use of the dependency relations information in the SDP, by combining convolutional neural networks and two-channel recurrent neural networks with long short term memory (LSTM) units.", "labels": [], "entities": []}, {"text": "We propose a bidirectional architecture to learn relation representations with directional information along the SDP forwards and backwards at the same time, which benefits classifying the direction of relations.", "labels": [], "entities": []}, {"text": "Experimental results show that our method outperforms the state-of-the-art approaches on the SemEval-2010 Task 8 dataset.", "labels": [], "entities": [{"text": "SemEval-2010 Task 8 dataset", "start_pos": 93, "end_pos": 120, "type": "DATASET", "confidence": 0.6349923387169838}]}], "introductionContent": [{"text": "Relation classification aims to classify the semantic relations between two entities in a sentence.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9709304869174957}]}, {"text": "For instance, in the sentence \"The e 1 has been caused by water hammer e 2 \", entities burst and pressure are of relation CauseEffect(e 2 , e 1 ).", "labels": [], "entities": []}, {"text": "Relation classification plays a key role in robust knowledge extraction, and has become a hot research topic in recent years.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9621925055980682}, {"text": "robust knowledge extraction", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.5958948334058126}]}, {"text": "Nowadays, deep learning techniques have made significant improvement in relation classification, * Corresponding author compared with traditional relation classification approaches focusing on designing effective features ( or kernels) Although traditional approaches are able to exploit the symbolic structures in sentences, they still suffer from the difficulty to generalize over the unseen words.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.9409851133823395}, {"text": "relation classification", "start_pos": 146, "end_pos": 169, "type": "TASK", "confidence": 0.7333918362855911}]}, {"text": "Some recent works learn features automatically based on neural networks (NN), employing continuous representations of words (word embeddings).", "labels": [], "entities": []}, {"text": "The NN research for relation classification has centered around two main network architectures: convolutional neural networks and recursive/recurrent neural networks.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.9470533132553101}]}, {"text": "Convolutional neural network aims to generalize the local and consecutive context of the relation mentions, while recurrent neural networks adaptively accumulate the context information in the whole sentence via memory units, thereby encoding the global and possibly unconsecutive patterns for relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 294, "end_pos": 317, "type": "TASK", "confidence": 0.793848305940628}]}, {"text": "learned compositional vector representations of sentences with a recursive neural network.", "labels": [], "entities": []}, {"text": "proposed a simple customizaition of recursive neural networks.", "labels": [], "entities": []}, {"text": "proposed a convolutional neural network with position embeddings.", "labels": [], "entities": []}, {"text": "Recently, more attentions have been paid to modeling the shortest dependency path (SDP) of sentences.", "labels": [], "entities": []}, {"text": "developed a dependency-based neural network, in which a convolutional neural network has been used to capture features on the shortest path and a recursive neural network is designed to model subtrees.", "labels": [], "entities": []}, {"text": "applied long short term memory (LSTM) based recurrent neural networks (RNNs) along the shortest dependency path.", "labels": [], "entities": []}, {"text": "However, SDP is a special structure in which every two neighbor words are separated by a dependency relations.", "labels": [], "entities": []}, {"text": "Previous works treated dependency relations in the same way as words or some syntactic features like partof-speech (POS) tags, because of the limitations of convolutional neural networks and recurrent neural networks.", "labels": [], "entities": []}, {"text": "Our first contribution is that we propose a recurrent convolutional neural network (RCNN) to encode the global pattern in SDP utilizing a two-channel LSTM based recurrent neural network and capture local features of every two neighbor words linked by a dependency relation utilizing a convolution layer.", "labels": [], "entities": []}, {"text": "We further observe that the relationship between two entities are directed.", "labels": [], "entities": []}, {"text": "For instance, shows that the shortest path of the sentence \"The e 1 has been caused by water hammer e 2 .\" corresponds to relation CauseEffect(e 2 , e 1 ).", "labels": [], "entities": []}, {"text": "The SDP of the sentence also corresponds to relation Cause-Effect(e 2 , e 1 ), where e 1 refers to the entity at front end of SDP and e 2 refers to the entity at back end of SDP, and the inverse SDP corresponds to relation Cause-Effect(e 1 , e 2 ).", "labels": [], "entities": []}, {"text": "Previous work () simply transforms a (K+1)-relation task into a (2K + 1) classification task, where 1 is the Other relation and K is the number of directed relations.", "labels": [], "entities": []}, {"text": "Besides, the recurrent neural network is a biased model, where later inputs are more dominant than earlier inputs.", "labels": [], "entities": []}, {"text": "It could reduce the effectiveness when it is used to capture the semantics of a whole shortest dependency path, because key components could appear anywhere in a SDP rather than the end.", "labels": [], "entities": []}, {"text": "Our second contribution is that we propose a bidirectional recurrent convolutional neural networks (BRCNN) to learn representations with bidirectional information along the SDP forwards and backwards at the same time, which also strengthen the ability to classifying directions of relationships between entities.", "labels": [], "entities": [{"text": "classifying directions of relationships between entities", "start_pos": 255, "end_pos": 311, "type": "TASK", "confidence": 0.7958611249923706}]}, {"text": "Experimental results show that the bidirectional mechanism significantly improves the performance.", "labels": [], "entities": []}, {"text": "We evaluate our method on the SemEval-2010 relation classification task, and achieve a state-ofthe-art F 1 -score of 86.3%.", "labels": [], "entities": [{"text": "SemEval-2010 relation classification task", "start_pos": 30, "end_pos": 71, "type": "TASK", "confidence": 0.8289507776498795}, {"text": "F 1 -score", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.9897900074720383}]}], "datasetContent": [{"text": "We evaluated our BRCNN model on the SemEval-2010 Task 8 dataset, which is an established benchmark for relation classification The dataset has (K+1)=10 distinguished relations, as follows.", "labels": [], "entities": [{"text": "SemEval-2010 Task 8 dataset", "start_pos": 36, "end_pos": 63, "type": "DATASET", "confidence": 0.773771658539772}, {"text": "relation classification", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.7776203155517578}]}, {"text": "\u2022 Cause-Effect The former K=9 relations are directed, whereas the Other class is undirected, we have (2K+1)=19 different classes for 10 relations.", "labels": [], "entities": []}, {"text": "All baseline systems and our model use the official macroaveraged F 1 -score to evaluate model performance.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9449077993631363}]}, {"text": "This official measurement excludes the Other relation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparing RCNN with CNNs and  RNNS.", "labels": [], "entities": []}]}