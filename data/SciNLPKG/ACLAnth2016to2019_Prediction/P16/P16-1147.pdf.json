{"title": [{"text": "Stack-propagation: Improved Representation Learning for Syntax", "labels": [], "entities": [{"text": "Improved Representation Learning", "start_pos": 19, "end_pos": 51, "type": "TASK", "confidence": 0.7260770996411642}, {"text": "Syntax", "start_pos": 56, "end_pos": 62, "type": "TASK", "confidence": 0.7291867733001709}]}], "abstractContent": [{"text": "Traditional syntax models typically leverage part-of-speech (POS) information by constructing features from hand-tuned templates.", "labels": [], "entities": []}, {"text": "We demonstrate that a better approach is to utilize POS tags as a reg-ularizer of learned representations.", "labels": [], "entities": []}, {"text": "We propose a simple method for learning a stacked pipeline of models which we call \"stack-propagation\".", "labels": [], "entities": []}, {"text": "We apply this to dependency parsing and tagging, where we use the hidden layer of the tagger network as a representation of the input tokens for the parser.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.875269889831543}, {"text": "tagging", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9263655543327332}]}, {"text": "At test time, our parser does not require predicted POS tags.", "labels": [], "entities": []}, {"text": "On 19 languages from the Universal Dependencies, our method is 1.3% (absolute) more accurate than a state-of-the-art graph-based approach and 2.7% more accurate than the most comparable greedy model.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, transition-based dependency parsers powered by neural network scoring functions have dramatically increased the state-of-theart in terms of both speed and accuracy.", "labels": [], "entities": [{"text": "transition-based dependency parsers", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.6064422925313314}, {"text": "speed", "start_pos": 162, "end_pos": 167, "type": "METRIC", "confidence": 0.996042013168335}, {"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.994986891746521}]}, {"text": "Similar approaches also achieve state-ofthe-art in other NLP tasks, such as constituency parsing or semantic role labeling ().", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.9003199636936188}, {"text": "semantic role labeling", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.648588607708613}]}, {"text": "These approaches all share a common principle: replace hand-tuned conjunctions of traditional NLP feature templates with continuous approximations learned by the hidden layer of a feed-forward network.", "labels": [], "entities": []}, {"text": "* Research conducted at Google.", "labels": [], "entities": []}, {"text": "However, state-of-the-art dependency parsers depend crucially on the use of predicted part-ofspeech (POS) tags.", "labels": [], "entities": []}, {"text": "In the pipeline or stacking (Wolpert, 1992) method, these are predicted from an independently trained tagger and used as features in the parser.", "labels": [], "entities": []}, {"text": "However, there are two main disadvantages of a pipeline: (1) errors from the POS tagger cascade into parsing errors, and (2) POS taggers often make mistakes precisely because they cannot take into account the syntactic context of a parse tree.", "labels": [], "entities": []}, {"text": "The POS tags may also contain only coarse information, such as when using the universal tagset of.", "labels": [], "entities": []}, {"text": "One approach to solve these issues has been to avoid using POS tags during parsing, e.g. either using semi-supervised clustering instead of POS tags ( or building recurrent representations of words using neural networks . However, the best accuracy for these approaches is still achieved by running a POS tagger over the data first and combining the predicted POS tags with additional representations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 240, "end_pos": 248, "type": "METRIC", "confidence": 0.9986340403556824}]}, {"text": "As an alternative, a wide range of prior work has investigated jointly modeling both POS and parse trees (;.", "labels": [], "entities": []}, {"text": "However, these approaches typically require sacrificing either efficiency or accuracy compared to the best pipeline model, and often they simply re-rank the predictions of a pipelined POS tagger.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9985070824623108}]}, {"text": "In this work, we show how to improve accuracy for both POS tagging and parsing by incorporating stacking into the architecture of a feed-forward network.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9989261031150818}, {"text": "POS tagging", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.864393025636673}, {"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.8771575689315796}]}, {"text": "We propose a continuous form of stacking that allows for easy backpropagation down the pipeline across multiple tasks, a process we call Stack-propagation uses a continuous and differentiable link between Task A and Task B, allowing for backpropagation from Task B into Task A's model.", "labels": [], "entities": []}, {"text": "Updates to Task A act as regularization on the model for Task B, ensuring the shared component is useful for both tasks.", "labels": [], "entities": []}, {"text": "At the core of this idea is that we use POS tags as regularization instead of features.", "labels": [], "entities": []}, {"text": "Our model design for parsing is very simple: we use the hidden layer of a window-based POS tagging network as the representation of tokens in a greedy, transition-based neural network parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9840835928916931}, {"text": "POS tagging network", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.6687541007995605}]}, {"text": "Both networks are implemented with a refined version of the feed-forward network) from, as described in . We link the tagger network to the parser by translating traditional feature templates for parsing into feed-forward connections from the tagger to the parser.", "labels": [], "entities": []}, {"text": "At training time, we unroll the parser decisions and apply stackpropagation by alternating between stochastic updates to the parsing or tagging objectives ().", "labels": [], "entities": []}, {"text": "The parser's representations of tokens are thus regularized to be individually predictive of POS tags, even as they are trained to be useful for parsing when concatenated and fed into the parser network.", "labels": [], "entities": []}, {"text": "This model is similar to the multi-task network structure of, where Collobert et al.", "labels": [], "entities": []}, {"text": "(2011) shares a hidden layer between multiple tagging tasks.", "labels": [], "entities": []}, {"text": "The primary difference here is that we show how to unroll parser transitions to apply the same principle to tasks with fundamentally different structure.", "labels": [], "entities": []}, {"text": "The key advantage of our approach is that attest time, we do not require predicted POS tags for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 96, "end_pos": 103, "type": "TASK", "confidence": 0.9625683426856995}]}, {"text": "Instead, we run the tagger network up to the hidden layer over the entire sentence, and then dynamically connect the parser network to the tagger network based upon the discrete parser configurations as parsing unfolds.", "labels": [], "entities": []}, {"text": "In this way, we avoid cascading POS tagging errors to the parser.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.6471512168645859}]}, {"text": "As we show in Section 5, our approach can be used in conjunction with joint transition systems in the parser to improve both POS tagging as well as parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.7832347750663757}, {"text": "parsing", "start_pos": 148, "end_pos": 155, "type": "TASK", "confidence": 0.9647879004478455}]}, {"text": "In addition, because the parser re-uses the representation from the tagger, we can drop all lexicalized features from the parser network, leading to a compact, faster model.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe the layout of our combined architecture.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce stackpropagation and show how we train our model.", "labels": [], "entities": []}, {"text": "We evaluate our approach on 19 languages from the Universal Dependencies treebank in Section 4.", "labels": [], "entities": [{"text": "Universal Dependencies treebank", "start_pos": 50, "end_pos": 81, "type": "DATASET", "confidence": 0.7442955374717712}]}, {"text": "We observe a >2% absolute gain in labeled accuracy compared to state-of-the-art, LSTM-based greedy parsers ( ) and a >1% gain compared to a state-of-the-art, graphbased method ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.8901844024658203}]}, {"text": "We also evaluate our method on the Wall Street Journal, where we find that our architecture outperforms other greedy models, especially when only coarse POS tags from the universal tagset are provided during training.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 35, "end_pos": 54, "type": "DATASET", "confidence": 0.9678970575332642}]}, {"text": "In Section 5, we systematically evaluate the different components of our approach to demonstrate the effectiveness of stack-propagation compared to traditional types of joint modeling.", "labels": [], "entities": []}, {"text": "We also show that our approach leads to large reductions in cascaded errors from the POS tagger.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 85, "end_pos": 95, "type": "TASK", "confidence": 0.6006430387496948}]}, {"text": "We hope that this work will motivate further research in combining traditional pipelined structured prediction models with deep neural architectures that learn intermediate representations in a task-driven manner.", "labels": [], "entities": []}, {"text": "One important finding of this work is that, even without POS tags, our architecture outperforms recurrent approaches that build custom word representations using character-based LSTMs ( . These results suggest that learning rich embeddings of words may not be as important as building an intermediate representation that takes multiple features of the surrounding context into account.", "labels": [], "entities": []}, {"text": "Our results also suggest that deep models for dependency parsing may not discover POS classes when trained solely for parsing, even when it is fully within the capacity of the model.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8219907581806183}, {"text": "parsing", "start_pos": 118, "end_pos": 125, "type": "TASK", "confidence": 0.9669389128684998}]}, {"text": "Designing architectures to apply stack-propagation in other coupled NLP tasks might yield significant accuracy improvements for deep learning.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9957869648933411}]}, {"text": "In this example, the parser has three templates, stack:0, stack:1, and input:0.", "labels": [], "entities": []}, {"text": "Bottom: The feature templates create many-to-many connections from the hidden layer of the tagger to the input layer of the parser.", "labels": [], "entities": []}, {"text": "For example, the predicted root of the sentence (\"ate\") is connected to the input of most parse decisions.", "labels": [], "entities": []}, {"text": "At test time, the above structure is constructed dynamically as a function of the parser output.", "labels": [], "entities": []}, {"text": "Note also that the predicted POS tags are not directly used by the parser.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our approach on several dependency parsing tasks across a wide variety of languages.", "labels": [], "entities": [{"text": "dependency parsing tasks", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.8262719511985779}]}, {"text": "We first investigated our model on 19 languages from the Universal Dependencies Treebanks v1.2.", "labels": [], "entities": [{"text": "Universal Dependencies Treebanks v1.2", "start_pos": 57, "end_pos": 94, "type": "DATASET", "confidence": 0.686761699616909}]}, {"text": "We selected the 19 largest cur-2 http://universaldependencies.org rently spoken languages for which the full data was freely available.", "labels": [], "entities": []}, {"text": "We used the coarse universal tagset in our experiments with no explicit morphological annotations.", "labels": [], "entities": []}, {"text": "To measure parsing accuracy, we report unlabeled attachment score (UAS) and labeled attachment score (LAS) computed on all tokens (including punctuation), as is standard for non-English datasets.", "labels": [], "entities": [{"text": "parsing", "start_pos": 11, "end_pos": 18, "type": "TASK", "confidence": 0.9510567784309387}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.90505450963974}, {"text": "unlabeled attachment score (UAS)", "start_pos": 39, "end_pos": 71, "type": "METRIC", "confidence": 0.7854072252909342}, {"text": "labeled attachment score (LAS) computed", "start_pos": 76, "end_pos": 115, "type": "METRIC", "confidence": 0.9183202130453927}]}, {"text": "For simplicity, we use the arc-standard (Nivre, 2004) transition system with greedy decoding.", "labels": [], "entities": []}, {"text": "Because this transition system only produces projective trees, we first apply a projectivization step to all treebanks before unrolling the gold derivations during training.", "labels": [], "entities": []}, {"text": "We make an exception for Dutch, where we observed a significant gain on development data by introducing the SWAP action and allowing non-projective trees.", "labels": [], "entities": []}, {"text": "For models that required predicted POS tags, we trained a window-based tagger using the same features as the tagger component of our stacking model.", "labels": [], "entities": []}, {"text": "We used 5-fold jackknifing to produce predicted tags on the training set.", "labels": [], "entities": []}, {"text": "We found that the window-based tagger was comparable to a stateof-the-art CRF tagger for most languages.", "labels": [], "entities": []}, {"text": "For every network we trained, we used the development data to evaluate a small range of hyperparameters, stopping training early when UAS no longer improved on the held-out data.", "labels": [], "entities": [{"text": "UAS", "start_pos": 134, "end_pos": 137, "type": "DATASET", "confidence": 0.7572033405303955}]}, {"text": "We use H = 1024 hidden units in the parser, and H = 128 hidden units in the tagger.", "labels": [], "entities": []}, {"text": "The parser embeds the tagger activations with D = 64.", "labels": [], "entities": [{"text": "D", "start_pos": 46, "end_pos": 47, "type": "METRIC", "confidence": 0.9790160655975342}]}, {"text": "Note that following , we did not use any auxiliary data beyond that in the treebanks, such as pre-trained word embeddings.", "labels": [], "entities": []}, {"text": "For a final set of experiments, we evaluated on the standard Wall Street Journal (WSJ) part of the Penn Treebank  converter).", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) part", "start_pos": 61, "end_pos": 91, "type": "DATASET", "confidence": 0.9652266246931893}, {"text": "Penn Treebank  converter", "start_pos": 99, "end_pos": 123, "type": "DATASET", "confidence": 0.9748900532722473}]}, {"text": "We followed standard practice and used sections 2-21 for training, section 22 for development, and section 23 for testing.", "labels": [], "entities": []}, {"text": "Following , we used section 24 to tune any hyperparameters of the model to avoid overfitting to the development set.", "labels": [], "entities": []}, {"text": "As is common practice, we use pretrained word embeddings from the word2vec package when training on this dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Labeled Attachment Score (LAS) on Universal Dependencies Treebank. Top: Results without any POS tag observa- tions. \"B'15 LSTM\" is the character-based LSTM model (", "labels": [], "entities": [{"text": "Labeled Attachment Score (LAS)", "start_pos": 10, "end_pos": 40, "type": "METRIC", "confidence": 0.8310021062692007}, {"text": "Universal Dependencies Treebank", "start_pos": 44, "end_pos": 75, "type": "DATASET", "confidence": 0.8605247934659322}]}, {"text": " Table 3: WSJ Test set results for greedy and state-of-the-art  methods. For reference, we show the most accurate models  from Alberti et al. (2015) and Weiss et al. (2015), which use  a deeper model and beam search for inference.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.6972483992576599}]}, {"text": " Table 4: Averaged parsing and POS tagging results on the UD  treebanks for joint variants of stackprop. Given the window- based architecture, stackprop leads to higher parsing accura- cies than joint modeling (83.38% vs. 82.58%).", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9547201991081238}, {"text": "POS tagging", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.7087097316980362}, {"text": "UD  treebanks", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.885132372379303}]}]}