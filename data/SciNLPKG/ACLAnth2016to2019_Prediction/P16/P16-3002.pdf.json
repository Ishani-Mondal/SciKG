{"title": [], "abstractContent": [{"text": "A hierarchical word alignment model that searches for k-best partial alignments on target constituent 1-best parse trees has been shown to outperform previous models.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.681629091501236}]}, {"text": "However, relying solely on 1-best parses trees might hinder the search for good alignments because 1-best trees are not necessarily the best for word alignment tasks in practice.", "labels": [], "entities": [{"text": "word alignment tasks", "start_pos": 145, "end_pos": 165, "type": "TASK", "confidence": 0.8244171341260275}]}, {"text": "This paper introduces a dependency forest based word alignment model, which utilizes target dependency forests in an attempt to minimize the impact on limitations attributable to 1-best parse trees.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.6990388780832291}]}, {"text": "We present how k-best alignments are constructed over target-side dependency forests.", "labels": [], "entities": []}, {"text": "Alignment experiments on the Japanese-English language pair show a relative error reduction of 4% of the alignment score compared to a model with 1-best parse trees.", "labels": [], "entities": []}], "introductionContent": [{"text": "In statistical machine translation (SMT), word alignment plays an essential role in obtaining phrase tables ( or syntactic transformation rules).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8083117057879766}, {"text": "word alignment", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7561084628105164}]}, {"text": "IBM models (, which are based on word sequences, have been widely used for obtaining word alignments because they are fast and their implementation is available as GIZA++.", "labels": [], "entities": [{"text": "obtaining word alignments", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.661853144566218}]}, {"text": "Recently, a hierarchical alignment model (whose implementation is known as Nile 2 ) (), which performs better than IBM models, has been proposed.", "labels": [], "entities": []}, {"text": "In the hierarchical alignment model, both source and target con-stituency trees are used for incorporating syntactic information as features, and it searches for k-best partial alignments on the target constituent parse trees.", "labels": [], "entities": []}, {"text": "It achieved significantly better results than the IBM Model4 in Arabic-English and ChineseEnglish word alignment tasks, even though the model was trained on only 2,280 and 1,102 parallel sentences as gold standard alignments.", "labels": [], "entities": [{"text": "ChineseEnglish word alignment tasks", "start_pos": 83, "end_pos": 118, "type": "TASK", "confidence": 0.69023547321558}]}, {"text": "However, their models rely only on 1-best source and target side parse trees, which are not necessarily good for word alignment tasks.", "labels": [], "entities": [{"text": "word alignment tasks", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.8369536399841309}]}, {"text": "In SMT, forest-based decoding has been proposed for both constituency and dependency parse trees (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9906228184700012}, {"text": "dependency parse", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.6779332607984543}]}, {"text": "A forest is a compact representation of n-best parse trees.", "labels": [], "entities": []}, {"text": "It provides more alternative parse trees to choose from during decoding, leading to significant improvements in translation quality.", "labels": [], "entities": []}, {"text": "In this paper, we borrow this idea to build an alignment model using dependency forests rather than 1-best parses, which makes it possible to provide the model with more alternative parse trees that maybe suitable for word alignment tasks.", "labels": [], "entities": [{"text": "word alignment tasks", "start_pos": 218, "end_pos": 238, "type": "TASK", "confidence": 0.8486911455790201}]}, {"text": "The motivation of using dependency forests instead of constituency forests in our model is that dependency forests are more appropriate for alignments between language pairs with long-distance reordering, such as the one we study in this paper.", "labels": [], "entities": []}, {"text": "This is because they are more suitable for capturing the complex semantic relations of words in a sentence.", "labels": [], "entities": []}, {"text": "We conducted alignment experiments on the Japanese-English language pair.", "labels": [], "entities": [{"text": "alignment", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.9490670561790466}]}, {"text": "Experimental results show a relative error reduction of 4% of the alignment score compared to the model with 1-best parse trees.", "labels": [], "entities": [{"text": "error", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.8782523274421692}, {"text": "alignment score", "start_pos": 66, "end_pos": 81, "type": "METRIC", "confidence": 0.941728949546814}]}], "datasetContent": [{"text": "We conducted alignment experiments on the Japanese-English language pair.", "labels": [], "entities": [{"text": "alignment", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.9490670561790466}]}, {"text": "For dependency parsers, we used KNP () for Japanese and Berkeley Parser ( for English.", "labels": [], "entities": []}, {"text": "We converted constituent parse trees obtained by Berkeley Parser to dependency parse trees using rules.", "labels": [], "entities": []}, {"text": "We used 300, 100, 100 sentences from ASPEC-JE 2 for training, development and test data, respectively.", "labels": [], "entities": [{"text": "ASPEC-JE 2", "start_pos": 37, "end_pos": 47, "type": "DATASET", "confidence": 0.7168789505958557}]}, {"text": "Our model as well as Nile has a feature called third party alignment feature, which activates for an alignment link that is presented in the alignment of a third party model.", "labels": [], "entities": []}, {"text": "The beam size k was set to 128.", "labels": [], "entities": []}, {"text": "We used different number of parse trees to create a target forest, e.g., 1, 10, 20, 50, 100 and 200.", "labels": [], "entities": []}, {"text": "The baseline in this experiment is a model with 1-best parse trees on the target side.", "labels": [], "entities": []}, {"text": "For reference, we also experimented on Nile 6 , the Bayesian subtree alignment model (Nakazawa model) () and IBM Model4.", "labels": [], "entities": [{"text": "Nile 6", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.9225182831287384}, {"text": "IBM Model4", "start_pos": 109, "end_pos": 119, "type": "DATASET", "confidence": 0.9027009606361389}]}, {"text": "We used Nile without automatically extracted rule features and constellation features to make a fair comparison with our model.", "labels": [], "entities": []}, {"text": "shows the alignment results evaluated on precision, recall and F-score for each experimental setting.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9997643828392029}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9996250867843628}, {"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9991475343704224}]}, {"text": "The first row shows the names of different experimental settings.", "labels": [], "entities": []}, {"text": "Each number in the row shows the number of n-best parse trees used to create target forests.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision, Recall and F-score for ASPEC-JE. The numbers in the first row refer to the number  of k-best parse trees used to generate forests.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986328482627869}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9956597685813904}, {"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.999244213104248}, {"text": "ASPEC-JE", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.5915275812149048}]}]}