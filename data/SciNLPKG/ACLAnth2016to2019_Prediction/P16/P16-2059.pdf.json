{"title": [{"text": "Learning Monolingual Compositional Representations via Bilingual Supervision", "labels": [], "entities": [{"text": "Monolingual Compositional Representations", "start_pos": 9, "end_pos": 50, "type": "TASK", "confidence": 0.7303281227747599}]}], "abstractContent": [{"text": "Bilingual models that capture the semantics of sentences are typically only evaluated on cross-lingual transfer tasks such as cross-lingual document categorization or machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.695744514465332}]}, {"text": "In this work, we evaluate the quality of the monolingual representations learned with a variant of the bilingual compositional model of Her-mann and Blunsom (2014), when viewing translations in a second language as a semantic annotation as the original language text.", "labels": [], "entities": []}, {"text": "We show that compositional objectives based on phrase translation pairs out-perform compositional objectives based on bilingual sentences and on monolingual paraphrases.", "labels": [], "entities": [{"text": "phrase translation pairs out-perform compositional", "start_pos": 47, "end_pos": 97, "type": "TASK", "confidence": 0.8058279037475586}]}], "introductionContent": [{"text": "The effectiveness of new representation learning methods for distributional word representations ( ) has brought renewed interest to the question of how to compose semantic representations of words to capture the semantics of phrases and sentences.", "labels": [], "entities": [{"text": "distributional word representations", "start_pos": 61, "end_pos": 96, "type": "TASK", "confidence": 0.6135452588399252}]}, {"text": "These representations offer the promise of capturing phrasal or sentential semantics in a general fashion, and could in principle benefit any NLP applications that analyze text beyond the word level, and improve their ability to generalize beyond contexts seen in training.", "labels": [], "entities": []}, {"text": "While most prior work has focused either on composing words into short phrases, or on supervised task-specific composition functions, inter alia), recently showed that a simple composition architecture (vector averaging) can yield sentence models that consistently perform well in semantic textual similarity tasks in a wide range of domains, and outperform more complex sequence models.", "labels": [], "entities": []}, {"text": "Interestingly, these models are trained using PPDB, the paraphrase database (, which was learned from bilingual parallel corpora.", "labels": [], "entities": []}, {"text": "In bilingual settings, there are also a few examples of bilingual sentence models ().", "labels": [], "entities": []}, {"text": "However, they have only been evaluated in cross-lingual transfer settings (e.g., cross-lingual document classification, or machine translation), which do not directly evaluate the quality of the sentence-level semantic representations learned.", "labels": [], "entities": [{"text": "cross-lingual document classification", "start_pos": 81, "end_pos": 118, "type": "TASK", "confidence": 0.6436550517876943}, {"text": "machine translation)", "start_pos": 123, "end_pos": 143, "type": "TASK", "confidence": 0.807715098063151}]}, {"text": "In this work, we directly evaluate the usefulness of modeling semantic equivalence using compositional models of translated texts for detecting semantic textual similarity in a single language.", "labels": [], "entities": []}, {"text": "For instance, in addition to using translated texts to model cross-lingual transfer from English to a foreign language, we can view English translations as a semantic annotation of the foreign text, and evaluate the usefulness of the resulting foreign representations.", "labels": [], "entities": [{"text": "cross-lingual transfer from English to a foreign language", "start_pos": 61, "end_pos": 118, "type": "TASK", "confidence": 0.82989452034235}]}, {"text": "While learning representations in languages other than English is a pressing practical problem, this paper will focus on evaluating English sentence representations learned on English semantic similarity tasks to facilitate comparison with prior work.", "labels": [], "entities": []}, {"text": "Our results show that sentence representations learned using a bilingual compositional objective outperform representations learned using monolingual evidence, whether compositional or not.", "labels": [], "entities": []}, {"text": "In addition, phrasal translations yield better representations than full sentence translations, even when applied to sentence-level tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "At training time we learn word embeddings for each combination of objective (Section 2.2) and type of training examples, using modified implementations of open-source implementations for J bi () and J pa.", "labels": [], "entities": []}, {"text": "This results in six model configurations.", "labels": [], "entities": []}, {"text": "Each was trained for 10 epochs using tuned hyperparameters.", "labels": [], "entities": []}, {"text": "At tuning time we use the SMT-europarl subset of STS-2012.", "labels": [], "entities": [{"text": "SMT-europarl subset of STS-2012", "start_pos": 26, "end_pos": 57, "type": "DATASET", "confidence": 0.6813202351331711}]}, {"text": "We consider mini-batch sizes of {25, 50, 100}, \u03b4 \u2208 {1, 10, 100} with Euclidean distance, \u03b4 \u2208 {0.4, 0.6, 0.8} with cosine similarly, and \u03bb \u2208 {1, 10 \u22123 , 10 \u22125 , 10 \u22127 , 10 \u22129 }.", "labels": [], "entities": []}, {"text": "In J bi , we consider k \u2208 {1, 5, 10, 15}, and in J pa we tuned over the sampling strategy \u2208 {M IX, M AX} and the distance function used.", "labels": [], "entities": []}, {"text": "To speedup tuning for J pa , we follow, by limiting training to 100k pairs, and tuning to 5 epochs.", "labels": [], "entities": []}, {"text": "Tuning results confirmed the importance of negative sampling and distance function in our models: in J bi , increasing k consistently helps the bilingual models, whereas the correlation score for monolingual models degrade fork > 10.", "labels": [], "entities": []}, {"text": "In J pa , M AX always outperforms M IX.", "labels": [], "entities": [{"text": "M AX", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.6594513952732086}]}, {"text": "Euclidean distance was consistently chosen for bilingual sentences and monolingual phrases, while cosine similarity was chosen for bilingual phrases.", "labels": [], "entities": []}, {"text": "At test time we construct sentence-level embeddings by averaging the representations of words in each sentence, and compute cosine similarity to capture the similarity between sentences.", "labels": [], "entities": []}, {"text": "reports the Pearson correlation scores achieved for each approach and dataset.", "labels": [], "entities": [{"text": "Pearson correlation scores", "start_pos": 12, "end_pos": 38, "type": "METRIC", "confidence": 0.8917653361956278}]}], "tableCaptions": [{"text": " Table 3: Pearson correlation scores obtained on the English STS sets (with per year averages) and on  semantic-relatedness task (SICK). The left columns report results based on new representations learned  in this work, while the 2 rightmost columns report reference results from prior work (", "labels": [], "entities": [{"text": "Pearson correlation scores", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.8727129896481832}, {"text": "English STS sets", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.8113466103871664}]}, {"text": " Table 4: Undertrained word ratios (tokens seen  fewer than 100 times during training) are uncor- related with performance in Table 3.", "labels": [], "entities": [{"text": "Undertrained word ratios", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.670163502295812}]}, {"text": " Table 5: Impact of memorization: Pearson corre- lation scores on SICK with training sets with and  without filtering out training pairs that contain any  bigrams that appear in SICK. Number of training  pairs (# Pairs) is shown in millions.", "labels": [], "entities": [{"text": "Pearson corre- lation", "start_pos": 34, "end_pos": 55, "type": "METRIC", "confidence": 0.9307398796081543}]}, {"text": " Table 6: Impact of training set size: Average Pear- son correlation per test set with different numbers  (in millions) of bilingual phrase pairs, compared  to the full set of bilingual sentences and monolin- gually pretrained GloVe.", "labels": [], "entities": [{"text": "Pear- son correlation", "start_pos": 47, "end_pos": 68, "type": "METRIC", "confidence": 0.5776952058076859}]}]}