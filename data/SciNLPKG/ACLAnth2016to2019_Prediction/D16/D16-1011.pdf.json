{"title": [], "abstractContent": [{"text": "Prediction without justification has limited applicability.", "labels": [], "entities": []}, {"text": "As a remedy, we learn to extract pieces of input text as justifications-rationales that are tailored to be short and coherent , yet sufficient for making the same prediction.", "labels": [], "entities": []}, {"text": "Our approach combines two modular components, generator and encoder, which are trained to operate well together.", "labels": [], "entities": []}, {"text": "The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction.", "labels": [], "entities": []}, {"text": "Rationales are never given during training.", "labels": [], "entities": [{"text": "Rationales", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9686375856399536}]}, {"text": "Instead , the model is regularized by desiderata for rationales.", "labels": [], "entities": []}, {"text": "We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases.", "labels": [], "entities": [{"text": "multi-aspect sentiment analysis", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.7902806202570597}]}, {"text": "Our approach out-performs attention-based baseline by a significant margin.", "labels": [], "entities": []}, {"text": "We also successfully illustrate the method on the question retrieval task.", "labels": [], "entities": [{"text": "question retrieval task", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.8441352645556132}]}], "introductionContent": [{"text": "Many recent advances in NLP problems have come from formulating and training expressive and elaborate neural models.", "labels": [], "entities": [{"text": "NLP problems", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.9240743517875671}]}, {"text": "This includes models for sentiment classification, parsing, and machine translation among many others.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.964160680770874}, {"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9131326079368591}, {"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.8016296327114105}]}, {"text": "The gains inaccuracy have, however, come at the cost of interpretability since complex neural models offer little transparency concerning their inner workings.", "labels": [], "entities": [{"text": "interpretability", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.9779250621795654}]}, {"text": "In many applications, such as medicine, predictions are used to drive critical decisions, including treatment options.", "labels": [], "entities": []}, {"text": "a very pleasant ruby red-amber color with a rela9vely brilliant finish, but a limited amount of carbona9on, from the look of it. aroma is what i think an amber ale should be -a nice blend of caramel and happiness bound together.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the proposed joint model on two NLP applications: (1) multi-aspect sentiment analysis on product reviews and (2) similar text retrieval on AskUbuntu question answering forum.", "labels": [], "entities": [{"text": "multi-aspect sentiment analysis", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.7330042123794556}, {"text": "AskUbuntu question answering forum", "start_pos": 151, "end_pos": 185, "type": "DATASET", "confidence": 0.7904797941446304}]}], "tableCaptions": [{"text": " Table 1: Statistics of the beer review dataset.", "labels": [], "entities": [{"text": "beer review dataset", "start_pos": 28, "end_pos": 47, "type": "DATASET", "confidence": 0.8922505776087443}]}, {"text": " Table 2: Precision of selected rationales for the first three aspects. The precision is evaluated based on whether the selected words", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9622560143470764}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9995396137237549}]}, {"text": " Table 3: Comparing neural encoders with bigram SVM model.", "labels": [], "entities": []}]}