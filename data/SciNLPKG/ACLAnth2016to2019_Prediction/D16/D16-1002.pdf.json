{"title": [{"text": "Rule Extraction for Tree-to-Tree Transducers by Cost Minimization", "labels": [], "entities": [{"text": "Rule Extraction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7112443000078201}, {"text": "Cost Minimization", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.735861212015152}]}], "abstractContent": [{"text": "Tree transducers that model expressive linguistic phenomena often require word-alignments and a heuristic rule extractor to induce their grammars.", "labels": [], "entities": []}, {"text": "However, when the corpus of tree/string pairs is small compared to the size of the vocabulary or the complexity of the grammar, word-alignments are unreliable.", "labels": [], "entities": []}, {"text": "We propose a general rule extraction algorithm that uses cost functions over tree fragments, and formulate the extraction as a cost minimization problem.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7511135935783386}]}, {"text": "As a by-product, we are able to introduce back-off states at which some cost functions generate right-hand-sides of previously unseen left-hand-sides, thus creating transducer rules \"on-the-fly\".", "labels": [], "entities": []}, {"text": "We test the generalization power of our induced tree transducers on a QA task over a large Knowledge Base, obtaining a reasonable syntactic accuracy and effectively overcoming the typical lack of rule coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9900122284889221}]}], "introductionContent": [{"text": "Tree transducers are general and solid theoretical models that have been applied to a variety of NLP tasks, such as machine translation), text summarization), question answering (), paraphrasing and textual entailment (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7389651983976364}, {"text": "text summarization", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7504343390464783}, {"text": "question answering", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.8894728124141693}, {"text": "paraphrasing", "start_pos": 182, "end_pos": 194, "type": "TASK", "confidence": 0.9589682221412659}, {"text": "textual entailment", "start_pos": 199, "end_pos": 217, "type": "TASK", "confidence": 0.7071314454078674}]}, {"text": "One strategy to obtain transducer rules is by exhaustive enumeration; however, this method is ineffective when there is a high structural language variability and we wish to have an expressive model.", "labels": [], "entities": []}, {"text": "Another strategy is to heuristically extract rules from a corpus of tree/string pairs and word-alignments, as GHKM algorithm does (); however, word-alignments are difficult to estimate when the corpus is small.", "labels": [], "entities": []}, {"text": "This would be the case, for example, of machine translation for low-resourced languages where there is often small numbers of parallel sentences, or in Question Answering (QA) tasks where the number of Knowledge Base (KB) identifiers (concepts) is much larger than QA datasets.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7847823798656464}, {"text": "Question Answering (QA) tasks", "start_pos": 152, "end_pos": 181, "type": "TASK", "confidence": 0.8473355770111084}]}, {"text": "Our main contribution is an algorithm that formulates the rule extraction as a cost minimization problem, where the search for the best rules is guided by an ensemble of cost functions over pairs of tree fragments.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7556639015674591}]}, {"text": "In GHKM, a tree fragment and a sequence of words are extracted together if they are minimal and their word alignments do not fall outside of their respective boundaries.", "labels": [], "entities": []}, {"text": "However, given that alignment violations are not allowed, the quality of the extracted rules degrades as the rate of misaligned words increases.", "labels": [], "entities": []}, {"text": "In our framework, we can mimic GHKM by assigning an infinite cost to pairs of tree fragments that violate such conditions on word alignments and by adding a cost regularizer on the size of the tree fragments.", "labels": [], "entities": []}, {"text": "Smoother cost functions, however, would permit controlled misalignments, contributing to generalization.", "labels": [], "entities": [{"text": "generalization", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.9734420776367188}]}, {"text": "Given the generality of these cost functions, we believe that the applicability of tree transducers will be extended.", "labels": [], "entities": []}, {"text": "A by-product of introducing these cost functions is that some of them may act as rule back-offs, where transducer rules are built \"on-the-fly\" when the transducer is at a predefined back-off state but there is no rule whose left-hand-side (lhs) matches the input subtree.", "labels": [], "entities": []}, {"text": "These back-off states can be seen as functions that are capable of generating right-hand-sides (rhs) for unseen input subtrees.", "labels": [], "entities": []}, {"text": "Our rule extraction algorithm and back-off scheme are general, in the sense that they can be applied to any tree transformation task.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8260499536991119}]}, {"text": "However, in this paper, we extrinsically evaluate the quality of the extracted rules in a QA task, where the objective is to transform syntactic trees of questions into constituent trees that represent Sparql queries on Freebase, a large Knowledge Base.", "labels": [], "entities": []}, {"text": "Implementing all components of a QA system at a sufficient level is out of the scope of this paper; for that reason, in order to evaluate our contribution in isolation, we use the FREE917 corpus released by, for which an entity and predicate lexicon is available . We show that a tree-to-tree transducer induced using our rule extraction and back-off scheme is accurate and generalizes well, which was not previously achieved with tree transducers in semantic parsing tasks such as QA overlarge KBs.", "labels": [], "entities": [{"text": "FREE917 corpus released", "start_pos": 180, "end_pos": 203, "type": "DATASET", "confidence": 0.9644923210144043}, {"text": "rule extraction", "start_pos": 322, "end_pos": 337, "type": "TASK", "confidence": 0.7260162979364395}, {"text": "semantic parsing tasks", "start_pos": 451, "end_pos": 473, "type": "TASK", "confidence": 0.8072173794110616}]}], "datasetContent": [{"text": "Data The training data is a corpus of questions annotated with their logical forms that can be executed on Freebase to obtain a precise answer.", "labels": [], "entities": []}, {"text": "For an unseen set of questions, the task is to obtain automatically their logical forms and retrieve the correct answer.", "labels": [], "entities": []}, {"text": "Our objective is to evaluate the generalization capabilities of a transducer induced using our rule extraction on an unseen open-domain test set.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.7519207298755646}]}, {"text": "We parsed questions from FREE917 into source constituent trees using the Stanford caseless model ().", "labels": [], "entities": [{"text": "FREE917", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.857908308506012}]}, {"text": "Target constituent (meaning) representations were obtained by a simple heuristic conversion from the \u03bb\u2212DCS expressions released by.", "labels": [], "entities": []}, {"text": "We evaluate on the same training and testing split as in.", "labels": [], "entities": []}, {"text": "Tree pairs (2.9%) for which the gold executable meaning representation did not retrieve valid results were filtered out.", "labels": [], "entities": []}, {"text": "Baselines We compared to two baselines.", "labels": [], "entities": []}, {"text": "The first one is SEMPRE (), a stateof-the-art semantic parser that uses a target language grammar to over-generate trees, and a log-linear model to estimate the parameters that guide the decoder towards trees that generate correct answers.", "labels": [], "entities": [{"text": "SEMPRE", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.7349884510040283}]}, {"text": "For FREE917, SEMPRE uses a manually-created entity lexicon released by, but an automatically generated predicate lexicon.", "labels": [], "entities": [{"text": "FREE917", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.7800142168998718}]}, {"text": "In-stead, our system and the second baseline use manually created entity and predicate lexicons, where the latter was created by selecting all words from every question that relate to the target predicate.", "labels": [], "entities": []}, {"text": "For example, for the question \"what olympics has egypt participated in\", we created an entry that maps the discontinuous phrase \"olympics participated in\" to the predicate OlympicsParticipatedIn.", "labels": [], "entities": [{"text": "OlympicsParticipatedIn", "start_pos": 172, "end_pos": 194, "type": "DATASET", "confidence": 0.9127428531646729}]}, {"text": "The second baseline is a tree-to-tree transducer whose rules are extracted using a straightforward adaptation of the GHKM algorithm () for pairs of trees.", "labels": [], "entities": []}, {"text": "Word-to-concept alignments are extracted using three different strategies: i) ghkm-g uses the IBM models ( as implemented in GIZA++ (, ii) ghkm-m maps KB concepts (target leaves) to as many source words as present in the entity/predicate lexicons, and iii) ghkm-c maps KB concepts as in ii) but only retaining the longest contiguous sequence of source words (or right-most sequence if there is a tie).", "labels": [], "entities": []}, {"text": "Bridging predicates are assumed when a KB concept does not align (according to the lexicon) to any source word.", "labels": [], "entities": [{"text": "Bridging predicates", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8489554226398468}]}, {"text": "Finally, rule state names are set according to the mechanism described in Section 5.", "labels": [], "entities": []}, {"text": "Our ent, pred and bridge cost/back-off functions assign a low cost (or high score) to source and target tree patterns with no variables whose leaves appear in either the entity or the predicate lexicons.", "labels": [], "entities": []}, {"text": "Scaling factors \u03bb i (see Eq. 1) were subjectively tuned on 20 training examples.", "labels": [], "entities": []}, {"text": "When used as back-off functions, they generate as many rhs as entities or predicates can be retrieved from the lexicons by at least one of the words in the source tree pattern.", "labels": [], "entities": []}, {"text": "Bridging predicates are dispreferred by adding an extra constant cost.", "labels": [], "entities": [{"text": "Bridging predicates", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7085478901863098}]}, {"text": "At back-off, this score function generates a variable predicate, acting as a wildcard in Sparql.", "labels": [], "entities": [{"text": "Sparql", "start_pos": 89, "end_pos": 95, "type": "DATASET", "confidence": 0.913152813911438}]}, {"text": "Our system t2t For the rule extraction, we use abeam size of 10, and we output 100 derivations for every tree pair.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.8383754193782806}]}, {"text": "We do not impose any limit in the depth of lhs or rhs, or in the number of variables.", "labels": [], "entities": []}, {"text": "To increase the coverage of our rules, we produce deleting tree transducers by replacing fully lexicalized branches that are directly attached to the root of a lhs with a deleting variable.", "labels": [], "entities": []}, {"text": "For the parameter estimation, we used 3 iterations of the latent variable averaged structured perceptron, where the number of iterations was selected on 20% of held-out training data.", "labels": [], "entities": []}, {"text": "To assess the equality between the gold and the decoded tree, we compare their denotations.", "labels": [], "entities": []}, {"text": "The features for the discriminative training were the lhs and rhs roots, the number of variables, deleting variables and leaves, the presence of entities or predicates in the rhs, the rule state and children states, and several measures of character overlaps between the leaves of the source and information associated to leaves in target tree patterns.", "labels": [], "entities": []}, {"text": "For decoding, we used standard techniques () to constrain and prune weighted regular tree grammars given a tree transducer and a source tree, and used the cube-growing algorithm to generate 10, 000 derivations, converted them to Sparql queries, and retained those that were valid (either syntactically corrector that retrieved any result).", "labels": [], "entities": []}, {"text": "We compute the accuracy of the system as the percentage of questions for which the 1-best output tree retrieves the correct answer, and the coverage as the percentage for which the correct answer is within the 10, 000 best derivations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9995842576026917}, {"text": "coverage", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9926900267601013}]}, {"text": "The average rule extraction time per tree pair when using beam size 1 was 0.46 seconds (median 0.35, maximum 2.94 seconds).", "labels": [], "entities": []}, {"text": "When using beam size 10, the average was 4.7 seconds (median 2.02, maximum 104.4 seconds), which gives us a glimpse of how the beam size influences the computational complexity for the typical tree size of FREE917 questions.", "labels": [], "entities": [{"text": "FREE917", "start_pos": 206, "end_pos": 213, "type": "DATASET", "confidence": 0.8437252044677734}]}], "tableCaptions": []}