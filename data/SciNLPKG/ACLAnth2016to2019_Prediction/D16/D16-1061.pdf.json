{"title": [], "abstractContent": [{"text": "The advent of social media and its prosperity enable users to share their opinions and views.", "labels": [], "entities": []}, {"text": "Understanding users' emotional states might provide the potential to create new business opportunities.", "labels": [], "entities": []}, {"text": "Automatically identifying user-s' emotional states from their texts and classifying emotions into finite categories such as joy, anger, disgust, etc., can be considered as a text classification problem.", "labels": [], "entities": [{"text": "text classification", "start_pos": 174, "end_pos": 193, "type": "TASK", "confidence": 0.7472624778747559}]}, {"text": "However , it introduces a challenging learning scenario where multiple emotions with different intensities are often found in a single sentence.", "labels": [], "entities": []}, {"text": "Moreover, some emotions co-occur more often while other emotions rarely co-exist.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach based on emotion distribution learning in order to address the aforementioned issues.", "labels": [], "entities": [{"text": "emotion distribution learning", "start_pos": 52, "end_pos": 81, "type": "TASK", "confidence": 0.7864512006441752}]}, {"text": "The key idea is to learn a mapping function from sentences to their emotion distributions describing multiple emotions and their respective intensities.", "labels": [], "entities": []}, {"text": "Moreover, the relations of emotions are captured based on the Plutchik's wheel of emotions and are subsequently incorporated into the learning algorithm in order to improve the accuracy of emotion detection.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9981123208999634}, {"text": "emotion detection", "start_pos": 189, "end_pos": 206, "type": "TASK", "confidence": 0.7391659617424011}]}, {"text": "Experimental results show that the proposed approach can effectively deal with the emotion distribution detection problem and perform remarkably better than both the state-of-the-art emotion detection method and multi-label learning methods.", "labels": [], "entities": [{"text": "emotion distribution detection", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.7499978542327881}, {"text": "emotion detection", "start_pos": 183, "end_pos": 200, "type": "TASK", "confidence": 0.7582570612430573}]}], "introductionContent": [{"text": "The advent of social media and its prosperity enable the creation of massive online user-generated con- *", "labels": [], "entities": []}], "datasetContent": [{"text": "As the output of EDL is a distribution, a natural choice of criteria is the averaged similarity or distance between the actual emotion distribution and the predicted distribution.", "labels": [], "entities": []}, {"text": "There are many metrics that can be applied to measure the distance between two distributions.", "labels": [], "entities": []}, {"text": "In this paper six of them are used to evaluate the results of EDL, i.e, Euclidean, S\u03d5rensen, Squared X 2 , KL divergence, Intersection and Fidelity, as suggested in.", "labels": [], "entities": [{"text": "EDL", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.6279155015945435}, {"text": "Intersection", "start_pos": 122, "end_pos": 134, "type": "METRIC", "confidence": 0.9266738891601562}, {"text": "Fidelity", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9791758060455322}]}, {"text": ", where The formulae of the six criteria are summarized in.2.", "labels": [], "entities": []}, {"text": "Note that the virtual label y 0 is removed before evaluation.", "labels": [], "entities": []}, {"text": "As EDL can output both the relevant emotions and their respective emotion intensities, MLL can be seen as a special case of EDL that it only outputs emotion labels but not their intensities.", "labels": [], "entities": []}, {"text": "Several evaluation criteria typically used in MLL can also be used to measure EDL's ability of distinguishing relevant emotions from irrelevant ones, including hamming loss, one error, coverage, ranking loss, and average precision as suggested by, which are summarized in.2.", "labels": [], "entities": [{"text": "MLL", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.927876353263855}, {"text": "coverage", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9919100403785706}, {"text": "precision", "start_pos": 221, "end_pos": 230, "type": "METRIC", "confidence": 0.6288952231407166}]}, {"text": "Hamming loss evaluates how many times an emotion label is misclassified.", "labels": [], "entities": [{"text": "Hamming loss", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7445602118968964}]}, {"text": "One-error evaluates the fraction of sentences whose top-ranked emotion is not in the relevant emotion set.", "labels": [], "entities": []}, {"text": "Coverage evaluates how many steps are needed to move down the ranked emotion list so as to coverall the relevant emotions of the example.", "labels": [], "entities": []}, {"text": "Ranking loss evaluates the fraction of reversely ordered emotion pairs.", "labels": [], "entities": []}, {"text": "Average precision evaluates the average fraction of the relevant emotions ranked higher than a particular emotion y \u2208 Y.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9945666790008545}]}, {"text": "For each algorithm, ten-fold cross validation is conducted.", "labels": [], "entities": []}, {"text": "EDL is first compared with four existing Label Distribution Learning (LDL) methods (Geng,.2.", "labels": [], "entities": [{"text": "Label Distribution Learning (LDL)", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.8337511916955312}, {"text": "Geng", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.9436398148536682}]}, {"text": "For all the measures, \"\u2193\" indicates \"the smaller the better\", while \"\u2191\" indicates \"the larger the better\".", "labels": [], "entities": []}, {"text": "The best performance on each measure is highlighted by boldface.", "labels": [], "entities": []}, {"text": "The two-tailed t-tests with 5% significance level are performed to see whether the differences between EDL and the baselines are statistically significant.", "labels": [], "entities": [{"text": "significance level", "start_pos": 31, "end_pos": 49, "type": "METRIC", "confidence": 0.968079000711441}, {"text": "EDL", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.7816876769065857}]}, {"text": "We use \u2022 to indicate significance difference.", "labels": [], "entities": [{"text": "significance difference", "start_pos": 21, "end_pos": 44, "type": "METRIC", "confidence": 0.974093496799469}]}, {"text": "As the state-of-the-art emotion detection method proposed in ( can output the emotion distributions based on a dimensional reduction method, we present its experimental results on the Ren-CECps corpus in the last row of.2.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7573865950107574}, {"text": "Ren-CECps corpus", "start_pos": 184, "end_pos": 200, "type": "DATASET", "confidence": 0.8542528748512268}]}, {"text": "It can be observed that EDL performs significantly better than all the baseline LDL methods and the state-of-the-art emotion detection approach on all criteria considered here.", "labels": [], "entities": [{"text": "EDL", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.6707118153572083}, {"text": "emotion detection", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7524427175521851}]}, {"text": "Since EDL can be seen as an extension of MLL, EDL is compared with 7 widely used MLL methods using the virtual label Maximum a posteriori (MAP) principle is used to determine which emotion set is related to the given sentence.", "labels": [], "entities": [{"text": "Maximum a posteriori (MAP)", "start_pos": 117, "end_pos": 143, "type": "METRIC", "confidence": 0.7573579847812653}]}, {"text": "CC (classifier chains method) overcomes the limitations of BR and performs better but requires more computations.", "labels": [], "entities": [{"text": "BR", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.8652764558792114}]}, {"text": "ECC (ensemble classifier chains) applies classifier chains in an ensemble framework and obtains high predictive performances.", "labels": [], "entities": []}, {"text": "MLLOC (Multi-label LOcal Correlation) tries to exploit emotion correlations in the expression data locally.", "labels": [], "entities": []}, {"text": "The global discrimination fitting and local correlation sensitivity are incorporated into a unified framework, and solution for the optimization are developed.", "labels": [], "entities": [{"text": "global discrimination fitting", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.6839137077331543}]}, {"text": "Rank-SVM provides away of controlling the complexity of the overall learning system while having a small empirical error.", "labels": [], "entities": []}, {"text": "The architectures of Rank-SVM is based on linear models of Support Vector Machines (SVM).", "labels": [], "entities": []}, {"text": "LIFT constructs features specific to each emotion by conducting clustering analysis on its positive or negative instances, and then performs training and testing by querying the clustering results (Zhang, 2011).", "labels": [], "entities": []}, {"text": "BP-MLL is derived from the famous backpropagation algorithm through employing a novel error function capturing the characteristics of multi-label learning, i.e., the emotions belonging to a sentence should be ranked higher than those not belonging to that sentence (Zhang and).", "labels": [], "entities": [{"text": "BP-MLL", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.668452262878418}]}, {"text": "The virtual label y 0 used in EDL and the threshold value used in MLL are all set to 2.5.", "labels": [], "entities": [{"text": "EDL", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.895783543586731}, {"text": "MLL", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.6338170766830444}]}, {"text": "Besides, the \u03b5, \u03be 1 and \u03be 2 are set as 0.25, 0.0001, 0.1 respectively.", "labels": [], "entities": []}, {"text": "For the MLL methods, the value of k is set to 8 in ML-KNN, ratio is 0.02 and \u00b5 is 2 in ML-RBF.", "labels": [], "entities": [{"text": "MLL", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9261979460716248}, {"text": "ML-KNN", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.8260121941566467}, {"text": "ratio", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.9552921056747437}, {"text": "ML-RBF", "start_pos": 87, "end_pos": 93, "type": "DATASET", "confidence": 0.9184245467185974}]}, {"text": "Linear kernel is used in LIFT.", "labels": [], "entities": []}, {"text": "Rank-SVM uses the RBF kernel with the width \u03c3 equals to 1.", "labels": [], "entities": [{"text": "RBF kernel", "start_pos": 18, "end_pos": 28, "type": "DATASET", "confidence": 0.7047670483589172}]}, {"text": "The evaluation results of the proposed approach in comparison to all MLL baselines are presented in.2.", "labels": [], "entities": []}, {"text": "EDL performs best on all evaluation measures.", "labels": [], "entities": [{"text": "EDL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5649294853210449}]}, {"text": "It verifies the advantage of EDL owing to the consideration of varying intensity of the basic emotions.", "labels": [], "entities": [{"text": "EDL", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.7584627866744995}]}], "tableCaptions": [{"text": " Table 4: Experimental results in comparison with the LDL methods and the emotion detection approach.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7961775064468384}]}, {"text": " Table 5: Experimental results in comparison with the MLL methods.", "labels": [], "entities": [{"text": "MLL", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.6732293367385864}]}]}