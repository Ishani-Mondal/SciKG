{"title": [{"text": "Verb Phrase Ellipsis Resolution Using Discriminative and Margin-Infused Algorithms", "labels": [], "entities": [{"text": "Verb Phrase Ellipsis Resolution", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7675601989030838}]}], "abstractContent": [{"text": "Verb Phrase Ellipsis (VPE) is an anaphoric construction in which a verb phrase has been elided.", "labels": [], "entities": [{"text": "Verb Phrase Ellipsis (VPE)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8049361854791641}]}, {"text": "It occurs frequently in dialogue and informal conversational settings, but despite its evident impact on event coreference resolution and extraction, there has been relatively little work on computational methods for identifying and resolving VPE.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.8006167014439901}, {"text": "identifying and resolving VPE", "start_pos": 217, "end_pos": 246, "type": "TASK", "confidence": 0.562007412314415}]}, {"text": "Here, we present a novel approach to detecting and resolving VPE by using supervised discriminative machine learning techniques trained on features extracted from an automatically parsed, publicly available dataset.", "labels": [], "entities": [{"text": "detecting and resolving VPE", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.8149028718471527}]}, {"text": "Our approach yields state-of-the-art results for VPE detection by improving F1 score by over 11%; additionally, we explore an approach to antecedent identification that uses the Margin-Infused-Relaxed-Algorithm, which shows promising results.", "labels": [], "entities": [{"text": "VPE detection", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9920295476913452}, {"text": "F1 score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9860239624977112}, {"text": "antecedent identification", "start_pos": 138, "end_pos": 163, "type": "TASK", "confidence": 0.6757766604423523}]}], "introductionContent": [{"text": "Verb Phrase Ellipsis (VPE) is an anaphoric construction in which a verbal constituent has been omitted.", "labels": [], "entities": [{"text": "Verb Phrase Ellipsis (VPE)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8052307715018591}]}, {"text": "In English, an instance of VPE consists of two parts: a trigger, typically an auxiliary or modal verb, that indicates the presence of a VPE; and an antecedent, which is the verb phrase to which the elided element resolves (.", "labels": [], "entities": []}, {"text": "For example, in the sentence, \"The government includes money spent on residential renovation; Dodge does not\", the trigger \"does\" resolves to the antecedent \"includes money spent on residential renovation\".", "labels": [], "entities": []}, {"text": "The ability to perform VPE resolution is important for tasks involving event extraction, especially in conversational genres such as informal dialogue where VPE occurs more frequently).", "labels": [], "entities": [{"text": "VPE resolution", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.993021547794342}, {"text": "event extraction", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.7332720458507538}]}, {"text": "Most current event extraction systems ignore VPE and derive some structured semantic representation by reading information from a shallow dependency parse of a sentence.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7298278659582138}, {"text": "VPE", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.942026674747467}]}, {"text": "Such an approach would not only miss many valid links between an elided verb and its arguments, it could also produce nonsensical extractions if applied directly on an auxiliary trigger.", "labels": [], "entities": []}, {"text": "In the example above, a naive approach might produce an unhelpful semantic triple such as.", "labels": [], "entities": []}, {"text": "There have been several previous empirical studies of VPE).", "labels": [], "entities": [{"text": "VPE", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9710219502449036}]}, {"text": "Many previous approaches were restricted to solving specific subclasses of VPE (e.g., VPE triggered by do), or have relied on simple heuristics for some or all of the steps in VPE resolution, such as by picking the most recent previous clause as the antecedent.", "labels": [], "entities": [{"text": "VPE resolution", "start_pos": 176, "end_pos": 190, "type": "TASK", "confidence": 0.967773973941803}]}, {"text": "In this paper, we develop a VPE resolution pipeline which encompasses abroad class of VPEs), decomposed into the following two steps.", "labels": [], "entities": [{"text": "VPE resolution", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9479054510593414}]}, {"text": "In the VPE detection step, the goal is to determine whether or not a word triggers VPE.", "labels": [], "entities": [{"text": "VPE detection", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.9897391200065613}]}, {"text": "The second step, antecedent identification, requires selecting the clause containing the verbal antecedent, as well as determining the exact boundaries of the antecedent, which are often difficult to define.", "labels": [], "entities": [{"text": "antecedent identification", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.7612676322460175}]}, {"text": "Our contribution is to combine the rich linguistic analysis of earlier work with modern statistical approaches adapted to the structure of the VPE resolution problem.", "labels": [], "entities": [{"text": "VPE resolution problem", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.9694953362147013}]}, {"text": "First, inspired by earlier work, our system exploits linguistically informed features specific to VPE in addition to standard features such as lexical features or POS tags.", "labels": [], "entities": []}, {"text": "Second, we adapt the Margin-Infused-Relaxed-Algorithm (MIRA)), which has been popular in other tasks, such as machine translation () and parsing), to antecedent identification.", "labels": [], "entities": [{"text": "Margin-Infused-Relaxed-Algorithm (MIRA))", "start_pos": 21, "end_pos": 61, "type": "METRIC", "confidence": 0.6806198209524155}, {"text": "machine translation", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7795435190200806}, {"text": "parsing", "start_pos": 137, "end_pos": 144, "type": "TASK", "confidence": 0.9106529355049133}]}, {"text": "This algorithm admits a partial loss function which allows candidate solutions to overlap to a large degree.", "labels": [], "entities": []}, {"text": "This makes it well suited to antecedent identification, as candidate antecedents can overlap greatly as well.", "labels": [], "entities": [{"text": "antecedent identification", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.7573367059230804}]}, {"text": "On VPE detection, we show that our approach significantly improves upon a deterministic rule-based baseline and outperforms the state-of-the-art system of by 11%, from 69.52% to 80.78%.", "labels": [], "entities": [{"text": "VPE detection", "start_pos": 3, "end_pos": 16, "type": "TASK", "confidence": 0.9784916341304779}]}, {"text": "For antecedent identification we present results that are competitive with the state-of-the-art (.", "labels": [], "entities": [{"text": "antecedent identification", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6335972249507904}]}, {"text": "We also present state-of-the-art results with our end-to-end VPE resolution pipeline.", "labels": [], "entities": [{"text": "VPE resolution", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.9280546605587006}]}, {"text": "Finally, we perform feature ablation experiments to analyze the impact of various categories of features.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our results following the proposed metrics of Bos and Spenader (2011), as do.", "labels": [], "entities": []}, {"text": "Accuracy for antecedent identification is computed according ton = the number of correctly identified tokens between the candidate antecedent and the gold standard antecedent.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9870461225509644}, {"text": "antecedent identification", "start_pos": 13, "end_pos": 38, "type": "TASK", "confidence": 0.727515310049057}, {"text": "ton", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9602071642875671}]}, {"text": "Precision is n divided by the length of the candidate antecedent, recall is n divided by the length of the correct antecedent, and accuracy is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.990913987159729}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9993625283241272}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9994874000549316}, {"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9993205070495605}, {"text": "recall", "start_pos": 178, "end_pos": 184, "type": "METRIC", "confidence": 0.9949753284454346}]}, {"text": "For MIRA, final results are determined by choosing the weight vector that achieved the best performance on a validation set that is split off from part of the training set, as calculated after each update step.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.951518177986145}]}, {"text": "MIRA has several hyper-parameters that were tuned through a grid search over the validation set.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7615387439727783}]}, {"text": "The most crucial parameters were the learning rate \u03b1, and C, while the value of K did not cause significant changes inaccuracy.", "labels": [], "entities": [{"text": "learning rate \u03b1", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.8903297583262125}]}, {"text": "In, we see that MIRA improves upon the baseline with a 29% increase in overall accuracy.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.6100810766220093}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.997406542301178}]}, {"text": "MIRA provides significant gains for each form of VPE, although there is room for improvement, especially when identifying the antecedents of do-so triggers.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7499153017997742}, {"text": "VPE", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9606434106826782}]}, {"text": "achieve an accuracy of 65.20% with their joint resolution model for antecedent identification when using the train-test split proposed by; our model achieves 62.20% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.999396562576294}, {"text": "antecedent identification", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.6342480182647705}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.997917115688324}]}, {"text": "However, their experimental design was slightly different than ours -they only considered antecedents of triggers detected by their oracle trigger detection method, while we use all gold-standard triggers, meaning our results are not directly comparable to theirs.", "labels": [], "entities": []}, {"text": "Our cross validated results (65.18% accuracy) paint a better picture of the quality of our model because the small size of the dataset (554 samples) can cause highly varied results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9988659620285034}]}, {"text": "In we present end-to-end results obtained from our system when using the triggers detected by our VPE detection model (see Section 4).", "labels": [], "entities": [{"text": "VPE detection", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.8388007283210754}]}, {"text": "We compare these results to the end-to-end results of the best model of.", "labels": [], "entities": []}, {"text": "Following Liu et al., we assign partial credit during end-to-end evaluation in the following way: for each correctly detected (true positive) trigger, the Bos and Spenader (2011) antecedent evaluation score between the trigger's predicted antecedent and its gold antecedent is used (as opposed to a value of 1).", "labels": [], "entities": []}, {"text": "As can be seen from, we trade about 6 points of precision for 14 points of recall, thus improving state-of-the-art end-to-end accuracy from 47.51% to 51.96%.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9993756413459778}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9993311166763306}, {"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9052029252052307}]}], "tableCaptions": [{"text": " Table 1: Auxiliary categories for VPE and their frequencies in", "labels": [], "entities": [{"text": "VPE", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9774462580680847}]}, {"text": " Table 2: VPE detection results (baseline F1, Machine Learning", "labels": [], "entities": [{"text": "VPE detection", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.9534175395965576}, {"text": "F1", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.5166968107223511}]}, {"text": " Table 3: Results (precision, recall, F1) for VPE detection using", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9994076490402222}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9978093504905701}, {"text": "F1", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.9982194304466248}, {"text": "VPE detection", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9907125532627106}]}, {"text": " Table 4: Results (baseline accuracy, MIRA accuracy, accuracy", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.8505275845527649}, {"text": "MIRA", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9965536594390869}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.7815026640892029}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9992290735244751}]}, {"text": " Table 5: End-to-end results (precision, recall, F1) using the", "labels": [], "entities": [{"text": "End-to-end", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9539849162101746}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9973784685134888}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.995557963848114}, {"text": "F1", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.9971989393234253}]}, {"text": " Table 6: Feature ablation results (feature set excluded, preci-", "labels": [], "entities": []}, {"text": " Table 7: Feature ablation results (feature set excluded, preci-", "labels": [], "entities": []}]}