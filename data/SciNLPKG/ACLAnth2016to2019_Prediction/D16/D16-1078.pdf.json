{"title": [{"text": "Speculation and Negation Scope Detection via Convolutional Neural Networks", "labels": [], "entities": [{"text": "Negation Scope Detection", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.8442578911781311}]}], "abstractContent": [{"text": "Speculation and negation are important information to identify text factuality.", "labels": [], "entities": [{"text": "negation", "start_pos": 16, "end_pos": 24, "type": "TASK", "confidence": 0.8948590159416199}]}, {"text": "In this paper, we propose a Convolutional Neural Network (CNN)-based model with probabilistic weighted average pooling to address speculation and negation scope detection.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 146, "end_pos": 170, "type": "TASK", "confidence": 0.9345656434694926}]}, {"text": "In particular, our CNN-based model extracts those meaningful features from various syntactic paths between the cues and the candidate tokens in both constituency and dependency parse trees.", "labels": [], "entities": []}, {"text": "Evaluation on BioScope shows that our CNN-based model significantly outperforms the state-of-the-art systems on Abstracts, a sub-corpus in BioScope, and achieves comparable performances on Clinical Records, another sub-corpus in BioScope.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 139, "end_pos": 147, "type": "DATASET", "confidence": 0.876445472240448}, {"text": "Clinical Records", "start_pos": 189, "end_pos": 205, "type": "DATASET", "confidence": 0.8405924439430237}, {"text": "BioScope", "start_pos": 229, "end_pos": 237, "type": "DATASET", "confidence": 0.9048696160316467}]}], "introductionContent": [{"text": "Factual information is critical to understand a sentence or a document inmost typical NLP applications.", "labels": [], "entities": []}, {"text": "Speculation and negation extraction has been drawing more and more attentions in recent years due to its importance in distinguishing counterfactual or uncertain information from the facts.", "labels": [], "entities": [{"text": "Speculation and negation extraction", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7800368517637253}]}, {"text": "Generally speaking, speculation is a type of uncertain expression between certainty and negation, while negation is a grammatical category which reverses the truth value of a proposition.", "labels": [], "entities": []}, {"text": "Commonly, speculation and negation extraction involves two typical subtasks: cue identification and scope detection.", "labels": [], "entities": [{"text": "negation extraction", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.9199375510215759}, {"text": "cue identification", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7980334460735321}, {"text": "scope detection", "start_pos": 100, "end_pos": 115, "type": "TASK", "confidence": 0.8447863757610321}]}, {"text": "Here, a cue is a word or phrase that has speculative or negative meaning (e.g., suspect, guess, deny, not), while a scope is a text fragment governed by the corresponding cue in a sentence.", "labels": [], "entities": []}, {"text": "Consider the following two sentences for examples: In sentence S1, the speculative cue \"may\" governs the scope \"may harm our lungs\", while the negative cue \"not\" governs the scope \"not like playing football\" in sentence S2.", "labels": [], "entities": []}, {"text": "Previous work have achieved quite success on cue identification (e.g., with F1-score of 86.79 for speculative cue detection in).", "labels": [], "entities": [{"text": "cue identification", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.9280078113079071}, {"text": "F1-score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9995423555374146}, {"text": "speculative cue detection", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.5778238475322723}]}, {"text": "In comparison, speculation and negation scope detection is still a challenge due to its inherent difficulties and those upstream errors.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.9595632354418436}]}, {"text": "In this paper, we focus on scope detection.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.9743601977825165}]}, {"text": "Previous work on scope detection can be classified into heuristic rules based methods (e.g.,, machine learning based methods (e.g.,, and hybrid approaches which integrate empirical models with manual rules ( ).", "labels": [], "entities": [{"text": "scope detection", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.9429630935192108}]}, {"text": "Different from those previous studies, this paper presents a Convolutional Neural Network (CNN)-based approach for scope detection.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.8671415448188782}]}, {"text": "CNN models, firstly invented to capture more abstract features for computer vision (), have achieved certain success on various NLP tasks in recent years, such as semantic role labeling), machine translation (, event extraction (, etc.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 163, "end_pos": 185, "type": "TASK", "confidence": 0.6624560356140137}, {"text": "machine translation", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.832934558391571}, {"text": "event extraction", "start_pos": 211, "end_pos": 227, "type": "TASK", "confidence": 0.7905206680297852}]}, {"text": "These studies have proved the ability of CNN models in learning meaningful features.", "labels": [], "entities": []}, {"text": "In particular, our CNN-based model extracts various kinds of meaningful features from the syntactic paths between the cue and the candidate token in both constituency and dependency parse trees.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 171, "end_pos": 187, "type": "TASK", "confidence": 0.6727515459060669}]}, {"text": "The importance of syntactic information in scope detection has been justified in previous work (.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.9378132224082947}]}, {"text": "Our model can also benefit from the ability of neural networks in extracting useful information from syntactic paths () or more complex syntactic trees (.", "labels": [], "entities": []}, {"text": "Moreover, instead of traditional average pooling, our CNN-based model utilizes probabilistic weighted average pooling to alleviate the overfitting problem (.", "labels": [], "entities": []}, {"text": "Experimental results on BioScope prove the effectiveness of our CNNbased model.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.8636101484298706}]}, {"text": "The reminder of this paper is organized as follows: Section 2 gives an overview of the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our CNN-based model with probabilistic weighted average pooling for scope detection.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.8773556053638458}]}, {"text": "Section 4 illustrates the experimental settings, and reports the experimental results and analysis.", "labels": [], "entities": []}, {"text": "Finally, Section 5 draws the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first introduce the evaluation data, and then describe the experimental settings.", "labels": [], "entities": []}, {"text": "Finally, we report the experimental results and analysis.", "labels": [], "entities": []}, {"text": "Following the previous work (e.g.,, we divide the Abstracts sub-corpus into 10 folds to perform 10-fold cross-validation.", "labels": [], "entities": [{"text": "Abstracts sub-corpus", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.9085201621055603}]}, {"text": "Moreover, to examine the robustness of our CNN-based model towards different text types within biomedical domain, all the models are trained on the same Abstracts sub-corpus.", "labels": [], "entities": []}, {"text": "Therefore, the results on Abstracts can be regarded as in-domain evaluation while the results on Clinical Records and Full Papers can be regarded as cross-domain evaluation.", "labels": [], "entities": [{"text": "Abstracts", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.8692584037780762}, {"text": "Clinical Records and Full Papers", "start_pos": 97, "end_pos": 129, "type": "DATASET", "confidence": 0.8642636656761169}]}, {"text": "For the measurement, traditional Precision, Recall, and F1-score are used to report the tokenbased performance in scope detection, while the Percentage of Correct Scopes (PCS) is adopted to report the scope-based performance, which considers a scope correct if all the tokens in the sentence have been assigned the correct scope classes fora specific cue.", "labels": [], "entities": [{"text": "Precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9855411648750305}, {"text": "Recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.8780918121337891}, {"text": "F1-score", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9977219700813293}, {"text": "scope detection", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.8021896481513977}, {"text": "Percentage of Correct Scopes (PCS)", "start_pos": 141, "end_pos": 175, "type": "METRIC", "confidence": 0.6489147671631404}]}, {"text": "Obviously, PCS can better describe the overall performance in scope detection.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.9374006390571594}]}, {"text": "Besides, Percentage of Correct Left Boundaries (PCLB) and Percentage of Correct Right Boundaries (PCRB) are reported as partial measurements.", "labels": [], "entities": [{"text": "Percentage of Correct Left Boundaries (PCLB)", "start_pos": 9, "end_pos": 53, "type": "METRIC", "confidence": 0.9111047387123108}, {"text": "Percentage of Correct Right Boundaries (PCRB)", "start_pos": 58, "end_pos": 103, "type": "METRIC", "confidence": 0.7961695641279221}]}, {"text": "In all our experiments, both the constituency and dependency parse trees are produced by Stanford Parser 2 . Specially, we train the parser on the GENIA Treebank 1.0 3 (), which contains Penn Treebank-style syntactic (phrase structure) annotation for the GENIA corpus.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7709424495697021}, {"text": "GENIA Treebank 1.0 3", "start_pos": 147, "end_pos": 167, "type": "DATASET", "confidence": 0.9543197304010391}, {"text": "Penn Treebank-style syntactic", "start_pos": 187, "end_pos": 216, "type": "DATASET", "confidence": 0.9474666515986124}, {"text": "GENIA corpus", "start_pos": 255, "end_pos": 267, "type": "DATASET", "confidence": 0.9318924248218536}]}, {"text": "The parser achieves the performance of 87.12% in F1-score in terms of 10-fold cross-validation on GENIA TreeBank 1.0.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9988580942153931}, {"text": "GENIA TreeBank 1.0", "start_pos": 98, "end_pos": 116, "type": "DATASET", "confidence": 0.9736181894938151}]}, {"text": "For the hyper-parameters in our CNN-based model, we set d 0 =100, d p =10, w=3, n 1 =200, n 2 =500, \u03bb=10 -4 , p=0.8.", "labels": [], "entities": []}, {"text": "The embeddings of the tokens in ordinary sentences (as word sequences) are initialized by Word2Vec 4 (.", "labels": [], "entities": [{"text": "Word2Vec 4", "start_pos": 90, "end_pos": 100, "type": "DATASET", "confidence": 0.9117853939533234}]}, {"text": "For the baseline, we utilize the classifier-based baseline developed by.", "labels": [], "entities": []}, {"text": "Besides those typical features, constituency and dependen-cy syntactic features are also included.", "labels": [], "entities": []}, {"text": "Furthermore, Mallet 5 is selected as the classifier.", "labels": [], "entities": [{"text": "Mallet 5", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.9358118772506714}]}, {"text": "In addition, since our CNN-based model may result in discontinuous blocks, we utilize a postprocessing algorithm) to ensure the continuity of scopes.", "labels": [], "entities": []}, {"text": "Meanwhile, the cue must be in its scope as defined in Bioscope.", "labels": [], "entities": [{"text": "Bioscope", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.8582455515861511}]}, {"text": "summarizes the performances of scope detection on Abstracts.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.8919003903865814}, {"text": "Abstracts", "start_pos": 50, "end_pos": 59, "type": "DATASET", "confidence": 0.924765408039093}]}, {"text": "In, CNN_C and CNN_D refer the CNN-based model with constituency paths and dependency paths, respectively (the same below).", "labels": [], "entities": []}, {"text": "It shows that our CNN-based models (both CNN_C and CNN_D) can achieve better performances than the baseline inmost measurements.", "labels": [], "entities": []}, {"text": "This indicates that our CNN-based models can better extract and model effective features.", "labels": [], "entities": []}, {"text": "Besides, compared to the baseline, our CNN-based models consider fewer features and needless human intervention.", "labels": [], "entities": []}, {"text": "It also manifests that our CNN-based models improve significantly more on negation scope detection than on speculation scope detection.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.9446442325909933}, {"text": "speculation scope detection", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.7534364263216654}]}, {"text": "Much of this is due to the better ability of our CNN-based models in identifying the right boundaries of scopes than the left ones on negation scope detection, with the huge gains of 29.44% and 25.25% on PCRB using CNN_C and CNN_D, respectively.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.8979306221008301}, {"text": "PCRB", "start_pos": 204, "end_pos": 208, "type": "DATASET", "confidence": 0.8653478622436523}]}, {"text": "illustrates that the performance of speculation scope detection is higher than that of negation (Best PCS: 85.75% vs 77.14%).", "labels": [], "entities": [{"text": "speculation scope detection", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.7670111258824667}, {"text": "negation", "start_pos": 87, "end_pos": 95, "type": "TASK", "confidence": 0.9766460061073303}]}, {"text": "It is mainly attributed to the shorter scopes of negation cues.", "labels": [], "entities": [{"text": "negation cues", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9031716883182526}]}, {"text": "Under the circumstances that the average length of negation sentences is almost as long as that of speculation ones (29.28 vs 29.77), shorter negation scopes mean that more tokens do not belong to the scopes, indicating more negative instances.", "labels": [], "entities": []}, {"text": "The imbalance between positive and negative instances has negative effects on both the baseline and the 5 http://mallet.cs.umass.edu/ CNN-based models for negation scope detection.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 155, "end_pos": 179, "type": "TASK", "confidence": 0.9678566455841064}]}, {"text": "also shows that our CNN_D outperforms CNN_C in negation scope detection (PCS: 77.14% vs 70.86%), while our CNN_C performs better than CNN_D in speculation scope detection (PCS: 85.75% vs 74.43%).", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.960503101348877}, {"text": "speculation scope detection", "start_pos": 143, "end_pos": 170, "type": "TASK", "confidence": 0.722936749458313}]}, {"text": "To explore the results of our CNN-based models in details, we present the analysis of top 10 speculative and negative cues below on CNN_C and CNN_D, respectively.", "labels": [], "entities": [{"text": "CNN_C", "start_pos": 132, "end_pos": 137, "type": "DATASET", "confidence": 0.9004451632499695}, {"text": "CNN_D", "start_pos": 142, "end_pos": 147, "type": "DATASET", "confidence": 0.8172768553098043}]}, {"text": "illustrates the PCSs of the most frequent 10 speculative cues using CNN_C.", "labels": [], "entities": [{"text": "CNN_C", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9368640184402466}]}, {"text": "The cues in the horizontal axis are in the order of lowest to highest in frequency.", "labels": [], "entities": []}, {"text": "Among those cues, \"suggest\", \"may\", \"indicate\", and \"appear\" are commonly used to express opinions of certain individuals.", "labels": [], "entities": []}, {"text": "The scopes of these cues are integrated semantic fragments (probably clauses) governed by corresponding cues in grammatical sense, and the tokens in the scope tend to share the same chunk with the cue in the constituency parse tree.", "labels": [], "entities": []}, {"text": "Hence, constituency paths are more useful for speculation scope detection.", "labels": [], "entities": [{"text": "speculation scope detection", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.9188167452812195}]}, {"text": "also shows that the PCSs of all the top 10 speculative cues are higher than 70% except \"or\" (PCS: 60.44%), mainly due to the flexible usage of \"or\", which  can connect two words, two professional terms, or even two clauses.", "labels": [], "entities": [{"text": "PCSs", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9958751797676086}]}, {"text": "illustrates the performances of the most frequent 10 negative cues using CNN_D.", "labels": [], "entities": [{"text": "CNN_D", "start_pos": 73, "end_pos": 78, "type": "DATASET", "confidence": 0.890776256720225}]}, {"text": "In those negative cues, \"not\" is in the absolute majority, and \"not\" and \"no\" cover over 70%.", "labels": [], "entities": []}, {"text": "We have noticed that most negative cues (e.g., \"not\", \"no\", \"without\", \"fail\") are often applied to negate phrases, and the tokens in negation scope tend to have the tight dependency relationship with them.", "labels": [], "entities": []}, {"text": "Therefore, our model can achieve better results using dependency paths for negation scope.", "labels": [], "entities": [{"text": "negation scope", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.9309845864772797}]}, {"text": "In, most negative cues have good PCSs (higher than 70%).", "labels": [], "entities": [{"text": "PCSs", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.998331606388092}]}, {"text": "However, \"unable\" has poor PCS of 16.67%.", "labels": [], "entities": [{"text": "PCS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9985887408256531}]}, {"text": "This is due to the fact that \"unable\" usually occurs in the phrase structure \"be unable to\", which often follows a subject.", "labels": [], "entities": []}, {"text": "It is notable that a cue is always in its scope and most cues in BioScope are much closer to the left boundaries than to the right ones.", "labels": [], "entities": []}, {"text": "Hence, the tokens labeled as B (i.e., inside the scope and before the cue) are much fewer than the ones labeled as A or O.", "labels": [], "entities": []}, {"text": "Such imbalance makes it hard to judge whether the tokens before \"unable\" are in of its scope or not.", "labels": [], "entities": []}, {"text": "The performances of our CNN-based models on the other two sub-corpora, i.e., Clinical Records and Full Papers, are presented in.", "labels": [], "entities": []}, {"text": "Although Abstracts and Clinical Records have different genres, our CNN-based models can obtain satisfactory results on Clinical Records using both constituency paths and dependency paths, proving the portability of our models.", "labels": [], "entities": []}, {"text": "also shows that the results of negation scope are better than those of speculation scope on Clinical Records (PCS: 89.66% vs 73.92%).", "labels": [], "entities": [{"text": "negation scope", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7106606811285019}, {"text": "Clinical Records", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.8727031648159027}, {"text": "PCS", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.5784160494804382}]}, {"text": "We argue the reason is that both the lengths of negation sentences and scopes (8.53 and 3.87, respectively) in Clinical Records are much shorter, indicating that the structures of negation sentences are simpler than those of speculation ones.", "labels": [], "entities": [{"text": "Clinical Records", "start_pos": 111, "end_pos": 127, "type": "DATASET", "confidence": 0.865866482257843}]}, {"text": "After error analysis of speculation scopes, we find that 54.83% of our error scopes contain the annotated scopes, just like sentence S5: (S5) This does not [appear to represent a stone] and is not mobile.", "labels": [], "entities": []}, {"text": "The annotated scope of the cue \"appear\" is \"appear to represent a stone\".", "labels": [], "entities": []}, {"text": "However, our CNN-based model identifies the whole sentence as the scope.", "labels": [], "entities": []}, {"text": "These errors indicate that some words maybe wrongly identified as the components of scopes because the scopes in Clinical Records are short and their structures are simple.", "labels": [], "entities": []}, {"text": "Compared with Abstracts and Clinical Records, the results on Full Papers are much lower.", "labels": [], "entities": [{"text": "Abstracts and Clinical Records", "start_pos": 14, "end_pos": 44, "type": "DATASET", "confidence": 0.6766947656869888}, {"text": "Full Papers", "start_pos": 61, "end_pos": 72, "type": "DATASET", "confidence": 0.8667995035648346}]}, {"text": "This is mainly due to the poor PCRBs, indicating a considerable quantity of right boundaries of scopes cannot be identified correctly.", "labels": [], "entities": []}, {"text": "We should note that the average lengths of both speculation and negation sentences  Clinical Records.", "labels": [], "entities": [{"text": "lengths", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9621279835700989}, {"text": "negation", "start_pos": 64, "end_pos": 72, "type": "TASK", "confidence": 0.9307368993759155}]}, {"text": "Normally, longer sentences mean more complicated syntactic structures.", "labels": [], "entities": []}, {"text": "Besides the results trained on Abstracts, we also consider the 10-fold cross-validation on Clinical Records and Full Papers.", "labels": [], "entities": [{"text": "Abstracts", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.8260749578475952}, {"text": "Clinical Records", "start_pos": 91, "end_pos": 107, "type": "DATASET", "confidence": 0.88035649061203}]}, {"text": "The PCSs of speculation and negation scope detection are 74.73% (CNN_C) and 91.03% (CNN_C) on Clinical Records, which are both higher than the ones trained on Abstracts.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.9760716358820597}, {"text": "CNN_C", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.7919653058052063}, {"text": "CNN_C)", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.6835525780916214}, {"text": "Clinical Records", "start_pos": 94, "end_pos": 110, "type": "DATASET", "confidence": 0.8257285356521606}, {"text": "Abstracts", "start_pos": 159, "end_pos": 168, "type": "DATASET", "confidence": 0.9671623110771179}]}, {"text": "Remember that Abstracts and Clinical Records come from the different genres.", "labels": [], "entities": []}, {"text": "However, we get lower PCSs on Full Papers (49.54% for speculation scope detection using CNN_C, and 44.67% for negation scope detection using CNN_C).", "labels": [], "entities": [{"text": "PCSs", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9945794343948364}, {"text": "speculation scope detection", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.740590234597524}, {"text": "CNN_C", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.9100556969642639}, {"text": "negation scope detection", "start_pos": 110, "end_pos": 134, "type": "TASK", "confidence": 0.9343451658884684}, {"text": "CNN_C", "start_pos": 141, "end_pos": 146, "type": "DATASET", "confidence": 0.904339869817098}]}, {"text": "In addition to the complex structures of long sentences, another reason is that the smaller size of the Full Papers sub-corpus compared to the other two sub-corpora.", "labels": [], "entities": [{"text": "Full Papers sub-corpus", "start_pos": 104, "end_pos": 126, "type": "DATASET", "confidence": 0.9406585892041525}]}, {"text": "Fewer sentences and scopes (only 672 speculation scopes in 519 sentences and 376 negation scopes in 339 sentences) mean that we cannot get an excellent model.", "labels": [], "entities": []}, {"text": "compares our CNN-based models with the state-of-the-art systems.", "labels": [], "entities": []}, {"text": "It shows that our CNNbased models can achieve higher PCSs (+1.54%) than those of the state-of-the-art systems for speculation scope detection and the second highest PCS for negation scope detection on Abstracts, and can get comparable PCSs on Clinical Records (73.92% vs 78.69% for speculation scopes, 89.66% vs 90.74% for negation scopes).", "labels": [], "entities": [{"text": "PCSs", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9948628544807434}, {"text": "speculation scope detection", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.6689676145712534}, {"text": "negation scope detection", "start_pos": 173, "end_pos": 197, "type": "TASK", "confidence": 0.9256853659947714}, {"text": "Abstracts", "start_pos": 201, "end_pos": 210, "type": "DATASET", "confidence": 0.9613794684410095}]}, {"text": "It is worth noting that Abstracts and Clinical Records come from different genres.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The performances on the Abstracts sub-corpus.", "labels": [], "entities": [{"text": "Abstracts sub-corpus", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.9545639753341675}]}, {"text": " Table 3: The performances of our CNN-based models on Clinical Records and Full Papers.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of our CNN-based model with the state- of-the-art in PCS.", "labels": [], "entities": []}]}