{"title": [{"text": "Zero-Resource Translation with Multi-Lingual Neural Machine Translation", "labels": [], "entities": [{"text": "Zero-Resource Translation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7225008606910706}, {"text": "Multi-Lingual Neural Machine Translation", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.716022789478302}]}], "abstractContent": [{"text": "In this paper, we propose a novel finetuning algorithm for the recently introduced multi-way, multilingual neural machine translate that enables zero-resource machine translation.", "labels": [], "entities": [{"text": "multilingual neural machine translate", "start_pos": 94, "end_pos": 131, "type": "TASK", "confidence": 0.6810977756977081}, {"text": "zero-resource machine translation", "start_pos": 145, "end_pos": 178, "type": "TASK", "confidence": 0.6375317573547363}]}, {"text": "When used together with novel many-to-one translation strategies, we empirically show that this finetuning algorithm allows the multi-way, multilingual model to translate a zero-resource language pair (1) as well as a single-pair neural translation model trained with up to 1M direct parallel sentences of the same language pair and (2) better than pivot-based translation strategy, while keeping only one additional copy of attention-related parameters .", "labels": [], "entities": []}], "introductionContent": [{"text": "A recently introduced neural machine translation () has proven to be a platform for new opportunities in machine translation research.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.7253941893577576}, {"text": "machine translation research", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.8537071347236633}]}, {"text": "Rather than word-level translation with language-specific preprocessing, neural machine translation has found to work well with statistically segmented subword sequences as well as sequences of characters (.", "labels": [], "entities": [{"text": "word-level translation", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7447318434715271}, {"text": "neural machine translation", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.703860362370809}]}, {"text": "Also, recent works show that neural machine translation provides a seamless way to incorporate multiple modalities Work carried out while the author was at IBM Research.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.6700898706912994}]}, {"text": "other than natural language text in translation (.", "labels": [], "entities": []}, {"text": "Furthermore, neural machine translation has been found to translate between multiple languages, achieving better translation quality by exploiting positive language transfer (.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.6929401556650797}]}, {"text": "In this paper, we conduct in-depth investigation into the recently proposed multi-way, multilingual neural machine translation . Specifically, we are interested in its potential for zero-resource machine translation, in which there does not exist any direct parallel examples between a target language pair.", "labels": [], "entities": [{"text": "multilingual neural machine translation", "start_pos": 87, "end_pos": 126, "type": "TASK", "confidence": 0.631484292447567}, {"text": "zero-resource machine translation", "start_pos": 182, "end_pos": 215, "type": "TASK", "confidence": 0.6633872191111246}]}, {"text": "Zero-resource translation has been addressed by pivot-based translation in traditional machine translation research (), but we explore away to use the multi-way, multilingual neural model to translate directly from a source to target language.", "labels": [], "entities": [{"text": "Zero-resource translation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7824999094009399}, {"text": "pivot-based translation", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.7570888102054596}, {"text": "machine translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7501377165317535}]}, {"text": "In doing so, we begin by studying different translation strategies available in the multi-way, multilingual model in Sec.", "labels": [], "entities": []}, {"text": "The strategies include a usual one-to-one translation as well as variants of many-to-one translation for multi-source translation (.", "labels": [], "entities": []}, {"text": "We empirically show that the many-to-one strategies significantly outperform the one-to-one strategy.", "labels": [], "entities": []}, {"text": "We move onto zero-resource translation by first evaluating a vanilla multi-way, multilingual model on a zero-resource language pair, which revealed that the vanilla model cannot do zero-resource translation in Sec.", "labels": [], "entities": [{"text": "zero-resource translation", "start_pos": 13, "end_pos": 38, "type": "TASK", "confidence": 0.7562927603721619}]}, {"text": "Based on the many-to-one strategies we proposed earlier, we design a novel finetun-ing strategy that does not require any direct parallel corpus between a target, zero-resource language pair in Sec.", "labels": [], "entities": []}, {"text": "5.2, which uses the idea of generating a pseudo-parallel corpus).", "labels": [], "entities": []}, {"text": "This strategy makes an additional copy of the attention mechanism and finetunes only this small set of parameters.", "labels": [], "entities": []}, {"text": "Large-scale experiments with Spanish, French and English show that the proposed finetuning strategy allows the multi-way, multilingual neural translation model to perform zero-resource translation as well as a single-pair neural translation model trained with up to 1M true parallel sentences.", "labels": [], "entities": [{"text": "multilingual neural translation", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.7512732942899069}, {"text": "zero-resource translation", "start_pos": 171, "end_pos": 196, "type": "TASK", "confidence": 0.748147577047348}]}, {"text": "This result re-confirms the potential of the multi-way, multilingual model for low/zero-resource language translation, which was earlier argued by .", "labels": [], "entities": [{"text": "low/zero-resource language translation", "start_pos": 79, "end_pos": 117, "type": "TASK", "confidence": 0.7043756365776062}]}], "datasetContent": [{"text": "Before continuing on with zero-resource machine translation, we first evaluate the translation strategies described in the previous section on multisource translation, as these translation strategies form a basic foundation on which we extend the multi-way, multilingual model for zero-resource machine translation.", "labels": [], "entities": [{"text": "zero-resource machine translation", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.6578365465005239}, {"text": "multisource translation", "start_pos": 143, "end_pos": 166, "type": "TASK", "confidence": 0.842806339263916}, {"text": "zero-resource machine translation", "start_pos": 281, "end_pos": 314, "type": "TASK", "confidence": 0.6546645065148672}]}], "tableCaptions": [{"text": " Table 1: Data statistics.  \u2020: newstest-2012.  \u2021: newstest-2013", "labels": [], "entities": [{"text": "newstest-2012", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9102550148963928}, {"text": "newstest-2013", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.8497958183288574}]}, {"text": " Table 2: One-to-one translation qualities using the multi-way,", "labels": [], "entities": []}, {"text": " Table 3: Many-to-one quality (Es+Fr\u2192En) using three transla-", "labels": [], "entities": []}, {"text": " Table 4: Zero-resource translation from Spanish (Es) to French", "labels": [], "entities": [{"text": "Zero-resource translation from Spanish (Es) to French", "start_pos": 10, "end_pos": 63, "type": "TASK", "confidence": 0.8226397567325168}]}, {"text": " Table 5: Zero-resource translation from Spanish (Es) to French (Fr) with finetuning. When pivot is  \u221a  , English is used as a pivot", "labels": [], "entities": []}]}