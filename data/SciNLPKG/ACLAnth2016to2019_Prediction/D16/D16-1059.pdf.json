{"title": [{"text": "Recursive Neural Conditional Random Fields for Aspect-based Sentiment Analysis", "labels": [], "entities": [{"text": "Aspect-based Sentiment Analysis", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.7743853330612183}]}], "abstractContent": [{"text": "In aspect-based sentiment analysis, extracting aspect terms along with the opinions being expressed from user-generated content is one of the most important subtasks.", "labels": [], "entities": [{"text": "aspect-based sentiment analysis", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7359404861927032}]}, {"text": "Previous studies have shown that exploiting connections between aspect and opinion terms is promising for this task.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel joint model that integrates recur-sive neural networks and conditional random fields into a unified framework for explicit aspect and opinion terms co-extraction.", "labels": [], "entities": []}, {"text": "The proposed model learns high-level discrimina-tive features and double propagates information between aspect and opinion terms, simultaneously.", "labels": [], "entities": []}, {"text": "Moreover, it is flexible to incorporate hand-crafted features into the proposed model to further boost its information extraction performance.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8452271819114685}]}, {"text": "Experimental results on the dataset from SemEval Challenge 2014 task 4 show the superiority of our proposed model over several baseline methods as well as the winning systems of the challenge.", "labels": [], "entities": [{"text": "SemEval Challenge 2014 task 4", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.7915268182754517}]}], "introductionContent": [{"text": "Aspect-based sentiment analysis) aims to extract important information, e.g., opinion targets, opinion expressions, target categories, and opinion polarities, from usergenerated content, such as microblogs, reviews, etc.", "labels": [], "entities": [{"text": "Aspect-based sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8268685340881348}]}, {"text": "This task was first studied by, followed by,, ,,.", "labels": [], "entities": []}, {"text": "In aspect-based sentiment analysis, one of the goals is to extract explicit aspects of an entity from text, along with the opinions being expressed.", "labels": [], "entities": [{"text": "aspect-based sentiment analysis", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7169568439324697}]}, {"text": "For example, in a restaurant review \"I have to say they have one of the fastest delivery times in the city.\", the aspect term is delivery times, and the opinion term is fastest.", "labels": [], "entities": []}, {"text": "Among previous work, one of the approaches is to accumulate aspect and opinion terms from a seed collection without label information, by utilizing syntactic rules or modification relations between them ().", "labels": [], "entities": []}, {"text": "In the above example, if we know fastest is an opinion word, then delivery times is probably inferred to bean aspect because fastest is its modifier.", "labels": [], "entities": []}, {"text": "However, this approach largely relies on hand-coded rules and is restricted to certain Part-of-Speech (POS) tags, e.g., opinion words are restricted to be adjectives.", "labels": [], "entities": []}, {"text": "Another approach focuses on feature engineering based on predefined lexicons, syntactic analysis, etc.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8378347754478455}, {"text": "syntactic analysis", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.7733130753040314}]}, {"text": "(. A sequence labeling classifier is then built to extract aspect and opinion terms.", "labels": [], "entities": [{"text": "sequence labeling classifier", "start_pos": 5, "end_pos": 33, "type": "TASK", "confidence": 0.7141386469205221}]}, {"text": "This approach requires extensive efforts for designing hand-crafted features and only combines features linearly for classification which ignores higher order interactions.", "labels": [], "entities": []}, {"text": "To overcome the limitations of existing methods, we propose a novel model, named Recursive Neural Conditional Random Fields (RNCRF).", "labels": [], "entities": []}, {"text": "Specifically, RNCRF consists of two main components.", "labels": [], "entities": []}, {"text": "The first component is a recursive neural network (RNN)) based on a dependency tree of each sentence.", "labels": [], "entities": []}, {"text": "The goal is to learn a high-level feature representation for each word in the context of each sentence and make the representation learning for aspect and opinion terms interactive through the underlying dependency structure among them.", "labels": [], "entities": []}, {"text": "The output of the RNN is then fed into a Conditional Random Field (CRF) () to learn a discriminative mapping from high-level features to labels, i.e., aspects, opinions, or others, so that context information can be well captured.", "labels": [], "entities": []}, {"text": "Our main contributions are to use RNN for encoding aspect-opinion relations in high-level representation learning and to present a joint optimization approach based on maximum likelihood and backpropagation to learn the RNN and CRF components simultaneously.", "labels": [], "entities": []}, {"text": "In this way, the label information of aspect and opinion terms can be dually propagated from parameter learning in CRF to representation learning in RNN.", "labels": [], "entities": []}, {"text": "We conduct expensive experiments on the dataset from SemEval challenge 2014 task 4 (subtask 1) () to verify the superiority of RNCRF over several baseline methods as well as the winning systems of the challenge.", "labels": [], "entities": [{"text": "SemEval challenge 2014 task 4", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.6537332892417907}]}], "datasetContent": [{"text": "We evaluate our model on the dataset from SemEval Challenge 2014 task 4 (subtask 1), which includes reviews from two domains: restaurant and laptop 3 . The detailed description of the dataset is given in.", "labels": [], "entities": [{"text": "SemEval Challenge 2014 task 4", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.6072782516479492}]}, {"text": "As the original dataset only includes manually annotate labels for aspect terms but not for opinion terms, we manually annotated opinion terms for each sentence by ourselves to facilitate our experiments.", "labels": [], "entities": []}, {"text": "For word vector initialization, we train word embeddings with word2vec () on the Yelp Challenge dataset 4 for the restaurant domain and on the Amazon reviews dataset) for the laptop domain.", "labels": [], "entities": [{"text": "word vector initialization", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.7554196715354919}, {"text": "Yelp Challenge dataset 4", "start_pos": 81, "end_pos": 105, "type": "DATASET", "confidence": 0.9563018083572388}, {"text": "Amazon reviews dataset", "start_pos": 143, "end_pos": 165, "type": "DATASET", "confidence": 0.8188684781392416}]}, {"text": "The Yelp dataset contains 2.2M restaurant reviews with 54K vocabulary size.", "labels": [], "entities": [{"text": "Yelp dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9772268533706665}]}, {"text": "For the Amazon reviews, we only extracted the electronic domain that contains 1M reviews with 590K vocabulary size.", "labels": [], "entities": []}, {"text": "We vary different dimensions for word embeddings and chose 300 for both domains.", "labels": [], "entities": []}, {"text": "Empirical sensitivity studies on different dimensions of word embeddings are also conducted.", "labels": [], "entities": []}, {"text": "Dependency trees are generated using Stanford Dependency Parser ( . Regarding CRFs, we implement a linearchain CRF using CRFSuite.", "labels": [], "entities": []}, {"text": "Because of the relatively small size of training data and a large number of parameters, we perform pretraining on the parameters of DT-RNN with cross-entropy error, which is a common strategy for deep learning).", "labels": [], "entities": []}, {"text": "We implement minibatch stochastic gradient descent (SGD) with a batch size of 25, and an adaptive learning rate (AdaGrad) initialized at 0.02 for pretraining of DT-RNN, which runs 4 epochs for the restaurant domain and 5 epochs for the laptop domain.", "labels": [], "entities": [{"text": "minibatch stochastic gradient descent (SGD)", "start_pos": 13, "end_pos": 56, "type": "TASK", "confidence": 0.7319232991763523}, {"text": "adaptive learning rate (AdaGrad) initialized", "start_pos": 89, "end_pos": 133, "type": "METRIC", "confidence": 0.7746165139334542}]}, {"text": "For parameter learning of the joint model RNCRF, we implement SGD with a decaying learning rate initialized at 0.02.", "labels": [], "entities": [{"text": "RNCRF", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.722876787185669}]}, {"text": "We also try with varying context window size, and use 3 for the laptop domain and 5 for the restaurant domain, respectively.", "labels": [], "entities": []}, {"text": "All parameters are chosen by cross validation.", "labels": [], "entities": []}, {"text": "As discussed in Section 5.1, hand-crafted features can be easily incorporated into RNCRF.", "labels": [], "entities": [{"text": "RNCRF", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.6411915421485901}]}, {"text": "We generate three types of simple features based on POS tags, name-list and sentiment lexicon to show further improvement by incorporating these features.", "labels": [], "entities": []}, {"text": "Following, we extract two sets of name list from the training data for each domain, where one includes high-frequency aspect terms, and the other includes high-probability aspect words.", "labels": [], "entities": []}, {"text": "These two sets are used to construct two lexicon features, i.e. we build a 2D binary vector: if a word is in a set, the corresponding value is 1, otherwise 0.", "labels": [], "entities": []}, {"text": "For POS tags, we use Stanford POS tagger (, and convert them to universal POS tags that have 15 different categories.", "labels": [], "entities": [{"text": "Stanford POS tagger", "start_pos": 21, "end_pos": 40, "type": "DATASET", "confidence": 0.8372976779937744}]}, {"text": "We then generate 15 one-hot POS tag features.", "labels": [], "entities": []}, {"text": "For sentiment lexicon, we use the collection of commonly used opinion words (around 6,800) (Hu and Liu, 2004a).", "labels": [], "entities": [{"text": "sentiment lexicon", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.962131917476654}]}, {"text": "Similar to name list, we create a binary feature to indicate whether the word belongs to opinion lexicon.", "labels": [], "entities": []}, {"text": "We denote by RNCRF+F the proposed model with the three types of features.", "labels": [], "entities": [{"text": "RNCRF+F", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.7277434666951498}]}, {"text": "Compared to the winning systems of SemEval Challenge 2014 task 4 (subtask 1), RNCRF or RN-CRF+F uses additional labels of opinion terms for training.", "labels": [], "entities": [{"text": "SemEval Challenge 2014 task 4", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.8689417123794556}, {"text": "RN-CRF+F", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.4419308404127757}]}, {"text": "Therefore, to conduct fair comparison experiments with the winning systems, we implement RNCRF-O by omitting opinion labels to train our model (i.e., labels become \"BA\", \"IA\", \"O\").", "labels": [], "entities": [{"text": "BA", "start_pos": 165, "end_pos": 167, "type": "METRIC", "confidence": 0.9772889018058777}, {"text": "IA", "start_pos": 171, "end_pos": 173, "type": "METRIC", "confidence": 0.6092990636825562}]}, {"text": "Accordingly, we denote by RNCRF-O+F the RNCRF-O model with the three additional types of handcrafted features.", "labels": [], "entities": [{"text": "F", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.770687997341156}]}, {"text": "We compare our model with several baselines: \u2022 CRF-1: a linear-chain CRF with standard linguistic features including word string, stylistics, POS tag, context string, and context POS tags.", "labels": [], "entities": []}, {"text": "\u2022 CRF-2: a linear-chain CRF with both standard linguistic features and dependency information including headword, dependency relations with parent token and child tokens.", "labels": [], "entities": []}, {"text": "\u2022 LSTM: an LSTM network built on top of word embeddings proposed by ( ).", "labels": [], "entities": []}, {"text": "We keep original settings in (Liu et al., 2015) but replace their word embeddings with ours (300 dimension).", "labels": [], "entities": []}, {"text": "We try different hidden layer dimensions (50, 100, 150, 200) and reported the best result with size 50.", "labels": [], "entities": []}, {"text": "\u2022 LSTM+F: the above LSTM model with the three additional types of hand-crafted features as with RNCRF.", "labels": [], "entities": [{"text": "F", "start_pos": 7, "end_pos": 8, "type": "METRIC", "confidence": 0.8090184330940247}]}, {"text": "\u2022 SemEval-1, SemEval-2: the top two winning systems for SemEval challenge 2014 task 4 (subtask 1).", "labels": [], "entities": [{"text": "SemEval challenge 2014 task 4", "start_pos": 56, "end_pos": 85, "type": "TASK", "confidence": 0.8894201636314392}]}, {"text": "\u2022 WDEmb+B+CRF 6 : the model proposed by) using word and dependency path embeddings combined with linear context embedding features, dependency context embedding features and hand-crafted features (i.e., feature engineering) as CRF input.", "labels": [], "entities": []}, {"text": "The comparison results are shown in for both the restaurant domain and the laptop domain.", "labels": [], "entities": []}, {"text": "Note that we provide the same annotated dataset (both aspect labels and opinion labels are included for training) for CRF-1, CRF-2 and LSTM for fair comparison.", "labels": [], "entities": [{"text": "CRF-1", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.8752641081809998}, {"text": "CRF-2", "start_pos": 125, "end_pos": 130, "type": "DATASET", "confidence": 0.9034523367881775}]}, {"text": "It is clear that our proposed model RNCRF achieves superior performance compared with most of the baseline models.", "labels": [], "entities": [{"text": "RNCRF", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.7209392189979553}]}, {"text": "The performance is even better by adding simple hand-crafted features, i.e., RN-CRF+F, with 0.92% and 3.87% absolute improvement over the best system in the challenge for aspect extraction for the restaurant domain and the laptop domain, respectively.", "labels": [], "entities": [{"text": "RN-CRF+F", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.7446545759836832}, {"text": "aspect extraction", "start_pos": 171, "end_pos": 188, "type": "TASK", "confidence": 0.7969997525215149}]}, {"text": "This shows the advantage of  show promising results in sequence tagging problems, they fail to achieve comparable performance when lacking of extensive features (e.g., CRF-1).", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.809548944234848}]}, {"text": "By adding dependency information explicitly in CRF-2, the result only improves slightly for aspect extraction.", "labels": [], "entities": [{"text": "CRF-2", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.8587026000022888}, {"text": "aspect extraction", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.8108781278133392}]}, {"text": "Alternatively, by incorporating dependency information into a deep learning model (e.g., RN-CRF), the result shows more than 7% improvement for aspect extraction and 2% for opinion extraction.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.7928453087806702}, {"text": "opinion extraction", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.8025128841400146}]}, {"text": "By removing the labels for opinion terms, RNCRF-O produces inferior results than RNCRF because the effect of dual propagation of aspect and opinion pairs disappears with the absence of opinion labels.", "labels": [], "entities": []}, {"text": "This verifies our previous assumption that DT-RNN could learn the interactive effects within aspects and opinions.", "labels": [], "entities": []}, {"text": "However, the performance of RNCRF-O is still comparable to the top systems and even better with the addition of simple linguistic features: 0.24% and 2.71% superior than the best system in the challenge for the restaurant domain and the laptop domain, respectively.", "labels": [], "entities": [{"text": "RNCRF-O", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.5636851787567139}]}, {"text": "This shows the robustness of our model even without additional opinion labels.", "labels": [], "entities": []}, {"text": "LSTM has shown comparable results for aspect extraction ( ).", "labels": [], "entities": [{"text": "LSTM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7181171774864197}, {"text": "aspect extraction", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.8556278944015503}]}, {"text": "However, in their work, they used well-pretrained word embeddings by training with large corpus or extensive external resources, e.g., chunking, and NER.", "labels": [], "entities": []}, {"text": "To compare their model with RNCRF, we re-implement LSTM with the same word embedding strategy and labeling resources as ours.", "labels": [], "entities": [{"text": "RNCRF", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.7096130847930908}]}, {"text": "The results show that our  \u2022 DT-RNN+SoftMax: rather than using a CRF, a softmax classifier is used on top of DT-RNN.", "labels": [], "entities": []}, {"text": "\u2022 CRF+word2vec: a linear-chain CRF with word embeddings only without using DT-RNN.", "labels": [], "entities": []}, {"text": "\u2022 RNCRF+POS/NL/Lex: the RNCRF model with POS tag or name list or sentiment lexicon feature(s).", "labels": [], "entities": []}, {"text": "The comparison results are shown in.", "labels": [], "entities": []}, {"text": "Similarly, both aspect and opinion term labels are provided for training for each of the above models.", "labels": [], "entities": []}, {"text": "Firstly, RNCRF achieves much better results compared to DT-RNN+SoftMax (+11.60% and +10.72% for the restaurant domain and the laptop domain in aspect extraction).", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.8367239534854889}]}, {"text": "This is because DT-RNN fails to fully exploit context information for sequence labeling, which, in contrast, can be achieved by CRF.", "labels": [], "entities": []}, {"text": "Secondly, RNCRF outperforms CRF+word2vec, which proves the importance of  DT-RNN for modeling interactions between aspects and opinions.", "labels": [], "entities": []}, {"text": "Hence, the combination of DT-RNN and CRF inherits the advantages from both models.", "labels": [], "entities": []}, {"text": "Moreover, by separately adding hand-crafted features, we can observe that name-list-based features and the sentiment lexicon feature are most effective for aspect extraction and opinion extraction, respectively.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 156, "end_pos": 173, "type": "TASK", "confidence": 0.8108372986316681}, {"text": "opinion extraction", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.7792414128780365}]}, {"text": "This maybe explained by the fact that name-list-based features usually contain informative evident for aspect terms and sentiment lexicon provides explicit indication about opinions.", "labels": [], "entities": []}, {"text": "Besides the comparison experiments, we also conduct sensitivity test for our proposed model in terms of word vector dimensions.", "labels": [], "entities": []}, {"text": "We tested a set of different dimensions ranging from 25 to 400, with 25 increment.", "labels": [], "entities": []}, {"text": "The sensitivity plot is shown in.", "labels": [], "entities": [{"text": "sensitivity", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9816871285438538}]}, {"text": "The performance for aspect extraction is smooth with different vector lengths for both domains.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8549121916294098}]}, {"text": "For restaurant domain, the result is stable when dimension is larger than or equal to 100, with the highest at 325.", "labels": [], "entities": [{"text": "dimension", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9801969528198242}]}, {"text": "For the laptop domain, the best result is at dimension 300, but with relatively small variations.", "labels": [], "entities": []}, {"text": "For opinion extraction, the performance reaches a good level when the dimension is larger than or equal to 75 for the restaurant domain and 125 for the laptop domain.", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8378522992134094}]}, {"text": "This proves the stability and robustness of our model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: SemEval Challenge 2014 task 4 dataset", "labels": [], "entities": [{"text": "SemEval Challenge 2014 task 4 dataset", "start_pos": 10, "end_pos": 47, "type": "DATASET", "confidence": 0.8580268820126852}]}, {"text": " Table 2: Comparison results in terms of F1 scores.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9795208275318146}]}, {"text": " Table 3: Impact of different components.", "labels": [], "entities": []}]}