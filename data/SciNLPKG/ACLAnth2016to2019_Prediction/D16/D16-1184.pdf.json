{"title": [], "abstractContent": [{"text": "Syntactic parsing of web queries is important for query understanding.", "labels": [], "entities": [{"text": "Syntactic parsing of web queries", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8384707808494568}, {"text": "query understanding", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8964034020900726}]}, {"text": "However, web queries usually do not observe the grammar of a written language, and no labeled syntactic trees for web queries are available.", "labels": [], "entities": []}, {"text": "In this paper , we focus on a query's clicked sentence, i.e., a well-formed sentence that i) contains all the tokens of the query, and ii) appears in the query's top clicked web pages.", "labels": [], "entities": []}, {"text": "We argue such sentences are semantically consistent with the query.", "labels": [], "entities": []}, {"text": "We introduce algorithms to derive a query's syntactic structure from the dependency trees of its clicked sentences.", "labels": [], "entities": []}, {"text": "This gives us a web query treebank without manual labeling.", "labels": [], "entities": []}, {"text": "We then train a dependency parser on the treebank.", "labels": [], "entities": []}, {"text": "Our model achieves much better UAS (0.86) and LAS (0.80) scores than state-of-the-art parsers on web queries.", "labels": [], "entities": [{"text": "UAS", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9900100827217102}, {"text": "LAS (0.80) scores", "start_pos": 46, "end_pos": 63, "type": "METRIC", "confidence": 0.955843722820282}]}], "introductionContent": [{"text": "Syntactic analysis is important in understanding a sentence's grammatical constituents, parts of speech, syntactic relations, and semantics.", "labels": [], "entities": [{"text": "Syntactic analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9300387799739838}]}, {"text": "In this paper, we are concerned with the syntactic structure of a short text.", "labels": [], "entities": [{"text": "syntactic structure of a short text", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.8519091010093689}]}, {"text": "The challenge is that short texts, for example, web queries, do not observe grammars of written languages (e.g., users often overlook capitalization, function words, and word order when creat- * Correspondence author.", "labels": [], "entities": []}, {"text": "The syntactic structure of query cover iphone 6 plus tells us that the head token is cover, indicating its intent is to shop for the cover of an iphone, instead of iphones.", "labels": [], "entities": []}, {"text": "With this knowledge, search engines show ads of iphone covers instead of iphones.", "labels": [], "entities": []}, {"text": "For distance earth moon, the head is distance, indicating its intent is to find the distance between the earth and the moon.", "labels": [], "entities": [{"text": "distance", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9689837098121643}]}, {"text": "For faucet adapter female, the intent is to find a female faucet adapter.", "labels": [], "entities": []}, {"text": "In summary, correctly identifying the head of a query helps identify its intent, and correctly identifying the modifiers helps rewrite the query (e.g., dropping non-essential modifiers).", "labels": [], "entities": []}, {"text": "Syntactic parsing of web queries is challenging for at least two reasons.", "labels": [], "entities": [{"text": "Syntactic parsing of web queries", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8874335765838623}]}, {"text": "First, grammatical signals from function words and word order are not available.", "labels": [], "entities": []}, {"text": "Query distance earth moon is missing function words between (preposition), and (coordinator), and the (determiner) in conveying the intent distance between the earth and the moon.", "labels": [], "entities": []}, {"text": "Also, it is likely that queries {distance earth moon, earth moon distance, earth distance moon, \u00b7 \u00b7 \u00b7 } have the same intent, which means they should have the same syntactic structure.", "labels": [], "entities": []}, {"text": "Second, there is no labeled dependency trees (treebank) for web queries, nor is there a standard for constructing such dependency trees.", "labels": [], "entities": []}, {"text": "It will take a tremendous amount of time and effort to come up with such a standard and a treebank for web queries.", "labels": [], "entities": []}, {"text": "In this paper, we propose an end-to-end solution from treebank construction to syntactic parsing for web queries.", "labels": [], "entities": [{"text": "treebank construction", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7559224963188171}, {"text": "syntactic parsing", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7361923456192017}]}, {"text": "Our model achieves a UAS of 0.830 and an LAS of 0.747 on web queries, which is dramatic improvement over state-of-the-art parsers trained from standard treebanks.", "labels": [], "entities": [{"text": "UAS", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9991466999053955}, {"text": "LAS", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9984753727912903}]}], "datasetContent": [{"text": "In this section, we start with some case studies.", "labels": [], "entities": []}, {"text": "Then we describe data and compare models.", "labels": [], "entities": []}, {"text": "In experiments, we use the standard UAS (unlabeled attachment score) and LAS (labeled attachment score) score for measuring the quality of dependency parsing.", "labels": [], "entities": [{"text": "UAS (unlabeled attachment score)", "start_pos": 36, "end_pos": 68, "type": "METRIC", "confidence": 0.8177113433678945}, {"text": "LAS (labeled attachment score) score", "start_pos": 73, "end_pos": 109, "type": "METRIC", "confidence": 0.9240796736308506}, {"text": "dependency parsing", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7630024254322052}]}, {"text": "They are calculated as: LAS = # correct arc directions and labels # total arcs (3)", "labels": [], "entities": [{"text": "LAS", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9990473389625549}]}], "tableCaptions": [{"text": " Table 5: Training dataset generation statistics", "labels": [], "entities": [{"text": "Training dataset generation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6532698174317678}]}]}