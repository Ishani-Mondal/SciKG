{"title": [{"text": "TweeTime: A Minimally Supervised Method for Recognizing and Normalizing Time Expressions in Twitter", "labels": [], "entities": [{"text": "Recognizing and Normalizing Time Expressions in Twitter", "start_pos": 44, "end_pos": 99, "type": "TASK", "confidence": 0.8148142439978463}]}], "abstractContent": [{"text": "We describe TweeTIME, a temporal tagger for recognizing and normalizing time expressions in Twitter.", "labels": [], "entities": []}, {"text": "Most previous work in social media analysis has to rely on temporal resolvers that are designed for well-edited text, and therefore suffer from reduced performance due to domain mismatch.", "labels": [], "entities": [{"text": "social media analysis", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.683385948340098}]}, {"text": "We present a minimally supervised method that learns from large quantities of unlabeled data and requires no hand-engineered rules or hand-annotated training corpora.", "labels": [], "entities": []}, {"text": "TweeTIME achieves 0.68 F1 score on the end-to-end task of resolving date expressions, outperforming abroad range of state-of-the-art systems.", "labels": [], "entities": [{"text": "TweeTIME", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7958321571350098}, {"text": "F1 score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9701333045959473}]}], "introductionContent": [{"text": "Temporal expressions are words or phrases that refer to dates, times or durations.", "labels": [], "entities": []}, {"text": "Resolving time expressions is an important task in information extraction (IE) that enables downstream applications such as calendars or timelines of events, knowledge base population), information retrieval (, automatically scheduling meetings from email and more.", "labels": [], "entities": [{"text": "Resolving time expressions", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8686516483624777}, {"text": "information extraction (IE)", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.8766059756278992}, {"text": "information retrieval", "start_pos": 186, "end_pos": 207, "type": "TASK", "confidence": 0.8222172260284424}]}, {"text": "Previous work in this area has applied rule-based systems or supervised machine learning on small collections of hand-annotated news documents ().", "labels": [], "entities": []}, {"text": "Social media especially contains time-sensitive information and requires accurate temporal analysis, for example, for detecting real-time cybersecurity events (, disease outbreaks ( and extracting personal information (.", "labels": [], "entities": []}, {"text": "However, most work on social media simply uses generic temporal resolvers and therefore suffers from suboptimal performance.", "labels": [], "entities": []}, {"text": "Recent work on temporal resolution focuses primarily on news articles and clinical texts.", "labels": [], "entities": [{"text": "temporal resolution", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7965251207351685}]}, {"text": "Resolving time expressions in social media is a non-trivial problem.", "labels": [], "entities": [{"text": "Resolving time expressions in social media", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.886561115582784}]}, {"text": "Besides many spelling variations, time expressions are more likely to refer to future dates than in newswire.", "labels": [], "entities": []}, {"text": "For the example in, we need to recognize that Monday refers to the upcoming Monday and not the previous one to resolve to its correct normalized date (5/9/2016).", "labels": [], "entities": [{"text": "5/9/2016", "start_pos": 151, "end_pos": 159, "type": "DATASET", "confidence": 0.7825714826583863}]}, {"text": "We also need to identify that the word Sun is not referring to a Sunday in this context.", "labels": [], "entities": []}, {"text": "In this paper, we present anew minimally supervised approach to temporal resolution that requires no in-domain annotation or hand-crafted rules, instead learning from large quantities of unlabeled text in conjunction with a database of known events.", "labels": [], "entities": [{"text": "temporal resolution", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7149887084960938}]}, {"text": "Our approach is capable of learning robust time expression models adapted to the informal style of text found on social media.", "labels": [], "entities": []}, {"text": "For popular events, some related tweets (e.g. 2) may contain explicit or other simple time mentions that can be captured by a generic temporal tagger.", "labels": [], "entities": []}, {"text": "An open-domain information extraction system ( can then identify events (e.g.) by aggregating those tweets.", "labels": [], "entities": [{"text": "open-domain information extraction", "start_pos": 3, "end_pos": 37, "type": "TASK", "confidence": 0.6412432293097178}]}, {"text": "To automatically generate temporally annotated data for training, we make the following novel distant supervision assumption: 2 Tweets posted near the time of a known event that mention central entities are likely to contain time expressions that refer to the date of the event.", "labels": [], "entities": []}, {"text": "Based on this assumption, tweets that contain the same named entity (e.g.) are heuristically labeled as training data.", "labels": [], "entities": []}, {"text": "Each tweet is associated with multiple overlapping labels that indicate the day of the week, day of the month, whether the event is in the pastor future and other time properties of the event date in relation to the tweet's creation date.", "labels": [], "entities": []}, {"text": "In order to learn a tagger that can recognize temporal expressions at the word-level, we present a multipleinstance learning approach to model sentence and word-level tags jointly and handle overlapping labels.", "labels": [], "entities": []}, {"text": "Using heuristically labeled data and the temporal tags predicted by the multiple-instance learning model as input, we then train a log-linear model that normalizes time expressions to calendar dates.", "labels": [], "entities": []}, {"text": "Building on top of the multiple-instance learning model, we further improve performance using a missing data model that addresses the problem of errors introduced during the heuristic labeling process.", "labels": [], "entities": []}, {"text": "Our best model achieves a 0.68 F1 score when resolving date mentions in Twitter.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9863139986991882}]}, {"text": "This is a 17% increase over SUTime (, outperforming other state-of-the-art time expression resolvers HeidelTime, TempEX) and UWTime () as well.", "labels": [], "entities": [{"text": "HeidelTime", "start_pos": 101, "end_pos": 111, "type": "DATASET", "confidence": 0.754122793674469}, {"text": "UWTime", "start_pos": 125, "end_pos": 131, "type": "DATASET", "confidence": 0.8580746650695801}]}, {"text": "Our approach also produces a confidence score that allows us to trade recall for precision.", "labels": [], "entities": [{"text": "confidence score", "start_pos": 29, "end_pos": 45, "type": "METRIC", "confidence": 0.9379026591777802}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9991108775138855}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.996803879737854}]}, {"text": "To the best of our knowledge, TweeTIME is the first time resolver designed specifically for social media data.", "labels": [], "entities": []}, {"text": "3 This is also the first time that distant supervision is successfully applied for end-to-end temporal recognition and normalization.", "labels": [], "entities": [{"text": "temporal recognition", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.7034069448709488}]}, {"text": "Previous distant supervision approaches only address the normalization problem, assuming gold time mentions are available attest time.", "labels": [], "entities": [{"text": "normalization", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.9661040306091309}]}], "datasetContent": [{"text": "In the following sub-sections we present experimental results on learning to resolve time expressions in Twitter using minimal supervision.", "labels": [], "entities": []}, {"text": "We start by describing our dataset, and proceed to present our results, including a large-scale evaluation on heuristically-labeled data and an evaluation comparing against human judgements.", "labels": [], "entities": []}, {"text": "We first evaluate our tagging model, by testing how well it can predict the heuristically generated labels.", "labels": [], "entities": []}, {"text": "As noted in previous work on distant supervision (), this type of evaluation usually under-estimates precision, however it provides us with a useful intrinsic measure of performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9993665814399719}]}, {"text": "In order to provide even coverage of months in the training and test set, we divide the twitter corpus into 3 subsets based on the mod-5 week of each tweet's creation date.", "labels": [], "entities": []}, {"text": "To train system we use tweets that are created in 1st, 2nd or 3rd weeks.", "labels": [], "entities": []}, {"text": "To tune parameters of the MiDaT model we used tweets from 5th weeks, and to evaluate the performance of the trained model we used tweets from 4th weeks.", "labels": [], "entities": []}, {"text": "The performance of the MiDaT model varies with the penalty and reward parameters.", "labels": [], "entities": []}, {"text": "To find a (near) optimal setting of the values we performed a grid search on the dev set and found that a penalty of \u221225 and reward of 500 works best.", "labels": [], "entities": [{"text": "reward", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9747377634048462}]}, {"text": "A comparison of MultiT and MiDaT's performance at predicting heuristically generated labels is shown in.", "labels": [], "entities": []}, {"text": "In addition to automatically evaluating our tagger on a large corpus of heuristically-labeled tweets, we also evaluate the performance of our tagging and date-resolution models on a random sample of tweets taken from a much later time period, that were manually annotated by the authors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance comparison of MultiT and MiDaT at pre-", "labels": [], "entities": [{"text": "MultiT", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.822151243686676}]}, {"text": " Table 3: Performance comparison of TweeTIME and SUTime", "labels": [], "entities": [{"text": "SUTime", "start_pos": 49, "end_pos": 55, "type": "TASK", "confidence": 0.528174877166748}]}, {"text": " Table 5: Feature ablation of the Temporal Resolver by remov-", "labels": [], "entities": [{"text": "Temporal Resolver", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7249239683151245}]}, {"text": " Table 6: Performance comparison of TweeTIME against state-", "labels": [], "entities": []}, {"text": " Table 7: Representative Examples of System (SUTime, HeidelTime, TweeTIME) Errors", "labels": [], "entities": [{"text": "TweeTIME) Errors", "start_pos": 65, "end_pos": 81, "type": "METRIC", "confidence": 0.8737932046254476}]}]}