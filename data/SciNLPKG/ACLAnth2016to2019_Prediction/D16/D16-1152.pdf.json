{"title": [{"text": "Toward Socially-Infused Information Extraction: Embedding Authors, Mentions, and Entities", "labels": [], "entities": [{"text": "Socially-Infused Information Extraction", "start_pos": 7, "end_pos": 46, "type": "TASK", "confidence": 0.7138028542200724}]}], "abstractContent": [{"text": "Entity linking is the task of identifying mentions of entities in text, and linking them to entries in a knowledge base.", "labels": [], "entities": [{"text": "Entity linking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7697351574897766}]}, {"text": "This task is especially difficult in microblogs, as there is little additional text to provide disambiguating context ; rather, authors rely on an implicit common ground of shared knowledge with their readers.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to capture some of this implicit context by exploiting the social network structure in microblogs.", "labels": [], "entities": []}, {"text": "We build on the theory of homophily, which implies that socially linked individuals share interests, and are therefore likely to mention the same sorts of entities.", "labels": [], "entities": []}, {"text": "We implement this idea by encoding authors, mentions, and entities in a continuous vector space, which is constructed so that socially-connected authors have similar vector representations.", "labels": [], "entities": []}, {"text": "These vectors are incorporated into a neural struc-tured prediction model, which captures structural constraints that are inherent in the entity linking task.", "labels": [], "entities": []}, {"text": "Together, these design decisions yield F1 improvements of 1%-5% on benchmark datasets, as compared to the previous state-of-the-art.", "labels": [], "entities": [{"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9994668364524841}]}], "introductionContent": [{"text": "Entity linking on short texts (e.g., Twitter messages) is of increasing interest, as it is an essential step for many downstream applications, such as market research (, topic detection and tracking, and question answering (.", "labels": [], "entities": [{"text": "Entity linking on short texts (e.g., Twitter messages)", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8127442435784773}, {"text": "topic detection and tracking", "start_pos": 170, "end_pos": 198, "type": "TASK", "confidence": 0.8697793781757355}, {"text": "question answering", "start_pos": 204, "end_pos": 222, "type": "TASK", "confidence": 0.9208700060844421}]}, {"text": "Tweet entity linking is a particularly difficult problem, because the short context around an entity mention is often insufficient for entity disambiguation.", "labels": [], "entities": [{"text": "Tweet entity linking", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9036380251248678}, {"text": "entity disambiguation", "start_pos": 135, "end_pos": 156, "type": "TASK", "confidence": 0.7350364029407501}]}, {"text": "For example, as shown in, the entity mention 'Giants' in tweet t 1 can refer to the NFL football team New York Giants or the MLB baseball team San Francisco Giants.", "labels": [], "entities": []}, {"text": "In this example, it is impossible to disambiguate between these entities solely based on the individual text message.", "labels": [], "entities": []}, {"text": "We propose to overcome the difficulty and improve the entity disambiguation capability of the entity linking system by employing social network structures.", "labels": [], "entities": [{"text": "entity disambiguation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7107935398817062}]}, {"text": "The sociological theory of homophily asserts that socially connected individuals are more likely to have similar behaviors or share similar interests ().", "labels": [], "entities": []}, {"text": "This property has been used to improve many natural language processing tasks such as sentiment analysis, topic classification and user attribute inference (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.9635945558547974}, {"text": "topic classification", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.894858330488205}, {"text": "user attribute inference", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.7072787483533224}]}, {"text": "We assume Twitter users will have similar interests in real world entities to their near neighbors -an assumption of entity homophily -which is demonstrated in.", "labels": [], "entities": []}, {"text": "The social relation between users u 1 and u 2 may lead to more coherent topics in tweets t 1 and t 2 . Therefore, by successfully linking the less ambiguous mention 'Red Sox' in tweet t 2 to the Boston Red Sox baseball team, the tweet entity linking system will be more confident on linking 'Giants' to the San Francisco Giants football team in tweet t 1 . To exploit social information, we adopt the recent advance on embedding information networks (, which induces low-dimensional representations for author nodes based on the network structure.", "labels": [], "entities": []}, {"text": "By learning the semantic interactions between the author embeddings and the pre-trained Freebase entity embeddings, the entity linking system can incorporate more disambiguating context from the social network.", "labels": [], "entities": []}, {"text": "We also consider lowdimensional representations of mentions, another source of related information for entity linking, with the intuition that semantically related mentions can refer to similar entities.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.7162228971719742}]}, {"text": "Previously proposed approaches ( are based on hand-crafted features and off-the-shelf machine learning algorithms.", "labels": [], "entities": []}, {"text": "Our preliminary study suggests that simply augmenting the traditional surface features with the distributed representations barely improves the performance of these entity linking systems.", "labels": [], "entities": []}, {"text": "Therefore, we propose NTEL, a Neural model for Tweet Entity Linking, to leverage the distributed representations of authors, mentions, and entities.", "labels": [], "entities": [{"text": "Tweet Entity Linking", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.8776979645093282}]}, {"text": "NTEL cannot only make efficient use of statistical surface features built from a knowledge base, but also learn the interactions between these distributed representations.", "labels": [], "entities": [{"text": "NTEL", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8628982901573181}]}, {"text": "Our contributions are summarized as follows: \u2022 We present a novel model for entity linking that exploits distributed representations of users, mentions, and entities.", "labels": [], "entities": []}, {"text": "\u2022 We combine this distributed model with a feedforward neural network that learns non-linear combinations of surface features.", "labels": [], "entities": []}, {"text": "\u2022 We perform message-level inference using a dynamic program to avoid overlapping mentions.", "labels": [], "entities": [{"text": "message-level inference", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.7380502820014954}]}, {"text": "The architecture is trained with lossaugmented decoding, a large margin learning technique for structured prediction.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.6494301557540894}]}, {"text": "\u2022 The complete system, NTEL, outperforms the previous state-of-the-art () by 3% average F1 on two benchmark datasets.", "labels": [], "entities": [{"text": "NTEL", "start_pos": 23, "end_pos": 27, "type": "DATASET", "confidence": 0.8196889162063599}, {"text": "F1", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.9974768757820129}]}], "datasetContent": [{"text": "In this section, we evaluate NTEL on the NEEL and TACL datasets as described in \u00a7 2, focusing on investigating whether social information can improve the task.", "labels": [], "entities": [{"text": "NEEL and TACL datasets", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.7579883262515068}]}, {"text": "We also compare NTEL with the previous state-of-the-art system.", "labels": [], "entities": [{"text": "NTEL", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.7855411171913147}]}, {"text": "Following, we train all the models with the NEEL-train dataset and evaluate different systems on the NEEL-test and TACL datasets.", "labels": [], "entities": [{"text": "NEEL-train dataset", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.9733240306377411}, {"text": "NEEL-test", "start_pos": 101, "end_pos": 110, "type": "DATASET", "confidence": 0.9017526507377625}, {"text": "TACL datasets", "start_pos": 115, "end_pos": 128, "type": "DATASET", "confidence": 0.782251238822937}]}, {"text": "In addition, 800 tweets from the NEELtrain dataset are sampled as our development set to perform parameter tuning.", "labels": [], "entities": [{"text": "NEELtrain dataset", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.9631129205226898}, {"text": "parameter tuning", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.6817470490932465}]}, {"text": "Note that also attempt to optimize F1 scores by balancing precision and recall scores on the development set; we do not fine tune our F1 in this way, so that we can apply a single trained system across different test sets.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9684876501560211}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9992398023605347}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9980171918869019}, {"text": "F1", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.940750777721405}]}, {"text": "Metrics We follow prior work ( and perform the standard evaluation for an end-to-end entity linking system, computing precision, recall, and F1 score according to the entity references and the system outputs.", "labels": [], "entities": [{"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9855203032493591}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9993815422058105}, {"text": "F1 score", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9852463603019714}]}, {"text": "An output entity is considered as correct if it matches the gold entity and the mention boundary overlaps with the gold mention boundary.", "labels": [], "entities": []}, {"text": "More details about the metrics are described by.", "labels": [], "entities": []}, {"text": "Competitive systems Our first baseline system, NTEL-nonstruct, ignores the structure information and makes the entity assignment decision for each mention candidate individually.", "labels": [], "entities": []}, {"text": "For NTEL, we start with a baseline system using the surface features, and then incorporate the two bilinear functions (user-entity and mention-entity) described in Equation 5 incrementally.", "labels": [], "entities": []}, {"text": "Our main evaluation uses the RETWEET+ network, since the retweet network had the greatest entity homophily; an additional evaluation compares across network types.", "labels": [], "entities": [{"text": "RETWEET", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9348635077476501}]}, {"text": "Parameter tuning We tune all the hyperparameters on the development set, and then re-train the models on the full training data with the best parameters.", "labels": [], "entities": [{"text": "Parameter", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9569724202156067}]}, {"text": "We choose the number of hidden units for the MLP from {20, 30, 40, 50}, and the regularization penalty for our composition model from {0.001, 0.005, 0.01, 0.05, 0.1}.", "labels": [], "entities": [{"text": "MLP", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.665813148021698}]}, {"text": "The sizes of user embeddings and word embeddings are selected from {50, 100} and {200, 400, 600} respectively.", "labels": [], "entities": []}, {"text": "The pre-trained Freebase entity embedding size is 1000.", "labels": [], "entities": [{"text": "Freebase entity embedding", "start_pos": 16, "end_pos": 41, "type": "DATASET", "confidence": 0.888816237449646}]}, {"text": "The learning rate for the SGD algorithm is set as 0.01.", "labels": [], "entities": [{"text": "SGD algorithm", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.8916224241256714}]}, {"text": "During training, we check the performance on the development set regularly to perform early stopping.", "labels": [], "entities": []}, {"text": "summarizes the empirical findings for our approach and S-MART (Yang and Chang, 2015) on the tweet entity linking task.", "labels": [], "entities": [{"text": "S-MART", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.907302737236023}, {"text": "tweet entity linking task", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.755900576710701}]}, {"text": "For the systems with user-entity bilinear function, we report results obtained from embeddings trained on RETWEET+ in, and other results are available in.", "labels": [], "entities": [{"text": "RETWEET", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.8811176419258118}]}, {"text": "The best hyper-parameters are: the number of hidden units for the MLP is 40, the L2 regularization penalty for the composition parameters is 0.005, and the user embedding size is 100.", "labels": [], "entities": []}, {"text": "For the word embedding size, we find 600 offers marginal improvements over 400 but requires longer training time.", "labels": [], "entities": []}, {"text": "Thus, we choose 400 as the size of word embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of data sets.", "labels": [], "entities": []}, {"text": " Table 2: The average entity-driven similarity results for the net-", "labels": [], "entities": []}, {"text": " Table 3: Statistics of author social networks used for training", "labels": [], "entities": []}, {"text": " Table 4: Evaluation results on the NEEL-test and TACL datasets for different systems. The best results are in bold.", "labels": [], "entities": [{"text": "NEEL-test", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.8173859715461731}, {"text": "TACL datasets", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.6973246484994888}]}, {"text": " Table 5: Comparison of different social networks with our full", "labels": [], "entities": []}]}