{"title": [{"text": "News Stream Summarization using Burst Information Networks", "labels": [], "entities": [{"text": "News Stream Summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6571538945039114}]}], "abstractContent": [{"text": "This paper studies summarizing key information from news streams.", "labels": [], "entities": [{"text": "summarizing key information from news streams", "start_pos": 19, "end_pos": 64, "type": "TASK", "confidence": 0.8171974221865336}]}, {"text": "We propose simple yet effective models to solve the problem based on a novel and promising representation of text streams-Burst Information Networks (BINets).", "labels": [], "entities": []}, {"text": "A BINet can be aware of redundant information, allows global analysis of a text stream, and can be efficiently built and dynamically updated, which perfectly fits the demands of text stream summarization.", "labels": [], "entities": [{"text": "text stream summarization", "start_pos": 178, "end_pos": 203, "type": "TASK", "confidence": 0.5405880510807037}]}, {"text": "Extensive experiments show that the BINet-based approaches are not only efficient and can be used in a real-time online summarization setting , but also can generate high-quality summaries , outperforming the state-of-the-art approach .", "labels": [], "entities": []}], "introductionContent": [{"text": "Text stream summarization aims to summarize key information from a text stream containing huge numbers of documents, which is an important and useful task that can be used for many real-world applications.", "labels": [], "entities": [{"text": "Text stream summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5510838528474172}, {"text": "summarize key information from a text stream containing huge numbers of documents", "start_pos": 34, "end_pos": 115, "type": "TASK", "confidence": 0.7639481425285339}]}, {"text": "For example, a news portal website editor needs to summarize news streams in the past day for generating a list of headline news; an editor of Sports Weekly may want a summary of the past week news stream for editing the magazine; and geologists and meteorologists will benefit from a summary of disaster events from the past year news stream (as shown in) for their study.", "labels": [], "entities": [{"text": "Sports Weekly", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.9054206907749176}]}, {"text": "In contrast to traditional text summarization tasks (e.g., single and multi-document summarization) * This work was done when the first author was visiting Microsoft Research Asia that have been extensively studied for decades, the task of stream summarization is a younger research problem which attempts to solve a summarization problem in the big-data setting.", "labels": [], "entities": [{"text": "text summarization tasks", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.7244532207647959}, {"text": "stream summarization", "start_pos": 240, "end_pos": 260, "type": "TASK", "confidence": 0.6589922904968262}, {"text": "summarization", "start_pos": 317, "end_pos": 330, "type": "TASK", "confidence": 0.9735925793647766}]}, {"text": "For a text stream with millions of documents involving various topics and events, traditional single-and multi-document summarization approaches cannot address the information overload challenge.", "labels": [], "entities": []}, {"text": "For example, a singledocument summarization model will generate 1 million document summaries fora text stream with 1 million documents, which are still overwhelming fora person to learn the key information in the stream.", "labels": [], "entities": []}, {"text": "In such cases, one needs to a summary of the whole stream instead of summaries of each document.", "labels": [], "entities": []}, {"text": "shows the paradigm of stream summarization.", "labels": [], "entities": [{"text": "stream summarization", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.5754446089267731}]}, {"text": "Compared with single-and multidocument summarization, stream summarization has three differences: (1) it summarizes a text stream containing millions of documents involving a variety of topics and events while single-and 784 2009 disaster summary 2010 disaster summary \u2022 ...", "labels": [], "entities": []}, {"text": "\u2022 Sep 2, 2009: About 60 people die when a 7.1-magnitude earthquake hit the island of Java.", "labels": [], "entities": []}, {"text": "\u2022 Jan 12, 2010: A 7.0-magnitude earthquake hit Haiti, killing about 200,000 people.", "labels": [], "entities": []}, {"text": "\u2022 Sep 9, 2009: More than 30 people are killed when fast moving floods caused by heavy rain sweep through Istanbul.", "labels": [], "entities": []}, {"text": "\u2022: An 8.8-magnitude earthquake rocked Chile, killing at least 700 people dead and affecting more than 1.5 million people.", "labels": [], "entities": []}, {"text": "\u2022 Sep 30, 2009: A 7.6-magnitude earthquake hit the island of Sumatra, leaving more than 1,000 people dead and thousands injured.", "labels": [], "entities": []}, {"text": "\u2022 Apr 5, 2010: An explosion in a West Virginia coalmine kills at least 25 people and leaves 4 unaccounted for.", "labels": [], "entities": []}, {"text": "multi-document summarization summarizes one or a handful of documents about the same news event; (2) instead of selecting sentences to generate a summary, stream summarization selects representative documents to summarize a text stream; (3) summaries fora text stream may vary significantly for users who have different interests and preferences (e.g., summaries for an environmental expert and a sports fan should not be the same).", "labels": [], "entities": [{"text": "multi-document summarization summarizes one or a handful of documents about the same news event", "start_pos": 0, "end_pos": 95, "type": "TASK", "confidence": 0.6640478244849614}]}, {"text": "Therefore, in order to generate targeted summaries for specific users, a stream summary needs to be generated based on a reference summary.", "labels": [], "entities": []}, {"text": "For instance, one can use the 2009 disaster summary (the left part in) as a reference to learn how to write the 2010 disaster summary (the right part in).", "labels": [], "entities": [{"text": "2009 disaster summary", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.7949418624242147}]}, {"text": "In general, there are three challenges for summarizing a text stream.", "labels": [], "entities": [{"text": "summarizing a text stream", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.8693239837884903}]}, {"text": "First, a stream summarization model should be able to be aware of redundant information in the stream for avoiding generating redundant content in the summary; second, a stream summarization algorithm should be capable of analyzing text content on the stream level for identifying the most important information in the stream; third, a stream summarization model should be efficient, scalable and able to run in an online fashion because data size of a text stream is usually huge, and it is dynamic and updated every second.", "labels": [], "entities": [{"text": "stream summarization", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.6465666890144348}]}, {"text": "The previous approaches (e.g.,)) tend to cluster similar documents as event detection to avoid redundancy, rank the clusters based on their sizes and topical relevance to the reference summaries, and select one document from each cluster as representative documents.", "labels": [], "entities": [{"text": "event detection", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7373187839984894}]}, {"text": "Due to the high time complexity of clustering models, their approaches usually run slowly and are not scalable.", "labels": [], "entities": []}, {"text": "To overcome the limitations, we propose Burst Information Networks (BINet) as a novel representation of a text stream.", "labels": [], "entities": []}, {"text": "Ina BINet), anode is a burst word (including entities) with the time span of one of its burst periods, and an edge between two nodes indicates how strongly they are related.", "labels": [], "entities": []}, {"text": "Based on the BINet representation, we propose two models -NodeRank and AreaRank -for summarizing a news stream.", "labels": [], "entities": [{"text": "summarizing a news stream", "start_pos": 85, "end_pos": 110, "type": "TASK", "confidence": 0.888460099697113}]}, {"text": "We conduct extensive experiments to evaluate our approaches by comparing several baselines and the state-of-the-art approaches in various settings and show that the BINet-based approaches are efficient, scalable and can work in an online fashion and that they can generate high-quality summaries fora news stream, outperforming the stateof-the-art.", "labels": [], "entities": []}, {"text": "The major contributions of this paper are: \u2022 We propose BINets as a novel representation of text streams.", "labels": [], "entities": []}, {"text": "BINets can perfectly address the challenges of text stream summarization, which can be aware of information redundancy (Section 3), enables global analysis of the text stream (Section 4.1 and 4.2), and be efficiently built and updated incrementally (Section 4.3).", "labels": [], "entities": [{"text": "text stream summarization", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.6340903341770172}]}, {"text": "\u2022 We propose two ranking-based models based on the BINet representation, which can effectively learn to summarize a text stream from a reference summary, and outperform the stateof-the-art model.", "labels": [], "entities": [{"text": "summarize a text stream", "start_pos": 104, "end_pos": 127, "type": "TASK", "confidence": 0.8638855069875717}]}, {"text": "\u2022 We create and release anew benchmark dataset for evaluating real-time stream summarization.", "labels": [], "entities": [{"text": "real-time stream summarization", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.607819398244222}]}], "datasetContent": [{"text": "For comparison to the previous work, we use the same data with Ge et al.", "labels": [], "entities": []}, {"text": "(2015b) (i.e., 2009 and 2010 APW and XIN news stories in English Gigaword () as a news stream.", "labels": [], "entities": [{"text": "APW and XIN news stories", "start_pos": 29, "end_pos": 53, "type": "DATASET", "confidence": 0.8208022594451905}]}, {"text": "We detect burst words using Kleinberg algorithm), which models word burst detection as a burst state decoding problem.", "labels": [], "entities": [{"text": "word burst detection", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.663629432519277}]}, {"text": "In total, there are 140,557 documents in the dataset.", "labels": [], "entities": []}, {"text": "as reference summaries for summarizing the news stream during 2010.", "labels": [], "entities": [{"text": "summarizing the news stream during 2010", "start_pos": 27, "end_pos": 66, "type": "DATASET", "confidence": 0.7474806010723114}]}, {"text": "The information of the reference summaries is summarized in.", "labels": [], "entities": []}, {"text": "In evaluation, they pooled entries in stream sumamries generated by various approaches, annotated each entry based on the reference summary and the manually edited event chronicles on the web, and used precision@K to evaluate the quality of top K event entries in a stream summary instead of using ROUGE) because news stream summaries are eventcentric.", "labels": [], "entities": [{"text": "precision@K", "start_pos": 202, "end_pos": 213, "type": "METRIC", "confidence": 0.91722438732783}, {"text": "ROUGE", "start_pos": 298, "end_pos": 303, "type": "METRIC", "confidence": 0.9866365790367126}]}, {"text": "In this paper, we adopt the same evaluation setting and use the same reference summaries and the annotations with our previous work) to evaluate our summaries' quality.", "labels": [], "entities": []}, {"text": "For the event entries that are not in's annotations, we have 3 human judges annotate them according to the previous annotation guideline and consider an entry correct if it is annotated as correct by at least 2 judges.", "labels": [], "entities": []}, {"text": "We evaluate our approaches by comparing to's approach and the baselines in their work: \u2022 RANDOM: this baseline randomly selects documents in the dataset as event entries.", "labels": [], "entities": [{"text": "RANDOM", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9468976855278015}]}, {"text": "\u2022 NB: this baseline uses Naive Bayes to cluster documents for event detection and ranks the clusters based on the combination score of topical relevance and the event impact (i.e., event cluster size).", "labels": [], "entities": [{"text": "NB", "start_pos": 2, "end_pos": 4, "type": "DATASET", "confidence": 0.7690581679344177}, {"text": "event detection", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7384824156761169}]}, {"text": "The earliest documents in the topranked clusters are selected as entries.", "labels": [], "entities": []}, {"text": "\u2022 B-HAC: similar to NB except that BurstVSM representation () is used for event detection using Hierarchical Agglomerative Clustering algorithm.", "labels": [], "entities": [{"text": "B-HAC", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9699791669845581}, {"text": "BurstVSM", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9575614333152771}, {"text": "event detection", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.7356656640768051}]}, {"text": "\u2022 TAHBM: similar to NB except that the stateof-the-art event detection model (TaHBM) proposed by is used for event detection.  discussed.", "labels": [], "entities": [{"text": "TAHBM", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9352680444717407}, {"text": "NB", "start_pos": 20, "end_pos": 22, "type": "DATASET", "confidence": 0.8921388983726501}, {"text": "stateof-the-art event detection", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.6360034247239431}, {"text": "event detection", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.8206380307674408}]}, {"text": "Moreover, these two tasks differ greatly in the data size and redundancy identification mechanism.", "labels": [], "entities": [{"text": "redundancy identification", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.726909726858139}]}, {"text": "Therefore, it is not feasible to directly compare multi-document summarization models to our approaches unless they are adapted for our setting.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "It can be clearly observed that BINet-based approaches outperform baselines and perform comparably to the state-ofthe-art model on generating the summaries on most topics: AreaRank achieves the significant improvement over the state-of-the-art model on sports and disasters, and performs comparably on politics and military and NodeRank's performance achieves the comparable performance to previous state-of-the-art model though it is inferior to AreaRank on most topics.", "labels": [], "entities": []}, {"text": "Among these five topics, almost all models perform well on disaster and military topics because disaster and military reference summaries have more entries than the topics such as politics and sports and topics of event entries in the summaries are focused.", "labels": [], "entities": []}, {"text": "The high-quality training data benefits models' performance especially for AreaRank which is purely data-driven.", "labels": [], "entities": [{"text": "AreaRank", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9046376347541809}]}, {"text": "In contrast, on sports and politics, the number of entries in the reference summaries is small, which results in weaker supervision and affect the performance of models.", "labels": [], "entities": []}, {"text": "It is notable that AreaRank does not perform well on generating the comprehensive summary in which topics of event entries are miscellaneous.", "labels": [], "entities": []}, {"text": "The reason for the undesirable performance is that the topics of event entries in the comprehensive reference summary are not focused, which results in very few reference (positive) examples for each topic.", "labels": [], "entities": []}, {"text": "As a result, the miscellaneousness of topics of positive examples makes them tend to be overwhelmed by large numbers of negative examples during training the model, leading to very week supervision and making it difficult for AreaRank to learn the patterns  To evaluate our approaches in areal setting, we create a benchmark dataset 4 containing 7.9 million English news stories (without exact duplication) during Feb 5 to Mar 31, 2015, collecting from Bing news portal   NodeRank and AreaRank) on the real-time stream.", "labels": [], "entities": [{"text": "Bing news portal   NodeRank", "start_pos": 453, "end_pos": 480, "type": "DATASET", "confidence": 0.866046279668808}, {"text": "AreaRank", "start_pos": 485, "end_pos": 493, "type": "DATASET", "confidence": 0.6661700010299683}]}, {"text": "Specifically, we used news stream during Feb 5 to Mar 23 for training to generate news summaries for everyday during Mar 24 to Mar 30 in an online fashion.", "labels": [], "entities": []}, {"text": "This is a practical setting and can be useful for automatically generating headline news everyday.", "labels": [], "entities": [{"text": "automatically generating headline news everyday", "start_pos": 50, "end_pos": 97, "type": "TASK", "confidence": 0.7365064859390259}]}, {"text": "Daily news summaries in Current Event Portal 6 at Wikipedia are used as reference summaries for training and gold standard for evaluating our approaches.", "labels": [], "entities": [{"text": "Current Event Portal 6 at Wikipedia", "start_pos": 24, "end_pos": 59, "type": "DATASET", "confidence": 0.6464400837818781}]}, {"text": "In this paper, we tested on generating summaries on Disaster and accident (Disaster) and Armed conflicts and attacks (Attack) topics.", "labels": [], "entities": []}, {"text": "Instead of evaluating Precision@K as we did on the Gigaword corpus which is a small dataset, we used Mean Reciprocal Rank (MRR) which is defined as follows to seethe ranking position of event entries of the gold standard in the summaries generated by our approaches: where gold is the gold standard summaries at time t, T testis the period of test set (i.e., Mar 24 to Mar 30) and rank e k is the highest rank of an event entry e k of the gold standard summary in our summary at t.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.9264883697032928}, {"text": "Mean Reciprocal Rank (MRR)", "start_pos": 101, "end_pos": 127, "type": "METRIC", "confidence": 0.9530319372812907}]}, {"text": "A high MRR means the event entries of gold standard tend to be ranked at top positions in our generated summaries.", "labels": [], "entities": [{"text": "MRR", "start_pos": 7, "end_pos": 10, "type": "METRIC", "confidence": 0.9926451444625854}]}, {"text": "The evaluation is conducted manually.", "labels": [], "entities": []}, {"text": "shows the performance of BINet-based 6 https://en.wikipedia.org/wiki/Portal:Current events/ approaches on the real-time news stream.", "labels": [], "entities": [{"text": "BINet-based 6", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.8212162852287292}]}, {"text": "The BINet-based approaches achieve better results than the online version of B-HAC model on both topics, demonstrating the advantages of the BINet representation.", "labels": [], "entities": []}, {"text": "It is also notable that AreaRank performs better than NodeRank because it scores a document area as a whole by taking into account various information of the area.", "labels": [], "entities": []}, {"text": "For AreaRank, MRR on the disaster topic is about 0.2, meaning that the average ranking position of gold standard event entries is 5, which is a promising result and shows our approach can be effective to find key information.", "labels": [], "entities": [{"text": "MRR", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9515506625175476}]}, {"text": "More importantly, it only takes 500 seconds to build a BINet and 388 seconds to run PageRank for 1,000 iterations for global importance analysis on the 7.9 million documents while other methods in even cannot be applied on the stream because they cannot handle so large scale of data or work in an online fashion, which is why we did not compare to them in this setting.", "labels": [], "entities": [{"text": "BINet", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.6930944323539734}, {"text": "PageRank", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.8927128314971924}, {"text": "global importance analysis", "start_pos": 118, "end_pos": 144, "type": "TASK", "confidence": 0.7066091299057007}]}], "tableCaptions": [{"text": " Table 1. In a stream summary, entries should not  be redundant. Formally, we define a stream sum- mary (i.e., event chronicle) E = {e 1 , e 2 , \u00b7 \u00b7 \u00b7 , e K }  where e k = (t e k , w e k ) is an event entry including  the event's time information t e k and text description  w e k which is set of words in text.", "labels": [], "entities": []}, {"text": " Table 2: The number of event entries in the reference sum-", "labels": [], "entities": []}, {"text": " Table 3: Performance of various approaches on stream summarization on five topics.", "labels": [], "entities": [{"text": "stream summarization", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.6097355782985687}]}, {"text": " Table 4: Ablation test on feature combination for generating", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9942804574966431}]}, {"text": " Table 5: Error analysis of BINet-based approaches.", "labels": [], "entities": []}, {"text": " Table 6: Run time of BINet-based approaches and Ge et al. (2015b)'s approach", "labels": [], "entities": []}, {"text": " Table 6. The run time is  tested on a workstation with Intel Xeon 3.5 GHz  CPU and 64GB RAM. The efficiency of our model  is much better than", "labels": [], "entities": []}]}