{"title": [{"text": "EQUATION PARSING : Mapping Sentences to Grounded Equations", "labels": [], "entities": [{"text": "PARSING", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.6190685629844666}]}], "abstractContent": [{"text": "Identifying mathematical relations expressed in text is essential to understanding abroad range of natural language text from election reports, to financial news, to sport commentaries to mathematical word problems.", "labels": [], "entities": []}, {"text": "This paper focuses on identifying and understanding mathematical relations described within a single sentence.", "labels": [], "entities": []}, {"text": "We introduce the problem of Equation Parsing-given a sentence, identify noun phrases which represent variables, and generate the mathematical equation expressing the relation described in the sentence.", "labels": [], "entities": [{"text": "Equation Parsing-given a sentence", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.9110945463180542}]}, {"text": "We introduce the notion of projective equation parsing and provide an efficient algorithm to parse text to projective equations.", "labels": [], "entities": [{"text": "projective equation parsing", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.6276027957598368}]}, {"text": "Our system makes use of a high precision lexicon of mathematical expressions and a pipeline of struc-tured predictors, and generates correct equations in 70% of the cases.", "labels": [], "entities": []}, {"text": "In 60% of the time, it also identifies the correct noun phrase \u2192 variables mapping, significantly outperform-ing baselines.", "labels": [], "entities": []}, {"text": "We also release anew annotated dataset for task evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding text often involves reasoning with respect to quantities mentioned in it.", "labels": [], "entities": []}, {"text": "Understanding the news article statement in Example 1 requires identifying relevant entities and the mathematical relations expressed among them in text, and determining how to compose them.", "labels": [], "entities": []}, {"text": "Similarly, solving a math word problem with a sentence like Example 2, requires realizing that it deals with a single number, knowing the meaning of \"difference\" and composExample 1 Emanuel's campaign contributions total three times those of his opponents put together.", "labels": [], "entities": []}, {"text": "Example 2 Twice a number equals 25 less than triple the same number.", "labels": [], "entities": []}, {"text": "Example 3 Flying with the wind , a bird was able to make 150 kilometers per hour.", "labels": [], "entities": []}, {"text": "Example 4 The sum of two numbers is 80.", "labels": [], "entities": []}, {"text": "Example 5 There are 54 5-dollar and 10-dollar notes.", "labels": [], "entities": []}, {"text": "ing the right equation -\"25\" needs to be subtracted from a number only after it is multiplied by 3.", "labels": [], "entities": []}, {"text": "As a first step towards understanding such relations, we introduce the Equation Parsing task -given a sentence expressing a mathematical relation, the goal is to generate an equation representing the relation, and to map the variables in the equation to their corresponding noun phrases.", "labels": [], "entities": [{"text": "Equation Parsing task", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.800096352895101}]}, {"text": "To keep the problem tractable, in this paper we restrict the final output equation form to have at most two (possibly coreferent) variables, and assume that each quantity mentioned in the sentence can be used at most once in the final equation.", "labels": [], "entities": []}, {"text": "In example 1, the gold output of an equation parse should be V 1 = 3 \u00d7 V 2 , with V 1 = \"Emanuel's campaign contributions\" and V 2 = \"those of his opponents put together\".", "labels": [], "entities": []}, {"text": "The task can be seen as a form of semantic parsing () where instead of mapping a sentence to a logical form, we want to map it to an equation.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7563571929931641}]}, {"text": "However, there are some key differences that make this problem very challenging in ways that differ from the \"standard\" semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.7583895921707153}]}, {"text": "In Equation Parsing, not all the components of the sentence are mapped to the final equation.", "labels": [], "entities": [{"text": "Equation Parsing", "start_pos": 3, "end_pos": 19, "type": "TASK", "confidence": 0.8543284237384796}]}, {"text": "There is a need to identify noun phrases that correspond to variables in the relations and determine that some are irrelevant and can be dropped.", "labels": [], "entities": []}, {"text": "Moreover, in difference from semantic parsing into logical forms, in Equation Parsing multiple phrases in the text could correspond to the same variable, and identical phrases in the text could correspond to multiple variables.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7428587675094604}, {"text": "Equation Parsing", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.7414426803588867}]}, {"text": "We call the problem of mapping noun phrases to variables the problem of grounding variables.", "labels": [], "entities": []}, {"text": "Grounding is challenging for various reasons, key among them are that: (i) The text often does not mention \"variables\" explicitly, e.g., the sentence in example 3 describes a mathematical relation between the speed of bird and the speed of wind, without mentioning \"speed\" explicitly.", "labels": [], "entities": []}, {"text": "(ii) Sometimes, multiple noun phrases could refer to the same variable.", "labels": [], "entities": []}, {"text": "For instance, in example 2, both \"a number\" and \"the same number\" refer to the same variable.", "labels": [], "entities": []}, {"text": "On the other hand, the same noun phrase might refer to multiple variables, as in example 4, where the noun phrase \"two numbers\" refer to two variables.", "labels": [], "entities": []}, {"text": "In addition, the task involves deciding which of the quantities identified in the sentence are relevant to the final equation generation.", "labels": [], "entities": [{"text": "final equation generation", "start_pos": 111, "end_pos": 136, "type": "TASK", "confidence": 0.7357827226320902}]}, {"text": "In example 5, both \"5\" and \"10\" are not relevant for the final equation \"V 1 + V 2 = 54\".", "labels": [], "entities": []}, {"text": "Finally, the equation needs to be constructed from a list of relevant quantities and grounded variables.", "labels": [], "entities": []}, {"text": "Overall, the output space becomes exponential in the number of quantities mentioned in the sentence.", "labels": [], "entities": []}, {"text": "Determining the final equation that corresponds to the text is an inference step over a very large space.", "labels": [], "entities": []}, {"text": "To address this, we define the concept of \"projectivity\" -a condition where the final equation can be generated by combining adjacent numbers or variables, and show that most sentences expressing mathematical relations exhibit the projectivity property.", "labels": [], "entities": []}, {"text": "Finally, we restrict our inference procedure to only search over equations which have this property.", "labels": [], "entities": []}, {"text": "Our approach builds on a pipeline of structured predictors that identify irrelevant quantities, recognize coreferent variables, and, finally, generate equations.", "labels": [], "entities": []}, {"text": "We also leverage a high precision lexicon of mathematical expressions and develop a greedy lexicon matching strategy to guide inference.", "labels": [], "entities": []}, {"text": "We discuss and exemplify the advantages of this approach and, in particular, explain where the \"standard\" NLP pipeline fails to support equation parsing, and necessitates the new approach proposed here.", "labels": [], "entities": [{"text": "equation parsing", "start_pos": 136, "end_pos": 152, "type": "TASK", "confidence": 0.7712318897247314}]}, {"text": "Another contribution of this work is the development of anew annotated data set for the task of equation parsing.", "labels": [], "entities": [{"text": "equation parsing", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.8525987863540649}]}, {"text": "We evaluate our method on this dataset and show that our method predicts the correct equation in 70% of the cases and that in 60% of the time we also ground all variables correctly.", "labels": [], "entities": []}, {"text": "The next section presents a discussion of related work.", "labels": [], "entities": []}, {"text": "Next we formally describe the task of equation parsing.", "labels": [], "entities": [{"text": "equation parsing", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7681277096271515}]}, {"text": "The following sections describe our equation representation and the concept of projectivity, followed by the description of our algorithm to generate the equations and variable groundings from text.", "labels": [], "entities": []}, {"text": "We conclude with experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now describe the data set, and the annotation procedure used.", "labels": [], "entities": []}, {"text": "We then evaluate the system's performance on predicting trigger list, equation tree, and the complete equation parse.", "labels": [], "entities": [{"text": "predicting trigger list", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.81354159116745}, {"text": "complete equation parse", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.6947592496871948}]}, {"text": "We created anew dataset consisting of 385 sentences extracted from algebra word problems and financial news headlines.", "labels": [], "entities": []}, {"text": "For algebra word problems, we used the MIT dataset ( ), and two high school mathematics textbooks, Elementary Algebra (College of Redwoods) and Beginning and Intermediate Algebra (Tyler Wallace).", "labels": [], "entities": [{"text": "algebra word problems", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6955073277155558}, {"text": "MIT dataset", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.9572347402572632}, {"text": "Beginning and Intermediate Algebra (Tyler Wallace)", "start_pos": 144, "end_pos": 194, "type": "DATASET", "confidence": 0.5797691494226456}]}, {"text": "Financial news headlines were extracted from The Latest News feed of MarketWatch, over the month of February, 2015.", "labels": [], "entities": [{"text": "The Latest News feed of MarketWatch", "start_pos": 45, "end_pos": 80, "type": "DATASET", "confidence": 0.7968899011611938}]}, {"text": "All sentences with information describing a mathematical relation among at most two (possibly coreferent) variables, were chosen.", "labels": [], "entities": []}, {"text": "Next, we pruned sentences which require multiple uses of a number to create the equation.", "labels": [], "entities": []}, {"text": "This only removed a few time related sentences like \"In 10 years, John will be twice as old as his son.\".", "labels": [], "entities": []}, {"text": "We empirically found that around 97% of sentences describing a relation fall under the scope of our dataset.", "labels": [], "entities": []}, {"text": "The annotators were shown each sentence paired with the normalized equation representing the relation in the sentence.", "labels": [], "entities": []}, {"text": "For each variable in the equation, the annotators were asked to mark spans of text which best describe what the variable represents.", "labels": [], "entities": []}, {"text": "The annotation guidelines are provided in the appendix.", "labels": [], "entities": []}, {"text": "We wanted to consider only noun phrase constituents for variable grounding.", "labels": [], "entities": []}, {"text": "Therefore, for each annotated span, we extracted the noun phrase with maximum overlap with the span, and used it to represent the variables.", "labels": [], "entities": []}, {"text": "Finally, a tuple with each variable being mapped to one of the noun phrases representing it, forms a valid output grounding (variable trigger list).", "labels": [], "entities": []}, {"text": "We computed interannotator agreement on the final annotations where only noun phrases represent variables.", "labels": [], "entities": []}, {"text": "The agreement (kappa) was 0.668, indicating good agreement.", "labels": [], "entities": [{"text": "agreement (kappa)", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.9417453557252884}]}, {"text": "The average number of mention annotations per sentence was 1.74.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performance of system components", "labels": [], "entities": []}, {"text": " Table 4: Performance on equation parsing", "labels": [], "entities": [{"text": "equation parsing", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7817137837409973}]}]}