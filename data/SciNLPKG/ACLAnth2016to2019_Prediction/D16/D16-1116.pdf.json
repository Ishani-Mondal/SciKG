{"title": [{"text": "Semantic Parsing with Semi-Supervised Sequential Autoencoders", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8501104712486267}]}], "abstractContent": [{"text": "We present a novel semi-supervised approach for sequence transduction and apply it to semantic parsing.", "labels": [], "entities": [{"text": "sequence transduction", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.6704000681638718}, {"text": "semantic parsing", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.8093606531620026}]}, {"text": "The unsupervised component is based on a generative model in which latent sentences generate the unpaired logical forms.", "labels": [], "entities": []}, {"text": "We apply this method to a number of semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7275624573230743}]}], "introductionContent": [{"text": "Neural approaches, in particular attention-based sequence-to-sequence models, have shown great promise and obtained state-of-the-art performance for sequence transduction tasks including machine translation (), syntactic constituency parsing, and semantic role labelling (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 187, "end_pos": 206, "type": "TASK", "confidence": 0.8090241551399231}, {"text": "syntactic constituency parsing", "start_pos": 211, "end_pos": 241, "type": "TASK", "confidence": 0.6659810145696005}, {"text": "semantic role labelling", "start_pos": 247, "end_pos": 270, "type": "TASK", "confidence": 0.677519957224528}]}, {"text": "A key requirement for effectively training such models is an abundance of supervised data.", "labels": [], "entities": []}, {"text": "In this paper we focus on learning mappings from input sequences x to output sequences yin domains where the latter are easily obtained, but annotation in the form of (x, y) pairs is sparse or expensive to produce, and propose a novel architecture that accommodates semi-supervised training on sequence transduction tasks.", "labels": [], "entities": [{"text": "sequence transduction tasks", "start_pos": 294, "end_pos": 321, "type": "TASK", "confidence": 0.7597043514251709}]}, {"text": "To this end, we augment the transduction objective (x \u2192 y) with an autoencoding objective where the input sequence is treated as a latent variable (y \u2192 x \u2192 y), enabling training from both labelled pairs and unpaired output sequences.", "labels": [], "entities": []}, {"text": "This is common in situations where we encode natural language into a logical form governed by some grammar or database.", "labels": [], "entities": []}, {"text": "While such an autoencoder could in principle be constructed by stacking two sequence transducers, modelling the latent variable as a series of discrete symbols drawn from multinomial distributions creates serious computational challenges, as it requires marginalising over the space of latent sequences \u03a3 * x . To avoid this intractable marginalisation, we introduce a novel differentiable alternative for draws from a softmax which can be used with the reparametrisation trick of.", "labels": [], "entities": []}, {"text": "Rather than drawing a discrete symbol in \u03a3 x from a softmax, we draw a distribution over symbols from a logistic-normal distribution at each time step.", "labels": [], "entities": []}, {"text": "These serve as continuous relaxations of discrete samples, providing a differentiable estimator of the expected reconstruction log likelihood.", "labels": [], "entities": [{"text": "expected reconstruction log likelihood", "start_pos": 103, "end_pos": 141, "type": "METRIC", "confidence": 0.5945792719721794}]}, {"text": "We demonstrate the effectiveness of our proposed model on three semantic parsing tasks: the GEO-QUERY benchmark), the SAIL maze navigation task () and the Natural Language Querying corpus) on OpenStreetMap.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7375946342945099}, {"text": "GEO-QUERY benchmark", "start_pos": 92, "end_pos": 111, "type": "DATASET", "confidence": 0.7714946269989014}, {"text": "SAIL maze navigation task", "start_pos": 118, "end_pos": 143, "type": "TASK", "confidence": 0.7488797008991241}]}, {"text": "As part of our evaluation, we introduce simple mechanisms for generating large amounts of unsupervised training data for two of these tasks.", "labels": [], "entities": []}, {"text": "In most settings, the semi-supervised model outperforms the supervised model, both when trained on additional generated data as well as on subsets of the existing data.", "labels": [], "entities": []}], "datasetContent": [{"text": "GEO what are the high points of states surrounding mississippi answer(high point 1(state(next to 2(stateid('mississippi')))))  We evaluate our model on the three tasks in multiple settings.", "labels": [], "entities": []}, {"text": "First, we establish a supervised baseline to compare the S2S model with prior work.", "labels": [], "entities": []}, {"text": "Next, we Our randomly generated unsupervised datasets can be downloaded from http://deepmind.com/ publications  train our SEQ4 model in a semi-supervised setting on the entire dataset with the additional monomodal training data described in the previous section.", "labels": [], "entities": []}, {"text": "Finally, we perform an \"ablation\" study where we discard some of the training data and compare S2S to SEQ4.", "labels": [], "entities": [{"text": "SEQ4", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.9360234141349792}]}, {"text": "S2S is trained solely on the reduced data in a supervised manner, while SEQ4 is once again trained semi-supervised on the same reduced data plus the machine readable part of the discarded data (SEQ4-) or on the extra generated data (SEQ4+).", "labels": [], "entities": []}, {"text": "Training We train the model using standard gradient descent methods.", "labels": [], "entities": []}, {"text": "As none of the datasets used here contain development sets, we tune hyperparameters by cross-validating on the training data.", "labels": [], "entities": []}, {"text": "In the case of the SAIL corpus we train on three folds (two mazes for training and validation, one for test each) and report weighted results across the folds following prior work ().", "labels": [], "entities": [{"text": "SAIL corpus", "start_pos": 19, "end_pos": 30, "type": "DATASET", "confidence": 0.7346198260784149}]}], "tableCaptions": [{"text": " Table 2: Non-neural and neural model results on GEOQUERY", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8806140422821045}]}, {"text": " Table 3: Results of the GEOQUERY ablation study.", "labels": [], "entities": [{"text": "GEOQUERY ablation study", "start_pos": 25, "end_pos": 48, "type": "DATASET", "confidence": 0.8839947382609049}]}, {"text": " Table 4: Results on the NLMAPS corpus.", "labels": [], "entities": [{"text": "NLMAPS corpus", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9278022348880768}]}, {"text": " Table 5: Results of the NLMAPS ablation study.", "labels": [], "entities": [{"text": "NLMAPS ablation study", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.8471677501996359}]}, {"text": " Table 8: Positive and negative examples of latent language together with the randomly generated logical form from the unsupervised", "labels": [], "entities": []}, {"text": " Table 7: Results of the SAIL ablation study. Results are from", "labels": [], "entities": [{"text": "SAIL ablation study", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.8306844631830851}]}]}