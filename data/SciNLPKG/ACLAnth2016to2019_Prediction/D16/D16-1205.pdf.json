{"title": [{"text": "Representing Verbs with Rich Contexts: an Evaluation on Verb Similarity", "labels": [], "entities": [{"text": "Representing Verbs with Rich Contexts", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8295632004737854}, {"text": "Similarity", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.6609725952148438}]}], "abstractContent": [{"text": "Several studies on sentence processing suggest that the mental lexicon keeps track of the mutual expectations between words.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7127248346805573}]}, {"text": "Current DSMs, however, represent context words as separate features, thereby loosing important information for word expectations, such as word interrelations.", "labels": [], "entities": []}, {"text": "In this paper, we present a DSM that addresses this issue by defining verb contexts as joint syntactic dependencies.", "labels": [], "entities": []}, {"text": "We test our representation in a verb similarity task on two datasets, showing that joint contexts achieve performances comparable to single dependencies or even better.", "labels": [], "entities": []}, {"text": "Moreover, they are able to overcome the data sparsity problem of joint feature spaces, in spite of the limited size of our training corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional Semantic Models (DSMs) rely on the Distributional Hypothesis, stating that words occurring in similar contexts have similar meanings.", "labels": [], "entities": []}, {"text": "On such theoretical grounds, word co-occurrences extracted from corpora are used to build semantic representations in the form of vectors, which have become very popular in the NLP community.", "labels": [], "entities": []}, {"text": "Proximity between word vectors is taken as an index of meaning similarity, and vector cosine is generally adopted to measure such proximity, even though other measures have been proposed ().", "labels": [], "entities": []}, {"text": "Most of DSMs adopt a bag-of-words approach, that is they turn a text span (i.e., a word window or a parsed sentence) into a set of words and they register separately the co-occurrence of each word with a given target.", "labels": [], "entities": []}, {"text": "The problem with this approach is that valuable information concerning word interrelations in a context gets lost, because words co-occurring with a target are treated as independent features.", "labels": [], "entities": []}, {"text": "This is why works like Ruiz-, and proposed to introduce richer contexts in distributional spaces, by using entire word windows as features.", "labels": [], "entities": []}, {"text": "These richer contexts proved to be helpful to semantically represent verbs, which are characterized by highly context-sensitive meanings, and complex argument structures.", "labels": [], "entities": []}, {"text": "In fact, two verbs may share independent words as features despite being very dissimilar from the semantic point of view.", "labels": [], "entities": []}, {"text": "For instance kill and heal share the same object nouns in The doctor healed the patient and the The poison killed the patient, but are highly different if we consider their joint dependencies as a single context.", "labels": [], "entities": []}, {"text": "Nonetheless, richer contexts like these suffer from data sparsity, therefore requiring either larger corpora or complex smoothing processes.", "labels": [], "entities": []}, {"text": "In this paper, we propose a syntactically savvy notion of joint contexts.", "labels": [], "entities": []}, {"text": "To test our representation, we implement several DSMs and we evaluate them in a verb similarity task on two datasets.", "labels": [], "entities": []}, {"text": "The results show that, even using a relatively small corpus, our syntactic joint contexts are robust with respect to data sparseness and perform similarly or better than single dependencies in a wider range of parameter settings.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we provide psycholinguistic and computational background for this research, describing recent models based on word windows.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our reinterpretation of joint contexts with syntactic dependencies.", "labels": [], "entities": []}, {"text": "Evaluation settings and results are presented in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The DSMs are evaluated on two test sets: VerbSim () and the verb subset of SimLex-999 ().", "labels": [], "entities": [{"text": "VerbSim", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.7536082863807678}]}, {"text": "The former includes 130 verb pairs, while the latter includes 222 verb pairs.", "labels": [], "entities": []}, {"text": "Both datasets are annotated with similarity judgements, so we measured the Spearman correlation between them and the scores assigned by the model.", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 75, "end_pos": 95, "type": "METRIC", "confidence": 0.8443350493907928}]}, {"text": "The VerbSim dataset allows for comparison with, since they also evaluated their model on this test set, achieving a Spearman correlation score of 0.616 and outperforming all the baseline methods.", "labels": [], "entities": [{"text": "VerbSim dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.933710128068924}, {"text": "Spearman correlation score", "start_pos": 116, "end_pos": 142, "type": "METRIC", "confidence": 0.8650519847869873}]}, {"text": "The verb subset of SimLex-999, at the best of our knowledge, has never been used as a benchmark dataset for verb similarity.", "labels": [], "entities": []}, {"text": "The SimLex dataset is known for being quite challenging: as reported by, the average performances of similarity models on this dataset are much lower than on alternative benchmarks like WordSim () and MEN ().", "labels": [], "entities": [{"text": "SimLex dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.7255330979824066}]}, {"text": "We exclude from the evaluation datasets all the target words occurring less than 100 times in our corpus.", "labels": [], "entities": []}, {"text": "Consequently, we cover 107 pairs in the VerbSim dataset (82.3, the same of) and 214 pairs in the SimLex verbs dataset (96.3).", "labels": [], "entities": [{"text": "VerbSim dataset", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9682555794715881}, {"text": "SimLex verbs dataset", "start_pos": 97, "end_pos": 117, "type": "DATASET", "confidence": 0.6745287477970123}]}, {"text": "reports the Spearman correlation scores for the vector cosine on our DSMs.", "labels": [], "entities": [{"text": "Spearman correlation scores", "start_pos": 12, "end_pos": 39, "type": "METRIC", "confidence": 0.6108455955982208}]}, {"text": "At a glance, we can notice the discrepancy between the results obtained in the two datasets, as SimLex verbs confirms to be very difficult to model.", "labels": [], "entities": []}, {"text": "We can also recognize a trend related to the number of contexts, as the performance tends to improve when more contexts are taken into account (with some exceptions).", "labels": [], "entities": []}, {"text": "Single dependencies and joint contexts perform very similarly, and no one has a clear edge on the other.", "labels": [], "entities": []}, {"text": "Both of them outperform the bag-of-words model on the VerbSim dataset by a nice margin, whereas the scores of all the model types are pretty much the same on SimLex verbs.", "labels": [], "entities": [{"text": "VerbSim dataset", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9712000489234924}]}, {"text": "Finally, it is noteworthy that the score obtained on VerbSim by the joint context model with 100K dimensions goes very close to the result reported by. and report the results of the models with SVD reduction.", "labels": [], "entities": [{"text": "VerbSim", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.8888868093490601}]}, {"text": "Independently of the number of dimensions k, the joint contexts almost always outperform the other model types.", "labels": [], "entities": []}, {"text": "Overall, the performance of the joint contexts seems to be more stable across several parameter configurations, whereas bag-of-words and single dependencies are subject to bigger drops.", "labels": [], "entities": []}, {"text": "Exceptions can be noticed only for the VerbSim dataset, and only with a low number of dimensions.", "labels": [], "entities": [{"text": "VerbSim dataset", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9635794460773468}]}, {"text": "Finally, the correlation coefficients for the two datasets seem to follow different trends, as the models with a higher number of contexts perform better on SimLex verbs, while the opposite is true for the VerbSim dataset.", "labels": [], "entities": [{"text": "VerbSim dataset", "start_pos": 206, "end_pos": 221, "type": "DATASET", "confidence": 0.9698480367660522}]}], "tableCaptions": [{"text": " Table 1: Spearman correlation scores for VerbSim and for the", "labels": [], "entities": [{"text": "correlation", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.5089532136917114}, {"text": "VerbSim", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.8640109300613403}]}, {"text": " Table 2: Spearman correlation scores for VerbSim, after the", "labels": [], "entities": [{"text": "correlation", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.49968329071998596}, {"text": "VerbSim", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.8178188800811768}]}, {"text": " Table 3: Spearman correlation scores for the verb subset of", "labels": [], "entities": [{"text": "Spearman correlation scores", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.7271609902381897}]}]}