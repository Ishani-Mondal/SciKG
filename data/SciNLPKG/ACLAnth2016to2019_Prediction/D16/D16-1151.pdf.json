{"title": [], "abstractContent": [{"text": "For AI systems to reason about real world situations , they need to recognize which processes are at play and which entities play key roles in them.", "labels": [], "entities": []}, {"text": "Our goal is to extract this kind of role-based knowledge about processes, from multiple sentence-level descriptions.", "labels": [], "entities": []}, {"text": "This knowledge is hard to acquire; while semantic role labeling (SRL) systems can extract sentence level role information about individual mentions of a process, their results are often noisy and they do not attempt create a globally consistent characterization of a process.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.7992864449818929}]}, {"text": "To overcome this, we extend standard within sentence joint inference to inference across multiple sentences.", "labels": [], "entities": []}, {"text": "This cross sentence inference promotes role assignments that are compatible across different descriptions of the same process.", "labels": [], "entities": []}, {"text": "When formulated as an Integer Linear Program, this leads to improvements over within-sentence inference by nearly 3% in F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 120, "end_pos": 122, "type": "METRIC", "confidence": 0.997220516204834}]}, {"text": "The resulting role-based knowledge is of high quality (with a F1 of nearly 82).", "labels": [], "entities": [{"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9983813762664795}]}], "introductionContent": [{"text": "Knowledge about processes is essential for AI systems in order to understand and reason about the world.", "labels": [], "entities": []}, {"text": "At the simplest level, even knowing which class of entities play key roles can be useful for tasks involving recognition and reasoning about processes.", "labels": [], "entities": []}, {"text": "For instance, given a description \"a puddle drying in the sun\", one can recognize this as an instance of the process evaporation using a macrolevel role knowledge: Among others, the typical undergoer of evaporation is a kind of liquid (the pud-1) Evaporation is the process by which liquids are converted to their gaseous forms.", "labels": [], "entities": []}, {"text": "2) Evaporation is the process by which water is converted into water vapor.", "labels": [], "entities": [{"text": "Evaporation", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.9841659069061279}]}, {"text": "3) Water vapor rises from water due to evaporation.", "labels": [], "entities": []}, {"text": "4) Clouds arise as water evaporates in the sun.", "labels": [], "entities": []}, {"text": "dle), and the enabler is usually a heat source (the sun).", "labels": [], "entities": []}, {"text": "Our goal is to acquire this kind of role-based knowledge about processes from sentence-level descriptions in grade level texts.", "labels": [], "entities": []}, {"text": "Semantic role labeling (SRL) systems can be trained to identify these process specific roles.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7812733203172684}]}, {"text": "However, these were developed for sentence-level interpretation and only ensure within sentence consistency of labels, limiting their ability to generate coherent characterizations of the process overall.", "labels": [], "entities": [{"text": "sentence-level interpretation", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.7140106856822968}]}, {"text": "In particular, the same process participant may appear in text at different syntactic positions, with different wording, and with different verbs, which makes it hard to extract globally consistent descriptions.", "labels": [], "entities": []}, {"text": "In this work, we propose across sentence inference method to address this problem.", "labels": [], "entities": []}, {"text": "To illustrate the challenge consider some example sentences on evaporation shown in.The underlined spans correspond to fillers for an undergoer role i.e., the main entity that is undergoing evaporation.", "labels": [], "entities": []}, {"text": "However, the filler water occurs as different syntactic arguments with different main actions.", "labels": [], "entities": []}, {"text": "Without large amounts of process-specific training data, a supervised classifier will notable to learn these variations reliably.", "labels": [], "entities": []}, {"text": "Nevertheless, since all these sentences are describing evaporation, it is highly likely that water plays a single role.", "labels": [], "entities": []}, {"text": "This expectation can be encoded as a factor during inference to promote consistency and improve accuracy, and is the basis of our approach.", "labels": [], "entities": [{"text": "consistency", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.9820181131362915}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9989369511604309}]}, {"text": "We formalize this cross sentence joint inference idea as an Integer Linear Program (ILP).", "labels": [], "entities": []}, {"text": "Our central idea is to collect all sentences fora single process, generate candidate arguments, and assign roles that are globally consistent for all arguments within the process.", "labels": [], "entities": []}, {"text": "This requires a notion of consistency, which we model as pairwise alignment of arguments that should receive the same label.", "labels": [], "entities": [{"text": "consistency", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.9706289172172546}]}, {"text": "Argument-level entailment alone turns out to be ineffective for this purpose.", "labels": [], "entities": []}, {"text": "Therefore, we develop an alignment classifier that uses the compatibility of contexts in which the candidate arguments are embedded.", "labels": [], "entities": []}, {"text": "We transform the original role-label training data to create alignment pairs from arguments that get assigned the same label, thus avoiding the need for additional labeling.", "labels": [], "entities": []}, {"text": "Finally, the ILP combines the output of the SRL classifier and the alignment classifier in an objective function in order to find globally consistent assignments.", "labels": [], "entities": []}, {"text": "An empirical evaluation on a process dataset shows that proposed cross sentence formulation outperforms a strong within sentence joint inference baseline, which uses scores from a custom built role classifier that is better suited for the target domain.", "labels": [], "entities": [{"text": "cross sentence formulation", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.6240066389242808}]}, {"text": "In summary, this work makes the following contributions: 1.", "labels": [], "entities": []}, {"text": "A cross-sentence, collective role-labeling and alignment method for harvesting process knowledge.", "labels": [], "entities": []}, {"text": "2. A high quality semantic resource that provides knowledge about scientific processes discussed in grade-level texts including physical, biological, and natural processes.", "labels": [], "entities": []}, {"text": "3. An evaluation which shows that the proposed cross sentence inference yields high quality process knowledge.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our goal is to generate knowledge about processes discussed in grade-level science exams.", "labels": [], "entities": []}, {"text": "Since existing semantic resources such as FrameNet do not provide adequate coverage for these, we created a dataset of process sentences annotated with the four process roles: undergoer, enabler, action, and result.", "labels": [], "entities": []}, {"text": "This dataset consists of 1205 role fillers extracted from 537 sentences retrieved from the web.", "labels": [], "entities": []}, {"text": "We first compiled the target processes from a list of process-oriented questions found in two collections: (i) New York Regents science exams, and (ii) helpteaching.com, a Web-based collection Query Patterns name is the process of x name is the process by which x name {occurs when} x name { helps to | causes } x of practice questions.", "labels": [], "entities": [{"text": "New York Regents science exams", "start_pos": 111, "end_pos": 141, "type": "DATASET", "confidence": 0.7091054677963257}]}, {"text": "Then, we identified 127 process questions from which we obtained a set of 180 unique target processes.", "labels": [], "entities": []}, {"text": "For each target process, we queried the web using Google to find definitionstyle sentences, which describe the target process.", "labels": [], "entities": []}, {"text": "For each process we discarded some noisy sentences through a combination of automatic and manual filtering.", "labels": [], "entities": []}, {"text": "shows some examples of the 14 query patterns that we used to find process descriptions.", "labels": [], "entities": []}, {"text": "Because these patterns are not process-specific, they work for unseen processes as well.", "labels": [], "entities": []}, {"text": "To find role fillers from these sentences, we first processed each sentence using EasySRL () to generate candidate arguments.", "labels": [], "entities": [{"text": "EasySRL", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.7175530791282654}]}, {"text": "Some of the query patterns can be used to generate additional arguments.", "labels": [], "entities": []}, {"text": "For example, in the pattern \"name is the process of x\" if x is a noun then it is likely to bean undergoer, and thus can be a good candidate.", "labels": [], "entities": []}, {"text": "Then two annotators annotated the candidate arguments with the target roles if one were applicable and marked them as NONE otherwise.", "labels": [], "entities": [{"text": "NONE", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9209407567977905}]}, {"text": "Disagreements were resolved by a third annotator.", "labels": [], "entities": []}, {"text": "The annotations spanned a random subset of 54 target processes.", "labels": [], "entities": []}, {"text": "The role label distribution is shown below:  We conducted five fold cross validation experiments to test role extraction.", "labels": [], "entities": [{"text": "role extraction", "start_pos": 105, "end_pos": 120, "type": "TASK", "confidence": 0.7678621411323547}]}, {"text": "To ensure that we are testing the generalization of the approach to unseen processes, we generated the folds such that the processes in the test fold were unseen during training.", "labels": [], "entities": []}, {"text": "We compared the basic role classifier described in Section 3.3, the within sentence and the cross sentence inference models.", "labels": [], "entities": []}, {"text": "We tune the ILP parameter \u03bb for cross sentence inference based on a coarsegrained sweep on the training folds.", "labels": [], "entities": [{"text": "cross sentence inference", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.697383979956309}]}, {"text": "We also compared with a simple baseline that learned a mapping from PropBank roles produced by EasySRL system to the process roles by using the roles and the verb as features.", "labels": [], "entities": []}, {"text": "We also add the FrameNet frames invoked by the lexical unit in the sentence.", "labels": [], "entities": []}, {"text": "Note this is essentially a subset of the features we use in our role classifier.", "labels": [], "entities": []}, {"text": "As a second baseline, we compare with a (nearly) out-of-thebox application of SEMAFOR (), a FrameNet based frame-semantic parser.", "labels": [], "entities": []}, {"text": "We modified SEMAFOR to override the frame identification step since the process frame information is already associated with the test sentences.", "labels": [], "entities": [{"text": "frame identification", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7468268871307373}]}, {"text": "compares performance of the different methods.", "labels": [], "entities": []}, {"text": "The learned role mapping of shallow semantic roles performs better than SEMAFOR but worse than the simple role classifier.", "labels": [], "entities": []}, {"text": "SEMAFOR uses a large set of features which help it scale fora diverse set of frames in FrameNet.", "labels": [], "entities": [{"text": "SEMAFOR", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7470632195472717}]}, {"text": "However, many of these many not be well suited for the process sentences in our relatively smaller dataset.", "labels": [], "entities": []}, {"text": "Therefore, we use our custom role classifier as a strong baseline to demonstrate within and cross sentence gains.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Process role inference performance.  \u2020 \u2020 indicates", "labels": [], "entities": []}, {"text": " Table 7: Performance (F1) across all roles.", "labels": [], "entities": [{"text": "Performance", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9760373830795288}, {"text": "F1)", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9687233865261078}]}, {"text": " Table 8: Performance impact of inference components.  \u2020 \u2020", "labels": [], "entities": []}, {"text": " Table 9: Performance of different feature groups for alignment.", "labels": [], "entities": [{"text": "alignment", "start_pos": 54, "end_pos": 63, "type": "TASK", "confidence": 0.9845412969589233}]}]}