{"title": [{"text": "Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads", "labels": [], "entities": [{"text": "Predicting Popular Reddit Threads", "start_pos": 66, "end_pos": 99, "type": "TASK", "confidence": 0.8608872890472412}]}], "abstractContent": [{"text": "We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial, natural language action space.", "labels": [], "entities": [{"text": "popularity prediction and tracking task", "start_pos": 23, "end_pos": 62, "type": "TASK", "confidence": 0.8197887539863586}]}, {"text": "A specified number of discussion threads predicted to be popular are recommended, chosen from a fixed window of recent comments to track.", "labels": [], "entities": []}, {"text": "Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub-actions.", "labels": [], "entities": []}, {"text": "The proposed model, which represents dependence between sub-actions through a bi-directional LSTM, gives the best performance across different experimental configurations and domains, and it also generalizes well with varying numbers of recommendation requests.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper is concerned with learning policies for sequential decision-making tasks, where a system takes actions given options characterized by natural language with the goal of maximizing a longterm reward.", "labels": [], "entities": []}, {"text": "More specifically, we consider tasks with a combinatorial action space, where each action is a set of multiple interdependent sub-actions.", "labels": [], "entities": []}, {"text": "The problem of a combinatorial natural language action space arises in many applications.", "labels": [], "entities": []}, {"text": "For example, in real-time news feed recommendation, a user may want to read diverse topics of interest, and an action (i.e. recommendation) from the computer agent would consist of a set of news articles that are not all similar in topics ().", "labels": [], "entities": []}, {"text": "In advertisement placement, an action is a selection of several ads to display, and bundling with complementary products might receive higher click-throughrate than displaying all similar popular products.", "labels": [], "entities": [{"text": "advertisement placement", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.7490433752536774}]}, {"text": "In this work, we consider Reddit popularity prediction, which is similar to newsfeed recommendation but different in two respects.", "labels": [], "entities": [{"text": "Reddit popularity prediction", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.6370839476585388}]}, {"text": "First, our goal is not to make recommendations based on an individual's preferences, but instead based on the anticipated long-term interest level of abroad group of readers from a target community.", "labels": [], "entities": []}, {"text": "Second, we try to predict rather than detect popularity.", "labels": [], "entities": []}, {"text": "Unlike individual interests, community interest level is not often immediately clear; there is a time lag before the level of interest starts to takeoff.", "labels": [], "entities": []}, {"text": "Here, the goal is for the recommendation system to identify and track written documents (e.g. news articles, comments in discussion forum threads, or scientific articles) in real time -attempting to identify hot updates before they become hot to keep the reader at the leading edge.", "labels": [], "entities": [{"text": "track written documents (e.g. news articles, comments in discussion forum threads, or scientific articles)", "start_pos": 64, "end_pos": 170, "type": "TASK", "confidence": 0.6693117022514343}]}, {"text": "The premise is that the user's bandwidth is limited, and only a limited number of things can be recommended out of several possibilities.", "labels": [], "entities": []}, {"text": "In our experimental work, we use discussion forum text, where the recommendations correspond to recent posts or comments, assessing interest based on community response as observed in \"likes\" or other positive reactions to those comments.", "labels": [], "entities": []}, {"text": "For training purposes, we can use community response measured at a time much later than the original post or publication.", "labels": [], "entities": []}, {"text": "This problem is well-suited to the reinforcement learning paradigm, since the reward (the level of community uptake or positive response) is not immediately known, so the system needs to learn a mechanism for estimating future reactions.", "labels": [], "entities": []}, {"text": "Different from typical reinforcement learning, the action space is combinatorial since an action corresponds to a set of comments (sub-actions) chosen from a larger set of candidates.", "labels": [], "entities": []}, {"text": "A sub-action is a written comment (or document, for another variant of this task).", "labels": [], "entities": []}, {"text": "Two challenges associated with this problem include the potentially high computational complexity of the combinatorial action space and the development of a framework for estimating the long-term reward (the Q-value in reinforcement learning) from a combination of sub-actions characterized by natural language.", "labels": [], "entities": []}, {"text": "Here, we focus on the second problem, exploring different deep neural network architectures in an effort to efficiently account for the potential redundancy and/or temporal dependency of different sub-actions in relation to the state space.", "labels": [], "entities": []}, {"text": "We sidestep the computational complexity issue (for now) by working with a task where the number of combinations is not too large and by further reducing costs by random sampling.", "labels": [], "entities": []}, {"text": "There are two main contributions in this paper.", "labels": [], "entities": []}, {"text": "First, we propose a novel reinforcement learning task with both states and combinatorial actions defined by natural language, 1 which is introduced in section 2.", "labels": [], "entities": []}, {"text": "This task, which is based on comment popularity prediction using data from the Reddit discussion forum, can serve as a benchmark in social media recommendation and trend spotting.", "labels": [], "entities": [{"text": "comment popularity prediction", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6099260350068411}, {"text": "trend spotting", "start_pos": 164, "end_pos": 178, "type": "TASK", "confidence": 0.7185290157794952}]}, {"text": "The second contribution is the development of a novel deep reinforcement learning architecture for handling a combinatorial action space associated with natural language.", "labels": [], "entities": []}, {"text": "Prior work related to both the task and deep reinforcement learning is reviewed in section 3, Details for the new models and baseline architectures are described in section 4.", "labels": [], "entities": []}, {"text": "Experimental results in section 5 show the proposed methods outperform baseline models and that a bidirectional LSTM is effective for characterizing the combined utility of sub-actions.", "labels": [], "entities": []}, {"text": "A brief summary of findings and open questions are in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our data consists of 5 subreddits (askscience, askmen, todayilearned, worldnews, nfl) with diverse  In our experiments, in order to have long enough discussion threads, we filter out discussion trees with fewer than 100 comments.", "labels": [], "entities": []}, {"text": "For each subreddit, we randomly partition 90% of the data for online training, and 10% of the data for testing (deployment).", "labels": [], "entities": []}, {"text": "The basic subreddit statistics are shown in.", "labels": [], "entities": []}, {"text": "We report the random policy performances and heuristic upper bound performances (averaged over 10,000 episodes) in and Table 3.", "labels": [], "entities": []}, {"text": "The upper bound performances are obtained using stabilized karma scores and offline constructed tree structure.", "labels": [], "entities": []}, {"text": "The mean and standard deviation are obtained by 5 independent runs.", "labels": [], "entities": [{"text": "mean", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9747195243835449}, {"text": "standard", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9419357776641846}]}, {"text": "In all our experiments we set N = 10.", "labels": [], "entities": []}, {"text": "Explicitly representing all N -choose-K actions requires a lot of memory and does not scale up.", "labels": [], "entities": []}, {"text": "We therefore use a variant of Q-learning: when taking the max over Upper bounds are estimated by greedily searching through each discussion tree to find K max karma discussion threads (overlapped comments are counted only once).", "labels": [], "entities": []}, {"text": "This upper bound may not be attainable in a real-time setting.: Mean and standard deviation of random and upperbound performance on askscience, with N = 10 and K = 2, 3, 4, 5.", "labels": [], "entities": [{"text": "Mean", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9918666481971741}]}, {"text": "In we provide learning curves of different models on the askscience subreddit during online learning.", "labels": [], "entities": []}, {"text": "In this experiment, we set N = 10, K = 3.", "labels": [], "entities": []}, {"text": "Each curve is obtained by averaging over 3 independent runs, and the error bars are also shown.", "labels": [], "entities": []}, {"text": "All models start with random performance, and converge after approximately 15 experience replays.", "labels": [], "entities": []}, {"text": "The DRRN-Sum converges as fast as baseline models, with better converged performance.", "labels": [], "entities": [{"text": "DRRN-Sum", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.6026478409767151}]}, {"text": "DRRNBiLSTM converges slower than other methods, but with the best converged performance.", "labels": [], "entities": [{"text": "DRRNBiLSTM", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8532595634460449}]}, {"text": "After we train all the models on the training set, we fix the model parameters and apply (deploy) on the test set, where the models predict which action to take but no reward is shown until evaluation.", "labels": [], "entities": []}, {"text": "The test performance is averaged over 1000 episodes, and we report mean and standard deviation over 5 independent runs.", "labels": [], "entities": [{"text": "mean", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.984860897064209}]}, {"text": "On askscience, we try multiple settings with N = 10, K = 2, 3, 4, 5 and the results are shown in Table 4.", "labels": [], "entities": []}, {"text": "Both DRRN-Sum and DRRN-BiLSTM consistently outperform baseline methods.", "labels": [], "entities": [{"text": "DRRN-Sum", "start_pos": 5, "end_pos": 13, "type": "DATASET", "confidence": 0.8545097708702087}, {"text": "DRRN-BiLSTM", "start_pos": 18, "end_pos": 29, "type": "DATASET", "confidence": 0.8610844612121582}]}, {"text": "The DRRNBiLSTM performs better with larger K, probably due to the greater chance of redundancy in combining more sub-actions.", "labels": [], "entities": [{"text": "DRRNBiLSTM", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8797497153282166}]}, {"text": "We also perform online training and test across different subreddits.", "labels": [], "entities": []}, {"text": "With N = 10, K = 3, the test performance gains over the linear baseline are shown in.", "labels": [], "entities": []}, {"text": "Again, the test performance is     In actual model deployment, a possible scenario is that users may have different requests.", "labels": [], "entities": []}, {"text": "For example, a user may ask the agent to provide K = 2 discussion threads on one day, due to limited reading time, and ask the agent to provide K = 5 discussion threads on the other day.", "labels": [], "entities": []}, {"text": "For the baseline models (Linear, PA-DQN, DRRN), we will need to train separate models for different K's.", "labels": [], "entities": []}, {"text": "The proposed methods (DRRN-Sum and DRRN-BiLSTM), on the other hand, can easily handle a varying K.", "labels": [], "entities": [{"text": "DRRN-Sum", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.8945417404174805}, {"text": "DRRN-BiLSTM", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9193967580795288}]}, {"text": "To test whether the performance indeed generalizes well, we train proposed models on askscience with N = 10, K = 3 and test them with N = 10, K \u2208 2, 4, 5, as shown in.", "labels": [], "entities": []}, {"text": "Compared to the proposed models that are specifically trained for these K's, the generalized test performance indeed degrades, as expected.", "labels": [], "entities": []}, {"text": "However, in many cases, our proposed methods still outperform all three baselines (Linear, PA-DQN and DRRN) that are trained specifically for these K's.", "labels": [], "entities": []}, {"text": "This shows that the proposed methods can generalize to varying K's even if it is trained on a particular value of K.", "labels": [], "entities": []}, {"text": "In, we show an anecdotal example with state and sub-actions.", "labels": [], "entities": []}, {"text": "The two sub-actions are strongly correlated and have redundant information.", "labels": [], "entities": []}, {"text": "By combining the second sub-action compared to choosing just the first sub-action alone, DRRN-Sum and DRRN-BiLSTM predict 86% and 26% relative increase in action-value, respectively.", "labels": [], "entities": [{"text": "DRRN-Sum", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.890610933303833}, {"text": "DRRN-BiLSTM", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.8106705546379089}]}, {"text": "Since these two sub-actions are highly redundant, we hypothesize DRRN-BiLSTM is better than DRRN-Sum at capturing interdependency between sub-actions.", "labels": [], "entities": [{"text": "DRRN-BiLSTM", "start_pos": 65, "end_pos": 76, "type": "DATASET", "confidence": 0.8547666668891907}, {"text": "DRRN-Sum", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.8828043937683105}]}], "tableCaptions": [{"text": " Table 1: Basic statistics of filtered subreddit data sets", "labels": [], "entities": []}, {"text": " Table 2: Mean and standard deviation of random and upper-", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989790916442871}, {"text": "standard", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.8314275145530701}]}, {"text": " Table 3: Mean and standard deviation of random and upper-", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989746809005737}, {"text": "standard", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.7815739512443542}]}, {"text": " Table 4: On askscience, average karma scores and standard deviation of baselines and proposed methods (with N = 10)", "labels": [], "entities": [{"text": "standard", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9593536257743835}]}, {"text": " Table 5: On askscience, average karma scores and standard de-", "labels": [], "entities": []}]}