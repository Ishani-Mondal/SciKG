{"title": [{"text": "Learning to Capitalize with Character-Level Recurrent Neural Networks: An Empirical Study", "labels": [], "entities": [{"text": "Learning to Capitalize with Character-Level Recurrent Neural Networks", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.741994746029377}]}], "abstractContent": [{"text": "In this paper, we investigate case restoration for text without case information.", "labels": [], "entities": [{"text": "case restoration", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.9146714210510254}]}, {"text": "Previous such work operates at the word level.", "labels": [], "entities": []}, {"text": "We propose an approach using character-level recurrent neural networks (RNN), which performs competitively compared to language model-ing and conditional random fields (CRF) approaches.", "labels": [], "entities": []}, {"text": "We further provide quantitative and qualitative analysis on how RNN helps improve truecasing.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language texts (e.g., automatic speech transcripts or social media data) often come in nonstandard forms, and normalization would typically improve the performance of downstream natural language processing (NLP) applications.", "labels": [], "entities": []}, {"text": "This paper investigates a particular sub-task in text normalization: case restoration or truecasing.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8200985193252563}, {"text": "case restoration", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.7734133899211884}]}, {"text": "Truecasing refers to the task of restoring case information (uppercase or lowercase) of characters in a text corpus.", "labels": [], "entities": []}, {"text": "Case information is important for certain NLP tasks.", "labels": [], "entities": []}, {"text": "For example, used unlabeled mixed case text to improve named entity recognition (NER) on uppercase text.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7788292467594147}]}, {"text": "The task often presents ambiguity: consider the word \"apple\" in the sentences \"he bought an apple\" and \"he works at apple\".", "labels": [], "entities": []}, {"text": "While the former refers to a fruit (hence, it should be in lowercase), the latter refers to a company name (hence, it should be capitalized).", "labels": [], "entities": []}, {"text": "Moreover, we often need to recover the case information for words that are previously unseen by the system.", "labels": [], "entities": []}, {"text": "In this paper, we propose the use of characterlevel recurrent neural networks for truecasing.", "labels": [], "entities": []}, {"text": "Previous approaches for truecasing are based on word level approaches which assign to each word one of the following labels: all lowercase, all uppercase, initial capital, and mixed case.", "labels": [], "entities": []}, {"text": "For mixed case words, an additional effort has to be made to decipher exactly how the case is mixed (e.g., MacKenzie).", "labels": [], "entities": [{"text": "MacKenzie", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.95570969581604}]}, {"text": "In our approach, we propose a generative, character-based recurrent neural network (RNN) model, allowing us to predict exactly how cases are mixed in such words.", "labels": [], "entities": []}, {"text": "Our main contributions are: (i) we show that character-level approaches are viable compared to word-level approaches, (ii) we show that characterlevel RNN has a competitive performance compared to character-level CRF, and (iii) we provide our quantitative and qualitative analysis on how RNN helps improve truecasing.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our approach is evaluated on English and German datasets.", "labels": [], "entities": [{"text": "English and German datasets", "start_pos": 29, "end_pos": 56, "type": "DATASET", "confidence": 0.6484470292925835}]}, {"text": "For English, we use a Wikipedia corpus from ( 3.6.0 ().", "labels": [], "entities": []}, {"text": "We use a recommended configuration for training the truecaser.We use CRFSuite version 0.12 to train the character-based CRF model.", "labels": [], "entities": [{"text": "CRFSuite version 0.12", "start_pos": 69, "end_pos": 90, "type": "DATASET", "confidence": 0.857669452826182}]}, {"text": "Our feature set includes character N-grams (N \u2208 {1, 2, 3}) and word N-grams (N \u2208 {1, 2}) surrounding the current character.", "labels": [], "entities": []}, {"text": "We tune the 2 regularization parameter \u03bb using a grid search where \u03bb \u2208 {0.01, 0.1, 1, 10}.", "labels": [], "entities": []}, {"text": "We use an open-source character RNN implementation.", "labels": [], "entities": []}, {"text": "We train a SMALL model with 2 layers and 300 hidden nodes, and a LARGE model with 3 layers and 700 hidden nodes.", "labels": [], "entities": [{"text": "SMALL", "start_pos": 11, "end_pos": 16, "type": "TASK", "confidence": 0.7445715069770813}]}, {"text": "We also vary the hidden unit type (LSTM/GRU).", "labels": [], "entities": []}, {"text": "The network is trained using truncated backpropagation for 50 time steps.", "labels": [], "entities": []}, {"text": "We use a mini-batch stochastic gradient descent with batch size 100 and RMSprop update.", "labels": [], "entities": [{"text": "RMSprop", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.7102159261703491}]}, {"text": "We use dropout regularization () with 0.25 probability.", "labels": [], "entities": []}, {"text": "We choose the model with the smallest validation loss after 30 epochs.", "labels": [], "entities": [{"text": "validation", "start_pos": 38, "end_pos": 48, "type": "TASK", "confidence": 0.9152450561523438}]}, {"text": "For decoding, we set beam size to 10.", "labels": [], "entities": []}, {"text": "The experimental settings are reported in more depth in the supplementary materials.", "labels": [], "entities": []}, {"text": "Our system and code are publicly available at http://statnlp.org/research/ta/.", "labels": [], "entities": []}, {"text": "shows the experiment results in terms of precision, recall, and F 1 . Most previous work did not evaluate their approaches on the same dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.999717652797699}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9997298121452332}, {"text": "F 1", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9941130876541138}]}, {"text": "We compare our work to) using the same WSJ sections for training and evaluation on 2M word training data.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.7829341888427734}]}, {"text": "Chelba and Acero only reported error rate, and all our RNN and CRF approaches outperform their results in terms of error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9801429510116577}]}], "tableCaptions": [{"text": " Table 2: Truecasing performance in terms of precision (P), recall (R), and F 1 . All improvements of the best performing character-based systems  (bold) over the best performing word-based systems (underlined) are statistically significant using sign test (p < 0.01). All improvements of the  best performing RNN systems (italicized) over CRF-CHAR are statistically significant using sign test (p < 0.01).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 45, "end_pos": 58, "type": "METRIC", "confidence": 0.9258220493793488}, {"text": "recall (R)", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9430869221687317}, {"text": "F 1", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9916186928749084}]}, {"text": " Table 1: Statistics of the data.", "labels": [], "entities": []}, {"text": " Table 3: Percentage distribution of the case categories and OOV words", "labels": [], "entities": []}]}