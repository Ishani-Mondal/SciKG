{"title": [], "abstractContent": [{"text": "When considering asocial media corpus, we often have access to structural information about how messages are flowing between people or organizations.", "labels": [], "entities": []}, {"text": "This information is particularly useful when the linguistic evidence is sparse, incomplete, or of dubious quality.", "labels": [], "entities": []}, {"text": "In this paper we construct a simple model to leverage the structure of Twitter data to help determine the set of languages each user is fluent in.", "labels": [], "entities": []}, {"text": "Our results demonstrate that imposing several intuitive constraints leads to improvements in performance and stability.", "labels": [], "entities": []}, {"text": "We release the first annotated data set for exploring this task, and discuss how our approach maybe extended to other applications.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language identification (LID) is an important first step in many NLP pipelines since most downstream tasks need to employ language-specific resources.", "labels": [], "entities": [{"text": "Language identification (LID)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8171116709709167}]}, {"text": "In many situations, LID is a trivial task that can be addressed e.g. by a simple Naive Bayes classifier trained on word and character n-gram data: a document of significant length will be quickly disambiguated based on its vocabulary ().", "labels": [], "entities": [{"text": "LID", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.7938815355300903}]}, {"text": "However, social media platforms like Twitter produce data sets in which individual documents are extremely short, and language use is idiosyncratic: LID performance on such data is dramatically lower than on traditional corpora ().", "labels": [], "entities": [{"text": "LID", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.9343773126602173}]}, {"text": "The widespread adoption of social media throughout the world amplifies the problem as less-studied languages lack the annotated resources needed to train the most effective NLP models (e.g. treebanks for statistical parsing, tagged corpora for part-of-speech tagging, etc).", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.7853514850139618}, {"text": "part-of-speech tagging", "start_pos": 244, "end_pos": 266, "type": "TASK", "confidence": 0.7176453322172165}]}, {"text": "All of this motivates the research community's continued interest in LID ().", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}