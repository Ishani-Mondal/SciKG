{"title": [{"text": "An Embedding Model for Predicting Roll-Call Votes", "labels": [], "entities": [{"text": "Predicting Roll-Call Votes", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.8556083838144938}]}], "abstractContent": [{"text": "We develop a novel embedding-based model for predicting legislative roll-call votes from bill text.", "labels": [], "entities": [{"text": "predicting legislative roll-call votes from bill text", "start_pos": 45, "end_pos": 98, "type": "TASK", "confidence": 0.8575245652879987}]}, {"text": "The model introduces multidimen-sional ideal vectors for legislators as an alternative to single dimensional ideal point models for quantitatively analyzing roll-call data.", "labels": [], "entities": []}, {"text": "These vectors are learned to correspond with pre-trained word embeddings which allows us to analyze which features in a bill text are most predictive of political support.", "labels": [], "entities": []}, {"text": "Our model is quite simple, while at the same time allowing us to successfully predict legislator votes on specific bills with higher accuracy than past methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9931508302688599}]}], "introductionContent": [{"text": "Quantitative analysis of political data can contribute to our understanding of governments.", "labels": [], "entities": []}, {"text": "One important source of such data is roll-call votes, records of how legislators vote on bills.", "labels": [], "entities": []}, {"text": "Analysis of roll-call data can reveal interesting information about legislators (such as political leanings and ideological clusters) and can also allow prediction of future votes.", "labels": [], "entities": []}, {"text": "Previous work on analyzing roll-call votes has chiefly involved positioning congresspeople on ideal point models.", "labels": [], "entities": []}, {"text": "Ideal point models assume all legislators and bills can be plotted as single points in onedimensional \"political space.\"", "labels": [], "entities": []}, {"text": "The closer a particular bill's position is to a particular congressperson's, the more utility the congressperson is expected to derive from the bill.", "labels": [], "entities": []}, {"text": "Initial work on ideal point models focused on using them to test theories about legislative behavior, such as predicting that the relative differences between ideal points of congresspeople of different parties, and thus party polarization, would increase overtime.", "labels": [], "entities": []}, {"text": "Ideal point models are often created using Bayesian techniques overlarge amounts of roll-call data).", "labels": [], "entities": []}, {"text": "However, these models are not used to make predictions.", "labels": [], "entities": []}, {"text": "They are trained using the complete vote matrix for the bill, which indicates how each congressperson voted on each bill.", "labels": [], "entities": []}, {"text": "Therefore, they cannot say anything about how congresspeople will vote on anew bill, as until some congresspeople have voted on the bill its ideal point is not known.", "labels": [], "entities": []}, {"text": "We target this vote prediction problem: given the text of a bill and a congressperson, can we independently predict how each congressperson will vote on the bill?", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.7922534942626953}]}, {"text": "The first prior attempt at this task was made by who create an ideal point topic model which integrates a topic model similar to LDA for the bill text with an ideal point model for the congresspeople.", "labels": [], "entities": []}, {"text": "They use variational inference to approximate the posterior distribution of the topics and ideal points, predicting with a linear model.", "labels": [], "entities": []}, {"text": "further extend this work with an issue-adjusted model, a similar model that modifies congressperson ideal points based on topics identified with labeled LDA, but which cannot be used for predictions.", "labels": [], "entities": []}, {"text": "Further work in a similar vein includes, who introduced temporal information to a graphical model for predicting Congressional votes, and, who used sparse factor analysis to estimate Senatorial ideal points from bill text and the votes of party leadership.", "labels": [], "entities": []}, {"text": "In this work we revisit this task with a simple bilinear model that learns multidimensional embeddings for both legislators and bills, combining them to make vote predictions.", "labels": [], "entities": []}, {"text": "We represent a bill as the average of its word embeddings.", "labels": [], "entities": []}, {"text": "We represent legislators as ideal vectors, trained end-to-end for vote prediction.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.8198760747909546}]}, {"text": "These ideal vectors serve as a useful, easy-to-train, multidimensional representation of legislator ideology that does not rely on elaborate statistical models or any further assumptions about legislator behavior.", "labels": [], "entities": []}, {"text": "Finally, we train our model by optimizing a cross-entropy objective instead of the posterior of a topic model.", "labels": [], "entities": []}, {"text": "The final model achieves high accuracy at predicting roll-call votes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9992475509643555}, {"text": "predicting roll-call votes", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.8333578308423361}]}], "datasetContent": [{"text": "Data Following past work, our dataset is derived from the Govtrack database.", "labels": [], "entities": [{"text": "Govtrack database", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.986400693655014}]}, {"text": "1 Specifically, our dataset consists of all votes on the full-text (not amendments) of bills or resolutions from the 106th-111th Congress, six of the most recent Congresses for which bill texts are readily available.", "labels": [], "entities": []}, {"text": "Details of each these congresses are shown in.", "labels": [], "entities": []}, {"text": "To create our dataset, we first find a list of all votes on the full text of bills, and create a matrix of how each congressperson voted on each bill, which will be used in training and in testing.", "labels": [], "entities": []}, {"text": "In accordance with previous work, we only consider yes-or-no votes and omit abstentions and \"present\" votes (Gerrish and Blei, 2011).", "labels": [], "entities": []}, {"text": "We then simply collect the set of words used in each bill.", "labels": [], "entities": []}, {"text": "Overall, our dataset consists of 4067 bills and over a million unique yes-or-no votes.: Main results comparing predictive accuracy of our model EMB with a several baselines (described in the text) on the 106th-111th Congress.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9729032516479492}]}, {"text": "Model We tested prediction accuracy of the average-of-embeddings model, EMB, by running it for ten epochs at a learning rate of \u03b7 = 0.1 and d emb set to 10.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.972769558429718}, {"text": "EMB", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.9472357630729675}]}, {"text": "Hyperparameters were tuned on a heldout section of the 107th Congress.", "labels": [], "entities": []}, {"text": "We ran on each of the 106th to 111th Congresses individually using five-fold cross-validation.", "labels": [], "entities": []}, {"text": "Baselines We compare our results to three different baselines.", "labels": [], "entities": []}, {"text": "The first, YEA, is a majority class baseline which assumes all legislators vote yea.", "labels": [], "entities": [{"text": "YEA", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.7262533903121948}]}, {"text": "The second, IDP, is our model with d emb set to 1 to simulate a simple ideal point model.", "labels": [], "entities": []}, {"text": "The third, GB, is Gerrish and Blei's reported predictive accuracy of 89 % on average from the 106th to 111th Congresses, which is to the extent of our knowledge the best predictive accuracy on roll-call votes yet achieved in the literature.", "labels": [], "entities": [{"text": "GB", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.9989888072013855}, {"text": "predictive", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.7068766951560974}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.5994575619697571}]}, {"text": "Gerrish and Blei report on the same data set using cross-validation and like us train and test on each congress individually, but do not split out results into individual congresses.", "labels": [], "entities": []}, {"text": "Predictive Results The main predictive experimental results are shown in  and obtained an accuracy of 89.5%, in between GB and EMB.", "labels": [], "entities": [{"text": "Predictive", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9753769040107727}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9991550445556641}, {"text": "GB", "start_pos": 120, "end_pos": 122, "type": "METRIC", "confidence": 0.9846195578575134}, {"text": "EMB", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.5973114371299744}]}, {"text": "This indicates that the word embeddings are also responsible for part, but not all, of the accuracy improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.998613715171814}]}, {"text": "We also report minority class F1 scores for EMB in, finding an overall average F1 score of 0.645.", "labels": [], "entities": [{"text": "F1", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.8475570678710938}, {"text": "EMB", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.8245104551315308}, {"text": "F1 score", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9920975863933563}]}, {"text": "Ideal Vectors Beyond predictive accuracy, one of the most interesting features of the model is that it produces ideal vectors as its complete representation of congresspeople.", "labels": [], "entities": [{"text": "Ideal Vectors", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7210060060024261}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8380323052406311}]}, {"text": "These vectors are much easier to compute than standard ideal points, which require relatively complex and computationally intensive statistical models).", "labels": [], "entities": []}, {"text": "Additionally unlike ideal point models, which tend to contain many assumptions about legislative behavior, ideal vectors arise naturally from raw data and bill text).", "labels": [], "entities": []}, {"text": "In, we show the ideal vectors for the 111th Congress.", "labels": [], "entities": []}, {"text": "We use PCA to project the vectors down to two dimensions.", "labels": [], "entities": []}, {"text": "This graph displays several interesting patterns in agreement with theories of legislative behavior.", "labels": [], "entities": []}, {"text": "For example, political scientists theorize that the majority party in a legislature will display more unity in roll-call votes because they decide what gets voted on and only allow a vote on a bill if they can unify behind it and pass it, while that bill may divide the other party.", "labels": [], "entities": []}, {"text": "On this graph, in accordance with that prediction, the majority Democrats are more clustered than the minority Republicans.", "labels": [], "entities": []}, {"text": "We observe similar trends in the ideal vectors of the other Congresses.", "labels": [], "entities": []}, {"text": "Moreover, the model lets us examine the positions of individual congresspeople.", "labels": [], "entities": []}, {"text": "In the figure, the 34 Democrats who: PCA projection of the ideal vectors for 111th Congress, both House and Senate.", "labels": [], "entities": [{"text": "PCA", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.905853271484375}]}, {"text": "Republicans shown in red, Democrats who voted for Affordable Care Act (ACA) in blue, Democrats who voted against ACA in yellow, and independents in green.", "labels": [], "entities": [{"text": "Affordable Care Act (ACA)", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.5060932636260986}]}, {"text": "voted against the Affordable Care Act (ACA, better known as Obamacare) are shown in yellow.", "labels": [], "entities": []}, {"text": "The ACA was a major Democratic priority and point of difference between the two parties.", "labels": [], "entities": []}, {"text": "The Democrats who voted against it tended to be relatively conservative and closer to the Republicans.", "labels": [], "entities": []}, {"text": "The model picks upon this distinction.", "labels": [], "entities": []}, {"text": "Furthermore, since our model maps individual words and congresspeople to the same vector space, we can use it to determine how words (and by proxy issues) unite or divide congresspeople and parties.", "labels": [], "entities": []}, {"text": "In, we show the scaled probabilities that congresspeople will vote fora bill containing only the word \"enterprise\" versus one containing only the word \"science\" in the 110th Congress.", "labels": [], "entities": []}, {"text": "The word \"enterprise,\" denoting pro-business legislation, neatly divides the parties.", "labels": [], "entities": []}, {"text": "Both are for it, but Republicans favor it more.", "labels": [], "entities": []}, {"text": "More interestingly, the word \"science\" creates division within the parties, as neither was at the time more for science funding than the other but both contained congresspeople with varying levels of support for it.", "labels": [], "entities": []}, {"text": "An ideal point model would likely capture the \"enterprise\" dimension, but not the \"science\" one, and would not be able to distinguish between libertarians like Ron Paul (R-TX) who are against both \"corporate welfare\" and government science funding, conservative budget hawks like Jeff Flake (R-AZ) who favor business but are skeptical of government funding of science, and es- tablishment Republicans like Kevin McCarthy (R-CA) who support both.", "labels": [], "entities": []}, {"text": "Indeed, ideal point models are known to perform poorly at describing ideologically idiosyncratic figures like Ron.", "labels": [], "entities": []}, {"text": "Providing the ability to explore multiple dimensions of difference between legislators will be extremely helpful for political scientists analyzing the dynamics of legislatures.", "labels": [], "entities": []}, {"text": "Lexical Properties Finally, as with topic modeling approaches, we can use our model to analyze the relationships between congresspeople or parties and individual words in bills.", "labels": [], "entities": []}, {"text": "For example, Table 4 shows the ten words closest by cosine similarity to each party's average congressperson (stop words omitted) for the 110th Congress.", "labels": [], "entities": []}, {"text": "The Democratic list mostly contains words relating to governing and regulating, such as \"consumer,\" \"state,\" and \"educational,\" likely because the Democrats were at the time the majority party with the responsibility for passing large governmental and regulatory bills like budgets.", "labels": [], "entities": []}, {"text": "The Republican list is largely concerned with the military, with words like \"veterans,\" \"service,\" and \"executive,\" probably because of the importance at the time of the wars in Iraq and Afghanistan, started by a Republican president.: Top ten words by cosine similarity for each party in the 110th Congress with stop words removed.", "labels": [], "entities": [{"text": "Republican list", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8612414598464966}]}], "tableCaptions": [{"text": " Table 1: Dataset details for 106-111th Congress.", "labels": [], "entities": []}, {"text": " Table 2: Main results comparing predictive accu- racy of our model EMB with a several baselines (de- scribed in the text) on the 106th-111th Congress.", "labels": [], "entities": []}, {"text": " Table 2. We see that  EMB performs substantially better than YEA on all  six Congresses. It has a weighted average of 90.6%  on an 84.5% baseline, compared to Gerrish and  Blei's 89% on an identical dataset. IDP, however,  actually does worse than the baseline, demonstrat- ing that the bulk of our gain in prediction accu- racy comes from using ideal vectors instead of ideal  points. To further test this hypothesis, we experi- mented with replacing word embeddings with LDA", "labels": [], "entities": [{"text": "YEA", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.7226282954216003}]}]}