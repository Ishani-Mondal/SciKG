{"title": [{"text": "Gaussian Visual-Linguistic Embedding for Zero-Shot Recognition", "labels": [], "entities": [{"text": "Zero-Shot Recognition", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7273431122303009}]}], "abstractContent": [{"text": "An exciting outcome of research at the intersection of language and vision is that of zero-shot learning (ZSL).", "labels": [], "entities": []}, {"text": "ZSL promises to scale visual recognition by borrowing distributed semantic models learned from linguistic corpora and turning them into visual recognition models.", "labels": [], "entities": [{"text": "visual recognition", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7482353448867798}]}, {"text": "However the popular word-vector DSM embeddings are relatively impoverished in their expressivity as they model each word as a single vector point.", "labels": [], "entities": []}, {"text": "In this paper we explore word-distribution embeddings for ZSL.", "labels": [], "entities": []}, {"text": "We present a visual-linguistic mapping for ZSL in the case where words and visual categories are both represented by distributions.", "labels": [], "entities": []}, {"text": "Experiments show improved results on ZSL benchmarks due to this better exploiting of intra-concept variability in each modality", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning vector representations of word meaning is a topical area in computational linguistics.", "labels": [], "entities": [{"text": "Learning vector representations of word meaning", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8240050574143728}]}, {"text": "Based on the distributional hypothesis -that words in similar context have similar meaningsdistributed semantic models (DSM)s build vector representations based on corpus-extracted context.", "labels": [], "entities": []}, {"text": "DSM approaches such as topic models (, and more recently neural networks have had great success in a variety of lexical and semantic tasks (.", "labels": [], "entities": []}, {"text": "However despite their successes, classic DSMs are severely impoverished compared to humans due to learning solely from word cooccurrence without grounding in the outside world.", "labels": [], "entities": []}, {"text": "This has motivated a wave of recent research into multi-modal and crossmodal learning that aims to ground DSMs in nonlinguistic modalities (.", "labels": [], "entities": []}, {"text": "Such multi-modal DSMs are attractive because they learn richer representations than language-only models (e.g., that bananas are yellow fruit (), and thus often outperform language only models in various lexical tasks.", "labels": [], "entities": []}, {"text": "In this paper, we focus on a key unique and practically valuable capability enabled by cross-modal DSMs: that of zero-shot learning (ZSL).", "labels": [], "entities": []}, {"text": "Zero-shot recognition aims to recognise visual categories in the absence of any training examples by cross-modal transfer from language.", "labels": [], "entities": [{"text": "Zero-shot recognition", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8219879269599915}]}, {"text": "The idea is to use a limited set of training data to learn a linguistic-visual mapping and then apply the induced function to map images from novel visual categories (unseen during training) to a linguistic embedding: thus enabling recognition in the absence of visual training examples.", "labels": [], "entities": []}, {"text": "ZSL has generated big impact) due to the potential of leveraging language to help visual recognition scale to many categories without labor intensive image annotation.", "labels": [], "entities": [{"text": "visual recognition scale", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.7899798353513082}]}, {"text": "DSMs typically generate vector embeddings of words, and hence ZSL is typically realised by variants of vector-valued cross-modal regression.", "labels": [], "entities": []}, {"text": "However, such vector representations have limited expressivity -each word is represented by a point, with no notion of intra-class variability.", "labels": [], "entities": []}, {"text": "In this paper, we consider ZSL in the case where both visual and linguistic concepts are represented by Gaussian distribution embeddings.", "labels": [], "entities": []}, {"text": "Specifically, our Gaussian-embedding approach to ZSL learns concept distributions in both domains: Gaussians representing individual words (as in) and Gaussians representing visual concepts.", "labels": [], "entities": []}, {"text": "Simultaneously, it learns a cross-domain mapping that warps language-domain Gaussian concept representations into alignment with visual-domain concept Gaussians.", "labels": [], "entities": []}, {"text": "Some existing vector DSM-based crossmodal ZSL mappings ( can be seen as special cases of ours where the within-domain model is pre-fixed as vector corresponding to the Gaussian means alone, and only the cross-domain mapping is learned.", "labels": [], "entities": []}, {"text": "Our results show that modeling linguistic and visual concepts as Gaussian distributions rather than vectors can significantly improve zero-shot recognition results.", "labels": [], "entities": [{"text": "zero-shot recognition", "start_pos": 134, "end_pos": 155, "type": "TASK", "confidence": 0.76021608710289}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Zero-shot recognition results on AWA (% accuracy).", "labels": [], "entities": [{"text": "Zero-shot recognition", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6127994805574417}, {"text": "AWA", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9789144992828369}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9978832602500916}]}]}