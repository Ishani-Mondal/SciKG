{"title": [{"text": "Rationale-Augmented Convolutional Neural Networks for Text Classification", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7900443971157074}]}], "abstractContent": [{"text": "We present anew Convolutional Neural Network (CNN) model for text classification that jointly exploits labels on documents and their constituent sentences.", "labels": [], "entities": [{"text": "text classification", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7236897498369217}]}, {"text": "Specifically, we consider scenarios in which annotators explicitly mark sentences (or snippets) that support their overall document categorization, i.e., they provide rationales.", "labels": [], "entities": []}, {"text": "Our model exploits such supervision via a hierarchical approach in which each document is represented by a linear combination of the vector representations of its component sentences.", "labels": [], "entities": []}, {"text": "We propose a sentence-level convolutional model that estimates the probability that a given sentence is a rationale, and we then scale the contribution of each sentence to the aggregate document representation in proportion to these estimates.", "labels": [], "entities": []}, {"text": "Experiments on five classification datasets that have document labels and associated rationales demonstrate that our approach consistently outperforms strong base-lines.", "labels": [], "entities": []}, {"text": "Moreover, our model naturally provides explanations for its predictions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural models that exploit word embeddings have recently achieved impressive results on text classification tasks.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.8431204358736674}]}, {"text": "Feed-forward Convolutional Neural Networks (CNNs), in particular, have emerged as a relatively simple yet powerful class of models for text classification.", "labels": [], "entities": [{"text": "Feed-forward Convolutional Neural Networks (CNNs)", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.6406075997012002}, {"text": "text classification", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.8123914897441864}]}, {"text": "These neural text classification models have tended to assume a standard supervised learning setting in which instance labels are provided.", "labels": [], "entities": [{"text": "neural text classification", "start_pos": 6, "end_pos": 32, "type": "TASK", "confidence": 0.7452233036359152}]}, {"text": "Here we consider an alternative scenario in which we assume that we are provided a set of rationales () in addition to instance labels, i.e., sentences or snippets that support the corresponding document categorizations.", "labels": [], "entities": []}, {"text": "Providing such rationales during manual classification is a natural interaction for annotators, and requires little additional effort.", "labels": [], "entities": [{"text": "manual classification", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.583140105009079}]}, {"text": "Therefore, when training new classification systems, it is natural to acquire supervision at both the document and sentence level, with the aim of inducing a better predictive model, potentially with less effort.", "labels": [], "entities": []}, {"text": "Learning algorithms must be designed to capitalize on these two types of supervision.", "labels": [], "entities": []}, {"text": "Past work (Section 2) has introduced such methods, but these have relied on linear models such as Support Vector Machines (SVMs), operating over sparse representations of text.", "labels": [], "entities": []}, {"text": "We propose a novel CNN model for text classification that exploits both document labels and associated rationales.", "labels": [], "entities": [{"text": "text classification", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8000254034996033}]}, {"text": "Specific contributions of this work as follows.", "labels": [], "entities": []}, {"text": "This is the first work to incorporate rationales into neural models for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.8317607939243317}]}, {"text": "(2) Empirically, we show that the proposed model uniformly outperforms relevant baseline approaches across five datasets, including previously proposed models that capitalize on rationales ( and multiple baseline CNN variants, including a CNN equipped with an attention mechanism.", "labels": [], "entities": []}, {"text": "We also report state-of-the-art results on the important task of automatically assessing the risks of bias in the studies described in full-text biomedical articles (.", "labels": [], "entities": []}, {"text": "(3) Our model naturally provides explanations for its predic-tions, providing interpretability.", "labels": [], "entities": []}, {"text": "We have made available online both a Theano 1 and a Keras implementation 2 of our model.", "labels": [], "entities": []}, {"text": "proposed the basic CNN model we describe below and then build upon in this work.", "labels": [], "entities": []}, {"text": "Properties of this model were explored empirically in ().", "labels": [], "entities": []}, {"text": "We also note that extended this model to jointly accommodate multiple sets of pre-trained word embeddings.", "labels": [], "entities": []}, {"text": "Roughly concurrently to proposed a similar CNN architecture, although they swapped in one-hot vectors in place of (pre-trained) word embeddings.", "labels": [], "entities": []}, {"text": "They later developed a semi-supervised variant of this approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used five text classification datasets to evaluate our approach in total.", "labels": [], "entities": [{"text": "text classification", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7030924409627914}]}, {"text": "Four of these are biomedical text classification datasets (5.1) and the last is a collection of movie reviews (5.2).", "labels": [], "entities": [{"text": "biomedical text classification", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.6548129121462504}]}, {"text": "These datasets share the property of having recorded rationales associated with each document categorization.", "labels": [], "entities": []}, {"text": "We summarize attributes of all datasets used in this work in.", "labels": [], "entities": []}, {"text": "We used a collection Risk of Bias (RoB) text classification datasets, described at length elsewhere).", "labels": [], "entities": [{"text": "Risk of Bias (RoB) text classification datasets", "start_pos": 21, "end_pos": 68, "type": "DATASET", "confidence": 0.7501362495952182}]}, {"text": "Briefly, the task concerns assessing the reliability of the evidence presented in full-text biomedical journal articles that describe the conduct and results of randomized controlled trials (RCTs).", "labels": [], "entities": []}, {"text": "This involves, e.g., assessing whether or not patients were properly blinded as to whether they were receiving an active treatment or a comparator (such as a placebo).", "labels": [], "entities": []}, {"text": "If such blinding is not done correctly, it compromises the study by introducing statistical bias into the treatment efficacy estimate(s) derived from the trial.", "labels": [], "entities": []}, {"text": "A formal system for making bias assessments is codified by the Cochrane Risk of Bias Tool).", "labels": [], "entities": [{"text": "Cochrane Risk of Bias Tool", "start_pos": 63, "end_pos": 89, "type": "DATASET", "confidence": 0.7108920335769653}]}, {"text": "This tool defines multiple domains; the risk of bias maybe assessed in each of these.", "labels": [], "entities": []}, {"text": "We consider four domains here.", "labels": [], "entities": []}, {"text": "(1) Random sequence generation (RSG): were patients were assigned to treatments in a truly random fashion?", "labels": [], "entities": [{"text": "Random sequence generation (RSG)", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7694545388221741}]}, {"text": "(2) Allocation concealment (AC): were group assignments revealed to the person assigning patients to groups (so that she may have knowingly or unknowingly) influenced these assignments?", "labels": [], "entities": [{"text": "Allocation concealment (AC)", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.8263442516326904}]}, {"text": "(3) Blinding of Participants and Personnel (BPP): were all trial participants and individuals involved in running the trial blinded as to who was receiving which treatment?", "labels": [], "entities": [{"text": "Blinding of Participants and Personnel (BPP)", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.7160403691232204}]}, {"text": "(4) Blinding of outcome assessment (BOA): were the parties who measured the outcome(s) of interest blinded to the intervention group assignments?", "labels": [], "entities": [{"text": "Blinding of outcome assessment (BOA)", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.6721211501530239}]}, {"text": "These assessments are somewhat subjective.", "labels": [], "entities": []}, {"text": "To increase transparency, researchers performing RoB assessment therefore record rationales (sentences from articles) supporting their assessments.", "labels": [], "entities": []}, {"text": "We also ran experiments on a movie review (MR) dataset with accompanying rationales.", "labels": [], "entities": [{"text": "movie review (MR) dataset", "start_pos": 29, "end_pos": 54, "type": "DATASET", "confidence": 0.5333899209896723}]}, {"text": "developed and published the original version of this dataset, which comprises 1000 positive and 1000 negative movie reviews from the Internet Movie Database (IMDB).", "labels": [], "entities": [{"text": "Internet Movie Database (IMDB)", "start_pos": 133, "end_pos": 163, "type": "DATASET", "confidence": 0.8679711620012919}]}, {"text": "augmented this dataset by adding rationales corresponding to the binary classifications for 1800 documents, leaving the remaining 200 for testing.", "labels": [], "entities": []}, {"text": "Because 200 documents is a modest test sample size, we ran 9-fold cross validation on the 1800 annotated documents (each fold comprising 200 documents).", "labels": [], "entities": []}, {"text": "The rationales, as originally marked in this dataset, were sub-sentential snippets; for the purposes of our model, we considered the entire sentences containing the marked snippets as rationales.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset characteristics. N is the number of  instances, #sen is the average sentence count, #token  is the average token per-sentence count and #rat is  the average number of rationales per document.", "labels": [], "entities": []}, {"text": " Table 2: Accuracies on the four RoB datasets. Uni-SVM: unigram SVM, Bi-SVM: Bigram SVM, RA-SVM:  Rationale-augmented SVM (", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9754189848899841}, {"text": "RoB datasets", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.7409119307994843}]}, {"text": " Table 3: Accuracies on the movie review dataset.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9965632557868958}, {"text": "movie review dataset", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.7336847980817159}]}]}