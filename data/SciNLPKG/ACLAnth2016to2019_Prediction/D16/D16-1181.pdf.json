{"title": [], "abstractContent": [{"text": "We describe a neural shift-reduce parsing model for CCG, factored into four unidirec-tional LSTMs and one bidirectional LSTM.", "labels": [], "entities": [{"text": "neural shift-reduce parsing", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.6370052297910055}]}, {"text": "This factorization allows the linearization of the complete parsing history, and results in a highly accurate greedy parser that outper-forms all previous beam-search shift-reduce parsers for CCG.", "labels": [], "entities": []}, {"text": "By further deriving a globally optimized model using a task-based loss, we improve over the state of the art by up to 2.67% labeled F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 132, "end_pos": 134, "type": "METRIC", "confidence": 0.9943063855171204}]}], "introductionContent": [{"text": "Combinatory Categorial Grammar) parsing is challenging due to its so-called \"spurious\" ambiguity that permits a large number of non-standard derivations).", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar) parsing", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6430792033672332}]}, {"text": "To address this, the de facto models resort to chart-based CKY, despite CCG being naturally compatible with shiftreduce parsing.", "labels": [], "entities": []}, {"text": "More recently, introduced the first shift-reduce model for CCG, which also showed substantial improvements over the long-established state of the art.", "labels": [], "entities": []}, {"text": "The success of the shift-reduce model () can be tied to two main contributing factors.", "labels": [], "entities": []}, {"text": "First, without any feature locality restrictions, it is able to use a much richer feature set; while intensive feature engineering is inevitable, it has nevertheless delivered an effective and conceptually simpler alternative for both parameter estimation and inference.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 235, "end_pos": 255, "type": "TASK", "confidence": 0.7009762525558472}]}, {"text": "Second, it couples beam search with global optimization, which makes it less prone to search errors than fully greedy models (.", "labels": [], "entities": [{"text": "beam search", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.8639436960220337}]}, {"text": "In this paper, we present a neural architecture for shift-reduce CCG parsing based on long short-term memories (LSTMs;.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.6593210697174072}]}, {"text": "Our model is inspired by, in which we explicitly linearize the complete history of parser states in an incremental fashion by requiring no feature engineering (), and no atomic feature sets).", "labels": [], "entities": []}, {"text": "However, a key difference is that we achieve this linearization without relying on any additional control operations or compositional tree structures, both of which are vital in the architecture of.", "labels": [], "entities": []}, {"text": "Crucially, unlike the sequence-to-sequence transduction model of , which primarily conditions on the input words, our model is sensitive to all aspects of the parsing history, including arbitrary positions in the input.", "labels": [], "entities": []}, {"text": "As another contribution, we present a global LSTM parsing model by adapting an expected Fmeasure loss (.", "labels": [], "entities": [{"text": "LSTM parsing", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.9064763188362122}, {"text": "Fmeasure loss", "start_pos": 88, "end_pos": 101, "type": "METRIC", "confidence": 0.9664768874645233}]}, {"text": "As well as naturally incorporating beam search during training, this loss optimizes the model towards the final evaluation metric, allowing it to learn shiftreduce action sequences that lead to parses with high expected F-scores.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.9770529270172119}]}, {"text": "We further show the globally optimized model can be leveraged with greedy inference, resulting in a deterministic parser as accurate cal assignment accuracy than the C&C parser, even with the same supertagging model ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.5619441866874695}]}, {"text": "In our parser, we follow this strategy and adopt the Zhang and Clark (2011) style shift-reduce transition system, which assumes a set of lexical categories has been assigned to each word using a supertagger ().", "labels": [], "entities": []}, {"text": "Parsing then proceeds by applying a sequence of actions to transform the input maintained on a queue, into partially constructed derivations, kept on a stack, until the queue and available actions on the stack are both exhausted.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9760310053825378}]}, {"text": "At each time step, the parser can choose to shift (sh) one of the lexical categories of the front word onto the stack, and remove that word from the queue; reduce (re) the top two subtrees on the stack using a CCG rule, replacing them with the resulting category; or take a unary (un) action to apply a CCG type-raising or type-changing rule to the stack-top element.", "labels": [], "entities": []}, {"text": "For example, the deterministic sequence of shift-reduce actions that builds the derivation in is: sh \u21d2 NP , un \u21d2 S /(S \\NP ), sh \u21d2 (S \\NP )/NP , re \u21d2 S /NP , sh \u21d2 NP and re \u21d2 S , where we use \u21d2 to indicate the CCG category produced by an action.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted all experiments on) with the standard splits.", "labels": [], "entities": []}, {"text": "We assigned POS tags with the C&C POS tagger, and used 10-fold jackknifing for both POS tagging and supertagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.7731082439422607}]}, {"text": "All parsers were evaluated using F1 over labeled CCG dependencies.", "labels": [], "entities": [{"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.996320366859436}]}, {"text": "For supertagging, the baseline models are the RNN model of , the bidirectional RNN (BRNN) model of, and the BLSTM supertagging models in and . For parsing experiments, we compared with the global beam-search shift-reduce parsers of and.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.593482255935669}, {"text": "parsing", "start_pos": 147, "end_pos": 154, "type": "TASK", "confidence": 0.9815385341644287}]}, {"text": "One neural shift-reduce CCG parser baseline is, which is a beam-search shift-reduce parser based on and; and the others are the RNN shift-reduce models in.", "labels": [], "entities": []}, {"text": "Additionally, the chart-based C&C parser was included by default.", "labels": [], "entities": []}, {"text": "11 All our LSTM models are non-stacking with a single layer.", "labels": [], "entities": []}, {"text": "hidden state size is 256, and the size of the attentional hidden layer (x t , Eq. 5) is 200.", "labels": [], "entities": []}, {"text": "All parsing model LSTMs have a hidden state size of 128, and the size of the action hidden layer (b t , Eq. 4) is 80.", "labels": [], "entities": []}, {"text": "Pretrained word embeddings for all models are 100-dimensional (, and all other embeddings are 50-dimensional.", "labels": [], "entities": []}, {"text": "We also pretrained CCG lexical category and POS embeddings on the concatenation of the training data and a Wikipedia dump parsed with C&C.", "labels": [], "entities": []}, {"text": "13 All other parameters were uniformly initialized in \u00b1 6/(r + c), where rand care the number of rows and columns of a matrix (.", "labels": [], "entities": []}, {"text": "For training, we used plain non-minibatched stochastic gradient descent with an initial learning rate \u03b7 0 = 0.1 and we kept iterating in epochs until accuracy no longer increases on the dev set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9990178346633911}]}, {"text": "For all models, a learning rate schedule \u03b7 e = \u03b7 0 /(1 + \u03bbe) with \u03bb = 0.08 was used fore \u2265 11.", "labels": [], "entities": [{"text": "learning rate schedule \u03b7 e", "start_pos": 18, "end_pos": 44, "type": "METRIC", "confidence": 0.8574507236480713}]}, {"text": "Gradients were clipped whenever their norm exceeds 5.", "labels": [], "entities": [{"text": "Gradients", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9621003866195679}]}, {"text": "Dropout training as suggested by, with a dropout rate of 0.3, and an 2 penalty of 1 \u00d7 10 \u22125 , were applied to all models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 1-best supertagging results on both the dev and test  sets. BLSTM is the baseline model without attention; BLSTM- local and -global are the two attention-based models.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.8438549637794495}]}, {"text": " Table 2: Tuning beam size and supertagger \u03b2 on the dev set.", "labels": [], "entities": [{"text": "supertagger \u03b2", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.7996406257152557}]}, {"text": " Table 3: F1 on dev for all the greedy models.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9988986253738403}]}, {"text": " Table 4: Parsing results on the dev (Section 00) and test (Section 23) sets with 100% coverage, with all LSTM models using the  BLSTM-local supertagging model. All experiments using auto POS. CAT (lexical category assignment accuracy). LSTM-greedy  is the full greedy parser.", "labels": [], "entities": [{"text": "BLSTM-local", "start_pos": 129, "end_pos": 140, "type": "METRIC", "confidence": 0.8492196798324585}]}, {"text": " Table 6: Comparison of our XF1 models with chart-based  parsers on the test set. denotes a tri-trained model and  *  indi- cates a different POS tagger.", "labels": [], "entities": []}]}