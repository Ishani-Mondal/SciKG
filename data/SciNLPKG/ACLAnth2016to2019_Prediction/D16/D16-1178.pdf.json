{"title": [{"text": "Friends with Motives: Using Text to Infer Influence on SCOTUS", "labels": [], "entities": [{"text": "Friends with Motives", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.607038289308548}, {"text": "SCOTUS", "start_pos": 55, "end_pos": 61, "type": "TASK", "confidence": 0.43902432918548584}]}], "abstractContent": [{"text": "We present a probabilistic model of the influence of language on the behavior of the U.S. Supreme Court, specifically influence of amicus briefs on Court decisions and opinions.", "labels": [], "entities": []}, {"text": "The approach assumes that amici are rational, utility-maximizing agents who try to win votes or affect the language of court opinions.", "labels": [], "entities": []}, {"text": "Our model leads to improved predictions of justices' votes and perplexity of opinion language.", "labels": [], "entities": []}, {"text": "It is amenable to inspection, allowing us to explore inferences about the persua-siveness of different amici and influenceability of different justices; these are consistent with earlier findings.", "labels": [], "entities": []}, {"text": "\"Language is the central tool of our trade.\"", "labels": [], "entities": []}, {"text": "John G. Roberts, 2007 (Garner, 2010)", "labels": [], "entities": []}], "introductionContent": [{"text": "The Supreme Court of the United States (SCOTUS), the highest court in the American judiciary, makes decisions with far-reaching effects.", "labels": [], "entities": []}, {"text": "Ina typical case, there are four participating parties: petitioners and respondents who file briefs arguing the merits of their sides of a case (\"merits briefs\"); third-party entities with an interest (but not a direct stake) in the case, who file amicus curiae 1 briefs to provide further arguments and recommendations on either side; and justices who, after oral arguments and discus-1 Amicus curiae is Latin for \"friends of the court.\"", "labels": [], "entities": []}, {"text": "Hereafter, we use amicus in singular and amici in plural to refer to these interested third parties.", "labels": [], "entities": []}, {"text": "It is common for several amici to coauthor a single brief, which we account for in our model.", "labels": [], "entities": []}, {"text": "sions, vote on the case and write \"opinions\" to explain the Court's decisions.", "labels": [], "entities": []}, {"text": "In recent years, amicus briefs are increasingly being employed as a lobbying tool to influence the Court's decision-making process).", "labels": [], "entities": []}, {"text": "The content of these briefs reveals explicit attempts to persuade justices and provides a fascinating setting for empirical study of influence through language.", "labels": [], "entities": []}, {"text": "As such, we take the perspective of an amicus, proposing a probabilistic model of the various parties to a case that accounts for the amicus' goals.", "labels": [], "entities": []}, {"text": "Our model of SCOTUS is considerably more comprehensive than past work in political science, which has focused primarily on ideal point models that use votes as evidence.", "labels": [], "entities": [{"text": "SCOTUS", "start_pos": 13, "end_pos": 19, "type": "TASK", "confidence": 0.8260757327079773}]}, {"text": "Text has been incorporated more recently as away of making such models more interpretable, but without changing the fundamental assumptions).", "labels": [], "entities": []}, {"text": "Here, we draw on decision theory to posit amici as rational agents.", "labels": [], "entities": [{"text": "decision theory", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.8645196259021759}]}, {"text": "We assume these amici-agents maximize their expected utility by framing their arguments to sway justices towards favorable outcomes.", "labels": [], "entities": []}, {"text": "We build directly on, who used utility functions to explicitly model the goals of amici in a probabilistic setting.", "labels": [], "entities": []}, {"text": "Their approach only considered amici in aggregate, inferring nothing about any specific amicus, such as experience or motivation for filing briefs.", "labels": [], "entities": []}, {"text": "Here, we enrich their model to allow such analysis and also introduce Court opinions as evidence.", "labels": [], "entities": []}, {"text": "By modeling the justices' author-ing process as well, we can capture an important aspect of amici's goals: influencing the text of the opinions.", "labels": [], "entities": []}, {"text": "In \u00a73, we demonstrate the effectiveness of our approach on vote prediction and perplexity.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.8809055685997009}]}, {"text": "Furthermore, we present analyses that reveal the persuasiveness of amici and influenceability of justices that are consistent with past findings.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we use SCOTUS cases between 1985-2014; votes and metadata are from and brief texts come from.", "labels": [], "entities": []}, {"text": "We concatenate each of the 2,643 cases' merits briefs from both parties to form a single document, where the text is used to infer the representation of the casein topical space (\u03b8; i.e., merits briefs are treated as \"facts of the case\").", "labels": [], "entities": []}, {"text": "Likewise, opinions supporting the same side of the case (i.e., majority and concurring vs. dissents) were concatenated to form a single document.", "labels": [], "entities": []}, {"text": "In our dataset, the opinions are explicitly labeled with the justice who authored them (as well as other justices who decide to \"join\" it).", "labels": [], "entities": []}, {"text": "As the amicus briefs in the dataset were not explicitly labeled with the side that they support, built a binary classifier with bag-ofn-gram features that took advantage of cues in the brief content that strongly signal the side that the amici supports (e.g., \"in support of petitioner\").", "labels": [], "entities": []}, {"text": "We used their classifier to label the amici's supporting side.", "labels": [], "entities": []}, {"text": "Additionally, we created regular expression rules to identify and standardize amicus authors from the header of briefs.", "labels": [], "entities": []}, {"text": "We filtered amici who have participated in fewer than 5 briefs and merged regional chapters of amicus organizations together (i.e., \"ACLU of Kansas\" and \"ACLU of Kentucky\" are both labeled \"ACLU\").", "labels": [], "entities": []}, {"text": "On the other hand, we separated labeled amicus briefs by the U.S. Solicitor General according to the presidential administration when the brief is filed (i.e., an amicus brief filed during Obama's administration will be labeled \"USSG-Obama\").", "labels": [], "entities": []}, {"text": "The top three amici by number of briefs filed are American Civil Liberties Union (463), Utah (376), and National Asso- ciation of Criminal Defense Lawyers (359).", "labels": [], "entities": [{"text": "American Civil Liberties Union", "start_pos": 50, "end_pos": 80, "type": "DATASET", "confidence": 0.9531675279140472}, {"text": "National Asso- ciation of Criminal Defense Lawyers", "start_pos": 104, "end_pos": 154, "type": "TASK", "confidence": 0.6131550446152687}]}, {"text": "We represent a document as a bag of n-grams with part of speech tags that follow the simple but effective pattern (Adjective|Cardinal|Noun)+ Noun.", "labels": [], "entities": []}, {"text": "We filter phrases appearing fewer than 100 times or in more than 8,500 documents, obtaining a final set of 48,589 phrase types.", "labels": [], "entities": []}, {"text": "summarizes the details of our corpus.", "labels": [], "entities": []}, {"text": "We quantify the performance of our vote model using 5-fold cross validation and on predicting future votes from past votes.", "labels": [], "entities": []}, {"text": "The utility function in the vote model uses the response function in Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 69, "end_pos": 71, "type": "DATASET", "confidence": 0.9039387702941895}]}, {"text": "5. Due to the specification of IP models, we need the case parameters of new cases to predict the direction of the votes.", "labels": [], "entities": []}, {"text": "accomplished this by using regression on legislative text to predict the case parameters (a, b).", "labels": [], "entities": []}, {"text": "Here, we follow a similar approach, fitting ridge regression models on the merits brief topic mixtures \u03b8 to predict a and b for each case.", "labels": [], "entities": []}, {"text": "On the held-out test cases, we sampled the mixture proportions for the merits and amicus briefs directly using latent Dirichlet allocation with parameters learned while fitting our vote model.", "labels": [], "entities": []}, {"text": "With the parameters from our fitted vote model and ridge regression, we can predict the votes of every justice for every case.", "labels": [], "entities": []}, {"text": "We compared the performance of our model with two strong baselines: (i) a random forest trained on case-centric metadata coded by to make predictions on how justices would vote () and (ii)'s amici IP model, which uses amicus briefs and their version of utility; it is a simpler version of our vote model that does not consider the persuasiveness of different amici or the influenceability of different justices.", "labels": [], "entities": []}, {"text": "For prediction in, we used the same approach described above to estimate the case parameters a, b, and regressing on amicus brief topics (\u2206) instead for amicus polarities c p and c r .  shows performance on vote prediction.", "labels": [], "entities": [{"text": "prediction", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.966733455657959}, {"text": "regressing", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.9909991025924683}, {"text": "vote prediction", "start_pos": 207, "end_pos": 222, "type": "TASK", "confidence": 0.7636727392673492}]}, {"text": "We evaluated the models using 5-fold cross validation, as well as on forecasting votes in 2013 and 2014 (trained using data from 1985 to the preceding year).", "labels": [], "entities": [{"text": "forecasting votes", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.8626068234443665}]}, {"text": "Our model outperformed the baseline models.", "labels": [], "entities": []}, {"text": "The improvement inaccuracy over is small; most likely because both models are very similar, the main difference being the parametrization of amicus briefs.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.8511602282524109}]}, {"text": "In the 2013 test set, the distribution of votes is significantly skewed towards the petitioner (compared to the training data), which resulted in the most frequent class classifier performing much better than everything else.", "labels": [], "entities": [{"text": "2013 test set", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.738298773765564}]}, {"text": "illustrates our model's estimated ideal points for selected topics.", "labels": [], "entities": []}, {"text": "We also estimated the opinion model using the utility function with response function in Eq.", "labels": [], "entities": []}, {"text": "6. We use perplexity as a proxy to measure the opinion content predictive ability of our model.", "labels": [], "entities": [{"text": "opinion content predictive", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.6277414460976919}]}, {"text": "Perplexity on a test set is commonly used to quantify the generalization ability of probabilistic models and make comparisons among models over the same observation space.", "labels": [], "entities": []}, {"text": "For a case with opinion w supporting side s, the perplexity is defined as where N is the number of tokens in the opinion and a lower perplexity indicates better generalization performance.", "labels": [], "entities": []}, {"text": "The likelihood term can be approximated using samples from the inference step.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9542630910873413}]}, {"text": "shows the perplexity of our model on opinions in the test set.", "labels": [], "entities": []}, {"text": "As described in \u00a72.4, we learn the vote model in the first stage before estimating the opinion model.", "labels": [], "entities": []}, {"text": "Here, we compare our model against using vote models that do not include U vote to evaluate the sensitivity of our opinion 120: marriage, same sex, man: Justices' ideal points for selected topics.", "labels": [], "entities": []}, {"text": "Justices whose topic IPs are close to each other are more likely to vote in the same direction on cases involving those topics.", "labels": [], "entities": []}, {"text": "The IP estimated by our model is consistent with publicly available knowledge regarding justices' ideological stances on these issues.", "labels": [], "entities": [{"text": "IP", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9710724949836731}]}, {"text": "model to the vote model parameters.", "labels": [], "entities": []}, {"text": "Additionally, we compared against two baselines trained on just the opinions: one using LDA and another using the author-topic model).", "labels": [], "entities": []}, {"text": "For the author-topic model, we treat each opinion as being \"authored\" by the participating justices, a pseudoauthor representing the litigants which is shared between opinions in a case, and a unique amicus author for each side.", "labels": [], "entities": []}, {"text": "Our model with U opinion achieves better generalization performance than the simpler baselines, while we do not see significant differences in whether the first stage vote models use U vote . This is not surprising since the vote model's results are similar with or without U vote and it influences the opinion model indirectly through priors and U opinion . In our model, the latent variable \u0393 j captures the proportion of topics that justice j is likely to contribute to an opinion.", "labels": [], "entities": []}, {"text": "When j has a high probability of voting fora particular side, our informed prior increases the likelihood that j's topics will be selected for words in the opinion.", "labels": [], "entities": []}, {"text": "While \u0393 j serves a similar purpose to \u03c8 j in characterizing j through her ideological positions, \u03c8 j relies on votes and gives us a \"direction\" of j's ideological standing, whereas \u0393 j is estimated from text produced by the justices and only gives us the \"magnitude\" of her tendency to author on a particular issue.", "labels": [], "entities": []}, {"text": "In, we identify the top topics in \u0393 j by considering the deviation from the mean of all justice's \u0393, i.e., Amici Persuasiveness.", "labels": [], "entities": [{"text": "Amici Persuasiveness", "start_pos": 107, "end_pos": 127, "type": "TASK", "confidence": 0.7561259865760803}]}, {"text": "fect on the case IP, which we call \"persuasiveness.\"", "labels": [], "entities": []}, {"text": "A large \u03c0 e indicates that across the dataset, e exerts a larger effect on the case IPs, that is, according to our model, she has a larger impact on the Court's decision than other amici. is a swarm plot illustrating the distribution of \u03c0 values for different types of amicus writers.", "labels": [], "entities": []}, {"text": "Our model infers that governmental offices tend to have larger \u03c0 values than private organizations, especially the U.S. Solicitor General.", "labels": [], "entities": []}, {"text": "14 In fact, found through interviews with SCOTUS law clerks that \"amicus briefs from the solicitor general are 'head and shoulders' above the rest, and are often considered more carefully than party briefs.\"", "labels": [], "entities": []}, {"text": "Another interesting observation from is the low \u03c0 value for ACLU and ABA, despite being prolific amicus brief filers.", "labels": [], "entities": [{"text": "\u03c0", "start_pos": 48, "end_pos": 49, "type": "METRIC", "confidence": 0.9727327823638916}, {"text": "ACLU", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.838337779045105}, {"text": "ABA", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.7134512662887573}]}, {"text": "While it is tempting to say that amici with low \u03c0 values are ineffective, we find that there is almost no correlation between \u03c0 and the proportion of cases where they were on the winning side.: Top three topics contributed to Court opinions for selected justices (\u0393).", "labels": [], "entities": []}, {"text": "The full list can be found in supplementary \u00a7C.", "labels": [], "entities": []}, {"text": "\"persuasive\" amicus tends to win.", "labels": [], "entities": []}, {"text": "Instead, an amicus with large \u03c0 will impact the case IP most, and thus explain a justice's vote or opinion (even dissenting) more than the other components in a case.", "labels": [], "entities": [{"text": "IP", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9463568925857544}]}, {"text": "Insofar as \u03c0 explains a vote, we must exercise caution; it is possible that the amicus played no role in the decision-making process and the values of \u03c0 e simply reflect our modeling assumptions and/or artifacts of the data.", "labels": [], "entities": []}, {"text": "Without entering the minds of SCOTUS justices, or at least observing their closeddoor deliberations, it is difficult to measure the influence of amicus briefs on justices' decisions.", "labels": [], "entities": []}, {"text": "The latent variable \u03c7 j measures the relative effect of amicus briefs on justice j's vote IP; when \u03c7 j is large, justice j's vote probability is affected by amicus briefs more.", "labels": [], "entities": [{"text": "latent variable \u03c7 j", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.9146122336387634}, {"text": "IP", "start_pos": 90, "end_pos": 92, "type": "METRIC", "confidence": 0.8574057221412659}]}, {"text": "Since \u03c7 j is shared between all cases that a justice participates in, \u03c7 j should correspond to how much they value amicus briefs.", "labels": [], "entities": []}, {"text": "Some justices, such as the late Scalia, are known to be dubious of amicus briefs, preferring to leave the task of reading these briefs to their law clerks, who will pick out any notable briefs for them; we would expect Scalia to have a smaller \u03c7 than other justices.", "labels": [], "entities": []}, {"text": "In, we compare the \u03c7 values of justices with how often they cite an amicus brief in any opinion they wrote.", "labels": [], "entities": []}, {"text": "The \u03c7 values estimated by our model are sides is \u22120.0549.", "labels": [], "entities": []}, {"text": "On average, an amicus supports the winning side in 55% of cases.", "labels": [], "entities": []}, {"text": "For the ACLU, ABA, CAC, and CWFA, the proportions are 44%, 50%, 47%, and 50% respectively.", "labels": [], "entities": [{"text": "ACLU", "start_pos": 8, "end_pos": 12, "type": "DATASET", "confidence": 0.9036407470703125}]}, {"text": "We note that the \u03c7 values correlate considerably with the general ideological leanings of the justices.", "labels": [], "entities": []}, {"text": "This might be a coincidence or an inability of the model's specification to discern between ideological extremeness and influenceability.", "labels": [], "entities": []}, {"text": "econometrics estimates structural utility-based decisions (, inter alia).", "labels": [], "entities": []}, {"text": "Researchers have used SCOTUS texts to study authorship (, historical changes (, power relationships (DanescuNiculescu-, and pragmatics).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 Model  5-fold 2013 2014  Most frequent  0.597 0.694 0.650  Random forest  0.651 0.648 0.633  Vote model without U vote 0.661 0.655 0.660  Sim et al. (2015)  0.675 0.658 0.661  Vote model with U vote  0.685 0.664 0.672", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of vote prediction. There are 70 cases  (625 votes) and 69 cases (619 votes) in the 2013 and 2014  test sets, respectively.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9913396239280701}, {"text": "vote prediction", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.7627929151058197}]}, {"text": " Table 3: Perplexity of Court's opinions (\u00d710 3 ). There  are 30,133 phrases (98 opinions) and 23,706 phrases (109  opinions) in the 2013 and 2014 test set, respectively. Re- sults marked  \u2020 are initialized with a vote model U vote .", "labels": [], "entities": []}, {"text": " Table 5: Justice \u03c7 values and their average amicus cita- tion rates between 2010-2015, provided by Franze and  Anderson (2015).", "labels": [], "entities": []}]}