{"title": [{"text": "Learning a Lexicon and Translation Model from Phoneme Lattices", "labels": [], "entities": []}], "abstractContent": [{"text": "Language documentation begins by gathering speech.", "labels": [], "entities": [{"text": "Language documentation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6637606620788574}]}, {"text": "Manual or automatic transcription at the word level is typically not possible because of the absence of an orthography or prior lexicon, and though manual phone-mic transcription is possible, it is prohibitively slow.", "labels": [], "entities": [{"text": "phone-mic transcription", "start_pos": 155, "end_pos": 178, "type": "TASK", "confidence": 0.7286104559898376}]}, {"text": "On the other hand, translations of the minority language into a major language are more easily acquired.", "labels": [], "entities": []}, {"text": "We propose a method to harness such translations to improve automatic phoneme recognition.", "labels": [], "entities": [{"text": "automatic phoneme recognition", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.6095224718252817}]}, {"text": "The method assumes no prior lexicon or translation model, instead learning them from phoneme lattices and translations of the speech being transcribed.", "labels": [], "entities": []}, {"text": "Experiments demonstrate phoneme error rate improvements against two baselines and the model's ability to learn useful bilingual lexical entries.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most of the world's languages are dying out and have little recorded data or linguistic documentation (.", "labels": [], "entities": []}, {"text": "It is important to adequately document languages while they are alive so that they maybe investigated in the future.", "labels": [], "entities": []}, {"text": "Language documentation traditionally involves one-onone elicitation of speech from native speakers in order to produce lexicons and grammars that describe the language.", "labels": [], "entities": [{"text": "Language documentation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6901036202907562}]}, {"text": "However, this does not scale: linguists must first transcribe the speech phonemically as most of these languages have no standardized orthography.", "labels": [], "entities": []}, {"text": "This is a critical bottleneck since it takes a trained linguist about 1 hour to transcribe the phonemes of 1 minute of speech ().", "labels": [], "entities": []}, {"text": "Smartphone apps for rapid collection of bilingual data have been increasingly investigated.", "labels": [], "entities": [{"text": "rapid collection of bilingual data", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.709496122598648}]}, {"text": "It is common for these apps to collect speech segments paired with spoken translations in another language, making spoken translations quicker to obtain than phonemic transcriptions.", "labels": [], "entities": []}, {"text": "We present a method to improve automatic phoneme transcription by harnessing such bilingual data to learn a lexicon and translation model directly from source phoneme lattices and their written target translations, assuming that the target side is a major language that can be efficiently transcribed.", "labels": [], "entities": [{"text": "automatic phoneme transcription", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6127756834030151}]}, {"text": "1 A Bayesian non-parametric model expressed with a weighted finite-state transducer (WFST) framework represents the joint distribution of source acoustic features, phonemes and latent source words given the target words.", "labels": [], "entities": []}, {"text": "Sampling of alignments is used to learn source words and their target translations, which are then used to improve transcription of the source audio they were learnt from.", "labels": [], "entities": []}, {"text": "Importantly, the model assumes no prior lexicon or translation model.", "labels": [], "entities": []}, {"text": "This method builds on work on phoneme translation modeling, speech translation (), computer-aided translation, (;, translation modeling from automatically transcribed speech, word segmentation and translation modeling (, Bayesian word alignment () and language model learning from lattices ().", "labels": [], "entities": [{"text": "phoneme translation modeling", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.8356230656305949}, {"text": "speech translation", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7756105959415436}, {"text": "computer-aided translation", "start_pos": 83, "end_pos": 109, "type": "TASK", "confidence": 0.7503392994403839}, {"text": "translation modeling from automatically transcribed speech", "start_pos": 115, "end_pos": 173, "type": "TASK", "confidence": 0.9013701975345612}, {"text": "word segmentation", "start_pos": 175, "end_pos": 192, "type": "TASK", "confidence": 0.7531258761882782}, {"text": "translation modeling", "start_pos": 197, "end_pos": 217, "type": "TASK", "confidence": 0.9075532853603363}, {"text": "Bayesian word alignment", "start_pos": 221, "end_pos": 244, "type": "TASK", "confidence": 0.603092779715856}]}, {"text": "While we previously explored learning a translation model from word lattices (, in this paper we extend the model to perform unsupervised word segmentation over phoneme lattices in order to improve phoneme recognition.", "labels": [], "entities": [{"text": "phoneme recognition", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.7369993180036545}]}, {"text": "Experiments demonstrate that our method significantly reduces the phoneme error rate (PER) of transcriptions compared with a baseline recogniser and a similar model that harnesses only monolingual information, by up to 17% and 5% respectively.", "labels": [], "entities": [{"text": "phoneme error rate (PER)", "start_pos": 66, "end_pos": 90, "type": "METRIC", "confidence": 0.8605414579312006}]}, {"text": "We also find that the model learns meaningful bilingual lexical items.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the lexicon and translation model by their ability to improve phoneme recognition, measuring phoneme error rate (PER).", "labels": [], "entities": [{"text": "phoneme recognition", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7301760613918304}, {"text": "phoneme error rate (PER)", "start_pos": 105, "end_pos": 129, "type": "METRIC", "confidence": 0.792597696185112}]}, {"text": "We used less than 10 hours of English-Japanese data from the BTEC corpus (), comprised of spoken utterances paired with textual translations.", "labels": [], "entities": [{"text": "BTEC corpus", "start_pos": 61, "end_pos": 72, "type": "DATASET", "confidence": 0.9538223743438721}]}, {"text": "This allows us to assess the approach assuming quality acoustic models.", "labels": [], "entities": []}, {"text": "We used acoustic models similar to to obtain source phoneme lattices.", "labels": [], "entities": []}, {"text": "Gold phoneme transcriptions were obtained by transforming the text with pronunciation lexicons and, in the Japanese case, first segmenting the text into tokens using).", "labels": [], "entities": []}, {"text": "We run experiments in both directions: EnglishJapanese and Japanese-English (en-ja and ja-en), while comparing against three settings: the ASR 1-best path uninformed by the model (ASR); a monolingual version of our model that is identical except without conditioning on the target side (Mono); and the model applied using the source language sentence as the target (Oracle).", "labels": [], "entities": [{"text": "ASR 1-best path", "start_pos": 139, "end_pos": 154, "type": "METRIC", "confidence": 0.8696804245313009}]}, {"text": "We tuned on the first 1,000 utterences (about 1 hour) of speech and trained on up to 9 hours of the", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Phoneme error rates (percent) when train- ing on 9 hours of speech, averaged over 4 runs.", "labels": [], "entities": [{"text": "error rates", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9171731472015381}]}]}