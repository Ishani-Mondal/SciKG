{"title": [], "abstractContent": [{"text": "Multiple treebanks annotated under heterogeneous standards give rise to the research question of best utilizing multiple resources for improving statistical models.", "labels": [], "entities": []}, {"text": "Prior research has focused on discrete models, leveraging stacking and multi-view learning to address the problem.", "labels": [], "entities": []}, {"text": "In this paper, we empirically investigate heterogeneous annotations using neu-ral network models, building a neural network counterpart to discrete stacking and multi-view learning, respectively, finding that neural models have their unique advantages thanks to the freedom from manual feature engineering.", "labels": [], "entities": []}, {"text": "Neural model achieves not only better accuracy improvements, but also an order of magnitude faster speed compared to its discrete baseline, adding little time cost compared to a neural model trained on a single treebank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9969134330749512}, {"text": "speed", "start_pos": 99, "end_pos": 104, "type": "METRIC", "confidence": 0.9718989729881287}]}], "introductionContent": [{"text": "For many languages, multiple treebanks have been annotated according to different guidelines.", "labels": [], "entities": []}, {"text": "For example, several linguistic theories have been used for defining English dependency treebanks, including, LTH and Stanford dependencies).", "labels": [], "entities": []}, {"text": "For German, there exist TIGER () and T\u00fcBa-D/Z ().", "labels": [], "entities": [{"text": "TIGER", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9917199611663818}, {"text": "T\u00fcBa-D", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.8988192081451416}]}, {"text": "For Chinese, treebanks have been made available under various segmentation granularities.", "labels": [], "entities": []}, {"text": "These give rise to the research problem * Work done when the first author was visiting SUTD. of effectively making use of multiple treebanks under heterogeneous annotations for improving output accuracies ().", "labels": [], "entities": [{"text": "SUTD.", "start_pos": 87, "end_pos": 92, "type": "DATASET", "confidence": 0.8624581694602966}]}, {"text": "The task has been tackled using two typical approaches.", "labels": [], "entities": []}, {"text": "The first is based on stacking).", "labels": [], "entities": [{"text": "stacking", "start_pos": 22, "end_pos": 30, "type": "TASK", "confidence": 0.9566333889961243}]}, {"text": "As shown in(a), the main idea is to have a model trained using a source treebank, which is then used to guide a target treebank model by offering source-style features.", "labels": [], "entities": []}, {"text": "This method has been used for leveraging two different treebanks for word segmentation) and dependency parsing ().", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7704183459281921}, {"text": "dependency parsing", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.8669760227203369}]}, {"text": "The second approach is based on multi-view learning).", "labels": [], "entities": []}, {"text": "The idea is to address both annotation styles simultaneously by sharing common feature representations.", "labels": [], "entities": []}, {"text": "In particular, Johansson (2013) trained dependency parsers using the domain adaptation method of, keeping a copy of shared features and a separate copy of features for each treebank.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7995794713497162}, {"text": "domain adaptation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7207958102226257}]}, {"text": "trained POS taggers by coupling the labelsets from two different treebanks into a single combined labelset.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.7658050656318665}]}, {"text": "A summary of such multi-view methods is shown in(b), which demonstrates their main differences compared to stacking).", "labels": [], "entities": []}, {"text": "Recently, neural network has gained increasing research attention, with highly competitive results being reported for numerous NLP tasks, including word segmentation (, POS-tagging (: Two main approaches to utilizing heterogeneous annotations.).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 148, "end_pos": 165, "type": "TASK", "confidence": 0.7749639749526978}]}, {"text": "On the other hand, the aforementioned methods on heterogeneous annotations are investigated mainly for discrete models.", "labels": [], "entities": []}, {"text": "It remains an interesting research question how effective multiple treebanks can be utilized by neural NLP models, and we aim to investigate this empirically.", "labels": [], "entities": []}, {"text": "We follow, taking POS-tagging for case study, using the methods of and as the discrete stacking and multi-view training baselines, respectively, and building neural network counterparts to their models for empirical comparison.", "labels": [], "entities": []}, {"text": "The base tagger is a neural CRF model (, which gives competitive accuracies to discrete CRF taggers.", "labels": [], "entities": []}, {"text": "Results show that neural stacking allows deeper integration of the source model beyond one-best outputs, and further the fine-tuning of the source model during the target model training.", "labels": [], "entities": [{"text": "neural stacking", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7178999781608582}]}, {"text": "In addition, the advantage of neural multi-view learning over its discrete counterpart are many-fold.", "labels": [], "entities": []}, {"text": "First, it is free from the necessity of manual cross-labelset interactive feature engineering, which is far from trivial for representing annotation correspondence (.", "labels": [], "entities": []}, {"text": "Second, compared to discrete model, parameter sharing in deep neural network eliminates the issue of exponential growth of search space, and allows separated training of each label type, in the same way as multi-task learning).", "labels": [], "entities": []}, {"text": "Our neural multi-view learning model achieves not only better accuracy improvements, but also an order of magnitude faster speed compared to its discrete baseline, adding little time cost compared to a neural model trained on a single treebank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9979992508888245}]}, {"text": "The C++ implementations of our neural network stacking and multi-view learning models are available under GPL, at https://github.com/chenhongshen/NNHetSeq.", "labels": [], "entities": [{"text": "NNHetSeq", "start_pos": 146, "end_pos": 154, "type": "DATASET", "confidence": 0.923258364200592}]}], "datasetContent": [{"text": "We adopt the Penn Chinese Treebank version 5.0 (CTB5) () as our main corpus, with the standard data split following previous work).", "labels": [], "entities": [{"text": "Penn Chinese Treebank version 5.0 (CTB5)", "start_pos": 13, "end_pos": 53, "type": "DATASET", "confidence": 0.97274599224329}]}, {"text": "People's Daily (PD) is used as second corpus with a different scheme.", "labels": [], "entities": [{"text": "People's Daily (PD)", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.9616594513257345}]}, {"text": "We filter out PD sentences longer than 200 words.", "labels": [], "entities": []}, {"text": "Details of the datasets are listed in.", "labels": [], "entities": []}, {"text": "The standard token-wise POS tagging accuracy is used as the evaluation metric.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.6736833602190018}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.7204568386077881}]}, {"text": "The systems are implemented with LibN3L ( . For all the neural models, we set the hidden layer size to 100, the initial learning rate for Adagrad to 0.01 and the regularization parameter \u03bb to 10 \u22128 . word2vec 1 is used to pretrain word embeddings.", "labels": [], "entities": []}, {"text": "The Chinese Giga-word corpus version 5 (), segmented by zpar 2 (, is used for the training corpus for word embeddings.", "labels": [], "entities": [{"text": "Chinese Giga-word corpus version 5", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.8380938529968261}]}, {"text": "The size of word embedding is 50.", "labels": [], "entities": []}, {"text": "We use the development dataset for two main purposes.", "labels": [], "entities": []}, {"text": "First, under each setting, we tune the model parameters, such as the number of training epochs.", "labels": [], "entities": []}, {"text": "Second, we study the influence of several important hyper-parameters using the development dataset.", "labels": [], "entities": []}, {"text": "For example, for the NN multi-view learning model, the corpus weights ratio (section 5) plays an important role for the performance.", "labels": [], "entities": []}, {"text": "We determine the parameters of the model by studying the accuracy along with the increasing epochs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.999742329120636}]}, {"text": "Effect of batch size and dropout.", "labels": [], "entities": []}, {"text": "The batch size affects the speed of training convergence and the final accuracies of the neural models, and the dropout rate has been shown to significantly influence the performance ( . We investigate the effects of these two hyper-parameters by adopting a corpus weight ratio of 1 : 1 (All the CTB training data is used, while the same amount of PD is sampled randomly), drawing the accuracies of the neural multi-view learning model against the number of training epochs with various combinations of the dropout rated and batch size b.", "labels": [], "entities": []}, {"text": "The results are shown for the multi-view learning model.", "labels": [], "entities": []}, {"text": "For the stacking model, we use b=100 for the PD sub model.", "labels": [], "entities": [{"text": "stacking", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.9733249545097351}]}, {"text": "The results are shown in, where the two dashed lines on the top at epoch 30 represent the dropout rate of 20%, the two solid lines in the middle represent zero dropout rate, and the two dotted lines in the bottom represent a dropout rate 50%.", "labels": [], "entities": []}, {"text": "Without using dropout, the performance increases in the beginning, but then decreases as the number of training epochs increases beyond 10.", "labels": [], "entities": []}, {"text": "This indicates that the NN models can overfit the training data without dropout.", "labels": [], "entities": []}, {"text": "However, when a 50% dropout rate is used, the initial performances are significantly worse, which implies that the 50% dropout rate can be too large and leads to underfitting.", "labels": [], "entities": []}, {"text": "As a result, we choose a dropout rate of 20% for the remaining experiments, which strikes the balance between over-System Accuracy CRF Baseline ( 94.10 CRF Stacking ( 94.81 CRF Multi-view ( 95  fitting and underfitting.", "labels": [], "entities": [{"text": "Accuracy CRF Baseline", "start_pos": 122, "end_pos": 143, "type": "METRIC", "confidence": 0.8719943165779114}]}, {"text": "also shows that the batch size has a relative small influence on the accuracies, which varies according to the dropout rate.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9932367205619812}]}, {"text": "We simply choose a batch size of 1 for the remaining experiments according to the performance at the dropout rate 20%.", "labels": [], "entities": []}, {"text": "Effect of corpus weights ratio.", "labels": [], "entities": []}, {"text": "shows the effects of different corpus weights ratios.", "labels": [], "entities": []}, {"text": "In particular, a corpus weights ratio of 1:0.2 yields relative low accuracies.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.974504292011261}]}, {"text": "This is likely because it makes use of the least amount of PD data.", "labels": [], "entities": []}, {"text": "The ratios of 1:1 and 1:4 give comparable performances.", "labels": [], "entities": []}, {"text": "We choose the former for our final tests because it is a much faster choice.", "labels": [], "entities": []}, {"text": "shows the final results on the CTB test data.", "labels": [], "entities": [{"text": "CTB test data", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9762800137201945}]}, {"text": "We lists the results of stacking method of re-implemented by, and CRF multi-view method reported by.", "labels": [], "entities": []}, {"text": "We adopt pair-wise significance test) when comparing the results between two different models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracies on CTB-test.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9978908896446228}, {"text": "CTB-test", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.7269265651702881}]}, {"text": " Table 3: Time for testing CTB training data.", "labels": [], "entities": [{"text": "Time", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.981383740901947}, {"text": "CTB training data", "start_pos": 27, "end_pos": 44, "type": "DATASET", "confidence": 0.779900848865509}]}]}