{"title": [{"text": "Automatic Features for Essay Scoring -An Empirical Study", "labels": [], "entities": [{"text": "Essay Scoring", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.8407123386859894}]}], "abstractContent": [{"text": "Essay scoring is a complicated processing requiring analyzing, summarizing and judging expertise.", "labels": [], "entities": [{"text": "Essay scoring", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9510992467403412}, {"text": "summarizing", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.9215455651283264}]}, {"text": "Traditional work on essay scoring focused on automatic handcrafted features, which are expensive yet sparse.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.8943789005279541}]}, {"text": "Neural models offer away to learn syntactic and semantic features automatically, which can potentially improve upon discrete features.", "labels": [], "entities": []}, {"text": "In this paper , we employ convolutional neural network (CNN) for the effect of automatically learning features, and compare the result with the state-of-art discrete baselines.", "labels": [], "entities": []}, {"text": "For in-domain and domain-adaptation essay scoring tasks, our neural model empirically outperforms discrete models.", "labels": [], "entities": [{"text": "domain-adaptation essay scoring tasks", "start_pos": 18, "end_pos": 55, "type": "TASK", "confidence": 0.7259490340948105}]}], "introductionContent": [{"text": "Automatic essay scoring (AES) is the task of building a computer-based grading system, with the aim of reducing the involvement of human raters as far as possible.", "labels": [], "entities": [{"text": "Automatic essay scoring (AES)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7274491190910339}]}, {"text": "AES is challenging since it relies not only on grammars, but also on semantics, discourse and pragmatics.", "labels": [], "entities": []}, {"text": "Traditional approaches treat AES as a classification), regression (, or ranking classification problem, addressing AES by supervised learning.", "labels": [], "entities": []}, {"text": "Features are typically bag-of-words, spelling errors and lengths, such word length, sentence length and essay length, etc.", "labels": [], "entities": []}, {"text": "Some grammatical features are considered to assess the quality of essays.", "labels": [], "entities": []}, {"text": "A drawback is feature engineering, which can be time-consuming, since features need to be carefully handcrafted and selected to fit the approriate model.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7833697497844696}]}, {"text": "A further drawback of manual feature templates is that they are sparse, instantiated by discrete pattern-matching.", "labels": [], "entities": []}, {"text": "As a result, parsers and semantic analyzers are necessary as a preprocessing step to offer syntactic and semantic patterns for feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.7309235632419586}]}, {"text": "Given variable qualities of student essays, such analyzers can be highly unreliable.", "labels": [], "entities": []}, {"text": "Neural network approaches have been shown to be capable of inducing dense syntactic and semantic features automatcially, giving competitive results to manually designed features for several tasks.", "labels": [], "entities": []}, {"text": "In this paper, we empirically investigate a neural network method to learn features automatically for AES, without the need of external pre-processing.", "labels": [], "entities": [{"text": "AES", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.5994458794593811}]}, {"text": "In particular, we build a hierarchical CNN model, with one lower layer representing sentence structures and one upper layer representing essay structure based on sentence representations.", "labels": [], "entities": []}, {"text": "We compare automatically-induced features by the model with state-of-art baseline handcrafted features.", "labels": [], "entities": []}, {"text": "Empirical results show that neural features learned by CNN are very effective in essay scoring task, covering more high-level and abstract information compared to manual feature templates.", "labels": [], "entities": [{"text": "essay scoring task", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8379573027292887}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Details of the ASAP data; the last two columns  are score range and median scores. For genre, ARG spec- ifies argumentative essays, RES means response essays  and NAR denotes narrative essays.", "labels": [], "entities": [{"text": "ASAP data", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.837794691324234}, {"text": "RES", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.9858152866363525}, {"text": "NAR", "start_pos": 173, "end_pos": 176, "type": "METRIC", "confidence": 0.9513296484947205}]}]}