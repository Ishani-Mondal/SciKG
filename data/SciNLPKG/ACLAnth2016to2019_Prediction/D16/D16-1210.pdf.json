{"title": [{"text": "Unsupervised Word Alignment by Agreement Under ITG Constraint", "labels": [], "entities": [{"text": "Unsupervised Word Alignment", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5656503935654958}, {"text": "ITG Constraint", "start_pos": 47, "end_pos": 61, "type": "DATASET", "confidence": 0.8926898241043091}]}], "abstractContent": [{"text": "We propose a novel unsupervised word alignment method that uses a constraint based on Inversion Transduction Grammar (ITG) parse trees to jointly unify two directional models.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7298802584409714}]}, {"text": "Previous agreement methods are not helpful for locating alignments with long distances because they do not use any syntactic structures.", "labels": [], "entities": [{"text": "locating alignments", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.8425181210041046}]}, {"text": "In contrast, the proposed method symmetrizes alignments in consideration of their structural coherence by using the ITG constraint softly in the posterior regulariza-tion framework (Ganchev et al., 2010).", "labels": [], "entities": []}, {"text": "The ITG constraint is also compatible with word alignments that are not covered by ITG parse trees.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.7318707704544067}]}, {"text": "Hence, the proposed method is robust to ITG parse errors compared to other alignment methods that directly use an ITG model.", "labels": [], "entities": [{"text": "ITG parse", "start_pos": 40, "end_pos": 49, "type": "TASK", "confidence": 0.6383987367153168}]}, {"text": "Compared to the HMM (Vogel et al., 1996), IBM Model 4 (Brown et al., 1993), and the baseline agreement method (Ganchev et al., 2010), the experimental results show that the proposed method significantly improves alignment performance regarding the Japanese-English KFTT and BTEC corpus, and in translation evaluation, the proposed method shows comparable or statistical significantly better performance on the Japanese-English KFTT and IWSLT 2007 corpus.", "labels": [], "entities": [{"text": "BTEC corpus", "start_pos": 274, "end_pos": 285, "type": "DATASET", "confidence": 0.8816529810428619}, {"text": "translation evaluation", "start_pos": 294, "end_pos": 316, "type": "TASK", "confidence": 0.9183177053928375}, {"text": "IWSLT 2007 corpus", "start_pos": 436, "end_pos": 453, "type": "DATASET", "confidence": 0.9170990387598673}]}], "introductionContent": [{"text": "Word alignment is an important component of statistical machine translation (SMT) systems such as phrase-based SMT ( and hierarchical phrase-based SMT.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7288687378168106}, {"text": "statistical machine translation (SMT)", "start_pos": 44, "end_pos": 81, "type": "TASK", "confidence": 0.7743952671686808}, {"text": "phrase-based SMT", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.5365173518657684}, {"text": "phrase-based SMT", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.5191559791564941}]}, {"text": "In addition, word alignment is utilized for multi-lingual tasks other than SMT, such as bilingual lexicon extraction ( ).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.797835648059845}, {"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9915129542350769}, {"text": "bilingual lexicon extraction", "start_pos": 88, "end_pos": 116, "type": "TASK", "confidence": 0.6338602403799692}]}, {"text": "The most conventional approaches to word alignment are the IBM models () and the HMM model (, which align each source word to a single target word (i.e., directional models).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.8267956972122192}]}, {"text": "In these models, bidirectional word alignments are traditionally induced by combining the Viterbi alignments in each direction using heuristics.", "labels": [], "entities": []}, {"text": "exploited a symmetrized posterior probability for bidirectional word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.70634825527668}]}, {"text": "In these methods, each directional model is independently trained.", "labels": [], "entities": []}, {"text": "Previous researches have improved bidirectional word alignments by jointly training two directional models to agree with each other (.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7201827615499496}]}, {"text": "Such a constraint on the agreement in a training phase is one of the most effective approaches to word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.8167334198951721}]}, {"text": "However, none of the previous agreement constraints have taken into account syntactic structures.", "labels": [], "entities": []}, {"text": "Therefore, they have difficulty recovering the alignments with long distances, which frequently occur, especially in grammatically different language pairs.", "labels": [], "entities": []}, {"text": "Some unsupervised word alignment models such as and, have been based on syntactic structures.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.715846598148346}]}, {"text": "In particular, it has been proven that Inversion Transduction Grammar (ITG) (Wu, 1997), which captures structural coherence between parallel sentences, helps in word alignment ().", "labels": [], "entities": [{"text": "Inversion Transduction Grammar (ITG) (Wu, 1997)", "start_pos": 39, "end_pos": 86, "type": "TASK", "confidence": 0.795686735348268}, {"text": "word alignment", "start_pos": 161, "end_pos": 175, "type": "TASK", "confidence": 0.7810202538967133}]}, {"text": "However, ITG has not been introduced into an agreement constraint so far.", "labels": [], "entities": [{"text": "ITG", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.9288289546966553}]}, {"text": "We propose an alignment method that uses an ITG constraint to encourage agreement between two directional models in consideration of their structural coherence.", "labels": [], "entities": []}, {"text": "Our ITG constraint is based on the Viterbi alignment decided by a bracketing ITG parse tree, and used as a soft constraint in the posterior regularization framework ().", "labels": [], "entities": []}, {"text": "In addition, our ITG constraint works also on word alignments that are not covered by ITG parse trees, as a standard symmetric constraint.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7242887318134308}]}, {"text": "Hence, the proposed method is robust to ITG parse errors compared to an alignment method that uses an ITG directly in model training (e.g.,).", "labels": [], "entities": [{"text": "ITG parse", "start_pos": 40, "end_pos": 49, "type": "TASK", "confidence": 0.705563485622406}]}, {"text": "Word alignment evaluations show that the proposed method achieves significant gains in Fmeasure and alignment error rate (AER) on the KFTT (Neubig, 2011) and the BTEC JapaneseEnglish (Ja-En) corpus ().", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7163139432668686}, {"text": "Fmeasure and alignment error rate (AER)", "start_pos": 87, "end_pos": 126, "type": "METRIC", "confidence": 0.9102461561560631}, {"text": "KFTT (Neubig, 2011)", "start_pos": 134, "end_pos": 153, "type": "DATASET", "confidence": 0.9023830691973368}, {"text": "BTEC JapaneseEnglish (Ja-En) corpus", "start_pos": 162, "end_pos": 197, "type": "DATASET", "confidence": 0.8846723238627116}]}, {"text": "Machine translation evaluations show that our constraint significantly outperforms or is comparable to the baseline symmetric constraint () in BLEU on the KFTT Ja-En and IWSLT 2007 Ja-En corpus).", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7779556810855865}, {"text": "BLEU", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.9958720803260803}, {"text": "KFTT Ja-En and IWSLT 2007 Ja-En corpus", "start_pos": 155, "end_pos": 193, "type": "DATASET", "confidence": 0.8985149349485125}]}], "datasetContent": [{"text": "We compared our proposed ITG constraint (itg) with the baseline agreement constraint (  2011), and Ja-En BTEC Corpus ().", "labels": [], "entities": [{"text": "Ja-En BTEC Corpus", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.8930139740308126}]}, {"text": "We used the first 10K sentence pairs in the training data for the IWSLT 2007 translation task, which were manually annotated with word alignment, as the BTEC Corpus.", "labels": [], "entities": [{"text": "IWSLT 2007 translation task", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.7685596346855164}, {"text": "word alignment", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.6790609210729599}, {"text": "BTEC Corpus", "start_pos": 153, "end_pos": 164, "type": "DATASET", "confidence": 0.9858812391757965}]}, {"text": "In translation evaluations, we used the KFTT and Ja-En IWSLT 2007 translation tasks . shows each corpus size.", "labels": [], "entities": [{"text": "translation evaluations", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.9184715747833252}, {"text": "KFTT", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.9563571214675903}, {"text": "Ja-En IWSLT 2007 translation", "start_pos": 49, "end_pos": 77, "type": "DATASET", "confidence": 0.8247846066951752}]}, {"text": "In each training data set, all words were lowercased and sentences with over 80 words on either side were removed.", "labels": [], "entities": [{"text": "training data set", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.803933580716451}]}, {"text": "We measured the performance of word alignment with AER and F-measure.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7638723254203796}, {"text": "AER", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9989088773727417}, {"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9850950241088867}]}, {"text": "We used only sure alignments for calculating F-measure . We introduced itg and sym into the HMM and IBM Model 4.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.617003321647644}, {"text": "IBM Model 4", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.8784943222999573}]}, {"text": "Training is bootstrapped from IBM Model 1, followed by HMM and IBM Model 4.", "labels": [], "entities": [{"text": "HMM", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.851536750793457}, {"text": "IBM", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.8892699480056763}]}, {"text": "All models were trained with five consecutive iterations.", "labels": [], "entities": []}, {"text": "In the many-to-many alignment extraction, we used the filtering method), where a threshold is optimized on the corresponding AER of the baseline model (i.e., HMM+sym or IBM Model 4+sym) . shows the results of word alignment evaluations 8 , where none denotes that the model has no constraint.", "labels": [], "entities": [{"text": "alignment extraction", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7896082401275635}, {"text": "AER", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.9875875115394592}, {"text": "word alignment evaluations", "start_pos": 209, "end_pos": 235, "type": "TASK", "confidence": 0.8266498645146688}]}, {"text": "In KFTT and BTEC Corpus, itg achieved significant improvement against sym and none on IBM Model 4 (p \u2264 0.05) . However, in the Hansard Corpus, itg shows no improvement against sym.", "labels": [], "entities": [{"text": "KFTT", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.911084771156311}, {"text": "BTEC Corpus", "start_pos": 12, "end_pos": 23, "type": "DATASET", "confidence": 0.9563426375389099}, {"text": "Hansard Corpus", "start_pos": 127, "end_pos": 141, "type": "DATASET", "confidence": 0.9884175062179565}]}, {"text": "This indicates that capturing structural coherence by itg yields a significant benefit to word alignment in a linguistically different language pair such as Ja-En.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.7426581382751465}]}, {"text": "For example, some function words appear more than once in both a source and target sentence, and they are not symmetrically aligned with each other, especially in regards to the Ja-En language pair.", "labels": [], "entities": []}, {"text": "Although the baseline methods tend to be unable to align such long-distance word pairs, the proposed method can correctly catch them because itg can determine the relation of long-distance words.", "labels": [], "entities": []}, {"text": "We discuss more details about the effectiveness of the ITG constraint in Section 4.1.", "labels": [], "entities": []}, {"text": "We measured translation performance with BLEU ().", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9592686891555786}, {"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9988710284233093}]}, {"text": "All language models are 5-gram and trained using SRILM) on target side sentences in the training data.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.830449104309082}]}, {"text": "When extracting phrases, we apply the method proposed by, where many-tomany alignments are generated based on the averages of the posterior probabilities from two directional models . We used the Moses phrase-based SMT systems () for decoding.", "labels": [], "entities": [{"text": "SMT", "start_pos": 215, "end_pos": 218, "type": "TASK", "confidence": 0.894026517868042}]}, {"text": "We set the distortion-limit parameter to infinite 11 , and other pa- rameters as default settings.", "labels": [], "entities": []}, {"text": "Parameter tuning was conducted by 100-best batch MIRA (Cherry and Foster, 2012) with 25 iterations.", "labels": [], "entities": [{"text": "Parameter tuning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7832258641719818}, {"text": "MIRA (Cherry and Foster, 2012)", "start_pos": 49, "end_pos": 79, "type": "DATASET", "confidence": 0.700982429087162}]}, {"text": "shows the average BLEU of five different tunings . In both KFTT and IWSLT 2007, itg achieved significant improvement against both none and sym on HMM model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9994974136352539}, {"text": "KFTT", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.9676347970962524}, {"text": "IWSLT 2007", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.8877931237220764}]}, {"text": "On IBM Model4, itg significantly outperforms none and is comparable to sym in KFTT, while itg significantly outperforms sym and is comparable to none in IWSLT 2007.", "labels": [], "entities": [{"text": "KFTT", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9171985387802124}, {"text": "IWSLT 2007", "start_pos": 153, "end_pos": 163, "type": "DATASET", "confidence": 0.9521898329257965}]}], "tableCaptions": [{"text": " Table 1: The numbers of parallel sentences for each data set.", "labels": [], "entities": []}, {"text": " Table 2: Word alignment performance.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7732533514499664}]}, {"text": " Table 3: Machine translation performance.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8280961811542511}]}]}