{"title": [{"text": "Controlling Output Length in Neural Encoder-Decoders", "labels": [], "entities": []}], "abstractContent": [{"text": "Neural encoder-decoder models have shown great success in many sequence generation tasks.", "labels": [], "entities": [{"text": "sequence generation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7178914695978165}]}, {"text": "However, previous work has not investigated situations in which we would like to control the length of encoder-decoder outputs.", "labels": [], "entities": []}, {"text": "This capability is crucial for applications such as text summarization, in which we have to generate concise summaries with a desired length.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7917343080043793}]}, {"text": "In this paper, we propose methods for controlling the output sequence length for neural encoder-decoder models: two decoding-based methods and two learning-based methods.", "labels": [], "entities": []}, {"text": "1 Results show that our learning-based methods have the capability to control length without degrading summary quality in a summarization task.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.9115938246250153}]}], "introductionContent": [{"text": "Since its first use for machine translation), the encoder-decoder approach has demonstrated great success in many other sequence generation tasks including image caption generation (), parsing (), dialogue response generation () and sentence summarization ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.733866885304451}, {"text": "sequence generation", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.7448851466178894}, {"text": "image caption generation", "start_pos": 156, "end_pos": 180, "type": "TASK", "confidence": 0.8156769871711731}, {"text": "parsing", "start_pos": 185, "end_pos": 192, "type": "TASK", "confidence": 0.9727757573127747}, {"text": "dialogue response generation", "start_pos": 197, "end_pos": 225, "type": "TASK", "confidence": 0.7849589983622233}, {"text": "sentence summarization", "start_pos": 233, "end_pos": 255, "type": "TASK", "confidence": 0.7704368531703949}]}, {"text": "In particular, in this paper we focus on sentence summarization, which as its name suggests, consists of generating shorter versions of sentences for applications such as document summarization () or headline generation (.", "labels": [], "entities": [{"text": "sentence summarization", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.7277936935424805}, {"text": "document summarization", "start_pos": 171, "end_pos": 193, "type": "TASK", "confidence": 0.7149267196655273}, {"text": "headline generation", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.8401376605033875}]}, {"text": "Recently, automatically constructed large training data for sentence summarization, and this has led to the rapid development of neural sentence summarization (NSS) or neural headline generation (NHG) models.", "labels": [], "entities": [{"text": "sentence summarization", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7183702290058136}, {"text": "sentence summarization (NSS)", "start_pos": 136, "end_pos": 164, "type": "TASK", "confidence": 0.8077850341796875}, {"text": "neural headline generation (NHG)", "start_pos": 168, "end_pos": 200, "type": "TASK", "confidence": 0.7593398094177246}]}, {"text": "There are already many studies that address this task ().", "labels": [], "entities": []}, {"text": "One of the essential properties that text summarization systems should have is the ability to generate a summary with the desired length.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.698739618062973}]}, {"text": "Desired lengths of summaries strongly depends on the scene of use, such as the granularity of information the user wants to understand, or the monitor size of the device the user has.", "labels": [], "entities": []}, {"text": "The length also depends on the amount of information contained in the given source document.", "labels": [], "entities": [{"text": "length", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.99443119764328}]}, {"text": "Hence, in the traditional setting of text summarization, both the source document and the desired length of the summary will be given as input to a summarization system.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.6925041228532791}]}, {"text": "However, methods for controlling the output sequence length of encoderdecoder models have not been investigated yet, despite their importance in these settings.", "labels": [], "entities": []}, {"text": "In this paper, we propose and investigate four methods for controlling the output sequence length for neural encoder-decoder models.", "labels": [], "entities": []}, {"text": "The former two methods are decoding-based; they receive the desired length during the decoding process, and the training process is the same as standard encoderdecoder models.", "labels": [], "entities": []}, {"text": "The latter two methods are learning-based; we modify the network architecture to receive the desired length as input.", "labels": [], "entities": []}, {"text": "In experiments, we show that the learning-based methods outperform the decoding-based methods for long (such as 50 or 75 byte) summaries.", "labels": [], "entities": []}, {"text": "We also find that despite this additional length-control capability, the proposed methods remain competitive to existing methods on standard settings of the DUC2004 shared task-1.", "labels": [], "entities": [{"text": "DUC2004 shared task-1", "start_pos": 157, "end_pos": 178, "type": "DATASET", "confidence": 0.8054881493250529}]}], "datasetContent": [{"text": "We trained our models on apart of the Annotated English Gigaword corpus (Napoles et al., 2012), which Rush et al.", "labels": [], "entities": [{"text": "Annotated English Gigaword corpus (Napoles et al., 2012)", "start_pos": 38, "end_pos": 94, "type": "DATASET", "confidence": 0.8661238388581709}]}, {"text": "(2015) constructed for sentence summarization.", "labels": [], "entities": [{"text": "sentence summarization", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7201302647590637}]}, {"text": "We perform preprocessing using the standard script for the dataset . The dataset consists of approximately 3.6 million pairs of the first sentence from each source document and its headline.", "labels": [], "entities": []}, {"text": "shows the length histograms of the summaries in the training set.", "labels": [], "entities": []}, {"text": "The vocabulary size is 116,875 for the source documents and 67,564 for the target summaries including the beginning-ofsentence, end-of-sentence, and unknown word tags.", "labels": [], "entities": []}, {"text": "For LenEmb and LenInit, we input the length of each headline during training.", "labels": [], "entities": [{"text": "LenEmb", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.9157791137695312}, {"text": "LenInit", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9275535941123962}, {"text": "length", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9851345419883728}]}, {"text": "Note that we do not train multiple summarization models for each headline length, but a single model that is capable of controlling the length of its output.", "labels": [], "entities": []}, {"text": "We evaluate the methods on the evaluation set of DUC2004 task-1 (generating very short singledocument summaries).", "labels": [], "entities": [{"text": "DUC2004", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.882111132144928}]}, {"text": "In this task, summarization systems are required to create a very short summary for each given document.", "labels": [], "entities": [{"text": "summarization", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.9820338487625122}]}, {"text": "Summaries over the length limit (75 bytes) will be truncated and there is no bonus for creating a shorter summary.", "labels": [], "entities": []}, {"text": "The evaluation set consists of 500 source documents and 4 human-written (reference) summaries for each source document.", "labels": [], "entities": []}, {"text": "shows the length histograms of the summaries in the evaluation set.", "labels": [], "entities": []}, {"text": "Note that the human-written summaries are not always as long as 75 bytes.", "labels": [], "entities": []}, {"text": "We used three variants of ROUGE) as evaluation metrics: ROUGE-1 (unigram), ROUGE-2 (bigram), and ROUGE-L (longest common subsequence).", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.917900562286377}, {"text": "ROUGE-2", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.8964771032333374}, {"text": "ROUGE-L", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9292473793029785}]}, {"text": "The two-sided permutation test was used for statistical significance testing (p \u2264 0.05).", "labels": [], "entities": [{"text": "statistical significance testing", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.8369501630465189}]}, {"text": "source five-time world champion michelle kwan withdrew from the #### us figure skating championships on wednesday , but will petition us skating officials for the chance to compete at the #### turin olympics . reference injury leaves kwan 's olympic hopes in limbo f ixLen kwan withdraws from us gp kwan withdraws from us skating championships kwan pulls out of us figure skating championships for turin olympics f ixRng kwan withdraws from us gp kwan withdraws from figure skating championships kwan pulls out of us figure skating championships for turin olympics bid LenEmb kwan withdraws from us skating (50) kwan withdraws from us figure skating championships world champion kwan withdraws from #### olympic figure skating championships LenInit kwan quits us figure skating (50) kwan withdraws from #### us figure skating worlds kwan withdraws from #### us figure skating championships for #### olympics tion methods, we use the same reference summaries.", "labels": [], "entities": []}, {"text": "Note that, f ixLen and f ixRng generate the summaries with a hard constraint due to their decoding process, which allows them to follow the hard constraint on length.", "labels": [], "entities": []}, {"text": "Hence, when we calculate the scores of LenEmb and LenInit, we impose a hard constraint on length to make the comparison fair (i.e. LenEmb (0,L) and LenInit (0,L) in the table).", "labels": [], "entities": [{"text": "LenEmb", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.9289098978042603}, {"text": "LenInit", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.915595293045044}, {"text": "length", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9856171011924744}]}, {"text": "Specifically, we use the same beam search as that for f ixRng with minimum length of 0.", "labels": [], "entities": []}, {"text": "For the purpose of showing the length control capability of LenEmb and LenInit, we show at the bottom two lines the results of the standard beam search without the hard constraints on the length 6 . We will use the results of LenEmb (0,\u221e) and LenInit (0,\u221e) in the discussions in Sections 6.2 and 6.3.", "labels": [], "entities": []}, {"text": "The results show that the learning-based meth-6 f ixRng is equivalence to the standard beam search when we set the range as (0, \u221e).", "labels": [], "entities": []}, {"text": "ods (LenEmb and LenInit) tend to outperform decoding-based methods (f ixLen and f ixRng) for the longer summaries of 50 and 75 bytes.", "labels": [], "entities": []}, {"text": "However, in the 30-byte setting, there is no significant difference between these two types of methods.", "labels": [], "entities": []}, {"text": "We hypothesize that this is because average compression rate in the training data is 30%) while the 30-byte setting forces the model to generate summaries with 15.38% in average compression rate, and thus the learning-based models did not have enough training data to learn compression at such a steep rate.", "labels": [], "entities": []}, {"text": "show examples from the validation set of the Annotated Gigaword Corpus.", "labels": [], "entities": [{"text": "Annotated Gigaword Corpus", "start_pos": 45, "end_pos": 70, "type": "DATASET", "confidence": 0.8791712919871012}]}, {"text": "The tables show that all models, including both learningbased methods and decoding-based methods, can often generate well-formed sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: ROUGE scores with various length limits. The scores with  *  are significantly worse than the best score in  the column (bolded).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9903936982154846}, {"text": "length", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9692248106002808}]}, {"text": " Table 4: Final state of the beam when the learning-based model is instructed to output a 30 byte summary for the  source document in Table 3.", "labels": [], "entities": []}, {"text": " Table 5: Comparison with existing studies for  DUC2004.  Note that top four rows are  reproduced from Table 1.", "labels": [], "entities": [{"text": "DUC2004", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9197196960449219}]}]}