{"title": [{"text": "Comparing Computational Cognitive Models of Generalization in a Language Acquisition Task", "labels": [], "entities": [{"text": "Comparing Computational Cognitive Models of Generalization", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.5216802457968394}]}], "abstractContent": [{"text": "Natural language acquisition relies on appropriate generalization: the ability to produce novel sentences, while learning to restrict productions to acceptable forms in the language.", "labels": [], "entities": [{"text": "Natural language acquisition", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7168176968892416}]}, {"text": "Psycholinguists have proposed various properties that might play a role in guiding appropriate generalizations, looking at learning of verb alternations as a testbed.", "labels": [], "entities": []}, {"text": "Several computational cognitive models have explored aspects of this phenomenon, but their results are hard to compare given the high variability in the linguistic properties represented in their input.", "labels": [], "entities": []}, {"text": "In this paper, we directly compare two recent approaches, a Bayesian model and a connectionist model, in their ability to repli-cate human judgments of appropriate generalizations.", "labels": [], "entities": []}, {"text": "We find that the Bayesian model more accurately mimics the judgments due to its richer learning mechanism that can exploit distributional properties of the input in a manner consistent with human behaviour.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native speakers of a language are mostly able to generalize appropriately beyond the observed data while avoiding overgeneralizations.", "labels": [], "entities": []}, {"text": "A testbed area for studying generalization behavior in language acquisition is verb alternations -i.e., learning the patterns of acceptability of alternative constructions for expressing similar meanings.", "labels": [], "entities": []}, {"text": "For example, English speakers readily use anew verb like text in both the double-object (DO) construction (\"text me the details\") and the prepositional-dative (PD) (\"text the details to me\") -an instance of the dative alternation.", "labels": [], "entities": []}, {"text": "However, speakers avoid overgeneralizing the DO construction to verbs such as explain that resist its use (\"?explain me the details\"), even though they occur with analogous arguments in the PD alternative (\"explain the details to me\").", "labels": [], "entities": []}, {"text": "Psycholinguistic studies have focused on the possible properties of natural language that enable such generalization while constraining it to acceptable forms.", "labels": [], "entities": []}, {"text": "Initially, children are linguistically conservative: they generally use verbs in constructions that are very close to exemplars in the input (.", "labels": [], "entities": []}, {"text": "Children reach adult-like competence by gradually forming more general associations of constructions to meaning that allow them to extend verb usages to unwitnessed forms.", "labels": [], "entities": []}, {"text": "Much work has emphasized the role of verb classes that capture the regularities across semanticallysimilar verbs, enabling appropriate generalization (e.g.,.", "labels": [], "entities": []}, {"text": "Usage-based approaches have argued that such class-based behaviour can arise in learning through the clustering of observed usages that share semantic and syntactic properties (e.g.,.", "labels": [], "entities": []}, {"text": "A number of studies also reveal that the statistical properties of the language play a central role in limiting generalization (e.g.,).", "labels": [], "entities": []}, {"text": "Individual verbs often show statistical biases that favor their appearance in one construction over another (;).", "labels": [], "entities": []}, {"text": "For example, while both give and push can occur in either DO or PD constructions, give strongly favors the DO construction (\"give me the box\"), while push strongly favors the PD (\"push the box to me\") ().", "labels": [], "entities": []}, {"text": "Generally, the more frequent a verb is overall, the less likely speakers are to extend it to an unobserved construction.", "labels": [], "entities": []}, {"text": "In addition, when a verb repeatedly occurs in one construction when an alternative construction could have been appropriate, speakers appear to learn that the verb is inappropriate in the alternative, regardless of its overall frequency.", "labels": [], "entities": []}, {"text": "Given these observations, it has been argued that both the semantic and statistical properties of a verb underlie its degree of acceptability in alternating constructions (e.g.,.", "labels": [], "entities": []}, {"text": "Recently, propose a computational model designed to study the role of verb semantics and frequency in the acquisition of the dative alternation.", "labels": [], "entities": [{"text": "acquisition of the dative alternation", "start_pos": 106, "end_pos": 143, "type": "TASK", "confidence": 0.68857901096344}]}, {"text": "However, they only evaluate their model preferences for one of the two constructions, which does not provide a full picture of the alternation behaviour; moreover, they incorporate certain assumptions about the input that may not match the properties of naturalistic data.", "labels": [], "entities": []}, {"text": "In this paper, we compare the model of to the Bayesian model of that offers a general framework of verb construction learning.", "labels": [], "entities": [{"text": "verb construction learning", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.8424593806266785}]}, {"text": "We replicate the approach taken in in order to provide appropriate comparisons, but we also extend the experimental settings and analysis to enable a more fulsome evaluation, on data with more naturalistic statistical properties.", "labels": [], "entities": []}, {"text": "Our results show that the Bayesian model provides a better fit to the psycholinguistic data, which we suggest is due to its richer learning mechanism: its two-level clustering approach can exploit distributional properties of the input in a manner consistent with human generalization behaviour.", "labels": [], "entities": []}], "datasetContent": [{"text": "As in, to test the model preferences for the DO or PD, the models are presented with an input consisting of a verb lexeme, its semantic features, and the transfer feature set to 1 (i.e., this is a \"transfer\" semantics suitable fora dative construction).", "labels": [], "entities": []}, {"text": "For the AB model, we measure preferences for each construction as the activation rate of each of the corresponding output nodes, as in Ambridge and Blything.", "labels": [], "entities": []}, {"text": "In the BFS model, the preference for each construction is measured as its likelihood over the learned clusters given the verb and its semantic features.", "labels": [], "entities": []}, {"text": "Formally, the prediction in the Bayesian model is: where sis the predicted syntactic construction (DO or PD) and F testis the set of test features representing a verb v and its corresponding semantic features.", "labels": [], "entities": []}, {"text": "P (s|k) is the probability of the syntactic pattern feature having the value sin cluster k, calculated as the proportional occurrences of sin k.", "labels": [], "entities": [{"text": "P", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8984858393669128}]}, {"text": "P (k|F test ) is the probability of cluster k given test features F test , calculated as in Eqn.", "labels": [], "entities": [{"text": "P (k|F test )", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.7892336760248456}]}, {"text": "Following, we calculate P (k|F test ) in two ways, using just the constructions (level one) or both the classes (level two) and the constructions, to see whether verb class knowledge improves performance.", "labels": [], "entities": [{"text": "P (k|F test )", "start_pos": 24, "end_pos": 37, "type": "METRIC", "confidence": 0.8111108030591693}]}, {"text": "Using solely the construction level, the probability of k reflects the frequency with which usages of verb v occur in cluster k.", "labels": [], "entities": []}, {"text": "Using the verb class level in addition, the distribution of the verb over classes in the second level is combined with the distribution of those classes over the constructions in level one, to get the likelihood of k.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 201, "end_pos": 211, "type": "METRIC", "confidence": 0.9796180129051208}]}, {"text": "These model preferences of the verbs fora dative construction are compared, using Pearson correlation, to the DO/PD acceptability judgment data collected from adult participants by.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 82, "end_pos": 101, "type": "METRIC", "confidence": 0.966911643743515}]}, {"text": "Note that Ambridge and Blything only evaluate their model's preferences for verbs to take the DO construction.", "labels": [], "entities": []}, {"text": "To fully understand the preference and generalization patterns, we also analyze the results for the PD preference.", "labels": [], "entities": []}, {"text": "Even more importantly, we calculate the difference between the preferences for the DO and the PD constructions per verb, and compare these to analogous scores for the human data, as suggested by.", "labels": [], "entities": []}, {"text": "The DO\u2212PD difference scores, which we will refer to as the verb bias score, are crucial because, as in the human data, it is these scores that accurately capture a learner's relative preference fora construction given a particular verb.", "labels": [], "entities": [{"text": "DO\u2212PD difference scores", "start_pos": 4, "end_pos": 27, "type": "METRIC", "confidence": 0.9381020903587342}, {"text": "verb bias score", "start_pos": 59, "end_pos": 74, "type": "METRIC", "confidence": 0.7164691587289175}]}, {"text": "We examine the ability of each model to match the dative construction preferences of human judgments, as described just above, under two different experimental scenarios.", "labels": [], "entities": []}, {"text": "In Section 5.1, we follow the experimental settings of.", "labels": [], "entities": []}, {"text": "We replicate their results on the AB model showing correlation with human DO preferences, but find that only the BFS model achieves a significant correlation with the crucial verb bias score that appropriately assesses per-verb preference.", "labels": [], "entities": [{"text": "BFS", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9236726760864258}]}, {"text": "We adjust the experimental settings in Section 5.2 to use more naturalistic input data -by training in proportion to raw frequencies and excluding the artificial other construction -achieving an improvement in the verb bias score for both models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Frequency data for the dative verbs in the", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8196402192115784}]}, {"text": " Table 2: Pearson correlation values between human and", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9066329300403595}]}, {"text": " Table 3: Pearson correlation values between human and", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9077510833740234}]}]}