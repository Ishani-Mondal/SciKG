{"title": [], "abstractContent": [{"text": "Community-driven Question Answering (CQA) systems that crowdsource experiential information in the form of questions and answers and have accumulated valuable reusable knowledge.", "labels": [], "entities": [{"text": "Community-driven Question Answering (CQA)", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7432616402705511}]}, {"text": "Clustering of QA datasets from CQA systems provides a means of organizing the content to ease tasks such as manual curation and tagging.", "labels": [], "entities": []}, {"text": "In this paper, we present a clustering method that exploits the two-part question-answer structure in QA datasets to improve clustering quality.", "labels": [], "entities": [{"text": "QA datasets", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.759710967540741}]}, {"text": "Our method, MixKMeans, composes question and answer space similarities in away that the space on which the match is higher is allowed to dominate.", "labels": [], "entities": []}, {"text": "This construction is motivated by our observation that semantic similarity between question-answer data (QAs) could get localized in either space.", "labels": [], "entities": []}, {"text": "We empirically evaluate our method on a variety of real-world labeled datasets.", "labels": [], "entities": []}, {"text": "Our results indicate that our method significantly outperforms state-of-the-art clustering methods for the task of clustering question-answer archives.", "labels": [], "entities": []}], "introductionContent": [{"text": "Community-based Question Answering (CQA) systems such as Yahoo!", "labels": [], "entities": [{"text": "Question Answering (CQA)", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7978346288204193}]}, {"text": "Answers 1 , StackOverflow 2 and Baidu Zhidao have become dependable sources of knowledge to solve common user problems.", "labels": [], "entities": [{"text": "Baidu Zhidao", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8547514975070953}]}, {"text": "Unlike factoid question answering , CQA systems focus on crowdsourcing how and why questions and their answers.", "labels": [], "entities": [{"text": "factoid question answering", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.7347478171189626}]}, {"text": "As is the case with any system where content is generated by web users, the generated content would be of varying quality, reliability, readability and abstraction.", "labels": [], "entities": []}, {"text": "Thus, manual curation of such datasets is inevitable to weed out low quality and duplicate content to ensure user satisfaction.", "labels": [], "entities": []}, {"text": "A natural way to aid manual curation of such broad-based CQA archives is to employ clustering so that semantically related QAs are grouped together; this would help organize the corpus in away that experts engaged in manual curation be assigned specific clusters relating to areas of their expertise.", "labels": [], "entities": []}, {"text": "Clustering also provides a platform to enable tagging the QA dataset; cluster topics could be used as tags, or other QAs in the same cluster could be tagged as being related to a QA.", "labels": [], "entities": [{"text": "QA dataset", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.6580211371183395}]}, {"text": "The fundamental difference between CQA archives and general text document collections is the existence of a two-part structure in QAs and the difference in lexical \"character\" between the question and answer parts.", "labels": [], "entities": []}, {"text": "This lexical chasm (i.e., gap) () between question and answer parts has been a subject of much study, especially, in the context of improving QA retrieval.", "labels": [], "entities": [{"text": "QA retrieval", "start_pos": 142, "end_pos": 154, "type": "TASK", "confidence": 0.854410856962204}]}, {"text": "In this paper, we consider using the two-part structure in QAs for clustering CQA datasets.", "labels": [], "entities": [{"text": "clustering", "start_pos": 67, "end_pos": 77, "type": "TASK", "confidence": 0.8744102716445923}, {"text": "CQA datasets", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.7323013246059418}]}, {"text": "Motivating Example: lists four example QAs from the context of a CQA system focused on addressing myriad technical issues.", "labels": [], "entities": []}, {"text": "These QAs have been tagged in the table with a manually identified root-cause to aid understanding; the root-cause is not part of the CQA data per se.", "labels": [], "entities": [{"text": "CQA data", "start_pos": 134, "end_pos": 142, "type": "DATASET", "confidence": 0.9708456099033356}]}, {"text": "QA1 and QA2 are seen to address related issues pertaining to routers, whereas QA3 and QA4 are focused on the same nar-row issue dealing with java libraries.", "labels": [], "entities": []}, {"text": "Since QA1 and QA2 address different problems, they may not be expected to be part of the same cluster in finegrained clusterings.", "labels": [], "entities": []}, {"text": "On the other hand, the solutions suggested in QA3 and QA4 are distinct and different legitimate solutions to the same problem cause.", "labels": [], "entities": [{"text": "QA3", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.9174398183822632}, {"text": "QA4", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.7950187921524048}]}, {"text": "Thus, from a semantics perspective, it is intuitive that QA3 and QA4 should be part of the same cluster in any clustering of the CQA dataset to aid actioning on them together; a human expert might decide to merge the question parts and tag one of the answers as an alternative answer.", "labels": [], "entities": [{"text": "CQA dataset", "start_pos": 129, "end_pos": 140, "type": "DATASET", "confidence": 0.9529591202735901}]}, {"text": "Let us now examine the lexical relatedness between the pairs as illustrated in.", "labels": [], "entities": []}, {"text": "State-of-the-art text similarity measures that quantify word overlaps are likely to judge QA1 and QA2 to be having a medium similarity when either the question-part or the answerpart are considered.", "labels": [], "entities": []}, {"text": "For the pair (QA3, QA4), the question-part similarity would be judged to be high and the answer-part similarity as low.", "labels": [], "entities": []}, {"text": "Thus, the high similarity between the root-causes of QA3 and QA4 manifest primarily in their question-parts.", "labels": [], "entities": []}, {"text": "Analogously, we observed that some QAs involving the same root-cause lead to high answer-part similarity despite poor question-part similarity.", "labels": [], "entities": []}, {"text": "This is especially true in cases involving suggestion of the same sequence of solution steps despite the question-part being divergent due to focusing on different symptoms of the same complex problem.", "labels": [], "entities": []}, {"text": "From these observations, we posit that high similarities on either the question-space or answer-space is indicative of semantic relatedness.", "labels": [], "entities": []}, {"text": "Any clustering method that uses a sum, average or weighted sum aggregation function to arrive at pair-wise similarities, such as a K-Means clustering that treats the collated QA as a single document, would intuitively be unable to heed to such differential manifestation of semantic similarities across the two parts.", "labels": [], "entities": []}, {"text": "Our Contributions: We address the problem of harnessing the two-part structure in QA pairs to improve clustering of CQA data.", "labels": [], "entities": []}, {"text": "Based on our observations on CQA data such as those illustrated in the example, we propose a clustering approach, MixKMeans, that composes similarities (dissimilarities) in the question and answer spaces using a max (min) operator style aggregation.", "labels": [], "entities": [{"text": "CQA data", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.8147760927677155}]}, {"text": "Through abundant empirical analysis on real-world CQA data, we illustrate that our method outperforms the state-of-theart approaches for the task of CQA clustering.", "labels": [], "entities": [{"text": "CQA clustering", "start_pos": 149, "end_pos": 163, "type": "TASK", "confidence": 0.834472268819809}]}], "datasetContent": [{"text": "Datasets: We use the recently released data col-lection,, for our experimental evaluation.", "labels": [], "entities": []}, {"text": "Unlike most other datasets, this has each QA labeled with a set of related QAs, as alluded to in Section 3; this makes automated evaluation feasible in lieu of a laborious user study.", "labels": [], "entities": []}, {"text": "We use the android, gis, stats and physics datasets from the CQADupStack collection, with our choice of datasets motivated by dataset size.", "labels": [], "entities": [{"text": "CQADupStack collection", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.981605589389801}]}, {"text": "These datasets comprise 2193, 3726, 4004 and 5044 QAs respectively.", "labels": [], "entities": []}, {"text": "Baselines: We use two baselines from literature in our study, (i) AENN (, (ii) GHF-ART ().", "labels": [], "entities": [{"text": "AENN", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9942130446434021}, {"text": "GHF-ART", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.824786901473999}]}, {"text": "AENN, as alluded to in Section 2, refers to the K-Means clustering in the latent space learnt by correlated auto-encoders across the Q-A subspaces.", "labels": [], "entities": [{"text": "AENN", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9725733995437622}]}, {"text": "AENN requires triplets of the form in the training phase; we populate the other answer part by the answer to a related question from the dataset (it maybe noted that this is advantageous to AENN since it gets to 'see' some related labelings in the training, whereas other methods can't).", "labels": [], "entities": [{"text": "AENN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6880866885185242}]}, {"text": "GHF-ART is the state-of-the-art multi-modal clustering approach that is targeted towards scenarios that involve a text modality.", "labels": [], "entities": [{"text": "GHF-ART", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8482432961463928}]}, {"text": "Unlike typical clustering algorithms that can generate a pre-specified (k) number of clusters, the number of clusters in the GHF-ART output is controlled by a vigilance parameter, \u03c1.", "labels": [], "entities": [{"text": "GHF-ART output", "start_pos": 125, "end_pos": 139, "type": "DATASET", "confidence": 0.8711268603801727}]}, {"text": "Lower values of \u03c1 result in smaller number of clusters and vice versa.", "labels": [], "entities": []}, {"text": "A third intuitive baseline is the degenerate x = 1 instantiation of MixKMeans, which we will denote as X1.", "labels": [], "entities": [{"text": "MixKMeans", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.9388481378555298}]}, {"text": "We are interested in evaluating the improvement achieved by MixKMeans over the best possible instantiation of X1; towards that, for every setting denoted by the combination, we do a search over possible positive values of w q and w a within the locus of the line w q + w a = 1.", "labels": [], "entities": []}, {"text": "It maybe noted that this search space includes simple QA clustering using K-Means, being the case where w q = w a = 0.5.", "labels": [], "entities": [{"text": "QA clustering", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.8074702322483063}]}, {"text": "We collect the best result of X1 from across the grid-search for each setting.", "labels": [], "entities": []}, {"text": "This approach, which we will denote as X1 * , while impractical in real scenarios due to usage of labeled data, gives an empirical upper bound of the accuracy of X1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9995123147964478}]}, {"text": "Experimental Setup: We use a latent space di-.", "labels": [], "entities": []}, {"text": "We use the Fscore 7 measure to experimentally compare the approaches.", "labels": [], "entities": [{"text": "Fscore 7 measure", "start_pos": 11, "end_pos": 27, "type": "METRIC", "confidence": 0.9814633727073669}]}, {"text": "The F-score is computed using the related labellings in the CQADupStack data, in a manner as described in Section 3.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9948042035102844}, {"text": "CQADupStack data", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9901974499225616}]}, {"text": "As pointed out therein, due to the sparse labellings, the F-score may only be regarded as a loose lower bound of their real values on a fully-labeled dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9951045513153076}]}], "tableCaptions": []}