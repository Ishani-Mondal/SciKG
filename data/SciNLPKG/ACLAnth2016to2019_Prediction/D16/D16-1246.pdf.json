{"title": [{"text": "A Stacking Gated Neural Architecture for Implicit Discourse Relation Classification", "labels": [], "entities": [{"text": "Implicit Discourse Relation", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.7627060214678446}]}], "abstractContent": [{"text": "Discourse parsing is considered as one of the most challenging natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8784817457199097}]}, {"text": "Implicit discourse relation classification is the bottleneck for discourse parsing.", "labels": [], "entities": [{"text": "Implicit discourse relation classification", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7554601579904556}, {"text": "discourse parsing", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7075356990098953}]}, {"text": "Without the guide of explicit discourse connectives, the relation of sentence pairs are very hard to be inferred.", "labels": [], "entities": []}, {"text": "This paper proposes a stacking neural network model to solve the classification problem in which a convolu-tional neural network (CNN) is utilized for sentence modeling and a collaborative gated neural network (CGNN) is proposed for feature transformation.", "labels": [], "entities": [{"text": "sentence modeling", "start_pos": 151, "end_pos": 168, "type": "TASK", "confidence": 0.7850667834281921}, {"text": "feature transformation", "start_pos": 233, "end_pos": 255, "type": "TASK", "confidence": 0.7422948479652405}]}, {"text": "Our evaluation and comparisons show that the proposed model outper-forms previous state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "As a fundamental task in natural language processing (NLP), discourse parsing entails the discovery of the latent relational structure in multi-sentence level analysis.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.7884889344374338}, {"text": "discourse parsing", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7051620632410049}, {"text": "multi-sentence level analysis", "start_pos": 138, "end_pos": 167, "type": "TASK", "confidence": 0.6271036167939504}]}, {"text": "It is also central to many practical tasks such as question answering (), machine translation and automatic summarization ().", "labels": [], "entities": [{"text": "question answering", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9189155101776123}, {"text": "machine translation", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8475505113601685}, {"text": "summarization", "start_pos": 108, "end_pos": 121, "type": "TASK", "confidence": 0.7295724749565125}]}, {"text": "Discourse parsing is also the shared task of, and many previous works previous on this task.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8678736686706543}]}, {"text": "Ina discourse parser, implicit relation recognition has been the bottleneck due to lack of explicit connectives (like \"because\" or \"and\") that can be strong indicators for the senses between adjacent clauses ().", "labels": [], "entities": [{"text": "implicit relation recognition", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.6398584445317587}]}, {"text": "This work therefore focuses on implicit relation recognition that infers the senses of the discourse relations within adjacent sentence pairs.", "labels": [], "entities": [{"text": "implicit relation recognition", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.5905814071496328}]}, {"text": "Most previous works on PDTB implicit relation recognition only focus on one-versus-others binary classification problems of the top level four classes.", "labels": [], "entities": [{"text": "PDTB implicit relation recognition", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.7945505231618881}]}, {"text": "Traditional classification methods directly rely on feature engineering, based on bag-of-words, production rules, and some linguistically-informed features ().", "labels": [], "entities": []}, {"text": "However, discourse relations root in semantics, which maybe hard to recover from surface level feature, thus these methods did not report satisfactory performance.", "labels": [], "entities": []}, {"text": "Recently, neural network (NN) models have shown competitive or even better results than traditional linear models with handcrafted sparse features ().", "labels": [], "entities": []}, {"text": "They have been proved to be effective for many tasks, also including discourse parsing.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.78720822930336}]}, {"text": "adopt recursive neural network and incorporate with entity-augmented distributed semantics.", "labels": [], "entities": []}, {"text": "explore a shallow convolutional neural network and achieve competitive performance.", "labels": [], "entities": []}, {"text": "Although simple neural network has been shown effective, the result has not been quite satisfactory which suggests that there is still space for improving.", "labels": [], "entities": []}, {"text": "The concerned task could be straightforwardly formalized as a sentence-pair classification problem, which needs inferring senses solely based on the two arguments without cues of connectives.", "labels": [], "entities": [{"text": "sentence-pair classification", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.7297070920467377}]}, {"text": "Two problems should be carefully handled in this task: how to model sentences and how to capture the interactions between the two arguments.", "labels": [], "entities": []}, {"text": "The former could be addressed by Convolutional Neural Network (CNN) which has been proved effective for sentence modeling (, while the latter is the key problem, which might need deep semantic analysis for the interaction of two arguments.", "labels": [], "entities": [{"text": "sentence modeling", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7822136580944061}]}, {"text": "To solve the latter problem, we propose collaborative gated neural network (CGNN) which is partially inspired by Highway Network whose gate mechanism achieves success (.", "labels": [], "entities": []}, {"text": "Our method will be evaluated on the benchmark dataset against state-of-the-art methods.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 briefly describes our model, introducing the stacking architecture of CNN and CGNN, Section 3 shows the experiments and analysis, and Section 4 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: F1 scores (%) with different models.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9724847078323364}]}, {"text": " Table 2: Comparisons of F1 scores (%) (symbol + means EXP. with Entrel).", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9766456186771393}, {"text": "EXP.", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9719440340995789}, {"text": "Entrel", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9672689437866211}]}, {"text": " Table 3: Comparisons of F1 scores (%) (EXP. without Entrel).", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9695307612419128}, {"text": "EXP.", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9451393485069275}, {"text": "Entrel", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9581514000892639}]}]}