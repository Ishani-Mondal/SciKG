{"title": [{"text": "Distinguishing Past, On-going, and Future Events: The EventStatus Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "Determining whether a major societal event has already happened, is still ongoing , or may occur in the future is crucial for event prediction , timeline generation, and news sum-marization.", "labels": [], "entities": [{"text": "event prediction", "start_pos": 126, "end_pos": 142, "type": "TASK", "confidence": 0.7718968391418457}, {"text": "timeline generation", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.7078490555286407}]}, {"text": "We introduce anew task and anew corpus, EventStatus, which has 4500 En-glish and Spanish articles about civil unrest events labeled as PAST, ONGOING , or FUTURE.", "labels": [], "entities": [{"text": "PAST", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.8421663045883179}, {"text": "ONGOING", "start_pos": 141, "end_pos": 148, "type": "METRIC", "confidence": 0.959160327911377}, {"text": "FUTURE", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.8836264610290527}]}, {"text": "We show that the temporal status of these events is difficult to classify because local tense and aspect cues are often lacking, time expressions are insufficient, and the linguistic contexts have rich semantic composi-tionality.", "labels": [], "entities": []}, {"text": "We explore two approaches for event status classification: (1) a feature-based SVM classifier augmented with a novel induced lexicon of future-oriented verbs, such as \"threat-ened\" and \"planned\", and (2) a convolutional neural net.", "labels": [], "entities": [{"text": "event status classification", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.7015990912914276}]}, {"text": "Both types of classifiers improve event status recognition over a state-of-the-art TempEval model, and our analysis offers linguistic insights into the semantic composition-ality challenges for this new task.", "labels": [], "entities": [{"text": "event status recognition", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6392731169859568}]}], "introductionContent": [{"text": "When a major societal event is mentioned in the news (e.g., civil unrest, terrorism, natural disaster), it is important to understand whether the event has already happened (PAST), is currently happening (ON-GOING), or may happen in the future (FUTURE).", "labels": [], "entities": [{"text": "PAST)", "start_pos": 174, "end_pos": 179, "type": "METRIC", "confidence": 0.9636106491088867}, {"text": "ON-GOING", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9931371212005615}, {"text": "FUTURE)", "start_pos": 245, "end_pos": 252, "type": "METRIC", "confidence": 0.9715338051319122}]}, {"text": "We introduce anew task and corpus for studying the temporal/aspectual properties of major events.", "labels": [], "entities": []}, {"text": "The EventStatus corpus consists of 4500 English and Spanish news articles about civil unrest events, such as protests, demonstrations, marches, and strikes, in which each event is annotated as PAST, ON-GOING, or FUTURE (sublabeled as PLANNED, ALERT or POSSIBLE).", "labels": [], "entities": [{"text": "PAST", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.9816480875015259}, {"text": "ON-GOING", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9176842570304871}, {"text": "FUTURE", "start_pos": 212, "end_pos": 218, "type": "METRIC", "confidence": 0.9953693747520447}, {"text": "ALERT", "start_pos": 243, "end_pos": 248, "type": "METRIC", "confidence": 0.9288759231567383}]}, {"text": "This task bridges event extraction research and temporal research in the tradition of TIMEBANK ( and.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.8037881553173065}, {"text": "TIMEBANK", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.8466088771820068}]}, {"text": "Previous corpora have begun this association: TIMEBANK, for example, includes temporal relations linking events with Document Creation Times (DCT).", "labels": [], "entities": [{"text": "Document Creation Times (DCT)", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.7226846317450205}]}, {"text": "But the EventStatus task and corpus offers several new research directions.", "labels": [], "entities": []}, {"text": "First, major societal events are often discussed before they happen, or while they are still happening, because they have the potential to impact a large number of people.", "labels": [], "entities": []}, {"text": "News outlets frequently report on impending natural disasters (e.g., hurricanes), anticipated disease outbreaks (e.g., Zika virus), threats of terrorism, and plans or warnings of potential civil unrest (e.g., strikes and protests).", "labels": [], "entities": []}, {"text": "Traditional event extraction research has focused primarily on recognizing events that have already happened.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7696380317211151}]}, {"text": "Furthermore, the linguistic contexts of on-going and future events involve complex compositionality, and features like explicit time expressions are less useful.", "labels": [], "entities": []}, {"text": "Our results demonstrate that a state-of-the-art TempEval system has difficulty identifying on-going and future events, mislabeling examples like these: Second, we intentionally created the EventStatus corpus to concentrate on one particular event frame (class of events): civil unrest.", "labels": [], "entities": []}, {"text": "In contrast, previous temporally annotated corpora focus on a wide variety of events.", "labels": [], "entities": []}, {"text": "Focusing on one frame (semantic depth instead of breadth) makes this corpus analogous to domain-specific event extraction data sets, and therefore appropriate for evaluating rich tasks like event extraction and temporal question answering, which require more knowledge about event frames and schemata than might be represented in large broad corpora like TIMEBANK (.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 190, "end_pos": 206, "type": "TASK", "confidence": 0.7370053827762604}, {"text": "temporal question answering", "start_pos": 211, "end_pos": 238, "type": "TASK", "confidence": 0.6322033703327179}]}, {"text": "Third, the EventStatus corpus focuses on specific instances of high-level events, in contrast to the lowlevel and often non-specific or generic events that dominate other temporal datasets.", "labels": [], "entities": [{"text": "EventStatus corpus", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.7395071089267731}]}, {"text": "1 Mentions of specific events are much more likely to be realized in non-finite form (as nouns or infinitives, such as \"the strike\" or \"to protest\") than randomly selected event keywords.", "labels": [], "entities": []}, {"text": "In breadth-based corpora like the EventCorefBank (ECB) corpus), 34% of the events have non-finite realization; in TIMEBANK, 45% of the events have non-finite realization.", "labels": [], "entities": [{"text": "EventCorefBank (ECB) corpus", "start_pos": 34, "end_pos": 61, "type": "DATASET", "confidence": 0.6682707369327545}]}, {"text": "By contrast, in a frame-based corpus like ACE2005), 59% of the events have non-finite forms.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9252875447273254}]}, {"text": "In the EventStatus corpus, 80% of the events have non-finite forms.", "labels": [], "entities": [{"text": "EventStatus corpus", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.7799245119094849}]}, {"text": "Whether this is due to differences in labeling or to intrinsic properties of these events, the result is that they are much harder to label because tense and aspect are less available than for events realized as finite verbs.", "labels": [], "entities": []}, {"text": "Fourth, the EventStatus data set is multilingual: we collected data from both English and Spanish texts, allowing us to compare events representing the same event frame across two languages that are known to differ in their typological properties for describing events.", "labels": [], "entities": [{"text": "EventStatus data set", "start_pos": 12, "end_pos": 32, "type": "DATASET", "confidence": 0.8339821696281433}]}, {"text": "Using the new EventStatus corpus, we investigate two approaches for recognizing the temporal status of events.", "labels": [], "entities": [{"text": "EventStatus corpus", "start_pos": 14, "end_pos": 32, "type": "DATASET", "confidence": 0.733063206076622}, {"text": "recognizing the temporal status of events", "start_pos": 68, "end_pos": 109, "type": "TASK", "confidence": 0.812514454126358}]}, {"text": "We create a SVM classifier that incorporates features drawn from prior TempEval work) as well as anew automatically induced For example in TIMEBANK almost half the annotated events (3720 of 7935) are hypothetical or generic, i.e., PERCEP-TION, REPORTING, ASPECTUAL, I ACTION, STATE or I STATE rather than the specific OCCURRENCE.", "labels": [], "entities": [{"text": "PERCEP-TION", "start_pos": 231, "end_pos": 242, "type": "METRIC", "confidence": 0.9446431994438171}, {"text": "REPORTING", "start_pos": 244, "end_pos": 253, "type": "METRIC", "confidence": 0.9124157428741455}, {"text": "ASPECTUAL", "start_pos": 255, "end_pos": 264, "type": "METRIC", "confidence": 0.8547191023826599}, {"text": "STATE", "start_pos": 276, "end_pos": 281, "type": "METRIC", "confidence": 0.8646884560585022}]}, {"text": "lexicon of 411 English and 348 Spanish \"futureoriented\" matrix verbs-verbs like \"threaten\" and \"fear\" whose complement clause or nominal direct object argument is likely to describe a future event.", "labels": [], "entities": []}, {"text": "We show that the SVM outperforms a state-of-theart TempEval system and that the induced lexicon further improves performance for both English and Spanish.", "labels": [], "entities": []}, {"text": "We also introduce a Convolutional Neural Network (CNN) to detect the temporal status of events.", "labels": [], "entities": []}, {"text": "Our analysis shows that it successfully models semantic compositionality for some challenging temporal contexts.", "labels": [], "entities": [{"text": "semantic compositionality", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7267079651355743}]}, {"text": "The CNN model again improves performance in both English and Spanish, providing strong initial results for this new task and corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all subsequent evaluations, we use gold event mentions.", "labels": [], "entities": []}, {"text": "We randomly sampled around 20% of the annotated documents as the parameter tuning set and used the rest as the test set.", "labels": [], "entities": []}, {"text": "Rather than training once on a distinct training set, all our experiment results are based on 10-fold cross validation on the test set, (1191 Spanish documents, 2364 English documents; see for the distribution of event mentions).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Counts of Temporal Status Labels in EventStatus.", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9455775618553162}]}, {"text": " Table 6: Experimental Results on English Data. Each cell shows Recall/Precision/F-score.", "labels": [], "entities": [{"text": "English Data", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.8754323124885559}, {"text": "Recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9972163438796997}, {"text": "Precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.6309528946876526}, {"text": "F-score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.6969243884086609}]}, {"text": " Table 7: Experimental Results on Spanish Data. Each cell shows Recall/Precision/F-score.", "labels": [], "entities": [{"text": "Spanish Data", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9388307929039001}, {"text": "Recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9981741905212402}, {"text": "Precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.7265371680259705}, {"text": "F-score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.8268680572509766}]}, {"text": " Table 8: Confusion Matrices for TIPSem (with transitivity).", "labels": [], "entities": [{"text": "TIPSem", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.6166747212409973}]}]}