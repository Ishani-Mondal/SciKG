{"title": [{"text": "Structured prediction models for RNN based sequence labeling in clinical text", "labels": [], "entities": [{"text": "Structured prediction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7814619541168213}, {"text": "RNN based sequence labeling", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8739187568426132}]}], "abstractContent": [{"text": "Sequence labeling is a widely used method for named entity recognition and information extraction from unstructured natural language data.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9239960014820099}, {"text": "named entity recognition", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.6951959033807119}, {"text": "information extraction from unstructured natural language data", "start_pos": 75, "end_pos": 137, "type": "TASK", "confidence": 0.8509874939918518}]}, {"text": "In the clinical domain one major application of sequence labeling involves extraction of relevant entities such as medication , indication, and side-effects from Electronic Health Record Narratives.", "labels": [], "entities": [{"text": "Electronic Health Record Narratives", "start_pos": 162, "end_pos": 197, "type": "DATASET", "confidence": 0.6764778941869736}]}, {"text": "Sequence labeling in this domain presents its own set of challenges and objectives.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9454920291900635}]}, {"text": "In this work we experiment with Conditional Random Field based structured learning models with Recurrent Neural Networks.", "labels": [], "entities": []}, {"text": "We extend the previously studied CRF-LSTM model with explicit modeling of pairwise potentials.", "labels": [], "entities": []}, {"text": "We also propose an approximate version of skip-chain CRF inference with RNN potentials.", "labels": [], "entities": []}, {"text": "We use these methods 1 for structured prediction in order to improve the exact phrase detection of clinical entities.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.7386355996131897}, {"text": "phrase detection of clinical entities", "start_pos": 79, "end_pos": 116, "type": "TASK", "confidence": 0.8181707084178924}]}], "introductionContent": [{"text": "Patient data collected by hospitals falls into two categories, structured data and unstructured natural language texts.", "labels": [], "entities": []}, {"text": "It has been shown that natural text clinical documents such as discharge summaries, progress notes, etc are rich sources of medically relevant information like adverse drug events, medication prescriptions, diagnosis information etc.", "labels": [], "entities": []}, {"text": "Information extracted from these natural text documents can be useful fora multitude of purposes ranging Code is available at https://github.com/abhyudaynj/LSTM-CRF-models from drug efficacy analysis to adverse effect surveillance.", "labels": [], "entities": []}, {"text": "A widely used method for Information Extraction from natural text documents involves treating the text as a sequence of tokens.", "labels": [], "entities": [{"text": "Information Extraction from natural text documents", "start_pos": 25, "end_pos": 75, "type": "TASK", "confidence": 0.8854648868242899}]}, {"text": "This format allows sequence labeling algorithms to label the relevant information that should be extracted.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.6543448716402054}]}, {"text": "Several sequence labeling algorithms such as Conditional Random Fields (CRFs), Hidden Markov Models (HMMs), Neural Networks have been used for information extraction from unstructured text.", "labels": [], "entities": [{"text": "information extraction from unstructured text", "start_pos": 143, "end_pos": 188, "type": "TASK", "confidence": 0.8665567636489868}]}, {"text": "CRFs and HMMs are probabilistic graphical models that have a rich history of Natural Language Processing (NLP) related applications.", "labels": [], "entities": []}, {"text": "These methods try to jointly infer the most likely label sequence fora given sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use an annotated corpus of 1154 English Electronic Health Records from cancer patients.", "labels": [], "entities": [{"text": "annotated corpus of 1154 English Electronic Health Records from cancer patients", "start_pos": 10, "end_pos": 89, "type": "DATASET", "confidence": 0.7859622619368813}]}, {"text": "Each note was annotated 2 by two annotators who label clinical entities into several categories.", "labels": [], "entities": []}, {"text": "These categories can be broadly divided into two groups, Clinical Events and Attributes.", "labels": [], "entities": []}, {"text": "Clinical events include any specific event that causes or might contribute to a change in a patient's medical status.", "labels": [], "entities": []}, {"text": "Attributes are phrases that describe certain important properties about the events.", "labels": [], "entities": []}, {"text": "The annotation guidelines can be found at https://github.com/abhyudaynj/LSTM-CRFmodels/blob/master/annotation.md Clinical Event categories in this corpus are Adverse Drug Event (ADE), Drugname , Indication and Other Sign Symptom and Diseases (Other SSD).", "labels": [], "entities": []}, {"text": "ADE, Indication and Other SSD are events having a common vocabulary of Sign, Symptoms and Diseases (SSD).", "labels": [], "entities": [{"text": "Sign, Symptoms and Diseases (SSD)", "start_pos": 71, "end_pos": 104, "type": "TASK", "confidence": 0.6007368564605713}]}, {"text": "They can be differentiated based on the context that they are used in.", "labels": [], "entities": []}, {"text": "A certain SSD should be labeled as ADE if it can be manually identified as aside effect of a drug based on the evidence in the clinical note.", "labels": [], "entities": []}, {"text": "It is an Indication if it is an affliction that a doctor is actively treating with a medication.", "labels": [], "entities": [{"text": "Indication", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.9097021222114563}]}, {"text": "Any other SSD that does not fall into the above two categories ( for e.g. an SSD in patients history) is labeled as Other SSD.", "labels": [], "entities": []}, {"text": "Drugname event labels any medication or procedure that a physician prescribes.", "labels": [], "entities": []}, {"text": "The attribute categories contain the following properties, Severity , Route, Frequency, Duration and Dosage.", "labels": [], "entities": [{"text": "Route", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9487911462783813}, {"text": "Frequency", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9588383436203003}, {"text": "Duration", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9777237772941589}, {"text": "Dosage", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9534458518028259}]}, {"text": "Severity is an attribute of the SSD event types , used to label the severity a disease or symptom.", "labels": [], "entities": []}, {"text": "Route, Frequency, Duration and Dosage are attributes of Drugname.", "labels": [], "entities": [{"text": "Route", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8412360548973083}, {"text": "Frequency", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.8829360604286194}, {"text": "Duration", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.98816978931427}, {"text": "Dosage", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9142313003540039}]}, {"text": "They are used to label the medication method, frequency of dosage, duration of dosage, and the dosage quantity respectively.", "labels": [], "entities": [{"text": "duration", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9878309369087219}]}, {"text": "The annotation statistics of the corpus are provided in the.", "labels": [], "entities": []}, {"text": "Each document is split into separate sentences and the sentences are tokenized into individual word and special character tokens.", "labels": [], "entities": []}, {"text": "The models operate on the tokenized sentences.", "labels": [], "entities": []}, {"text": "In order to accelerate the training procedure, all LSTM models use batch-wise training using a batch of 64 sentences.", "labels": [], "entities": []}, {"text": "In order to do this, we restricted the sentence length to 50 tokens.", "labels": [], "entities": []}, {"text": "All sentences longer than 50 tokens were split into shorter size samples, and shorter sentences were prepadded with masks.", "labels": [], "entities": []}, {"text": "The CRF baseline model(3.5) does not use batch training and so the sentences were used unaltered.", "labels": [], "entities": [{"text": "CRF baseline", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8957648873329163}]}, {"text": "The first layer for all LSTM models was a 200 dimensional word embedding layer.", "labels": [], "entities": []}, {"text": "In order to improve performance, we initialized embedding layer values in these models with a skip-gram word embedding ().", "labels": [], "entities": []}, {"text": "The skip-gram embedding was calculated using a combined corpus of PubMed open access articles, English Wikipedia and an unlabeled corpus of around hundred thousand Electronic Health Records.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 95, "end_pos": 112, "type": "DATASET", "confidence": 0.8560642600059509}]}, {"text": "The EHRs used in the annotated corpus are not in this unlabeled EHR corpus.", "labels": [], "entities": [{"text": "EHR corpus", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.8975566625595093}]}, {"text": "This embedding is also used to provide word vector representation to the CRF baseline model.", "labels": [], "entities": [{"text": "word vector representation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.6515490512053171}]}, {"text": "The bidirectional LSTM layer which outputs \u03c9(x) contains LSTM neurons with a hidden size ranging from 200 to 250.", "labels": [], "entities": []}, {"text": "This hidden size is kept variable in order to control for the number of trainable parameters between different LSTM based models.", "labels": [], "entities": []}, {"text": "This helps ensure that the improved performance in these models is only because of the modified model structure, and not an increase in trainable parameters.", "labels": [], "entities": []}, {"text": "The hidden size is varied in such away that the number of trainable parameters are close to 3.55 million parameters.", "labels": [], "entities": []}, {"text": "Therefore, the Approx skip chain CRF has 200 hidden layer size, while standard Bi-LSTM model has 250 hidden layer.", "labels": [], "entities": [{"text": "Approx skip chain CRF", "start_pos": 15, "end_pos": 36, "type": "DATASET", "confidence": 0.6659635305404663}]}, {"text": "Since the \u03c9(x) layer is bidirectional, this effectively means that the Bi-LSTM model has 500 hidden layer size, while Approx skip chain CRF model has 400 dimensional hidden layer.", "labels": [], "entities": []}, {"text": "We use dropout () with a probability of 0.50 in all LSTM models in order to improve regularization performance.", "labels": [], "entities": []}, {"text": "We also use batch norm) between layers wherever possible in order to accelerate training.", "labels": [], "entities": []}, {"text": "All RNN models are trained in an end-to-end fashion using Adagrad) with momentum.", "labels": [], "entities": []}, {"text": "The CRF model was trained using L-BFGS with L2 regularization.", "labels": [], "entities": []}, {"text": "We use Begin Inside Outside (BIO) label modifiers for models that use CRF objective.", "labels": [], "entities": []}, {"text": "We use ten-fold cross validation for our results.", "labels": [], "entities": []}, {"text": "The documents are divided into training and test documents.", "labels": [], "entities": []}, {"text": "From each training set fold, 20% of the sentences form the validation set which is used for model evaluation during training and for early stopping.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 133, "end_pos": 147, "type": "TASK", "confidence": 0.6175025254487991}]}, {"text": "We report the word based and exact phrase match based micro-averaged recall, precision and F-score.", "labels": [], "entities": [{"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9722762703895569}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9996020197868347}, {"text": "F-score", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.9979678988456726}]}, {"text": "Exact phrase match based evaluation is calculated on a per phrase basis, and considers a phrase as positively labeled only if the phrase exactly matches the true boundary and label of the reference phrase.", "labels": [], "entities": []}, {"text": "Word based evaluation metric is calculated on labels of individual words.", "labels": [], "entities": []}, {"text": "A word's predicted label is considered as correct if it matches the reference label, irrespective of whether the remaining words in its phrase are labeled correctly.", "labels": [], "entities": []}, {"text": "Word based evaluation is a more relaxed metric than phrase based evaluation.", "labels": [], "entities": [{"text": "Word based evaluation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5819433927536011}]}], "tableCaptions": [{"text": " Table 1: Annotation statistics for the corpus.", "labels": [], "entities": []}, {"text": " Table 2: Cross validated micro-average of Precision, Recall and F-score for all clinical tags", "labels": [], "entities": [{"text": "Precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9977788329124451}, {"text": "Recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9808716773986816}, {"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9928479194641113}]}]}