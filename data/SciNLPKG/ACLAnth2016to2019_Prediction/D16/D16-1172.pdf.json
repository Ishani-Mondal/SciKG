{"title": [{"text": "Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification", "labels": [], "entities": [{"text": "Document-Level Sentiment Classification", "start_pos": 50, "end_pos": 89, "type": "TASK", "confidence": 0.7185330589612325}]}], "abstractContent": [{"text": "Recently, neural networks have achieved great success on sentiment classification due to their ability to alleviate feature engineering.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.9783675968647003}, {"text": "feature engineering", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7282232642173767}]}, {"text": "However , one of the remaining challenges is to model long texts in document-level sentiment classification under a recurrent architecture because of the deficiency of the memory unit.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 68, "end_pos": 107, "type": "TASK", "confidence": 0.7073002556959788}]}, {"text": "To address this problem, we present a Cached Long Short-Term Memory neural networks (CLSTM) to capture the overall semantic information in long texts.", "labels": [], "entities": []}, {"text": "CLSTM introduces a cache mechanism, which divides memory into several groups with different forgetting rates and thus enables the network to keep sentiment information better within a recurrent unit.", "labels": [], "entities": [{"text": "CLSTM", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8411992788314819}]}, {"text": "The proposed CLSTM outperforms the state-of-the-art models on three publicly available document-level sentiment analysis datasets.", "labels": [], "entities": [{"text": "document-level sentiment analysis", "start_pos": 87, "end_pos": 120, "type": "TASK", "confidence": 0.6511421104272207}]}], "introductionContent": [{"text": "Sentiment classification is one of the most widely used natural language processing techniques in many areas, such as E-commerce websites, online social networks, political orientation analyses, etc.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9281704127788544}, {"text": "political orientation analyses", "start_pos": 163, "end_pos": 193, "type": "TASK", "confidence": 0.7436608076095581}]}, {"text": "Recently, deep learning approaches ( have gained encouraging results on sentiment classification, which frees researchers from handcrafted feature engineering.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.9726711213588715}]}, {"text": "Among these methods, Recurrent Neural Networks (RNNs) are one of the most * Corresponding author.", "labels": [], "entities": []}, {"text": "prevalent architectures because of the ability to handle variable-length texts.", "labels": [], "entities": []}, {"text": "Sentence-or paragraph-level sentiment analysis expects the model to extract features from limited source of information, while document-level sentiment analysis demands more on selecting and storing global sentiment message from long texts with noises and redundant local pattern.", "labels": [], "entities": [{"text": "Sentence-or paragraph-level sentiment analysis", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7655633315443993}, {"text": "document-level sentiment analysis", "start_pos": 127, "end_pos": 160, "type": "TASK", "confidence": 0.7470787366231283}]}, {"text": "Simple RNNs are not powerful enough to handle the overflow and to pickup key sentiment messages from relatively far time-steps . Efforts have been made to solve such a scalability problem on long texts by extracting semantic information hierarchically, which first obtain sentence representations and then combine them to generate high-level document embeddings.", "labels": [], "entities": []}, {"text": "However, some of these solutions either rely on explicit a priori structural assumptions or discard the order information within a sentence, which are vulnerable to sudden change or twists in texts especially a long-range one).", "labels": [], "entities": []}, {"text": "Recurrent models match people's intuition of reading word byword and are capable to model the intrinsic relations between sentences.", "labels": [], "entities": []}, {"text": "By keeping the word order, RNNs could extract the sentence representation implicitly and meanwhile analyze the semantic meaning of a whole document without any explicit boundary.", "labels": [], "entities": []}, {"text": "Partially inspired by neural structure of human brain and computer system architecture, we present the Cached Long Short-Term Memory neural networks (CLSTM) to capture the long-range sentiment information.", "labels": [], "entities": []}, {"text": "In the dual store memory model proposed by, memories can reside in the short-term \"buffer\" fora limited time while they are simultaneously strengthening their associations in long-term memory.", "labels": [], "entities": []}, {"text": "Accordingly, CLSTM equips a standard LSTM with a similar cache mechanism, whose internal memory is divided into several groups with different forgetting rates.", "labels": [], "entities": [{"text": "forgetting", "start_pos": 142, "end_pos": 152, "type": "METRIC", "confidence": 0.9467633366584778}]}, {"text": "A group with high forgetting rate plays a role as a cache in our model, bridging and transiting the information to groups with relatively lower forgetting rates.", "labels": [], "entities": []}, {"text": "With different forgetting rates, CLSTM learns to capture, remember and forget semantics information through a very long distance.", "labels": [], "entities": []}, {"text": "Our main contributions are as follows: \u2022 We introduce a cache mechanism to diversify the internal memory into several distinct groups with different memory cycles by squashing their forgetting rates.", "labels": [], "entities": [{"text": "forgetting", "start_pos": 182, "end_pos": 192, "type": "METRIC", "confidence": 0.9181784987449646}]}, {"text": "As a result, our model can capture the local and global emotional information, thereby better summarizing and analyzing sentiment on long texts in an RNN fashion.", "labels": [], "entities": [{"text": "summarizing and analyzing sentiment on long texts", "start_pos": 94, "end_pos": 143, "type": "TASK", "confidence": 0.7650883112634931}]}, {"text": "\u2022 Benefiting from long-term memory unit with a low forgetting rate, we could keep the gradient stable in the long back-propagation process.", "labels": [], "entities": [{"text": "forgetting rate", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.854089766740799}]}, {"text": "Hence, our model could converge faster than a standard LSTM.", "labels": [], "entities": []}, {"text": "\u2022 Our model outperforms state-of-the-art methods by a large margin on three document-level datasets.", "labels": [], "entities": []}, {"text": "It worth noticing that some of the previous methods have utilized extra user and product information.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we study the empirical result of our model on three datasets for document-level sentiment classification.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 82, "end_pos": 121, "type": "TASK", "confidence": 0.7614809970060984}]}, {"text": "Results show that the proposed model outperforms competitor models from several aspects when modelling long texts.", "labels": [], "entities": []}, {"text": "Most existing datasets for sentiment classification such as Stanford Sentiment Treebank () are composed of short paragraphs with several sentences, which cannot evaluate the effectiveness of the model under the circumstance of encoding long texts.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.9673982262611389}, {"text": "Stanford Sentiment Treebank", "start_pos": 60, "end_pos": 87, "type": "DATASET", "confidence": 0.9047277768452963}]}, {"text": "We evaluate our model on three popular real-world datasets, Yelp 2013, Yelp 2014 and IMDB.", "labels": [], "entities": [{"text": "Yelp 2013", "start_pos": 60, "end_pos": 69, "type": "DATASET", "confidence": 0.9194636046886444}, {"text": "Yelp", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.8058914542198181}, {"text": "IMDB", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.9215819239616394}]}, {"text": "shows the statistical information of the three datasets.", "labels": [], "entities": []}, {"text": "All these datasets can be publicly accessed . We pre-process and split the datasets in the same way as did.", "labels": [], "entities": []}, {"text": "\u2022 Yelp 2013 and Yelp 2014 are review datasets derived from Yelp Dataset Challenge 2 of year 2013 and 2014 respectively.", "labels": [], "entities": [{"text": "Yelp 2013", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.8859128654003143}, {"text": "Yelp Dataset Challenge 2", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.927440732717514}]}, {"text": "The sentiment polarity of each review is 1 star to 5 stars, which reveals the consumers' attitude and opinion towards the restaurants.", "labels": [], "entities": []}, {"text": "\u2022 IMDB is a popular movie review dataset consists of 84919 movie reviews ranging from 1 to 10 ().", "labels": [], "entities": [{"text": "IMDB", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.6826390624046326}, {"text": "movie review dataset", "start_pos": 20, "end_pos": 40, "type": "DATASET", "confidence": 0.5976262986660004}]}, {"text": "Average length of each review is 394.6 words, which is much larger than the length of two Yelp review datasets.", "labels": [], "entities": [{"text": "Yelp review datasets", "start_pos": 90, "end_pos": 110, "type": "DATASET", "confidence": 0.9009856581687927}]}, {"text": "We use Accuracy (Acc.) and MSE as evaluation metrics for sentiment classification.", "labels": [], "entities": [{"text": "Accuracy (Acc.)", "start_pos": 7, "end_pos": 22, "type": "METRIC", "confidence": 0.8962740749120712}, {"text": "sentiment classification", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.9538100957870483}]}, {"text": "Accuracy is a standard metric to measure the overall classification result and Mean Squared Error (MSE) is used to figure out the divergences between predicted sentiment labels and the ground truth ones.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9936947226524353}, {"text": "Mean Squared Error (MSE)", "start_pos": 79, "end_pos": 103, "type": "METRIC", "confidence": 0.964890867471695}]}], "tableCaptions": [{"text": " Table 1: Statistics of the three datasets used in this paper. The rating scale (Class) of Yelp2013 and Yelp2014  range from 1 to 5 and that of IMDB ranges from 1 to 10. Words/Doc is the average length of a sample and  Sents/Doc is the average number of sentences in a document.", "labels": [], "entities": [{"text": "Yelp2013", "start_pos": 91, "end_pos": 99, "type": "DATASET", "confidence": 0.9264614582061768}, {"text": "Yelp2014", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.7985486388206482}, {"text": "IMDB", "start_pos": 144, "end_pos": 148, "type": "DATASET", "confidence": 0.8195144534111023}]}, {"text": " Table 2: Sentiment classification results of our model against competitor models on IMDB, Yelp 2014 and  Yelp 2013. Evaluation metrics are classification accuracy (Acc.) and MSE. Models with * use user and  product information as additional features. Best results in each group are in bold.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8928104043006897}, {"text": "IMDB", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.9624282121658325}, {"text": "Yelp", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8204275965690613}, {"text": "Yelp 2013", "start_pos": 106, "end_pos": 115, "type": "DATASET", "confidence": 0.8369521200656891}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.7860471606254578}, {"text": "Acc.", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.9511853456497192}, {"text": "MSE", "start_pos": 175, "end_pos": 178, "type": "METRIC", "confidence": 0.9340632557868958}]}, {"text": " Table 3: Optimal hyper-parameter configuration for  three datasets.", "labels": [], "entities": []}]}