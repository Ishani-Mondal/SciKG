{"title": [{"text": "Neural Generation of Regular Expressions from Natural Language with Minimal Domain Knowledge", "labels": [], "entities": [{"text": "Neural Generation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8229245245456696}]}], "abstractContent": [{"text": "This paper explores the task of translating natural language queries into regular expressions which embody their meaning.", "labels": [], "entities": []}, {"text": "In contrast to prior work, the proposed neural model does not utilize domain-specific crafting, learning to translate directly from a parallel corpus.", "labels": [], "entities": []}, {"text": "To fully explore the potential of neural models , we propose a methodology for collecting a large corpus 1 of regular expression, natural language pairs.", "labels": [], "entities": []}, {"text": "Our resulting model achieves a performance gain of 19.6% over previous state-of-the-art models.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper explores the task of translating natural language text queries into regular expressions which embody their meaning.", "labels": [], "entities": [{"text": "translating natural language text queries", "start_pos": 32, "end_pos": 73, "type": "TASK", "confidence": 0.8008825659751893}]}, {"text": "Regular expressions are built into many application interfaces, yet most users of these applications have difficulty writing them).", "labels": [], "entities": []}, {"text": "Thus a system for automatically generating regular expressions from natural language would be useful in many contexts.", "labels": [], "entities": []}, {"text": "Furthermore, such technologies can ultimately scale to translate into other formal representations, such as program scripts.", "labels": [], "entities": []}, {"text": "Prior work has demonstrated the feasibility of this task.", "labels": [], "entities": []}, {"text": "proposed a model that learns to perform the task from a parallel corpus of regular expressions and the text descriptions.", "labels": [], "entities": []}, {"text": "To account for the given representational disparity between formal regular expressions and natural language, their model utilizes a domain specific The corpus and code used in this paper is available at https: //github.com/nicholaslocascio/deep-regex component which computes the semantic equivalence between two regular expressions.", "labels": [], "entities": []}, {"text": "Since their model relies heavily on this component, it cannot be readily applied to other formal representations where such semantic equivalence calculations are not possible.", "labels": [], "entities": []}, {"text": "In this paper, we reexamine the need for such specialized domain knowledge for this task.", "labels": [], "entities": []}, {"text": "Given the same parallel corpus used in, we use an LSTM-based sequence to sequence neural network to perform the mapping.", "labels": [], "entities": []}, {"text": "Our model does not utilize semantic equivalence in any form, or make any other special assumptions about the formalism.", "labels": [], "entities": []}, {"text": "Despite this and the relatively small size of the original dataset (824 examples), our neural model exhibits a small 0.1% boost inaccuracy.", "labels": [], "entities": []}, {"text": "To further explore the power of neural networks, we created a much larger public dataset, NL-RX.", "labels": [], "entities": []}, {"text": "Since creation of regular expressions requires specialized knowledge, standard crowd-sourcing methods are not applicable here.", "labels": [], "entities": []}, {"text": "Instead, we employ a two-step generate-and-paraphrase procedure that circumvents this problem.", "labels": [], "entities": []}, {"text": "During the generate step, we use a small but expansive manually-crafted grammar that translates regular expression into natural language.", "labels": [], "entities": []}, {"text": "In the paraphrase step, we rely on crowd-sourcing to paraphrase these rigid descriptions into more natural and fluid descriptions.", "labels": [], "entities": []}, {"text": "Using this methodology, we have constructed a corpus of 10,000 regular expressions, with corresponding verbalizations.", "labels": [], "entities": []}, {"text": "Our results demonstrate that our sequence to sequence model significantly outperforms the domain specific technique on the larger dataset, reaching again of 19.6% over of the state-of-the-art technique.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets We split the 10,000 regexp and description pairs in NL-RX into 65% train, 10% dev, and 25% test sets.", "labels": [], "entities": [{"text": "NL-RX", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.9498209953308105}]}, {"text": "In addition, we also evaluate our model on the dataset used by, although it contains far fewer data points.", "labels": [], "entities": []}, {"text": "We use the 75/25 train/test split used in their work in order directly compare our performance to theirs.", "labels": [], "entities": []}, {"text": "Training We perform a hyper-parameter gridsearch (on the dev set), to determine our model hyper-parameters: learning-rate = 1.0, encoderdepth = 2, decoder-depth = 2, batch size = 32, dropout = 0.25.", "labels": [], "entities": []}, {"text": "We use a Torch () implementation of attention sequence to sequence networks from.", "labels": [], "entities": []}, {"text": "We train our models on the train set for 20 epochs, and choose the model with the best average loss on the dev set.", "labels": [], "entities": []}, {"text": "Evaluation Metric To accurately evaluate our model, we perform a functional equality check called DFA-Equal.", "labels": [], "entities": []}, {"text": "We employ functional equality because there are many ways to write equivalent regular expressions.", "labels": [], "entities": []}, {"text": "For example, (a|b) is functionally equivalent to (b|a), despite their string representations differing.", "labels": [], "entities": []}, {"text": "We report DFA-Equal accuracy as our model's evaluation metric, using's implementation to directly compare our results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.5191487669944763}]}, {"text": "Baselines We compare our model against two baselines: BoW-NN: BoW-NN is a simple baseline that is a Nearest Neighbor classifier using Bag Of Words representation for each natural language description.", "labels": [], "entities": []}, {"text": "For a given test example, it finds the closest cosinesimilar neighbor from the training set and uses the regexp from that example for its prediction.", "labels": [], "entities": []}, {"text": "Semantic-Unify: Our second baseline, SemanticUnify, is the previous state-of-the-art model from, explained above.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: DFA-Equal accuracy on different datasets.  KB13: Dataset from Kushman and Barzilay(2013), NL- RX-Synth: NL Dataset with original synthetic descrip- tions, NL-RX-Turk: NL Dataset with Mechanical Turk  paraphrased descriptions. Best scores are in bold.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.897606372833252}]}]}