{"title": [{"text": "A Graph Degeneracy-based Approach to Keyword Extraction *", "labels": [], "entities": [{"text": "Keyword Extraction", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7593411207199097}]}], "abstractContent": [{"text": "We operate a change of paradigm and hypothesize that keywords are more likely to be found among influential nodes of a graph-of-words rather than among its nodes high on eigenvector-related centrality measures.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we introduce unsuper-vised techniques that capitalize on graph de-generacy.", "labels": [], "entities": []}, {"text": "Our methods strongly and significantly outperform all baselines on two datasets (short and medium size documents), and reach best performance on the third one (long documents).", "labels": [], "entities": []}], "introductionContent": [{"text": "Keyword extraction is a central task in NLP.", "labels": [], "entities": [{"text": "Keyword extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8825022876262665}]}, {"text": "It finds applications from information retrieval (notably web search) to text classification, summarization, and visualization.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.71456478536129}, {"text": "text classification", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.8084398210048676}, {"text": "summarization", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9887800216674805}]}, {"text": "In this study, we focus on the task of unsupervised single-document keyword extraction.", "labels": [], "entities": [{"text": "single-document keyword extraction", "start_pos": 52, "end_pos": 86, "type": "TASK", "confidence": 0.6836647888024648}]}, {"text": "Following (), we concentrate on keywords only, letting the task of keyphrase reconstruction as a post-processing step.", "labels": [], "entities": [{"text": "keyphrase reconstruction", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.804542064666748}]}, {"text": "More precisely, while we capitalize on a graph representation of text like several previous approaches, we deviate from them by making the assumption that keywords are not found among prestigious nodes (or more generally, nodes high on eigenvector-related centrality metrics), but rather among influential nodes.", "labels": [], "entities": []}, {"text": "Those nodes may not have many important connections (like their prestigious counterparts), but they are ideally placed at the core * This research is supported in part by the OpenPaaS::NG project. of the network.", "labels": [], "entities": []}, {"text": "In other words, this switches the objective from capturing the quality and quantity of single node connections, to taking into account the density and cohesiveness of groups of nodes.", "labels": [], "entities": []}, {"text": "To operate this change of paradigm, we propose several algorithms that leverage the concept of graph degeneracy ().", "labels": [], "entities": []}, {"text": "Our contributions are threefold: (1) we propose new unsupervised keyword extraction techniques that reach state-of-the art performance, (2) we apply the K-truss algorithm to the task of keyword extraction for the first time, and (3) we report new insights on the interplay between window size, graphof-words structure, and performance.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7535384595394135}, {"text": "keyword extraction", "start_pos": 186, "end_pos": 204, "type": "TASK", "confidence": 0.7522639632225037}]}], "datasetContent": [{"text": "To evaluate performance, we used three standard, publicly available datasets featuring documents of various types and sizes.", "labels": [], "entities": []}, {"text": "shows the distributions of document size and manually assigned keywords for each dataset.", "labels": [], "entities": []}, {"text": "The Hulth2003 1) dataset contains abstracts drawn from the Inspec database of physics and engineering papers.", "labels": [], "entities": [{"text": "Hulth2003 1) dataset", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.762439414858818}, {"text": "Inspec database of physics and engineering papers", "start_pos": 59, "end_pos": 108, "type": "DATASET", "confidence": 0.9363195810999189}]}, {"text": "Following our baselines, we used the 500 documents in the validation set and the \"uncontrolled\" keywords assigned by human annotators.", "labels": [], "entities": []}, {"text": "The mean document size is 120 words and on average, 21 keywords (in terms of unigrams) are available for each document.", "labels": [], "entities": []}, {"text": "We also used the training set of Marujo2012 1 , containing 450 web news stories of about 440 words on average, covering 10 different topics from art and culture to business, sport, and technology).", "labels": [], "entities": [{"text": "Marujo2012 1", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.8032998144626617}]}, {"text": "For each story, the keyphrases assigned by at least 9 out of 10 Amazon Mechanical Turkers are provided as gold standard.", "labels": [], "entities": []}, {"text": "After splitting the keyphrases into unigrams, this makes for an average of 68 keywords per document, which is much higher than for the two other datasets, even the one comprising long documents (Semeval, see next).", "labels": [], "entities": []}, {"text": "The Semeval 2 dataset () offers parsed scientific papers collected from the ACM Digital Library.", "labels": [], "entities": [{"text": "Semeval 2 dataset", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.6358565886815389}, {"text": "ACM Digital Library", "start_pos": 76, "end_pos": 95, "type": "DATASET", "confidence": 0.960033098856608}]}, {"text": "More precisely, we used the 100 articles in the test set and the corresponding authorand-reader-assigned keyphrases.", "labels": [], "entities": []}, {"text": "Each document is approximately 1,860 words in length and is associated with about 24 keywords.", "labels": [], "entities": []}, {"text": "In Marujo2012, the keywords were assigned in an extractive manner, but many of them are verbs.", "labels": [], "entities": [{"text": "Marujo2012", "start_pos": 3, "end_pos": 13, "type": "DATASET", "confidence": 0.9114630222320557}]}, {"text": "In the two other datasets, keywords were freely chosen by human coders in an abstractive way and as such, some of them are not present in the original text.", "labels": [], "entities": []}, {"text": "On these datasets, reaching perfect recall is therefore impossible for our methods (and the baselines), which by definition all are extractive.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.919277548789978}]}, {"text": "We computed the standard precision, recall, and F-1 measures for each document and averaged them at the dataset level (macro-averaging).", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9897152781486511}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9975595474243164}, {"text": "F-1", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9976294636726379}]}], "tableCaptions": [{"text": " Table 1: Hulth2003, K-truss, W = 11.  *statistical significance at p < 0.001 with respect to all baselines.   \u2020 baseline systems.", "labels": [], "entities": [{"text": "Hulth2003", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.6184969544410706}, {"text": "statistical significance", "start_pos": 40, "end_pos": 64, "type": "METRIC", "confidence": 0.8979182243347168}]}, {"text": " Table 2: Marujo2012, k-core, W = 13.  *statistical significance at p < 0.001 with respect to all baselines.", "labels": [], "entities": [{"text": "Marujo2012", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.9166053533554077}, {"text": "statistical significance", "start_pos": 40, "end_pos": 64, "type": "METRIC", "confidence": 0.8843984305858612}]}, {"text": " Table 3: Semeval, K-truss, W = 20.  *statistical significance at p < 0.001 w.r.t. main.  \u2020 baseline systems.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 38, "end_pos": 62, "type": "METRIC", "confidence": 0.9127300083637238}]}]}