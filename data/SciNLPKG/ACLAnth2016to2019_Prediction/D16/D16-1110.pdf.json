{"title": [{"text": "Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems", "labels": [], "entities": [{"text": "Sentiment Recognition", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8362522423267365}]}], "abstractContent": [{"text": "In this paper, we describe our approach of enabling an interactive dialogue system to recognize user emotion and sentiment in real-time.", "labels": [], "entities": []}, {"text": "These modules allow otherwise conventional dialogue systems to have \"empathy\" and answer to the user while being aware of their emotion and intent.", "labels": [], "entities": []}, {"text": "Emotion recognition from speech previously consists of feature engineering and machine learning where the first stage causes delay in decoding time.", "labels": [], "entities": [{"text": "Emotion recognition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9305112361907959}]}, {"text": "We describe a CNN model to extract emotion from raw speech input without feature engineering.", "labels": [], "entities": []}, {"text": "This approach even achieves an impressive average of 65.7% accuracy on six emotion categories, a 4.5% improvement when compared to the conventional feature based SVM classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9981489181518555}]}, {"text": "A separate, CNN-based sentiment analysis module recognizes sentiments from speech recognition results, with 82.5 F-measure on human-machine dialogues when trained with out-of-domain data.", "labels": [], "entities": [{"text": "CNN-based sentiment analysis", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6950288613637289}, {"text": "F-measure", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9798597693443298}]}], "introductionContent": [{"text": "Interactive dialogue systems and chatbots have been around fora while.", "labels": [], "entities": []}, {"text": "Some, though not all, systems have statistical and machine learning modules to enable them to improve overtime.", "labels": [], "entities": [{"text": "overtime", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9456984400749207}]}, {"text": "With the pervasiveness of such systems on mobile devices, expectations of user experience have also increased.", "labels": [], "entities": []}, {"text": "We expect human-machine dialogues to get closer to human-human dialogues.", "labels": [], "entities": []}, {"text": "One important factor is that we expect machines to understand our emotions and intent and respond with empathy.", "labels": [], "entities": []}, {"text": "We propose a module of emotion and sentiment recognition for an interactive dialogue system.", "labels": [], "entities": [{"text": "emotion and sentiment recognition", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.6455805450677872}]}, {"text": "This module enables the system to assess the user's current emotional state and sentiment, and thereby decide the appropriate response at every dialogue state.", "labels": [], "entities": []}, {"text": "The dialogue management system handles the mixed-initiative dialogues while taking into account user emotion and sentiment, in addition to query content.", "labels": [], "entities": []}, {"text": "Emotion and sentiment recognition enables our system to handle user queries previously unseen in training data.", "labels": [], "entities": [{"text": "sentiment recognition", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.9037698805332184}]}, {"text": "Positive user queries containing positive emotion and sentiment label would have a positive response, and similarly a negatively labeled statement would have a negative response.", "labels": [], "entities": []}, {"text": "Examples are shown below: User: I lost my job.", "labels": [], "entities": []}, {"text": "Response: Sorry to hear that.", "labels": [], "entities": []}, {"text": "Success is in never giving up.", "labels": [], "entities": []}, {"text": "User: I just graduated from college!", "labels": [], "entities": []}, {"text": "I am happy for you.", "labels": [], "entities": []}, {"text": "User: I went on a vacation last month and it was pretty bad, I lost all my luggage Response: That doesn't sound so good.", "labels": [], "entities": []}, {"text": "Hope your next vacation will be a good one.", "labels": [], "entities": []}, {"text": "User: My last vacation was amazing, I loved it!", "labels": [], "entities": []}, {"text": "Response: That sounds great.", "labels": [], "entities": []}, {"text": "I would like to travel with you.", "labels": [], "entities": []}, {"text": "Meanwhile, dialogue systems like this need to have real-time recognition of user emotion and sentiment.", "labels": [], "entities": []}, {"text": "Previous approaches of emotion recognition from speech involve feature engineering ( as a first step which invariably causes delay in decoding.", "labels": [], "entities": [{"text": "emotion recognition from speech", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.7943440899252892}]}, {"text": "So we are interested in investigating a method to avoid feature engineering and instead use a Convolutional Neural Network to extract emotion from raw audio input directly.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments on emotion recognition with raw audio, we built a dataset from the TED-LIUM corpus release 2 (.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.777742862701416}, {"text": "TED-LIUM corpus release 2", "start_pos": 87, "end_pos": 112, "type": "DATASET", "confidence": 0.9236469268798828}]}, {"text": "It includes 207 hours of speech extracted from 1495 TED talks.", "labels": [], "entities": []}, {"text": "We annotated the data with an existing commercial API followed by manual correction.", "labels": [], "entities": []}, {"text": "We use these 6 categories: criticism, anxiety, anger, loneliness, happiness, and sadness.", "labels": [], "entities": []}, {"text": "We obtained a total of 2389 segments for the criticism category, 3855 for anxiety, 12708 for anger, 3618 for loneliness, 8070 for happy and 1824 for sadness.", "labels": [], "entities": []}, {"text": "The segments have an average length slightly above 13 seconds.", "labels": [], "entities": []}, {"text": "For the speech emotion detection module we setup our experiments as binary classification tasks, in which each segment is classified as either part of a particular emotion category or not.", "labels": [], "entities": [{"text": "speech emotion detection", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.7472309470176697}]}, {"text": "For each category the negative samples were chosen randomly from the clips that did not belong to the positive category.", "labels": [], "entities": []}, {"text": "We took 80% of the data as training set, and 10% each as development and test set.", "labels": [], "entities": []}, {"text": "The development set was used to tune the hyperparameters and determine the early stopping condition.", "labels": [], "entities": []}, {"text": "We implemented our CNN with the THEANO framework: Sentiment analysis result on human-machine dialogue when trained from Twitter and Movie Review dataset.", "labels": [], "entities": [{"text": "THEANO", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9747158288955688}, {"text": "Sentiment analysis", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.9038358628749847}, {"text": "Movie Review dataset", "start_pos": 132, "end_pos": 152, "type": "DATASET", "confidence": 0.9575216770172119}]}, {"text": "We chose rectified linear as the non-linear function for the hidden layers, as it generally provided better performance over other functions.", "labels": [], "entities": []}, {"text": "We used standard backpropagation training, with momentum set to 0.9 and initial learning rate to 10 \u22125 . As a baseline we used a linear-kernel SVM model from the LibSVM (Chang and Lin, 2011) library with the INTERSPEECH 2009 emotion feature set (, extracted with openSMILE ().", "labels": [], "entities": [{"text": "INTERSPEECH 2009 emotion feature set", "start_pos": 208, "end_pos": 244, "type": "DATASET", "confidence": 0.8208322048187255}]}, {"text": "These features are computed from a series of input frames and output a single static summary vector, e.g, the smooth methods, maximum and minimum value, mean value of the features from the frames (.", "labels": [], "entities": []}, {"text": "A similar one-layer CNN setup was used also for the sentiment module, again with rectified linear as the activation function.", "labels": [], "entities": []}, {"text": "As our dataset contains many neutral samples, we trained two distinct CNNs: one for positive sentiment and one for negative, and showed the average results among the two categories.", "labels": [], "entities": []}, {"text": "For each of the two training corpora we took 10% as development set.", "labels": [], "entities": []}, {"text": "We used as baseline a method that uses positive and emotion keywords from the Linguistic Inquiry and Word Count (LIWC 2015) dictionary (Pennebaker et al., 2015).", "labels": [], "entities": [{"text": "Linguistic Inquiry and Word Count (LIWC 2015) dictionary", "start_pos": 78, "end_pos": 134, "type": "TASK", "confidence": 0.6450663119554519}]}], "tableCaptions": [{"text": " Table 1: Accuracy obtained, percentage, in the Convolutional", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993048906326294}, {"text": "Convolutional", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.6158612966537476}]}, {"text": " Table 2: Corpus statistics for text sentiment experiments with CNN.", "labels": [], "entities": [{"text": "text sentiment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7927613258361816}]}, {"text": " Table 3: Sentiment analysis result on human-machine dialogue when trained from Twitter and Movie Review dataset", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9777073562145233}, {"text": "Movie Review dataset", "start_pos": 92, "end_pos": 112, "type": "DATASET", "confidence": 0.9678095976511637}]}]}