{"title": [{"text": "Understanding Negation in Positive Terms Using Syntactic Dependencies", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a two-step procedure to extract positive meaning from verbal negation.", "labels": [], "entities": [{"text": "extract positive meaning from verbal negation", "start_pos": 44, "end_pos": 89, "type": "TASK", "confidence": 0.6921742260456085}]}, {"text": "We first generate potential positive interpretations manipulating syntactic dependencies.", "labels": [], "entities": []}, {"text": "Then, we score them according to their likelihood.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9754670858383179}]}, {"text": "Manual annotations show that positive interpretations are ubiquitous and intuitive to humans.", "labels": [], "entities": []}, {"text": "Experimental results show that dependencies are better suited than semantic roles for this task, and automation is possible.", "labels": [], "entities": []}], "introductionContent": [{"text": "Negation is a complex phenomenon present in all human languages, allowing for the uniquely human capacities of denial, contradiction, misrepresentation, lying, and irony.", "labels": [], "entities": []}, {"text": "Despite negation always being marked-in the absence of a negation cue, statements are positiveacquiring and understanding sentences that contain negation is more challenging than those that do not.", "labels": [], "entities": []}, {"text": "Children acquire negation after learning to communicate, and adults take longer to process negated statements than positive ones.", "labels": [], "entities": []}, {"text": "In any given language, humans communicate in positive terms most of the time, and use negation to express something unusual or an exception.", "labels": [], "entities": []}, {"text": "Albeit most sentences are affirmative, negation is ubiquitous: In scientific papers, 13.76% of statements contain a negation (; in product reviews, 19% (; and in Conan Doyle stories, 22.23%).", "labels": [], "entities": []}, {"text": "From a theoretical point of view, it is accepted that negation conveys positive meaning).", "labels": [], "entities": []}, {"text": "For example, when reading (1) John didn't order the right parts, humans intuitively understand that (1a) John ordered something, or more specifically, (1b) John ordered the wrong parts.", "labels": [], "entities": []}, {"text": "Determining which words are intended to be negated-identifying the foci of negation, thereby revealing positive interpretations-is challenging.", "labels": [], "entities": []}, {"text": "First, as exemplified in (1a, 1b), there is a granularity continuum yielding interpretations that entail each other, e.g., (1b) entails (1a).", "labels": [], "entities": []}, {"text": "Second, a single negation often yields several positive interpretations, e.g., from (2) John doesn't eat meat, we can extract that (2a) John eats something other than meat and (2b) Some people eat meat, but not John.", "labels": [], "entities": []}, {"text": "This paper presents a methodology to extract positive interpretations from verbal negation.", "labels": [], "entities": [{"text": "extract positive interpretations from verbal negation", "start_pos": 37, "end_pos": 90, "type": "TASK", "confidence": 0.6360709468523661}]}, {"text": "The main contributions are: (1) deterministic procedure to generate potential interpretations by manipulating syntactic dependencies; (2) analysis showing that dependencies yield finer-grained interpretations and better results than previous work using semantic roles; (3) a corpus of negations and their positive interpretations; 1 and (4) experimental results with gold-standard and predicted linguistic information.", "labels": [], "entities": []}], "datasetContent": [{"text": "We report results obtained with several combinations of features in.", "labels": [], "entities": []}, {"text": "We detail results obtained with features extracted from gold-standard and predicted linguistic annotations (part-of-speech tags and syntactic dependencies) as annotated in the gold and auto files from the CoNLL-2011 Shared Task release of).", "labels": [], "entities": [{"text": "CoNLL-2011 Shared Task release", "start_pos": 205, "end_pos": 235, "type": "DATASET", "confidence": 0.8471301198005676}]}, {"text": "All models are trained with gold-standard linguistic annotations, and tested with either gold-standard or predicted linguistic annotations.", "labels": [], "entities": []}, {"text": "Testing with gold-standard POS tags and syntactic dependencies.", "labels": [], "entities": []}, {"text": "Training with the word form of the negation mark is virtually useless, it yields a Pearson correlation of \u22120.109.", "labels": [], "entities": [{"text": "negation mark", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.8764719665050507}, {"text": "Pearson correlation", "start_pos": 83, "end_pos": 102, "type": "METRIC", "confidence": 0.9695971608161926}]}, {"text": "Basic features (negation mark, verb and flag indicating coarseor fine-grained interpretation) are also ineffective to score potential interpretations (Pearson: 0.033).", "labels": [], "entities": []}, {"text": "Including features derived from the syntactic path yields higher correlation, 0.474, even though these features only capture the syntactic relationship between the focus from which the interpretation was generated and the verb.", "labels": [], "entities": [{"text": "correlation", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9689498543739319}]}, {"text": "Finally, adding focus features yields the best results (Pearson: 0.53, +11.8%).", "labels": [], "entities": [{"text": "Pearson", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9957116842269897}]}, {"text": "Testing with predicted POS tags and syntactic dependencies.", "labels": [], "entities": []}, {"text": "We selected 20% of positive interpretations in our corpus as test instances, totalling 379 interpretations (Section 6).", "labels": [], "entities": []}, {"text": "When executing the procedure to generate potential interpretations (Section 4.1) with predicted linguistic information, however, we are unable to generate all of them due to incorrect and missing syntactic dependencies.", "labels": [], "entities": []}, {"text": "Specifically, 352 of the 379 interpretations are generated (92.8%).", "labels": [], "entities": []}, {"text": "While we do not generate 7.2% of instances, this percentage is substantially lower than previous work grounded on semantic roles (Section 5.2).", "labels": [], "entities": []}, {"text": "Pearson correlations with predicted linguistic information are calculated using the 352 instances that were also generated with gold dependencies (and thus assigned a score during the manual annotations).", "labels": [], "entities": []}, {"text": "Correlations are slightly higher and follow a similar trend than the correlations obtained with gold-standard linguistic information.", "labels": [], "entities": []}, {"text": "These results should betaken with a grain of salt: the test instances are not exactly the same, and the 352 test instances in this scenario are presumably easier to score than the remainder 27, as dependencies were predicted correctly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Negated statements, all potential positive interpretations automatically generated and their manually assigned scores.", "labels": [], "entities": []}, {"text": " Table 2: Basic corpus analysis. For each dependency, we show", "labels": [], "entities": [{"text": "corpus analysis", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7678452730178833}]}, {"text": " Table 5: Pearson correlations obtained with the test split. Re-", "labels": [], "entities": [{"text": "Pearson correlations", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.9135172367095947}]}]}