{"title": [{"text": "Unsupervised Text Recap Extraction for TV Series", "labels": [], "entities": [{"text": "Unsupervised Text Recap Extraction", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6411565691232681}]}], "abstractContent": [{"text": "Sequences found at the beginning of TV shows help the audience absorb the essence of previous episodes, and grab their attention with upcoming plots.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel task, text recap extraction.", "labels": [], "entities": [{"text": "text recap extraction", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.894594689210256}]}, {"text": "Compared with conventional summarization, text recap extraction captures the duality of sum-marization and plot contingency between adjacent episodes.", "labels": [], "entities": [{"text": "summarization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9862291812896729}, {"text": "text recap extraction", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.8351628581682841}]}, {"text": "We present anew dataset, TVRecap, for text recap extraction on TV shows.", "labels": [], "entities": [{"text": "TVRecap", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.941564679145813}, {"text": "text recap extraction", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8469505310058594}]}, {"text": "We propose an unsupervised model that identifies text recaps based on plot descriptions.", "labels": [], "entities": []}, {"text": "We introduce two contingency factors , concept coverage and sparse reconstruction , that encourage recaps to prompt the up-coming story development.", "labels": [], "entities": []}, {"text": "We also propose a multi-view extension of our model which can incorporate dialogues and synopses.", "labels": [], "entities": []}, {"text": "We conduct extensive experiments on TVRecap, and conclude that our model outperforms summa-rization approaches.", "labels": [], "entities": [{"text": "TVRecap", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9618484973907471}]}], "introductionContent": [{"text": "According to a study by FX Networks, in U.S., the total number of ongoing scripted TV series hit anew high of 409 on broadcast, cable, and streaming in 2015 . Such a large number indicates there are more shows than anyone can realistically watch.", "labels": [], "entities": []}, {"text": "To attract prospective audiences as well as help current viewers recall the key plot when airing new episodes, some TV shows add a clip montage, which is called a recap sequence, at the beginning of new episodes or seasons.", "labels": [], "entities": []}, {"text": "Recaps not only help the audience 1 http://tinyurl.com/jugyyu2 absorb the essence of previous episodes, but also grab people's attention with upcoming plots.", "labels": [], "entities": []}, {"text": "However, creating those recaps for every newly aired episode is labor-intensive and time-consuming.", "labels": [], "entities": []}, {"text": "To our advantage, there are many textual scripts freely available online which describe the events and actions happening during the TV show episodes 2 . These textual scripts contain plot descriptions of the events, dialogues of the actors, and sometimes also the synopsis summarizing the whole episode.", "labels": [], "entities": []}, {"text": "These abundant textual resources enable us to study a novel, yet challenging task: automatic text recap extraction, illustrated in.", "labels": [], "entities": [{"text": "automatic text recap extraction", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.668784499168396}]}, {"text": "The goal of text recap extraction is to identify segments from scripts which both summarize the current episode and prompt the story development of the next episode.", "labels": [], "entities": [{"text": "text recap extraction", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.8214687705039978}]}, {"text": "This unique task brings new technical challenges as it goes beyond summarizing prior TV episodes, by introducing a concept of plot contingency to the upcoming TV episode.", "labels": [], "entities": [{"text": "summarizing prior TV episodes", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.8719909340143204}]}, {"text": "It differs from conventional summarization techniques which do not consider the interconnectivity between neighboring episodes.", "labels": [], "entities": [{"text": "summarization", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.9816514253616333}]}, {"text": "Text recaps should capture the duality of summarization and plot contingency between neighboring episodes.", "labels": [], "entities": [{"text": "summarization", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.9664418697357178}]}, {"text": "To our knowledge, no dataset exists to study this research topic.", "labels": [], "entities": []}, {"text": "In this paper, we present an unsupervised model to automatically extrapolate text recaps of TV shows from plot descriptions.", "labels": [], "entities": []}, {"text": "Since we assume recaps should cover the main plot of the current episode and also prompt the story development of the next episode, our model jointly optimizes these two ob-Boone stares at Sayid and Shannon from behind a tree with a weird look on his face.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collected anew dataset, called TVRecap, for text recap extraction on TV series.", "labels": [], "entities": [{"text": "TVRecap", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9597262144088745}, {"text": "text recap extraction on TV series", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.8612395723660787}]}, {"text": "We gathered and processed scripts, subtitles and synopses from websites 4 as components to build our model upon.", "labels": [], "entities": []}, {"text": "We also established ground truth to help future research on this challenging topic.", "labels": [], "entities": []}, {"text": "TVRecap includes all seasons from the widely-known show \"Lost\" with a total of 106 episodes.", "labels": [], "entities": [{"text": "TVRecap", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9738264083862305}]}, {"text": "Statistics of our dataset are shown in This section describes how textual scripts and synopses are processed, and how we automatically define the ground truth of text recap annotations.", "labels": [], "entities": []}, {"text": "Descriptions, Dialogues and Synopses A script for one TV series episode is a sequence of dialogues interleaved with descriptions (marked by square brackets).", "labels": [], "entities": []}, {"text": "We automatically split the script into descriptions and dialogues.", "labels": [], "entities": []}, {"text": "For each episode, We also downloaded the synopsis, a human-written paragraph summarizing the main plot of the episode.", "labels": [], "entities": []}, {"text": "shows examples of a script and a synopsis from our TVRecap dataset.", "labels": [], "entities": [{"text": "TVRecap dataset", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.9907444417476654}]}, {"text": "(a) Script: containing descriptions and dialogues.", "labels": [], "entities": []}, {"text": "Boone steals the decreasing water supply in a misguided attempt to help everyone, but the survivors turn on him.", "labels": [], "entities": []}, {"text": "A sleep-deprived Jack chases after what appears to be his deceased father in the forests and eventually discovers caves with freshwater.", "labels": [], "entities": []}, {"text": "Jack comes to terms with his role as leader.", "labels": [], "entities": []}, {"text": "In flashbacks, Jack goes to Australia to retrieve his deceased father.", "labels": [], "entities": []}, {"text": "All plot descriptions and dialogues are timealigned automatically using the subtitle files . We first aligned the dialogue sentences from the script with the subtitle files which contain time-stamps (in milliseconds) of the spoken dialogues.", "labels": [], "entities": []}, {"text": "Then we estimated time-stamps of description sentences using surrounding dialogues.", "labels": [], "entities": []}, {"text": "Since descriptions sometimes contain words not relevant to the event, we manually post-processed all descriptions and recap sentences as follows: remove trivial sentences such as \"music on\", (2) remove introductory terms like \"Shot of \", (3) complete missing grammatical components (like omitted subjects) of sentences when possible.", "labels": [], "entities": []}, {"text": "Text Recap Annotations The goal of our ground truth annotation is to identify the text descriptions associated with the TV show recap.", "labels": [], "entities": []}, {"text": "We performed this annotation task in three steps.", "labels": [], "entities": []}, {"text": "First, we automatically extracted the recap sequence, which is a montage of important scenes from previous episodes to inform viewers of what has happened in the show, from the TV show video.", "labels": [], "entities": []}, {"text": "These recap sequences, if available, are always shown at the beginning of TV episodes.", "labels": [], "entities": []}, {"text": "We automatically separated video recap sequences from fulllength video files by detecting a lengthy appearance of black frames in the first several minutes of the episode.", "labels": [], "entities": []}, {"text": "Second, we located the frames of the recap sequences in the videos of previous episodes, and recorded their time-stamps.", "labels": [], "entities": []}, {"text": "Finally, the recap annotations are automatically identified by comparing the video time-stamps with the text description time-stamps.", "labels": [], "entities": []}, {"text": "A description is annotated as part of the recap if at least 4 frames from the video recap are present during this description.", "labels": [], "entities": []}, {"text": "We designed our experiments to evaluate whether our TREM model, by considering contingency between adjacent episodes, can achieve better results than summarization techniques.", "labels": [], "entities": [{"text": "TREM", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.6205350160598755}, {"text": "summarization", "start_pos": 150, "end_pos": 163, "type": "TASK", "confidence": 0.9743012189865112}]}, {"text": "Furthermore, we want to examine how each contingency factor as proposed in Section 4.2 contributes to the system performance.", "labels": [], "entities": []}, {"text": "As our model can integrate multiple views, we want to dissect the effects of using different combinations of three views.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of TVRecap.", "labels": [], "entities": [{"text": "TVRecap", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.9637780785560608}]}, {"text": " Table 2: Experimental results on different methods using descriptions. Contingency-based methods generally outperforms", "labels": [], "entities": []}, {"text": " Table 3: A case study on sparse reconstruction as proposed in Section 4.2.2. Sentences in the first column are reconstructed by", "labels": [], "entities": [{"text": "sparse reconstruction", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.7097737342119217}]}, {"text": " Table 4: Comparison of views in summarization-only TREM", "labels": [], "entities": [{"text": "summarization-only TREM", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.7151566445827484}]}]}